<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 21 Feb 2021 12:38:42 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 21 Feb 2021 12:38:42 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[I made a PRORES-lookalike for Windows]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26191274">thread link</a>) | @CinematicStudio
<br/>
February 19, 2021 | https://cinematicstudio.app/blog/prores.html | <a href="https://web.archive.org/web/*/https://cinematicstudio.app/blog/prores.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://cinematicstudio.app/blog/prores.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26191274</guid>
            <pubDate>Fri, 19 Feb 2021 09:44:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What people don't post on Instagram]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26191095">thread link</a>) | @galfarragem
<br/>
February 19, 2021 | https://durmonski.com/psychology/what-people-dont-post-on-instagram/ | <a href="https://web.archive.org/web/*/https://durmonski.com/psychology/what-people-dont-post-on-instagram/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://durmonski.com/psychology/what-people-dont-post-on-instagram/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26191095</guid>
            <pubDate>Fri, 19 Feb 2021 09:12:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Where Everything Went Wrong: Error Handling and Error Messages in Rust]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 10 (<a href="https://news.ycombinator.com/item?id=26191006">thread link</a>) | @lukastyrychtr
<br/>
February 19, 2021 | https://msirringhaus.github.io/Where-everything-went-wrong/ | <a href="https://web.archive.org/web/*/https://msirringhaus.github.io/Where-everything-went-wrong/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><strong>Today you are frustrated.</strong></p>

<p>This is so annoying. YouÃ¢â‚¬â„¢ve written a Rust crate and now that you want to test it for the very first time, <em>it doesnÃ¢â‚¬â„¢t work!</em></p>

<p>Come on, Rust! How dare you? You promised that once one gets past the compiler, it.<br>
<em>Just.<br>
<strong>Works!</strong></em><br>
And now this!</p>

<p>Ok, ok. You calm yourself down. Lets start from the beginning. You want to create so called <a href="https://docs.sentry.io/platforms/native/guides/minidumps/">minidumps</a>. This is a file that contains information about a crashed program (like stacks of all threads, CPU registers, system info, etc.).
The minidump consists of various sections, such as the minidump header (including time of day, versions and basically a table of contents), a thread section (including all threads of the process and their stacks), memory mappings and libraries, etc. [Just to give some context, as all of this is actually not really important.]</p>

<p>For this, you created a <a href="https://github.com/msirringhaus/minidump_writer_linux">crate</a>. One section gets written after the other, while information about the targeted process is retrieved from the system. You even created a nice, simple API. You hand in a process ID and an open file, where the minidump should be written to. like this:</p>

<div><div><pre><code>    <span>MinidumpWriter</span><span>::</span><span>new</span><span>(</span><span>pid</span><span>,</span> <span>blamed_thread</span><span>)</span>
        <span>.dump</span><span>(</span><span>&amp;</span><span>mut</span> <span>dump_file</span><span>)</span>
        <span>.expect</span><span>(</span><span>"Dumping failed!"</span><span>)</span>
</code></pre></div></div>

<p>You can also hand in user specified memory regions that should be included in the dump, like so:</p>

<div><div><pre><code>    <span>let</span> <span>app_memory</span> <span>=</span> <span>AppMemory</span> <span>{</span>
        <span>ptr</span><span>:</span> <span>some_address</span><span>,</span>
        <span>length</span><span>:</span> <span>memory_size</span><span>,</span>
    <span>};</span>

    <span>MinidumpWriter</span><span>::</span><span>new</span><span>(</span><span>pid</span><span>,</span> <span>pid</span><span>)</span>
        <span>.set_app_memory</span><span>(</span><span>vec!</span><span>[</span><span>app_memory</span><span>])</span>
        <span>.dump</span><span>(</span><span>&amp;</span><span>mut</span> <span>tmpfile</span><span>)</span>
        <span>.expect</span><span>(</span><span>"Dumping failed"</span><span>);</span>
</code></pre></div></div>



<p>But when you run your nice library code in an application, you get <code>'Dumping failed: "Failed in ptrace::read: Sys(EIO)"'</code>.</p>

<p><em>How useless is that?!</em></p>

<p>Okay, maybe you could enhance your library error handling, a little. And by enhance, you mean Ã¢â‚¬Å“implement one in the first placeÃ¢â‚¬ï¿½.</p>

<h2 id="state-of-the-dart">State of the dart</h2>

<p>Your current approach is to define</p>

<div><div><pre><code><span>type</span> <span>Error</span> <span>=</span> <span>Box</span><span>&lt;</span><span>dyn</span> <span>error</span><span>::</span><span>Error</span> <span>+</span> <span>std</span><span>::</span><span>marker</span><span>::</span><span>Send</span> <span>+</span> <span>std</span><span>::</span><span>marker</span><span>::</span><span>Sync</span><span>&gt;</span><span>;</span>
<span>pub</span> <span>type</span> <span>Result</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>=</span> <span>result</span><span>::</span><span>Result</span><span>&lt;</span><span>T</span><span>,</span> <span>Error</span><span>&gt;</span><span>;</span>
</code></pre></div></div>

<p>and using <code>Result&lt;T&gt;</code> in all of your functions as the return value and handing all of them to the parent function using <code>?</code>. Thus the original error pierces through your callstack like a dart throughÃ¢â‚¬Â¦.jelly (Yes, you are good with words and you know it.).</p>

<div><div><pre><code>    <span>pub</span> <span>fn</span> <span>init</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>()</span><span>&gt;</span> <span>{</span>
        <span>self</span><span>.read_auxv</span><span>()</span><span>?</span><span>;</span>
        <span>self</span><span>.enumerate_threads</span><span>()</span><span>?</span><span>;</span>
        <span>self</span><span>.enumerate_mappings</span><span>()</span><span>?</span><span>;</span>
        <span>Ok</span><span>(())</span>
    <span>}</span>
</code></pre></div></div>

<p>In Rust parlance, this is also called bubbling up errors.</p>

<p>Usually, you just bubble up errors from libraries you use, but for the rare errors you have to define yourself, you currently just do</p>
<div><div><pre><code><span>Err</span><span>(</span><span>"Found no auxv entry"</span><span>.into</span><span>())</span>
</code></pre></div></div>

<p>Well, now you know there is an error, at least. And that it has <em>something</em> to do with your usage of <code>ptrace</code>. But you have no idea where that happens. You use that functionality in various places. Is it during the init-phase? During one of the sections? And if so, which one? What are you trying to read? And from where? Or in short: <strong>What is going on?!</strong></p>

<h2 id="shoes-off-get-some-tea-research-time">Shoes off, get some tea: Research time!</h2>

<p>Well, Rust has been around for quite some time now and they always boast about how error handling is a first class citizen and all that. So error handling should be a done deal, right? With a canonical way of dealing with errors, officially documented and all that should be right there, correct?</p>

<p>Oh boy, were you wrong.</p>

<p>Turns out, this is a very active field ofÃ¢â‚¬Â¦mhÃ¢â‚¬Â¦experimentation, lets say. There has been <a href="https://blog.yoshuawuyts.com/error-handling-survey/">a survey</a> recently, listing and quickly describing most the different libraries and ways for error handling that emerged, fallen out of favor, got forked, died anyways, got superseded, fallen out of favor again, etc.
And the opinions seem to change frequently, if you should use <code>error-chain</code> or <code>failure</code> or <code>fehler</code> or <code>snafu</code> or <code>thiserror</code> or <code>anyhow</code> or <code>eyre</code> orÃ¢â‚¬Â¦</p>

<p>You opened a can of hornets there, or whatever that saying is.</p>

<p>Then you find <a href="https://blog.rust-lang.org/inside-rust/2020/11/23/What-the-error-handling-project-group-is-working-on.html">this gem</a> and donÃ¢â‚¬â„¢t know if you should laugh or cry. Almost six years after Rust hit 1.0 an error handling project group is formed. Six. Years. <em>(heavy breathing)</em></p>

<p>Well, okay. At least they are sorting it out now. Problem is, you needÃ¢â‚¬Â¦.<em>SIX YEARS? Are you serious?</em>Ã¢â‚¬Â¦ahem, sorryÃ¢â‚¬Â¦Problem is, you need helpful error messages now.</p>

<p>After reading a few decent blogs on the topic (like <a href="http://www.sheshbabu.com/posts/rust-error-handling/">this</a> or <a href="https://nick.groenen.me/posts/rust-error-handling/">that</a>), there seems to emerge a consensus, at least for libraries: Return something that derives from <code>std::error::Error</code>. Either implement them by hand, or use a crate that does it for you, using macro magic. like <code>thiserror</code>. Which method you use depends on your level of laziness plus your patience regarding compile times.</p>

<h2 id="examples-vs-reality">Examples vs. Reality</h2>

<p>Another post highlighted <a href="https://doc.rust-lang.org/rust-by-example/error/multiple_error_types/wrap_error.html">error wrapping</a>, a particularly intriguing idea to you.</p>

<p>Unfortunately, all the articles have the understandable, but rather annoying tendency to use very simple example code for illustration purposes. Unrealistically simple, you might even say. They have callstacks of depth 1, return only three kinds of error in total in their API, and their errors are obvious and easily describable (e.g. Ã¢â‚¬Å“Input file XY not found in your Ã¢â‚¬Ëœcounting wordsÃ¢â‚¬â„¢ programÃ¢â‚¬ï¿½).</p>

<p>You have a more complicated callstack, with tons of different errors and code reuse in different places. For example, the function you think is to blame for the above error is <code>copy_from_process()</code>, which calls <code>ptrace::read()</code>, which probably returns something like <code>Failed in ptrace::read: Sys(EIO)</code>.
This function is used in multiple places in your code, e.g.:</p>

<div><div><pre><code>Ã¢â€Å“Ã¢â€â‚¬ init()
Ã¢â€â€š   Ã¢â€Å“Ã¢â€â‚¬ read_auxv()
Ã¢â€â€š   Ã¢â€â€š  Ã¢â€Å“Ã¢â€â‚¬ open(format!("/proc/{}/auxv", self.pid))
Ã¢â€â€š   Ã¢â€â€š  Ã¢â€â€Ã¢â€â‚¬ some_parsing()
Ã¢â€â€š   Ã¢â€Å“Ã¢â€â‚¬ ...
Ã¢â€â€š   Ã¢â€Å“Ã¢â€â‚¬ enumerate_mappings()
Ã¢â€â€š   Ã¢â€â€š  Ã¢â€Å“Ã¢â€â‚¬ open(format!("/proc/{}/maps", self.pid))
Ã¢â€â€š   Ã¢â€â€š  Ã¢â€â€Ã¢â€â‚¬ some_parsing()
Ã¢â€â€š   Ã¢â€â€š
Ã¢â€â€š   Ã¢â€â€Ã¢â€â‚¬ some_more_checks()
Ã¢â€â€š      Ã¢â€â€Ã¢â€â‚¬ copy_from_process()
Ã¢â€â€š
Ã¢â€â€Ã¢â€â‚¬ dump()
   Ã¢â€â€š
   Ã¢â€Å“Ã¢â€â‚¬ sections::header::write()
   Ã¢â€â€š
   Ã¢â€Å“Ã¢â€â‚¬ sections::thread_list_stream::write()
   Ã¢â€â€š  Ã¢â€â€Ã¢â€â‚¬ copy_from_process()
   Ã¢â€â€š
   Ã¢â€Å“Ã¢â€â‚¬ sections::mappings::write()
   Ã¢â€â€š  Ã¢â€â€Ã¢â€â‚¬ elf_identifier_for_mapping()
   Ã¢â€â€š     Ã¢â€â€Ã¢â€â‚¬ copy_from_process()
   Ã¢â€â€š
   Ã¢â€Å“Ã¢â€â‚¬ sections::app_memory::write()
   Ã¢â€â€š  Ã¢â€â€Ã¢â€â‚¬ copy_from_process()
   Ã¢â€â€š
   Ã¢â€â€Ã¢â€â‚¬ ...
</code></pre></div></div>

<p>Same goes for opening files, which happens in multiple places (two examples of which are shown in <code>init()</code>), so getting <code>FileNotFound</code> without context is going to be equally fun, and so on.</p>



<p>Wrapping errors still sounds like a nice idea, but one layer alone is not going to <del>wrap it</del> cut it.
Going with <code>copy_from_process()</code> as an example, you see a few possibilities:</p>
<ol>
  <li>Wrapping the <code>ptrace</code> error into an <code>CopyFromProcessError</code>, but that gives you nothing (except maybe some context, if you add some)</li>
  <li>With <code>InitError</code>s and <code>DumpingError</code>s that wrap the <code>ptrace</code> errors, you will still not know which section failed and why, but know if it was during <code>init()</code> or not.</li>
</ol>

<p>You might add context to option 2 as well (see below on how), but each section has a variety of reasons why it could fail. Some unique to the section, some shared among a few, some among all of them.</p>

<p>Complex problems sometimes require complex solutions, maybe?</p>

<h2 id="inc-err-ption">Inc <em>Err()</em> ption</h2>

<p>Using <code>thiserror</code> and the fabulous <code>#[from]</code> macro, you quickly define a plethora of errors and wrappers, starting from the deepest, darkest places in your callstack, wrapping your way up:</p>

<div><div><pre><code><span>#[derive(Debug,</span> <span>Error)]</span>
<span>pub</span> <span>enum</span> <span>PtraceDumperError</span> <span>{</span>
    <span>#[error(</span><span>"nix::ptrace() error"</span><span>)]</span>
    <span>PtraceError</span><span>(</span><span>#[from]</span> <span>nix</span><span>::</span><span>Error</span><span>),</span>
    <span>...</span>
<span>}</span>

<span>#[derive(Debug,</span> <span>Error)]</span>
<span>pub</span> <span>enum</span> <span>SectionAppMemoryError</span> <span>{</span>
    <span>#[error(</span><span>"Failed to copy memory from process"</span><span>)]</span>
    <span>CopyFromProcessError</span><span>(</span><span>#[from]</span> <span>PtraceDumperError</span><span>),</span>
    <span>...</span>
<span>}</span>

<span>#[derive(Debug,</span> <span>Error)]</span>
<span>pub</span> <span>enum</span> <span>DumpError</span> <span>{</span>
    <span>#[error(</span><span>"Error during init phase"</span><span>)]</span>
    <span>InitError</span><span>(</span><span>#[from]</span> <span>InitError</span><span>),</span>
    <span>#[error(transparent)]</span>
    <span>PtraceDumperError</span><span>(</span><span>#[from]</span> <span>PtraceDumperError</span><span>),</span>
    <span>#[error(</span><span>"Failed when writing section AppMemory"</span><span>)]</span>
    <span>SectionAppMemoryError</span><span>(</span><span>#[from]</span> <span>SectionAppMemoryError</span><span>),</span>
    <span>...</span>
</code></pre></div></div>

<p>The fun part is: You have to touch very little of your existing code, thanks to the automatic conversion from one error to the other, conveniently provided by <code>#[from]</code>:</p>
<div><div><pre><code><span>- pub fn init(&amp;mut self) -&gt; Result&lt;()&gt; {
</span><span>+ pub fn init(&amp;mut self) -&gt; Result&lt;(), InitError&gt; {
</span>     self.read_auxv()?;
     self.enumerate_threads()?;
     self.enumerate_mappings()?;
     Ok(())
 }
</code></pre></div></div>

<p>or</p>

<div><div><pre><code><span>- pub fn get_stack_info(&amp;self, int_stack_pointer: usize) -&gt; Result&lt;(usize, usize)&gt; {
</span><span>+ pub fn get_stack_info(&amp;self, int_stack_pointer: usize) -&gt; Result&lt;(usize, usize), DumperError&gt; {
</span> // snip

    let mapping = self
        .find_mapping(stack_pointer)
<span>-        .ok_or("No mapping for stack pointer found")?;
</span><span>+        .ok_or(DumperError::NoStackPointerMapping)?;
</span>    let offset = stack_pointer - mapping.start_address;
    let distance_to_end = mapping.size - offset;
  // snip
</code></pre></div></div>

<p>If you run your test binary again, you now get</p>
<div><div><pre><code>Failed when writing section AppMemory
</code></pre></div></div>
<p>which isÃ¢â‚¬Â¦.<em>(Throws a stack of papers from the desk)</em>Ã¢â‚¬Â¦short. Too short, and not that much more helpful, actually. Well, you know which section is failing. Thats good. But where are all the nice error messages you specified in your errors?</p>

<p>Hm, you do only use <code>println!("{}", error);</code>. Maybe <code>{:?}</code> is better?</p>
<div><div><pre><code>SectionAppMemoryError(CopyFromProcessError(PtraceError(Sys(EIO))))
</code></pre></div></div>

<p>Aha! Now you are getting somewhere! Tiny, tiny, painfully <strong>tiny</strong> steps, but you are getting somewhere! No error texts, but at least a chain!</p>

<p>Normal printing doesnÃ¢â‚¬â„¢t seem to recursively go through all the wrapped errors, but stop at the top most. For this, you need to either go through all the errors yourself by hand, or use a crate that does this for you. There are a number of them that provide this, but <code>anyhow</code> will do (its by the same author as <code>thiserror</code>, so interoperability shouldnÃ¢â‚¬â„¢t be an issue).</p>

<div><div><pre><code>    <span>println!</span><span>(</span><span>"{:#}"</span><span>,</span> <span>anyhow</span><span>::</span><span>Error</span><span>::</span><span>new</span><span>(</span><span>error</span><span>));</span>
</code></pre></div></div>

<p>aaaaand:</p>

<div><div><pre><code>Failed when writing section AppMemory: Failed to copy memory from process: nix::ptrace() error: EIO: I/O error
</code></pre></div></div>

<p><em>Collects papers from the â€¦</em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://msirringhaus.github.io/Where-everything-went-wrong/">https://msirringhaus.github.io/Where-everything-went-wrong/</a></em></p>]]>
            </description>
            <link>https://msirringhaus.github.io/Where-everything-went-wrong/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26191006</guid>
            <pubDate>Fri, 19 Feb 2021 08:57:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software Engineers struggle to write â€œchunksâ€ function]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26190554">thread link</a>) | @javaguy1
<br/>
February 18, 2021 | https://shekhargulati.com/2021/02/18/why-do-software-engineers-struggle-to-write-chunks-function/ | <a href="https://web.archive.org/web/*/https://shekhargulati.com/2021/02/18/why-do-software-engineers-struggle-to-write-chunks-function/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-6533">
	<!-- .entry-header -->

	
	
	<div>
		
<p>In the last couple of years, I took close to two hundred interviews. These interviews range from Java engineers with two years of experience to architects holding more than fifteen years of experience. The first round of our interview process, irrespective of the candidate experience, involves solving a small problem in a Google document.&nbsp;</p>



<p>I prefer Google docs because it removes the unnecessary fluff and most candidates are familiar with it. I understand that you may feel awkward and conscious when someone watches you while you are writing code. At the same time, it does give some understanding on how candidates keep calm under pressure, recover from their mistakes, and explain things.</p>



<p>I donâ€™t expect people to write completely syntactically correct formatted code in Google docs. I give them 20 minutes of peaceful time to write the program. I once read that in other tech organizations, it is expected that you explain your approach and your thinking as you write code on a whiteboard (virtual or physical), but I prefer to give people an uninterrupted time so that they donâ€™t have to do two things at a time. I try to make sure that they have understood the problem by giving them a couple of inputs and their expected output.&nbsp;</p>



<p>One question that I have used in most of our L1 interview rounds is shown below. Since 2021 I have stopped using this question so I thought it can be useful to share my analysis on how people performed in attempting this problem.</p>



<p><strong><em>You have to write a function that chunks an array into smaller arrays of specified size. For example, chunks([1,2,3,4,5] , 2) should return [[1,2],[3,4], [5]].</em></strong></p>



<p>Coming up with your own â€œFizz Buzz Testâ€[1] is not easy. I came up with the following requirements on which I evaluate such coding questions [2].</p>



<ol><li>It should be a real problem. The kind of problem you solve in a real-world scenario.</li><li>It should feel simple and give confidence to the developer that they can solve it.</li><li>The solution should not require more than 20 lines of code.</li><li>The problem should not be domain specific that it gives advantage to some candidates.</li><li>It should not require any special data structure, which you donâ€™t use in your day to day work.</li><li>Problem should not have a long text. Anyone should be able to read the problem text in less than a minute.</li><li>It should not require knowledge of a special library function.</li><li>A reasonable developer should be able to write the first version in 15-20 minutes. Candidates do tend to miss a few aspects of the problem, so it can involve more than one iteration.</li></ol>



<p><strong><em>I have used this question for evaluating Java candidates only. It is possible that it is not a good question for your specific programming language. So, please keep </em></strong><strong><em>this point </em></strong><strong><em>in </em></strong><strong><em>your</em></strong><strong><em> mind.</em></strong></p>



<p>There are three skills that I am trying to evaluate about the candidate.</p>



<ol><li>Can they code?</li><li>Can they explain the code they have written?</li><li>Can they explain how they will test the code they have written?</li></ol>



<p>Coming back to the chunks problem, one possible Java solution is shown below.</p>


<pre title="">public static int[][] chunks(int[] numbers, int chunkSize) {
   int length = numbers.length;
   int resultArraySize = (length % chunkSize == 0) ? length / chunkSize : length / chunkSize + 1;
   int[][] result = new int[resultArraySize][];
 
   int numberArrIndex = 0;
   for (int i = 0; i &lt; resultArraySize; i++) {
       int chunkArraySize = i == resultArraySize - 1 &amp;&amp; (length % chunkSize != 0)
               ? length % chunkSize
               : chunkSize;
 
       int[] chunk = new int[chunkArraySize];
 
       for (int j = 0; j &lt; chunkArraySize; j++) {
           chunk[j] = numbers[numberArrIndex++];
       }
       result[i] = chunk;
   }
   return result;
}
</pre>


<p>Java 8 solution using the Stream API is shown below. I donâ€™t expect candidates to write this version.</p>


<pre title="">public static int[][] chunk(int[] numbers, int size) {
   return IntStream.iterate(0, i -&gt; i + size)
           .limit((long) Math.ceil((double) numbers.length / size))
           .mapToObj(cur -&gt; Arrays.copyOfRange(numbers, cur, cur + size &gt; numbers.length ? numbers.length : cur + size))
           .toArray(int[][]::new);
}
</pre>


<p>My analysis is that only 10% of the total candidates solved the problem correctly in the first attempt. 30-40% missed a few scenarios and while explaining the solution they figured out the gaps and suggested improvements to fix their first version. And, remaining 50% failed to write even the partially correct first version.&nbsp;</p>



<p>Following are my observations on the attempts made by people:</p>



<ul><li>Candidates for some reason choose a function name different from chunks. I fail to understand why they donâ€™t use function name as chunks. Some of the names used by candidates <em>getSmallArray</em>, <em>getChunksArray</em>, <em>getMeArray</em>, <em>getRefactorArray</em>, <em>getChunks</em>, <em>splitArrayInChunks</em>, <em>convertArray</em>, <em>splitArray</em>, <em>chunkInputArray</em>, etc.</li><li>Candidates who did well in the attempt first wrote chunks algorithm in plain English and then attempted to write code.</li><li>Candidates struggled to come up with the correct function declaration in the first go. They directly wrote the first version of the problem and then came up with the correct declaration.</li><li>Many candidates struggled with multi-dimensional array syntax.&nbsp;</li><li>The first solution written by most candidates didnâ€™t handle the last chunk correctly. They created all chunks with equal size. So, the answer returned by their solution is [[1,2], [3,4], [5,0]]. Some candidates while explaining the solution with the example input figured out the problem and explained how they will handle this scenario.</li><li>Candidates struggled with the size of the result array. They need to consider whether the array is fully divisible by chunkSize or leaves a remainder.</li><li>Some candidates at times used String. They failed to make much progress.</li><li>Candidates make chunks an instance method of some class. They donâ€™t think whether they should make the method static. For some reason, they think static is bad.</li><li>Some candidates prefer to convert an array to a List and then only they can write code.&nbsp;</li><li>Java developers still struggle with Generics. Only a handful of them were able to convert the program to a version that uses generics.</li><li>Only a handful of developers can eloquently explain the code they have written.&nbsp;</li></ul>



<p>By no means I am underestimating the pressure of giving an interview. Both taking a good interview and giving an interview are difficult. I know it is hard for most of us to write code when someone is watching us in an interview. But, given that this is the kind of code we write everyday and we do have to pair with others. I think it is still a better and scalable way to filter good candidates from average candidates.&nbsp;</p>



<h2>References</h2>



<ol><li>Fizz Buzz Test â€“ <a href="https://wiki.c2.com/?FizzBuzzTest">Link</a></li><li>Picking problems for programming interviews â€“ <a href="https://lethain.com/appropriate-programming-problems/">Link</a></li></ol>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://shekhargulati.com/2021/02/18/why-do-software-engineers-struggle-to-write-chunks-function/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26190554</guid>
            <pubDate>Fri, 19 Feb 2021 07:18:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Endgame: Creating Backdoors in AWS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26190497">thread link</a>) | @rishabhsagar
<br/>
February 18, 2021 | https://endgame.readthedocs.io/en/latest/ | <a href="https://web.archive.org/web/*/https://endgame.readthedocs.io/en/latest/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://endgame.readthedocs.io/en/latest/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26190497</guid>
            <pubDate>Fri, 19 Feb 2021 07:04:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Write and Read Google Spreadsheet from Telegram Bot with Google Cloud Functions]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26190430">thread link</a>) | @fazlerocks
<br/>
February 18, 2021 | https://xakpc.info/write-and-read-google-spreadsheet-from-telegram-bot-with-google-cloud-functions | <a href="https://web.archive.org/web/*/https://xakpc.info/write-and-read-google-spreadsheet-from-telegram-bot-with-google-cloud-functions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://xakpc.info/write-and-read-google-spreadsheet-from-telegram-bot-with-google-cloud-functions</link>
            <guid isPermaLink="false">hacker-news-small-sites-26190430</guid>
            <pubDate>Fri, 19 Feb 2021 06:48:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Universal Warrior, Part III: The Cult of the Badass]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26190353">thread link</a>) | @parsecs
<br/>
February 18, 2021 | https://acoup.blog/2021/02/19/collections-the-universal-warrior-part-iii-the-cult-of-the-badass/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2021/02/19/collections-the-universal-warrior-part-iii-the-cult-of-the-badass/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://acoup.blog/2021/02/19/collections-the-universal-warrior-part-iii-the-cult-of-the-badass/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26190353</guid>
            <pubDate>Fri, 19 Feb 2021 06:29:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cache-Tries: O(1) Concurrent Lock-Free Hash Tries (2018) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26190123">thread link</a>) | @feniv
<br/>
February 18, 2021 | http://aleksandar-prokopec.com/resources/docs/p137-prokopec.pdf | <a href="https://web.archive.org/web/*/http://aleksandar-prokopec.com/resources/docs/p137-prokopec.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>&lt;435D0B962E4D6E4F887B1123181692F0&gt;]/Index[1866 106]/Info 1865 0 R/Length 151/Prev 963274/Root 1867 0 R/Size 1972/Type/XRef/W[1 3 1]&gt;&gt;stream
hÃbbd```b``Âµâ€˜@$Â£Ë†dÅ¡"Oâ‚¬HÃ§' â€™Ã¹!ï¿½d\â€ºbÂ³Â¬â€¹Hï¿½Ã‰Ã‡ Ã±Â¸.Â°Ã¸b0Â¹LÂºâ‚¬HÂ®	 Ã™Å’â€¡`â€˜`Ã»Â¯XÃ—BÂ°Â½Ã³A"Â¬Â¬`v+XM Ë†Ã”z
f_â€œB`ÃµÂ½ â€™Ã½#ËœÃ­"Ã—Æ’eÃ‰ÃŸÃ†Ã²LÅ’Ã¬Â·Ã€Â¾``%5Ã¹Å¸Ã¡wÃŠ.â‚¬jÅ 
endstream
endobj
startxref
0
%%EOF
                                                                                                                                   
1971 0 obj
&lt;&gt;stream
hÃb```Â¢.Å¾GÃ‚ ÃŒÃ€ÃŠÃ€Ã†Ã€Ã‚Ã€ÃÃ¶Ã˜â‚¬,Ã‚â€”Ã›Â¾ÃŠÃ»ÃÅ¡Ã¹Ã­ï¿½Â§t{Ã˜Â´Ã¬Ã¿`Ã‡ywâ€˜Ã¿Å¾)ï¿½Â¯â‚¬Ã¦-;0Â¡Â¡oÂ³Ã´yÃ»ooâ€“Ëœ50 AVÆ’Ã§MÂ´â€¡vÂ¨?me_ÃÃ¥Ã¦(â€œÂ¬0Â³Â«Ã¦Ã°
â€œÃ´KÃ¦EDÂ²8ÃºiÃ¾Ã±1irÃ«Ã¹Â¢â€“"ÃˆZ/Ã”Â¡Ã²EyÃ†Ã¡UKÂ¯r\Â¸Ã‰Ã¢Ã¨u,Ã£Â¾Ã‚dÂ«UnÃ³Ãšâ‚¬ÃšÂ½Ãª2ÃNÃ¬Â±hÅ kÃ’Ã”ZÃ²Eâ€™Ã…Ã‘W3Ã Ã˜tâ€°Â¸â€ /Ã²=MÃ®/Ã•hÂ¬^5ÃQ Ãºï¿½Â´Ã¤Æ’Ã‡^Â¾Â¨Â¶TÃkhÅ Ã¯Ã‘^â€º"â€œ Ã¬6MZ^3ÃŸÂ¡Ã›]Ã¥Ã½â€œ@&amp;h$Â´â€¡Ã˜Ã„Ã·ExÂ¨Å¾Ã—8ÃEÂ¤Ã‰Wl2ËœÃ´PÃ¹Ã‚Â«-Ã¾Ã¨6â€¦9^Â¶Ã¬ï¿½Mâ€™Ã¹8ÃŠÂ¤@Â¼((
Ã·Â³&nbsp;`h(ËœÃƒÂ¤ÃŠA%%&nbsp; Â£ï¿½Â²â€°â€¹[ZZXÂ¥1â‚¬T2
â€šâ‚¬Â°YRËœ	
)Â¥AÅ’Â²Ã€Ã€)Tâ„¢ï¿½ÃÂ¦2(Â©Â¸Â¸Â¸xâ‚¬XP4ÂªMÃ‰%Â´ï¿½ËœX:4ï¿½ï¿½Â§Pï¿½ï¿½uddÂ¸ÃœÃ¼Ãµâ€]â€š<krÃ—â€“ Ã†oÃ«Ã4Â¬i[`jÃ Ã³wÃ¶â€“#l#^745x:h3,~Ãzâ€ yâ€˜Ã‘ï¿½Â±ï¿½a{Ã·Ã‘6Â»@â€ â€º="" ^ÃÂºh="" Â°Ã¶Ã‘Ã¿!Ãµâ€¡Ã¡2Æ’^Ãƒ="" Ã‘="" b6,="" |="" ÃŒï¿½â€œÃ Ã¾bÂªfÃ Ã‹ï¿½Ã¹â€šï¿½ï¿½5ÃˆÂ¯aÃ +9="" Ã¤Â³10Â¨Ã»ï¿½Ã¹-="" |Ã«Ã˜="" Ã²lzï¿½ï¿½ÃÅ¡Ã€Ã¤="" endstream="" endobj="" 1867="" 0="" obj="" <<="" metadata="" 642="" r="" names="" 1900="" openaction="" 1868="" outlines="" 1261="" pagelayout="" singlepage="" pagemode="" usenone="" pages="" 1861="" type="" catalog="">&gt;
endobj
1868 0 obj
&lt;&gt;
endobj
1869 0 obj
&lt;&gt;/ProcSet[/PDF/Text]&gt;&gt;/Rotate 0/Type/Page&gt;&gt;
endobj
1870 0 obj
&lt;&gt;stream
hÃÃ”[iSGÃ½Ã»ÃªÂ£ÃªÂº/bCâ‚¬â€dÃˆÂ²WÂ«pÃ@Â¯â€¡&lt;3Ã˜bÃ½Â¾WÃÃƒÃŒ&nbsp;yÂ½GM5}TeeeÂ¾|â„¢Ã•Ã¨Â¬â€PBgÂ¥Ã±â€¹Â­ÃšÅ¾XarÃ¢â€°Ãâ€”GÂ¼8pD4Ã¥$Å Ã¤Oâ€™ÃˆÂ¡\AÂªÂ¼Â¦Ã±Å 1â€“gÃ¨Ãš:Ã‡3&lt;Ã«"_ÃÂ¸ty7b(wÂ§dâ€Qï¿½cÃª(Å’ÃÃ¥ZÃ†â€“Q!Â§qâ€˜Ã²%Å’/Â£-L4|ÃaRÃ¤sÃœÂª2/Ã£â€Ã•&amp;Ã²ÃŒtRÂ®amÃ»\Ã–â€¢1L6â„¢Ã‘â€¢ï¿½Å½wÂ­6Â¾kÂµpZQ*kâ€sÅ¾Ã£Z+\Â«Ã«â€WÅ Ã³Â°^xâ€ºÃŠÂµ |.Ã£Ãš(â€šÂµÃ¥nÃÃ¥Ã’sÃGÃªÃš)bbNÃ£,StrÃ‘Â»Â³"j]Â®9(&gt;QRË†},o`1râ„¢â€¡ÃƒjÃ˜TÅ¾K"yWÃÂ²H!Â±tâ€¢râ„¢Â¦Â­Ã³]oÃ¦Ã‡Ã¾Â¼Ã…YYÃ¯zÂ¢ÃŒÃsQ)Â³"Ã§Â¢!ï¿½Jâ€”Â¥Ã¡Ã¼â€¢+Ã’Ã¸Â²Ãª\ÃÃŒ[Â¸ÃŒqÃ”Â¹Ã‹UÃ¼Ã’â€“/Ã§Â±t+:W]GÃ‡Ã•&nbsp;Ã±Ã¨Â¤Ã‹)4â€š5Â§^Â¨vÃ“Â½â€ LÂ¥3Å’Â©y5b4Ã«aÂ³Ã¹â€¹|Vï¿½'cÃ¼	-+qÃ´Ã´).Ã­Ã²Ã²W7Â½Ã‹ÂºÃ’Ã¾ky,_Oâ€ OÅ¸ÃŠÂ½Ã¡Ã¨Â¼}&nbsp;Ã¥Â«ï¿½rÃ¿Æ’nO^ÃŠoÃ¤Q}6Ã¹â‚¬TËœ&amp;L*V\lmTÃ¥Â°Ã”&amp;Â¥ÃŠ8Ã½QÃŸÅ¾NÃ®njyÃ˜~â€“'&lt;Ã›â€ â€œÃ»Aï¿½Ã¥Â»Â£oÂºgâ€œf8Ã ÃŸ_]M&amp;7Ã£)Ãâ€¡M5]JÅ½Â¢ï¿½â€”VÃ‡Ã¤RÂ¬Jâ€ºÃ“Ã—+$Ã„&lt;â€¦Å¾â€”ÃÃ¹*Ã€ÃÂ¦Å¡l*Ã„Ã¦&gt;Ã»ÃªÂ¬â„¢Ã”Ã•Â³ÃºÂ°Â·7jzÆ’Ã³^3ÃÃ¡JÃ®Â¿Ã›AÃ·Â¶Tâ€¢6?Â¦:
6Â¯:c&amp;Uâ€¢Â¥|Ã“Ã‚Ãšâ€”*Â¯Ã¼Ã¿â‚¬Ã¦Â¼Â­Ã¨Â¦ÃºÂ¢Â½'Â§Â©tÃ´Â«Â¬9Â¯{Ã½Â«ÃÃ¸jÂ­8*@â‚¬Ãv$Å“5UÃDSSâ€¦ï¿½Ã‡Ã½Ã‡Ã­Ã¹Ã6CZX@â€cZâ‚¬â€sÂ¦2pÂ¨Ã­=â€i\Ã‚.â€™ÃfhÃ§*Ã¢ÃºÃ½Ã6Ã˜ÃŸnÃ¨Ã§oÅ¸=Ã»Ã¦Ã¨Ã¤â€°1f,Ã¼AC|Â¤Ã§zÃ¡â€Â­,Â°Ã¦\â€¦â€7Ã¢Ã­hÃ¸Ã³Ã°Â¦&gt;3JÃ«mâ€ Â®Ã¢h&gt;UZâ€â„¢*"LÃ¹ÂªhÃÃ†Æ’â€¡ï¿½Â´ÃÃ›Å’Ã«Â¡yâ€Ãµ.TÂ±Ã{ï¿½ï¿½Â«bÃœ|Ã–7ÃÂ¬Âµ9â€ºÅ’Å¡zÂ¼ÃÃš+ÃŒÃ±Â¿#Ã‚%&amp;Å½8Ã¡a{Ã‰l&gt;Ã±ÃQÃÃ´Ã†;PÂºÃ›Ã™~Â¸c	â€XÃšÂ·QË†Ã–+Ã„Ë†Å½-@
â€˜Å’-HÃˆHv_Å¾Ã¬â‚¬.pÂ¶jÃ›Â°ï¿½D],Â¹â€”ÃˆÃ„JÃ¹Ã­%ÃºvÃ˜Å’Â¯zÂ­Å½Å½O&nbsp;#Â¾Ã´gâ€ºÂ·Ã±ï¿½J&lt;Ã–YZ,Â¬$HÂ¹Â¹@Ã‡â€œÂºÅ“GÃµË†RÃ¹ï¿½7/_Ã­ËœÃ¤â€š{eâ€™v&nbsp;`[yÂ°â€¡Å¾`C`	NÃ¦TÂ¨Â°Ã¼ÃŒÅ¾Â½Â¹X/Ã«QÂ¿Â¹ÂºÆ’H*Ã­Ã¬Â¾zÂ»Â£Ã¡â€š*Ã¤-Ã‘;ï¿½Ã’Â°Ãâ€˜Ã¸
#Ã© Ã„7Ã¥Â´wÃ¹[ÃÃ¯CÂµï¿½Ã`Ã¢Å“Ãfï¿½QÃ¡LÂ´Ã‘Ã¦Å’Ãj6Ã½ÃÃ¸ÃªÂº7Ã Ã’Ã˜ï¿½Ã£ÃƒÃ½CÃ¢jsUÃšÂ¸â€¢Dtk7'ÃµÂ§ÃšVÂ¢/Wo2&nbsp;Ã‘Ãâ€ Ã—`Â°Ã­Ã°Â¿Ã¥@Â®+Å¸Ã‚Llâ€š3Ã¿Ã—Â¸k@Â¼Â¬Ã• ^â‚¬|Â¬â€˜SÂ¶Ã¨
â€™Ã¾Ã‘kÃ¢"Ã€â„¢â€ï¿½wzÂ¤$edÃ²&amp;Ã¦*Ã©?|tk+Ã‡DÅ½W1%AFÂ£Ã‰E7[ï¿½Ã±Ã­Ã©Â¸.|Â³Ãœ"Up`ï¿½â€'m@Â·Ã€q\eÅ k#ÃÃ¿Ã•Ã˜fâ€¹Â±i_Ã¢tloRâ€¢ËœÃ¾Ã¾Å½Ã­Â¶Ã‘9Ãƒâ€™^Ã¤]	&nbsp;Ã¬Â¢6Ã¹Â¿ï¿½Ã©uÃ¤gÃÂ¢r=8Â«Ã‡Lâ€?5Ã‚*4}xÅ &lt;^_Ã·Ã¤Ã•ÃÃU=ï¿½7ÃµÂ¨Å¾Ãƒ}Ã¥?Ã«Ã‘PÂµÅ“Ã¼6â€â€œÂ«Q]Ã‹â€¹Ã¡Ã­H^4Â¿Ã–rÃœ|â€™Ã£ÃºWÂ¼P7â€”W9hÃ°Ã Ã™Â°?Ë†Ã Ã¥Â®QÃ®Ã‹gÃ²Â¹&lt;@Â¢Ã…)Ë†Ã¤Â¡|%bâ€“oD2Ã²Ã³&gt;)ÃŠÃ·"GÃ™â€œÂ§Ã²LÅ¾K!/Ã¥â€¢lÃ¤?Ã¤ÃÂ²/Â¯Ã¥@Ã¥ï¿½@Â®'Gr,'Ã²VÃ¾*â€œÅ¸Ã¤ï¿½Ã¼Ã§Ã‡vâ€“ÃgÃƒÃ³fpÃ™Âªx|V&amp;"Ã¢Ã¹Ã½ÃÃÃ‹"Å“&amp;Ã‰Ã½Â«ÃÃ¨Â¸Å¾|%wÂ§â€šÃ…B$Ã¹Â¦FÂ¾Ã¯Ã„(Ã“Ã¨Â´Bâ€˜Ãš^PkTYÂ«â‚¬Â¢
Å ÃšÃ©m^Ã¢Â¢Å’Vw7ï¿½Bâ€¹Ã´Â­Ã‚Â¨ÂºIÂ§PÂªvnFEÃ§_Â³ï¿½QfÃ±Ã„X-ÃºÂ½Ã‹Â±pÃ²`8ËœÃ¬Ã­
?}xâ€šxcÃ„kâ€™Å¡U0Ã€ï¿½Ã¥Ã¶AÃ“Â¯â€˜ÃÃ†ÃˆÃºGÂ¹Ã²Âºw]Ã‹Â£Ã¯^Ã®Â¾yÃ±gÃ˜Ã…asZï¿½&amp;ï¿½Ã®dO~3Ã©Ãµâ€ºÂ³ÃÃ%ÃQÃœÃ­Ãº{VUZï¿½Ã²]J1jn&amp;Ãƒâ€˜Ã¼Â¡S$`Ã¶Ã©Ã“â€˜Å¸ÂµÂ¦Â¨Æ’`i)XZÂªÃ˜[Â°ÃÂ¼GucAÃâ€¡Â­Ã¶Ã¥(Â´Ã—
#Â¥OmÂ«gÃ¯|Ã®0,&lt;Â¼fJÂ£KÃ«Â¬&nbsp;Â½"Â²â€ â€ â€+Â²8i1&gt;â€šâ€˜gâ€¢Â±0Ã©(,R_â€¹Yâ€œÆ’Å Ã¸
ÃŸâ€°x?&nbsp;oÂ¶Å“Ã¢(Ãº1Ã¥Â½ÃˆbÅ¸â€šÂ¢Y)Ã†â€¢ÃƒftÂ¤biÃÃ™Iâ€ºÃ‹$AÃ“ËœÃ§0Ã™EÂ¢Â§]Ã´Ã Â¤1Ãï¿½aÃ§â€“%HQÃŠÂ©ï¿½I8H,1â€“c9â€™9FCwï¿½Â¥?Ã¤â€™Ã¨Ã›|â€â€¢Ã¯ÃµÃ†5â€”hÃÃ’N=Â¢-^[hFÃ£	]Ã±xiqÃ›Âº&amp;:Ã¬uÃhcÃ®Ã‘â€Ã¦&nbsp;Ã¥Ã‰Ã°Ã&nbsp;AÂ§Ã…Â¼RyÃºÃNÃ¤Ã»Ã¦|r5nÂ«Â¢Ã“Ã‚Ã›Ã hYÃ{Ã£+Ã‘BÅ½Ã®wA Ã«Ã¤/Â·ÃƒI}~Å Ã³ Ãâ€¡Ã½~oDÂ·)&gt;`s{wTÅ“Ã°Â¦â€¡&gt;Ã»ÃµEw6ÃªÂ¬RÃÃ´oÃ‡Â«pLÅ½Ã»Ã·KÂ¡â€”Â¯â€ºÃ”,Ã„Â¨Ã‡Â¥Ã•â€ºDÃ¶Ã®aÃ¤Eâ€™oÃ¥wL^NÃÃŠÂ¿vï¿½Ã²N~XÃ¹AÃ¾(Â²â€“Â§Â£ÃÃ™ÃÃµâ€Ã¢â€¹lÂ§Â¶sÃ¸&lt;ÃŠ_Â¶B@5â€¡jÃ½Â¶bÃµFÂ£Ã¡oÂ­Ã¾1ÃµÃ“Ã¹y,LBÅ¾ÃÃ¶Ã»Ãµd	AÃâ€ 7wÃ­Ã­Ã³Ã©ÃšN!ÂµÂµÅ â€šÂ¬Ã·FÂ±
Ã†nÂ¯aÃµÃ£Ã¦r0Æ’Ã›25&amp;Ã¹Ã·?ufQÃ¬Ã¥â€”Ã™â€™N
pÃÃ–ZÃ„Ã®`Â»[â€œÃšÃÃ•ZÃ¸6&gt;vÃ°
Â³ÃŸÃ‰,ÃÃ·â€ºÂ¯Ã/ÃºÃ¸JÃ´Fh}Â¼Mx{GÂ¨Ã¤`ÃªÃ0
Aâ‚¬â€°Ãâ€˜M0=0MÂ±Å¡Å’l&gt;Ã¸rPnVts{X$Å¾Ãâ€¦gSÃ›2_Ã¯ÃÃ¹ÃœaÃ?Ã¶1=XÂ±K,ï¿½Ã¢Ã°â€°&amp;uEÅ’,O Ã¬Ã¸Ã˜â€ X\Â¥\ ï¿½"qKâ€¦Ã€Â®8ÃÂ¶Â©}Ã‡Ã£Ã™%Â¸s$`Ã&gt;Â²Ã‹`Â¸iTÃš{LÃ„[Â¼â€º[\&amp;Â¾;â€=Â«7zÂ¸Ã…3Ã“pÃâ€˜Â¬J`Ã±Ã€|Â¯â‚¬ÃµÂ¸oqÂ½:n!AÅ½Ã¨Ã˜Â¯bâ€™â€ Â¾Ã"Â¦Â¯ZÃ¯yHwÃ‹ï¿½Â®W@ÂºÃŸ
Ã’Ã³ZHÂ«!]Å¾\Ã•â€œÅ¾ÃQÂ²AÃ§Ã—Â·Ë†â€VÃ¶.Å¡F+rÃ•Ã€BÂ¹ï¿½#Ã¯Âª^Â²=Râ€¢VÂºÃ³AÃ²+&lt;â€¡;Â©Â¬rqÃÂ»Â²ZÃ´Â®Ã£OÃ¶Å¾-hÃ»Ã‹ï¿½Ã¦Â¶Â°â€Â«:Å¸_Ã‰Â´Â¼â€™+2/.Ã¤cÃ‹ËœÃ½ÂºetjÂ¶%Ã–Âª.Â©EÂ½ÃTÂªÂ¦&nbsp;eÃÅ“NÂ³xÂ¢Ã¡PÂ¦RÅ¡Â©Ã”r\Â·Â¨Ã“â€”ÃƒÃ‰Ã¾Ã‘Ã›Ã—Å“OÅ¡Ã«Ã•
M+Â©fÃ±^:Å¡*3Ã¬Ã†ÃÃ½ÃŸ3"sy&nbsp;Dgâ€¢Ã¨Ã£Â²â€”TÃ¶Â¡8Ã¸Ã§ï¿½ï¿½ï¿½â€˜ï¿½,'?-Ëœ5Ã©Ã–Ã¯Â£)Ë†#Â²Ã¾Ã¥Ã®Â¶ÃŒRÂº40Â¸Ëœâ€¡â€¢,LÂ¾\Â¶YXï¿½ÃŸÃƒYÃ¤Ã­Ã¹Ã§Ã¸l8ÂªÂ¿ 'k}Ã½QN0Ã\Vâ€ UXÃŠÃŠÂ¦9â„¢YÃˆÃ·dâ€œGâ€™Â²Å½Aâ€Ã™â€œG|IfÂ¶HÃ¦cÃ¿Æ’Ë†Ã¿Ã“bÃ”Å¸Ã©Â«â‚¬â€¢	\\ÃBâ€”Ã€%Â³Ã§Ã³7Â»Ã¨Noï¿½_Â¿ÃšÃ%Å Ã¬5Ãƒ~Ã’sÂ²â€¦GÃ *(Ã†â€ï¿½Â¹Ã¸TÂ¿2chÃ Ã–â€˜Ãâ€°[Â¸%Â¨w Âªâ€“$fIÂªGÃ QÂ²:$--Â°Ã›Ã“â€™â€”bÃ©â€¡Â­S)aâ€™b,Ã£2Ã¨2Â¸FÃÃ¬AÃ˜cÃ±.Å¸c0MÃœLÃ–Xï¿½Ã¶&gt;â€”6_
â€¦Ã˜â€2Q]BCIÂºÂ°ï¿½â€°Ë†ï¿½Ã‰mÂ»@Ã¸?â‚¬aÃ¿ Â®dÂ³Ã¸â€º[H.ÃÃˆÂ¯e@,Cosâ€¹â€ zAÅ¸Ã™oFvÃ¬TÃ‰~]@fiËœ(Ãºâ€“TÃ¨Â°5VÂ­Ã·\Ã”pâ€ºÃ„Â·]Ã¼wkÃ‡ÃªÃ¸Ã¯Ã”ÃªT,Ã¦ÃÂ²|.Â¢â€”ÃŸ!yï¿½Â¦"yÃ¹Â®Ã 
Ë†â€šjqâ€¦ÃŸï¿½YÃÃ†Ã•Ã˜Â²=o`~Ã³9Ã4Â£yGY`%-~â‚¬\\TkÃ‡Â½Â¾Ã­Ã’Â¬Ã’
iÃ¹,Ã‘â‚¬Â¡Â¢Â¡â€¢~Ãˆ4Â¢^tÃ£Æ’â€¡Ã¯X$ÃŸ,Ã¸Ã±mÂ¦d#lÃ‚Ã¤KÃ—tâ€ºPÂ¸j
â€˜ÃŸÂ©Ã€TÂ»"y(â€¹Â£!Ã°Ã™TLâ€”Â­â€¡Ã¹9Ã®Q;&gt;Ã§
?NÅ¾uÃ3Ãœ)Ã¼â€“Ã†rgÃ…Âº{Â·PÃ¥Â·Ã£Ãâ€Kâ€¢Ãƒï¿½â„¢Â§Ë†Ã­h&amp;Â²"â€™;'â€šC&amp;Ã›Â¾M`Ã¡Ã³Ã{Â²m~&nbsp;Å’Â¥â€“Ã¦Â­â„¢3ÃÃ¤ZÃ¿iÃ’:<fÃ½aï¿½ÃµÃ»Å½6}Ã¨rï¿½mÃˆÃaÃ¡3Å¸ewn?&Â§y+Ã§ÃªÃ‚lvâ€“!#Â¹ Âª|iuwâ€œ="" fÃ«Ã™%â‚¬="" tÂ¢gÃ±09Ã¤tÃ²Ã“oÃ¾Ã°Å¸h,â„¢Ã„nâ€œÃŠÃ¿fbÃ‰ï¿½="" kÃ‹xâ€˜Ãµ"Â±Ãœ*Â¡Ã´Ã‹â€¦xÃ·Ã¹â€r="fÂªk3Ã¯â€”3Â¨|Ã‰#Â¢Ã™=â€“Ã·â€”Ã³Ã…Â¦Ã™Å¸]5Å â€¦Â©Ã³Ã“Ã¾Ã©pr5_Â¥Å¡Ã–Â¡Å¡Ã‘YÂ¿">â€š&amp;Ã¶Ã«kÃ–Å¡ÃE3h&amp;wÂ²_ï¿½Ã‡-iÃ¬/â€ºÂ³^Ã¨zï¿½H;FÃ¨OÅ¡â€ºÃ¾]Ã‡)!Ãœ	Â½Â¹nÃºÂ½Ã‘\HÃ~Uu6Ã³â€!pÃ‚big)$Ã¬Â¿~Ã¹Â·g?Ã¾yÃ²i|Â·â€™Ã‘yÃ³xpÅ¡Ã¥xÅ¡Â¸Wâ€¦Â¿Ã±Â«XÂ¶4â€ºÃ‚Ã§Ã–)â€ÃÃ‚r&lt;Ã¶ÃœÂªÆ’Ã¢Ã²Â¸Ã¿Ã¦Ã‰Æ’qâ€¦Ã‡Ã´oÃ³Ã·Â§Âµï¿½Ã¥Ã»â€“Å¸Â­Â²~NÂ¹KÅ¸m&lt;"Ã¶Ã’Ã…xÃ—ÂºÃ·vÂ£Ã¢Ã§Â°Â¦ï¿½Ã»_QÂµÃµy~Ã´TÂ¡s!ÃUï¿½ Â¶Å’aï¿½Å’Å¸Â·â€”XÃ¬2mG*â€”Â¶Ã¬c0Â·EXKâ€Â¹|Ã´Ã‰mâ‚¬Ã„ÃkÃ‘Â³/Ã›Ã‹â€¡Â¡Å¡_8HÅ“Ã‹Ã§Ã„â€“Ã‡â€šCÃ/Ã»ÃŒÃ«Vâ€â€”Å“NÃ¹GÅ“.Ã™ÂµNâ€”VÃ†fâ€¡-Mc"(rnÃ³=~Â¿Â»ÃŒÃƒpâ€“Â§9ÃÃ»nyÃ¦Ã‹Ã»Ã dÃ‡]B9ÃÂ´ï¿½7-Ã°,Â·Âª&nbsp;sxÃ‚ï¿½Â°zÃƒ+â€¡EÂ·zÃ¿Ã¾`Ã·Ã›Â½Â¥]â€˜Âµ\Ã‹oÃ€ÂµÃ¡Å“Ã»11&amp;
7â€™Ã«d2Â¹l:â€˜3Ã‘Â¯hR%Â¼ï¿½kâ€˜-â€¢4Ãƒâ€”Â°0â€¦Å“Â¸uâ€ {|ï¿½Â¡nÃ•Å¾RÃ¡hÂ©Ã¬9Ã²/Ã®)Â©\Å¾)~Ã‹pË†ï¿½`Â®XÂ¿ÂµÃ¶Å¾\Ã™ÃŒbâ„¢â€ Ã©I	Ã¤â€ ÃÃƒï¿½WÃ­Ã†Å“Ã—kÂ±Ã¶Â¸FssÃ",o(â€¦JÃ¡Ãâ€ Ã’cÂ¼&amp;Ã‡uvÃ–l(Ã¹9Â´Ã§GÃ¢ï¿½Ã„Ã£~Â¿Ã¡!Ã™ÃÂºlâ€¡Ã~Å’Å¸Å¾â€˜/tÃ¿QZÃ«ÃŠÅ¾Â¦QÃoÃ§â€ZÃ³C Â®Â±Uï¿½Ã¼â€2OÃœÃŠÃ«Â³Ã‡2[â„¢9ÃˆAÂ¹bâ€¹Ã¯ÃDÃ¹Â°Ã’ÂºG]Ã¼Â¡IÃºÂ®Â¤ÃÃ¿ÃŠ&nbsp;ÃˆL
ÃšaÃ§DÃ¨Â¯Ã‚xJ&gt;Ã‹Ã¿2Ã Jâ€”*$3|Ã€s7Ã³~Ã¦(ËœfÃ‰Ãâ€“YÃºÂ­HIxï¿½Ã¥nBJÂ°Ã¾ï¿½Ã˜Ã™Ãšï¿½Ã‹Ã Â·Ã˜Â¸Å“~9aÂ­Â¬?ï¿½Ãµ{Ã—Ã­QÃ¾!u?Ã¿Â¹Ã½Â¼Â¹/-Ã‚Ã½Å½ÃÃŸVVÃ·â€“sÃ°-Ã·aÃ…Ã³ÃˆÃ´Ã¦{Å½G]Â­Â¯â€œÃ®Ã‘Â¯0Â¦Â¿Â¢xÂ¹Ã¡Â®Ã¡ÃªÃªÃŸÅ¡ï¿½Ã‚RÃœ&nbsp;Â¸Ã™Ã·kÂ£YÃ»%Ã€Å Ãª_Z*Â¦Ã¯Â½Ã»aÃ¯Ã¥Â¢Â£Ã¼Â¾ÂºÃÂ¬ËœÃ”}Â®N\JL,uÃ€Â¨â€™mÂ¡/Â¶Ã¥?Â° Ã³iÅ¡$XmgÃ¥?~Ã£Ã€Ã²Å¸nÃ“ÃŒÃœÃ¤(ÃÃ«Ã¼Â°Ã¼Ã‡Ã’k@ï¿½Æ’Ã¿eÃ¶Â¹:G[Ã¾Ã»Â·V:ÃšXÃâ€Â»Ã¨KÃ§Ã¬bÃ¹oÃµâ€šÃCcÃœ&nbsp;Ã’6Ã€Â´6_Â¹â€¦Ã†
WÃ‰JËœ
endstream
endobj
1871 0 obj
&lt;&gt;stream
xÃšÂ¤Â·p%ÃœÃ’5;['Â¶Ã­â€°mÃ›Â¶Ã­L<qfb'Ã›â„¢Ã˜Â¶mÃ›Ã¾3ÃÃ½Ã{Å¸Ã»Ã¢Â¯Â¯ÃÂ¯nÃ•Â®Â³Ã¶Ã®^ÃÂ»{Ãµ>uH	Ã¥â€¢hÅ’Ã­MDÃ­lï¿½iÃ©Â¸Ã’Â¶Ã’â€ &amp;Å½ÃÂ¶&amp;V:F:FRRegkâ€œÃ¿tCÂªjÃ¢Ã¨dagÃ‹ÃµO3!GÃ§ÃaÃ§Ok%gâ‚¬Å“â€˜3â‚¬
Ã€ÃˆÃŒÃ…ÃŠÃ‚Ã…ÃŠ`b`dÃº;;G.â‚¬Å’â€¦â€˜Â¹ï¿½â€°5@Ã‰ÃœÃ€Ã‘Ãâ€ TÃˆÃÃÃƒÃ‘Ã‚ÃŒÃœÃ¹Â¯X.Ã®â‚¬â€ zÃ¤Ã-Â¬-Ã¬Ã­Ã¢ty;kkÅ¡Â³â€”Â³7Â±Ã¼Â¹Ã€Ã…Ã–Ã˜Ã„&nbsp;lÃ¢hÃ£Â°3Ëœ~Å¡ÃšÂ¹YÃ˜Å¡DMLJvÂ¦ÃnÅ½&amp;Å¸Ã”F&amp;Â¶N&amp;N\Ã¿F#&amp;/
&nbsp;3Â±5q4Â°ÃˆÂ»Z[Ã½â€¡%%Ã€ÃÃ‚Ã™Ã¼â€œÃ¯Â³V&amp;Ã®F&amp;Ã¶Â®
0Â°5Ãˆâ€°JÃ¿	Ã…Â¿â€™Ã¹_Âº3Ã¸Â«&amp;Ã†Ã¿ Ã¼c'jÃ§hf&nbsp;0wvÂ¶Ã§Â¢Â§Ã¿Ã‚Ã´Ãï¿½â€œ)ï¿½Â­â€°3Ã¥Â¿9+}FÃ¾Â¬$3ÃÅ¸â€¢Ã¥Â¯â€¢ÃµÂ¯â€¢Ã­Â¯â€¢Ã½Â¯â€¢Ã£Â¯â€¢Ã³ÃÃŠÃˆÃ°Ã—ÃºÃ™!Ã€?nÃ¶'Ã´g=Ã¿Ã¸Ã)Ã“Ã¿ËœÃ½g
Â¤"Â¶Ã†Bv66&amp;Â¶ÃN0Å’câ€¹ÃÃ¦Å¡ËœYÃ˜Ã‚ÃÃ¿Â¡RÃ¶Â°70Å’MLÃ¿ï¿½eÅ“-ÃœZtÅ’â€ ?Å¸~Ã“Ã¹,â‚¬Â±ï¿½Â­ÂµÃ‡Â¿ÃŒe
lLÃ´Â¢bÃ’jÃªÃ‚Ã”Ã¿.ÃƒÃš
ÃšÂ¹Â¼h9Ã˜Â´LÃŒÃ†ÃÂ´Ã¬lÃ¬Å¸Â§â€œ7Â°Ã¸?Ã©0Ã¼Ã‹WÃ‚Ã–Ã”Ã°iÃ¿WÃšÃ†.Ã¶Ã¿â€˜ÂºÃ«?T&nbsp;Ã¸KÃ…â€â‚¬Â§â€™ÂµsÃ¾Ã¬ â‚¬Ã¢Ã¿BÅ½ÃšÅ¸Ã¢Ã¾ÃŸÂ«Ã°ï¿½Ã·Ã±i3Â°2Ã¼Ã·ÃºÃ»<aÃ¼Ã¿â€œÃ _Â®Ã¿eyÂ¼Ã¨Ã¾ï¿½Ã¿Å¡Ã»Ã£Ã´?4Ã½ï¿½Ã«ÃÃ¿ÂµÃ Ã¾s1iÃ¿Ã¯â€ ÃºÃ¿iâ€Ã¿Ã—Ã¼? Ã­Ã¿btÃ¿â€^Ã”Ã…ÃšÃºÂ¯aÃ¸="" â€šâ€œp6Ã¸Â¼ÃŠâ€“Â§Â¨ï¿½ï¿½â€¦ÂµÃ‡Ã«Ã±Å¸mÃ•lÃ¾<ï¿½="" a;;Â«Ã¿bÂ£Ã´Ã·iÃ¹g([3kï¿½-#Ã“?6-Å“d-ÃœmÅ’Ã¥-Å“ï¿½="">Kh`Ã­dÃ²ï¿½}â€¢?-Â²Ã¾Å’'oÃ§dÃ±WAi99Ã¾Ã“â€˜Â²Â¹â€¦â€˜â€¢Â­â€°â€œâ‚¬Ã¥Ã¿â€0pÃºÂ¬Â°3â‚¬ï¿½â€¢Ã¥/lÃ²Ã™Æ’ÃHÃ„Ã–ÃˆÃÃ¸OÂ§â„¢XÃ™Å½Å½0Å¸ï¿½++Ã€â€¹`Ã±Ã‰Ã¬Ã¸Ã¬Â¡9â‚¬Å¾ÃÃ–ÃÃ¹Ã“`Ã¯Ã¢Ã¬Ã³Ã™[GËœ?Â³ÃÃ†&nbsp;Ã¼Â³ÃµÃ„&nbsp;ÃºÃ¢Ãâ€¹Ã¼Â±Â³Ã¨Â¥Ã¾â€¦&gt;-eÃ¾â€¦8Ã´Â²Ã¿BÅ¸~rÃ¿DzÃ¹Â¡Oâ€¢"ÃOÆ’"Fâ€ OSÃ£Â¿AFÂ½Ã‰ÃŸ â‚¬ÃÃ´oï¿½@oÃ¾7Ã¸IlÃ±7Ã¸Ã‰lÃµ7Ã¸â„¢&nbsp;ÃµÃŸÃ gâ€ 6Ã¿â€šÅ¸o4Â½Ã­ÃŸÃ g\Â»Â¿ÃÃÂ¸Ã¶Æ’Å¸qÃ¿?Ã£:Ã½
~Ã–Ã“Ã¹/Ã¸om2rqtÃ¼Ã¬Ã£_OÃªgÃ¿â€ºZ|*Ã‡Ã„Ã„ÃÃ„fiÃÃË†;Ã˜Â²&amp;Ã¸Ã·câ€¢Å½Ã­Ã8|Ã¿uÃ„-â€ÃšÂ®â€“Ã«ï¿½B&nbsp;ÃÃ“
s^Ã¤Â¢@Ã§Ã¬~Ã¤Ã“&amp;Ã²	SÃ‘GÂ£â€¢::Æ’â€¢Ã®â€ wJ$ÃºRÃopSÃƒÃ¯IdÃÃ§'iÂ¦}Â©Å½M}f[c3Ã´â€¹&amp;Ã…AÂ·Ã›Â¯3â€4W{sÃ©Gb<dmÃ¥Ã¦ï¿½Ã¤ Â§tp="" Ã£ÃŸ#!198ËœÃ¡@â€šÃ›Ã’Ã›*Â«ffÃ›%hÅ“Â®Â¿Å½Å¸%Ã â€°="Â¥Ã´ï¿½0Â±nÃ·/â€”Ãï¿½[lÂ¥Ã ÃƒÃ›KÃÂ¦Ã³%vÂ³aKÃ©OfHwÂ»E0_b)oP:ï¿½ÃŠÃ‡Â°Râ‚¬" Å¡Ã¡â€Â²="" Ã‰,Ã .bo}Ã™n="" kÃ¹Ã¶$Â½fÂµ,="Ã’Ãœ" Ã¾â€ºÃ’="" Ã»Ã™Ã½iÃ¨Ãª%'dâ€š)yÂµ="" \xÃƒâ€škÃ¤g-Ã’ï¿½="" oÃŸwÃ­ï¿½Ã‹="" Ã™â€™Ã«Âª`Ã¨7Â»7Ã¬(Ã”Ã³]ÃŸÂ®k+nyÂ¤ÂªÃŸ="" Ã‹rl="" Ã™vÅ¾f%"fÂ«Ã¦Ã•}ÃËœâ‚¬5g}Â­-sÂ¢'xfy="" Â±vÃšÂ¥â€¢hnÃï¿½Ã®Ã$gÃœÃ¸{v]o_zytxË†Ã´ÃœÃœÂ¯,Â»Å¾Ãƒ)Å¡yâ€¦bcÃ–q6qÂ®Â¤tf5i\ÃÃ«qÃ†_ntÂ Ã§Âª2â€¹Ã¶Â¾bÃ‰Å¸dfsqÃ‘Ã§â„¢i~Ã³e2uÂ©ÂµÃœÂ¬ÃšÂ Â¯Ã="" \Ã‡y_Ã—Ã¢="" 8Ã›Ã­Ã‹Ã»Ã¹3(e2b="" $mzÃµâ€¡a7Â£Â¬Âªâ€œ="ÃŠÃ•ÃÃ…PÃšÅ¸râ€™vâ€¢Ã¡u9}Ãºl0Â³â€Â£;â€¦Â¯IÃµ=ÃÂ±ÃºÃ¾Ã·â€œË†Ã§Ã»='(ÃfÃ°Ã®7S-thÃ¯ÃŒ" Ã’d?Â¤]Ã–zÃ­Ã¢Â¡Ã²Ë†Â°,ÃŠÃ’Å¸Â½Ã¾ï¿½nÃ¥Â¦Â¹Ã¬Ã¾Å¡Ã¯Ã°Å½h7â€°Â©;Âµâ€º4Â¤Â°Ã¸Â¢Ã…]Â¨z]lÃ¥Ã§Ë†Ã€7ÃšÃÅ“â€¦Ã‹Â©tvÃ 9â„¢Ã¶0f((ptsÃ„â€˜Â±oÃ–,Æ’ÃˆÂ¡bÃ…Â¦$wklÂ¬]zâ€™utÃ²%2Â±xÅ½(1Ã»nÃŸuq2Æ’#Ã´`â€Ã£mÃ¤sÅ¡nhÃµÂ­Â°Â¶â€¢ï¿½{ï¿½Ãˆ;Ã„Ãšï¿½Ã–ï¿½Ã¸Ã£aÃ—Â£Å’Ë†bbeâ€¦Ã€Å’sÃ˜Â´Â©Ã®Â¸%"Ã”ËœÃ¡w]ï¿½Ã³Å’â€™mÃ’Âª#â€”="ï¿½ËœÅ¸Ã´Â«â€oÃ†Ã»iÃÃºÃ£â€(?AJÂ¨Â¼ÃŠÂ«" Â¶â€ºz*ï¿½Ã¸Ã´â„¢Ã†3wÃ¾Â®Ã«Â¶Å’Ã«hnÅ“Ã¯â€aÃ¸:ÃœÅ’dÃ¦â€(qjÅ½s.Ã…+Ã¿uÂ·*ÃidÅ’Ã˜Ã³tï¿½Ãâ€°Â¯)Ãºy%Â¼Â¾qsÃ‚Ã•fÃ¡Ã‡Â¼â€”Å’="" aâ„¢x62Â¸Â¢Ã®="" Ã²Ã£Ã¨Â®ï¿½%â€ºÃ“uâ€@Ã®Â°Â§e\<Ãâ€”:Â¦Â¼1(z="" Ã—ijb*="" kÃˆkÅ½Æ’â€¡Å¸Â©idÃ¡Â¡Ã³'bf)Â¿ÂµuÃbi:ï¿½Ã2qhÂµgÃÃ±Ã²Ãï¿½_Ã¥iÃ¡Ã¼Â¼â€ pn0Â»Â­!â€”Ã…â€™câ€Ã“Â³)}="" *â€¢qhÂ§Å’:hâ€šÂ¶Ã‘lfÂ¤Â¬â€ Ãœpâ€ºÃ¼Ã·Ã°Ãâ€”â‚¬6Ã‘+Ã¨Â«Â®Â»Ã¸ï¿½Â´Æ’pâ€ºÃ£Å¡ï¿½Æ’Ã‹3ÃˆbeÃ«â€ Ã;Ã°Ã¼Ã™?Ã‡Ã©6Ã–Â¤'Ã‡Ã†Ãºâ€ºÃ²Ã¼ÃÂºÃ¶u6Ã³rÂ©:Ãï¿½4dikâ‚¬â€ºjÂ¿Ã„Ã•%Ã="">Ã¤ÃÃÃºï¿½Â§â€™Ã—Ã§Ãrâ€“Ã‰Â¬NÃ¢Â¸5|QÅ¸IXAuZË†Ã½Ã‚{Ã©6Ã¿Ã…Ã†\3WÅ’ÃIRmÃ€ÃÂ¯Ã³gÂ´=Ã¬Ã€X7(ÂºÃ‚Ã–Ã¶4Ã°^mÃâ€ Å’,Ãªï¿½â‚¬7yÂ¦Ë†Ã…bâ€™ÃŒÃ¨
guÃ‚
&lt;Â·[~Ã‡Ã¨Â¶Â®Â¤â€šÂ°,H|%dÂºâ€¢Ã–8lÂ¥dUkhiÃ
Â¾Ãƒ/:l2Æ’Ã‰ÃšbC<mÃ…iËœâ€¢r ÃdÂ´.[&Ã¤q^a="" mÃ–Ã‚="Ã¯Å¸8Å¡Ã‰Ã¦7PÂ¡ËœÃ·xdï¿½Â®HE`i" ]kÃ…Ã‚ÃµÃ’Â­eÂ¨fÅ¡Ã“Â¡Â©Ã˜bâ€ Ã¤â€¹Å Ã©ï¿½Â£]Å“Ã¹â€™hÃ¼+;iâ€Ã²â€šâ€˜xÃ¶â€Ã³m="" 1[Ã»ÃÅ¸ï¿½uÂ®Â¥&hÃ¾Â¥Ã”Ã¤[Ã’Â¨`ÃŒkÃ³vÃÃÃ¡Â¾â€<Ã¾Ã¹Å¡Å¡+bÃrÃ¡Ë†Ëœ"Ã¯nÃ°;Ã¼Â¼oÂµÃ¸aÆ’â€˜"jeâ€â€Ã¥Ã¶Â®3="" c}hqï¿½="" ï¿½jÃ7ï¿½|jÃ6!3Ã‘Å¸Ã„Â¢Å¡rjÃl="" ,â€°^Ã="" Ã®Ã‡Å½_kÃÃˆÃ™Ã·Ã¨Ã¤Ã¢pâ„¢Â½pÂª9Å¾ï¿½Å½â„¢Ã£.Ã¦Â¦Âµï¿½Â®Ã—ÃÃ¨%i="" Ã¸Ã¦1Âª08â€Â¼<ï¿½ÂµÃ’ÂªwÂ¬"Ã“nÃ†Ã­ï¿½â€¹Å¾ÃºrÃ‘(Å’dÃ³Ã­Ã¸!qs]="" Â¦}ÃµÃ¾â„¢Â¦Å¡ÃgÂ®Ã¥3vÂ§Ã¯btâ„¢)Ã·ï¿½Â¹]hÃŠÃ”sÃ‹Ã°Ã¨ï¿½yÃ¦Ë†Ã©5Ã­Â¤Ã©:Ã«gÅ“Ã‰Ã­Ã•oï¿½Ã›Ã«c(josi-Ë†-bÂ¸Â¨xoÃâ€¢Â¯Â¸_Â¯(Â x~x.Ã›eï¿½y5@Â¿lÃ¹Ã£ÃªÃ‘Ã¸d6â€˜Ã½(Ã‡eqm;Â»Âº="" Ã–0lkyÂ¹"znÂ°ÃzpÃ¥Â¥hï¿½Ã â€°Ã´Ãš,Â¹â€”Ã»="" Â£*ÃŸâ€¦wÃï¿½Ã¿Ã†2Ã¤Ã·Ã¾Å’Ã™ÃœÃÃ»ÃˆnacÂ¹2Ã¦Ã‚="" ",1acÃƒÂ©â€tË†Ã„pÂ¯mpÃ»pbÃ±Â¡ÃÃ²="" Ã¨â€Ã§eï¿½Ã„Â´Ã Â¸Â¦ÃÃµÃ³m:="Ã…?Â§ÃšÃ½)0" Â´^,Â®="ÃyÂµeh{+Ã‹Ã â€”ÂªÃŒÃ¥RÃˆÃ¡ï¿½Ã¥Â¡DÂ©Â¹Ã¡Ã»Ã…Â°aÂ½rÃ²ÃÃªÃ”RÂ·&nbsp;Â½1.Â³Å’jF*Â¿Ãºâ€ºnKÂ³Â·:â€°â€šÂ«ÃˆÃ´SÃ,~Ã¸&nbsp;wÃ”EÃ‹â„¢">|ÃsÃ«Å“:Ã’Ã¦uÃ¢Â½BÃ®Â®TG&amp;â€¢Ã­8Ã´Â¢Ã»Ãï¿½0&nbsp;Ã¡Ã‚ÃÃ´6Ã¿UÃ±tÃŒ:Â¶&gt;EDâ„¢ï¿½Â£6Ã¼Â£Â·Ã©	&nbsp;?ÃšÅ¸Â²ZiÅ½â‚¬Ã£ÃµEÃ²:â‚¬|ÃQâ€š^H`Ã§â€°Ã«y&gt;Ãº4Ã´câ€”â‚¬KÅ ÃªÃ®ÃÂ´Â¨Â¯ÃŒÃ	'W-IÃ‚â€œÃ†Ã«XÂ¬ï¿½Ã­&gt;6[Y/ÃÂ¨Â¿.}â€¹Â¹JÃ³~S<wÂ±Â¯Â¯Ã´w*â€2Â¨y~ï¿½jÂ±Ã Â¥Ã™^Âµâ€š^Å¸â€:â€˜Â¬fÂ¸Ã¿ci`ÃŸÃ’Ã‹hâ€”iÃ©Â¦xzâ€¦â€œÃ¡Ãª &ttÃŒÅ ntÅ¾&ÃÅ“Ã–Â¹Â®Ã»Å¾Ã´g_|Ã”rxÃ·q(Â·wsqpÃ“3kÂ©iÃ¼Ãƒâ€˜Â©!,tlÃ‘pÃ»Â¬="">ÃŠÃ©Â±qâ€ºÂ´Ã¥Å“^ÂµÂ¹Â¿Ã±Ã—Â®Ã›â€¡fÃÃ‹MÃ´Ã½UÃ‘Ã¬hÃœï¿½n%Â£Ã¸V2Å¸â€šÂ¢Â­|jÃ¯PO..â€°yÃ‡Ã·Ã¯xcÂ­â€¹Â±Â°gÅ¾ÃŸZÂµ[hÅ’Ë†Â¥â‚¬Aâ„¢Ã§AÃ•o{voï¿½%Ã‡!Ã‘Ã‘Â¢Tâ€œq@AÃ™Ã¥Ã¼ÃœDÃ¤LÂ½â€¢,Ã‘(&amp;â€ 7drkï¿½Â¶|Å¸Â°Ã¦Ez&amp;&gt;Â¾Å¡â€œD %â€“^Â¿Pâ€ºÃ›Ã…Ãâ€¢	â€tÃªÃƒ5E"Â¾ï¿½G{Ãcâ€KSMe;
Ã˜ÂºÃ€â€“Ã„câ€“7Ã‘Â¥;Â¥Â«Â¹+Ã‚Ã’ï¿½PUâ€¢ay9t
[Â³Ã‘Ã°MÃœ 80g;~Å½ï¿½ Å’%8Ã„ï¿½1Â¬/ËœÅ¸Â¦ÂµÂ¾VÂ«Ã‘ÃÂ«ÃŠâ€¹iHs-Ã©Ã½Ã†Ã¨c%Ã¾ÃºÂ¼Ã¸tÃœÃµhÅ½Ã„ï¿½Â¿TmÃ£â€šr%ÃŸâ‚¬%ï¿½Ã¤Â«Ã°69Â».=â€¹Â»DÂ¯Ã¸:Ã»Â²kâ‚¬TsÃ—Ãº$/â€¢Ã€:ÃÂ´1Â­i%Ã¨KÂ¡Â½Â¬ÃÃœ;ByÃƒ~~;Â©â€¦â€š2Â±Â¦DÃ“+
sÃaÃ¦Ã¡Ã–\LÂ¨dXÃ´kvÂ¯iâ€šÃŠâ€¹mÃ¨KÃ±â‚¬Ã†wÂ´Ë†6Ã©Â¼Ã”Â¯Ã™vÂ«Â°Ã£)Â¾Â¹{Ã¡0wbÃ¤Ã»
Ã»Ã¾Ã¡NzUâ€*Â¤mÃŒÃ‘ÂªSuÂ¡%S`{~Ã«â‚¬Â§â€¡Æ’nÃ¹&gt;Ã™/6bGÂ³ÃœÃ´^^yJAÃºÃ¨Â¢Â²Ã·Å Sp|Ë†Ã‚&gt;Ã²_Ãµâ€°6Ã‡WÅ¾UgÂ¿â€“ZYâ€Â¤VÃ"Ã‰Ã¹ï¿½$,Ãº]ÃºÂ¶Ã¼&nbsp;Å¸uÃ_YsÂ¼Ã”Ãˆï¿½6Ã—Ã‰Ã­Ã¯Ã¢ÃºÃ 3Å â€ Âª]I^&lt;Â§OÃY+"9Â¤7Â¹Ã…ÃšÃ„Ã³Âµï¿½Ã²hï¿½5Ãº&amp;VÃ¢â€¹_Â³Ã¤Â¾MyÃª"Ã­FÃ£9)IaÃ°Ã‘JÃ’Ã»Ã¬Â»Â¨Ã±vÂµÃ¡\&lt;â€Å½	Ã—Ã‡Ã¡ï¿½q Å½ÃšÃ­Ã½ÃªÃ€uÃ­dDqNÂ¾hÃ²ZÃ¡â€œÃ–Ã¬xâ€º#JÃ£hÃ›byÃ¦~O{Â¥xâ€ºÃ”cxÂ£RSÅ â€¡Ã¬bÃ¡#Â½aâ€™Â£&amp;Â®Ã¼[Ã¡Ã½$jÂ®Sï¿½Ã¨â€:O0R]?â€zÃœÂ¹Â½Ã›Ã›â€¹ÃÃ£k/bbÅ“Ãµ$â€¹GÃ²Ã¬IÃ…ÃµÃ—Â¢â€¹Â©Â²ÃÂ£â€˜Å¸nZÃÃºdKâ€˜Ãºï¿½P(Â§Pâ€™CAÂºÂ¶3ï¿½dF/Ã¯T&lt;ÃŸ%Ã«Ã²ÃœÃŸNÃ©Â¯ÃŠLeâ€NUâ€¢Â·(Â½Å’Ã¬Å Â©Ã˜(VÅ’c[pÃ—.ï¿½Ã¯]pukâ€º&nbsp;Ã¸dÃ»Â¡Â¥Ã¸â€ºÃƒÃ¬Ã¤2RÃ½Ã¼NËœx)Ã·Â³Th+EÃÃ‰ÃÅ½dÅ¸ÃœÅ¾Y,~Â°Â©Ã¾ZÃ‰]9\Â´Â­Æ’Ã˜kÃŠYYÂ¸ÃƒcÂ±Å¸i]â€“Ã“Å¾Â²IAÂ¤Ed&amp;Ã’Ã¥Å“Å¾8%Ã’NnÃ£ÃÅ¸KÂ¾Ã½AmCÃ“Ã‰Ã›IÃ¿Ã½Å Mâ€˜Ã…Ã·Â«Ã²,ï¿½	Ãâ€“Ã•Ã”ï¿½â€¦â€¹Ã–Â«Ãˆ[~Ã­Ã­Â±1+&amp;Â¬Ã•3â€ºÂ¡â„¢Â§Qâ€™ÃŒÂ¤Âµ8Ã .Ã¬Ã„pâ€¢Â£CÃ˜Â¦_Â¿Â©Ã·Ã±Â·9bÃ„Ã gÃºIÃ¨JÃ–3lÂ¢Â§Ã§%ÃÅ½wÃ%Ã£#Â°]$Ã‡Ã›!Â¦Ã¬nâ€™Ã‚â‚¬QÃ¡kMÃƒQ"Â³Æ’3â€ %Ã™Ã˜4ÃÂ¯Âºâ€ºâ€”$ÃÂ¡â€šDÃ°&gt;Â®!Å¾PÅ 3e"vÃœÂ²Å½[Ã³Ã¤Ãº=â€¢Â¾â€“5CÃÃ jï¿½â€¢ÃƒdÃ½&amp;Ã‚1i}â€¦4ÃÃ¡{y$0ï¿½lÃ‰Â¯BÂ½	Ã–Fâ€“jÅ¡cPJâ€š&amp;â€™Ã†Ãx#Ã¾oÅ Ã¨Ã´|(MÂ²â€˜Ã†Ã¿Ã…Â¬dlâ€”Ã6[*â‚¬â€œÂ½3Ã»Â±WÂ¯*â„¢Ãºâ€ Ã”ÃªÂ½Â¦ÂºÂ¥â€šAÃ”BvÃ·mrÂ¸â€ x[X5Ã€&lt;ÃwZ+Â¾Ã‚Ã†Ã­ÃºÃ£Ã€Ë†â€œÃ¡Ã´QÃ§Â¶Âº?Ã¦&amp;Ã£Ë†â€ â„¢Ã±$Â©hlÃ­ÃÃˆÃ¿$Âºâ€ÃfÂ¤Ã¹eâ€”Â£Ã¬%OÂ®ÃÂ­cÆ’Ã„PFÂµâ‚¬Ã—Å½af9Æ’Â´Ã‡Ãw&nbsp;(â€Ã—mÃ§Ã¼Å¾zï¿½AÂ¦Ãï¿½Ã¨N%Â¿FIï¿½ï¿½N1Ã€Ã‚jeÃ·ï¿½=Ã‡Â¡Â¸â€°Ã·Â¤ï¿½6ÃŒÃ†TÃˆâ€“Æ’Ã¹ÃÃˆvÃ’Ã‰ÃµwmÃ€Â¢Â³Ã”A'Â¨Ã€^Å¡Ã¼Â´HbÂ¡Ã²qÂ»Å’Â¾Ã¬Å’Å¾Ã²vqÃ„5xï¿½PÂ¾Â¬=[â€¢Ã§â‚¬}Â¦l;Ã¸Â³!â€œï¿½Â­Ã Ã¨&amp;ÂºFÃ‰Â²Ã‡.?Â³'niY;4/[Ã¹'â€ºÃ„&nbsp;Ëœ$Ã´fÃ‡Ã„Â¾Ã¨0Â¦Â°&gt;Ã‚{pÂ´Ã´Ã¸SÃ›7oÂ¯Ã—â€&nbsp;Ã¯Ã§Ã¢Â²â„¢.Â¾Ã½Â¨Ã¼Â§Â¹Ã®n[LÂ¹Å â€˜â€CÂ°&amp;â€šÃ®Ã–Ã£Ã¥-d#$Å¸ÂªÃ†Ã˜Â°ÃƒÂ¼â€°1f Ãz!Æ’Â±Ã‰
'4Å dzjÃŒÃ’â€¢_=#Å’NÃ­$ÃƒVÃ‹,VÃ¨7Ã³(&gt;PÃ«~&nbsp;â€Ã²Ã‰kÂ½Â©w
â€œÃ»RPÃ™ÃÃ†Å¾Â¼Å¾Ã¹,63ÃÃ“FU)Â¦Ã‚ÂµÃŸÂ»ï¿½Â²9ï¿½)AUZÃawâ€Ã«*Ã†Ãªt+_Â¶Ã»â€Â¦TUï¿½Ã?Â»Å¡Ã¾Å’;1â€™Ã”t|9ï¿½Ã›ÂºpÃ°ÃªÃ¯J)â€”bÅ’I(â€Â¥bâ€HwÃµÃ§Â¡xâ‚¬=KhjÂ¡1â€¢Â¦ËœTM}Â³Ã¶6Ã‹ï¿½HkÃÂ¥KUhiÂ·Å¸â„¢Æ’wÅ’ï¿½Ã­O0Ã›ÃÂ¨Ã¤Ã›Å½ZÃµ q#ÃŠXÂ©Â¿ËœÃ¢Ã—Â«\(Ã‡]tÃ”â€“Å“FUÃÃ‰NÃ·â€ f3/dÂ§Â¿;Ã¬â€™Ã°n?IÃ€ÃŠ7Å¡QÃ€ÃšÂ´Ã›mQ`XÂ¯Gâ€Â©Ã„4=Ã‹[Ã Å½vÃ‡lÃœÅ½MÃŒy+Fâ€˜Â°Ã¨(â€šKÂ©Ã³Ã±Ã«Å½â€°Ã½&nbsp;Â¨&lt;Â±Ã¡Ã˜#â€œÂ«Å’Ã‚7Ã±$ï¿½Å¸Ã¿â€ cË†Ã‰:Â¹â€º&gt;ï¿½YÃ®Ã³Ã”Ã©ï¿½Ã„Â§Â³KÃ™Ã‹Ã³cN	Ã·Ã—Â©J5Å Ã£;Ã—Â¦Â¶qÃ¨Ã‚nÅ“MOÃ‰â€˜ÃÃ£Ãâ€œÃƒÃ–5Âªâ‚¬Â§Ã”Â¦Ã•`'Ã¨â€”nRâ€™ÃUÃ¬4NÃœeXâ€ Ãâ€¢dUQu'C
(â€:Ã™IÃâ€Ã´â€_@	Ã¦8â€šXÂ¸_b.Ë†7Ã¨a~Ã­Ã¹Â¼KÂ³WD(Ã¨Â¢Ã”.â€¢Â±&lt;Â·â€°ÃªÃ¶&nbsp;Å¸â€¢fÃ‘hÃ–ÃÃœ	Ã–Ã»â€“Ã…QÃ¡Å½Ã‡F:ÂªÃ…HÃÃ¯KÃ¼Â¸Ã¹&gt;BÂ¹)wâ€°PÂ¦ÃÂ¥VÃÃ±Â­ËœÃ™Ã¬qÃ¸9c1JÂ´Ã±Â½Ã¶Ã=Ã¤Wâ€¦Ã’ÃYobi}#ÃºÃ°pï¿½ÃƒyÃƒâ€™Â³9Ãâ€¢*â€¢Â¬|Â£=â„¢Å“ÃµÂ®ï¿½TÃ¸Ã°Ã˜f&lt;2Â¾ÃÃ¾Ã™qÅ¸0ÃkÃ¢Ã´PÃ¡â€°ÃŒaÂ¤|/_
)CÃƒâ€¢C
Ãª0pDÃÃÂ¤*Â¤Ã‡Å #Ã·/#Ã¾ï¿½eÃ°Â¨.ÃŠWKï¿½hÃ¦Â°ï¿½xÃ©VÃ–m7ÃŸ N
Â¶WÃ¬ÃÃ·â€”:
[W-Â»Ã¤Å½Â»Ã³â€škÅ Â¸ÃŸi|Ã¢Ã³,{\Â«ï¿½Â«Â¯^ÃºË†Ã¨bxÃ³Râ€šÅ r5 ÂªÂ°nÃ‡*ÃªÂ¼Â¦dÂ½Ã˜â€Ã¨Ã©Ã„Yï¿½+1Ã’Â²â€¹Ã°Â¤\ÃŒâ€ ]Â¶7%Â°Â©}LMNÃ£Â¶ÃŠÃŠÂ¦Â¸/*Â©ÃŒ}Ã©&nbsp;Ã†Â¥SÃŸQÃ¶[F(Ã¤Ã•â€¦ÃŸ|Â»"TÃšÃªÃ£ÂºOÃ¤Ã»â€™Ã®PrÅ¸Eyâ€˜ÃÂª,]Ã‹Ã‚Å ?PÃœy"Ã˜Å¡Qâ€¦QÃ™Â´]ZJÂ¼Ã£gÃ½i,jUj%Â¡Ã¡Ã–&nbsp;
qÅ¸~+â€Â¥Ã–oÂ§jÂ¦bÃ¾â€šÃ¬tâ€šÂ¨Ã¡Nï¿½&nbsp;Ã¶â€™AÃ†_GÃ‹Â¬Ë†ke"dXÂ¦Â³Ã³=ï¿½Â¡qâ„¢Ã²SÃ·Ã…â€Â©/3BzÅ¡Â°a0Pd*ÃŸï¿½Ã³Ãœ=Â¥+Â´tËœz#Ã™â€œÃ:q/Ë†Ã—Â¯Â¤Ã¨ÃˆiÆ’ÃŸÂ¥`wËœUÃcl'Beeâ€$Â¸Ã†Ã¤Ã Ã¥Â§7Ã&lt;]RÂ¼Å¡Â·m/sÂ¥Ã›k mÂ¤fÃ‘rc8ÃƒÂ¸Ëœ"E8&gt;"yâ€™%Ã™/ÃœÃ«&nbsp;)â€¦â€¦Jâ€¡&gt;Ã‚Æ’vÂ¼Ã– 3/Ã«[Â¬â€™ÂµÃBÃºdÂ±Ãœi[Â¡UÂµNbÃšÃÆ’ï¿½eÃ‰WKï¿½TÃ¡tâ€¦Ã«Ã€yÃ»{Â©QsLÂ«ï¿½3ÃˆÃ´ÃÃ±|:Â§_ÃŒÅ½Ã¢ÃªÃ­$Ã¹Ã—ÃºÃ»;UÃ…dÂ±
ÃœÂ½.U4rÂ³9OyÃEÃ¼Â¸StCÃ¯Ã©Ã·
FÃ©Ãâ€š\JÂ¤_Ã–Ã¢bÂ½_Mâ€™â€Â©Ã‰â€šÃ®Â¾0Ã§Â¥â€”Ã“Â³:Â¿Â±Â°Z7
Ã‹
Ã]ï¿½ÃŠÃŒ'-Ã²Â¥Ã¤@Â¢3qÃŠÃ›jÃhÂ®{Â¿ÃpÂ¤Â¡MÃ­â€¹_
â€“0uÂ§Ã”1Ã²ï¿½ÃŠOÃ—XPÃ³ÃÃ¯Ã”_'Â«Ã‚mlÂ©pÃ•ÃŠ	QfeGCÂ¢(â€ºÂ¿EÂ·mÃ©
ÃVÅ½Â¨ÃÅ½Â»Â«â€˜Ã˜26Ã¡1ÂµÃˆPâ€ 1ÃƒÂ¡(jÂ¨Â½ Ã›Ã©3Ã…Â«Â©ÃŸÅ“â€¡Ã‚CEÅ“L'
{Æ’Ãš=-Â¥ÃšNï¿½Ã*Ã´EÃ«Ã¨XÃ 4Â«Â¦Ã†=ÃŒÂª=b
/Stj*Ã¿ÃŠ#]Ã„ÃÃ·Ã¢â€ Ã¬^â€¹e
Â´5Â¢hA5hdÃSGd@Ã»Â¯â€œhÃ¼Ã¤Â±/+BaM92c!Â¿Ã—Â©[Ã†!Å“â„¢ÃÂ¤&gt;â€“gâ€¢Â´Â£Å½â€˜"&gt;,sÃ†Â¿Z*Âµjkâ€¦aâ‚¬Ã¶â€ Zl,Hâ€™=`Ë†â€“Â¤Â¨ï¿½Ã§GÂ¥â€°ï¿½Ã€Ã¦Ã€Ã²ï¿½Ã¡CÃbÃ’c4Â°E1[ÃšÃ€/Â©â€ºÂ±y8â€œÃ¹ÃÃ¿ËœÂ¿-Â¶Ã¨o?WÃÃ¸Â£Ã€ÃŠÂ¦Sb,}eï¿½Ã©vÃGâ€Ã…Ã‹Â±Â¾Ã˜&lt;Ã±ÃÃ²AbÃ¸Fz(Â¦ï¿½Âºâ€˜?'Ã¬yuÃ©Â¾â€šcÂ¿Â¹Ã½Ã”Ã»Â±4Â¤Â¡ÃÃ²â€°HVÅ¡7ZÃƒjt%Ã¹â€ PÂ°ï¿½+â„¢&gt;Ã€Ã¹â€“Â°ÃŠ1!
Ã”Â¥â€“UÅ½\;â€˜ï¿½iGb]sQ&amp;Â¦â€Ã„.Ã±Ã·RÂ³Hâ€šxÃ¬â€°Æ’ÂºÂ²Â°^Ãºi&nbsp;ÃÂ¹Å¸wÃ¦]iU&amp;Â§ÃbNÃ´Ã&lt;=Â½ÃRÂ»;Ã¿7&nbsp;&lt;.rlÂª&gt;	Ã…Â¹&amp;rÅ’ÃƒLÃ”Ã…t1Ã³â„¢Â¼1Â¸byNÃ¶kÂ±Ã©Å’Ã„Ã‘QÂºâ€¡â„¢ï¿½@W:yÃ Ã…\Æ’ XÂ´Ã­Ã®Ã1Ã‚ÂµÃ—Ã§Ã›Â©0?e&nbsp;â€¹iÃ±Ã€Â¬ÃŒÃZcÃ¶â„¢Â¾XÃ‘7ÃŸ4Ã§~ÃŒKtW';_â€˜Ã–Ã›Ë†Â´no{"ÃÃ“ÃŠwÃ¯Â²04Ã™ï¿½Å¡R1C_â‚¬Â±Ã¢Å¾qâ€¡SË†0â„¢( \ï¿½Qï¿½hÃ¯â€¦`{Â¢,Ã¨&lt;ÃŒ/8V}:0,Ã¦Â¤Ã¦sÃ´â€M=IiÃˆÂ±ÃË†Ëœ8tmKFËœgÃ¼Å¡6Ã¬]	5Ã·Ã·Â©Ã‡BUâ€ qFÂ§Â­oÂ£Ã‘?Ã·Å“ËœJï¿½zÂ¸pÃ©ÃÃµâ€¢Ã¶-!nË†Ã«ÃºRâ€™Ã£uÃ„Ã£;Ã•Â¡}lÅ½Ãœï¿½&amp;1ÃÃ®Ã”Ã(zÂ¤Â©czÅ½Ã¢Â¿Ã‰Â½'Â¼Â±dÂºâ€œÂ½IO9Ã—vÃ©Ã£Â¯HÃ¿Â¢ï¿½â€ â€œ1HÂ·â€Ã‹*Ã†Â³Ã¤â€¹Â»Å½U=DÃ¨wÃ§â€¡Â­Ã;Ã‰*Â©fÂ®bÂµ3Â¶Ã©Ã¯,Â¢Ã]â‚¬4Ã…Ã°Ã†ugÃ£Â¿N_XAÂ¨â€“â€ºMGÃ„Ëœï¿½Ã®â€œPyÃºpÃ²
43ÃÃ¤!-Ã²Ã“hÃ‘E+7Q"â€“cÂªÂ©Å¾Ã¨â€˜5Â¦ï¿½Ãâ€“Â­Ë†Â¯0K&nbsp;:â€°Å½Â½yâ€ºÂ¼)Å¸Å’Ã±YÃ´aË†ÃÂºREÃªÂ½sÃ©â€”Â¯Ã¾Ã˜Â¨KÃâ€™Y=vÂ³Ã˜Ã—Ã—Ã”ID%?/9zâ€¢WÂ­ÃÃ¯ 'â€™ÃÃ™
@Ã²â€œ7Kâ€ EÂ³â€˜Ã»?5ï¿½aaÂ½Â¯Ã¢;[Å Ã¡d,Ã‰Ã¡Ëœ3qâ„¢Ãyâ„¢Ãµï¿½8Â¿Ã¯Ã‘Â´Ã‘Ã³Â¨Ã¡\Ã¨{Â¾tï¿½Ã±Ã´ï¿½pt'Â¤Æ’F0â€ÃˆÂ²Â¥Ã’Â¼BÂ¸BNÃ'Ã¹Â©ï¿½Ã1SÃ ï¿½Â­Â£Ã‘EÂ´â€°Ãn[
eÃ­AÃ¹5yÂ¶Å½â€š`Âº</wÂ±Â¯Â¯Ã´w*â€2Â¨y~ï¿½jÂ±Ã Â¥Ã¹^Âµâ€š^Ã¿â€:â€˜Â¬fÂ¸Ã¿ci`ÃŸÃ²Ã«hâ€”iÃ©Â¦xzâ€¦â€œÃ¡Ãª></mÃ¥iËœâ€¢r></dmÃ¥Ã¦ï¿½Ã¤></aÃ¼Ã¿â€œÃ _Â®Ã¿eyÂ¼Ã¨Ã¾ï¿½Ã¿Å¡Ã»Ã£Ã´?4Ã½ï¿½Ã«Ã¯Ã¿ÂµÃ Ã¾s1iÃ¿Ã¯â€ ÃºÃ¿iâ€Ã¿Ã—Ã¼?></qfb'Ã»â„¢Ã¸Â¶mÃ»Ã¾3Ã¯Ã½Ã¾{Ã¿Ã»Ã¢Â¯Â¯Ã¾Â¯nÃµÂ®Â³Ã¶Ã®^Ã½Â»{Ãµ></fÃ½aï¿½ÃµÃ»Å¾6}Ã¨rï¿½mÃ¨Ã½aÃ¡3Ã¿ewn?&Â§y+Ã§ÃªÃ¢lvâ€“!#Â¹></krÃ—â€“></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://aleksandar-prokopec.com/resources/docs/p137-prokopec.pdf">http://aleksandar-prokopec.com/resources/docs/p137-prokopec.pdf</a></em></p>]]>
            </description>
            <link>http://aleksandar-prokopec.com/resources/docs/p137-prokopec.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-26190123</guid>
            <pubDate>Fri, 19 Feb 2021 05:35:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Anjuna Support for Amazon Nitro Enclaves]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26189898">thread link</a>) | @boxstream
<br/>
February 18, 2021 | https://www.anjuna.io/amazon-nitro-enclaves | <a href="https://web.archive.org/web/*/https://www.anjuna.io/amazon-nitro-enclaves">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.anjuna.io/amazon-nitro-enclaves</link>
            <guid isPermaLink="false">hacker-news-small-sites-26189898</guid>
            <pubDate>Fri, 19 Feb 2021 04:52:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[All in Good Time]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26189084">thread link</a>) | @oftenwrong
<br/>
February 18, 2021 | https://www.granolashotgun.com/granolashotguncom/easy-to-design-hard-to-build | <a href="https://web.archive.org/web/*/https://www.granolashotgun.com/granolashotguncom/easy-to-design-hard-to-build">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.granolashotgun.com/granolashotguncom/easy-to-design-hard-to-build</link>
            <guid isPermaLink="false">hacker-news-small-sites-26189084</guid>
            <pubDate>Fri, 19 Feb 2021 03:00:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Object Detection at 2530 FPS with TorchScript, TensorRT, and 8-Bit Quantization]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26189046">thread link</a>) | @cwaffles
<br/>
February 18, 2021 | https://paulbridger.com/posts/tensorrt-object-detection-quantized/ | <a href="https://web.archive.org/web/*/https://paulbridger.com/posts/tensorrt-object-detection-quantized/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><h5>December 31, 2020</h5><h2 id="intro">Intro
<a href="#intro">#</a></h2><p>My previous post <a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline">Object Detection at 1840 FPS</a> made some readers wonder who would need to detect anything at 1840 FPS, but my good friend and â€œperformance geekâ€ <a href="https://tanelpoder.com/">Tanel PÃµder</a> had a different response:</p><blockquote><p>Nice article, I wonder if you could get to 2000 FPS?</p></blockquote><p>Challenge accepted.</p><p>This article is a deep dive into the techniques needed to get there. We will rewrite Pytorch model code, perform <a href="https://github.com/NVIDIA/TensorRT/tree/master/tools/onnx-graphsurgeon">ONNX graph surgery</a>, optimize <a href="https://github.com/NVIDIA/TensorRT/tree/master/plugin/batchedNMSPlugin">a TensorRT plugin</a> and finally weâ€™ll quantize the model to bits (to 8 bit precision, that is). We will also keep track of divergence from full-precision accuracy with the COCO2017 validation dataset.</p><p>Code supporting this article can be found here: <a href="https://github.com/pbridger/tensorrt-ssd300-8bit-quantized">github.com/pbridger/tensorrt-ssd300-8bit-quantized</a>.</p><p>A quick preview of the final results:</p><div><p>
<label for="tabs-Preview-0">FP32 TensorRT</label></p><p><img src="https://paulbridger.com/posts/tensorrt-object-detection-quantized/files/ssd300.fp32.b16.k256.trt.svg"></p><p>
<label for="tabs-Preview-1">FP16 TensorRT</label></p><p><img src="https://paulbridger.com/posts/tensorrt-object-detection-quantized/files/ssd300.fp16.b16.k256.trt.svg"></p><p>
<label for="tabs-Preview-2">INT8 TensorRT</label></p><p><img src="https://paulbridger.com/posts/tensorrt-object-detection-quantized/files/ssd300.int8.b16.k256.trt.svg"></p><p>
<label for="tabs-Preview-3">All Results</label></p></div><p>So how do we get to 2000 FPS? My previous post already brought the big guns â€” a <a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline">TensorRT-optimized DeepStream pipeline</a> was needed to hit 1840 FPS running on 2x Nvidia 2080Ti cards. This time we will abandon TorchScript and <a href="https://developer.nvidia.com/deepstream-sdk">DeepStream</a>, and weâ€™ll put in the work to fully embrace TensorRT model compilation and execution.</p><h3 id="on-optimizing-arbitrary-numbers">On Optimizing Arbitrary Numbers
<a href="#on-optimizing-arbitrary-numbers">#</a></h3><p>1840 FPS, 2000 FPS, 2530 FPS â€” there is nothing special about any of these numbers, they are all hardware, resolution and model dependent. These optimization articles are about the practical usage of cutting-edge tools and techniques to achieve ambitious project goals or unlock cost savings.</p><p>Tuning a pipeline for throughput maximizes hardware utilization and efficiency in the datacenter, and it allows us to deploy larger models or more complex systems in compute-limited contexts (think IoT, embedded and mobile). Itâ€™s also just fun to explore the limits of powerful tools!</p><p>Letâ€™s get started with a baseline from the <a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline">previous article</a>.</p><h2 id="stage-0-deepstream-baseline">Stage 0: DeepStream Baseline
<a href="#stage-0-deepstream-baseline">#</a></h2><p>To recap, we got peak throughput with the DeepStream pipeline by using a hybrid model â€” a TensorRT-optimized SSD300 front-end with postprocessing code running in TorchScript in the libtorch runtime. All processing on GPU, of course. Hereâ€™s a reminder of some of the throughput milestones from the last article:</p><p>Why did we need TorchScript? Several common object-detection postprocessing operations â€” including thresholding and non-max-suppression (NMS) â€” canâ€™t be seamlessly exported from Pytorch to ONNX and compiled with TensorRT. Leaving these operations in TorchScript allowed us to get great performance without rewriting any model code or creating TensorRT plugins.</p><p>Looking at the performance trace from Nsight Systems, we can see the TorchScript postprocessing comes in just under 10 ms. When we compiled the inference step with TensorRT we saw around 43 ms of TorchScript turn into about 16 ms equivalent processing â€” so anything executing in TorchScript seems ripe for optimization.</p><p>Hereâ€™s what it looked like in Nsight Systems:</p><a href="https://paulbridger.com/posts/tensorrt-object-detection-quantized/images/ds_80pc_tensorrt_hacked_ds_two_batch.png"><figure><img src="https://paulbridger.com/posts/tensorrt-object-detection-quantized/images/ds_80pc_tensorrt_hacked_ds_two_batch_hudc758a7e69d7157937e6a1d7caab6946_489589_896x520_fill_box_top_2.png" width="896" height="520"><figcaption><small></small></figcaption></figure></a><p>Letâ€™s eliminate the TorchScript postprocessing and get the entire model running end-to-end in TensorRT.</p><h2 id="stage-1-end-to-end-tensorrt">Stage 1: End-to-End TensorRT
<a href="#stage-1-end-to-end-tensorrt">#</a></h2><p>The baseline Pytorch SSD300 model (including postprocessing) cannot be easily compiled with TensorRT for several reasons, all of which involve missing (or impossible) support for tensor operations:</p><ul><li><p>Subscripted tensor assignment results in <code>ScatterND</code> (indexed assignment) nodes in ONNX.</p></li><li><p>Score thresholding uses a mask operation, which cannot be expressed in the fixed-dimension world of TensorRT.</p></li><li><p>Torchvisionâ€™s batched non-max suppression (NMS) operation has no exact equivalent in TensorRT.</p></li></ul><p>We can fix the first by tweaking model code and re-exporting to ONNX, but to fix the other issues weâ€™ll have to modify the ONNX computational graph â€” replacing these operations with a TensorRT plugin.</p><h3 id="11-rewriting-subscripted-tensor-assignment">1.1 Rewriting Subscripted Tensor Assignment
<a href="#11-rewriting-subscripted-tensor-assignment">#</a></h3><p>The baseline postprocessing contains some bounding-box rescaling code:</p><div><pre><code data-lang="python">        <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>:</span><span>2</span><span>]</span> <span>=</span> <span>self</span><span>.</span><span>scale_xy</span> <span>*</span> <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>:</span><span>2</span><span>]</span>
        <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>2</span><span>:]</span> <span>=</span> <span>self</span><span>.</span><span>scale_wh</span> <span>*</span> <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>2</span><span>:]</span>

        <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>:</span><span>2</span><span>]</span> <span>=</span> <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>:</span><span>2</span><span>]</span> <span>*</span> <span>self</span><span>.</span><span>dboxes_xywh</span><span>[:,</span> <span>:,</span> <span>2</span><span>:]</span> <span>+</span> <span>self</span><span>.</span><span>dboxes_xywh</span><span>[:,</span> <span>:,</span> <span>:</span><span>2</span><span>]</span>
        <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>2</span><span>:]</span> <span>=</span> <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>2</span><span>:]</span><span>.</span><span>exp</span><span>()</span> <span>*</span> <span>self</span><span>.</span><span>dboxes_xywh</span><span>[:,</span> <span>:,</span> <span>2</span><span>:]</span>

        <span># transform format to ltrb</span>
        <span>l</span><span>,</span> <span>t</span><span>,</span> <span>r</span><span>,</span> <span>b</span> <span>=</span> <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>0</span><span>]</span> <span>-</span> <span>0.5</span> <span>*</span> <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>2</span><span>],</span>\
                     <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>1</span><span>]</span> <span>-</span> <span>0.5</span> <span>*</span> <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>3</span><span>],</span>\
                     <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>0</span><span>]</span> <span>+</span> <span>0.5</span> <span>*</span> <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>2</span><span>],</span>\
                     <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>1</span><span>]</span> <span>+</span> <span>0.5</span> <span>*</span> <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>3</span><span>]</span>

        <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>0</span><span>]</span> <span>=</span> <span>l</span>
        <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>1</span><span>]</span> <span>=</span> <span>t</span>
        <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>2</span><span>]</span> <span>=</span> <span>r</span>
        <span>bboxes_batch</span><span>[:,</span> <span>:,</span> <span>3</span><span>]</span> <span>=</span> <span>b</span></code></pre></div><p>This code will export to an ONNX graph without issue, but parsing with TensorRT will result in an error: <code>No importer registered for op: ScatterND</code> or <code>getPluginCreator could not find plugin ScatterND</code>.</p><p>We can rewrite the code to avoid generating <code>ScatterND</code> nodes by not using subscript assignment:</p><div><pre><code data-lang="python">    <span>def</span> <span>rescale_locs</span><span>(</span><span>self</span><span>,</span> <span>locs</span><span>):</span>
        <span>locs</span> <span>*=</span> <span>self</span><span>.</span><span>scale_xyxywhwh</span>

        <span>xy</span> <span>=</span> <span>locs</span><span>[:,</span> <span>:,</span> <span>:</span><span>2</span><span>]</span> <span>*</span> <span>self</span><span>.</span><span>dboxes_xywh</span><span>[:,</span> <span>:,</span> <span>2</span><span>:]</span> <span>+</span> <span>self</span><span>.</span><span>dboxes_xywh</span><span>[:,</span> <span>:,</span> <span>:</span><span>2</span><span>]</span>
        <span>wh</span> <span>=</span> <span>locs</span><span>[:,</span> <span>:,</span> <span>2</span><span>:]</span><span>.</span><span>exp</span><span>()</span> <span>*</span> <span>self</span><span>.</span><span>dboxes_xywh</span><span>[:,</span> <span>:,</span> <span>2</span><span>:]</span>

        <span>wh_delta</span> <span>=</span> <span>torch</span><span>.</span><span>cat</span><span>([</span><span>wh</span><span>,</span> <span>wh</span><span>],</span> <span>dim</span><span>=-</span><span>1</span><span>)</span> <span>*</span> <span>self</span><span>.</span><span>scale_wh_delta</span>
        <span>cxycxy</span> <span>=</span> <span>torch</span><span>.</span><span>cat</span><span>([</span><span>xy</span><span>,</span> <span>xy</span><span>],</span> <span>dim</span><span>=-</span><span>1</span><span>)</span></code></pre></div><p>Problem solved, this code exports without issue to ONNX and then TensorRT. See <a href="">subscript_assignment.py</a> in the repo for an isolated example:</p><div><p>
<label for="tabs-subscript_assignment-0">Code: subscript_assignment.py</label></p><div><div><pre><code data-lang="python">    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>X</span><span>):</span>
        <span>X</span><span>[:,</span> <span>:</span><span>2</span><span>]</span> <span>=</span> <span>0</span>
        <span>return</span> <span>X</span>
</code></pre></div></div><p>
<label for="tabs-subscript_assignment-1">ONNX Graph</label></p><div><a href="https://paulbridger.com/posts/tensorrt-object-detection-quantized/images/subscript_assignment.png"><figure><img src="https://paulbridger.com/posts/tensorrt-object-detection-quantized/images/subscript_assignment_hu463f7206af736e81218c08508fc927eb_438088_896x800_fill_box_center_2.png" width="896" height="800"><figcaption><small></small></figcaption></figure></a></div><p>
<label for="tabs-subscript_assignment-2">Export Output</label></p><div><div><pre><code data-lang="markdown">[TensorRT] WARNING: /build/TensorRT/parsers/onnx/onnx2trt_utils.cpp:220: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.
[TensorRT] WARNING: /build/TensorRT/parsers/onnx/onnx2trt_utils.cpp:246: One or more weights outside the range of INT32 was clamped
<span>[TensorRT] ERROR: INVALID_ARGUMENT: getPluginCreator could not find plugin ScatterND version 1
</span>exporting SubscriptAssign to models/subscript_assign.onnx
compiling models/subscript_assign.onnx with TensorRT
</code></pre></div></div></div><h3 id="12-tensorrt-and-masking">1.2 TensorRT and Masking
<a href="#12-tensorrt-and-masking">#</a></h3><p>Masking is essential to efficient SSD postprocessing. It needs to be done before calculating NMS because of the large number of possible detection bounding boxes (over 8000 for each of 81 classes for this model). Without first reducing the candidate boxes the NMS calculation would be hugely expensive.</p><p>However, TensorRT compilation depends on tensor dimensions being known at compile time. TensorRT layer output dimensions are allowed to vary based on input dimensions, but not based on the result of the layer calculation itself. Unfortunately, this is exactly what supporting masking in TensorRT would require.</p><p>Masking in Pytorch will result in <code>NonZero</code> ONNX nodes which cannot be expressed as a TensorRT layer or plugin. TensorRT fails with <code>No importer registered for op: NonZero.</code> or <code>getPluginCreator could not find plugin NonZero</code>. See <a href="">masking.py</a> in the repo for an example:</p><div><p>
<label for="tabs-masking-0">Code: masking.py</label></p><div><div><pre><code data-lang="python">    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>X</span><span>):</span>
        <span>X</span> <span>=</span> <span>X</span><span>[</span><span>X</span><span>.</span><span>sum</span><span>(</span><span>dim</span><span>=-</span><span>1</span><span>)</span> <span>&gt;</span> <span>0</span><span>]</span>
        <span>return</span> <span>X</span>
</code></pre></div></div><p>
<label for="tabs-masking-1">ONNX Graph</label></p><div><a href="https://paulbridger.com/posts/tensorrt-object-detection-quantized/images/masking.png"><figure><img src="https://paulbridger.com/posts/tensorrt-object-detection-quantized/images/masking_hu463f7206af736e81218c08508fc927eb_219236_896x320_fill_box_center_2.png" width="896" height="320"><figcaption><small></small></figcaption></figure></a></div><p>
<label for="tabs-masking-2">Export Output</label></p><div><div><pre><code data-lang="markdown"><span>[TensorRT] ERROR: INVALID_ARGUMENT: getPluginCreator could not find plugin NonZero version 1
</span>/opt/conda/lib/python3.6/site-packages/torch/onnx/symbolic_opset9.py:2329: UserWarning: Exporting aten::index operator with indices of type Byte. Only 1-D indices are supported. In any other case, this will produce an incorrect ONNX graph.
  warnings.warn("Exporting aten::index operator with indices of type Byte. "
/opt/conda/lib/python3.6/site-packages/torch/onnx/symbolic_opset9.py:591: UserWarning: This model contains a squeeze operation on dimension 1 on an input with unknown shape. Note that if the size of dimension 1 of the input is not 1, the ONNX model will return an error. Opset version 11 supports squeezing on non-singleton dimensions, it is recommended to export this model using opset version 11 or higher.
  "version 11 or higher.")
exporting Masking to models/masking.onnx
compiling models/masking.onnx with TensorRT
</code></pre></div></div></div><p>One solution here would be to replace a probability-threshold mask with a top-k approach, which results in an output with fixed dimensions and can therefore be executed in TensorRT. However because we need both top-k and NMS to complete model postprocessing, there is a better alternative.</p><h3 id="13-replacing-masking-and-nms-with-batchednmsplugin">1.3 Replacing Masking and NMS with <code>batchedNMSPlugin</code>
<a href="#13-replacing-masking-and-nms-with-batchednmsplugin">#</a></h3><p>TensorRT ships with a set of open source plugins that extend the functionality of the core layers. One such layer (<a href="https://github.com/NVIDIA/TensorRT/tree/master/plugin/batchedNMSPlugin">batchedNMSPlugin</a>) does almost exactly what we need: NMS on some top-k detections.</p><p>So how do we use it? We will have to go beyond the simple Pytorch -&gt; ONNX -&gt; TensorRT export pipeline and start modifying the ONNX, inserting a node corresponding to the <code>batchedNMSPlugin</code> plugin and cutting out the redundant parts.</p><p>A library called <a href="https://github.com/NVIDIA/TensorRT/tree/master/tools/onnx-graphsurgeon">ONNX GraphSurgeon</a> makes manipulating the ONNX graph easy, all we need to do is figure out where to insert the new node. This is the full postprocessing computational graph (not including all the convolutions):</p><a href="https://paulbridger.com/posts/tensorrt-object-detection-quantized/images/full_postprocessing.png"><figure><img src="https://paulbridger.com/posts/tensorrt-object-detection-quantized/images/full_postprocessing_hu463f7206af736e81218c08508fc927eb_562695_896x940_fill_box_bottom_2.png" width="896" height="940"><figcaption><small></small></figcaption></figure></a><p>There are two ways to figure out where to insert the <code>batchedNMSPlugin</code>:</p><ul><li><p>The hard way is to stare at the ONNX representation above, map it back to Pytorch code and figure out which tensors are the correct inputs to the plugin. Be my guest.</p></li><li><p>The easy way is to tweak the Pytorch model code to produce exactly the outputs the plugin will need. These are then easily accessible in the ONNX graph as outputs, and can be plugged into a new <code>batchedNMSPlugin</code> node as inputs.</p></li></ul><p>See the <code>build_onnx</code> function to review how I did it (the easy way). The resulting modified ONNX looks like this:</p><a href="https://paulbridger.com/posts/tensorrt-object-detection-quantized/images/nms_plugin_postprocessing.png"><figure><img src="https://paulbridger.com/posts/tensorrt-object-detection-quantized/images/nms_plugin_postprocessing_hu463f7206af736e81218c08508fc927eb_474181_896x955_fill_box_bottom_2.png" width="896" height="955"><figcaption><small></small></figcaption></figure></a><p>This looks a lot simpler, but more importantly this ONNX can be compiled and optimized end-to-end with TensorRT. See the <code>build_trt_engine</code> function for details.</p><h3 id="14-results-and-analysis">1.4 Results and Analysis
<a href="#14-results-and-analysis">#</a></h3><p>Compiling the modified ONNX graph and running using 4 CUDA streams gives 275 FPS throughput. With <code>float16</code> optimizations enabled (just like the DeepStream model) we hit 805 FPS.</p><blockquote>Mean average precision (IoU=0.5:0.95) on â€¦</blockquote></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://paulbridger.com/posts/tensorrt-object-detection-quantized/">https://paulbridger.com/posts/tensorrt-object-detection-quantized/</a></em></p>]]>
            </description>
            <link>https://paulbridger.com/posts/tensorrt-object-detection-quantized/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26189046</guid>
            <pubDate>Fri, 19 Feb 2021 02:55:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[12 requests per second: A realistic look at Python web frameworks]]>
            </title>
            <description>
<![CDATA[
Score 267 | Comments 105 (<a href="https://news.ycombinator.com/item?id=26188765">thread link</a>) | @gilad
<br/>
February 18, 2021 | https://suade.org/dev/12-requests-per-second-with-python/ | <a href="https://web.archive.org/web/*/https://suade.org/dev/12-requests-per-second-with-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<article>

<figure>
<img src="https://suade.org/content/images/2021/01/The_Tortoise_and_the_Hare_-_Project_Gutenberg_etext_19993-1.jpeg" alt="12 requests per second">
</figure>
<section>
<div>
<blockquote>
<p>A realistic look at Python web frameworks</p>
</blockquote>
<p>If you take a look around the blogosphere at various benchmarks for Python web frameworks, you might start to feel pretty bad about your own setup. Or, alternatively, super-hyped about the possibilities.</p><p>Consider, for instance, the incredible work of the guys at <a href="https://magic.io/blog/uvloop-blazing-fast-python-networking/">magic stack</a>, getting <strong>100,000 requests per second</strong> from <a href="https://github.com/MagicStack/uvloop">uvloop</a> in a single thread. This is on par with compiled language like Go's performance.</p><p>But that benchmark doesn't really cover a fully fleshed out web framework, right? We need a lot more functionality and structure from our frameworks than reading and writing bytes. What about fully fleshed-out web-frameworks in python?</p><p>One such framework is <a href="https://github.com/sanic-org/sanic">Sanic</a>, which again has been shown to have similar performance: <strong>100,000</strong> requests per-second. Or there's <a href="https://vibora.io/">Vibora</a>. Not only does this claim to be a drop-in replacement for <a href="https://github.com/pallets/flask">Flask</a>, but it also has its own templating engine. And it handles <strong>350,000 requests per second</strong>!</p><p>Even more mind-blowing is <a href="https://github.com/squeaky-pl/japronto">Japronto</a> which claims an insane <strong>1.2 million requests per-second</strong> in a single thread ğŸ¤¯ trouncing the performance of other languages and frameworks:</p><p><img src="https://raw.githubusercontent.com/squeaky-pl/japronto/master/benchmarks/results.png" alt="https://github.com/squeaky-pl/japronto"></p><p>Recently we've been doing a lot of work improving the performance of our Python APIs. Currently we're running <a href="https://github.com/pallets/flask">Flask</a>, and we initially had a single question: <em>how can we serve more requests from a single worker thread? </em>But looking at these benchmarks had us asking more:</p><ol><li>Can we meaningfully compare them to our setup?</li><li>How realistic are they for a full production application?</li><li>Would we be better using one of these frameworks over Flask?</li></ol><p>In other words, how much should we trust these benchmarks? And to what extent should they influence our choice of technology?</p><p>In order to answer these questions, in this post, I benchmark a realistic Flask application along with it's <a href="https://github.com/sanic-org/sanic">Sanic</a> equivalent. I'm going to guess that most readers come from a background with one of the more "traditional" Python frameworks (<a href="https://github.com/pallets/flask">Flask</a> or <a href="https://www.djangoproject.com/">Django</a>), and it's certainly more relevant to devs here at Suade Labs. For this reason, I run the Flask app in a number of different ways, to see what the best bang for our buck is: how performant can we make our application with (almost) zero changes to the code? Along the way we'll pick up some tips for the original question: <em>how can we serve more requests from a single worker thread?</em></p><p><strong>Sidenote: </strong>if you're new to Python's web frameworks, or its asynchronous libraries, take a look at [1] from the addenda at the bottom of this post for a quick explainer. This post mostly assumes you know these things.</p><h2 id="the-baseline">The baseline</h2><p>First let's run some simple "Hello, World!" benchmarks on our system to get a meaningful baseline for comparison. For reference, the Flask benchmarks on <a href="https://www.techempower.com/benchmarks/#section=data-r18&amp;hw=ph&amp;test=fortune&amp;l=zijzen-f">techempower</a> give 25,000 requests per second.</p><p>Here's our Flask app:</p><pre><code>app = Flask(__name__)

@app.route("/", methods=["GET", "POST"])
def hello():
    if request.method == "GET":
        return "Hello, World!"

    data = request.get_json(force=True)
    try:
        return "Hello, {id}".format(**data)
    except KeyError:
        return "Missing required parameter 'id'", 400</code></pre><p>I ran it under a variety of conditions. First "raw" via <code>python app.py</code>, and then under <a href="https://gunicorn.org/">Gunicorn</a> with a single <code>sync</code> worker via <code>gunicorn -k sync app:app</code> and finally Gunicorn with a single <a href="https://github.com/gevent/gevent">gevent</a> worker via <code>gunicorn -k gevent app:app</code>. In theory Gunicorn should handle concurrency and dropped connections much better than the raw python, and using the gevent worker should allow us to do asynchronous IO without changing our code [2a]. We also ran these benchmarks under <a href="https://www.pypy.org/">PyPy</a>, which in theory should speed up any CPU-bound code without making any changes (if you haven't heard of PyPy see [2b] in the addenda below for a quick explanation and some terminology).</p><p>And what about Sanic? Well, here's the "rewrite" of our app:</p><pre><code>app = Sanic(__name__)

@app.route("/", methods=["GET", "POST"])
async def hello(request):
    if request.method == "GET":
        return text("Hello, World!")

    data = request.json
    try:
        return text("Hello, {id}".format(**data))
    except KeyError:
        raise InvalidUsage("Missing required parameter 'id'")</code></pre><p>And here are the results:</p><figure><img src="https://suade.org/content/images/2021/01/hello_world-3.png" alt="" srcset="https://suade.org/content/images/size/w600/2021/01/hello_world-3.png 600w, https://suade.org/content/images/size/w1000/2021/01/hello_world-3.png 1000w, https://suade.org/content/images/2021/01/hello_world-3.png 1161w" sizes="(min-width: 720px) 720px"></figure><div><p>Some technical details: I used Python 3.7 with the regular CPython interpreter and Python 3.6 with PyPy 7.3.3. At the time of writing, running 3.6 is the latest PyPy interpreter, and their Python 2.7 interpreter is faster in some edge cases, but as Python 2 is <a href="https://www.python.org/doc/sunset-python-2/">officially dead</a>, I don't believe it productive to benchmark. My system details are available in the addenda [3]. I used <a href="https://github.com/wg/wrk">wrk</a> to actually execute the benchmarks.</p><p>I'll break the results down in two parts. First: Sanic dominates, with 23,000 requests a second, although running our Flask app under Guncorn + gevent and PyPy does a pretty good job at keeping up. Second: what's going on with the performance range for our Flask app?</p></div><p>Under CPython, we see that using Gunicorn quadruples the number of Flask requests per second from 1,000 to 4,000 and using a gevent worker adds a mild (sub 10%) speed boost to this. The PyPy results are more impressive. In the raw test, it is churning through 3,000 requests a second; it received the same 4x speed boost from Gunicorn, getting us to 12,000 requests a second; finally with the addition of gevent, it cranks up to 17,000 requests a second, 17x more than the raw CPython version without changing a single line of code.</p><p>I was quite struck by the fact that gevent had such little effect on the CPython process - probably this is because the CPU is maxed out at this point. On the other hand, it seems that PyPy's better speed means it is still spending time waiting on system calls / IO, even under Gunicorn. Adding gevent to the mix means that it switches between concurrent connections, processing them as fast as the CPU will let it.</p><p>To get a real sense of this, I ran the benchmark whilst monitoring CPU usage. Here's a short test against the raw app under PyPy:</p><figure><img src="https://suade.org/content/images/2021/01/sync_cpu_usage.png" alt="" srcset="https://suade.org/content/images/size/w600/2021/01/sync_cpu_usage.png 600w, https://suade.org/content/images/2021/01/sync_cpu_usage.png 919w" sizes="(min-width: 720px) 720px"></figure><p>You can see that the program hops between CPU cores and rarely utilises 100% of a given core. On the other hand, here's part of a much longer test against the Gunicorn gevent worker under PyPy:</p><figure><img src="https://suade.org/content/images/2021/01/gevent_cpu_usage.png" alt="" srcset="https://suade.org/content/images/size/w600/2021/01/gevent_cpu_usage.png 600w, https://suade.org/content/images/2021/01/gevent_cpu_usage.png 900w" sizes="(min-width: 720px) 720px"></figure><p>Now it's evident that there is no switching between CPU cores (the process has become "sticky") and the individual core is being utilised to a far higher degree.</p><p><strong>Key takeaways</strong>: Sanic wins. PyPy is fast. Run your "traditional" app under Gunicorn.</p><h2 id="realistic-benchmarks">Realistic benchmarks</h2><div><p>The benchmark above, while fun, is pretty meaningless for real-world applications. Let's add some more functionality to our app!</p><p>First, we'll allow users to actually store data in a database, which we'll retrieve via an ORM (in our case <a href="https://www.sqlalchemy.org/">SQLAlchemy</a>, the de-facto stand-alone ORM in python). Second, we'll add input-validation to make sure our users get meaningful error messages, and that we're not accepting junk that crashes our app. Finally we'll add a response marshaller to automate the process of converting our database object to JSON.</p></div><p>We'll write a simple book store app, for a publishing house. We have a number of authors each writing zero or more books in several genres. For simplicity, each book has only a single author, but can have multiple genres - for example we could have a book which is in both the "Existential Fiction" and "Beatnik Poetry" categories. We're going to add 1 million authors to our database and roughly 10 million books. [4]</p><p>Our SQLAlchemy models look a little like this:</p>
<pre><code>class Author(db.Model):
    id = db.Column(UUIDType, primary_key=True)
    name = db.Column(db.String, nullable=False)
    ... # snip!

class Book(db.Model):
    author_id = db.Column(
        UUIDType, db.ForeignKey("author.id"), nullable=False, index=True
    )
    author = db.relationship("Author", backref="books")
    ... # snip!
</code></pre>
<p>To marshal these, we use <a href="https://marshmallow.readthedocs.io/en/stable/">Marshmallow</a>, which is a popular Python marshalling library. Here's an example of the Marshmallow model for the Author overview:</p>
<pre><code>class Author(Schema):
    id = fields.Str(dump_only=True)
    name = fields.Str(required=True)
    country_code = EnumField(CountryCodes, required=True)
    email = fields.Str(required=True)
    phone = fields.Str(required=True)
    contact_address = fields.Str(required=True)
    contract_started = fields.DateTime(format="iso")
    contract_finished = fields.DateTime(format="iso")
    contract_value = fields.Integer()
</code></pre>
<p>In our endpoints these are used for validating input and returning results like so:</p>
<pre><code>@bp.route("/author", methods=["GET", "POST"])
def author():
    """View all authors, or create a new one."""

    if request.method == "GET":
        args = validate_get(marshallers.LimitOffsetSchema())
        limit = args["limit"]
        offset = args["offset"]

        authors = Author.query.limit(limit).offset(offset).all()
        return jsonify(marshallers.authors.dump(authors))

    if request.method == "POST":
        author = Author(**validate_post(marshallers.author))

        db.session.add(author)
        db.session.commit()

        return jsonify({"id": author.id})
</code></pre>
<p>The full source code can be viewed in the <a href="https://github.com/olliemath/async_python">GitHub repo</a>. Here, the thing to note is that <code>marshallers.foo</code> is an instance of a <a href="https://marshmallow.readthedocs.io/en/stable/">Marshmallow</a> schema, which can be used both to validate a Foo input, for instance in a POST request, as well as to marshal Foo instances ready for returning as JSON.</p>
<p>In order to actually perform asynchronous database requests, some fancy footwork is required with patching libraries, which depends on which postgres connector you use. SQLAlchemy does not support this out of the box, and in fact its primary developer has a great post arguing that <a href="https://techspot.zzzeek.org/2015/02/15/asynchronous-python-and-databases/">an async ORM is not always a great idea</a>. Juicy technical details in addenda [5], but beware that just using a Gunicorn gevent worker will not necessarily get you what you want.</p><p>PyPy tends to suffer a performance hit when using C-extensions and libraries instead of pure python, conversely CPython should get a performance boost from the C-based libs. To take account of this I tested two different underlying database connectors: both <a href="https://github.com/psycopg/psycopg2">psycopg2</a> and a â€¦</p></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://suade.org/dev/12-requests-per-second-with-python/">https://suade.org/dev/12-requests-per-second-with-python/</a></em></p>]]>
            </description>
            <link>https://suade.org/dev/12-requests-per-second-with-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26188765</guid>
            <pubDate>Fri, 19 Feb 2021 02:21:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dismantling Racism in Mathematics Instruction [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26188717">thread link</a>) | @kofejnik
<br/>
February 18, 2021 | https://equitablemath.org/wp-content/uploads/sites/2/2020/11/1_STRIDE1.pdf | <a href="https://web.archive.org/web/*/https://equitablemath.org/wp-content/uploads/sites/2/2020/11/1_STRIDE1.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>Ã¥,Â®kÂ´yX=â„¢:Â§â€™Ã‹Â§fâ€¦-@rÃ¯P
Â¢â€
Â´Å¾Ã’Ã›â€ ~hÃ”AÃ™â€œo
UÃsÂ»Ã‘Â²@mÃˆ3Â±lAÃ™Ë†2@XÃ¥Ã¸Â©1MÃ²H&amp;ï¿½Ã‚	TÃ–Ã—Â¹Ã¤Å“ Â¡Ã¨Â¹
ÃšÃ¶Â²Â±Ã™Â©Ã–CÃ…]Ã¶Ã‡Ã©â€šÃ– Â§&nbsp;VECÃÂ£CTÃºÂ£Ã³Å¾\Ã‹â‚¬!ToÃ„SL#Ã¢	y(7^Ã…2
:ÂºdÂ¥Ã—a$}AÃ¥â€¹Â¸Ã£gBERÂº Â£â€¦Â²Ã·Å’Â¥=Â¤â€â‚¬â€|Ã—â€œÂ¦l&nbsp;aÃŒâ€Å“â€¦T1
Å¡Â­hâ€ºâ€¢Ã‘ÃƒÃ·Â­Ã•U=Â¦â€“vâ€ºÂ§Ã¨
Ã²P.	Â¹7Ã˜Å½!ÃÃ”JEÃºÂ¾|*Â½Æ’Ã¹â€šÃ³â€šJï¿½Âµâ€œÃ“ÃÃ±Ã’+Ã¤HÃ¾{M~Ã’&gt;Ã»Ã­Â¾#5â€¢&nbsp;â€°Â¥Å¡Ãšâ€°.^â€˜ÃºÃ”Ã§	9#G~â€™Ã¹TÃ´KÃ˜Ã¿Â¨	Æ’	ï¿½â€¹ËœÅ¡BNâ€ SÂ§Â´BÂ©Â¥cs6HCÃ•2Ã‘VÂ·Ãµ'_QÃ¿XÂ»Ã²LÃ’u_	â€”Æ’)Â²lÃ»â‚¬fÂ½Ã¯Å½Â£Ã„c Ã¤â€ºYÃ›Ã’ÃªÃ™,uÃœbjÂªLÃµcÅ’Ã Ã¯Ã»<rf8jâ€œ3Â¹'yÃ—Â³ÃŠz2ï¿½):8gl{bucï¿½Ã…:Ã¨Å Å¾Å“â‚¬â€™*eÃ†2ÃÃºv9ÃµÂ¦;@Ã¬qÂ¥ï¿½bËœÃÃŠÂªÂ©zÂºÂ©Ã‘ Ã¤8vÃ¤tÂ°wsqÃc!fÂ¯â€zsÃ•Ã¤ï¿½{Â¸}Â°Ã¹Ãƒâ€œ="Ã­ÃšÃ»Ã²FÃªÃŠâ€”:cÂ¤&nbsp;O&quot;Â¶UÃ€H8Â»/Â´Ã®AÃ·ÂºÅ’Ã¢&amp;ÃÃ†kPÂ°\â€™Â¹Ã‰(â€¢Ã•$Ã¡#Ã»TÃ£4Ã“Å’;']â€¦&quot;_Ã‡Ã«$â€¹â€˜ï¿½Â²Ã­FKÂ½;0iÃ¢Â¸Ã YÃ´Ã¶m){Ã²h0" â€“qÂ»'$Â·zÃ¦bÃ¶â€°Â´ÃœÃ°.Â¹!Â¢k]Ã²sÃ!Ã‹!!oÂ¤Â¥Ã´Ã‘Ã°ÃÃ©&Ã¨1%mÃ´Â¤â€˜fzÂ©="" yÅ¾="Câ€œï¿½7Ã£Å¡ËœpSÃ”Â¥" Ã´fÂ½`b5ÃÂ¼Ã“udÂ²pÃ›Ã…Å¸#Ã¤ï¿½9Âª^Â¦Ã–vmÃ‘xâ€Â¹Å“Â Ã‘Ã¯Æ’â€“'â€¦="}Ã¸QPÃ·Ã¤<`9â€“Ã…Ã­,ÃqÂ®|ÃÂ²Ã‚AÂ©â€¦Â«Ã´{â€”Ã‹â€ÃœÅ¸ÃƒKÂº<Ã–,ÃJ2%&nbsp;ï¿½.dumÂ±ÃŠÂ¢â€°<â€¡â€ºâ€¢Â·Li+â€™+ÃŠ1Ãªï¿½Ã“Â²â€šÃ¶ÂµÃ–?ÃŒâ€˜sYuÃµÃµyk|ÂµÃ“Â¤\Ã‡Â±Lâ€¹Ã‘Eâ€¡ÃµÃ¶" Ã¤lÃŒÃ…Ã¹8Ã“Å¾â€œzuÃ»3ÃŸÃ™vÃ²Ã…#Â°}Ã„Ã¤â€ kÃ¥sgÂ¯Â¬Ã^Ã¤ÃÂ¨Â²Å¸d5Â©_Ã¼rÂ»â€a="" uÃ’dnÃmÆ’tË†Ã­Ã\Â­Â¹(pr.Â¼"ÂµÃŒiÃ•<Ã–qÃ»"Å Ã¦kÅ½Â¨Ã–ÃsÃâ€œÃŠâ€˜Ã¶Â±Ã²hÃ–Ã’Ã›Â¥<xcÃ¸(`="" Ã«Â¥â€™*iÃ‚yÃ¶Ã—:ÃŒâ€”[49rÃ­Â±%="" uwÃ±Ã¦oÂµsâ€¢â€™0â‚¬8â€ â€ºËœÃ•Ã‘Ã¤yÃ´â€šÂ¦[!â€“gÃ‰Ã—Â¼Ã–ÃˆiÂ«Â¿Ã»qâ€šÃ»Ã½?Ã§â€ idÃµâ€œï¿½Â«vÂ«jqabâ€¹"Â¨Ã–0Â©Âµ\Â²j?(Ã‘.ÃŒÃ‘#Ã¤Ã¡\Â«]$Ãâ€°{="">:Âªâ€“R[m{Ã¯c
#Ã¤ÃŒHÂ´A`jm_&gt;MÃ‚ï¿½{ÂµÂ¤}ÃƒTBÂ¹Ã±ÂªÂ²ÂºÃ¥ï¿½Ã‰ÃÃ¸Ã±_//?Ã¼Ã¦Ã¿Â³OÃ¿Ã€Â£`Ã§Ã’Ã·J3â€¹Ã¶SÂ·Ã¼ï¿½Ã“â€¦Â¢ÃÂ¸Ãâ€“DÃœOcÃ¾ÃÃŸÃ¼Ã»oÅ½ÃÃŸâ€¦ÃŸÃ½)Ã¼â€Å¸ï¿½Ã¿ÃºÃ¡Ã‡Â½Ã’Ã³â€¢ÃªÃ‚pÂ¡_Â¨â€º|ï¿½Ã‡Å¡GÂ½VRsÃ¤Âµâ€”Ã„-AÃ¤Ã¼Ã¾Â»%&gt;~ÃºÃ¸Ã«Ã·Ãâ€¡ï¿½Ã¯Ã¿|Ã»Ã¯Â¾Ã—c8â€“ÃµNÅ¸Ã°Ã«q}bwâ€¹Â¾Ã¶Ã©Å½Ã‡Â¢Å¸Ã¿â€œÂ¿?Â¼hxÃ¹Ã›OÂ¾Ã¯BÃ¸Â®DÃ½5Ã‡Ã¾Ã£iÂ¯yÂ²Å’qï¿½`.{ÃŸÂ­â€œï¿½â€K#Â±JÂ¹Ã‚Y*Â¦@LÃÃ¦Â¥Ã—Ã€Ã¯~Ã¹Ã°Ã²Â¾Å’?Ã¼ÃºÃŸÃ¸Ã®ÃƒgÃ½Ã©Å¸Ã¿Ã´â€”Ã°Ã½Ã‹Ã±â€¡Ã°Ã¾Ã³Â§OÃ¡â€”mÃ¸Ã³3^Ã¼Ã R/!Â¡iÂ¾ÃŒQRE?Ã”Å¾â€¹Âµ7_Å’Ã«Ã‹Ã¸Ã¿Â³_Â¶Â°q3AÂ¶VÂ£( Ã€
	
2+
â€¹Å½W:Vx 8Â¸Ã¸T\Ã¼Ã¡Ãª``Ã Â±â€™â‚¬TÅ tUÃ•Ã¼Ã˜Ã»ï¿½Ã­Â³Â½Â»Ã]Â¯vÃ§â€™ÃÂ£Ã¶ÃÃ?Ã»&amp;Ã¯Â»3Kâ€“Ã±ÃŠÂ¿&gt;â€¹Â¾Â¿Ã¦â€”Ã§Â¿8Å¸EEÂ³ÃªË†ÃœYâ€˜5Ã®â€”sË†Å¾N#XÃ¥Â·gÂ·Ã¼Ã¹ÃÃ›{Â¡Â¥ÃµÃŠâ€™YÃ‚Ã„Ã¾Âªï¿½5g-$Ã¶=`Ã¶pzÃ„Ã¹Å¸â€ºÃÃ¸Ã¶Ã¼p{zEOkï¿½%vâ€¦OeÂ³eÃ†Å¸Å Ã›tÃ‰_gÃ˜Â¿ÃbÃSÃ	&nbsp;n+`ÃªTh2Â¯:ÃªÃ‘Â»Ã¯DC`Ã³xqâ€”Ã‰Å Ã¿Ã¹ÃµÃ¼Ã«Â­Ã‘eÂ¶Ã¸uâ€™Ã¾nÃ¹*Â¹9Ã†Ã¾%Â£ï¿½ï¿½Âªâ„¢n:ÃŠÃ½9@+Ã·Â¦BcÂºÂµÃˆxÂ¼h5oÂ·Ã§wâ€°ÃšÂ°Ã„Ã¾!~(â€™aâ‚¬%Ã‚ï¿½Ã­ÂªÂªâ€”Ã„Ã©ÃÃ²GÃ›&nbsp;Â¶â€œ?Ã‹.Ã±;Ã³Å Ã½[Fï¿½(Ã·,ÃŸÃ€Uâ€˜3Ã¡Â³Â¼Â¬Â´Â»Ã»Â«'ï¿½â€“DÃ•Å’Ã„Ã§6Â³5ÃfbjÂ®Â²Ã®lÃÆ’Ã»Ã·Ã˜â€°Ã]vu5YÃµÂ¬Ã’oÂ­ÃµÂºÂªO
PNÃ–Å“Fv7Â­Ã´ Ãµ[ 7xâ€šMhâ€¡â€šÃ¯Â«Â»eÅ’Ã½Â«Ã¼Ã²)AÃ’$kï¿½Â®Å½Uâ€˜$H=oIÃ¤%Ã€Â¼Ëœiâ€œDÃ‰Â¾Ã†Ã˜Â¿Ã‹LÂ¥CU~Â¶Ã³mÃ“Ã‡Ã¢Ãªâ€š5evPÃ·~Ãµ@Ã‘^Ã”.â€¡ÃÂ¿uÃŠ Â¦&amp;Ã·Ãƒâ€“yâ€rÃ¬65M!$Â¥Å Â¢ÂªÃ¾â„¢2*Ã’ËœAÃˆ5\`-Å¾ÃˆÃ8]pÂ¾L|X"ÃÃ°wg	MQ#Â¦h5WÃ‚Ã™ÃµÂ­xÃ€ï¿½Â¦*â€”Ã–#1!&gt;ÃŒÃÃ°â€šÃ½Ã³ÃŒÅ’Ã™fÃ‹Â¹Ã¹Aâ‚¬)mÃ‚H9DÅ¡Ã¯Ã‹Ã„Â¢8ÃÃ°bÃ¢â€°Æ’Râ€7NRÂ¿â€“Ã wÃ˜?Ã‘â€°Â¦Ã’pÃ’Ã¬â€ï¿½Å¸ [Â¥â€¢Â¥Ã¥ i=hÃ»/qÃ•9Ã¹Ã/Å¾Ã`Ã¿@'ZÃ•ï¿½Â®Â»Ã¸â€Ã´BoÃ©i
TiÃ”RhgÅ¾Ã–	C}Å¡yÃ¼Ã¬Ã›/â€¡UÃµÅ’Ã¼[{Â¡{YÃ–Ã¶ÃnSÂ´-xÂ§ï¿½$ÃŠÃÂ­ËœÃ„Ã•0ÃÂ£â€ºÂ¶7Ã„7ÃƒÃ±Ã®Ã»(J~Ã»6Ã„â€“Ãrï¿½Ãº{Ã»Â¢
_-â‚¬â€~E&nbsp;Ã€&nbsp;Ã²Æ’yÃ©RÃÂ»ÃÂº'VFÂ¶Â¤O^Ã°Ã‡Ã©ÃÃ¶Â°ZÃÅ¸Ã·Â¾ï¿½5Â«sÃ¬_Ã­DSÂ¹&nbsp;Ã®Ã³Ã…Â¡"â€“Ã»ÃµÂ»;hÃ³f]8i&lt;Ã•QÃ—c8_Ã±pVhÃ˜Ã¾Â¥9ÃÃ–IÃ·Ã†Ã…&nbsp;Ã¹Ã’ÃcuÃ«XXZÃ…tÂ¤hÃ¾Sâ€™Ã°ÃƒÃ¹UÂ¢RÃ’Ã±Â°ÃÅ Ã¯[Ã¬Â¤KhÂµ6Ã¹Ã€]Â½Ã›â€˜â€°t'ÃµQfÃ°Ã»â„¢n6Hâ€“Â¨Ëœ`GaÃšBGtâ€¦xÂ¼Â¨Ã«Â¯ÃšÃBÅ“7Å½&gt;Ã’Â¾AÃ”Ã‹â€¡DÃƒÃ‘%Â²Â¶Â¬oÃ¶Â¯tjÃ“Ã¨â€¹Ã•zÃfï¿½Ã¤Â±Ã…oËœÃÃ‚PÃ¥ehÃ›$x/,Â°DÃ‰zï¿½Dy[iâ€°Âµ(Ã½!Ã’â€¢TÃ‚Ã™@Ãˆ:(vpsÃ¹Â¦?Ã¾`[aKÃ¶+}Ã™Ã°5v,Ãœ`Å¡+Â±Â¥jÂ­T^Â¶Â±RÃ°Â±nÃ…jdÃµ%Ã•OFHÃ¨~x~Ã…Â¶Æ’v4Â¨uÂºÂ¶râ€°â€¹;Â¥Â²*Ã¯â€œÂ¼\*Â®]Ã’K~Ã¨ï¿½e?Â¸-GÃ´bÅ¾bÂ»@bÂ¿ï¿½Ã‚fuÆ’4Vuï¿½\Â©Â«ÃŸÂ±Ã”Ã…ÃªSÂµD9cNâ€œÃ›Ã™ÃŸÃ¼Â­bÃ¤Â¨tRnÃ&nbsp;â€”!Â«Ã¤)PÃ²\ÃÂ¼Â²Â¤:bÂ±SÂªÂ»Ã‘;â€š|Ã’â€ºÃ³Â¶	T.Â°CbÃâ€“!@Â¾lj$ï¿½Â»â„¢vÅ Â®)Â¿Å½ï¿½Ã¯Ã¢ï¿½eEâ€¡.Â¢Ã¡Ã¸Ã³-Â¶Tâ€“Ã˜AÃ‘#Vt6uÃ…Ã‚5Ã‹Ã¥ÃÃ²â€¦Ã²Â«m7TKï¿½fÃ¯ÃŸÂ¶Ã…Ã€ÃšKu&gt;Ëœ?
'Â³oÃ»U7Ã¥$Ã±Ã¶Ã…Â°#cGÂ¯?ÃÃ¾_Â©Âª{â„¢#Ãµâ€”â€”ISâ€¡
â€ÃŒÃ¢ÃŠÃ‘MÃ­]Å½(Â¸Ã§Â§IÃ·Ã»#QkÂ¶&lt;8ÃªM&gt;[Ã˜eÅ¡H&nbsp;râ€¡X(9Ã–JD?Ã¦â€”Ã‰lÂ½9Â¢ ]Ã¤Â©biÃ‹Ã&nbsp;â€˜Ã¦Â®i[?uW&lt;&nbsp;9Å¡~Ã™Æ’ Ã£tÃ²Ã©"Â½N~Â¼bkÃŸÃˆrÃÃ²â€]R,Ã¯râ‚¬q4ÃˆÂ½Ã‚8hÂ¬Â¡sâ€¡`
h.Â¼*Â¡Ã¥0^&gt;Ã¾Â¾Ã§Â±â€¦o!]`GÃ‰Å &nbsp;Â»Ã³â€šzWï¿½gÂµâ€¹Â¤Z(O:]kÂ¥NÃºÅ¸â€ CÂ¾Ã,Ã˜Â¢Ã¯Ã¤Ã¾NxÃŒ23Â«_Å¾ÃƒL=â€¡Ã½â€™Â¾OÃ Ãª'Ã§Ã™Ã½&gt;Â§Ë†â€™tâ€°*YÃœm:â€ÂªÃ©nÂ­Ã²7HyÃ„Ã´9Â«Ã˜_â€šÃ¨fï¿½akÃâ€¢Ã¬Ã¾M)Ã¬Â¶aâ€“Â»Å“xÃ¸Ã›â€œ0Ã‡Ã–y?Ã¦Ã³;b*ÃÂ»rkD,Â¶0yÂ«Â§â€ Â®â€¡RÅ¡Ã…Ã‘â€ºI;Â²Ãµjâ€¦Â®Ã²aÃªQ@ÃŒÅ¡Â¹`Ã­%&lt;Ã°Ã–QpÅ¸Å“aÃ‡Mâ€¹ ÃšÂ¸jï¿½ÃÃÅ’Â±Ã¤ï¿½Ã–â€™Â¶|ALÃŒÂ¶Â¼â€™bNA=hwÃ·ÃºÅ 5Ã‰AÃ‘Â¼Â¨Ã²Ã5Ã€Ã®Â²?tâ€“Sâ€#	Â¶Â¶â€¡Ã²Ã§Ã¯ÃŸÃ¯Â¡Ã¥Ã¨Ãš.ÂªoÃ¤uÂ½;â€™fÂ¸ÃºVÅ¸CÃ€â€“Ã¶`Â¶%ÃŸÃµ]Â°09iMw0MlÂ·kqÂ«EÃŠTOy[Ã™cxÃ¾yË†&gt; Ã¯Ã»b&gt;0gâ€vÃ…W6HÃ£Ã¬Â«Ã½xÂ³uSÃ‰Å¡Ã…Å½&nbsp;R)ï¿½â€°8H_Ã¿Ã«VdrÂ±5^Ã @&amp;qeÆ’-ÃªÃ‘câ€¡ÃBÂ¡Ã«\Ã¡zâ€Ã–â€¦Ã’Ã™Â­hRÃ¼$Å“`Ã‹y&gt;ÃŸ=bGÃ’â€š&nbsp;UfÃ¬1Å½Qâ€ ZÂ½Ã“ÃEtÂ²Ã†VÃ³T&lt;=-CÃ‡ÃÂ®<vÃ¼â€¡Ãºâ€ Ã©'â€°ï¿½k]â€“'ÂªÃ¨|9Ã‚ÃˆÂ·[ÃŠr"bâ€ #Ãƒâ€œ[mÃµÂ¦_ql]yÂ¨Â¾Ã‰Â½9ÃƒvÃ±Â¤<\Â­ï¿½#(â€°Å½ÂµzÂ¤qÃ¹â€˜b>Ã¨Â°$Ã›Ã¿Ã›Ã»Ã„ÃµMË†Ã<cÃ‹xj>!Â´Âªoeâ€™ÃÃ†"eÃˆÃ&nbsp;TÂ¨Å“dÂ´(Câ€°&gt;\Â¾;KÃ°02Â´%Wâ€œZÂ¯Ã¨Â´Å¡f%â€ Ã©Ã‰Â°Ã¬ï¿½â€” â€˜kmÃ©_BÃ»Å½Â³ï¿½â„¢DÃ²Ã¤Å¡~Â°Ã‡;lÃ»=Â¬Ã’â€¢)mÂ©~Â°Ã£Ã-â€â€ Â£â€”[Â¾Ã“Ã³p|ÃˆÂ¢8hÂ»ÃµÂ©ÃŠÂ¿uï¿½PÃ®ÃªÂ«Â¤Ã—Æ’Ã‰(Ã£8â€¹Â¢Ã˜Ãºï¿½Å¾O|v:â€™&nbsp;Â£E&nbsp;LÂ½S=Ã“ÃŒï¿½ï¿½â€”%CÅ’Ã¤Ã¦1Å¡?bxzÅ¾Ã¹Ã¦<dÃ›:â€ÃªsmlÃºryÂªÃ¯ï¿½b Ã‘Ã‰Ã_lÃ½zaâ€ z-a;â€”="ï¿½]#Ë†Ã±|XFÃ‘Eâ€ Â­^Ã¼]ï¿½Â¤iÃ“â€”Ã¤Z1Wi#â€°Å¾CvÃ°ÃŒbï¿½bkÃ—Yzwâ€°Ãš0zEâ€6â€œÂ¯@vÅ½Ãâ€°yYbÂ³Ã¥[Â¾">ÃˆÂ®ï¿½Â±CÃ«â‚¬Ã–-PÃŠÂªÂ»VÂ·q&amp;1Ã¼Ã¥]fâ€°Å“oWÃ˜Ã5&nbsp;Ãˆ9ÃŸÃ¦EH6&nbsp;M?$ï¿½â€“Ã˜Ã‚ÃµÃˆ+vâ€{Â°â€œÂ¾ÃƒÃ¦ÃTâ€”ï¿½kÂ¦Ã¢cÂ´LÃâ€™Ã·l	Ã¾Ã¥1Â¾Ã²Ã†oâ€â€“â€°mÂ¬4â€¦ËœÅ¾ÃWkÃ¾ryï¿½Â­ZÂ¯dâ€ºÃ™Â§)cÃ¦ÂªFâ€”qÃ­1Ã–Ã¡Å¸KÂ¾=DÂ¼Ã›sDÃ…Ã¢;Ã-XY
=â„¢Ã…Å¸Â±Ã•â€?WÃb	Fï¿½ÃªÃÂ¦Ã³â€šEÃ¬GÂ°Â¼Ã¡ÃŒÃ¥olÂ¹â€ !ÃƒÂ´hÂ®vw&nbsp;f[Ã‚Â¾.YÂ¤?â€¹[Â¬Ã¾Ã™â€”8Â¿Ã°BiÃ¯vÃ•&nbsp;ÂºÃ¡'ÃµlR12lÂ½Ã Ã¶rÂµÃ¼Ã '|VÃ½j:k'x)qÃˆMSâ‚¬-Ã—dÃ.â€“ÃŸÂ£x.Â®=Ã”Ã©&lt;Â´{ ybÂ°Ã¥Å’Ã´.Ã,Â°Â£mâ€/V	;Ã†yâ€”lÂ¥dÃµâ€°sÂ¤(Æ’rÂ§ÃÃÂ¡uÃ€Â°TWâ€“|@Â©bÃ˜:
ÃˆbÃ»?[ÃºÃ¥)6SWÃ„ÃºÃ Ãâ€¢$ÃƒOË†Ã„Ã˜B
GZ|^ÃªÂ¨}ZMÂ¦Ã•AÂ¾5\Ã½AÃ–ip&gt;c\ÃªOÂ¡ï¿½$ï¿½ÃŠ/lï¿½&amp;Ã†Â¸â€¢fÃ«wpÂ´.Ë†)xÃ€Ã–h`Â¯Â°CÃ®Â´Â´ÃYUÃ£Ã¹Ã—Â²Ã„Ã“,L\Â­Ã¢Ã•oÃ«ÃŒÃÃo1b0GÃ˜
Lvt<y ;dÃ©ÂªÃ™zsÅ¾cvËœÅ¾Ã£glï¿½â€ fï¿½Ã²ÃˆÂ¦dï¿½'Ã»8Ã±Ã¼[Â¡ÃÂ¹Å¡:â€ Â Â½$Ã(Ã™?â€”$8Ã‡Å½ymÃ‹@ÃŒzï¿½!â€šï¿½aÃ«ï¿½$hdu="" Ã´wlÃ¸$ï¿½iÂ°Ã¥â€°Ã‚â€tâ€¢Â¯6Ã¬fï¿½Ã˜"ÃœÂ¬Â¶:Â§q7â‚¬Ã“â€¢Ã“Ã²$â€¦â€¡ï¿½[â€ºhÃ¸lÃ¿"Â¨<â€ºtÃ¼dÂ¤~â„¢ckâ€¡â€¡â€œÃ·$â€wÃ´sÃÂ¹ÃºgÃ‹&Ãbâ€¡Â¾Â£ÃŒÃ»gÃ‚ï¿½yÂ¶Ãâ€“&qÃ´1\Â uÃº6iâ€ºÂ¶|lÃ˜ÂºÃ„Ã£="">Nn}â€¡Ã— Ã®~Ã 6\cï¿½lsÃ¬%Â¤ÂªÂ¼Fâ€”9Â¤Ã—&nbsp;,Â±â€¦â€°Å OL
Y"(	Â¶*QÃ¹4Ã–Â£Ã“â€[â€“Â¨`GÂ¿?â€2Â¼sâ€¦Â­JTÃ¾cÆ’Å’GÂ«â€ºÃ¬Ã¡lUbrÂ®â€“Â±Ã‰wÃ[ï¿½Â¼ï¿½-KLfÃ¡Ã‚Ãœ[Ã&nbsp;|ÃËœcÃ«â€˜Ã•Ã¸Ã°9Ã®Ã°zaÃ·iÃ¶b3l]"â€™.â€œâ€˜Ã‘Æ’ÃºCjâ„¢â€™8?Â°uâ€°ÃŠÃ£ ^Ã’Ã»&gt;Æ’-J\Ã¾ÃƒHÃˆË†n`â€¹â€¢ï¿½0Ã·Å“9Â¶(QÃ‰HÅ¸â€ÃŠ3Â¶*qÂ¹ÃƒÅ½Â¿
Ã²+
Ã˜Å¡Ã„&amp;X&nbsp;'Ã•7â„¢Ã…Â±%â€°ÃŒwÃ¬?Â±o&lt;`kÅ“Â°Â³A]DÂ°â€°ÃÂ³â€¡ËœÃ®ÂªÅ¡1ÃšÃ¥â€ºÃ†[â€™ÃˆÂ¤Â£Â¢Ã§ XÃ’Ã´[câ€ Â­I\~OP*{Ã&lt;Ã˜Â¢D;Ã¼f(Â½`â€˜bâ€¹â€”Ã‹`ï¿½6JÃœÂª}2FxÃ¾`â€¹â€¢Ã—3Ã¯(jÃ²Ã—Ã˜ÂªÃ„eï¿½bÃ¯8Ã„Ã¥Ã¿Ã¬Ã—/lIÃ†qÂ«ZUÂ«ï¿½Câ€¡ÃŒBÃƒNfÃÃ…Â¯dvÃ´Ã°AÆ’Ã¢Ã¢`Â«Ã¸ppexÂ°Ã,Â¤Ã€â€¢*9Âªnâ€œÃŒÃ¬Ã¿Ã·&amp;^{7Ãâ„¢Ã¯ÃŒÃºÃ¹HÃ­Âµï¿½Â½Ã«{~ÃxfQÃ‡7Ã¸mÃ¾Â®Â¹KÃ‰1Ã¨VÂ¢Ã’.Â¾Å½GÂºÂ¦[Ã‰Å¡Å¾Ã‹FkÃ&nbsp;Ãï¿½Â¤&nbsp;Â¾Ã¨Ã›â€ Â®$Ã­ÃŠ]Â´Z,QÅ¡Ã’â€¢Â¤Â¹zËœÃzË†ÃH=â‚¬Âª*,1Â­Ã‚FXÂºâ€™Â¸=	]Ãˆ|ÃªÃÃ’SÂ¨HÃ›â‚¬tCÃÂ«kÂ²vMÃ·1â€”Ã´$$t`?Ãï¿½Ht"
ÃÃ‡Ã¼CÃ@â€šÃ²â€¦.dÃ¨HPÃ¨&gt;â‚¬Å¾ï¿½Â¥GÃ·1.rÃ•Ã£AÂ´~Ã‘}=	
]GÅ¾Ã­v:gï¿½Ã¥Â©Ã!zt!pÅ¸vzÃ´$Âºï¿½Â¼Ã‘ÃÃ©)H@.Ã©BÃ²&gt;Å¾Ã½qIï¿½AÃ‚1Â¢	Å½oÃ­ï¿½â€šâ€â€Â®$-Â»Ã‹s=HÃˆ=KÃ´3zÂºâ€˜Â¸â€Å¾â‚¬â€Ã¥wÂºâ€˜Â¬Ã¯6Â§' Â¡Â¡KIÃ»â€œÃ€ÃºÂ´RJWvF@B3Â¥;	ÃºuIÂ§/Â¢kIÃºAâ€¡/!Â¢kIÂ¢Â³â€”ï¿½Ã²Â£Ã„ï¿½_Bâ€ÃÂ½5bcWÃ)Ã¯_Ã¨Ã°%DCÂºâ€”&nbsp;{:|	Ã‘)/â€°?Ã©Ã°%D#Âºâ€” :{	Ã’/Âºâ€”ËœÃ«3:{	]LLÂ³1&amp;Ã^N@t3)tÃ®,ÂºÅ¡â€”â€˜jÃ‡Ë†ÃMÃ†g:v	]NÃ„
ï¿½ÂºÅ’n'Ã¢;â€œÂµNTQ&nbsp;Ã›â€°8Â§Sâ€”â‚¬Ã‘Ã­DÂ¸R[@[ÃÃ­DÃÂ¡KÃ€Âºï¿½:u	Ëœâ€“D!6|=!Â¥t;tÃªÂ°ÃNï¿½ÂºLKBÂ¤&nbsp;GÂ·â€œ`Ã©Ã”%`}ÂºÅ¾â€otÃªÂ°â€œ&lt;8Ã½Ã›`â‚¬IÆ’Ã—â€™LÃ¨zÃÃ©Ã”%`]OÂºâ€LKBÂ¤`HÃ—`Ã¨Ã%dÂºÅ¸â‚¬Âºâ€Ã¬â€”ï¿½Â¹MKBÂ¤`LÃ·@g.AÃ‘Ã½Ã´oJg.AÃ’ÃµoDg.A;ÃÆ’Ã“ËœÃ\â€švâ€šÂ§â€Ã\â€švâ€šKâ€šÅ½\Ã‚Â¦%!RpzÃÃŸÃ¨Ãˆ%l}ÂºÂ¡Ã}Â¤#â€”Â°uÃ©â€ zG'.ï¿½KÃ©â€ Ãº6Â¦â€”Ã€%tE}KÃ©Ã„%ttE}Â£Ã³â€“Ã Ã‘ÃµlHÃ§-ÃÂ£;ÃªYJÃ§-ÃÂ£;Ãªâ€”Â¡Ã£â€“Ã°Ã‘%ÃµÂ«OÃ‡-Ã¡Â£KÃªï¿½Â¶Dâ‚¬.Â©W7tÃšÂ¾â€nÂ©W	Â·Dâ‚¬nÂ©O?Ã¨Â°%}ÂºÂ¦&gt;iâ€œï¿½ÃƒtM}Â¢Ãƒâ€“Å’Ã¨Å¡z4Â¤Ãƒâ€“Å“Ã’.Ag-QÃˆÃ¨Å¾Ãºâ€œÃ‘YKÃ¨Å¾zÃ”Â£Â³â€“(Ã=ÃµË†Å½ZÃ¢@Ã·Ã”Å¸Ã¯tÃ”â€¦â€.Âª?tÃ”â€¡]TÃ¨Â¨%Â§Â³$Ã¾Â¦Â£â€“8ÃEÃµâ€¡NZ"AÃ•â€º':iâ€°CJ7Ã•â€ºÂ³â€ÃZÂ¢0Â¢â€ºÃª
ï¿½Â´Dâ€š.Âª7Ã¯ÂµIH%tSÂ½Â¡Æ’â€“HÃ´Ã©Â¦ÃºÃ’Ã‘&amp;!â€¢ÃMÃµâ€ ZbA7Ã•:gâ€°EBWÃ•â€œ)ï¿½Â´DÃ‚Ã’]Ãµâ€ÃYÂ¢AWÃ•â€œNB-Â±&nbsp;Â»Ãªï¿½Â²Ã„#Â£Ã‹Ãªï¿½Â²Dâ€.Â«?Ã¡Å’%&amp;	]WÃº)ï¿½Â²DÃ„Ã’}uÂ¯Ã“Â¥Câ€“ËœÃ}uÂ¯â€œÃ’KLRÂºÂ°Â®ÃÃ‘	KdÃš~n:Â§â€“Ã˜Ãâ€¢uÂ¬â€ºÃ’KdztgÃÃ’câ€Ã”EwÃ–Â­ÃŸÃ¨x%&gt;tiï¿½Â²tÂºÅ¸&gt;ÃZÂ§Ã¨t%Btiï¿½Ãª%tÂ¼ÂºÂµNÃ‘Ã¡Jâ€Ftk]JÂµIHmtkï¿½Â¢Ãƒâ€¢Ã‘Â­uÅ W"4Â¦[Ã«Ã’HÃ§&amp;Â©ï¿½nÂ­SZRÃZÂ§Ã¨p%B=ÂºÂµNÃ‘Ã©Jâ€Ã¨Ã’ÂºEÂ§+Â¢KÃ«ï¿½Â®Ã„Â§Kâ€”Ã–-:^â€°OFâ€”Ã–-:^â€°ÃYÃ‡Ã¨x%:-?7iIH]-?7iIH]te]Â£Ã³â€¢Ã˜Â´Ã½ÃœÂ¤%!5ÂµÃ½ÃœÂ¤%!5Ã‘ï¿½uÅ½XbC7Ã–Â¹â€NXÃ¢2Â¦Ã«Å“â€“â€Ã”BÃ–=:aâ€°]XÃ·Ã¨â€%.SÂºÂ°Ã®Ã©Ã $uÃ}Ãµ&nbsp;Kg,1Ã©Ã‘}Ãµ@KBj&nbsp;Ã«ÃªCÅ¸YbBÃ—Ã•â€¡Â¡Â¿8ÃµÃ˜Â½)]W&amp;tÃŠÂºÂ­^:eâ€°Gï¿½nÂ«tÃŒÂºÂ«Å¾Ã1K&lt;Ã¨Â®zÃ¢:Ã†Ã„Ãµ
Ã„â€”Å’Ã®Âª'tÃ
ÂºÂªÂ¾Ã9K,Ã¨Â¦zC-Â±&nbsp;â€ºÃª
Â´Dâ€š.Âª?	ÂµÃ„ï¿½.Âª?tÃ’ÂºÂ§Ã‘QKtO=Â¢Â³â€“Æ’~Ã«
Ãº_Ã¯_Ã¿Â¹|ï¿½}ÂºÂ¦ï¿½Â±ï¿½Â¥â€™Ã¾hbmfÃ²ÃœÃšÃ§q=}Â½Ã¹ÃÃ Ã…â€œÃ®hZÃ©â€¦tM}JXÃ—ï¿½ËœÃ§Ã¥`Å 3Â»Â½&lt;Ã¾Ã‚Â£Ã¢%{&gt;â€ Â¿BÃ²Å½WÅ“y7Å“&gt;Ã¤vÂ±?}Ã»Ã­Ë†Ã‹Ã¶wWaÃ~Ã¡Â¸â€A9"XqÂ­7y^
Ã³Ã¥Ã°zMÃ¤Ã¦Ã¯ÃšÃ—KzÃ“u0Â»ÃŸÃ¨&nbsp;xÃ94qh4ï¿½=@&lt;Ã®XKÃ¿UÂ¾Ã”Â¤F'ÃºÂ¯ÃÃ;Â¾hÃ‘xÃ½/ÃËœËœÃƒÃ¬VÂ¸ÃÃ¨Ã°e^zÂ±YÃ”Â¿@Â´<s5+Ã±yÂ³ÃÅ¾!Å’)ÃŸ#Ã¦Ã¾Ãšâ€˜:Â»ÃƒÆ’ÃµÃ€Ã~ï¿½Ã˜Å’ÃtÅ½â€˜eâ€¹)xÃ¹Ã§Ã²kÃÃ.38Ãº2Ã·Ã“nÃšl&Â£aÅ¡zÂ­Â¼Ã‰07Ã³Ã¥` ÂµlÅ¸Ã°qÂ¨Ã¨uv'Ãdâ€¡ËœÃ€%ynÃÃ³ÃÃ‰ÃÃ­Â·sÅ¸Ã°rÂ¨Ã¸Ã¹Å¾Â«Â¼Ã™xÂ±lÅ¾â„¢ÃƒsÃ½Ã´ÃªÃ­Å½â€¹Ã”Ã¾'+oÃ³Â¼"Ã¦kÃ¢ÃÂ±ty|Â·Ã‹Âµ="" 3^Â©Â­kÃ³Â§Ã¹Ã„lveÂ®Â¿Ã®?lÂ½Ã™iâ€¦ÃšÂ±Ã”cjÃ­6Â³Â·Ã«Â·ÂºÃ¬oï¿½câ€“v6Â¯Ã°="" â€˜ÃÅ¸8="">/ÃÃ©Â²=mdÃ™AKECÂ»Âµ?TÃš)Ã¬bÂ¶ÃÅ¡Ã“Z?Ã‘AK5WÃ“Ã™Â¬Ã¬r1TÃ›&amp;Ã¤ï¿½Â¦Ã´Â´Ã¥&nbsp;ï¿½?L6â€ºUÃ…Ã‡9ÃÃˆÃ¥,â€”?Ã¯Ã¯Ã²,â€ºmÃšÃ¼Ã“â€”Ã½Ã®LnÂ²WÂ«Aâ€ ;FÃŸÃ¤!Ã»cÃ–}kÃ§Â¿Â£51Ã“oâ€ºu9Ã»&lt;6kÃ­Â²Â¤â€¡.Ã¥ÃOÃ§#2Ã…Ã¥@TÃ±~Å¡aÃ·Ã¶Å½Â»â€Âº_LhÃ±uÅ’â€“qâ€™ï¿½Ã§Å¸aÂ±QÂ´Ã½Â¡â€ Å¾Â»â€Ã¸k1Â»Â»â‚¬^WÃˆÃ´n{-Ëœâ€“/â€°	=yÃ™Ã©bÃ•yÃ¾ÃˆÂ¾Ã¸â€“ÃŸÂ«<iÃ¨Ã™Ã‹.Ã£Ã¥xÂ¬ÃkÂ¸Â½&Â³ÃÃ±ÃÃ¥jok"@Å¸vÃ£yÃ€vÃ„ÃºÂ¾Â³ÃÃlÃ¾1[Ã¼Ã‡Â´vixzÃ¸Â²Ãƒh=â€œÃ­â€ºÅ¾cÃ«Ã›Ã¥ 3Ã¿ÃµÃ¼Ã»sÂ¾y#-d_^Â»^o'+[Â®Â¿Â¡Ã­Ã£tvzâ€ºmÃmÃ»Ã·Ã–ny="">&nbsp;Ã‡//]&lt;Â®Â§c2Ã´Ã‹Ã˜."Ã†f~\2Ã‹SSNm\^&lt;Ã‘Ã³â€”â€”Â¾Â¬â€¡cÂ­ÃŸaâ€¹Â´vÂ¹6Â³Â§Ã‚ÃMfÃ³Ã¯)])ÂºxXÃ&amp;3ÃÃÂµPÃ³K1+â€¢VÂ²Â¦Â½Ã«!HÃ¨HÃ‘Â·ÃµlÂ¬Ã‰Ã˜Ã¢=Â­Ã¾Â°^Ã‹j<o^Å¾Å’Ã‡6Å¸Â¤tÂ¤Ã¨ÃÃ·Ã•|Ã¬Ã¼Ã Ã®â€¹]Ã¿Ã—Â¼<Ã™Ã¢ÃÃ§ÃÃ–<Ã¤Ã­c_vÂ¸xÂ·Ã‘d.Ã&Â¶Ã¤kÃÃ®Ã¸Ã‰ÃÃ•!jÃ½g go_^Ã»Â±Å½Ã2â€¡â€¡Â¦Ã¬iÃ³%_Ã½.oâ€¡_Ã¢Ãƒgâ€”Â¾Â£Ã§="" ÃÂ¯fcÅ’}Ã¦jÃ²Ã–Â¿ÃµÃ£Ã²Â¡Ã£nmÃï¿½Â¢Ã³_Â«Ã‰Ã˜Ã§sâ€œâ€Å“Ã­fq9ÂºÂ£Â¥+="" Ã—Ã«Ã‰de'Ã½fÃ¦Å¾â€”Â¶-wÂ³Â¬ÃÃ\Ã»Å¾Ã®â‚¬lÂ»yÃ†fÃÃ›dcÃ‡â„¢â€”Â±Â»Ã¿9h;â€“Ã®"Â­?Å“ÃœÃ®â€ Â­â‚¬Ã¼\ÃÂ¥Â±Ã¥Ã;â€“Ã„Ã¯â€¹Â¼Â®\ÃœÂ®Ã‡v@Â¶ï¿½7-Ãâ€™Ã˜Ã¬bÂ»xÃ‹Ã„.ÃœÂ­â‚¬Ãœoâ€¢Ãd|ÃoÃŠ{~Ã¶kâ„¢Ã™â€”Ã†Ã¯:e;="" [ÃÃ—sÂ±Ã±Å“Ã³9oâ€¹Ã˜="">}Â¡NÃ‡Ã¿*a8Ã›Å¡â€¹Ã–CQVÃ²Ã¯Ã³Ã &gt;yÃ±^Ã’Ã©lÃ½ÃµÃ®ï¿½Â¬\iâ€*ï¿½Ã¦|Ãâ€˜ÃÃ³Ã¸Ã—â€¹Â®â€¡Â¶@6Âºâ€ºÃ©!Â¢â€ nÃ§SÂ§Ã°%_[Â²Å“Ã€Ã”Ã˜&lt;â€šï¿½â€šï¿½â€º/Ã‚LÃ›Ã…3ï¿½CLLY*fÅ¾ÃŸwâ‚¬'/Â»Ã½oÂ³3Â«%Â±bf;Â¦9Ã°%q6OÃ°ÃÂ¡Ãâ€œâ€”ÃÂ®Â·Z&nbsp;Â±fÃ†Ã“*a,C|Ã£MÃÃKâ€°â€º7NÂ³ÃµÂ¦Ã“J_Ã‹ÃŸtâ€¹ï¿½Ã¨Ã¤eÂ·Ã±â€ºfÃ™~?Â¬1Â¹ï¿½-Å Ã«Ã¢bâ€¢Ã¤nB^JÃœÂ®Ã‡Â£#SÃÃ³Å Ãˆ6Ã™Ã·ÃŠuâ€“WÂµo^J|Â«ÃŸâ€¢Ã“Â±YÃ–Ã¬yÃ™VÅ“Ã½z78Ã‡Ã¦.enÃŸTâ€¢Â´oIÂ¿Ã«Ã·Â¾rÃŸ%ï¿½GEÃ¦^Â¤ZyÂ«Â¸Bâ€ .{|uÃ™â€œâ€“Ã™Ã·4a_%â€ºVÂº&amp;0rÃ™Ã«K3e9{Ã…Â®tG/ËœÃ¸Â¸Ã°OÆ’u9Ã·Ã¥?ÃšÃ°ï¿½Ã”ÃÃ¯Â¸Ã¥&nbsp;Â¿â€º-ÃŒI+â€°8Ã™Ã·Å¾GÂ¯Ã“â€“ÃƒÂ®}Ã•Â¥EÃŠï¿½Ne)ÃŠÂ¯Ã¥sÃ˜Rï¿½NMï¿½*ÂºÃ¤
_Ã½ï¿½Z*Ã¹sÃÂ³Â¢â€2e?xÂ¿'Ã«]Â¯O}
Z*:sÃ—Å¡Ã¶Â°Yï¿½Ã¯ï¿½Ã»Ã…JÃŠOcâ€“Ãª&amp;ï¿½vÂ§Â¥Â²Â¬Ã†Vz0Ã²in&amp;Æ’Ã‘x&lt;zËœÂ¯Ã”ÃµÃ“]ï¿½ÃšÃƒÃ®&lt;&amp;â€¢ï¿½Ã¨â€˜ÃŠQÃÂ»lR[Xâ€ºÃ—yÃÂ¢g*GÂ¹wÃ–Â£Â©Â³Å¾}&nbsp;â€¡*GÂ¸tÃ“Â¡Â¶ÂªÂ¶6nÃ©Â©ÃŠWÂ¨%Â³Ã¿Â³_Â¿Â¡uÃuÃ‡Ã¡pÂ¸\ÃŠ%\.%eâ€Ãâ€”	Â¡â€šÂ¬â€â€¹PFÆ’JEBh)Æ’
#Ã‚P&amp;-Ãˆ
tPÅ¸â€ÃºÃ€ÃŠZVÂ¬8Â¬s&nbsp;Â¨ÃƒÂ©â€œÂªLÂ«Râ€°6Å“Â³6Ã’ÂµMâ€”MÃš{Â®Â¡UÃ©Â¿$Ã·Å“ÃœÃ³{Â¿ÃŸÃ§Ã(Ã¬Ã‘Ã·Ã³&gt;;Ã§vÃ®Ã¹ÃÂ°Ã®sâ€˜Ã‘Â«JqgÃ‹)ZÃ¨YÂ¥8:Â¿,ÃµÃ¸â€ºbâ€Å¾U
;YnBÃY^ZÃ¹jÃŠVÂ¾Â¡:kÃ¾gÃ´Â¬RÅ“Â£â€™Ã‚Â²Ã²8dkÂ¿.Ã¨YÂ¥0Ã½â€™Ã˜ËœÃ•zW)ÃŒi?AÃ‰Ã®&gt;Â«&lt;Ã´Â®RTÃ›eDï¿½YÃ³Ã‹â€°VÅ ZÃ»7Â¢F+ï¿½Ã“Ã¥â€jâ€˜^V
ZÂ¤Ã“	Ã•&lt;&lt;Â¬ÂµÃ¦Ã§Â°wÅ“^VÅ Â©ÃÃ¥Â«BO+Ã…Â¥Ã‹	VJO+Ã…ÃœÂ¤Ã‹	Â½Â¬Dâ€¡.zY)F?%JCO+Ã…LÃ‘Ã¡â€â€¹Å¾VÅ Â¹@â€¡Â¬Å’Å¾VÅ Â¹Mâ€”Â¬)zZ)â€ '\Ã´Â²RNÂ¸Ã¨eÂ¥ :Å“pÃ‘Ã‹J1St8Ã¡Â¢Â§â€¢bfÃ©pÃ‚EO+Ã…ÃŒÃ“Ã¡â€â€¹Å¾VÅ Â¡Â»	XBo+â€¦ÃÃâ€Å’ÃV
Â¡Â³	Ã™Mz\)`Å“Ã&amp;h5z^Ã‰oâ€Â®&amp;lÃ´Â¼â€™Å¸â€°RÃ½Æ’ÃWrÃ“#Q.z_Ã‰Â­I7:z`Ã‰kÅ N&amp;t
zaÃ‰Ã©$ï¿½LÃ°Ã¨â€¦%Â§Ã³t1Ãâ€ºÂ¢'â€“|Â¾H&gt;zbÃ‰gÅ“&amp;|OÃK.Â¯Ã“ÃDâ‚¬ÃXrÃ¹ÃKvÃ‘#Kâ€¹t/1&nbsp;Gâ€“&lt;Ã¨ZÂ¢@ï¿½,yÃÂµD!Â£Wâ€“Ã¨ZÃ¢@Â¯,9ÃÂ±Ã„Ã¡=Â³Ã´Å½Å½%Ã´ÃŒÃ’;Âºâ€¢H$Ã´ÃÃ’3Âºâ€¢HdÃ´ÃÃ’3Âºâ€¢XÃ;KÃÃ¨Tb1N-Â½Å¡Â¥[â€°=Â´Ã´ÂªAÂ§Â®Ã»Ã¿oC-=Æ’zâ€°Ã€Ã’}kÃ’CKÂ¯&nbsp;^bÂ°pÃ¯_:Ã´ÃÃ’â€œÃªâ€“Ã±y*ËœÃ˜Ã[Ã‹Âºâ€™ÃªÃ–Ã–Ã”WÃŸÃ¸+ï¿½JÃ€Ã®{MÃ{Ã‹ÃšVÅ¾â€¡'&gt;{Ãª7Ã—â€“3*â€”Ã¨ÃŒÃ’â€ºÃ‹jâ€™Â´1Ã´Ã¸Â¾#/Ã¿Ã¶Ãš-Âºâ€™Â¸ÃÃƒÃ‹Â£Â¤ï¿½Ã¡Å¸?Ã»Ã³woÃ¨ypï¿½_â€Ã–Â¶Ã®|jÃºÃ”Ã¸&nbsp;Ã›Ã•Ã§â‚¬@Ã®â€œ4?ÃºÃœKÃ§Â¯Ã’YÃ„L?&amp;ÃŒHÂª[Ã†&gt;vÃ¤ÃŒÃ…ktÂ±Â£Cï¿½;â€™ÃªÃÃÃ½Ã‡Â¾OÃ— ]=Â¬Â¼&gt;|Ã°Ã¸[t
rï¿½CÃ´*ÃµÂ­Â»Ã¶Ã¥/tÃ’Ã­fwÃ¿Ã•Â¤â€œË†ZÂºylÃ¯Ã¡Ã“Â¿Â¸Å½â€“ Ã¿sÃ·â„¢8OWÂ³FÃ«ÃˆÂ¹?ÃÃˆCÃ¨,Ã¢U;Ã¼Ã¦=Â¿ÃœÂ«sÃ§Å¸tÂ±JÅ¡Ã»Â¿= ï¿½DÂ§Â§ÃŠcÃ»Â¾vï¿½Å¾^rÃ§5AÃ‡Â£dÃ‹Å¾Ã¨Ã±Ã¥â€˜VÃ¾Ã”Ã¨&gt;Â¢â€œ4Ã¿&lt;Â½Â¼Â¬"[Ã¹sâ€.$6â€ºFÅ¸Ã½=Â¼Â¬jÂ©Ã›Ã½ï¿½H\â€™ÃÂ§ÃdÃ´Ã¬Â²6:â€™Â¨TFÃšÃ©Ãe=t%1Iwâ€ºÂ£Ã·â€“uÃ‘â„¢D$9vâ€¦Å¾[Ã–â€œÃ©â€˜pgxÅ¡Å¾[zpâ€ºÃ®$Ã©Â±Â¥Ã­â€.%Ã©NzkÃ©IFâ€”ï¿½AzjÃ©]J,*Ã´ÃÃ’Â«Âºâ€¢HÃ;KÃ¯Ã¨VÃ¢@Â¯,9Ã”Ã©ZbÂ°@Â¯,yÃÂ¹D`Ë†ÃXrÂ¡{	_JO,Ã¹tÃ¨bâ€šG/,yÃ‘Ã…â€-Â©Ã‘Ã»JnzMâ€Â©AÃ+ÃÃ•â€Â¬Ã’Â¦Ã—â€¢Å¡t7Â¡Ã‡â€¢BÃ¨nÃ‚â€¢ÃÃ“J1t8Ã¡zÅ’Å¾VÅ Ã©ÃÃ¥â€J/	oÃ‘Ã©â€ÂªA+EÂ¥t;aJÃ©aÂ¥Â¨Å’Å½'LCÃ´Â®ROï¿½jÃ´ÂªÂ²-:Å¸Uâ€“Ã©Ue#Ã¨~Ã‚â€œu3zUÃ™:&nbsp;Ã°Ã”&lt;Â±Â¿LÃ’â€¦&amp;Ã½TÂ·sÃŸâ€¦;Â«\^Â¬Â¢
ÃÃ Ã·Ã•;Ã‚;tBï¿½Â©,Ã’Æ’ÃŠF-Ãâ€¦eÂ°{â€¹^T6Å Å½((	Â½Â¦Ã´AJgâ€™â€ ~;â€â‚¬Ã( )Â½Â¥Ã´ÃQ@nÃª%â€:Â¤`Â¤Ã=Â¦Ã´]R(zHÃ©:Â¥@$[Ã¨!Â¥oÃ¨ËœÃ‚PÂ¿AÃ¯(}CÃ‡â€Ãšâ€œÃ´Å’Ã’?tM!Â¨OdÃ´Å’Ã’?Ãâ€œÃ¿?Ã¾CzEÃ©':(Ã¯5&gt;Ã±zCÃ©Â«I:)ÃUwÂ¿Â¶Do(Ã½E7Ã¥Â·Â¤yÃ¢zAÃ©3:*Â¿Ã•Å¸~;Â£â€&gt;â€ºÂ¥Â«Ã²YÂºÃ£â€ºÃ‹Ã´â‚¬Ã’wtV&gt;Â«O]Â¢Ã§â€œÃ¾Â£Â³Ã²XÂ²Ã½Ã•[Ã´|Ã’stXÃ¾ÃšÃ´ÃŒez=)â€“Â¿FÂ¿Â¡_AÂ¢ÃƒÃ²VÃ­Ã€Â»Ã´vR:-O%c__Â¢Â§â€œrÃmyÂª&gt;ÃµÂ½Å“â€dÅ½Å½Ã‹KÃ©Ã¸Â«Ã´pRÂº./
|zÅ½ÃMJCÃ—Ã¥Â£tÃ¬=â€ºâ€Â§MÃ·Ã¥Â¡ï¿½CÂ§gâ€œÃ‘}Ã¹'ÃÃ¾-z4)Ëœ6Â¾Bï¿½&amp;ejÃ’â€¦Ã¹&amp;mÃ½â€ÃLÃŠE'Ã¦â€ºÃ/ÃÂ¤'â€œrÃ‘â€°yÂ¦2Ã±Kz1)YJGÃ¦â€”Â¡Â£Ã´bRÂ²Å’Å½ÃŒ+â€¢=oÃ‘Æ’IÃ©Ã¨ÃŠÂ¼2Ã´=â€”â€ï¿½Â®ÃŒ'Ã•Â½Â¿Â£Ã§â€™Ã²-Ã‘ï¿½Ã¹#iÂ¾HÂ¯%.ÃÂ¡Ã¹Â£~hÅ¾K\&nbsp;CÃ³FÂºÃ³{Ã´VÃ¢Ã„ï¿½Å¡/â€ Å¾Â§Â§GÃ¨Ã”<qÃ»Ã¤ez)qâ€nÃÃ‰Ã˜Ã‹Ã´pÃ¢jï¿½Â®Ãsz(qÂ¥cÃ—Ã¦Æ’dÃ¼5z'qâ€¡ÃÃ[Â¦Â¯Ã’3â€°;tnÂ¨Ã­Ã½â€¢Â¾â€º"Ã’Â¤Æ’3 ÃÃ¾Ã’Â¿Ã©â€¢Ã„Â¡9Âº8Ã³6?7gï¿½$nÃ‘Ã…yâ€”Ã®Ã¾â„¢="">â€ºÃ¢B'gÃÃ°	}6Eâ€ NÃÂ¸M.Ã“â€°c3ttÂ¦%Â£Â¯gÃ´BÃ¢]ï¿½iÃµÃ©%zqÅ½Â®ÃÂ²Ã¤#Ã¯Ã‘Ã³Ë†{tvâ€“
ÃŒÃ¨Â³)BmÂº;ÃƒvÃ&nbsp;Ã—Ã€Ãï¿½]â€º^Â¡Ã‡Å¾]{nÃ’Ã›â€šÃÂ¬ÃšiÃ½â€™Ë†]Å¾Y;Â¯ÃÃ“câ€ NÃÂ¨ÃŠâ€”;Ã´4Â¡Ã›3jÃ«Ã©aâ€BÂ·gSÃ²Â¬^Ã‘Â¢Ã£Â³iâ€º~IÃ„Â«EÃ—gQÃµhFÃ¯"Ëœ:?â€¹Zâ€”Ã©YDÃ§gP}F/â€°ËœÃ‘Ã½Ã™â€œÃ¬Â»Nï¿½"$:@{â€ Â¾Ko"Â¨&amp;]&nbsp;5Ã‰Ã“Ã¿Â¢7TF'hMÃ³Ã—Ã´$Â£4Â¦rÂ¤C/"0ÂºAcÅ¡Ã¯ÃÆ’mâ€“Å½Ãâ€Ã´3Ã´Ã‚Â£+4eÃ°MzÃ¡Ã‘Å¡2râ€°Å¾Cxtâ€¦Â¦Å’Ã“kË†tâ€¦Â¦l[Â¦Ã§^ï¿½ÃÃâ€™3Ã´b@â€ºÃÃâ€™msÃ´Ã‚â€ºÂ¤34d?=â€ X0GwhÃˆÃ¦Ã›Ã´bÃÂ¡Ã‰Ã±[Ã´bÂ¢WÃ¨)Ã„:D3j?ÃÃ¨-Ã„ÂºD+â€™Ã©%Ã„Ë†â€nÃ‘Ë†ÃºÅ¸Ãµâ€™ï¿½;Ztâ€¹F<i!vdtâ€¹64nÃ©%!Ã¿eÃ‡hÃƒÂ®ez1Æ’Å½Ã‘â€Ãª%zÂ±Æ’Â®Ã‘â€ }6Ã‰Ã¿Ã‘5zp}Å¸^a="" Ã‰Ã¨="" Ã˜Ã±Â½â€šxbÃ·ÃˆÂ«~ï¿½Ã@liÃ©"qzÂ¤7s&Ã©"iÃ©="" zÂ±eâ€ nâ€™6ÃœÂ¡'cÃ¨$aÃ‰Ã¡Å’^@Å’Â¡â€ºâ€5ÃµdÃˆÃ¨&yÃ©3Ã´Ã½Ã…Å“:]%jÃ°Å¸Ã´Ã½Ã…Å“yÂºjÃ”="">}7Ã‰CÃ¨*IÃ•Ã“Ã´ÃµÃ… :KÃ’Ã¨UÃºÃºbï¿½%(ï¿½Â¼E__JÃ©09Ã•sÃ´Ã±Ã…Â¢&amp;gÃ¤}ÃºÃ¸bÃ‘$&amp;&amp;â„¢&nbsp;o/6Ã‘eb*â€¡Ã¨Ã“â€¹Mtâ„¢ËœÃŠ%ÃºÃ´b]&amp;&amp;]Â¤O/6Ã‘ebÃšÃ´Ã¥Ã…(ÂºLLâ€¡Â¾Â¼Eâ€”â€°Ã‘#!ï¿½Ã–Â¤Ã“â€Å“Â¤/VÂµÃ©6!Ã­ÃºÃ²bTFÂ·	â„¢Â¥/fÃ‘m2ZÃ´Ã™Ã….:NÃ†}vÂ±â€¹Å½â€œA_]Â£Ã£DLÃ’WÃƒÃ¨:Ã´Ã‘Ã…Â²â€Ãï¿½ÃGÃ‹fÃ¨&gt;Ã³Ã´Ã‘Ã…Â²9ÂºO@7Â£Â¯.â€ etÅ¸Ã®Â¥o.Â¶Ã‘ï¿½ÂºG_\Å’Â£uï¿½Â¾Â¸GÃªÅ“~HÃˆÃšÃ¨Bï¿½Â£.Ã–5Ã©D;I\Â¬â€ºÂ¥ulÅ¡&gt;Â¸ËœG7Ãª}nÂ±ï¿½nÃ”Â­Ã‘Ã§Ã»Ã¨HÃZ&nbsp;Ã-Ã¶Ã‘â€˜:Â¥'BÃ–GWÃªTwâ„¢&gt;Â·Ã˜Ã—Â¦3uÂ¨N[Â¼@wÃªPÂ·C[|@wÃªï¿½	Ã©Eâ€¡Ã•â„¢}jÃ±]Âª3Ã´Â¡Ã…tÂªÂ®ÃwÃÂ­Âº1Ã™Â½NZ|AÃ‡Ãª}eÃ±	]Â«Ã´â€˜Ã…'tÂ­.Ã”Ã©#â€¹OÃ¨\]&nbsp;o,^Â¡su`}cÃ±
ÃÂ«ÃƒÃ´ï¿½Ã…+tÂ¯Ã'Â¿ÃÂ½â€“/Â¡O,~iÃ“Ã…â€“Â®JÅ¸X<c[ÂºÃÃ´â€¦Ã…3tÂ±Â¥Â¢ ,Â¾Â¡â€œ-Ã›}`Ã±="" ï¿½lÃ™Ã†Ã©â€¹oÃ¨dÃ‹Â¶ï¿½="">Â°Ã¸Â¦E7[Â®Ã´ÃºÃ€Ã¢:ÃšrÃ•Ã©Ã³Å Ã¨hÃ‹Âµï¿½&gt;Â¯Ã¸Â§CW[Âª	ÃºÂ¼Ã¢!ÂºÃš2U&gt;G_W<dg[Â¦ï¿½Â³Ã´uÃ…gtÂ·%Ã¾=}\Ã±Ãmâ€°Â¶_Â£ï¿½+^Â¢Ãƒ-ÃÃ®%ÃºÂ¶Ã¢%:ÃœÃ’$Ã¨Ã“Å Å¸Ã¾ÃƒnÂ£Ã„@qn&â€“ÃšÂ¤â€¹ï¿½ Ë†="" "ÂºÃ›Ã¬$hi9â€¦a-,Ã¬,dÂ°1Ã•"zÂ¦ËœdÂ°0rÃ¿ï¿½jÂ¸Ã®ÃÃ¹â€“pÂ¸Ãâ€Å¾nÃŠÃ†:Â­jÃ‘Ã“mÃ™<Â§Ã‹Âª="Ãâ€ï¿½Â·tYâ€¢zÂ¢Â·Â²Â³Â¤Ã‹ÂªÂ½Ãï¿½Ã©VÂ­Ã¨Ã­â€ ÃŒ~Ã‘aÃ•Å ÃnÃˆÃ®Å Â«Vâ€”Ã´x3Ã¦k:Â¬Zï¿½Ã‘Ã£ÃËœÃ“]UkÂ¤'qHwUÂ­â€˜Å¾Ã„ÃUÂµ<" iÃ€â€œï¿½fzsÂºÂ«j}Â£Ã‡â€ºÂ±owuÂ­zÂ¼{twÃ•Ã²$Â¤ï¿½â€˜Å¾Ã„Å’Ã®Âªz#="â€°)ÃUÂµÃ´x3Â¦tWÃ•ÂºÂ¢Ã‡â€ºqOwUÂ­Ã´x3Ã–tWÃ•ÂºÂ¡Ã‡â€ºAgUÂ¯;zÂ¼tVÃµz&nbsp;Ã‡â€ºAgUÂ¯gzÂ¼tVÃµÃºMï¿½7Æ’ÃÂªbÅ¸Ã¨ÃµFÃUUÃ¬Ëœ^o]UÃ…Â¾Ã’Ã«ï¿½&nbsp;Â«ÂªÃ˜wzÂ½tUÃ»IÂ¯7â€šÂ®ÂªbKzÂ½" 3ÂºÂªÅ yÃ’Ã€(obbwuÂ±qÅ¾Ã„â€šÂ®ÂªbÅ¾â€4Ã°hÃ7ÃÃ‡iÃ¯Â·Â¢Ã§awuÂ±wzÂ½tu5Ã»@Ã7ï¿½Å½Âªf[Ã´|Ã¨Â¦jÃ¶gbÃ¯7â‚¬Å½ÂªfkzÂ¾="" tt5[ÃÃ³mÂ Â£ÂªÃ™gzÂ¾="" tt{Ã›Â¦Ã§â€º@wuÂ±szÂ½tuÃµÃº{dÂ¯7Ã¡â€šÃÂª^Ã—Ã´zÃ¿Ã£Å¸ï¿½ï¿½â€°Ã¡Â§="" endstream="" endobj="" 5917="" 0="" obj="" <<="" bitspercomponent="" 8="" colorspace="" devicegray="" filter="" jpxdecode="" height="" 765="" intent="" relativecolorimetric="" length="" 30351="" name="" x="" smask="" 5916="" r="" subtype="" image="" type="" xobject="" width="" 787="">&gt;stream
jP  
â€¡
ftypjp2 jp2 jpxbjpx rreqÃ¸Ã¸â‚¬@ .-jp2hihdrÃ½colrvjp2cÃ¿OÃ¿Q)Ã½Ã¿RÃ¿\#B@HHPHHPHHPHHPHHPÃ¿ï¿½
?Ã¿â€œÃ&nbsp;Ãˆ\Â®Fâ€˜Ã¬â€“ÂªQv~}Ã &nbsp;M!â€ Ã¿Ã‰Ã±cÃŒCÅ½Ã¨GÃ¨Ã‹â‚¬Ã£W	S Ã¸Ã‹â‚¬â‚¬Ã¿ï¿½
5Ã¿â€œÃŸpÃ¨Y.:)Â¯Ã³|Ã½Â½â„¢Â¹AÃ¢GÃšï¿½ÃƒÃ¾/Â³&amp;Ã¾ÃšÃƒÃ â‚¬tâ‚¬â‚¬â‚¬â‚¬Ã¿ï¿½
SÃ¿â€œÃŸY`gÃ¥Ã´Ã¥	e~;Ã•jÃÃ¶LpCÂ¶q'Ã£Â¿ÃŠ9@vÃŒÃ„u)â€”Ãš2ï¿½Â«FÃ¡FÅ¡qâ€ºÃ™Ã¤Â­Æ’qÃµ+Ãaâ‚¬Ã°Ã â„¢ï¿½Ã—ÃŒO!Aâ‚¬â‚¬Ã¿ï¿½
Ã¿â€œÃÂ´Pâ‚¬â‚¬â‚¬â‚¬â‚¬Ã¿ï¿½
1Ã¿â€œÃŸXÂ°[Ã†Å¡7â€â‚¬.Å¡Ã»Ã¸44ÃµÂ´cÂ¼bÃ½^ÂªÃ¸@TÂ·Ã¯Ãœâ‚¬â‚¬â‚¬â‚¬Ã¿ï¿½
[Ã¿â€œÃŸYÂ¨$6Â¼Ã¯!aÂ¹9TÂ¡^&gt;Ã•Å“Â¤Ã«_"-Ã™$Å½KÃ¦ÃœaÅ¸dqÅ“hâ‚¬Ã¾â€”'eYQ/Â¦Wy1Â¿â€ºÃˆÃºÅ¸Ã«ssÃ±Â¯4Ã§XÃ±Ëœ+Ã£Å½Ã¯Ã–Â·oIâ‚¬â‚¬â‚¬Ã¿ï¿½
\Ã¿â€œÃŸYÂ¨31ue	Å“ÃÃ°\Ã®Â©ZU6MÃŠÃ†Â¡ÃºÂ²CÅ¸Â¯Ã¶Ã³mQÃ¿TÂ·oâ€¹Â»Ã‰lÃ¶!NÂ®c6Â¡Â£ÃŠSÂ¾EÃ±Â¤aÃœ^â€™ÃŠâ‚¬Ã£â‚¬Ã§,xZ.â‚¬â‚¬Ã¿ï¿½
Ã¿â€œÃÂ´Pâ‚¬â‚¬â‚¬â‚¬â‚¬Ã¿ï¿½
TÃ¿â€œÃŸYx#Å¡â€¡ÃŒ+ÃŠbjÃ®Æ’Ã¥!Ã¦Â®?ï¿½Â§V}Ã*Ã‡Ã”&gt;Ãƒâ€ LÃ½Å¾â„¢LGÃ‰
x6=cÃ‚Ã¹gÃ±â€¹wÃÃ¾,Ã—1â‚¬Ã¢â‚¬Ã§Sâ€˜"â‚¬â‚¬Ã¿ï¿½
	[Ã¿â€œÃŸBÂ°Â¯ )&nbsp;Å¸â€º
Â¬Ãƒw%Â¬
Â·Ã¬|Ã¨Ëœ(ÂµÂ¶AÃ‘Ã¢&amp;Â©Ã•â€Ãœâ€”ÃÃ¼Â³Å¸
Ã¹PÅ’Ã™Â·Ã‰Ãâ€˜`GÃŠÃ§Ã»â‚¬Ã£â‚¬`1â€”lâ€ â‚¬â‚¬Ã¿ï¿½

LÃ¿â€œÃŸY@Ã‡â€â€¡&gt;56Â¬`OÅ¸â‚¬Ã˜ÂºÂ¢1jÃ“ÃµÃµUÃÃ›â€šÂ¶Â±mÃ‡YsÂ¬CÃ·Ã³Ã¦Ã®7ÃºÃ°Ã ;gwvoï¿½Ã³Ã¢â‚¬UÃšdÃ˜â‚¬â‚¬â‚¬Ã¿ï¿½
Ã¿â€œÃÂ´Pâ‚¬â‚¬â‚¬â‚¬â‚¬Ã¿ï¿½
IÃ¿â€œâ‚¬Ã€Ã¡Ã tâ‚¬ ?Â°Â³Ã|,â€¹BPV1pÅ½Ã±(	â‚¬Å“Ã¨VÃ«0NÆ’H+^{Â¶Ãƒâ€¹Å â€¹Ã»Ã¥â€¹ÃƒÃ†yNÃ—â‚¬Â¢Â¦&amp;Ã¿ï¿½
HÃ¿â€œÃâ€ZÃ€]Â¾KÂ¤#Ã­â€ºwÃ´Gâ€š_Â®Â¸Ã„Ã¸8&gt; Ã¸@C(Ã¡_Ã™^2â€!Ã´Å“ =Ã¨â€”Ã°lGbÂ¥Ã‰Â¡Âµâ‚¬Ã¿ï¿½
Â£Ã¿â€œÃ‡Ã†F&gt;#Ã²@[Ã–&gt;Ã¬Â¨ÃÃŸRxtÂ®tlFÃ§1Ã¸Â¼ï¿½eÃ·Ã©Ã’Â­C&lt;Ã¨â€°I
GÃ«Â«)AÃŸqÂ¢1Ã‰Â«|Å½Â¢KÃ‰Ã³ÃœRÃ´Â¯Ã°Ã¡Ã´RÂ±ï¿½ÃMxâ€¹Ã„8Â±#ZÃªu#pâ€Ã’Å â€˜Å¡Â¾Å’oÂ½â‚¬Ã±'Ã¼Â¦â€¡lÃ­ÃŒlÃ–Å½lÂ¡
â€™â€”ÃÃ³jâ€ºwÂ°Ã£Å¸Ã¡xÂ­1Ã°Ã€]Â¾_09ÃŒÃ¿ï¿½
Ã¿â€œâ‚¬â‚¬â‚¬â‚¬â‚¬â‚¬Ã¿ï¿½
EÃ¿â€œÃï¿½D&lt;,&gt;Ã€`â€”â„¢Ã¶Ã†U]Oâ„¢Ã–E\Ã§Â¢Âº#Ã©Ã¼Ã´//Ã–sÃÅ“Â³PQÂ°â‚¬ÃŠ+Â°@Ã•Ã°H@
Ã­â‚¬Ã¿ï¿½
Â°Ã¿â€œÃ‡Ã„^&gt;#QÃ±1[EkÂ­Ã™Â¹BÃŒâ€Âª.â€¹`Ãªâ‚¬â€“ï¿½geMÃ½m3.VÅ Å Â»tÃšÃ¹Å¡Ã¥MÂ¿kÅ¸4-Ã³vGF3kÃ¬\oH,,Ã¥ÃÅ½1Å’nÃ¸ÃÃ¢Ã€HÂµ,Å¾Ã‘ÃÃ­S\Ã'Âº 7.]Ã¯Ã­Â«â„¢EÂ¤Ã» 
Â½C_Ã†Ã²Ã˜&lt;Ã¢Ã°Ã¼@D5â€ºT.Ã‰"TÅ¸p\MÂ¥;JÅ Ã†â€“Â¦Ã„ÃµNÃ¢E*Ã›&nbsp;OwÃ¿ï¿½
Â­Ã¿â€œÃ‡Ã„b&gt;"Ã±Ã±â€¢1`â€”Âµâ€œC4Â¼Ã¥ÂºÃ™ÂºÃ…XÅ¡Ã„Â«:Â¶â€šÃ â€¦ÃšÅ“?ÃÃ–Ã„2;Ã‘dÃ„Ã¢Ã¸Ã™Ã¬Ã·Ã·?Â¨(Ã‡ÃŠTÃ‡Â¶Ã¸XGÃ¶â€˜!Â¡8?ÃŠÃ¼Ã¸Â®â€™Ã—â€ºoÃ»Ã±
-9qÂ«â€ 7Mâ€”UÂ³ÃšÂ±EÃ¢(Ã³ï¿½Å¡Â»UÃ¬DÃ·Â¹Â°Â¤ËœÃ â€ºÃ‚Ãâ€˜â€¦Â¤Â²Ã£caâ‚¬{Ã¸ÃÃšOÃœÃ’VÆ’"4\
ÃˆÂ¢Å’BÃƒPÃ€0Â±â€Ã²Â­&amp;Ã¿ï¿½</dg[Â¦ï¿½Â³Ã´uÃ¥gtÂ·%Ã¾=}\Ã±Ã½mâ€°Â¶_Â£ï¿½+^Â¢Ã£-Ã¯Ã®%ÃºÂ¶Ã¢%:Ã¼Ã²$Ã¨Ã³Å¡Ã¿Ã¾Ã£nÂ£Ã¤@qn&â€“ÃºÂ¤â€¹ï¿½></c[ÂºÃ­Ã´â€¦Ã¥3tÂ±Â¥Â¢></i!vdtâ€¹64nÃ©%!Ã¿eÃ§hÃ£Â®ez1Æ’Å¾Ã±â€Ãª%zÂ±Æ’Â®Ã±â€></qÃ»Ã¤ez)qâ€nÃ­Ã©Ã¸Ã«Ã´pÃ¢jï¿½Â®Ã­sz(qÂ¥cÃ—Ã¦Æ’dÃ¼5z'qâ€¡Ã®Ã­[Â¦Â¯Ã²3â€°;tnÂ¨Ã­Ã½â€¢Â¾â€º"Ã²Â¤Æ’3></o^Å¾Å“Ã§6Ã¿Â¤tÂ¤Ã¨Ã½Ã·Ãµ|Ã¬Ã¼Ã Ã®â€¹]Ã¿Ã—Â¼<Ã¹Ã¢Ã¯Ã§Ã¯Ã¶<Ã¤Ã­c_vÂ¸xÂ·Ã±d.Ã¯&Â¶Ã¤kÃ¾Ã®Ã¸Ã©Ã¯Ãµ!jÃ½g></iÃ¨Ã¹Ã«.Ã£Ã¥xÂ¬Ã¡kÂ¸Â½&Â³Ã­Ã±Ã¯Ã¥jok"@Ã¿vÃ£yÃ vÃ¤ÃºÂ¾Â³Ã½Ã¡lÃ¾1[Ã¼Ã§Â´vixzÃ¸Â²Ã£h=â€œÃ­â€ºÅ¾cÃ«Ã»Ã¥></s5+Ã±yÂ³Ã¯Å¾!Å“)ÃŸ#Ã¦Ã¾Ãºâ€˜:Â»Ã£Æ’ÃµÃ Ã¾~ï¿½Ã¸Å“Ã¯tÅ¾â€˜eâ€¹)xÃ¹Ã§Ã²kÃ¾Ã¯.38Ãº2Ã·Ã³nÃºl&Â£aÅ¡zÂ­Â¼Ã©07Ã³Ã¥`></y></dÃ»:â€ÃªsmlÃºryÂªÃ¯ï¿½b></cÃ«xj></vÃ¼â€¡Ãºâ€ Ã©'â€°ï¿½k]â€“'ÂªÃ¨|9Ã¢Ã¨Â·[Ãªr"bâ€ #Ã£â€œ[mÃµÂ¦_ql]yÂ¨Â¾Ã©Â½9Ã£vÃ±Â¤<\Â­ï¿½#(â€°Å¾ÂµzÂ¤qÃ¹â€˜b></rf8jâ€œ3Â¹'yÃ—Â³Ãªz2ï¿½):8gl{bucï¿½Ã¥:Ã¨Å¡Å¾Å“â‚¬â€™*eÃ¦2Ã½Ãºv9ÃµÂ¦;@Ã¬qÂ¥ï¿½bËœÃ¾ÃªÂªÂ©zÂºÂ©Ã±></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://equitablemath.org/wp-content/uploads/sites/2/2020/11/1_STRIDE1.pdf">https://equitablemath.org/wp-content/uploads/sites/2/2020/11/1_STRIDE1.pdf</a></em></p>]]>
            </description>
            <link>https://equitablemath.org/wp-content/uploads/sites/2/2020/11/1_STRIDE1.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-26188717</guid>
            <pubDate>Fri, 19 Feb 2021 02:15:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automate deleting old Google emails and calendar events]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26188686">thread link</a>) | @SUPERCILEX
<br/>
February 18, 2021 | https://alexsaveau.dev/blog/tips/privacy/automation/automate-deleting-old-google-emails-and-calendar-events | <a href="https://web.archive.org/web/*/https://alexsaveau.dev/blog/tips/privacy/automation/automate-deleting-old-google-emails-and-calendar-events">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p>Google <a href="https://blog.google/technology/safety-security/automatically-delete-data/">introduced</a> auto deletion for web, YouTube, and location activity back in 2019, but hasnâ€™t come out with official solutions for their other products yet. Notably, gmail and gcal have data that likely isnâ€™t needed after some number of months.</p> <p>To automate deleting old data, <a href="https://developers.google.com/apps-script">Google Apps Script</a> is the handiest tool available. Off we go:</p> <ul id="markdown-toc"> <li><a href="#creating-a-script" id="markdown-toc-creating-a-script">Creating a script</a></li> <li><a href="#scheduling-scripts-as-cron-jobs" id="markdown-toc-scheduling-scripts-as-cron-jobs">Scheduling scripts as CRON jobs</a></li> <li><a href="#using-scripts-across-multiple-google-accounts" id="markdown-toc-using-scripts-across-multiple-google-accounts">Using scripts across multiple Google accounts</a></li> <li><a href="#thorn-google-accounts-in-the-advanced-protection-program" id="markdown-toc-thorn-google-accounts-in-the-advanced-protection-program">Thorn: Google accounts in the Advanced Protection Program</a></li> <li><a href="#appendix" id="markdown-toc-appendix">Appendix</a> <ul> <li><a href="#email-deletion" id="markdown-toc-email-deletion">Email deletion</a> <ul> <li><a href="#script" id="markdown-toc-script">Script</a></li> </ul> </li> <li><a href="#calendar-event-deletion" id="markdown-toc-calendar-event-deletion">Calendar event deletion</a> <ul> <li><a href="#script-1" id="markdown-toc-script-1">Script</a></li> </ul> </li> </ul> </li> </ul> <h2 id="creating-a-script">Creating a script</h2> <p>Visit <a href="https://script.new/">script.new</a> and write your own code, or paste in the solutions Iâ€™ve been using from the <a href="#appendix">appendix</a>. Hit save, and the editor will automatically pick the first function it sees to run by default.</p> <p>You can then click on Run to execute the script manually, giving it permissions to access your account.</p> <blockquote> <p>Note: the first time you run a script operating on lots of data, it will probably fail several times with various quota errors. You can either continue running it manually until the script reaches a steady state (having processed all your data), or move on to scheduling it and let things eventually sort themselves out.</p> </blockquote> <h2 id="scheduling-scripts-as-cron-jobs">Scheduling scripts as CRON jobs</h2> <p>Once youâ€™ve executed the script at least once to give it the correct permissions, you can use the Triggers page found in the left sidebar to schedule your script for periodic execution. The defaults when you add a trigger are good enough, but I tend to downgrade the schedule from every hour to once a day as an hourly job seems a tad wasteful.</p> <h2 id="using-scripts-across-multiple-google-accounts">Using scripts across multiple Google accounts</h2> <p>You can share a script like a Google Doc, but youâ€™ll have to run it once and create a Trigger for each account. The main benefit of sharing the script is that modifications only need to be performed once instead of being copied to each account.</p> <h2 id="thorn-google-accounts-in-the-advanced-protection-program">Thorn: Google accounts in the Advanced Protection Program</h2> <p>Sadly, if your Google account is enrolled in the <a href="https://landing.google.com/advancedprotection/">Advanced Protection Program</a>, there is no way that Iâ€™m aware of to run unapproved Apps Scripts. When you try to accept the permissions on the first run, the request will be denied. This is apparently <a href="https://support.google.com/accounts/answer/7539956?hl=en#zippy=%2Ccan-i-use-non-google-apps-services-or-apps-script-with-advanced-protection">intentional</a> which is a bummer.</p> <hr> <h2 id="appendix">Appendix</h2> <p>These are the scripts Iâ€™ve been using to manage my own old data.</p> <blockquote> <p>Note: when I say â€œdeleteâ€ below, I really mean â€œmove to trash.â€ The scripts donâ€™t empty the trash, allowing for the standard 30-day grace period to elapse.</p> </blockquote> <h3 id="email-deletion">Email deletion</h3> <p>This script deletes emails that donâ€™t have the <code>indef</code> label <em>and</em> are 18 months old (or older). It also deletes any unread emails that have been archived.</p> <p>Reference docs are available <a href="https://developers.google.com/apps-script/reference/gmail">here</a> and you can read about creating labels in Gmail <a href="https://support.google.com/mail/answer/118708">here</a>.</p> <p>Expected workflow:</p> <ul> <li>Manually label all critical emails with the <code>indef</code> label. Any other email is transient and will eventually be deleted.</li> <li>Any email you swipe away (archive) without opening is unneeded and gets deleted immediately. This mainly enables Inbox Zero without having to manually open emails you donâ€™t care about to mark them as read and then archive them.</li> </ul> <h4 id="script">Script</h4>  <div><div><pre><code><span>/** Deletes 18 month+ old emails and unread archived emails. */</span>
<span>function</span> <span>processMail</span><span>()</span> <span>{</span>
  <span>deleteEmailMatching</span><span>(</span><span>'</span><span>label:unread -label:inbox</span><span>'</span><span>);</span>
  <span>deleteEmailMatching</span><span>(</span><span>'</span><span>older_than:18m -label:indef</span><span>'</span><span>);</span>
<span>}</span>

<span>function</span> <span>deleteEmailMatching</span><span>(</span><span>query</span><span>)</span> <span>{</span>
  <span>let</span> <span>threads</span> <span>=</span> <span>[];</span>
  <span>while</span> <span>(</span><span>true</span><span>)</span> <span>{</span>
    <span>threads</span> <span>=</span> <span>GmailApp</span><span>.</span><span>search</span><span>(</span><span>query</span><span>,</span> <span>0</span><span>,</span> <span>100</span><span>);</span>
    <span>if</span> <span>(</span><span>threads</span><span>.</span><span>length</span> <span>&gt;</span> <span>0</span><span>)</span> <span>{</span>
      <span>trash</span><span>(</span><span>threads</span><span>);</span>
    <span>}</span> <span>else</span> <span>{</span>
      <span>break</span><span>;</span>
    <span>}</span>
  <span>}</span>
<span>}</span>

<span>function</span> <span>trash</span><span>(</span><span>threads</span><span>)</span> <span>{</span>
  <span>threads</span><span>.</span><span>forEach</span><span>(</span><span>thread</span> <span>=&gt;</span> <span>{</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>`Deleting email '</span><span>${</span><span>thread</span><span>.</span><span>getFirstMessageSubject</span><span>()}</span><span>': </span><span>${</span><span>thread</span><span>.</span><span>getPermalink</span><span>()}</span><span>`</span><span>);</span>
  <span>});</span>
  <span>GmailApp</span><span>.</span><span>moveThreadsToTrash</span><span>(</span><span>threads</span><span>);</span>
<span>}</span>
</code></pre></div></div> <h3 id="calendar-event-deletion">Calendar event deletion</h3> <p>This script deletes calendar events that are 18 months old (or older). It includes an <code>OTHER_EMAILS</code> field that allows a single account to handle auto-deleting events for any other account.</p> <p>Reference docs are available <a href="https://developers.google.com/apps-script/reference/calendar">here</a>.</p> <p>Expected workflow:</p> <ul> <li>Give the <code>Make changes to events</code> permission to the account running the script for any calendar where you want auto-deletion running. Then add the calendarâ€™s email to the <code>OTHER_EMAILS</code> array in the script. If itâ€™s not your primary calendar, you can find its ID/email by going to the calendarâ€™s settings and looking at the first field under the <code>Integrate calendar</code> section.</li> </ul> <h4 id="script-1">Script</h4>  <div><div><pre><code><span>const</span> <span>OTHER_EMAILS</span> <span>=</span> <span>[</span>
  <span>'</span><span>foo@example.com</span><span>'</span><span>,</span>
  <span>'</span><span>...</span><span>'</span><span>,</span>
<span>]</span>

<span>/** Deletes calender events that took place 18 months ago or earlier. */</span>
<span>function</span> <span>processCalendars</span><span>()</span> <span>{</span>
  <span>for</span> <span>(</span><span>let</span> <span>calendar</span> <span>of</span> <span>CalendarApp</span><span>.</span><span>getAllCalendars</span><span>())</span> <span>{</span>
    <span>if</span> <span>(</span><span>calendar</span><span>.</span><span>isOwnedByMe</span><span>()</span> <span>||</span> <span>OTHER_EMAILS</span><span>.</span><span>includes</span><span>(</span><span>calendar</span><span>.</span><span>getId</span><span>()))</span> <span>{</span>
      <span>console</span><span>.</span><span>log</span><span>(</span><span>`Deleting old events in calendar: </span><span>${</span><span>calendar</span><span>.</span><span>getName</span><span>()}</span><span> (</span><span>${</span><span>calendar</span><span>.</span><span>getId</span><span>()}</span><span>)`</span><span>);</span>
      <span>deleteOldEvents</span><span>(</span><span>calendar</span><span>);</span>
    <span>}</span>
  <span>}</span>
<span>}</span>

<span>function</span> <span>deleteOldEvents</span><span>(</span><span>calendar</span><span>)</span> <span>{</span>
  <span>const</span> <span>epoch</span> <span>=</span> <span>new</span> <span>Date</span><span>(</span><span>0</span><span>);</span>
  <span>const</span> <span>eitghteenMonthsAgo</span> <span>=</span> <span>new</span> <span>Date</span><span>(</span>
      <span>new</span> <span>Date</span><span>().</span><span>getTime</span><span>()</span> <span>-</span> <span>(</span><span>1000</span> <span>*</span> <span>60</span> <span>*</span> <span>60</span> <span>*</span> <span>24</span> <span>*</span> <span>30</span> <span>*</span> <span>18</span><span>));</span>

  <span>while</span> <span>(</span><span>true</span><span>)</span> <span>{</span>
    <span>const</span> <span>oldEvents</span> <span>=</span>
        <span>calendar</span><span>.</span><span>getEvents</span><span>(</span><span>epoch</span><span>,</span> <span>eitghteenMonthsAgo</span><span>,</span> <span>{</span><span>max</span><span>:</span> <span>100</span><span>});</span>
    <span>if</span> <span>(</span><span>oldEvents</span><span>.</span><span>length</span> <span>==</span> <span>0</span><span>)</span> <span>{</span>
      <span>break</span><span>;</span>
    <span>}</span>

    <span>for</span> <span>(</span><span>let</span> <span>event</span> <span>of</span> <span>oldEvents</span><span>)</span> <span>{</span>
      <span>console</span><span>.</span><span>log</span><span>(</span><span>`Deleting event '</span><span>${</span><span>event</span><span>.</span><span>getTitle</span><span>()}</span><span>' `</span> <span>+</span>
          <span>`that took place between </span><span>${</span><span>event</span><span>.</span><span>getStartTime</span><span>()}</span><span> and </span><span>${</span><span>event</span><span>.</span><span>getEndTime</span><span>()}</span><span>`</span><span>);</span>
      <span>event</span><span>.</span><span>deleteEvent</span><span>();</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div> </div></div>]]>
            </description>
            <link>https://alexsaveau.dev/blog/tips/privacy/automation/automate-deleting-old-google-emails-and-calendar-events</link>
            <guid isPermaLink="false">hacker-news-small-sites-26188686</guid>
            <pubDate>Fri, 19 Feb 2021 02:11:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[5-MeO-DMT: The Story Behind the 'â€œGod Moleculeâ€ (2020)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26188612">thread link</a>) | @mardiyah
<br/>
February 18, 2021 | https://doubleblindmag.com/5-meo-dmt-the-story-behind-the-god-molecule/ | <a href="https://web.archive.org/web/*/https://doubleblindmag.com/5-meo-dmt-the-story-behind-the-god-molecule/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>The Colorado River toadâ€”a.k.a. the Sonoran Desert toadâ€”is flat and squat. No distinctive markings adorn its swampy olive skin, and while a passerby may remark upon its large size, the toad does little to draw attention to itself. And yet, for an animal so easy to miss or ignore, the amphibian provides a surprising asset for psychonauts: The Colorado River toad is the only animal source of â€œthe God moleculeâ€â€”5-MeO-DMT.&nbsp;</p>
<h2 id="h-5-meo-dmt-sonoran-desert-toad-venom-synthetic-psychedelic-plant-medicine-or-all-three"><span id="5-MeO_DMT_Sonoran_Desert_Toad_Venom_Synthetic_Psychedelic_Plant_Medicine_or_All_Three">5-MeO DMT: Sonoran Desert Toad Venom, Synthetic Psychedelic, Plant Medicine, or All Three?</span></h2>
<p>5-MeO-DMT is a potent psychedelic found within the excretion of the Colorado River toad (<em>Bufo alvarius </em>or<em> Incilius alvarius</em>). Although, itâ€™s also present in some plants and can be <a href="https://doubleblindmag.com/toad-venom-vs-synthetic-5-meo-dmt/">made synthetically</a>â€”the latter being the most sustainable way to consume the entheogen. It belongs to a class of chemical compounds called <a href="https://psychedelicstoday.com/2018/01/05/psychedelic-tryptamine-chemistry/">tryptamines</a>, which include psilocybin and DMT (N,N-dimethyltryptamine).</p>
<p>In the United States, the Colorado River toad is one of the most common and controversial sources of 5-MeO-DMT. Its native habitat runs along the southwestern United States and northern Mexico. But, the oldest known uses of 5-MeO-DMT come from South America. The chemical is a natural constituent in <em>Anadenanthera peregrina </em>seeds, which are used to make entheogenic Yopo snuff.&nbsp;</p>
<h3 id="h-5-meo-dmt-trip-how-long-does-it-last"><span id="5-MeO-DMT_Trip_How_Long_Does_It_Last">5-MeO-DMT Trip: How Long Does It Last?&nbsp;</span></h3>

<p>5-MeO-DMT produces an intense but short psychedelic experience. A full dose 5-MeO-DMT trip lasts between 30 and 90 minutes at most, and the majority are even significantly shorter than that. However, while the time on the clock may tick away quickly for those on the outside world, it certainly doesnâ€™t for those in the middle of the psychedelic experience.</p>
<p>During a 5-MeO-DMT trip, itâ€™s not uncommon for consumers to feel like theyâ€™ve transcended time. A 5-MeO-DMT trip is strong enough to take participants out of normal consciousness, into a state of temporary unconsciousness, with <a title="" target="_blank" href="https://doubleblindmag.com/ego-death/">ego death</a> making room for therapeutic exploration of the subconscious or an encounter with the divine. For this reason, a <a href="https://doubleblindmag.com/trip-sit-lsd-psilocybin/">trip sitter</a> plays an important role in monitoring the participant while theyâ€™re on their journey.</p>
<h3 id="h-5-meo-dmt-average-dosage"><span id="5-MeO-DMT_Average_Dosage">5-MeO-DMT Average Dosage</span></h3>
<p>The average dosage of 5-MeO-DMT is small compared to many other psychedelics. Researchers report that <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6292276/#:~:text=5%2DMeO%2DDMT%20appears%20to,with%20consumption)%2C%20which%20requires%20further">five to seven milligrams</a> are enough to occasion a moderate to strong experience. Those using toad secretion rather than synthetic 5-MeO-DMT often <a href="https://www.forbes.com/sites/davidcarpenter/2020/02/02/5-meo-dmt-the-20-minute-psychoactive-toad-experience-thats-transforming-lives/#398c2d2338a1">take doses of up to 50 milligrams</a>. Itâ€™s risky, however, for new consumers to start with such a dose, which may be overwhelming and more likely to cause negative reactions.</p>
<h3 id="h-how-do-you-take-5-meo-dmt"><span id="How_Do_You_Take_5-MeO-DMT">How Do You Take 5-MeO-DMT?</span></h3>
<p>5-MeO-DMT is most often inhaled through a vaporization device. Both synthesized 5-MeO-DMT and powdered toad venom comes in a crystallized or viscous form, and theyâ€™re often smoked using a high-heat pipe or rig. The active effects kick in within a mere couple seconds after inhalation, causing consumers to lose their sense of motor control and retreat inward into the depths of their consciousness.&nbsp;</p>
<h2 id="h-5-meo-dmt-vs-dmt"><span id="5-MeO-DMT_vs_DMT">5-MeO-DMT <em>vs</em>. DMT</span></h2>
<p>Dimethyltryptamine (DMT) is the active chemical component in <a title="" target="_blank" href="https://doubleblindmag.com/what-is-ayahuasca-iowaska/">ayahuasca</a>, famously dubbed â€œthe spirit molecule.â€ Itâ€™s what thousands of tourists seek out during psychedelic pilgrimages to Latin America every year. DMT can also be smoked on its own, occasioning a more rapid, intense trip than the hours-long ayahuasca experience.&nbsp;&nbsp;</p>
<h3 id="h-5-meo-dmt-is-different"><span id="5-MeO-DMT_is_Different">5-MeO-DMT is Different</span></h3>

<p>Itâ€™s a derivative of DMT, meaning that they are related compounds. But, the two can produce different experiential and physiological effects. 5-MeO is often considered to be stronger than DMT, and consumers <a href="https://www.reddit.com/r/5MeODMT/comments/esb3jm/first_time_dmt_vs_5_meo_dmt/ff8wr6a/">often report</a> that it inspires a potent transcendent experienceâ€”devoid of visualsâ€”rather than a highly visual experience, such as what DMT is known for.&nbsp;&nbsp;</p>

<figure><img width="819" height="1024" src="https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-meo-dmt-bufo-alvarius-1-1-819x1024.jpg" alt="" srcset="https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-meo-dmt-bufo-alvarius-1-1-819x1024.jpg 819w, https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-meo-dmt-bufo-alvarius-1-1-240x300.jpg 240w, https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-meo-dmt-bufo-alvarius-1-1-768x960.jpg 768w, https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-meo-dmt-bufo-alvarius-1-1.jpg 835w" sizes="(max-width: 819px) 100vw, 819px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20819%201024'%3E%3C/svg%3E" data-lazy-srcset="https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-meo-dmt-bufo-alvarius-1-1-819x1024.jpg 819w, https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-meo-dmt-bufo-alvarius-1-1-240x300.jpg 240w, https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-meo-dmt-bufo-alvarius-1-1-768x960.jpg 768w, https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-meo-dmt-bufo-alvarius-1-1.jpg 835w" data-lazy-src="https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-meo-dmt-bufo-alvarius-1-1-819x1024.jpg"><figcaption>Colorado River Toad<em> </em>(Bufo alvarius) via <a href="https://commons.wikimedia.org/wiki/File:2009-03-13Bufo_alvarius067.jpg" target="_blank" rel="noreferrer noopener">Wikimedia Commons</a>.</figcaption></figure>

<h2 id="h-the-god-molecule-and-mystical-experiences"><span id="The_God_Molecule_and_Mystical_Experiences">The â€œGod Moleculeâ€ and Mystical Experiences</span></h2>
<p>5-MeO-DMT is called â€œthe God Moleculeâ€ for a simple and yet astounding reason: It can make one feel as if they are speaking to, connected with, or becoming one with the divine. Like many other psychedelics, 5-MeO-DMT is an <a href="https://doubleblindmag.com/what-does-entheogen-actually-mean/">entheogen</a>. An <em>entheogen</em> is a chemical compound that can trigger <a href="https://doubleblindmag.com/rick-strassman-dmt-mystical-state/">mystical experiences</a>â€”feelings of intense spirituality.&nbsp;</p>
<p>But you need not be religious or spiritual to have an entheogenic experience with 5-MeO-DMT (or any psychedelic for that matter). Every personâ€™s individual experience is unique, and â€œGodâ€ is merely one word to describe the <a href="https://doubleblindmag.com/why-feeling-connected-is-good-for-your-health/">connection</a> that the drug seems to make possible. Instead of â€œGod,â€ others may prefer terms like Brahman, Nirvana, Gaia, Nature, Universal Consciousness, Higher Power, or none at all. Whatever term they use, each personâ€™s experience is ultimately different, and the meaning and interpretation of that experience is up to the individual.&nbsp;</p>
<p>The idea that spirituality can be chemically triggered is one that many may find uncomfortable. But, as scientists probe into the mysterious world of psychedelics, many studies are finding exactly that: Psychedelics can inspire intense mystical experiences, similar to spontaneous religious epiphanies and spiritual revelations. Like religious or spiritual epiphanies, these chemically-induced experiences can be life-changingâ€”and often correlate with the magnitude of healing the subject may experience for whatever indication they are aiming to treat with the psychedelic.&nbsp;</p>

<p><strong><em>Read: <a href="https://doubleblindmag.com/toad-venom-vs-synthetic-5-meo-dmt/">Is it Worth Kidnapping Toads to Extract their Psychedelic Venomâ€”When You Could Make it In a Lab?</a></em></strong></p>

<p>Indeed, some of the core tenants of a mystical experience include a deep-rooted feeling of unity and interconnectedness with the world around you, as well as profound feelings of joy, transcendence of time and space, and feelings of importance beyond the scope of the self. Psychedelic mystical experiences can be particularly profound because they can inspire a sense that this interconnectedness <em>is</em> reality, that this experience <em>is</em> the natural state of the worldâ€”the experience can have an inherent truth that extends beyond what words can describe.&nbsp;</p>
<p>In 2011, researchers used psilocybin to<a href="https://europepmc.org/backend/ptpmcrender.fcgi?accid=PMC3537171&amp;blobtype=pdf"> test the long-term impact of psychedelic therapy on personality changes in adults</a>; psilocybin is the active constituent in magic mushrooms (sometimes simply called <a href="https://doubleblindmag.com/how-to-take-shrooms-shroom-dosage-shroom-effects/">shrooms</a>). In general, personality is considered relatively set after adults reach the age of 30. But, in this particular study, researchers found that psilocybin could inspire â€œlasting personality changesâ€ for over a year after treatment.&nbsp;</p>
<p>And these changes were positive. After high-dose psilocybin therapy, participants who achieved a â€œmystical experienceâ€â€”defined by specific criteria put forth by psychedelic scientistsâ€”left the study with higher marks of openness than they had upon arrival. â€œOpennessâ€ consists of a collection of personality traits, that includes a willingness to try new experiences, tolerance of othersâ€™ viewpoints, the appreciation of aesthetic qualities, and more.&nbsp;</p>

<p><strong><em>Read: <a href="https://doubleblindmag.com/rick-strassman-dmt-mystical-state/">Rick Strassman on DMT and the Mystical State</a></em></strong></p>

<p>Other studies found that psychedelic experiences have reduced depression and anxiety, aided in trauma therapy for post-traumatic stress, and even had positive impacts in reducing alcoholic addictions and obsessive-compulsive tendencies. But, the majority of these studies were performed on more common psychedelics, like psilocybin, lysergic acid diethylamide (LSD), and ketamine.</p>
<p>Now, researchers are testing the ability of 5-MeO-DMT to occasion similar resultsâ€”and theyâ€™ve had small successes thus far. Recently, scientists proved that the toad molecule indeed can<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6292276/"> inspire mystical experiences</a>, and may even hold potential as a more manageable therapy tool than psilocybin and LSD.&nbsp;</p>
<p>Of course, not every person will have such an awe-inspiring interaction with the drug. Itâ€™s even possible to have a challenging experienceâ€”one thatâ€™s uncomfortable, traumatizing, and even unsafe. Unlike your average medicine, there is no regulation nor substantive clinical research that provide guidance about how to use 5-MeO-DMT, while scientists also have not extensively looked into whether or not certain people may face considerable physical and mental health risks when trying the compound.</p>

<figure><img width="1013" height="768" src="https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-MeO-DMT.png" alt="" srcset="https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-MeO-DMT.png 1013w, https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-MeO-DMT-300x227.png 300w, https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-MeO-DMT-768x582.png 768w" sizes="(max-width: 1013px) 100vw, 1013px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201013%20768'%3E%3C/svg%3E" data-lazy-srcset="https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-MeO-DMT.png 1013w, https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-MeO-DMT-300x227.png 300w, https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-MeO-DMT-768x582.png 768w" data-lazy-src="https://doubleblindmag.com/wp-content/uploads/2020/08/DoubleBlind-5-MeO-DMT.png"><figcaption>Chemical structure of 5-MeO-DMT via <a href="https://commons.wikimedia.org/wiki/File:5-MeO-DMT.png" target="_blank" rel="noreferrer noopener">Wikimedia Commons</a>.</figcaption></figure>

<h2 id="h-therapeutic-research-on-5-meo-dmt"><span id="Therapeutic_Research_on_5-MeO-DMT">Therapeutic Research on 5-MeO-DMT</span></h2>
<p>In recent years, 5-MeO-DMT has garnered some attention among the scientific community. The chemical compound is particularly intriguing to those interested in psychedelic therapy. The 5-MeO-DMT experience can inspire profound experiences, but in a very short time-spanâ€”less than half an hour! By comparison, a psilocybin or LSD experience can last upward of six hours. But research on the psychoactive is only just beginning. Nevertheless, the following is a brief summary of what researchers have discovered thus far:</p>
<h3 id="h-5-meo-dmt-and-alcoholism"><span id="5-MeO-DMT_and_Alcoholism">5-MeO-DMT and Alcoholism&nbsp;</span></h3>
<p>In 2018, researchers with the Crossroads Treatment Center in Tijuana, Mexico <a href="https://www.sciencedirect.com/science/article/pii/S0079612318300931">presented a case study for the combined use of ibogaine and 5-MeO-DMT</a> in the treatment of alcoholism. In their case study, a 42-year-old man was able to remain sober for one month after treatment, returning to mild alcohol use two months after treatment. The patient did report reduced cravings and desire to drink alcohol following the treatment.&nbsp;</p>
<h3 id="h-5-meo-dmt-and-depression-and-anxiety"><span id="5-MeO-DMT_and_Depression_and_Anxiety">5-MeO-DMT and Depression and Anxiety&nbsp;</span></h3>
<p>In March of 2019, researchers from John Hopkins University<a href="https://www.hopkinsmedicine.org/news/newsroom/news-releases/fast-acting-psychedelic-associated-with-improvements-in-depressionanxiety"> surveyed 362 adults who used 5-MeO-DMT</a>. They found that 80 percent of participants reported improvements in depression and anxiety after use.&nbsp;</p>
<h3 id="h-5-meo-dmt-and-mindfulness"><span id="5-MeO-DMT_and_Mindfulness">5-MeO-DMT and Mindfulness</span></h3>
<p>In a 2019 study published in the journal <em>Psychopharmacology</em>, researchers reported that a single dose of 5-MeO-DMT <a href="https://link.springer.com/article/10.1007%2Fs00213-019-05236-w">increased feelings of mindfulness</a>, satisfaction with life, and decreased feelings of anxiety and depression. These positive effects were still noticeable four weeks after treatment. The 5-MeO-DMT was administered to 42 participants in a naturalistic and community-oriented setting.</p>
<h3 id="h-5-meo-dmt-and-neurogenesis"><span id="5-MeO-DMT_and_Neurogenesis">5-MeO-DMT and Neurogenesis&nbsp;</span></h3>
<p>In 2018, Brazilian and Sweedish researchers <a href="https://www.frontiersin.org/articles/10.3389/fnmol.2018.00312/full">teamed up to test the effects of 5-MeO-DMT</a> on neurogenesis in adult mice. <em>Neurogenesiâ€¦</em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://doubleblindmag.com/5-meo-dmt-the-story-behind-the-god-molecule/">https://doubleblindmag.com/5-meo-dmt-the-story-behind-the-god-molecule/</a></em></p>]]>
            </description>
            <link>https://doubleblindmag.com/5-meo-dmt-the-story-behind-the-god-molecule/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26188612</guid>
            <pubDate>Fri, 19 Feb 2021 02:03:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Squad: Forth on Chip-8]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26188165">thread link</a>) | @RodgerTheGreat
<br/>
February 18, 2021 | https://internet-janitor.itch.io/squad | <a href="https://web.archive.org/web/*/https://internet-janitor.itch.io/squad">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://internet-janitor.itch.io/squad</link>
            <guid isPermaLink="false">hacker-news-small-sites-26188165</guid>
            <pubDate>Fri, 19 Feb 2021 01:06:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Introduction to the Tether/Bitfinex Controversy]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26188084">thread link</a>) | @morpheos137
<br/>
February 18, 2021 | https://bennettftomlin.com/2020/12/08/an-introduction-to-the-tether-bitfinex-controversy/ | <a href="https://web.archive.org/web/*/https://bennettftomlin.com/2020/12/08/an-introduction-to-the-tether-bitfinex-controversy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Bitfinex is one of the historically largest Bitcoin exchanges and Tether is by far the largest stablecoin.  Each potentially has significant influence over the industry on their own, and their interconnectedness makes this more of a concern.  However, since both were founded years ago and many of the events have happened and been in revealed in bits and spurts it can be difficult to understand their place in the cryptocurrency environment.  This will hopefully serve as a basic introductory document that will then prompt further research.</p>



<p>Bitfinex was founded by Raphael Nicolle, a <a href="https://www.linkedin.com/in/raphaelnicolle/?locale=en_US">helpdesk</a> technician(<a href="https://bennettftomlin.files.wordpress.com/2020/12/screen-shot-2020-12-08-at-6.31.10-pm.png">best I can do for an archive is a screenshot</a>), in 2012.  It quickly grew in popularity in part due to its ability to serve as a meta-exchange where you could trade on Bitfinex, Mt. Gox, or Bitstamp from the same interface, and later their lending features.  However, even from the founding there were issues that plagued Bitfinex.  Not the least of which being that the<a href="https://news.bitcoin.com/new-details-emerge-bitfinexs-history-amid-hacking-probe/"> source code for Bitfinex was stolen from Bitcoinica</a> (<a href="https://web.archive.org/web/20201209003651/https://news.bitcoin.com/new-details-emerge-bitfinexs-history-amid-hacking-probe/">archive</a>), an earlier hacked and failed exchange created by a 17 year old.  Furthermore, the nature of the meta-exchange meant that they also frequently had large amounts of funds on other exchanges including Mt. Gox. As late as April 21st of 2013 you can see in the leaked email below that they had half of their funds on Mt. Gox.  Mt. Gox was famously hacked for three years and had approximately 650,000 Bitcoin stolen, culminating in ending withdrawals on <a href="https://www.bloomberg.com/news/articles/2014-02-07/bitcoin-price-falls-as-mt-gox-exchange-halts-activity">February 24, 2014</a> (<a href="https://web.archive.org/web/20200806060624/https://www.bloomberg.com/news/articles/2014-02-07/bitcoin-price-falls-as-mt-gox-exchange-halts-activity">archive</a>).  It is unknown if Bitfinex had funds on Mt. Gox when it became impossible to withdraw.</p>



<figure><img src="https://web.archive.org/web/20201209003651im_/https://news.bitcoin.com/wp-content/uploads/2016/09/bitfinex-gox-email.jpg" alt="bitfinex-gox-email"><figcaption><a href="https://news.bitcoin.com/new-details-emerge-bitfinexs-history-amid-hacking-probe/">https://news.bitcoin.com/new-details-emerge-bitfinexs-history-amid-hacking-probe/</a></figcaption></figure>



<p>The early history of Tether is complicated.  The precursor to Tether, RealCoin was started in <a href="https://blogs.wsj.com/moneybeat/2014/07/08/dollar-backed-digital-currency-aims-to-fix-bitcoins-volatility-dilemma/">July</a> (<a href="https://web.archive.org/web/20170928084624/https://blogs.wsj.com/moneybeat/2014/07/08/dollar-backed-digital-currency-aims-to-fix-bitcoins-volatility-dilemma/">archive</a>) of 2014 by Brock Pierce (who was <a href="https://www.latimes.com/archives/la-xpm-2002-may-18-me-den18-story.html">arrested in Spain with a fugitive child sexual offender</a> (<a href="https://web.archive.org/web/20201209010719/https://www.latimes.com/archives/la-xpm-2002-may-18-me-den18-story.html">archive</a>)[released with no charges] and was once <a href="https://www.rollingstone.com/culture/culture-features/brock-pierce-hippie-king-of-cryptocurrency-700213/">sued for child sexual abuse</a> [he was voluntarily dismissed of all charges])(<a href="https://bennettftomlin.com/2020/11/06/the-time-brock-pierce-dmed-me/">who once DMed me</a>), Reeve Collins, and Craig Sellars. It was going to be the first dollar backed stablecoin, where each token on the blockchain would represent a dollar in the bank.  This was possible thanks to a new protocol built on top of Bitcoin called Omni that allowed for these tokens to be minted easily.  On September 5th 2014 <a href="https://offshoreleaks.icij.org/nodes/82024464">Tether Holdings Limited</a> (<a href="https://web.archive.org/web/20201209011637/https://offshoreleaks.icij.org/nodes/82024464">archive</a>) was founded by Phil Potter (CSO of Bitfinex at the time) and Giancarlo Devasini (CFO of Bitfinex)[<a href="http://www1.adnkronos.com/Archivio/AdnAgenzia/1996/12/03/Cronaca/PIRATI-INFORMATICI-MICROSOFT-AL-CONTRATTACCO_130900.php">once ordered to pay 100 Million Italian Lira to Microsoft over his sale of pirated software</a>(<a href="https://web.archive.org/web/20201209023901/http://www1.adnkronos.com/Archivio/AdnAgenzia/1996/12/03/Cronaca/PIRATI-INFORMATICI-MICROSOFT-AL-CONTRATTACCO_130900.php">archive</a>)]. On <a href="https://omniexplorer.info/tx/ce36efda15bc6cf99ba6a010e71b47b00a5ea2071a392839effe7ed392cf690f">October 6th 2014</a> (<a href="https://web.archive.org/web/20201209012443/https://omniexplorer.info/tx/ce36efda15bc6cf99ba6a010e71b47b00a5ea2071a392839effe7ed392cf690f">archive</a>) [Bitcoin/Omni transaction id: ce36efda15bc6cf99ba6a010e71b47b00a5ea2071a392839effe7ed392cf690f] the very first Tether tokens were minted.  At some point during this process Tether and Bitfinex ended up having the same leadership team and the same ownership (though they would deny this fact for a while).  <strong>UPDATE: ADDITIONAL CONTEXT ON THIS CLAIM <a href="https://twitter.com/BennettTomlin/status/1362520823681187847">HERE</a></strong></p>



<p>Bitfinex was <a href="https://www.bbc.com/news/technology-37009319">first hacked in May 2015</a> (<a href="https://web.archive.org/web/20201209020249/https://www.bbc.com/news/technology-37009319">archive</a>).  It was just 1500 Bitcoins from their hot wallet and they covered it out of their corporate funds. This did little to affect the general confidence in Bitfinex and it retained its position as one of the largest exchanges.  Bitfinexâ€™s position became more complicated when in June of 2016 the CFTC ordered Bitfinex to pay a $75,000 fine for â€œ<a href="https://web.archive.org/web/20180620074228/https://www.cftc.gov/PressRoom/PressReleases/pr7380-16">offering illegal off-exchange financed retail commodity transactions in bitcoin and other cryptocurrencies</a>â€œ.  Part of the issue was that the Bitcoins were not â€œphysically deliveredâ€ from the perspective of the CFTC.  This may have been a motivating factor for Bitfinexâ€™s switchover to BitGo for their wallet security.  <a href="https://www.coindesk.com/bitfinex-bitcoin-hack-know-dont-know">BitGo would have allowed for them to segregate each userâ€™s balance</a> (<a href="https://web.archive.org/web/20201209022839/https://www.coindesk.com/bitfinex-bitcoin-hack-know-dont-know">archive</a>).  It was also supposed to provide them with significantly improved multi-signature security.  Then they were hacked again in August 2016.  This was one of the largest Bitcoin hacks of all time totally 119,756 BTC.  In response to this hack, Bitfinex gave the majority of their clients a 30.67% haircut (at least one customer was excluded, <a href="https://twitter.com/nathanielpopper/status/933130228175552513">Coinbase</a>[<a href="https://web.archive.org/web/20201209023544/https://twitter.com/nathanielpopper/status/933130228175552513">archive</a>]).  They credited each customer with a BFX token that represented $1 of the haircut.  They said they would pay back all BFX tokens eventually or would offer equity in exchange for them.  Bitfinex promised to provide a security audit and a <a href="https://www.bitfinex.com/posts/135">financial audit</a> (<a href="https://web.archive.org/web/20201209024343/https://www.bitfinex.com/posts/135">archive</a>).  They did not.  Many of these BFX tokens were converted to equity in Bitfinex, and these users became passionate advocates for Bitfinex.  Eventually all tokens were paid off or converted.</p>



<p>Tether was hacked once as well.  In November 2017, <a href="https://tether.to/tether-critical-announcement/">$30,950,010</a> (<a href="https://web.archive.org/web/20201209025631/https://tether.to/tether-critical-announcement/">archive</a>) Tethers were removed from their wallet.  In order to respond to this Tether <a href="https://twitter.com/dexx7y/status/1046999405449162752">forced</a> (<a href="https://archive.li/ow1WR">archive</a>) a hard fork of the Omni Protocol to mark those Tethers as no longer valid. Eventually Omni added a feature that allowed for transactions to be frozen by the issuer, an ability that Tether maintains to this day.</p>



<p>One of the most commonly voiced frustrations with Tether is that they have never provided a true and full financial audit to prove that they were backed. Tether for years promised that they would get an audit and have yet to follow through.  Early on in their history they did have attestations from a Taiwanese accounting firm [<a href="https://tether.to/wp-content/uploads/2017/09/Tether-Ltd-20161231.pdf">12/16</a> (<a href="https://web.archive.org/web/20180608165825/https://tether.to/wp-content/uploads/2017/09/Tether-Ltd-20161231.pdf">archive</a>), <a href="https://tether.to/wp-content/uploads/2017/09/Tether-Ltd-20170131.pdf">1/17</a> (<a href="https://web.archive.org/web/20180608165847/https://tether.to/wp-content/uploads/2017/09/Tether-Ltd-20170131.pdf">archive</a>), <a href="https://tether.to/wp-content/uploads/2017/09/Tether-Ltd-20170228.pdf">2/17</a> (<a href="https://web.archive.org/web/20201209030804/https://tether.to/wp-content/uploads/2017/09/Tether-Ltd-20170228.pdf">archive</a>), and <a href="https://tether.to/wp-content/uploads/2017/09/Tether-Ltd-20170331.pdf">3/17</a> (<a href="https://web.archive.org/web/20201209030842/https://tether.to/wp-content/uploads/2017/09/Tether-Ltd-20170331.pdf">archive</a>)].  Due to banking difficulties in Taiwan (we will get back to this) they stopped this relationship.  They then hired Friedman LLP in New York for promised <a href="https://tether.to/tether-update/">â€œcomprehensive balance sheet audits on a quarterly basis going back to Dec. 31, 2016. We will share those results with you as they become available in the coming weeks or month.â€</a> (<a href="https://web.archive.org/web/20201209031130/https://tether.to/tether-update/">Archive</a>)  This audit (like the promised Bitfinex audit) never arrived.  Tether said the following in response to this relationship ending, <a href="https://www.coindesk.com/tether-confirms-relationship-auditor-dissolved">â€œWe confirm that the relationship with Friedman is dissolved.&nbsp;&nbsp;Given the excruciatingly detailed procedures Friedman was undertaking for the relatively simple balance sheet of Tether, it became clear that an audit would be unattainable in a reasonable time frame.â€</a> (<a href="https://web.archive.org/web/20201209031423/https://www.coindesk.com/tether-confirms-relationship-auditor-dissolved">Archive</a>)  Tether did release a memo from Friedman that was explicitly <a href="https://tether.to/wp-content/uploads/2017/09/Final-Tether-Consulting-Report-9-15-17_Redacted.pdf?__cf_chl_jschl_tk__=0373e80d4605b2403e4fa9ad178b59f58332e003-1607482972-0-AXwPytlF2ASiAPHNVyFGCJ0LzggZ5e42AZzl1D1SgWRpnkY3Ax7fbGPzlbHbkcNqXlTurC1OX3n-4RAq6wIpqdl0eKH4mhd2XryfOODH6hYHAEygAyoYCFwNnw0PQdoSSGxzNDi6a1wr2IRskMsIXd6BawH5IUiokknVrvtKZtm4_BqD1b70YalyCuPuQJurkzAyjO3gbqEb3jsNVNZFXsxVfpwS969ys3dk1W4smwOqEIwiMMGtLYnf0EobcSdMD-RVj2geKymVBJP-oG3p5jgRVhwRK0Zer7itaokNKEhTheoEW3Yji_10RKZF4Qfq2Lm4AgOQsE1KjhoIif5LNU2F4-HmHG6WZqm10j2PSLFToE836a11X9Yx7AdZXyZ_4nYW5lylIJsvldUgvq3wQsMFrZ152DHaH5n6FKEjzrlH">not meant to be relied upon</a>. (<a href="https://web.archive.org/web/20201209031607/https://tether.to/wp-content/uploads/2017/09/Final-Tether-Consulting-Report-9-15-17_Redacted.pdf?__cf_chl_jschl_tk__=0373e80d4605b2403e4fa9ad178b59f58332e003-1607482972-0-AXwPytlF2ASiAPHNVyFGCJ0LzggZ5e42AZzl1D1SgWRpnkY3Ax7fbGPzlbHbkcNqXlTurC1OX3n-4RAq6wIpqdl0eKH4mhd2XryfOODH6hYHAEygAyoYCFwNnw0PQdoSSGxzNDi6a1wr2IRskMsIXd6BawH5IUiokknVrvtKZtm4_BqD1b70YalyCuPuQJurkzAyjO3gbqEb3jsNVNZFXsxVfpwS969ys3dk1W4smwOqEIwiMMGtLYnf0EobcSdMD-RVj2geKymVBJP-oG3p5jgRVhwRK0Zer7itaokNKEhTheoEW3Yji_10RKZF4Qfq2Lm4AgOQsE1KjhoIif5LNU2F4-HmHG6WZqm10j2PSLFToE836a11X9Yx7AdZXyZ_4nYW5lylIJsvldUgvq3wQsMFrZ152DHaH5n6FKEjzrlH">Archive</a>) This was for cash balances as of September 2017.  The next update (which was still not an audit) came not from an accounting firm, but from a law firm.  Tether engaged Freesh, Sporkin, and Sullivan LLP to review their bank accounts and provide a letter saying that the number of dollars in the bank was greater than the number of <a href="https://tether.to/wp-content/uploads/2018/06/FSS1JUN18-Account-Snapshot-Statement-final-15JUN18.pdf">Tethers in circulation</a> (<a href="https://web.archive.org/web/20201209032159/https://tether.to/wp-content/uploads/2018/06/FSS1JUN18-Account-Snapshot-Statement-final-15JUN18.pdf">archive</a>).  It is important to note that again this document does not seem to have been meant for public release.  Since this update there has been no more review of Tetherâ€™s backing (weâ€™ll come back to this).</p>



<p>Against this backdrop both Bitfinex and Tether struggled with their banking.  This started in April 2017 when Wells Fargo, the correspondent bank for Tether and Bitfinexâ€™s Taiwanese banks, cut off their withdrawals.  Since then Bitfinex and Tether have jumped from bank to bank.  They briefly banked at Noble Bank International an international financial entity that was founded by Brock Pierce and John Betts (an investor most noted for trying to buyout Mt Gox).  After Noble faced financial difficulties Tether landed at Deltec bank.  </p>



<p>Due to Bitfinexâ€™s difficulties in securing and maintaining banking they partnered with <a href="https://bennettftomlin.com/2020/11/07/a-list-of-companies-who-worked-with-crypto-capital/">Crypto Capital Corp</a>.  Crypto Capital Corp was run by <a href="https://www.justice.gov/usao-sdny/pr/arizona-man-and-israeli-woman-charged-connection-providing-shadow-banking-services">Reggie Fowler and Ravid Yosef</a> (<a href="https://web.archive.org/web/20201209033930/https://www.justice.gov/usao-sdny/pr/arizona-man-and-israeli-woman-charged-connection-providing-shadow-banking-services">archive</a>).  Reggie Fowler has been arrested on bank fraud charges, and Ravid Yosef is still on the run.  </p>



<p>Shortly before the news broke about the charges and arrest of Reggie Fowler the New York Attorney General revealed that they were investigating Tether and Bitfinex for <a href="https://iapps.courts.state.ny.us/fbem/DocumentDisplayServlet?documentId=vIexA1b0spKOnK_PLUS_ZUGTJ3A==&amp;system=prod">fraud</a> (<a href="https://web.archive.org/web/20201209034305/https://iapps.courts.state.ny.us/fbem/DocumentDisplayServlet?documentId=vIexA1b0spKOnK_PLUS_ZUGTJ3A%3D%3D&amp;system=prod">archive</a>).  Several shocking details were revealed in this investigation (some of which I have covered <a href="https://bennettftomlin.com/2020/02/13/analysis-of-december-nyag-and-tether-filings/">here</a>, <a href="https://bennettftomlin.com/2019/05/21/key-excerpts-and-commentary-from-nyag-tether-court-transcript/">here</a>, <a href="https://bennettftomlin.com/2020/12/06/analysis-of-the-new-york-supreme-court-remittitur-in-the-tether-and-bitfinex-new-york-attorney-general-case/">here</a>), including that Bitfinex had given $1 bn to Crypto Capital and had not even signed a contract.  When Crypto Capital stopped serving Bitfinexâ€™s withdrawal requests (which Bitfinex actively was lying about), Bitfinex exchanged $625 mn of their â€˜bookâ€™ dollars in Crypto Capital for money that Tether had in their bank account in order to service withdrawals.  This in effect made Tether insolvent.  This happened before Tether changed their promise from fully backed by cash. After this Bitfinex entered into a credit agreement with Tether wherein Tether extended a loan of up to $900mn to Bitfinex.  The loan was secured by iFinex shares which were owned by Digfinex the parent company for both Tether and Bitfinex.  The NYAG report includes the following line, â€œThe transaction documents were signed on behalf of Bitfinex and Tether by the same two individuals.  Those two individuals are also directors and owners of Digfinex, Bitfinex and Tether.â€  (See the postscript for some other things that were discovered when the NYAG released the order.)</p>



<p>When news of this effective insolvency broke, Bitfinex responded by creating a new token called <a href="https://www.bitfinex.com/wp-2019-05.pdf">UNUS SED LEO</a> (<a href="https://web.archive.org/web/20201209040248/https://www.bitfinex.com/wp-2019-05.pdf">archive</a>) or Leo from here on out.  They intended to sell 1 billion tokens, each for a dollar, in order to help close out the loan facility. (All tokens were sold but the loan facility has not been paid off.)  The token provided some discounts on Bitfinexâ€™s platform to itâ€™s holder.  However, most of its potential value derviced from the other promises they made including that they would buy back an amount of LEO equal to 27% of their (unaudited) revenue each month, or their promise to use 95% of the net recovered funds from Crypto Capital to buy and burn LEO.  </p>



<p>Since then Tetherâ€™s size has absolutely exploded with it growing to nearly $20,000,000,000.  Bitfinex and Tether are still under investigation by the NYAG, but have had their appeal rejected and they will be moving to <a href="https://bennettftomlin.com/2020/12/06/analysis-of-the-new-york-supreme-court-remittitur-in-the-tether-and-bitfinex-new-york-attorney-general-case/">trial soon</a>.</p>



<p>This is far from an exhaustive look at Tether (Iâ€™m working on a book with <a href="https://twitter.com/CasPiancey">CasPiancey</a> for that), but hopefully you have a better understanding of the â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bennettftomlin.com/2020/12/08/an-introduction-to-the-tether-bitfinex-controversy/">https://bennettftomlin.com/2020/12/08/an-introduction-to-the-tether-bitfinex-controversy/</a></em></p>]]>
            </description>
            <link>https://bennettftomlin.com/2020/12/08/an-introduction-to-the-tether-bitfinex-controversy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26188084</guid>
            <pubDate>Fri, 19 Feb 2021 00:55:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Facebook Calls Australia's Bluff]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26187669">thread link</a>) | @1cvmask
<br/>
February 18, 2021 | https://www.platformer.news/p/facebook-calls-australias-bluff | <a href="https://web.archive.org/web/*/https://www.platformer.news/p/facebook-calls-australias-bluff">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.platformer.news/p/facebook-calls-australias-bluff</link>
            <guid isPermaLink="false">hacker-news-small-sites-26187669</guid>
            <pubDate>Fri, 19 Feb 2021 00:07:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Florida outperformed lockdown states on excess deaths, education, and economy]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 4 (<a href="https://news.ycombinator.com/item?id=26187395">thread link</a>) | @Pausanias
<br/>
February 18, 2021 | https://rationalground.com/floridas-covid-19-response-has-outperformed-lockdown-states-on-excess-deaths-education-and-the-economy/ | <a href="https://web.archive.org/web/*/https://rationalground.com/floridas-covid-19-response-has-outperformed-lockdown-states-on-excess-deaths-education-and-the-economy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://rationalground.com/floridas-covid-19-response-has-outperformed-lockdown-states-on-excess-deaths-education-and-the-economy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26187395</guid>
            <pubDate>Thu, 18 Feb 2021 23:38:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to know if you're interviewing at a product-led company]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26187334">thread link</a>) | @skotzko
<br/>
February 18, 2021 | https://andrewskotzko.com/how-to-know-if-youre-interviewing-at-a-product-led-company/ | <a href="https://web.archive.org/web/*/https://andrewskotzko.com/how-to-know-if-youre-interviewing-at-a-product-led-company/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><main id="genesis-content"><article aria-label="How to know if youâ€™re interviewing at a product-led company"><div><div><figure><img loading="lazy" width="732" height="307" src="https://andrewskotzko.com/wp-content/uploads/2021/02/TN9ww6_OmxtkBn4j3aKpJw7c2cQZJsdZSEt6FlMAgqTBTD_i2Z4gzRmNvW42Jx1CFbIreJIpDTB4i2QR_bH5JGIoxZH5EIkH3kTji7t8uMhgBO61qtJ84EHpab-QgVWt53Y2hF2_.png" alt="" srcset="https://andrewskotzko.com/wp-content/uploads/2021/02/TN9ww6_OmxtkBn4j3aKpJw7c2cQZJsdZSEt6FlMAgqTBTD_i2Z4gzRmNvW42Jx1CFbIreJIpDTB4i2QR_bH5JGIoxZH5EIkH3kTji7t8uMhgBO61qtJ84EHpab-QgVWt53Y2hF2_.png 732w, https://andrewskotzko.com/wp-content/uploads/2021/02/TN9ww6_OmxtkBn4j3aKpJw7c2cQZJsdZSEt6FlMAgqTBTD_i2Z4gzRmNvW42Jx1CFbIreJIpDTB4i2QR_bH5JGIoxZH5EIkH3kTji7t8uMhgBO61qtJ84EHpab-QgVWt53Y2hF2_-300x126.png 300w" sizes="(max-width: 732px) 100vw, 732px"></figure></div><p>Iâ€™m seeing this sentiment pop up with alarming frequency. Many product people are dealing with career uncertainty â€” and not just the â€œwill my company make it through the pandemic?â€ variety. Without the usual distractions of life available, things that were easily overlooked are now front and center.</p><p>And what are many of these product people realizing without the distractions of normal life?</p><p><strong>Theyâ€™re set up to fail.</strong></p><p>Their work environment and culture is not set up to create strong products. It is distinctly <em>not</em> set up to empower the collaboration of product, design, and engineering to build things that matter.</p><p>This has led many to realize itâ€™s time for a job change.</p><p>As product people, we want to work in a product-led company. A place that truly values the craft and contribution of product, and that empowers individuals and teams to work to their highest potential. A place that is built around creating amazing products that truly make life better for the people theyâ€™re trying to serve.</p><p>We all know itâ€™s possible. Itâ€™s what the best product companies are doing. Yet despite many attempts tried, there are many frustrated PMs that canâ€™t seem to get their work environment to change.</p><p>This is because, frankly, they joined the wrong company in the first place.</p><p>They took a role where good product work occurs in spite of the dominant practices and culture, not because of them.</p><p>Jobs like this waste precious years of your career. Iâ€™ve made this mistake too, and it hurts. I hope this article helps you avoid it in the future.</p><p>Itâ€™s actually really hard to know how strong of a product culture and environment that a team has prior to living in it. Even within the FAANG companies, every team and manager is different and you need to find out the truth.</p><p>After reading this, you should have a go-to set of questions to ask the next companies you interview. These will help you suss out the reality of how the company operates before you commit to an offer. Iâ€™m writing this for product managers, but itâ€™s equally relevant to design and engineering.</p><p>So, what <em>can</em> you do to make sure that your next company is <em>actually</em> a good place to be a product person?</p><p>The key to solving this is to <em>interview companies the same way we interview users and customers</em>.</p><p>Think of this as â€œThe Mom Test,â€ applied to product job interviews.</p><h2 id="interviewing-companies-like-users-customers">Interviewing companies like users/customers<a href="#interviewing-companies-like-users-customers"></a></h2><h3 id="why-you-need-to-do-this">Why you need to do this<a href="#why-you-need-to-do-this"></a></h3><p>One of the most common complaints in the job search process is â€œthis place isnâ€™t what I thought it would be.â€</p><p>People join a company full of vigor and excitement, and within a few months they are bored, going through the motions, and fantasizing yet again about being somewhere that â€œgets product.â€</p><p>It doesnâ€™t have to be this way.</p><div><figure><img loading="lazy" src="https://andrewskotzko.com/wp-content/uploads/2021/02/t3pawlU7qxNyGBkCZMWQLQxfOUct30uDWgZqusxwAHau6pIJ6hAh530ETyv3vLRSapIHNHHSBevu-zemY4za4V5cY7ONyvP97DtHfMILgezcPqd8eOngk1mPY7nD9smhqwVqNA64.jpg" alt="" width="480" height="308" srcset="https://andrewskotzko.com/wp-content/uploads/2021/02/t3pawlU7qxNyGBkCZMWQLQxfOUct30uDWgZqusxwAHau6pIJ6hAh530ETyv3vLRSapIHNHHSBevu-zemY4za4V5cY7ONyvP97DtHfMILgezcPqd8eOngk1mPY7nD9smhqwVqNA64.jpg 640w, https://andrewskotzko.com/wp-content/uploads/2021/02/t3pawlU7qxNyGBkCZMWQLQxfOUct30uDWgZqusxwAHau6pIJ6hAh530ETyv3vLRSapIHNHHSBevu-zemY4za4V5cY7ONyvP97DtHfMILgezcPqd8eOngk1mPY7nD9smhqwVqNA64-300x192.jpg 300w" sizes="(max-width: 480px) 100vw, 480px"></figure></div><p>As PMs, we invest so much getting ready for those damn product interviews that we often forget: <strong>we need to interview the company just as hard as theyâ€™re interviewing us.</strong></p><p>This is called â€œreverse interviewing.â€ As product people, we already know how to do this.</p><p>We know how to interview customers and users. We know to ask questions to account for bias and speculation, surface actual behavior, and understand how decisions are really made.</p><p>When applying for a job, we need to apply those same skills to interview our interviewers.</p><p>As Marty Cagan said to me in <a href="https://pod.fo/e/af7e6">our podcast conversation</a>:</p><blockquote><p><em>From your point of view, your job is to learn as much as possible about how that company really works, and especially how that manager would be like to work for.</em></p></blockquote><p>Letâ€™s see how to do just that.</p><h3 id="principles-for-interviewing">Principles for interviewing<a href="#principles-for-interviewing"></a></h3><p>Two excellent resources on interviewing usersâ€”which you really should read if you havenâ€™tâ€”are <a href="https://www.producttalk.org/2016/03/customer-interview-questions/">this post by Teresa Torres</a> and <a href="https://amzn.to/2MXuN2D">The Mom Test</a>.</p><p>I distill their points into these two overarching principles for interviewing:</p><ol><li>Separate your research questions and interview questions</li><li>Ask questions that uncover actual past behavior, rather than speculative or aspirational future behavior</li></ol><h3 id="separate-research-questions-from-interview-questions">Separate research questions from interview questions<a href="#separate-research-questions-from-interview-questions"></a></h3><p>The user research community has learned that we often canâ€™t directly ask our questions and get reliable answers.</p><p>The way around this is to map our research questions to interview questions.</p><p>Research questions are what we really want to know. Interview questions are what we actually ask to get the interviewee telling stories that show their behavior. (This is a concept I learned from Teresa Torres in her <a href="https://learn.producttalk.org/p/continuous-interviewing">excellent interviewing course</a>.)</p><p>For example, imagine you work at Spotify and your team is assigned to work on reducing the churn rate.</p><p>Letâ€™s say youâ€™ve learned that users who play a given playlist consistently at the start of their workday are retained ~20% longer than those who donâ€™t. Your research questions might be:</p><ul><li>Why are people using the same playlist every day?</li><li>What are people looking for in such a playlist? How do they choose playlists?</li><li>When, where, and how do people find these playlists?</li><li>What is unique about playlists that have high retention rates?</li><li>Are users more likely to exhibit the desired behavior with a playlist they follow, or one they create?</li></ul><p>Some interview questions to get stories containing this information could be:</p><ul><li>Tell me about your morning playlist? How did you first find it?</li><li>Walk me through your day. Start with the moment you woke up.</li><li>Tell me about how you start your workday</li><li>Tell me about the last playlist you discovered that you really liked</li><li>Tell me about the last playlist you made yourself</li></ul><p>Each of these prompts a story about actual behavior, and we can then ask more questions to go deeper. A well-extracted story can often answer multiple research questions at once.</p><p>Now letâ€™s talk about how to apply this to finding a great product environment to work in.</p><h3 id="the-droids-were-looking-for">The droids weâ€™re looking for <a href="#the-droids-were-looking-for"></a></h3><p>What weâ€™re seeking in our job search: empowered product teams.</p><p>Empowered product teamsâ€”as opposed to delivery or feature teamsâ€”only exist in environments with strong product leadership.</p><p>Empowered product teams:</p><ol id="block-31aad864-d497-461b-8f72-65138efd7926"><li>are small, cross-functional, and durable</li><li>address product risks early with collaborative product discovery, and regularly â€œkill their darlingsâ€ en route to ideas that work</li><li>are accountable to delivering results rather than output</li></ol><p>These teams exist in product orgs with an environment that has:</p><ol id="block-31aad864-d497-461b-8f72-65138efd7926"><li>a focused and insight-rich product strategy</li><li>regular, ongoing cadence of lightweight research directly with their user/customer, rather than handing this off to a research group</li><li>people connected to the product vision in a visceral, energetic way</li><li>managers that are proactively and regularly coaching and developing team members</li><li>an equal partnership with the rest of the business</li></ol><p>Teams like this are great places to be a product person. These are where magical career experiences and products come from. And they are made up of ordinary, hard-working, sincere people just like you.</p><p>(To go deep on the idea of empowered teams, read Marty Caganâ€™s latest book, <a href="https://amzn.to/3cFAo8G">EMPOWERED</a>, and listen to the <a href="https://pod.fo/e/af7e6">deep dive conversation I had with him about the ideas in the book</a>.)</p><p>Our research question is: â€œis this a place that empowers product people/teams?â€</p><p>Now that we know what weâ€™re looking for, how do we assess a given job opportunity?</p><p>This is where our interview questions come in.</p><h2 id="reverse-interview-questions">Reverse interview questions<a href="#reverse-interview-questions"></a></h2><p>Since every company we talk to will <em>say</em> theyâ€™re a good product company, we need to dig deeper. Just as with users, we canâ€™t take them at their word. We need evidence from real behavior.</p><p>Based on my own career, research, listener questions and podcast interviews with product people, here are my top reverse interview questions (click to jump to the section for the given question):</p><ol><li><a href="#1-what-were-the-last-few-things-your-team-has-built-and-shipped-and-how-did-you-decide-to-do-those">What were the last few things your team has built and shipped, and how did you decide to do those?</a></li><li><a href="#2-whens-the-last-time-you-talked-with-your-customers-users-how-often-have-you-done-that-in-the-last-month">Whenâ€™s the last time you talked with your customers? How often have you done that in the last month?</a></li><li><a href="#3-what-was-the-last-feature-or-product-your-team-killed">What was the last feature or product your team killed?</a></li><li><a href="#4-can-you-describe-your-product-vision">Can you describe your product vision?</a></li><li><a href="#5-tell-me-about-the-last-coaching-session-you-had-with-your-manager-how-often-did-that-happen-last-month">Tell me about the last coaching session you had with your manager. How often did that happen last month?</a></li></ol><p>Letâ€™s discuss the rationale for each of these, and what you want to hear/avoid.</p><h3 id="1-what-were-the-last-few-things-your-team-has-built-and-shipped-and-how-did-you-decide-to-do-those">1) What were the last few things your team has built and shipped, and how did you decide to do those?<a href="#1-what-were-the-last-few-things-your-team-has-built-and-shipped-and-how-did-you-decide-to-do-those"></a></h3><h4 id="why-youre-asking">Why youâ€™re asking<a href="#why-youre-asking"></a></h4><p>We need to understand the core of how work happens here. How is work assigned? Who decides what gets built, and how?</p><p>This is the biggest indicator of whether this team is empowered. This is the motherlode. Plan to dig deep into this one. Pull every thread and see where it takes you.</p><h4 id="what-youre-looking-for">What youâ€™re looking for<a href="#what-youre-looking-for"></a></h4><p>We want to see that leadership has assigned the team clear objectives â€” customer or business problems to solve â€” and empowered the team to come up with solutions to those problems. Weâ€™re looking to see that leadership has pointed the team in the right direction, and empowered them to figure it out.</p><p>We want to hear things like â€œwell, our goal this quarter is to increase the average 4-week retention for a new user cohort from 33% to at least 40%. We interview users every week and dug into this pattern from last quarterâ€™s data. The PM/designer/tech lead ran a fast series of prototypes/experiments to figure out what worked with users, and to make sure our stakeholders could support it. After we had enough confidence that it was the right thing to build, we put it on the backlog and built it out for production.â€</p><p>Whatâ€™s wrapped up in that statement? Tons of goodness:</p><ul><li>A clear goal, with metrics, that the whole team is focused on</li><li>A regular cadence of user/customer contact</li><li>Insights that inform the product strategy and shape the objectives the teams pursue</li><li>Rapid, iterative, and collaborative prototyping and continuous discovery practices</li><li>Addressing the <a href="https://svpg.com/four-big-risks/">four big risks</a> early on in discovery, before building for production</li><li>A collaborative, rather than subservient, relationship with stakeholdersâ€”we hear that the product team exists to delight the customer, in a way that works for the business</li></ul><p>Weâ€™d also love to dig into the tradeoffs and tough calls that were made in that process. This is a place weâ€™d love to hear the product vision and principles shaping the daily product decisions that the â€¦</p></div></article></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://andrewskotzko.com/how-to-know-if-youre-interviewing-at-a-product-led-company/">https://andrewskotzko.com/how-to-know-if-youre-interviewing-at-a-product-led-company/</a></em></p>]]>
            </description>
            <link>https://andrewskotzko.com/how-to-know-if-youre-interviewing-at-a-product-led-company/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26187334</guid>
            <pubDate>Thu, 18 Feb 2021 23:31:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generating realistic user timestamps in SQL]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26187291">thread link</a>) | @cedricd
<br/>
February 18, 2021 | https://blog.narrator.ai/generating-random-timestamps-in-sql/ | <a href="https://web.archive.org/web/*/https://blog.narrator.ai/generating-random-timestamps-in-sql/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p><em>Photo by <a href="https://unsplash.com/@loic?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Djim Loic</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></em></p><p>This is the second in a three part series showing how we generate interesting fake data to demo Narrator. <a href="https://blog.narrator.ai/how-to-generate-a-series-of-numbers-in-redshift/">Part 1</a> described how to create a numbers table.</p><p>Generating time series data can extremely useful for testing, debugging, and demoing. For example, whenever we demo Narrator's data platform we show generated data from a fake company. The data is all generated by creating user events at specific (randomish) times. Creating realistic timestamps is at the core of this process.</p><p>Unfortunately, creating realistic synthetic timestamps in SQL is pretty unintuitive. Postgres has a neat <code><a href="https://dataschool.com/learn-sql/generate-series/">generate_series()</a></code> function that can create timestamps, but it'll create them evenly (which is <a href="https://popsql.com/learn-sql/postgresql/how-to-use-generate-series-to-avoid-gaps-in-data-in-postgresql">quite useful</a>, but not what we want).</p><p>Here we'll show how we create timestamps that follow reasonable usage patterns. We'll start with a simple case and build it up bit by bit.</p><blockquote>The code below will all be for Redshift. It should be straightforward to convert to any other warehouse.</blockquote><p>The basic process is to pick a target start and end date, the number of timestamps needed, and use a numbers table to select the right number of rows. From there a little math will create timestamps in that interval with the properties we want.</p><h2 id="random-timestamps">Random Timestamps</h2><p>The first step is to create timestamps evenly spread throughout our time interval.</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>The code above is not too bad. It creates timestamps on a per-minute basis. The timestamps are is random so there's no truly obvious pattern.</p><figure><img src="https://blog.narrator.ai/content/images/2021/02/image.png" alt="" srcset="https://blog.narrator.ai/content/images/size/w600/2021/02/image.png 600w, https://blog.narrator.ai/content/images/size/w1000/2021/02/image.png 1000w, https://blog.narrator.ai/content/images/2021/02/image.png 1596w" sizes="(min-width: 720px) 720px"></figure><p>Well, there is one obvious pattern â€“ the slope is perfectly straight. That's not super realistic. Let's try modeling usage increasing over time.</p><h2 id="increasing-timestamps">Increasing Timestamps</h2><p>Let's assume our timestamps represent user activity â€“ say website sessions. Over time this usage is going to increase, so we should have our synthetic timestamps follow that. </p><p>An <a href="https://en.wikipedia.org/wiki/Exponential_growth">exponential</a> function is a great one to follow, since it measures compounding growth. It's generally of the form </p><figure><img src="https://www.gstatic.com/education/formulas2/355397047/en/exponential_growth_formula.svg" alt="f(x)=a(1+r)^{x}"></figure><!--kg-card-begin: markdown--><p>We'll use the form f(x) = r<sup>x</sup> for simplicity's sake. For example, 2<sup>x</sup> looks like this:</p>
<!--kg-card-end: markdown--><figure><img src="https://blog.narrator.ai/content/images/2021/02/image-2.png" alt="" srcset="https://blog.narrator.ai/content/images/size/w600/2021/02/image-2.png 600w, https://blog.narrator.ai/content/images/size/w1000/2021/02/image-2.png 1000w, https://blog.narrator.ai/content/images/2021/02/image-2.png 1354w" sizes="(min-width: 720px) 720px"><figcaption>exponential function with base 2</figcaption></figure><p>This models the hockey-stick growth all startups want to see and is actually a fairly good representation of actual user growth. </p><p>So the problem is how to generate timestamps that follow a function. The code to do this isn't too crazy:</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>Which looks like this:</p><figure><img src="https://blog.narrator.ai/content/images/2021/02/image-3.png" alt="" srcset="https://blog.narrator.ai/content/images/size/w600/2021/02/image-3.png 600w, https://blog.narrator.ai/content/images/size/w1000/2021/02/image-3.png 1000w, https://blog.narrator.ai/content/images/2021/02/image-3.png 1554w" sizes="(min-width: 720px) 720px"></figure><p>So what's going on?</p><!--kg-card-begin: markdown--><p>First we're using the function 2<sup>x</sup> - 1 to generate a y value between 0 and 1 for x between 0 and 1. This simplifies things a lot. We'll deal with values not between 0 and 2 in the next section</p>
<!--kg-card-end: markdown--><p>So we have <code>random() as x</code> and <code>2^x - 1 as y</code> </p><p>The main difference from before is that we'll use <code>y</code> instead of <code>x</code> to create the actual timestamp value. </p><p>We also offset y from the end of the time period instead of the beginning. This is because for early dates the values of y are more similar to each other (the flatter part of the curve). That means in a given time span (say a day) there are more of them, making the curve trend down. Negating y this way basically mirrors the graph around the y axis and solves that issue.</p><h2 id="adjusting-the-output">Adjusting the Output</h2><p>That looks nice, but what if we want to more carefully control the function we're using? For example, let's make the graph much steeper. To do this we just have to change the function. </p><!--kg-card-begin: markdown--><p>For an exponential function we'll get a steeper curve if we give the growth rate a higher number: going from f(x) = 2<sup>x</sup> to say f(x) = 5<sup>x</sup>. Pretty straightforward.</p>
<!--kg-card-end: markdown--><figure><img src="https://blog.narrator.ai/content/images/2021/02/image-4.png" alt="" srcset="https://blog.narrator.ai/content/images/size/w600/2021/02/image-4.png 600w, https://blog.narrator.ai/content/images/size/w1000/2021/02/image-4.png 1000w, https://blog.narrator.ai/content/images/2021/02/image-4.png 1302w" sizes="(min-width: 720px) 720px"><figcaption>Plot of 2<sup>x</sup> (red) and 5<sup>x</sup> (blue)</figcaption></figure><p>In the last section we crafted our function so that for all values of <code>x</code> from 0..1 <code>y</code> is also between 0..1. That simplification won't be possible this time, so we'll have an additional step where we scale <code>y</code> back down. </p><p>Here it is</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>The code is nearly the same. We just have to do a simple linear interpolation of <code>y</code> to get it between 0 and 1. </p><p>It's fairly easy to see the graph is now steeper, and that there are fewer timestamps earlier, and more timestamps later, than before.</p><figure><img src="https://blog.narrator.ai/content/images/2021/02/image-7.png" alt="" srcset="https://blog.narrator.ai/content/images/size/w600/2021/02/image-7.png 600w, https://blog.narrator.ai/content/images/size/w1000/2021/02/image-7.png 1000w, https://blog.narrator.ai/content/images/2021/02/image-7.png 1502w" sizes="(min-width: 720px) 720px"></figure><h2 id="incremental-creation"><br>Incremental Creation</h2><p>This is great at creating a whole set of timestamps, but what if you want to create them a bit at a time? We do this with our demo account â€“ every day we add new user events based on these timestamps to make the demo look like it's live and up to date.</p><p>In the examples above we generated timestamps between some time in the past and now. This won't work for incremental generation, since subsequent days won't line up. Picking 24 hours ago and now as the two endpoints will give a discontinuity as each new day effectively starts the curve over.</p><p>The simplest way to have one overarching curve across multiple runs is to fix both the start and end dates. In other words, pick a future date for the end and stick to it (say 5 years in the future). From there simply filter on timestamp in the select query to generate the date range you need</p><pre><code>select
    date_trunc('day', ts)::date AS day,
    count(1) as total_timestamps
from quickly_increasing_timestamps
where ts &gt; '2021-02-02'::timestamp and ts &lt; 2021-02-03'::timestamp
group by day
order by day asc</code></pre><h2 id="wrapping-up">Wrapping Up</h2><p>There it is. A nice set of auto-generated timestamps that follow any curve we'd like. In a future post we'll dive into how we use these synthetic timestamps to build out an entire set of realistic customer behaviors. </p>
                </div>
            </section></div>]]>
            </description>
            <link>https://blog.narrator.ai/generating-random-timestamps-in-sql/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26187291</guid>
            <pubDate>Thu, 18 Feb 2021 23:26:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Some Background (On CheapETH)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26187156">thread link</a>) | @lumpa
<br/>
February 18, 2021 | https://www.deveth.org/background.html | <a href="https://web.archive.org/web/*/https://www.deveth.org/background.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

  <nav>
    <div>
      <p><a href="https://www.deveth.org/"><img src="https://www.deveth.org/logo.png" alt="deveth.org" width="110"></a>
      </p>
    </div>
  </nav>

  <main>
    

    <p>In February 2021, George Hotz (geohot) et al. <a href="https://github.com/cheapETH/go-ethereum/tree/cheapeth">forked the Ethereum chain</a> to form <a rel="nofollow" href="https://cheapeth.org/">cheapETH</a>. A project intended to provide a stable, affordable
      testnet for the
      Ethereum ecosystem, with cross-chain communication functionality. The founders of the devETH project participated
      in this community, spending time and resources building infrastructure surrounding the project.</p>
    <p>Unfortunately, days after the project was started, a member of the cheapETH community discovered and pointed out
      <a href="https://github.com/cheapETH/go-ethereum/commit/412c38434d8d88840452c090e738a672139a73d4#diff-67b4f96b9bd587cc5f508f38eb63f372fa31f339bf66fedcb188f78774318201R88">patch</a>
      in the cheapETH fork of go-ethereum, that grants 25,000,000 cheapETH tokens to the developers associated with the
      project. According to the <a href="https://github.com/cheapETH/cheapeth-website/blob/442027739ee61444c711346c7e3b2a06aecd94aa/index.html#L93">cheapETH
        website</a>, that would theoretically amount to 25,000 Ethereum as per the pegged 1/1000 ratio described by the
      cheapETH developers. This single transaction has <b>theoretical</b> market value of $46 million USD at the time of
      writing. (Feb 18th)
    </p>
    <p>Following this revelation on the cheapETH Discord server, a number of community members expressed their concern
      regarding this seemingly gratuitous developer fund, and the details surrounding its implementation. Instead of
      addressing these issues, the cheapETH staff appointed in the Discord community resorted to deleting messages and
      banning members of the community who were posing unwanted questions about the financial motivations of the
      cheapETH project.</p>
    <p>The devETH project authors do not intend to make any assumptions/accusations as to the financial
      dealings/motivations of the cheapETH developers - They are free to do whatever they wish with their project.
      However, prompted by the drastic response in the Discord community, and a suggestion by <a href="https://github.com/cheapETH/go-ethereum/pull/2#issuecomment-779544030">George Hotz</a>, a group of
      cheapETH community members decided to launch the devETH project as a direct fork of the cheapETH project.</p>
    <p>We intend to continue innovating on the vision of the cheapETH project, and wish all the best to the cheapETH
      team on their endeavour.</p>
    <p>The devETH team invites anyone interested in our take on the cheapETH vision to participate in our <a href="https://discord.gg/xFmCcaEjPK">Discord server</a>.</p>
    <p>- The devETH team</p>

  </main>

  
  


</div>]]>
            </description>
            <link>https://www.deveth.org/background.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26187156</guid>
            <pubDate>Thu, 18 Feb 2021 23:12:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Consulting Business Model]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26187118">thread link</a>) | @shoo
<br/>
February 18, 2021 | https://commoncog.com/blog/the-consulting-business-model/ | <a href="https://web.archive.org/web/*/https://commoncog.com/blog/the-consulting-business-model/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <section>
        <p>In Singapore, and Malaysia, and India, and Vietnam, if youâ€™re a young software engineer fresh out of college, you have effectively three choices for a first job:</p><ul><li>You can go work for a product company, one where the tech is the focus. This is most likely a startup. (Unlike in Silicon Valley, there are rather limited opportunities for established tech companies in these countries).</li><li>You can go work in the IT department of some non-tech company, like Bosch, or Citibank, or AIA.</li><li>Or you can go work for an outsourcing / professional service firm.</li></ul><p>That last option is a really big one. A large portion of tech company jobs I know in Vietnam, Singapore and Malaysia come from some consulting firm. Those firms exist on a spectrum. At the bottom are the pure outsourcing companies â€” the ones that treat its employees like so much gristle to be fed to a meat grinder. At the top are the premier consulting companies â€” the <a href="https://pivotal.io/labs">Pivotals</a> and the <a href="https://eastagile.com/">East Agiles</a> of their respective markets. And there are, of course, a plethora of consulting firms in between; I know more than a dozen friends who have elected to start consulting firms. I even ran one for a year.</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>All of this is to say that Iâ€™m just really, really interested in the business of consulting. And I think I should be: in Asia, software consulting continues to make up a large proportion of tech jobs. You simply canâ€™t ignore them if you work in the industry.</p><p>(The same goes for accounting and law and media, financial advisories and estate planning and ad agencies, real estate brokers and PR firms and investment banks. There are whole industries where the primary employer is a professional service firm).</p><p>Professional service firms are interesting businesses. They don't own assets. They own labour. They don't manufacture things (for the most part). They charge a multiple of their peopleâ€™s time costs. As a result, they have <em>very</em> different takes on profitability, company growth, and employee retention. If you want to work for one, you damn well better know how they work.</p><!--kg-card-begin: markdown--><!--kg-card-end: markdown--><p>I was faffing around on Goodreads three weeks ago when I stumbled upon David Maisterâ€™s <em>Managing the Professional Service Firm</em>. Maister was a former Harvard Business School professor and consultant; <em>Managing the Professional Service Firm</em> was written as a series of articles over the course of the 80s â€” the majority of which were published in <em>American Lawyer</em>.</p><p>Maisterâ€™s book is incredible. The first two chapters lay out the underlying principles of a professional service business. The rest of the book examines the second and third-order implications of those principles â€” and form the basis of a highly effective agency management style.</p><p>I want to summarise the first two chapters of Maisterâ€™s book here. I <em>canâ€™t</em> do more than that; Maisterâ€™s book is a <a href="https://commoncog.com/blog/the-3-kinds-of-non-fiction-book/#treebooks">ğŸŒ³ tree book</a>, which makes it impossible to summarise. But I think the core principles are worth writing about â€” if youâ€™re considering a job in a professional service firm, youâ€™ll probably find these two chapters the most useful.</p><h2 id="maisters-s-core-thesis">Maistersâ€™s Core Thesis</h2><p>Maisterâ€™s core thesis is this:</p><p>Professional service firms must be managed differently from industrial and mass-consumer businesses. This is due to two reasons. First, professional service firms perform highly customised work. This makes the application of product management (or manufacturing) principles a bad fit for them.</p><p>Second, professional service firms require a healthy component of face-to-face client interaction. The top performers must have special client-facing skills, which in turn places a heavy burden on the firm to recruit and train the best people in your field <em>with</em> such client-management skills (if youâ€™re familiar with Joe Average Programmer, you should know that this is a lot harder than it sounds). In turn, this forces the professional firm to actively compete in two markets: the â€˜inputâ€™ market for talent, and the â€˜outputâ€™ market for its services.</p><p>Maister writes:</p><blockquote>â€¦ while it is clear that the management problems of professional firms are sufficiently different from industrial or mass-consumer businesses to require their own â€œmanagement theoryâ€; it is also clear that, in spite of many differences, businesses within the professional service sector face very similar issues, regardless of the specific profession they are in. When I began my work, I treated these propositions as hypotheses. Ten years, many professions, and countless firms later, I take them as confirmed facts.</blockquote><p><em>My</em> thesis is that an understanding of underlying business models leads to better career decisions. So. What does that â€˜management theoryâ€™ consist of?</p><h3 id="all-professional-service-firms-have-the-same-mission">All Professional Service Firms Have The Same Mission</h3><p>The first is Maisterâ€™s observation that <em>all</em> professional services firms seem to have the exact same mission:</p><blockquote>â€œTo deliver outstanding client service; to provide fulfilling careers and professional satisfaction for our people; and to achieve financial success so that we can reward ourselves and grow.â€</blockquote><p>It doesnâ€™t matter if the firm is large or small, if itâ€™s located in America or Japan, or if itâ€™s investment banking or law. The words of the mission may differ but the meaning is essentially same.</p><figure><img src="https://commoncog.com/blog/content/images/2019/08/Paper.Commonplace.48.png" alt=""><figcaption>The three universal goals of every professional service firm.</figcaption></figure><p>Itâ€™s no coincidence that these three goals are so universal to professional service firms. As it turns out, such firms <em>must</em> balance between the demands of the client marketplace, the realities of the talent marketplace, and the firmâ€™s economic ambitions if they are to survive.</p><p>What this means, exactly, will become clear in a minute.</p><h3 id="the-most-important-managing-decision-is-the-firm-s-leverage">The Most Important Managing Decision is the Firmâ€™s Leverage</h3><p>When in pursuit of the three goals, the <strong>most important factor</strong> the firm must manage is its ratio of junior, mid-level, and senior staff members in the firmâ€™s organisation. Maister calls this ratio the â€˜leverageâ€™ of the firm.</p><p>The archetypical professional service firm consist of three levels. Theyâ€™re often called â€˜grindersâ€™, â€˜mindersâ€™, and â€˜findersâ€™. This is true for law firms (associate, junior partner, senior partner), management consultancies (junior consultant, manager, vice president), investment bankers (analyst, associate, vice president, director â€” though analysts don't really count) and so on.</p><p>The ratio of junior, mid-level, and senior staff members make up the â€˜shapeâ€™ of the firm â€” and the shape of the firm <em>should</em> be determined by the skill requirements of the work it does.</p><p>Maister points out that there are three â€˜typesâ€™ of client work (in reality, as with most things, these points exist on a spectrum). The client work is determined by the market, but the <em>mix</em> of project types is up to the firm.</p><p>Iâ€™ve mentioned this in my <a href="https://commoncog.com/blog/you-cant-ignore-business-models-in-your-career/#the-joys-and-limitations-of-working-for-a-consultancy">previous post on business models</a>, but here it is again:</p><ol><li><strong>Brain projects.</strong> â€œIn the first type (Brains), the clientâ€™s problem is at the forefront of professional or technical knowledge, or at least is of extreme complexity. The key elements of this type of professional service are creativity, innovation, and the pioneering of new approaches, concepts or techniques: in effect, new solutions to new problems. The firm that targets this market will be attempting to sell its services on the basis of the high professional craft of its staff. In essence, their appeal to their market is, â€œHire us because weâ€™re smart.â€</li><li><strong>Grey Hair projects.</strong> â€œGrey Hair projects, while they may require a highly customized â€œoutputâ€ in meeting the clientsâ€™ needs, involve a lesser degree of innovation and creativity in the actual performance of the work than would a Brains project. The general nature of the problem to be addressed is not unfamiliar, and the activities necessary to complete the project may be similar to those performed on other projects. Clients with Grey Hair problems seek out firms with experience in their particular type of problem. In turn, the firm sells its knowledge, its experience, and its judgment. In effect, they are saying, â€œHire us because we have been through this before; we have practice at solving this type of problem.â€</li><li><strong>Procedure projects.</strong> â€œThe third type of project, the Procedure project, usually involves a well-recognized and familiar type of problem. While there is still a need to customize to some degree, the steps necessary to accomplish this are somewhat programmatic. The client may have the ability and resources to perform the work itself, but turns to the professional firm because the firm can perform the service more efficiently, because the firm is an outsider, or because the clientâ€™s own staff capabilities to perform the activity are somewhat constrained and are better used elsewhere. In essence, the professional firm is selling its procedures, its efficiency, its availability: â€œHire us because we know how to do this and can deliver it effectively.â€</li></ol><p>The labour demands for each project are ordered in descending fashion: â€˜Brainâ€™ projects require experienced, senior staff, as nearly everything is custom-made for the client. â€˜Grey Hairâ€™ projects address problems that are more familiar, and thus provide some opportunity for delegation. â€˜Procedureâ€™ projects involve the highest proportion of junior time relative to senior time, and thus demand a completely different shape for firms that specialise in such projects.</p><p>The mix of projects that the firm undertakes is hugely influential on <em>many</em> aspects of the firmâ€™s operations. Maister writes:</p><!--kg-card-begin: markdown--><blockquote>
<p>Consider what will happen if a firm brings in a mix of client work such that its â€œproperâ€ staffing requirements would be for a slightly higher mix of juniors, and a lesser mix of seniors than it has (i.e., the work is slightly more procedural than the firm would normally expect). What will happen?</p>
<p><img src="https://commoncog.com/blog/content/images/2019/08/Paper.Commonplace.49.png" alt="Paper.Commonplace.49"></p>
<p>As Figure 1â€“2 suggests, the short-run consequence will be that higher priced people will end up performing lower-value tasks (probably at lower fees), and there will be an underutilization of senior personnel. The firm will make less money than it should be making.</p>
<p><img src="https://commoncog.com/blog/content/images/2019/08/Paper.Commonplace.50.png" alt="Paper.Commonplace.50"></p>
<p>The opposite problem is no less real. If a firm brings in work that has skill requirements of a higher â€¦</p></blockquote></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://commoncog.com/blog/the-consulting-business-model/">https://commoncog.com/blog/the-consulting-business-model/</a></em></p>]]>
            </description>
            <link>https://commoncog.com/blog/the-consulting-business-model/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26187118</guid>
            <pubDate>Thu, 18 Feb 2021 23:08:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Kanban board that helps Engineers learn Marketing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26186864">thread link</a>) | @krm01
<br/>
February 18, 2021 | https://phireworks.co/pro/?pro | <a href="https://web.archive.org/web/*/https://phireworks.co/pro/?pro">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<table>
  <tbody><tr>
    <td>

      <h3>Examples from real companies. </h3>
      <h4>New marketing ideas are constantly added to your dashboard so you can learn how other founders acquired their first set of customers.</h4>
    </td>

    <td>

      <h3>Drag &amp; drop to organize</h3>
      <h4>Organize and prioritize weekly marketing experiments that you can implement yourself. Design your process for consistent growth.</h4>
    </td>

    <td>

      <h3>Practical and actionable guides</h3>
      <h4>Discover practical marketing ideas without the fluff, so you can save time and start implementing right away.  </h4>
    </td>
  </tr>
</tbody></table>





</div></div>]]>
            </description>
            <link>https://phireworks.co/pro/?pro</link>
            <guid isPermaLink="false">hacker-news-small-sites-26186864</guid>
            <pubDate>Thu, 18 Feb 2021 22:44:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Terror Management Theory]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26186711">thread link</a>) | @spekcular
<br/>
February 18, 2021 | https://ernestbecker.org/resources/terror-management-theory/ | <a href="https://web.archive.org/web/*/https://ernestbecker.org/resources/terror-management-theory/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <article id="post-60" class="page">
  <div>
    
<h2>Terror Management Theory</h2>
<p><iframe src="https://www.youtube.com/embed/Joalg73L_gw" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe><br>Terror Management Theory (TMT) was developed in 1986 by social psychologists Jeff Greenberg, Tom Pyszczynski, and Sheldon Solomon based upon Ernest Beckerâ€™s ideas.</p>
<p>TMT posits that while humans share with all life-forms a biological predisposition toward self-preservation in the service of reproduction, we are unique in our capacity for symbolic thought, which fosters self-awareness and the ability to reflect on the past and ponder the future. This spawns the realization that death is inevitable and can occur at any time for reasons that cannot be anticipated or controlled.</p>
<p><strong>The awareness of death engenders potentially debilitating terror that is â€œmanagedâ€ by the development and maintenance of cultural worldviews:</strong> humanly constructed beliefs about reality shared by individuals that minimize existential dread by conferring meaning and value. All cultures provide a sense that life is meaningful by offering an account of the origin of the universe, prescriptions for appropriate behavior, and assurance of immortality for those who behave in accordance with cultural dictates. <strong>Literal immortality is afforded by souls, heavens, afterlives, and reincarnations associated with all major religions. Symbolic immortality is obtained by being part of a great nation, amassing great fortunes, noteworthy accomplishments, and having children.</strong></p>
<p>Psychological equanimity also requires that individuals perceive themselves as persons of value in a world of meaning. This is accomplished through social roles with associated standards. Self-esteem is the sense of personal significance that results from meeting or exceeding such standards.</p>
<p>Three lines of research provide empirical support for TMT:</p>
<div>
<ul>
<li>The anxiety-buffering function of self-esteem is established by studies where <strong>momentarily elevated self-esteem results in lower self-reported anxiety</strong> and physiological arousal.</li>
<li>Making death salient by asking people to think about themselves dying (or viewing graphic depictions of death, being interviewed in front of a funeral parlor, or subliminal exposure to the word â€œdeadâ€ or â€œdeathâ€) <strong>intensifies strivings to defend their cultural worldviews</strong> by increasing positive reactions to similar others, and negative reactions toward those who are different.</li>
<li>Research verifies the existential function of cultural worldviews and self-esteem by demonstrating that <strong>non-conscious death thoughts come more readily to mind when cherished cultural beliefs or self-esteem is threatened</strong>.</li>
</ul>
</div>
<p>TMT has generated empirical research (currently more than 500 studies) examining a host of other forms of human social behavior, including aggression, stereotyping, needs for structure and meaning, depression and psychopathology, political preferences, creativity, sexuality, romantic and interpersonal attachment, self-awareness, unconscious cognition, martyrdom, religion, group identification, disgust, human-nature relations, physical health, risk taking, and legal judgments.</p>
<p>In 2015, Greenberg, Pyszczynski and Solomon published <a href="http://www.amazon.com/Worm-Core-Role-Death-Life/dp/1400067472/ref=sr_1_1?ie=UTF8&amp;qid=1442374782&amp;sr=8-1&amp;keywords=the+worm+at+the+core" target="_blank" rel="noopener noreferrer"><em>The Worm at the Core</em></a>, which reviews this vast body of research supporting Beckerâ€™s central claim that the fear of death is â€œthe mainspring of human activity.â€</p>
<p><strong>Related Books</strong><br>

<a target="_blank" href="https://www.elsevier.com/books/handbook-of-terror-management-theory/routledge/978-0-12-811844-3" rel="noopener noreferrer">Handbook of Terror Management Theory</a> (This is the most up-to-date anthology on TMT research)<br>

<a href="http://www.amazon.com/In-Wake-9-11-Psychology-Terror/dp/1557989540" target="_blank" rel="noopener noreferrer">In the Wake of 9/11: The Psychology of Terror</a><br><a href="http://www.guilford.com/books/Handbook-of-Experimental-Existential-Psychology/Greenberg-Koole-Pyszczynski/9781593850401" target="_blank" rel="noopener noreferrer">The Handbook of Experimental Existential Psychology</a></p>
<p><strong>Resources</strong><br>
<a href="http://www.tmt.missouri.edu/" target="_blank" rel="noopener noreferrer">TMT Website</a><br><a href="http://www.imdb.com/title/tt0365215/" target="_blank" rel="noopener noreferrer">Flight From Death</a></p>
<p><strong>Reviews of <em>The Worm at the Core</em></strong><br><a href="http://www.theguardian.com/books/2015/jul/31/the-worm-at-the-core-on-the-role-of-death-in-life-solomon-greenberg-pyszczynski-review" target="_blank" rel="noopener noreferrer">The Guardian, July 31, 2015</a><br><a href="http://www.newstatesman.com/culture/books/2015/09/why-cant-we-stop-death?utm_content=bufferddfd2&amp;utm_medium=social&amp;utm_source=facebook.com&amp;utm_campaign=buffer" target="_blank" rel="noopener noreferrer">New Statesman, September 1, 2015</a><br><a href="http://www.nationalinterest.org/feature/how-the-fear-death-changes-you-13658?utm_content=buffer4bbe3&amp;utm_medium=social&amp;utm_source=facebook.com&amp;utm_campaign=buffer" target="_blank" rel="noopener noreferrer">The National Interest, August 24, 2015</a><br><a href="http://chronicle.com/article/Mortal-Motivation/230303/" target="_blank" rel="noopener noreferrer">The Chronicle, May 22, 2015</a><br><a href="http://www.theatlantic.com/health/archive/2015/05/what-good-is-thinking-about-death/394151/" target="_blank" rel="noopener noreferrer">The Atlantic, May 28, 2015</a></p>


<p><strong>Songs About Becker/TMT</strong><br>

<a href="https://www.youtube.com/watch?v=BfdT3YR4RKk" target="_blank" rel="noopener noreferrer"><span>KALIâ€”Terror Management Theory</span></a><br>

<a href="https://boobsofdoom.bandcamp.com/album/13-terror-management-theory" target="_blank" rel="noopener noreferrer">Boobs of Doomâ€”Terror Management Theory</a><br>

<a href="https://canoncorerecords.bandcamp.com/track/terror-management-theory" target="_blank" rel="noopener noreferrer"><span>Skyline + Seluekosâ€”Terror Management Theory</span></a><br>

<a href="https://www.youtube.com/watch?v=QoK06y4dIfo" target="_blank" rel="noopener noreferrer">Under Threatâ€”Terror Management Theory<br>

</a><a href="https://www.youtube.com/watch?v=GhYxp8OtUOU" target="_blank" rel="noopener noreferrer">Hallucinogeniusâ€”Terror Management Theory</a><br>

<a href="https://soundcloud.com/abadgeoffriendship/3-outblinker-ernest-becker" target="_blank" rel="noopener noreferrer">Outblinkerâ€”Ernest Becker</a><br>

<a href="https://richaucoin.bandcamp.com/album/release" target="_blank" rel="noopener noreferrer">Rich Aucoinâ€”Release (entire album)</a><br>
<em>â€œIt was originally to be called Death Release and is largely based around the work of psychologist Ernest Beckerâ€™s Denial of Death and his studentsâ€™ follow-up The Worm At The Core and terror management theory.â€</em>
<a target="_blank" href="https://www.house-music.co/2019/06/rich-aucoin-shares-video-for-base-from.html" rel="noopener noreferrer">https://www.house-music.co/2019/06/rich-aucoin-shares-video-for-base-from.html</a>




</p>
    
      </div>
  <!--end entry-content-->

</article>
<!-- end post-60 --></div></div>]]>
            </description>
            <link>https://ernestbecker.org/resources/terror-management-theory/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26186711</guid>
            <pubDate>Thu, 18 Feb 2021 22:33:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Texas power outage is a nation-wide problem]]>
            </title>
            <description>
<![CDATA[
Score 241 | Comments 395 (<a href="https://news.ycombinator.com/item?id=26186645">thread link</a>) | @gwoplock
<br/>
February 18, 2021 | https://garrettbattaglia.com/post/texas-power/ | <a href="https://web.archive.org/web/*/https://garrettbattaglia.com/post/texas-power/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
        <p>Let me preface this with an explanation. Over the last few days I read online people saying that Texas' power outages had been caused by Texas being on its own gridâ€¦ deregulationâ€¦ Not following national standardsâ€¦  had Texas been connected to the Eastern Interconnection or the Western Interconnection none of this would have happened. But not one post shows any evidence or requirements that backed up these claims. So, I went looking for proof and instead of finding requirements, I found a nationwide problem with winterization. As an aside I am not an expert in the grid or electricity, I am a software developer, and this is my best interpretation of the requirements I could find.</p>
<p>Letâ€™s start off with how the electrical grid works in the US. The grid is made up of 3 interconnections: the Eastern Interconnection, the Western Interconnection, and the Texas Interconnect. Each of these interconnections operate in (near) isolation with their own frequency, voltage, and phase. There are several high voltage DC interconnects (HVDC or DC-DC) between them. In each of these interconnections there is at least one grid operators, for example ERCOT in Texas. These grid operators manage the generation and load of their interconnection, acting as almost as an electric clearing house. They are also responsible for keeping voltage and frequency within range and directing distributors (like ONCOR in north Texas) to shed load during Electrical Emergency Alerts (EEA). An important thing to note for later, from the best I can tell the different grid operators in the Eastern Interconnect share power in a â€œnon-firm, as-available basisâ€.</p>
<p>What happened in Texas, starting 12:30 AM February 15. The long and short of it is an estimated 34GW of generation went offline in about 2 hours[1]. Looking at ERCOTâ€™s tweets [2,3,4], generation was starting to have an issue at 00:17:45 and some load needed to be shed so ERCOT issued the first EEA (EEA1). In the February EEA tools document[5] EEA1 can open up around 1.6GW of â€œpeekerâ€ generation and importation from the Eastern and Western Interconnections. But by 1:12:06 that wasnâ€™t enough and additional load had to be shed.  A second EEA was issued (EEA2) shedding another 1.6GW. But just a few minutes later the house came crashing down and at 1:25:40 the third EEA (EEA3) was issued. In addition to starting rolling blackouts to shed most of the load it also allowed for other actions to free .1-.2GW of load.</p>
<p>The 34GW of generation lost was from every fuel source used. Most of it was frozen-off natural gas (gas) wells, some of it was frozen wind turbines, solar panels that had snow on them and even a nuclear plant had to go offline due to issues with feedwater pressure sensing issues related to the cold.
What do the North American Electric Reliability Corporation (NERC) standards say about protecting any of these sources? Not much.</p>
<p>Letâ€™s start by looking at the least complex, wind turbines. On September 12, 2012 NERC published a Lesson Learned document in regards to Texasâ€™s issues with some of the wind farms freezing in extreme winter weather[6]. According to the document the event that was predicted over a week beforehand brought 4 days of low temperature, high winds and wind chills, ice and snow that limited the generation facility to just 25% of capacity. The facility did have a SOP for icing conditions that was implemented. However, the facility never defined itâ€™s minimum operating temperature. When lightning knocked out some of the sensing equipment, the turbines had to be stop for safety. The repair crews couldnâ€™t immediately get to the turbines and they had to sit, this gave the oil a chance to cool and partly freeze. When the turbines were returned to service, they tripped back off due to high oil pressure. Eventually after working with the manufacturer they were able to safely heat the oil and restart the turbines. One of the big lessons from this was to install cold weather packs for wind turbines and watch the oil temperature. Youâ€™d think that would solve future outage, but no, in 2019 in the midwestwind turbines failed due to exceptionally low temperatures, around -21. Again the cold weather package hadnâ€™t been installed and was one of the root causes of the failure[7].</p>
<p>The nuclear plantâ€™s sensing problems had happened before too. Although it wasnâ€™t a nuclear plant, there are several documented cases on NERCâ€™s website citing cold weather and sensor issues [8,9]. This repeated in Texas (2011) and in the south east (2018)[10].</p>
<p>Letâ€™s discuss natural gas next. It appears that most of the issues in the problematic natural gas fired facilities was due to low gas supplies. In 2012 NERC warned of the interconnectivity of natural gas and electric[11]. Natural gas coming out of the ground has a naturally high water content. This water can freeze the extraction equipment during sub-freezing weather in improperly winterized wells creating what is know as a freeze-off. businesses, residential customers, and powerplants all run off the same supply, once wells start freezing off the supply dwindles for all. Natural gas companies prioritize residential customers as needed and will cut businesses and powerplants. This obviously creates issues in electrical generation.</p>
<p>In this latest case, much of the gas generation loss was due to under pressure conditions at the generation site. When generation sites detect this kind of fault, they are taken offline for safety. Not only is this what happened this year, but it has happened many, many times before</p>
<p>The most resent case I could find was 2018 in the south east[10]. Starting on January 18, 2018 a large area in the south east US experienced unusually cold weather. This caused 183 generation facilities to go offline or operate with greatly reduced output. At the peak there was nearly 30GW of production lost. This caused several grid operators to issue EEAs and begin rolling blackouts. In the â€œevent areaâ€ 14% of the failures could be directly attributed to the cold weather. And another 30% could be indirectly linked to weather, including mechanical failures know to happen in cold weather and gas supply issues. NERC found that more than 33% of the failed powerplants didnâ€™t have a winterization plan.</p>
<p>Why didnâ€™t these plants have a winterization plan? Because it wasnâ€™t required[10,12].</p>
<p>This wouldnâ€™t be so bad if this wqs the first time it happened, it wasnâ€™t even the second time it happened. In 2014 a polar vortex hit the US. bringing temperatures well below normal. During this event 55% of the outages were at gas power plants and in all 90GW of generation was lost[13].</p>
<p>The earliest report I could find was from the 2011 winter event in Texas[14]. A very strong cold front hit Texas (and other parts of the south central US) bringing temperatures below freezing for over 4 days and winds over 30 MPH. Leading up to the event, ERCOT and other grid operators in surrounding areas felt that there wouldnâ€™t be a need for rolling blackouts. At the beginning of the event ERCOT had 3.1GW of reserve, nearly 1GW over the minimum required. However, over the next 2 days ERCOT lost nearly 30GW of production in 193 generation facilities. ERCOT was able to stabilize the grid with rolling blackouts and the other EEA methods[5]. Other grids suffered problems as well, EPE (El Paso) and SRP (Arizona) lost nearly 1.4GW due to cold weather. Another issue in ERCOTâ€™s region was nearly 50% of the â€œblack startâ€ facilities were either down for scheduled maintenance or failed on startup. One of the main causes again was the loss of gas during this blackout period. 14.8 Bcf of natural gas production was lost due to freeze-offs, electrical outages (ironically) and customer curtailments. following the previous equivalent storm in 1989, the PUCT (Public Utility Commission of Texas) issued several recommendations and guidelines for winterization of power plants and gas wells. However, due to the infrequency of these storms the implementation lacked. With many of the same facilities that failed in 1989 also failed in 2011.  My guess is these same sites failed again in 2021. Interestingly the NERC found that it is quite possible that gas production in these unusually cold conditions may be impossible.</p>
<p>What has been done since 2011? Not a whole lot. A request for a new standard was issued to NERC in late 2012, however a few months later it was denied.[15] Also in 2012 NERC put out a set of guidelines for developing a plan for winter weather[16]. In 2017 NERC put out a special reliability report on the relationship between gas and electricity[17]. Finally, after the 2018 event NERC received another standard request that was approved[23], however it wonâ€™t be finalized until late 2021[18,19,20].</p>
<p>From what I can see, ERCOT has more restrictive rules in their Generator Winter Weatherization Workshop than NERC[21]. All generation stations must have plans for emergencies, address abnormal weather, critical failure points, weather design limits, alternative fuels and testing[21,22]. ERCOT reports that there were 80 spot checks done in the 2019/2020 season with 71 being gas plants and 6 being black start gas plants. 23 had to improve and would be reinspected in early 2021 the rest passed.</p>
<p>The issue of extreme cold weather and electrical outages is a national issue that needs to be addressed. However, after repeated failings it hasnâ€™t really been addressed. Hopefully with the new NERC requirements and the Texas legislature in session progress can be made.</p>
<hr>
<p>[1] <a href="http://www.ercot.com/news/releases/show/225244">http://www.ercot.com/news/releases/show/225244</a><br>
[2] <a href="https://twitter.com/ERCOT_ISO/status/1361197991659503618">https://twitter.com/ERCOT_ISO/status/1361197991659503618</a><br>
[3] <a href="https://twitter.com/ERCOT_ISO/status/1361211669788176384">https://twitter.com/ERCOT_ISO/status/1361211669788176384</a><br>
[4] <a href="https://twitter.com/ERCOT_ISO/status/1361215084010352644">https://twitter.com/ERCOT_ISO/status/1361215084010352644</a><br>
[5] <a href="http://www.ercot.com/content/wcm/lists/219692/EEA_Tools_One_Pager_Winter_2021_2-13-2021.pdf">http://www.ercot.com/content/wcm/lists/219692/EEA_Tools_One_Pager_Winter_2021_2-13-2021.pdf</a><br>
[6] <a href="https://www.nerc.com/pa/rrm/ea/Lessons%20Learned%20Document%20Library/LL20120901_Wind_Farm_Winter_Storm_Issues.pdf">https://www.nerc.com/pa/rrm/ea/Lessons%20Learned%20Document%20Library/LL20120901_Wind_Farm_Winter_Storm_Issues.pdf</a><br>
[7] <a href="https://www.nerc.com/pa/rrm/ea/Lessons%20Learned%20Document%20Library/LL20200601_Unanticipated_Wind_Generation_Cutoffs_during_a_Cold_Weather_Event.pdf">https://wâ€¦</a></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://garrettbattaglia.com/post/texas-power/">https://garrettbattaglia.com/post/texas-power/</a></em></p>]]>
            </description>
            <link>https://garrettbattaglia.com/post/texas-power/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26186645</guid>
            <pubDate>Thu, 18 Feb 2021 22:26:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top Latex Fonts]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26186538">thread link</a>) | @alderz
<br/>
February 18, 2021 | https://r2src.github.io/top10fonts/ | <a href="https://web.archive.org/web/*/https://r2src.github.io/top10fonts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<h2>assembled by Jaap Joris Vens</h2>

<p>

This page contains ten paragraphs typeset by the
<a href="http://www.latex-project.org/"><span>L<sup>a</sup>T<sub>e</sub>X</span>
typesetting system</a>, converted to images by
the <a href="http://savannah.nongnu.org/projects/dvipng/">dvipng</a>
utility.  Each paragraph<sup>1</sup> showcases a different font family
and provides some background and usage instructions.

The source of this page is <a href="https://github.com/r2src/top10fonts/">available on GitHub</a>.

All the fonts are free and open source and are included by default in
most <span>L<sup>a</sup>T<sub>e</sub>X</span>
distributions.  All fonts are also available
on <a href="http://www.ctan.org/tex-archive/fonts/">CTAN</a>, as well as in the
<a href="http://www.tug.dk/FontCatalogue/"><span>T<sub>e</sub>X</span>
Font Catalogue</a>.<br>
<span>
&nbsp;&nbsp;&nbsp;<sup>1</sup> except for this one, which is the only
paragraph rendered by your browser.
</span>
</p>

<p>
<img src="https://r2src.github.io/top10fonts/lmodern.png" alt="1 Computer Modern">
</p>

<p>
<img src="https://r2src.github.io/top10fonts/kpfonts.png" alt="2 Kepler Fonts">
</p>
<p>
<img src="https://r2src.github.io/top10fonts/fontcomp.png" alt="Comparison table">
</p>
<p>
<img src="https://r2src.github.io/top10fonts/kpsans.png" alt="Kepler Sans">
</p>

<p>
<img src="https://r2src.github.io/top10fonts/didot.png" alt="6 GFS Didot">
</p>

<p>
<img src="https://r2src.github.io/top10fonts/utopia.png" alt="4 Utopia">
</p>

<p>
<img src="https://r2src.github.io/top10fonts/venturis.png" alt="5 Venturis ADF">
</p>
<p>
<img src="https://r2src.github.io/top10fonts/venturisrm1.png" alt="">
</p>
<p>
<img src="https://r2src.github.io/top10fonts/venturisrm2.png" alt="">
</p>
<p>
<img src="https://r2src.github.io/top10fonts/venturisrm3.png" alt="">
</p>

<p>
<img src="https://r2src.github.io/top10fonts/libertine.png" alt="6 Libertine">
</p>

<p>
<img src="https://r2src.github.io/top10fonts/gyre.png" alt="7 TeX Gyre Collection">
</p>
<p>
<img src="https://r2src.github.io/top10fonts/gyrebonum.png" alt="Bonum">
</p>
<p>
<img src="https://r2src.github.io/top10fonts/gyrepagella.png" alt="Pagella">
</p>
<p>
<img src="https://r2src.github.io/top10fonts/gyreschola.png" alt="Schola">
</p>
<p>
<img src="https://r2src.github.io/top10fonts/gyretermes.png" alt="Termes">
</p>

<p>
<img src="https://r2src.github.io/top10fonts/antiqua.png" alt="7 URW Antiqua">
</p>

<p>
<img src="https://r2src.github.io/top10fonts/bera.png" alt="10 Bitstream Vera">
</p>

<p>
<img src="https://r2src.github.io/top10fonts/boisik.png" alt="8 Boisik">
</p>



</div>]]>
            </description>
            <link>https://r2src.github.io/top10fonts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26186538</guid>
            <pubDate>Thu, 18 Feb 2021 22:19:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Which startups let their employees sell stock?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26186119">thread link</a>) | @gk1
<br/>
February 18, 2021 | https://sacra.com/startup-employee-liquidity/ | <a href="https://web.archive.org/web/*/https://sacra.com/startup-employee-liquidity/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <article class="page">
      <section>
        <div>
          

          <div>
            <p>Selling stock is a taboo subject at a lot of startups.</p>

            <p>To normalize talking about liquidity and help employees make informed career decisions, we built this list of companies that do and donâ€™t allow employees to sell their stock.</p>

            <p><strong>Want to help?</strong> <a href="https://airtable.com/shrbQ6hB22DzXsHOR">Fill out out our survey</a>.</p>
          </div>
        </div>
      </section>
      <section>
        <div>
          

          <div>
            <div>
              <h3>Do you work at a VC-backed company?</h3>

              <p>Help us add to this database anonymously. Your responses will be kept confidential.</p>

              <p><a href="https://airtable.com/shrbQ6hB22DzXsHOR">Add a report</a>
            </p></div>
            <div>
              <h3>Are you an employer?</h3>

              <p>Tell us about your companyâ€™s policies around secondary sales and employee liquidity. Weâ€™d love to hear from you.</p>

              <p><a href="https://airtable.com/shr8aZVC34siGSxAx">Respond to this report</a>
            </p></div>
          </div>
        </div>
      </section>

      <section>
        <div>
          <h2>Liquidity programs by stage</h2>
          
          <div>
            <p>Later-stage companies are more likely to allow employee stock sales, either through company-led transactions or by allowing employee-led transactions. Doing so allows them to provide long-time members of the team with an opportunity to de-risk by getting some liquidity. 

            </p><p>However, today, some companies like Pipe have begun making liquidity available for their employees as early as seed/Series A.</p>

            <p>Some companies donâ€™t allow for employee sales of their stock. In some instances, these companies implement transfer restrictions that prevent private sales from occurring.</p>

          </div>
        </div>
      </section>
      <section>
        <div>
          <h2>Resources for employees</h2>



          <h3>Stock option exercise lending</h3> 
          
          <p>One barrier to employee liquidity is exercising your stock options, which can be expensive and confusing. Some companies help by allowing employees to borrow cash to meet their option exercise and tax obligations. </p>

          <h3>Secondary brokerages</h3>
          
          <p>If your company allows for you to sell your stock, but doesnâ€™t offer regular company-led liquidity, you may be able to sell it on a secondary marketplace or via a broker.</p>
          <h3>Secondary funds</h3>
          
          <p>Certain venture funds specialize in â€œspecial situationsâ€ like employee and/or founder liquidity at private companies, and actually prefer to buy stock in secondary markets.</p>
          <h3>Company liquidity platforms</h3>
          
          <p>If your company offers regular liquidity by way of tender offers, share buybacks, or auctions, you will likely know about it well in advance. If youâ€™re not sure, you can ask your HR or finance team and they will let you know if your company allows for these types of transactions.</p>

          <h4>Learn more</h4>

          
        </div>
      </section>
    </article>
  </div></div>]]>
            </description>
            <link>https://sacra.com/startup-employee-liquidity/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26186119</guid>
            <pubDate>Thu, 18 Feb 2021 21:46:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to connect to Ethereum network using Go]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26186024">thread link</a>) | @Sahil_Sen
<br/>
February 18, 2021 | https://www.quiknode.io/guides/web3-sdks/how-to-connect-to-ethereum-network-using-go | <a href="https://web.archive.org/web/*/https://www.quiknode.io/guides/web3-sdks/how-to-connect-to-ethereum-network-using-go">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span>
        <div><p>The following will show you how to initialize your Go project, connect to the Ethereum network and get the latest block number, quickly, easily, and headache-free, provided you have installed the latest version of Go on your environment.&nbsp;</p><p>1. Create a file called quiknode.go&nbsp;</p></div><pre><code>package main

import (
	"fmt"
	"log"

	"github.com/ethereum/go-ethereum/ethclient"
)

func main() {

	client, err := ethclient.Dial("<strong>ADD_YOUR_ETHEREUM_NODE_URL</strong>")

	if err != nil {
		log.Fatalf("Oops! There was a problem", err)
	} else {
		fmt.Println("Success! you are connected to the Ethereum Network")
	}
}
<br></code></pre><p>Replace `<strong>ADD_YOUR_ETHEREUM_NODE_URL</strong>` with the provider endpoint you saved earlier.</p><div><p>2. Create a module to track dependencies. If youÃ¢â‚¬â„¢re not familiar with go, this is an essential step in setting up your projectÃ¢â‚¬â„¢s dependencies. With Go itÃ¢â‚¬â„¢s quite easy</p></div><pre><code>go mod init quiknode</code></pre><p>This will ensure the ethclient that was included in your code is downloaded from GitHub and installed locally. It happens automatically and the latest version should be pulled into your environment along with built-in Go modules.&nbsp;</p><pre><code>Go run quiknode.go</code></pre><div><p>If everything goes well, you will see the following message:</p><figure data-trix-attachment="{&quot;content&quot;:&quot;<span class='trix-attachment-spina-image' data-label=''> <img class='w-full' src='https://www.quiknode.io/rails/active_storage/blobs/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBWdz09IiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--4a207b2262042d5a1236f6ebc0cd4ee79d0afaad/main.go.png' alt='' /> </span>&quot;}" data-trix-content-type="undefined"><span data-label=""> <img src="https://www.quiknode.io/rails/active_storage/blobs/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBWdz09IiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--4a207b2262042d5a1236f6ebc0cd4ee79d0afaad/main.go.png" alt=""> </span><figcaption></figcaption></figure></div><div><p>That was easy! You are now running your own node that is connected and synced. Next, check if your node is working and pull some information from the blockchain.</p></div><p>4. Modify your code to obtain additional information from the ETH blockchain:</p><pre><code>package main

import (
    "context"
    "fmt"
    "log"

    "github.com/ethereum/go-ethereum/ethclient"
)

func main() {
    client, err := ethclient.Dial("ADD_YOUR_ETHEREUM_NODE_URL")
   
    if err != nil {
		log.Fatalf("Oops! There was a problem", err)
    } 
    else {
		fmt.Println("Sucess! you are connected to the Ethereum Network")
	}
	header, err := client.HeaderByNumber(context.Background(), nil)
	if err != nil{
		log.Fatal(err)
	} 
	else {
		fmt.Println(header.Number.String())
	}
}</code></pre><p>&nbsp;A quick explanation of the code above:</p><p>Lines 1-9: Declaring the main package and adding dependencies necessary to connect to the blockchain.<br>Line 11: Invoking the main function.</p><p>Line 12: Setting up our client and connecting it to an Ethereum node hosted by QuikNode.</p><p>Line 14: Checking for connection errors.<br>Line 18: Displaying a message on the successful connection.<br>Line 20: Sending a request to our node to obtain the latest block number.<br>Lines 21-26: Checking for request error and outputting a success message if no errors, converting the hash number to a string and displaying it.</p><p>DonÃ¢â‚¬â„¢t forget to replace `<strong>ADD_YOUR_ETHEREUM_NODE_URL</strong>` with the http endpoint address for your own node.&nbsp;</p><p>Upon successful execution, you will see a similar message:</p><div><br><figure data-trix-attachment="{&quot;content&quot;:&quot;<span class='trix-attachment-spina-image' data-label=''> <img class='w-full' src='https://www.quiknode.io/rails/active_storage/blobs/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBBWjA9IiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--97d5ab1060be2f31abcb7f37e157d0d482ab5316/Screenshot%20(63).png' alt='' /> </span>&quot;}" data-trix-content-type="undefined"><span data-label=""> <img src="https://www.quiknode.io/rails/active_storage/blobs/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBBWjA9IiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--97d5ab1060be2f31abcb7f37e157d0d482ab5316/Screenshot%20(63).png" alt=""> </span><figcaption></figcaption></figure></div><p>ThatÃ¢â‚¬â„¢s it! You can now use your own QuikNode and build the next awesome dApp using Go.</p>
      </span>
    </p></div>]]>
            </description>
            <link>https://www.quiknode.io/guides/web3-sdks/how-to-connect-to-ethereum-network-using-go</link>
            <guid isPermaLink="false">hacker-news-small-sites-26186024</guid>
            <pubDate>Thu, 18 Feb 2021 21:39:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Analysis of 100 Weeks of Curated AI News]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26185936">thread link</a>) | @andreyk
<br/>
February 18, 2021 | https://www.skynettoday.com/digests/ai-news-analysis | <a href="https://web.archive.org/web/*/https://www.skynettoday.com/digests/ai-news-analysis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>        
      
      
      <h4>A look at trends from 100 weeks of AI news, and AI-generated AI news snippets!</h4>
      
      </div><div>
      <p>With this weekâ€™s â€œLast Week in AI,â€ Skynet Today has just released its 100th edition of <a href="https://lastweekin.ai/">our weekly newsletter summarizing each weekâ€™s major AI news</a>! 
Thatâ€™s almost 2 years of covering the developments in AI, sifting through the often noisy AI news landscape for important trends, while highlighting potential hypes and concerns.</p>

<p>To commemorate this occasion, weâ€™re publishing a few notable statistics on these past 100 weeks.
And, for fun, weâ€™ve fine-tuned a GPT-2 model on all the AI news articles weâ€™ve covered so far to generate a few AI news snippets.</p>

<h2 id="weekly-ai-news-trends-across-100-weeks">Weekly AI News Trends across 100 weeks</h2>

<figure>
 <img src="https://www.skynettoday.com/assets/img/digests/100_analysis/article_count.png" alt="Article Count">
  <figcaption>
    The number of articles per newsletter increased after mid-2019 when we adopted a more automated pipeline for collecting and filtering AI news articles.
  </figcaption>
</figure>

<figure>
 <img src="https://www.skynettoday.com/assets/img/digests/100_analysis/keyword_trends_cumulative_ai_topics.png" alt="AI Topics">
  <figcaption>
    It seems like at least for the articles we collect, ones related to "robots" grew much faster than other areas.
    Note: keyword trends also count related terms - for example, "hardware" also counts mentions of "GPU"
  </figcaption>
</figure>

<figure>
 <img src="https://www.skynettoday.com/assets/img/digests/100_analysis/keyword_trends_cumulative_news_topics.png" alt="AI News Topics">
  <figcaption>
    After late 2019, articles regarding facial recognition grew much faster than others, with Covid-19 articles making a sudden entrance starting early 2020.
    Articles regarding Deep Fakes also saw a sudden jump starting mid-2019.
  </figcaption>
</figure>

<figure>
 <img src="https://www.skynettoday.com/assets/img/digests/100_analysis/keyword_trends_cumulative_institutions.png" alt="AI Institution Topics">
  <figcaption>
    Perhaps unsurprisingly, Google dominates the AI news cycle in terms of mentions of institution names.
    In distant seconds are the other tech giants of Amazon, Facebook, and Microsoft.
  </figcaption>
</figure>

<figure>
 <img src="https://www.skynettoday.com/assets/img/digests/100_analysis/sentiment_by_topic.png" alt="Sentiment">
  <figcaption>
    Sentiment analysis of article summaries across various topics has some expected but neat results; some AI applications, such as art, have mostly positive coverage, while others such as surveillance have generally negative coverage.
  </figcaption>
</figure>

<h2 id="ai-generated-ai-news-articles">AI-Generated AI News Articles</h2>

<p>We finetuned a GPT-2 model on the AI articles we linked throughout our newsletters to generate the follow AI news snippets.
While theyâ€™re written in the style of AI news, mentioning the appropriate keywords and phrases, theyâ€™re generally logically inconsistent and contain obvious factual errors.
For example, the first snippet mentions a researcher by the name of Atushi Sakamoto.
While this name does belong to a real researcher, in real life he is a Professor of Integrated Life Sciences at Hiroshima University, not someone studying AI at the University of Tokyo.
This is unsurprising given how these models work (see <a href="https://www.skynettoday.com/briefs/gpt2">here</a>, <a href="https://www.skynettoday.com/editorials/humans-not-concentrating">here</a>, and <a href="https://www.skynettoday.com/briefs/gpt3">here</a>).</p>

<p>But, reading these generated snippets can still be an interesting experience - some are as bad as others are hilarious:</p>

<!-- Quote Slideshow code from https://www.w3schools.com/howto/howto_js_quotes_slideshow.asp -->

<!-- Dots/bullets/indicators -->


<div>

  <div>
    <h5> Researchers develop a traffic light for self-driving cars </h5> 
    <p><q>
    A pair of new papers from University of Tokyo Institute of Technology researchers and the World Health Organization claim to have addressed one of the great challenges of artificial intelligence: traffic lights. Thanks to machine learning, they can illuminate traffic for much more effective and safer operation than they could on paper. In research authored by Atsushi Sakamoto and colleagues at the Institute of Intelligent Systems and Decision Support in Tokyo, the team presents an efficient way to turn traffic lights on and off. In practice, however, identifying and setting the timing for lighting within a traffic space can prove difficult, as itâ€™s often unpredictable and there may even be visual clues that indicate the start of a car ahead or the end of a short one. Sakamoto and colleagues came up with an efficiency-enabling solution based on approaches developed by researchers at Google, IBM, and Toyota.
    </q>
  </p></div>

  <div>
    <h5> How I used NLP's GPT-3 to write the AI I Created </h5>
    <p><q>
    When it comes to creating AI, there are 2 main choices I have:- write a clean code or- just use the output from the original app to clean code. Either way, there are a lot of good articles and code examples on arxiv.com.The reason I choose the latter is both lovely and surprising: with a solid foundation of 30 lines of code (more on that later), this way of creating and using AI is fairly simple. I wanted a clean, sharp and concise writing experience that would let my coworkers and I take on difficult creative problems with clear writing. What I didn't expect was for the first part of the code to become a bottleneck, exposing the messiness of the AI. The second reason may be more complex: I was writing this sentence while driving, and as I was about to cross the street, I accidentally sent the car driving by on the bright day and ended up writing another code to keep driving. Despite its simplicity, the problem with GPT-3 is its inability to generate long sequences.
    </q>
  </p></div>

  <div>
    <h5> AI researchers propose making chatbots and voice assistants more like their real-world peers </h5>
    <p><q> 
    Chatbots, which are a form of virtual personas, have long been the interface between human and machine. Advances in the past few years have democratized voice assistants, responding to the needs of multiple speakers at once, aiming to reduce set times and improve duration. But much of the field has proven difficult to apply conversational AI effectively in the real world, especially on sensitive tasks involving such as sales or customer service.To address this issue, a team from MIT Technology Review (MIT Tech Review) and Beijing-based research institute Beijing Brain Institute have developed a novel approach to training conversational AI systems on a dataset of short conversations over long periods of time. The researchers developed a chatbot named QUEBO after their lab name, which stands for QUEBO, "QuÅ-" or "QUE-BO." They say the research will serve as a benchmark to benchmark conversational AIâ€™s capability to handle small conveniences like social media conversations in real time.
    </q>
  </p></div>

  <div>
    <h5> Amazon to Retrain a Third of Its U.S. Workers as Automation Advances </h5>
    <p><q>
    So far, the American workforce has been largely in workers of color. But Amazon is about to ramp up hiring of some of its more 200,000 hourly workers, according to a person familiar with the companyâ€™s plans. The new hires wonâ€™t be those in the same field as its more self-professed â€œwhite-collar workers,â€ as the company abbreviates its growing staff. Instead, the roughly 1,000 new workers will be drawn from two large and multiracial groups: Amazon has laid off thousands of Black and Latinx workers, has laid off dozens of Latinx employees, and is currently seeking Federal Employment Development money to pay for new workers. â€œRight now, the numbers of Black, Latinx, and African American workers are shrinking, because thereâ€™s still not enough talent available to continue these high-volume, high-pressure work,â€ the person familiar with Amazonâ€™s plans explained. Amazon declined to comment on the more than 1,000 new positions it plans to employ.
    </q>
  </p></div>

  <div>
    <h5> Meet Microsoft's first AI-powered coffee machine </h5>
    <p><q>
    Jeff Dean, chair of Microsoftâ€™s artificial intelligence (AI) division, recently sat down with WIRED senior writer Will Knight to discuss the value of building products that do a lot of good, but donâ€™t always do much of anything else. Dean tells WIRED that he thinks weâ€™ll all need to find some sort of â€œgeneral purpose productâ€ â€” a conceptual mashup of software and hardware that completely reimagines the capabilities of a specific computer (or, more generally, a business) in order to tackle one task. Itâ€™ll probably require buy-in from product builders, analyst agnostics, human resources departments, call centers, product managers, and a few other well-intentioned minds, but Microsoft has a pretty good shot at that right now. Dean tells WIRED that while thereâ€™s certainly value in building product companies that â€œdo something interesting,â€ they also need to do it in a way that can tackle customer needs.
    </q>
  </p></div>

  <p><a onclick="plusSlides(-1)">â®</a>
  <a onclick="plusSlides(1)">â¯</a>
</p></div>

<p>See <a href="https://github.com/andreykurenkov/ai-news-analysis/edit/main/gpt2_articles.txt">here</a> for all the raw generated article snippets.</p>

<p>For those who are interested, see <a href="https://github.com/andreykurenkov/ai-news-analysis">here</a> for the code we used to generate the plots above as well as train and run the GPT-2 model. Or, play with the data right away by copying and messing around with this <a href="https://drive.google.com/file/d/1EXWDQvkksuV9Gursd9uE3ul6ZWR08fv3/view?usp=sharing">Colab Notebook</a>.</p>






    </div></div>]]>
            </description>
            <link>https://www.skynettoday.com/digests/ai-news-analysis</link>
            <guid isPermaLink="false">hacker-news-small-sites-26185936</guid>
            <pubDate>Thu, 18 Feb 2021 21:33:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Let's break CPython together, for fun and mischief]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26185831">thread link</a>) | @lochsh
<br/>
February 18, 2021 | https://mcla.ug/blog/cpython-hackage.html | <a href="https://web.archive.org/web/*/https://mcla.ug/blog/cpython-hackage.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
	
	<p><span>Sun 13 October 2019</span></p><p>I promise that nothing we do here will be useful.</p>
<p>But I promise it will be entertaining, and (hopefully) educational:</p>
<ul>
<li>
<p>if you don't know anything about the CPython internals, you're about to
learn (a bit)</p>
</li>
<li>
<p>if you do know about the CPython internals, you're hopefully about to
learn some new ways to abuse them ğŸ˜‰</p>
</li>
</ul>
<h2>Clarification</h2>
<p>Before we proceed to hackage, let me make sure it's clear what I'm talking
about when I say "CPython internals". CPython is the reference implementation
of Python, and it's what most people use. It's what comes as standard on any
system I've ever used.</p>
<p>A Python implementation includes the interpreter, the built-in types and the
standard library. With CPython, apart from much of the standard library which
is in Python, this is all written in C. There are other implementations:</p>
<ul>
<li>PyPy is written in Python itself and has a JIT compiler, it's really fast</li>
<li>Jython runs on the JVM</li>
<li>IronPython runs on .NET the Microsoft framework</li>
</ul>
<p>Everything we do here is exploiting the specific implementation details
of CPython.</p>
<h3>YMMV</h3>
<p>Please bear in mind that Python was not designed to do the things we're going
to do, and some of the fun things that worked with the version of Python I used
here, my operating system, &amp;c., might end up segfaulting for you. Running stuff
in ipython rather than the standard REPL will also likely end up with more
issues occurring when things are hacked.</p>
<h2>To whet your appetite</h2>
<p>Let's have a look at the Python language reference. The first two sentences of
the <a href="https://docs.python.org/3/reference/datamodel.html">data model</a> say this:</p>
<blockquote>
<p>Objects are Pythonâ€™s abstraction for data. All data in a Python program is
represented by objects or by relations between objects.</p>
</blockquote>
<p>In CPython a Python object is defined in the
<a href="https://github.com/python/cpython/blob/10e5c66789a06dc9015a24968e96e77a75725a7a/Include/object.h#L104"><code>PyObject</code></a>
struct:</p>

<div>
<pre id="vimCodeElement"><span id="L1">1 </span><span>typedef</span> <span>struct</span> _object {
<span id="L2">2 </span>    _PyObject_HEAD_EXTRA
<span id="L3">3 </span>    Py_ssize_t ob_refcnt;
<span id="L4">4 </span>    <span>struct</span> _typeobject *ob_type;
<span id="L5">5 </span>} PyObject;
</pre>
</div>

<p>(The first bit here, <code>_PyObject_HEAD_EXTRA</code>, is only valid when compiling Python
with a special tracing debugging feature, so don't worry about it.)</p>
<p>We have the reference count <code>ob_refcnt</code>, which is used for memory management
and tells us how many other objects are referencing this one. When the
reference count of an object is zero, its memory and resources can be freed by
the garbage collector.</p>
<p>We also have the type information, <code>ob_type</code>, which tells us how to interact
with the object, what its behaviour is, what data it contains.</p>
<p>Going back to the data model:</p>
<blockquote>
<p>Every object has an identity, a type and a value. An objectâ€™s identity never
changes once it has been created; you may think of it as the objectâ€™s address
in memory. The â€˜isâ€™ operator compares the identity of two objects; the id()
function returns an integer representing its identity.</p>
<p>CPython implementation detail: For CPython, id(x) is the memory address where
x is stored.</p>
</blockquote>
<p>So what I'd expect CPython to do is dynamically allocate memory for a new
<code>PyObject</code> each time we create a new object.</p>
<p>Let's test this out with some integers:</p>

<div>
<pre id="vimCodeElement"><span id="L1">1 </span>&gt;&gt;&gt; x = <span>500</span>
<span id="L2">2 </span>&gt;&gt;&gt; y = <span>500</span>
<span id="L3">3 </span>&gt;&gt;&gt; x <span>is</span> y
<span id="L4">4 </span><span>False</span>
</pre>
</div>

<p>That makes sense: a new <code>PyObject</code> has been allocated for each variable we've
made here, and so they are at different places in memory. But what if we use
smaller integers?</p>

<div>
<pre id="vimCodeElement"><span id="L1">1 </span>&gt;&gt;&gt; x = <span>5</span>
<span id="L2">2 </span>&gt;&gt;&gt; y = <span>5</span>
<span id="L3">3 </span>&gt;&gt;&gt; x <span>is</span> y
<span id="L4">4 </span><span>True</span>
</pre>
</div>

<p>How surprising! Let's have a look in the <a href="https://github.com/python/cpython/blob/10e5c66789a06dc9015a24968e96e77a75725a7a/Objects/longobject.c#L38">CPython
source</a>
to see why this might be:</p>

<div>
<pre id="vimCodeElement"><span id="L1"> 1 </span><span>#ifndef NSMALLPOSINTS</span>
<span id="L2"> 2 </span><span>#define NSMALLPOSINTS           </span><span>257</span>
<span id="L3"> 3 </span><span>#endif</span>
<span id="L4"> 4 </span><span>#ifndef NSMALLNEGINTS</span>
<span id="L5"> 5 </span><span>#define NSMALLNEGINTS           </span><span>5</span>
<span id="L6"> 6 </span><span>#endif</span>
<span id="L7"> 7 </span>
<span id="L8"> 8 </span>
<span id="L9"> 9 </span>
<span id="L10">10 </span>
<span id="L11">11 </span>
<span id="L12">12 </span>
<span id="L13">13 </span><span>static</span> PyLongObject small_ints[NSMALLNEGINTS + NSMALLPOSINTS];
</pre>
</div>

<p>So it seems integers between -5 and 256 inclusive are statically allocated in a
big old array!  This is an optimisation that CPython has chosen to do -- the
idea is that these integers are going to be used a lot, and it would be time
consuming to allocate new memory every time.</p>
<p>But...if that means some integers have a defined place in memory, can
we...corrupt that memory?</p>
<h2>import ctypes</h2>
<p><img alt="ctypes" src="https://mcla.ug/blog/images/goosebumpsctypes.jpg" title="Someone whispering 'import ctypes' and goosebumps appearing on the arm of the listener"></p>
<p>Most good CPython shenanigans begins with importing ctypes, which is Python's
standard C foreign function interface. An FFI allows different languages to
interoperate. ctypes provides C compatible data types and allows calling
functions from shared libraries and such.</p>
<p>The ctypes docs tell us about the function
<a href="https://docs.python.org/3.7/library/ctypes.html#ctypes.memmove"><code>memmove</code></a>:</p>
<blockquote>
<p>ctypes.memmove(dst, src, count)</p>
<p>Same as the standard C memmove library function: copies count bytes from
   src to dst. dst and src must be integers or ctypes instances that can be
   converted to pointers.</p>
</blockquote>
<p>So what if we copied the memory where 6 is to where 5 is?</p>

<div>
<pre id="vimCodeElement"><span id="L1">1 </span>&gt;&gt;&gt; <span>import</span> ctypes
<span id="L2">2 </span>&gt;&gt;&gt; <span>import</span> sys
<span id="L3">3 </span>&gt;&gt;&gt; ctypes.memmove(<span>id</span>(<span>5</span>), <span>id</span>(<span>6</span>), sys.getsizeof(<span>5</span>))
<span id="L4">4 </span>&gt;&gt;&gt; <span>5</span> + <span>5</span>
<span id="L5">5 </span><span>12</span>
</pre>
</div>

<p>What fun! But this is small fry stuff. We can do more. We have ambition.</p>
<h2>Ambition</h2>
<p>I don't what to change one integer. I want to change ALL the integers.</p>
<p>What if we changed what happens when you add integers together? What if we made
it subtract instead?</p>
<p><img alt="mischief" src="https://mcla.ug/blog/images/thearm.gif" title="The Arm from Twin Peaks rubbing his hands together mischeviously"></p>
<p>The way operator resolution works in Python is that the corresponding "magic
method" or "dunder method" (for double underscores) is called. For example <code>x +
y</code> will become <code>x.__add__(y)</code>. So the <code>int.__add__</code> method is going to be our
target for mischevious hackage.</p>

<div>
<pre id="vimCodeElement"><span id="L1">1 </span><span>def</span> <span>fake_add</span>(x, y):
<span id="L2">2 </span>    <span>return</span> x - y
<span id="L3">3 </span>&gt;&gt;&gt; <span>int</span>.__add__ = fake_add
<span id="L4">4 </span><span>TypeError</span>: can't set attributes of built-in/extension type <span>'</span><span>int</span><span>'</span>
</pre>
</div>

<p>Annoying, but unsurprising. Python is permissive in the sense that it doesn't
have access modifiers like C++ or Java â€“ you can't really define private
attributes of a class. But you can't do just anything, and patching built-ins like
this is one of the things Python prevents us from doing â€“ unless we try very
hard.</p>
<p>So what can we try instead?  All attribute resolution comes down to looking up
attribute names in an object's dictionary. For example, <code>x.y</code> would resolve to
<code>x.__dict__["y"]</code><sup id="fnref:1"><a href="#fn:1">1</a></sup>. What if we try accessing <code>int.__add__</code> that way?</p>

<div>
<pre id="vimCodeElement"><span id="L1">1 </span>&gt;&gt;&gt; <span>int</span>.__dict__[<span>"</span><span>__add__</span><span>"</span>] = fake_add
<span id="L2">2 </span><span>TypeError</span>: <span>'</span><span>mappingproxy</span><span>'</span> <span>object</span> does <span>not</span> support item assignment
</pre>
</div>

<p>Tarnation. But of course, we knew it would not be as easy as this. Perhaps lesser
programmers would give up here. "It's not allowed," they might say. But we are
strong and we are determined.</p>
<p>What is this
<a href="https://docs.python.org/3/library/types.html#types.MappingProxyType">mappingproxy</a> the interpreter speaks of?</p>
<blockquote>
<p>Read-only proxy of a mapping.</p>
</blockquote>
<p>Ok, so this is just some cast over the actual dictionary. If we can cast it to
a dictionary, we can assign to it. But doing this with a Python cast is just
creating a copy:</p>

<div>
<pre id="vimCodeElement"><span id="L1">1 </span>&gt;&gt;&gt; <span>dict</span>(<span>int</span>.__dict__)[<span>"</span><span>__add__</span><span>"</span>] = fake_add
<span id="L2">2 </span>&gt;&gt;&gt; <span>1</span> + <span>5</span>
<span id="L3">3 </span><span>6</span>
<span id="L4">4 </span>&gt;&gt;&gt; (<span>1</span>).__add__(<span>5</span>)
<span id="L5">5 </span><span>6</span>
<span id="L6">6 </span>&gt;&gt;&gt; <span>int</span>.__add__ == fake_add
<span id="L7">7 </span><span>False</span>
</pre>
</div>

<p>We need to go deeper. Let's look at the <a href="https://github.com/python/cpython/blob/10e5c66789a06dc9015a24968e96e77a75725a7a/Objects/descrobject.c#L954">CPython
source</a> for the mappingproxy type.</p>

<div>
<pre id="vimCodeElement"><span id="L1"> 1 </span><span>typedef</span> <span>struct</span> {
<span id="L2"> 2 </span>    PyObject_HEAD
<span id="L3"> 3 </span>    PyObject *mapping;
<span id="L4"> 4 </span>} mappingproxyobject;
<span id="L5"> 5 </span>
<span id="L6"> 6 </span><span>static</span> PyMappingMethods mappingproxy_as_mapping = {
<span id="L7"> 7 </span>    (lenfunc)mappingproxy_len,                  
<span id="L8"> 8 </span>    (binaryfunc)mappingproxy_getitem,           
<span id="L9"> 9 </span>    <span>0</span>,                                          
<span id="L10">10 </span>};
</pre>

</div>

<p>The <code>PyMappingMethods</code> of a type tell us how it behaves as a mapping: what does
<code>x[key]</code> do (<code>mp_subscript</code>)? What does <code>x[key] = y</code> do (<code>mp_ass_subscript</code>)?</p>
<p>What this is telling us is that the mapping proxy is basically a wrapper around
a normal dictionary with the function pointer to the subscript assignment
method set to NULL.</p>
<p>We can use ctypes to cast this and reveal the underlying dictionary.</p>

<div>
<pre id="vimCodeElement"><span id="L1"> 1 </span><span>import</span> ctypes
<span id="L2"> 2 </span>
<span id="L3"> 3 </span>
<span id="L4"> 4 </span><span>class</span> <span>PyObject</span>(ctypes.Structure):
<span id="L5"> 5 </span>    <span>pass</span>
<span id="L6"> 6 </span>
<span id="L7"> 7 </span>
<span id="L8"> 8 </span>PyObject._fields_ = [
<span id="L9"> 9 </span>    (<span>'</span><span>ob_refcnt</span><span>'</span>, ctypes.c_ssize_t)
<span id="L10">10 </span>    (<span>'</span><span>ob_type</span><span>'</span>, ctypes.POINTER(PyObject))
<span id="L11">11 </span>]
<span id="L12">12 </span>
<span id="L13">13 </span>
<span id="L14">14 </span><span>class</span> <span>MappingProxy</span>(PyObject):
<span id="L15">15 </span>    _fields_ = [(<span>'</span><span>dict</span><span>'</span>, ctypes.POINTER(PyObject))]
</pre>
</div>

<p>The trouble is, once we have the dict as a PyObject pointer, how do we get it
back to being a plain old Python dict?  It's no good doing this:</p>

<div>
<pre id="vimCodeElement"><span id="L1">1 </span>&gt;&gt;&gt; MappingProxy.from_address(<span>id</span>(<span>int</span>.__dict__)).dict
<span id="L2">2 </span>&lt;LP_PyObject at <span>0x7f6e98c8e7b8</span>&gt;
</pre>
</div>

<p>if we have no way to interpret this as a dict. We can use this pleasing wee
trick from the CPython API, courtesy of <a href="http://lucumr.pocoo.org/about/">Armin
Ronacher</a><sup id="fnref:2"><a href="#fn:2">2</a></sup>  which will put it as a value into another existing
dictionary where it will be interpreted the same as any other object, then we
can extract it!</p>

<div>
<pre id="vimCodeElement"><span id="L1"> 1 </span><span>def</span> <span>pyobj_cast</span>(obj):
<span id="L2"> 2 </span>    <span>return</span> ctypes.cast(<span>id</span>(obj), ctypes.POINTER(PyObject)
<span id="L3"> 3 </span>
<span id="L4"> 4 </span>
<span id="L5"> 5 </span><span>def</span> <span>get_dict</span>(proxy):
<span id="L6"> 6 </span>    dict_as_pyobj = MappingProxy.from_address(<span>id</span>(proxy)).dict
<span id="L7"> 7 </span>    fence = {}
<span id="L8"> 8 </span>    ctypes.pythonapi.PyDict_SetItem(
<span id="L9"> 9 </span>            pyobj_cast(fence),
<span id="L10">10 </span>            pyobj_cast(<span>"</span><span>victory</span><span>"</span>),
<span id="L11">11 </span>            dict_as_pyobj)
<span id="L12">12 </span>    <span>return</span> fence[<span>"</span><span>victory</span><span>"</span>]
<span id="L13">13 </span>
<span id="L14">14 </span>int_dict = get_dict(<span>int</span>.__dict__)
<span id="L15">15 </span>int_dict[<span>"</span><span>__add__</span><span>"</span>] = fake_add
</pre>
</div>

<p>Have we done it???</p>



<p>D'oh! But wait a minute...</p>



<p>What! But the data model says:</p>
<blockquote>
<p>to evaluate the expression x + y, where x is an instance of a class that has
an __add__() method, x.__add__(y) is called</p>
</blockquote>
<p>We've been lied to...this is clearly not true! It seems CPython has some
shortcut in place.</p>
<p>To be fair, they probably didn't think we'd ever find out this "lie" by
performing these shenanigans. We need to go yet deeper still to fulfill our
pointless quest. We <em>will</em> have control of the builtins.</p>
<h2>Full type mappings</h2>
<p>Back to the CPython source. What is in this type information that's in the
PyObject struct we looked at earlier? The answer: lots of stuff that I am not going to put here, but the most
interesting parts for our purposes are the <a href="https://github.com/python/cpython/blob/10e5c66789a06dc9015a24968e96e77a75725a7a/Doc/includes/typestruct.h#L16">method
suites</a>:</p>

<div>
<pre id="vimCodeElement"><span id="L1">1 </span><span>typedef</span> <span>struct</span> _typeobject {
<span id="L2">2 </span>    ...
<span id="L3">3 </span>    PyNumberMethods *tp_as_number;
<span id="L4">4 </span>    PySequenceMethods *tp_as_sequence;
<span id="L5">5 </span>    PyMappingMethods *tp_as_mapping;
<span id="L6">6 </span>    ...
<span id="L7">7 </span>} PyTypeObject;
</pre>
</div>

<p>This struct contains other structs defining the behaviour of the type
via function pointers. We're specifically interested in this
<a href="https://github.com/python/cpython/blob/10e5c66789a06dc9015a24968e96e77a75725a7a/Include/cpython/object.h#L95"><code>tp_as_number</code></a>
member. Its first member, <code>nb_add</code>, is the function pointer to the add
method. This is what we want to overwrite. This is our new target.</p>

<div>
<pre id="vimCodeElement"><span id="L1">1 </span><span>typedef</span> <span>struct</span> {
<span id="L2">2 </span>    binaryfunc nb_add;
<span id="L3">3 </span>    binaryfunc nb_subtract;
<span id="L4">4 </span>    binaryfunc nb_multiply;
<span id="L5">5 </span>    ...
<span id="L6">6 </span>} PyNumberMethods;
</pre>
</div>

<p>So, like we â€¦</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mcla.ug/blog/cpython-hackage.html">https://mcla.ug/blog/cpython-hackage.html</a></em></p>]]>
            </description>
            <link>https://mcla.ug/blog/cpython-hackage.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26185831</guid>
            <pubDate>Thu, 18 Feb 2021 21:26:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Bug on Aurora PostgreSQL 12 causes Autovacuum to hang forever]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26185711">thread link</a>) | @fdr
<br/>
February 18, 2021 | https://www.migops.com/blog/2021/02/15/a-bug-on-aurora-postgresql-12-causes-autovacuum-to-hang-forever/ | <a href="https://web.archive.org/web/*/https://www.migops.com/blog/2021/02/15/a-bug-on-aurora-postgresql-12-causes-autovacuum-to-hang-forever/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.migops.com/blog/2021/02/15/a-bug-on-aurora-postgresql-12-causes-autovacuum-to-hang-forever/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26185711</guid>
            <pubDate>Thu, 18 Feb 2021 21:18:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gleam 0.14 â€“ type-safe language for the Erlang VM]]>
            </title>
            <description>
<![CDATA[
Score 244 | Comments 38 (<a href="https://news.ycombinator.com/item?id=26185690">thread link</a>) | @lpil
<br/>
February 18, 2021 | https://gleam.run/news/gleam-v0.14-released/ | <a href="https://web.archive.org/web/*/https://gleam.run/news/gleam-v0.14-released/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <div>
<p>Hot on the heels of Gleam v0.13 comes another release, <a href="https://github.com/gleam-lang/gleam/releases/tag/v0.14.0">Gleam v0.14</a>!
As always, letâ€™s take a look at some of the highlights.</p>

<h2 id="dialyzer--erlang-typespecs">Dialyzer &amp; Erlang typespecs</h2>

<p>Many dynamically typed BEAM languages support Erlangâ€™s typespecs, type
annotations that can be analysed with the <a href="https://erlang.org/doc/man/dialyzer.html">Dialyzer</a> tool. While
not as powerful or reliable as Gleamâ€™s type system it can be a useful tool
for finding problems with your Erlang or Elixir code. Dialyzer doesnâ€™t
require typespecs but it can work better if they are added to the code.</p>

<p>Starting with this release Gleam will generate typespecs for all functions
and Erlang type definitions for all declared types within a Gleam program,
giving you one extra tool to help you write robust and reliable code when
using Gleam alongside Elixir or Erlang.</p>

<p>For a quick example, hereâ€™s some code in Gleam:</p>

<div><div><pre><code><span>pub</span> <span>type</span> <span>LinkedList</span><span>(</span><span>element</span><span>)</span> <span>{</span>
  <span>Empty</span>
  <span>Node</span><span>(</span><span>element</span><span>,</span> <span>LinkedList</span><span>(</span><span>element</span><span>))</span>
<span>}</span>

<span>pub</span> <span>fn</span> <span>is_empty</span><span>(</span><span>list</span><span>)</span> <span>{</span>
  <span>list</span> <span>==</span> <span>Empty</span>
<span>}</span>

<span>pub</span> <span>fn</span> <span>map</span><span>(</span><span>list</span><span>,</span> <span>fun</span><span>)</span> <span>{</span>
  <span>case</span> <span>list</span> <span>{</span>
    <span>Empty</span> <span>-&gt;</span> <span>Empty</span>
    <span>Node</span><span>(</span><span>i</span><span>,</span> <span>list</span><span>)</span> <span>-&gt;</span> <span>Node</span><span>(</span><span>fun</span><span>(</span><span>i</span><span>),</span> <span>map</span><span>(</span><span>list</span><span>,</span> <span>fun</span><span>))</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>And hereâ€™s the Erlang code and typespecs it compiles to:</p>

<div><div><pre><code><span>-</span><span>module</span><span>(</span><span>linked_list</span><span>).</span>
<span>-</span><span>compile</span><span>(</span><span>no_auto_import</span><span>).</span>

<span>-</span><span>export</span><span>([</span><span>is_empty</span><span>/</span><span>1</span><span>,</span> <span>map</span><span>/</span><span>2</span><span>]).</span>
<span>-</span><span>export_type</span><span>([</span><span>linked_list</span><span>/</span><span>1</span><span>]).</span>

<span>-</span><span>type</span> <span>linked_list</span><span>(</span><span>H</span><span>)</span> <span>::</span> <span>empty</span> <span>|</span> <span>{</span><span>node</span><span>,</span> <span>H</span><span>,</span> <span>linked_list</span><span>(</span><span>H</span><span>)}.</span>

<span>-</span><span>spec</span> <span>is_empty</span><span>(</span><span>linked_list</span><span>(</span><span>any</span><span>()))</span> <span>-&gt;</span> <span>boolean</span><span>().</span>
<span>is_empty</span><span>(</span><span>List</span><span>)</span> <span>-&gt;</span>
    <span>List</span> <span>=:=</span> <span>empty</span><span>.</span>

<span>-</span><span>spec</span> <span>map</span><span>(</span><span>linked_list</span><span>(</span><span>R</span><span>),</span> <span>fun</span><span>((</span><span>R</span><span>)</span> <span>-&gt;</span> <span>U</span><span>))</span> <span>-&gt;</span> <span>linked_list</span><span>(</span><span>U</span><span>).</span>
<span>map</span><span>(</span><span>List</span><span>,</span> <span>Fun</span><span>)</span> <span>-&gt;</span>
    <span>case</span> <span>List</span> <span>of</span>
        <span>empty</span> <span>-&gt;</span>
            <span>empty</span><span>;</span>

        <span>{</span><span>node</span><span>,</span> <span>I</span><span>,</span> <span>List</span><span>@</span><span>1</span><span>}</span> <span>-&gt;</span>
            <span>{</span><span>node</span><span>,</span> <span>Fun</span><span>(</span><span>I</span><span>),</span> <span>map</span><span>(</span><span>List</span><span>@</span><span>1</span><span>,</span> <span>Fun</span><span>)}</span>
    <span>end</span><span>.</span>
</code></pre></div></div>

<p>No annotations are required at all in your Gleam code to get full typespec
coverage, Gleamâ€™s compiler reuses the type information from its powerful type
inference algorithm to determine the correct typespecs.</p>

<p>Thank you <a href="https://gitlab.com/greggreg">Greg</a> for this brilliant new feature!</p>

<h2 id="erlang-escripts">Erlang escripts</h2>

<p>Erlang projects are unusual in that typically instead of having a <code>main</code>
function as the entrypoint of your application you define a tree of actors to
come online and process items of work while your program is running.</p>

<p>This can be a powerful way to write long-lived services that make use of the
runtimeâ€™s fault tolerance features, but it does not lend itself well to
short-lived programs such as command line scripts. It can be confusing to
newcomers from other languages too.</p>

<p>For these short lived programs Erlang <a href="https://erlang.org/doc/man/escript.html">escripts</a> are typically used.
These are lightweight Erlang programs that have a <code>main</code> function as an entrypoint.</p>

<p>To make it easier to use these from Gleam the <code>gleam new</code> command now has an
escript template that can be used to create an escript project without any
further configuration required.</p>

<div><div><pre><code>gleam new my_script <span>--template</span> escript
</code></pre></div></div>

<p>A world class developer experience is a key goal of the Gleam project.
Further tooling improvements are right around the corner!</p>

<h2 id="night-mode">Night mode</h2>

<p>Gleam has the ability to render <a href="https://hexdocs.pm/gleam_stdlib/">HTML documentation</a> 
for your code, ready to upload to Hexdocs.</p>

<p>Thanks to <a href="https://github.com/tynanbe">Tynan Beatty</a> the documentation is
looking better than ever! Thereâ€™s too many improvements to list but the big
one is they now have a night mode! If youâ€™re a night owl like me Iâ€™m sure you
will enjoy the lower contrast dark tones when doing some late evening coding.</p>

<p><img src="https://gleam.run/images/news/gleam-v0.14-released/night-mode.png" alt="A screenshot of Gleam's rendered docs showing a beautiful dark theme"></p>

<h2 id="better-errors-again">Better errors, again</h2>

<p>At the risk of sounding like a broken record Gleamâ€™s error messages have been
improved yet again. Hereâ€™s an example of one of the improvements:</p>

<p>Before:</p>

<div><div><pre><code>error: Syntax error
    â”Œâ”€ /src/thing.gleam:115:18
    â”‚
115 â”‚ pub fn overlappedBy(compare, a, b) -&gt; Bool {
    â”‚                  ^^ I was not expecting this.

Expected one of: "("
</code></pre></div></div>

<p>Now:</p>

<div><div><pre><code>error: Syntax error
    â”Œâ”€ /src/thing.gleam:115:18
    â”‚
115 â”‚ pub fn overlappedBy(compare, a, b) -&gt; Bool {
    â”‚                  ^^ This is not a valid name.

Hint: Names start with a lowercase letter and contain a-z, 0-9, or _.
Try: overlapped_by
</code></pre></div></div>

<p>Thank you to <a href="https://github.com/samontea">Samuel Mercier</a> and <a href="https://github.com/pd-andy">Andy
Thompson</a> for these.</p>

<h2 id="static-bit-string-validation">Static bit string validation</h2>

<p>Bit string syntax is a feature that Gleam inherits from Erlang. It provides a
way to declartively and concisely construct and manipulate raw bits of data
through literals and pattern matching.</p>

<p>With this Gleam release we apply further static analysis to bit string
literals and patterns used in Gleam programs to catch invalid or incorrect
code.</p>

<p>Hereâ€™s an example of one of the errors that may be reported:</p>

<div><div><pre><code>error: Syntax error
  â”Œâ”€ /Users/a/parser_test/src/a.gleam:2:20
  â”‚
2 â”‚   &lt;&lt;1:size(1)-unit(0)&gt;&gt;
  â”‚                    ^ This is not a valid BitString unit value.

Hint: unit must be an integer literal &gt;= 1 and &lt;= 256
See: https://gleam.run/book/tour/bit-strings
</code></pre></div></div>

<p>Thank you <a href="https://gitlab.com/greggreg">Greg</a> for this bit string safety net.</p>

<h2 id="docker-images">Docker images</h2>

<p>Up until now <a href="https://github.com/CrowdHailer">Peter Saxton</a> has been very kindly
building Gleam docker images for use in <a href="https://sendmemo.app/">Memo</a> and the
wider community.</p>

<p>With this release he has ported his build automation over to the Gleam repo
so we have automation creation of OCI/Docker images built and published
automatically with each release.</p>

<p>We are building these variants:</p>

<ul>
  <li><code>gleam-erlang</code>: Gleam and the Erlang tooling on Ubuntu Linux</li>
  <li><code>gleam-erlang-slim</code>: Gleam and the Erlang tooling on slim Debian Linux</li>
  <li><code>gleam-erlang-alpine</code>: Gleam and the Erlang tooling on Alpine Linux</li>
  <li><code>gleam-elixir</code>: Gleam and the Elixir tooling on Ubuntu Linux</li>
  <li><code>gleam-elixir-slim</code>: Gleam and the Elixir tooling on slim Debian Linux</li>
  <li><code>gleam-elixir-alpine</code>: Gleam and the Elixir tooling on Alpine Linux</li>
</ul>

<p>For all the images see the <a href="https://github.com/orgs/gleam-lang/packages/container/package/gleam">Gleam image registry</a>. Thanks Peter!</p>

<h2 id="other-stuff">Other stuff</h2>

<p>These are just some of the highlights, but thereâ€™s plenty more improvements
made to the compiler and the standard library since the last release. For all
the details check out the changelog files:</p>

<ul>
  <li><a href="https://github.com/gleam-lang/gleam/blob/main/CHANGELOG.md">Gleamâ€™s changelog</a></li>
  <li><a href="https://github.com/gleam-lang/stdlib/blob/main/CHANGELOG.md">Gleam stdlibâ€™s changelog</a></li>
</ul>

<h2 id="discord-chat">Discord chat</h2>

<p>Itâ€™s time to plug the Gleam Discord server again! The community continues to
grow and it would be great to have you there too, so please click on the
button below.</p>

<center>
  <a href="https://discord.gg/Fm8Pwmy"><img src="https://img.shields.io/discord/768594524158427167?color=blue" alt="Discord chat"></a>
</center>

<h2 id="try-it-out">Try it out</h2>

<p>If you want to try out the new version of Gleam head over to the <a href="https://gleam.run/getting-started/">getting started
page</a>. Iâ€™d love to hear how you find it and get your feedback so
Gleam can continue to improve.</p>

<p>Want to view some existing Gleam projects? Head on over to the
<a href="https://github.com/gleam-lang/awesome-gleam">awesome-gleam</a> list. Looking for something to build in
Gleam? Check out <a href="https://github.com/gleam-lang/suggestions/issues">the suggestions tracker</a>.</p>

<h2 id="supporting-gleam">Supporting Gleam</h2>

<p>If you would like to help make strongly typed programming on the Erlang
virtual machine a production-ready reality please consider <strong><a href="https://github.com/sponsors/lpil">sponsoring
Gleam</a></strong> via the GitHub Sponsors program.</p>

<p>â­ Or alternatively give us a star on <a href="https://github.com/gleam-lang/gleam">GitHub</a>! â­</p>

<p>This release would not have been possible without the support of all the
people who have <a href="https://github.com/sponsors/lpil">sponsored</a> and contributed
to it, so a huge thank you to them.</p>

<ul>
  <li><a href="https://github.com/adamnbowen">Adam Bowen</a></li>
  <li><a href="https://github.com/amokan">Adam Mokan</a></li>
  <li><a href="https://github.com/aditya7iyengar">Adi Iyengar</a></li>
  <li><a href="https://github.com/scripttease">Al Dee</a></li>
  <li><a href="https://github.com/mudriyjo">Alexander Babin</a></li>
  <li><a href="https://github.com/farhadi">Ali Farhadi</a></li>
  <li><a href="https://github.com/pd-andy">Andy Thompson</a></li>
  <li><a href="https://github.com/bees">Arian Daneshvar</a></li>
  <li><a href="https://github.com/arnodirlam">Arno Dirlam</a></li>
  <li><a href="https://github.com/benmyles">Ben Myles</a></li>
  <li><a href="https://github.com/nono">Bruno Michel</a></li>
  <li><a href="https://github.com/brightly-salty">Caden Haustein</a></li>
  <li><a href="https://github.com/choonkeat">Chew Choon Keat</a></li>
  <li><a href="https://github.com/chrislloyd">Chris Lloyd</a></li>
  <li><a href="https://github.com/worldofchris">Chris Young</a></li>
  <li><a href="https://github.com/tlvenn">Christian Meunier</a></li>
  <li><a href="https://github.com/clangley">clangley</a></li>
  <li><a href="https://github.com/cleverbunny">Clever Bunny LTD</a></li>
  <li><a href="https://github.com/codec-abc">codec-abc</a></li>
  <li><a href="https://github.com/colelawrence">Cole Lawrence</a></li>
  <li><a href="https://github.com/connorlay">Connor Lay (Clay)</a></li>
  <li><a href="https://github.com/cschembor3">Connor Schembor</a></li>
  <li><a href="https://github.com/unthought">Dan Mueller</a></li>
  <li><a href="https://github.com/davydog187">Dave Lucia</a></li>
  <li><a href="https://github.com/rawkode">David McKay</a></li>
  <li><a href="https://github.com/davidpdrsn">David Pedersen</a></li>
  <li><a href="https://github.com/dangdennis">Dennis Dang</a></li>
  <li><a href="https://github.com/lostbean">Edgar Gomes</a></li>
  <li><a href="https://github.com/ericmj">Eric Meadows-JÃ¶nsson</a></li>
  <li><a href="https://github.com/eterps">Erik Terpstra</a></li>
  <li><a href="https://github.com/floriank">Florian Kraft</a></li>
  <li><a href="https://github.com/itsgreggreg">greggreg</a></li>
  <li><a href="https://github.com/ggpasqualino">Guilherme Pasqualino</a></li>
  <li><a href="https://github.com/hendi">Hendrik Richter</a></li>
  <li><a href="https://github.com/hhandoko">Herdy Handoko</a></li>
  <li><a href="https://github.com/human154">human154</a></li>
  <li><a href="https://github.com/Ian-GL">Ian GonzÃ¡lez</a></li>
  <li><a href="https://github.com/igagen">Ingmar Gagen</a></li>
  <li><a href="https://github.com/ivarvong">Ivar Vong</a></li>
  <li><a href="https://github.com/gampleman">Jakub Hampl</a></li>
  <li><a href="https://github.com/jamesmacaulay">James MacAulay</a></li>
  <li><a href="https://github.com/janpieper">Jan Pieper</a></li>
  <li><a href="https://github.com/jechol">Jechol Lee</a></li>
  <li><a href="https://github.com/jeffkreeftmeijer">Jeff Kreeftmeijer</a></li>
  <li><a href="https://github.com/jiangplus">jiangplus</a></li>
  <li><a href="https://github.com/joecorkerton">Joe Corkerton</a></li>
  <li><a href="https://github.com/Jwsonic">John Palgut</a></li>
  <li><a href="https://github.com/josevalim">JosÃ© Valim</a></li>
  <li><a href="https://github.com/jveiga">JoÃ£o Veiga</a></li>
  <li><a href="https://github.com/jmn">Jussi Norlund</a></li>
  <li><a href="https://github.com/kapp-technology">Kapp Technology</a></li>
  <li><a href="https://github.com/kodeFant">Lars Lillo Ulvestad</a></li>
  <li><a href="https://github.com/lawik">Lars Wikman</a></li>
  <li><a href="https://github.com/leandrocp">Leandro Cesquini Pereira</a></li>
  <li><a href="https://github.com/malcolmseyd">Malcolm Seyd</a></li>
  <li><a href="https://github.com/mario-mazo">mario</a></li>
  <li><a href="https://github.com/mvellandi">Mario Vellandi</a></li>
  <li><a href="https://github.com/markmark206">Mark Markaryan</a></li>
  <li><a href="https://github.com/markusfeyh">Markus</a></li>
  <li><a href="https://github.com/derhechi">Markus Hechenberger</a></li>
  <li><a href="https://github.com/MattCheely">Matthew Cheely</a></li>
  <li><a href="https://github.com/bausano">Michael Bausano</a></li>
  <li><a href="https://github.com/michaeljones">Michael Jones</a></li>
  <li><a href="https://github.com/michallepicki">MichaÅ‚ ÅÄ™picki</a></li>
  <li><a href="https://github.com/mroach">Mike Roach</a></li>
  <li><a href="https://github.com/slashmili">Milad</a></li>
  <li><a href="https://github.com/ndreynolds">Nick Reynolds</a></li>
  <li><a href="http://www.ninefx.com/">NineFX</a></li>
  <li><a href="https://github.com/jraregris">Oddmund StrÃ¸mme</a></li>
  <li><a href="https://github.com/sorentwo">Parker Selbert</a></li>
  <li><a href="https://github.com/phiat">Patrick Ryan</a></li>
  <li><a href="https://github.com/PeteJodo">Pete Jodo</a></li>
  <li><a href="https://github.com/CrowdHailer">Peter Saxton</a></li>
  <li><a href="https://github.com/praveenperera">Praveen Perera</a></li>
  <li><a href="https://github.com/qingliangcn">qingliangcn</a></li>
  <li><a href="https://github.com/happysalada">Raphael Megzari</a></li>
  <li><a href="https://github.com/chouzar">RaÃºl  Humberto Chouza Delgado</a></li>
  <li><a href="https://github.com/redmar">Redmar Kerkhoff</a></li>
  <li><a href="https://github.com/reneklacan">RenÃ© KlaÄan</a></li>
  <li><a href="https://github.com/romatthe">Robin Mattheussen</a></li>
  <li><a href="https://github.com/rvcas">rvcas</a></li>
  <li><a href="https://github.com/samaaron">Sam Aaron</a></li>
  <li><a href="https://github.com/samontea">samontea</a></li>
  <li><a href="https://github.com/mrgleam">Santi</a></li>
  <li><a href="https://github.com/sascha-wolf">Sascha Wolf</a></li>
  <li><a href="https://github.com/sasa1977">SaÅ¡a JuriÄ‡Ã§</a></li>
  <li><a href="https://github.com/scottwey">Scott Wey</a></li>
  <li><a href="https://github.com/seanjensengrey">Sean Jensen-Grey</a></li>
  <li><a href="https://github.com/sporto">Sebastian</a></li>
  <li><a href="https://github.com/shanesveller">Shane Sveller</a></li>
  <li><a href="https://github.com/shritesh">Shritesh Bhattarai</a></li>
  <li><a href="https://github.com/simonewebdesign">Simone Vittori</a></li>
  <li><a href="https://github.com/syukronrm">Syukron Rifail M</a></li>
  <li><a href="https://github.com/terkiterje">Terje Bakken</a></li>
  <li><a href="https://github.com/timbuchwaldt">Tim Buchwaldt</a></li>
  <li><a href="https://github.com/tomekowal">Tomasz Kowal</a></li>
  <li><a href="https://github.com/thara">Tomochika Hara</a></li>
  <li><a href="https://github.com/topherhunt">Topher Hunt</a></li>
  <li><a href="https://github.com/tsloughter">Tristan Sloughter</a></li>
  <li><a href="https://github.com/twilco">Tyler Wilcock</a></li>
  <li><a href="https://github.com/tynanbe">tynanbe</a></li>
  <li><a href="https://github.com/wojtekmach">Wojtek Mach</a></li>
</ul>

<p>Thanks for reading! Have fun! ğŸ’œ</p>

</div>

</article></div>]]>
            </description>
            <link>https://gleam.run/news/gleam-v0.14-released/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26185690</guid>
            <pubDate>Thu, 18 Feb 2021 21:16:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Over 140K virus species identified in human gut, 50% never seen before]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26185338">thread link</a>) | @finphil
<br/>
February 18, 2021 | https://nuadox.com/post/643491384977948672/140k-virus-species-in-human-gut | <a href="https://web.archive.org/web/*/https://nuadox.com/post/643491384977948672/140k-virus-species-in-human-gut">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="643491384977948672">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/643491384977948672/140k-virus-species-in-human-gut"><h2>Over 140K virus species identified in human gut, 50% never seen before</h2></a>
                                <figure data-orig-width="1280" data-orig-height="904"><img src="https://64.media.tumblr.com/1a0215a61c5578609506d640223a0ec8/5275df9a1bb2e1fe-38/s1280x1920/64f1e6d38b7d741e57ff618b396d3322a825dc76.jpg" alt="image" data-orig-width="1280" data-orig-height="904" width="1280" height="904"></figure><p><b>- By <a href="https://href.li/?https://www.sanger.ac.uk/">Wellcome Sanger Institute</a> -</b></p><p>

Viruses are the most numerous biological entities on the planet. Now researchers at the Wellcome Sanger Institute and EMBLâ€™s European Bioinformatics Institute (EMBL-EBI) have identified over 140,000 viral species living in the human gut, more than half of which have never been seen before.

<br></p><p>The paper, published today in <i><a href="https://href.li/?https://doi.org/10.1016/j.cell.2021.01.029">Cell</a></i>, contains an analysis of over 28,000 gut microbiome samples collected in different parts of the world. The number and diversity of the viruses the researchers found was surprisingly high, and the data opens up new research avenues for understanding how viruses living in the gut affect human health.</p><p>The human gut is an incredibly biodiverse environment. In addition to bacteria, hundreds of thousands of viruses called bacteriophages, which can infect bacteria, also live in the human gut.</p><p>It is known that imbalances in our gut microbiome can contribute to diseases and complex conditions such as Inflammatory Bowel Disease, allergies and obesity. But relatively little is known about the role our gut bacteria, and the bacteriophages that infect them, play in human health and disease.</p><p>Using a DNA-sequencing method called metagenomics*, researchers at the Wellcome Sanger Institute and EMBLâ€™s European Bioinformatics Institute (EMBL-EBI) explored and catalogued the biodiversity of the viral species found in 28,060 public human gut metagenomes and 2,898 bacterial isolate genomes cultured from the human gut.</p><p>The analysis identified over 140,000 viral species living in the human gut, more than half of which have never been seen before.</p><h2>â€œItâ€™s important to remember that not all viruses are harmful, but represent an integral component of the gut ecosystem. For one thing, most of the viruses we found have DNA as their genetic material, which is different from the pathogens most people know, such as SARS-CoV-2 or Zika, which are RNA viruses. Secondly, these samples came mainly from healthy individuals who didnâ€™t share any specific diseases. Itâ€™s fascinating to see how many unknown species live in our gut, and to try and unravel the link between them and human health.â€<b><br></b></h2><p><b>Dr Alexandre Almeida, Postdoctoral Fellow at EMBL-EBI and the Wellcome Sanger Institute</b><br></p><p>Among the tens of thousands of viruses discovered, a new highly prevalent clade â€“ or group of viruses believed to have a common ancestor â€“ was identified, which the authors refer to as the Gubaphage. This was found to be the second most prevalent virus clade in the human gut, after the crAssphage, which was discovered in 2014.</p><p>Both of these viruses seem to infect similar types of human gut bacteria, but without further research itâ€™s very difficult to know the exact functions of the newly discovered Gubaphage.</p><h2>â€œAn important aspect of our work was to ensure that the reconstructed viral genomes were of the highest quality. A stringent quality control pipeline coupled with a machine learning approach enabled us to mitigate contamination and obtain highly complete viral genomes. High-quality viral genomes pave the way to better understand what role viruses play in our gut microbiome, including the discovery of new treatments such as antimicrobials from bacteriophage origin.â€<br></h2><p><b><a href="https://href.li/?https://www.sanger.ac.uk/person/camarillo-guerrero-luis-fernando/">Dr Luis F. Camarillo-Guerrero,</a>&nbsp;first author of the study from the Wellcome Sanger Institute</b></p><p>

The results of the study form the basis of the Gut Phage Database (GPD), a highly curated database containing 142,809 non-redundant phage genomes that will be an invaluable resource for those studying bacteriophages and the role they play on regulating the health of both our gut bacteria and ourselves.

<br></p><h2>â€œBacteriophage research is currently experiencing a renaissance. This high-quality, large-scale catalogue of human gut viruses comes at the right time to serve as a blueprint to guide ecological and evolutionary analysis in future virome studies.â€</h2><p><b><a href="https://href.li/?https://www.sanger.ac.uk/person/lawley-trevor/">Dr Trevor Lawley,</a>&nbsp;senior author of the study from the Wellcome Sanger Institute</b></p><p>â€“</p><p><i>

* Metagenomics is the study of a collection of genetic material (genomes) from a mixed community of organisms. Metagenomics usually refers to the study of microbial communities. The NIH National Human Genome Research Institute has more information here: <a href="https://href.li/?https://www.genome.gov/genetics-glossary/Metagenomics" title="* this link opens in a new window/tab">https://www.genome.gov/genetics-glossary/Metagenomics</a></i><br></p><p><b>Source:&nbsp;<a href="https://href.li/?https://www.sanger.ac.uk/news_item/scientists-identify-over-140000-virus-species-in-the-human-gut-half-of-which-are-new-to-science/">Wellcome Sanger Institute</a></b></p><p><b>Full study:</b>&nbsp;â€œMassive expansion of human gut bacteriophage diversityâ€,&nbsp;<i>Cell</i>.</p><p><a href="https://href.li/?https://doi.org/10.1016/j.cell.2021.01.029">https://doi.org/10.1016/j.cell.2021.01.029</a><br></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/611601599114231808/fruit-fly-gut-microbiome">We could perhaps learn a lot by looking into a fruit flyâ€™s gut</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/virus">virus</a>
                                    
                                        <a href="https://nuadox.com/tagged/gut">gut</a>
                                    
                                        <a href="https://nuadox.com/tagged/biology">biology</a>
                                    
                                        <a href="https://nuadox.com/tagged/microbiology">microbiology</a>
                                    
                                        <a href="https://nuadox.com/tagged/bacteriophage">bacteriophage</a>
                                    
                                        <a href="https://nuadox.com/tagged/molecular-biology">molecular biology</a>
                                    
                                        <a href="https://nuadox.com/tagged/dna">dna</a>
                                    
                                        <a href="https://nuadox.com/tagged/genomics">genomics</a>
                                    
                                    </p>
                                </span></p>
                                
                            </div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/643491384977948672/140k-virus-species-in-human-gut</link>
            <guid isPermaLink="false">hacker-news-small-sites-26185338</guid>
            <pubDate>Thu, 18 Feb 2021 20:52:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DeepDow â€“ Portfolio Optimization with Deep Learning]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26185234">thread link</a>) | @optimalsolver
<br/>
February 18, 2021 | https://jankrepl.github.io/deepdow/ | <a href="https://web.archive.org/web/*/https://jankrepl.github.io/deepdow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
        
        <p>
   <img src="https://i.imgur.com/x77b8Lc.png" width="80%">
</p>


<p><a href="https://github.com/jankrepl/deepdow">DeepDow</a> is a Python package that focuses on neural networks that are able to perform asset allocation in a single forward pass.</p>


<p>Portfolio optimization is traditionally a two step procedure</p>

<ol>
  <li>Creation of beliefs about the future performance of securities</li>
  <li>Finding optimal portfolio given these beliefs</li>
</ol>

<p>One notorious example of the two step procedure (inspired by Markowitz) is</p>

<ol>
  <li>Estimation of expected returns \(\mu\) and covariance matrix $\boldsymbol{\Sigma}$</li>
  <li>Solving a convex optimization problem, e.g. $\boldsymbol{\mu}^T \textbf{w} - \gamma \textbf{w}^T  \boldsymbol{\Sigma} \textbf{w}$ such that $\textbf{w} &gt; 0$ and ${\bf 1}^T \textbf{w}=1$.</li>
</ol>

<p>Commonly, these two steps are absolutely separated since they require different approaches and different software.</p>

<p><code>deepdow</code> absolutely abandons this paradigm. It strives to merge the above mentioned two steps into one. The fundamental idea is to construct end-to-end deep networks that input the rawest features (returns, volumes, â€¦) and output asset allocation. This approach has multiple benefits:</p>

<ul>
  <li>Hyperparameters can be turned into trainable weights (i.e. ğ›¾ in 2nd stage)</li>
  <li>Leveraging deep learning to extract useful features for allocation, no need for technical indicators</li>
  <li>Single loss function</li>
</ul>


<p>Financial timeseries can be seen a 3D tensor with the following dimensions</p>

<ul>
  <li>time</li>
  <li>asset</li>
  <li>indicator/channel</li>
</ul>

<p>To give a specific example, one can investigate daily (time dimension) open price returns, close price returns and volumes (channel dimension) of multiple NASDAQ stocks (asset dimension). Graphically, one can imagine</p>

<p>
   <img src="https://i.imgur.com/RYcdN6y.png" width="55%">
</p>

<p>By fixing a time step (representing now), we can split our tensor into 3 disjoint subtensors</p>

<p>
   <img src="https://i.imgur.com/rsttnxn.png" width="50%">
</p>

<p>Firstly, <strong>x</strong> represents all the knowledge about the past and present. The second tensor <strong>g</strong> represents information contained in the immediate future that we cannot use to make investment decisions. Finally, <strong>y</strong> is the future evolution of the market. One can now move along the time dimension and apply the same decomposition at every time step. This method of generating a dataset is called the rolling window.</p>

<p>Now we focus on a special type of neural networks that input <strong>x</strong> and return a single weight allocation <strong>w</strong> over all assets such that $\sum_{i} w_{i} = 1$. In other words, given our past knowledge <strong>x</strong> we construct a portfolio <strong>w</strong> that we buy right away and hold for horizon time steps. Let <strong>F</strong> be some neural network with parameters ğœƒ, the below image represents the high level prediction pipeline.</p>
<p>
   <img src="https://i.imgur.com/sJ30WFE.png" width="65%">
</p>

<p>The last piece of the puzzle is definition of the loss function. In the most general terms, the per sample loss <strong>L</strong> is any function that inputs <strong>w</strong> and <strong>y</strong> and outputs a real number. However, in most cases we first compute the portfolio returns <strong>r</strong> over each time step in the horizon and then apply some summarization function <strong>S</strong> like mean, standard deviation, etc.</p>

<p>
   <img src="https://i.imgur.com/L0A2bRS.png" width="95%">
</p>


<p>Ok, but how do we construct such networks? Rather than hardcoding a single architecture <code>deepdow</code> implements powerful building blocks (layers) that the user can put together himself. The two most important groups of layers are</p>

<ul>
  <li><strong>Transformation</strong> layers: The goal is to extract features from the inputs
    <ul>
      <li>RNN</li>
      <li>1D convolutions</li>
      <li>Time warping</li>
      <li>â€¦</li>
    </ul>
  </li>
  <li><strong>Allocation</strong> layers: Given input tensors they output a valid asset allocation
    <ul>
      <li>Differentiable convex optimization (<code>cvxpylayers</code>) i.e. Markowitz</li>
      <li>Softmax (sparse and constrained variants as well)</li>
      <li>Clustering based allocators</li>
      <li>â€¦</li>
    </ul>
  </li>
</ul>

<p>The general pattern is to create a pipeline of multiple transformation layers followed by a single allocation layer at the end. Note that almost
any real valued hyperparameter can be turned into a learnable parameter or even predicted by some subnetwork.</p>


<p>If this article sparked your interest, feel free to check the below links.</p>

<ul>
  <li><a href="https://github.com/jankrepl/deepdow">GitHub</a></li>
  <li><a href="https://deepdow.readthedocs.io/en/latest/auto_examples/end_to_end/getting_started.html#sphx-glr-auto-examples-end-to-end-getting-started-py">Getting started tutorial</a></li>
  <li><a href="https://deepdow.readthedocs.io/">Docs</a></li>
  <li><a href="https://deepdow.readthedocs.io/en/latest/auto_examples/index.html">More examples</a></li>
</ul>

<p>I will be more than happy to answer any questions. Additionally, constructive criticism or help with development is much welcomed.</p>






        
      </section></div>]]>
            </description>
            <link>https://jankrepl.github.io/deepdow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26185234</guid>
            <pubDate>Thu, 18 Feb 2021 20:42:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bad Software and Expensive Mistakes]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26185082">thread link</a>) | @mattmarcus
<br/>
February 18, 2021 | https://www.moderntreasury.com/journal/bad-software-and-expensive-mistakes | <a href="https://web.archive.org/web/*/https://www.moderntreasury.com/journal/bad-software-and-expensive-mistakes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Recently, thereâ€™s been discussion about an accidental $900 million wire that Citibank sent out while Revlon was restructuring some of its debt. You can read the details <a href="https://www.bloomberg.com/opinion/articles/2021-02-17/citi-can-t-have-its-900-million-back" target="_blank">here</a>, but in short, the payment escaped controls and was completed, and when the team realized their mistake they asked for their money back. But they <a href="https://arstechnica.com/tech-policy/2021/02/citibank-just-got-a-500-million-lesson-in-the-importance-of-ui-design/" target="_blank">couldnâ€™t</a> get it all back.<br></p><p>Although $900 million is an astonishing number, Citibank is not alone. In 2018 Deutsche Bank accidentally wired an exchange <a href="https://money.cnn.com/2018/04/19/investing/deutsche-bank-35-billion-mistake/index.html" target="_blank">$35 billion</a> â€” $5 billion more than the bank was worth at the time. The worst â€œfat-fingerâ€ mistake I know of happened in Tokyo in 2005, when a trader filed a share order worth <a href="https://spectrum.ieee.org/riskfactor/computing/it/japan-traders-617-billion-fat-finger-nearmiss-rattles-tokyo-market" target="_blank">$617 billion</a> and sent it to the exchange.<br></p><p>These types of errors happen all the time, and theyâ€™re entirely the fault of software, not people.&nbsp;<br></p><p>The Citibank case goes to the heart of why we started Modern Treasury.&nbsp;<br></p><p>In 2015, Sam and I started building a marketplace for individuals to invest in the renovation loans that LendingHome was making. Building a â€œfractionalâ€ marketplace <a href="#1">[1]</a> increases the number of transactions in a system. When it really started working, it exploded the number of payments we made â€” from hundreds to tens of thousands per month â€” and thatâ€™s when we started uncovering the many issues that we now call â€œpayment operations.â€<br></p><p>In spite of being the lifeblood of every business, there has been a dearth of modern software built for payment operations in the past half century. So I wanted to share a few of our near misses and provide a perspective on why we believe so passionately that payment operations deserves great software.&nbsp;</p><h4>Could Citiâ€™s Mistake Have been Prevented?&nbsp;<br></h4><p>There are several levels.<br></p><p>Hereâ€™s a screenshot of the <a href="https://www.oracle.com/industries/financial-services/banking/flexcube-universal-banking/" target="_blank">Flexcube</a> product that the team at Citibank used for this transaction. The team wanted to pay out interest but not loan principal, but in order to do so the software required an internal â€œwashâ€ account, and a process that involved checking three boxes (and no less: checking only one doesnâ€™t trigger any alerts.) I think we can agree that this product is less than intuitive to use.<br></p><figure><p><img src="https://assets.website-files.com/5d7e7bbbcad517dd46cb55d3/602ec598b91eff48eb08f141_flexcube.png" loading="lazy" alt=""></p></figure><p>In addition to being simple to use, a payment ops product needs to be flexible. For this team, there is no API, so the workflow had been hard-coded years before. It was so out of date that the team had to have a <a href="https://www.bloomberg.com/opinion/articles/2021-02-17/citi-can-t-have-its-900-million-back" target="_blank">manual</a> to instruct how to work around it. The reason the high amount was being typed in at all was that this â€œsoftware will only let you pay principal to some lenders if you pretend to pay it to every lenderâ€ (<a href="https://www.bloomberg.com/opinion/articles/2021-02-17/citi-can-t-have-its-900-million-back" target="_blank">source</a>). The workflow is so rigid itâ€™s all or nothing.</p><p>Finally, controls. The Citibank team went through three levels of approvals over email. A good payment operations system should dynamically route payments to the right person or persons for release, but only if those users get the information they need to make an informed decision. Over email, that doesnâ€™t happen.&nbsp;</p><p>Good people operating bad software will eventually make a mistake.&nbsp;<br>â€<br></p><h3>How Software Like This Gets Built</h3><h4>Act One: The Tech Team Wants to Talk to the Bank</h4><p>The first realization we had when we set out to solve this problem at LendingHome was that in order to make payments, you must do so through your bank. But banks do not have clean APIs. To compensate, we had to build a custom bank integration.&nbsp;</p><p>The US has a single system for wire transfers, the Fedwire system, and that is the common denominator across all banks. But each bank then operates its own â€œbank coreâ€ software on top of the Fedwire system, and that software maintains accounts and ledgers, records transactions, and so on. The bank therefore actually has a separate interface. So we now have two interfaces:&nbsp;</p><p>Customer -- Bank -- Fedwire</p><p>Building on these interfaces takes investment of time and resources, because bank cores are challenging to integrate with and understand. Some banks use <a href="https://www.moderntreasury.com/journal/what-is-direct-transmission" target="_blank">Direct Transmission</a> over SFTP while others provide SOAP APIs. Timings <a href="https://docs.moderntreasury.com/reference#ach-timings" target="_blank">vary</a>. There are different, competing, data exchange formats for things like reporting on errors, and the configurations can vary from banks on identical cores.&nbsp;<br></p><p>When pressed for resources, teams cut corners. Itâ€™s hard to justify investing in wonderful design and robust systems for internal processes, so much of whatâ€™s out there is half-built, inflexible, and non-intuitive, and rarely gets any attention from the design team.&nbsp;<br></p><p>The result of poor software is workarounds. We had finance colleagues who had Excel wizard skills and a tolerance for manual process pain at which we marveled, but at some point even they would come down to the engineering floor and, in a desperate cry for help, ask us to â€œJUST COMPUTER IT!â€<br></p><p>(We registered that domain a couple of years later. Check out <a href="http://www.justcomputerit.com/" target="_blank">www.justcomputerit.com</a> the next time youâ€™re frustrated with a payment ops problem.)</p><h4>Act Two: Itâ€™s Not One Bank, Itâ€™s Many</h4><p>Itâ€™s not just a single bank integration problem. Itâ€™s many.<br></p><p>Most companies, once they become somewhat large, operate on more than one bank. So not only does the engineering team have to understand and integrate with one bank, they have to repeat that process for each subsequent bank from scratch, and as we have seen, thatâ€™s a scary proposition.<br></p><p>Now we have many integrations:<br></p><p>Customer&nbsp;<br>-- Bank 1 -- Fedwire<br>-- Bank 2 -- Fedwire<br>-- Bank 3 -- Fedwire<br>-- Bank 4 -- Fedwire<br></p><div><p>Every bank is a unique filter on the Fedwire system, making it even harder to make it flexible, intuitive software. The challenges of a single bank integration are now proliferating, and the engineering team tasked with this has to grow.</p></div><h4>Act Three: The Controller Wants Control</h4><p>Thereâ€™s good reasons why bank relationships are sensitive. After all, the executive team has a fiduciary responsibility to make sure company funds are safe and secure at all times. The CFO and their team are concerned about the prospect of the engineering team building an integration to talk to the bank and move money around whenever they want. Not to mention that with each money movement, the accounting team has to track, tag, and reconcile every dollar that moves in and out of every bank account.<br></p><p>â€œMove fast and break thingsâ€ is quite literally the worst way to sell software to CFOs.&nbsp;<br></p><p>So now we discover the next layer of issues: a good bank integration is necessary but not sufficient. There must be a smart, easy-to-use, and intuitive app for the controller that allows them to manage the process. Some of the features this app must have include the ability to create rules to manage the API, to monitor what is happening, and to provide context and trigger approvals for actions that are unexpected.&nbsp;<br></p><p>One such surprise happened to us when we were subleasing office space from Salesforce. The accounting team saw a giant payment to Salesforce and came over to us, angry and flustered that someone irresponsible had sent Salesforce several salariesâ€™ worth of cash for what should have been a few CRM seats. We were amused as we had to explain that indeed, the payment was made to Salesforce, yes, that Salesforce, but no, it wasnâ€™t for software. It was rent.&nbsp;<br></p><h4>Bonus Act: Idempotency and Reversibility</h4><p>There are some very specific engineering concerns that anyone building a payment ops system has to keep in mind.&nbsp;<br></p><p>The first one is idempotency, or doing things only once. We put together a post on <a href="https://www.moderntreasury.com/journal/why-idempotency-matters-in-payments" target="_blank">â€œWhy Idempotency Matters in Payments</a>,â€ which I highly encourage anyone working in payments to read, because the only thing worse than sending the wrong amount is sending it twice.&nbsp;<br></p><p>We lived this. One day we accidentally double-funded every mortgage: many millions of dollars, paid out twice. That was not a good day. Mercifully, because mortgages are disbursed to <a href="https://www.moderntreasury.com/journal/how-to-build-an-escrow-product" target="_blank">escrow</a>, we got all the funds back, but we never forgot idempotency matters in payments after that day.&nbsp;<br></p><div><p>Wires are not reversible, which makes mistakes particularly scary. There are other payment types, such as ACH, that are. If you sent an ACH and you didnâ€™t mean to, or if someone debits your account without your permission, you can reverse it.<a href="#2">[2]</a> Approvals are important, but theyâ€™re particularly important for irreversible transactions, such as the wire Citi sent and couldnâ€™t recall after sending.&nbsp;</p></div><h4>Thinking About Payment Ops as a Single Continuous Process</h4><p>Steve Jobs said, â€œDesign is not just what it looks like and feels like. Design is how it works.â€&nbsp;<br></p><p>This sums up how we believe payment operations should run. Rather than have many silos for information â€” from a database to a CSV to a bank portal to an accounting system â€” we believe in a single piece of payment operations software. This software crosses systems and, perhaps most importantly, it crosses teams. The tech team wants to live in the <a href="https://www.moderntreasury.com/developer-solutions" target="_blank">API</a>, the finance team wants to live in the <a href="https://www.moderntreasury.com/finance-solutions" target="_blank">app</a>, accountants need <a href="https://www.moderntreasury.com/journal/introducing-continuous-accounting" target="_blank">continuous accounting</a>, and customer service teams need to <a href="https://www.moderntreasury.com/journal/how-customer-support-teams-use-modern-treasury" target="_blank">answer customer requests</a>.&nbsp;<br></p><p>Weâ€™ve written at length in the <a href="https://www.moderntreasury.com/journal" target="_blank">Modern Treasury Journal</a> about these issues. ACH, wire, and paper check account for the <a href="https://www.moderntreasury.com/journal/b2b-payments-vs-c2b-payments-what-makes-them-so-different" target="_blank">vast majority</a> of payments in the US, and yet have seen very little innovation in the last fifty years.&nbsp;<br></p><p>We believe that will change this decade. <a href="https://angel.co/company/moderntreasury/jobs" target="_blank">Join us</a>, <a href="https://app.moderntreasury.com/sign_up" target="_blank">build with us</a>, and <a href="https://www.moderntreasury.com/journal" target="_blank">learn with us</a>.&nbsp;<br></p></div></div><div><h4>References</h4><div><div id="1"><p>A fractional loan marketplace is one where each loan is sold not to one institutional investor but to many individuals. This means that every repayment of that loan has to be split between all the investors that &nbsp;invested in each loan, and therefore number of individual transactions in the system balloons.</p></div><div id="2"><div><p>There are lots of ACH return codes, and you can check out our post on <a href="https://www.moderntreasury.com/journal/what-happens-when-you-ach-a-dead-person" target="_blank">What Happens When You ACH a Dead Person </a>to learn more about those.</p></div></div></div></div></div>]]>
            </description>
            <link>https://www.moderntreasury.com/journal/bad-software-and-expensive-mistakes</link>
            <guid isPermaLink="false">hacker-news-small-sites-26185082</guid>
            <pubDate>Thu, 18 Feb 2021 20:32:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Series A to Revolutionize Computing]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26184594">thread link</a>) | @tosh
<br/>
February 18, 2021 | https://blog.repl.it/seriesa | <a href="https://web.archive.org/web/*/https://blog.repl.it/seriesa">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>Our mission is to give everyone in the world <strong>computer superpowers</strong>. We build powerful yet approachable tools &amp; platforms for developers, students, and educators.</p>
<p>We see a new generation of hackers and entrepreneurs rising to seize the power of computers and the internet to create software that empowers them and their communities. They refuse to be programmed by the software priesthood that wants them to endlessly consume ads. Instead, they build a more free society where computers work for and under human users, not the other way around. The world we're describing is coming, and we exist to accelerate the shift.</p>
<p><img src="https://repl.art/replit.png" alt="art"></p>
<p>Replit is a multiplayer computing environment that makes it <a href="https://blog.replit.com/internet-of-fun">fun</a> to learn how to code, build, and <a href="https://repl.it/talk/share">share apps</a> with other people. You can create a cloud-powered computer in milliseconds -- we call them "repls" -- and you can create as many of them as you'd like, all for free. Repls come with storage for your code and files, a <a href="https://blog.repl.it/database">database</a> for your data, and a <a href="https://repl.it/site/multiplayer">multiplayer editor</a> &amp; console to code with your friends. For <a href="https://repl.it/pricing">$7/month</a>, you'll get more powerful machines and, with one-click, make them <a href="https://blog.repl.it/alwayson">run forever</a>.</p>
<p><img src="https://blog.repl.it/images/database/database1.gif" alt="db"></p>
<p>When you invite a friend to your repl, you can see them in your editor and talk to them <a href="https://blog.repl.it/annotations-for-education">right in your code</a>. You can make <a href="https://docs.repl.it/repls/http-servers">web</a>, <a href="https://blog.repl.it/native-graphics-love">desktop</a>, and even command-line apps. Replit takes care of the entire process of <a href="https://docs.repl.it/repls/web-hosting">publishing and hosting apps</a> so you can focus on your ideas.</p>
<p><img src="https://venturebeat.com/wp-content/uploads/2021/02/Live-Code-Editing.gif?resize=800%2C450&amp;strip=all" alt="multiplayer"></p>
<p>When you've built something you want to share, you can share the <a href="https://blog.replit.com/spotlight">repl URL</a>, and your users can play with your app, react to it, comment on it, and even fork and remix it. Replit gives you a profile to keep and showcase all your apps and repls. You can make <a href="https://repl.it/site/teams">shared team profiles</a> for your class, friends, or company to collaborate on repls.</p>
<p><img src="https://blog.repl.it/images/spotlight/ios-demo.gif" alt="share"></p>
<p>Because you can make a repl in milliseconds, Replit makes it fun and safe to experiment with ideas. Learning comes naturally as a side effect of playing in the Replit ecosystem.</p>
<p>Millions of people have learned how to code with Replit and built great apps with thousands of happy users. Some have even built businesses and become rich &amp; famous.</p>
<p>Replit's design principles:</p>
<ul>
<li><p><strong>Learnable yet scalable interfaces</strong>: Interfaces today present the same UI to vastly different users, from children to adults, from novices to experts. Our mission demands that we make computing environments more accessible to novices while making it possible to transition to more powerful interfaces. Replit starts with a simple editor and console, which gets learners very far. The UI, however, is adaptable and presents different faces to different users and use-cases.</p>
</li>
<li><p><strong>Infrastructure as legos</strong>: A core part of commanding computer power is to be able to build for the modern internet-connected world. Despite progress in cloud computing, infrastructure remains inaccessible to novices, hobbyists, and educators. We change this by designing simple and scalable components, like cloud-hosted servers accessible right from the repl, storage, databases, etc., that require little configuration and maintenance by the programmer. Coders can then mix and match components to create endless possibilities.</p>
</li>
<li><p><strong>People-centric technology</strong>: It's more exciting and fun to create and learn with other people. The future demands that computers and the internet have human interconnectedness as a core primitive. From our multiplayer computing protocol to our community spaces for sharing software, we build support for human beings, and we put collaboration right at the heart of our technology.</p>
</li>
</ul>
<h2 id="series-a">Series A</h2>
<p>As a team, we've always thought about the long-term, and we've grown Replit responsibly. We have so much conviction in our mission and our plan that we're willing to take our time. </p>
<p>Last year, with rapid growth in all aspects of our business, we felt it was a good time to raise a sizeable round to make faster progress our mission. We raised <a href="https://venturebeat.com/2021/02/18/replit-raises-20-million-for-collaborative-browser-based-coding/">$20M in Series A</a> financing led by <a href="https://acapital.com/">A.Capital</a> with strong participation from our seed investors: Andreessen Horowitz, Bloomberg Beta, Y Combinator, and Reach Capital. </p>
<p>Since then, thanks to the new capital and to <a href="https://amasad.me/moad">Engelbartian Bootstrapping</a>, we've accelerated feature development, and there's so much more on the horizon: extra resources for more complex projects, support for any language or package, further dev ops simplifications for novices and pros, business collaboration features, improvements to <a href="https://repl.it/teams-for-education">teacher workflows</a>, high quality content, a game development library, and more breakthroughs in collaborative coding. We're excited to see all the amazing things you build with the tools we provide!</p>
<p>Finally, we're hiring for multiple roles and want to bring on people who share our vision and passion. If you're interested in making computing more accessible while working with a creative and hardworking team building fantastic technology, <a href="https://repl.it/careers">join us</a>!</p>

	</div></div>]]>
            </description>
            <link>https://blog.repl.it/seriesa</link>
            <guid isPermaLink="false">hacker-news-small-sites-26184594</guid>
            <pubDate>Thu, 18 Feb 2021 19:53:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pocket Guide: Business Writing for Startup Founders]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26184367">thread link</a>) | @qnd
<br/>
February 18, 2021 | https://www.artlapinsch.com/writing-for-founders/ | <a href="https://web.archive.org/web/*/https://www.artlapinsch.com/writing-for-founders/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              <p>Clear writing is important. </p><p>Especially if you are running a company.</p><ul><li>It is faster to read</li><li>It leaves no room for confusion</li><li>It makes the next steps obvious</li></ul><hr><p>To write more clearly, apply the following:</p><h2 id="active-speech">Active Speech</h2><p>Don't write <em>"the report was prepared by our sales lead."</em></p><p>Instead, write <em>"Our sales lead prepared the report."</em></p><h2 id="no-redundancies">No Redundancies</h2><p>Don't write <em>"the successful campaign had positive results."</em></p><p>Instead, write <em>"the campaign was successful."</em></p><h2 id="specificity">Specificity</h2><p>Don't write <em>"we processed a lot of requests in the past few weeks."</em></p><p>Instead write, <em>"from 2/12/2020 - 3/11/2020 we processed 500+ requests."</em></p><h2 id="structure">Structure</h2><p>Don't write without a structure.</p><p>Instead, pick a structure <em>(bullets; headlines; etc.)</em> and stick with it.</p><h2 id="narrative">Narrative</h2><p>Don't go from A to Z to B to D.</p><p>Instead, go from A to B to C <em>(beginning, middle, end)</em>.</p><h2 id="next-steps">Next Steps</h2><p>Don't leave next steps open for interpretation. </p><p>Instead, communicate who <em>(owner)</em>, will do what<em> (task)</em>, and by when <em>(ETA)</em>.</p><hr><p>Save time. Show direction. Trigger action.</p><p>Write clearly. </p><hr><p><em>Someone helped me with these tips many years ago. I hope it helps you.</em></p><p><em>If you have feedback, thoughts, or want to get in touch, ping me on <a href="https://twitter.com/artlapinsch">twitter</a>.</em></p><!--kg-card-begin: html--><!-- Begin Mailchimp Signup Form -->




<!--End mc_embed_signup--><!--kg-card-end: html--><hr><h3 id="further-reading">Further Reading</h3><ul><li><strong><a href="https://www.google.com/search?client=safari&amp;rls=en&amp;q=the+day+you+became+a+better+writer+scott+adams&amp;ie=UTF-8&amp;oe=UTF-8">The Day You Became a Better Write</a></strong> <em>(Scott Adams)</em></li><li><strong><a href="https://www.artlapinsch.com/writing-guide/">A Guide to Better Writing</a></strong> <em>(Art Lapinsch) </em>ğŸ‘ˆ<em> </em>This is an in-depth guide with 35 of my favorite resources on writing</li></ul>
                <section>
                  
                  <ul>
                      <li>
                        <a href="https://www.artlapinsch.com/tag/guide/" title="guide">guide</a>
                      </li>
                  </ul>
                </section>
            </div></div>]]>
            </description>
            <link>https://www.artlapinsch.com/writing-for-founders/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26184367</guid>
            <pubDate>Thu, 18 Feb 2021 19:32:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Coronavirus in Slovakia: What Is Going On]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26184366">thread link</a>) | @scandox
<br/>
February 18, 2021 | https://spectator.sme.sk/c/22598901/coronavirus-in-slovakia-what-is-going-on.html | <a href="https://web.archive.org/web/*/https://spectator.sme.sk/c/22598901/coronavirus-in-slovakia-what-is-going-on.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The answer is just three words.</p><div><p><a href="https://m.smedata.sk/api-media/media/image/spectator/9/68/6821849/6821849_1200x.jpeg?rev=3"><img alt="Mathematician Richard KollÃ¡r during the press conference in the Presidential Palace on February 16, 2021. " src="https://m.smedata.sk/api-media/media/image/spectator/9/68/6821849/6821849_600x400.jpeg?rev=3"><span><span><svg width="30px" height="30px"><use xlink:href="#svg-icon-magnifier"></use></svg><span></span></span></span></a><span><small>Mathematician Richard KollÃ¡r during the press conference in the Presidential Palace on February 16, 2021.  (Source: TASR)</small></span></p></div><article data-article-stats-id="22598901" id="js-article" data-user-login-url="https://prihlasenie.sme.sk"><p><span data-deep-event-tags="position-top"><span><span title="pÃ´vodnÃ¡ veÄ¾kosÅ¥ pÃ­sma">Font size:</span><span title="zmenÅ¡iÅ¥ pÃ­smo"><span data-ga-event-id="gaev-art-toolbox" data-ga-event-category="article_toolbox_top" data-ga-event-action="fontminus">A</span><sup>-</sup></span>|<span title="zvÃ¤ÄÅ¡iÅ¥ pÃ­smo"><span data-ga-event-id="gaev-art-toolbox" data-ga-event-category="article_toolbox_top" data-ga-event-action="fontplus">A</span><sup>+</sup></span></span></span></p>
<p><em>Richard KollÃ¡r is a mathematician. He delivered this speech during the press conference after a meeting of scientists with President Zuzana ÄŒaputovÃ¡ on February 16, 2021. </em></p><p>I am a mathematician and I will speak exclusively about numbers and data. I will answer one question, often posed by journalists and the wider public - how we are doing and what is going on regarding the pandemic in Slovakia.</p><p>The answer is very simple. Just three words.</p><p>We don't know. We don't know, in fact.</p><p>I will try to sum up all the things we do not know.</p><p>We are missing absolutely key data to be able to assess the effects of our measures, and the epidemiological situation we are in.</p><p>We have no clue how many people are arriving to hospitals as new patients, we have no clue how many are leaving the hospitals. We therefore cannot say what is causing the increase in the number of hospitalisations we are seeing.</p><p>We don't know that about ventilators either, because the numbers we have do not match. When you put the arrivals and the departures in an equation, you do not get the number we have got now.</p><p>We don't know the age of the hospital patients, so we don't know what's going on.</p><p>We don't know how many infections are hospital-acquired.</p><p>We don't know how many patients are transferred from Covid to non-Covid wards in hospitals.</p><p>We don't know what is the structure of the tests we are performing.</p><p>We don't now how many tests have been done per health indication in hospitals, how many were indicated by epidemiologists or self-indicated.</p><p>We don't know how many tests were part of screening.</p><p>We don't know how many tests are performed in hospitals and what are their results.</p><p>We have no information about tracing.</p><p>We don't now exactly how many people have been traced and how many have been indicated as positive. We don't know how many of the people who were found through tracing ended up in hospitals.</p><p>We don't know what the effectiveness of our tracing is.</p><p>We don't know where the problem lies.</p><p>We don't know about the new variants. We probably have the best tests in Europe to find that out. We are the only country with tests for the British strain. Yet we still don't know how its prevalence developed in the Slovak samples in January. We have looked at one day's sample, but we have no clue how it developed in time. Even though there have been promises and interest in doing that, we still do not have that data.</p><p>We haven't learned from the regional public health offices where Slovak citizens become infected.</p><p>We don't know if it is safe to go to the store. We don't know if it is safe to travel by public transport.</p><p>We don't know how many people got infected where and we do not report such numbers.</p><p>We don't know how the opening of schools last week went, and how many have been closed.</p><p>We don't know how many people have passed through the border crossings and we don't know which countries they came from; how many then end up positive and hospitalised.</p><p>As for the tests proposed by the Education Ministry, we don't know how they have been validated and what are their parametres. We know they are being purchased, but we don't have a clue what they will look like.</p><p>When we apply  theCovid automat, we don't know how its parametres are assessed. We cannot assess the incidence because the numbers of PCR and antigen tests are counted together. PCR tests are reported based on the person's permanent residence, antigen tests are reported based on the testing site location.</p><p>We don't know how things stand with hospitalisations.</p><p>We have no idea how to calculate the reproduction number, which is why we don't dare to announce it during press conferences.</p><p>We have no clue how these three parametres are combined and evaluated on the level of districts.</p><p>We don't know why some districts have the colour they have.</p><p>We don't know why the Health Ministry laid off 10 percent of its staff as part of the corona-crisis measures just like other ministries, and why they have not reinforced the analytical units.</p><p>We are in a data hell. And we don't know if we are facing another wave; if it will be stronger than the one we are going through, or milder.</p><p>We don't know if we are facing the same fate as the Czech city of Cheb, where a quarter of a percent of its inhabitants have died in the past five weeks. Perhaps Slovakia is facing the same.</p><p>We don't know, we have no way of knowing what is going on.</p><p>
            17. Feb 2021 at 13:15
        &nbsp;|&nbsp;Richard KollÃ¡r
    
    </p></article></div>]]>
            </description>
            <link>https://spectator.sme.sk/c/22598901/coronavirus-in-slovakia-what-is-going-on.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26184366</guid>
            <pubDate>Thu, 18 Feb 2021 19:31:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IBM Apollo/Saturn Press Information [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26184346">thread link</a>) | @Felonius_Monk
<br/>
February 18, 2021 | https://www.apollopresskits.com/cs/c/?cta_guid=69bda2b0-603b-4c91-bf30-c3d425396f31&signature=AAH58kE89ooPCBnAEHIF6NwUgRUo-tIeiA&pageId=7962764933&placement_guid=00362abe-1f60-422e-99aa-75f5e9edf2e9&click=76a4887d-6ed6-41ad-8f35-f49bfbfb5ef6&hsutk=c7a00000190d1bd81cf30177b699595f&canon=https%3A%2F%2Fwww.apollopresskits.com%2Fapollo-presskit-directory&utm_referrer=https%3A%2F%2Fpinboard.in%2Fu%3Amichaelcolenso%2Fbefore%3A1569472943&portal_id=413105&redirect_url=APefjpE9rO6ok2BaATb973oLgLwidfs4zRYwQVkhov4aq3jijtJU9oC3_MkthEIQajAD2N7OYtegEpDri0ocRWxVVLga-zgB54CWPGlhDPe5Hs7yGVQ4i-Bg8al-HsINkLxHD7A5NZMRQuOTY2HFAYJ1b50AuY62q-AzqiHpeVCtj-WgsQyex1s | <a href="https://web.archive.org/web/*/https://www.apollopresskits.com/cs/c/?cta_guid=69bda2b0-603b-4c91-bf30-c3d425396f31&signature=AAH58kE89ooPCBnAEHIF6NwUgRUo-tIeiA&pageId=7962764933&placement_guid=00362abe-1f60-422e-99aa-75f5e9edf2e9&click=76a4887d-6ed6-41ad-8f35-f49bfbfb5ef6&hsutk=c7a00000190d1bd81cf30177b699595f&canon=https%3A%2F%2Fwww.apollopresskits.com%2Fapollo-presskit-directory&utm_referrer=https%3A%2F%2Fpinboard.in%2Fu%3Amichaelcolenso%2Fbefore%3A1569472943&portal_id=413105&redirect_url=APefjpE9rO6ok2BaATb973oLgLwidfs4zRYwQVkhov4aq3jijtJU9oC3_MkthEIQajAD2N7OYtegEpDri0ocRWxVVLga-zgB54CWPGlhDPe5Hs7yGVQ4i-Bg8al-HsINkLxHD7A5NZMRQuOTY2HFAYJ1b50AuY62q-AzqiHpeVCtj-WgsQyex1s">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>&gt;&gt;'&gt;7&gt;G&gt;W&gt;g&gt;w&gt;â€¡&gt;â€”&gt;Â§&gt;Â·&gt;Ã‡&gt;Ã—&gt;Ã§&gt;Ã·???'?7?G?W?g?x?Ë†?Ëœ?Â¨?Â¸?Ãˆ?Ã™?Ã©?Ã¹@	@@*@:@J@Z@k@{@â€¹@Å“@Â¬@Â¼@Ã@Ã@Ã­@Ã¾AAA/A?AOA`ApAï¿½Aâ€˜AÂ¢AÂ²AÃƒAÃ“AÃ¤AÃ´BBB&amp;B6BGBWBhBxBâ€°BÅ¡BÂªBÂ»BÃ‹BÃœBÃ­BÃ½CCC/C@CQCaCrCÆ’Câ€CÂ¤CÂµCÃ†CÃ—CÃ§CÃ¸D	DD+D;DLD]DnDDï¿½DÂ¡DÂ²DÃ‚DÃ“DÃ¤DÃµEEE(E9EJE[ElE}EÅ½EÅ¸EÂ°EÃEÃ’EÃ£EÃ´FFF(F9FJF[FlF}Fï¿½F&nbsp;FÂ±FÃ‚FÃ“FÃ¤FÃ¶GGG)G;GLG]GnGâ‚¬Gâ€˜GÂ¢GÂ´GÃ…GÃ–GÃ¨GÃ¹H
HH-H?HPHaHsHâ€Hâ€“HÂ§HÂ¹HÃŠHÃœHÃ­HÃ¿II"I3IEIVIhIzIâ€¹Iï¿½IÂ®IÃ€IÃ’IÃ£IÃµJJJ*J;JMJ_JqJâ€šJâ€JÂ¦JÂ·JÃ‰JÃ›JÃ­JÃ¿KK"K4KFKXKiK{Kï¿½KÅ¸KÂ±KÃƒKÃ•KÃ§KÃ¹L
LL.L@LRLdLvLË†LÅ¡LÂ¬LÂ¾LÃLÃ¢LÃ´MMM+M=MOMaMsMâ€¦Mâ€”MÂ©MÂ¼MÃMÃ MÃ²NNN)N;NMN_NrNâ€Nâ€“NÂ©NÂ»NÃNÃŸNÃ²OOO)O;ONO`OrOâ€¦Oâ€”OÂªOÂ¼OÃOÃ¡OÃ³PPP+P=PPPbPuPâ€¡PÅ¡PÂ­PÂ¿PÃ’PÃ¤PÃ·Q	QQ/QAQTQgQyQÅ’QÅ¸QÂ±QÃ„QÃ—QÃ©QÃ¼RR"R4RGRZRmRâ‚¬Râ€™RÂ¥RÂ¸RÃ‹RÃRÃ±SSS)S<sosbsusË†sâ€ºsÂ®sÃsÃ”sÃ§sÃºt t="" t3tftytlttâ€™tÂ¥tÂ¸tÃ‹tÃtÃ²uuu+u="">UQUeUxUâ€¹UÅ¾UÂ±UÃ…UÃ˜UÃ«UÃ¾VV%V8VKV_VrVâ€¦Vâ„¢VÂ¬VÂ¿VÃ“VÃ¦VÃºW
W W4WGW[WnWâ€šWâ€¢WÂ©WÂ¼WÃWÃ£WÃ·X
XX1XEXXXlXâ‚¬Xâ€œXÂ§XÂºXÃXÃ¢XÃµY	YY0YDYXYkYYâ€œYÂ§YÂºYÃYÃ¢YÃ¶Z	ZZ1ZEZYZlZâ‚¬Zâ€ZÂ¨ZÂ¼ZÃZÃ¤ZÃ¸[[[3[G[[[o[Æ’[â€”[Â«[Â¿[Ã“[Ã§[Ã»\\#\7\K\`\t\Ë†\Å“\Â°\Ã„\Ã˜\Ã¬]]])]=]Q]e]z]Å½]Â¢]Â¶]Ã‹]ÃŸ]Ã³^^^0^D^Y^m^â€š^â€“^Âª^Â¿^Ã“^Ã§^Ã¼__%_9_N_b_w_â€¹_&nbsp;_Â´_Ã‰_Ã_Ã²```/`D`X`m`â€š`â€“`Â«`Â¿`Ã”`Ã©`Ã½aa'a;aPaeazaÅ½aÂ£aÂ¸aÃaÃ¡aÃ¶bb b5bIb^bsbË†bï¿½bÂ²bÃ‡bÃ›bÃ°ccc/cDcYcncÆ’cËœcÂ­cÃ‚cÃ—cÃ¬ddd+d@dUdjddâ€¢dÂªdÂ¿dÃ”dÃ©dÃ¾ee)e&gt;eSehe}eâ€œeÂ¨eÂ½eÃ’eÃ¨eÃ½ff'f=fRfgf}fâ€™fÂ§fÂ½fÃ’fÃ¨fÃ½gg(g=gSghg~gâ€œgÂ©gÂ¾gÃ”gÃ©gÃ¿hh*h?hUhjhâ‚¬hâ€“hÂ«hÃhÃ–hÃ¬iii-iCiXiniâ€iâ„¢iÂ¯iÃ…iÃ›iÃ°jjj2jHj]jsjâ€°jÅ¸jÂµjÃŠjÃ jÃ¶kk"k8kNkdkzkï¿½kÂ¦kÂ¼kÃ’kÃ¨kÃ¾ll*l@lVlllâ€šlËœlÂ®lÃ„lÃšlÃ°mmm3mIm_mumâ€¹mÂ¡mÂ¸mÃmÃ¤mÃºnn'n=nSnjnâ‚¬nâ€“nÂ­nÃƒnÃ™nÃ°ooo3oIo`ovoÅ’oÂ£oÂ¹oÃoÃ¦oÃ½pp*p@pWpmpâ€pÅ¡pÂ±pÃ‡pÃpÃ´qq"q8qOqfq|qâ€œqÂªqÃ€qÃ—qÃ®rrr2rHr_rvrï¿½rÂ¤rÂºrÃ‘rÃ¨rÃ¿ss,sCsZsqsË†sÅ¸sÂ¶sÃsÃ¤sÃºtt(t?tVtmtâ€tâ€ºtÂ²tÃ‰tÃ tÃ·uu&amp;u=uTukuâ€šuâ„¢uÂ°uÃ‡uÃuÃ¶v
v$v;vRvjvï¿½vËœvÂ¯vÃ‡vÃvÃµww$w;wRwjwï¿½wËœwÂ°wÃ‡wÃwÃ¶x
x%x<xtxkxâ€šxÅ¡xÂ±xÃ‰xÃ xÃ¸yy'y>yVynyâ€¦yï¿½yÂ´yÃŒyÃ£yÃ»zz*zBzZzqzâ€°zÂ¡zÂ¸zÃzÃ¨{{{/{G{_{v{Å½{Â¦{Â¾{Ã–{Ã®|||5|M|e|}|â€¢|Â­|Ã…|Ãœ|Ã´}}$}&lt;}T}l}â€}Å“}Â´}Ã}Ã¥}Ã½~~-~E~]~u~ï¿½~Â¥~Â¾~Ã–~Ã®7Ogâ€”Â°ÃˆÃ Ã¹â‚¬â‚¬)â‚¬Aâ‚¬Zâ‚¬râ‚¬Å â‚¬Â£â‚¬Â»â‚¬Ã”â‚¬Ã¬ï¿½ï¿½ï¿½5ï¿½Nï¿½fï¿½ï¿½â€”ï¿½Â°ï¿½Ãˆï¿½Ã¡ï¿½Ã¹â€šâ€š*â€šCâ€š[â€štâ€šÅ’â€šÂ¥â€šÂ¾â€šÃ–â€šÃ¯Æ’Æ’ Æ’9Æ’QÆ’jÆ’Æ’Æ’â€ºÆ’Â´Æ’ÃÆ’Ã¥Æ’Ã¾â€â€0â€Hâ€aâ€zâ€â€œâ€Â¬â€Ã„â€Ãâ€Ã¶â€¦â€¦(â€¦Aâ€¦Zâ€¦râ€¦â€¹â€¦Â¤â€¦Â½â€¦Ã–â€¦Ã¯â€ â€ !â€ :â€ Sâ€ lâ€ â€¦â€ Å¾â€ Â·â€ Ãâ€ Ã©â€¡â€¡â€¡4â€¡Mâ€¡gâ€¡â‚¬â€¡â„¢â€¡Â²â€¡Ã‹â€¡Ã¤â€¡Ã½Ë†Ë†0Ë†IË†bË†{Ë†â€¢Ë†Â®Ë†Ã‡Ë†Ã Ë†Ãºâ€°â€°,â€°Fâ€°_â€°xâ€°â€˜â€°Â«â€°Ã„â€°Ãâ€°Ã·Å Å *Å CÅ ]Å vÅ ï¿½Å Â©Å Ã‚Å ÃœÅ Ãµâ€¹â€¹(â€¹Bâ€¹[â€¹uâ€¹Å½â€¹Â¨â€¹Ã‚â€¹Ã›â€¹ÃµÅ’Å’(Å’BÅ’[Å’uÅ’ï¿½Å’Â¨Å’Ã‚Å’ÃœÅ’Ãµï¿½ï¿½)ï¿½Bï¿½\ï¿½vï¿½ï¿½ï¿½Â©ï¿½Ãƒï¿½Ãï¿½Ã·Å½Å½+Å½DÅ½^Å½xÅ½â€™Å½Â¬Å½Ã†Å½Ã Å½Ãºï¿½ï¿½-ï¿½Gï¿½aï¿½{ï¿½â€¢ï¿½Â¯ï¿½Ã‰ï¿½Ã£ï¿½Ã½ï¿½ï¿½1ï¿½Kï¿½eï¿½ï¿½Å¡ï¿½Â´ï¿½Ãï¿½Ã¨â€˜â€˜â€˜6â€˜Pâ€˜kâ€˜â€¦â€˜Å¸â€˜Â¹â€˜Ã“â€˜Ã®â€™â€™"â€™&lt;â€™Wâ€™qâ€™â€¹â€™Â¦â€™Ã€â€™Ãšâ€™Ã´â€œâ€œ)â€œDâ€œ^â€œxâ€œâ€œâ€œÂ­â€œÃˆâ€œÃ¢â€œÃ¼â€â€1â€Lâ€fâ€ï¿½â€â€ºâ€Â¶â€Ãâ€Ã«â€¢â€¢ â€¢;â€¢Uâ€¢pâ€¢Å â€¢Â¥â€¢Ã€â€¢Ãšâ€¢Ãµâ€“â€“*â€“Eâ€“_â€“zâ€“â€¢â€“Â°â€“ÃŠâ€“Ã¥â€”â€”â€”5â€”Pâ€”kâ€”â€ â€”Â¡â€”Â»â€”Ã–â€”Ã±ËœËœ'ËœBËœ]ËœwËœâ€™ËœÂ­ËœÃˆËœÃ£ËœÃ¾â„¢â„¢4â„¢Oâ„¢jâ„¢â€¦â„¢&nbsp;â„¢Â»â„¢Ã–â„¢Ã±Å¡Å¡'Å¡BÅ¡^Å¡yÅ¡â€Å¡Â¯Å¡ÃŠÅ¡Ã¥â€ºâ€ºâ€º7â€ºRâ€ºmâ€ºË†â€ºÂ¤â€ºÂ¿â€ºÃšâ€ºÃµÅ“Å“,Å“GÅ“cÅ“~Å“â„¢Å“ÂµÅ“ÃÅ“Ã«ï¿½ï¿½"ï¿½=ï¿½Yï¿½tï¿½ï¿½ï¿½Â«ï¿½Ã†ï¿½Ã¢ï¿½Ã½Å¾Å¾4Å¾PÅ¾kÅ¾â€¡Å¾Â¢Å¾Â¾Å¾ÃšÅ¾ÃµÅ¸Å¸,Å¸HÅ¸cÅ¸Å¸â€ºÅ¸Â¶Å¸Ã’Å¸Ã®&nbsp;	&nbsp;%&nbsp;A&nbsp;\&nbsp;x&nbsp;â€&nbsp;Â°&nbsp;Ã‹&nbsp;Ã§Â¡Â¡Â¡:Â¡VÂ¡rÂ¡Å½Â¡ÂªÂ¡Ã†Â¡Ã¡Â¡Ã½Â¢Â¢5Â¢QÂ¢mÂ¢â€°Â¢Â¥Â¢ÃÂ¢ÃÂ¢Ã¹Â£Â£1Â£MÂ£iÂ£â€¦Â£Â¡Â£Â½Â£Ã™Â£ÃµÂ¤Â¤-Â¤IÂ¤eÂ¤ï¿½Â¤Å¾Â¤ÂºÂ¤Ã–Â¤Ã²Â¥Â¥*Â¥GÂ¥cÂ¥Â¥â€ºÂ¥Â¸Â¥Ã”Â¥Ã°Â¦Â¦)Â¦EÂ¦aÂ¦~Â¦Å¡Â¦Â¶Â¦Ã“Â¦Ã¯Â§Â§(Â§DÂ§`Â§}Â§â„¢Â§Â¶Â§Ã’Â§Ã¯Â¨Â¨(Â¨DÂ¨aÂ¨}Â¨Å¡Â¨Â¶Â¨Ã“Â¨Ã¯Â©Â©)Â©EÂ©bÂ©~Â©â€ºÂ©Â¸Â©Ã”Â©Ã±ÂªÂª*ÂªGÂªdÂªâ‚¬Âªï¿½ÂªÂºÂªÃ—ÂªÃ³Â«Â«-Â«JÂ«gÂ«Æ’Â«&nbsp;Â«Â½Â«ÃšÂ«Ã·Â¬Â¬0Â¬MÂ¬jÂ¬â€¡Â¬Â¤Â¬ÃÂ¬ÃÂ¬Ã»Â­Â­5Â­RÂ­oÂ­Å’Â­Â©Â­Ã†Â­Ã£Â®Â®Â®:Â®WÂ®tÂ®â€™Â®Â¯Â®ÃŒÂ®Ã©Â¯Â¯#Â¯@Â¯^Â¯{Â¯ËœÂ¯ÂµÂ¯Ã“Â¯Ã°Â°
Â°*Â°HÂ°eÂ°â€šÂ°Å¸Â°Â½Â°ÃšÂ°Ã·Â±Â±2Â±PÂ±mÂ±Å Â±Â¨Â±Ã…Â±Ã£Â²Â²Â²;Â²YÂ²vÂ²â€Â²Â±Â²ÃÂ²Ã¬Â³
Â³'Â³EÂ³bÂ³â‚¬Â³Å¾Â³Â»Â³Ã™Â³Ã¶Â´Â´2Â´OÂ´mÂ´â€¹Â´Â¨Â´Ã†Â´Ã¤ÂµÂµÂµ=Âµ[ÂµyÂµâ€“ÂµÂ´ÂµÃ’ÂµÃ°Â¶Â¶,Â¶IÂ¶gÂ¶â€¦Â¶Â£Â¶ÃÂ¶ÃŸÂ¶Ã½Â·Â·9Â·WÂ·uÂ·â€œÂ·Â±Â·ÃÂ·Ã­Â¸Â¸)Â¸GÂ¸eÂ¸Æ’Â¸Â¡Â¸Â¿Â¸ÃÂ¸Ã»Â¹Â¹8Â¹VÂ¹tÂ¹â€™Â¹Â°Â¹ÃÂ¹Ã­ÂºÂº)ÂºGÂºfÂºâ€ÂºÂ¢ÂºÃ€ÂºÃŸÂºÃ½Â»Â»:Â»XÂ»vÂ»â€¢Â»Â³Â»Ã‘Â»Ã°Â¼Â¼-Â¼KÂ¼jÂ¼Ë†Â¼Â¦Â¼Ã…Â¼Ã£Â½Â½ Â½?Â½]Â½|Â½â€ºÂ½Â¹Â½Ã˜Â½Ã¶Â¾Â¾3Â¾RÂ¾qÂ¾ï¿½Â¾Â®Â¾ÃÂ¾Ã«Â¿
Â¿)Â¿GÂ¿fÂ¿â€¦Â¿Â¤Â¿Ã‚Â¿Ã¡Ã€Ã€Ã€&gt;Ã€\Ã€{Ã€Å¡Ã€Â¹Ã€Ã˜Ã€Ã·ÃÃ4ÃSÃrÃâ€˜ÃÂ°ÃÃÃÃ®Ã‚
Ã‚,Ã‚KÃ‚jÃ‚â€°Ã‚Â¨Ã‚Ã‡Ã‚Ã¦ÃƒÃƒ$ÃƒCÃƒbÃƒï¿½Ãƒ&nbsp;ÃƒÃ€ÃƒÃŸÃƒÃ¾Ã„Ã„&lt;Ã„[Ã„{Ã„Å¡Ã„Â¹Ã„Ã˜Ã„Ã·Ã…Ã…6Ã…UÃ…uÃ…â€Ã…Â³Ã…Ã’Ã…Ã²Ã†Ã†0Ã†PÃ†oÃ†ï¿½Ã†Â®Ã†ÃÃ†Ã­Ã‡Ã‡,Ã‡KÃ‡kÃ‡Å Ã‡ÂªÃ‡Ã‰Ã‡Ã©ÃˆÃˆ(ÃˆGÃˆgÃˆâ€ ÃˆÂ¦ÃˆÃ…ÃˆÃ¥Ã‰Ã‰$Ã‰DÃ‰dÃ‰Æ’Ã‰Â£Ã‰ÃƒÃ‰Ã¢ÃŠÃŠ"ÃŠAÃŠaÃŠï¿½ÃŠÂ¡ÃŠÃ€ÃŠÃ Ã‹Ã‹ Ã‹@Ã‹_Ã‹Ã‹Å¸Ã‹Â¿Ã‹ÃŸÃ‹Ã¿ÃŒÃŒ?ÃŒ^ÃŒ~ÃŒÅ¾ÃŒÂ¾ÃŒÃÃŒÃ¾ÃÃ&gt;Ã^Ã~ÃÅ¾ÃÂ¾ÃÃÃÃ¾ÃÃ?Ã_ÃÃÅ¸ÃÂ¿ÃÃŸÃÃ¿Ã Ã@Ã`Ãâ‚¬Ã&nbsp;ÃÃÃÃ¡ÃÃ!ÃBÃbÃâ€šÃÂ¢ÃÃƒÃÃ£Ã‘Ã‘$Ã‘DÃ‘eÃ‘â€¦Ã‘Â¥Ã‘Ã†Ã‘Ã¦Ã’Ã’'Ã’GÃ’hÃ’Ë†Ã’Â©Ã’Ã‰Ã’ÃªÃ“
Ã“+Ã“LÃ“lÃ“ï¿½Ã“Â­Ã“ÃÃ“Ã®Ã”Ã”0Ã”PÃ”qÃ”â€™Ã”Â²Ã”Ã“Ã”Ã´Ã•Ã•5Ã•VÃ•wÃ•â€”Ã•Â¸Ã•Ã™Ã•ÃºÃ–Ã–;Ã–\Ã–}Ã–Å¾Ã–Â¿Ã–ÃŸÃ—Ã—!Ã—BÃ—cÃ—â€Ã—Â¥Ã—Ã†Ã—Ã§Ã˜Ã˜)Ã˜JÃ˜kÃ˜Å’Ã˜Â­Ã˜ÃÃ˜Ã¯Ã™Ã™1Ã™RÃ™sÃ™â€Ã™ÂµÃ™Ã–Ã™Ã¸ÃšÃš:Ãš[Ãš|ÃšÅ¾ÃšÂ¿ÃšÃ Ã›Ã›"Ã›DÃ›eÃ›â€ Ã›Â¨Ã›Ã‰Ã›ÃªÃœÃœ-ÃœNÃœoÃœâ€˜ÃœÂ²ÃœÃ”ÃœÃµÃÃ8ÃYÃ{ÃÅ“ÃÂ¾ÃÃŸÃÃ"ÃDÃeÃâ€¡ÃÂ¨ÃÃŠÃÃ¬ÃŸ
ÃŸ/ÃŸPÃŸrÃŸâ€ÃŸÂµÃŸÃ—ÃŸÃ¹Ã Ã &lt;Ã ^Ã Ã Â¡Ã ÃƒÃ Ã¥Ã¡Ã¡(Ã¡JÃ¡lÃ¡ï¿½Ã¡Â¯Ã¡Ã‘Ã¡Ã³Ã¢Ã¢7Ã¢YÃ¢zÃ¢Å“Ã¢Â¾Ã¢Ã Ã£Ã£$Ã£FÃ£hÃ£Å Ã£Â¬Ã£ÃÃ£Ã°Ã¤Ã¤4Ã¤VÃ¤xÃ¤Å¡Ã¤Â¼Ã¤ÃÃ¥Ã¥#Ã¥EÃ¥gÃ¥â€°Ã¥Â«Ã¥ÃÃ¥Ã°Ã¦Ã¦4Ã¦VÃ¦yÃ¦â€ºÃ¦Â½Ã¦ÃŸÃ§Ã§$Ã§FÃ§iÃ§â€¹Ã§Â­Ã§ÃÃ§Ã²Ã¨Ã¨7Ã¨YÃ¨{Ã¨Å¾Ã¨Ã€Ã¨Ã£Ã©Ã©(Ã©JÃ©mÃ©ï¿½Ã©Â²Ã©Ã”Ã©Ã·ÃªÃª&lt;Ãª^Ãªï¿½ÃªÂ¤ÃªÃ†ÃªÃ©Ã«Ã«.Ã«QÃ«sÃ«â€“Ã«Â¹Ã«ÃœÃ«Ã¾Ã¬!Ã¬DÃ¬fÃ¬â€°Ã¬Â¬Ã¬ÃÃ¬Ã²Ã­Ã­7Ã­ZÃ­}Ã­&nbsp;Ã­ÃƒÃ­Ã¥Ã®Ã®+Ã®NÃ®qÃ®â€Ã®Â·Ã®ÃšÃ®Ã½Ã¯ Ã¯CÃ¯fÃ¯â€°Ã¯Â¬Ã¯ÃÃ¯Ã²Ã°Ã°8Ã°[Ã°~Ã°Â¡Ã°Ã…Ã°Ã¨Ã±Ã±.Ã±QÃ±tÃ±ËœÃ±Â»Ã±ÃÃ²Ã²$Ã²HÃ²kÃ²Å½Ã²Â±Ã²Ã•Ã²Ã¸Ã³Ã³?Ã³bÃ³â€¦Ã³Â©Ã³ÃŒÃ³Ã°Ã´Ã´6Ã´ZÃ´}Ã´Â¡Ã´Ã„Ã´Ã¨ÃµÃµ/ÃµRÃµvÃµâ„¢ÃµÂ½ÃµÃ Ã¶Ã¶'Ã¶KÃ¶oÃ¶â€™Ã¶Â¶Ã¶Ã™Ã¶Ã½Ã·!Ã·DÃ·hÃ·Å’Ã·Â°Ã·Ã“Ã·Ã·Ã¸Ã¸&gt;Ã¸bÃ¸â€ Ã¸ÂªÃ¸ÃÃ¸Ã±Ã¹Ã¹9Ã¹]Ã¹ï¿½Ã¹Â¥Ã¹Ã‰Ã¹Ã¬ÃºÃº4ÃºXÃº|Ãº&nbsp;ÃºÃ„ÃºÃ¨Ã»Ã»0Ã»TÃ»xÃ»Å“Ã»Ã€Ã»Ã¤Ã¼Ã¼,Ã¼PÃ¼uÃ¼â„¢Ã¼Â½Ã¼Ã¡Ã½Ã½)Ã½MÃ½rÃ½â€“Ã½ÂºÃ½ÃÃ¾Ã¾'Ã¾KÃ¾oÃ¾â€Ã¾Â¸Ã¾ÃœÃ¿Ã¿%Ã¿IÃ¿mÃ¿â€™Ã¿Â¶Ã¿Ã›Ã¿Ã¿XYZ descEPSON  sRGBEPSON  sRGBEPSON  sRGBtextCopyright (c) SEIKO EPSON CORPORATION 2000 - 2006. All rights reserved.Ã¿Ã›C
	
#!!!$'$ &amp; ! Ã¿Ã›C                                                   Ã¿Ã€
	Ã¶"Ã¿Ã„	
Ã¿Ã„Âµ}!1AQa"q2ï¿½â€˜Â¡#BÂ±ÃRÃ‘Ã°$3brâ€š	
%&amp;'()*456789:CDEFGHIJSTUVWXYZcdefghijstuvwxyzÆ’â€â€¦â€ â€¡Ë†â€°Å â€™â€œâ€â€¢â€“â€”Ëœâ„¢Å¡Â¢Â£Â¤Â¥Â¦Â§Â¨Â©ÂªÂ²Â³Â´ÂµÂ¶Â·Â¸Â¹ÂºÃ‚ÃƒÃ„Ã…Ã†Ã‡ÃˆÃ‰ÃŠÃ’Ã“Ã”Ã•Ã–Ã—Ã˜Ã™ÃšÃ¡Ã¢Ã£Ã¤Ã¥Ã¦Ã§Ã¨Ã©ÃªÃ±Ã²Ã³Ã´ÃµÃ¶Ã·Ã¸Ã¹ÃºÃ¿Ã„	
Ã¿Ã„Âµw!1AQaq"2ï¿½Bâ€˜Â¡Â±Ã	#3RÃ°brÃ‘
$4Ã¡%Ã±&amp;'()*56789:CDEFGHIJSTUVWXYZcdefghijstuvwxyzâ€šÆ’â€â€¦â€ â€¡Ë†â€°Å â€™â€œâ€â€¢â€“â€”Ëœâ„¢Å¡Â¢Â£Â¤Â¥Â¦Â§Â¨Â©ÂªÂ²Â³Â´ÂµÂ¶Â·Â¸Â¹ÂºÃ‚ÃƒÃ„Ã…Ã†Ã‡ÃˆÃ‰ÃŠÃ’Ã“Ã”Ã•Ã–Ã—Ã˜Ã™ÃšÃ¢Ã£Ã¤Ã¥Ã¦Ã§Ã¨Ã©ÃªÃ²Ã³Ã´ÃµÃ¶Ã·Ã¸Ã¹ÃºÃ¿Ãš?Ã¹#'`Ã§Ã°Â©Â£r#Ã‚Ã³Ã­PÂ»Ã–Å¸m|Ã—Ãªâ€Ã—cÃâ€™Ãâ„¢Â¨Ãï¿½â€º=+Z&lt;Â»YÃ2c&amp;Â³KÃ¨09Â«Ã &nbsp;W=Â«Â­;Ã™3Å½Â®Â©\Å¡uSÃ¦Â·Nâ€¡Ã’Â¤â€°ï¿½rÃ¥ÃŸÂ¨5ÃŠÃ¥sï¿½jKdÃš0ÃŒGÂ¥SÂ³LÃ¤vÃœ{HÂ¡Ã¡â‚¬y"â€˜d#Ã¥(Ãf;:2Â¸Å¾â€Ã‡â€šâ€œÃŠqâ€™Â¼Ã–iÃ‡b.Â¶!rYÃ· Ãš=GÂ­;Ã‹u$Â²â‚¬=h!Uâ€Ã¥sÃÃ”Ã“yÂ²Zp:ÃµÃ…VÃš&amp;;Ã´#0-Ã•â€¹Â¼
SÂ¾7`â€™Â£ÂµE*Ã¢=Ã™*1Å Å¡VxÃÂ³)RF9Ã¯MÃ…Â­[Ã˜D%â€ ÃÃ›W9 Å¾Ã´Ã‘Ã»Â·ÃÃƒNhÃ”Â²;ï¿½Â«Å’Å’RJYSÃ…=FTÂ´&nbsp;â€¢Ã›Ã…1Ã‹Â¤ï¿½cÃ gÂ­HÃ oQÃ¦Ã·Â¢*Ã…Ã‰ï¿½OJQ-
cdÃ‡$Æ’Ã–â€3G.rKgÂ§Âµ+9â€™rE1e3Ã˜Ã»Â½ÃªÂµ{â€ Â¬Â°.ï¿½&nbsp;uÃ˜:Ã½Ã®Ãµ\\2Ã¡2ZIgo,â‚¬8ÃZÂªÂ¢RÃƒ$ï¿½Ã˜Ã“TÃ–Ã¥Ã†)ÃªÃ	&lt;&nbsp;Kâ‚¬A=â€¦WÃ¤HÃ…â€ Å“Ã½iÂ¦I7ï¿½Å“ï¿½Zâ€™B$ÃšÃÃƒÅ¾1Ã©I+n$Â¬+ÃŠ&lt;Ã€Â¡Â¾ËœÃ­I!RÃ nÃ­ÃÂ½0DÃŒË†rE1Ã•Ã”t$Ã¶5V]â€™Â¹fÃ²Å½Ã¢^â€â€˜Â²yÅ’Ã€Ã¤â€œÃ†{ÃB#lLÂ³Â¹&nbsp;Â¬kÃ¾Â±~Â½*tÂ±â„¢6H 0Â¨â€¹â„¢1Ã¤Â¾:Ã”,ÃÃ’&nbsp;2Tï¿½Â¸_â„¢GNÃÂ´Ã¹mÃ|Â¶W&nbsp;Â¶Ã‘&amp;wÃ&gt;ÃµX6cÂ¥69Ã²ÃŒH=	Â¦#ogÃ¹GVvd;Â½Ã…"1ï¿½Ãƒ{Å â€¦Ã¢Ã7Å“Â¹ï¿½Ë†ÃÃ¥Â¦9Ã½Ã¦Ã€Â§Ã´Â­bÃ–ÃºÂ®Ã¤@Â¨I8Ã"ï¿½Ã†Ã„d+ï¿½ÃœNgT@|Ã‡ÃšÂ«Â±s&amp;Ã°8Â¤â€™zÂµÃœâ€“PLËœÂ·zÃ³WÃšÂ»HÃ¾Ãƒ&amp;Â¨	cÃ Â§ÃÃ‡5eÃš&amp;Â¶Ã‚Å“Â±Ã’â€™Â¶â€šâ€™zÃ£_5â„¢XÃ°Â§&nbsp;Ã¨iâ‚¬Ã‹ï¿½
Ã§UË†ËœErÂ¼Å¡gÃ‰â€™Â¹nMRâ€”cDÃµ,Ã‚Ãƒ`mÃ¸^Ã‹Ã¯K4*Â¤â€“9Å¡Â¯Ã‹ÃÅ’Å’Ã•5Ã„Â¬QJ&amp;jâ€”Â¹ï¿½ÂµÃï¿½%_1Ã½Ã¦iÃ«	3Â°,sMÃ)Ãƒw"â€œtÂ¹Ã‚ï¿½Æ’Â¥	1Â±2Ã±â€šzÃ»TÃ€Æ’fÃ´Â¦Ã¡|â€œÂ´Ã¤Â¯sLÃ³YG&lt;Ã£Â­1jÃ„cÃ¥!!Â°Ã„Ã§4ÃˆÃ¦-Å¸6BÃÃ˜â€œSLÅ¸Â»â€¢nÅ“UxÃŠloâ€”sSJÃ¨Â¥Â±4{ï¿½Ã†wÃÂ¥â€™
ÃŠÃÅ“â€˜Ã‰ZHÃ‘Æ’cÃ—Â·Â¥Xx2[
Â´Ã£Â¡=i7gÂ¡7Â³ÃÂªÅ½â€˜â€¢ï¿½Âªvâ€Ã¬Ã€cÂ³9 UtË†3Â±^{bÂ¥"*Fx5-+Ãª7kâ€”"hÃ™ï¿½/Ã—ï¿½â€œÃ’Â¿@~Ã›%Â§Ã‚Ã½(ÃÃ `
Å¸ZÃ¼Ã¸â€¦zâ€“aâ€¦Ã…~Ë†Ã¼2â€ÃÃ°ÃCï¿½Â¹?g^GÃ’Â¾[Ë†4Â¥Â»ï¿½Ã¹zÃ·Ã™Ã˜2eï¿½ÃÂ§Å’Â¤sJ2N1NDÃ‰Ã±gÂ¸,iÂµSÂ°{Ã’ï¿½Ju!â€˜p:Ã“ÃŠÃ§Ã’â€Ã‡Ã°Ã’Ëœ4Ã‘Ã‰lsRÂ°Ã£Å½Â´â€¦Ã©@ÃAÃ­BÂ¦Ã“Ã’Â¤Ã†iPYTï¿½Â¦?â„¢â‚¬Ã4Â¤Â±â€œqRÃœÃ“qâ€Ã¢â€œÅ pÃ†qÅ¾)1Å’â€˜HÂ·ÃÂ¦ï¿½Ã˜Ã‰4Ã°Ã…â€”8Ã…!ROÂµ
Â¹Ã‰Â¨Ã rÂ£Å’ÃµÂ«ÂºÃ“_&nbsp;(;SÃ°Â¬Ã€Ã·ÂªÅ“â€“Ã†	Â¡â€”g"â‚¬Fj'Ãˆ{wÂ©ï¿½ÃˆÃ©Mâ€™2Ã£Ã³@â€¦N3ÃšÅ“Ã©Ã*Ã¥@R8ÃµÂ¦Â»0ï¿½&gt;QÃ–Ëœâ€Ã†:Ãµâ€¦â€¹Ã¹iepÃÅ¾Âª0Â¤1Â¥qÅ¡gv[!Ã€aNÃª=iË†ï¿½iÃ©Å¾*&amp;â€¹yÆ’Å¡Â°TÃºÃ’Ã£Å .CÅ¾Ã˜Â¡ï¿½0Ã…&lt;Ã JAÅ C!ÃšQÃ‡9Â§ÃµÃ…&lt;Ã£Å¡AÃˆÃ(Â¼â‚¬8Â§ï¿½AM\\sÃ–â‚¬HÃ‡Ã–Å¸Å¾=Ã©6Æ’Ã”qH`Ã®ÃˆÃ¦Å“S$cï¿½Zv4Æ’Ã¯uÃ¢ËœFË†6Ã§Å¾Ãµ&gt;qÃšâ€ºÂ³Å¾(Â©Ã‡QBÃ™cÂ¤:Ã±Dg=Â¨
ï¿½Ã¹&lt;ÃÂ¤gÅ“y8Â¨Å¸7
iÅ“/Ã­NÃšiÂªqÃÂ§Ã#eÃÂ½76Ã®Ã•6zÃ’Ã°FV*[â€ºÂ½MÅ’Ã°jcï¿½Â¡!Â°GJ[}Ã­ÃÃ·Â¨Ã­â€â€¢Fy'&amp;â€˜Ë†-Â·4Ãµ\ÃƒÅ¾â€`tÂ¥lÃ’($Ã»PÅ½0iÂ»}iOÅ¾â€šï¿½Ã³&gt;Ã¢â€bÃ‡Å½Ã´Ã¢)Ã»pÃ”cÅ½iË†â€¹'Âµ&amp;ÃA=iÃ¤sÅ B1@ÃˆÃ¤â€¦%Ã€zvÃÂ£Â¥;Â©Ã+câ‚¬Â­ ;Â¶Å½Â§Ã’Å¾â€˜â€¦Ã4`Ã¹â€Ã¾U  Å¡`0&amp;Ã“Ã….9Ã¦Å¸Ã†NÃˆÃ·&nbsp;Ã­{Ã”Râ‚¬`Ã²jnK)Â¬â‚¬Â°=Ã¨@Ã„TÃˆÃ¹ï¿½@Ã‘*ÃŠGZÂ·Ã‘M4.Ã¯Ã‚â€EUrÅ½iÃ£'&nbsp;)4Ã¬wÃ­H#=*2â„¢qÂ¸p:TÂ¤~QAÃ‰^8Â¦@
1â„¢Ë†;M&lt;|Ã€â€ =hHâ€šÅ½iâ‚¬Ã˜â€¢â€šÃ¡Â¹Â§Ã­Ã£Â¥9WÃƒÂ¸6;P9Ã§Å¡fÃÃ‡$*B0rOZÃ±Å’R^Ã´2Ã¥zsNQÃ‡)IÃ¨Å Â¹Ã¶Â¥U<qÂ·Ã’â€ï¿½Å’ÃœktÃ¬*n:bÅ“qÅ ls@ aÃ¹rÃ£Â½?Ã—Å¡oe="">Ã”Ã–R~Z@â‚¬1Ã’Â¥\0Ã!#8â‚¬`"Å’cÂ¥8qÃ’Å’ï¿½Ã–â‚¬+â€“*zÃ¶Â§Â¦JeÂºÃ’â€¢ÃŸ4Å¾ÃÂ©Ë†R9Ã9sÃ©J8Ã…Å¾Â¸Â¡cqIÂ°â€˜Å¸Z~94Å“Ã£Ãšâ‚¬Â°gâ€œ
iÃŒHZ6Ã¼Â¸Ã¯@tf\Å U\(Ã¦â€ Ã©Å“PÂ¤â€Ã„)SsOÃ€4Å’&nbsp;Ã°(Â°Ã†7ÃœÂ¨Å“Ã¼Â¸&amp;Â¦)â€Ã‡JÂ®Ã±â‚¬ï¿½3Ã¢?Ãš#lÅ¸Â®PÂ¹R"Qâ€š+Ã†â€˜3H ÃµÃµÃ­_Â´â€¢Â³EÃ±VIÃŠâ€™Â²Ã‚Â¸9Ã©^*Â»â€“@Ã„â€˜Å¾
~â€ºâ€”ÂºÃ‚Ãï¿½â„¢Ã„ÃŸÃšÃˆtÂ²}Ã~aÅ“L.&nbsp;*Ã£Ã˜Ã“ÃŠ	%ÃšÂ«ÃÂ¯Â¥5\ÃÃÂ½Â»Å“Ãš"ÂµÃ²Å“RË†Ã•U[Â®{Ã’PtÃjMÂ§Ã–Â¯Â¦â€¦Ã«m	DlNÃ³ÃŒgï¿½Â¥Bcâ€“BUÂ°@Ã¨jhÃ™Å“Ã£8CÃ›Ã–â€™VKÃ¥Â¨Ã€ÃµÂ¦$Ã˜ï¿½Ã˜CÃ¥â€-0â€”R;Ã®Ã§â€¢)Pc
ÃºÃ”ÃšWÃšÂ¬:Ã•%}AjYBÂ²Â»Ã€^yÃ¯BÃœËœÃ—bÃ´99Â¦|â€šN1JÂªÅ Ã»KÃÃ•Ã‰ÃÂ¬ÃŒ#hÃ‰Ã­Nw1ÃƒÆ’Ã²â€™1Å¡Yï¿½xPX1ÃÂ¤fVÅ’Ã®0Ã¤fâ€ºÃ–Ã–5Dp0â€¦ÃŠÂ¸Â©T)^IÃºjÃ¹NAÃ›Ã³Ã–â€”ivâ€¦2ÃœoQÂ¹9;ËœqÃTÃ¤ï¿½,Ã‡jâ€šD&gt;b	Ã²M#4`Â¡â‚¬ÂªÂ²Ãâ€”Â­Â¬mFIâ€šiâ€ºÃ±Ã•KzR02`d:Ã“Ã•Â©'ÃÃ”Â±-Âµ+â€“*JÃ®*	Ã£Ã¯â€ºhCÃtÃjKÂ¼Å“â€“G}Ã…Uy
S]â€¹oÂ°Ã°Ã¯Ã–Ã©QÂ¾Ã—â€œÂ¯$Ã´Ã­HHaÃœÅ’HÃ¤TÃ˜â€â€¹1DÃÃˆ^Ã¯DÃ¬
C})Ã #5ÃŒï¿½â€â€œÃ’â€™VdÃ™ÃÃ¬wËœÃ‘Â¦Ã£ÃÃ°)Å“(Ã‰qÃ³vÂ¤ÃŸÃˆBÃ™Å¾â€â€¦rÂ¤Ã¼Ã•Iâ€”ro3Ã·Å Ã‘Ã†â€¡zâ€˜Å Å“1Ãœ:Å Â¨Â²2ï¿½Â¹Ã=*ÃËœÂ´aB}Ã®Ã¾â€Ã¥Â¬LÂ¢B?xÃï¿½Â·uÂ¥â€°JqÂ´qÃ”Å kÂ·â€“Ã"'Â®jÃšacÃ‹ï¿½Ã«ÃµÂ¡Ã¨Â¬â€¡'dQIâ€°wSÃtÂ§ï¿½Â²:Ã¼ÃœwÂ§\â€š2;cÂµ1Ã”Â¤â€¹Ã‡hÂ²oBÂ´Â¾â€šËœÃ¹oÃÂ³ÃšÂ¤cÂ¶MÂ£Å“Ã¼ÃŒiÅ ÂªwÂ¢Ã«â€œIï¿½Ãˆâ€š3Ã€Ã¢â€¡Â½ï¿½ÃŸËœÃ¸vâ„¢Â«gw:FQÂºN;Ã“F(Ã¸\ï¿½21K,.ÃŠÂ¬ÃŒA&lt;Ã±Y6Â®fÃµ`Æ’,HN3ÃHÃ…â‚¬ qÅ ~ZDÃ˜Å’pÂ¾ÃµÃ²ÃÃ‚)ÃŸÃœÃ“KPCÅ Â¸ï¿½JÂ¼Ã§=Âªo(yEÂ·ÃµÃ¤Å¡â‚¬ÃÃ†EFoÃÂ¨Ã©R6CÂ¨CÃ—Ã´Â¥fkÂ¯â„¢Â³6pz{SKUï¿½Ã‹ÃˆÅ â€Â°cÃŸÃ«QbC)e#Â¾â€'ÃhÂªÃ®CÃ‚Â¯AO\â€eâ€¦Ã¾Ã©Ã¯PÃ™rXÃ§&lt;Ã±RÃ¹Å¸"
Â½*Å¡Â¾&nbsp;Ã—b8ÃŒÃ¥ÃŠÂ£Â¨Ãµ&nbsp;Â¡â‚¬oÃ¢Ã=Â¤`Qâ‚¬Ãozlâ€˜ÂªÂ²Â²Â¹!â€ M$Â»â€¢Ã”"Ã²Ã€aï¿½Â¦Ë†â€^aÃ‚Ã§Â±Ã#)1w Ã·Ã…NÃ´Ã–Â¨-Â¦Ã¤â€™FLÃ»â€”pÃ‡Ã†Â¥ï¿½Ã¤b8lv'h$â€™;ï¿½JwÃ¯Ã‡Â©Â¡Â«Ã™â€°Ã©Â¹|ï¿½IÃ¬iÃ±â€™Ã€N}jÂ¸â€™A)ï¿½fAÃ®jrÃ‘â€Ã‰nTÃ´ÂªÃ¥4jÃ„Ã­â€œâ€¡ dÃ«PÃ‹$Æ’â‚¬i|ÃŸ0@Ã‡Ã”Qâ€f$JÃ£TÂ¥mÃ‰KÂ¸Â¥ÃŠaÂ°KÃÂ§ÃŠ#â€œÃ¦'Ã€ÃµÂ¡K$ Âªâ€š{fâ€™I`Ã—â€¢ÃºR/&gt;@ï¿½6Ã´&lt;})Ã"Â£TÃ§9Ã…Yï¿½c1Â·i<tgildwÂ§uÂ¸s.Ã$8|Ã­'â€˜]Â¿Ã‚Ã©lÃ´gf'Ã·Ãª8Ã¯Ã…qÃâ„¢Ã09ÃˆÂ®Ã—Ã¡Å’-sÃ±cbË†ÃšÃ¤}kï¿½Ã¿ï¿½u ft="">4~â€¡Ã…xÃ·3rGJÂ²Â©Âµ0;S"R5&amp;OÃ¡_â€”\ÃºTâ€â€œÅ“SÆ’n=)Ã‰ÃˆÃ+.Ã@Ã‰Â¥qÅ’ "Â£u;Ã†:Tâ€¦x4Ã¢â„¢'Å¡h@â€¹â€Ã«MHÃ™e,NsR"ï¿½Â½zSÃ¶ï¿½Ãï¿½ÃˆÃˆÃ‰Ãƒ
â€¹ÃŠA'CÆ’VYyvÂ¦â€¢ÃÃ…4PÂ¼TqÅ“1ï¿½jPÅ“m4,d0ÃjWï¿½BÂ£*/^Ã”ÃÅ½Â£Â«q!8Â¤ebÃ€Å Â«Å Ã„{|Â§Å PÃ¢Â¦Ã˜7zÃ’â€˜â€œÃ‡jâ€ºÅ½Ã…fpCÅ¸\Ã”â€¦rÂ¼uÂ©JÅ’dRtÂ¢Ã Bâ€˜Ã¹iÅ½Ã´Â±Ã†qâ€“Ã«SÂºâ€”h'Â­bÂ©â€Å½GzPâ‚¬19Ã¢â€œh4\,UGq);Rï¿½Ã‹"â€ Ã¦Â¬Ã†3Ã–â€”oÃÃˆÃ
â€°!Â¤dScSÃ€'9Â§Â¨Ã…+Å½Ã„GÃ¥Ã†iÃ¸ï¿½/Ã–ËœÃ„Ã¶Â¡Â£Æ’UÂ¥?Â¿Ã™'Ãnâ€¢(gÂ¨e$ÃÂ£nÃ¬Ã¾â€¢BdÃ¥p?ZdoÂ½Â·ÂºjlÃ `Å bÂªâ€¦<bâ€¢Ã‡aÃÂ¹Ã†)h Ã£Âµ2f="" `="" Å¡wÂ â€™n;Ã’Ã¥pÃ´Â©t|Â¹Ã‡z@Â«h\râ€¹ï¿½i&Ë†ÃÂ²Â·nâ€¢*Â±uÃ‰Â§l{Ã“Â¸â€¦Ã€Ã†ÃŸzÂ«rÂ²#nÃµan="" ÃˆÂ¦8-*Â²â€˜â€˜Ãšâ€Ãï¿½zb9ï¿½vï¿½*Ãˆ@Ã€Ã®jsÃ†yÃ’â‚¬bï¿½eÃÅ½Ã¤oÂºvÃ’="" ÃÂ¸wv="ÂªÃ“cnÂ¤Ã˜Ã´Â¥p+Â¤Qâ€°" .[xï¿½Ã«jâ€˜*1#Â½;$â€˜Ã…;ï¿½3ï¿½Ãšâ€="" Ã¦oÃ†)Ã¦#Â¸0Â©6Ã€Ã§ï¿½jï¿½cÃ¦â€šzâ€Ã Å’="" iâ€°o="M!r">Â´Â±ï¿½Ã‘Ã¼Ã‡Ã°Â©CaqÃ…6?-[`oÃˆ
Ë†H
0U<uÂ³â‚¬*'Ã‡Âµ$2Â¸.@= xï¿½hk{="" p]Ãeï¿½1t3n="i6ï¿½3p_Ã†Â§" ;r="" dÃ Ã§Â©="" +Ãï¿½â€¦Â±Å¡Â«ï¿½!ÃµÃ©Å Ã‘="" Å“="" ptÃ§Ã‘`+$dÃ¤h9Â§Ã¹b<tÃ9sÅ n\pbÂ±Ã¹Å xâ‚¬{tÅ’Â»â€ï¿½Ã©h`\Ã§=":Tâ€º">Z`Uâ€š-OLÅ¾Â¸Â¤u(pÃˆÃ¬Y#bÃ¼Â«HÂ¨_Ã¦qH
Ã–Â±BÃ¥6gÂ¦iÃ²0Râ€°Â»Å¸ZÂ¶8ÂªÃ—Ã¼Ã»â€”9ÂªÂ¸â€¡2r8Ã§Ã–Å¾Ã‘Ã¤n<bâ€¢â‚¬Â¡Â¹Ã£Å¡â€Ã£â€ vÃ€ï¿½Ã†j\9Â¤ï¿½â€š1Å½ 5ï¿½â€™8Ã…ï¿½e="" Ã¹ËœÂ·="">â€šÂ¥ï¿½Â¤2Ã¢Ëœ#`Ã â€œâ€˜VvÃ±@Å Â¬Å’â€`fÂ¡Gï¿½\ÃˆY~^Ã†Â¯#Å¾Â¦ËœÃ£ â€š(Â¸ÃŠÃc#Ã‰Â¦â€°Â§yÅ¡//jÅ’UÃ¥TÃ©HIÃ“Â¸Å Å½Å¸8sÃ”Å¾â€¢pÃ§Ã‹8Ã«Mdï¿½Ã‡!Ã P`bgÂ­UtÃ³Å¾Â¢Â¬Ã£?{Ã°Â¦Âªï¿½Ã™Ã‡ï¿½Å’TO,Å½ÃÃ³H&nbsp; Ã‚Ã³Å½â€šÂ¥eRâ€Ã…"Â±dÃ“@GÂ±fyÃ“Ã˜ÂªÅ½zÅ¡ï¿½%i\Â®6Å â€˜Ã±Å’7ZM3Â¥Å½Fâ€â€“ï¿½Ã’Â¤Â·-Â¼Ã¿wÃ“Â½\	ï¿½23QÃŒnX/Ã³OtÂ±)\Ã¢Â£â€˜x8Ã Ã”Â¼mÃÂ­FÃ‹Ã³nÃj
 )â€˜ÃˆÃ­Uâ€+	Ã‰8&amp;Â¯mmÃ™=)Â²Ã„A#4â‚¬Â¡:â€“â€¢
Å’Ã£Â¿Â¥9Â¢`O Å“tÂ©e[`\ZaRfbï¿½Â£VwÂ¯Å“cfÃ‰Ã¹Â«2ï¿½Â£Â·ZnÃÃ¤Ã£Å½â€Ãtbrâ‚¬{Ã‘V6â€¦8ÃÃ„~RÅ’Æ’Â´Ã±OÃ«Ã€Ã»TÃ·Ã‘y7[
Ã¡Âºâ€˜DcÃ¥ÃœÂª3ÃÃ—Ã«Ã´ZSâ€“â€”$Â·Å’ÃˆÃ›TÃ²9ÃkÂ¨Ã³V2Ã€â€ Â«.xxÂ«Ã—â€š
hÃ€IRe;xÃ 
ÃÂ«Â«Å“5Â®Ã™f(Ã’IË†'tÃzÅ¸Ã¤0Â®cÃ•Â¹#Â½PVeqâ€“Ã¦Â¬Ã‡pc&amp;Ã¬n=1G+9dâ„¢*ÃŒÂ«+rQâ€¡T/Â¶AÃ³hâ€Ã†Â¯Ã²Å“â€“=)Â¥â€™Â°Ã´ÂªÃ‘jJ]DXâ€ºrï¿½&nbsp;&amp;zÃ”Â©!kï¿½/8NËœÂ¨ÃœÃ‰Ã¥Ã£!vÃ±Å &lt;â€¹â€¦â€¦&amp;â€˜2ï¿½â€™Â§Ã–â€¹ueZÃ¢4e&amp;Ã³`ï¿½J|Ã’c-#eÂ³ÃŸÂ­@ÃŒÃªXÂ¯FÃ­Ã©IÂ½ËœÃ‡8Ã Ã•Ã˜Â«u'Ã»RË†ÃŠÂ°ÃœÃÂª$WGÃµÃz`]Â²*Â³@Ã«Ã©SÂ¶8Ã˜wÃµÂ¥Â³Â²Â¦Ã…iâ€ºÃ¦(&gt;Ã¸=Ã¨â€Â¿â€Ã›Â¸bzÃ•ï¿½,HÃ…Â³â€ Ã·ÃœÃ‰'Ã²Â«RMX|ÃŠÃ–,Ã€IÂµâ‚¬<cÃ–â€ºÂ±Â¡ÃŠÆ’Ã·â€¡jÅ¡wâ€.Ã…Å¡Â®â€¦ÃˆÃ‹Å¾Ã´â€œ)6ÃÃ°Â¦8Ã‡ï¿½Â¨Ã•Ã¹ tï¿½Ã¯vËœÂ¿â€™@ï¿½h="MVÃ²a]@*â€“Â¬Â«REâ€˜â€”\â€ Ã©Ã›" @Ãâ€™a8Â«="" Ëœ08Ã…1cÃ„8Â§{Â½="">Ã„Â©ËœÃ¹hsÃ«UZ"Â¸p&gt;b{Ã–Å N#â‚¬Ã¹â€¹â€¡#Â¡Â¨"â€fÃAÂ¬ÃµÃ•â€œKQÂ¹â€œzï¿½â„¢&gt;Ã”Ã–ï¿½ÃÃƒ7jÂ°Â³0Ã„Ã“Ã„ï¿½#Â®sÃ€Ã¶Â¦â€°Â¹Loâ€¦Ã¾R=Âª`Ã­Ã¦+(Â¢Â¥HÃ·ï¿½vÃ­#Â½DÃÃ‹Â¿ÃµÂ«Ã¦Â¾â€ â€”LY\Â¾Ã€Ã‰Ã€8Ã€`AjÅ '@Å¸2â€šÃÂ¾â€¢$Â²Â¡u,Â¹Ã£Å â€¹6CÃ¬A#Ã¤
8dEâ€“ÃzÃ”Ã»Â£*Â»â€ XÃ¶Ã’Å¸6Ã HÃ¶4_&nbsp;st%gBx#Ã”Ã‘'BÂ®[Ã›Â¥6FUBÅ“ï¿½NÃµ ÃŠ&amp;ÃµxÂ¥{ÃŒÂ®#QÃ‰MÂ§Ã›Â½Oâ€¢Ã³rÂ¡})Â¥e`Â®qÃ”R9pÃ‘ï¿½â€“SÃ—Â©ÃªÃ‡{â€™HPÅ¾^Op*G2Å¸â€”*GoJâ€¢Ã•â€°xÂ­?Ë†Â£Ã¡Ë†Ã&nbsp;Â©Â½Â¶vDqÃ‰j@ ï¿½Ã–â€™mÂ®|Â¨Å“Ã­Ã­Å¡â€°QVCï¿½â€7B{Uï¿½â‚¬Ã¨ÃªÃË†Ã Å’tÂªk[ï¿½Ã™j%ÂµÂ±ï¿½â€°vÃˆÃ†8Â¤â€¢Ëœ#(SÃÃ Å¡Â²Â·HC'Ã“Â±Â¨Å“Â±Ã^Ã¢â€™nÃ·dÃÂ·y
I	Å’)â€˜M"Ã¡Â¸'â€˜R*Â©sâ€šÃ‘Ã…0&lt;Ã†E8Â¹Â¦ËœÃ•â‚¬\ï¿½,â€ CÃ´Â¥â€°Ã”ÃªÂ¼wÃKÂ³02ï¿½2Ã–â€™0â„¢(Pï¿½EK&nbsp;Â®ÂºÃ³%ÃÃˆ Ã±VÂ·Â·â€œÂ¼Â·JÅ’Â¢Ã£*sÅ |LÃ’Å“,ï¿½vÃ³Æ’Ã’Â¥Ã­q=HÃ„â€¦Ã¨3VÂ¶&lt;â€˜ï¿½ÃœÃ©U%ÃOâ€¢<r>Ã…dcÃ‡/]DÃ–ÃŒr(7Ã…Ã¾!Ã·â€¡ZÃ½Ã°-â‚¬Ã´XÃ˜EÂªp&gt;â€šÂ¿<tï¿½'Ã–`ï¿½â€”{Ã‰"Âªï¿½Â©Â¯Ã’ Ã˜Ãšx{oÂ¶#\1Ã¿ï¿½Ã²|c="" v="\Â¹jÃ™ÂªÃZâ€˜ZbÃ Å¾Å“Ã”Â£+Ã£ÃhsÃ–Å“G8Â£â€”Å¡@" Ã¹{sbÃ¤Å¾ixÃ›Ã8)zÃ¦Å“Â¼ï¿½hÃ›g-ÃšÅ½hÃ¹xÂ ryÂ£Ã°iÃ˜Ã€Â¤yË†Â§re5Ã¶â€šÃ«nulÃ§<snm?Ã‡f@="" Â®Ã®yÂ§Ã¯Ã¢ï¿½="" nï¿½:Ã“Ã‡â€ pyÃ©@="">Â´â€ ÃµÃ§ Ã”Â½N)Å½Yï¿½2h&nbsp;Â¶Ãœâ€˜Pâ€™H'=Ãª]ÃƒÃ‹Å½3Qâ‚¬d*â‚¬rr8!Ã ThrH^â€¢)Ã‡zâ„¢\ÃŒ1Å“wÂ«F"Å“Ã¤wÂ¡ï¿½WÃ—Â¥Ë†lÂª.@Â¨Å Ã_8Â§0pÂ£Ãhï¿½&nbsp;Vâ€œÂ¸Â§`"dâ€˜â€°Ã¹Â±ÃœUË†Ã›&nbsp;nÂµM.&lt;Ã¦8Ã¹sÃšÂ¦Â·WÃ	Ã;Ã“hIâ€“Â·
iÃ‰n)Ã˜â€š(&gt;â€š&nbsp;Â¢FÃ¬aÂ°jEVUÃniÂ¥A9=E=â€°Ã‡Å Â§oÃÃ–ï¿½Â¤!Nâ€œÃ‰Â¥ÃÃÅ’RÅ’wÂ§gÃ–â€Ã£&gt;Ã´cÃ–Ëœ
Ã€ÃÅ¾Ã”â€¡ÃµÂ¥Ã3IÂ·fï¿½Æ’@r)Ã˜ï¿½Gâ€“
Ã“Ãâ€°9Â£Â·Â¤fÅ½Ã¢â‚¬Â§ Æ’JÃ§Ã¥E9Ã¶Â¤tÅ 4:Ã Ã”Ã“Ã€#$wÂ¨â€¡.Â¤Å’TÃ Ãc!Ã†iÃ¤fÅ“qHÃi
Ã¤Ncn*@yÂ§g9&nbsp;.1Â¹â€Â©Ã·i[Ã’ï¿½t&gt;â€ï¿½Ã‹w4Â¼Ã’Ã’â€˜Ã‡Â½&amp;9Â£Ã°Â¥Ã’Ã¦Ëœâ€ Ã wÂ¥Ã£Âµ!Å¾*Ã»ÃzÃ’jÃ¬:Ã“â€¡JacÃšï¿½I@Ã„#4â€E)Ã©KÅ½hÂ¸	ï¿½Å¾â€Å½Â´Â£Â®(9ÃºÅ¡hxÂ£Â§Ã½E(â€˜â€¢Â¤
A9Â©3@Ã‡ZCÂ¸Å’7SBÃ­Ã©Ã’Â¤$bâ€œSâ€¡Â¥!Ã8Â§ï¿½1@Â¤Â¹Ã‡&amp;â€”Ã¹RÃ¢Å’Ã¢ËœdÃ®)pÃ Ã±Å v~â‚¬eÂ½Â¨{TjK1'ÂµHGj@1Ã†)â‚¬â€¦r1Ãšï¿½Æ’Æ’Ã“&amp;8&nbsp;â‚¬F1@\hÃ±M
Ã‰9&nbsp;$Â©Ã QÂ³Â¾MÂ«Å“Å¡Ã®nÂ´(Ã£Â¯Jwj#Ã’)Ã§Å Ã¢â‚¬Å½Ã§Â½8â‚¬xÃ….8Â¢â‚¬Â¸ÃœcÃ¢â€œp'ÃÅ¾EFsÅ Ã£qÅ¡i\Â·"Â¤Â¦Ã½MF&gt;Ã¶)Ã˜ÃµÂ¥â€œÅ¡CLbâ€/Ã®Â½(&nbsp;Ã°Ã·Â¤Â©6Å’Ã¦â€œo4cGâ‚¬ÃºÅ½iÃ˜ Ã“YOÃ°Ãµ&nbsp;Cv}Â©Â¡HÃ§Ã²ï¿½Â¸n<wÂ§Ã±Å½Â´Ã€bÅ½zÃ½h`sÃ…iâ‚¬Ã˜Â¤Ã‡z1Â±Â·Å¡Â¢ÃŠ7Ã¤â€œï¿½jÂ·"Â³gÅ â€¦Â£Ã½Ã–iÂ lÃ¸Â³Ã¶â€â€“fÃ¸Å¸Ã¥Ã Â²Ë†ï¿½â€¢Ã¢*Ã²n*Ã©â€“Ã©Å¡ÃµÃŸÅ½Ã³Ãâ€¹â‚¬â€“6@ÂªÃ¤Ã§+^qÃ¦ymÂ¸\Ã³ÃˆÂ¯Ã“Â²Ã¥l,â€˜Ã²Ã¸â€”zÂ²Ã¨ï¿½=â€ºÃ©Ã¹Ëœ1Â»ï¿½efÃ‘Â±Â¸y Ã¡Â»sÃ¤qÂ¸â€¦sÃ€Â®Ã§kÅ“ÃšËœ="" aÃ«jc}Ã¤Â´Ã”Â¸eâ€œ8}Ã©="" ï¿½Â¤="" Ã°ï¿½Â­5zÃ«Ãâ€˜b@l~ahhÂ°Â£nÃ”Ã”m,hÃ£="" ï¿½zÃ’Â«Ã‡$atÃ­ï¿½Ã‘gÃ”^Ã¶Ã£Â¶Â¡â€¹`thÂ£q="" tÃ¯Ã«r.Ã™$ÃšÂ¹Ãš:Ã“Æ’|ÃtfÂ¤wÂ¶â€="" Â©â€˜Â¼Ã€bÅ½â€¢*Ã€â€™f]Ã“Â½$â€˜9="izBLÃÂ«ÃÂºÃ<Â¦Ã–Â¡HÃ¤WÃ¹â€ E=Ã®Å“Å’Â¹Ã¹â€¡zÃ‡Ãï¿½8&quot;â€”Â½Â¹vï¿½Ã ÃŒ" Â£oÂ¨4Ã¸Â¦Ã˜dyÃ¡Ã˜Ã”oÃ³â€¡Â±ÃœzÃ“uÃ°Â¹p="" qkÂ ÂµÃÃ¡!Ã†wr="" 3ÃŒâ€œÃÃŸ'*zrkÃœgw(ï¿½xÃ¹Ã stâ€¢â€˜vvÂ¸Ã¹'deÃ½Ã™Ã§â€šiÃ©itljsÂ¦`ÃœnqÃˆÂ¦Ã†Ã«Ã½ÃœÃÂ¦Ã="" Ã©tjâ€¦Ã¡!Ã°azhlÂ¾aÃ<Å¡pup[p9Ã­qÂ³Â¢Â¸ÃµÂ¢(vlâ„¢~nÂ£â€œpmÃ‚ï¿½Â¹$nwbÅ Â«â€˜Å¾~Â´â‚¬â€[Â¡Ã¾tyÂ±Â«Å’qâ„¢Â£Â°Â§Â»="" Ã±ï¿½Ãâ€7wÃsÃ‰4Â³!â„¢Å½="M;Â¨Ë†Ëœ" â€¦ÃˆÃ‡Â¤ytÃˆÃ‹$yÃ£Â­9jpÂ¢lÃÃ’*Â¨bÃ¹Ãa@zÅ½;6ï¿½Ã‹ÃƒtÂ &6â€¢Ã‹="" Ã´Â¨]Ëœ&ÃÂ§Â¨Â©Ã¡ï¿½â€#Å¡m\my\wÃ¹â€ºÅ Ã˜Å¡lÆ’Ã²â€”p="IÂ§Â°â„¢Ã¹L`wâ€˜IÂ´8ÃªjnÃâ€¢Ã·Â¬ÃªÂªÃ¼nÃ©Å lÃ‡rÃ‡Â¸`Ã•â€”â€°{Ã±Â¹Gzï¿½Â¤Mâ‚¬Â®AÃ…" Ã«Â Ã“ÃªË†Ã¡`Å½f:Ã­4Â²Ã]â€˜Ã¥tpï¿½Ã©lt?v1â€šfriÂ¨l`Â©cÃ”ÃºÃ•Ã™="KÂ²ÃœÂ±Ã§">Ã‡CÃÂ¨Â¼Ã–;Tâ€ Ã§Ã’â€ºsÃ¼Â¤Ã³Ã…YÃ˜câ€°Å“Â¾Ã¦Â¡Ã™dâ€â€°J#Â°8Ã‡oZâ€;1gvÃ†*GwÃ˜Â¤Â¼3M2Å¾T`Â¦3Å¾Ã´-5Ã®GÂ°Â²dÆ’Ã—Å“SÃ0ufbâ„¢<gÃ’â€“<Ã„â€™g`)Â²â€¡ï¿½poÂ¥=jÃ²uÃ™<ÃŒâ€˜ÃÃºÃ“Å’Å¾d>n}Ã©Â¨$VgÃ¹[ÃºSÅ¡IÃÃ¬tÃJz7Â¨Ã­}	â€yâ€;Ã¶Ã´Â¥pï¿½Ã³Å¡Ë†I0Ã§mKï¿½â€ºÂ²HÃ«RÃ·+Â¸#ÃƒÂ®ÃOÅ¾vÃ§ Â·Â¡Â¦Ep$P1Ã“Å’Å¾Ã”Ãµï¿½Â³gâ‚¬8ÃºÃÃ•Ã˜4Ã—AÂ¤2Â¦Ã¼ï¿½â„¢Ã§Ã¨e8yÃ›ÃBÃ²ÃKFÂ¿Oj#!KaH^Ã¸Â«â€™ÃÂ«iÂ©nYÃ­ï¿½aÅ’â€¡Â¹'â€šiâ€™;Ã…bÃ€Â¦	#ï¿½sÃ¤Å¾AÃ¦â€”x2b{{Ã”$MÂ¼Ë†6Ãˆâ€¡'4Ã¢`</gÃ²â€“<Ã¤â€™g`)Â²â€¡ï¿½poÂ¥=jÃ²uÃ¹<Ã¬â€˜Ã°ÃºÃ³Å“Å¾d></wÂ§Ã±Å¾Â´Ã bÅ¾zÃ½h`sÃ¥iâ‚¬Ã¸Â¤Ã§z1Â±Â·Å¡Â¢Ãª7Ã¤â€œï¿½jÂ·"Â³gÅ¡â€¦Â£Ã½Ã¶iÂ lÃ¸Â³Ã¶â€â€“fÃ¸Ã¿Ã¥Ã Â²Ë†ï¿½â€¢Ã¢*Ã²n*Ã©â€“Ã©Å¡ÃµÃŸÅ¾Ã³Ã¾â€¹â‚¬â€“6@ÂªÃ¤Ã§+^qÃ¦ymÂ¸\Ã³Ã¨Â¯Ã³Â²Ã¥l,â€˜Ã²Ã¸â€”zÂ²Ã¨ï¿½=â€ºÃ©Ã¹Ëœ1Â»ï¿½efÃ±Â±Â¸y></tï¿½'Ã¶`ï¿½â€”{Ã©"Âªï¿½Â©Â¯Ã²></r></cÃ¶â€ºÂ±Â¡ÃªÆ’Ã·â€¡jÅ¡wâ€.Ã¥Å¡Â®â€¦Ã¨Ã«Å¾Ã´â€œ)6Ã°Ã°Â¦8Ã§ï¿½Â¨ÃµÃ¹></bâ€¢â‚¬Â¡Â¹Ã£Å¡â€Ã£â€ vÃ ï¿½Ã¦j\9Â¤ï¿½â€š1Å¾></uÂ³â‚¬*'Ã§Âµ$2Â¸.@=></bâ€¢Ã§aÃ®Â¹Ã¦)h></tgildwÂ§uÂ¸s.Ã¡$8|Ã­'â€˜]Â¿Ã¢Ã©lÃ´gf'Ã·Ãª8Ã¯Ã¥qÃ­â„¢Ã¾09Ã¨Â®Ã—Ã¡Å“-sÃ±cbË†ÃºÃ¤}kï¿½Ã¿ï¿½u></qÂ·Ã²â€ï¿½Å“Ã¼ktÃ¬*n:bÅ“qÅ¡ls@></xtxkxâ€šxÅ¡xÂ±xÃ©xÃ xÃ¸yy'y></sosbsusË†sâ€ºsÂ®sÃ¡sÃ´sÃ§sÃºt></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.apollopresskits.com/cs/c/?cta_guid=69bda2b0-603b-4c91-bf30-c3d425396f31&amp;signature=AAH58kE89ooPCBnAEHIF6NwUgRUo-tIeiA&amp;pageId=7962764933&amp;placement_guid=00362abe-1f60-422e-99aa-75f5e9edf2e9&amp;click=76a4887d-6ed6-41ad-8f35-f49bfbfb5ef6&amp;hsutk=c7a00000190d1bd81cf30177b699595f&amp;canon=https%3A%2F%2Fwww.apollopresskits.com%2Fapollo-presskit-directory&amp;utm_referrer=https%3A%2F%2Fpinboard.in%2Fu%3Amichaelcolenso%2Fbefore%3A1569472943&amp;portal_id=413105&amp;redirect_url=APefjpE9rO6ok2BaATb973oLgLwidfs4zRYwQVkhov4aq3jijtJU9oC3_MkthEIQajAD2N7OYtegEpDri0ocRWxVVLga-zgB54CWPGlhDPe5Hs7yGVQ4i-Bg8al-HsINkLxHD7A5NZMRQuOTY2HFAYJ1b50AuY62q-AzqiHpeVCtj-WgsQyex1s">https://www.apollopresskits.com/cs/c/?cta_guid=69bda2b0-603b-4c91-bf30-c3d425396f31&amp;signature=AAH58kE89ooPCBnAEHIF6NwUgRUo-tIeiA&amp;pageId=7962764933&amp;placement_guid=00362abe-1f60-422e-99aa-75f5e9edf2e9&amp;click=76a4887d-6ed6-41ad-8f35-f49bfbfb5ef6&amp;hsutk=c7a00000190d1bd81cf30177b699595f&amp;canon=https%3A%2F%2Fwww.apollopresskits.com%2Fapollo-presskit-directory&amp;utm_referrer=https%3A%2F%2Fpinboard.in%2Fu%3Amichaelcolenso%2Fbefore%3A1569472943&amp;portal_id=413105&amp;redirect_url=APefjpE9rO6ok2BaATb973oLgLwidfs4zRYwQVkhov4aq3jijtJU9oC3_MkthEIQajAD2N7OYtegEpDri0ocRWxVVLga-zgB54CWPGlhDPe5Hs7yGVQ4i-Bg8al-HsINkLxHD7A5NZMRQuOTY2HFAYJ1b50AuY62q-AzqiHpeVCtj-WgsQyex1s</a></em></p>]]>
            </description>
            <link>https://www.apollopresskits.com/cs/c/?cta_guid=69bda2b0-603b-4c91-bf30-c3d425396f31&amp;signature=AAH58kE89ooPCBnAEHIF6NwUgRUo-tIeiA&amp;pageId=7962764933&amp;placement_guid=00362abe-1f60-422e-99aa-75f5e9edf2e9&amp;click=76a4887d-6ed6-41ad-8f35-f49bfbfb5ef6&amp;hsutk=c7a00000190d1bd81cf30177b699595f&amp;canon=https%3A%2F%2Fwww.apollopresskits.com%2Fapollo-presskit-directory&amp;utm_referrer=https%3A%2F%2Fpinboard.in%2Fu%3Amichaelcolenso%2Fbefore%3A1569472943&amp;portal_id=413105&amp;redirect_url=APefjpE9rO6ok2BaATb973oLgLwidfs4zRYwQVkhov4aq3jijtJU9oC3_MkthEIQajAD2N7OYtegEpDri0ocRWxVVLga-zgB54CWPGlhDPe5Hs7yGVQ4i-Bg8al-HsINkLxHD7A5NZMRQuOTY2HFAYJ1b50AuY62q-AzqiHpeVCtj-WgsQyex1s</link>
            <guid isPermaLink="false">hacker-news-small-sites-26184346</guid>
            <pubDate>Thu, 18 Feb 2021 19:30:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BioNTech/Pfizer sought 54.08 Euro per vaccine dose from EU (de)]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 41 (<a href="https://news.ycombinator.com/item?id=26184301">thread link</a>) | @_Microft
<br/>
February 18, 2021 | https://www.tagesschau.de/investigativ/ndr-wdr/corona-impfstoff-biontech-105.html | <a href="https://web.archive.org/web/*/https://www.tagesschau.de/investigativ/ndr-wdr/corona-impfstoff-biontech-105.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                <div>
    
    
    <div>
        <div>
            <p><span>
                    Exklusiv
                </span>
            </p>
            
            <p>
                Stand: 18.02.2021 17:00 Uhr
            </p>
        </div>
    </div>
</div>
                
                    

    
    
        
    
    <p>
        <strong>Die Pharmaunternehmen Pfizer und BioNTech wollten nach Informationen von </strong><strong><em>NDR, WDR</em></strong><strong> und "SZ" im Juni von der EU fÃ¼r eine Dosis Impfstoff 54,08 Euro. Der Arzneimittelchef der Ã„rztekammer spricht von "unseriÃ¶sem Profitstreben".</strong>
    </p>

    

    




    

                
                    

    
    
        <div>

    

    
        <div>
            <p>
                    <span><em>Von Markus Grill und Georg Mascolo,  </em></span><em>
                    <span>NDR/WDR</span></em>
                </p>
        </div>
    
</div>
    

    




    

                
                    

    
    
        
    
    <p>
        Im Juni des vergangenen Jahres ging bei der EU-Kommission ein streng vertrauliches Angebot der Pharmahersteller Pfizer und BioNTech ein. Darin boten sie nach Informationen von <em>NDR, WDR</em> und "SÃ¼ddeutscher Zeitung" ihren Impfstoff zum Preis von 54,08 Euro pro Dosis an, bei einer Abnahme von 500 Millionen Dosen. Insgesamt wollten BioNTech/Pfizer also 27 Milliarden Euro fÃ¼r so viel Impfstoff, dass man damit gut die HÃ¤lfte der EU-BevÃ¶lkerung impfen kÃ¶nnte. Der Preis, so versicherten Pfizer/BioNTech, beinhalte bereits "den hÃ¶chsten prozentualen Rabatt", der einem Industrieland weltweit angeboten worden sei.
    </p>

    

    




    

                
                    

    
    
        
    
    <p>
        Mit 54,08 Euro wÃ¤re der BioNTech-Impfstoff allerdings mehr als 20-mal so teuer gewesen wie eine Dosis jenes Impfstoffs, den AstraZeneca gemeinsam mit der UniversitÃ¤t Oxford entwickelt hat. "Ich halte den Preis fÃ¼r unseriÃ¶s", kritisiert der Vorsitzende der Arzneimittelkommission der Deutschen Ã„rzteschaft, Wolf Dieter Ludwig, das Angebot von Pfizer/BioNTech. "Ich sehe darin ein Profitstreben, das in der jetzigen Situation der Pandemie in keiner Weise gerechtfertigt ist."
    </p>

    

    




    

                
                    

    
    
        
    

    




    
        
        
            
            
            
            
            
            
                
    
    

        
    

            
            
            
            
            
        
    

                
                    

    
    
        
    

    




    
        
        
            
            
            
            
            
                
            
            
            
            
            
            
        
    

                
                    

    
    
        

    

    <h2>VerstÃ¤ndnis fÃ¼r ZÃ¶gern der EU</h2>


    

    




    

                
                    

    
    
        
    
    <p>
        WomÃ¶glich werfen diese vergleichsweise hohen Preisvorstellungen auch ein neues Licht auf die ZurÃ¼ckhaltung mancher EU-LÃ¤nder im Sommer gegenÃ¼ber dem BioNTech-Impfstoff. Ludwig jedenfalls sagt, dass er die EU verstehe: "Ich denke, sie hat mit Recht gezÃ¶gert bei einem derartig hohen Preis."
    </p>

    

    




    

                
                    

    
    
        
    
    <p>
        In einem Interview mit dem "Spiegel" Anfang des Jahres kritisierte BioNTech-Chef Ugur Sahin die Verhandlungen mit der EU: "Der Prozess in Europa lief sicherlich nicht so schnell und geradlinig ab wie mit anderen LÃ¤ndern", sagte der Firmenchef. "Offenbar herrschte der Eindruck: Wir kriegen genug, es wird alles nicht so schlimm, und wir haben das unter Kontrolle. Mich hat das gewundert."
    </p>

    

    




    

                
                    

    
    
        
    
    <p>
        Eine Anfrage zu einem GesprÃ¤ch Ã¼ber das hohe Preisangebot lieÃŸ Sahin diese Woche unbeantwortet. Eine Firmensprecherin beantwortete konkrete Fragen zum Angebot nicht, wies aber darauf hin, dass der Preis fÃ¼r den Impfstoff "von verschiedenen Faktoren abhÃ¤ngig" sei. Er liege "in einer gewissen Spanne fÃ¼r alle LÃ¤nder mit hÃ¶herem Einkommen". Bisher habe das Unternehmen jedoch keine Gewinne gemacht. Wenn man aber Gewinne aus dem Vertrieb des Covid-19-Impfstoffs mache, wolle man diese "in die Weiterentwicklung dieser Technologie reinvestieren". Ein Sprecher der EU-Kommission teilte per E-Mail mit, dass die EU-Kommission aus vertragsrechtlichen GrÃ¼nden keine Angaben Ã¼ber die Preise machen dÃ¼rfe.
    </p>

    

    




    

                
                    

    
    
        
    

    




    
        
        
            
            
            
            
            
                
            
            
            
            
            
            
        
    

                
                    

    
    
        

    

    <h2>Offenbar deutlich niedrigeren Preis durchgesetzt</h2>


    

    




    

                
                    

    
    
        
    
    <p>
        Erst im November kam die EU zu einem Vertragsabschluss mit Pfizer/BioNTech. Der endgÃ¼ltige Preis wird bis heute zwar geheim gehalten, doch nach Informationen von <em>NDR, WDR</em> und "SZ" soll er bei 15,50 Euro pro Dosis liegen. Als erste hatte auch die Nachrichtenagentur Reuters diesen Preis erfahren. Die EU hÃ¤tte damit also eine deutliche Preissenkung gegenÃ¼ber dem Angebot im Juni erreicht.
    </p>

    

    




    

                
                    

    
    
        
    
    <p>
        Auch die USA zahlen in etwa gleich viel. Sie hatten im Juli bereits einen Vertrag mit Pfizer geschlossen, der ihnen 100 Millionen Dosen fÃ¼r 1,95 Milliarden Dollar sicherte. Umgerechnet ergibt das rund 16 Euro pro Dosis.
    </p>

    

    




    

                
                    

    
    
        
    

    




    
        
        
            
            
            
            
            
                
            
            
            
            
            
            
        
    

                
                    

    
    
        

    

    <h2>Staatliche Subventionierung in MillionenhÃ¶he</h2>


    

    




    

                
                    

    
    
        
    
    <p>
        Ãœberraschend ist aber nicht nur der hohe Preis, den Pfizer/BioNTech von der EU kassieren wollten, sondern auch die Behauptung in dem Angebot an die EU, man hÃ¤tte die Entwicklung des Impfstoffes "komplett selbst finanziert".
    </p>

    

    




    

                
                    

    
    
        
    
    <p>
        Das mag vielleicht fÃ¼r Pfizer gelten. Nicht aber fÃ¼r die deutsche Firma BioNTech, die den Impfstoff entwickelt hatte - auch wenn manche derzeit glauben, dass BioNTech allein mit dem Geld der Hexal-GrÃ¼nder Andreas und Thomas StrÃ¼ngmann aufgebaut wurde. 
    </p>

    

    




    

                
                    

    
    
        
    
    <p>
        TatsÃ¤chlich war ihr Engagement entscheidend - aber BioNTech wurde auch mit mehreren Millionen Euro staatlich subventioniert. So teilt das Bundesministerium fÃ¼r Bildung und Forschung (BMBF) auf Anfrage von <em>NDR, WDR</em> und "SZ" mit, dass das Ministerium "die GrÃ¼ndungsphase von Biontech maÃŸgeblich unterstÃ¼tzt und die entscheidenden ersten Jahre der AusgrÃ¼ndung finanziell und auch strukturell gefÃ¶rdert hat".
    </p>

    

    




    

                
                    

    
    
        
    
    <p>
        Einen weiteren Schub hatte BioNTech demnach von 2012 bis 2017 als Gewinner des Spitzencluster-Wettbewerbs erhalten, das vom Forschungsministerium mit 12,9 Millionen Euro gefÃ¶rdert worden sei, wie BMBF-Sprecher Stephan KÃ¼gele mitteilte. Auf Nachfrage teilt auch die BioNTech-Sprecherin mit, das Unternehmen habe "wÃ¤hrend der ersten Jahre nach GrÃ¼ndung ca. 50 Millionen Euro FÃ¶rdergelder durch die Clusterinitiative und EU-Programme erhalten." Im Sommer 2020 bekam die Firma weitere 375 Millionen Euro vom Bundesforschungsministerium fÃ¼r die mRNA-basierte Impfstoffentwicklung zugesagt.
    </p>

    

    




    

                
                    

    
    
        
    

    




    
        
        
            
            
            
            
            
                
            
            
            
            
            
            
        
    

                
                    

    
    
        

    

    <h2>Impfschutz wichtiger als AktionÃ¤rsinteressen</h2>


    

    




    

                
                    

    
    
        
    
    <p>
        "Die pharmazeutische Industrie sagt ja immer, die hohen Kosten entstehen aufgrund der Forschungs- und Entwicklungskosten, aber auch, weil der Nutzen so groÃŸ ist", sagt Wolf Dieter Ludwig. TatsÃ¤chlich kÃ¶nne man den Nutzen derzeit aber nicht endgÃ¼ltig beurteilen und die Forschung und Entwicklung sei zum Teil mit staatlichen Geldern subventioniert worden. Allein die US-Regierung zahlte mehrere Milliarden US-Dollar an verschiedene Hersteller. 
    </p>

    

    




    

                
                    

    
    
        
    
    <p>
        "Von daher sind diese hohen Preisforderungen aus meiner Sicht nicht berechtigt", sagt Ludwig. Er verstehe zwar, dass die AktionÃ¤re dieser Firmen auch ihren Anteil wollen. "Aber wir sind derzeit in einer Krisensituation, wo es das Ziel sein muss, nicht nur in den IndustrielÃ¤ndern, sondern weltweit zu impfen. Vor diesem Hintergrund, denke ich, haben die Interessen der AktionÃ¤re weniger Bedeutung als die Interessen der BevÃ¶lkerungen, die von dieser Pandemie befreit werden wollen."
    </p>

    

    




    

                
                    

    
    
        
    

    




    
        
        
            
            
            
            
            
            
            
                

    

        

        
    

            
            
            
            
        
    

                
                    

    
    
        
    

    




    
        
        
            
            
            
            
            
                
            
            
     â€¦</article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tagesschau.de/investigativ/ndr-wdr/corona-impfstoff-biontech-105.html">https://www.tagesschau.de/investigativ/ndr-wdr/corona-impfstoff-biontech-105.html</a></em></p>]]>
            </description>
            <link>https://www.tagesschau.de/investigativ/ndr-wdr/corona-impfstoff-biontech-105.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26184301</guid>
            <pubDate>Thu, 18 Feb 2021 19:26:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Year of Rails]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26184215">thread link</a>) | @jashkenas
<br/>
February 18, 2021 | https://macwright.com/2021/02/18/a-year-of-rails.html | <a href="https://web.archive.org/web/*/https://macwright.com/2021/02/18/a-year-of-rails.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><picture><source srcset="https://macwright.com/images/2021-02-18-a-year-of-rails-railroad.webp" type="image/webp"><img alt="Railroad" src="https://macwright.com/images/2021-02-18-a-year-of-rails-railroad.jpg"></picture></p><p>I spent most of 2020 working with <a href="https://rubyonrails.org/">Ruby on Rails</a>. I moved a project from <a href="https://nextjs.org/">Next.js</a> + <a href="https://www.rust-lang.org/">Rust</a> toâ€¦&nbsp;Rails, baby! Back to the future. My earlier post on <a href="https://macwright.com/2020/05/10/spa-fatigue.html"><em>Second-guessing the modern web</em></a> was inspired by this experience, that for the product we were building, a â€˜modernâ€™ stack was not working as well as a traditional one.</p><p>We didnâ€™t do competitive analysis against Laravel, Django, or Phoenix. Theyâ€™re similar, not radically better or worse. There are multiple acceptable solutions to a problem, and this was more a matter of choosing the right <em>kind</em> of solution than pursuing some kind of perfect choice and burning hours and motivation doing the window-shopping.</p><p>What helped Rails win was that the team had a little more experience in Ruby (with the exception of myself), and we found plenty of resources for developing and deploying the stack. Rails fit perfectly into the ideology of <a href="http://boringtechnology.club/"><em>Choosing boring technology</em></a>. Another part of the product would be the hard, innovative part, so it made no sense to grapple with bleeding-edge web frameworks.</p><p>This was a really fun experience. Thereâ€™s a lot to love about Rails. Other communities could learn a bit from the Ruby &amp; Rails culture and wisdom. I wonâ€™t implement <em>everything</em> in Rails, but itâ€™ll be part of the toolbox.</p><p>Before this, I hadnâ€™t touched the stuff. And I bet a lot of people are like that - they came of age in the world of React and Go, and havenâ€™t tried anything even remotely similar to Rails. For their benefit, and to debrief from 2020, here are some notes on the experience. Plus, <a href="https://macwright.com/2020/10/28/if-not-spas.html">Rails-like projects in JavaScript</a> are ramping up quickly, and itâ€™s fun to know the origins.</p><h2 id="the-good">The good</h2><h3 id="debugging-rails-apps-is-amazing">Debugging Rails apps is amazing</h3><p>A while ago, I <a href="https://twitter.com/tmcw/status/1321133460501585922">wrote on Twitter</a></p><blockquote><p>the real reason why javascript developers donâ€™t use breakpoints and use console.log is that breakpoints donâ€™t work</p></blockquote><p>After years of working in JavaScript, Iâ€™m used to bad debugging experiences. The Chrome debuggerâ€™s <a href="https://developers.google.com/web/updates/2015/05/automatically-pause-on-any-exception">automatic pause on caught exceptions</a> is amazing, sometimes. But throwing a <code>debugger</code> statement in some React code is dodgy as hell. Sometimes it works, mostly it doesnâ€™t. You have to deal with code that might not have the right <a href="https://www.html5rocks.com/en/tutorials/developertools/sourcemaps/">sourcemap</a> to translate from bundled &amp; minified code to original source. Subtle abstractions like React hooks and advanced transpiler stuff like <a href="https://github.com/facebook/regenerator">Regenerator</a> mean that your codeâ€™s stacktrace probably looks nothing like what you expect, with lots of internal garbage. Sure, you can learn better techniques for diagnosing and debugging errors, but itâ€™s not just you - the debugging story in JavaScript is pretty bad. This applies even to Node.js, where one of the debugging stories is to connect Chromeâ€™s debugger to a Node.js instance:&nbsp;a finicky solution that doesnâ€™t consistently work.</p><p>In Rails, there is <a href="https://github.com/deivid-rodriguez/byebug">byebug</a>. You write <strong><code>byebug</code></strong> in your source code, and you get an interactive REPL right there. It works in views, controllers, database migrations, everywhere. It almost always works. Variables are named what you expect. The whole system is paused at that moment, and you can actually interact with it, using all of the Rails utilities and your installed gems.</p><p>If a page crashes unexpectedly, you get a similar REPL experience, in your browser, automatically. With an automatically cleaned-up stacktrace that excludes Railsâ€™s own frames. Like the byebug interface, this REPL actually works and is consistently helpful in finding root causes. Rarely will you need to use <code>puts</code> to print something to the console because this debugging system is so good.</p><h3 id="the-magic-mostly-works">The magic mostly works</h3><p>Our Rails app didnâ€™t have any <code>require</code> statements. You mention a moduleâ€™s name, and itâ€™s automatically included, using <a href="https://github.com/fxn/zeitwerk">Zeitwork</a>, a tool that comes standard with Rails.</p><p>This kind of system was terrifying to me before. What if you accidentally import something just by mentioning it? What if two things have the same name and you import the wrong one? How do you really know whatâ€™s happening? Sure, youâ€™re happy now, with all of that annoying importing and exporting taken care of, but the sky might fall.</p><p>Or maybe it justâ€¦ doesnâ€™t. Maybe impure, vaguely risky techniques are just a net positive over time, and making everything fully explicit isnâ€™t really necessary? Now when Iâ€™m using other systems, I wonder - what if I could just mention one of my React components and it would justâ€¦ be there? Sure, the system would have to complain if there were two components with the same name, and it would have to make assumptions about directory structure, but overall, wouldnâ€™t this be nice?</p><p>This applies to a lot of other parts of the system too. Rails is famous for doing pluralization - you name a model <code>Post</code> and you automatically get an interface called <code>posts</code>. But what, you ask, of words with uneven pluralization rules? Rails actually&nbsp;<a href="https://weblog.rubyonrails.org/2005/8/25/10-reasons-rails-does-pluralization/">does the right thing</a>, almost always. And when it fails, you can override it. It actually just saves time, reliably.</p><h3 id="testing-works">Testing works</h3><p>Iâ€™ve tried to test front-end applications. Iâ€™ve set up <a href="https://nightwatchjs.org/">nightwatch</a>, <a href="https://jestjs.io/">jest</a>, <a href="https://enzymejs.github.io/enzyme/">enzyme</a>, <a href="https://www.cypress.io/">cypress</a>, and probably 5-10 other frameworks. <em>Front-end testing is universally terrible.</em> Projects like Cypress are throwing untold hours into making it less terrible, taking on massive amounts of complexity to abstract away from fickle browser behavior and complex interactions.</p><p>But it still sucks. Frontend testing has no good attributes: itâ€™s unreliable, hard to automate, hard to debug when it fails, and often doesnâ€™t even assert for important behaviors, so it doesnâ€™t actually identify regressions. Running frontend tests in CI is resource-heavy, requiring you to set up headless X windows environments on servers or use specialized CI services that produce screencasts of test runs.</p><p>Testing fully-server-rendered applications, on the other hand, is <em>amazing</em>. A vanilla testing setup with Rails &amp; <a href="https://rspec.info/">RSpec</a> can give you fast, stable, concise, and actually-useful test coverage. You can actually assert for behavior and navigate through an application like a user would. These tests are solving a simpler problem - making requests and parsing responses, without the need for a full browser or headless browser, without multiple kinds of state to track.</p><p>Not only do the tests work better, the testing culture is a completely different universe. There are entire books written about how to write RSpec tests that catch bugs, allow software evolution, and arenâ€™t filled with boilerplate.</p><h3 id="gems-are-so-powerful">Gems are so powerful</h3><p>Powerful and dangerous.</p><p>Iâ€™m used to modules as they work in other systems - Python, Node, Elm, and so on. They provide objects, functions, and variables that you can import and combine into your code explicitly. Usually they sit on some specific level of abstraction - itâ€™s a utility for connecting to servers or a React component you can use.</p><p>Gems can do so much more. You install something like <a href="https://github.com/heartcombo/devise">Devise</a> into your system and it adds views, routes, methods, utilities, you name it. Itâ€™s not like â€œloading some functionsâ€, itâ€™s more like composing a whole different app <em>into</em> your app, implicitly.</p><p>This is obviously terrifying. It means that you canâ€™t look at your directories of views and your file of <code>routes.rb</code> and know what exists at a glance. There are other layers, lurking in the ephemeral space of third-party code. They interact in serious but uncertain ways.</p><p>But itâ€™s also pretty incredible - the idea that something like <a href="http://www.passportjs.org/">passport</a>, Nodeâ€™s middleware, could instead be a full-fledged authentication system. It means that you have to write a lot less code, and it also means that the people who <em>use</em> that code have a lot more code in common. That gems can work on a higher level of abstraction, making it possible to cobble together software faster, to write less â€˜glue code.â€™</p><h3 id="theres-so-much-good-writing-about-rails">Thereâ€™s so much good writing about Rails</h3><p>Even if you donâ€™t write Ruby, you should pay attention to <a href="https://sandimetz.com/">Sandi Metz</a>. Sheâ€™s incredibly wise and has so many incredible ideas to share.</p><p>And then thereâ€™s <a href="https://blog.arkency.com/">arkency</a>, <a href="https://thoughtbot.com/blog/">ThoughtBot</a>, and so many other thoughtful writers with years of experience in Rails. Sometimes itâ€™s a little shocking to google for some obscure problem and see a decade of discussion about it.</p><p>The best practices are also formalized into tools like <a href="https://codeclimate.com/">Code Climate</a> and <a href="https://github.com/troessner/reek">reek</a>. Iâ€™ve never seen so many actually-useful suggestions come out of automated systems as I did in the world of Ruby and Rails.</p><h3 id="ruby">Ruby</h3><p>Ruby is a pretty pleasant language to work in. Sure, it has a lot of syntax and a sprawling standard library, but you donâ€™t have to use all of that if you donâ€™t want to. It took me a while to adjust to the object-oriented way of doing things - in particular, the idea that you canâ€™t just have a free-range function floating out there, unassociated with a class or module, like you can in JavaScript. And you canâ€™t just create an arbitrary one-off object - you either need to define a class to create an object, or use a Hash to store data.</p><p>But Rubyâ€™s standard library isnâ€™t that huge. Iâ€™ve seen JavaScriptâ€™s â€˜standard libraryâ€™ grow a lot too, and frankly itâ€™s nice to have methods like <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/padStart"><code>String.prototype.padStart</code></a> instead of having every little thing in userspace. The only part that felt actively weird was <a href="https://rubygems.org/gems/activesupport/versions/6.1.1">activesupport</a> - a gem that extends Rubyâ€™s core objects, but is part of Rails. It felt weird to have <em>string</em> methods that would only work if your environment was Rails.</p><p>The <a href="https://kapeli.com/dash">Dash</a> app for documentation rocketed from my pile of unused tools to an absolute must-have. In the world of Ruby and Rails, with <em>most</em> gems having pretty good, semi-standard documentation, you can search for, and get answers, super fast. The Ruby language documentation and the Rails documentation is absolutely great. The JavaScript equivalent - <a href="https://developer.mozilla.org/en-US/">MDN</a> - pales in comparison.</p><h2 id="the-bad">The bad</h2><h3 id="the-asset-pipeline">The asset pipeline</h3><p>Remember SASS and the YUI Compressor? These are, unfortunately, defaults in the <a href="https://guides.rubyonrails.org/asset_pipeline.html">asset pipeline</a>. Thereâ€™s <a href="https://edgeguides.rubyonrails.org/webpacker.html">Webpacker</a> too, which has a parallel approach to CSS and images as the asset pipeline. It has <a href="https://github.com/rails/webpacker#integrations">opinionated integrations</a> with stuff like React. Ah, and I should mention that Railsâ€™s <a href="https://github.com/rails/rails/tree/main/actionview/app/assets/javascripts">JavaScript utilities are written inâ€¦ CoffeeScript</a>.</p><p>I get it - itâ€™s hard to keep up with the latest trends in frontend. But this is one â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://macwright.com/2021/02/18/a-year-of-rails.html">https://macwright.com/2021/02/18/a-year-of-rails.html</a></em></p>]]>
            </description>
            <link>https://macwright.com/2021/02/18/a-year-of-rails.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26184215</guid>
            <pubDate>Thu, 18 Feb 2021 19:17:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designing a RISC-V CPU, Part 1]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26184136">thread link</a>) | @newswasboring
<br/>
February 18, 2021 | https://mcla.ug/blog/risc-v-cpu-part-1.html#fnref:3 | <a href="https://web.archive.org/web/*/https://mcla.ug/blog/risc-v-cpu-part-1.html#fnref:3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
	
	<p><span>Tue 16 February 2021</span></p><p>I have no experience in digital logic design. That is, I didn't until I
recently decided that I would like to try designing my own CPU and running it
on an FPGA! If you too are a software engineer with a vague interest in
hardware design, I hope this series of posts about what I've learnt will be
helpful and interesting. In this first installment, I hope to answer these
questions:</p>
<ul>
<li>
<p>What is digital logic design?</p>
</li>
<li>
<p>How do I get started, and what tools might I use?</p>
</li>
</ul>
<p>In future installments, I will go into more detail about my CPU design and the
RISC-V architecture, as well as hopefully answering these questions:</p>
<ul>
<li>
<p>What about digital logic design is fundamentally different from software
  design?</p>
</li>
<li>
<p>What about digital logic design is similar to software design?</p>
</li>
</ul>
<p>You can see the code for my CPU at the time of writing
<a href="https://github.com/lochsh/riscy-boi/tree/47e94dc6e9665f73c871add002c34d1516fd5106">here</a>
or an up to date version <a href="https://github.com/lochsh/riscy-boi">here</a>.</p>
<h2>What is digital logic design?</h2>
<p>Digital logic design is designing logic circuits that operate on binary values.
The elementary components are logic gates: an AND gate, for example, has two
inputs and one output. The output is 1 iff<sup id="fnref:1"><a href="#fn:1">1</a></sup> both inputs are 1.</p>
<p>Typically, we design synchronous circuits which use flip-flops to store state,
and thereby synchronise the operation of the circuit to a common clock.
Flip-flops are composed of logic gates.</p>
<p>Analogue circuit design is concerned with the electronic components that make
up logic gates, like transistors and diodes. This level of abstraction is often
needed for applications dealing directly with signals derived from analogue
sensors, like radio receivers. When designing a CPU, this level of abstraction
would not be feasible: modern CPUs can have billions of transistors!</p>
<p>Instead, we use tools that can translate our digital logic design into
different useful formats: the configuration of an FPGA (see below); a
simulation; silicon layout.</p>
<h2>What is an FPGA and why are they used?</h2>
<p>We noted above that the same digital logic design tools can be used whether we
are creating a custom ASIC to be made into silicon, or configuring an FPGA. A
Field-Programmable Gate Array is an integrated circuit containing an array of
programmable logic blocks. You could imagine it is as a big array of logic
gates that can be connected together in various ways.</p>
<p>Making a custom chip generally costs millions, and of course once your chip is
manufactured it cannot be changed. Thus, generally FPGAs are used when:</p>
<ul>
<li>
<p>You cannot afford to create a custom ASIC due to lack of capital (e.g. if
  you're just some hacker like me and not ARM or Intel)</p>
</li>
<li>
<p>You cannot afford to create a custom ASIC because your volume is too low to
  make it worth the high one-off costs (e.g. if you are making a small quantity
  of MRI machines with custom data acquisition hardware)</p>
</li>
<li>
<p>You need the flexibility</p>
</li>
</ul>
<p>The downsides? FPGAs have a much higher per-chip cost, and they are generally
much slower as a consequence of being able to connect logic blocks together in
very flexible ways. In contrast, a custom design can be reduced to the minimum
number of transistors, with no concern for flexibility.</p>
<p>I think it's helpful context to compare the custom ASIC design process against
that of an FPGA design:</p>
<ul>
<li>
<p><span>Logic design</span>: just like we'd do for an FPGA, the logic design of an ASIC is
  done in a hardware description language.</p>
</li>
<li>
<p><span>Verification</span>: FPGA designs may well be verified, but you might expect the
  process for an ASIC design to be more rigorous â€“ after all, the design
  can't be changed once manufactured! Often verification will involve formally
  verifying<sup id="fnref:2"><a href="#fn:2">2</a></sup> parts of the design.</p>
</li>
<li>
<p><span>Synthesis</span>: This creates a <em>netlist</em>: a list of logic blocks and their
  connections. The connections are called <em>nets</em>, and the blocks are called
  <em>cells</em>. For both FPGAs and ASICs, the cells are vendor-specific.</p>
</li>
<li>
<p><span>Placement and routing</span> (P&amp;R): for an FPGA, this involves mapping the logic
  blocks described in the netlist to actual blocks in the FPGA. The resulting
  binary is often called a <em>bitstream</em>.  For an ASIC, this involves deciding
  where to place the cells on the silicon, and how to connect them up. Both
  applications generally use automated optimisation tools for this.</p>
</li>
</ul>
<h2>What tools do I need?</h2>
<h3>A hardware description language: I am using <a href="https://github.com/nmigen/nmigen">nMigen</a><sup id="fnref:3"><a href="#fn:3">3</a></sup></h3>
<p>You may have heard of Verilog or VHDL: both popular hardware description
languages (HDLs). I use "popular" here to mean widely used, not widely loved.</p>
<p>I won't pretend to know much about these tools: I only know that smarter people
than me with vast logic design experience have a lot of hate for them.
Due to the problems with Verilog and other similar tools, there have been
various attempts at making more useful and friendlier alternatives.  nMigen is
one such project, which creates a domain-specific language in Python. In their
own words:</p>
<blockquote>
<p>Despite being faster than schematics entry, hardware design with Verilog and
VHDL remains tedious and inefficient for several reasons. The event-driven
model introduces issues and manual coding that are unnecessary for
synchronous circuits, which represent the lion's share of today's logic
designs. Counterintuitive arithmetic rules result in steeper learning curves
and provide a fertile ground for subtle bugs in designs. Finally, support for
procedural generation of logic (metaprogramming) through "generate"
statements is very limited and restricts the ways code can be made generic,
reused and organized.</p>
<p>To address those issues, we have developed the nMigen FHDL, a library that
replaces the event-driven paradigm with the notions of combinatorial and
synchronous statements, has arithmetic rules that make integers always behave
like mathematical integers, and most importantly allows the design's logic to
be constructed by a Python program. This last point enables hardware
designers to take advantage of the richness of the Python languageâ€”object
oriented programming, function parameters, generators, operator overloading,
libraries, etc.â€”to build well organized, reusable and elegant designs.</p>
</blockquote>
<p>If, like me, you've never used Verilog, then not all of this will have more
than abstract meaning to you. But it certainly sounds promising,
and I can attest that it has been very straightforward to get started with
logic design without the reportedly large barrier of grappling with Verilog. I
would recommend it, particularly if you are already familiar with Python!</p>
<p>The only downside I can think of is that nMigen is still in development, and
in particular the documentation is not complete. There is a helpful community
at #nmigen on <a href="https://mcla.ug/blog/chat.freenode.net">chat.freenode.net</a>.</p>
<h3>A wave viewer for inspecting simulations: I am using <a href="http://gtkwave.sourceforge.net/">GTKWave</a></h3>
<p>nMigen provides simulation tooling: I use it in my tests, written using
<code>pytest</code>. I record the signals during these tests and view them in a wave
viewer to help debug.</p>
<p><img alt="gtkwave" src="https://mcla.ug/blog/images/gtkwave.png" title="A screenshot of GTKWave"></p>
<h3>Optional: An FPGA dev board. I am using a myStorm BlackIce II</h3>
<p>You don't need an FPGA dev board to create your own CPU. You could do
everything in simulation! The fun of having a board to work with, for me, is
being able to flash LEDs and see my design in action.</p>
<p>Of course, if you were creating something more useful than my very basic CPU,
then you would probably want some hardware to run it on, and this would be less
"optional"!</p>
<h2>Getting started with nMigen</h2>
<p>Rather than immediately trying to design a CPU, I started by making an
Arithmetic Logic Unit (ALU) in nMigen. The ALU is a key piece of any CPU design
that I have seen: it performs arithmetic operations.</p>
<p>Why start with this? I knew I would need an ALU for my CPU; I knew I could make
a simple one; I knew that the feeling of making something is an important
motivator when starting a new project!</p>
<p>My design looked something like this:</p>

<div>
<pre id="vimCodeElement"><span id="L1"> 1 </span><span>"""</span><span>Arithmetic Logic Unit</span><span>"""</span>
<span id="L2"> 2 </span><span>import</span> enum
<span id="L3"> 3 </span>
<span id="L4"> 4 </span><span>import</span> nmigen <span>as</span> nm
<span id="L5"> 5 </span>
<span id="L6"> 6 </span>
<span id="L7"> 7 </span><span>class</span> <span>ALUOp</span><span>(</span>enum<span>.</span>IntEnum<span>)</span><span>:</span>
<span id="L8"> 8 </span>    <span>"""</span><span>Operations for the ALU</span><span>"""</span>
<span id="L9"> 9 </span>    ADD <span>=</span> <span>0</span>
<span id="L10">10 </span>    SUB <span>=</span> <span>1</span>
<span id="L11">11 </span>
<span id="L12">12 </span>
<span id="L13">13 </span><span>class</span> <span>ALU</span><span>(</span>nm<span>.</span>Elaboratable<span>)</span><span>:</span>
<span id="L14">14 </span>    <span>"""</span>
<span id="L15">15 </span><span>    Arithmetic Logic Unit</span>
<span id="L16">16 </span>
<span id="L17">17 </span><span>    * op (in): the opcode</span>
<span id="L18">18 </span><span>    * a (in): the first operand</span>
<span id="L19">19 </span><span>    * b (in): the second operand</span>
<span id="L20">20 </span>
<span id="L21">21 </span><span>    * o (out): the output</span>
<span id="L22">22 </span><span>    </span><span>"""</span>
<span id="L23">23 </span>
<span id="L24">24 </span>    <span>def</span> <span>__init__</span><span>(</span>self<span>,</span> width<span>)</span><span>:</span>
<span id="L25">25 </span>        <span>"""</span>
<span id="L26">26 </span><span>        Initialiser</span>
<span id="L27">27 </span>
<span id="L28">28 </span><span>        Args:</span>
<span id="L29">29 </span><span>            width (int): data width</span>
<span id="L30">30 </span><span>        </span><span>"""</span>
<span id="L31">31 </span>        self<span>.</span>op <span>=</span> nm<span>.</span>Signal<span>()</span>
<span id="L32">32 </span>        self<span>.</span>a <span>=</span> nm<span>.</span>Signal<span>(</span>width<span>)</span>
<span id="L33">33 </span>        self<span>.</span>b <span>=</span> nm<span>.</span>Signal<span>(</span>width<span>)</span>
<span id="L34">34 </span>        self<span>.</span>o <span>=</span> nm<span>.</span>Signal<span>(</span>width<span>)</span>
<span id="L35">35 </span>
<span id="L36">36 </span>    <span>def</span> <span>elaborate</span><span>(</span>self<span>,</span> _<span>)</span><span>:</span>
<span id="L37">37 </span>        m <span>=</span> nm<span>.</span>Module<span>()</span>
<span id="L38">38 </span>
<span id="L39">39 </span>        <span>with</span> m<span>.</span>Switch<span>(</span>self<span>.</span>op<span>)</span><span>:</span>
<span id="L40">40 </span>            <span>with</span> m<span>.</span>Case<span>(</span>ALUOp<span>.</span>ADD<span>)</span><span>:</span>
<span id="L41">41 </span>                m<span>.</span>d<span>.</span>comb <span>+=</span> self<span>.</span>o<span>.</span>eq<span>(</span>self<span>.</span>a <span>+</span> self<span>.</span>b<span>)</span>
<span id="L42">42 </span>            <span>with</span> m<span>.</span>Case<span>(</span>ALUOp<span>.</span>SUB<span>)</span><span>:</span>
<span id="L43">43 </span>                m<span>.</span>d<span>.</span>comb <span>+=</span> self<span>.</span>o<span>.</span>eq<span>(</span>self<span>.</span>a <span>-</span> self<span>.</span>b<span>)</span>
<span id="L44">44 </span>        <span>return</span> m
</pre>
</div>

<p>As you can see, we've created a lot of nMigen <code>Signal</code> instances to represent
well...the signals that define the interface to our ALU! But what is this
<code>elaborate</code> method? My understanding is that "elaboration" is the name for the
first step in synthesising the netlist (see above). The idea in the nMigen code
above is that we've created some <em>elaboratable</em> structure (by inheriting from
<code>nm.Elaboratable</code>), i.e. something that describes digital logic we want to
synthesise. The <code>elaborate</code> method describes that digital logic. It has to
return an nMigen <code>Module</code>.</p>
<p>Let's have a closer look at the contents of the <code>elaborate</code> method. The
<code>Switch</code> will create some kind of decision logic in the synthesised design.
But what is <code>m.d.comb</code>? nMigen has the concept of synchronous (<code>m.d.sync</code>)
and combinatorial<sup id="fnref:4"><a href="#fn:4">4</a></sup> (<code>m.d.comb</code>) control domains. From the nMigen
<a href="https://nmigen.info/nmigen/latest/lang.html#lang-domains">docs</a>:</p>
<blockquote>
<p>A control domain is a named group of signals that change their value in
identical conditions.</p>
<p>All designs have a single predefined <em>combinatorial domain</em>, containing all
signals that change immediately when any value used to compute them changes.
The name comb is reserved for the combinatorial domain.</p>
<p>A design can also have any amount of user-defined <em>synchronous domains</em>, also
called clock domains, containing signals that change when a specific edge
occurs on the domainâ€™s â€¦</p></blockquote></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mcla.ug/blog/risc-v-cpu-part-1.html#fnref:3">https://mcla.ug/blog/risc-v-cpu-part-1.html#fnref:3</a></em></p>]]>
            </description>
            <link>https://mcla.ug/blog/risc-v-cpu-part-1.html#fnref:3</link>
            <guid isPermaLink="false">hacker-news-small-sites-26184136</guid>
            <pubDate>Thu, 18 Feb 2021 19:11:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scala 3.0.0-RC1 â€“ first release candidate is here]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 4 (<a href="https://news.ycombinator.com/item?id=26184110">thread link</a>) | @tmfi
<br/>
February 18, 2021 | https://dotty.epfl.ch/blog/2021/02/17/scala3-rc1.html | <a href="https://web.archive.org/web/*/https://dotty.epfl.ch/blog/2021/02/17/scala3-rc1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-wrapper"> 
   <main> 
    <header> 
      
      
    </header> 
    <p>Greetings from the Scala 3 team! We are delighted to announce the first release candidate of the stable version of Scala 3 â€“ Scala 3.0.0-RC1.</p> 
    <p>This release brings some last-minute polishings, clean-ups and changes before the big release. There were a few language changes to improve the user experience, as well as the polishings of the metaprogramming framework. We have also worked on the issues that had to be fixed before the stable release.</p> 
    <p>Overall, more than <a href="https://github.com/lampepfl/dotty/pulls?q=is%3Apr+is%3Aclosed+closed%3A%3E2020-12-02+sort%3Acomments-desc">400 PRs</a> were merged after the M3 release and until today! Read more below!</p> <!--more--> 
     
    <p>Type parameters on extensions can now be combined with type parameters on the methods themselves. E.g.:</p> 
    <pre><code>List(1, 2, 3).second[Int]
extension [A](xs: List[A])
   def sumBy[B](f: A =&gt; B)(using Numeric[B]): B = ...
</code></pre> 
    <p>Type arguments matching method type parameters are passed as usual:</p> 
    <pre><code>List("a", "bb", "ccc").sumBy[Int](_.length)
</code></pre> 
    <p>By contrast, type arguments matching type parameters following <code>extension</code> can be passed only if the method is referenced as a non-extension method:</p> 
    <pre><code>sumBy[String](List("a", "bb", "ccc"))(_.length)
</code></pre> 
    <p>Or, when passing both type arguments:</p> 
    <pre><code>sumBy[String](List("a", "bb", "ccc"))[Int](_.length)
</code></pre> 
    <p>For discussion, see <a href="https://github.com/lampepfl/dotty/pull/10940">PR #10940</a>. For more information about the extension methods, see <a href="https://dotty.epfl.ch/docs/reference/contextual/extension-methods.html">documentation</a>.</p> 
     
    <p>The following are the changes to the <code>import</code> syntax made in this release.</p> 
    <p>Wildcard import <code>_</code> is replaced by <code>*</code>. The motivation is that the majority of other languages use <code>*</code>. For example:</p> 
    <pre><code>import scala.annotation.*  // imports everything in the annotation package
</code></pre> 
    <p>Renaming operator <code>=&gt;</code> is replaced by a soft keyword <code>as</code>. <code>as</code> is also allowed outside braces. For example:</p> 
    <pre><code>import scala.collection.mutable as mut
import NumPy as np
</code></pre> 
    <p>For the details and discussion, see <a href="https://github.com/lampepfl/dotty/pull/11244">PR #11244</a>. Read more about this change in the <a href="https://dotty.epfl.ch/docs/reference/changed-features/imports.html">documentation</a>.</p> 
     
    <p><a href="https://github.com/lampepfl/dotty/pull/11240">PR #11240</a> changed the syntax of vararg splices in patterns and function arguments. The new syntax uses a postfix <code>*</code>, instead of <code>: _*</code>, analogously to how a vararg parameter is declared.</p> 
     
    <p>An obscure use of <code>_</code> occurs in var definitions:</p> 
    <pre><code>var x: T = _
</code></pre> 
    <p>It defines a concrete variable x without an initial value, or rather the default initial value that the JVM assigns to object fields. It can only be used in a class or object, not to initialize a local variable.</p> 
    <p>We came up with an arguably better way to express this idiom: the special <code>uninitialized</code> value in the <code>scala.compiletime</code> object. To get an uninitialized field, you now write:</p> 
    <pre><code>import scala.compiletime.uninitialized

var x: A = uninitialized
</code></pre> 
    <p>This way expresses the intent of the idiom in a more verbose and easy to read way than simply writing an underscore.</p> 
    <p>For discussion, see <a href="https://github.com/lampepfl/dotty/pull/11231">PR #11231</a>, and the <a href="https://dotty.epfl.ch/docs/reference/dropped-features/wildcard-init.html">documentation</a> is available on our website.</p> 
     
    <p>Starting from RC1, we no longer generate a function parent for companions of case classes. Which means, for example, that given <code>case class Foo(x: Int)</code>, you won't be able to use <code>Foo</code> in a position where a function is expected:</p> 
    <pre><code>case class Foo(x: Int)
def f(g: Int =&gt; Foo) = g(10)

f(Foo)
</code></pre> 
    <p>Results in:</p> 
    <pre><code>1 |f(Foo)
  |  ^^^
  |The method `apply` is inserted. The auto insertion will be deprecated, please write `Foo.apply` explicitly.
</code></pre> 
    <p>As the warning suggests, now you should write <code>Foo.apply</code> instead of <code>Foo</code>. See <a href="https://github.com/lampepfl/dotty/issues/6190">Issue #6190</a> and <a href="https://github.com/lampepfl/dotty/pull/7207">PR #7207</a> for discussion.</p> 
     
    <p>We have settled on using the well-known <code>scaladoc</code> as a name for the documentation tool for Scala 3 (known previously as <code>scala3doc</code>).. The obsolete <code>dotty-doc</code> (or <code>scala3-doc</code>) is removed in RC1. We have also removed all the Kotlin dependencies (Dokka, etc.) from scaladoc. For details, see <a href="https://github.com/lampepfl/dotty/pull/11349">PR #11349</a>. To read more about <code>scaladoc</code>, see <a href="https://dotty.epfl.ch/docs/usage/scaladoc/index.html">documentation</a></p> 
     
    <p><a href="https://github.com/lampepfl/dotty/pull/11355">PR #11355</a> changes the <code>-source</code> specifier for the Scala version(s) after 3.0 from <code>3.1</code> to <code>future</code>. I.e. it is now <code>-source future</code> and <code>-source future-migration</code> instead of <code>-source 3.1</code> and <code>-source 3.1-migration</code>. Language imports are changed analogously. The reason for the change is that we want to keep the possibility open to ship a <code>3.1</code> version that does not yet contain all the changes enabled under <code>-source future</code>.</p> 
     
    <ul> 
     <li>Warn when matching against an opaque type <a href="https://github.com/lampepfl/dotty/pull/10664">#10664</a></li> 
     <li>Fix <a href="https://github.com/lampepfl/dotty/issues/8634">#8634</a>: Support -release option <a href="https://github.com/lampepfl/dotty/pull/10746">#10746</a> â€“ the same way Scala 2 does. This setting allows you to specify a version of the Java platform (8, 9 etc) and compile the code with classes specific to the that Java platform, and emit the bytecode for that version.</li> 
    </ul> 
     
    <p>A lot of work has been done on the metaprogramming side of things. Mostly we are cleaning up and polishing the API to prepare it for the stable release. The following are the important metaprogramming changes that took place:</p> 
    <ul> 
     <li>Add <code>scala.quoted.Expr.unapply</code> as dual of <code>Expr.apply</code> <a href="https://github.com/lampepfl/dotty/pull/10580">#10580</a></li> 
     <li>Remove <code>Expr.StringContext.unapply</code> <a href="https://github.com/lampepfl/dotty/pull/10675">#10675</a></li> 
     <li>Add reflect <code>MatchCase</code> <code>TypeRepr</code> <a href="https://github.com/lampepfl/dotty/pull/10735">#10735</a></li> 
     <li>Rename <code>scala.quoted.staging.{Toolbox =&gt; Compiler}</code> <a href="https://github.com/lampepfl/dotty/pull/11129">#11129</a></li> 
     <li>Fix <a href="https://github.com/lampepfl/dotty/issues/10863">#10863</a>: Make show <code>AnyKind</code>ed <a href="https://github.com/lampepfl/dotty/pull/10988">#10988</a></li> 
     <li>Add ParamClause to allow multiple type param clauses <a href="https://github.com/lampepfl/dotty/pull/11074">#11074</a></li> 
     <li>Rework reflect Symbol fields API <a href="https://github.com/lampepfl/dotty/pull/10705">#10705</a></li> 
     <li>Rename <code>Liftable</code> to <code>ToExpr</code> and <code>Unliftable</code> to <code>FromExpr</code> <a href="https://github.com/lampepfl/dotty/pull/10618">#10618</a></li> 
     <li>Expand non-transparent macros after Typer <a href="https://github.com/lampepfl/dotty/pull/9984">#9984</a></li> 
     <li>Rework TastyInspector API to allow inspection of all files <a href="https://github.com/lampepfl/dotty/pull/10792">#10792</a></li> 
     <li>Allow leading context parameters in extension methods <a href="https://github.com/lampepfl/dotty/pull/10940">#10940</a></li> 
     <li>Rename <code>Not</code> to <code>NotGiven</code> to make its purpose clearer <a href="https://github.com/lampepfl/dotty/pull/10720">#10720</a></li> 
     <li>Fix <a href="https://github.com/lampepfl/dotty/issues/10709">#10709</a>: Add missing level check before inlining <a href="https://github.com/lampepfl/dotty/pull/10781">#10781</a></li> 
    </ul> 
     
    <p>If you have questions or any sort of feedback, feel free to send us a message on our <a href="https://gitter.im/lampepfl/dotty">Gitter channel</a>. If you encounter a bug, please <a href="https://github.com/lampepfl/dotty/issues/new">open an issue on GitHub</a>.</p> 
    <h2><a href="#contributors" id="contributors"></a>Contributors</h2> 
    <p>Thank you to all the contributors who made this release possible ğŸ‰</p> 
    <p>According to <code>git shortlog -sn --no-merges 3.0.0-M3..3.0.0-RC1</code> these are:</p> 
    <pre><code>   183  Martin Odersky
   138  Nicolas Stucki
    36  Krzysztof Romanowski
    25  Filip ZybaÅ‚a
    25  Liu Fengyun
    24  Lan, Jian
    22  Jamie Thompson
    19  Tom Grigg
    17  Andrzej Ratajczak
    16  StÃ©phane Micheloud
    15  Guillaume Martres
    11  PaweÅ‚ Marks
     9  Phil
     6  Aleksander Boruch-Gruszecki
     6  Jonathan BrachthÃ¤user
     6  Natsu Kagami
     6  odersky
     4  Jasper Moeys
     4  Adrien Piquerez
     3  SÃ©bastien Doeraene
     3  MichaÅ‚ PaÅ‚ka
     3  Albert Chen
     2  Alexandre Archambault
     2  Som Snytt
     2  kenji yoshida
     2  Luc Henninger
     2  Ayush
     2  Raphael Jolly
     2  Anatolii Kmetiuk
     2  Olivier Blanvillain
     2  changvvb
     1  ysthakur
     1  Ang Hao Yang
     1  Ang9876
     1  AngAng
     1  August Nagro
     1  Ciara O'Brien
     1  Dale Wijnand
     1  Florian Cassayre
     1  Florian Schmaus
     1  Iltotore
     1  Jason Zaugg
     1  Julien Richard-Foy
     1  Katrix
     1  Master-Killer
     1  Michael Pilquist
     1  Mikael Blomstrand
     1  Mike Samuel
     1  Philippus
     1  Philippus Baalman
     1  Rick M
     1  Stephane MICHELOUD
     1  Timur Abishev
     1  Tomas
     1  ansvonwa
     1  ayush
     1  costa100
     1  iroha168
     1  noti0na1
     1  riiswa
     1  tanishiking
</code></pre> 
    <p>If you want to get your hands dirty and contribute to Scala 3, now is a good time to get involved! Head to our <a href="https://dotty.epfl.ch/docs/contributing/getting-started.html">Getting Started page for new contributors</a>, and have a look at some of the <a href="https://github.com/lampepfl/dotty/issues?q=is%3Aissue+is%3Aopen+label%3Aexp%3Anovice">good first issues</a>. They make perfect entry points into hacking on the compiler.</p> 
    <p>We are looking forward to having you join the team of contributors.</p> 
    <hr> 
    <p><img id="author-img" src="https://dotty.epfl.ch/images/anatolii.png"> <span id="author-signature"> Anatolii Kmetiuk </span> 
    </p> 
   </main> 
  </div></div>]]>
            </description>
            <link>https://dotty.epfl.ch/blog/2021/02/17/scala3-rc1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26184110</guid>
            <pubDate>Thu, 18 Feb 2021 19:09:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rockset is up to 9.4 times faster than Druid on Star Schema Benchmark queries]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26184105">thread link</a>) | @box2A1
<br/>
February 18, 2021 | https://rockset.com/blog/rockset-up-to-9x-faster-than-apache-druid-star-schema-benchmark/ | <a href="https://web.archive.org/web/*/https://rockset.com/blog/rockset-up-to-9x-faster-than-apache-druid-star-schema-benchmark/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Real-time analytics is all about deriving insights and taking actions as soon as data is produced. When broken down into its core requirements, real-time analytics means two things: access to fresh data and fast responses to queries. These are essentially two measures of latency, which we term data latency and query latency, respectively.</p>
<p>Data latency is the time from when data is produced to when it can be queried, and is a function of how efficiently a database can sustain writes. As it usually gets less focus in benchmarks, we released <a href="https://rockset.com/blog/rockset-1-billion-events-in-a-day-with-1-second-data-latency/">RockBench</a>, a data latency benchmark, last September. Using RockBench, we ascertained Rocksetâ€™s suitability for many real-time analytics applications due to its ability to keep data latency to under 1 second, while ingesting 1 billion events per day, on a standard 4XLarge Virtual Instance.</p>
<h3>Query Latency and the Star Schema Benchmark</h3>
<p>Query latency is the second key measure of real-time analytics performance and is the focus of the rest of this post.
To evaluate query latency, we turned to the Star Schema Benchmark (SSB), an industry-standard benchmark to measure database performance on analytical applications. The SSB was designed for a batch analytics scenario, rather than real-time analytics, but will still yield useful insight into Rocksetâ€™s performance on analytical queries.</p>
<p>The SSB has also been used for performance measurements of other modern data technologies. In June 2020, Imply released a <a href="https://go.imply.io/rs/910-OTN-223/images/Apache-Druid-and-Google-BigQuery-performance-evaluation.pdf">study</a> of Apache Druid and Google BigQuery performance on the SSB. For the Rockset benchmark, we used the same hardware resources that were used in the Druid benchmark to provide greater context for our SSB evaluation.</p>
<h3>Up to 9.4x Faster than Druid</h3>
<p>From the benchmarking results, we observed one SSB query execute 9.4x faster on Rockset than on Druid, with many queries running 2x to 4x faster. The entire SSB suite ran 1.5x faster on <a href="https://rockset.com/comparisons/rockset-vs-apache-druid">Rockset compared to Druid</a>. This demonstrates better performance with resource parity, since pricing was not available for a true price-performance comparison.</p>
<p>In making these comparisons, we recognize we are not experts in configuring Druid, so we relied on a benchmark report from those who have the most knowledge about their system and can tune it best. In addition, benchmarks represent a snapshot in time, and systems will get faster with each new release. We are using the most recent benchmark published by Imply for comparison, but we expect Druid performance will continue to improve, as will Rocksetâ€™s.</p>
<h3>Running the Star Schema Benchmark on Rockset</h3>
<p><strong>Benchmark Overview</strong></p>
<p>The SSB comprises a suite of 13 analytical SQL queries that provide a good combination of functional and selectivity coverage.</p>
<p>We conducted the benchmark using SSB data at scale factor 100, which corresponds to 100GB and 600M rows of data. We denormalized the generated data prior to loading to provide a more direct comparison to the Druid benchmark, which avoided query-time joins, since Druid only recently added some limited join support.</p>
<p><span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/1d31s1aajogl/6wQnA481EPGFKQEBq9jqlD/c385adf28f987ec64149ee5ce6b6af4c/rockset-ssb-diagram.png?w=560&amp;fm=webp 560w,
https://images.ctfassets.net/1d31s1aajogl/6wQnA481EPGFKQEBq9jqlD/c385adf28f987ec64149ee5ce6b6af4c/rockset-ssb-diagram.png?w=1120&amp;fm=webp 1120w,
https://images.ctfassets.net/1d31s1aajogl/6wQnA481EPGFKQEBq9jqlD/c385adf28f987ec64149ee5ce6b6af4c/rockset-ssb-diagram.png?w=2240&amp;fm=webp 2240w" sizes="(max-width: 590px) 100vw, 590px" type="image/webp">
          <source srcset="https://images.ctfassets.net/1d31s1aajogl/6wQnA481EPGFKQEBq9jqlD/c385adf28f987ec64149ee5ce6b6af4c/rockset-ssb-diagram.png?w=560 560w,
https://images.ctfassets.net/1d31s1aajogl/6wQnA481EPGFKQEBq9jqlD/c385adf28f987ec64149ee5ce6b6af4c/rockset-ssb-diagram.png?w=1120 1120w,
https://images.ctfassets.net/1d31s1aajogl/6wQnA481EPGFKQEBq9jqlD/c385adf28f987ec64149ee5ce6b6af4c/rockset-ssb-diagram.png?w=2240 2240w" sizes="(max-width: 590px) 100vw, 590px">
          <img alt="rockset-ssb-diagram" title="" src="https://images.ctfassets.net/1d31s1aajogl/6wQnA481EPGFKQEBq9jqlD/c385adf28f987ec64149ee5ce6b6af4c/rockset-ssb-diagram.png" loading="lazy">
        </picture>
        </span>
      </span>
<em>Figure 1: Performance harness used to generate and load SSB data, run queries and measure query runtimes</em></p>
<p>Loading into Rockset was straightforward and required zero configuration, apart from specifying some keys for column-based clustering. Once the SSB data was loaded into Rockset, we ran a load-generator query script, based on the Rockset Python client, that issued queries and measured runtimes.</p>
<p><strong>Benchmark Results</strong></p>
<p>We recorded the following runtimes across the 13 SSB queries.</p>
<p><span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/1d31s1aajogl/gtyqIwjx5kKG2PxpXGrJk/2842c3354e855724fee008c2a252a1da/rockset-ssb-results.png?w=281&amp;fm=webp 281w,
https://images.ctfassets.net/1d31s1aajogl/gtyqIwjx5kKG2PxpXGrJk/2842c3354e855724fee008c2a252a1da/rockset-ssb-results.png?w=562&amp;fm=webp 562w,
https://images.ctfassets.net/1d31s1aajogl/gtyqIwjx5kKG2PxpXGrJk/2842c3354e855724fee008c2a252a1da/rockset-ssb-results.png?w=1124&amp;fm=webp 1124w" sizes="(max-width: 590px) 100vw, 590px" type="image/webp">
          <source srcset="https://images.ctfassets.net/1d31s1aajogl/gtyqIwjx5kKG2PxpXGrJk/2842c3354e855724fee008c2a252a1da/rockset-ssb-results.png?w=281 281w,
https://images.ctfassets.net/1d31s1aajogl/gtyqIwjx5kKG2PxpXGrJk/2842c3354e855724fee008c2a252a1da/rockset-ssb-results.png?w=562 562w,
https://images.ctfassets.net/1d31s1aajogl/gtyqIwjx5kKG2PxpXGrJk/2842c3354e855724fee008c2a252a1da/rockset-ssb-results.png?w=1124 1124w" sizes="(max-width: 590px) 100vw, 590px">
          <img alt="rockset-ssb-results" title="" src="https://images.ctfassets.net/1d31s1aajogl/gtyqIwjx5kKG2PxpXGrJk/2842c3354e855724fee008c2a252a1da/rockset-ssb-results.png" loading="lazy">
        </picture>
        </span>
      </span>
<em>Figure 2: Benchmark results when running SSB on Rockset (600M rows, 100GB data set)</em></p>
<p>All queries in the SSB suite executed in under 1 second on Rockset, with a median runtime of 254 ms. This result demonstrates Rocksetâ€™s ability to run complex analytics with sub-second performance, a common requirement for real-time analytics applications.</p>
<p>When comparing to these results with Druidâ€™s, we observe that 9 out of the 13 queries ran faster on Rockset. Rockset was 9.4x faster on the query with the largest speedup, with many queries in the 2x to 4x range, whereas Druidâ€™s largest advantage was a 3.2x speedup. The suite of 13 queries completed in 4,146 ms on Rockset compared to 6,043 ms on Druid, corresponding to a 1.5x speedup overall. The following figures show Rocksetâ€™s query runtimes compared to those reported in Implyâ€™s Druid and BigQuery paper.</p>
<p><span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/1d31s1aajogl/3iI6RKmdNIU1LMPZADHr4L/c85c70cd8a53d8a2e25f1359e210f5ab/rockset-druid-ssb.png?w=408&amp;fm=webp 408w,
https://images.ctfassets.net/1d31s1aajogl/3iI6RKmdNIU1LMPZADHr4L/c85c70cd8a53d8a2e25f1359e210f5ab/rockset-druid-ssb.png?w=815&amp;fm=webp 815w,
https://images.ctfassets.net/1d31s1aajogl/3iI6RKmdNIU1LMPZADHr4L/c85c70cd8a53d8a2e25f1359e210f5ab/rockset-druid-ssb.png?w=1630&amp;fm=webp 1630w" sizes="(max-width: 590px) 100vw, 590px" type="image/webp">
          <source srcset="https://images.ctfassets.net/1d31s1aajogl/3iI6RKmdNIU1LMPZADHr4L/c85c70cd8a53d8a2e25f1359e210f5ab/rockset-druid-ssb.png?w=408 408w,
https://images.ctfassets.net/1d31s1aajogl/3iI6RKmdNIU1LMPZADHr4L/c85c70cd8a53d8a2e25f1359e210f5ab/rockset-druid-ssb.png?w=815 815w,
https://images.ctfassets.net/1d31s1aajogl/3iI6RKmdNIU1LMPZADHr4L/c85c70cd8a53d8a2e25f1359e210f5ab/rockset-druid-ssb.png?w=1630 1630w" sizes="(max-width: 590px) 100vw, 590px">
          <img alt="rockset-druid-ssb" title="" src="https://images.ctfassets.net/1d31s1aajogl/3iI6RKmdNIU1LMPZADHr4L/c85c70cd8a53d8a2e25f1359e210f5ab/rockset-druid-ssb.png" loading="lazy">
        </picture>
        </span>
      </span>
<em>Figure 3: Comparing Rockset and Druid SSB results</em></p>
<p><span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/1d31s1aajogl/2nTaKbhcNK407P8T9r15ye/477be128e68d9a5535629d2cbccbbb7f/rockset-ssb-graph.png?w=429&amp;fm=webp 429w,
https://images.ctfassets.net/1d31s1aajogl/2nTaKbhcNK407P8T9r15ye/477be128e68d9a5535629d2cbccbbb7f/rockset-ssb-graph.png?w=857&amp;fm=webp 857w,
https://images.ctfassets.net/1d31s1aajogl/2nTaKbhcNK407P8T9r15ye/477be128e68d9a5535629d2cbccbbb7f/rockset-ssb-graph.png?w=1714&amp;fm=webp 1714w" sizes="(max-width: 590px) 100vw, 590px" type="image/webp">
          <source srcset="https://images.ctfassets.net/1d31s1aajogl/2nTaKbhcNK407P8T9r15ye/477be128e68d9a5535629d2cbccbbb7f/rockset-ssb-graph.png?w=429 429w,
https://images.ctfassets.net/1d31s1aajogl/2nTaKbhcNK407P8T9r15ye/477be128e68d9a5535629d2cbccbbb7f/rockset-ssb-graph.png?w=857 857w,
https://images.ctfassets.net/1d31s1aajogl/2nTaKbhcNK407P8T9r15ye/477be128e68d9a5535629d2cbccbbb7f/rockset-ssb-graph.png?w=1714 1714w" sizes="(max-width: 590px) 100vw, 590px">
          <img alt="rockset-ssb-graph" title="" src="https://images.ctfassets.net/1d31s1aajogl/2nTaKbhcNK407P8T9r15ye/477be128e68d9a5535629d2cbccbbb7f/rockset-ssb-graph.png" loading="lazy">
        </picture>
        </span>
      </span>
<em>Figure 4: Graph showing Rockset, Druid and BigQuery runtimes on SSB queries</em></p>
<h3>How Rockset Accelerates Real-Time Analytics</h3>
<p>Several Rockset features work in concert to accelerate these SSB queries and real-time analytics in general.</p>
<ul>
<li>Converged Indexâ„¢</li>
<li>Column-based clustering</li>
<li>Vectorization</li>
</ul>
<p><strong>Converged Index</strong></p>
<p>Rockset stores all ingested data in a <a href="https://rockset.com/blog/how-rocksets-converged-index-powers-real-time-analytics/">Converged Index</a>, which is a combination of: </p>
<ul>
<li>Inverted index</li>
<li>Column-based index</li>
<li>Row-based index</li>
</ul>
<p>Each query can take advantage of the index that is best suited for it and leads to the fastest execution. For instance, highly selective queries typically benefit from using the inverted index, while queries that require aggregations over large numbers of records will benefit from using the column-based index. By indexing data in three different ways, multiple types of queries can be executed efficiently without any manual intervention.</p>
<p><strong>Column-based clustering</strong></p>
<p>Users can configure column-based clustering so as to colocate data according to a clustering key they specify. This maximizes the opportunity for sequential access and reduces the amount of data that needs to be scanned for each query.</p>
<p><strong>Vectorization</strong></p>
<p>Rockset uses columnar data chunks to exchange data between query execution operators. This allows vectorized processing, where operations are performed on many values, instead of one value, at a time, resulting in more efficient query execution.</p>
<h3>What This Means for Developers of Real-Time Analytics</h3>
<p>With this SSB performance evaluation, we determined that Rockset is capable of delivering the sub-second query latency needed for real-time analytics, with better performance than alternatives like Druid. Coupled with the earlier RockBench evaluation that established Rocksetâ€™s ability to analyze data being written in real time, we see that Rockset can be a good fit for real-time analytics applications that require fast queries on the latest data. These include many use cases like logistics tracking, security analytics, e-commerce personalization, gaming leaderboards and customer-facing SaaS analytics.</p>
<p>While this evaluation was performed on a denormalized data set, Rockset's design also allows it to execute joins efficiently, so applications are not limited to operating on denormalized data. Future work would include running Rockset performance evaluations involving joins on normalized data.</p>
<p>Additionally, SSB data is well structured and therefore less representative of the real-life semi-structured data sets we commonly come across. It should be noted that Rockset can support the same analytical SQL queries on complex, nested data as well.</p>
<p>Given Rocksetâ€™s ability to provide both the write and read performance required for real-time analytics, we invite you to include Rockset in your consideration if you are developing real-time analytics features or products. Read the <a href="http://rockset.com/star-schema-benchmark">Rockset Performance Evaluation on the Star Schema Benchmark</a> white paper to get the details on how we ran the SSB evaluation. Or, <a href="https://console.rockset.com/create">sign up for a free Rockset account</a> to try running your own queries on Rockset!</p></div></div>]]>
            </description>
            <link>https://rockset.com/blog/rockset-up-to-9x-faster-than-apache-druid-star-schema-benchmark/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26184105</guid>
            <pubDate>Thu, 18 Feb 2021 19:09:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimizing jQuery DOM Manipulation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26183834">thread link</a>) | @pazvanti
<br/>
February 18, 2021 | https://petrepopescu.tech/2021/02/optimizing-jquery-dom-manipulation/ | <a href="https://web.archive.org/web/*/https://petrepopescu.tech/2021/02/optimizing-jquery-dom-manipulation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>If you are working with JavaScript then most probably jQuery is a library you are using quite frequently. jQuery is useful and provides many features that are harder to achieve with basic JavaScript. Due to the fact that it usually runs on the client-side, many donâ€™t pay too much attention to optimizing the code. That is why there are many websites that load slowly, have sluggish UIs, or seem to respond with delay. So, in this article, I will show an optimization technique that can save a lot of time when rendering the page with dynamically added elements.</p><h4>Our scenario: Loading products without reloading the page</h4><p>Let us take a look at a common use case where this technique may be useful. You are a developer that is working on an online store. Because of the nature of the infrastructure and the clientâ€™s requirements, React is not an option so you fall back to a more â€œtraditionalâ€ approach. There is only one server application, being it Play (Java/Scala), CodeIgniter (PHP) or any other framework that using a template engine renders the DOM of the pages.</p><p>Now, as part of the catalog navigation feature, you get the partial result (in batches of 100 items) and display them on the page with a pagination menu at the bottom. When the next page is clicked, instead of physically going to a new page, you use AJAX calls to get the new items and do DOM manipulation to display them. The steps are like this:</p><ol><li>AJAX call to /items?page=&lt;pageNumber&gt;</li><li>Receive response as JSON</li><li>Clear the existing displayed items from the page</li><li>Rebuild the DOM with the new items</li></ol><h4>First implementation (bad): Rendering each element individually</h4><p>Let us look at a portion of the code. This function creates the HTML for a product and alters the DOM so that it is displayed on the page (image, name, and price)</p><pre><code lang="javascript">function&nbsp;makeItemOnPage(item,&nbsp;itemNo)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;we&nbsp;create&nbsp;a&nbsp;container&nbsp;for&nbsp;the&nbsp;current&nbsp;item
&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;itemContainer&nbsp;=&nbsp;'&lt;div&nbsp;class="col-sm-2&nbsp;itemContainer"&nbsp;id="item-'&nbsp;+&nbsp;itemNo&nbsp;+&nbsp;'"&nbsp;style="padding:&nbsp;10px"&gt;&lt;/div&gt;';
&nbsp;&nbsp;&nbsp;&nbsp;$("#products").append(itemContainer);

&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;we&nbsp;create&nbsp;a&nbsp;div&nbsp;for&nbsp;the&nbsp;product&nbsp;imate&nbsp;and&nbsp;display&nbsp;it
&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;productImage&nbsp;=&nbsp;'&lt;div&nbsp;class="productImage"&nbsp;id="productImage-'&nbsp;+&nbsp;itemNo&nbsp;+&nbsp;'"&gt;&lt;/div&gt;';
&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;currentItemContainer&nbsp;=&nbsp;$("#products").find("#item-"&nbsp;+&nbsp;itemNo);
&nbsp;&nbsp;&nbsp;&nbsp;currentItemContainer.append(productImage);
&nbsp;&nbsp;&nbsp;&nbsp;$("#productImage-"+itemNo).append('&lt;img&nbsp;src="'&nbsp;+&nbsp;item.image&nbsp;+&nbsp;'"&nbsp;/&gt;');

&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;We&nbsp;append&nbsp;the&nbsp;product&nbsp;name&nbsp;and&nbsp;the&nbsp;price
&nbsp;&nbsp;&nbsp;&nbsp;currentItemContainer.append('&lt;/div&gt;&lt;div&nbsp;class="productDetails"&gt;&lt;strong&gt;'&nbsp;+&nbsp;item.name&nbsp;+&nbsp;'&lt;/strong&gt;&nbsp;-&nbsp;'&nbsp;+&nbsp;item.price&nbsp;+&nbsp;'$');

&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;We&nbsp;create&nbsp;an&nbsp;Add&nbsp;To&nbsp;Cart&nbsp;button
&nbsp;&nbsp;&nbsp;&nbsp;currentItemContainer.append('&lt;button&nbsp;type="button"&nbsp;class="btn&nbsp;btn-success&nbsp;btn-block"&gt;&lt;i&nbsp;class="fa&nbsp;fa-bell"&gt;&lt;/i&gt;&nbsp;Add&nbsp;to&nbsp;cart&lt;/button&gt;')
}</code></pre><div><figure><img loading="lazy" width="471" height="246" src="https://petrepopescu.tech/wp-content/uploads/2021/01/image-5.png" alt="" srcset="https://petrepopescu.tech/wp-content/uploads/2021/01/image-5.png 471w, https://petrepopescu.tech/wp-content/uploads/2021/01/image-5-300x157.png 300w" sizes="(max-width: 471px) 100vw, 471px"></figure></div><p>Let us render 1000 items in total and see the time it takes. I exaggerated a bit the number of items so that the total gains from optimization to be better shown. We can easily see how long it takes by using the browserâ€™s performance analyzer. As can be seen in the image, it took about 1.7 seconds for the items to be rendered on the page. It may not seem much (we do have 1000 items), but the HTML in this case is quite simple and does not have too many inner objects. A page that has a much more complex design can easily have a more complex HTML code for each item. And even so, the user having to wait almost 2 seconds for the items to get displayed is not good from an UX point of view. I think we can optimize things quite a lot.</p><p>First thing we see is that we do a lot of search for elements in the page and many appends. We search for the items container, append a div for the current item container, search for it, append the image, append the name and price and after that another append for the button. Analyzing the times in the Performance Inspector, we see that those appends take quite a long time, almost equal to the total time. So, letâ€™s try creating the HTML for the entire item as one string and appending it all once.</p><p>The code is like this:</p><pre><code lang="javascript">function&nbsp;makeItemOnPage(item,&nbsp;itemNo)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;we&nbsp;create&nbsp;a&nbsp;container&nbsp;for&nbsp;the&nbsp;current&nbsp;item
&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;productImageHtml&nbsp;=&nbsp;getProductImageHtml(item,&nbsp;itemNo);
&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;productDetailsHtml&nbsp;=&nbsp;getProductDetailsHtml(item,&nbsp;itemNo);
&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;addToCart&nbsp;=&nbsp;getAddToCartButton(item,&nbsp;itemNo);
&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;itemContainer&nbsp;=&nbsp;'&lt;div&nbsp;class="col-sm-2&nbsp;itemContainer"&nbsp;id="item-'&nbsp;+&nbsp;itemNo&nbsp;+&nbsp;'"&nbsp;style="padding:&nbsp;10px"&gt;';
&nbsp;&nbsp;&nbsp;&nbsp;itemContainer&nbsp;+=&nbsp;productImageHtml;
&nbsp;&nbsp;&nbsp;&nbsp;itemContainer&nbsp;+=&nbsp;productDetailsHtml;
&nbsp;&nbsp;&nbsp;&nbsp;itemContainer&nbsp;+=&nbsp;addToCart;
&nbsp;&nbsp;&nbsp;&nbsp;itemContainer&nbsp;+=&nbsp;"&lt;/div&gt;";
&nbsp;&nbsp;&nbsp;&nbsp;$("#products").append(itemContainer);
}

function&nbsp;getProductImageHtml(item,&nbsp;itemNo)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;'&lt;div&nbsp;class="productImage"&nbsp;id="productImage-'&nbsp;+&nbsp;itemNo&nbsp;+&nbsp;'"&gt;&lt;img&nbsp;src="'&nbsp;+&nbsp;item.image&nbsp;+&nbsp;'"&nbsp;/&gt;&lt;/div&gt;';
}

function&nbsp;getProductDetailsHtml(item,&nbsp;itemNo)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;'&lt;div&nbsp;class="productDetails"&gt;&lt;strong&gt;'&nbsp;+&nbsp;item.name&nbsp;+&nbsp;'&lt;/strong&gt;&nbsp;-&nbsp;'&nbsp;+&nbsp;item.price&nbsp;+&nbsp;'$&lt;/div&gt;';
}

function&nbsp;getAddToCartButton(item,&nbsp;itemNo)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;'&lt;button&nbsp;type="button"&nbsp;class="btn&nbsp;btn-success&nbsp;btn-block"&gt;&lt;i&nbsp;class="fa&nbsp;fa-bell"&gt;&lt;/i&gt;&nbsp;Add&nbsp;to&nbsp;cart&lt;/button&gt;';
}</code></pre><div><figure><img loading="lazy" width="428" height="153" src="https://petrepopescu.tech/wp-content/uploads/2021/01/image-6.png" alt="" srcset="https://petrepopescu.tech/wp-content/uploads/2021/01/image-6.png 428w, https://petrepopescu.tech/wp-content/uploads/2021/01/image-6-300x107.png 300w" sizes="(max-width: 428px) 100vw, 428px"></figure></div><p>Now, doing the benchmark again we clearly see a decrease in render time. It is now less than one second, about 1/3 of the previous time. This is because the number of calls to .append() was reduced to only one per item. But we can do even better.</p><h4>Building the needed HTML and appending once</h4><p>Now comes the final optimization. Instead of building each product view and appending it, we can do this by building the entire list of products and adding the resulting HTML to the container in one single go. This way we call append() once which will result in only one redraw of the UI elements. The code is almost identical, but instead of calling append at the end, we just return the resulting string.</p><pre><code lang="javascript">function&nbsp;makeItemOnPage(item,&nbsp;itemNo)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;we&nbsp;create&nbsp;a&nbsp;container&nbsp;for&nbsp;the&nbsp;current&nbsp;item
&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;productImageHtml&nbsp;=&nbsp;getProductImageHtml(item,&nbsp;itemNo);
&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;productDetailsHtml&nbsp;=&nbsp;getProductDetailsHtml(item,&nbsp;itemNo);
&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;addToCart&nbsp;=&nbsp;getAddToCartButton(item,&nbsp;itemNo);
&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;itemContainer&nbsp;=&nbsp;'&lt;div&nbsp;class="col-sm-2&nbsp;itemContainer"&nbsp;id="item-'&nbsp;+&nbsp;itemNo&nbsp;+&nbsp;'"&nbsp;style="padding:&nbsp;10px"&gt;';
&nbsp;&nbsp;&nbsp;&nbsp;itemContainer&nbsp;+=&nbsp;productImageHtml;
&nbsp;&nbsp;&nbsp;&nbsp;itemContainer&nbsp;+=&nbsp;productDetailsHtml;
&nbsp;&nbsp;&nbsp;&nbsp;itemContainer&nbsp;+=&nbsp;addToCart;
&nbsp;&nbsp;&nbsp;&nbsp;itemContainer&nbsp;+=&nbsp;"&lt;/div&gt;";
&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;itemContainer;
}</code></pre><div><div><p>Now, where we receive our data from the server, after building the HML string, we call append on the container, similar to the code on the right. Letâ€™s re-run the benchmark again.</p><figure><img loading="lazy" width="408" height="167" src="https://petrepopescu.tech/wp-content/uploads/2021/01/image-7.png" alt="" srcset="https://petrepopescu.tech/wp-content/uploads/2021/01/image-7.png 408w, https://petrepopescu.tech/wp-content/uploads/2021/01/image-7-300x123.png 300w" sizes="(max-width: 408px) 100vw, 408px"></figure><p>Now we have less than 150ms in this particular example, more than 4 times faster than in the previous version and 12 times faster than the first version. The final result <a href="http://petrepopescu.tech/wp-content/uploads/2021/01/jquery-dom-optimization.zip">can be downloaded from here</a>.</p></div><div><pre><code lang="javascript">function&nbsp;makeItems()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$("#products").empty();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;items = getItems();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;itemNo&nbsp;=&nbsp;0;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;items&nbsp;=&nbsp;"";
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;(itemNo&nbsp;=&nbsp;0;&nbsp;itemNo&lt;&nbsp;items.length;&nbsp;itemNo++)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;items&nbsp;+=&nbsp;makeItemOnPage(items[itemNo],&nbsp;itemNo);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$("#products").append(items);
&nbsp;&nbsp;&nbsp;&nbsp;}</code></pre></div></div><h4>Conclusions</h4><p>I used a similar technique to optimize page generation based on some input for an offline-only utility that runs in the browser. It was a log viewer and parser and the initial version took around 6 seconds to process a 3000 log file. After optimizing the calls, the same log was parsed and displayed in less than 0.8 seconds, a big improvement in both time and user experience.</p><p>Now, I know that generating HTML code like this has drawbacks, but there are many scenarios where not only does it help, it offers benefits like reduced server load. If you are careful to properly split code generation and donâ€™t mix different elements in the same generator function, the JavaScript code can remain clean and easy to maintain.</p><p>As a final note, I am primarily a back-end developer, so more experienced JavaScript users may have even better solutions as well as objections to this approach.</p></div></div></div>]]>
            </description>
            <link>https://petrepopescu.tech/2021/02/optimizing-jquery-dom-manipulation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26183834</guid>
            <pubDate>Thu, 18 Feb 2021 18:47:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Easy Profiling Go Benchmark Tests with Bash]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26183698">thread link</a>) | @blainsmith
<br/>
February 18, 2021 | https://blainsmith.com/articles/easy-profiling-go-benchmark-tests-with-bash/ | <a href="https://web.archive.org/web/*/https://blainsmith.com/articles/easy-profiling-go-benchmark-tests-with-bash/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content">
  <article>
    <header>
      
      <p id="date">
        <time>Feb 18, 2021</time>
      </p>
    </header>
    <p>There are a lot of great articles on the interwebs about profiling entire Go applications for CPU and memory usage, however I can never remember the syntax for doing the same thing for specific Benchmark-prefixed tests. Editors have great support for running these tests, but sometimes I want to be able to produce binary and profile output files to open in the visualizer for further inspection. So like any lazy programmer I made a few scripts to do all the work for me.</p>
<p><strong>bench.sh</strong></p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span></code></pre></td>
<td>
<pre><code data-lang="bash"><span>#!/bin/sh
</span><span></span>
<span>if</span> <span>[</span> <span>$#</span> -eq <span>0</span> <span>]</span>
    <span>then</span>
        <span>printf</span> <span>"Runs a specified benchmark test func and opens the profile in Chrome.\n\n"</span>
        <span>printf</span> <span>"Usage:\n"</span>
        <span>printf</span> <span>"\t./bench.sh &lt;cpu|mem&gt; &lt;dir&gt; &lt;function&gt;\n\n"</span>
        <span>printf</span> <span>"Example:\n"</span>
        <span>printf</span> <span>"\t./bench.sh cpu ./internal BenchmarkBinaryEncoding\n\n"</span>
        <span>exit</span> <span>0</span>
<span>fi</span>

go <span>test</span> -bench<span>=</span><span>${</span><span>3</span><span>}</span> -benchmem -<span>${</span><span>1</span><span>}</span>profile profile.out -o bench.test <span>${</span><span>2</span><span>}</span>
go tool pprof -http<span>=</span>:6060 bench.test profile.out
</code></pre></td></tr></tbody></table>
</div>
</div><p><strong>trace.sh</strong></p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span></code></pre></td>
<td>
<pre><code data-lang="bash"><span>#!/bin/sh
</span><span></span>
<span>if</span> <span>[</span> <span>$#</span> -eq <span>0</span> <span>]</span>
    <span>then</span>
        <span>printf</span> <span>"Runs a specified benchmark test func and opens the trace profile in Chrome.\n\n"</span>
        <span>printf</span> <span>"Usage:\n"</span>
        <span>printf</span> <span>"\t./trace.sh &lt;dir&gt; &lt;function&gt;\n\n"</span>
        <span>printf</span> <span>"Example:\n"</span>
        <span>printf</span> <span>"\t./trace.sh ./internal BenchmarkBinaryEncoding\n\n"</span>
        <span>exit</span> <span>0</span>
<span>fi</span>

go <span>test</span> -bench<span>=</span><span>${</span><span>2</span><span>}</span> -trace trace.out -o trace.test <span>${</span><span>1</span><span>}</span>
go tool trace -http<span>=</span>:6060 trace.test trace.out
</code></pre></td></tr></tbody></table>
</div>
</div><p>Lets consider a sample Go project layout that looks something like the following:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span></code></pre></td>
<td>
<pre><code data-lang="text">my-go-project/
â”œâ”€ cmd/
â”‚  â”œâ”€ server/
â”‚  â”‚  â”œâ”€ main.go
â”œâ”€ internal/
â”‚  â”œâ”€ encoding.go
â”‚  â”œâ”€ encoding_bench_test.go
â”‚  â”œâ”€ encoding_test.go
â”œâ”€ scripts/
â”‚  â”œâ”€ bench.sh
â”‚  â”œâ”€ tests.sh
â”‚  â”œâ”€ trace.sh
â”œâ”€ go.mod
â”œâ”€ go.sum
â”œâ”€ README.md
</code></pre></td></tr></tbody></table>
</div>
</div><p>Inside the internal directory there is encoding_bench_test.go which has a benchmark function called BenchmarkBinaryEncoding that we want to profile.</p>
<p><strong>./internal/encoding_bench_test.go</strong></p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span></code></pre></td>
<td>
<pre><code data-lang="go"><span>package</span> <span>internal_test</span>
<span>...</span>
<span>func</span> <span>BenchmarkBinaryEncoding</span><span>(</span><span>b</span> <span>*</span><span>testing</span><span>.</span><span>B</span><span>)</span> <span>{</span>
    <span>...</span>
<span>}</span>
<span>...</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>You can see we placed <strong>bench.sh</strong> and <strong>trace.sh</strong> inside the scripts folder so we can run it from the root of the project and see the help menu.</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span><span>9
</span></code></pre></td>
<td>
<pre><code data-lang="text">my-go-project on master via Go v1.16
&gt; ./scripts/bench.sh
Runs a specified benchmark test in app's package and opens the profile in Chrome.

Usage:
	./bench.sh &lt;cpu|mem&gt; &lt;dir&gt; &lt;function&gt;

Example:
	./bench.sh cpu ./internal BenchmarkBinaryEncoding
</code></pre></td></tr></tbody></table>
</div>
</div><p>Running it with the correct arguments will perform the following:</p>
<ol>
<li>Run the benchmark test BenchmarkBinaryEncoding within the internal package and capture the cpu|memory profile</li>
<li>Write a test binary and profile file to disk</li>
<li>Launch the profiler visualizer on port :6060 with test binary and profile</li>
</ol>
<p>Now let's run the BenchmarkBinaryEncoding function in the internal package.</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span></code></pre></td>
<td>
<pre><code data-lang="text">my-go-project on master via Go v1.16
&gt; ./scripts/bench.sh cpu ./internal BenchmarkBinaryEncoding
goos: linux
goarch: amd64
pkg: my-go-project/internal
cpu: Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz
BenchmarkBinaryEncoding-8   	  567564	      1916 ns/op	     979 B/op	       3 allocs/op
PASS
ok  	my-go-project/internal	2.047s
Serving web UI on http://localhost:6060
</code></pre></td></tr></tbody></table>
</div>
</div><p>At this point the browser should open automatically so you can poke around the CPU profile. Once you are done you can close the browser and quit the bash process and go about your business.</p>
<p>The <strong>trace.sh</strong> script operates the same way as <strong>bench.sh</strong>, but it opens the trace visualizer in the browser.</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span></code></pre></td>
<td>
<pre><code data-lang="text">my-go-project on master via Go v1.16
&gt; ./scripts/trace.sh ./internal BenchmarkBinaryEncoding
goos: linux
goarch: amd64
pkg: my-go-project/internal
cpu: Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz
BenchmarkBinaryEncoding-8   	  567564	      1916 ns/op	     979 B/op	       3 allocs/op
PASS
ok  	my-go-project/internal	2.047s
2021/02/18 13:17:50 Parsing trace...
2021/02/18 13:17:51 Splitting trace...
2021/02/18 13:17:51 Opening browser. Trace viewer is listening on http://[::]:6060
</code></pre></td></tr></tbody></table>
</div>
</div><p>I found these scripts to be super helpful to reduce the feedback loop of changing code and running a benchmark to see if things changed. I hope this helps you as much as it has helped me in my day-to-day work and if there are things that can be improved please reach out and let me know.</p>
<p>Happy pprof-ing!</p>

  </article>
</section></div>]]>
            </description>
            <link>https://blainsmith.com/articles/easy-profiling-go-benchmark-tests-with-bash/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26183698</guid>
            <pubDate>Thu, 18 Feb 2021 18:37:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The 1802 Membership Card Computer]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26183553">thread link</a>) | @bilegeek
<br/>
February 18, 2021 | http://www.sunrise-ev.com/1802.htm | <a href="https://web.archive.org/web/*/http://www.sunrise-ev.com/1802.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Once upon a time, microcomputers were simple and easy to understand. So simple in fact that a kid like me, with no computer experience whatsoever, could actually understand them, build them, program them, and put them to work in his very own projects!</p><p>The COSMAC 1802 was created in the 1970's at the dawn of the microcomputer revolution, by <a href="https://en.wikipedia.org/wiki/Joseph_Weisbecker">Joseph Weisbecker</a> of RCA Corporation. It used their new CMOS fabrication process, which had very low power consumption, very high noise immunity, and was very simple to use. It was intended for military and aerospace; applications too tough for other microcomputers to survive.</p><p>But Joe was a hacker at heart. He wrote a series of articles starting in the August 1976 issue of Popular Electronics magazine called "Build the COSMAC ELF". It described a simple low-cost computer, using the 1802 microprocessor. At the time, microcomputer systems cost hundreds to thousands of dollars. (Hmm... they still do today!) But Weisbecker's ELF cost about $80! Yet, it was an honest-to-goodness real live computer, able to do anything its much bigger cousins could do -- albeit a bit slower and cruder.</p><p>It was the ideal computer trainer. Hobbyists built thousands of ELFs, learning about computer design, construction, and programming in the process. A dozen companies produced versions of the ELF, also selling for low prices. It was the "Legos" of computers; a simple building-block computer that could be assembled many ways to become almost anything, limited only by your imagination.</p><p>I learned about computing on my ELF. It put me on a career in engineering, as it did for thousands of others. 1802's got designed into all sorts of amazing things; video games, music synthesizers, auto engine controllers, military weapon systems, and even NASA missions such as the Galileo spacecraft. Eat stardust, PCs and Macs!</p><p>Today's computers are far more powerful than the 1802. But they have also become so complicated that virtually no one can build them or truly understand how they work. We depend on someone else to make them for us, and to provide us with the megabytes of pre-written software needed to do anything with them. You can't learn the basics if there is nothing "basic" to learn on! I decided to do something about it.</p><p>The <strong>Membership Card</strong> is a reproduction of the original Popular Electronics Elf computer, repackaged to fit in a pocket-sized Altoids(R) tin. It is entirely built with 1980's parts and technology. It uses only common low-cost through-hole parts (no custom ICs or surface-mount assembly). To use it, you don't need a modern PC, or megabytes of proprietary software. Now you can learn about computers right from the ground up, and <u>really</u> understand how they work!</p><div>

<img src="http://www.sunrise-ev.com/MembershipCard/dev4k-cpu-asm.jpg" width="464" height="279" title="Membership Card Assembled" alt="Membership Card Assembled">
<img src="http://www.sunrise-ev.com/photos/pixelshim.gif" width="12" height="279">

<h3>What's inside?</h3>

<p>There are two circuit boards, each the size of a credit card. One is the <strong>Membership Card</strong> itself. It has the 1802 microprocessor, up to 64k bytes of memory, 22 bits of I/O, clock, reset, and power supply circuits, plus a supercapacitor to maintain memory contents without power. It can be used by itself as a microcontroller for projects like the Parallax BASIC Stamps or Arduino microcontrollers. All power, input, and output signals are available on the 30-pin header along the bottom.</p>
<br clear="left">

<img src="http://www.sunrise-ev.com/MembershipCard/dev4j-fpanel-asm.jpg" width="464" height="286" title="Membership Card Front Panel Assembled" alt="Membership Card Front Panel Assembled">
<img src="http://www.sunrise-ev.com/photos/pixelshim.gif" width="12" height="286">

<p>The second board is the <strong>Front Panel</strong>. It provides the switches and LEDs for a "blinkin-lights" control panel, just like the classic computers of old. The Front Panel lets you read and write to memory and I/O ports manually, without any help from software or external devices. A USB-serial adapter (<a href="https://www.sparkfun.com/products/9718">Sparkfun #9718</a> or equivalent) plugs directly into the 6-pin header to provide power and serial I/O. The Front Panel also brings the power and I/O signals out to a robust DB25 to connect external devices. It can be plugged into a PC parallel or RS-232 serial port, so a PC can load, save, and run programs.</p>

<p>The Membership Card can be purchased as a bare board with manual, or as a complete kit with all parts including the RCA 1802 microcomputer, 32k bytes of RAM, and even an empty Altoids tin to put it all in. An optional Cover Card provides a finished cover with holes and labels for all the lights, switches, and connectors.</p>

<img src="http://www.sunrise-ev.com/MembershipCard/mshipcardkit.jpg" width="400" height="285" title="Membership Card Kit" alt="Membership Card Kit">
<img src="http://www.sunrise-ev.com/photos/pixelshim.gif" width="20" height="285">

<h3>Specifications</h3>
<ul>
<li>CPU: RCA CDP1802ACE microprocessor.
</li><li>Clock: Stable 4 MHz ceramic resonator.
</li><li>Memory:	32k bytes RAM; plus socket for another 32k RAM or EPROM. Supercapacitor holds RAM contents without power.
</li><li>I/O: one 8-bit output port, with LEDs.
<br>one 8-bit input port, with switches.
<br>one 1-bit output, with red LED.
<br>four 1-bit flag inputs, one with pushbutton switch, one with green LED
<br>one interrupt input.
</li><li>Connectors: 6-pin power/TTL serial connector (/ON, TX, RX, +V, GND).
<br>25-pin DB25 connector with all I/O (power, PC parallel, RS-232 serial).
</li><li>Size: 3-1/2" x 2-1/8" x 3/4" (89 x 54 x 19 mm).
</li><li>Power: 3v to 5v DC at 0.1 to 5ma (depends on clock speed, memory size, and number of LEDs on).
</li><li>Aroma: A hint of curiously strong peppermint.
</li></ul>

<a name="1802mc-special">
<p>The <b>Membership Card</b> is your ticket to the fascinating world of microcomputing. Return with us now to those thrilling days of yesteryear, when the heroic pioneers of the microcomputer revolution built their own computers from scratch, and learned to program them to do incredible things, all for a tiny amount of money!</p>

<hr>
</a><ul><a name="1802mcbare">
	</a><li><a name="1802mcbare"></a><a href="http://www.sunrise-ev.com/MembershipCard/memberk3.pdf">Membership Card Manual, rev.K3</a> in PDF format. This is the current version.
	</li><li><a href="http://www.sunrise-ev.com/MembershipCard/dev4k3-sch.png">Membership Card Schematic</a> in PNG format. How often do you get a real schematic for anything today? The schematic, parts list, and part sources are all in the manual as well.
	</li><li><a href="http://www.sunrise-ev.com/MembershipCard/1802cpuK3.pdf">"Special" 1802 CPU Card Quickstart Manual</a> in PDF format. This is an abbreviated manual for operating the 1802MC CPU card by itself.
	</li><li><a href="http://www.sunrise-ev.com/MembershipCard/memberjk3.pdf">Membership Card Manual, rev.JK3</a> in PDF format. Rev.JK3 was the previous version I was shipping last year. Email me if you need a manual for an older version.
	</li><li><a href="http://www.sunrise-ev.com/MembershipCard/1802cheatsheet.pdf">1802 Elf "Cheat Sheet"</a> in PDF format. A pocket card with the 1802 pinouts, instruction set, and operating summary for the Membership Card and other 1802-based computers.
	</li></ul>
Software
	<ul>
	<li>BASIC for the 1802
		<ul>
		<li><b>Tiny BASIC</b> is Tom Pittman's classic 1976 integer BASIC in just 2K bytes. Lee Hart, Herb Johnson, and Loren Christiansen have tweaked it for the 1802MC's memory map. The vintage TMSI IDIOT monitor is included for serial I/O.
			<ul>
			<li><a href="http://www.sunrise-ev.com/photos/1802/tb0_christiansen.zip">Tiny BASIC</a> is a ZIP file with everything needed. Burn the HEX file into a 4K-32K EPROM. Address the EPROM at 0000h, and RAM at 8000h. It's currently assembled to run with a rev.J or later Front Panel.
			</li><li><a href="http://www.ittybittycomputers.com/IttyBitty/TinyBasic/TBuserMan.txt">Tiny BASIC User Manual</a> by Tom Pittman (c) 1976. It documents the language, and provides many examples and internal details. His <a href="http://www.ittybittycomputers.com/IttyBitty/TinyBasic/">website</a> has more info, sample programs, and the interesting history of Tiny BASIC.
			</li><li><a href="http://www.ittybittycomputers.com/IttyBitty/TinyBasic/TBEK.txt">Tiny BASIC Experimenters Kit</a> This booklet provides many internal details, including an assembler for the intermediate language that Tiny BASIC was written in.
			</li><li><a href="http://www.sunrise-ev.com/photos/1802/TFBOTBAS.HTM">The First Book of Tiny BASIC Programs</a> by Tom Pittman (c) 1981. This is a gold mine of impressive Tiny BASIC programs; games, spreadsheets, disassemblers, etc.
			</li></ul>
		</li><li><b>BASIC3</b> is RCA's floating-point BASIC (equivalent to Microsoft BASIC), written by Ron Cenker in 1981. It's been resurrected by Chuck Yakym, Ed Keefe, Herb Johnson, and Lee Hart to run on the 1802MC or any ELF using the EF3 and Q pins for serial input/output.
			<ul>
			<li><a href="http://www.sunrise-ev.com/MembershipCard/BASIC3v11user.pdf">BASIC3 User Manual</a> for RCA BASIC3, in PDF format.
			</li><li>BASIC3 program ROMs: Download, and burn into a 16K 27C128 or 32K 27C256 EPROM. Address it to start at 0000h (U2-LO), and RAM to start at 8000h (U8-HI). BASIC3 starts immediately on power-up or reset, so no Front Panel or "jump" instruction is needed to start it. BASIC3 includes an auto-start feature; if a BASIC program is stored in ROM, it will run automatically on power-up or reset. <a href="http://www.sunrise-ev.com/MembershipCard/CALL3800.pdf">CALL3800.pdf</a> describes how to use this feature.
				<ul>
				<li><a href="http://www.sunrise-ev.com/MembershipCard/MCBASIC3.bin">MCBASIC3.bin</a> for any version Membership Card by itself (no Front Panel); or with rev.I and earlier MC Front Panels.
				</li><li><a href="http://www.sunrise-ev.com/MembershipCard/MCBASIC3J.bin">MCBASIC3J.bin</a> with rev.J and later Membership Card Front Panels.
				</li></ul>
			</li></ul>
		</li></ul>

</li><li>Monitor programs
	<ul>
	<li>Chuck Yakym's <b>MCSMP Super Monitor Program</b> plus <b>BASIC3</b>, in a single 32K EPROM. Download, and burn it into a 27C256 EPROM. Here are his <a href="http://www.sunrise-ev.com/MembershipCard/Readme.txt">Quickstart notes</a> and <a href="http://www.sunrise-ev.com/MembershipCard/MCSMP20.pdf">Instructions</a> for installing and running MCSMP in PDF format.
<ul>
<li>Versions for an EPROM at 8000h (jumper U2-HI), and RAM at 0000h (jumper U8-LO). In classic ELF fashion, you need a front panel to load an LBR 8000h instruction (C0 80 00) into the first 3 bytes of RAM, and execute it.
<ul>
<li><a href="http://www.sunrise-ev.com/MembershipCard/MCSMP20.bin">MCSMP20.bin</a> for any Membership Card with rev.I or earlier Front Panels.
</li><li><a href="http://www.sunrise-ev.com/MembershipCard/MCSMP20J.bin">MCSMP20J.bin</a> with rev.J and later MC Front Panels.
</li><li><a href="http://www.sunrise-ev.com/MembershipCard/mcsmp20r_vt52_1.1.bin">MCSMP20J plus VT52 Adventureland</a> <span color="red">NEW!</span> MCSMP20J with "Adventureland", written in 1980 by famous game author Scott Adams. It's brought to you by the tireless efforts of Richard Goedeken. Instructions and the source code (licensed under BSD are available <a href="https://github.com/richard42/1802-adventureland-plus">HERE</a> on Github. This version uses VT52 ESC commands, so set your Terminal program for VT52 emulation.
</li><li><a href="http://www.sunrise-ev.com/MembershipCard/mcsmp20r_ansi_1.1.bin">MCSMP20J plus ANSI Adventureland</a> Same, but this version uses ANSI ESC commands to add color. Set your Terminal program for ANSI mode.
</li></ul>
</li><li>Versions for an EPROM at 0000h (jumper U2-LO), and RAM at 8000h (jumper U8-HI). The monitor starts immediately on power-up or reset, so no Front Panel or LBR instruction is needed to start them.
<ul>
<li><a href="http://www.sunrise-ev.com/MembershipCard/MCSMP20A.bin">MCSMP20A.bin</a> for any version Membership Cards, either stand-alone, or with rev.I or earlier Front Panels.
</li><li><a href="http://www.sunrise-ev.com/MembershipCard/MCSMP20B.bin">MCSMP20B.bin</a> for any Membership Card with rev.J or later Front Panels.
</li></ul>
</li></ul>
</li><li><b>ELF-LINK</b> by Josh Bensadon controls the Membership Card from a PC parallel port. No software at all is needed in the Membership Card itself to examine and change memory, and load, save, and execute programs. Here is <a href="http://www.sunrise-ev.com/MembershipCard/ELF-LINK.BAS">ELF-LINK.BAS for QuickBASIC</a> in plain ASCII format, so you can see how to do it with your favorite programming language. And here is <a href="http://www.sunrise-ev.com/MembershipCard/ELF-LINK.exe">ELF-LINK.exe in executable format</a> if you don't have QuickBASIC. Who will be the first to translate it into C? :-)
	</li></ul>
	</li></ul>
More 1802 Information
	<ul>
	<li><a href="http://www.exemark.com/Microcontrollers/PopularElecwebc.pdf">Build the COSMAC "ELF" -- A Low-Cost Experimenter's Microcomputer</a>. The original Aug 1976 Popular Electronics article by Joseph Weisbecker that started it all.
	</li><li><a href="http://www.sunrise-ev.com/vcf-elf.htm">The VCF-ELF</a> is â€¦</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.sunrise-ev.com/1802.htm">http://www.sunrise-ev.com/1802.htm</a></em></p>]]>
            </description>
            <link>http://www.sunrise-ev.com/1802.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-26183553</guid>
            <pubDate>Thu, 18 Feb 2021 18:27:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Frax: Worldâ€™s first fractional-algorithmically stabilized stablecoin]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 4 (<a href="https://news.ycombinator.com/item?id=26183483">thread link</a>) | @Bluestein
<br/>
February 18, 2021 | https://docs.frax.finance/overview | <a href="https://web.archive.org/web/*/https://docs.frax.finance/overview">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div data-editioncontainer="true"><div data-slate-editor="true" data-key="c661deaabfde4250bbd107c32d586f40" autocorrect="on" spellcheck="true" data-gramm="false"><p data-key="5c2f6050e8fe4fbea3690680c1d996b1"><span><span data-key="6ccd4104bbe54ed8bfc0983c8bef054d"><span data-offset-key="6ccd4104bbe54ed8bfc0983c8bef054d:0">Many stablecoin protocols have entirely embraced one spectrum of design (entirely collateralized) or the other extreme (entirely algorithmic with no backing). Collatralized stablecoins either have custodial risk or require on-chain overcollateralization. These designs provide a stablecoin with a fairly tight peg with higher confidence than purely algorithmic designs. Purely algorithmic designs such as Basis, Empty Set Dollar, and Seigniorage Shares provide a highly trustless and scalable model that captures the early Bitcoin vision of decentralized money but with useful stability. The issue with algorithmic designs is that they are difficult to bootstrap, slow to grow (as of Q4 2020 none have significant traction), and exhibit extreme periods of volatility which erodes confidence in their usefulness as actual stablecoins. They are mainly seen as a game/experiment than a serious alternative to collateralized stablecoins.

Frax attempts to be the first stablecoin protocol to implement design principles of both to create a highly scalable, trustless, extremely stable, and ideologically pure on-chain money. The Frax protocol is a two token system encompassing a stablecoin, Frax (FRAX), and a governance token, Frax Shares (FXS). The protocol also has pool contracts which hold collateral (at genesis USDT and USDC). Pools can be added or removed with governance.

Although there's no predetermined timeframes for how quickly the amount of collateralization changes, we believe that as FRAX adoption increases, users will be more comfortable with a higher percentage of FRAX supply being stabilized algorithmically rather than with collateral. The collateral ratio refresh function in the protocol can be called by any user once per hour. The function can change the collateral ratio in steps of .25% if the price of FRAX is above or below $1. When FRAX is above $1, the function lowers the collateral ratio by one step and when the price of FRAX is below $1, the function increases the collateral ratio by one step. Both refresh rate and step parameters can be adjusted through governance. In a future update of the protocol, they can even be adjusted dynamically using a PID controller design. The price of FRAX, FXS, and collateral are all calculated with a time-weighted average of the Uniswap pair price and the ETH:USD Chainlink oracle. The Chainlink oracle allows the protocol to get the true price of USD instead of an average of stablecoin pools on Uniswap. This allows FRAX to stay stable against the dollar itself which would provide greater resiliency instead of using a weighted average of existing stablecoins only.</span></span></span></p><p data-key="6a0fb64f8ddf49a292075e3f23b3f9a4"><span><span data-key="c7f1350efb8f4be4bbfcd688e0dcabba"><span data-offset-key="c7f1350efb8f4be4bbfcd688e0dcabba:0">FRAX stablecoins can be minted by placing the appropriate amount of its constituent parts into the system. At genesis, FRAX is 100% collateralized, meaning that minting FRAX only requires placing collateral into the minting contract. During the fractional phase, minting FRAX requires placing the appropriate ratio of collateral and burning the ratio of Frax Shares (FXS). While the protocol is designed to accept any type of cryptocurrency as collateral, this implementation of the Frax Protocol will mainly accept on-chain stablecoins as collateral to smoothen out volatility in the collateral so that FRAX can transition to more algorithmic ratios smoothly. As the velocity of the system increases, it becomes easier and safer to include volatile cryptocurrency such as ETH and wrapped BTC into future pools with governance. </span></span></span></p></div></div></div></div></div></div>]]>
            </description>
            <link>https://docs.frax.finance/overview</link>
            <guid isPermaLink="false">hacker-news-small-sites-26183483</guid>
            <pubDate>Thu, 18 Feb 2021 18:22:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Planet Money on HP's myriad ripoffs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26183419">thread link</a>) | @samizdis
<br/>
February 18, 2021 | https://pluralistic.net/2021/02/18/ink-stained-wretches/#hache-pe | <a href="https://web.archive.org/web/*/https://pluralistic.net/2021/02/18/ink-stained-wretches/#hache-pe">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1894">
	<!-- .entry-header -->

	
	
	<div>
		<p><!--
Tags:
accountancy, monopoly, coalitions, corruption, monopoly, npr, printers, hp, scams, podcasts, eff, spoken word, mp3s, mmt

Summary:
Planet Money on HP's myriad ripoffs; Strength in numbers

URL:
https://pluralistic.net/2021/02/18/ink-stained-wretches/

Title:
Pluralistic: 18 Feb 2021 ink-stained-wretches

Bullet:
ğŸ¦¸ğŸ¾â€â™‚ï¸

Separator:
_,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,_

Top Sources:
Today's top sources: Naked Capitalism (https://nakedcapitalism.com/).

--><br>
<a href="https://pluralistic.net/2021/02/18/ink-stained-wretches/"><img src="https://i0.wp.com/craphound.com/images/18Feb2021.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/18Feb2021.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>

<ul>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/02/18/ink-stained-wretches/#hache-pe">Planet Money on HP's myriad ripoffs</a>: Ink-stained wretches of the world, unite!
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/02/18/ink-stained-wretches/#countless">Strength in numbers</a>: The crisis in accounting.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/02/18/ink-stained-wretches/#retro">This day in history</a>: 2006, 2011, 2016
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/02/18/ink-stained-wretches/#bragsheet">Colophon</a>: Recent publications, upcoming/recent appearances, current writing projects, current reading
</li>
</ul>

<hr>
<p><a name="hache-pe"></a><br>
<img src="https://i2.wp.com/craphound.com/images/hp-drm-og_0.png?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/craphound.com/images/hp-drm-og_0.png?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Back in November, I published an article for EFF about HP's latest printer-ink ripoff: after offering its customers a free-ink-for-life plan, it unilaterally switched them all to a $1/month-for-life plan.</p>
<p><a href="https://www.eff.org/deeplinks/2020/11/ink-stained-wretches-battle-soul-digital-freedom-taking-place-inside-your-printer">https://www.eff.org/deeplinks/2020/11/ink-stained-wretches-battle-soul-digital-freedom-taking-place-inside-your-printer</a></p>
<p>I advocate on a lot of issues related to tech policy and 99% of the time, I'm trying to get people to care about complex technical issues before they become crises â€“ but people can't see the danger until it's too late.</p>
<p>Printer ink is the exception.</p>
<p>Everybody knows that printers are a ripoff: a monopolized, abusive industry that has devoted itself to the dirtiest, most deceptive, immoral tactics, and then handwaved them away with insulting, butter-wouldn't-melt, disingenuous excuses about doing it for our own good.</p>
<p>That article inspired a <em>fantastic</em> segment on the history of printer-ink shenanigans from NPR's Planet Money, "Why Printers Are The Worst."</p>
<p><a href="https://www.npr.org/2021/02/17/968704526/why-printers-are-the-worst">https://www.npr.org/2021/02/17/968704526/why-printers-are-the-worst</a></p>
<p>The Planet Money team did a characteristically excellent job of explaining just how depraved the ink scam is â€“ it's not just about screwing us all over, it's also about jettisoning every scrap of decency and consideration in service to unbridled greed.</p>
<p>This â€“ after all â€“ is the industry that pioneered sending out fake "security updates" that actually downgrade your device so that it no longer accepts third-party ink, thereby discouraging millions of people from running critical updates.</p>
<p>The printer companies â€“ led by HP â€“ are repeat offenders. They do something inexcusable, get caught, issue a nonpology, and thenâ€¦do it again, only worse. The latest Planet Money segment does an outstanding job of laying out just how rotten the business of printing is.</p>
<p>You can subscribe to the Planet Money podcast RSS here:</p>
<p><a href="https://feeds.npr.org/510289/podcast.xml">https://feeds.npr.org/510289/podcast.xml</a></p>
<p>And here's a direct link to the MP3 for this episode:</p>
<p><a href="https://play.podtrac.com/npr-510289/edge1.pod.npr.org/anon.npr-mp3/npr/pmoney/2021/02/20210217_pmoney_pmpod1065.mp3https://www.npr.org/2021/02/17/968704526/why-printers-are-the-worst">https://play.podtrac.com/npr-510289/edge1.pod.npr.org/anon.npr-mp3/npr/pmoney/2021/02/20210217_pmoney_pmpod1065.mp3https://www.npr.org/2021/02/17/968704526/why-printers-are-the-worst</a></p>
<hr>
<p><a name="countless"></a><br>
<img src="https://i0.wp.com/craphound.com/images/counters.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/counters.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Accountancy is more likely to be mocked than celebrated (or condemned), but accountants, far more than poets, are the unacknowledged legislators of the world.</p>
<p>Though "bean counters" are employed by firms, they are notionally bound by a professional code of ethics every bit as serious as the Hippocratic Oath: "count things honestly." Without an accurate accounting of quantities, you can't make good decisions on quality.</p>
<p>Though accountancy concerns itself with counting things, it is inextricably bound up with the realm of ideas, and accounting conventions (how you account for things) are philosophical matters, not empirical ones.</p>
<p>It's no coincidence that Modern Monetary Theory owes more to accountancy than it does to economics. Economic accounts of the economy have an unfortunate tendency to proceed from first principles, creating models based on pure reason, without checking in on the actual world.</p>
<p>For example, neoclassical econ's "homo economicus," the rational value-maximizing actor who populated so many models; or economists' insistence on targeting inflation with interest rates; or treating national "debts" like they were household debts.</p>
<p>It's telling that the greatest economics revolution of my lifetime was "behavioral economics," which could also be called "checking to see whether real people act like we've assumed they acted."</p>
<p>If it seems weird that economists would spend generations operating on the incorrect assumption that people behave in a certain way without ever checking, consider that Aristotle assumed women had fewer teeth than men, â€“ and never bothered to count.</p>
<p><a href="https://www.scientificamerican.com/article/aristotles-error/">https://www.scientificamerican.com/article/aristotles-error/</a></p>
<p>Accountants check, and what they find isâ€¦gnarly. In "An Accounting Model of the UK Exchequer," Andrew Berkeley, Richard Tye &amp; Neil Wilson offer a mindbending account (heh) of where money comes from (hint: not taxes), and where it goes ("poof").</p>
<p><a href="https://gimms.org.uk/wp-content/uploads/2020/12/An-Accounting-Model-of-the-UK-Exchequer-Google-Docs.pdf">https://gimms.org.uk/wp-content/uploads/2020/12/An-Accounting-Model-of-the-UK-Exchequer-Google-Docs.pdf</a></p>
<p>The authors did a two-part MMT Podcast interview describing the paper's findings, and it is the most extraordinary 2.5h audio you're likely to find: not just the realities of money, but the deliberate obfuscation thereof.</p>
<p><a href="https://pileusmmt.libsyn.com/84-andrew-berkeley-richard-tye-neil-wilson-an-accounting-model-of-the-uk-exchequer-part-1">https://pileusmmt.libsyn.com/84-andrew-berkeley-richard-tye-neil-wilson-an-accounting-model-of-the-uk-exchequer-part-1</a></p>
<p><a href="https://pileusmmt.libsyn.com/86-andrew-berkeley-richard-tye-neil-wilson-an-accounting-model-of-the-uk-exchequer-part-2">https://pileusmmt.libsyn.com/86-andrew-berkeley-richard-tye-neil-wilson-an-accounting-model-of-the-uk-exchequer-part-2</a></p>
<p>One thing the Exchequer paper reveals is that accountants bat for both teams: team clarity and team obscurity. As many finance scandals and finance dramas have reminded us, accounting can be turned to obscuring and dazzling rather than revelation.</p>
<p>After all, somewhere in HM Exchequer is a team of accountants who know <em>exactly</em> how money works â€“ and know that it's nothing like the account produced by economists or politicians. They know it because they are in charge of it. They do money, all day long.</p>
<p>When accountants go rogue, things get bad. And thanks to neoclassical economics â€“ and its emphasis on the "efficiency" of monopolies â€“ we are living through a golden age of ghastly accounting fraud.</p>
<p>Just four companies â€“ EY, KPMG, PWC and Deloitte â€“ audit the books of 97% of the 350 largest UK companies; but they make far more selling these companies consulting services, and have made a habit of lying about those books in order to boost their consulting income.</p>
<p>Accountancy is meant to be a profession that understands that conflicts of interest are a moral hazard. But just as doctors convince themselves they won't get addicted to their own painkillers, accountants talk themselves into believing that conflicts won't corrupt them.</p>
<p>That's how the Big Four accounting companies came to sign off Carillion's fraudulent books. The company hid Â£7b worth of debts, took on management of vital government services up and down the country, then collapsed, leaving the nation stranded.</p>
<p><a href="https://en.wikipedia.org/wiki/Carillion#Financial_difficulties">https://en.wikipedia.org/wiki/Carillion#Financial_difficulties</a></p>
<p>For the Big Four, Carillion's collapse was a feature, not a bug. After all, the only accounting firms large enough to oversee its bankruptcy wereâ€¦the Big Four, who billed millions for cleaning up the mess left behind by their own fraud.</p>
<p>Accounting fraud is a fascinating potential fracture line in economic reform. After all, fraudulent accountants may help <em>some</em> plutes get rich â€“ like, say Bernie Madoff, or Donald Trump â€“ but they often do so at the expense of <em>other</em> plutes.</p>
<p>Like Exxon, which lied to its investors for 11 years about the value of its shale-gas holdings, which it purchased at the peak of the fracking bubble and whose revenues and liabilities it has buried in its financial statements ever since.</p>
<p><a href="https://www.desmogblog.com/2021/02/02/whistleblower-sec-complaint-alleges-exxon-fraud-overvalue-fracking-assets">https://www.desmogblog.com/2021/02/02/whistleblower-sec-complaint-alleges-exxon-fraud-overvalue-fracking-assets</a></p>
<p>The company is finally writing down $19.3b worth of those assets, but the true figure is more like $50b. And yes, Exxon's big investors include a lot of passive funds that invest pension savings, meaning this hurts Main Street as well as Wall Street.</p>
<p>But as ever, those pension-savers are the Lucky Duckies here, because â€“ joke's on us â€“ Americans have basically no pension savings, thanks to the wage stagnation and asset inflation that left almost all working Americans facing penury in old age.</p>
<p>Hey, at least they're not getting ripped off by Exxon! The real victims of this decade-long, multibillion-dollar fraud are the same people who got snookered into buying into shitty Trump casinos and luxury buildings: rich people.</p>
<p>By definition, rich people deal in quantities that exceed their ability to personally count so they are especially vulnerable to scam accounting. It's only when the frauds tank a company we all suffer, as jobs and businesses disappear, screwing workers  and cities.</p>
<p>The absence of a neutral ref and scorekeeper is a really big deal in online business and policy circles. The ad-tech duopoly isn't merely content to price-gouge advertisers â€“ they also lie about what those sky-high prices are paying for:</p>
<p><a href="https://pluralistic.net/2020/10/05/florida-man/#wannamakers-ghost">https://pluralistic.net/2020/10/05/florida-man/#wannamakers-ghost</a></p>
<p>But each member of the duopoly has a different scam. Google's frauds are complex, behind-the-scenes market manipulations, an abstruse, mathematical grift that leverages complexity and monopoly to fleece its customers.</p>
<p><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3500919">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3500919</a></p>
<p>Facebook is much more straightforward. It just lies. Back in 2016, FB lied about how many people were watching videos, and encouraged hundreds of media company to beggar themselves to chase fraudulent video dollars:</p>
<p><a href="https://www.wired.com/story/facebook-lawsuit-pivot-to-video-mistake/">https://www.wired.com/story/facebook-lawsuit-pivot-to-video-mistake/</a></p>
<p>Accounting fraud is in Facebook's DNA. After all, this is a company whose primary sales-pitch is, "We will count everything you do and then charge people to help them sell you stuff."</p>
<p>This proposition is intrinsically hard to evaluate. How can a customer know if their FB ad generated a sale, or whether it was an ad elsewhere, or random chance, or even that elusive beast, customer loyalty?</p>
<p>The main source for the belief in Facebook's efficacy isâ€¦Facebook. It's not a neutral party, and the accountants who sign off on its books have repeatedly shown themselves to be untrustworthy.</p>
<p>Here's the latest scandal: since 2018, FB's been defending a class-action suit brought by its customers who claim that FB lied about "potential reach" â€“ that is, how many users would see their ads.</p>
<p><a href="https://www.ft.com/content/c144b3e0-a502-440b-8565-53a4ce5470a5">https://www.ft.com/content/c144b3e0-a502-440b-8565-53a4ceâ€¦</a></p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pluralistic.net/2021/02/18/ink-stained-wretches/#hache-pe">https://pluralistic.net/2021/02/18/ink-stained-wretches/#hache-pe</a></em></p>]]>
            </description>
            <link>https://pluralistic.net/2021/02/18/ink-stained-wretches/#hache-pe</link>
            <guid isPermaLink="false">hacker-news-small-sites-26183419</guid>
            <pubDate>Thu, 18 Feb 2021 18:18:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Avoid Zoom (2020)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26183409">thread link</a>) | @mooreds
<br/>
February 18, 2021 | https://www.alchemists.io/articles/avoid_zoom/ | <a href="https://web.archive.org/web/*/https://www.alchemists.io/articles/avoid_zoom/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  


  <main>
    <section>
      

      <section>
        

        <article>
          <div>
<p><a href="https://zoom.us/"><img src="https://www.alchemists.io/images/articles/avoid_zoom/icon.png" alt="Logo" width="300" height="300"></a>
</p>
<p>Avoid Zoom</p>
</div>
<div>
<h2 id="_overview">Overview</h2>
<div>
<p>Even before the Coronavirus pandemic, which has made video conferencing tools all the more
important, Zoom was a rising star in the field. Zoom provided solutions for common collaboration
problems with a lot of useful features, including surprisingly good video and audio despite multiple
attendees having various levels of bandwidth in the conversation. Previously, we were limited to
Google Meet, Slack Video, Webex, GoToMeeting, etc., all of which were various aspects of awful, and
having Zoom on the scene showed promise of a better experience.</p>
<p>By early 2019, though, reports emerged of disturbing conduct by Zoom as a company, casting doubt on
the integrity of their software offering as a whole. By mid-2019, these disturbances were exposed as
shocking displays of neglect and disregard for customer securityâ€‰â€”â€‰to a point where Apple had to
patch macOS due to shady code installed by the Zoom installer. Around this time, I choose to avoid
Zoom and removed it from the <a href="https://www.alchemists.io/projects/mac_os-config">macOS Configuration</a> project. Iâ€™ve not
gone back, despite the ubiquity of platform in the time of Coronavirus.</p>
<p>Perhaps the long tail of a companyâ€™s trajectory and practices is often forgotten in an age when we
are constantly bombarded with information, but this article is meant to put Zoomâ€™s historic
misconduct back into perspective and explain why I think more people should be avoiding the platform
all together.</p>

</div>
</div>
<div>
<h2 id="_evidence">Evidence</h2>
<div>
<p>The following spans many monthâ€™s worth of articles Iâ€™ve collected about Zoomâ€™s disturbing track
record. While mostly listed in chronological order, youâ€™ll want to read through each of these to
paint the picture of Zoomâ€™s past behavior and what thatâ€™s exposed about their underlying ethics.
<em>Spoiler Alert</em>: Zoom hasnâ€™t substantially improved since these issues arose and I donâ€™t expect
their tactics to change anytime soon.</p>

<p>From numerous security vulnerabilities to complying with the Chinese authoritarian regime, the
severity of these issues should at least tempt you to avoid using Zoomâ€‰â€”â€‰especially in regards to
aiding China, which is exacting
<a href="https://en.wikipedia.org/wiki/Cultural_genocide_of_Uyghurs">cultural genocide of the Uyghurs</a>.
Iâ€™ve been to Xinjiang, met the Uyghurs, eaten with them, browsed through their bazaars, etc. They
donâ€™t deserve this kind of treatment and we can do our part by not funding companies that diminish
their value.</p>
<p>In addition to the above, I find Zoomâ€™s lack of regard for the people they are helping to
communicate more effectively very disconcerting. Video conferencing is particularly sensitive in
nature and I would think that customer security would be a top priority in Zoomâ€™s software offering.
Instead, Zoom is prioritizing capturing the market as quickly as possible and at any cost. I
understand the need for growth but you can achieve this without sacrificing those you serve.</p>
</div>
</div>
<div>
<h2 id="_tangential_concerns">Tangential Concerns</h2>
<div>
<p>If you, too, want to avoid the ethical mess that is Zoom and happen to be using Keybase, be aware
they have <a href="https://keybase.io/blog/keybase-joins-zoom">joined Zoom</a>. Youâ€™ll want to reconsider
your options in this space. Iâ€™d recommend using <a href="https://1password.com/">1Password</a>,
<a href="https://bitwarden.com/">Bitwarden</a>, or others.</p>
</div>
</div>
<div>
<h2 id="_alternatives">Alternatives</h2>
<div>
<p>Should you be looking for alternatives to Zoom conferencing, here are a few choices that might be of
interest. Iâ€™ve not vetted all of these myself so tread with caution.</p>
<div>
<ul>
<li>
<p><a href="https://tandem.chat/">Tandem</a> - Focuses on providing a quick way in which to collaborate with
others with minimal overhead.</p>
</li>
<li>
<p><a href="https://www.around.co/">Around</a> - Early days for this company but has an interesting focus on
speakers/attendees which float around your workspace.</p>
</li>
<li>
<p><a href="https://www.remotion.com/">Remotion</a> - Provides a similar experience to Around and is currently
in Beta.</p>
</li>
<li>
<p><a href="https://www.vowel.com/">Vowel</a> - Early days for this service but provides a quick way to
collaborate with fellow colleagues, present, share, and transcribe audio into text.</p>
</li>
<li>
<p><a href="https://jamm.app/">Jamm</a> - Similar in nature to Around and Remotion but also has aspects of
Screenhero. If you remember Screenhero before Slack killed it.</p>
</li>
<li>
<p><a href="https://team.video/">Team Video</a> - Provides an experience focused around meetings within the
confines of their app which may or may not be what you want.</p>
</li>
<li>
<p><a href="https://screen.so/">Screen</a> - A new product/service brought to you by the same people who made
Screenhero.</p>
</li>
<li>
<p><a href="https://tuple.app/">Tuple</a> - Collaboration, screen sharing, and multiple cursor mouse control
for two people only. Worth pointing out due to mentioning Screen above.</p>
</li>
<li>
<p><a href="https://jitsi.org/">Jitsi</a> - An active and open source alternative to Zoom which has been
around since 2003. Provides dial-in, recording, simulcasting, end-to-end encryption, and more.</p>
</li>
<li>
<p><a href="https://joinwork.space/">Spaces</a> - Provides a more focused collaboration with another person or
multiple people with a focus on being able to screenshare, teach, share multiple cursors, etc.</p>
</li>
<li>
<p><a href="https://jackfruit.live/">Jackfruit</a> - Enterprise focused where the key features are around
webinars. Seems like a great tool for presenting to audiences of thirty people or less.</p>
</li>
<li>
<p><a href="https://hopin.to/">Hopin</a> - A full fledged online platform for virtual events and conferences
with a bunch of great features for making a pleasant experience.</p>
</li>
<li>
<p><a href="https://remo.co/">Remo</a> - Built for larger audiences and conferencing purposes in general but
is all browser based.</p>
</li>
<li>
<p><a href="https://www.mmhmm.app/">mmhmm</a> - A recent newcomer in this space innovating upon the standard
experience. Access is by invite only at the moment.</p>
</li>
<li>
<p><a href="https://makespace.fun/">MakeSpace</a> - Another innovative solution but has no visible product
offering Iâ€™m aware of. Worth keeping an eye on, though.</p>
</li>
<li>
<p><a href="https://tappy.so/">Tappy</a> - Early days for this service but the goal is to make collaboration
amongst your colleagues quick for 1:1 chat, group chat, screen sharing, note taking, etc.</p>
</li>
</ul>
</div>
</div>
</div>
<div>
<h2 id="_parting_thoughts">Parting Thoughts</h2>
<div>
<p>As an individual, switching to an alternative solution is fairly trivial. As a company, I realize
introducing this kind of change in the midst of a busy work schedule is not as swift an option. Even
more so with large teams. If nothing else, initiating a discussion around Zoomâ€™s reckless disregard
for security might be enough to get the ball rolling and even lead to insights on how communication
could be improved in general.</p>
<p>Iâ€™ve managed to avoid using Zoom since removing their software offering entirely. When scheduling
meetings with others, if they try to send me a Zoom link, Iâ€™ll suggest alternatives. Unfortunately,
I have encountered some fiery pushback from some in various social channels and havenâ€™t been able to
convince my local meetupsâ€‰â€”â€‰yetâ€‰â€”â€‰to switch to different software. Therefore, I am no longer able
to attend these meetups until more people take a stand against Zoomâ€™s behavior.</p>
<p>Your mileage may vary with that kind of zero-tolerance approach. Still, Iâ€™d rather fight for a
future that encourages ethical behavior and prioritizes people ahead of any capitalistic gain. I
hope you agree and vote by not spending money on companies or software that promote these practices.
We <em>can</em> make a difference, little by little!</p>
</div>
</div>
        </article>
      </section>
    </section>
  </main>

  

</div></div>]]>
            </description>
            <link>https://www.alchemists.io/articles/avoid_zoom/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26183409</guid>
            <pubDate>Thu, 18 Feb 2021 18:17:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cutting Build Time in Half with Dockerâ€™s Buildx Kubernetes Driver]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26183334">thread link</a>) | @jeremy_k
<br/>
February 18, 2021 | https://releaseapp.io/blog/cutting-build-time-in-half-docker-buildx-kubernetes | <a href="https://web.archive.org/web/*/https://releaseapp.io/blog/cutting-build-time-in-half-docker-buildx-kubernetes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>At Release, environments are our main focus, but we canâ€™t create environments without builds. Recently we undertook a project to revisit our build infrastructure and determine if it needed to be upgraded. Build times had become a big factor in our service delivery and we needed a way to improve our customersâ€™ experiences. One of the main areas that we wanted to improve upon was the parallelism of building multiple docker images for a single application.</p><p>The title of the article already spoiled the solution, and the alternative â€˜Release Did This One Thing To Cut Their Build Time In Half!â€™ didnâ€™t quite fly with the rest of the company, but Dockerâ€™s new <a href="https://github.com/docker/buildx" target="_blank" rel="noreferrer">buildx</a> project fit the bill. First, weâ€™ll cover what our original infrastructure looked like and how long builds on an example project were taking. Then, weâ€™ll describe the changes we made to use buildx and the speed increases we observed.</p><p>Letâ€™s start off with a diagram of what our original infrastructure looked like.</p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/75WoaAxoZMIL73zK0JKPId/f98ff948f97c0cc7b979c4b4352a032c/release-builder-architecture.png" alt="release-builder-architecture"></p><p>As you can see, the requests for builds would flow into our main Rails application and then divvied out to the different builder instances through Sidekiq. The <code>builder</code> container is Ruby code that would authenticate to Github, clone the repository, check out the correct SHA, and then execute the <code>docker build</code>. Due to the way we built the authentication to pull the code from Github, a single <code>builder</code> container could only clone one repository at a time. Which meant that the container could only do a single build request at a time. We added threading in the Ruby code to be able to execute multiple <code>docker build</code> commands at a time, but the number of builder containers we had spun up limited our concurrent builds. While itâ€™s not hard to horizontally scale with Kubernetes, we saw this authentication setup as a major bottleneck. </p><p>Another issue we encountered was that we had no mechanism for attempting to place builds on servers where they had been previously built, instead opting for grabbing the first free server. This meant there was very little chance to land on the same server and get the full benefit of Docker caching. While this isnâ€™t a deal breaker for us, we still believed we could do better when creating the version of our build infrastructure. Enough of the theoretical, letâ€™s actually build something!</p><p>Release Applications can contain many docker images and one of our favorite example repositories to showcase this is our fork of <a href="https://github.com/awesome-release/release-example-voting-app" target="_blank" rel="noreferrer">example-voting-app</a>. Looking at the <a href="https://github.com/awesome-release/release-example-voting-app/blob/master/docker-compose.yml" target="_blank" rel="noreferrer">docker-compose</a> we see that there are 3 different Docker images that we have to build, <code>result</code>, <code>vote</code>, and <code>worker</code>. Now that we have an understanding of Releaseâ€™s original infrastructure and the application we want to build, letâ€™s start up a fresh build and see the results.</p><p><em>NOTE</em> I forked the <code>awesome-release</code> repo to my own Github, <code>jer-k</code> for the following results.</p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/21reYa1lgqocT6MTojva4J/0d6826574fb8718d76bfcf6c855dd490/uncached-release.png" alt="uncached-release"></p><p>We can see that this brand new build with no cache hits took two minutes and 15 seconds to complete. Next, we want to make a few changes to ensure that each Docker image needs to be rebuilt. The changes are listed below.</p><div><pre><p><span>1</span><span>git status</span></p><p><span>2</span><span>On branch release_builders</span></p><p><span>3</span><span>Changes to be committed:</span></p><p><span>4</span><span>  (use "git restore --staged &lt;file&gt;..." to unstage)</span></p><p><span>5</span><span>    modified:   result/views/index.html</span></p><p><span>6</span><span>    modified:   vote/app.py</span></p><p><span>7</span><span>    modified:   worker/src/main/java/worker/Worker.java</span></p></pre></div><p>For the purpose of this blog post, I ensured the following build ran on the same builder as the first and that we will have cache hits. As noted before, this wasnâ€™t always the case in our production environment.</p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/69tKlV3mBuV6S6c7BhSaay/c51464f443c1888cd4f74fe3394b32f4/cached-release.png" alt="cached-release"></p><p>The caching helps and cuts 45 seconds off the build! The uncached build took almost twice as long as the second build with caching, but our assumption was that we could do a lot better (cached and uncached) with some new technology.</p><h2 id="enter-dockers-buildx-kubernetes-driver">Enter Dockerâ€™s Buildx Kubernetes Driver</h2><p>One of the first things we wanted to solve was the concurrency issue and we set out to ensure that Docker itself was able to handle a larger workload. We came across the issue <a href="https://github.com/moby/moby/issues/9656" target="_blank" rel="noreferrer">Concurrent â€œdocker buildâ€ takes longer than sequential builds</a> where people were describing what we feared; Docker slowed down when many builds were being run at the same time. Lucky for us, that issue was opened in 2014 and plenty of work had been done to resolve this issue. The final comment, by a member of the Docker team, was <a href="https://github.com/moby/moby/issues/9656#issuecomment-610476810" target="_blank" rel="noreferrer">â€œClosing this. BuildKit is highly optimized for parallel workloads. If you see anything like this in buildkit or buildkit compared to legacy builder please report a new issue with a repro case.â€</a> Thus we set out to learn more about <a href="https://docs.docker.com/develop/develop-images/build_enhancements/" target="_blank" rel="noreferrer">BuildKit</a> (the Github repository is located <a href="https://github.com/moby/buildkit" target="_blank" rel="noreferrer">here</a>). While researching, we came across <a href="https://github.com/docker/buildx" target="_blank" rel="noreferrer">buildx</a>, which ended up having three key features we believed would resolve many of our issues. These three features were the <a href="https://github.com/docker/buildx#buildx-bake-options-target" target="_blank" rel="noreferrer">bake</a> command, the <a href="https://github.com/docker/buildx#--driver-driver" target="_blank" rel="noreferrer">buildx kubernetes driver</a>, and the ability for the Kubernetes driver to consistently send builds to the same server. Letâ€™s cover each of these, first up the <code>bake</code> command.</p><div><pre><p><span>1</span><span>buildx bake [OPTIONS] [TARGET...]</span></p><p><span>2</span><span>Bake is a high-level build command.</span></p><p><span>3</span><span></span></p><p><span>4</span><span>Each specified target will run in parallel as part of the build.</span></p></pre></div><p><code>bake</code> intrigued us because it seemed to be a built-in command for us to avoid using Ruby threading for our parallelism. <code>bake</code> takes an input of a file, which can either be in the form of a <code>docker-compose</code>, <code>.json</code>, or <code>.hcl</code>. We initially tested <code>bake</code> with the docker-compose from example-voting-app and we were blown away at how smoothly it built directly out of the box and how quickly it was able to build the three images! However, we opted to create our own <code>.json</code> file generator in Ruby, parsing our <a href="">Application Template</a> into an output. Here is our generated file for example-voting-app.</p><div><pre><p><span>1</span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>"group"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>3</span><span>    </span><span>"default"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>4</span><span>      </span><span>"targets"</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>5</span><span>        </span><span>"vote"</span><span>,</span><span></span></p><p><span>6</span><span>        </span><span>"result"</span><span>,</span><span></span></p><p><span>7</span><span>        </span><span>"worker"</span><span></span></p><p><span>8</span><span>      </span><span>]</span><span></span></p><p><span>9</span><span>    </span><span>}</span><span></span></p><p><span>10</span><span>  </span><span>}</span><span>,</span><span></span></p><p><span>11</span><span>  </span><span>"target"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>12</span><span>    </span><span>"vote"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>13</span><span>      </span><span>"context"</span><span>:</span><span> </span><span>"./vote"</span><span>,</span><span></span></p><p><span>14</span><span>      </span><span>"tags"</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>15</span><span>        </span><span>"&lt;REDACTED&gt;.dkr.ecr.us-west-2.amazonaws.com/jer-k/release-example-voting-app/vote:latest"</span><span>,</span><span></span></p><p><span>16</span><span>        </span><span>"&lt;REDACTED&gt;.dkr.ecr.us-west-2.amazonaws.com/jer-k/release-example-voting-app/vote:buildx-builders"</span><span></span></p><p><span>17</span><span>      </span><span>]</span><span></span></p><p><span>18</span><span>    </span><span>}</span><span>,</span><span></span></p><p><span>19</span><span>    </span><span>"result"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>20</span><span>      </span><span>"context"</span><span>:</span><span> </span><span>"./result"</span><span>,</span><span></span></p><p><span>21</span><span>      </span><span>"tags"</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>22</span><span>        </span><span>"&lt;REDACTED&gt;.dkr.ecr.us-west-2.amazonaws.com/jer-k/release-example-voting-app/result:latest"</span><span>,</span><span></span></p><p><span>23</span><span>        </span><span>"&lt;REDACTED&gt;.dkr.ecr.us-west-2.amazonaws.com/jer-k/release-example-voting-app/result:buildx-builders"</span><span></span></p><p><span>24</span><span>      </span><span>]</span><span></span></p><p><span>25</span><span>    </span><span>}</span><span>,</span><span></span></p><p><span>26</span><span>    </span><span>"worker"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>27</span><span>      </span><span>"context"</span><span>:</span><span> </span><span>"./worker"</span><span>,</span><span></span></p><p><span>28</span><span>      </span><span>"tags"</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>29</span><span>        </span><span>"&lt;REDACTED&gt;.dkr.ecr.us-west-2.amazonaws.com/jer-k/release-example-voting-app/worker:latest"</span><span>,</span><span></span></p><p><span>30</span><span>        </span><span>"&lt;REDACTED&gt;.dkr.ecr.us-west-2.amazonaws.com/jer-k/release-example-voting-app/worker:buildx-builders"</span><span></span></p><p><span>31</span><span>      </span><span>]</span><span></span></p><p><span>32</span><span>    </span><span>}</span><span></span></p><p><span>33</span><span>  </span><span>}</span><span></span></p><p><span>34</span><span></span><span>}</span></p></pre></div><p>There are other inputs which can make their way into this file, such as build args, but since example-voting-app does not have any, they are omitted.</p><p>Next, we wanted to find more information on the Kubernetes driver and we found this blog post <a href="https://medium.com/nttlabs/buildx-kubernetes-ad0fe59b0c64" target="_blank" rel="noreferrer">Kubernetes driver for Docker BuildX</a> from the author of the <a href="https://github.com/docker/buildx/pull/167" target="_blank" rel="noreferrer">Pull Request</a>. We encourage you to read the latter as it covers getting up and running with the Kubernetes driver as well how the caching works, which is exactly what we needed. With that information in hand, we were able to start work on adding the buildx servers to our cluster. We created a generic way to deploy the servers into different clusters and adjust the number of replicas with the final command being</p><div><pre><p><span>1</span><span>docker buildx create --name #{name} --driver kubernetes --driver-opt replicas=#{num_replicas},namespace=#{builder_namespace} --use</span></p></pre></div><p>For us, we created a <code>release-builder</code> namespace with five replicas, in our development cluster. We can see the output by querying for the pods</p><div><pre><p><span>1</span><span>kubectl get pods --namespace=release-builder</span></p><p><span>2</span><span>NAME                            READY   STATUS    RESTARTS   AGE</span></p><p><span>3</span><span>development0-86d99fcf46-26j9f   1/1     Running   0          6d10h</span></p><p><span>4</span><span>development0-86d99fcf46-5scpq   1/1     Running   0          6d13h</span></p><p><span>5</span><span>development0-86d99fcf46-jkk2b   1/1     Running   0          15d</span></p><p><span>6</span><span>development0-86d99fcf46-llkgq   1/1     Running   0          18d</span></p><p><span>7</span><span>development0-86d99fcf46-mr9jt   1/1     Running   0          20d</span></p></pre></div><p>Since we have five replicas, we wanted to ensure that when we build applications, they end up on the same server so that we get the greatest amount of caching possible (distributed caching is a topic for another day). Luckily for us, <code>buildx</code>, with the Kubernetes driver, has an option for where to send the builds called <code>loadbalance</code>.</p><div><pre><p><span>1</span><span>loadbalance=(sticky|random) - Load-balancing strategy. </span></p><p><span>2</span><span>If set to "sticky", the pod is chosen using the hash of the context path. Defaults to "sticky"</span></p></pre></div><p>The default <code>sticky</code> means that the builds should always end up on the same server due to the hashing (more detailed information on this is described in the aforementioned blog post). With all of that in place, we are ready to test out our new setup!</p><p>Using the same example-voting-app repository as before, I created a new branch <code>buildx_builders</code> and pointed the code to the buildx servers. </p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/3gqbExE2XQMNqyUQ60m27m/9e215fc99510b5a18bb6792eba5679ec/uncached-buildx.png" alt="uncached-buildx"></p><p>What we see is that this uncached build was more than twice as fast as the other uncached build and even faster than the cached build on the old infrastructure! But uncached builds should be a thing of the past with the sticky load balancing, so letâ€™s make the same changes as the previous branch and see the results.</p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/2MxDyCqaSrOnffVSNC3SFu/abc0896e3eef27b927394b12fc9e1e29/cached-buildx.png" alt="cached-buildx"></p><p>This build finished three times faster than the previous cached build! These types of speed increases are the reason we set out to redo our build infrastructure. The faster the builds complete, the faster we can create environments and help our customers deliver their products.</p><p>Weâ€™re still experimenting with <code>buildx</code> and learning as we go, but the initial results were more than enough for us to migrate our own production builds to the new infrastructure. Weâ€™re going to continue to blog about this topic as we learn more and scale so check back in with the Release blog in the future!</p></div></article></div>]]>
            </description>
            <link>https://releaseapp.io/blog/cutting-build-time-in-half-docker-buildx-kubernetes</link>
            <guid isPermaLink="false">hacker-news-small-sites-26183334</guid>
            <pubDate>Thu, 18 Feb 2021 18:11:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dockerize Your Dev Env]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26183231">thread link</a>) | @benzaita
<br/>
February 18, 2021 | https://benzaita.github.io/dockerized-cli/index.html | <a href="https://web.archive.org/web/*/https://benzaita.github.io/dockerized-cli/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
            <div>
                <section>
                    <figure><img src="https://benzaita.github.io/dockerized-cli/assets/code.svg"></figure>
                    
                    <p>
                        Declare which build and/or development tools are needed in code, rather than in a README file.
                    </p>
                </section>
                <section>
                    <figure><img src="https://benzaita.github.io/dockerized-cli/assets/door.svg"></figure>
                    
                    <p>
                        Bootstrapping a development environment is as easy as running <code>dockerized shell</code>.
                    </p>
                </section>
                <section>
                    <figure><img src="https://benzaita.github.io/dockerized-cli/assets/checkmark.svg"></figure>
                    
                    <p>
                        No more "Works on my machine" because everyone in the team is using
                        exactly the same toolset.
                    </p>
                </section>
                <section>
                    <figure><img src="https://benzaita.github.io/dockerized-cli/assets/flip-horizontal.svg"></figure>
                    
                    <p>
                        Your CI can use exactly the same toolset as your developers.
                    </p>
                </section>
                <section>
                    <figure><img src="https://benzaita.github.io/dockerized-cli/assets/dock-row.svg"></figure>
                    
                    <p>
                        No need for <code>nvm</code>, <code>virtualenv</code>, <code>SDKMAN</code>, and such. Each
                        development environment is isolated.
                    </p>
                </section>
                <section>
                    <figure><img src="https://benzaita.github.io/dockerized-cli/assets/drink-margarita.svg"></figure>
                    
                    <p>
                        You no longer need to maintain messy <code>docker run</code> commands yourself.
                    </p>
                </section>
                <section>
                    <figure><img src="https://benzaita.github.io/dockerized-cli/assets/magic-wand.svg"></figure>
                    
                    <p>
                        Just prepend any command with <code>dockerized exec</code>.
                    </p>
                </section>
                <section>
                    <figure><img src="https://benzaita.github.io/dockerized-cli/assets/vscode.svg"></figure>
                    
                    <p>
                        "dockerized" complements VS Code and can use the <a href="https://code.visualstudio.com/docs/remote/containers">Remote Container</a>
                        you already configured.
                    </p>
                </section>
                <section>
                    <figure><img src="https://benzaita.github.io/dockerized-cli/assets/emoji.svg"></figure>
                    
                    <p>
                        You can use the "dockerized" development environment, or set up one
                        directly on your machine. Unlike other tools
                        "dockerized" is a non-intrusive guest on your machine.
                    </p>
                </section>
                <section>
                    <figure><img src="https://benzaita.github.io/dockerized-cli/assets/fast.svg"></figure>
                    
                    <p>
                        "dockerized" can <a href="https://github.com/benzaita/dockerized-cli/wiki/Caching-the-'dockerized'-image">cache</a> the build environment to speed up builds on CI pipelines.
                    </p>
                </section>
            </div>
        </article></div>]]>
            </description>
            <link>https://benzaita.github.io/dockerized-cli/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26183231</guid>
            <pubDate>Thu, 18 Feb 2021 18:02:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Age of Steam]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26183224">thread link</a>) | @allturtles
<br/>
February 18, 2021 | https://technicshistory.com/2021/02/18/the-age-of-steam-introduction/ | <a href="https://web.archive.org/web/*/https://technicshistory.com/2021/02/18/the-age-of-steam-introduction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>The most striking feature of the engineering quad of my <em>alma mater</em>, Rice University, are the three massive slabs of granite erected on large plinths at its center, each canted at a different angle: 45, 90, and 180 degrees. Less remarked upon, but more significant to my young, impressionable, and romantic mind, was another sculpture, entitled â€œEnergy,â€ tucked off on the north side of the quad, against the faÃ§ade of the Abercrombie Laboratory. It depicts, in relief, a biblical figure clad in a loincloth and sporting a majestic beard, pulling beams of light from the sun with his left hand and casting them down to earth with his right â€“ the apotheosis of the engineer. For indeed, virtually all of the energy used by human civilization derives from the sun, in some fashion or another,<a href="#_ftn1">[1]</a> a revelation which struck me with great force as an undergraduate.</p>



<p>In the eighteenth century, the predominant source of non-animal energy in European society came from falling water â€“ water that had been lifted into the clouds by the warmth of the sun before descending as rain.<a href="#_ftn2">[2]</a> Watermills were known and used across Eurasia from ancient times â€“ the earliest evidence comes from the third century BCE. At the height of the Roman Empire, engineers developed the technology on a gargantuan scale, as evidenced by the ruins of the Barbegal mill complex in southern France, which consisted of sixteen wheels running in pairs down a steep hillside, all supplied by a large stone aqueduct. However, there is no evidence for widespread use of the waterwheel prior to the middle ages, when they multiplied across the streams of Western Europe by the thousands. The Domesday Book, for example, an eleventh-century royal census of England and Wales, counted over 5,000 mills in the territories claimed by William the Conqueror.</p>



<p>The endless rotation of the wheel was most often applied to the grinding of grain, but mills for the fulling of woolen cloth were also common â€“ they beat the fibers into a firm felt with wooden triphammers controlled by a camshaft. By the later middle ages, however, inventive craftsmen had applied the watermill to nearly every industrial task imaginable, as historian Lynn White, Jr. cataloged:</p>



<blockquote><p>â€¦mills for tanning or laundering, mills for sawing, for crushing anything from olives to ore, mills for operating the bellows of blast furnaces, the hammers of the forge, or the grindstones to finish and polish weapons and armors, mills for reducing pigments for paint or pulp for paper or the mash for beer, were increasingly to be found all over Europe.<a href="#_ftn3">[3]</a></p></blockquote>



<p>As long as the rains fell and the waters flowed, these machines carried out tasks that in previous ages would have been possible only at the cost of sore muscles, aching joints, and dripping sweat â€“ whether human or animal.</p>



<p>Millwrights developed a variety of techniques over the centuries to adapt the wheel to different circumstances. The vertical â€œundershotâ€ wheel, with water directed against the bottom of the wheel, served well on streams with a shallow grade but a high flow of water. The â€œovershotâ€ wheel, on the other hand, which brought water to the top of the wheel where it filled buckets attached to its circumference, worked better for steep, low-volume streams. A trickle too feeble to push an undershot wheel could still fill buckets, if more slowly, and the steep grade made it easier to bring the water to the top of the wheel (although some sort of wooden flume was required to complete the millrace, which, along with the buckets, made the overshot wheel a more complex design). Horizontal wheels, on the other hand, though relatively inefficient, allowed for very simple mill construction. A horizontal wheel under a flour mill built atop the millrace could turn the grinding stone directly, without the need for a lantern gear to translate a vertical rotation into a horizontal one.</p>



<p>Yet for all the variety of its applications, the supply of water power was strictly limited. One could dam mill ponds to even out the flow of water and cut races to bring water directly to the wheel, but a given watercourse could provide a reliable supply of power to only so many mills. Along the Vienne in southwestern France, mills crowded together as densely as twenty per kilometer of water. The congestion of the streams of the Rhine region with waterwheels was likely responsible for the terminal decline of the Atlantic salmon fisheries in those waterways in the later middle ages.<a href="#_ftn4">[4]</a> As streams reached the saturation point, conflict over control of the water between upstream and downstream millers inevitably ensued. Many important precedents in property law revolved around such disputes. In 1600, for example, in a case came before the Kingâ€™s Bench in England, the plaintiff had torn down a pair of decrepit fulling mills to replace them with mills to grind grain. In the interval, the defendant rerouted the water supply to his own upstream mills, claiming that the plaintiff had sacrificed his ancient rights to the water (from â€œtime whereof memoryâ€) by tearing down the original mills. The court ruled in favor the plaintiff â€“ concluding that the destruction of the mills themselves did not destroy his right to the watercourse.<a href="#_ftn5">[5]</a></p>



<p>Humans had tapped another potent source of energy, of course, since time immemorial â€“ that of fire. Unlike water power, fire could produce heat to warm homes and smelt ores, but could not drive any kind of mechanical process. Wood historically provided most of the fuel supply for both domestic and industrial heating, sometimes supplemented by peat. But Britain stood out for its increasing exploitation of coal from the sixteenth century onward. By 1700, Britons were digging up nearly 3 million tons of it each year, over thirteen times as much as in 1560, although the population of the island as a whole had not even doubled in that time period.&nbsp;</p>



<p>In the course of the eighteenth century, inventors discovered that, when combined, these two elemental forces of fire and water could turn cheap, energy-dense coal into mechanical energy freed from the shackles of topography. Their creation, the steam engine, would transform the world. The industrial revolution â€” and all it brought in its train, from cheap clothing to regimented factory labor â€” began under water power but accelerated under a head of steam. Travel, war, and empire would never be the same after the creation of the railroad and the steamship.</p>



<p>Electrical power, too, was a product of steam. Edison set out to â€œsubdivide the light,â€ scaling down the overpowering glow of electric arc lighting into something that could be used inside the home. But the even more profound long-term effect of the spread of electrical lighting systems was the ability to subdivide the power of a steam engine, and deliver it wherever, and in whatever quantity, one might desire. Steam removed the constraints that tied machinery to a nearby water source; electric power removed the need for any mechanical connection at all between a source of power and its point of use.</p>



<p>Steam power had knock on affects in other areas of technology and science, as well. Throughout the late eighteenth and nineteenth centuries, the heyday of steam, the development of steam engines simultaneously benefited from and stimulated improvements in metallurgy and the science of heat.</p>



<p>This series will survey the history of this â€œage of steamâ€, an age that continues, in attenuated form, up to the present day. For despite the predominance of petroleum-based fuels in transportation over the last century, and the increasing pressure in recent decades to shift to steam-free sources of energy like solar and wind, much of our electricity still comes from heating water to make steam. This subject matter marks a departure for this blog, which heretofore has focused on the history of computing and communications technologies. Moreover, there is no shortage of popular accounts of the early history of the steam engine, including the recent <em>Energy </em>by Richard Rhodes and <em>The Most Powerful Idea in the World</em> by William Rosen. However, I believe this series will bring some fresh perspective on the story, especially by extending it into the twentieth century, unlike the many accounts that leave off as soon as the locomotive became a viable means of transport, around 1830.</p>



<p>Evidence for experiments and devices that turned steam into motion date back to the first century BCE, But Not until the philosophers of the seventeenth century developed a science of pressure were inventors able to create the first engines that could drive machinery by steam. We will begin this series in earnest next time by examining the emergence of this science, whose most important result was the revelation that the air itself has weight.</p>



<hr>



<p><a href="#_ftnref1">[1]</a> Nuclear and geothermal power are partial exceptions, deriving as they do from the husks of long-dead suns, rather than from our present one.</p>



<p><a href="#_ftnref2">[2]</a> Wind power also played an important role on the open plains of northwestern Europe, but it was generally less reliable than water and had more limited applications.</p>



<p><a href="#_ftnref3">[3]</a> Lynn White, Jr., <em>Medieval Technology and Social Change </em>(London: Oxford University Press, 1964), 89.</p>



<p><a href="#_ftnref4">[4]</a> H. Lenders, T. Chamuleau, A. Hendriks, <em>et al</em>., â€œHistorical Rise of Waterpower Initiated the Collapse of Salmon Stocks,â€ &nbsp; <em>Scientific Reports </em>6, 29269 (2016).</p>



<p><a href="#_ftnref5">[5]</a> T. E. Lauer, â€œThe Common Law Background of the Riparian Doctrine,â€ Missouri Law Review 28, 1 (Winter 1963), 83.</p>
			</div></div>]]>
            </description>
            <link>https://technicshistory.com/2021/02/18/the-age-of-steam-introduction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26183224</guid>
            <pubDate>Thu, 18 Feb 2021 18:02:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GPT-3, Esq? Evaluating AI Legal Summaries [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 37 (<a href="https://news.ycombinator.com/item?id=26183114">thread link</a>) | @gavelin
<br/>
February 18, 2021 | http://www.davidvictorrodriguez.com/uploads/2/6/4/2/26420847/gpt-3_esq_-_evaluating_ai_legal_summaries.pdf | <a href="https://web.archive.org/web/*/http://www.davidvictorrodriguez.com/uploads/2/6/4/2/26420847/gpt-3_esq_-_evaluating_ai_legal_summaries.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.davidvictorrodriguez.com/uploads/2/6/4/2/26420847/gpt-3_esq_-_evaluating_ai_legal_summaries.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-26183114</guid>
            <pubDate>Thu, 18 Feb 2021 17:53:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Turn an Idea into a Business]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26183057">thread link</a>) | @davidkolodny
<br/>
February 18, 2021 | https://www.wilburlabs.com/blueprints/how-to-turn-an-idea-into-a-business | <a href="https://web.archive.org/web/*/https://www.wilburlabs.com/blueprints/how-to-turn-an-idea-into-a-business">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Turning an idea into a business can be one of the most fulfilling and rewarding challenges of a lifetime. ItÃ¢â‚¬â„¢s not easy, but the skills and experiences required to start a business are learnable. </p><p>Great entrepreneurs are made, not born. Hard work, drive, and absolute determination can make up for gaps in skills and experience. The rest is learned by doing, making mistakes, and adapting along the way.</p><p>Wilbur Labs is a startup studio turning bold ideas into market-leading companies. Since 2016 we have launched and invested in 15 technology companies, including <a href="https://www.vacationrenter.com/">VacationRenter</a>, <a href="https://www.vitabox.com/">Vitabox</a>, <a href="https://www.joblist.com/">Joblist</a>, and <a href="https://www.barkbus.com/">Barkbus</a>. Today, our portfolio companies have hundreds of millions of users from around the world, and have generated billions of dollars in sales. We plan to launch several companies every year.</p><p>One question that weÃ¢â‚¬â„¢re constantly asked is: <br></p></div><h2>How do you turn an idea into a business?</h2><div><p>Launching a business is typically a one-time event. At Wilbur Labs, itÃ¢â‚¬â„¢s a repeatable and systematized process. Turning a bold idea into a business Ã¢â‚¬â€œ over and over Ã¢â‚¬â€œ is what we do. Over time, we have defined several critical steps that are key to effectively turn any idea into a business. WeÃ¢â‚¬â„¢re sharing that playbook with you to help you on your journey.</p><p><em>Note: This guide assumes that you already have an idea for a business. Coming up with an idea for a company is a separate topic covered in our <a href="https://www.wilburlabs.com/blueprints/how-to-get-startup-ideas">How to Get Startup Ideas</a> Blueprint.</em></p></div><h2>Step 1: Research</h2><div><p>The research stage is where you pair your initial idea with independent and external information. This should include first-hand research, speaking with industry experts, and talking with target customers to answer key questions:</p><ul><li>What problem are you trying to solve? </li><li>How big is this problem?</li><li>How would this make people's lives better?</li><li>Why are the current solutions not optimal?</li><li>Who are the competitors?</li><li>What is the business model?</li><li>How big of a business could you build?</li><li>Are you the right person to solve this problem?</li><li>What advantages do you have in solving this problem?</li><li>Do you care about this enough to work on it for 5+ years?</li><li>What are the outstanding challenges or questions?</li></ul><p>During this stage, you should talk with as many people as possible. You will be surprised how many target customers and industry experts are receptive to cold outreach to discuss a business idea. We recommend using LinkedIn or Twitter to source experts who know the problem you are trying to solve, and ask if theyÃ¢â‚¬â„¢re open to having a quick chat to discuss your idea. Many people passionate about an industry or a problem love talking with others who are equally as interested.</p><p>In addition to cold outreach, you should also use your personal network to reach out to any existing industry contacts who may be helpful Ã¢â‚¬â€œ or know people who might be helpful Ã¢â‚¬â€œ in researching this idea.</p><p>Be cautious about asking business advice from people close to you, because itÃ¢â‚¬â„¢s unlikely that you will get truly honest and critical feedback. Expect pushback because itÃ¢â‚¬â„¢s unlikely that everyone will love your idea, and thatÃ¢â‚¬â„¢s okay. Some of our boldest ideas received mixed feedback in the beginning. The point here is that you hear multiple viewpoints and use feedback to guide your research and planning. </p><p>Make sure to go very deep on your research during this stage. Some of our ideas remain in this stage for 6 to 12 months. Ideas are easy and everyone has them. This stage helps filter out the so-so ideas to prevent you from wasting time in a later stage. Frontloading research and due diligence here can also reduce risk and expedite future stages.</p><p>The best business ideas will bring a sense of urgency and motivation, pushing you to keep moving forward. If you are able to gain significant momentum through research, it makes sense to move into the planning stage.</p></div><h2>Step 2: Plan</h2><div><p>In the planning stage you should focus on taking your learnings and creating an executable plan. This will require diving deeper into the areas you looked into during the research phase, as well as answering new questions.</p><p>At Wilbur Labs, we create a Ã¢â‚¬Å“Concept EvaluationÃ¢â‚¬ï¿½ which is our own version of a business plan. Whatever format you choose, itÃ¢â‚¬â„¢s important to have a written plan that organizes all your research into an actionable plan that looks at every angle of your idea.</p><p>We like to work backwards during this stage, thinking about how we want the business to look 3 to 5 years ahead and then build a roadmap to get there. In our Concept Evaluation, we answer a number of questions, including but not limited to:</p><ul><li>What does the product look like at launch, year 1, year 2, etc?</li><li>How will you get customers (marketing/distribution)? How much will it cost?</li><li>What are the sources of revenue?</li><li>WhatÃ¢â‚¬â„¢s the expected lifetime value of a customer?</li><li>How will you retain customers long term to boost lifetime value?</li><li>Where is the break-even point (cost) of this business?</li><li>Where is the break-even point (time) of this business?</li><li>How do you solve the challenges you identified in the research phase?</li><li>What initial investment is required to get this off the ground?</li><li>How much time will it take to get this off the ground?</li><li>What investment is required over the next 3-5 years?</li><li>WhatÃ¢â‚¬â„¢s the optimal funding source?</li><li>What partnership(s) will you need?</li><li>What type of infrastructure will this company need?</li><li>What team is needed to build and grow this business?</li><li>What advisors could you reach out to for help?</li></ul><p>In addition to answering the questions above, our Concept Evaluations also include a product roadmap/gantt chart, financial model, and start-up checklist.<strong><br></strong></p><h3><strong>Product Roadmap</strong></h3><p>The product roadmap and corresponding gantt chart provide a simple, but tangible way to look at the different work streams that will be a part of each phase of the business. The key here is to plan out dependencies, so you can parallel process and avoid bottlenecks.</p><p>You wonÃ¢â‚¬â„¢t be able to do everything on day one. The important question to ask yourself during this planning stage is: what is the Minimum Viable Product (MVP) that you can launch with and how do you build on that MVP post launch? We are believers in launching as soon as possible to collect real customer feedback and use that to evolve the product along the way. <strong><br></strong></p><h3><strong>Financial Model</strong></h3><p>Our financial model is built using assumptions we find on our own, or inputs from industry experts. While this model is likely to change in the real world, we want to keep a close eye on the economics and the break even point. This is used to forecast the growth plan, timing, and investment level required. </p><p>Funding is a separate topic on its own and there is no universal best practice to finance a business. As an entrepreneur, you will need to look at a number of factors, including your personal situation, business cash requirements, and long term plan. ItÃ¢â‚¬â„¢s worth spending time with advisors or mentors to discuss the best funding option for your situation. <strong><br></strong></p><h3><strong>Startup Checklist</strong></h3><p>We love checklists and have a checklist for everything. Checklists ensure consistency and completeness in carrying out a task. Checklists also allow you to frontload all the planning so you can focus on executing at the next stage. For our startup checklist, we include everything required to get from day zero to launch day. This includes corporate structuring and entity formation; legal and accounting prep; compliance, hiring, product building; distribution and marketing; operations, partnerships, and business development. We are extremely thorough and write out every critical task, corresponding notes, status, and owner.</p><p>Before moving on to the next stage you should ask yourself, <em>Ã¢â‚¬Å“Do I want to spend the next 5+ years of my life building this business?Ã¢â‚¬ï¿½ </em></p><p>More often than not, entrepreneurship is not a way to get rich quickly. You will likely need to work harder and longer, with higher stress and more at stake than working a regular day job. The journey is absolutely worth it for the right person, but itÃ¢â‚¬â„¢s important that you go into it knowing what to expect. Many companies die early due to missed expectations on what it takes to start a company. If possible, you can start out part-time and build traction before diving in full-time. </p><p>If you want to dedicate years of your life solving this problem, and building a business along the way, then move on to the execute phase.</p></div><h2>Step 3: Execute</h2><div><p>Every single person has ideas, but very few take the jump and start a company. The execution stage is where you leave the planning stage and take that jump. You have spent time researching, putting together a plan, and you are now ready to dedicate time to building a business.</p><p>Depending on the type of business, this stage will look very different. In all cases, this stage involves working through your plan, roadmap, and startup checklist to begin getting your idea off the ground. </p><p>The primary focus of this stage is prioritization. Prioritizing often will allow you to manage bottlenecks and work in parallel across different areas of your business. The goal is to align your input (time &amp; money) with the activities that will yield the highest output (progress on your plan). This is easier said than done, but it is absolutely critical to execute your plan in an efficient way.</p><p>If you need to raise money or get funding, this is the stage where that could happen. This is also the stage where you may need to start building your team by hiring contractors or employees. </p></div><h2>Step 4: Adapt</h2><div><p>Roughly 90% of businesses fail, and this is the stage where that usually happens. One thingÃ¢â‚¬â„¢s for certain in starting a business: you will never be able to create and follow a bulletproof plan. As your business takes off, youÃ¢â‚¬â„¢ll need to constantly adapt and change your plan. The best entrepreneurs are comfortable being uncomfortable, adapting as they go.</p><p>The optimal Ã¢â‚¬Å“go liveÃ¢â‚¬ï¿½ point will vary by business. At Wilbur Labs, we strongly believe that getting customers to vote for products and services with their wallet or with their time is by far the best measure of product-market fit. If customers wonÃ¢â‚¬â„¢t spend time or money on your â€¦</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.wilburlabs.com/blueprints/how-to-turn-an-idea-into-a-business">https://www.wilburlabs.com/blueprints/how-to-turn-an-idea-into-a-business</a></em></p>]]>
            </description>
            <link>https://www.wilburlabs.com/blueprints/how-to-turn-an-idea-into-a-business</link>
            <guid isPermaLink="false">hacker-news-small-sites-26183057</guid>
            <pubDate>Thu, 18 Feb 2021 17:50:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open Terms Archive: Terms and Conditions of popular services tracked on GitHub]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26182878">thread link</a>) | @sirffuzzylogik
<br/>
February 18, 2021 | https://disinfo.quaidorsay.fr/en/open-terms-archive | <a href="https://web.archive.org/web/*/https://disinfo.quaidorsay.fr/en/open-terms-archive">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<div class="page">
				<div>
					

<nav>
	<ol itemscope="" itemtype="https://schema.org/BreadcrumbList">
		<li itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">	
			<a href="https://disinfo.quaidorsay.fr/en" itemprop="item">Home</a>
			
		</li>

		
			<li itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">	
				<a href="https://disinfo.quaidorsay.fr/en/our-tools" itemprop="item">Our tools</a>
				
			</li>
		
		
		<li itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
			Open Terms Archive
		</li>
	</ol>
</nav>

<p><img src="https://disinfo.quaidorsay.fr/assets/img/open-terms-archive/thumb.jpg" alt=""></p>

<p>Services have terms that can change over time. Open Terms Archive enables users rights advocates, regulatory bodies and any interested citizen to <strong>follow the changes to these terms</strong>.</p>

<h3 id="follow-the-changes-to-the-terms-of-service">Follow the changes to the Terms of Service</h3>

<p>Services are declared within Open Terms Archive with a declaration file listing all the documents that, together, constitute <strong>the terms under which this service can be used</strong>. These documents all have a type, such as â€œterms and conditionsâ€, â€œprivacy policyâ€, â€œdeveloper agreementâ€.</p>

<p>The practices described regarding information manipulation can lead to a <strong>better understanding of the vulnerabilities</strong> of these actors and the transcription of legislative constraints, recommendations from public authorities or voluntary measures implemented enables us to <strong>appreciate their loyalty</strong>.</p>

<h3 id="case-studies">Case studies</h3>

<ul>
  <li>Google has changed its Review Guidelines to prohibit apps that hat mislead users by impersonating someone else or another app or falsely imply a relationship to another company / developer. These measures thus close certain vulnerabilities exploited for information manipulation. <a href="https://github.com/ambanum/CGUs-versions/commit/98f6c">See the change</a>.</li>
</ul>

<p><img src="https://disinfo.quaidorsay.fr/assets/img/open-terms-archive/google-case-studie.png" alt=""></p>

<ul>
  <li>TikTok refers to Comminuty Guidelines to offer its users the opportunity to report content that would be considered inappropriate. <a href="https://github.com/ambanum/CGUs-versions/commit/0d2f0386">See the change</a>.</li>
</ul>

<p><img src="https://disinfo.quaidorsay.fr/assets/img/open-terms-archive/tiktok-case-studie.png" alt=""></p>

<ul>
  <li>Google AdSense has changed its Acceptable Use Policy to add a reference to Coordinated Deceptive Practices to prohibit (i) practices that seek to coordinate with other sites or accounts and concealing or misrepresenting identity or other material details, when content relates to politics, social issues or matters of public concern and (ii) directe content about politics, social issues, or matters of public concern to users in a country other than oneâ€™s own, if you misrepresent or conceal oneâ€™s country of origin or other material details. <a href="https://github.com/ambanum/CGUs-versions/commit/c62b7">See the change</a>.</li>
</ul>

<p><img src="https://disinfo.quaidorsay.fr/assets/img/open-terms-archive/google-case-studie.png" alt=""></p>

<p><a href="https://github.com/ambanum/CGUs/wiki/%C3%89tudes-de-cas">Discover more case studies</a></p>

<h2 id="how-it-works">How it works</h2>

<p><em>Words in bold are <a href="https://en.wikipedia.org/wiki/Domain-driven_design">business domain names</a>.</em></p>

<p><strong>Services</strong> are <strong>declared</strong> within <em>Open Terms Archive</em> with a <strong>declaration file</strong> listing all the <strong>documents</strong> that, together, constitute the <strong>terms</strong> under which this <strong>service</strong> can be used. These <strong>documents</strong> all have a <strong>type</strong>, such as â€œterms and conditionsâ€, â€œprivacy policyâ€, â€œdeveloper agreementâ€â€¦</p>

<p>In order to track their <strong>changes</strong>, <strong>documents</strong> are periodically obtained by fetching a web location and selecting content within the web page to remove the noise (ads, navigation menu, login fieldsâ€¦).</p>

<p>Anyone can run their own private instance and track changes on their own. However, we also publish each version on a <a href="https://github.com/ambanum/CGUs-versions"><strong>public</strong> instance</a> that makes it easy to explore the entire history and enables notifying over email whenever a new version is recorded.
Users can <a href="#be-notified"><strong>subscribe</strong> to <strong>notifications</strong></a>.</p>

<p><em>For now, when multiple versions coexist, <strong>terms</strong> are only <strong>tracked</strong> in their English version and for the European jurisdiction.</em></p>

<h3 id="exploring-the-versions-history">Exploring the versions history</h3>

<p>From the <strong>repository homepage</strong> <a href="https://github.com/ambanum/CGUs-versions">CGUs-versions</a>, open the folder of the service of your choice. You will see the set of documents tracked for that service, now click on the document of your choice. The latest version (updated hourly) will be displayed.</p>

<p><em>For more details, see our <a href="https://github.com/ambanum/CGUs#exploring-the-versions-history">wiki</a></em>.</p>

<h3 id="be-notified">Be notified</h3>

<p>You can <a href="https://59692a77.sibforms.com/serve/MUIEAKuTv3y67e27PkjAiw7UkHCn0qVrcD188cQb-ofHVBGpvdUWQ6EraZ5AIb6vJqz3L8LDvYhEzPb2SE6eGWP35zXrpwEFVJCpGuER9DKPBUrifKScpF_ENMqwE_OiOZ3FdCV2ra-TXQNxB2sTEL13Zj8HU7U0vbbeF7TnbFiW8gGbcOa5liqmMvw_rghnEB2htMQRCk6A3eyj">subscribe</a> to receive an email whenever a document is updated in the database.</p>

<p><strong>Beware, this service is in beta and you are likely to receive a large amount of notifications!</strong> You can unsubscribe by replying to any email you will receive.</p>

<p><em>For more details, see our <a href="https://github.com/ambanum/CGUs#be-notified">wiki</a></em>.</p>

<h2 id="scripta-manent">Scripta Manent</h2>

<p>Scripta Manent lists 637 Terms of Services (in French, Conditions GÃ©nÃ©rales dâ€™Utilisation or CGU) and legal documents coming from 174 digital service providers and gives simple tools to compare changes between two dates of your choice.</p>

<p><a href="https://disinfo.quaidorsay.fr/en/open-terms-archive/scripta-manent">Compare</a></p>

<h2 id="experiments">Experiments</h2>

<p>Experiments are ongoing so as to produce use cases using Open Terms Archive data.</p>

<p><a href="https://disinfo.quaidorsay.fr/en/open-terms-archive/experiments">See ours experiments</a></p>

<h2 id="api">API</h2>

<p>An API endpoint to find specific terms in the Open Terms Archive dataset is available.</p>

<p><a href="https://disinfo.quaidorsay.fr/api/open-terms-archive/">Access the API</a></p>

<h2 id="contributing">Contributing</h2>

<p>The tool is built as an <strong>open source and collaborative software</strong>, which means that everyone can contribute to its improvement and to the addition of documents and service providers to be tracked.</p>

<ul>
  <li>
    <p>Terms of Service Didnâ€™t Read (ToSDR)
The association Terms of Service Didnâ€™t Read (ToSDR) had developed a similar tool, <a href="https://tosback.org/">TOSBack</a> and thus transferred its resources and documents followed for several years to our tool.</p>
  </li>
  <li>
    <p>Direction GÃ©nÃ©rale des Entreprises<br>
The Direction GÃ©nÃ©rale des Entreprises (DGE), through the Digital Regulation Expertise Center (PEReN), contributes to the tool by developing new functionalities, such as tracking images and documents in PDF format.</p>
  </li>
</ul>

<div>
	<h3>Help us to improve Open Terms Archive</h3>
	<p>You can add service providers or documents that you would like to follow or suggest ways to add value to the case studies.</p>
	<p><a href="https://github.com/ambanum/CGUs">Contribute</a>
</p></div>

				</div>
			</div>
		</div></div>]]>
            </description>
            <link>https://disinfo.quaidorsay.fr/en/open-terms-archive</link>
            <guid isPermaLink="false">hacker-news-small-sites-26182878</guid>
            <pubDate>Thu, 18 Feb 2021 17:37:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ruby Garbage Collection Deep Dive: Tri-Color Mark and Sweep]]>
            </title>
            <description>
<![CDATA[
Score 132 | Comments 15 (<a href="https://news.ycombinator.com/item?id=26182796">thread link</a>) | @mooreds
<br/>
February 18, 2021 | https://jemma.dev/blog/gc-mark-and-sweep | <a href="https://web.archive.org/web/*/https://jemma.dev/blog/gc-mark-and-sweep">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>In the <a href="https://jemma.dev/blog/gc-internal">first post</a> in the Ruby Garbage Collection Deep Dive series, we went through a few definitions to give us a picture of how Ruby stores values in memory. If you havenâ€™t read it yet, <a href="https://jemma.dev/blog/gc-internal">read it first</a>! Weâ€™ll build on those definitions in this post. Particularly, weâ€™ll talk more about the Ruby Heap, Pages, Slots and RVALUES.</p>

<p>Okay, now that we have those baseline definitions out of the way, this post is going to explain the algorithm Rubyâ€™s garbage collector uses to determine which objects it can collect: the Tri-Color Mark and Sweep algorithm. There are two phases to this algorithm. You guessed it: marking and sweeping. In the marking phase, the garbage collector marks all slots which contain accessible RVALUES. In the sweeping phase, the garbage collector clears the RVALUES out of all slots which are not marked. Letâ€™s dig in!</p>

<h2 id="tri-color-mark-and-sweep">Tri-Color Mark and Sweep</h2>

<h3 id="marking">Marking</h3>

<p>Weâ€™ll start off by discussing the marking phase. This is most straightforward to understand if we imagine the <a href="https://ruby-doc.org/core-3.0.0/ObjectSpace.html">Ruby ObjectSpace</a> to be a directed graph with root nodes. All of the nodes in the graphs are RVALUES. All of the edges in the graph are references from one RVALUE to another.</p>

<p>Rubyâ€™s garbage collector starts at the root nodes and traces every edge it can access from these root nodes, marking every RVALUE it sees through this process. At the end, any RVALUE which was not traced, and therefore not accessible from a root RVALUE will be garbage collected.</p>

<h4 id="tri-color">Tri-Color</h4>

<p>Okay, but the algorithm Ruby uses for garbage collection is called a Tri-Color Mark and Sweep algorithm, so whatâ€™s the Tri-Color part all about? The Tri-Color algorithm is a model we can use to understand what Rubyâ€™s garbage collector is doing, and how tracks its progress. The three colors in the Tri-Color algorithm (three shades, really) are white, black and grey.</p>

<p>At the beginning of garbage collection, every slot in the Ruby Heap is white. Then, as part of the initial setup, all slots which contain root RVALUEs are marked as grey.</p>

<p>Root RVALUES are all of the RVALUES that a Ruby program knows it will need to run. Examples of these are RVALUES that exist on the stack of instructions that the program is following, or protected global variables.</p>

<p>With all root slots grey, and all other slots white, we then get to the crux of the algorithm:</p>

<div><div><pre><code><span>while</span> <span>(</span><span>!</span><span>grey_slots</span><span>.</span><span>empty?</span><span>)</span>
  <span>current_slot</span> <span>=</span> <span>grey_slots</span><span>.</span><span>pop</span>
  <span>grey_slots</span> <span>+=</span> <span>current_slot</span><span>.</span><span>referenced_slots</span>
  <span>black_slots</span> <span>&lt;&lt;</span> <span>current_slot</span>
<span>end</span>
</code></pre></div></div>

<p>We iterate over all grey slots, coloring the slots that their RVALUES reference grey, and coloring themselves black. The algorithm continues until there are no grey slots left. At this point, any black slots contain RVALUES which were reachable by the RVALUEs in the root slots, and any white slots do not contain RVALUES which were reachable so can be swept away!</p>

<p>For the visual learners, hereâ€™s a gif of what the algorithm is doing:</p>

<p><img src="https://jemma.dev/assets/mark.gif" alt="mark-gif"></p>

<h4 id="references">References</h4>

<p>There is one detail which needs further explanation here: how does an RVALUE know which other RVALUES it references?</p>

<p>It depends on the type of object. For Ruby builtins, tracing the references are just baked into the garbage collector code itself. For example, to find all references from an array RVALUE, the collector iterates each element in the array and finds its references. For a hash, it will do this for both the keys and the values. This all happens in the garbage collectorâ€™s <a href="https://github.com/ruby/ruby/blob/296a2cab07ce530809ee74dee61180fbb3ca6f91/gc.c#L6269"><code>mark_children</code></a> method.</p>

<p>But, when objects are defined by C extensions, the C extensions must mark all child objects on their own. Weâ€™ll dive more into this in a future C extensions post (which Iâ€™ll backlink here).</p>

<p>Okay, so now that we understand how we find all accessbile objects, we need to learn how to dispose of all unaccessible objects.</p>

<h3 id="sweeping">Sweeping</h3>

<p>At this point, we have two sets: black slots and white slots. Internally, these are represented as a <code>marked</code> bitmap. Every Page on the Ruby Heap has its own <code>marked</code> bitmap with one bit per slot. A <code>1</code> bit means the slot is accessible, or Black in our Tri-Color scheme. A <code>0</code> bit means that the slot is no longer accessible, or White in our Tri-Color scheme.</p>

<p>In addition to holding this <code>marked</code> bitmap, each page also has a <code>freelist</code> which represents slots on that page which do not have live objects. The garbage collector iterates over all pages, finding all slots which are not marked. Where applicable, the garbage collector then adds the unmarked slots to each pageâ€™s freelist. If the RVALUES which were occupying these slots are also taking up space in the operating system heap, it also frees this memory.</p>

<p>Once pages have been swept, there might be pages which are now completely unallocated; they have no slots which contain RVALUES. These pages are referred to as â€œTomb Pages.â€ Tomb pages have their memory completely returned to the operating systemâ€™s heap. This is really helpful for memory management. It means that sweeping can result in freeing memory, or diminishing the overall size of the Ruby Heap.</p>

<p>Any pages with at least one occupied slot are called â€œEden Pagesâ€. The sweeping phase might reduce the number of occupied slots in an Eden Page. The garbage collector will use the freelists from Eden Pages for future object allocations. That is to say, if you instantiate an object, the garbage collector will look for one of these free slots in an Eden Page and place the RVALUE representing your object in there.</p>

<p><img src="https://jemma.dev/assets/eden-and-tomb.png" alt="eden-and-tomb"></p>

<p>There is one more nuance here. As of Ruby 3.0, if auto-compaction is enabled, compaction will actually happen as part of the sweeping phase. A more in depth explanation of how and why this happens will follow in a later post about compaction in this Garbage Collection Deep Dive Series.</p>

<h3 id="tldr">TL;DR</h3>

<p>The Tri-Color mark and sweep algorithm is what Rubyâ€™s garbage collector uses to determine which slots hold objects which no longer have accessible references. It marks all of the slots it has references to by following the Tri-Color algorithm in which it follows all references from root RVALUES. Once the garbage collector knows which objects are accessible from the roots, it can begin the sweep phase, where it will add the unoccupied slots to each pageâ€™s freelist, and release any operating system memory those RVALUES held. This enables the slots to be reused for new object allocation.</p>

<p>Here are a few new definitions we learned:</p>

<ul>
  <li><strong>Eden page</strong>: A page which contains slots with RVALUES, might also have empty slots</li>
  <li><strong>Tomb page</strong>: A page which contains only empty slots</li>
  <li><strong>Free list</strong>: A linked list per Heap Page of empty slots</li>
</ul>

<p>And thatâ€™s it for this post! Iâ€™m going to continue writing blog posts in this series, and am also writing a book about managed garbage collection, with a focus on Ruby. If this interests you, join the newsletter below or follow me <a href="https://twitter.com/jemmaissroff">on twitter</a> for updates!</p>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://jemma.dev/blog/gc-mark-and-sweep</link>
            <guid isPermaLink="false">hacker-news-small-sites-26182796</guid>
            <pubDate>Thu, 18 Feb 2021 17:32:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SSH zero trust and Identity aware TCP sockets]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26182574">thread link</a>) | @bgpdude
<br/>
February 18, 2021 | https://www.mysocket.io/post/introducing-ssh-zero-trust-identity-aware-tcp-sockets | <a href="https://web.archive.org/web/*/https://www.mysocket.io/post/introducing-ssh-zero-trust-identity-aware-tcp-sockets">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.17.5"><div dir="ltr"><div><blockquote id="viewer-foo"><span>In this article, we'll look at Mysocket's zero-trust <strong><em>cloud-delivered, authenticating firewall. </em></strong><em>Allowing</em><strong><em> </em></strong>you<strong><em> to replace your trusted IP ranges with trusted identities.</em></strong></span></blockquote><p id="viewer-5nqh3"><span>Last month we introduced our first zero trust features by introducing the concept of <em>Identity Aware Sockets</em>. Itâ€™s been great to see folks giving this a spin and start using it as a remote access alternative for the traditional VPN. </span></p><p id="viewer-fer1e"><span>Most services out there today are HTTP based, typically served over HTTPS. However, there are a few other commonly used services that are not HTTP based and, as a result, up until today, didnâ€™t benefit from our identity-aware sockets. In this article, weâ€™ll introduce Zero trust support for non-HTTP based service, with the introduction Identity aware TCP sockets. Specifically, weâ€™ll look at providing zero trust services for SSH as an example.</span></p><h2 id="viewer-f7q8k"><span>Determining the userâ€™s identity, authentication, and authorization</span></h2><p id="viewer-7aaq0"><span>Turning your mysocket services into an identity-aware socket is as simple as adding theâ€Šâ€”â€Šcloud_authentication flag to mysocketctl when creating the service. While doing so, you have the ability to add a list of email domains and/or a list of email addresses. Now each time a user tries to access your service, a browser will pop up asking the user to authenticate. Once authentication is finished, we know the userâ€™s identity, and if that identity matches the list of authorized users, only then will the user be let through.</span></p><div id="viewer-8qt08"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.mysocket.io/post/introducing-ssh-zero-trust-identity-aware-tcp-sockets" data-pin-media="https://static.wixstatic.com/media/3b930f_6d1a7f0ff700466a8c76794820ad9d07~mv2.png/v1/fit/w_1000%2Ch_788%2Cal_c/file.png" src="https://static.wixstatic.com/media/3b930f_6d1a7f0ff700466a8c76794820ad9d07~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-dik4f"><span><em>Creating an Identity-aware TCP socket</em></span></p><p id="viewer-547m1"><span>If you think about what is happening here, youâ€™ll realize that what we have here is a <strong><em>per session, authenticating firewall</em></strong>. Only after the user is authenticated and authorized do we allow the network traffic through. Notice that this is much more advanced than your traditional firewall; now, <strong>every network flow has an identity</strong>. Thatâ€™s powerful!</span></p><p id="viewer-3aeq1"><span>This flow of redirecting users to authenticate and then back to the service was do-able because itâ€™s done in the browser and largely built of HTTP session management. Now weâ€™d like to extend this with non-HTTP services, so weâ€™ll need to find an alternative for the HTTP session part. 
The solution for this comes with the help of Mutual TLS (MTLS). MTLS forces the client to authenticate itself when talking to the server. This is achieved by presenting a signed client certificate to the server. </span></p><h2 id="viewer-5u1ae"><span>Identity aware TCP sockets</span></h2><p id="viewer-70lha"><span>With the introduction of identity-aware TCP sockets, the mysocket edge proxies act as an authenticating firewall. Since we are relying on client TLS certificates, all traffic is securely tunneled over a TLS connection. </span></p><p id="viewer-bj4d7"><span>As you can see in the flow below, there are a few actions to take before the user can get through. To make this a seamless experience for the users of your service, weâ€™ve extended the mysocketctl command-line tool with the required functionality that kicks of the authentication flow. It starts the authentication process; after that, it requests a client certificate (your ticket in), and then it sets up the TLS tunnel for you. After that, users can send traffic over this authenticated and encrypted tunnel. In its simplest form, it will look something like this:</span></p><pre id="viewer-flnpc"><span>echo <span>"hello"</span> <span>|</span> mysocketctl client tls \
  <span>--</span>host muddy<span>-</span>pond<span>-</span><span>7106.</span>edge<span>.</span>mysocket<span>.</span>io </span></pre><p id="viewer-13s5a"><span>In the example above, weâ€™re sending the string hello, to the service served by muddy-pond-7106.edge.mysocket.io. </span></p><div id="viewer-f4os0"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.mysocket.io/post/introducing-ssh-zero-trust-identity-aware-tcp-sockets" data-pin-media="https://static.wixstatic.com/media/3b930f_c2866a82888c4a62b9a8bab0e9f92473~mv2.png/v1/fit/w_1000%2Ch_934%2Cal_c/file.png" src="https://static.wixstatic.com/media/3b930f_c2866a82888c4a62b9a8bab0e9f92473~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-3ga6i"><span><em>Traffic flow</em></span></p><p id="viewer-1bp5o"><span>Before the string â€œhelloâ€ arrives at the service protected by mysocket, the mysocketctl client will take care of the authentication flow, requests the TLS client certificate, and sends whatever comes in over stdin to the mysocket edge services.</span></p><h2 id="viewer-a30pl"><span>SSH zero trust</span></h2><p id="viewer-a007o"><span>Now that we understand the high-level flow letâ€™s look at a more practical example. In this example, we have a server for which Iâ€™d like to make the SSH service available to only a subset of users. The ssh is on a private network such as your corporate network, your home network, or even in a private VPC or just firewalled off from the Internet.</span></p><p id="viewer-etkl7"><span>First, weâ€™ll provision the service using mysocketctl on the server-side and set up the tunnel.</span></p><pre id="viewer-7qh2i"><span>mysocketctl connect \
  --name 'remote access for my ssh server' \
  --cloudauth \
  --allowed_email_addresses'<a href="mailto:contractor@gmail.com" target="_blank" rel="noopener">contractor@gmail.com</a> \
  --allowed_email_domains 'mycorp.com' \
  --port 22 --host localhost \
  --type tls</span></pre><p id="viewer-7eojd"><span>In this example, I'm creating a mysocket service of type TLS, and we enable cloud authentication. This will force the user to present a valid client TLS certificate. The certificate can only ever be handed out to users that authenticate with a mycorp.com email address or using the specific email addresses contractor@gmail.com. </span></p><p id="viewer-fspee"><span>The same command will also set up a secure tunnel to the closest mysocket tunnel servers and expose the ssh service running on port 22. </span></p><div id="viewer-38v9c"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.mysocket.io/post/introducing-ssh-zero-trust-identity-aware-tcp-sockets" data-pin-media="https://static.wixstatic.com/media/3b930f_beee2579d42c444e9691f335223bec3c~mv2.png/v1/fit/w_1000%2Ch_1000%2Cal_c/file.png" src="https://static.wixstatic.com/media/3b930f_beee2579d42c444e9691f335223bec3c~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-cptfu"><span>The result is that this SSH service is now accessible to allowed users only, as crimson-thunder-8434.edge.mysocket.io:38676 
Only inbound traffic with a valid client TLS ticket will be let through. Valid TLS client certificates will only ever be issued to users with a mycorp.com domain or the two contractor email addresses we specified.</span></p><h2 id="viewer-7tgjk"><span>Setting up an SSH session</span></h2><p id="viewer-4ckui"><span>Ok, time to test this and connect to this ssh service. Remember that we need a valid TLS client certificate. These are issued only with a valid token, and the token is only handed out to authorized users. To make all of this easier, we've extended the mysocketctl tool to take care of this workflow. The example below shows how we use the ssh ProxyCommand to make that easier for us, like this.</span></p><pre id="viewer-ealjl"><span>ssh ubuntu@crimson<span>-</span>thunder<span>-</span><span>8434.</span>edge<span>.</span>mysocket<span>.</span>io \
  <span>-</span>o <span>'ProxyCommand=mysocketctl client tls --host %h'</span></span></pre><p id="viewer-f19kv"><span>This will tell ssh to send all ssh traffic through this <em>mysocketctl client </em>command. This will start the authentication process, fetch the TLS client certificate for us, set up the TLS tunnel to the mysocket edge server, and transport the ssh traffic through this authenticated tunnel. The user can now log in to the ssh server using whatever method youâ€™re used to.</span></p><p id="viewer-d6uat"><span>With this, weâ€™ve made our private ssh server accessible from the Internet, while the <strong><em>authenticating mysocket firewall</em></strong> is only allowing in session from client identities we approved beforehand. No VPN needed. Pretty cool, right?</span></p><h2 id="viewer-eb2c3"><span>Mysocket SSH Certificate authorities.</span></h2><div id="viewer-b9r2n"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.mysocket.io/post/introducing-ssh-zero-trust-identity-aware-tcp-sockets" data-pin-media="https://static.wixstatic.com/media/3b930f_8e04f5a076f144949126529b45666dca~mv2.png/v1/fit/w_586%2Ch_754%2Cal_c/file.png" src="https://static.wixstatic.com/media/3b930f_8e04f5a076f144949126529b45666dca~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-efkub"><span>SSH is quite similar to TLS in terms of workflow. It too supports authenticating users using signed certificates. </span></p><p id="viewer-ardlc"><span>
So we decided to expand on this functionality. In addition to an API endpoint that is responsible for signing TLS certificates, we also created one for signing SSH keys. </span></p><p id="viewer-ddpai"><span>If we build on the example above, the user can now, in addition to requesting a TLS client certificate, also request a signed SSH certificate. Our SSH certificate signing service will only sign the signing request if the user is authenticated and authorized, using the same logic as before.</span></p><h2 id="viewer-aacq7"><span>Setting up the server</span></h2><p id="viewer-54iu2"><span>In order to use this, weâ€™ll need to make a few minor changes to the SSH server. The configuration changes below are needed to enable authentication using CA keys.</span></p><pre id="viewer-2kmdr"><span>echo <span>"TrustedUserCAKeys /etc/ssh/ca.pub"</span> <span>&gt;&gt;</span><span>/</span>etc<span>/</span>ssh<span>/</span>sshd_config
echo <span>"AuthorizedPrincipalsFile %h/.ssh/authorized_principals"</span> <span>&gt;&gt;</span><span>/</span>etc<span>/</span>ssh<span>/</span>sshd_config
echo <span>"mysocket_ssh_signed"</span> <span>&gt;</span> <span>~</span>ubuntu<span>/</span><span>.</span>ssh<span>/</span>authorized_principals</span></pre><p id="viewer-109k2"><span>Finally, also make sure to get the Public key for the CA (<em>mysocketctl socket show)</em> and copy it into the ca.pub file (/etc/ssh/ca.pub).</span></p><p id="viewer-2bu8s"><span>Now the server is configured to work with and allow authentication based on signed SSH keys from the mysocket certificate authority. Note that all signed certificates will have two principles, the email address of the authenticated user, as well as â€˜<em>mysocket_ssh_signed</em>â€™. In the example configuration above, we told the server to map users with the principle â€˜<em>mysocket_ssh_signed</em>â€™ to the local user ubuntu. </span></p><p id="viewer-68m6q"><span>Now weâ€™re ready to connect, but instead of making the ssh command even longer, Iâ€™m going to add the following to my ssh config file ~/.ssh/config</span></p><pre id="viewer-1vb64"><span>Host <span>*</span><span>.</span>edge<span>.</span>mysocket<span>.</span>io
    ProxyCommand bash <span>-</span>c <span>'mysocketctl client ssh-keysign --host %h; ssh -tt -o IdentitiesOnly=yes -i ~/.ssh/%h %r@%h.mysocket-dummy &gt;&amp;2 &lt;&amp;1'</span>

Host <span>*</span><span>.</span>mysocket<span>-</span>dummy
    ProxyCommand mysocketctl client tls <span>--</span>host <span>%</span>h</span></pre><p id="viewer-5gufv"><span>The above will make sure that for all ssh sessions to *.edge.mysocket.io we start the authentication flow, fetch a TLS client certificate, and set up the TLS tunnel. Weâ€™ll also submit an SSH key signing request, which will result in a short-lived signed SSH certificate that will be used for authenticating the SSH user.</span></p><p id="viewer-ct266"><span>Now the user can just SSH like this, and the whole workflow will kick-off.</span></p><pre id="viewer-9bo6g"><span>ssh ubuntu@crimson<span>-</span>thunder<span>-</span><span>8434.</span>edge<span>.</span>mysocket<span>.</span>io</span></pre><p id="viewer-300rj"><span>For those interested, the ssh certificate will end up in your ~/.ssh/ directory and will look something like this.</span></p><pre id="viewer-bs1lt"><span>$ ssh-keygen -Lf ~/.ssh/nameless-thunder-8896.edge.mysocket.io-cert.pub
/Users/andreetoonk/.ssh/nameless-thunder-8896.edge.mysocket.io-cert.pub:
        Type: <a href="mailto:ecdsa-sha2-nistp256-cert-v01@openssh.com" target="_blank" rel="noopener">ecdsa-sha2-nistp256-cert-v01@openssh.com</a> user certificate
        Public key: ECDSA-CERT SHA256:0u6TICEhrISMCk7fbwBi629In9VWHaDG1IfnXoxjwlg
        Signing CA: ECDSA SHA256:MEdE6L0TUS0ZZPp1EAlI6RZGzO81A429lG7+gxWOonQ (using ecdsa-sha2-nistp256)
        Key ID: "<a href="mailto:atoonk@gmail.com" target="_blank" rel="noopener">atoonk@gmail.com</a>"
        Serial: 5248869306421956178
        Valid: from 2021-02-13T12:15:20 to 2021-02-13T12:25:20
<strong>        Principals:
                atoonk@gmail.com
                mysocket_ssh_signed</strong>
        Critical Options: (none)
        Extensions:
                permit-X11-forwarding
                permit-agent-forwarding
                permit-port-forwarding
                permit-pty
                permit-user-rc</span></pre><p id="viewer-8jf8b"><span>With this, users can SSH to the same server as before, but the cool thing is that the server wonâ€™t need to know any traditional known credentials for its users. Things like passwords or a public key entry in the authorized_keys file belong to the past. Instead, with the help of <em>mysocketctl</em>, the user will present a short-lived signed ssh certificate, which the server will trust.</span></p><p id="viewer-d3l5j"><span>With this, we achieved true Single Sign-on (SSO) for your SSH servers. Since the certificates are â€¦</span></p></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mysocket.io/post/introducing-ssh-zero-trust-identity-aware-tcp-sockets">https://www.mysocket.io/post/introducing-ssh-zero-trust-identity-aware-tcp-sockets</a></em></p>]]>
            </description>
            <link>https://www.mysocket.io/post/introducing-ssh-zero-trust-identity-aware-tcp-sockets</link>
            <guid isPermaLink="false">hacker-news-small-sites-26182574</guid>
            <pubDate>Thu, 18 Feb 2021 17:17:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Love F# for Mathematical Planning]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26182563">thread link</a>) | @dunefox
<br/>
February 18, 2021 | https://matthewcrews.com/blog/2020-12-09-why-i-love-fsharp-for-mathematical-planning/ | <a href="https://web.archive.org/web/*/https://matthewcrews.com/blog/2020-12-09-why-i-love-fsharp-for-mathematical-planning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<article>
   

  <div>
<blockquote>
<p>A designer knows he has achieved perfection not when there is nothing left to add, but when there is nothing left to take away</p>
<ul>
<li>Antoine de Saint-Exupery</li>
</ul>
</blockquote>
<p>On my journey of growing as a developer, I am consistently inspired by language features which seem incredibly simple but yield remarkable benefit. As I try to master F#, I am frequently surprised by how powerful the language is for expressing ideas while having so few features. Discussions frequently pop up about the need for ever more powerful abstractions, yet I find myself amazed by how far you can take the language with what is already there.</p>
<p>I am no programming language expert, but I admire languages that maintain a lean feature set. Every new feature added to a language makes it just a little bit more difficult to fully understand and a little more intimidating for new developers. It is an impressive design feat when a language can remain approachable for beginners but enable the flexibility that library authors need.</p>
<p>I am an Industrial Engineering turned Machine Learning Engineer, and I focus on the problem of maximizing the profitability and efficiency of companies. Often the solution involves a Mathematical Planning Model (aka Mathematical Programming). What I hope to do in the next few paragraphs is illustrate to you how some of the most basic features of F#, Discriminated Unions and Units of Measure, eliminate the most pernicious bugs when developing these models.</p>
<h2 id="the-domain-of-mathematical-planning">The Domain of Mathematical Planning</h2>
<p>The domain of Mathematical Planning is made up of Decisions, Constraints, and Objectives. A Decision is a choice that a business needs to make. It can be how many of Item X do we buy, do we build in Location A or Location B, or how many people do we assign to each job. Constraints are the rules we need to abide by. They are the limitations on what is possible. A Constraint could be that we only have 10 people available, or we can only build in Seattle or Portland, or we only have $1,000,000 to invest. The Objective is how we measure success. It is the function we want to maximize or minimize. We could minimize waste, maximize profit, or minimize cost.</p>
<p>Many of my colleagues are building their models with Python. Python is a great language and I have been productive with it in the past. Here is a snippet of what a mathematical planning model may look like in Python:</p>
<div><pre><code data-lang="python"><span># Define a list of items to optimize for</span>
items <span>=</span> [<span>"A"</span>, <span>"B"</span>, <span>"C"</span>]

<span># Define a list of locations to assign items to</span>
locations <span>=</span> [<span>"Portland"</span>, <span>"Seattle"</span>, <span>"Detroit"</span>]

<span># Define a dictionary of revenue associated with each item and location tuple</span>
revenue <span>=</span> {(<span>"A"</span>,<span>"Portland"</span>):<span>1.5</span>;, (<span>"A"</span>,<span>"Seattle"</span>):<span>1.7</span> <span>...</span> }

<span># Define a dictionary with the availability of each item</span>
availability <span>=</span> {<span>"A"</span>:<span>10.0</span>, <span>"B"</span>:<span>20.0</span>, <span>"C"</span>:<span>14.0</span>}

<span># Create a Decision for each Item, Location combination. This will be how much</span>
<span># of a given item we decide to send to that location</span>
allocation <span>=</span> LpVariable<span>.</span>dicts(<span>"AmountSent"</span>,(items,locations), <span>0</span>)

<span># Create an instance of a `Problem` object and state that we want to maximize</span>
<span># the objective we give it</span>
problem <span>=</span> LpProblem(<span>"ItemAllocation"</span>, LpMaximize)

<span># We create an expression which evaluates the total revenue</span>
revenue_expr <span>=</span>
    lpSum([revenue[i][l] <span>*</span> allocation[i][l] <span>for</span> i <span>in</span> items <span>for</span> l <span>in</span> locations])

<span># We set the Objective of the Problem by adding it</span>
problem <span>+=</span> revenue_expr, <span>"MaximizeRevenue"</span>

<span># For each item in items, create a constraint which states that the total number</span>
<span># of items that is allocated cannot exceed the availability of the item</span>
<span>for</span> i <span>in</span> items:
    problem <span>+=</span> lpSum([allocation[l][i] <span>for</span> l <span>in</span> location] <span>&lt;=</span> availability[i])

</code></pre></div><p>This is the beginning of a straightforward assignment problem. We have a list of items, <code>items</code>. For each <code>item</code> in <code>items</code>, we must decide how many we send to each <code>location</code> in <code>locations</code>. There is a limit on how much of each <code>item</code> is available for us to send. There is a revenue associated with sending a particular <code>item</code> to a given <code>location</code>. In this problem we want to maximize our revenue which is calculated by multiplying the <code>decision</code> for a given <code>item</code> and <code>location</code> by the <code>revenue</code> associated with it. Finally, we create a constraint for each <code>item</code> in <code>items</code> which states that the total number of a given <code>item</code> that is allocated cannot exceed the total that is available.</p>
<p>This is only part of the problem. Normally there would be more constraints that would make it more interesting. This is enough of a problem to illustrate my case though. There are two errors in this model already. If you were paying close attention you may have found one. I promise you cannot detect the second.</p>
<h2 id="the-power-of-domain-modeling-using-discriminated-unions">The Power of Domain Modeling Using Discriminated Unions</h2>
<p>F# provides two simple but powerful features which help ensure against the errors in the Python code. The first is Discriminated Unions. If we were to reformulate this problem using F#, the first thing we would do was define some simple types to model our domain.</p>
<div><pre><code data-lang="fsharp"><span>type</span> <span>Item</span> <span>=</span> Item <span>of</span> <span>string</span>
<span>type</span> <span>Location</span> <span>=</span> Location <span>of</span> <span>string</span>
</code></pre></div><p>Instead of just using strings to describe our Items and Locations, we create simple, single case Discriminated Unions (DU). These DUs provide context around what the strings are meant to represent. Letâ€™s go ahead and create our <code>item</code> and <code>locations</code> lists again. This time, wrapping them in DUs.</p>
<div><pre><code data-lang="fsharp"><span>let</span> items <span>=</span> 
  <span>[</span><span>"A"</span><span>;</span> <span>"B"</span><span>;</span> <span>"C"</span><span>]</span> 
  <span>|&gt;</span> List.map Item

<span>let</span> locations <span>=</span> 
  <span>[</span><span>"Portland"</span><span>;</span> <span>"Seattle"</span><span>;</span> <span>"Detroit"</span><span>]</span>
  <span>|&gt;</span> List.map Location
</code></pre></div><p>We will also update our <code>availability</code> information to use these new types.</p>
<div><pre><code data-lang="fsharp"><span>let</span> availability <span>=</span>
    <span>[</span>
        Item <span>"A"</span><span>,</span> 10<span>.</span>0
        Item <span>"B"</span><span>,</span> 20<span>.</span>0
        Item <span>"C"</span><span>,</span> 14<span>.</span>0
    <span>]</span> <span>|&gt;</span> Map
</code></pre></div><p>We will create the Decisions for each <code>item</code> and <code>location</code>. We store these <code>Decision</code> types in a <code>Map</code> which is indexed by an <code>(Item * Location)</code> tuple.</p>
<div><pre><code data-lang="fsharp"><span>let</span> allocation <span>=</span>
    DecisionBuilder<span>&lt;</span>Servings<span>&gt;</span> <span>"AmountSent"</span> <span>{</span>
        <span>for</span> i <span>in</span> items <span>do</span>
            <span>for</span> l <span>in</span> locations <span>-&gt;</span>
                Continuous <span>(</span>0<span>.</span>0<span>,</span> infinity<span>)</span>
    <span>}</span> <span>|&gt;</span> Map
</code></pre></div><p>We now attempt to create the same constraints we did in Python with a direct translation.</p>
<div><pre><code data-lang="fsharp"><span>let</span> allocationContraints <span>=</span>
    ConstraintBuilder <span>"ItemLimit"</span> <span>{</span>
        <span>for</span> i <span>in</span> items <span>-&gt;</span>
            List.sum <span>[</span><span>for</span> l <span>in</span> locations <span>-&gt;</span> 1<span>.</span>0 <span>*</span> allocation<span>.[</span>l<span>,</span> i<span>]]</span> <span>&lt;==</span> availability<span>.[</span>i<span>]</span>
    <span>}</span>   
</code></pre></div><p>Except, the compiler is gives us an error on the indexing of <code>allocation</code>.</p>
<p><img src="https://matthewcrews.com/img/2020-12-08-indexing-error.png" alt="Compiler error for indexing Map"></p>
<p>What some of you may have noticed in the Python code is that the <code>allocation</code> collection is indexed by an <code>Item</code> then <code>Location</code>. The original code was trying to access it by <code>location</code> then by <code>item</code>. This would have thrown an error at runtime due to a missing value. In F# this becomes a compiler error. The type system itself it is helping you. This may seem small, but this is one of the most painful types of errors when debugging a Mathematical Planning model.</p>
<p>Someone may say that this can be accomplished in other languages and I would agree. I believe where F# is unique is in the simplicity and ease of using single case Discriminated Unions for wrapping primitives. It is virtually no additional effort.</p>
<h2 id="units-of-measure-the-achilles-heel-of-numbers">Units of Measure: The Achilles Heel of Numbers</h2>
<p>There is an underappreciated problem in software development, numbers are rarely just numbers. They represent something: <code>cm</code>, <code>feet</code>, <code>kg</code>, or <code>meters</code>. Normally we do not care about a raw number. Our primary concern is with what the number represents. In most languages there are no easy mechanisms for tracking the Units of Measure associated with a number. F# on the other hand has baked the concept of a Unit of Measure into the type system.</p>
<p>The Units of Measure feature will reveal the second problem with the Python code that otherwise may remain undetected. Letâ€™s update our domain with some new types to track the units on our numbers.</p>
<div><pre><code data-lang="fsharp"><span>[&lt;</span>Measure<span>&gt;]</span> <span>type</span> <span>Servings</span>
<span>[&lt;</span>Measure<span>&gt;]</span> <span>type</span> <span>Kg</span>
</code></pre></div><p>We now have units to represent <code>Servings</code> and <code>Kg</code>. Letâ€™s update our <code>availability</code> collection to store numbers with these units attached.</p>
<div><pre><code data-lang="fsharp"><span>let</span> availability <span>=</span>
    <span>[</span>
        Item <span>"A"</span><span>,</span> 10<span>.</span>0<span>&lt;</span>Kg<span>&gt;</span>
        Item <span>"B"</span><span>,</span> 20<span>.</span>0<span>&lt;</span>Kg<span>&gt;</span>
        Item <span>"C"</span><span>,</span> 14<span>.</span>0<span>&lt;</span>Kg<span>&gt;</span>
    <span>]</span> <span>|&gt;</span> Map
</code></pre></div><p>We have now provided more context around our availability numbers. We now know they are stored in units of <code>Kg</code>. The F# compiler will enforce correct algebra as we work with them. We now update our Decisions to be in units of <code>Servings</code>.</p>
<div><pre><code data-lang="fsharp"><span>let</span> allocation <span>=</span>
    DecisionBuilder<span>&lt;</span>Servings<span>&gt;</span> <span>"AmountSent"</span> <span>{</span>
        <span>for</span> i <span>in</span> items <span>do</span>
            <span>for</span> l <span>in</span> locations <span>-&gt;</span>
                Continuous <span>(</span>0<span>.</span>0<span>&lt;</span>Servings<span>&gt;,</span> 1_000_000<span>.</span>0<span>&lt;</span>Servings<span>&gt;)</span>
    <span>}</span> <span>|&gt;</span> Map
</code></pre></div><p>With our Decisions updated, we go back to our constraint definition and we now see a new bug.</p>
<p><img src="https://matthewcrews.com/img/2020-12-08-units-of-measure-mismatch.png" alt="Units of Measure Mismatch"></p>
<p>The important part of this message is at the bottom. The compiler is complaining that the left-hand is in units of <code>Servings</code> and the right-hand side is in units of <code>Kg</code>. It does not make sense to compare values that are in different units, so the compiler is throwing an error. In other languages this error would go undetected. Worse, it may not even be caught in unit testing because the math will still work, it just wonâ€™t give correct results.</p>
<p>Letâ€™s go ahead and add some conversion data so that we can fix this.</p>
<div><pre><code data-lang="fsharp"><span>let</span> itemMass <span>=</span>
    <span>[</span>
        Item <span>"A"</span><span>,</span> 1<span>.</span>1<span>&lt;</span>Kg<span>/</span>Servings<span>&gt;</span>
        Item <span>"B"</span><span>,</span> 2<span>.</span>0<span>&lt;</span>Kg<span>/</span>Servings<span>&gt;</span>
        Item <span>"C"</span><span>,</span> 0<span>.</span>7<span>&lt;</span>Kg<span>/</span>Servings<span>&gt;</span>
    <span>]</span> <span>|&gt;</span> Map
</code></pre></div><p>We now have data which will allow us to convert from <code>Serving</code> to <code>Kg</code>. Letâ€™s incorporate it into our constraint creation expression.</p>
<div><pre><code data-lang="fsharp"><span>let</span> allocationContraints <span>=</span>
  ConstraintBuilder <span>"ItemLimit"</span> <span>{</span>
    <span>for</span> i <span>in</span> items <span>-&gt;</span>
      List.sum <span>[</span><span>for</span> l <span>in</span> locations <span>-&gt;</span> itemMass<span>.[</span>i<span>]</span> <span>*</span> itemAllocation<span>.[</span>i<span>,</span> l<span>]]</span> <span>&lt;==</span> availability<span>.[</span>i<span>]</span>
  <span>}</span> 
</code></pre></div><p>Now the compiler is happy because the units are in <code>Kg</code> on both sides. This simple feature of ensuring correct Units of Measure eliminates what is possibly the most nefarious bug in Mathematical Planning. It would be hard to calculate the number of hours wasted on badly formulated models due to mismatched Units of Measure.</p>
<h2 id="simple-building-blocks">Simple Building Blocks</h2>
<p>F# is an incredibly expressive language while staying lean on the number of features. Other languages have taken the approach of throwing every possible feature in. F# is relatively slow to â€¦</p></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://matthewcrews.com/blog/2020-12-09-why-i-love-fsharp-for-mathematical-planning/">https://matthewcrews.com/blog/2020-12-09-why-i-love-fsharp-for-mathematical-planning/</a></em></p>]]>
            </description>
            <link>https://matthewcrews.com/blog/2020-12-09-why-i-love-fsharp-for-mathematical-planning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26182563</guid>
            <pubDate>Thu, 18 Feb 2021 17:16:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to process large amounts of data in Elixir with Ecto]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26182276">thread link</a>) | @todsacerdoti
<br/>
February 18, 2021 | https://mkaszubowski.com/2021/02/16/ecto-repo-stream-data-processing.html | <a href="https://web.archive.org/web/*/https://mkaszubowski.com/2021/02/16/ecto-repo-stream-data-processing.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">
  <p><strong>This is not a post about Big Data.</strong> This is about datasets that are
too big to handle entirely in-memory but too small to justify spending a few
hours writing a custom data pipeline.</p>

<p>Here is an easy way to deal with data that should take up to a few hours to
process:</p>

<div><div><pre><code><span>Repo</span><span>.</span><span>transaction</span><span>(</span><span>fn</span> <span>-&gt;</span>
  <span>YourSchema</span>
  <span>|&gt;</span> <span>order_by</span><span>(</span><span>asc:</span> <span>:inserted_at</span><span>)</span>
  <span>|&gt;</span> <span>any_query</span><span>()</span>
  <span>|&gt;</span> <span>Repo</span><span>.</span><span>stream</span><span>()</span>
  <span>|&gt;</span> <span>Stream</span><span>.</span><span>map</span><span>(</span><span>fn</span> <span>user</span> <span>-&gt;</span> <span>any_transformation</span><span>(</span><span>user</span><span>)</span> <span>end</span><span>)</span>
  <span>|&gt;</span> <span>Stream</span><span>.</span><span>filter</span><span>(</span><span>&amp;</span><span>any_filter</span><span>/</span><span>1</span><span>)</span>
  <span>|&gt;</span> <span>Stream</span><span>.</span><span>each</span><span>(</span><span>fn</span> <span>user</span> <span>-&gt;</span> <span>do_something_with_user</span><span>(</span><span>user</span><span>)</span> <span>end</span><span>)</span>
  <span>|&gt;</span> <span>Stream</span><span>.</span><span>run</span><span>()</span>
<span>end</span><span>,</span> <span>timeout:</span> <span>:infinity</span><span>)</span>
</code></pre></div></div>



<ul>
  <li><code>Repo.stream/1</code> has to be used inside a transaction for both PostgreSQL and
MySQL. It queries the DB in chunks (the default chunk size is 500 rows.)</li>
  <li>Weâ€™re passing <code>timeout: :infinity</code> to <code>Repo.transaction/2</code> to allow it to run
as long as it needs. <a href="https://hexdocs.pm/ecto/Ecto.Repo.html#module-shared-options">The default is 15
seconds</a>, after
which the transaction times out.</li>
  <li>Streaming the results will block one of the connections from Ectoâ€™s connection pool, so watch out for that if your connection pool size is small.</li>
  <li>Since itâ€™s run in a transaction, rows added after the function starts wonâ€™t be
read. You can re-run the script adding a <code>where</code> clause with a timestamp to
synchronise those entries.</li>
  <li>Since <code>Repo.stream</code> returns an Elixir stream, you have to use <code>Stream</code> module instead of <code>Enum</code>.
You can use <code>Stream</code> instead of <code>Enum</code> for most of what youâ€™d typically need.
Just use <a href="https://hexdocs.pm/elixir/Stream.html#run/1">Stream.run/1</a> at the end to actually run the
processing.</li>
  <li>Before you run the function on the entire dataset, you can easily add <code>|&gt;
limit(10)</code> clause to your query and test if processing is correct.</li>
</ul>

<h2 id="example-use-cases">Example use cases</h2>

<ul>
  <li>Migrate the data from one table to another.</li>
  <li>Migrate the data to another database (for example: build an initial index in
ElasticSearch).</li>
  <li>Export the data to a CSV file.</li>
  <li>Fill missing values for old data (after adding a new column).</li>
  <li>Any manual, one-time task you might want to do for some data.</li>
</ul>

<h2 id="alternative-approaches">Alternative approaches</h2>

<ul>
  <li>If you only need CSV and donâ€™t need to do any in-memory transformations, <a href="https://www.postgresqltutorial.com/export-postgresql-table-to-csv-file/">you
can export data from PostgreSQL
directly</a>
using the <code>COPY</code> statement. You can import data from CSV, too.</li>
  <li>If you want to make the processing parallel, take a look at
<a href="https://github.com/dashbitco/flow">Flow</a> (or
<a href="https://github.com/elixir-lang/gen_stage">GenStage</a>)</li>
</ul>

<h2 id="references">References:</h2>

<ul>
  <li><a href="https://hexdocs.pm/ecto/Ecto.Repo.html#c:stream/2">https://hexdocs.pm/ecto/Ecto.Repo.html#c:stream/2</a></li>
  <li><a href="https://hexdocs.pm/elixir/Stream.html">https://hexdocs.pm/elixir/Stream.html</a></li>
</ul>

  <hr>
</div></div>]]>
            </description>
            <link>https://mkaszubowski.com/2021/02/16/ecto-repo-stream-data-processing.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26182276</guid>
            <pubDate>Thu, 18 Feb 2021 16:57:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TeXmacs: The Macro editor and easy macro modification]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26182251">thread link</a>) | @amichail
<br/>
February 18, 2021 | https://texmacs.github.io/notes/docs/macro-editor.html | <a href="https://web.archive.org/web/*/https://texmacs.github.io/notes/docs/macro-editor.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    
    
    
    
    <p>
      The TeXmacs editor offers the possibility of examining and modifying
      macro definitions through a â€œshortcutâ€ tool, without having
      to know in which style file or package they are defined. 
    </p>
    <p>
      The tool is called â€œMacro editorâ€, and the modifications
      made via the Macro editor are saved in the preamble of the current
      document, while original definitions of macros are preserved in their
      respective files. The Macro editor can be used as well to write up a new
      macro starting from an existing macro.
    </p>
    <p>
      Let us examine two examples. 
    </p>
    <h2 id="auto-2">1.<span></span>Colored todo notes<span></span></h2>
    <p>
      TeXmacs has a <span>todo</span> macro which typesets its
      arguments (a reminder to self, let's say) with red font on a light red
      background, surrounded by brackets: <span color="#800000">[write a helpful blog
      post]</span>.
    </p>
    <p>
      Let us see how to change the macro to have colored notes in different
      colors. The Macro editor is accessible from macro applications
      themselves, so we insert a <span>todo</span> macro by typing <tt>\todo</tt> obtaining a red â€œtodoâ€ field: <span color="#800000">[]</span>.
      With the cursor inside the (already typeset) macro field, a button that
      invokes the Macro editor becomes available in the TeXmacs tool ribbons;
      in Figure <a href="#fig:macro-editor-wrench">1</a> we highlight the â€œwrenchâ€ button.
    </p>
    <div>
      <table>
        <tbody><tr>
          <td><img src="https://texmacs.github.io/notes/docs/macro-editor-1.The%20macro%20editor%2001%20-%20edited.png" width="562.33568"></td>
        </tr><tr>
          <td></td>
        </tr><tr>
          <td><p><span><p>
              <b>Figure 1. </b><a id="auto-3"></a>The Macro editor appears among the
              tools as the wrench icon <img src="https://texmacs.github.io/notes/docs/macro-editor-2.tm_focus_prefs.png" height="14.058392" width="14.058392">
              when the cursor is in a macro field (the icon is in this figure
              highlighted and connected to the macro with the arrow).<a id="fig:macro-editor-wrench"></a>
            </p></span>
          </p></td>
        </tr></tbody>
      </table>
    </div>
    <p>
      Clicking on the wrench button a menu appears, and we select â€œEdit
      macroâ€ (Figure <a href="#fig:macro-edit-menu">2</a>); selecting â€œEdit
      sourceâ€ would bring us to the location (package or style file)
      where the macro is defined.
    </p>
    <div>
      <table>
        <tbody><tr>
          <td><img src="https://texmacs.github.io/notes/docs/macro-editor-3.The%20macro%20editor%2002%20-%20edited.png" width="562.33568"></td>
        </tr><tr>
          <td></td>
        </tr><tr>
          <td><p><span><p>
              <b>Figure 2. </b><a id="auto-4"></a>The macro editing
              (â€œwrenchâ€) menu.<a id="fig:macro-edit-menu"></a>
            </p></span>
          </p></td>
        </tr></tbody>
      </table>
    </div>
    <p>
      Clicking on â€œEdit macroâ€ brings up the â€œEdit
      macroâ€ window, the protagonist of this blog post (Figure <a href="#fig:macro-editor-window">3</a>).
      Let us ignore in this blog post the menu items <a id="auto-5"></a> and <a id="auto-6"></a>, which would also allow a customization of the
      macro but do not have the general applicability of the macro editor.
    </p>
    <div>
      <table>
        <tbody><tr>
          <td><img src="https://texmacs.github.io/notes/docs/macro-editor-4.The%20macro%20editor%2003.png" height="345.8364432" width="565.1473584"></td>
        </tr><tr>
          <td></td>
        </tr><tr>
          <td><p><span><p>
              <b>Figure 3. </b><a id="auto-7"></a>The Macro editor window.<a id="fig:macro-editor-window"></a>
            </p></span>
          </p></td>
        </tr></tbody>
      </table>
    </div>
    <p>
      The first view is the â€œtext viewâ€, where the macro is
      represented in typeset form (as in the text mode of TeXmacs); in this
      case it results in a <span>todo</span> note which displays the
      name of the variable in the macro definition (<span color="#800000">[body]</span>).
      We are interested in the source so we select â€œSourceâ€ from
      the drop-down menu at the bottom left (Figure <a href="#fig:macro-text-mode">4</a>).
    </p>
    <div>
      <table>
        <tbody><tr>
          <td><img src="https://texmacs.github.io/notes/docs/macro-editor-5.The%20macro%20editor%2004%20-%20edited.png" width="562.33568"></td>
        </tr><tr>
          <td></td>
        </tr><tr>
          <td><p><span><p>
              <b>Figure 4. </b><a id="auto-8"></a>The <span>todo</span> macro
              in text mode inside the Macro editor.<a id="fig:macro-text-mode"></a>
            </p></span>
          </p></td>
        </tr></tbody>
      </table>
    </div>
    <p>
      The macro now is represented in source mode and we can edit it (Figure
      <a href="#fig:macro-source-mode">5</a>).
    </p>
    <div>
      <table>
        <tbody><tr>
          <td><img src="https://texmacs.github.io/notes/docs/macro-editor-6.The%20macro%20editor%2005.png" width="562.33568"></td>
        </tr><tr>
          <td></td>
        </tr><tr>
          <td><p><span><p>
              <b>Figure 5. </b><a id="auto-9"></a>The <span>todo</span> macro
              in source mode inside the Macro editor.<a id="fig:macro-source-mode"></a>
            </p></span>
          </p></td>
        </tr></tbody>
      </table>
    </div>
    <p>
      We would like to have green <span>todo</span> notes. We identify
      tentatively the two variables <span color="#008000"><i>todo-color</i></span> and
      <span color="#008000"><i>todo-bg-color</i></span> as the color of the text and
      the color of the backgroundâ€”it looks reasonable, and if this does
      not work, we can check how the macro <span>render-todo</span> is
      composed (in TeXmacs 1.99.18, which I am using to write this blog post,
      a bug prevents one to do this for the macro <span>render-todo</span>
      through the macro editorâ€”the attempt makes TeXmacs crashâ€”so
      if you want to check that macro please use the <a id="auto-10"></a> entry of the â€œwrenchâ€ menu and the
      file <tt>std-markup.ts</tt> will open at the position of the code
      for <span>render-macro</span>; the discussion of the <span>todo</span>
      example works despite this bug).
    </p>
    <p>
      We can check the values of the environment variables (see <a href="https://www.texmacs.org/tmweb/manual/webman-env.en.html">Standard
      environment variables</a> for a general discussion of the environment
      variables ) by typing them preceded by a backslash and pressing <span>Return</span> (for this we can either switch out of the
      macro editor and use the usual TeXmacs editor or we can set the macro
      editor to Text mode): <span color="#008000"><i>todo-color</i></span> evaluates to
      dark red and <span color="#008000"><i>todo-bg-color</i></span> to pastel red. Let
      us then substitute dark green and pastel green for them.
    </p>
    <p>
      To type our new text in place of either <span color="#008000"><i>todo-color</i></span>
      or <span color="#008000"><i>todo-bg-color</i></span>, we first click
      <strong>four</strong> times onto it to select its name and the
      surrounding markupâ€”clicking twice selects one of the words in the
      compound name of the variable (between hyphens), clicking three times
      selects the whole variable name without the <span>value</span>
      markup surrounding itâ€”and then we type over it the text that we
      wish to: â€œdark greenâ€ (without the quotes) in place of <span color="#008000"><i>todo-color</i></span> and â€œpastel greenâ€
      (likewise) in place of <span color="#008000"><i>todo-bg-color</i></span>.
    </p>
    <p>
      In Figure <a href="#fig:environment-variable-selected">6</a> we show the effect of clicking three or four
      times on the environment variable. When clicking three times (shown on
      the left side of the image), the <span>value</span> markup
      surrounding the variable name is not enclosed in the selection, which in
      this case does not reach the focus frame, as shown in the magnified view
      on the bottom; when clicking four times (as in the right side of the
      image), the selection reaches the edge of the focus frame and encloses
      the <span>value</span> markup.
    </p>
    <div>
      <table>
        <tbody><tr>
          <td><img src="https://texmacs.github.io/notes/docs/macro-editor-7.The%20macro%20editor%2006%20-%20marked.png" width="365.518192"></td>
        </tr><tr>
          <td></td>
        </tr><tr>
          <td><p><span><p>
              <b>Figure 6. </b><a id="auto-11"></a>The environment variable <span color="#008000"><i>todo-color</i></span> selected clicking three times
              (upper left) and four times (upper right). When clicking three
              times, the <span>value</span> markup surrounding the
              variable name is not enclosed in the selection, which does not
              reach the focus frame (magnified view at the bottom); when
              clicking four times, the selection extends to the whole focus
              frame and encloses the <span>value</span> markup.<a id="fig:environment-variable-selected"></a>
            </p></span>
          </p></td>
        </tr></tbody>
      </table>
    </div>
    <p>
      Clicking the <a id="auto-12"></a> or the <a id="auto-13"></a> button will save the edited macro
      in the document preamble.
    </p>
    <p>
      TeXmacs will save to the preamble the contents of the Macro editor
      window, so if one leaves the macro name as it is, the macro saved in the
      preamble is executed by TeXmacs in place of the original macro (while
      the original definition is not overwritten, the macro editor modifies
      only the current file). Changing in stead the name of the macro leaves
      the original definition in forceâ€”and one has a new macro with the
      new definition.
    </p>
    <p>
      Let us then in our example change the macro name to <span>todo-green</span>,
      by clicking inside the <span>todo</span> field on top and typing,
      we will have then a new macro availableâ€”repeating ourselves, if we
      hadn't, the <span>todo</span> macro would have pointed to the new
      definition we are saving in our preamble, and in this case all of the
      <span>todo</span> fields would have become green, including the
      ones we had already written. You can see the edited macro in Figure <a href="#fig:todo-macro-edited-green">7</a>.
    </p>
    <div>
      <table>
        <tbody><tr>
          <td><img src="https://texmacs.github.io/notes/docs/macro-editor-8.The%20macro%20editor%2007.png" width="562.33568"></td>
        </tr><tr>
          <td></td>
        </tr><tr>
          <td><p><span><p>
              <b>Figure 7. </b><a id="auto-14"></a>The â€œgreenâ€ version of
              the <span>todo</span> macro, which we named <span>todo-green</span><a id="fig:todo-macro-edited-green"></a>
            </p></span>
          </p></td>
        </tr></tbody>
      </table>
    </div>
    <p>
      Press <a id="auto-15"></a> to close the Macro
      editor confirming the changes, and we can see the new macro <span>todo-green</span>
      in our preamble: select â†’<a id="auto-16"></a> (in the
      â€œNotesâ€ style: in other styles it is â†’â†’<a id="auto-17"></a>). We look at it in Figure <a href="#fig:preamble">8</a>.
    </p>
    <div>
      <table>
        <tbody><tr>
          <td><img src="https://texmacs.github.io/notes/docs/macro-editor-9.The%20macro%20editor%2008%20-%20marked.png" height="345.8364432" width="566.5531976"></td>
        </tr><tr>
          <td></td>
        </tr><tr>
          <td><p><span><p>
              <b>Figure 8. </b><a id="auto-18"></a>The preamble of our document after
              saving the <span>todo-green</span> macro we composed
              starting from the <span>todo</span> macro. The arrow and
              the oval highlight the TeXmacs notification that we are looking
              at the preamble.<a id="fig:preamble"></a>
            </p></span>
          </p></td>
        </tr></tbody>
      </table>
    </div>
    <p>
      We can now use the new macro: <span color="#008000">[I would like to have blue
      notes too!]</span> and <span></span>.<span></span>.<span></span>.<span></span> <span color="#000080">[here is a blue todo
      note :-)]</span> (to do this, I started again from a <span>todo</span>
      note and applied again the Macro editor).
    </p>
    <p>
      For colors which do not have a name in TeXmacs, one can use HTML codes;
      if TeXmacs does not recognize a color name, it uses black.
    </p>
    <h2 id="auto-19">2.<span></span>More choice<span></span></h2>
    <p>
      In math mode the macro <span>choice</span> inserts a left brace
      that introduces a vertical list, represented with the help of a table.
    </p>
    <p>
      Here it is, inserted by typing <tt>\choice</tt> <span>â†©</span> inside a display math environment; we placed two
      elements inside it:
    </p>
    <table>
      <tbody><tr>
        <td><img src="https://texmacs.github.io/notes/docs/macro-editor-10.png" id="eq:choice-macro"></td>
        <td>(1)</td>
      </tr>
    </tbody></table>
    <p>
      Using the Macro editor, let's build a new macro that places the brace on
      the right.
    </p>
    <p>
      The first step is again placing the cursor in the macro input field (in
      the vector next to the brace in this case) and pressing the wrench key
      in the toolbar. The Macro editor window in this case shows the typeset
      macro in math mode (Figure <a href="#fig:choice_macro_math_mode">9</a>).
    </p>
    <div>
      <table>
        <tbody><tr>
          <td><img src="https://texmacs.github.io/notes/docs/macro-editor-11.The%20macro%20editor%208.png" width="566.5531976"></td>
        </tr><tr>
          <td></td>
        </tr><tr>
          <td><p><span><p>
              <b>Figure 9. </b><a id="auto-20"></a>Editing the <span>choice</span>
              macro in the Macro editor.<a id="fig:choice_macro_math_mode"></a>
            </p></span>
          </p></td>
        </tr></tbody>
      </table>
    </div>
    <p>
      The source mode representation of the macro is complex (Figure <a href="#fig:choice_macro_source_mode">10</a>),
      but maybe we do not need to know what is the <span>math-table-base</span>
      macro, nor what are <span color="#008000"><i>cell-swell</i></span> and <span color="#008000"><i>table-math-swell</i></span>; let's try.
    </p>
    <p>
      Let us notice the two paired delimiters <span color="blue">&lt;</span>left<span color="blue">|</span><span color="black">{</span><span color="blue">&gt;</span> and <span color="blue">&lt;</span>right<span color="blue">|</span><span color="black">.</span><span color="blue">&gt;</span>: we have to swap them. Of course, the left brace must
      become a right brace.
    </p>
    <p>
      As a second step, let us guess that the macro <span>math-table-base</span>
      and the variables <span color="#008000"><i>cell-swell</i></span> and <span color="#008000"><i>table-math-swell</i></span> determine the placement of the
      â€œvector of choiceâ€ with respect to the brace. We do not know
      whether <span>math-table-base</span> distinguishes right from
      left in such a way that the placement of the vector with respect to a
      closing brace would be awkward with the default settings of <span color="#008000"><i>cell-swell</i></span>
      and <span color="#008000"><i>table-math-swell</i></span>,
      butâ€”againâ€”let us try and see what happens!
    </p>
    <div>
      <table>
        <tbody><tr>
          <td><img src="https://texmacs.github.io/notes/docs/macro-editor-12.The%20macro%20editor%209.png" width="566.5531976"></td>
        </tr><tr>
          <td></td>
        </tr><tr>
          <td><p><span><p>
              <b>Figure 10. </b><a id="auto-21"></a>The source mode representation of
              the <span>choice</span> macro.<a id="fig:choice_macro_source_mode"></a>
            </p></span></p></td></tr></tbody></table></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://texmacs.github.io/notes/docs/macro-editor.html">https://texmacs.github.io/notes/docs/macro-editor.html</a></em></p>]]>
            </description>
            <link>https://texmacs.github.io/notes/docs/macro-editor.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26182251</guid>
            <pubDate>Thu, 18 Feb 2021 16:55:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Census Raises $16M Series A from Sequoia]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26181985">thread link</a>) | @nate
<br/>
February 18, 2021 | https://blog.getcensus.com/announcing-our-series-a-from-sequoia/ | <a href="https://web.archive.org/web/*/https://blog.getcensus.com/announcing-our-series-a-from-sequoia/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <section>
                <div>
                    <p>Iâ€™m thrilled to announce that Census has raised a $16 million Series A, led by Sequoia Capital. Andreessen Horowitz (who led our seed) is also participating, along with operators like Dylan Field (Figma CEO), Jason Warner (GitHub CTO), Akshay Kothari (Notion COO), Parker Conrad (Rippling CEO), Josh Ferguson (Mode Chief Architect), Bryant Chou (Webflow CTO), Joe Thomas (Loom CEO), Patrick McKenzie (Stripe) and Guillaume Cabane. This round brings our total amount raised to just over $20 million.</p><p>We're also launching the <a href="https://blog.getcensus.com/introducing-the-census-startup-program">Census Startup Program</a> to empower startups to easily build the last mile of the modern data stack. Companies with fewer than 40 employees and less than $10MM in funding will be able to use Census for a flat rate of $100 per month.</p><figure><img src="https://lh3.googleusercontent.com/PqQs9ECN6mKTopIPG2ZhvZL_-FmCS_h7uB_VAAizC02R6hS7wXGBj2G2ph7tafLbpJ_66C5dfvp6ljRvWCqejYEW-GHIiVWw5KEqwi42b2sijRGJsCFh-ZhMkWJffuIxVNbl0m2j" alt=""></figure><p>In 2018, we started with a simple product that helped business teams sync data from their cloud warehouses into their favorite tools. Since then, the data landscape has changed a lot â€“ now we're starting to see analytics &amp; data move to the core of all company operations. We <a href="https://blog.getcensus.com/meet-census/">launched publicly</a> last year with the world's first reverse ETL that natively publishes from any data warehouse (we dubbed this the "missing piece" in the modern data stack). The reaction has been nothing short of phenomenal â€“ Census is now syncing analytics for over half a billion users every day.</p><p>We're lucky to support some pretty amazing teams using Census, like Canva, Figma, Drizly, Heap Analytics, Netlify, Mode Analytics, Notion, and Chorus.ai just to name a few. These organizations are unified by a shared focus on delivering personalized experiences for every customer, even when they've scaled to hundreds of millions of users.</p><p>To do this, they treat data as a central pillar of their organization, instead of just paying lip service to being "data-driven." Putting data teams on the critical path of every business operation has emerged as the category of <a href="https://blog.getcensus.com/what-is-operational-analytics/">Operational Analytics</a> â€“ and has been the driving force for our company.</p><h3 id="operational-analytics-aka-the-data-warehouse-as-hub">Operational Analytics, aka. the Data Warehouse as Hub</h3><p>Three years ago, we asked, â€œWhy are we relying on a clumsy tangle of wires connecting every app when everything we need is already in the warehouse? What if you could leverage your data team to drive operations?â€</p><p>When the data warehouse is connected to the rest of the business, the possibilities are limitless. When we launched, our focus was enabling product-led companies like Figma, Canva, and Notion to drive better marketing, sales, and customer success. Along the way, our customers have pulled Census into more and more scenarios, like auto-prioritizing support tickets in <a href="https://blog.getcensus.com/census-zendesk-for-better-customer-support/">Zendesk</a>, automating invoices in <a href="https://headwayapp.co/census-changelog/netsuite-destination-186207">Netsuite</a>, or even integrating with HR systems. With our growing library of <a href="https://www.getcensus.com/integrations">native integrations</a>, Census makes it possible for data models in your cloud data warehouse to power any business workflow.</p><figure><img src="https://blog.getcensus.com/content/images/2021/02/Eventail-Diagram-4.png" alt="" srcset="https://blog.getcensus.com/content/images/size/w600/2021/02/Eventail-Diagram-4.png 600w, https://blog.getcensus.com/content/images/size/w1000/2021/02/Eventail-Diagram-4.png 1000w, https://blog.getcensus.com/content/images/size/w1600/2021/02/Eventail-Diagram-4.png 1600w, https://blog.getcensus.com/content/images/size/w2400/2021/02/Eventail-Diagram-4.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>The performance improvements we've seen in the modern data stack (fast incremental ingestion from our partners at <a href="https://fivetran.com/blog/fivetran-partners-with-census-to-complete-the-loop-on-operational-analytics">Fivetran</a>, separated workloads on Redshift, improving latency from Snowflake, the arrival of <a href="https://blog.getcensus.com/census-databricks/">Delta Lake</a>, etc.) finally make it possible for the data warehouse to act as a <a href="https://blog.getcensus.com/the-best-cdp-solution-is-already-sitting-in-your-data-warehouse/">new kind of CDP</a> (Customer Data Platform). One that enables hyper-scale businesses to deliver the attention and personalization that customers historically only get from, say, a small neighborhood boutique. This is the promise of Operational Analytics.</p><h3 id="the-rise-of-the-data-ops-ecosystem">The Rise of the Data Ops Ecosystem</h3><p>Census is part of a larger movement in the data ecosystem, one in which the precepts of Engineering and DevOps are washing over the world of analytics. Marc Andreessen famously said "software is eating the world." Our team has always believed in the corollary: "software practices will eat the business." We've made it our mission from day one to help data teams build solutions like engineers. And weâ€™ve worked with amazing partners in bringing this vision to reality.</p><figure><img src="https://lh6.googleusercontent.com/eLy_nydDOnPyVwsQEHTu8k3cGiicY2EAKJn6E8pC4gankSOLcc66qnhf1O0KiY4cD2Y6-LABH4KGMtQ9pw9D61APtXf5UPcGLp-f3bs-bFCnTsM42AInrUL6_PXvTUH6GW10t7aW" alt=""><figcaption>Fivetran + dbt + Census = Feedback Loop</figcaption></figure><p>Census takes models and insights from a data warehouse then <a href="https://whatsnew.getcensus.com/built-in-data-validation-186053">validates</a> and <a href="https://blog.getcensus.com/making-your-dbt-models-more-useful-with-census/">deploys</a> the results so they can be put to work in other teams (ie. the real world). With our native understanding of dbt model versions, you can safely orchestrate your entire data operations from input to output. Census closes the feedback loop to make the whole much greater than the sum of the parts.</p><p>But what most drives this movementâ€”and what we love most about itâ€”is the amazing community of developers, analysts, and operations experts that all help each other to build better systems. Our partners at Fishtown have fostered one of the most inclusive and helpful communities, which supported and embraced Census early on â€“ led by the intrepid <a href="https://twitter.com/clairebcarroll">Claire Caroll</a> (fun fact: she helped popularize our â€œreverse ETLâ€ concept in 2019). We participate in our small way with tool talks and office hours. Thereâ€™s a real excitement around the modern data stack, which is why we created our new startup program so folks could adopt this stack regardless of company size or budget.</p><h3 id="the-future-data-as-a-product">The Future: Data as a Product</h3><p>The next decade is going to be an exciting one for data teams, and our early customers are pointing the way. Instead of constantly building (and fixing) one-off reports, data teams are poised to become a central nervous system for the business.</p><p>Traditionally, BI teams have been focused on asynchronous, batch processing instead of real-time, personalized processing. Analysts build reports to answer questions about what happened in the business, which is like looking at the rear view mirror. This data architecture could crunch raw data into KPIs and charts but wasnâ€™t optimized for understanding individual users or entities. Even worse, it was disconnected from day-to-day operations, which forced data teams to do painful periodic reconciliations with the business.</p><figure><img src="https://blog.getcensus.com/content/images/2021/02/new-data-teams-4.png" alt="" srcset="https://blog.getcensus.com/content/images/size/w600/2021/02/new-data-teams-4.png 600w, https://blog.getcensus.com/content/images/size/w1000/2021/02/new-data-teams-4.png 1000w, https://blog.getcensus.com/content/images/size/w1600/2021/02/new-data-teams-4.png 1600w, https://blog.getcensus.com/content/images/size/w2400/2021/02/new-data-teams-4.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Operational Analytics changes the role of data teams</figcaption></figure><p>Modern data teams are built differently. Instead of a data sink, they are a platform for applications, analysis, visualization â€“ and most importantly, action. Instead of focusing on data aggregation for BI visualization, a new modeling layer must emerge that captures clean, unified yet individualized entities that can be used in any application. In order to support all these scenarios, a few things are crucial.</p><ol><li>The data infrastructure must be scalable, efficient, and real-time.</li><li>The data modeling layer must be versioned, tested, deployed, and ultimately standardized for broad consumption.</li><li>The data pipelines must reach any application, and be seamlessly monitored to create tight feedback loops with every part of the organization</li></ol><h3 id="the-road-map-ahead">The Road(map) Ahead</h3><p>Thereâ€™s a ton of capabilities in Census and even more to come. Hereâ€™s some of the areas weâ€™ve been working on and plan to expand upon this year.</p><ul><li><strong>Code-Based Orchestration.</strong> Today, we sync models seamlessly from a warehouse but we want to push the bar forward here and make every Census workflow versionable and pluggable into larger orchestration systems.</li><li><strong>Deeper Data Validation.</strong> When your data models are connected to business systems, failures become much worse (which is a good thing, after all if your mistakes have no impact, whatâ€™s the point?). Census is your last line of defense before the data is live so validating your data is key.</li><li><strong>Visual Query Experience.</strong> When data becomes a product, it means you have more consumers. Many of these consumers need a way to interact with models with a simple UX, which furthers our goal of data reaching every part of the organization.</li></ul><p>If this sounds like a lot, it's because it is. We're embarking on a long journey to transform data organizations into product teams. Teams that can scale to support many users and many use cases. By shifting into this central role, data teams stop being backwards-looking and become the biggest drivers of change in an organization â€“ the ultimate feedback loop.</p><h3 id="join-us">Join us</h3><p>The companies &amp; leaders who understand this will certainly succeed and I look forward to seeing an amazing cohort of Chief Data Officers in the decade to come. There is a huge amount of work ahead of us and I am unbelievably excited to tackle these problems every day. Empowering people with tools has been my passion ever since I started my career in technology. If you want to help make an impact and move the needle on the entire data ecosystem, <a href="https://jobs.ashbyhq.com/Census">come join our team</a>. Weâ€™re small but mighty and hiring for every position. You can reach me on <a href="https://twitter.com/borisjabes">Twitter</a> or via <a href="mailto:boris@getcensus.com">email</a>.</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.getcensus.com/announcing-our-series-a-from-sequoia/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26181985</guid>
            <pubDate>Thu, 18 Feb 2021 16:38:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rethinking Pair Programming]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26181867">thread link</a>) | @afkmango
<br/>
February 18, 2021 | https://amypeniston.com/rethinking-pair-programming/ | <a href="https://web.archive.org/web/*/https://amypeniston.com/rethinking-pair-programming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
  <div id="content">
    <div>
      

<figure><img width="1024" height="536" src="https://amypeniston.com/downloads/Social-Border-1024x536.jpg" data-src="https://amypeniston.com/downloads/Social-Border-1024x536.jpg" alt="" data-srcset="https://amypeniston.com/downloads/Social-Border-1024x536.jpg 1024w, https://amypeniston.com/downloads/Social-Border-300x157.jpg 300w, https://amypeniston.com/downloads/Social-Border-768x402.jpg 768w, https://amypeniston.com/downloads/Social-Border.jpg 1200w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://amypeniston.com/downloads/Social-Border-1024x536.jpg 1024w, https://amypeniston.com/downloads/Social-Border-300x157.jpg 300w, https://amypeniston.com/downloads/Social-Border-768x402.jpg 768w, https://amypeniston.com/downloads/Social-Border.jpg 1200w"></figure>



<p>Not a fan of pair programming? Youâ€™re not the only one.</p>



<p>For years, I hated pair programming. I thought it was an inconvenience without benefit, something you do to appease your manager or check a box.</p>



<p>I was wrong.</p>



<p>Over the last year, my co-founder and I have pair programmed for roughly 6 days a week. With practice, weâ€™ve honed our setup and, in doing so, figured out an effective way to collaborate on code.</p>



<p>In this post, I will share our pair programming formula and outline the benefits that we enjoy. I will also discuss the challenges and downsides of pair programming to prepare you for any pushback that you might receive.</p>



<p>If youâ€™re new to pair programming, I hope this post inspires you to apply it in your daily life.</p>



<p>If youâ€™re not a fan of pair programming, I hope this post challenges you to reframe your past experiences and rethink collaborative coding.</p>



<p>Either way, I provide an actionable plan to help you implement and optimize a collaborative setup.</p>



<p>Let me be clear: pair programming doesnâ€™t work for every project or for every team. But, it works for us and it might work for you. This post is for developers who are open to trying something new.</p>



<p>What follows is a deep dive into pair programming. Feel free to skip ahead to the sections that interest you the most:</p>



<ul><li><a href="#pair-programming">What is pair programming?</a></li><li><a href="#optimal-setup">Optimizing your pair programming setup</a></li><li><a href="#benefits">Benefits</a></li><li><a href="#challenges">Challenges &amp; downsides</a></li><li><a href="#other-tasks">Pairing on other tasks</a></li><li><a href="#programming-threesomes">Programming threesomes</a></li><li><a href="#conclusion">Conclusion</a></li></ul>



<p>Letâ€™s get into it.</p>



<figure><img width="1024" height="190" src="https://amypeniston.com/downloads/Post-8-1-1024x190.jpg" data-src="https://amypeniston.com/downloads/Post-8-1-1024x190.jpg" alt="" data-srcset="https://amypeniston.com/downloads/Post-8-1-1024x190.jpg 1024w, https://amypeniston.com/downloads/Post-8-1-300x56.jpg 300w, https://amypeniston.com/downloads/Post-8-1-768x142.jpg 768w, https://amypeniston.com/downloads/Post-8-1-1536x285.jpg 1536w, https://amypeniston.com/downloads/Post-8-1-2048x380.jpg 2048w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://amypeniston.com/downloads/Post-8-1-1024x190.jpg 1024w, https://amypeniston.com/downloads/Post-8-1-300x56.jpg 300w, https://amypeniston.com/downloads/Post-8-1-768x142.jpg 768w, https://amypeniston.com/downloads/Post-8-1-1536x285.jpg 1536w, https://amypeniston.com/downloads/Post-8-1-2048x380.jpg 2048w"></figure>



<h2 id="pair-programming">What is pair programming?</h2>



<p>Pair programming is a collaborative style of working on software development projects. It involves two individuals who are both engaged on the same code at the same time.</p>



<p>This is not the official Agile definition, which stipulates that developers share a single workstation.</p>



<p>To be clear: working side-by-side is not my ideal setup and I will not attempt to convince you to use it. Virtual pairing is far superior to brushing elbows â€“ but, more on that later.</p>



<p>In a typical pair programming session, there are two different roles:</p>



<ul><li>The <strong>Driver</strong> â€“ writes code</li><li>The <strong>Navigator</strong> â€“ offers direction and reviews code</li></ul>



<p>Every so often, the Driver and the Navigator switch roles. How frequently this occurs depends on the team and the project â€“ it can range from every few minutes to every few hours. The swap can also be triggered by an event, such as the Driver finishing a unit test or getting stuck.</p>



<p>The Driver and the Navigator maintain a running commentary throughout the duration of the session. This is often called â€œprogramming out loudâ€ and it is a challenge in itself. Speaking while coding is like narrating your morning routine: youâ€™re forced to vocalize something internal and often subconscious. Add in the fact that thereâ€™s another human listening to your rambling and itâ€™s not surprising that developers struggle to program out loud.</p>



<p>Regardless, for non-developers, pair programming seems harmless. Youâ€™ve got two developers coding together in real time. Whatâ€™s the big deal?</p>



<p>In reality, pair programming is a polarizing practice. Software developers are are either enthusiastic evangelists or outspoken opponents. Few claim to be ambivalent.</p>



<p>Until recently, I was a pair programming skeptic. My opinion had soured over the course of several years due to bad experiences falling into one of four categories:</p>



<ol><li><strong>Personal space violations:</strong> pairing with someone who has a greasy desk or unpleasant BO.</li><li><strong>Misaligned objectives: </strong>pairing with someone who refuses to engage, or, even worse, is more interested in showing off than collaborating.</li><li><strong>Management disasters:</strong> pairing with multiple people in a â€œgroup coding projectâ€ (a special type of hell that is inevitably doomed to failure).</li><li><strong>Character clashes:</strong> pairing with a bullish extrovert for a series of memorably uncomfortable and counterproductive sessions.</li></ol>



<p>For me, the net result of these negative experiences was a strong aversion to pair programming.</p>



<p>And that was pretty much the end of it. I avoided pair programming at all costs and off I went on my merry way.</p>



<p>Until I started pair programming with my co-founder.</p>



<p>Fast forward a year and now admit that I was wrong. It took finding the right partner and experimenting with different setups to finally unlock the benefits of pair programming.</p>



<p>In the next section, I outline the key components of an optimal pair programming setup. This includes finding a suitable partner, scheduling sensible time blocks and utilizing collaborative technologies.</p>



<p>Finally, Iâ€™ll discuss the practical logistics to help you structure your environment for remote pair programming success.</p>



<figure><img width="1024" height="190" src="https://amypeniston.com/downloads/Post-9-1024x190.jpg" data-src="https://amypeniston.com/downloads/Post-9-1024x190.jpg" alt="" data-srcset="https://amypeniston.com/downloads/Post-9-1024x190.jpg 1024w, https://amypeniston.com/downloads/Post-9-300x56.jpg 300w, https://amypeniston.com/downloads/Post-9-768x142.jpg 768w, https://amypeniston.com/downloads/Post-9-1536x285.jpg 1536w, https://amypeniston.com/downloads/Post-9-2048x380.jpg 2048w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://amypeniston.com/downloads/Post-9-1024x190.jpg 1024w, https://amypeniston.com/downloads/Post-9-300x56.jpg 300w, https://amypeniston.com/downloads/Post-9-768x142.jpg 768w, https://amypeniston.com/downloads/Post-9-1536x285.jpg 1536w, https://amypeniston.com/downloads/Post-9-2048x380.jpg 2048w"></figure>



<h2 id="optimal-setup">Optimizing your pair programming setup</h2>



<p>My co-founder and I have pair programmed roughly 6 days per week since March 2020, with each session lasting between 1 and 5 hours.</p>



<p>Here are the essential elements that make up our hyper-productive pair programming sessions:</p>



<figure><img width="1024" height="53" src="https://amypeniston.com/downloads/Frame-27-3-1024x53.png" data-src="https://amypeniston.com/downloads/Frame-27-3-1024x53.png" alt="" data-srcset="https://amypeniston.com/downloads/Frame-27-3-1024x53.png 1024w, https://amypeniston.com/downloads/Frame-27-3-300x16.png 300w, https://amypeniston.com/downloads/Frame-27-3-768x40.png 768w, https://amypeniston.com/downloads/Frame-27-3-1536x80.png 1536w, https://amypeniston.com/downloads/Frame-27-3-2048x107.png 2048w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://amypeniston.com/downloads/Frame-27-3-1024x53.png 1024w, https://amypeniston.com/downloads/Frame-27-3-300x16.png 300w, https://amypeniston.com/downloads/Frame-27-3-768x40.png 768w, https://amypeniston.com/downloads/Frame-27-3-1536x80.png 1536w, https://amypeniston.com/downloads/Frame-27-3-2048x107.png 2048w"></figure>



<h3>A Suitable Partner</h3>



<p>Finding the right person to pair with is the foundation of any successful pair programming session. This is obvious.</p>



<p>What is not so obvious is what exactly constitutes the â€œright personâ€.</p>



<p><strong>Personality</strong></p>



<p>Personality plays a big part of any successful relationship. If youâ€™re going to be pair programming with someone every day, itâ€™s important to make sure that you both get along. </p>



<p>Current or former colleagues can be perfect partners because your professional relationship sets the tone for your future engagements. The challenge with colleagues is to assess whether your personalities are a match; make sure to do a trial run or two.</p>



<p>Friends can also make good partners, but you must be careful to avoid distraction. Your personal relationship may inhibit decision making and detract from the seriousness and focus of your sessions.</p>



<p>Rather than be overly prescriptive, I will outline the important qualities to look for in a pair programming partner:</p>



<ul><li><strong>Humility and humor.</strong> Find someone who can admit to being wrong and laugh at their mistakes. Donâ€™t let ego third wheel your pair programming sessions.</li></ul>



<ul><li><strong>Willingness to communicate.</strong> When working remotely, communication is key. My co-founder and I both make a concerted effort to be better listeners and let each other finish our thoughts. Interruption is even more jarring when youâ€™re not sitting in the same room.</li></ul>



<ul><li><strong>Commitment. </strong>A mismatch in commitment will result in differing levels of interest and output. This will inevitably lead to resentment between contributors.</li></ul>



<p><strong>Experience &amp; Skills</strong></p>



<p>Should you pick a partner with the same expertise? In my experience, no â€“ diversity trumps overlap.</p>



<p>For example, my co-founder is a software developer and data scientist. He has significantly more technical experience than I do and is much faster at translating ideas into code.</p>



<p>It sounds like we might be a poor match, but the opposite is true:</p>



<ul><li>Because I ask novice questions, my co-founder is challenged to understand and explain concepts more thoroughly.</li><li>Because I am often unfamiliar with the language weâ€™re using, I spot things that only a fresh pair of eyes would.</li><li>Because I am slower to write code, we talk through solutions before implementing them, thus avoiding needless time sinks.</li></ul>



<p>The big caveat is that my co-founder actually wants to work with me. We acknowledge and celebrate the differences in our skill sets, rather than resenting one another for not being on the same level.</p>



<p>The combination of my design expertise and his programming skills enable us to own the development pipeline. We can start with an idea and translate it from mockups through to a final deliverable. We can tackle a wide variety of tasks without relying on other parties, thus speeding up the process and maintaining control. </p>



<p>I cannot overstate: diversity in skills gives you super powers.</p>



<p>Finally, I understand that not every developer has the luxury of choosing their pair programming partner. In this case, you must lead by example and champion the important qualities outlined above. Your efforts will determine your success.</p>



<h4>Recommendations</h4>



<p><em>Find a partner with a different skill set. Donâ€™t worry if thereâ€™s an experience gap, itâ€™s often better that way. Discuss what each of you bring to the table and acknowledge your strengths and weaknesses</em>.<em> Practice being better listeners.</em></p>



<figure><img width="1024" height="53" src="https://amypeniston.com/downloads/Frame-27-2-1024x53.png" data-src="https://amypeniston.com/downloads/Frame-27-2-1024x53.png" alt="" data-srcset="https://amypeniston.com/downloads/Frame-27-2-1024x53.png 1024w, https://amypeniston.com/downloads/Frame-27-2-300x16.png 300w, https://amypeniston.com/downloads/Frame-27-2-768x40.png 768w, https://amypeniston.com/downloads/Frame-27-2-1536x80.png 1536w, https://amypeniston.com/downloads/Frame-27-2-2048x107.png 2048w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://amypeniston.com/downloads/Frame-27-2-1024x53.png 1024w, https://amypeniston.com/downloads/Frame-27-2-300x16.png 300w, https://amypeniston.com/downloads/Frame-27-2-768x40.png 768w, https://amypeniston.com/downloads/Frame-27-2-1536x80.png 1536w, https://amypeniston.com/downloads/Frame-27-2-2048x107.png 2048w"></figure>



<h3>Schedule</h3>



<p>Once youâ€™ve found the right person, when and for how long should you schedule your pair programming sessions?</p>



<p>The time of day that you choose will be personal preference and job specific. We originally started coding in the mornings to get in a few hours before our 9-5 jobs. Weâ€™ve since stuck with this schedule and have found that a 7am start time works best for us.</p>



<p>At the beginning of every session, we confirm our stop time. Sessions are capped at five hours, which includes no more than four hours of active coding. To quote Cal Newportâ€™s â€œDeep Workâ€, this time is dedicated to â€œdistraction-free concentration that pushes [our] cognitive capabilities to their limitâ€.</p>



<p>But why not schedule longer sessions?</p>



<p>As we discovered early on, pair programming is physically and mentally exhausting. Working with a singular focus requires intense attention and intention. And, unlike solitary deep work, pair programming comes with an accountability partner who helps you stay fixated on the task at hand. You donâ€™t have the luxury of context switching to something easier when what youâ€™re working on gets tough.</p>



<p>We also block off all pair programming time in our calendars to prevent interruption.</p>



<p>During long sessions we usually take one or two five- to 10-minute breaks. We donâ€™t schedule these rest periods, but instead take them whenever one of us needs to.</p>



<p>Breaks are a chance to stretch our legs, make a fresh coffee and come back to our desks feeling refreshed. As many software developers can attest, bugs are often squashed immediately upon returning from a break.</p>



<p>Finally, our sessions happen daily, unless otherwise â€¦</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://amypeniston.com/rethinking-pair-programming/">https://amypeniston.com/rethinking-pair-programming/</a></em></p>]]>
            </description>
            <link>https://amypeniston.com/rethinking-pair-programming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26181867</guid>
            <pubDate>Thu, 18 Feb 2021 16:30:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Image Stabilization â€“ In Humans]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26181737">thread link</a>) | @bucket2015
<br/>
February 18, 2021 | https://i-kh.net/2021/02/18/image-stabilization-in-humans/ | <a href="https://web.archive.org/web/*/https://i-kh.net/2021/02/18/image-stabilization-in-humans/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      
        <p>As I read more neuroscience, I run into more interesting neural circuits. One of these circuits is the Vestibulo-Ocular Reflex (VOR) that helps us keep the eyes locked on a target when the head moves. </p>
<p>Whatâ€™s interesting about it are both its simple wiring (at first glance), and the extensive hidden support circuitry that can tell us more about how the brain works.</p>
<p>VOR is not the only circuit that helps us keep our eyes locked on target; there are others that work in parallel. I suspect that they probably use the same underlying principles.</p>
<p>(Note: some links here are behind a paywall. Remember that itâ€™s illegal to go to Sci-Hub and search for the DOI link of the article to get free access to it.)</p>
<h2 id="So-whatâ€™s-Vestibulo-Ocular-Reflex"><a href="#So-whatâ€™s-Vestibulo-Ocular-Reflex" title="So whatâ€™s Vestibulo-Ocular Reflex?"></a>So whatâ€™s Vestibulo-Ocular Reflex?</h2><p>Pick a point on the screen, and while looking at it, turn your head left to right. Your head will move, but your eyes will stay locked onto that point.</p>
<p>For that to happen, the muscles that control your eyeballs need to change their tension at exactly the right time and by exactly the right amount to compensate for the movement of the head. </p>
<p>While at first glance that may seem tricky, in reality, the brain deals with it the same way as the smartphone: it just uses our internal accelerometer, the <em>vestibular apparatus</em>, pictured below in the red box.</p>
<p><img src="https://i-kh.net/images/image-stabilization-in-humans/vestibular-organ.png" alt="The vestibular organ is the collection of tubes in the red box. Source: Blausen.com staff (2014). &quot;Medical gallery of Blausen Medical 2014&quot;. WikiJournal of Medicine 1 (2). DOI:10.15347/wjm/2014.010. ISSN 2002-4436"></p>
<h2 id="From-accelerometer-to-muscles"><a href="#From-accelerometer-to-muscles" title="From accelerometer to muscles"></a>From accelerometer to muscles</h2><p>From the vestibular organ, thereâ€™s a simple three-neuron-long connection that feeds the accelerometer signal to the muscles that move the eyes, first documented <a href="https://doi.org/10.1001/archneurpsyc.1933.02240140009001" target="_blank" rel="noopener">in the 1930s</a>. We can follow it to see what it does.</p>
<p><img src="https://i-kh.net/images/image-stabilization-in-humans/square31_fixed.png"></p>
<p>The neurons coming out of the vestibular organ output a steady stream of electric spikes. When the head turns left, the left vestibular neuron starts producing more electric spikes, and the right one - less. When the head stops moving, both vestibular neurons go back to the equal rate of spikes. If the head turns right, the opposite happens.</p>
<p>The signals from the vestibular neurons end up in the brainstem, the more basic part of the brain that sits between the cerebral cortex and the spine. There, another set of neurons directly connect them to the pools of motor neurons that move the eye muscles.</p>
<p>The muscle neurons, in turn, work according to rules we wonâ€™t go into right now, but itâ€™s safe to simplify and say that the more excited they get the more the eye muscles contract.</p>
<p>So basically, when the head turns left, the increased rate of spikes from the left vestibular neuron is directly fed into the motorneurons that turn the eyes right.</p>
<p>End-to-end, this circuit is very fast. Experiments show that once the head starts turning, it takes less than 10 ms for the muscles to engage.</p>
<p>(Btw, Wikipedia has a <a href="https://en.wikipedia.org/wiki/Vestibulo%E2%80%93ocular_reflex" target="_blank" rel="noopener">different wiring diagram</a>; Iâ€™ve seen it drawn both ways in papers. In practice, the result is the same either way.)</p>
<h2 id="Complication-1-the-neural-integrator"><a href="#Complication-1-the-neural-integrator" title="Complication #1: the neural integrator"></a>Complication #1: the neural integrator</h2><p>So, on the surface, it seems that weâ€™re done. The acceleration output feeds directly into the motorneurons, the eyes move, and weâ€™re happy.</p>
<p>But hereâ€™s the problem: when the head is done turning, the vestibular organs go back to signaling at the base rate. Then the tension in the eye muscles goes back to equal, pointing the eyes straight. Thatâ€™s not what we were hoping to see.</p>
<p>To fix that, we need to add a <em>neural integrator</em> to the picture.</p>
<p><img src="https://i-kh.net/images/image-stabilization-in-humans/neural_integrator.png"></p>
<p>The neural integrator does this: (1) it collects the total velocity signal sent to the eye muscles, and (2) outputs the spikes at exactly the right rate to keep the eyes pointed in the right direction.</p>
<p>I.e. it literally integrates the angular velocity to come up with the final position.</p>
<p>Our best guess that the integrator works using some clever mutually inhibitory feedback. If the left vestibular neuron sends more spikes, the right half of the neural integrator gets more excited, and ends up inhibiting the left half more, which ends up inhibiting the right half less. <a href="https://doi.org/10.1016/B978-008045046-9.01434-0" target="_blank" rel="noopener">This entry</a> in the Encyclopedia of Neuroscience describes the math in more detail.</p>
<p><img src="https://i-kh.net/images/image-stabilization-in-humans/neural_integrator_details.png" alt="A sketch of a neural integrator model. Source: Neural Integrator Models, Encyclopedia of Neuroscience (2009), https://doi.org/10.1016/B978-008045046-9.01434-0"></p>
<p>Some papers indicate that there may be a <a href="https://doi.org/10.1007/978-3-540-29678-2_3916" target="_blank" rel="noopener">number of different neurons</a> involved, and this may be a multi-stage process.</p>
<p>(On a tangent: there isnâ€™t just one neural integrator. There seem to be a number of them in the brain; for example, if you close your eyes and move around the room, a part of the cerebral cortex will keep an estimate of your position from your motion, though it wonâ€™t be very accurate. One of the papers linked above even argues that accumulating the evidence for two alternatives in a decision process could also be considered an integrator.)</p>
<h2 id="Complication-2-controlling-the-gain"><a href="#Complication-2-controlling-the-gain" title="Complication #2: controlling the gain"></a>Complication #2: controlling the gain</h2><p>Setting the neural integrator aside, hereâ€™s a different question: why is it that a 5Â° turn of the head causes a 5Â° turn of the eyes? What makes it not be 4Â°, or 10Â°? Are we just lucky that the neural connections work out to be exactly right?</p>
<p>Turns out, <a href="https://www.nature.com/articles/s41583-020-00392-x" target="_blank" rel="noopener">thereâ€™s a circuit</a> that runs through <a href="https://en.wikipedia.org/wiki/Cerebellum" target="_blank" rel="noopener">cerebellum</a> that keeps the gain (ratio of head turn to eye turn) at exactly the right value. Itâ€™s a pretty clever circuit that turns out to be so useful that the brain has copy-pasted it thousands of times (with a few changes) and reused it in nearly all motor functions, plus a number of non-motor functions.</p>
<p><img src="https://i-kh.net/images/image-stabilization-in-humans/cerebellum.png"></p>
<p>The center of this circuit are the inhibitory Purkinje cells, which, in this case, output a low, constant stream of spikes that lightly inhibit the connections from the vestibular neurons to the motorneurons.</p>
<p>The vestibular signal comes in through excitatory parallel fibers that make connections with Purkinje cells. When the head turns, these fibers make the Purkinje cell a bit more excited, making it inhibit the VOR circuit a bit more, kinda like tapping on the break.</p>
<p>Most of the time, this inhibition is just right to make the 5Â° head turn result in 5Â° eye turn. But what if itâ€™s wrong? </p>
<p>This is where another set of neurons comes in - the climbing fibers. When the brain detects that the image on the retina lags behind motion (i.e. the inhibition is too strong), these fire. This sets the Purkinje cell ringing like a bell for a bit, and it turns off some of the connections from the parallel fibers, reducing the inhibition, and letting the eyes move faster.</p>
<p>I havenâ€™t seen a good description for how the opposite error is fixed (eyes move too fast), but from what I remember from other circuits, the parallel-to-Purkinje connections gradually turn back on when the parallel fibers keep firing, so the error may just fix itself over time.</p>
<h2 id="Thatâ€™s-it"><a href="#Thatâ€™s-it" title="Thatâ€™s it"></a>Thatâ€™s it</h2><p>Thatâ€™s basically all I know about the Vestibulo-Occular Reflex so far.  As I mentioned, there are other mechanisms to keep the eyes steady, like the neck reflexes, or the slower and finer <a href="https://en.wikipedia.org/wiki/Optokinetic_response" target="_blank" rel="noopener">Opto-Kinetic Reflex</a> that uses the information from the retina instead of the vestibular organ.</p>

      
    </div></div>]]>
            </description>
            <link>https://i-kh.net/2021/02/18/image-stabilization-in-humans/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26181737</guid>
            <pubDate>Thu, 18 Feb 2021 16:21:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SSH Certificates Security]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26181568">thread link</a>) | @alexk
<br/>
February 18, 2021 | https://goteleport.com/blog/ssh-certificates | <a href="https://web.archive.org/web/*/https://goteleport.com/blog/ssh-certificates">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
      <a href="https://goteleport.com/blog/index.xml"><i></i></a>
      
      

        

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-security.png" width="100%" alt="SSH Certificates Security"></p>

<h2 id="ssh-access-hardening">SSH Access Hardening</h2>

<p>SSH certificates, when deployed properly, improve security.
A half-baked access system using certs is more vulnerable than a public-key-based one if a user or host gets hacked.</p>

<p>SSH is hard. Our team learned this at Rackspace, a large managed hosting and cloud provider.
We started with deploying public keys to every server. We added a jump server with a second factor login to prevent
hacks using stolen keys. Soon, infosec team asked us to log into a web portal to match SSH logins with emails.
Evolution does not produce the most efficient result, and our system did not turn out great either.
We were missing keys on some servers and found stale keys on others.
No one liked login screens popping up multiple times a day.
We received only one one-time password token, and some folks pointed their home webcam to it.</p>

<p>In 2015 we left Rackspace to build <a href="https://github.com/gravitational/teleport" data-size="large" aria-label="Star gravitational/teleport on GitHub">Teleport</a> â€” a unified access plane
for infrastructure, and we started with SSH. We chose SSH certificates as the main cryptography engineering primitive. Since then our customers and open source users have deployed Teleport at most impressive systems, and Teleport went through
several security audits.</p>

<p>I would like to share some of the lessons we learned with you.
We will start with the SSH authentication basics, dig into SSH certificates
and learn what it takes to build a secure SSH certificate-based authentication.</p>

<h3 id="ssh-public-key-authentication">SSH Public Key Authentication</h3>

<p>An SSH public key is distributed openly, and anyone holding it can verify messages
signed using its private key counterpart.</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-public-key-auth.png" width="100%" alt="SSH Public Key Authentication"></p>

<p>An SSH server generates a random string â€” a challenge â€” and asks a client to sign it.
The server verifies clientsâ€™ signature to prove that the client has the private key associated with
the trusted public key. Here is how it looks on the wire:</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-public-key-protocol.png" width="100%" alt="SSH Public Key Challenge"></p>

<p>Public keys constitute a solid way to authenticate and are used to secure both Web and SSH.</p>

<p>The problems with public key authentication are caused by key management: trust on first use (a.k.a. TOFU)
and rotating and revoking trusted public keys.</p>

<h3 id="trust-on-first-use">Trust On First Use</h3>

<p>When an SSH connection is first established, an SSH server sends its public key to identify
itself to a user.</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-host-auth.png" width="100%" alt="SSH Host Authentication"></p>

<p>The user can accept the public key offered by the SSH server and assume that the host is trusted
if the user connects to it first time. This authentication scheme is called â€œtrust on first useâ€ or TOFU.</p>

<p>If the hostâ€™s IP, name or public key change, the user can no longer trust this combination
of the hostname, the IP and the public key.</p>

<p>The user sees a scary warning.</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-tofu.png" width="100%" alt="SSH TOFU"></p>

<p>The user can alert security folks or ignore the warning by removing the old key.
For cloud environments, however, an IP address and a hostname can be
reused many times. Users learn to ignore those warnings, because there is no way to learn whether itâ€™s an attack or an IP or a hostname change. Letâ€™s call it TOFU fatigue.</p>

<h3 id="problems-with-public-keys">Problems With Public Keys</h3>

<p>A second problem of public keys for security is caused by complexities of public key distribution.
Imagine a deployment with 100 servers and 10 users, where every user has 2 public keys.
You have to build a system that distributes 20 userâ€™s public keys on each server and
100 public keys to every userâ€™s computer, and keep those up to date.</p>

<p>Directory services like LDAP are used to store userâ€™s and hostâ€™s public keys.
Every host runs an agent that connects to an LDAP server and updates public keys.
Sysadmin folks have been deploying this Keycloak and FreeIPA pair for years.</p>

<p>This system breaks down at a small and a large scale. Sysadmins of small systems
rarely deploy key management software. Itâ€™s not worth setting up FreeIPA and Keycloak for 3 nodes.
They use tools like Ansible and end up with keys going out of sync when someone loses their key, computer, or leaves the company. Sometimes, letâ€™s face it, there is no Ansible and everyone uses the same shared key.</p>

<p>Admins of large clusters learn that the system of moving the key around stops working beyond the 1K nodes or 100 users mark â€”
there are just too many keys to keep track of.</p>

<h2 id="ssh-certificates">SSH Certificates</h2>

<p>SSH certificates are built using public keys and donâ€™t offer anything extra from a cryptography engineering standpoint.</p>

<p>A certificate authority (CA) is a trusted party that holds its own public and private key pair.
SSH CA keys are used to sign user and host SSH certificates.
An SSH certificate consists of fields signed by the certificate authority.</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-certificate.png" width="100%" alt="SSH Certificate"></p>

<p>Clients cannot modify these fields without breaking the signature.</p>

<p>SSH certificate authentication extends public-key-based auth and uses the same protocol messages.
In addition to verifying the public key signature, SSH server will check whether
the certificate is signed by the trusted certificate authority.</p>

<h3 id="solving-the-tofu-problem">Solving the TOFU Problem</h3>

<p>Clients use metadata in SSH certificates to verify host identities too.
When an SSH connection is established, a host sends a signed SSH certificate to a client to verify
the hostâ€™s identity. The hostâ€™s certificate is signed by a trusted CA.
It includes information about the hostname, and has an expiration date.
Here Alice checks if she can trust the hostâ€™s cert:</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-host-certs.png" width="100%" alt="SSH Host Certificates"></p>

<p>As an extra precaution, SSH clients check if the hostname or the IP matches the certificate.
It makes it harder for a malicious host to impersonate another host.
If the signature check has failed or the CA is not trusted, either a serious misconfiguration
has happened or someone is attempting a man-in-the-middle attack.</p>

<p>Even if the public key of the host has been changed because the hostname has been reused in a cloud environment
during instance re-provisioning, the certificate will still match; there will be no conflict between different
public keys.</p>

<p>Sysadmins can replace the complex system of moving hundreds of public keys around
with two files â€” a host and a user SSH certificatesâ€™ authority public keys.
But in practice if we had stopped at this point, we would have made SSH security much, much worse.</p>

<h3 id="compromised-users-and-hosts">Compromised Users and Hosts</h3>

<p>If a user or a host gets compromised, we have to revoke their certs.
We are back to building a system of keeping track and distributing revocation lists to users and hosts.
Even worse, if a private key of a SSH user or a host certificate authority gets compromised,
all users and hosts certificates have to be invalidated and reissued.</p>

<p>This realization hits at the worst possible moment â€” when someone is hacked, there is no time to waste.
Time works against us because with every issued cert, the potential for compromise
increases. At least with public keys, we test the rotation on a regular basis. Revocation is so rare,
that it could be broken for all this time and no one would notice. This problem reminds me of backup restore â€”
you either test backup and restore regularly, or all bets are off.</p>

<h2 id="making-time-work-for-you">Making Time Work for You</h2>

<p>There is one trick that makes time work in favor of security.
SSH certificates include an optional expiry date that can be verified
by a server in addition to a signature.</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-short-lived.png" width="100%" alt="SSH Short Lived Certs"></p>

<p>Organizations ca issue certificates that are good for a few hours before they auto-expire
without any action. The shorter the duration for these certificates, the better.
Ideally, certs should be issued only for the duration of a session.
In practice, several hours or the duration of the workday are OK too.</p>

<p>Instead of distributing revocation lists, we can rely on time to do the job for us.</p>

<h3 id="user-certificates-and-sso">User Certificates and SSO</h3>

<p>How would users get a short-lived certificate? The best way is to use SSO
with GitHub, Okta or any other identity provider and get a cert.
Teleport opens login screen, issues a cert and delivers it back to a userâ€™s computer:</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-sso.png" width="100%" alt="SSH certs SSO"></p>

<p>Here is an example of Teleportâ€™s CLI tool <code>tsh</code> issuing a certificate
based on my GitHub credentials.</p>

<video autoplay="" loop="" muted="" playsinline="">
  <source src="https://goteleport.com/blog/images/2021/ssh-certs-github.mp4" type="video/mp4">
  <source src="https://goteleport.com/blog/images/2021/ssh-certs-github.webm" type="video/webm">
Your browser does not support the video tag.
</video>

<p>The cert is valid for 12 hours and has my GitHub identity encoded in it.</p>

<h2 id="rotate-ca-keys">Rotate CA Keys</h2>

<p>An attacker getting access to a private key of a certificate authority can impersonate
any user or host. Thatâ€™s why admins store CA private keys in the most secure place possible.
What happens if a user, a host, or a CA gets compromised? Youâ€™d need to replace certificate authority
and reissue all certs for hosts and users. Any system dealing with certs should support this out of the box.</p>

<p>Take a look at how I rotate a user CA in less than a minute with Teleport:</p>

<video autoplay="" loop="" muted="" playsinline="">
  <source src="https://goteleport.com/blog/images/2021/ssh-certs-rotation.mp4" type="video/mp4">
  <source src="https://goteleport.com/blog/images/2021/ssh-certs-rotation.webm" type="video/webm">
Your browser does not support the video tag.
</video>

<p>With user certificate authority updated, all certificates issued by the old CA become invalid.
Itâ€™s not a problem if you use SSO; users have to re-login to get new certs.
The same command rotates hosts CA as well. Instead of waiting for the compromise
to happen, we should be rotating certificate authorities every day turning
them from a precious secret to a replaceable commodity. Here again, time
will work in our favor, not against us.</p>

<h2 id="wrapping-up">Wrapping Up</h2>

<p>Use certs with caution, and beware of long-lived certificates. Rotate your CA regularly
and use SSO to get user certs. And maybe, give <a href="https://github.com/gravitational/teleport" data-size="large" aria-label="Star gravitational/teleport on GitHub">Teleport</a> a try.</p>


        
        
        <p><strong>Related Posts</strong></p>
          <ul>
            
            <li><a href="https://goteleport.com/blog/how-to-ssh-properly/">How to SSH Properly | SSH Security Best Practices</a></li>
            
            <li><a href="https://goteleport.com/blog/ssh-handshake-explained/">SSH Handshake Explained | What is SSH Handshake?</a></li>
            
            <li><a href="https://goteleport.com/blog/ssh-restricted-shells/">Restricted Shell | Restricted commands for SSH</a></li>
            
          </ul>
        

        
        
        <a href="https://goteleport.com/tags/ssh/">ssh</a>
        
        <a href="https://goteleport.com/tags/teleport/">teleport</a>
        
        <a href="https://goteleport.com/tags/security/">security</a>
        

      
      
      &nbsp;
      </article></div>]]>
            </description>
            <link>https://goteleport.com/blog/ssh-certificates</link>
            <guid isPermaLink="false">hacker-news-small-sites-26181568</guid>
            <pubDate>Thu, 18 Feb 2021 16:09:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An overview of declassified CIA cables on Thailand]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26181299">thread link</a>) | @cwwc
<br/>
February 18, 2021 | https://secretsiam.news/p/an-overview-of-declassified-cia-cables | <a href="https://web.archive.org/web/*/https://secretsiam.news/p/an-overview-of-declassified-cia-cables">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This is another extra edition of Secret Siam. Over coming weeks Iâ€™ll be sharing some of my articles that have been previously published elsewhere. They will be free for everyone to read, not just paying subscribers, and Iâ€™ll still be publishing two original newsletters each week. Todayâ€™s edition is an analysis of declassified CIA cables about Thailand. It was initially published in 2017, but Iâ€™ve updated it to include another cable that was declassified since then.</p><p>If youâ€™re enjoying Secret Siam and havenâ€™t subscribed yet, please do. For $5 a month, or less with an annual subscription, youâ€™ll have full access to all newsletters and posts, and if you prefer not to pay you can sign up for free editions like this one.&nbsp;</p><p>In 2017, after a long struggle by freedom of information campaigners, the Central Intelligence Agency of the United States finally put 13 million pages of declassified documents online. These documents were already in the public domain, but previously could only be viewed on four computers at the U.S. National Archives in Maryland, available between 9 am and 4:30 pm from Monday to Friday. This meant that most people around the world could never see them.&nbsp;<a href="https://www.cia.gov/library/readingroom/">Now we all can</a>. Many of the documents are heavily redacted, but they nevertheless contain many useful insights.</p><p>Nobody should assume that the CIA was right about everything â€” far from it â€” and many of the documents are heavily redacted, but they nevertheless contain many useful insights. The following is an overview of documents that help shed some light on dark episodes in Thai history. Itâ€™s in chronological order, starting with the oldest documents then moving to more recent ones.</p><h4><strong>A loveless marriage and a rumoured abdication</strong></h4><p>On June 9, 1946, the 18-year-old Bhumibol Adulyadej accidentally shot his brother King Ananda Mahidol through the head when they were playing with a Colt .45 pistol in Anandaâ€™s bedchamber in the Grand Palace in Bangkok. The distraught Bhumibol became King Rama IX the same day, but soon fled to Switzerland, ostensibly to finish his studies at the University of Lausanne, although he actually never completed his degree. Instead he was sunk in deep depression, and terrified of having to return to Bangkok to cremate the corpse of the beloved brother he had killed.</p><p>Meanwhile, Thai royalists were split about what to do about Bhumibol. Many favoured revealing the truth about the regicide, so that Bhumibol would have to abdicate and Prince Chumbhotbongs Paribatra would become monarch instead. Others thought the best solution was to try to support the weak and troubled Bhumibol and train him to play his role as a figurehead and protector of elite royalist interests. One way they tried to do this was by arranging his marriage to the feisty Sirikit Kitiyakara, who was much more audacious and bold than the struggling young king.</p><p>According to this&nbsp;<a href="https://www.cia.gov/readingroom/docs/CIA-RDP82-00457R004600410012-7.pdf">document from April 1950</a>, Bhumibol had no affection for Sirikit and was trying to avoid returning to Thailand for the cremation. In the end he was persuaded to return, and ironically he was supported by the progressive faction in the Thai government, because they believed he would be easily manipulated. This was true, but the palace and military manipulated him more cleverly than the progressives, and he ended up ruling for 70 years and doing prolonged damage to Thai democracy.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F2e34db15-3782-46e9-835d-e2ed150f5d60_1224x1584.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F2e34db15-3782-46e9-835d-e2ed150f5d60_1224x1584.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/2e34db15-3782-46e9-835d-e2ed150f5d60_1224x1584.jpeg&quot;,&quot;height&quot;:1584,&quot;width&quot;:1224,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:206761,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><h3><strong>The king and his coups</strong></h3><p>In September 1957, the notoriously corrupt army chief Sarit Thanarat seized power in a coup, deposing Field Marshal Phibun Songkhram. This was the start of a remarkable palace revival in Thailand, because unlike his predecessor Sarit pretended to respect the monarchy and used royalist propaganda to bolster his dictatorial rule.</p><p>The palace has always tried to pretend that Bhumibol was above politics and never played any part in the numerous military coups that have disfigured Thailandâ€™s modern history. But overwhelming evidence â€” including numerous declassified British and U.S. diplomatic cables â€” suggest otherwise.</p><p>This&nbsp;<a href="https://www.cia.gov/readingroom/docs/CIA-RDP79-00927A001400080001-9.pdf">confidential CIA report from September 1957</a>&nbsp;says that Bhumibol admitted to US ambassador Max Waldo Bishop that he played an â€œactive role in the coupâ€.</p><p>Bhumibol also stated that he â€œintended to withdraw from the political arenaâ€ after a new government was firmly established.</p><p>This proved to be entirely untrue â€” the coup of September 1957 was the beginning of a royalist resurgence in which the palace gradually established ever greater influence in Thai politics.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8e7dfd78-fab0-48eb-81c3-c1d0c40b287a_1224x1584.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8e7dfd78-fab0-48eb-81c3-c1d0c40b287a_1224x1584.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/8e7dfd78-fab0-48eb-81c3-c1d0c40b287a_1224x1584.jpeg&quot;,&quot;height&quot;:1584,&quot;width&quot;:1224,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:305664,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><h3>Dalai Lama not welcome</h3><p>In 1959, at the beginning of a Tibetan uprising against Chinese rule, the Dalai Lama fled his country with the help of the CIA and escaped to India, where he formed a government in exile. He began pressing for the United Nations to take action on Tibet, and wanted to visit other countries to help build support for the cause.</p><p>But according to this <a href="https://www.cia.gov/readingroom/docs/CENTRAL%20INTELLIGENCE%20BULL%5B15787673%5D.pdf">top secret bulletin</a>, King Bhumibol declined to welcome the Dalai Lama in Thailand, because he feared that a visit from a Buddhist leader would undermine his own claim to be the main â€œdefender of the faithâ€. </p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F4e8f3547-18bd-4045-848b-9fdf73d05183_1962x718.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F4e8f3547-18bd-4045-848b-9fdf73d05183_1962x718.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/4e8f3547-18bd-4045-848b-9fdf73d05183_1962x718.jpeg&quot;,&quot;height&quot;:533,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:365310,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><h3><strong>A paranoid monarch</strong></h3><p>One consistent theme in diplomatic and intelligence cables about Bhumibol from several countries was his sense of paranoia.&nbsp;This&nbsp;<a href="https://www.cia.gov/readingroom/docs/DOC_0005973844.pdf">top secret briefing to the U.S. president in June 1967</a>&nbsp;seems to share a similar assessment, warning that when the Thai king visited Washington he was likely to exaggerate the threat from communism.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff41f0b9c-86a3-4d1a-b1bd-f668617b79f6_1526x518.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff41f0b9c-86a3-4d1a-b1bd-f668617b79f6_1526x518.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/f41f0b9c-86a3-4d1a-b1bd-f668617b79f6_1526x518.png&quot;,&quot;height&quot;:494,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:98398,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><h3><strong>Bhumibol versus democracy</strong></h3><p>In 1973, a student uprising in Bangkok led to the apparent overthrow of military dictatorship after nearly a quarter of a century.&nbsp;Bhumibol made a public show of support for the students at a decisive moment, and this helped foster a persistent myth â€” actively promoted by the palace â€” that he was a â€œdemocraticâ€ king.</p><p>In fact, Bhumibol was a reactionary figure who never felt comfortable with democracy and who believed that Thailand should be ruled by the royalist elite.</p><p>Following the unexpected events of October 1973, Bhumibol quickly became disillusioned with democracy and the palace actively conspired to undermine parliamentary rule.</p><p>This led to a savage massacre of student protesters at Thammasat University by ultra-royalist forces in October 1976. Bhumibolâ€™s complicity in the destruction of democracy in this period is well established, but this&nbsp;<a href="https://www.cia.gov/readingroom/docs/DOC_0006007684.pdf">CIA document from February 1974</a>&nbsp;is interesting because it suggests that within six months of the student uprising the monarch had already given his permission to crush progressive forces in Thailand if necessary.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fdff67a0e-4c11-4704-9dee-e7fb5f97f826_1134x1115.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fdff67a0e-4c11-4704-9dee-e7fb5f97f826_1134x1115.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/dff67a0e-4c11-4704-9dee-e7fb5f97f826_1134x1115.jpeg&quot;,&quot;height&quot;:1115,&quot;width&quot;:1134,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:176839,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><h3>Worries over royal succession and political awakening</h3><p>Even after the withdrawal of US troops from Thailand in the mid-1970s, America continued to consider the kingdom a key Cold War ally, but was perpetually worried that Thais might be growing more receptive to other ideas. There were also concerns about the widely despised successor to the throne, Crown Prince Maha Vajiralongkorn.</p><p>An&nbsp;<a href="https://www.cia.gov/readingroom/docs/CIA-RDP03T02547R000100240001-5.pdf">intelligence assessment by several US agencies in November 1981</a>&nbsp;explicitly raised worries about royal succession as a destabilising factor in Thailand, stating:</p><blockquote><p>The current monarchâ€™s great popularity and personal qualities enable him to play a key role in moderating national crises. The lack of an equally capable successor, however, suggests that the power of the monarchy and its stabilizing influence will decline with succession. Moreover, the independence of the Palace from the military is likely to decrease. and the Armyâ€˜s political power will probably grow despite the wishes of certain junior officers that the military remain aloof from politics.</p></blockquote><p>The analysis also presciently forecast that increasing political engagement among ordinary Thais would become a significantly destabilising factor for the sclerotic Thai elite and their shaky status quo from the 1990s onwards.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd52f551d-236b-456b-a7a8-5d2e967ebba1_801x720.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd52f551d-236b-456b-a7a8-5d2e967ebba1_801x720.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/d52f551d-236b-456b-a7a8-5d2e967ebba1_801x720.jpeg&quot;,&quot;height&quot;:720,&quot;width&quot;:801,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:108202,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><h3><strong>Prem and the prince</strong></h3><p>Between 1980 and 1988 Thailand was a faux-democracy in which royalist general Prem Tinsulanonda served as prime minister on behalf of Bhumibolâ€™s faction among the royalist elite. Meanwhile, the kingâ€™s marriage to Queen Sirikit was unravelling, and army factionalism was rife. Sirikit became close to generals who wanted to replace Prem, and also sought to pressure Bhumibol to abdicate in favour of Vajiralongkorn, who had his own favourites among the political and military elite.</p><p>In April 1984, several US intelligence agencies produced&nbsp;<a href="https://www.cia.gov/readingroom/docs/CIA-RDP85T00310R000100040007-5.pdf">a secret joint report on Premâ€™s political prospects</a>. The report mentions that Vajiralongkorn was regarded as erratic and irresponsible.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0afd855-f176-4a8d-aac2-51b6f99d0acd_1108x406.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0afd855-f176-4a8d-aac2-51b6f99d0acd_1108x406.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/a0afd855-f176-4a8d-aac2-51b6f99d0acd_1108x406.jpeg&quot;,&quot;height&quot;:406,&quot;width&quot;:1108,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:80135,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>The report also noted that Vajiralongkorn supported a right-wing rival of Prem. This was notorious ultranationalist politician Samak Sundaravej. Meanwhile, Sirikit had a favourite of her own â€” the ambitious General Arthit Kamlang-ek.</p><p>These factors destabilised the country throughout the period of â€œPremocracyâ€</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F77008cf2-70c2-4946-b942-b8045848c7b7_1070x710.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F77008cf2-70c2-4946-b942-b8045848c7b7_1070x710.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/77008cf2-70c2-4946-b942-b8045848c7b7_1070x710.jpeg&quot;,&quot;height&quot;:710,&quot;width&quot;:1070,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:112079,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><h3><strong>The â€œDouble 9â€ coup of 1985</strong></h3><p>On September 9, 1985, a group of military officers linked to a faction known as the â€œYoung Turksâ€ tried to seize power in an abortive uprising that was quickly suppressed. One suspected reason for the collapse of the attempted coup was that senior military officers favoured by Sirikit and Vajiralongkorn initially promised their support but panicked and backed out at the last minute.</p><p>The coup was suppressed by forces loyal to General Chavalit Yongchaiyudh. Five civilians were killed during the brief fighting, including two foreign journalists, Neil Davis and Bill Latch of NBC. The <a href="https://www.cia.gov/readingroom/docs/CIA-RDP04T00447R000302260001-1.pdf">CIA analysis of the abortive coup</a> is heavily redacted but nevertheless still useful.</p><p>One of the interesting elements of the analysis is that it explicitly discusses the splits in the royal family and their impact on events. The analysis mentions that Sirikit supported General Pichit Kullavanij, a rival to Prem and might a support a coup by him.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F176e2e58-42a9-4982-84ff-5e93da820e0f_1102x720.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F176e2e58-42a9-4982-84ff-5e93da820e0f_1102x720.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/176e2e58-42a9-4982-84ff-5e93da820e0f_1102x720.jpeg&quot;,&quot;height&quot;:720,&quot;width&quot;:1102,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:240502,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><h3><strong>The uncertain kingdom</strong></h3><p>In February 1987, combined U.S. intelligence agencies produced yet another report fretting that â€œThailandâ€™s nagging political and economic problems â€” and expected changes in leadership â€” suggest that this important US ally may be headed for a period of â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://secretsiam.news/p/an-overview-of-declassified-cia-cables">https://secretsiam.news/p/an-overview-of-declassified-cia-cables</a></em></p>]]>
            </description>
            <link>https://secretsiam.news/p/an-overview-of-declassified-cia-cables</link>
            <guid isPermaLink="false">hacker-news-small-sites-26181299</guid>
            <pubDate>Thu, 18 Feb 2021 15:54:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zoom is the solution nobody asked for, to a problem that doesnâ€™t exist]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26181268">thread link</a>) | @tompccs
<br/>
February 18, 2021 | https://www.vanityfarce.com/office/work/zoom/2021/02/17/zoom.html | <a href="https://web.archive.org/web/*/https://www.vanityfarce.com/office/work/zoom/2021/02/17/zoom.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em>Disclaimer â€“ This post was poorly researched and most of the historical â€˜factsâ€™ are pieced together from my own recollection, books Iâ€™ve been reading and Wikipedia searches. Despite the lack of rigorous scholarship (or perhaps because of it) I expect the conclusion to be 100% correct.</em></p>

<p>When the pandemic is â€œoverâ€ â€“ or, more precisely, when the right people decide to declare it â€œoverâ€ and we are living in a world split between Covid-negative and Covid-positive countries with a several year life expectancy gap between them â€“ the consensus is that some things will go back to the way they were pre-2020, and others wonâ€™t. Whether or not you think white collar workers will still be working from home â€“ living in commuter belts, in or around small towns or in remoter parts of the country side with decent broadband â€“ or will have migrated back into the offices, city pubs and crammed trains, depends largely on whether or not you have a financial interest in the value of commercial real estate. One thing everyone seems to agree on, though, is that video conferencing technology, such as Zoom, has been, and will continue to be, central to this revolution in working patterns.</p>

<p>Whatever the future of white collar work holds, I feel I can confidently predict that video conferencing will be not-so-fondly remembered as a weird crutch that everyone was obsessed with for about 12-18 months, before people realised it actually serves no purpose at all.</p>

<p>To argue this point, I will ask the question â€“ why do we actually have offices in the first place? Who are they for? What problems do they solve? And which of those problems does video conferencing actually come close to addressing?</p>

<p>The history of bureaucratic white-collar work goes something like this: there are two main threads of office work which emerged around the Industrial Revolution â€“ state-administration, and the bourgeoise professions (accountants, lawyers, traders, etc). Of the two threads, state administration is the older: bureaucracies of this sort can be traced back to ancient Egypt. Hierarchies beyond a certain size need paperwork, because the people in charge need a way to have their wishes transmitted authentically without corruption (accidental of nefarious) to hundreds or thousands of  lowly peons. Hence the priestly, and later bureaucratic, class, tasked with the top-down administration of unwieldy empires and later nation-states according to the insights or whims of their rulers.</p>

<p>Obviously, this type of administration pre-dates the â€œofficeâ€ as we currently recognise it. There arenâ€™t many western institutions which have been in continuous operation from medieval through to post-industrial times which we can analyse in this way, but one of them might be the British Parliament. Originally an ad-hoc assembly of the Kingâ€™s noblemen, gathered as and when the King needed to raise some cash through taxation, this travelling parliament eventually evolved into the more stationary one we know today, where MPs have permanent offices and travel between their constituencies and the debating chambers according to how often they feel the need to escape from those people who elected them there in the first place. In 2021, those MPs are now spending a lot more time in their constituencies. Voting can now happen remotely, although MPs still have the option of attending debates in person. Itâ€™s hard to imagine British government functioning in quite the same way without the cut-and-thrust of rigorous parliamentary debate, but then again, itâ€™s hard to see how any type of video conferencing solution could recreate it either (just look at what happened in this <a href="https://www.youtube.com/watch?v=jB3P_0GAi0I">disastrous parish council meeting</a>)</p>

<p>What of the rest of the state apparatus? The ambassadors, bureaucrats, etc? Well, to once again take an example from British history, a small cadre of Oxbridge-educated civil servants based in Whitehall, London, used to administer the largest empire in history with no more advanced technology than the telegraph. I canâ€™t quite imagine a Zoom meeting between Prime Minister Disraeli and the governor-general of India, not to mention with the 120-or-so Indian noblemen scattered about the subcontinent, making this unwieldy task any easier.</p>

<p>So much for administering an empire. What about lower-level state administration â€“ things like welfare, sanitation, treasury, etc? You might not be surprised to learn that the primary reason for co-locating lots of bureaucrats is becauseâ€¦<em>thatâ€™s where the filing cabinets were!</em> If you needed to process a tax return, or look up some obscure by-law, you generally had to be co-located with reams and reams of paper containing this information. The fact that this constituted an â€œofficeâ€ is purely down to the fact that other people needed to be co-located with these files as well as you. The office was originally built for collaboration insofar as a library is built for meeting girls.</p>

<p>Weâ€™ve still not explored the other thread of this â€“ the thread that runs from Venetian merchants to Googleâ€™s bean-bags and free lunches. This one is harder to explain. As the artisan evolved into the factory worker, so too did the other professionals â€“ lawyers, accountants, merchants â€“ evolve into the office worker. What was the rationale for this? Why should a lawyer or accountant, each of whom has a few assigned clients, need to work in an office with lots of other lawyers and accountants? Rather than being co-located with their filing cabinets, I suppose the reason is to allow them to share a pool of ancillary staff, like paralegals, typists, etc. However, as the digital revolution has swept through (and, since WWII, rising wages), much of the ancillary staff have been done away with altogether, or else morphed into something called â€˜middle managementâ€™. The function of middle management, of course, is the same as the ancillary staff: to help the professionals do their jobs better, although by tweaking their job description they were able to negotiate better pay.</p>

<p>If you need ancillary staff (read: middle management), then it stands to reason that you need an office, too. And if you donâ€™t have an office, then you probably need something that will â€˜simulateâ€™ an office. Hereâ€™s the problem: whereas the ancillary staff of old knew that their job was to type things up, keep appointment diaries and fetch post, middle management believes their job is to hold meetings. Therefore, synonymous with â€˜home workingâ€™ is â€˜Zoom meetingsâ€™.</p>

<p>Iâ€™ve actually omitted a third thread of office history, which is the monastery (or university in 21st century parlance). Why the need to have a bunch of monks living together? In fact, the original Christian monk was a hermit, living in total solitude. But perhaps in not having a family such a degree of loneliness was too much to bear. Hence the monastery, where, as well as (or perhaps in the course of) worshipping God, monks partook in such pastimes as beer brewing, geometry, and science. The fact that big groups of celibate, literate men living in the same place led to all sorts of interesting by-products is perhaps the root of the modern idea of a university, and that legacy also dovetails into our modern corporate culture which has its roots in the 1980s, whose hallmarks are the borrowing of university lingo such as â€˜campusâ€™, and a growing obsession with a nicely marketable form of self-improvement which can be delivered through highly lucrative training contracts.</p>

<p>There is a fleeting sense in which a modern university, with students living in halls, unemployed and frugal, could look a bit like, if you squint, a short stint at a medieval monastery, and whatever value universities still hold is probably related to how long you can hold onto that mirage. But the modern office, with its 9-to-5 clock and day punctuated by meetings and the ambitious preoccupied by the arduous climb up the corporate hierarchy, is even further away. Perhaps the closest thing to the medieval monastery is the startup, with its ungodly hours and religious-fanatical devotion to the cause, and itâ€™s probably no coincidence that working in a startup is generally seen as incompatible with having a social or family life. But no, other than the monastic startup-office-cum-bedsit, the office serves no creative purpose. The modern office is little more than a cargo-cult monastery.</p>

<p>Having read and of course also agreed with all of this, one can only wonder what function software such as Zoom can possibly serve. And I think the answer to this is similar to something we often see from new digital technology: the skeuomorphism of existing â€˜analogueâ€™ concepts (ie, the modern â€˜desktopâ€™ containing â€˜filesâ€™ and â€˜documentsâ€™). Skeuomorphisms are almost always a temporary crutch, a cognitive bridge between the old inefficient way of doing something and the new but conceptually abstract way which will eventually replace it. Consider, for instance, the transition from written letters, to email, to instant messaging. Or how indeed the very idea of an email has become distinct in itself â€“ look at how email etiquette has gradually evolved from when you might write one as you would write a letter in the early 2000s to the modern â€œsee attached. cheers, Tomâ€. Or look at social media, how Facebook was built on top of your real-world idea of â€˜friendsâ€™ by inventing the highly skeuomorphic (and somewhat autistic) concept of â€˜friend requestsâ€™, before Instagram and Twitter developed the more digitally-native concept of â€˜followingâ€™.</p>

<p>Zoom is the â€˜friend requestâ€™ of the office world. As our work places reverse the 150-year migration from our homes into purpose built offices, recall that that reversal is due to the sudden erosion of the logic which made us move into offices in the first place: record keeping and reference, ancillary staff, and creative collaboration. Zoom and video conferencing is a sticking plaster, and perhaps a desperate plea by the old guard to remind us of how much better â€¦</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.vanityfarce.com/office/work/zoom/2021/02/17/zoom.html">https://www.vanityfarce.com/office/work/zoom/2021/02/17/zoom.html</a></em></p>]]>
            </description>
            <link>https://www.vanityfarce.com/office/work/zoom/2021/02/17/zoom.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26181268</guid>
            <pubDate>Thu, 18 Feb 2021 15:52:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designing a RISC-V CPU, Part 1: Learning hardware design as a software engineer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26181136">thread link</a>) | @lelf
<br/>
February 18, 2021 | https://mcla.ug/blog/risc-v-cpu-part-1.html | <a href="https://web.archive.org/web/*/https://mcla.ug/blog/risc-v-cpu-part-1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
	
	<p><span>Tue 16 February 2021</span></p><p>I have no experience in digital logic design. That is, I didn't until I
recently decided that I would like to try designing my own CPU and running it
on an FPGA! If you too are a software engineer with a vague interest in
hardware design, I hope this series of posts about what I've learnt will be
helpful and interesting. In this first installment, I hope to answer these
questions:</p>
<ul>
<li>
<p>What is digital logic design?</p>
</li>
<li>
<p>How do I get started, and what tools might I use?</p>
</li>
</ul>
<p>In future installments, I will go into more detail about my CPU design and the
RISC-V architecture, as well as hopefully answering these questions:</p>
<ul>
<li>
<p>What about digital logic design is fundamentally different from software
  design?</p>
</li>
<li>
<p>What about digital logic design is similar to software design?</p>
</li>
</ul>
<p>You can see the code for my CPU at the time of writing
<a href="https://github.com/lochsh/riscy-boi/tree/47e94dc6e9665f73c871add002c34d1516fd5106">here</a>
or an up to date version <a href="https://github.com/lochsh/riscy-boi">here</a>.</p>
<h2>What is digital logic design?</h2>
<p>Digital logic design is designing logic circuits that operate on binary values.
The elementary components are logic gates: an AND gate, for example, has two
inputs and one output. The output is 1 iff<sup id="fnref:1"><a href="#fn:1">1</a></sup> both inputs are 1.</p>
<p>Typically, we design synchronous circuits which use flip-flops to store state,
and thereby synchronise the operation of the circuit to a common clock.
Flip-flops are composed of logic gates.</p>
<p>Analogue circuit design is concerned with the electronic components that make
up logic gates, like transistors and diodes. This level of abstraction is often
needed for applications dealing directly with signals derived from analogue
sensors, like radio receivers. When designing a CPU, this level of abstraction
would not be feasible: modern CPUs can have billions of transistors!</p>
<p>Instead, we use tools that can translate our digital logic design into
different useful formats: the configuration of an FPGA (see below); a
simulation; silicon layout.</p>
<h2>What is an FPGA and why are they used?</h2>
<p>We noted above that the same digital logic design tools can be used whether we
are creating a custom ASIC to be made into silicon, or configuring an FPGA. A
Field-Programmable Gate Array is an integrated circuit containing an array of
programmable logic blocks. You could imagine it is as a big array of logic
gates that can be connected together in various ways.</p>
<p>Making a custom chip generally costs millions, and of course once your chip is
manufactured it cannot be changed. Thus, generally FPGAs are used when:</p>
<ul>
<li>
<p>You cannot afford to create a custom ASIC due to lack of capital (e.g. if
  you're just some hacker like me and not ARM or Intel)</p>
</li>
<li>
<p>You cannot afford to create a custom ASIC because your volume is too low to
  make it worth the high one-off costs (e.g. if you are making a small quantity
  of MRI machines with custom data acquisition hardware)</p>
</li>
<li>
<p>You need the flexibility</p>
</li>
</ul>
<p>The downsides? FPGAs have a much higher per-chip cost, and they are generally
much slower as a consequence of being able to connect logic blocks together in
very flexible ways. In contrast, a custom design can be reduced to the minimum
number of transistors, with no concern for flexibility.</p>
<p>I think it's helpful context to compare the custom ASIC design process against
that of an FPGA design:</p>
<ul>
<li>
<p><span>Logic design</span>: just like we'd do for an FPGA, the logic design of an ASIC is
  done in a hardware description language.</p>
</li>
<li>
<p><span>Verification</span>: FPGA designs may well be verified, but you might expect the
  process for an ASIC design to be more rigorous â€“ after all, the design
  can't be changed once manufactured! Often verification will involve formally
  verifying<sup id="fnref:2"><a href="#fn:2">2</a></sup> parts of the design.</p>
</li>
<li>
<p><span>Synthesis</span>: This creates a <em>netlist</em>: a list of logic blocks and their
  connections. The connections are called <em>nets</em>, and the blocks are called
  <em>cells</em>. For both FPGAs and ASICs, the cells are vendor-specific.</p>
</li>
<li>
<p><span>Placement and routing</span> (P&amp;R): for an FPGA, this involves mapping the logic
  blocks described in the netlist to actual blocks in the FPGA. The resulting
  binary is often called a <em>bitstream</em>.  For an ASIC, this involves deciding
  where to place the cells on the silicon, and how to connect them up. Both
  applications generally use automated optimisation tools for this.</p>
</li>
</ul>
<h2>What tools do I need?</h2>
<h3>A hardware description language: I am using <a href="https://github.com/nmigen/nmigen">nMigen</a><sup id="fnref:3"><a href="#fn:3">3</a></sup></h3>
<p>You may have heard of Verilog or VHDL: both popular hardware description
languages (HDLs). I use "popular" here to mean widely used, not widely loved.</p>
<p>I won't pretend to know much about these tools: I only know that smarter people
than me with vast logic design experience have a lot of hate for them.
Due to the problems with Verilog and other similar tools, there have been
various attempts at making more useful and friendlier alternatives.  nMigen is
one such project, which creates a domain-specific language in Python. In their
own words:</p>
<blockquote>
<p>Despite being faster than schematics entry, hardware design with Verilog and
VHDL remains tedious and inefficient for several reasons. The event-driven
model introduces issues and manual coding that are unnecessary for
synchronous circuits, which represent the lion's share of today's logic
designs. Counterintuitive arithmetic rules result in steeper learning curves
and provide a fertile ground for subtle bugs in designs. Finally, support for
procedural generation of logic (metaprogramming) through "generate"
statements is very limited and restricts the ways code can be made generic,
reused and organized.</p>
<p>To address those issues, we have developed the nMigen FHDL, a library that
replaces the event-driven paradigm with the notions of combinatorial and
synchronous statements, has arithmetic rules that make integers always behave
like mathematical integers, and most importantly allows the design's logic to
be constructed by a Python program. This last point enables hardware
designers to take advantage of the richness of the Python languageâ€”object
oriented programming, function parameters, generators, operator overloading,
libraries, etc.â€”to build well organized, reusable and elegant designs.</p>
</blockquote>
<p>If, like me, you've never used Verilog, then not all of this will have more
than abstract meaning to you. But it certainly sounds promising,
and I can attest that it has been very straightforward to get started with
logic design without the reportedly large barrier of grappling with Verilog. I
would recommend it, particularly if you are already familiar with Python!</p>
<p>The only downside I can think of is that nMigen is still in development, and
in particular the documentation is not complete. There is a helpful community
at #nmigen on <a href="https://mcla.ug/blog/chat.freenode.net">chat.freenode.net</a>.</p>
<h3>A wave viewer for inspecting simulations: I am using <a href="http://gtkwave.sourceforge.net/">GTKWave</a></h3>
<p>nMigen provides simulation tooling: I use it in my tests, written using
<code>pytest</code>. I record the signals during these tests and view them in a wave
viewer to help debug.</p>
<p><img alt="gtkwave" src="https://mcla.ug/blog/images/gtkwave.png" title="A screenshot of GTKWave"></p>
<h3>Optional: An FPGA dev board. I am using a myStorm BlackIce II</h3>
<p>You don't need an FPGA dev board to create your own CPU. You could do
everything in simulation! The fun of having a board to work with, for me, is
being able to flash LEDs and see my design in action.</p>
<p>Of course, if you were creating something more useful than my very basic CPU,
then you would probably want some hardware to run it on, and this would be less
"optional"!</p>
<h2>Getting started with nMigen</h2>
<p>Rather than immediately trying to design a CPU, I started by making an
Arithmetic Logic Unit (ALU) in nMigen. The ALU is a key piece of any CPU design
that I have seen: it performs arithmetic operations.</p>
<p>Why start with this? I knew I would need an ALU for my CPU; I knew I could make
a simple one; I knew that the feeling of making something is an important
motivator when starting a new project!</p>
<p>My design looked something like this:</p>

<div>
<pre id="vimCodeElement"><span id="L1"> 1 </span><span>"""</span><span>Arithmetic Logic Unit</span><span>"""</span>
<span id="L2"> 2 </span><span>import</span> enum
<span id="L3"> 3 </span>
<span id="L4"> 4 </span><span>import</span> nmigen <span>as</span> nm
<span id="L5"> 5 </span>
<span id="L6"> 6 </span>
<span id="L7"> 7 </span><span>class</span> <span>ALUOp</span><span>(</span>enum<span>.</span>IntEnum<span>)</span><span>:</span>
<span id="L8"> 8 </span>    <span>"""</span><span>Operations for the ALU</span><span>"""</span>
<span id="L9"> 9 </span>    ADD <span>=</span> <span>0</span>
<span id="L10">10 </span>    SUB <span>=</span> <span>1</span>
<span id="L11">11 </span>
<span id="L12">12 </span>
<span id="L13">13 </span><span>class</span> <span>ALU</span><span>(</span>nm<span>.</span>Elaboratable<span>)</span><span>:</span>
<span id="L14">14 </span>    <span>"""</span>
<span id="L15">15 </span><span>    Arithmetic Logic Unit</span>
<span id="L16">16 </span>
<span id="L17">17 </span><span>    * op (in): the opcode</span>
<span id="L18">18 </span><span>    * a (in): the first operand</span>
<span id="L19">19 </span><span>    * b (in): the second operand</span>
<span id="L20">20 </span>
<span id="L21">21 </span><span>    * o (out): the output</span>
<span id="L22">22 </span><span>    </span><span>"""</span>
<span id="L23">23 </span>
<span id="L24">24 </span>    <span>def</span> <span>__init__</span><span>(</span>self<span>,</span> width<span>)</span><span>:</span>
<span id="L25">25 </span>        <span>"""</span>
<span id="L26">26 </span><span>        Initialiser</span>
<span id="L27">27 </span>
<span id="L28">28 </span><span>        Args:</span>
<span id="L29">29 </span><span>            width (int): data width</span>
<span id="L30">30 </span><span>        </span><span>"""</span>
<span id="L31">31 </span>        self<span>.</span>op <span>=</span> nm<span>.</span>Signal<span>()</span>
<span id="L32">32 </span>        self<span>.</span>a <span>=</span> nm<span>.</span>Signal<span>(</span>width<span>)</span>
<span id="L33">33 </span>        self<span>.</span>b <span>=</span> nm<span>.</span>Signal<span>(</span>width<span>)</span>
<span id="L34">34 </span>        self<span>.</span>o <span>=</span> nm<span>.</span>Signal<span>(</span>width<span>)</span>
<span id="L35">35 </span>
<span id="L36">36 </span>    <span>def</span> <span>elaborate</span><span>(</span>self<span>,</span> _<span>)</span><span>:</span>
<span id="L37">37 </span>        m <span>=</span> nm<span>.</span>Module<span>()</span>
<span id="L38">38 </span>
<span id="L39">39 </span>        <span>with</span> m<span>.</span>Switch<span>(</span>self<span>.</span>op<span>)</span><span>:</span>
<span id="L40">40 </span>            <span>with</span> m<span>.</span>Case<span>(</span>ALUOp<span>.</span>ADD<span>)</span><span>:</span>
<span id="L41">41 </span>                m<span>.</span>d<span>.</span>comb <span>+=</span> self<span>.</span>o<span>.</span>eq<span>(</span>self<span>.</span>a <span>+</span> self<span>.</span>b<span>)</span>
<span id="L42">42 </span>            <span>with</span> m<span>.</span>Case<span>(</span>ALUOp<span>.</span>SUB<span>)</span><span>:</span>
<span id="L43">43 </span>                m<span>.</span>d<span>.</span>comb <span>+=</span> self<span>.</span>o<span>.</span>eq<span>(</span>self<span>.</span>a <span>-</span> self<span>.</span>b<span>)</span>
<span id="L44">44 </span>        <span>return</span> m
</pre>
</div>

<p>As you can see, we've created a lot of nMigen <code>Signal</code> instances to represent
well...the signals that define the interface to our ALU! But what is this
<code>elaborate</code> method? My understanding is that "elaboration" is the name for the
first step in synthesising the netlist (see above). The idea in the nMigen code
above is that we've created some <em>elaboratable</em> structure (by inheriting from
<code>nm.Elaboratable</code>), i.e. something that describes digital logic we want to
synthesise. The <code>elaborate</code> method describes that digital logic. It has to
return an nMigen <code>Module</code>.</p>
<p>Let's have a closer look at the contents of the <code>elaborate</code> method. The
<code>Switch</code> will create some kind of decision logic in the synthesised design.
But what is <code>m.d.comb</code>? nMigen has the concept of synchronous (<code>m.d.sync</code>)
and combinatorial<sup id="fnref:4"><a href="#fn:4">4</a></sup> (<code>m.d.comb</code>) control domains. From the nMigen
<a href="https://nmigen.info/nmigen/latest/lang.html#lang-domains">docs</a>:</p>
<blockquote>
<p>A control domain is a named group of signals that change their value in
identical conditions.</p>
<p>All designs have a single predefined <em>combinatorial domain</em>, containing all
signals that change immediately when any value used to compute them changes.
The name comb is reserved for the combinatorial domain.</p>
<p>A design can also have any amount of user-defined <em>synchronous domains</em>, also
called clock domains, containing signals that change when a specific edge
occurs on the domainâ€™s â€¦</p></blockquote></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mcla.ug/blog/risc-v-cpu-part-1.html">https://mcla.ug/blog/risc-v-cpu-part-1.html</a></em></p>]]>
            </description>
            <link>https://mcla.ug/blog/risc-v-cpu-part-1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26181136</guid>
            <pubDate>Thu, 18 Feb 2021 15:44:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One micro-angel's trash is another's come-up]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26181087">thread link</a>) | @eyaltoledano
<br/>
February 18, 2021 | https://microangel.so/p/make-an-offer-listings?r=46t31&utm_campaign=post&utm_medium=web&utm_source=hackernews | <a href="https://web.archive.org/web/*/https://microangel.so/p/make-an-offer-listings?r=46t31&utm_campaign=post&utm_medium=web&utm_source=hackernews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F16155a11-ae73-428f-b133-29ad0f0784c9_1020x442.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F16155a11-ae73-428f-b133-29ad0f0784c9_1020x442.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/16155a11-ae73-428f-b133-29ad0f0784c9_1020x442.png&quot;,&quot;height&quot;:442,&quot;width&quot;:1020,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:57295,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>Microangels have some pretty polarizing opinions about businesses listed as â€˜open for offers.â€™</p><p>In fact, most arenâ€™t reacting so well to these listings. The general consensus is that haggling sucks when it comes to investing in Micro-SaaS. </p><p>Investors want to have access to metrics that help them decide whether to make an offer as they scroll through deals.</p><p>I empathize with the inconvenience, but thatâ€™s all it is.</p><div><p>Itâ€™s true, you need as much information as you can to make a decision. Itâ€™s natural to expect someone looking to sell their product to be able to answer questions about the state of the product, the unit economics, marketing funnels, and so on. </p><p>Specifically, you want them to answer questions that help <em>you</em> reach a decision to invest/buy.</p></div><p>Generally, most of us have an idea of what weâ€™re looking for in a deal. But each micro-angel has a different style, and all want as much information as possible when browsing through deals.</p><p>A seller who asks buyers to â€˜Make an Offerâ€™ for their business is making a conscious choice to relinquish control over the starting price. Theyâ€™re giving up the price anchoring in your favour.</p><p>I can understand the initial reaction to â€˜make an offerâ€™ listings. If a product is listed without a price, it instantly spells <em>complicated order</em> for a potential buyer because that buyer has to determine that price to offer and then prepare to defend it.</p><p>Thatâ€™s how most microangels seem to react, and I just donâ€™t understand why.</p><p>Sure. It sucks to go through deals with completely made up terms. </p><p>Yep. Itâ€™s more work to have to actually <em>talk</em> to the person selling their business. It can even be a grind provided volume across several marketplaces.</p><p>Thereâ€™s no two ways around it â€” it takes more time. </p><p>But, like, seriouslyâ€¦ </p><p>Are you kidding me? </p><p>Buying a business isnâ€™t like buying something on Amazon. You can only be so <em>transactional</em> about it. </p><p>Marketplaces like <a href="https://www.microacquire.com/?utm_source=microangel">MicroAcquire</a> manage to attract interesting and diverse deal flow because theyâ€™re founder/seller-first. </p><p>In the case of micro acquisitions, sellers tend to be developers who have managed to create something valuable/profitable all on their own.</p><p>They donâ€™t have the pedigree, experience or time/patience to be meticulous about their reporting. Some shoot completely from the hip, and to me, <strong>that is a</strong> <strong>massive advantage</strong> <strong>as a micro-angel</strong>.</p><p>Story time:</p><p>One of my favourite humans to follow on Twitter is self-made real estate investor/developer <a href="https://twitter.com/sweatystartup">Nick Huber</a>. The manâ€™s a machine. </p><p>He started his real estate career by making a deliberate choice: to focus on a class of properties that would produce high margins, without having to deal with people (as a landlord must do), with strong cash-on-cash returns on his investments. </p><div><p>Pretty much any real estate investorâ€™s goal. </p><p>When he looked at the market, he found typical commercial properties trading at 6- to 12-cap<a id="footnote-anchor-1" href="#footnote-1">1</a> valuations, with returns that made him wonder if heâ€™d be better off investing in the stock market instead (he would). </p></div><p>To get his desired returns, he needed to be buying a different kind of property and orchestrate a high return based on the nature and archetype of the properties he would typically go buy and make offers on.</p><p>Ultimately, the choice was made to focus on self-storage properties for the simplicity of their operations. It was possible to increase the value of a self-storage business by optimizing its operations using technology and software. </p><p>Stuff like automatic billing, keyless access, automated surveillance recording, and so on.</p><p>As people zigged, Nick zagged:</p><p>To command larger cash on cash returns, he needed to buy properties <em>below their market value </em>and then boost his cashflow by optimizing costs and increasing rents. But everybody else was trying to do that too.</p><p>So Nick decided to focus on properties that most other investors donâ€™t want to or canâ€™t touch, which by design ensured he would command very high returns by executing a predictable playbook to optimize self-storage operations using technology.</p><p>The majority of self-storage locations today are fully-automated. But not all of them. Itâ€™s a big pie. Nick has proven to be an astute investor when it comes to sourcing and securing these hard-to-find deals.</p><p>His approach is <em>look for the mom and pop shops</em>. Self-storage businesses that still run on paper. Smaller ones that go under the radar or arenâ€™t even listed online. </p><p>They are profitable and are operated by an owner-manager that has likely been there since the start. And yet the property throws out fabulous free cashflows every year. Those were (and still are) his target.</p><p>So heâ€™d put in the work. Heâ€™d get on airplanes. Heâ€™d drive to The Middle of Nowhere. </p><p>And heâ€™d find the deals. And heâ€™d close â€˜em. Fabulous deals. </p><p>The point Iâ€™m trying to make is that thereâ€™s obviously a lot of pain and patience involved in filtering Micro-SaaS opportunities one by one. </p><p>It takes a lot of energy and time, which you may be unwilling to invest additional to your capital. </p><p>But in my opinion, that is exactly what separates those microangels who throw darts and those who are deliberate about what theyâ€™re looking for.</p><p>Itâ€™s the same thing which marks the difference between Nick and other real estate developers. Yeah itâ€™s a lot of hustling, but you know itâ€™s worth it, and itâ€™s a niche worth focusing on because most other investors arenâ€™t wiling to put in the work.</p><p>In fact, the point is proven by simply looking at <a href="https://twitter.com/sweatystartup">Nick Huberâ€™s Twitter</a>. Heâ€™s giving all of his secrets away. Wouldnâ€™t you expect at least some level of apprehension that giving away all this information might result in more competition? </p><p>Iâ€™d argue â€” beyond the simple truth that his niche is, in fact, super competitive - that he intrinsically knows that a tiny fraction of his readers will not only take action, but do so at the level of commitment that he is. Itâ€™s become a competitive moat. </p><p>Above and beyond the utilitarian benefits of looking at these deals, consider this:</p><p><a href="https://www.microacquire.com/?utm_source=microangel">MicroAcquire</a> is a working concept because it gives indie makers the ability to exit without having to go through a broker. That is its value proposition. No brokers. No fees. Just <em>serious</em> buyers. </p><p>As serious<em> </em>buyers, itâ€™s natural to expect serious preparation on the part of the seller, but it goes against the nature of the types of most individuals who would list on <a href="https://www.microacquire.com/?utm_source=microangel">MicroAcquire</a> to begin with.</p><p>Itâ€™s not uncommon for â€˜make an offerâ€™ listings to be describing a product that hasnâ€™t quite found its stride. In some cases, the owner of the product may not be well-equipped to provide you the information you need.</p><p>Itâ€™s in your best interest to take advantage of these listings because other investors are skipping over them. They could be diamonds in the rough, and youâ€™d disqualify them merely because there is no set asking price.</p><p>In a recent negotiation which Iâ€™ll be sharing, I managed to secure a deal to acquire a profitable and growing $75K ARR B2B SaaS. </p><p>The product was originally listed as â€˜Make an Offer.â€™ I didnâ€™t quite care, since the business fit into my initial criteria. I ended up adding the product to my watch list and submitting a request for more information to the seller, namely:</p><ul><li><p>Learn more about the actual product itself</p></li><li><p>Some unit economics (ARPU, LTV, CAC)</p></li><li><p>Profitability on the $75K ARR</p></li><li><p>Whether there was any net revenue growth every month</p></li><li><p>How secure the source of demand generation was</p></li><li><p>What the technology stack is</p></li><li><p>What the support burden is &amp; typical ticket</p></li></ul><p>I checked into my watch list a few days later and noticed the seller had put up a $350K asking price for the product. </p><p>Also, I received an answer to my request for info: a .CSV file of payouts since founding, a spreadsheet of costs and some Google Analytics screenshots.</p><p>I took the CSV, imported it into Google Sheets, built a few pivot tables and filters, and compiled the info I needed.</p><p>Additional to the information shared with the seller, I made a few remarkable discoveries hacking through the data:</p><ul><li><p>The product does one thing really simply &amp; well</p></li><li><p>ARPU in the $15 range, LTV in the $200 range and growing</p></li><li><p>The seller claimed $16K in profits annually, but on an SDE<a id="footnote-anchor-2" href="#footnote-2">2</a> basis the product actually clears $65K in profits annually. Not too shabby.</p></li><li><p>MRR grows linearly from a steady stream of trials, at a rate of about +$210 per month, after churn. Nice.</p></li><li><p>80% of the traffic is organic, 20% is direct. Good with that.</p></li><li><p>Tech stack is Node + React. Thatâ€™s my jam.</p></li><li><p>1-2 support tickets per week, usually sent to Knowledgebase</p></li><li><p>Some evidence of paid acquisition for as little as $35 CPA, but the owner does not have any marketing experience to scale with</p></li></ul><p>Welp, this is an awesome product. My reactions were obvious:</p><ul><li><p>Customers are staying on an average of 13+ months and growing, </p></li><li><p>Profits are strong, and meaningful </p></li><li><p>MRR is growing on autopilot from a dependable source of traffic</p></li><li><p>The stack is something I can maintain or work on</p></li><li><p>Itâ€™s a low maintenance product </p></li><li><p>The early success in paid acquisition indicates a path to buying MRR â€” especially if payback is as little as 2 months ($35 CPA / $15 ARPU)</p></li></ul><p>I wanted in. In fact, I was surprised nobody else had scooped this up yet. </p><p>Then I looked at the price again. </p><blockquote><p>$350,000</p></blockquote><p>At $350K, no wonder nobody was touching this. Especially if the seller was telling other buyers he was only clearing $16K annually, which was inaccurate.</p><p>I jumped at the chance and <a href="https://microangel.so/p/loi-template">wrote up an LOI</a> to acquire the business for $180,000, which worked out to a respectable 2.75x multiple on the $65K he was actually clearing every year.</p><p>Initially, he balked. I realized that winning this deal meant spending an extra fair bit of patience going through the motions of defending my offer and justifying why it was, in fact, quite a respectable number.</p><p>First, granted the profit margin he was claiming, $180,000 was an incredible offer for a product clearing only $16K per year (11.25x). I made sure he understood that even if the profit he claimed was true, the odds of him ever commanding a 11.25x multiple were certifiably zero.</p><p>Luckily, he was off on his calculations, and his business actually profited quite a lot more than he thought it did.</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://microangel.so/p/make-an-offer-listings?r=46t31&amp;utm_campaign=post&amp;utm_medium=web&amp;utm_source=hackernews">https://microangel.so/p/make-an-offer-listings?r=46t31&amp;utm_campaign=post&amp;utm_medium=web&amp;utm_source=hackernews</a></em></p>]]>
            </description>
            <link>https://microangel.so/p/make-an-offer-listings?r=46t31&amp;utm_campaign=post&amp;utm_medium=web&amp;utm_source=hackernews</link>
            <guid isPermaLink="false">hacker-news-small-sites-26181087</guid>
            <pubDate>Thu, 18 Feb 2021 15:41:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Futex Reacquainted]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26180930">thread link</a>) | @tabokie
<br/>
February 18, 2021 | https://tabokie.github.io/tech/2021/01/30/futex-reacquainted.html | <a href="https://web.archive.org/web/*/https://tabokie.github.io/tech/2021/01/30/futex-reacquainted.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      
      
      
      
      <p><span># tech, 2021-01-30</span></p><p>To be fair, the futex (Fast Userspace muTEX) syscall has a rather misleading name, in the sense that it simply isnÃ¢â‚¬â„¢t a mutex. In the original 2002 paper (Fuss, Futexes and Furwocks: Fast Userlevel Locking in Linux), it was invented specifically to implement a fast mutex, but capable of much more. I prefer to think of futex as a minimal useful subset that can fulfil most high level synchronization constructs.</p>

<h2 id="minimal-useful-subset">Minimal Useful Subset</h2>

<p>Before futex was borned, people in need of a proper mutex (waiter actually blocks) have to use heavy kernel objects like file lock (<a href="https://man7.org/linux/man-pages/man2/fcntl.2.html">fcntl</a>) or <a href="https://man7.org/linux/man-pages/man7/sysvipc.7.html">System V semaphore</a>. Since system calls are toxic to performance, kernel developers then seeked to compress kernel involvement in userspace synchronization by inventing futex.</p>

<p>So essentially this design process is a code refactor that encapsulates the thread blocking functionality into a new lightweight syscall. And such blocking can be easily elided when the lock isnÃ¢â‚¬â„¢t contended.</p>

<p>Here by Ã¢â‚¬Å“lightweightÃ¢â‚¬ï¿½ I mean the resource allocated for a futex should be minimal, so that thousands of futexes could live happily within a commodity setup. This requirement implicitly forbids the use of file descriptor as futex handle.</p>

<p>To meet all these standards, futex provides an interface like this (minimal form):</p>

<div><div><pre><code><span>int</span> <span>futex_wake</span><span>(</span><span>int</span> <span>*</span><span>addr</span><span>);</span>
<span>int</span> <span>futex_wait</span><span>(</span><span>int</span> <span>*</span><span>addr</span><span>,</span> <span>int</span> <span>val</span><span>);</span>
</code></pre></div></div>

<p>Without doubt this is a piece of elegancy. The idea of userspace address as unique identifier isnÃ¢â‚¬â„¢t rare in nowaday system code (see boostÃ¢â‚¬â„¢s <a href="https://github.com/boostorg/thread/blob/409c98f8b745e72bc326e93bfaf8a353d94a69b0/include/boost/thread/tss.hpp">thread local pointer</a>). WhatÃ¢â‚¬â„¢s brilliant is, futex further incorporates the CAS-like (compare and swap) semantics into this address Ã¢â‚¬â€œ the thread is blocked when <code>*addr</code> is indeed <code>val</code>. This turns out to be essential to enforce the atomicity of user~kernel transition:</p>

<div><div><pre><code><span>static</span> <span>int</span> <span>a</span> <span>=</span> <span>NO_SIGNAL</span><span>;</span>
<span>// properly wait for a signal</span>
<span>let</span> <span>cached_a</span> <span>=</span> <span>atomic_load</span><span>(</span><span>&amp;</span><span>a</span><span>);</span>
<span>while</span> <span>(</span><span>!</span><span>has_signal</span><span>(</span><span>cached_a</span><span>))</span> <span>{</span>
  <span>futex_wait</span><span>(</span><span>&amp;</span><span>a</span><span>,</span> <span>cached_a</span><span>);</span>
  <span>cached_a</span> <span>=</span> <span>atomic_load</span><span>(</span><span>&amp;</span><span>a</span><span>);</span>
<span>}</span>
<span>// incorrect version</span>
<span>if</span> <span>(</span><span>has_signal</span><span>(</span><span>atomic_load</span><span>(</span><span>&amp;</span><span>a</span><span>)))</span> <span>{</span>
  <span>futex_wait_racy</span><span>(</span><span>FUTEX_WAIT</span><span>,</span> <span>&amp;</span><span>a</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>In the incorrect version, this thread can block indefinitely when the signal has already arrived at <code>a</code>. The conditional loop also defends against spurious wakeups (more details later), which further propagates itself to the use of condition variable.</p>

<h2 id="technical-details">Technical Details</h2>

<p>
       ...
    ----------
        |          tid1       tid2       tid3
    +--------+      |          |          |
    |spinlock|  ~~~~~~~~~  ---------  ~~~~~~~~~
    |   key  +-&gt;| addr1 |-&gt;| addr2 |-&gt;| addr1 |-&gt;...
    +--------+  ~~~~~~~~~  ---------  ~~~~~~~~~
        | 
    ----------
</p>

<p>Kernel uses a fixed-size, seperate chaining, central hash table to store mappings between user provided address and the waiting threads (wait queue). A futex wonÃ¢â‚¬â„¢t occupy any resource until some threads start blocking on it. What puzzles me a little is why they didnÃ¢â‚¬â„¢t bother to maintain private wait queues for individual futexes, guess the benefit of fewer key comparisons isnÃ¢â‚¬â„¢t worth the complexity.</p>

<p>Unsurprisingly, this table becomes a performance bottleneck as computing nodes scale out, and poses challenge to system predictability. In a <a href="https://www.youtube.com/watch?v=-8c47dHuGIY">talk</a> by SUSE engineer, three major issues were identified:</p>

<ul>
  <li>Not optimized for NUMA access</li>
  <li>Hash table collisions</li>
  <li>Hash bucket spinlock contention</li>
</ul>

<p>When problems are defined, solutions arenÃ¢â‚¬â„¢t that far either. Below is a list of the major optimizations made to mitigate these issues over the years:</p>

<ol>
  <li>
    <div><p><code>FUTEX_PRIVATE_FLAG</code>: fast path for single-process use. (2007 <a href="https://lwn.net/Articles/229668/">patch</a>: new PRIVATE futexes)
</p><p>
When a futex is declared private within current process, which is true for most cases, there is no need for kernel to generate and maintain a global UID.
</p><p>
This new command managed to avoid: (a) Taking the mmap_sem semaphore, conflicting with other subsystems. (b) Modifying a ref_count on mm or an inode, still conflicting with mm or fs.
</p><p>
Benchmark shows 20% less instructions, 4x throughput under 4 threads stress test, 16x under 16 threads.</p></div>
  </li>
  <li>
    <p>Lockless <code>get_futex_key()</code> (a <a href="https://lore.kernel.org/patchwork/cover/645514/">series</a> of patches)</p>
  </li>
  <li>
    <div><p>Make hash table size adaptive (2014 <a href="https://github.com/torvalds/linux/commit/a52b89ebb6d4499be38780db8d176c5d3a6fbc17">commit</a>: Increase hash table size for better performance)
</p><p>
After this patch, global hash table is sized to <code>256 * cpu_num</code> instead of <code>256</code>.</p></div>
  </li>
  <li>
    <div><p>Lockless wakeups (2015 <a href="https://github.com/torvalds/linux/commit/1d0dcb3ad9d336e6d6ee020a750a7f8d907e28de">commit</a>: Implement lockless wakeups)
</p><p>
Internally acknowledge one or more tasks are to be awoken, then do the actual wakeups outside the critical section.</p></div>
  </li>
  <li>
    <div><p>Use MCS lock as bucket spinlock (32-bit qspinlock is <a href="https://github.com/torvalds/linux/commit/a33fda35e3a7655fb7df756ed67822afb5ed5e8d">merged</a> in 2015)
</p><p>
Unlike ticket spinlock, one acquires MCS lock by spinning on a private word part of a larger linked queue, which avoids lots of cache line bouncing and remote socket access.</p></div>
  </li>
  <li>
    <p>Use private hash table for each process (<a href="https://lore.kernel.org/lkml/49C4D5A0.5020106@cosmosbay.com/t/">rfc</a>)</p>
  </li>
</ol>

<h2 id="romance-between-futex--condition-variable">Romance Between Futex &amp; Condition Variable</h2>

<p>I was going to take a closer look at how pthread(NPTL) implements condition variable with futexes, and unveil some of the mysteries that prompted me to write this post in the first place.</p>

<p>To look Ã¢â‚¬Å“closerÃ¢â‚¬ï¿½, I skimmed through the commits of NPTLÃ¢â‚¬â„¢s condvar from 2002 to 2016. Even though during this period the code skeleton is relatively stable, but minor details kept changing. Plus the commit messages being chaotic, itÃ¢â‚¬â„¢s almost impossible to reason those changes.</p>

<p>This leaves me no choice but to read the latest implementation (in 2016), which is simplified to this pseudocode:</p>

<div><div><pre><code><span>/** cv's data members **
 * lock: internal mutex
 * wait_seq: sequence number for waiter
 * wakeup_seq: sequence number for wakeup signaled
 * woken_seq: sequence number for woken thread
 * broadcast_seq: sequence number for broadcast signaled
 * mutex_ref: reference to user mutex
 */</span>
<span>fn</span> <span>cond_wait</span><span>(</span><span>cv</span><span>,</span> <span>mutex</span><span>):</span>
  <span>lock</span><span>(</span><span>cv</span><span>.lock</span><span>);</span>
  <span>unlock</span><span>(</span><span>mutex</span><span>);</span>
  <span>cv</span><span>.wait_seq</span> <span>++</span><span>;</span>
  <span>cv</span><span>.futex</span> <span>++</span><span>;</span>
  <span>cv</span><span>.mutex_ref</span> <span>=</span> <span>mutex</span><span>;</span>
  <span>let</span> <span>wakeup_seq_before</span> <span>=</span> <span>cv</span><span>.wakeup_seq</span><span>;</span>
  <span>let</span> <span>broadcast_seq_before</span> <span>=</span> <span>cv</span><span>.broadcast_seq</span><span>;</span>
  <span>loop</span> <span>{</span>
    <span>let</span> <span>futexval</span> <span>=</span> <span>cv</span><span>.futex</span><span>;</span>
    <span>unlock</span><span>(</span><span>cv</span><span>.lock</span><span>);</span>
    <span>let</span> <span>ret</span> <span>=</span> <span>FUTEX_WAIT</span><span>(</span><span>cv</span><span>.futex</span><span>,</span> <span>futexval</span><span>);</span>
    <span>lock</span><span>(</span><span>cv</span><span>.lock</span><span>);</span>
    <span>if</span> <span>broadcast_seq_before</span> <span>!=</span> <span>cv</span><span>.broadcast_seq</span> <span>{</span>
      <span>break</span><span>;</span>
    <span>}</span>
    <span>if</span> <span>cv</span><span>.wakeup_seq</span> <span>!=</span> <span>wakeup_seq_before</span> <span>&amp;&amp;</span> <span>cv</span><span>.wakeup_seq</span> <span>!=</span> <span>cv</span><span>.woken_seq</span> <span>{</span>
      <span>cv</span><span>.woken_seq</span> <span>++</span><span>;</span>
      <span>break</span><span>;</span>
    <span>}</span>
    <span>if</span> <span>ret</span> <span>==</span> <span>TIMEDOUT</span> <span>{</span>
      <span>cv</span><span>.wakeup_seq</span> <span>++</span><span>;</span>
      <span>cv</span><span>.woken_seq</span> <span>++</span><span>;</span>
      <span>break</span><span>;</span>
    <span>}</span>
  <span>}</span>
  <span>unlock</span><span>(</span><span>cv</span><span>.lock</span><span>);</span>
  <span>lock</span><span>(</span><span>mutex</span><span>);</span>

<span>fn</span> <span>cond_signal</span><span>(</span><span>cv</span><span>):</span>
  <span>lock</span><span>(</span><span>cv</span><span>.lock</span><span>);</span>
  <span>if</span> <span>cv</span><span>.wait_seq</span> <span>&gt;</span> <span>cv</span><span>.wakeup_seq</span> <span>{</span>
    <span>cv</span><span>.wakeup_seq</span> <span>++</span><span>;</span>
    <span>cv</span><span>.futex</span> <span>++</span><span>;</span>
    <span>if</span> <span>FUTEX_WAKE_OP</span><span>(</span><span>cv</span><span>.futex</span><span>,</span> <span>1</span><span>,</span> <span>cv</span><span>.lock</span><span>,</span> <span>1</span><span>,</span> <span>FUTEX_OP_CLEAR_WAKE_IF_GT_ONE</span><span>)</span><span>.is_err</span><span>()</span> <span>{</span>
      <span>FUTEX_WAKE</span><span>(</span><span>cv</span><span>.futex</span><span>,</span> <span>1</span><span>);</span>
    <span>}</span>
  <span>}</span>
  <span>unlock</span><span>(</span><span>cv</span><span>.lock</span><span>);</span>

<span>fn</span> <span>cond_broadcast</span><span>(</span><span>cv</span><span>):</span>
  <span>lock</span><span>(</span><span>cv</span><span>.lock</span><span>);</span>
  <span>if</span> <span>cv</span><span>.wait_seq</span> <span>&gt;</span> <span>cv</span><span>.wakeup_seq</span> <span>{</span>
    <span>cv</span><span>.wakeup_seq</span> <span>=</span> <span>cv</span><span>.wait_seq</span><span>;</span>
    <span>cv</span><span>.woken_seq</span> <span>=</span> <span>cv</span><span>.wait_seq</span><span>;</span>
    <span>cv</span><span>.futex</span> <span>=</span> <span>cv</span><span>.wait_seq</span> <span>*</span> <span>2</span><span>;</span>
    <span>let</span> <span>futexval</span> <span>=</span> <span>cv</span><span>.futex</span><span>;</span>
    <span>cv</span><span>.broadcast_seq</span> <span>++</span><span>;</span>
    <span>unlock</span><span>(</span><span>lock</span><span>);</span>
    <span>if</span> <span>FUTEX_CMP_REQUEUE</span><span>(</span><span>cv</span><span>.futex</span><span>,</span> <span>1</span><span>,</span> <span>ALL</span><span>,</span> <span>cv</span><span>.mutex_ref</span><span>,</span> <span>futexval</span><span>)</span><span>.is_err</span><span>()</span> <span>{</span>
      <span>FUTEX_WAKE</span><span>(</span><span>cv</span><span>.futex</span><span>,</span> <span>ALL</span><span>);</span>
    <span>}</span>
  <span>}</span> <span>else</span> <span>{</span>
    <span>unlock</span><span>(</span><span>cv</span><span>.lock</span><span>);</span>
  <span>}</span>
</code></pre></div></div>

<p>What interests me most is how condvar interplays with futexes. Unlike what I expected, condvar owns two futexes: the first is <code>cv.lock</code>, used to synchronize internal modifications; the second is <code>cv.futex</code>, used to park threads. Besides them, condvar also interacts with the user provided mutex, which has one futex inside.</p>

<p>It is important for condvar to manage its own lock, because <code>cond_signal</code> can be called without lock, stated by <a href="https://pubs.opengroup.org/onlinepubs/009696699/functions/pthread_cond_broadcast.html">POSIX</a>:</p>

<blockquote>
  <p>The pthread_cond_broadcast() or pthread_cond_signal() functions may be called by a thread whether or not it currently owns the mutex that threads calling pthread_cond_wait() or pthread_cond_timedwait() have associated with the condition variable during their waits; however, if predictable scheduling behavior is required, then that mutex shall be locked by the thread calling pthread_cond_broadcast() or pthread_cond_signal().</p>
</blockquote>

<p>And a condvar can even be paired with multiple mutexes (not at the same time), quote <a href="https://pubs.opengroup.org/onlinepubs/007908775/xsh/pthread_cond_wait.html">POSIX</a> again:</p>

<blockquote>
  <p>The effect of using more than one mutex for concurrent pthread_cond_wait() or pthread_cond_timedwait() operations on the same condition variable is undefined; that is, a condition variable becomes bound to a unique mutex when a thread waits on the condition variable, and this (dynamic) binding ends when the wait returns.</p>
</blockquote>

<p>ItÃ¢â‚¬â„¢s also important to notice that multiple options are available to send out wakeups:</p>

<p><code>cond_signal</code> first attempts to call <code>FUTEX_WAKE_OP</code> before falling back to traditional <code>FUTEX_WAKE</code>. This particular command was introduced to kernel in <a href="https://github.com/torvalds/linux/commit/4732efbeb997189d9f9b04708dc26bf8613ed721">2005</a> specifically for optimizing <code>cond_signal</code>, which has the capability to modify and conditionally wakes up a second futex. The optimization targets at avoiding Ã¢â‚¬Å“hurry up and waitÃ¢â‚¬ï¿½ situation, where Ã¢â‚¬Å“this waiter wakes up and after a few instructions it attempts to acquire the cv internal lock, but that lock is still held by the thread calling pthread_cond_signalÃ¢â‚¬ï¿½. It works by moving the whole unlock procedure into kernel space:</p>

<div><div><pre><code><span>// cond_signal (userspace)                          // cond_wait (userspace)</span>
<span>FUTEX_WAKE_OP</span><span>(</span><span>cv</span><span>.futex</span><span>,</span> <span>1</span><span>,</span> <span>cv</span><span>.lock</span><span>,</span> <span>1</span><span>);</span>             <span>FUTEX_WAIT</span><span>(</span><span>cv</span><span>.futex</span><span>);</span>
  <span>// (kernel)                                       // blocked //</span>
  <span>let</span> <span>(</span><span>key1</span><span>,</span> <span>key2</span><span>)</span> <span>=</span> <span>(</span><span>key</span><span>(</span><span>cv</span><span>.futex</span><span>),</span> <span>key</span><span>(</span><span>cv</span><span>.lock</span><span>));</span> <span>//         //</span>
  <span>spin_lock</span><span>(</span><span>min</span><span>(</span><span>key1</span><span>,</span> <span>key2</span><span>));</span>                       <span>//         //</span>
  <span>spin_lock</span><span>(</span><span>max</span><span>(</span><span>key1</span><span>,</span> <span>key2</span><span>));</span>                       <span>//         //</span>
  <span>let</span> <span>ret</span> <span>=</span> <span>OP_UNLOCK</span><span>(</span><span>cv</span><span>.lock</span><span>);</span>                     <span>//         //</span>
  <span>wake</span><span>(</span><span>key1</span><span>,</span> <span>1</span><span>);</span>  <span>// ------------------------------&gt;</span>
                                                    <span>lock</span><span>(</span><span>cv</span><span>.lock</span><span>);</span>  <span>// already unlocked</span>
  <span>if</span> <span>ret</span> <span>{</span>                                          <span>//</span>
    <span>wake</span><span>(</span><span>key2</span><span>,</span> <span>1</span><span>);</span>  <span>// ----------------------------&gt;  in case the lock is contended</span>
  <span>}</span>
</code></pre></div></div>

<p>One thing I havenÃ¢â‚¬â„¢t figured out though is why calling <code>FUTEX_WAKE(1)</code> without lock is racy, which seems like a straightforward fix to this issue.</p>

<p>Similarly, <code>cond_broadcast</code> tries to use <code>FUTEX_CMP_REQUEUE</code>, which is the kernelÃ¢â‚¬â„¢s implementation â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tabokie.github.io/tech/2021/01/30/futex-reacquainted.html">https://tabokie.github.io/tech/2021/01/30/futex-reacquainted.html</a></em></p>]]>
            </description>
            <link>https://tabokie.github.io/tech/2021/01/30/futex-reacquainted.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26180930</guid>
            <pubDate>Thu, 18 Feb 2021 15:30:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Coq 8.13]]>
            </title>
            <description>
<![CDATA[
Score 113 | Comments 38 (<a href="https://news.ycombinator.com/item?id=26180078">thread link</a>) | @infruset
<br/>
February 18, 2021 | https://coq.inria.fr/news/coq-8-13-0-is-out.html | <a href="https://web.archive.org/web/*/https://coq.inria.fr/news/coq-8-13-0-is-out.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>





<p>
The Coq development team is proud to announce the immediate availability of
<a href="https://github.com/coq/coq/releases/tag/V8.13.0">Coq 8.13.0</a>
</p>

<p>
Highlights:
</p><ul>
<li>Introduction of primitive persistent arrays in the core language, implemented using imperative persistent arrays. </li>
<li>Introduction of definitional proof irrelevance for the equality type defined in the SProp sort. </li>
<li>Many improvements to the handling of notations, including number notations, recursive notations and notations with bindings. A new algorithm chooses the most precise notation available to print an expression, which might introduce changes in printing behavior.</li>
</ul>



<p>Please see <a href="https://coq.github.io/doc/v8.13/refman/changes.html#version-8-13" rel="nofollow">the changelog</a> to learn more about this release.</p>




</div></div>]]>
            </description>
            <link>https://coq.inria.fr/news/coq-8-13-0-is-out.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26180078</guid>
            <pubDate>Thu, 18 Feb 2021 14:23:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Configure the Traefik Reverse Proxy with Docker Compose and Docker Swarm]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26180044">thread link</a>) | @juliensalinas
<br/>
February 18, 2021 | https://juliensalinas.com/en/traefik-reverse-proxy-docker-compose-docker-swarm-nlpcloud/ | <a href="https://web.archive.org/web/*/https://juliensalinas.com/en/traefik-reverse-proxy-docker-compose-docker-swarm-nlpcloud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>My <a href="https://juliensalinas.com/en/traefik-reverse-proxy-docker-compose-docker-swarm-nlpcloud/container-orchestration-docker-swarm-nlpcloud">last article about Docker Swarm</a> was the first of a series of articles I wanted to write about the tools used behind <a href="https://nlpcloud.io/">NLP Cloud</a>. NLP Cloud serves all the spaCy NLP models through an API, whether they are pre-trained or custom models. One challenge is that each model runs inside its own container, and new models are added to the cluster on a regular basis. So we need a reverse proxy which is both efficient and flexible in front of all these containers.</p>
<p>The solution we chose is <a href="https://traefik.io/">Traefik</a>.</p>
<p>I thought it would be interesting to write an article about how we implemented Traefik and why we chose it over standard reverse proxies like Nginx.</p>
<h2 id="why-traefik">Why Traefik</h2>
<p>Traefik is still a relatively new reverse proxy solution compared to Nginx or Apache, but itâ€™s been gaining a lot of popularity. Traefikâ€™s main advantage is that is seamlessly integrates with Docker, Docker Compose and Docker Swarm (and even Kubernetes and more): basically your whole Traefik configuration can be in your <code>docker-compose.yml</code> file which is very handy, and, whenever you add new services to your cluster, Traefik discovers them on the fly without having to restart anything.</p>
<p>So Traefik makes maintainability easier and is good from a high-availability standpoint.</p>
<p>It is developed in Go while Nginx is coded in C so I guess it makes a slight difference in terms of performance, but nothing that I could perceive, and in my opinion it is negligible compared to the advantages it gives you.</p>
<p>Traefik takes kind of a learning curve though and, even if their documentation is pretty good, it is still easy to make mistakes and hard to find where the problem is coming from, so let me give you a couple of ready-to-use examples below.</p>
<h2 id="install-traefik">Install Traefik</h2>
<p>Basically you donâ€™t have much to do here. Traefik is just another Docker image youâ€™ll need to add to your cluster as a service in your <code>docker-compose.yml</code>:</p>
<div><div><pre><code><span>version</span><span>:</span> <span>'</span><span>3.8'</span>
<span>services</span><span>:</span>
    <span>traefik</span><span>:</span>
        <span>image</span><span>:</span> <span>traefik:v2.3</span>
</code></pre></div></div>
<p>There are several ways to integrate Traefik but, like I said above, we are going to go for the Docker Compose integration.</p>
<h2 id="basic-configuration">Basic Configuration</h2>
<p>90% of the Traefikâ€™s configuration is done through Docker <code>labels</code>.</p>
<p>Letâ€™s say we have 3 services:</p>
<ul>
<li>A corporate website that simply serves a static website at http://nlpcloud.io</li>
<li>An <code>en_core_web_sm</code> spaCy model served through a FastAPI Python API at http://api.nlpcloud.io/en_core_web_sm</li>
<li>An <code>en_core_web_lg</code> spaCy model served through a FastAPI Python API at http://api.nlpcloud.io/en_core_web_lg</li>
</ul>
<p><em>More details about <a href="https://spacy.io/usage/models">spaCy NLP models here</a> and <a href="https://fastapi.tiangolo.com/">FastAPI here</a>.</em></p>
<p>Here is a basic <strong>local staging</strong> configuration routing the requests to the correct services in your <code>docker-compose.yml</code>:</p>
<div><div><pre><code><span>version</span><span>:</span> <span>'</span><span>3.8'</span>
<span>services</span><span>:</span>
    <span>traefik</span><span>:</span>
        <span>image</span><span>:</span> <span>traefik:v2.4</span>
        <span>ports</span><span>:</span>
            <span>-</span> <span>"</span><span>80:80"</span>
        <span>command</span><span>:</span>
            <span>-</span> <span>--providers.docker</span>
        <span>volumes</span><span>:</span>
            <span>-</span> <span>/var/run/docker.sock:/var/run/docker.sock:ro</span>
    <span>corporate</span><span>:</span>
        <span>image</span><span>:</span> <span>&lt;your corporate image&gt;</span>
        <span>labels</span><span>:</span>
            <span>-</span> <span>traefik.http.routers.corporate.rule=Host(`localhost`)</span>
    <span>en_core_web_sm</span><span>:</span>
        <span>image</span><span>:</span> <span>&lt;your en_core_web_sm model API image&gt;</span>
        <span>labels</span><span>:</span>
            <span>-</span> <span>traefik.http.routers.en_core_web_sm.rule=Host(`api.localhost`) &amp;&amp; PathPrefix(`/en_core_web_sm`)</span>
    <span>en_core_web_lg</span><span>:</span>
        <span>image</span><span>:</span> <span>&lt;your en_core_web_lg model API image&gt;</span>
        <span>labels</span><span>:</span>
            <span>-</span> <span>traefik.http.routers.en_core_web_lg.rule=Host(`api.localhost`) &amp;&amp; PathPrefix(`/en_core_web_lg`)</span>
</code></pre></div></div>
<p>You can now access your corporate website at http://localhost, your <code>en_core_web_sm</code> at http://api.localhost/en_core_web_sm, and your <code>en_core_web_lg</code> at http://api.localhost/en_core_web_lg.</p>
<p>As you can see itâ€™s dead simple.</p>
<p>It was for our local staging only, so we now want to do the same for production in a Docker Swarm cluster:</p>
<div><div><pre><code><span>version</span><span>:</span> <span>'</span><span>3.8'</span>
<span>services</span><span>:</span>
    <span>traefik</span><span>:</span>
        <span>image</span><span>:</span> <span>traefik:v2.4</span>
        <span>ports</span><span>:</span>
            <span>-</span> <span>"</span><span>80:80"</span>
        <span>command</span><span>:</span>
            <span>-</span> <span>--providers.docker.swarmmode</span>
        <span>volumes</span><span>:</span>
            <span>-</span> <span>/var/run/docker.sock:/var/run/docker.sock:ro</span>
        <span>deploy</span><span>:</span>
            <span>placement</span><span>:</span>
                <span>constraints</span><span>:</span>
                    <span>-</span> <span>node.role == manager</span>
    <span>corporate</span><span>:</span>
        <span>image</span><span>:</span> <span>&lt;your corporate image&gt;</span>
        <span>deploy</span><span>:</span>
            <span>labels</span><span>:</span>
                <span>-</span> <span>traefik.http.routers.corporate.rule=Host(`nlpcloud.io`)</span>
    <span>en_core_web_sm</span><span>:</span>
        <span>image</span><span>:</span> <span>&lt;your en_core_web_sm model API image&gt;</span>
        <span>deploy</span><span>:</span>
            <span>labels</span><span>:</span>
                <span>-</span> <span>traefik.http.services.en_core_web_sm.loadbalancer.server.port=80</span>
                <span>-</span> <span>traefik.http.routers.en_core_web_sm.rule=Host(`api.nlpcloud.io`) &amp;&amp; PathPrefix(`/en_core_web_sm`)</span>
    <span>en_core_web_lg</span><span>:</span>
        <span>image</span><span>:</span> <span>&lt;your en_core_web_lg model API image&gt;</span>
        <span>deploy</span><span>:</span>
            <span>labels</span><span>:</span>
                <span>-</span> <span>traefik.http.services.en_core_web_lg.loadbalancer.server.port=80</span>
                <span>-</span> <span>traefik.http.routers.en_core_web_lg.rule=Host(`api.nlpcloud.io`) &amp;&amp; PathPrefix(`/en_core_web_lg`)</span>
</code></pre></div></div>
<p>You can now access your corporate website at http://nlpcloud.io, your <code>en_core_web_sm</code> at http://api.nlpcloud.io/en_core_web_sm, and your <code>en_core_web_lg</code> at http://api.nlpcloud.io/en_core_web_lg.</p>
<p>Itâ€™s still fairly simple but the important things to notice are the following:</p>
<ul>
<li>We should explicitely use the <code>docker.swarmmode</code> provider instead of <code>docker</code></li>
<li>Labels should now be put in the <code>deploy</code> section</li>
<li>We need to manually declare the port of each service by using the <code>loadbalancer</code> directive (this has to be done manually because of Docker Swarm lacking the port auto discovery feature)</li>
<li>We have to make sure that Traefik will be deployed on a manager node of the Swarm by using <code>constraints</code></li>
</ul>
<p>You now have a fully fledge cluster thanks to Docker Swarm and Traefik. Now itâ€™s likely that you have specific requirements and no doubt that the <a href="https://doc.traefik.io/traefik/contributing/documentation/">Trafik documentation</a> will help. But let me show you a couple of features we used at NLP Cloud.</p>
<h2 id="forwarded-authentication">Forwarded Authentication</h2>
<p>Letâ€™s say your NLP API endpoints are protected and users need a token to reach them. A good solution for this use case is to leverage <a href="https://doc.traefik.io/traefik/middlewares/forwardauth/">Traefikâ€™s ForwardAuth</a>.</p>
<p>Basically Traefik will forward all the user requests to a dedicated page you created for the occasion. This page will take care of checking the headers of the request (and maybe extract an authentication token for example) and determine whether the user has the right to access the resource. If it has, the page should return an HTTP 2XX code.</p>
<p>If a 2XX code is returned, Traefik will then make the actual request to the final API endpoint. Otherwise, it will return an error.</p>
<p>Please note that, for performance reasons, Traefik only forwards the user request headers to your authentication page, not the request body. So itâ€™s not possible to authorize a user request based on the body of the request.</p>
<p>Hereâ€™s how to achieve it:</p>
<div><div><pre><code><span>version</span><span>:</span> <span>'</span><span>3.8'</span>
<span>services</span><span>:</span>
    <span>traefik</span><span>:</span>
        <span>image</span><span>:</span> <span>traefik:v2.4</span>
        <span>ports</span><span>:</span>
            <span>-</span> <span>"</span><span>80:80"</span>
        <span>command</span><span>:</span>
            <span>-</span> <span>--providers.docker.swarmmode</span>
        <span>volumes</span><span>:</span>
            <span>-</span> <span>/var/run/docker.sock:/var/run/docker.sock:ro</span>
        <span>deploy</span><span>:</span>
            <span>placement</span><span>:</span>
                <span>constraints</span><span>:</span>
                    <span>-</span> <span>node.role == manager</span>
    <span>corporate</span><span>:</span>
        <span>image</span><span>:</span> <span>&lt;your corporate image&gt;</span>
        <span>deploy</span><span>:</span>
            <span>labels</span><span>:</span>
                <span>-</span> <span>traefik.http.routers.corporate.rule=Host(`nlpcloud.io`)</span>
    <span>en_core_web_sm</span><span>:</span>
        <span>image</span><span>:</span> <span>&lt;your en_core_web_sm model API image&gt;</span>
        <span>deploy</span><span>:</span>
            <span>labels</span><span>:</span>
                <span>-</span> <span>traefik.http.services.en_core_web_sm.loadbalancer.server.port=80</span>
                <span>-</span> <span>traefik.http.routers.en_core_web_sm.rule=Host(`api.nlpcloud.io`) &amp;&amp; PathPrefix(`/en_core_web_sm`)</span>
                <span>-</span> <span>traefik.http.middlewares.forward_auth_api_en_core_web_sm.forwardauth.address=https://api.nlpcloud.io/auth/</span>
                <span>-</span> <span>traefik.http.routers.en_core_web_sm.middlewares=forward_auth_api_en_core_web_sm</span>
    <span>api_auth</span><span>:</span>
        <span>image</span><span>:</span> <span>&lt;your api_auth image&gt;</span>
        <span>deploy</span><span>:</span>
            <span>labels</span><span>:</span>
                <span>-</span> <span>traefik.http.services.en_core_web_sm.loadbalancer.server.port=80</span>
                <span>-</span> <span>traefik.http.routers.en_core_web_sm.rule=Host(`api.nlpcloud.io`) &amp;&amp; PathPrefix(`/auth`)</span>
</code></pre></div></div>
<p>At NLP Cloud, the <code>api_auth</code> service is actually a Django + Django Rest Framework image in charge of authenticating the requests.</p>
<h2 id="custom-error-pages">Custom Error Pages</h2>
<p>Maybe you donâ€™t want to show basic Traefik error pages to users. If so, itâ€™s possible to replace error pages with your custom error pages.</p>
<p>Traefik does not keep any custom error page in memory, but it can use error pages served by one of your services.
When contacting your service in order to retrieve the custom error page, Traefik also passes the HTTP error code as a positional argument, so you can show different error pages based on the HTTP error.</p>
<p>Letâ€™s says we have a small static website served by Nginx that serves your custom error pages. We want to use its error pages for HTTP errors from 400 to 599. Hereâ€™s how you would do it:</p>
<div><div><pre><code><span>version</span><span>:</span> <span>'</span><span>3.8'</span>
<span>services</span><span>:</span>
    <span>traefik</span><span>:</span>
        <span>image</span><span>:</span> <span>traefik:v2.4</span>
        <span>ports</span><span>:</span>
            <span>-</span> <span>"</span><span>80:80"</span>
        <span>command</span><span>:</span>
            <span>-</span> <span>--providers.docker.swarmmode</span>
        <span>volumes</span><span>:</span>
            <span>-</span> <span>/var/run/docker.sock:/var/run/docker.sock:ro</span>
        <span>deploy</span><span>:</span>
            <span>placement</span><span>:</span>
                <span>constraints</span><span>:</span>
                    <span>-</span> <span>node.role == manager</span>
            <span>labels</span><span>:</span>
                <span>-</span> <span>traefik.http.middlewares.handle-http-error.errors.status=400-599</span>
                <span>-</span> <span>traefik.http.middlewares.handle-http-error.errors.service=errors_service</span>
                <span>-</span> <span>traefik.http.middlewares.handle-http-error.errors.query=/{status}.html</span>
    <span>corporate</span><span>:</span>
        <span>image</span><span>:</span> <span>&lt;your corporate image&gt;</span>
        <span>deploy</span><span>:</span>
            <span>labels</span><span>:</span>
                <span>-</span> <span>traefik.http.routers.corporate.rule=Host(`nlpcloud.io`)</span>
                <span>-</span> <span>traefik.http.routers.corporate.middlewares=handle-http-error</span>
    <span>errors_service</span><span>:</span>
        <span>image</span><span>:</span> <span>&lt;your static website image&gt;</span>
        <span>deploy</span><span>:</span>
            <span>labels</span><span>:</span>
                <span>-</span> <span>traefik.http.routers.corporate.rule=Host(`nlpcloud.io/errors`)</span>
</code></pre></div></div>
<p>For example thanks to the example above, a 404 error would now use this page: http://nlpcloud.io/errors/404.html</p>
<h2 id="https">HTTPS</h2>
<p>A cool feature from Traefik â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://juliensalinas.com/en/traefik-reverse-proxy-docker-compose-docker-swarm-nlpcloud/">https://juliensalinas.com/en/traefik-reverse-proxy-docker-compose-docker-swarm-nlpcloud/</a></em></p>]]>
            </description>
            <link>https://juliensalinas.com/en/traefik-reverse-proxy-docker-compose-docker-swarm-nlpcloud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26180044</guid>
            <pubDate>Thu, 18 Feb 2021 14:19:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Proven Tips and Strategies to Increase Organic Traffic to Your Blog in 2021]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26179930">thread link</a>) | @Shehuaba
<br/>
February 18, 2021 | https://yourcontentmart.co/increase-organic-traffic-to-your-blog/ | <a href="https://web.archive.org/web/*/https://yourcontentmart.co/increase-organic-traffic-to-your-blog/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
		<div>
		

	<div id="primary">

		
					<main id="main">
				

<article id="post-1185" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">

	
	
<div>

	
	<!-- .entry-header -->

	
	<div itemprop="text">

		
		
<p>If you run a SaaS business, you probably know by now that search engine traffic (aka organic traffic) is a big deal.</p>



<p>Due to this, the competition to get a top spot in the search engines (especially Google) is becoming stiffer by the day.</p>



<p>Also, search engines work in a really unpredictable manner. Such that, what works previously, might not really work today.</p>



<p>In this post, I want to share with you how to increase organic traffic to your blog in 2021.</p>



<p>These tips and strategies work really well for SaaS businesses, and Iâ€™m going to break it all down for you.</p>



<p>Letâ€™s get started.</p>




<h2><span id="Organic_Search_Engine_Traffic_Why_Is_It_a_Big_Deal"></span><strong>Organic (Search Engine) Traffic: Why Is It a Big Deal?</strong><span></span></h2>



<p>Recent <a href="https://www.brightedge.com/resources/research-reports/content-optimization" target="_blank" rel="noopener">research by BrightEdge</a> shows how important organic traffic is. </p>



<p>According to the report, search engines account for about 51% of all website traffic. Trumping other sources of traffic, such as social media and paid Ads.</p>



<div><figure><img loading="lazy" src="https://yourcontentmart.co/wp-content/uploads/2021/02/BrightEdge-Search-Traffic-Statistic.png" alt="organic traffic statistics by Brightedge" width="512" height="302" srcset="https://yourcontentmart.co/wp-content/uploads/2021/02/BrightEdge-Search-Traffic-Statistic.png 642w, https://yourcontentmart.co/wp-content/uploads/2021/02/BrightEdge-Search-Traffic-Statistic-300x178.png 300w" sizes="(max-width: 512px) 100vw, 512px"></figure></div>



<p>This shows that, if youâ€™re not focusing on optimizing your content to generate high-quality organic traffic as a SaaS business owner, youâ€™re leaving so much on the table.</p>



<p>Another <a href="https://sparktoro.com/blog/the-powerhouses-of-the-internet-are-turning-hostile-to-websites/" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">research conducted by SparkToro</a> also buttresses this fact. </p>



<p>According to them, Google currently accounts for 57.8% of referral traffic on the web. </p>



<p>Aside from Facebook which records 5.2% website traffic, other search engines such as Yahoo and Bing account for 4.3% and 3.7% of website traffic, respectively.</p>



<div><figure><img loading="lazy" src="https://yourcontentmart.co/wp-content/uploads/2021/02/sparktoro-search-engine-traffic-statistic.png" alt="sparktoro organic traffic statistic" width="573" height="340" srcset="https://yourcontentmart.co/wp-content/uploads/2021/02/sparktoro-search-engine-traffic-statistic.png 829w, https://yourcontentmart.co/wp-content/uploads/2021/02/sparktoro-search-engine-traffic-statistic-300x178.png 300w, https://yourcontentmart.co/wp-content/uploads/2021/02/sparktoro-search-engine-traffic-statistic-768x457.png 768w" sizes="(max-width: 573px) 100vw, 573px"></figure></div>



<p>From the above, you can see that in 2021 and beyond, generating organic traffic for your business is uber-important. And this is why a lot of businesses continue to invest heavily on it.</p>



<p>In fact, according to <a aria-label="Borrel Associates, (opens in a new tab)" href="https://www.borrellassociates.com/industry-papers/papers/trends-in-digital-marketing-services-april-16-detail" target="_blank" rel="noreferrer noopener">Borrel Associates,</a> businesses and brands in the United States spent about $79.27 billion on SEO services in 2020.</p>



<div><figure><img loading="lazy" src="https://yourcontentmart.co/wp-content/uploads/2021/02/Borrel-Associates-SEO-spend-statistics.png" alt="Borrel Associates SEO spend statistics 2020" width="585" height="302" srcset="https://yourcontentmart.co/wp-content/uploads/2021/02/Borrel-Associates-SEO-spend-statistics.png 932w, https://yourcontentmart.co/wp-content/uploads/2021/02/Borrel-Associates-SEO-spend-statistics-300x155.png 300w, https://yourcontentmart.co/wp-content/uploads/2021/02/Borrel-Associates-SEO-spend-statistics-768x398.png 768w" sizes="(max-width: 585px) 100vw, 585px"></figure></div>



<p>As you can see, the amount that businesses spend on SEO services continues to increase year over year. If it werenâ€™t that important or getting them results, they would most likely not do so.</p>



<p>Here are some other reasons why organic traffic still matters for you as a SaaS business owner in 2021.</p>



<h3><span id="1_You_Spend_Less_to_Generate_More_User_Signups"></span><strong>1. You Spend Less to Generate More User Signups</strong><span></span></h3>



<p>If youâ€™re looking to get more leads and user signups for your SaaS business and spend less money to do so, then you should leverage organic traffic. </p>



<p>This is because, if you optimize your content for search engines, chances are that youâ€™ll get more results from it in the long run.</p>



<p>According to <a href="https://www.demandmetric.com/content/content-marketing-infographic" target="_blank" rel="noopener">Demand Metric</a>, by using content marketing alone, business owners get results that outperform traditional marketing in terms of ROI.</p>



<div><figure><img loading="lazy" src="https://yourcontentmart.co/wp-content/uploads/2021/02/demand-metric-content-statistics.png" alt="demand metric organic traffic statistic" width="539" height="240"></figure></div>



<p>Also, the amount they spend while doing so is 62% less compared to if they use other traditional forms of marketing.</p>



<h3><span id="2_You_Gain_The_Trust_of_Your_Audience_Easily"></span><strong>2. You Gain The Trust of Your Audience Easily</strong><span></span></h3>



<p>Gaining the trust of your audience sure matters to you as an online business owner. If you want to gain this trust easily, then you should optimize your content for search engines.</p>



<p>When you do, youâ€™re most likely to show up in the SERPs when your target audience search for keywords related to what you do.</p>



<p>Since most people trust results from search engines, chances are that youâ€™ll gain their trust that way.</p>



<pre><strong>Fun fact,: About <a href="https://www.techclient.com/blogging-statistics/" target="_blank" rel="noopener">61% of consumers in the US</a> have made a purchase after stumbling on a blog post.</strong></pre>



<h3><span id="3_You_Get_Website_Traffic_On_Autopilot"></span><strong>3.</strong> <strong>You Get Website Traffic On Autopilot</strong><span></span></h3>



<p>This is one of the most important reasons why organic traffic continues to be useful. </p>



<p>If you create content and optimize it for search engines, youâ€™ll continue getting website visitors and traffic on autopilot.</p>



<p>Unlike paid Ads where you need to spend money each time you want to get more traffic to your website. With search engine traffic, you only need to set it up once and youâ€™ll continue getting targeted traffic without lifting a finger.</p>



<p>Sounds cool isnâ€™t it?</p>



<p>So, how exactly do you increase organic traffic to your blog in 2021.</p>



<p>Letâ€™s get to it.</p>



<h2><span id="How_To_Increase_Organic_Traffic_To_Your_Blog_Using_These_Proven_Tips_Strategies"></span><strong>How To Increase Organic Traffic To Your Blog Using These Proven Tips &amp; Strategies</strong><span></span></h2>



<p>You can see from the above that organic traffic is important and anyone running an online focus a lot on it. </p>



<p>What if I tell you that, most people who create content and optimize it for search engines do not get any results from it.</p>



<p>Youâ€™re surprised, right?</p>



<p>Well, donâ€™t be.</p>



<p><a aria-label=" (opens in a new tab)" href="https://ahrefs.com/blog/search-traffic-study/" target="_blank" rel="noreferrer noopener">Research by Ahrefs</a> proves that this is the case. According to them, 90.63% of the content published online, do not get any traffic from Google.</p>



<div><figure><img loading="lazy" src="https://yourcontentmart.co/wp-content/uploads/2021/02/Ahrefs-organic-traffic-statistic.png" alt="Ahrefs organic traffic statistic" width="519" height="405" srcset="https://yourcontentmart.co/wp-content/uploads/2021/02/Ahrefs-organic-traffic-statistic.png 679w, https://yourcontentmart.co/wp-content/uploads/2021/02/Ahrefs-organic-traffic-statistic-300x234.png 300w" sizes="(max-width: 519px) 100vw, 519px"></figure></div>



<p>This shows that optimizing your content for search engines isnâ€™t just enough in 2021. </p>



<p>You need to go the extra mile if you want to get any tangible results.</p>



<p>Still wondering how to increase organic traffic to your blog in 2021? Here are 4 proven tips and strategies you should implement right now.</p>



<h3><span id="1_Start_With_a_Solid_Foundation"></span><strong>1. Start With a Solid Foundation</strong><span></span></h3>



<p>If you want to get any form of results from organic traffic, then you should start with a solid foundation. </p>



<p>If you donâ€™t, youâ€™ll most likely fail with it.</p>



<p>The foundation that any SaaS business which optimizes for search engine traffic should start with, is <strong>keyword research</strong>.</p>



<p>The reason is simple.</p>



<p>If you create content that nobody is searching for, your chance of getting any search traffic from it is slim.</p>



<p>So, when you perform keyword research, youâ€™ll understand exactly what your target audience is searching for.&nbsp;</p>



<p>That way, you can create content that ranks well and get traffic for you from these search engines.</p>



<h4><strong>But, How Do You Get Started With Keyword Research For a SaaS Business</strong>?</h4>



<p>Simple, by doing a Google search. </p>



<p>Say, your SaaS business is in the productivity niche, you can type the keyword â€œproductivity tipsâ€ into Google.</p>



<p>When you do, itâ€™ll auto-suggest other keywords that people are actively searching for which are related to this root keyword.</p>



<div><figure><img loading="lazy" src="https://yourcontentmart.co/wp-content/uploads/2021/02/productivity-tips-Google-autosuggest.png" alt="keyword research on Google" width="536" height="418" srcset="https://yourcontentmart.co/wp-content/uploads/2021/02/productivity-tips-Google-autosuggest.png 707w, https://yourcontentmart.co/wp-content/uploads/2021/02/productivity-tips-Google-autosuggest-300x234.png 300w" sizes="(max-width: 536px) 100vw, 536px"></figure></div>



<p>From this, you can see that some of the keywords that your audience is also searching for include â€œproductivity tips for working from homeâ€, â€œproductivity tips for workâ€, â€œproductivity tips for entrepreneursâ€, â€œproductivity tips for small business ownersâ€ and so on.</p>



<p>With this information, you have an idea of some potential keywords that you can target for your content. </p>



<p>However, you donâ€™t know exactly the number of people searching for each of them.</p>



<p>While you can go ahead and write about any of these topics, you can take it a step further by knowing the approximate number of people searching for these keywords. </p>



<p>To do this, there are free tools and paid tools which you can use.</p>



<p>Some of the free options are <a href="https://ads.google.com/home/tools/keyword-planner/" target="_blank" rel="noopener">Google Keyword Planner</a> and <a href="https://neilpatel.com/ubersuggest/" target="_blank" rel="noopener">UberSuggest</a>. </p>



<p>The paid tools alternative include <a href="https://moz.com/" target="_blank" rel="noopener">Moz</a>, <a href="https://ahrefs.com/" target="_blank" rel="noopener">Ahrefs</a>, <a href="https://www.semrush.com/" target="_blank" rel="noopener">SEMrush</a>, and so on.</p>



<p>For the sake of this post, Iâ€™ll use SEMrush.</p>



<p>Letâ€™s say, you want to target â€œproductivity tipsâ€ as the keyword to write on.&nbsp; </p>



<p>All you need to do is hop on to SEMrushâ€™s Keyword Magic Tool and enter your target keyword and hit search:</p>



<div><figure><img loading="lazy" src="https://yourcontentmart.co/wp-content/uploads/2021/02/SEMrush-Keyword-Magic-Tool.png" alt="SEMrush Keyword Magic Tool" width="591" height="216" srcset="https://yourcontentmart.co/wp-content/uploads/2021/02/SEMrush-Keyword-Magic-Tool.png 843w, https://yourcontentmart.co/wp-content/uploads/2021/02/SEMrush-Keyword-Magic-Tool-300x110.png 300w, https://yourcontentmart.co/wp-content/uploads/2021/02/SEMrush-Keyword-Magic-Tool-768x282.png 768w" sizes="(max-width: 591px) 100vw, 591px"></figure></div>



<p>Once you do, itâ€™ll give you a comprehensive insight and report about that target keyword</p>



<div><figure><img loading="lazy" src="https://yourcontentmart.co/wp-content/uploads/2021/02/productivity-tips-SEMrush-keyword-research.png" alt="productivity tips SEMrush keyword research" width="556" height="376" srcset="https://yourcontentmart.co/wp-content/uploads/2021/02/productivity-tips-SEMrush-keyword-research.png 906w, https://yourcontentmart.co/wp-content/uploads/2021/02/productivity-tips-SEMrush-keyword-research-300x203.png 300w, https://yourcontentmart.co/wp-content/uploads/2021/02/productivity-tips-SEMrush-keyword-research-768x520.png 768w" sizes="(max-width: 556px) 100vw, 556px"></figure></div>



<p>As you can see, the root keyword â€œproductivity tipsâ€ has a search volume of 1000.</p>



<p>What this means is that, there are approximately 1000 persons searching for this keyword on Google.</p>



<p>Other related keywords such as â€œadhd productivity tipsâ€ â€œtranscription productivity tipsâ€ and â€œproductivity tips for working from homeâ€ has a search volume of 70, 70, and 110 respectively.</p>



<blockquote><p><strong>One thing to take note of is that the keyword volume is just an estimation. The exact number of persons searching for that keyword might be less or more than that.</strong></p></blockquote>



<p>With SEMrush, you can filter for different criteria such as volume, keyword difficulty, CPC, and so on. </p>



<p>After performing keyword research, you now have an idea of what your target audience is interested in, then you can proceed to the next strategy.</p>



<blockquote><p><em><strong>Additional Resources to Learn More About Keyword Research</strong></em></p><p>1. <a href="https://ahrefs.com/blog/keyword-research/" target="_blank" aria-label="Keyword Research: The Beginner's Guide By Ahrefs (opens in a new tab)" rel="noreferrer noopener"><strong>Keyword Research: The Beginnerâ€™s Guide By Ahrefs</strong></a></p><p>2. <a href="https://backlinko.com/keyword-research" target="_blank" rel="noopener"><strong>Keyword Research For SEO: The Definitive Guide</strong></a></p><p>3. <a href="https://neilpatel.com/blog/keyword-research/" target="_blank" rel="noopener"><strong>The Guide to Keyword Research By Neil Patel</strong></a></p></blockquote>



<h3><span id="2_Address_Your_Readers_Pain_Points_and_Solve_Them_Genuinely"></span><strong>2. Address Your Readersâ€™ Pain Points and Solve Them Genuinely</strong><span></span></h3>



<p>After keyword research, the next thing you need to do is create content.</p>



<p>While there is a lot of emphasis on creating content, thereâ€™s still a lot of grounds to cover in that regard. </p>



<p>This is because a lot of content out there is fluffy, hence donâ€™t generate organic traffic.</p>



<p>Here is how to create content that drives traffic from search engines.</p>



<h4><strong>Publish long-form Content</strong></h4>



<p>If you want to create content that genuinely helps your target audience, then you should focus on publishing long-form content.&nbsp;</p>



<p>The reason is simple. T</p>



<p>hereâ€™s a high chance of solving your target audienceâ€™s problems when you publish long-form content. As theyâ€™re more detailed and generally thorough.</p>



<p>Also, numerous industry researches have shown that long-form content outperforms short-form content.</p>



<p>In a recent research, Backlinko found out that the <a href="https://backlinko.com/search-engine-ranking" target="_blank" rel="noopener">average length of posts on Googleâ€™s first page is 1890 words</a>.</p>



<div><figure><img loading="lazy" src="https://yourcontentmart.co/wp-content/uploads/2021/02/backlinko-content-marketing-statistic.png" alt="backlinko content marketing statistic" width="545" height="378" srcset="https://yourcontentmart.co/wp-content/uploads/2021/02/backlinko-content-marketing-statistic.png 737w, https://yourcontentmart.co/wp-content/uploads/2021/02/backlinko-content-marketing-statistic-300x208.png 300w" sizes="(max-width: 545px) 100vw, 545px"></figure></div>



<p>Hence, if you want to stand any chance of getting traffic from search engines, you should publish long-form content.</p>



<h4><strong>Create Content that Matches Search Intent</strong></h4>



<p>If you Google â€œ<strong>educational content marketing</strong>â€œ, youâ€™ll find out that <a aria-label="this article I wrote on Winsome Writer (opens in a new tab)" href="https://winsomewriter.com/educational-content-marketing-strategies/" target="_blank" rel="noreferrer noopener">this article I wrote on Winsome Writer</a> currently ranks number 1 on the first page of Google.</p>



<div><figure><img loading="lazy" src="https://yourcontentmart.co/wp-content/uploads/2021/02/winsomewriter-post-that-ranks-no-1-on-Google.png" alt="educational content marketing" width="618" height="317" srcset="https://yourcontentmart.co/wp-content/uploads/2021/02/winsomewriter-post-that-ranks-no-1-on-Google.png 832w, https://yourcontentmart.co/wp-content/uploads/2021/02/winsomewriter-post-that-ranks-no-1-on-Google-300x154.png 300w, https://yourcontentmart.co/wp-content/uploads/2021/02/winsomewriter-post-that-ranks-no-1-on-Google-768x395.png 768w" sizes="(max-width: 618px) 100vw, 618px"></figure></div>



<p>Thatâ€™s not allâ€¦</p>



<p>I also rank above some of the biggest brands such as Content Marketing Institute, Izea, Convince and Convert, Forbes, and so on for this keyword.</p>



<div><figure><img loading="lazy" src="https://yourcontentmart.co/wp-content/uploads/2021/02/ranking-above-CMI-and-co.png" alt="ranking above my competitors" width="571" height="524" srcset="https://yourcontentmart.co/wp-content/uploads/2021/02/ranking-above-CMI-and-co.png 714w, https://yourcontentmart.co/wp-content/uploads/2021/02/ranking-above-CMI-and-co-300x276.png 300w" sizes="(max-width: 571px) 100vw, 571px"></figure></div>



<p>So, how did I do it?</p>



<p>By creating content that meet the search intent of my audience. When you do this, your content will definitely get traffic from search engines.</p>



<p>By search intent, I mean, ensuring that your content answers the questions of your audience correctly.</p>



<p>And guess what, with a simple Google search, you can easily and evaluate the search intent of a particular topic.</p>



<p>Hereâ€™s an example:</p>



<p>Say you want to write a post targeting the keyword: <strong><em>â€œresources for freelance writersâ€</em></strong></p>



<p>You can search for this keyword on â€¦</p></div></div></article></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://yourcontentmart.co/increase-organic-traffic-to-your-blog/">https://yourcontentmart.co/increase-organic-traffic-to-your-blog/</a></em></p>]]>
            </description>
            <link>https://yourcontentmart.co/increase-organic-traffic-to-your-blog/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179930</guid>
            <pubDate>Thu, 18 Feb 2021 14:07:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Browsers eating RAM]]>
            </title>
            <description>
<![CDATA[
Score 131 | Comments 134 (<a href="https://news.ycombinator.com/item?id=26179817">thread link</a>) | @todsacerdoti
<br/>
February 18, 2021 | https://www.flotato.com/post/memory-chrome-safari-flotato | <a href="https://web.archive.org/web/*/https://www.flotato.com/post/memory-chrome-safari-flotato">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>I reached a point where I could barely hear the podcast I was trying to listen to. That's how loud the fan was. Then I&nbsp;closed down all open Chrome windows, and a few minutes after, the fan went silent. So I decided to see if it was just me.</p><div href=""><h3>How I&nbsp;measured</h3><p>I&nbsp;ran the 2-tab test in a completely fresh macOS install on a virtual machine. Then I ran the 54-tabs test on my own Big Sur installation, but with all extensions disabled. To record a usage snapshot ~250 times per second, I&nbsp;used <a href="https://github.com/astrofrog/psrecord">psrecord.</a></p></div><div><h2>2&nbsp;tabs:&nbsp;Twitter, then Gmail</h2><p>To simulate a realistic environment, I&nbsp;did the same steps on Safari, then Chrome:&nbsp;Go to twitter.com, scroll around, then open a new tab with Gmail and open an email. A dot means I interacted with the system. You can hover a dot to see what I&nbsp;did. </p></div><div><h3>Putting Flotato to the test</h3><p>To be light-weight, Flotato doesn't just run a stripped down, Safari-backed web view, it also defaults to the mobile version if one is available. Here's Flotato compared to a regular session in Safari. Note the slightly lower CPU usage. It's kind of hard to put a finger on what exactly the mobile version isn't calculating that the desktop version is; the two versions are almost identical when you use them.</p></div><div><h2>54 tabs:&nbsp;the stress test</h2><p>I&nbsp;bet you have more than 2 tabs open right now, I&nbsp;sure have more. So here's a stress test where I&nbsp;open 54 tabs while measuring the impact on my Mac's RAM and CPU. A dot means I&nbsp;opened a new tab. Hover the dot to see which site I&nbsp;opened.</p></div><div><h2>Is it bad?</h2><p>When I saw the results I got suspicious. Chrome was using way more memory than I thought it would. Maybe it was the virtual machine blocking Chrome's direct access to my Macbook's* GPU?&nbsp;I&nbsp;decided to run the next test, the one with 54 tabs directly on my own Big Sur installation. The results were, well, slightly worse.</p><h3>The graphs don't tell the full story</h3><p>But it's probably not as bad as it looks. It's not a terrible thing that an app actually <em>uses</em> your computer. And you've got to hand it to Chrome:&nbsp;it is fast! </p><p>I'm sure Chrome is going out of its way to manage its memory usage across tabs, keeping the current tab fast and responsive. That's great if you're not running any other macOS apps than Chrome, effectively using Chrome as your operating system, and macOS&nbsp;as a kind of bootloader. </p><p>But when you're using Sketch, Final Cut, Photoshop next to Chrome, that seems to be a problem. MacOS&nbsp;likely tries to tell Chrome to take it easy, and Chrome likely <em>does</em> take it easy. These graphs don't tell that story. </p><p>So no, it's most likely not as bad as it looks, but that doesn't change the fact since switching to Safari, I almost forgot what my fan sounds like.</p><p>And then there's <em>this</em> chart. As we can see, the two browsers heat up the computer almost to the exact same level - Safari even getting slightly warmer. This probably points to psutil not being able to see all Safari's child processes, but only the main ones â€” despite the fact that Activity Monitor is able to group them. That's a little confusing. </p><figure><p><img src="https://uploads-ssl.webflow.com/5e78c687e58e25134b3fb751/602feb36d1388bb94f881998_EumcL7jXYAEBG_4.png" alt="Image"></p></figure><p>â€</p><p>â€</p><p><em>*&nbsp;Macbook 16" from 2019 with2.4 GHz, 8-Core Intel Core i9 with 32&nbsp;GB&nbsp;2667 MHz DDR4 RAM and an AMD&nbsp;Radeon Pro 5500M 8GB GPU</em></p></div></div>]]>
            </description>
            <link>https://www.flotato.com/post/memory-chrome-safari-flotato</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179817</guid>
            <pubDate>Thu, 18 Feb 2021 13:56:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Advanced Types in TypeScript]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26179620">thread link</a>) | @mooreds
<br/>
February 18, 2021 | https://www.geekabyte.io/2021/01/introduction-to-advance-types-in.html | <a href="https://web.archive.org/web/*/https://www.geekabyte.io/2021/01/introduction-to-advance-types-in.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-5372611965284124411" itemprop="description articleBody">
<p>This is the start of a series of posts where I take a look at aspects of TypeScript's type system that can be referred to as "Advanced".&nbsp; See this as an exploration of TypeScriptâ€™s type system past <span>Classes</span> and <span>Interfaces</span>.</p><p>A good mental model to have when exploring the advanced part of TypeScript type system is to see it as a more sophisticated mechanism for creating types.&nbsp;</p><p>The normal, non-advanced ways of creating types in TypeScript involve using features of the language like <span>type alias</span>,&nbsp; <span>class</span> and <span>interface</span>.&nbsp;</p>

<p>For example these:&nbsp;</p>

<pre><code>interface IPerson {
  name: string
  age: number
}

type TPerson = {
  name: string
  age: number
}

class CPerson {
  constructor(private name:string, private age: number) {}
  
  getName() {
    return this.name;
  }

  getAge() {
    return this.name;
  }
}
</code></pre>



<p>With the advanced type features, types can be constructed directly or indirectly based on other existing types. How exactly this is done, will be the subject of this series of posts.</p><p>The posts in the series include:</p><ul><li><a href="https://www.geekabyte.io/2021/01/introduction-to-generics-in-typescript.html">Introduction to Generics in TypeScript</a></li><li><a href="https://www.geekabyte.io/2021/01/generic-constraints-methods-and.html">Generic Constraints and More</a></li><li><a href="https://www.geekabyte.io/2021/01/union-and-intersection-types-in.html">Union and Intersection Types</a></li><li><a href="https://www.geekabyte.io/2021/02/literal-and-template-literal-types.html">Literal and Template Literal Types</a></li><li><a href="https://www.geekabyte.io/2021/02/using-literal-and-template-literal.html">Using Literal and Template Literal Types in TypeScript</a></li><li><a href="https://www.geekabyte.io/2021/02/overview-of-indexable-types-in.html">Overview of Indexable Types in TypeScript</a></li><li>Indexed Access Types and KeyOf - <i>Published soon</i></li><li>Type Queries: Typeof operator - <i>Published soon</i></li><li>Conditional Types - <i>Published soon</i></li><li>Mapped Types - <i>Published soon</i></li></ul>

</div></div>]]>
            </description>
            <link>https://www.geekabyte.io/2021/01/introduction-to-advance-types-in.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179620</guid>
            <pubDate>Thu, 18 Feb 2021 13:36:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Curl is C (2017)]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 65 (<a href="https://news.ycombinator.com/item?id=26179601">thread link</a>) | @taf2
<br/>
February 18, 2021 | https://daniel.haxx.se/blog/2017/03/27/curl-is-c/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2017/03/27/curl-is-c/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>For some reason, this post got picked up again and is <a href="https://news.ycombinator.com/item?id=26179601">debated today</a> in 2021, almost 4 years since I wrote it. Some things have changed in the mean time and I mightâ€™ve phrased a few things differently if I had written this today. But still, whatâ€™s here below is what I wrote back then. Enjoy!</p>



<div><figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_.png"><img loading="lazy" width="348" height="450" src="https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_-348x450.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_-348x450.png 348w, https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_-155x200.png 155w, https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_-768x992.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_.png 792w" sizes="(max-width: 348px) 100vw, 348px"></a></figure></div>



<p>Every once in a while someone suggests to me that curl and libcurl would do better if rewritten in a â€œsafe languageâ€. Rust is one such alternative language commonly suggested. This happens especially often when we publish new security vulnerabilities. (Update: I think Rust is a fine language! This post and my stance here has nothing to do with what I think about Rust or other languages, safe or not.)</p>



<h2>curl is written in C</h2>



<p>The curl code guidelines mandate that we stick to using C89 for any code to be accepted into the repository. C89 (sometimes also called C90) â€“ the oldest possible ANSI C standard. Ancient and conservative.</p>



<h2>C is everywhere</h2>



<p>This fact has made it possible for projects, companies and people to adopt curl into things using basically any known operating system and whatever CPU architecture you can think of (at least if it was 32bit or larger). No other programming language is as widespread and easily available for <em>everything</em>. This has made curl one of the most portable projects out there and is part of the explanation for curlâ€™s success.</p>



<p>The curl project was also started in the 90s, even long before most of these alternative languages youâ€™d suggest, existed. Heck, for a truly stable project it wouldnâ€™t be responsible to go with a language that isnâ€™t even old enough to start school yet.</p>



<h2>Everyone knows C</h2>



<p>Perhaps not necessarily true anymore, but at least the knowledge of C is very widespread, where as the current existing alternative languages for sure have more narrow audiences or amount of people that master them.</p>



<h2>C is not a safe language</h2>



<p>Does writing safe code in C require more carefulness and more â€œtricksâ€ than writing the same code in a more modern language better designed to be â€œsafeâ€ ? Yes it does. But weâ€™ve done most of that job already and maintaining that level isnâ€™t as hard or troublesome.</p>



<p>We keep scanning the curl code regularly with static code analyzers (we maintain a <em>zero <a href="https://scan.coverity.com/projects/curl">Coverity</a> problems</em> policy) and we run the test suite with <a href="http://valgrind.org/">valgrind</a> and <a href="https://en.wikipedia.org/wiki/AddressSanitizer">address sanitizers</a>.</p>



<h2>C is not the primary reason for our past vulnerabilities</h2>



<p>There. The simple fact is that most of our past vulnerabilities happened because of logical mistakes in the code. Logical mistakes that arenâ€™t really language bound and they would not be fixed simply by changing language.</p>



<p>Of course that leaves a share of problems that couldâ€™ve been avoided if we used another language. Buffer overflows, double frees and out of boundary reads etc, but the bulk of our security problems has not happened due to curl being written in C.</p>



<h2>C is not a new dependency</h2>



<p>It is easy for projects to add a dependency on a library that is written in C since thatâ€™s what operating systems and system libraries are written in, still today in 2017. Thatâ€™s the default. Everyone can build and install such libraries and theyâ€™re used and people know how they work.</p>



<p>A library in another language will add that language (and compiler, and debugger and whatever dependencies a libcurl written in that language would need) as a new dependency to a large amount of projects that are themselves written in C or C++ today. Those projects would in many cases downright ignore and reject projects written in â€œan alternative languageâ€.</p>



<h2>curl sits in the boat</h2>



<p>In the curl project weâ€™re deliberately conservative and we stick to old standards, to remain a viable and reliable library for everyone. Right now and for the foreseeable future. Things that worked in curl 15 years ago still work like that today. The same way. Users can rely on curl. We stick around. We donâ€™t knee-jerk react to modern trends. We sit still in the boat. We donâ€™t rock it.</p>



<h2>Rewriting means adding heaps of bugs</h2>



<p>The plain fact, that also isnâ€™t really about languages but is about plain old software engineering: translating or rewriting curl into a new language will introduce a lot of bugs. Bugs that we donâ€™t have today.</p>



<p>Not to mention how rewriting would take a huge effort and a lot of time. That energy can instead today be spent on improving curl further.</p>



<h2>What if</h2>



<p><em>If I would start the project today, would Iâ€™ve picked another language?</em> Maybe. Maybe not. If memory safety and related issues was the primary concern I had, then sure. But as Iâ€™ve mentioned above there are several others concerns too so it would really depend on my priorities.</p>



<h2>Finally</h2>



<p>At the end of the day the question that remains is: would we gain more than we would pay, and over which time frame? Who would gain and who would lose?</p>



<p>Iâ€™m sure that there will be or it may even already exist, curl and libcurl competitors and potent alternatives written in most of these new alternative languages. Some of them are absolutely really good and will get used and reach fame and glory. Some of them will be crap. Just like software always work. Let a thousand curl competitors bloom!</p>



<p>Will curl be rewritten at some point in the future? I wonâ€™t rule it out, but I find it unlikely. I find it even more unlikely that it will happen in the short term or within the next few years.</p>



<p>Discuss this post on <a href="https://news.ycombinator.com/item?id=13966241">Hacker news</a> or <a href="https://www.reddit.com/r/programming/comments/61rh9j/curl_is_c/">Reddit</a>!</p>



<p><strong>Followup-post: </strong><a href="https://daniel.haxx.se/blog/2017/03/30/yes-c-is-unsafe-but/">Yes, C is unsafe, butâ€¦</a></p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2017/03/27/curl-is-c/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179601</guid>
            <pubDate>Thu, 18 Feb 2021 13:34:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Proof of work: the reason behind Bitcoinâ€™s horrendous energy consumption]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26179585">thread link</a>) | @throw0101a
<br/>
February 18, 2021 | https://amycastor.com/2021/02/17/proof-of-work-the-reason-behind-bitcoins-horrendous-energy-consumption/ | <a href="https://web.archive.org/web/*/https://amycastor.com/2021/02/17/proof-of-work-the-reason-behind-bitcoins-horrendous-energy-consumption/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-6038">
		<div>
		
<p>Any company that supports bitcoin is making one thing clear: they donâ€™t care about the environment. At a time when global warming is a real threat to the planet, bitcoin is one of the worst offenders.&nbsp;</p>



<p>The global network of computers that â€œmineâ€ bitcoin consumes an entire countryâ€™s worth of energy in their race to win the next block on the blockchainâ€”and get the 6.25 bitcoin block reward, currently worth $300,000.&nbsp;</p>



<p>Since PayPal, Square, MicroStrategy, and <a href="https://amycastor.com/2021/02/08/tesla-spent-1-5b-in-clean-car-credits-on-bitcoin-the-filthiest-asset-imaginable/" target="_blank" rel="noreferrer noopener">Tesla</a> got onto the gameâ€”and started shilling bitcoin on social mediaâ€”the price of bitcoin has soared to new heights. And the higher the bitcoin price, the greater the lure for people to invest in warehouses full of power-hungry rigs to mine bitcoin for profit. </p>



<p>Digiconomistâ€™s <a href="https://digiconomist.net/bitcoin-energy-consumption" target="_blank" rel="noreferrer noopener">Bitcoin Energy Consumption Index,</a> run by Alex de Vries, a blockchain specialist at Big Four accounting firm PwC, estimates bitcoinâ€™s energy consumption to be 79 terawatt-hours of electricity per year, on par with the entire country of Chile. Per his index, bitcoin also emits 37 megatons of carbon dioxide per year, comparable to that of New Zealand.&nbsp;&nbsp;</p>



<p>Researchers at the University of Cambridge Judge Business School figure bitcoinâ€™s power consumption to be even higher. According to their <a href="https://cbeci.org/" target="_blank" rel="noreferrer noopener">Cambridge Bitcoin Electricity Consumption Index,</a> bitcoin consumes 124 terawatt-hours of electricity a year, bringing it inline with countries like Argentina and Norway.</p>



<p>In October, just before PayPal announced it would allow users to buy and sell bitcoin via their digital wallets, bitcoinâ€™s power consumption was 75 terawatt-hours per year, according to the CBECI. Since then, bitcoinâ€™s price climbed from $10,000 to upwards of $50,000, increasing its energy consumption by 40 percent the process.</p>



<p>In 2018, all of the worldâ€™s data centers consumed <a href="https://science.sciencemag.org/content/367/6481/984" target="_blank" rel="noreferrer noopener">205 terawatt-hours of electricity,</a> or 1% of all of the worldâ€™s electricity. Bitcoin accounts for half of that. </p>



<p>Can the worldâ€™s power grids tolerate this added demand for electricity in the midst of global warming? In the U.S., we are already seeing the impact of extreme weather on our power gridsâ€”millions in Texas <a href="https://www.nbcnews.com/news/weather/millions-texans-left-shivering-arctic-cold-without-power-n1257959" target="_blank" rel="noreferrer noopener">shivering in cold, dark homes</a> this week. And <a href="https://www.politico.com/states/california/story/2020/08/18/california-has-first-rolling-blackouts-in-19-years-and-everyone-faces-blame-1309757" target="_blank" rel="noreferrer noopener">rolling black outs in California</a> last year. In Iran last month, authorities blamed <a href="https://www.washingtonpost.com/world/2021/01/16/massive-blackouts-have-hit-iran-government-is-blaming-bitcoin/" target="_blank" rel="noreferrer noopener">massive blackouts on bitcoin mining.</a>  </p>



<h2><strong>Coal powered&nbsp;&nbsp;</strong></h2>



<p>And bitcoinâ€™s energy consumption isnâ€™t green eitherâ€”though bitcoiners like to say that it is. Bitcoin miners are tuned to profits. That means the fastest rigs and the cheapest energy available, mostly in the form of fossil fuels.&nbsp;</p>



<p>â€œCoal is fueling bitcoin,â€ Christian Stoll, an energy researcher at the Technical University of Munich, told <a href="https://www.wired.com/story/bitcoins-climate-impact-global-cures-local/?mbid=social_twitter&amp;mbid=social_twitter&amp;utm_brand=wired&amp;utm_brand=wired&amp;utm_campaign=wired&amp;utm_campaign=wired&amp;utm_medium=social&amp;utm_medium=social&amp;utm_social-type=owned&amp;utm_social-type=owned&amp;utm_source=twitter&amp;utm_source=twitter" target="_blank" rel="noreferrer noopener">Wired magazine</a> a few years ago.&nbsp;&nbsp;</p>



<p>In <a href="https://www.cell.com/joule/fulltext/S2542-4351(19)30255-7" target="_blank" rel="noreferrer noopener">a paper published in <em>Joule</em></a> in June 2019, Stoll and his researchers examined bitcoin mining based on where miners are located and the types of rigs they use. Two-thirds of all bitcoin mining is centered in China, 17% is in Europe, and 15% in North America, the researchers found.&nbsp;</p>



<p>In China, bitcoinâ€™s mining is spread throughout the countryâ€™s sprawling western provinces, Sichuan and Yunnan, and also in the north, in Xinjiang and Mongolia. In the Sichuan province, where about 58% of the worldâ€™s bitcoin mining takes place, miners take advantage of cheap hydroelectric powerâ€”but only during the rainy season, which lasts about six months.&nbsp;</p>



<p>Bitcoin is a 24/7 business, however, and when green energy isnâ€™t availableâ€”and the price of bitcoin is high enough to reap a profit in the dry seasonâ€”the miners in Sichuan turn to coal, the countryâ€™s most abundant energy source. <a href="https://www.iea.org/data-and-statistics?country=CHINA&amp;fuel=Energy%20supply&amp;indicator=ElecGenByFuel" target="_blank" rel="noreferrer noopener">Sixty-five percent of Chinaâ€™s electricity comes from coal.</a>&nbsp;Bitcoin miners in the Xinjiang province and inner Mongolia also rely heavily on coal-fired electricity.&nbsp;</p>



<p>Even when bitcoin uses clean energy, that pushes the use of dirty energy elsewhere. A few years ago, HyperBlock, a bitcoin mine in Missoula County, Montana, struck a deal with a nearby dam for cheap renewable power. They thought they were doing it right, until county officials noted that if energy from the dam went to bitcoin mining, the county as a whole would end up using more coal. </p>



<p>That was the end of that. <a href="https://www.wired.com/story/montana-county-crimp-bitcoin-save-the-earth/" target="_blank" rel="noreferrer noopener">In April 2019,</a> Missoula required all future mines to purchase or build their own renewable power. And soon after the price of bitcoin crashed in March 2020â€”slipping down to below $5,000â€”HyperBlock <a href="https://missoulian.com/news/local/bonner-bitcoin-company-ceases-operations/article_789d8594-f17c-5809-a8fe-918ad226266e.html" target="_blank" rel="noreferrer noopener">declared bankruptcy</a> because it could not pay its power bills.</p>



<h2><strong>Bitcoin mining and proof of work</strong></h2>



<p>Why is bitcoin so inefficient? It turns out that the system uses copious amounts energy not by accident but by design. </p>



<p>Satoshi Nakomoto, bitcoinâ€™s pseudonymous creator, had to figure out a way to solve the <a href="https://en.wikipedia.org/wiki/Double-spending" target="_blank" rel="noreferrer noopener">double-spend problem.</a> We donâ€™t have this problem with paper money. But with digital money, someone could copy the file and use it to spend the funds over and over, rendering the currency useless.&nbsp;</p>



<p>In a centralized system, a trusted third-party, like a bank, checks the digital money you spend against a central ledger to make sure thereâ€™s no funny business going on. But bitcoinâ€™s ledger (the blockchain) is decentralized, which makes the double-spend problem harder to solve.&nbsp;&nbsp;</p>



<p>The solution Satoshi came up with was a clever hack that involves bitcoin mining and proof-of-work. In bitcoin, mining is the process of adding new transactions to the blockchain, and proof-of-work secures the network so transactions canâ€™t be reversed. You would need more than half of all the computing power on the bitcoin network to double-spend a bitcoin.&nbsp;</p>



<p>It wasnâ€™t a perfect solution, but Satoshi solved what computer scientists had long thought was unsolvable: how to build a decentralized payment system. The irony is, unless you are collecting payments for <a href="https://news.bitcoin.com/ransomware-ryuk-rakes-in-150-million-in-bitcoin/" target="_blank" rel="noreferrer noopener">ransomware,</a> bitcoin has proven <a href="https://www.wsj.com/articles/why-bitcoin-hasnt-gained-traction-as-a-form-of-payment-11612886974" target="_blank" rel="noreferrer noopener">unusable as a payment system.</a> No merchant wants to risk their profit margin on bitcoinâ€™s volatility. </p>



<p>Today, bitcoin functions mainly as a <a href="https://www.coindesk.com/store-of-value-remains-cryptos-best-use-case" target="_blank" rel="noreferrer noopener">speculative investment,</a> getting scooped up by retailers and venture capitalistsâ€”and now big companies and <a href="https://cointelegraph.com/news/pension-funds-are-getting-in-on-bitcoin-according-to-grayscalehttps://www.hedgeweek.com/2021/01/19/294600/bitcoins-inefficiencies-are-creating-arbitrage-trades-crypto-hedge-funds" target="_blank" rel="noreferrer noopener">hedge funds</a>â€”in the hopes the price will go ever skyward.  &nbsp;</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">$250k by end of 2022. Just 5X from here. Looking a lot more likely than when I made the initial prediction three years ago, eh? <a href="https://twitter.com/hashtag/Bitcoin?src=hash&amp;ref_src=twsrc%5Etfw">#Bitcoin</a></p>â€” Tim Draper (@TimDraper) <a href="https://twitter.com/TimDraper/status/1362131856544702469?ref_src=twsrc%5Etfw">February 17, 2021</a></blockquote></div>
</div></figure>



<h2>Winning the lottery</h2>



<p>Bitcoin miners have their eyes feasted on the bitcoin block reward. </p>



<p>Every 10 minutes, the bitcoin network adds a new block to the blockchain, minting 900 new bitcoins a day in the process. That block reward is reduced by half every four years. Prior to May 2020, the bitcoin block reward was 12.5 bitcoinsâ€”double what it is nowâ€”and the network produced 1,800 new bitcoins per day. And around February 2024,* the block reward will be 3.125 bitcoins. </p>



<p>When you request a transaction on the bitcoin blockchain, your transaction goes into the <a rel="noreferrer noopener" href="https://www.blockchain.com/charts/mempool-size" target="_blank">bitcoin mempool,</a> a waiting area for unconfirmed bitcoin transactions. Miners select transactions from the poolâ€”usually the ones with the highest transaction feesâ€”and package those into a block ready to process as the next block in the blockchain. </p>



<p>Any server can produce a â€œcandidate block,â€ but if it were too easy to do, the network would be spammed. So there had to be a financial cost to creating a block, hence the work.&nbsp;</p>



<p>In the case of bitcoin, that work involves solving a hash puzzle; the cost is computing time and electricity. The hash puzzle is very difficult to solve, but easy for peers in the bitcoin network to verify, so they can prove you did the work and the block is valid.</p>



<p>Some people refer to this puzzle as a complex math problem, but itâ€™s really not. Working out a hash is easy, but in bitcoin, working out a hash that meets certain conditions is tricky. Finding the solution is a bit like winning a lottery.</p>



<h2>Solving the hash puzzle</h2>



<p>A <a href="https://en.wikipedia.org/wiki/Cryptographic_hash_function" target="_blank" rel="noreferrer noopener">hash</a> is a fixed-length output calculated from a piece of data. Whether you hash Herman Woukâ€™s â€œWar and Remembranceâ€ or a grocery store list, the resultant hash will always be the same length. And you will always get the same hash for the same string. But if even one letter changes in â€œWar and Remembrance,â€ the resultant hash will be different.</p>



<p>Bitcoin uses the <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Hashcash" target="_blank">hashcash proof-of-work,</a> originally developed by cryptographer Adam Back in 1997 as a way to prevent email spam and denial-of-service attacks, and the <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/SHA-2" target="_blank">SHA-256</a> hashing function, which has been around since 2001.</p>



<p>When you hash a bitcoin block, you also track the hash of the previous blockâ€”which â€œchainsâ€ a block to the one before it, and so on down the line to the first bitcoin block ever createdâ€”and a random number called a <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Cryptographic_nonce" target="_blank">nonce.</a> The idea is to produce a hash that is lower than the numeric value of the <a href="https://en.bitcoin.it/wiki/Target" target="_blank" rel="noreferrer noopener">network target.</a> (This target changes periodically to adjust the mining difficulty, thereby assuring only one block gets created every 10 minutes.) </p>



<p>When you mine bitcoin, you repeatedly hash the block while incrementing the nonce. Each time you change the nonce, you also change the value of the resultant hash. The number of hashes that a miner makes per second is called the hash rate; the higher your hash rate, the better your chance of solving the puzzle. A single bitcoin mining rig can make up to 14 trillion guesses per second.</p>



<p>If you discover a hash value that is small enough before anyone else does, you win! Your block is then transmitted to the rest of the network, and the other nodes begin work on the next block using the hash of the accepted block.&nbsp;</p>



<h2>Powerful computers</h2>



<p>As bitcoin went up in value over the years, miners found faster and faster ways to win the bitcoin lottery. When bitcoin was first introduced in 2009, you could mine bitcoin with the CPU on your own personal computer.</p>



<p>Those days are a distant memory. As bitcoin mining became more profitable, miners switched to graphic processing units (GPUs). And in 2011, they migrated to field-programmable gate arrays (FPGAs). But starting in 2013, the field was taken over by application-specific integrated circuit equipment (ASIC) rigsâ€”which is â€¦</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://amycastor.com/2021/02/17/proof-of-work-the-reason-behind-bitcoins-horrendous-energy-consumption/">https://amycastor.com/2021/02/17/proof-of-work-the-reason-behind-bitcoins-horrendous-energy-consumption/</a></em></p>]]>
            </description>
            <link>https://amycastor.com/2021/02/17/proof-of-work-the-reason-behind-bitcoins-horrendous-energy-consumption/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179585</guid>
            <pubDate>Thu, 18 Feb 2021 13:32:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenZFS â€“ dRAID, Finally]]>
            </title>
            <description>
<![CDATA[
Score 161 | Comments 46 (<a href="https://news.ycombinator.com/item?id=26179566">thread link</a>) | @throw0101a
<br/>
February 18, 2021 | https://klarasystems.com/articles/openzfs-draid-finally/ | <a href="https://web.archive.org/web/*/https://klarasystems.com/articles/openzfs-draid-finally/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>




<div>
<h3><em>This is part of our article series published as â€œOpenZFS in Depthâ€. <a href="https://klarasystems.com/articles/"><strong><span>Subscribe to our article series</span></strong> </a>to find out more about the secrets of OpenZFS</em></h3>



<hr>



<p><strong><em>Isaac Huangâ€™s <a href="https://www.youtube.com/watch?v=xPU3rIHyCTs">talk at the OpenZFS 2017 developers summit</a> witnessed the expansion of the ZFS storage endurance envelope for large installations.&nbsp; dRAID or distributed RAID is a new vdev type that complements existing ZFS data protection capabilities for very large storage arrays.&nbsp; Starting with the RAID-Z-like underpinnings, dRAID permutes, or mixes, disk blocks together in a way where accesses are evenly spread across all the drives. Fast spindle replacement is accomplished by using all members of the pool, using pre-allocated virtual spares, spread evenly over all the spindles. Contributors include Intel, Lawrence Livermore Labs, and HP Enterprise, which have material interest in storage at datacenter scale and high reliability. The OpenZFS user community are the benefactors of this enhancement if we apply it well.</em></strong></p>



<h3><strong>Avoiding the Death Spiral</strong></h3>



<p>Admins will often use wide RAID stripes to maximize usable storage given a number of spindles. RAID-Z deployments with large stripe widths, ten or larger, are subject to poor resilver performance for a number of reasons. Resilvering a full vdev means reading from every healthy disk and continuously writing to the new spare. This will saturate the replacement disk with writes while scattering seeks over the rest of the vdev. For 14 wide RAID-Z2 vdevs using 12TB spindles, rebuilds can take weeks. Resilver I/O activity is deprioritized when the system has not been idle for a minimum period. Full zpools get fragmented and require additional I/Oâ€™s to recalculate data during reslivering. A pool can degenerate into a never ending cycle of rebuilds or loss of the pool Aka: the Death Spiral.</p>



<p>As spindles age together, disks may fail in groups as defect counts and mechanical failure are not independent random processes with respect to age. SSDâ€™s further complicate this math as the wear leveling endurance will be very closely matched and clusters of devices under identical load may fail together.&nbsp; Manufacturer provided mean time to failure is a forward-looking statement and is not suitable for replenishment planning. One manufacturer claims 1.2 Million hour MTBF: a dubious 137 year commitment to quality. Itâ€™s poor planning to assume any drive isnâ€™t going to pick today to dramatically fail.&nbsp;</p>



<p>dRAID is an option providing rapid parity rebuild that can mitigate the death spiral behaviour of wide RAIDZ stripes, but as reflected in its default width setting of eight, it does not encourage wide stripes. Dedicating sufficient parity increases the durability of the ZFS pool and the investment in parity should be informed by the risk of losing the pool.</p>



<h3><strong>Distributed Spares?</strong></h3>



<p>Spare disks are a way of keeping a disk warm and ready to replace a failed member. Usually, a spareâ€™s life is leisurely idle until they are scrammed into action during a rebuild. That idleness is a wasted opportunity to do useful work. There are no specific spare disks in a dRAID. Rather, enough blocks are allocated throughout out the vdev to act as spares. The distributed spare is a clever redistribution of work so that all disks are always in use. A disk failure precipitates a rebuild into that dedicated space. After replacement disks are available, the vdev can be re-balanced to return the spare block and put the replacement disk in to use.</p>



<h3><strong><strong><strong>Fixed Stripe Width</strong></strong></strong></h3>



<p>Unlike RAID-Z, an entire stripe in dRAID is allocated at once, no matter how many disk blocks are needed to store the object. The stripe width is determined by the disk sector size multiplied by the number of data drives in the RAID group.</p>



<div data-columns="3" data-layout="50-25-25"><div>




<div><div>
<p>Did you know?</p>



<h2>You can maximize the <strong>power of your FreeBSD</strong> infrastructure with our <strong>Support Subscription!</strong></h2>




</div></div>




</div></div>



<p>RAID-Z has a method of optimizing block layout to minimize block allocations for small files. dRAID however priorities the speed of rebuilding parity and does not make the same space preserving attempt. If your files are a small fraction of the stripe size, dRAID will not be able to use all the disk blocks fully. For example, a default dRAID vdev has a stripe with of 32k (4k per disk, 8 disks); any allocation will require at least 32k. Internal padding is allocated to fill out the stripe width after the request object is stored. Using a smaller stripe width or providing a special mirror vdev will suit smaller allocations and improve drive utilization.</p>



<h3><strong>A Tale of Two Resilvers</strong></h3>



<p>After a failure, the real or distributed spare is written to in sequence, following only the parity layout in the space map to rebuild the drive according to parity data. Sequential reconstruction can be accomplished rapidly by issuing large I/O blocks, reducing seeks, and avoiding tree indirection overhead. The rebuilt diskâ€™s contents are not necessarily consistent with the Merkle tree that proves the zpools data is intact.&nbsp; Itâ€™s important to reconstruct this bitwise copy of the disk first, allowing the system to return to mostly intact state and return to service. That is to say, the sequential reconstruction process restores the redundancy level of the pool, but without being able to verify the checksums of the data. The advantage to this is that it can be completed much more quickly, reducing the window during which additional disk failures might put the pool at risk.</p>



<p>A healing resilver is triggered automatically after a sequential resilver, it is a final operation that verifies that all the contents of the drives match their initial checksums via block pointer traversal. The healing resilver has a number of optimizations to quickly find and reconstruct writes to the failed disk. When a replacement drive can be added to the pool, the rebalance operation is another sequential resilver followed by a healing resilver.</p>



<p>A scrub is the gold standard for a pool health; however, a scrub might be a prohibitive amount of work, visiting every block allocated in the pool. The healing resilver allows a practical return to operation in an environment where failures must be repaired routinely.</p>



<h3><strong><em>â€œAre We There Yet? When Can I Play With it?â€</em></strong></h3>



<p>According to a report from the January OpenZFS leadership meeting, OpenZFS 2.1 will support dRAID in early 2021. If you must have it now; the head branch of the OpenZFS build against recently supported operating systems: FreeBSD 12.1+, Linux 5.10+, Illumos, NetBSD et al. The OpenZFS regression test suite ztest is a good indication that dRAID satisfies the ZFS commitment to data protection. Corporate customers at IBM and Panasas have been flogging other distributed RAID systems for more than ten years. Itâ€™s a mature concept that complements the ZFS tool set.</p>



<h4><strong>Quick Start</strong></h4>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; There is no better way to learn software than to run headlong into mistakes.&nbsp;</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Weâ€™ll install ZFS head from source and gin up some â€˜mdâ€™ file backed disks.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; â€˜zpool create r2dRAID dRAID2:3d:1s:14c /dev/md1 /dev/md2 â€¦.&nbsp; /dev/md13 /dev/md14â€™</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; There it is, a zpool with a dRAID vdev, ready to go to work.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The OpenZFS wiki has a good description of <a href="https://openzfs.github.io/openzfs-docs/Basic%20Concepts/dRAID%20Howto.html">dRAID care, resilvering and rebalancing</a></p>



<p>Following the life cycle of failure and replacement in the documentation is recommended before those skills are tested in production.</p>



<h4><strong>dRAID Nomenclature</strong></h4>



<p>Letâ€™s decode the nomenclature that describes the geometry of a dRAID vdev. A string such as â€œdRAID2:3d:14c:1sâ€ encodes the following about a dRAID vdev.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -dRAID[&lt;parity&gt;][:&lt;data&gt;d][:&lt;children&gt;c][:&lt;spares&gt;s]</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -parity: Required, the number of spindles to use to store parity information. Eg: A dRAID3 can survive until a fourth disk failure without losing data. Parity may be 1,2 or 3.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -[d] data: (spindles per RAID group): Determines the width of the data stripe, 8 is the default. Larger values will increase the stripe width and reduce total parity.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -[c] children: This parameter should match the number of device entries that you feed to the vdev. A helpful check will warn you if you donâ€™t get the right number of disks named correctly: â€œinvalid number of dRAID children; 14 required but 13 providedâ€</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -[s] spares: The number of disk areas to mix in as distributed spares. No spares are created by default, a maximum of four are welcome. Each spare will remove a fraction of space from every disk.</p>



<h2><strong>Parting Short</strong></h2>



<p>The dRAID offers a solution for large arrays, vdevs with fewer than 20 spindles will have limited benefits from the new option. The performance and resilver result will be similar to RAIDZ for small numbers of spindles. Installations with many spindles will see the best results with regards to performance, fast spare activation and replacement. The benefits come with the associated cost of whole stripe at a time allocation for small objects in the pool. This overhead should be calculated in the design of the pool before itâ€™s an operational surprise.</p>



<p>There is no free lunch with dRAID for in saving parity or spare drives, they are your defense against data loss. As drives increase in size, their time to resilver increases and the amount of data they can destroy increases.</p>



<h2><strong>Like this article? Share it!</strong></h2>


</div>




</div></div>]]>
            </description>
            <link>https://klarasystems.com/articles/openzfs-draid-finally/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179566</guid>
            <pubDate>Thu, 18 Feb 2021 13:31:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clubhouse Goes Global]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26179391">thread link</a>) | @donohoe
<br/>
February 18, 2021 | https://restofworld.org/2021/four-countries-one-clubhouse/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2021/four-countries-one-clubhouse/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			<!-- Article Start -->
			
<p><span>W</span>hat happens when a buzzy app pegged as a digital soapbox for tech bros suddenly lands on the global stage?</p>



<p>Since December, people have joined Clubhouse, a fast-growing audio platform <a href="https://www.theinformation.com/articles/clubhouse-gets-investment-interest-at-1-billion-valuation">reportedly</a> valued at $1 billion, from countries including Ghana, Saudi Arabia, and <a href="https://www.reuters.com/article/us-clubhouse-thailand/thailand-warns-against-app-clubhouse-after-monarchy-discussions-idUSKBN2AH0VR?fbclid=IwAR0MtZxoE9dup4cAlLF7P3sYuaBkhjODgUraH5iefoLX_rs3RLp0Ip0YpSA">Thailand</a>. The app, which is currently invite-only, has been installed more than 5.5 million times, with 16% of those downloads in Japan, according to one <a href="https://www.washingtonpost.com/technology/2021/02/10/what-is-clubhouse-faq/">estimate</a>. From Berlin to Delhi, people are hosting live conversations that sound like a mix between a Zoom webinar and happy hour gossip.</p>



<p>Clubhouse is perhaps <a href="https://www.nytimes.com/2020/05/19/technology/clubby-silicon-valley-app-clubhouse.html">best-known</a> for attracting Silicon Valley insiders like <a href="https://www.businessinsider.com/clubhouse-app-good-time-show-hosts-elon-musk-mark-zuckerberg-2021-2">Elon Musk</a> and receiving funding from <a href="https://www.platformer.news/p/clubhouses-moment-arrives">Andreessen Horowitz</a>, a major venture capital firm whose <a href="https://www.platformer.news/p/clubhouses-moment-arrives">partners</a> are also noteworthy Clubhouse users. Launched in March of last year, Clubhouse is already confronting the challenges many social media platforms face when they scale internationally, especially when it comes to <a href="https://www.bloomberg.com/news/articles/2021-02-11/black-doctors-work-overtime-to-combat-clubhouse-covid-19-myths?sref=QYWxDQ1o">moderation</a> and <a href="https://www.businessinsider.in/tech/news/clubhouse-says-it-will-review-its-policies-after-stanford-warned-that-data-may-be-shared-with-chinas-government/articleshow/80898264.cms">security</a>. As it grows, Clubhouse will need to consider how to protect users in more authoritarian countries like China, where it was recently blocked by the government after users created conversations, or â€œrooms,â€ <a href="https://twitter.com/wongmjane/status/1358632701872381952">to openly discuss taboo topics</a> like <a href="https://restofworld.org/2020/counter-surveillance-revolution/">human rights abuses</a> in Xinjiang and <a href="https://restofworld.org/2020/lihkg-hong-kong-protests-forum/">pro-democracy protests</a> in Hong Kong.</p>



<p><em>Rest of World</em> took a look at four places that have seen a recent spike in Clubhouse users â€” Japan, India, Nigeria, and Hong Kong â€” to better understand the appâ€™s global rise, as well as the ripple effects new users in each location are leaving in their wake.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/Clubhouse_Flags-Japan-2-40x24.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/Clubhouse_Flags-Japan-2-768x432.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/Clubhouse_Flags-Japan-2-400x240.png 400w, https://restofworld.org/wp-content/uploads/2021/02/Clubhouse_Flags-Japan-2-600x360.png 600w, https://restofworld.org/wp-content/uploads/2021/02/Clubhouse_Flags-Japan-2-1000x600.png 1000w, https://restofworld.org/wp-content/uploads/2021/02/Clubhouse_Flags-Japan-2-1600x960.png 1600w, " sizes="(max-width: 640px) 100vw, 370px" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<h3><strong>JAPAN â€” Chasing celebrity&nbsp;</strong></h3>



<div><p><strong><em>&nbsp;</em></strong>Elon Musk first <a href="https://twitter.com/elonmusk/status/1355983231988862978?s=21">hopped on Clubhouse</a> in late January to discuss cryptocurrencies and investing in GameStop. The Tesla CEOâ€™s appearance helped bring mainstream attention to Clubhouse in the U.S., but it would be a mistake to cite Musk as the catalyst for its rise elsewhere. <strong><em></em></strong><em>â€œ</em>He has very little to do with the Japanese growth,â€ Koichi Tsunoda told <em>Rest of World </em>in a private Clubhouse chat, his preferred venue for an interview. A week before the Musk cameo, Tsunoda, the CFO of a platform for businesses <a href="https://yappli.co.jp/">called Yappli</a>, was part of the first wave of Japanese entrepreneurs to arrive on Clubhouse. Tsunoda said it took only three days for the majority of Japanâ€™s best-known tech influencers to secure invites. Tsunoda joined hoping to connect with investors abroad and bring more visibility to Japanâ€™s startup sector. But the app quickly expanded beyond the countryâ€™s tech bubble.</p><p>A handful of Japanese celebrities were invited to Clubhouse in late January by friends in the tech industry, including TV commentator and comedian <a href="https://twitter.com/atsushilonboo/status/1354441357738184704">Atsushi Tamura</a>, who was one of the first widely recognized figures to log on. He was followed by actress and fashion designer Naomi Watanabe, who racked up over 500,000 followers in her first two weeks on the app. Celebrated kabuki and film actor Ebizo Ichikawa is also a <a href="https://twitter.com/EBIZO_DES/status/1356535391403208706">Clubhouse convert</a>, appearing in rooms every few days in recent weeks.</p></div>


    <figure>
      <div>
				<ul>
					<li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/phone1-40x67.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/phone1-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/phone1-400x667.png 400w, https://restofworld.org/wp-content/uploads/2021/02/phone1-600x1000.png 600w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/phone4-40x67.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/phone4-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/phone4-400x667.png 400w, https://restofworld.org/wp-content/uploads/2021/02/phone4-600x1000.png 600w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/phone3-40x67.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/phone3-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/phone3-400x667.png 400w, https://restofworld.org/wp-content/uploads/2021/02/phone3-600x1000.png 600w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/phone5-40x67.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/phone5-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/phone5-400x667.png 400w, https://restofworld.org/wp-content/uploads/2021/02/phone5-600x1000.png 600w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li>
				</ul>
			</div>
      
    </figure>


<p>This constellation of celebrities made the app enticing to the general public. â€œClubhouse, maybe due to a lack of users, is very intimate,â€ said Tsunoda. â€œYou can talk to singers in Japan, you can talk to those comedians, and you can actually have a conversation with them.â€</p>



<p>Some Japanese-langauge rooms made passing references to Muskâ€™s talk when he finally joined Clubhouse on January 31, but by that time, the appâ€™s â€œhallwaysâ€ â€” the Clubhouse equivalent of a news feed â€” were already full of Japanese users hosting their own conversations. The app was established enough that <a href="https://twitter.com/takaya_i/status/1355047724643573761">government minister Taro Kono</a> even jumped on to recap his recent visit to Davos, Switzerland.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/Clubhouse_Flags-India-2-40x24.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/Clubhouse_Flags-India-2-768x432.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/Clubhouse_Flags-India-2-400x240.png 400w, https://restofworld.org/wp-content/uploads/2021/02/Clubhouse_Flags-India-2-600x360.png 600w, https://restofworld.org/wp-content/uploads/2021/02/Clubhouse_Flags-India-2-1000x600.png 1000w, https://restofworld.org/wp-content/uploads/2021/02/Clubhouse_Flags-India-2-1600x960.png 1600w, " sizes="(max-width: 640px) 100vw, 370px" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<h3><strong>INDIA â€” The iOS barrier</strong></h3>



<p>Every day, Pankaj Jain said he receives from 200 to 300 Clubhouse notifications. The angel investor and COO of the startup <a href="https://workomo.com/?utm_source=twitter&amp;utm_campaign=profile_pjain&amp;utm_medium=social">Workomo</a> joined in September, as members of the South Asian diaspora working in Silicon Valley carved out a space for themselves on the platform. But Jain, who lives in New York, saw no communities â€” or what the app calls â€œclubsâ€ â€” devoted specifically to India, let alone its startup ecosystem. After roping in Utsav Somani, a Delhi-based partner at AngelList India, he co-founded <a href="https://indianstartup.club/">The Indian Startup Club</a>, which now has nearly 8,000 members.<em><br></em><br>The club often runs a handful of rooms simultaneously, which have included pitch stages for budding Indian entrepreneurs, mental health and personal finance workshops for founders, and deep dives into cutting-edge industries like cryptocurrency and agricultural technology. â€œI never dreamt Clubhouse would blow up so quickly,â€ said Jain. â€œNow itâ€™s turning into a job. I just sit there and keep letting people in.â€</p>



<div><p>Jain hoped to broaden the conversation on Clubhouse beyond Silicon Valley, but when he tried inviting friends and colleagues from India to the platform, he found himself scrounging through his contact list for anyone who used an iPhone. Clubhouse is currently only available on iOS, but only around 3% <a href="https://www.statista.com/chart/22702/andoid-ios-market-share-selected-countries/">of Indians smartphone users</a> have an Apple device, which <a href="https://www.thequint.com/tech-and-auto/tech-news/here-is-why-apple-iphone-costs-more-in-india-compared-to-us#read-more">cost 40% more</a> in India than in the U.S., due to taxes and importation costs. â€œThereâ€™s a significant amount of FOMO thatâ€™s been going on,â€ said Jain. â€œImmediately, a huge part of the population canâ€™t get on the app â€” no matter what.â€</p><p>In early January, noted Silicon Valley venture capitalists Balaji Srinivasan and Naval Ravikant announced they would host a <a href="https://twitter.com/naval/status/1346171352009510913">Startup Bharat</a> conversation on Clubhouse for â€œtaking questions from Indian founders and open sourcing the Silicon Valley playbook.â€ Indian tech Twitter lit up with pleas for invites as well as posts <a href="https://twitter.com/kaustiwari/status/1346318199554363392">bemoaning iOS elitism</a>. The moment captured Clubhouseâ€™s limitations in India: When moneyed investors created a space for the countryâ€™s tech workers, most of the industry was still stuck at the door, waiting to be let in.</p></div>



<p>Clubhouseâ€™s founders, Rohan Seth and Paul Davison, said in a January <a href="https://www.joinclubhouse.com/welcoming-more-voices">blog post</a> that the company would â€œbegin work on our Android app soon.â€ Clubhouse did not respond to a request for comment asking for more information about a specific timetable. In the meantime, Jain said he has heard whispers among Indian entrepreneurs about building an Android clone of Clubhouse for <a href="https://yourstory.com/2019/12/india-internet-2019-report-reliance-jio">non-English speaking users</a> in India.&nbsp;</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/Clubhouse_Flags-HK-2-40x24.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/Clubhouse_Flags-HK-2-768x432.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/Clubhouse_Flags-HK-2-400x240.png 400w, https://restofworld.org/wp-content/uploads/2021/02/Clubhouse_Flags-HK-2-600x360.png 600w, https://restofworld.org/wp-content/uploads/2021/02/Clubhouse_Flags-HK-2-1000x600.png 1000w, https://restofworld.org/wp-content/uploads/2021/02/Clubhouse_Flags-HK-2-1600x960.png 1600w, " sizes="(max-width: 640px) 100vw, 370px" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<h3><strong>HONG KONG â€” Transnational, multilingual&nbsp;</strong></h3>



<div><p>Jane Manchun Wong describes herself as Clubhouseâ€™s first user in Hong Kong. Until recently, she was simply waiting for everyone else to show up. â€œThe HK Clubhouse community was nonexistent before mid-January,â€ she told<em> Rest of World </em>over email. A technology blogger and software engineer, Wong said she searched for months for other Hong Kongers using the app. On January 18, she came across a <a href="https://twitter.com/wongmjane/status/1351198778028650500">Cantonese-speaking room</a> hosted by Jonny Chan, who works in the tech industry in San Francisco and was chatting with a dozen or so of his friends. â€œIt was this serendipitous moment,â€ said Chan. â€œI felt, wow, Clubhouse really nailed the organic connection.â€</p><p>The pair had never met in person and lived on different continents, but they started working together to create some of the first Cantonese-speaking rooms on Clubhouse. The number of Hong Kong-based users on the app quickly grew, and the new arrivals began joining Wong and Chanâ€™s conversations.&nbsp;</p></div>



<p>When Chan eventually decided to launch a <a href="https://twitter.com/Jonnychn/status/1356285748979200001">24-hour Cantonese room</a>, he didnâ€™t think they could keep it open for the full day. But one perk of making friends across the world is that when Chan decided to call it a night, he could hand over the moderation baton to Wong, who kept things going from Hong Kong. â€œI woke up, and it was still going: I was so surprised,â€ Chan said. When the session hit the 24-hour mark, everyone clapped by flashing on and off their mute buttons. â€œItâ€™s one of those moments that you donâ€™t forget,â€ Chan said. â€œItâ€™s just this aha moment when you think, Wow, this app is so powerful.â€</p>



<figure><blockquote><p>â€œItâ€™s just this aha moment when you think, Wow, this app is so powerful.â€</p></blockquote></figure>



<div><p>Transnational run-ins are not uncommon on Clubhouse. Even <a href="https://www.wired.com/story/beijing-ban-clubhouse-wont-deter-listeners/amp">after the app was banned</a> in China, Mandarin speakers have logged on to have honest and deeply personal conversations, often touching on sensitive political subjects like relations between China and Taiwan. Japanese entrepreneurs and German investors have stepped into Indian-hosted rooms to deliberate the merits of moving to Bangalore for work. And Wong has taken part in discussions between users in Hong Kong and the U.S. about the experience of being Asian-American.</p><p>The cross-border dialogues arenâ€™t without incident. Wong recalled multiple instances of harassment in her rooms, where users talked in gibberish to mock Cantonese speakers or raised their hand just to tell Wong and others to speak in English. â€œI found these behaviors racist and offensive,â€ said Wong. â€œWhile we fortunately can report trolling, this kind of behavior can make us feel less safe on the platform.â€&nbsp;</p></div>



<p>The problem of audio moderation is not new: social media platforms <a href="https://cmci.colorado.edu/idlab/assets/bibliography/pdf/Jiang2019-discord.pdf">like Discord</a> and <a href="https://www.protocol.com/bulletins/clubhouse-china-blowing-up-censorship">YY in China</a> have featured live-audio chat rooms for years. <a href="https://www.poynter.org/fact-checking/2018/meet-the-next-misinformation-format-fake-audio-messages/">WhatsApp audio messages</a> have also been a noted source of misinformation. But critics have already accused Clubhouse of struggling to moderate English conversations, let alone those in other languages. â€œI doubt Clubhouseâ€™s moderation team understands all of the languages being spoken on the app, potentially leaving some abuses unchecked,â€ said Wong.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/Clubhouse_Flags-Nigeria-2-40x24.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/Clubhouse_Flags-Nigeria-2-768x432.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/Clubhouse_Flags-Nigeria-2-400x240.png 400w, https://restofworld.org/wp-content/uploads/2021/02/Clubhouse_Flags-Nigeria-2-600x360.png 600w, https://restofworld.org/wp-content/uploads/2021/02/Clubhouse_Flags-Nigeria-2-1000x600.png 1000w, https://restofworld.org/wp-content/uploads/2021/02/Clubhouse_Flags-Nigeria-2-1600x960.png 1600w, " sizes="(max-width: 640px) 100vw, 370px" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<h3><strong>NIGERIA</strong> â€“ <strong>Flirting, music, and charity</strong></h3>



<p>In mid-January, Nigerian radio personality Lanre Shonubi started a room on Clubhouse he called <a href="https://www.instagram.com/p/CKCQI0XDziS/?igshid=15ikg7y67sh9h">Shoot Your Shot Pro Max</a>. It began originally as a space to host fun, casual â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2021/four-countries-one-clubhouse/">https://restofworld.org/2021/four-countries-one-clubhouse/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2021/four-countries-one-clubhouse/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179391</guid>
            <pubDate>Thu, 18 Feb 2021 13:10:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nx (Numerical Elixir) is now publicly available]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26179373">thread link</a>) | @che_shr_cat
<br/>
February 18, 2021 | https://dashbit.co/blog/nx-numerical-elixir-is-now-publicly-available | <a href="https://web.archive.org/web/*/https://dashbit.co/blog/nx-numerical-elixir-is-now-publicly-available">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    
<ul>
  <li>
    <i></i> JosÃ© Valim
  </li>
  <li>
    <i></i> February 18th, 2021
  </li>
  <li>
    <i></i><a href="https://dashbit.co/blog/tags/nx">nx</a>, <a href="https://dashbit.co/blog/tags/defn">defn</a>
  </li>
</ul>
<p><img src="https://dashbit.co/images/posts/2021/nx.png" alt="Nx" width="400"></p>
<p>
Sean Moriarity and I are glad to announce that the project we have been working on for the last 3 months, Nx, is finally <a href="https://github.com/elixir-nx/nx">publicly available on GitHub</a>. Our goal with Nx is to provide the foundation for Numerical Elixir.</p>
<p>
In this blog post, I am going to outline the work we have done so far, some of the design decisions, and what we are planning to explore next. If you are looking for other resources to learn about Nx, you can <a href="https://thinkingelixir.com/podcast-episodes/034-jose-valim-reveals-project-nx/">hear me unveiling Nx on the ThinkingElixir podcast</a>.</p>
<h2>
  Nx</h2>
<p>
Nx is a multi-dimensional tensors library for Elixir with multi-staged compilation to the CPU/GPU. Letâ€™s see an example:</p>
<pre><code><span>iex&gt; </span><span>t</span><span> </span><span>=</span><span> </span><span>Nx</span><span>.</span><span>tensor</span><span data-group-id="4885761117-1">(</span><span data-group-id="4885761117-2">[</span><span data-group-id="4885761117-3">[</span><span>1</span><span>,</span><span> </span><span>2</span><span data-group-id="4885761117-3">]</span><span>,</span><span> </span><span data-group-id="4885761117-4">[</span><span>3</span><span>,</span><span> </span><span>4</span><span data-group-id="4885761117-4">]</span><span data-group-id="4885761117-2">]</span><span data-group-id="4885761117-1">)</span><span>
</span><span data-group-id="4885761117-5">#</span><span data-group-id="4885761117-5">Nx.Tensor</span><span data-group-id="4885761117-5">&lt;</span><span>
  </span><span>s64</span><span data-group-id="4885761117-6">[</span><span>2</span><span data-group-id="4885761117-6">]</span><span data-group-id="4885761117-7">[</span><span>2</span><span data-group-id="4885761117-7">]</span><span>
  </span><span data-group-id="4885761117-8">[</span><span>
    </span><span data-group-id="4885761117-9">[</span><span>1</span><span>,</span><span> </span><span>2</span><span data-group-id="4885761117-9">]</span><span>,</span><span>
    </span><span data-group-id="4885761117-10">[</span><span>3</span><span>,</span><span> </span><span>4</span><span data-group-id="4885761117-10">]</span><span>
  </span><span data-group-id="4885761117-8">]</span><span>
</span><span data-group-id="4885761117-5">&gt;</span></code></pre>
<p>
As you see, tensors have a type (s64) and a shape (2x2). Tensor operations are also done with the <code>Nx</code> module. To implement <a href="https://en.wikipedia.org/wiki/Softmax_function">the Softmax function</a>:</p>
<pre><code><span>iex&gt; </span><span>t</span><span> </span><span>=</span><span> </span><span>Nx</span><span>.</span><span>tensor</span><span data-group-id="2015320651-1">(</span><span data-group-id="2015320651-2">[</span><span data-group-id="2015320651-3">[</span><span>1</span><span>,</span><span> </span><span>2</span><span data-group-id="2015320651-3">]</span><span>,</span><span> </span><span data-group-id="2015320651-4">[</span><span>3</span><span>,</span><span> </span><span>4</span><span data-group-id="2015320651-4">]</span><span data-group-id="2015320651-2">]</span><span data-group-id="2015320651-1">)</span><span>
</span><span>iex&gt; </span><span>Nx</span><span>.</span><span>divide</span><span data-group-id="2015320651-5">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="2015320651-6">(</span><span>t</span><span data-group-id="2015320651-6">)</span><span>,</span><span> </span><span>Nx</span><span>.</span><span>sum</span><span data-group-id="2015320651-7">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="2015320651-8">(</span><span>t</span><span data-group-id="2015320651-8">)</span><span data-group-id="2015320651-7">)</span><span data-group-id="2015320651-5">)</span><span>
</span><span data-group-id="2015320651-9">#</span><span data-group-id="2015320651-9">Nx.Tensor</span><span data-group-id="2015320651-9">&lt;</span><span>
  </span><span>f64</span><span data-group-id="2015320651-10">[</span><span>2</span><span data-group-id="2015320651-10">]</span><span data-group-id="2015320651-11">[</span><span>2</span><span data-group-id="2015320651-11">]</span><span>
  </span><span data-group-id="2015320651-12">[</span><span>
    </span><span data-group-id="2015320651-13">[</span><span>0.03205860328008499</span><span>,</span><span> </span><span>0.08714431874203257</span><span data-group-id="2015320651-13">]</span><span>,</span><span>
    </span><span data-group-id="2015320651-14">[</span><span>0.23688281808991013</span><span>,</span><span> </span><span>0.6439142598879722</span><span data-group-id="2015320651-14">]</span><span>
  </span><span data-group-id="2015320651-12">]</span><span>
</span><span data-group-id="2015320651-9">&gt;</span></code></pre>
<p>
The high-level features in Nx are:</p>
<ul>
  <li>
    <p>
Typed multi-dimensional tensors, where the tensors can be unsigned integers (<code>u8</code>, <code>u16</code>, <code>u32</code>, <code>u64</code>), signed integers (<code>s8</code>, <code>s16</code>, <code>s32</code>, <code>s64</code>), floats (<code>f32</code>, <code>f64</code>) and brain floats (<code>bf16</code>);    </p>
  </li>
  <li>
    <p>
<a href="http://nlp.seas.harvard.edu/NamedTensor">Named tensors</a>, allowing developers to give names to each dimension, leading to more readable and less error prone codebases;    </p>
  </li>
  <li>
    <p>
Automatic differentiation, also known as autograd. The <code>grad</code> function provides reverse-mode differentiation, useful for simulations, training probabilistic models, etc;    </p>
  </li>
  <li>
    <p>
Tensors backends, which enables the main <code>Nx</code> API to be used to manipulate binary tensors, GPU-backed tensors, sparse matrices, and more;    </p>
  </li>
  <li>
    <p>
Numerical definitions, known as <code>defn</code>, provide multi-stage compilation of tensor operations to multiple targets, such as highly specialized CPU code or the GPU. The compilation can happen either ahead-of-time (AOT) or just-in-time (JIT) with a compiler of your choice;    </p>
  </li>
</ul>
<p>
For Python developers, <code>Nx</code> currently takes its main inspirations from <a href="https://numpy.org/"><code>Numpy</code></a> and <a href="https://github.com/google/jax"><code>JAX</code></a> but packaged into a single unified library.</p>
<p>
Our initial efforts have focused on the underlying abstractions. For example, while Nx implements dense tensors out-of-the-box, we also want the same high-level API to be valid for sparse tensors. You should also be able to use all functions in the <code>Nx</code> module with tensors that are backed by Elixir binaries and with tensors that are stored directly in the GPU.</p>
<p>
By ensuring the underlying tensor backend is ultimately replaceable, we can build an ecosystem of libraries on top of Nx, and allow end-users to experiment with different backends, hardware, and approaches to run their software on.</p>
<p>
<em>Nxâ€™s mascot is the Numbat, a marsupial native to southern Australia. Unfortunately the Numbat are endangered and it is estimated to be fewer than 1000 left. If you are excited about Nx, consider donating to Numbat conservation efforts, such as <a href="https://www.numbat.org.au/">Project Numbat</a> and <a href="https://www.australianwildlife.org/">Australian Wildlife Conservancy</a>.</em></p>
<h2>
Numerical definitions</h2>
<p>
One of the most important features in <code>Nx</code> is the numerical definition, called <code>defn</code>. Numerical definitions are a subset of Elixir tailored for numerical computing. Here is the <code>softmax</code> formula above, now written with <code>defn</code>:</p>
<pre><code><span>defmodule</span><span> </span><span>Formula</span><span> </span><span data-group-id="4810618200-1">do</span><span>
  </span><span>import</span><span> </span><span>Nx.Defn</span><span>

  </span><span>defn</span><span> </span><span>softmax</span><span data-group-id="4810618200-2">(</span><span>t</span><span data-group-id="4810618200-2">)</span><span> </span><span data-group-id="4810618200-3">do</span><span>
    </span><span>inspect_expr</span><span data-group-id="4810618200-4">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="4810618200-5">(</span><span>t</span><span data-group-id="4810618200-5">)</span><span> </span><span>/</span><span> </span><span>Nx</span><span>.</span><span>sum</span><span data-group-id="4810618200-6">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="4810618200-7">(</span><span>t</span><span data-group-id="4810618200-7">)</span><span data-group-id="4810618200-6">)</span><span data-group-id="4810618200-4">)</span><span>
  </span><span data-group-id="4810618200-3">end</span><span>
</span><span data-group-id="4810618200-1">end</span></code></pre>
<p>
The first difference we see with <code>defn</code> is that Elixirâ€™s built-in operators have been augmented to also work with tensors. Effectively, <code>defn</code> replaces Elixirâ€™s <code>Kernel</code> with <code>Nx.Defn.Kernel</code>.</p>
<p>
However, <code>defn</code> goes even further. When using <code>defn</code>, <code>Nx</code> builds a computation with all of your tensor operations. Letâ€™s inspect it:</p>
<pre><code><span>defn</span><span> </span><span>softmax</span><span data-group-id="0860724160-1">(</span><span>t</span><span data-group-id="0860724160-1">)</span><span> </span><span data-group-id="0860724160-2">do</span><span>
  </span><span>inspect_expr</span><span data-group-id="0860724160-3">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="0860724160-4">(</span><span>t</span><span data-group-id="0860724160-4">)</span><span> </span><span>/</span><span> </span><span>Nx</span><span>.</span><span>sum</span><span data-group-id="0860724160-5">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="0860724160-6">(</span><span>t</span><span data-group-id="0860724160-6">)</span><span data-group-id="0860724160-5">)</span><span data-group-id="0860724160-3">)</span><span>
</span><span data-group-id="0860724160-2">end</span></code></pre>
<p>
Now when invoked, you will see this printed:</p>
<pre><code><span>iex(3)&gt; </span><span>Formula</span><span>.</span><span>softmax</span><span data-group-id="4848142189-1">(</span><span>Nx</span><span>.</span><span>tensor</span><span data-group-id="4848142189-2">(</span><span data-group-id="4848142189-3">[</span><span data-group-id="4848142189-4">[</span><span>1</span><span>,</span><span> </span><span>2</span><span data-group-id="4848142189-4">]</span><span>,</span><span> </span><span data-group-id="4848142189-5">[</span><span>3</span><span>,</span><span> </span><span>4</span><span data-group-id="4848142189-5">]</span><span data-group-id="4848142189-3">]</span><span data-group-id="4848142189-2">)</span><span data-group-id="4848142189-1">)</span><span>
</span><span data-group-id="4848142189-6">#</span><span data-group-id="4848142189-6">Nx.Tensor</span><span data-group-id="4848142189-6">&lt;</span><span>
  </span><span>f64</span><span data-group-id="4848142189-7">[</span><span>2</span><span data-group-id="4848142189-7">]</span><span data-group-id="4848142189-8">[</span><span>2</span><span data-group-id="4848142189-8">]</span><span>
  
  </span><span>Nx.Defn.Expr</span><span>
  </span><span>parameter</span><span> </span><span>a</span><span>                                 </span><span>s64</span><span data-group-id="4848142189-9">[</span><span>2</span><span data-group-id="4848142189-9">]</span><span data-group-id="4848142189-10">[</span><span>2</span><span data-group-id="4848142189-10">]</span><span>
  </span><span>b</span><span> </span><span>=</span><span> </span><span>exp</span><span> </span><span data-group-id="4848142189-11">[</span><span> </span><span>a</span><span> </span><span data-group-id="4848142189-11">]</span><span>                               </span><span>f64</span><span data-group-id="4848142189-12">[</span><span>2</span><span data-group-id="4848142189-12">]</span><span data-group-id="4848142189-13">[</span><span>2</span><span data-group-id="4848142189-13">]</span><span>
  </span><span>c</span><span> </span><span>=</span><span> </span><span>exp</span><span> </span><span data-group-id="4848142189-14">[</span><span> </span><span>a</span><span> </span><span data-group-id="4848142189-14">]</span><span>                               </span><span>f64</span><span data-group-id="4848142189-15">[</span><span>2</span><span data-group-id="4848142189-15">]</span><span data-group-id="4848142189-16">[</span><span>2</span><span data-group-id="4848142189-16">]</span><span>
  </span><span>d</span><span> </span><span>=</span><span> </span><span>sum</span><span> </span><span data-group-id="4848142189-17">[</span><span> </span><span>c</span><span>,</span><span> </span><span>axes</span><span>:</span><span> </span><span>nil</span><span>,</span><span> </span><span>keep_axes</span><span>:</span><span> </span><span>false</span><span> </span><span data-group-id="4848142189-17">]</span><span>  </span><span>f64</span><span>
  </span><span>e</span><span> </span><span>=</span><span> </span><span>divide</span><span> </span><span data-group-id="4848142189-18">[</span><span> </span><span>b</span><span>,</span><span> </span><span>d</span><span> </span><span data-group-id="4848142189-18">]</span><span>                         </span><span>f64</span><span data-group-id="4848142189-19">[</span><span>2</span><span data-group-id="4848142189-19">]</span><span data-group-id="4848142189-20">[</span><span>2</span><span data-group-id="4848142189-20">]</span><span>
</span><span data-group-id="4848142189-6">&gt;</span><span>
</span><span data-group-id="4848142189-21">#</span><span data-group-id="4848142189-21">Nx.Tensor</span><span data-group-id="4848142189-21">&lt;</span><span>
  </span><span>f64</span><span data-group-id="4848142189-22">[</span><span>2</span><span data-group-id="4848142189-22">]</span><span data-group-id="4848142189-23">[</span><span>2</span><span data-group-id="4848142189-23">]</span><span>
  </span><span data-group-id="4848142189-24">[</span><span>
    </span><span data-group-id="4848142189-25">[</span><span>0.03205860328008499</span><span>,</span><span> </span><span>0.08714431874203257</span><span data-group-id="4848142189-25">]</span><span>,</span><span>
    </span><span data-group-id="4848142189-26">[</span><span>0.23688281808991013</span><span>,</span><span> </span><span>0.6439142598879722</span><span data-group-id="4848142189-26">]</span><span>
  </span><span data-group-id="4848142189-24">]</span><span>
</span><span data-group-id="4848142189-21">&gt;</span></code></pre>
<p>
This computation graph can also be transformed programatically. The transformation is precisely how we implement automatic differentiation, also known as <code>autograd</code>, by traversing each node and computing their derivative:</p>
<pre><code><span>defn</span><span> </span><span>grad_softmax</span><span data-group-id="5969204985-1">(</span><span>t</span><span data-group-id="5969204985-1">)</span><span> </span><span data-group-id="5969204985-2">do</span><span>
  </span><span>grad</span><span data-group-id="5969204985-3">(</span><span>t</span><span>,</span><span> </span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="5969204985-4">(</span><span>t</span><span data-group-id="5969204985-4">)</span><span> </span><span>/</span><span> </span><span>Nx</span><span>.</span><span>sum</span><span data-group-id="5969204985-5">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="5969204985-6">(</span><span>t</span><span data-group-id="5969204985-6">)</span><span data-group-id="5969204985-5">)</span><span data-group-id="5969204985-3">)</span><span>
</span><span data-group-id="5969204985-2">end</span></code></pre>
<p>
Finally, this computation graph can also be handed out to different compilers. As an example, we have implemented bindings for <a href="https://www.tensorflow.org/xla/">Googleâ€™s XLA</a> compiler, called EXLA. We can ask the <code>softmax</code> function to use this new compiler with a module attribute:</p>
<pre><code><span>@defn_compiler</span><span> </span><span data-group-id="5313365207-1">{</span><span>EXLA</span><span>,</span><span> </span><span>client</span><span>:</span><span> </span><span>:host</span><span data-group-id="5313365207-1">}</span><span>
</span><span>defn</span><span> </span><span>softmax</span><span data-group-id="5313365207-2">(</span><span>t</span><span data-group-id="5313365207-2">)</span><span> </span><span data-group-id="5313365207-3">do</span><span>
  </span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="5313365207-4">(</span><span>t</span><span data-group-id="5313365207-4">)</span><span> </span><span>/</span><span> </span><span>Nx</span><span>.</span><span>sum</span><span data-group-id="5313365207-5">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="5313365207-6">(</span><span>t</span><span data-group-id="5313365207-6">)</span><span data-group-id="5313365207-5">)</span><span>
</span><span data-group-id="5313365207-3">end</span></code></pre>
<p>
Once <code>softmax</code> is called, <code>Nx.Defn</code> will invoke <code>EXLA</code> to emit a just-in-time and highly-specialized compiled version of the code, tailored to the tensor type and shape. By passing <code>client: :cuda</code> or <code>client: :rocm</code>, the code can be compiled for the GPU. For reference, here are some benchmarks of the function above when called with a tensor of one million random float values on different clients:</p>
<pre><code>Name                       ips        average  deviation         median         99th %
xla gpu f32 keep      15308.14      0.0653 ms    Â±29.01%      0.0638 ms      0.0758 ms
xla gpu f64 keep       4550.59        0.22 ms     Â±7.54%        0.22 ms        0.33 ms
xla cpu f32             434.21        2.30 ms     Â±7.04%        2.26 ms        2.69 ms
xla gpu f32             398.45        2.51 ms     Â±2.28%        2.50 ms        2.69 ms
xla gpu f64             190.27        5.26 ms     Â±2.16%        5.23 ms        5.56 ms
xla cpu f64             168.25        5.94 ms     Â±5.64%        5.88 ms        7.35 ms
elixir f32                3.22      311.01 ms     Â±1.88%      309.69 ms      340.27 ms
elixir f64                3.11      321.70 ms     Â±1.44%      322.10 ms      328.98 ms

Comparison:
xla gpu f32 keep      15308.14
xla gpu f64 keep       4550.59 - 3.36x slower +0.154 ms
xla cpu f32             434.21 - 35.26x slower +2.24 ms
xla gpu f32             398.45 - 38.42x slower +2.44 ms
xla gpu f64             190.27 - 80.46x slower +5.19 ms
xla cpu f64             168.25 - 90.98x slower +5.88 ms
elixir f32                3.22 - 4760.93x slower +310.94 ms
elixir f64                3.11 - 4924.56x slower +321.63 ms</code></pre>
<p>
Where <code>keep</code> indicates the tensor was kept on the device instead of being transferred back to Elixir. You can see the benchmark in the <a href="https://github.com/elixir-nx/nx/tree/main/exla/bench"><code>bench</code></a> directory and find some examples in the <a href="https://github.com/elixir-nx/nx/tree/main/exla/examples"><code>examples</code></a> directory of the EXLA project.</p>
<h3>
Compiling numerical definitions</h3>
<p>
Before moving forward, it is important for us to take a look at how numerical definitions are compiled. For example, take the <code>softmax</code> function:</p>
<pre><code><span>defn</span><span> </span><span>softmax</span><span data-group-id="5791259392-1">(</span><span>t</span><span data-group-id="5791259392-1">)</span><span> </span><span data-group-id="5791259392-2">do</span><span>
  </span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="5791259392-3">(</span><span>t</span><span data-group-id="5791259392-3">)</span><span> </span><span>/</span><span> </span><span>Nx</span><span>.</span><span>sum</span><span data-group-id="5791259392-4">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="5791259392-5">(</span><span>t</span><span data-group-id="5791259392-5">)</span><span data-group-id="5791259392-4">)</span><span>
</span><span data-group-id="5791259392-2">end</span></code></pre>
<p>
One might think that Elixir takes the AST of the softmax function above and compiles it directly to the GPU. However, thatâ€™s not the case! Numerical definitions are first compiled to Elixir code that will emit the computation graph and this computation graph is then compiled to the GPU. The multiple stages go like this:</p>
<pre><code>Elixir AST
-&gt; compiles to .beam (Erlang VM bytecode)
   -&gt; executes into defn AST
      -&gt; compiles to GPU</code></pre>
<p>
This multi-stage programming is made possible thanks to Elixir macros. For example, when you see a conditional inside <code>defn</code>, that conditional looks exactly like Elixir conditionals, but it will be compiled to an accelerator:</p>
<pre><code><span>defn</span><span> </span><span>softmax</span><span data-group-id="8102420814-1">(</span><span>t</span><span data-group-id="8102420814-1">)</span><span> </span><span data-group-id="8102420814-2">do</span><span>
  </span><span>if</span><span> </span><span>Nx</span><span>.</span><span>any?</span><span data-group-id="8102420814-3">(</span><span>t</span><span data-group-id="8102420814-3">)</span><span> </span><span data-group-id="8102420814-4">do</span><span>
    </span><span>-</span><span>1</span><span>
  </span><span data-group-id="8102420814-4">else</span><span>
    </span><span>1</span><span>
  </span><span data-group-id="8102420814-4">end</span><span>
</span><span data-group-id="8102420814-2">end</span></code></pre>
<p>
In a nutshell, <code>defn</code> provides us with a subset of Elixir for numerical computations that can be compiled to specific hardware, such as CPU, GPU, and other accelerators. All of this was possible without making changes or forking the language.</p>
<p>
And while <code>defn</code> is a subset of the language, it is a considerable one. You will find support for:</p>
<ul>
  <li>
Mathematical operators  </li>
  <li>
Pipes (<code>|&gt;</code>), module attributes, the access syntax (i.e. <code>tensor[1][1..-1]</code>), etc  </li>
  <li>
Elixir macros constructs (imports, aliases, etc)  </li>
  <li>
Control-flow with conditionals (both <code>if</code> and <code>cond</code>), loops (coming soon), etc  </li>
  <li>
Transformations, an explicit mechanism to invoke Elixir code from a <code>defn</code> (which enables constructs such as <code>grad</code>)  </li>
</ul>
<p>
And more coming down the road.</p>
<h2>
Why functional programming?</h2>
<p>
At this point, you may be wondering: is functional programming a good fit for numerical computing? One of the main concerns is that immutability can be expensive when working with large blobs of memory. And thatâ€™s a valid concern! In fact, when using the default tensor backend, tensors will be backed by Elixir binaries which are copied on every operation. Thatâ€™s why it was critical for us to design <code>Nx</code> with pluggable backends from day one.</p>
<p>
However, as we move to higher-level abstractions, such as numerical definitions, we will start to reap the benefits of functional programming.</p>
<p>
For example, in order to build computation graphs, immutability becomes an indispensable tool both in terms of implementation and in terms of reasoning. The JAX library for Python, which has been one of the guiding lights for Nx design, also promotes functional and immutable principles:</p>
<blockquote>
  <p>
<em>JAX is intended to be used with a functional style of programming</em>  </p>
  <p>
â€” <a href="https://jax.readthedocs.io/en/latest/jax.ops.html?highlight=functional#indexed-update-operators">JAX Docs</a>  </p>
</blockquote>
<blockquote>
  <p>
<em>Unlike NumPy arrays, JAX arrays are always immutable</em>  </p>
  <p>
â€” <a href="https://jax.readthedocs.io/en/latest/notebooks/thinking_in_jax.html?highlight=immutable#JAX-vs.-NumPy">JAX Docs</a>  </p>
</blockquote>
<p>
Similarly, frameworks like <a href="https://thinc.ai/">Thinc.ai</a> argue that functional programming can provide better abstractions and more composable building blocks for deep learning libraries.</p>
<p>
We hope that, by exploring these ideas in a language that is functional by design, Elixir can bring new ideas and insights at the higher-level.</p>
<h2>
What is next?</h2>
<p>
There is a lot of work ahead of us â€¦</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dashbit.co/blog/nx-numerical-elixir-is-now-publicly-available">https://dashbit.co/blog/nx-numerical-elixir-is-now-publicly-available</a></em></p>]]>
            </description>
            <link>https://dashbit.co/blog/nx-numerical-elixir-is-now-publicly-available</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179373</guid>
            <pubDate>Thu, 18 Feb 2021 13:08:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Split Keyboards Gallery]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26179311">thread link</a>) | @Symbiote
<br/>
February 18, 2021 | https://aposymbiont.github.io/split-keyboards/ | <a href="https://web.archive.org/web/*/https://aposymbiont.github.io/split-keyboards/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://aposymbiont.github.io/split-keyboards/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179311</guid>
            <pubDate>Thu, 18 Feb 2021 13:01:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Moiva.io v3: a universal tool to Evaluate, Discover and Compare software]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26179252">thread link</a>) | @alexey2020
<br/>
February 18, 2021 | https://moiva.io/blog/universal-tool-to-evaluate-discover-compare-software | <a href="https://web.archive.org/web/*/https://moiva.io/blog/universal-tool-to-evaluate-discover-compare-software">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <div>
    <p><span>Feb 17 2021</span>
    <span>Â· written by</span>
    <a href="https://twitter.com/_aantipov" target="_blank">Alexey Antipov</a>
  </p></div>

  <p>Hi, Alexey is here. I have some exciting news for you!</p>
<p>I rewrote <a href="https://moiva.io/">Moiva.io</a> from scratch and made it a Universal and Flexible tool to suit a taste of every software developer be they a JavaScript, Python or [put your favorite language here] developer.</p>
<p>This article marks a third major release of Moiva.</p>
<p><img src="https://moiva.io/blog/images/universal-tool/full.png" alt="A screenshot of Moiva.io showing comparison of Vue and Svelte npm packages"></p>
<h2 id="whats-new-in-short">Whatâ€™s new (in short)</h2>
<ul>
<li>ability to search for and get data for any GitHub repository in addition to search and comparison of NPM packages.</li>
<li>possibility to bring (relatively easy) Search, Suggestion, and Comparison capabilities to other programming languages' package management systems like <a href="https://mvnrepository.com/">Maven</a> (Java), <a href="https://pypi.org/">PIP</a> (Python), or <a href="https://packagist.org/">Packagist</a> (PHP).</li>
<li>last but not least, Moiva got <a href="https://github.com/aantipov/moiva">open-sourced</a>.</li>
</ul>
<h2 id="why-i-did-it">Why I did it</h2>
<p>At first, I wanted to focus on JavaScript ecosystem, making npm packages first-class citizens in Moiva.io.</p>
<p>The goal was to provide developers with a good tool to evaluate and compare npm packages in different dimensions - Popularity, Maintenance, Security, etc.</p>
<p>But very soon I realized that there are many JavaScript-related projects which donâ€™t have any published npm packages.</p>
<p>Think of, for example, frameworks like <code>Meteor</code>.</p>
<p>Moiva.io could potentially be useful for the evaluation of those projects as well thanks to GitHub charts (Contributors, Issues, Commits Frequency, etc.), but search functionality was limited to npm packages only and everything was built around the concept of npm packages.</p>
<p>On the other hand, if Moiva gets opened up to the search, evaluation and comparison of <strong>any</strong> GitHub project, it will essentially convert Moiva into a universal tool and make it useful to many more developers.</p>
<p>So I got convinced that Moiva should become more Universal and Agile, I just need to come up with a good harmonious concept of how it should look, work and how to implement it.</p>
<h2 id="aha-moment">AHA moment</h2>
<p>In the beginning, the idea of supporting GitHub looked vague and blurred. I didnâ€™t have any good idea how to put together existing functionality for npm packages and the new one for GitHub repositories.</p>
<p>I could implement separate pages for npm and GitHub, but that was not ideal. Both have a lot in common when comparing JavaScript projects.</p>
<p>Then the <code>AHA</code> moment came - everything became clear, I realized how to put together different things and since then I was unstoppable.</p>
<p>Here is the essence of the solution.</p>
<h3 id="one-search-for-all">One Search for All</h3>
<p>The same single search field can be used to search for both npm packages and GitHub repositories. It can be easily achieved via search modifiers (prefixes).</p>
<p>The default search is for GitHub.</p>
<p>The search prefixed with <code>n:</code> is for npm packages.</p>
<p><img src="https://moiva.io/blog/images/universal-tool/search.gif" alt="A gif showing how Search field at Moiva.io works: search for NPM packages and GitHub repositories"></p>
<p>What I like about that solution is that it can be easily extended in the future to search for other things as well.</p>
<h3 id="show-only-relevant-charts">Show only relevant charts</h3>
<p>If a user selects only GitHub repositories without related npm packages, then we can just hide npm-related charts. No reason to show them.</p>
<p>Itâ€™s similar to how ThoughtWorks TechRadar and Developer Usage charts work - they are shown only when there is data for the selected npm packages.</p>
<p>At the same time, if the user selects a mix of npm and Github projects, we will show npm-related charts for the selected npm packages.</p>
<h3 id="how-about-urls">How about URLs</h3>
<p>Every comparison a user makes in Moiva should be easily reproducible via URL.</p>
<p>It means that Moiva should be able to derive from the URL what information to load, what to put into comparison.</p>
<p>When npm packages were the only citizens in the Moiva world, the task was solved easily - the selected npm packages' names were listed in a query parameter: <code>https://moiva.io/?compare=react+svelte+vue</code>.</p>
<p>Having 2 types of citizens, npm and Github, where one depends on the other, complicates things a bit. Moreover, we want to build a future-proof solution that can incorporate other types of citizens like PIP and Maven.</p>
<p>GitHub has a broader scope than npm and my first idea was to replace URL npm identifiers with GitHub identifiers. But there are 2 problems with it:</p>
<ul>
<li>itâ€™s not clear how to derive the npm package from the GitHub repository. At least I couldnâ€™t find the solution for that.</li>
<li>one GitHub repo can be a source of multiple npm packages. There is no 1:1 connection.</li>
</ul>
<p>It lead me to the conclusion that GitHub and npm should be referenced separately in the URL.</p>
<p>So I just decided to have separate query parameters: <code>https://moiva.io/?npm=svelte+vue&amp;github=meteor/meteor</code>.</p>
<h3 id="github-and-npm-reconciliation">GitHub and NPM reconciliation</h3>
<p>Imagine two situations:</p>
<ol>
<li>a user selects Vue as an npm package.</li>
<li>a user selects Vue as a GitHub repo.</li>
</ol>
<p>In the first situation Moiva shows npm-related data and charts like npm Downloads. In the second situation, it doesnâ€™t.</p>
<p>But is it fair? Most probably a user would expect to see the same set of information in both cases, right?</p>
<p>Could we still somehow derive information about the npm package from the GitHub repository? If yes, then we could show npm data for the selected GitHub repository.</p>
<p>Turns out we can make use of <a href="https://github.com/aantipov/moiva-catalog">Moiva Catalog</a> which was built to implement the Suggestions mechanism.
For every listed GitHub repository we can add a name of the npm package if there is one. It means we can solve the problem of the reconciliation for items listed in the catalog. And I think itâ€™s a good enough solution with which we can cover the most popular libraries.</p>
<p>We just need to take care of some details and edge cases.</p>
<ol>
<li>If a repository does have an npm package, but that package is just one of the repoâ€™s â€œby-productsâ€, then probably it doesnâ€™t make sense to show that npm package data when selecting the repository. To solve that problem, an additional flag <code>isNpmCoreArtifact</code> in the catalog can be used to indicate the â€œroleâ€ of the npm package.</li>
<li>If we successfully derive npm data from the GitHub repository, it means we essentially display the same information for both npm and GitHub and have different URL identifiers for the same page. Itâ€™s not good, especially in terms of SEO. So I decided to use npm packageâ€™s name as a URL identifier in such cases. Try load <code>https://moiva.io/?github=vuejs/vue</code> url and see what happens ;=)</li>
</ol>
<h3 id="data-model">Data model</h3>
<p>I mentioned just a few of the problems I had to solve. There were, of course, many others, like duplication handling, aliases, SEO, etc.</p>
<p>Most of the problems got a straightforward solution once I implemented a proper Data Model - I came up with a new abstraction called â€œLibraryâ€ and provided it with certain properties and behavior.</p>
<p>If you are interested, you can check the <a href="https://github.com/aantipov/moiva/">repositoryâ€™s readme</a> for more details about the Library concept.</p>
<h2 id="whats-next">Whatâ€™s next</h2>
<p>I clearly see a huge potential for <a href="https://moiva.io/">Moiva.io</a> to become a really useful tool to many developers.</p>
<p>It can grow and become better in different directions.
I will mention a few of them which look most important to me:</p>
<ul>
<li>enable search/suggestion/comparison for more languages' package systems (Maven, PIP, etc.).</li>
<li>add more useful charts and data, both generic and language/package-system specific.</li>
<li>improve significantly the alternatives suggestion system. Currently, itâ€™s based on <a href="https://github.com/aantipov/moiva-catalog">Moiva Catalog</a> and needs a lot of data to be put there. I see a way how the community could help and contribute there.</li>
</ul>
<hr>
<p>I hope I didnâ€™t waste your time and you found the reading and the project itself interesting.</p>
<p>Stay tuned and Subscribe to the newsletter. I want to publish more interesting content about Moiva development.</p>

</div></div>]]>
            </description>
            <link>https://moiva.io/blog/universal-tool-to-evaluate-discover-compare-software</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179252</guid>
            <pubDate>Thu, 18 Feb 2021 12:55:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Taking a Stand in the War on General-Purpose Computing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26179176">thread link</a>) | @TLM275
<br/>
February 18, 2021 | http://cheapskatesguide.org/articles/war-on-gp-computing.html | <a href="https://web.archive.org/web/*/http://cheapskatesguide.org/articles/war-on-gp-computing.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://cheapskatesguide.org/articles/war-on-gp-computing.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179176</guid>
            <pubDate>Thu, 18 Feb 2021 12:47:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making cracktro for a Game Boy game â€“ Quartet intro]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26179026">thread link</a>) | @retro_guy
<br/>
February 18, 2021 | https://eldred.fr/quartet | <a href="https://web.archive.org/web/*/https://eldred.fr/quartet">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="top">
			<main>
	

	<p><a href="https://makrill.itch.io/quartet"><em>Quartet</em></a> is a great homebrew Game Boy game, published by Mackerel Interactive in early 2021.
So why not do like the good old days and <a href="https://www.pouet.net/prod.php?which=87951">crack it</a>?</p>

<p>In this post(-mortem?), Iâ€™ll explain what went into creating this cracktro.
Iâ€™ll keep the most technical details out of the way until the end of this post, so it should still be a good read, even if you donâ€™t have a technical background.</p>

<!--more-->

<h2 id="context">Context</h2>

<p><a href="https://github.com/dalton-tulou">Dalton</a> released this game on Jan 8th, 2021.
Itâ€™s honestly a pretty good game in its own right, also well polished for all of DMG, SGB and GBC.</p>

<p>By the way, Dalton <a href="https://www.pouet.net/user.php?who=1289">was a demoscener back then</a>, notably on the Game Boy.
He programmed <a href="https://www.pouet.net/prod.php?which=80612">a trainer for a previous homebrew release</a>, which sparked this idea.</p>

<p>So, we set out to make a cracktro, and it had to be as polished as the base game.</p>

<h2 id="decisions">Decisions</h2>

<p>First order of business (actually second, since I started REing the ROM first) was deciding what we wanted the cracktro to be.</p>

<p>The original plan was to have something very parallax-heavy, simulating a bunch of layers; perhaps a landscape?
This eventually led to:</p>

<blockquote>
  <p>&lt;ISSOtm&gt; Playing on a Game Boy on the back seat of a car at night..?</p>
</blockquote>

<p>The plan stuck.
I drafted something real quick:</p>

<figure>
    <img src="https://eldred.fr/assets/quartet/storyboard.png" alt="Rough storyboard of the scene">
    <figcaption><i>Made quickly with GIMP, at 160Ã—144 to be sure of proportions.</i></figcaption>
</figure>

<p>Doc proposed a design fairly quickly:</p>

<figure>
    <img src="https://eldred.fr/assets/quartet/draft.gif" alt="Initial night-time draft">
    <figcaption><i>Honestly, this is pretty much the final, lol</i></figcaption>
</figure>

<p>I send pictures of me holding a GBC for reference, and he reworked the â€œcubeâ€, in his own terms :P</p>

<p>After that, I fired up <a href="https://github.com/aseprite/aseprite">Aseprite</a> to design the lightâ€™s animation:</p>

<figure>
    <img src="https://eldred.fr/assets/quartet/light.gif" alt="Light animation mockup">
    <figcaption><i>You might spot slight differences to the final. We had to make some cuts...</i></figcaption>
</figure>

<h2 id="first-implementation">First implementation</h2>

<p>I set out to display this on the actual console.
(Well, emulators, since they have debuggers :P)
I started with the monochrome console first, since it would be quicker and easier.
Believe it or not, but we were already hitting a snag.</p>

<figure>
    <img src="https://eldred.fr/assets/quartet/dmg.png" alt="Screenshot of a DMG render of the draft">
    <figcaption><i>Can you spot the problem?</i></figcaption>
</figure>

<p>See, the Game Boy only has 4 colors.
Dark for the background, dark gray for the characterâ€™s body and the window frame, light gray for the characterâ€™s head and arms, and white for the Game Boy and the light.</p>

<p>Wait, but thereâ€™s supposed to be light on top of the Game Boy!</p>

<h3 id="terrible-lcd-to-the-rescue">Terrible LCD to the rescue!</h3>

<p><a href="https://gbdev.io/pandocs/#specifications">The Game Boy has a fairly cheap LCD</a>, in accordance with Gunpei Yokoiâ€™s philosophy when designing the console.
Notably, it has a <em>really bad</em> response time: pixels take some time to change their luminance.
This tends to cause some kind of blur, especially when the whole screen moves at once.
Some games only ran at 30 fps on the Game Boy because it avoided that problem.</p>

<p>We exploit this slow response time by <a href="https://github.com/ISSOtm/quartet-intro/blob/c90fdf9534be5bd1c705db1d06761509ed5b3356/src/patch.asm#L595-L602"><em>blinking</em> the Game Boy between white and light gray</a>, effectively creating a 5th color!</p>

<video controls="" width="320px">
	<source src="https://eldred.fr/assets/quartet/first_light.webm" type="video/webm">
	<source src="https://eldred.fr/assets/quartet/first_light.mp4" type="video/mp4">

	Sorry, your browser doesn't support embedded videos, and GIFs don't play at 60 fps, so this effect doesn't show.
</video>

<p>This isnâ€™t <em>great</em>, but itâ€™s better than nothing; and besides, few are going to check it out on DMG, so itâ€™s not that big of a deal.</p>

<h3 id="sprite-carpet">â€œSprite carpetâ€</h3>

<p>Now, how to do this efficiently? We canâ€™t just store two copies of the Game Boy graphic, thatâ€™d be woefully inefficient.
No, instead, weâ€™ll use color palettes.</p>

<p>See, many retro graphics did not store colors directly, since that would take a lot of memory.
Instead, pixels stored <em>indices</em>, which were then used to index <em>color palettes</em>.
This sacrificed color diversity for memory, and enabled some effects.</p>

<p>For example, to fade out the entire screen, you wouldnâ€™t edit each pixel, youâ€™d simply change the few colors they refer to.
Lightning flashes can also be performed cheaply by temporarily replacing all colors with white.
Etc etc.</p>

<p>In our case, weâ€™ll make the Game Boy (the one the character is holding, not the console this is running on :P) use a different color palette, and weâ€™ll simply blink one color in the palette.
â€¦that said, the Game Boy only has <em>one</em> palette for its background.
Oh no!</p>

<p>(Note: Iâ€™ll be using the term â€œspritesâ€ to refer to hardware <em>objects</em>, which is technically a misnomerâ€¦ but Iâ€™m too used to it. Sorry!)</p>

<p>Well, it <em>does</em> have two separate palettes for spritesâ€¦ but now the Game Boy graphic must be rendered using sprites.
Ugh.</p>

<p>Game Boy sprites have a fixed size: either 8Ã—8 or 8Ã—16 pixels (toggled by <a href="https://gbdev.io/pandocs/#lcdc-2-obj-size">a global switch</a>).
The Game Boy graphic is 35Ã—57, so weâ€™ll need to use a lot of different sprites to make up the graphic.
Figuring out the optimal arrangement is a process I call â€œsprite carpetingâ€, and which I do in GIMP using a <em>lot</em> of layers.</p>

<figure>
    <img src="https://eldred.fr/assets/quartet/carpet.png" alt="Screenshot of the finished carpeting process" width="70%">
    <figcaption><i>Using one layer per sprite, at 50% opacity, lets me see where there's overlap, which can potentially be optimized away.</i></figcaption>
</figure>

<p>This takes <em>hours</em> of painful work.
And then I have to manually encode all the positions in codeâ€¦
And finally, I have to manually extract the relevant pixel data, and finally fix the couple mistakes I inevitably made.</p>

<figure>
    <img src="https://raw.githubusercontent.com/ISSOtm/quartet-intro/master/src/res/console_tiles.vert.png" alt="Final tile data for all the sprites" width="50%">
    <figcaption><i>This doesn't exactly match the carpeting above, since it had to change a bit down the line.</i></figcaption>
</figure>

<p>There are two reasons why the carpeting must be optimal, which pertain to two of the Game Boyâ€™s limitations: â€œ<strong>10-per-line</strong>â€ and â€œ<strong>40 sprites</strong>â€.
The Game Boy only has room for 40 sprites, though itâ€™s possible to cheat a bit (as youâ€™ll see later).
The Game Boyâ€™s <abbr title="Picture-Processing Unit">PPU</abbr> is only able to display 10 sprites <em>per scanline</em> (scanline = row of pixels).
Unlike the â€œ40 spritesâ€ limitation, there is absolutely no way to bypass this one.</p>

<p>Anyway, you saw the GIF, the console displays nicely, and the light animation works.
Since itâ€™s quite technical, I wonâ€™t get into how the light animation is achieved until near the end of this post.</p>

<p>Now that the base is there, letâ€™s move on to the next step.</p>

<h2 id="text">Text</h2>

<p>First off, Docâ€™ came up with a few fonts.</p>

<figure>
    <img src="https://eldred.fr/assets/quartet/font8x8.png" alt="8x8 font" width="50%">
    <figcaption><i>We quickly agreed that we'd need bigger characters for them to be easily legible. I still like how this looks.</i></figcaption>
</figure>

<figure>
    <img src="https://eldred.fr/assets/quartet/font_mid.png" alt="Middleground font" width="50%">
    <figcaption><i>Doc started working on 8x16 characters. I'm honestly impressed with how fast and good he is.</i></figcaption>
</figure>

<figure>
    <img src="https://eldred.fr/assets/quartet/font_final.png" alt="Final font" width="50%">
    <figcaption><i>This is essentially the final version. Shame that a lot of characters go unused in the final...</i></figcaption>
</figure>

<p>And then is a comment that I came to regret laterâ€¦</p>

<blockquote>
  <p>&lt;doc&gt; sry its a mess to work with<br>
&lt;doc&gt; shouldve been thinkin about tile space<br>
&lt;ISSOtm&gt; That should be fine<br>
&lt;ISSOtm&gt;<br><img src="https://eldred.fr/assets/quartet/tiles.png" alt="View of the tiles loaded at that time"></p>
</blockquote>

<p>At this point, I had implemented the Game Boy graphic (green tiles near the top), the characterâ€™s light animation (dark tiles in the middle) and the background (the rest), and we had plenty of space remaining.
So I thought weâ€™d be fine.
I had forgotten that I had yet to implement the Game Boyâ€™s light animationâ€¦</p>

<h2 id="interlude-rom-update">Interlude: ROM update</h2>

<p>At this point, DevEd tried to compile the code, which mysteriously failed on some asset conversion on his Mac.
I sent him my build directory, and this workedâ€”somehow.
Comp00terz, I guess?
However, the ROM that he then built misbehaved <em>a lot</em>â€”as in, it crashed.
Why?</p>

<p>Our cracktro does not contain the original gameâ€™s codeâ€”instead, we use <a href="https://rgbds.gbdev.io/docs/v0.4.2/rgblink.1#O">RGBLINKâ€™s â€œoverlayâ€ feature</a> to essentially patch the ROM in-place.
This does require obtaining a legitimate copy of the game (the â€œbase ROMâ€ / â€œbaseromâ€) in the first place, which was fairly easyâ€”just follow the link at the very top of this page to get one for free!</p>

<p>Except, as it turns out, Dalton had released a new version of the ROM!
And it also turned out that applying our patch to this version wasnâ€™t viable, ugh.
I guess it also means that our cracktro preserves an earlier version of the game?
Anyway, I sent DevEd my base ROM, and off we went.</p>

<h2 id="download-more-ram">Download more RAM?</h2>

<p>At this point, I finished implementing the Game Boyâ€™s light animation, and it was time to start working on the text.
First step was adding the font.</p>

<div><div><pre><code>ERROR: src/patch.asm(384):
    Assertion failed: Too many tiles! ($9950 &gt; $9800)
</code></pre></div></div>

<p>NOOOOOOOOOOOOOOO</p>

<p>We had more tiles than the Game Boyâ€™s video RAM could contain at once.
Were we doomed?
<em>At once</em>â€¦</p>

<p>Itâ€™s not necessary to keep the entire animationâ€™s tiles loaded at all times, since only the current frameâ€™s are displayed.
See where this is going?
We can load new tiles from ROM on each new frame!</p>

<h3 id="access-granted">Access granted</h3>

<p>The catch is that accessing the Game Boyâ€™s video memory has to be the most annoying thing on that platform.
There are two chips that can try to access video RAM: the <abbr title="Central Processing Unit">CPU</abbr>, and the <abbr title="Picture Processing Unit">PPU</abbr>: the former as part of the game program, the latter to push pixels to the LCD.</p>

<p>Thing is, the PPU has priority over the CPU for accessing <abbr title="Video RAM">VRAM</abbr>.
While the PPU is â€œlockingâ€ VRAM, reads from the CPU return <code>$FF</code>, and importantly for us, <strong>all writes are silently ignored</strong>.
I wonâ€™t go into too much detail into this, but this, and the way the light animation is performed, severely restrict how much time can be spent writing to VRAM, and thus, how many tiles we can load per frame.</p>

<p>If youâ€™re curious, <a href="https://github.com/ISSOtm/quartet-intro/blob/c90fdf9534be5bd1c705db1d06761509ed5b3356/src/patch.asm#L612-L633">this is the tile-streaming code</a>.</p>

<h2 id="music-time">Music time!</h2>

<p>Alright, the looks are good, so letâ€™s start to work on the audio side of things.
Since we donâ€™t have much free space, we were looking to reuse <em>Quartet</em>â€™s own sound player, if possible.
We knew it uses a modified version of <a href="http://gbdev.gg8.se/files/musictools/Aleksi%20Eeben/Carillon%20Editor.zip">Carillon</a>, we just had to figure out if it was possible to integrate with it, and how.</p>

<p>As it turned out, <em>Quartet</em> stores its music data compressed, and so fetches it all from RAM!
This was a blessing for us, since we just needed to do the same.
There was one catch, though: the pattern data format had been changed.</p>

<p>Music data, on many chiptune systems, has two parts: instrument data, which mostly defines their <a href="https://en.wikipedia.org/wiki/Timbre"><em>timbre</em></a>; and â€œpatternâ€ data, which is essentially a score, telling when to play a note with which instrument.</p>

<p>Instrument data was 1:1 with how vanilla Carillon generated it, but the pattern data went through some hoops I couldnâ€™t wrap my head around.
In the end, we decided to <a href="https://github.com/ISSOtm/quartet-intro/blob/c90fdf9534be5bd1c705db1d06761509ed5b3356/src/patch.asm#L970-L974">reuse most of <em>Quartet</em>â€™s code</a>, but <a href="https://github.com/ISSOtm/quartet-intro/blob/c90fdf9534be5bd1c705db1d06761509ed5b3356/src/patch.asm#L975-L1196">embark the vanilla playerâ€™s version of the pattern-reading code</a>.
Figuring out how to reuse <em>Quartet</em>â€™s pattern-reading code could have spared us some ROM space, but definitely not headaches.
Oh well, the project is open-source, youâ€™re welcome to try your hand at this if youâ€™re interested :^)</p>

<p>You may be wondering about the SGB-specific music, but Iâ€™ll â€¦</p></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://eldred.fr/quartet">https://eldred.fr/quartet</a></em></p>]]>
            </description>
            <link>https://eldred.fr/quartet</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179026</guid>
            <pubDate>Thu, 18 Feb 2021 12:27:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I am a heroin user. I do not have a drug problem]]>
            </title>
            <description>
<![CDATA[
Score 261 | Comments 625 (<a href="https://news.ycombinator.com/item?id=26179003">thread link</a>) | @CapitalistCartr
<br/>
February 18, 2021 | http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem | <a href="https://web.archive.org/web/*/http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			<p><span>C</span>arl Hart is a neuroscientist and Ziff Professor of Psychology at Columbia Universityâ€”he was the first tenured African-American professor of sciences at Columbia. His research focuses on the â€œbehavioral and neuropharmacological effects of psychoactive drugs in humans.â€ Hartâ€™s new book, <i>Drug Use For Grown-Ups</i>, is a bold and engaging effort to counter what he sees as generations of misinformation and moral grandstanding about drug use. Todayâ€™s â€œsensationalistic media coverage of the opioid crisis continues a long, awful tradition of exploiting ignorance and fear to vilify certain members of our society,â€ Hart writes. The media is not the only problem. Scientists, he states, â€œhave frequently overinterpreted and distortedâ€ drugsâ€™ effects on the brain.</p><p>Hart reports that more than 70 percent of drug usersâ€”whether they use alcohol, cocaine, prescription medications, or heroinâ€”do not meet the health criteria for drug addiction. In <i>Drug Use for Grown-Ups</i>, Hart strives to â€œpresent a more realistic image of the typical drug user: a responsible professional who happens to use drugs in his pursuit of happiness.â€ With genial candor, Hart presents himself as a model drug user. â€œI am now entering my fifth year as a regular heroin user,â€ he writes. â€œI do not have a drug-use problem. Never have. Each day, I meet my parental, personal, and professional responsibilities. I pay my taxes, serve as a volunteer in my community on a regular basis, and contribute to the global community as an informed and engaged citizen. I am better for my drug use.â€</p><p><i>Nautilus</i> caught up with Hart to discuss his drug use and his sharp points about science and society. He was as casually bold in conversation as he is in <i>Drug Use for Grown-Ups</i>.</p><figure data-alt="MacNamara_BREAKER"><img src="http://static.nautil.us/18174_0f004440ba0c8f1ccc5c355f3d77207f.png" width="733" alt=""><figcaption><span><strong>HABIT OF A HIGHLY EFFECTIVE PERSON:</strong> â€œMy heroin use is as rational as my alcohol use,â€ Carl Hart writes. â€œLike vacation, sex, and the arts, heroin is one of the tools that I use to maintain my work-life balance.â€</span><span>Courtesy of Carl Hart</span></figcaption></figure><p><b>You say â€œmost drug-use scenarios cause little or no harm and that some responsible drug-use scenarios are actually beneficial for human health and functioning.â€ How so?</b></p><p>Letâ€™s just talk about alcohol first. When youâ€™re at a wedding reception, alcohol serves as a social lubricant. People are more gregarious. They talk, they interact. The same is true with cocaine at parties, heroin among friends, or opium among friends, NDMA among lovers. It enhances empathy, openness, and forgiveness, all of these pro-social attributes.</p><p><b>Drug research, you write, is full of bad science. If you had to name one example, what would it be?</b></p><p>The notion that drug addiction is a brain disease. That encapsulates all thatâ€™s wrong with todayâ€™s science in this area. There is absolutely no data in humans to show that drug addiction is a brain disease. Yet the narrative, the dogma, the dominant perspective is that it does. Even though nobody will dispute that, thereâ€™s absolutely no data in humans to support that statement.</p><p><b>Yet opioids do change the brain biologically, do they not?</b></p><p>Yes, opioids bind to a class of receptors called endogenous opioids, which you find in endorphins, for example. Opioids bind to these receptorsâ€”just like natural chemicals doâ€”which results in a response. In some cases, because of decreased sensitivities and certain types of pain, they may enhance a sense of euphoria. So itâ€™s really just facilitating whatâ€™s already in the body naturally, a system that helps in our survival. Think of fructose or glucose. We add sugar to our tea, our coffee, whatever we have, we add more and more because we like it, it tastes good, and it enhances pleasure. It can give you energy. It can make life more interesting. Humans do not live on logic alone. And so sometimes we do these things, and thatâ€™s OK.</p><blockquote><p>People become addicted because they once had a middle-class-paying job that made them someone in their community.</p> </blockquote><p><b>How have scientists â€œoverinterpreted and distortedâ€ the effects of drugs on the brain?</b><br></p><p>Take brain imaging. People often show one image of someoneâ€™s brain. Letâ€™s say this person is addicted to methamphetamine, according to DSM criteria, versus the brain of someone whoâ€™s not addicted. If you see some difference, some researchers have a propensity to make more out of the differences than are there. Thereâ€™s a wide range of brain structural sizes, such that when we think about one personâ€™s size of their nucleus accumbens, it may be smaller or larger than somebody elseâ€™s nucleus accumbens. But both of the nucleus accumbens, despite their sizes, are within the normal range of human variability. Itâ€™s like height. One guy might be 5â€™10â€, another guy might be 6â€™2â€. But we donâ€™t say the guy whoâ€™s 5â€™10â€ is height deficient. We just say that heâ€™s in a normal range, and heâ€™s not as tall as the other guy. We wouldnâ€™t say one is deficient versus the other. In neuroscience, one of the things that has happened, particularly when it comes to drugs, people have over-interpreted the differences to mean pathology, when, in fact, both of the brain structures are within the normal range of human variability. The overinterpretation is to interpret it as being pathological.</p><p><b>You say the opioid crisis has been sensationalized, and write, â€œPeople are not dying because of opioids; they are dying because of ignorance.â€ What do you mean?</b></p><p>Some people donâ€™t know not to mix specific sedatives with opioids. For example, they donâ€™t know not to mix large amounts of alcohol or large amounts of antihistamines. Specific combinations can lead to respiratory depression, which can lead to death. Another point of ignorance involves people who buy street drugs and donâ€™t necessarily know if the drugs contain contaminants. Thatâ€™s the kind of ignorance Iâ€™m talking about.</p><div>
<article>
<p><a href="http://m.nautil.us/issue/91/The%20Amazing%20Brain/our-mind_boggling-sense-of-smell" data-trval="our-mind_boggling-sense-of-smell" data-trlbl="foc_rec" data-tract="internal_art">
<img src="http://static.nautil.us/17790_d881b3c19eeb9941a2ae1b1afe343442.png" alt="Sapolsky_TH-F1" width="314" height="177">
</a>
</p>
<div>
<p><span>
<span>

<span><a href="http://m.nautil.us/term/f/Neuroscience">Also in Neuroscience</a></span>&nbsp;&nbsp;</span>
</span></p><h4><a href="http://m.nautil.us/issue/91/The%20Amazing%20Brain/our-mind_boggling-sense-of-smell" data-trval="our-mind_boggling-sense-of-smell" data-trlbl="foc_rec" data-tract="internal_art">Our Mind-Boggling Sense of Smell</a></h4>
<p>By Ann-Sophie Barwich</p>
<p>
You might say the brain is our most photogenic organ. We are, thanks to modern neuroimaging, living amid an explosion of brain data. Just consider: We can zoom into the brainâ€™s connectivity to the most minute, molecular level. We can...<strong><a href="http://m.nautil.us/issue/91/The%20Amazing%20Brain/our-mind_boggling-sense-of-smell" data-trval="our-mind_boggling-sense-of-smell" data-trlbl="foc_rec" data-tract="internal_art">READ MORE</a></strong>
</p>

</div>

</article>
</div><p><b>So itâ€™s the mix of drugs that is the problem, not opioids like heroin themselves?&nbsp;</b></p><p>Yes, the majority of opioid deaths occur as a result of combining opioids with multiple sedatives. But there are certain opioids that do concern us if taken alone and the person isnâ€™t aware that they have this particular opioid. Those are fentanyl and the fentanyl analogs. These drugs are a lot more potent than something like heroin, meaning they require less of it to produce the effect. Most of the public arenâ€™t seeking fentanyl or its analogs, but people are tainting things like heroin and oxycodone pills with fentanyl or an analog.</p><p>One way to deal with this tainting, this contamination, is to have free drug-checking facilities, where people can submit samples of their drug and get a chemical readout of what is contained in the substance. That way theyâ€™ll know whether to take the substance or how much of it to take. The public also needs to know that most people who use these drugs are not addicts. If you understand that, then you know that for the people who do become addicted, we have to look beyond the drug and look at the personâ€™s environment, their life. Do they have co-occurring psychiatric illnesses? Do they have pain that is not treated? All of these kinds of issues become important.</p><p><b>At what point does biological change in the brain lead to physical addiction?</b></p><p>Physical addiction occurs as a result of opioidsâ€”or any other drug, alcohol tooâ€”being in the body for consecutive weeks or periods, in particularly high doses. And then the body tries to compensate. For example, with opioids, one of the things that happens is that your gut, your gastrointestinal system, slows down the receptors. Your body is trying to compensate by speeding up the gastrointestinal tract. So when the drug abruptly leaves after several weeks of constant administration of the opioid, now the body is unprepared for the drug not being there and it overcompensates. It really ramps up the motility of the gastrointestinal tract, which causes diarrhea, among other things.</p><blockquote><p>It can give you energy. It can make life more interesting. Humans do not live on logic alone.</p> </blockquote><p><b>Why do some people get addicted and not others?</b><br></p><p>The amount of drugs they take, the period at which they take it. Some people can take opioids for extended periods of time. As long as they keep the doses fairly low and they donâ€™t take multiple doses a day, they probably wonâ€™t experience physical dependence. Itâ€™s just like with alcohol. Most people drink alcohol on a regular basis, but they donâ€™t become physically dependent. Whereas others drink every day in large amounts, and they will become physically dependent.</p><p><b>Why canâ€™t people overcome addiction?</b></p><p>One of the major reasons people canâ€™t overcome it is because weâ€™re not very good at treating addiction in this country. Just think about why people become addicted. A large number become addicted because of co-occurring psychiatric illnesses, because of pain issues, because they once had a middle-class-paying job that made them someone in their home, someone in their community. Those jobs are gone. Then thereâ€™s no healthcare or thereâ€™s poor education. If your treatment is not addressing these issues, people are not going to overcome it. But if we have treatments that are holistic, and theyâ€™re looking at the individual, and not so much the drug, then weâ€™re good. But if weâ€™re just talking about the drug, then weâ€™re already behind the eight ball, then we will lose that battle.</p><p><b>Your definition of addiction follows the DSM-5, which refers to a â€œsubstance use disorderâ€ and values functioning over regular ingestion of a substance. How do you define â€œfunctioningâ€?</b></p><p>Functioning is determined by whether a user is happy in meeting their obligations, whatever they may be, whether theyâ€™re work-related, whether theyâ€™re family-related, or other social sorts of things. The person is not stressed out about their substance â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem">http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem</a></em></p>]]>
            </description>
            <link>http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179003</guid>
            <pubDate>Thu, 18 Feb 2021 12:23:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Danish Immigration Policies]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26179000">thread link</a>) | @HaoZeke
<br/>
February 18, 2021 | https://www.thelocal.dk/20210216/denmark-imprisons-international-student-at-migrant-facility-after-visa-overstay | <a href="https://web.archive.org/web/*/https://www.thelocal.dk/20210216/denmark-imprisons-international-student-at-migrant-facility-after-visa-overstay">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://storage.googleapis.com/ddos-shield.appspot.com/shield-logo-mono-darktext.svg" width="250px" height="50px" alt="Project Shield Logo"></p><p>You will be connected to <b>www.thelocal.dk</b> in just a moment...</p><p><a href="https://g.co/shield">Learn about Project Shield</a></p></div></div>]]>
            </description>
            <link>https://www.thelocal.dk/20210216/denmark-imprisons-international-student-at-migrant-facility-after-visa-overstay</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179000</guid>
            <pubDate>Thu, 18 Feb 2021 12:23:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build Pipeline Security]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26178756">thread link</a>) | @oxinabox
<br/>
February 18, 2021 | https://sprocketfox.io/xssfox/2021/01/18/pipeline/ | <a href="https://web.archive.org/web/*/https://sprocketfox.io/xssfox/2021/01/18/pipeline/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>
      
  <p><em>This occurred on an AWS website (not a site hosted on AWS, but a site run by AWS). It shows that security is hard, even for a $51 billion business. This issue can occur not just on websites but even SDKs and libraries</em></p>
<p><img src="https://sprocketfox.io/xssfox/pipeline/erik-mclean-TNjdgCBRMeU-unsplash.jpg" alt="Fox smelling the road"></p>
<blockquote>
<p>ğŸ“¸ Erik Mclean via unsplash</p>
</blockquote>
<p>While developers have a keen nose for <a href="https://en.wikipedia.org/wiki/Code_smell">code smells</a> us operations types have a keen nose for infrastructure smells. When I opened this git repository for first time it hit me. A <code>buildspec.yml</code> file.</p>
<h3 id="the-humble-buildspecyml">The humble <code>buildspec.yml</code></h3>
<p>For those unfamiliar, <code>buildspec.yml</code> is used by a service called <a href="https://docs.aws.amazon.com/codebuild/latest/userguide/build-spec-ref.html">CodeBuild</a> and basically defines the steps used to build a project, including running shell commands. Itâ€™s basically remote code execution as a service.</p>
<p>The presence of this file in a repository isnâ€™t call for alarm, but when itâ€™s in a public repository it certainly raises red flags. The usual concern is someones committed some secret credentials into this file. In this case the file was clean of credentials.</p>
<p>All good right? Not so fast.</p>
<p><img src="https://sprocketfox.io/xssfox/pipeline/lachlan-gowen-cWwqwN2uTo4-unsplash.jpg" alt="Fox sleeping"></p>
<blockquote>
<p>ğŸ“¸ Lachlan Gowen via unsplash</p>
</blockquote>
<h3 id="notices-your-deploysh"><em>notices your <code>deploy.sh</code></em></h3>
<p>The <code>buildspec.yml</code> referenced a <code>deploy.sh</code>. This is when I verbally said â€œoh noâ€. Like before no secrets committed. A good start. <code>deploy.sh</code> contains instructions to deploy out the project - like <code>aws s3 sync</code> and the like, so we can determine that when this gets run it has access to upload to the production site.</p>
<p><img src="https://sprocketfox.io/xssfox/pipeline/nathan-anderson-3Lazy6QQR6c-unsplash.jpg" alt="Fox yelling"></p>
<blockquote>
<p>ğŸ“¸ Nathan Anderson via unsplash</p>
</blockquote>
<p>The issue here is that the <code>buildspec.yml</code> and <code>deploy.sh</code> could be modified by a malicious user.</p>
<h3 id="the-pull-request">The pull request</h3>
<p>However malicious user doesnâ€™t have access to commit to the repository and an admin isnâ€™t going to merge malicious code, so this is no big deal right? Letâ€™s see what happens when we lodge a pull request.</p>
<p>Upon creation of the pull request GitHub triggers a CodeBuild job. This is a fairly common practice to make sure nothing in the pull request breaks the build. What prevents the pull request build from deploying to production? Lets check <code>deploy.sh</code></p>
<div><pre><code data-lang="sh"><span>if</span> <span>[[</span> <span>"</span>$CODEBUILD_WEBHOOK_HEAD_REF<span>"</span> <span>==</span> <span>"refs/heads/main"</span> <span>&amp;&amp;</span> <span>${</span>CODEBUILD_SOURCE_VERSION:0:3<span>}</span> !<span>=</span> <span>"pr/"</span> <span>]]</span>; <span>then</span>
</code></pre></div><p>oh no.</p>
<p>So deployment is purely controlled by a script that can be changed in the pull request.</p>
<p><img src="https://sprocketfox.io/xssfox/pipeline/scott-walsh-7LzKELgdzzI-unsplash.jpg" alt="Fox in grass"></p>
<blockquote>
<p>ğŸ“¸ Scott Walsh via unsplash</p>
</blockquote>
<h3 id="one-last-chance">One last chance</h3>
<p>At this stage weâ€™ve got remote code execution into the pipeline. Apart from <a href="https://www.vice.com/en/article/nzkxgm/bitcoin-mining-github-open-source-bots">mining some Bitcoin</a> this is pretty uneventful. What about the S3 sync we mentioned earlier? Itâ€™s possible that the role granted for pull requests is the same role used for deploying to production, so lets check it out.</p>
<p>I edited the shell script to have my code right at the start â€¦</p>
<div><pre><code data-lang="sh">echo <span>"testing a security issue"</span> &gt; test.html
aws s3 cp test.html s3://target_bucket/test.html
aws cloudfront create-invalidation --distribution-id $CLOUDFRONT_DIST_ID --paths <span>"/*"</span>
exit <span>1</span>
</code></pre></div><blockquote>
<p><code>target_bucket</code> value was recovered from original <code>deploy.sh</code></p>
</blockquote>
<p>â€¦ and lodged a pull request. I checked the website and sure enough my file was there. ğŸ˜®</p>
<p><img src="https://sprocketfox.io/xssfox/pipeline/nathan-anderson-XHK0JdmJxJc-unsplash.jpg" alt="Fox licking lips"></p>
<blockquote>
<p>ğŸ“¸ Nathan Anderson via unsplash</p>
</blockquote>
<h3 id="it-doesnt-end-there">It doesnâ€™t end there</h3>
<p>Itâ€™s quite possible that the role used for deployment might have access to lots of interesting things, a private subnet, IAM admin, CloudFormation. I didnâ€™t check further than this and submitted a disclosure reported to the security team immediately.</p>
<h3 id="prevention">Prevention</h3>
<p>If you still want pull requests to trigger builds on a public repository there a couple of things you can do to limit risk.</p>
<p>Place build scripts in a separate repo. Some build tools let you specify a separate repo to use for the build pipeline. Be careful though as this doesnâ€™t guarantee that the project build canâ€™t execute commands, depending on the programming language and build tools.</p>
<p>For services like CodeBuild you can utilize a separate IAM role for pull requests which is limited to just build requirements. Make sure the build agents for PRs arenâ€™t within a a trusted network.</p>




      
        
      
    </article>
    
    
      

    
  </div></div>]]>
            </description>
            <link>https://sprocketfox.io/xssfox/2021/01/18/pipeline/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26178756</guid>
            <pubDate>Thu, 18 Feb 2021 11:50:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Andy Warhol Museum Amiga Exhibit â€“ Iontank]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26178729">thread link</a>) | @rbanffy
<br/>
February 18, 2021 | https://www.iontank.com/projects/warhol-amiga | <a href="https://web.archive.org/web/*/https://www.iontank.com/projects/warhol-amiga">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span>
        How does one reliably display digital artwork originally created by Andy Warhol on the Amiga 1000 in the 80s? This was the challenge laid out for Iontank by The Andy Warhol Museum after Cory Arcangel and a team from Carnegie Mellon Universityâ€™s Computer Club successfully recovered digital Warhol images from floppy disks that had gone overlooked in the museumâ€™s archives. <p> Iontank proposed creating Amiga replicas out of decommissioned Amiga 1000s. All internal components were replaced with new solid-state hardware so the units would be more stable as they toured the globe, but Iontank also took great care to restore and integrate the original mice and keyboards so they would work with the new systems. Even the lights on the monitor and case illuminate as intended. </p><p> Replacements for the antique CRT screens were also prototyped. Promising projection tests were ultimately abandoned in favor of an industrial LCD screen, but it still lacked the dimensionality of a CRT. The solution was for Iontank to mill a clear acrylic lens that mated perfectly with the original monitor housing and matched the original screen curvature. To complete the illusion, Iontank created a custom Amiga 1000 emulator and file system to allow users to explore the images themselves. The emulator even recreated the slow disk access and lag of the beloved Amiga.</p><p> A second version of the Warhol Amiga system was also commissioned that allows users to experiment with a simulation of the GraphiCraft application Warhol had used. This Amiga lets visitors capture images using a digital camera and try their hand at creating Warhol-inspired artworks of their own.
      </p></span>
    </p></div>]]>
            </description>
            <link>https://www.iontank.com/projects/warhol-amiga</link>
            <guid isPermaLink="false">hacker-news-small-sites-26178729</guid>
            <pubDate>Thu, 18 Feb 2021 11:45:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Why of Technology]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26178726">thread link</a>) | @mpereira
<br/>
February 18, 2021 | https://www.murilopereira.com/the-why-of-technology/ | <a href="https://web.archive.org/web/*/https://www.murilopereira.com/the-why-of-technology/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure><img src="https://www.murilopereira.com/man_on_a_bicycle.jpg"></figure><blockquote><p>I think one of the things that really separates us from the high primates
is that weâ€™re tool builders. I read a study that measured the efficiency of
locomotion for various species on the planet. The condor used the least
energy to move a kilometer. Humans came in with a rather unimpressive
showing about a third of the way down the list. It was not too proud a
showing for the crown of creation. So, that didnâ€™t look so good.</p><p>But then, somebody at Scientific American had the insight to test the
efficiency of locomotion for a man on a bicycle. And, a man on a bicycle, a
human on a bicycle, blew the condor away, completely off the top of the
charts.</p><p>And thatâ€™s what a computer is to me. What a computer is to me is itâ€™s the
most remarkable tool that weâ€™ve ever come up with.</p><p>Itâ€™s the equivalent of a bicycle for our minds.</p><p>â€” <a href="https://www.youtube.com/watch?v=0lvMgMrNDlg&amp;feature=youtu.be&amp;t=322">Steve Jobs (1980)</a></p></blockquote><p>* * *</p><p><a href="https://www.it-hiroshima.ac.jp/institution/library/pdf/research52%5F007-013.pdf">No one knows</a> when or how we, the human species, started talking to each
other. It is likely a natural progression from gesturing, but we can only
speculate about it.</p><p>Language allowed us to break out of our brains and reveal the inner
workings of our consciousness to others.</p><figure><img src="https://www.murilopereira.com/language_speech.jpg" alt="Figure 2: Scott H. Young"><figcaption><p>Figure 2: <a href="https://www.scotthyoung.com/blog/2018/12/04/25-thinking-tools/">Scott H. Young</a></p></figcaption></figure><p>Language is the vessel that carried us from the stone age through the
agricultural revolution, the development of written language, the
scientific and industrial revolutions, and now, the digital age.</p><p>Writing allowed us to <em>offload</em> memories to the physical worldâ€”outside of
our brains. Through our collective and external memories, each generation
has a head start on the previous one. Little by little, standing on the
shoulders of taller and taller giants, we accumulate knowledge about
ourselves and everything around us.</p><p>Weâ€™ve been for long using tools to help us think: notebooks help us
calculate formulas, reason geometrically and preserve our ideas. With
computers, our <em>thinking</em> is now occurring outside of our brains.</p><p>Computers are extensions of our minds in that they allow us to store,
process, and retrieve information from them. With the advent of the
internet we now have immediate access to not only almost all of the
information ever produced by humankind but also to reproducible <em>thinking</em>
encoded into these machines: algorithms.</p><p>Our brain is still a much more impressive device than any of today's
computers. Computers learn
<a href="https://www.davidsilver.uk/wp-content/uploads/2020/03/nfsp-1.pdf">mostly</a>
by finding patterns in massive
quantities of examples given by us. Teaching a young kid about carsâ€”how
to recognize one, what they are, what their purpose is, and how they're
related to other thingsâ€”requires little supervision. Noam Chomsky talks
about it in
<a href="https://www.youtube.com/watch?v=hdUbIlwHRkY&amp;t=1462">this interview</a>.</p><p>Each of these processesâ€”storing, processing and retrieving
informationâ€”have concrete effects on the physical world: if Iâ€™m in
Munich, saying â€œshow route to Hamburgâ€ to my phone will immediately show me
the distance, ETAs and paths for different types of transport to reach my
destination. Not only do I now suddenly know how to navigate across the
country to reach another city, Iâ€™m also able to follow through the exact
path via GPSâ€”a sixth sense giving me perfect geolocation!</p><p>These <em>things</em> that we createdâ€”computers, and the internetâ€”are literally
<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6502424/">rewiring our brains</a>, right now, shaping how we think, and engage in social
relationships, changing not only our individual selves but the societies we
live in.</p><p>They started as mechanical machines that filled entire laboratories, turned
into beige boxes in our homes and places of work, and are now sleek slabs
of plastic, metal and glass in everyoneâ€™s pockets. Step by step they get
closer to our bodies, their interfaces more intuitive and natural.</p><p>The way we communicate with them is changing: before, we could only
interact with them by speaking their language. We have now taught them
ours. The torch of progress blazes on: itâ€™s a matter of <em>time</em> until theyâ€™re
connected directly with our brainsâ€”which is equally terrifying and
awe-inspiring.</p><figure><img src="https://www.murilopereira.com/neuralink.jpg" alt="Figure 3: Neuralink"><figcaption><p>Figure 3: <a href="https://neuralink.com/">Neuralink</a></p></figcaption></figure><p>Brain-computer interfaces present a monumental scientific and engineering
challenge, and brain-to-brain, a whole other category of difficulty.</p><p>First, we have no idea how information is encoded in the brain. That needs
to be understood. Second, even assuming weâ€™re able to take a perfect
snapshot of a piece of information in someoneâ€™s brainâ€”for example, how a
particular movie scene makes them feelâ€”we still need to be able to encode
it in a way that includes the full context of their subjective experiences.
Maybe the scene evokes unique memories of their childhood or is somehow
entangled with the smell of a particular cinemaâ€™s leather seats. Third, we
need to figure out how to safely write this perfect snapshot into someone
elseâ€™s brain in a way that can be perceived identically.</p><p>Which is to say, itâ€™s a difficult problem. But a worthwhile one: imagine
having the capability to suddenly become aware of answers for questions you
just thought about. To expertly control <a href="https://youtu.be/PLk8Pm%5FXBJE?t=13">truly integrated</a> prosthetics giving
you superhuman abilities. To give movement to the paralized, sound to the
deaf, and sight to the blind.</p><p>What would be the impacts on society if we were able to communicate an
order of magnitude more effectively? What if <em>everyone</em> was equipped with
the same undisputed basic knowledge of history and science?</p><p>There are internal thoughts that we can attempt to describe with a thousand
words, but ultimately fail to capture in a way thatâ€™s precise, much less
comprehensible by someone else. Words and sentences are an incomplete
representation of our internal thoughts. In the same way that 3D objects
cast 2D shadows (<a href="https://www.youtube.com/watch?v=N0WjV6MmCyM">and 4D, 3D</a>) communicating through language doesnâ€™t carry
all of our cultural and developmental contextâ€”transmitting all of that
along with every phrase would be impractical. Language is in this sense,
lossily compressed thought.</p><figure><img src="https://www.murilopereira.com/tesseract_shadow.jpg"></figure><p>Inert strings of words of ink and paper take a life of their own inside our
heads. Itâ€™s why the exact same information can be interpreted completely
differently by different people.</p><p>Before language, fire and cooking technology allowed us to reallocate
energy usage from the digestive system to the brain by outsourcing
digestion to outside of our bodies, making macronutrients more efficiently
absorbable. Almost all of a cooked meal is metabolized by the body, whereas
raw foods yield less than half of their nutrients.</p><p>Cooking is an extension of our digestive system, and enabled us to develop
large, calorie-hungry brains. It also gave us time to think: our primate
cousins spend half of their days chewing raw food to consume enough
calories to stay alive.</p><p>Brains can be seen as <em>survival machines</em>, locked inside dark skulls,
constantly building a model of the outside world by predicting and learning
through senses and memory. The biological human brain evolved to have the
necessary sophistication to not only expertly navigate and understand the
brute physical reality but also to construct <em>social</em> reality. Democracy,
religion, money: all made up by us, for us.</p><p>We remember the past so that we can predict the future, and by doing so, we
thrive.</p><p>We create technology, which functions as a non-biological extra layer to
our brains and bodies, augmenting, complementing, and sometimes replacing
our natural capabilities.</p><blockquote><p>The wheelâ€¦ is an extension of the foot.</p><p>The bookâ€¦ is an extension of the eyeâ€¦</p><p>Clothing, an extension of the skinâ€¦</p><p>Electric circuitry, an extension of the central nervous system.</p><p>â€”
<a href="https://en.wikipedia.org/wiki/Understanding_Media">Understanding Media: The Extensions of Man (1964)</a></p></blockquote><p>Relatively speaking, we are done evolving <em>biologically</em>. Further adaptations
and enhancements to our bodies and minds will come through technology.</p><figure><img src="https://www.murilopereira.com/brain_layers.jpg" alt="Figure 5: Check out &amp;ldquo;Neuralink and the Brain&amp;rsquo;s Magical Future&amp;rdquo; for a very entertaining primer on the brain."><figcaption><p>Figure 5: Check out â€œ<a href="https://waitbutwhy.com/2017/04/neuralink.html">Neuralink and the Brainâ€™s Magical Future</a>â€ for a very entertaining primer on the brain.</p></figcaption></figure><p>To be human is to have the ability to change the world around us. The shift
from hunting and gathering to farming allowed us to spend less energy to
acquire food while giving us a predictable calorie supply.</p><p>The resulting food surplus made it possible for populations to settle down
and grow quickly while supporting people not being directly involved in the
production of foodâ€”before agriculture that was everyoneâ€™s job. For one,
it allowed some to specialize and focus on developing better farming tools
and more resistant crops, starting a vicious cycle of improvement and
consumption that continues until today.</p><p>The transition from active foraging to a more sedentary lifestyle resulted
in worse health for the general population. The average farmer worked
harder than the average forager and got a worse diet in return. Our teeth,
bones and joints became more fragile, and we became afflicted by novel
diseases coming from newly domesticated animals, carriers of pathogens that
incubated in our new densely populated cities.</p><p>Owning land suddenly became really important. Agriculture and the concept
of private property reinforced each other and grew together, allowing us to
create value and secure the fruits of our labor. It also created the
circumstances for slavery to arise, and wars to be waged.</p><p>The groups of people growing the first crops could not have anticipated all
of the collateral effects of their breakthrough. They just wanted more
food.</p><p>If the past has taught us anything is that we have to be mindful of the
consequences of our progress. In an increasingly connected world, change is
often <a href="https://hbr.org/2017/05/linear-thinking-in-a-nonlinear-world">nonlinear</a> and unpredictable. Cars didnâ€™t just replace horsesâ€”they
forever changed the entire outlook of every city. Did Tim Berners-Lee
anticipate his invention adding to forces pulling whole countries apart?</p><p>Our progress will continue to bring us previously unimaginable challenges.
Against an unknowable future, it doesnâ€™t hurt to keep improving our
capabilities to adapt and, more difficultly, to cooperateâ€”especially at
scale.</p><figure><img src="https://www.murilopereira.com/humanity.jpg" alt="Figure 6: &amp;ldquo;Humanity&amp;rdquo; by Pawel Kuczynski"><figcaption><p>Figure 6: â€œ<a href="https://www.pictorem.com/24592/humanity.html">Humanity</a>â€ by Pawel Kuczynski</p></figcaption></figure><p>Computers are getting pretty good at driving carsâ€”even in the most
difficult situationsâ€”and can already instantly diagnose some diseases
better than human doctors. Technology has a way to <a href="https://www.thenewatlantis.com/publications/understanding-heidegger-on-technology">reveal</a> the potential of
our environment, and ourselves. We have to be careful not to look at â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.murilopereira.com/the-why-of-technology/">https://www.murilopereira.com/the-why-of-technology/</a></em></p>]]>
            </description>
            <link>https://www.murilopereira.com/the-why-of-technology/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26178726</guid>
            <pubDate>Thu, 18 Feb 2021 11:45:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An assessment of four bullet point styles for a technical resume]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26178714">thread link</a>) | @mcenedella
<br/>
February 18, 2021 | https://leetresumes.com/blog/an-assessment-of-four-bullet-point-styles-for-a-technical-resume | <a href="https://web.archive.org/web/*/https://leetresumes.com/blog/an-assessment-of-four-bullet-point-styles-for-a-technical-resume">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div><p>Perhaps 2/3 of a <a href="https://leetresumes.com/blog/how-to-write-a-great-technical-resume">great technical resume</a> is composed of bullet points. For most professionals, summarizing your career in just 10 - 25 bullet points feels overwhelming. With a little guidance, and by focusing on what's most important, however, it's pretty easy to get it right. </p><p>Let's review the best approach to populating the bullets on a technical resume, and demonstrate how Leet Resumes handles bullets when we <a href="https://leetresumes.com/">write technical resumes for experienced technology professionals for free</a>.</p><h2>Bullet Points Should Emphasize Your Achievements</h2><p>A resume is a document about your career.  It does not touch on your family life, hobbies, friendships, or religion. As a commercial document, with a commercial purpose, a resume's goal is to help you generate interview requests. Whether you're applying to a job, or passing along your resume for consideration by a friend, its goal is to communicate an effective, shorthand version of your career that causes the people who hire to say "yes, let's bring them in for an interview!"</p><p>The best way to generate these interview requests is to appeal to your future boss' or hiring managerâ€™s need to <a href="https://leetresumes.com/blog/why-you-should-include-numbers-on-your-technical-resume">solve a problem</a>. And the best way to demonstrate your ability to solve problems is to write effective bullet points that use <a href="https://leetresumes.com/blog/practical-methods-for-adding-more-numbers-to-your-technical-resume">numbers</a> to quantify your accomplishments. Quantified accomplishments are superior to opinion-based accomplishments, catch the recruiter's eye more easily, and set you apart from the other resumes in the stack.</p><p>Letâ€™s review some different types of bullet points commonly seen on technical resumes.</p><h2>Bullet Point Styles on Technical Resumes</h2><h3>Event-based</h3><ul><li>Developed</li><li>Shipped</li><li>Re-architected</li><li>Migrated</li><li>Launched</li><li>Refactored </li></ul><p>Most technical resumes default to event-based bullet points. Itâ€™s easiest because it mirrors your experience, and how you think about your past work. You shipped, developed, or launched something.</p><p>For the hiring manager, this bullet point style is difficult to use as an assessment tool. Sure, you did something, but how <strong>well</strong> did you do it? Almost all engineers can claim they showed up, wrote some code, and were involved in something being released to the public. So when you don't provide details about the outcome or the results, it's difficult for the hiring manager to make the case in her mind to pull your resume out of the pile instead of the other engineer. As a result, event-based bullet points leave it up to chance that a hiring manager will pick your resume for an interview.</p><h3>Performance-based</h3><ul><li>Identified xx items for improvement in existing systems</li><li>Improved system by increasing xx, reducing yy, optimizing zz items</li><li>Hired xx engineers </li><li>Improved availability by xxx%</li><li>Reduced latency by xx %</li><li>Refactored system to be 10x scalable</li><li>Deployed xx clusters, reducing maintenance costs by yy %</li><li>Built system that replaced manual system, saving xx days work annually</li><li>Improved security by releasing xx features</li><li>Fixed xx bugs</li></ul><p>The most effective type of bullet point is the performance-based bullet point. Using the <a href="https://leetresumes.com/blog/why-you-should-include-numbers-on-your-technical-resume">Action-Number-Method Pattern</a>, performance-based bullets combine an <strong>action</strong> indicating a positive change in state, with a specific objective <strong>numerical</strong> value indicating the scale of that change, and a <strong>method</strong> by which the change was effected, typically highlighting your skills in doing so.</p><p>Performance-based bullet points tell a more complete story to the hiring manager as she is reviewing resumes. By detailing your past performance, itâ€™s easier for her to estimate how you might contribute to her team in the future. Itâ€™s easier for her to understand that performance is important to you, and the types of performance improvements youâ€™ve created in the past. </p><p>As a result, when screening resumes, performance-based bullet points with numbers get picked more often.</p><h3>Administrative</h3><ul><li>Responsible for</li><li>Conducted testing </li><li>Participated in retrospectives</li><li>Attend scrum meetings</li><li>Performed code reviews</li><li>Assigned tasks to staff or peers</li></ul><p>The lowest-effort form of bullet point for technical resumes is the Administrative bullet point.  This style is popular because it is low effort. Engineers using Administrative bullets typically copy-pasta their job descriptions on to their resumes, turning their section about achievements into a listing of administrative duties and responsibilities. </p><p>As you can imagine, this easiest way to create bullet points is also the least effective. Hiring managers are familiar with job descriptions - after all, they're the ones writing them! So if your experience looks like every other job description and resume theyâ€™ve seen, they have no ability to understand that you are a better and different talent. </p><p>In addition, listing basic administrative duties such as these donâ€™t help you stand out. Your resume is not going to be selected from a stack because you attended scrum testings, ran unit tests, or did code reviews. Those are really considered to be basic behaviors that any experienced technology professional has done.</p><p>Because this style is ineffective at getting your resume selected for an interview, you should avoid using the Administrative style bullet point.</p><h3>Organizational</h3><ul><li>Promoted to / Selected to join</li><li>Joined</li><li>Transferred to</li><li>Worked on</li><li>Assigned to</li></ul><p>Finally, there is the Organizational style bullet point, which often explains how you came to be working on a particular project, or what organizational circumstances led to your presence on a team. With just one exception, Organizational bullet points should be avoided.</p><p>Organizational bullet points put too much focus on the configuration of your work in a prior company.  As a result, they do little to explain why your work is relevant to the hiring manager, or why he should select your resume for an interview. </p><p>Every company has its own method for assigning, transferring or matching engineers to required work. Itâ€™s probably different than the one used at the company youâ€™re applying to. As a result, Organizational bullet points tell the hiring manager relatively little about you, your capabilities, or your performance. </p><p>The one exception is â€œPromoted / Selected to Join.â€ Promotions and competitive selections <strong>do</strong> explain something about your performance to a hiring manager. They inform your future boss that the people who know you best, and who worked with you most closely, decided that you were ready for more responsibility. And that fact <strong>is </strong>helpful in getting your resume selected for an interview.</p><p>So when it comes to bullet points on your <a href="https://leetresumes.com/blog/practical-methods-for-adding-more-numbers-to-your-technical-resume">technical resume</a>, use the <strong>Action - Number - Method pattern</strong>, and prefer <strong>performance-based bullet points</strong>. This combination is most effective at getting your resume selected for interview requests, and getting you ahead in your career.</p><p>If youâ€™d like Leet Resumes to write your technical resume for free, <a href="https://leetresumes.com/">please sign up</a>.</p></div></div></div></div>]]>
            </description>
            <link>https://leetresumes.com/blog/an-assessment-of-four-bullet-point-styles-for-a-technical-resume</link>
            <guid isPermaLink="false">hacker-news-small-sites-26178714</guid>
            <pubDate>Thu, 18 Feb 2021 11:44:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Making Our Brains Noisier Feels Good]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26178708">thread link</a>) | @CapitalistCartr
<br/>
February 18, 2021 | http://m.nautil.us/issue/96/rewired/why-making-our-brains-noisier-feels-good | <a href="https://web.archive.org/web/*/http://m.nautil.us/issue/96/rewired/why-making-our-brains-noisier-feels-good">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			<p><span>N</span>ot since World War II has there been as great a threat to mental health as the current COVID-19 pandemic, according to Aiden James. The challenges to our mental health wonâ€™t â€œstop when the virus is under control and there are few people in hospital,â€ the president of the Royal College of Psychiatrists in the United Kingdom told <i>The Guardian</i> recently. â€œYouâ€™ve got to fund the long-term consequences.â€ With depression, anxiety, and substance abuse in the United States, and likely elsewhere, at <a href="https://www.cdc.gov/mmwr/volumes/69/wr/mm6932a1.htm" target="_blank">record highs</a>, that should not come as a surprise. At least antidepressants can be counted on to ameliorate some of the damage, right? Well, maybe not. Experts disagree strongly about how well our medications are helping. In 2018, <i>New Scientist</i> ran an article called â€œNobody Can Agree About Antidepressants.â€<sup>1</sup></p><p>So what do we do? A theory of brain function, particularly involving serotonin, recently proposed by neuroscientists Robin Carhart-Harris and David Nutt, at Imperial College London, may point a way forward for effective treatment.<sup>2</sup> The use of antidepressants has inadvertently left many of us less able to feel empathy toward others, laugh, cry, dream, and enjoy life just when we need those things the most: in the middle of a global pandemic.</p><blockquote><p>When our mind wanders, sleeps, or is under anesthesia, for example, our neurons are still firing all over the place.</p> </blockquote><p>The good news is that the research coming out of Imperial Collegeâ€™s Research Center has shown some impressive results in reducing treatment-resistant depression using psychedelics, such as the psilocybin found in â€œmagic mushrooms.â€ In a 2017 study, decreased depressive symptoms were observed in all 19 treatment-resistant individuals one week after their dose.<sup>3</sup> Five weeks later, 47 percent still had reduced symptoms. What is equally exciting is that Carhart-Harris and his co-authors have been using functional magnetic resonance imaging on subjects during the process to show that the mechanism of action is directly related to the amplification of spontaneous cognitive fluctuations.<sup>4</sup><br></p><p>Spontaneous brain fluctuations occur across all resting-state brain activity.<sup>5</sup> When our mind wanders, sleeps, or is under anesthesia, for example, our neurons are still firing all over the place.<sup>6</sup> Over time and through trauma, our spontaneous fluctuations can fall into negative resting-state patterns, like water rolls into a ditch. Antidepressants, such as serotonin uptake inhibitors, address this problem by cutting off water flow. Most work by reducing the functional connectivity of the â€œdefault mode network,â€ which is active when we mind-wander, daydream, self-reflect, worry, and ruminate. Unfortunately, this means that around 70 percent of people who take antidepressants report â€œemotional numbnessâ€ as a primary side effect.<sup>7</sup> Prescription antidepressants, anti-anxiety agents, and even many sleeping pills interfere with REM sleep and dreaming. This is ironic since there is well-researched evidence that REM dreaming plays a vital role in regulating negative emotions and depression.<sup>8</sup></p><p>Sleep researchers Antonio Zadra, Bob Stickgold, and Erin Wamsley showed, for example, that dreaming increases these fluctuations and improves how quickly test subjects could pass through a maze.<sup>9</sup> When the subjects dreamt about the maze in any way, or dreamt about the music that played while they navigated the maze, they completed the maze the next day nine times faster than those who did not dream about the maze.</p><div>
<article>
<p><a href="http://m.nautil.us/issue/8/Home/bacteria-love-lasered-jell_o" data-trval="bacteria-love-lasered-jell_o" data-trlbl="foc_rec" data-tract="internal_art">
<img src="http://static.nautil.us/1965_d46e1fcf4c07ce4a69ee07e4134bcef1.png" alt="Sapolsky_TH-F1" width="314" height="177">
</a>
</p>
<div>
<p><span>
<span>

<span><a href="http://m.nautil.us/term/f/Health">Also in Health</a></span>&nbsp;&nbsp;</span>
</span></p><h4><a href="http://m.nautil.us/issue/8/Home/bacteria-love-lasered-jell_o" data-trval="bacteria-love-lasered-jell_o" data-trlbl="foc_rec" data-tract="internal_art">Bacteria Love Lasered Jell-O</a></h4>
<p>By Zach Zorich</p>
<p>
Why donâ€™t we have an arsenal of fast-acting cures for tuberculosis, malaria, and pneumonia? In part itâ€™s because scientists canâ€™t fully understand what they canâ€™t observe: Namely, the way the pathogens that cause diseases and infections live within the human...<strong><a href="http://m.nautil.us/issue/8/Home/bacteria-love-lasered-jell_o" data-trval="bacteria-love-lasered-jell_o" data-trlbl="foc_rec" data-tract="internal_art">READ MORE</a></strong>
</p>

</div>

</article>
</div><p>Neuroscientists have known about spontaneous fluctuations since the 1930s but never knew what to make of them. Researchers chalked the phenomenon up to â€œrandom background noiseâ€ and proceeded to focus on coding the more easily testable 2 to 3 percent of conscious brain activity, but now they recognize that cognitive fluctuations play a much more significant role and that their patterns arenâ€™t random.<sup>6</sup> In <i>Consciousness and the Brain</i>, French neuroscientist Stanislas Dehaene writes that â€œneurons not only tolerate noise but even amplify it.â€ Neurons work by amplifying cognitive fluctuations and even harness their noisiness to help generate novel solutions to complex problems. Cognitive fluctuations may be drawing us nearer to a paradigm shift where â€œnoise is the new signal.â€</p><p>Brain frequencies are how fast certain groups of neurons fire together. The frequencies of cognitive fluctuations form patterns that become â€œcross-coupledâ€ into higher frequencies, around the beta (12 to 30 hertz) to gamma (30 to 180 hertz) range. As the slower waves, from infraslow (0.0001â€“0.1 Hertz) to theta (5 to 8 hertz), continually nest into faster ones and spread like an avalanche across various areas of the brain, we become aware that we are aware or â€œconscious.â€ That is, our thoughts are the results of syncopated patterns of noise that emerge like eddies from a turbulent stream.</p><p>For instance, if someone flashes an image on a screen in front of us for only 40 milliseconds, we will not consciously see it due to the frequency and propagation rate of conscious thought. If the image lasts 60 milliseconds, however, we will consciously see it. This is because there is time for these nested frequencies to spread out and become aware of the image. According to the neuroscientist and philosopher Georg Northoff, at the University of Ottawa, these cross-coupled frequencies eventually create metastable states of conscious awareness.<sup>10</sup></p><blockquote><p>Antidepressants have inadvertently left many of us less able to feel empathy when we need it most: in the middle of a global pandemic.</p> </blockquote><p>The study of these cognitive fluctuations is leading researchers to approach mental health treatment in new ways. Instead of trying to <i>reduce</i> spontaneous fluctuations with antidepressants, they are trying to <i>increase</i> them. This is counter-intuitive because spontaneous fluctuations and mind-wandering can also lead to depressive rumination and anxiety. The flux theory, however, is that these negative habits of thought can be disrupted by flooding the brain with spontaneous fluctuations. The disturbance loosens things up and allows us to change old habits.<br></p><p>If Northoff and Carhart-Harris are right, amplifying the noise might change our minds like shaking a snow-globe changes snow distribution. This is a good thingâ€”such a good thing, in fact, that it is leading to some incredible breakthroughs in mental health science. Rolland Griffiths and Stephen Ross, at the NYU Langone Center of Excellence on Addiction, for example, gave 80 patients with life-threatening cancer in Baltimore and New York City psilocybin. More than three-quarters reported significant relief from depression and anxiety related to their fear of dying.<sup>11</sup> These improvements remained even six months after the treatment and were related to the amplification of spontaneous fluctuations. Ross told <i>Scientific American</i>, â€œIt is simply unprecedented in psychiatry that a single dose of a medicine produces these kinds of dramatic and enduring results.â€<sup>12</sup></p><p>Spontaneous fluctuations are a tool we should not underestimate. More Americans have died from COVID-19 than in World War II, and the numbers are likely to double before the end. Millions more are grieving the loss of their loved ones. Many COVID-19 â€œlong-haulersâ€ are also dealing with mental health issues related to the lasting effects of the disease. We need safe and reliable mental health solutions, and no tool should be left out of the toolbox. Getting plenty of REM sleep and dreams uninhibited by alcohol, ibuprofen, and cannabis can help, as can decriminalizing psilocybin, as several cities are doing, to make therapies more accessible. Even looking at natural fractals, like trees and plants, can contribute to flux therapy.<sup>13</sup> Having a good theory about how spontaneous fluctuations work is the key to finding more treatments.</p><p>As the fear of illness and death consume the minds of many, the advances in this line of work offer some measure of comfort. They might just help us survive the COVID-19 aftermath.</p><p><i>Thomas Nail is a professor of philosophy at the University of Denver. Follow him on Twitter <a href="https://twitter.com/xThomas_Nail" target="_blank">@xThomas_Nail</a>.</i></p><p><b>References</b></p> <p>1. Wilson, C. Nobody can agree about antidepressants: Hereâ€™s what you need to know. <i>New Scientist</i> (2018).</p><p>2. Carhart-Harris, R.L. &amp; Nutt, D.J. Serotonin and brain function: A tale of two receptors. <i>Journal of Psychopharmacology</i> <b>31</b>, 1091-1120 (2017).</p><p>3. Carhart-Harris, R.L., <i>et al.</i> Psilocybin for treatment-resistant depression: fMRI-measured brain mechanisms. <i>Scientific Reports</i> <b>7</b>, 13187 (2017).</p><p>4. Carhart-Harris, R.L. The entropic brainâ€”Revisited. <i>Neuropharmacology</i> <b>142</b>, 167-178 (2018).</p><p>5. Northoff, G. <i>The Spontaneous Brain: From the Mind-Body to the World-Brain Problem</i> MIT Press, Cambridge, MA (2018); Raichle, M.E. The restless brain: How intrinsic activity organizes brain function. <i>Philosophical Transactions of the Royal Society B</i> <b>370</b>, 20140172 (2015).</p><p>6. Fox, M.D. &amp; Raichle, M.E. Spontaneous fluctuations in brain activity observed with functional magnetic resonance imaging. <i>Nature Reviews Neuroscience</i> <b>8</b>, 700-711 (2007); Dehaene, S. <i>Consciousness and the Brain: Deciphering How the Brain Codes Our Thoughts</i> Viking Penguin, New York, NY (2014).</p><p>7. Read, J. &amp; Williams, J. Adverse effects of antidepressants reported by a large international cohort: emotional blunting, suicidality, and withdrawal effects. <i>Current Drug Safety</i> <b>13</b>, 176-186 (2018).</p><p>8. Scarpelli, S., Bartolacci, C., Dâ€™Atri, A., Gorgoni, M., &amp; De Gennaro, L. The functional role of dreaming in emotional processes. <i>Frontiers in Psychology</i> <b>10</b>, 459 (2019).</p><p>9. Zadra, A. &amp; Stickgold, R. <i>When Brains Dream: Exploring the Science and Mystery of Sleep</i> W.W. Norton and Company, Inc., New â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://m.nautil.us/issue/96/rewired/why-making-our-brains-noisier-feels-good">http://m.nautil.us/issue/96/rewired/why-making-our-brains-noisier-feels-good</a></em></p>]]>
            </description>
            <link>http://m.nautil.us/issue/96/rewired/why-making-our-brains-noisier-feels-good</link>
            <guid isPermaLink="false">hacker-news-small-sites-26178708</guid>
            <pubDate>Thu, 18 Feb 2021 11:43:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Screenplay Format Reference]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26178387">thread link</a>) | @jstrieb
<br/>
February 18, 2021 | http://www.trilane.com/ref/index.html | <a href="https://web.archive.org/web/*/http://www.trilane.com/ref/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="915" nof="ly">
  <tbody><tr>
   <td>
    <p><img id="Picture3" height="93" width="90" src="http://www.trilane.com/ref/a_reels.jpg" alt="reels" title="reels"></p>
    <table nof="ly">
     <tbody><tr>
      <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="12" height="1" alt=""></td>
      <td></td>
     </tr>
     <tr>
      <td></td>
      <td nof="NB_BYVTNN000">[Top]</td>
     </tr>
    </tbody></table>
   </td>
   <td>
    <table nof="ly">
     <tbody><tr>
      <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="15" height="1" alt=""></td>
      <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="559" height="1" alt=""></td>
     </tr>
     <tr>
      <td></td>
      <td>
       <p><b><span>The Ultimate Screenplay Format Reference</span></b></p>
      </td>
     </tr>
    </tbody></table>
    
    <table nof="ly">
     <tbody><tr>
      <td>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="35" height="1" alt=""></td>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="389" height="1" alt=""></td>
        </tr>
        <tr>
         <td></td>
         <td>
          <p><span>FADE IN:</span></p>
          <p><b><span>Table of Contents</span></b></p>
          <p><b><span>measurements</span></b></p>
          <ul>
           <li><span><a href="http://www.trilane.com/ref/measure/measure.html">typeface</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/measure/measure.html">margins and tabs</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/measure/measure.html">page numbers</a></span></li>
          </ul>
          <p><b><span>scenes</span></b></p>
          <ul>
           <li><span><a href="http://www.trilane.com/ref/scenes/scenes.html">master scene headings</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/scenes/scenes.html#SecHeadings">secondary scene headings</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/scenes/spcl1/spcl1.html">montage</a>, <a href="http://www.trilane.com/ref/scenes/spcl1/spcl1.html">series of shots</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/scenes/spcl2/spcl2.html#flashback">flashbacks</a>, <a href="http://www.trilane.com/ref/scenes/spcl2/spcl2.html#flashseq">flashback sequences</a>, <a href="http://www.trilane.com/ref/scenes/spcl2/spcl2.html#quickflashes">quick flashes</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/scenes/spcl3/spcl3.html">dreams</a>, <a href="http://www.trilane.com/ref/scenes/spcl3/spcl3.html#daydream">daydreams</a>, <a href="http://www.trilane.com/ref/scenes/spcl3/spcl3.html#imagining">imaginings</a>, <a href="http://www.trilane.com/ref/scenes/spcl3/spcl3.html#vision">visions</a>, <a href="http://www.trilane.com/ref/scenes/spcl3/spcl3.html#animation">animation</a> and sequences thereof</span></li>
           <li><span><a href="http://www.trilane.com/ref/scenes/scenes2/scenes2.html">establishing shots</a></span></li>
           <li><a href="http://www.trilane.com/ref/scenes/scenes2/scenes2.html#spacingScenes"><span>spacing between scenes</span></a></li>
           <li><span><a href="http://www.trilane.com/ref/scenes/scenes2/scenes2.html#spacingLines">spacing between lines</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/scenes/scenes2/scenes2.html#transitions">scene transitions<span>, </span><span>MATCH CUT</span></a></span></li>
          </ul>
          <p><b><span>characters</span></b></p>
          <ul>
           <li><span><a href="http://www.trilane.com/ref/chars/chars.html">character introductions</a></span></li>
           <li><a href="http://www.trilane.com/ref/chars/chars.html#names"><span>character names</span></a></li>
           <li><span><a href="http://www.trilane.com/ref/chars/chars.html#cues">character cues</a></span></li>
          </ul>
          <p><b><span>narrative and action</span></b></p>
          <ul>
           <li><span><a href="http://www.trilane.com/ref/action/action.html">character introductions</a></span></li>
           <li><a href="http://www.trilane.com/ref/action/action4/action4.html#SUPER"><span>SUPER</span><span>, </span><span>SCROLL</span><span><span>, </span></span></a><a href="http://www.trilane.com/ref/action/action4/action4.html#onTV"><span>words on TV</span></a></li><a href="http://www.trilane.com/ref/action/action4/action4.html#onTV">
           </a><li><a href="http://www.trilane.com/ref/action/action4/action4.html#onTV"><b><span></span></b></a><b><a href="http://www.trilane.com/ref/action/action4/action4.html#insert"><span>INSERT</span></a></b></li>
           <li><span><a href="http://www.trilane.com/ref/action/action.html#sounds">sounds, MOS</a></span></li><a href="http://www.trilane.com/ref/action/action.html#sounds">
           </a><li><a href="http://www.trilane.com/ref/action/action.html#sounds"><span></span></a><a href="http://www.trilane.com/ref/action/action.html#spfx">special effects (<span>FX</span>, <span>SPFX</span>, <span>SFX</span>)</a></li>
           <li><span><a href="http://www.trilane.com/ref/action/action.html#POVs"><span>POV</span>, <span>CLOSE UP</span>, <span>PULL BACK</span></a></span></li>
           <li><span><a href="http://www.trilane.com/ref/action/action2/action2.html">slow motion</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/action/action2/action2.html#music">music</a>, <a href="http://www.trilane.com/ref/action/action2/action2.html#lyrics">music lyrics</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/action/action2/action2.html#clips">movie clips</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/action/action3/action3.html">unseen characters</a>, <a href="http://www.trilane.com/ref/action/action3/action3.html#phantom">phantom POV</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/action/action4/action4.html#stacking">action stacking</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/action/action5/action5.html">then we see ...</a></span></li>
          </ul>
          <p><b><span>dialog </span></b></p>
          <ul>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg.html#wrylies">actorâ€™s instructions</a> (a.k.a. wrylies)</span></li>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg.html#os"><span>(O.S.)</span></a> and <a href="http://www.trilane.com/ref/dlg/dlg.html#vo"><span>(V.O.)</span></a></span></li>
           <li><a href="http://www.trilane.com/ref/dlg/dlg.html#more"><span><span>MORE</span> <span>and</span> </span><span>CONTâ€™D / CONTINUED</span></a></li>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg2/dlg2.html">telephone conversations</a></span></li>
           <ul>
            <li><span><span><a href="http://www.trilane.com/ref/dlg/dlg2/dlg2.html#intercut"><span>INTERCUT</span></a></span><a href="http://www.trilane.com/ref/dlg/dlg2/dlg2.html#intercut"><span></span></a></span></li><a href="http://www.trilane.com/ref/dlg/dlg2/dlg2.html#intercut">
           </a></ul><a href="http://www.trilane.com/ref/dlg/dlg2/dlg2.html#intercut">
           </a><li><a href="http://www.trilane.com/ref/dlg/dlg2/dlg2.html#intercut"><span></span></a><a href="http://www.trilane.com/ref/dlg/dlg3/dlg3.html">overlapping dialog</a></li>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg3/dlg3.html#computer">computer conversations</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg4/dlg4.html#foreign">foreign languages</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg4/dlg4.html">telepathic dialog</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg5/dlg5.html">mute dialog</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg5/dlg5.html#beat"><span>(beat)</span></a></span></li>
           <li><a href="http://www.trilane.com/ref/dlg/dlg5/dlg5.html#punctuation"><span>-- </span></a></li>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg5/dlg5.html#punctuation"><span>...</span></a></span></li>
          </ul>
          <p><b><span>miscellaneous</span></b></p>
          <ul>
           <li><span><a href="http://www.trilane.com/ref/pages/pages.html">the title page</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/pages/pages.html#firstPage">the first page</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/pages/pages.html#credits">credits and titles</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/pages/pages.html#lastPage">the last page</a></span></li>
           <li><span>authorâ€™s intrusions</span></li>
           <li><span><a href="http://www.trilane.com/ref/misc/misc.html"><span>notes</span></a></span></li>
          </ul>
          
         </td>
        </tr>
       </tbody></table>
      </td>
      <td>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="45" height="1" alt=""></td>
         <td></td>
        </tr>
        <tr>
         <td></td>
         <td>
          <div>
             <p><span>Writing a screenplay is difficult.</span></p>
             <p><span>Formatting should be the least of all problems. Actually itâ€™s the most easiest to master, if you follow a set of simple rules.</span></p>
             <p><span><a href="http://astore.amazon.com/trilane-20/detail/1879505843/105-1611443-6684411">Trottierâ€™s Screenwriterâ€™s Bible</a> is currently considered the final authority on formatting issues. I recommend you read it. It will save you a lot of pain.</span></p>
             <p><span>Here you find a reference to those rules. Follow them and your screenplay will be well formatted.</span></p>
            </div>
         </td>
        </tr>
       </tbody></table>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="122" height="1" alt=""></td>
         <td></td>
        </tr>
        <tr>
         <td></td>
         <td>
          
         </td>
        </tr>
       </tbody></table>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="45" height="1" alt=""></td>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="344" height="1" alt=""></td>
        </tr>
        <tr>
         <td></td>
         <td>
          <p><span>If you donâ€™t believe me then take this from a pro:</span></p>
         </td>
        </tr>
       </tbody></table>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="47" height="1" alt=""></td>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="343" height="1" alt=""></td>
        </tr>
        <tr>
         <td></td>
         <td>
          <p><span>â€œReaders in Hollywood do a great deal of inductive reasoning, which goes something like this: â€œI just read 99 screenplays, they were all horrible, and they were all written in improper format. Therefore, if screenplay number 100 is also in improper format, it must be horrible, too.â€</span></p>
          <p><span><span>Michael Hauge, Collins 2007, Writing Screenplays That Sell </span></span></p>
         </td>
        </tr>
       </tbody></table>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="49" height="1" alt=""></td>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="340" height="1" alt=""></td>
        </tr>
        <tr>
         <td></td>
         <td>
          <p><span>â€˜Writing Screenplays That Sellâ€™ is another good book to read.</span></p>
         </td>
        </tr>
       </tbody></table>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="262" height="1" alt=""></td>
         <td></td>
        </tr>
        <tr>
         <td></td>
         <td>
          
         </td>
        </tr>
       </tbody></table>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="80" height="1" alt=""></td>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="311" height="1" alt=""></td>
        </tr>
        <tr>
         <td></td>
         <td>
          <p><span>At the bottom of this page you find a few books that are real helpful in addressing important issues beyond formatting.</span></p>
          <p><span>... all the best for your own screenwriting.</span></p>
         </td>
        </tr>
       </tbody></table>
      </td>
     </tr>
    </tbody></table>
    <table nof="ly">
     <tbody><tr>
      <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="35" height="1" alt=""></td>
      <td>
       
      </td>
     </tr>
    </tbody></table>
    <table nof="ly">
     <tbody><tr>
      <td>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="35" height="1" alt=""></td>
         <td>
          
         </td>
        </tr>
       </tbody></table>
      </td>
      <td>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="23" height="1" alt=""></td>
         <td>
          
         </td>
        </tr>
       </tbody></table>
      </td>
      <td>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="23" height="1" alt=""></td>
         <td>
          
         </td>
        </tr>
       </tbody></table>
      </td>
      <td>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="27" height="1" alt=""></td>
         <td>
          <div>
             <p><a href="http://astore.amazon.com/trilane-20/detail/193290736X"><img id="Picture22" height="125" width="83" src="http://www.trilane.com/ref/a_Writer_s_Journey_Vogler.jpg" alt="Writer's Journey_Vogler" title="Writer's Journey_Vogler"></a><br><span><b><br>The Writerâ€™s Journey<br></b>Christopher Vogler</span></p><p>Paperback <br>300 pages</p><p><a href="http://www.trilane.com/store"><span>Trilane aStore</span></a><br><a href="http://astore.amazon.com/trilane-20/detail/193290736X"><img id="Picture16" height="28" width="90" src="http://www.trilane.com/ref/a_buy-from-amazon.jpg" alt="buy-from-amazon" title="buy-from-amazon"></a></p>
            </div>
         </td>
        </tr>
       </tbody></table>
      </td>
      <td>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="23" height="1" alt=""></td>
         <td>
          <div>
             <div><p><a href="http://astore.amazon.com/trilane-20/detail/0440504910"><img id="Picture23" height="125" width="79" src="http://www.trilane.com/ref/a_Screenwriter_s_Problem_Solver_Field.jpg" alt="Screenwriter's Problem Solver_Field" title="Screenwriter's Problem Solver_Field"></a></p><p><span><b>The Screenwriterâ€™s Problem Solver<br></b>Syd Field</span></p><p>Paperback <br>384 pages</p><p><a href="http://www.trilane.com/store"><span>Trilane aStore</span></a><br><a href="http://astore.amazon.com/trilane-20/detail/0440504910"><img id="Picture18" height="28" width="90" src="http://www.trilane.com/ref/a_buy-from-amazon.jpg" alt="buy-from-amazon" title="buy-from-amazon"></a></p></div>
            </div>
         </td>
        </tr>
       </tbody></table>
      </td>
     </tr>
    </tbody></table>
   </td>
  </tr>
 </tbody></div></div>]]>
            </description>
            <link>http://www.trilane.com/ref/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26178387</guid>
            <pubDate>Thu, 18 Feb 2021 10:57:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The frame rate of the universe (2009)]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 55 (<a href="https://news.ycombinator.com/item?id=26178259">thread link</a>) | @codesections
<br/>
February 18, 2021 | https://www.librador.com/2009/01/16/The-frame-rate-of-the-universe/ | <a href="https://web.archive.org/web/*/https://www.librador.com/2009/01/16/The-frame-rate-of-the-universe/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
      
<div id="page-2009-2009-01-16-The-frame-rate-of-the-universe-">
  
  <p><abbr title="2009-01-16T01:04:00+01:00">16 Jan 2009</abbr></p><div>
    <p>

    I stumbled upon <a href="http://www.newscientist.com/article/mg20126911.300-our-world-may-be-a-giant-hologram.html?full=true">this
article</a> which presents the hypothesis that the universe is a 3D projection of a 2D
surface, like a giant hologram. I like to read about modern physics. It is so weird and I can't say
I really understand very much of it. But the descriptions provoke strange and fascinating images
and thoughts in my head. Like this one:</p><p>The article mentions the <a href="http://en.wikipedia.org/wiki/Planck_length">Planck length</a>, which as I understand it is
the smallest distance there is. It's extremely small: 1.6 Ã— 10<sup>-35</sup> meters, which makes
it billions and billions of times smaller than an atom (or even a proton). I'm used to thinking
about computer graphics, so I imagine the Planck length as the size of one "pixel" of the universe.
Nothing can be smaller than a pixel. (The pixels of the universe are small, I calculate the
resolution to correspond to 2.19 Ã— 10<sup>33</sup> DPI.) The radius of the observable universe is
4.4 Ã— 10<sup>26</sup> meters. If we want to fit the universe into a box, its sides would have to
be twice that size. That is 5.4 Ã— 10<sup>61</sup> Planck lengths. So that's the width, height and
depth of the universe in pixels. Quite a good resolution. (Actually since they are 3D cubes instead
of 2D squares, I should call them voxels instead of pixels. All 1.61 Ã— 10<sup>185</sup> of
them.)</p><p>There is also the <a href="http://en.wikipedia.org/wiki/Planck_time">Planck time</a>
which is the time it takes for light to travel one Planck length. As light is fast and the Planck
length is tiny (tiniest there is!), you can image that it's a very short period of time. Certainly.
The Planck time is 5.39 Ã— 10<sup>-44</sup> seconds. No measurable time can be shorter than that
according to quantum physics. Thinking about graphics again, this is like a limit on the frame rate
of the universe. Inverting the Planck time, I get 1.855 Ã— 10<sup>43</sup>. So by my surely
incorrect logic, we get the value of the universe's frame rate:</p><p>One thousand eight hundred
and fifty-five billion billion billion billion frames per second.</p><p>I'll say that
again:</p><p>18.55 septillion FPS!</p><p>Video cameras won't be perfect until they can record at
that speed.</p><p>I hope I got the calculations right, but I'm pretty sure my interpretation of the
quantum physics behind this are way off. It's still fascinating to think of the universe as a
computer simulation. Modern physics make it seem more like a video game than ever.<br>


</p>
  </div>
  
  
  <p><a href="http://disqus.com/">blog comments powered by </a>
</p></div>

    </div></div>]]>
            </description>
            <link>https://www.librador.com/2009/01/16/The-frame-rate-of-the-universe/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26178259</guid>
            <pubDate>Thu, 18 Feb 2021 10:37:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lithuania plans to hold drills in case of accident at the Belarus nuclear plant]]>
            </title>
            <description>
<![CDATA[
Score 156 | Comments 132 (<a href="https://news.ycombinator.com/item?id=26178235">thread link</a>) | @maury91
<br/>
February 18, 2021 | https://www.lrt.lt/en/news-in-english/19/1346034/lithuania-plans-to-hold-evacuation-drills-after-belarus-launches-nuclear-plant | <a href="https://web.archive.org/web/*/https://www.lrt.lt/en/news-in-english/19/1346034/lithuania-plans-to-hold-evacuation-drills-after-belarus-launches-nuclear-plant">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article id="article1346034">    

    
    
    <div>

        <div id="article_text1346034">
            <p>Lithuaniaâ€™s Interior Ministry plans to hold drills and assess the need to evacuate Vilniusâ€™ residents in case of an accident at the Astravyets nuclear plant in Belarus, located some 50 kilometres from the Lithuanian capital.</p>
            
            <p>"That will be one of the key questions during the drafting of the exercises schedule and probably going back to the scenarios: do we or do we not need to evacuate Vilnius residents,â€ Vitalij Dmitrijev, vice minister of the interior, told LRT RADIO.</p>
            <p>The so-called Astravyets drill was held in October 2019 in Vilnius and SvenÄionys districts, which are located close to the Belarusian border. During the exercises, authorities prepared to evacuate people from radiation-affected territories, distribute iodine pills, as well as simulated a resident cleanup and monitoring operation.</p>
            <p>The exercise involved around 300 officers, troops and civil servants from six municipalities and 24 institutions. Due to a dispute over the exercise scenario with the Vilnius authorities, officers from the capital did not take part in the drills.</p>
                

            <p><em>Read more: <a href="https://www.lrt.lt/en/news-in-english/19/1103053/lithuanians-stage-mock-evacuations-to-train-for-nuclear-accident-photos">Lithuanians stage mock evacuations to train for nuclear accident â€“ photos</a></em></p>
            <!--googleoff: all--><!--googleon: all-->            <p>Previously, the Vilnius authorities cancelled another exercise, planned in early September, to simulate an accident at the nuclear power plant in Belarus.</p>
            <p>Based on the information available to BNS, Vilnius Municipality faced resistance from the government at the time.</p>
            <p>Lithuanian officials say that the nuclear power plant built by the Russian state atomic corporation Rosatom and funded by a loan from the Kremlin was built in breach of international safety standards. Minsk denies all accusations.</p>
            <p>Estonia, Latvia, and Lithuania are also due to unplug from the Moscow-controlled energy grid that links them with Belarus. Vilnius says that the Kremlin may use the plant to derail the move.</p>
<!--googleoff: all--><div>
            
<div id="mlb2-1612938">
    <div>
        <div>
            <div>
                <div>
                    <p><img src="https://bucket.mlcdn.com/a/1239/1239192/templates/39/39540/5dcc95ea35753170c2955994a6fea7c948ffb283.png"></p><p>LRT English Newsletter<span><span><br></span><span><span>Every Friday morning.</span></span></span></p>
                    
                </div>
            </div>
            
        </div>
    </div>
</div>

<p><img src="https://track.mailerlite.com/webforms/o/1612938/i0s8k2?v4a60e9ef938a7fa0240ac9ba567062cb" width="1" height="1">
</p></div><!--googleon: all-->        </div>
    </div>
    <!--googleoff: all-->
        <!--googleon: all-->
        

<div data-id="gallery1346034"><div>
            <div>
                <div>
                    <div>
<p><img data-src="/img/2019/10/02/522637-581058-1287x836.jpg" alt="â€˜Astravyets drillâ€™ in Lithuania" title="â€˜Astravyets drillâ€™ in Lithuania" src="https://www.lrt.lt/img/2019/10/02/522637-581058-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>â€˜Astravyets drillâ€™ in Lithuania</p>            <p><span>1 / 5</span><span>D. Umbrasas / LRT</span></p>
        </div></div>
</div>
                    </div>
                    <div>
<p><img data-src="/img/2019/12/23/573047-835055-1287x836.jpg" alt="Lithuania has staged 'Astravyets drills' to prepare for nuclear emergencies" title="Lithuania has staged 'Astravyets drills' to prepare for nuclear emergencies" src="https://www.lrt.lt/img/2019/12/23/573047-835055-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>Lithuania has staged 'Astravyets drills' to prepare for nuclear emergencies</p>            <p><span>2 / 5</span><span>D. Umbrasas/LRT</span></p>
        </div></div>
</div>
                    </div>
                    <div>
<p><img data-src="/img/2019/10/02/522627-981621-1287x836.jpg" alt="â€˜Astravyets drillâ€™ in Lithuania" title="â€˜Astravyets drillâ€™ in Lithuania" src="https://www.lrt.lt/img/2019/10/02/522627-981621-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>â€˜Astravyets drillâ€™ in Lithuania</p>            <p><span>3 / 5</span><span>D. Umbrasas / LRT</span></p>
        </div></div>
</div>
                    </div>
                    <div>
<p><img data-src="/img/2019/10/02/522623-306261-1287x836.jpg" alt="â€˜Astravyets drillâ€™ in Lithuania" title="â€˜Astravyets drillâ€™ in Lithuania" src="https://www.lrt.lt/img/2019/10/02/522623-306261-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>â€˜Astravyets drillâ€™ in Lithuania</p>            <p><span>4 / 5</span><span>D. Umbrasas / LRT</span></p>
        </div></div>
</div>
                    </div>
                    <div>
<p><img data-src="/img/2019/10/02/522612-821132-1287x836.jpg" alt="â€˜Astravyets drillâ€™ in Lithuania" title="â€˜Astravyets drillâ€™ in Lithuania" src="https://www.lrt.lt/img/2019/10/02/522612-821132-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>â€˜Astravyets drillâ€™ in Lithuania</p>            <p><span>5 / 5</span><span>D. Umbrasas / LRT</span></p>
        </div></div>
</div>
                    </div>
                </div>
                
            </div>
        </div>
        
    </div>
 

    
    
</article>

        
    </div></div>]]>
            </description>
            <link>https://www.lrt.lt/en/news-in-english/19/1346034/lithuania-plans-to-hold-evacuation-drills-after-belarus-launches-nuclear-plant</link>
            <guid isPermaLink="false">hacker-news-small-sites-26178235</guid>
            <pubDate>Thu, 18 Feb 2021 10:34:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Urbit: The Good, the Bad, and the Insane]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26177720">thread link</a>) | @wcerfgba
<br/>
February 18, 2021 | https://wejn.org/2021/02/urbit-good-bad-insane/ | <a href="https://web.archive.org/web/*/https://wejn.org/2021/02/urbit-good-bad-insane/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  <p><span>Written</span>
    

    
      <span>on&nbsp;</span><time datetime="2021-02-17 19:02:00 +0100">2021-02-17</time>
    
    
  </p>

  

  

  

  <p>In this post Iâ€™m gonna be making all kinds of fun of <a href="https://urbit.org/">Urbit</a>.
And all that after spending just a few hours poking around it.</p>
<p>Originally, I wanted to write in the layout of the good, the bad, and the ugly,
but Iâ€™m not entirely sure how that would pan out.<sup><a href="#fn1" id="fnref1">1</a></sup></p>
<p>Before I begin, Iâ€™ll somewhat oversimplify and explain Urbit to those of you not
in the know.</p>
<p><em>And before I do that, hereâ€™s a PSA: thereâ€™s a <a href="#tldr">tl;dr at the end</a>. So you
donâ€™t need to read all this drivel. Youâ€™re welcome.</em></p>
<h2 id="urwhat">Urâ€¦what?</h2>
<p>According to its own webpage, Urbit is an â€œoverlay OSâ€ and network for the 21st
century.</p>
<p>What that means at the time of writing<sup><a href="#fn2" id="fnref2">2</a></sup> is that itâ€™s a single-threaded
interpreter running as a unix process that speaks udp protocol to a meshed
network (and http to your browser).</p>
<p>And all of that in the name of delivering you flaky, unreliable, and feature-poor
implementation of an internet forum. (in a nutshell)<sup><a href="#fn3" id="fnref3">3</a></sup></p>
<p>An additional component of Urbit is its â€œdistributedâ€ identity component, where
your identity is uniquely tied to a 32-bit integer. And to go with the zeitgeist,
itâ€™s backed by Ethereum blockchain. Naturally.</p>
<p>All we need is quantum computing and ML, and we have all the latest buzzwords.
<a href="https://groups.google.com/a/urbit.org/g/dev/c/a6hdQdzIgqo">Oh, wait.</a></p>
<p>But to better explain whatâ€™s going on, letâ€™s look atâ€¦</p>
<h2 id="a-bit-of-history">A bit of history</h2>
<p>Iâ€™m going to take Urbitâ€™s history page on authority here.</p>
<p>This project started in 2002 as a PhD thesis to reinvent computing. Over the
next 6 years the progress was a language specification (Nock) for
a turing-complete language with ~11 instructions.</p>
<p>Then, over 10+ years other people ran with it, took it further, and implemented:</p>
<ul>
<li>(more than one) VM interpreting that language</li>
<li>a higher level language â€“ Hoon (to make Nock â€œpracticalâ€)</li>
<li>an encrypted mesh protocol</li>
<li>a versioned control system</li>
<li>an application layer</li>
<li>a web frontend (several apps, actually)</li>
<li>an identity layer</li>
<li>â€¦</li>
</ul>
<p>If this smells like a bad case of <a href="https://en.wikipedia.org/wiki/Not_invented_here">NIH</a>,
itâ€™s probably because thatâ€™s exactly the case.</p>
<h2 id="urbit-as-an-ideal-good-and-insane-at-the-same-time">Urbit as an ideal: good and insane at the same time</h2>
<p>But letâ€™s talk about Urbit as an ideal for a moment.</p>
<p>Letâ€™s assume that when <a href="https://youtu.be/M04AKTCDavc">the marketing materials</a>
speak of</p>
<blockquote>
<p>defining an operating system on a single piece of paper</p>
</blockquote>
<p>and</p>
<blockquote>
<p>throwing away every line of code from the 1970s</p>
</blockquote>
<p>they mean well. Given some sort of hardware implementation of Nock (the low level
language) you theoretically <em>could</em> throw away everything and start from scratch.</p>
<p>And it would be all kinds of awesome, if you could have decent control over your
personal computing without all the cruft accumulated since â€™70s.</p>
<p>Onlyâ€¦ with Urbit this ideal would be so slow as to be useless. See, Nock has
one arithmetic operation, increment (<code>x+1</code>). So if you want to decrement <code>x</code>,
you have to loop from <code>0</code> to <code>x-1</code>. Or you can break your promise of throwing
away all the code from â€™70sâ€¦ and implement decrement in C.</p>
<p>And the same story (of replacing godawfully ineffective implementation of native
code with C implementation) goes pretty much for any reasonable functionality you
might expect. Crypto? Sorting? Basic math and string ops? All of it.</p>
<p>The entire frickinâ€™ peer to peer protocol is written in C, too. So are vast
swaths of the OS: db, ames, http, terminal, database, event processing, â€¦</p>
<p>Is it possible to truly throw away every line of code from the 1970s up until
nowâ€¦ and start from clean slate? Hell yeah. Only, probably not with Nock.</p>
<p>So we have the pivot to â€œoverlay OSâ€ (mentioned on urbit.org), in other words:
<strong>letâ€™s not throw away any lines of code, but instead build on top of them</strong>.
And then access the UI using a conventional browser over http, that will
interpret the React-based javascript (among other things).</p>
<p>So far so good.</p>
<p>Ubitâ€™s core promise:reality â€“ 0:1.</p>
<h2 id="hoon-as-a-language-amazing">Hoon as a language: amazing</h2>
<p>Letâ€™s move on to the Hoon language<sup><a href="#fn4" id="fnref4">4</a></sup>, the workhose of the platform.</p>
<p>Once you start diggin in, you will be constantly met with such <a href="https://github.com/urbit/urbit/blob/master/pkg/arvo/gen/cat.hoon">vomit inducing
beauty</a>:</p>
<pre><code>::  ConCATenate file listings
::
::::  /hoon/cat/gen
  ::
/?    310
/+    pretty-file, show-dir
::
::::
  ::
:-  %say
|=  [^ [arg=(list path)] vane=?(%g %c)]
=-  tang+(flop `tang`(zing -))
%+  turn  arg
|=  pax=path
^-  tang
=+  ark=.^(arch (cat 3 vane %y) pax)
?^  fil.ark
  ?:  =(%sched -:(flop pax))
    [&gt;.^((map @da cord) (cat 3 vane %x) pax)&lt;]~
  [leaf+(spud pax) (pretty-file .^(noun (cat 3 vane %x) pax))]
?-     dir.ark                                          ::  handle ambiguity
    ~
  [rose+[" " `~]^~[leaf+"~" (smyt pax)]]~
::
    [[@t ~] ~ ~]
  $(pax (welp pax /[p.n.dir.ark]))
::
    *
  =-  [palm+[": " ``~]^-]~
  :~  rose+[" " `~]^~[leaf+"*" (smyt pax)]
      `tank`(show-dir vane pax dir.ark)
  ==
==
</code></pre>
<p>that makes Perl the world champion of readable languages by comparison.</p>
<p>Iâ€™m not being entirely fair here, because Iâ€™m sure you can memorize the digraphs
in a few weeks<sup><a href="#fn5" id="fnref5">5</a></sup>, and eventually you get the hang of writing this.
But in the grand scheme of thingsâ€¦ why the heck would you want to?!</p>
<p>It is hard enough to write bug free code in a language that you can find
tens of thousands of top notch coders for (that would give you an honest
code review). Itâ€™s quite another thing doing basic reading of Hoon.</p>
<p>But letâ€™s say Iâ€™m biased, this is the future, and 5 years down the road it
will be the gold standard for personal computing dev<sup><a href="#fn6" id="fnref6">6</a></sup>.</p>
<p>What can you expect in terms of features, then?</p>
<p>Well, since youâ€™re essentially supposed to run on top of Nock, and itâ€™s
all supposed to be strictly deterministic on top of an event stream, my
imagination is failing me as to how itâ€™s going to support some sort of
parallel processing, because you probably donâ€™t want to be stuck humping
one core of your CPU.</p>
<p>Letâ€™s say you try to make it work in parallel using message passing.
Hmm, there goes determinism.</p>
<p>Or shared memory? There goes using â€œNockâ€ (as youâ€™re poking yet another
hole in the substrate).</p>
<p>Iâ€™m sure thereâ€™s a solution, but Iâ€™d bet you a doughnut itâ€™s not going
to be as pure as the marketing.</p>
<p>Hoon:reality â€“ draw (it works, but sigh)</p>
<h2 id="urbit-as-an-os--capable">Urbit as an OS â€“ capable?</h2>
<p>Do you remember how we were supposed to throw away all that code from â€™70s?</p>
<p>So thatâ€™s not happening (as described above).</p>
<p>But at least the OS is a shiny awesome thing capable of real tasks, yes?</p>
<p>Okay.</p>
<p>Given my short exposure to Urbit Iâ€™m sure Iâ€™m missing some dark corners
where clumps of awesome lurk, but if you expect more than a Weather app,
half-assed web forum, simple shared notebooks, and a weird ass terminal,
you will be sorely disappointed.</p>
<p>Again, this will be rectified in the future (of that Iâ€™m actually and
honestly sure).</p>
<p>There are already some third party Hoon implementations of bit torrent,
chat bots, etc.</p>
<p>And thereâ€™s some plans for bitcoin integration, 3rd party apps, etc.</p>
<p>So if the ecosystem takes off, it could be rich and wondrous.</p>
<p>Exceptâ€¦ most of it wonâ€™t be written in Hoon or Nock. Since Urbitians
are hard at work providing language bindings for well known languages.</p>
<p>So what are you gaining by using Urbit that you couldnâ€™t get elsewhere?
No, seriouslyâ€¦ I have yet to figure this one out.</p>
<p>Letâ€™s move onâ€¦</p>
<h2 id="hosted-urbit--only-if-you-want-to-wash-your-dirty-laundry-in-public">Hosted Urbit â€“ only if you want to wash your dirty laundry in public</h2>
<p>Now, letâ€™s think about hosting Urbit for just a moment.</p>
<p>You can run it on your Raspberry (and it will work). You even own your
data that way. <em>(duh? donâ€™t you always, in that case?)</em></p>
<p>But letâ€™s suppose you want to host it elsewhere. I mean, thereâ€™s this
awesome peer-to-peer encrypted protocol in Urbit, so itâ€™s secure, right?</p>
<p>Well, thereâ€™s encryption during transit, and then thereâ€™s encryption at
rest.</p>
<p>And the failboat comes in the latter case.</p>
<p><strong>Nothing in Urbit is encrypted at rest</strong>.</p>
<p>No, seriously, all the chat logs, events, everythingâ€¦ is dumped into
a journal on disk<sup><a href="#fn7" id="fnref7">7</a></sup> in cleartext form.</p>
<p>So, hey, also the whole â€œa vault for secretsâ€ from the marketing video?
Hmmâ€¦ are you going to risk it?</p>
<p>And are you going to risk storing your bitcoin wallet on Urbit,
unencrypted?</p>
<p>In other words, <strong>when hosting urbit at any 3rd party, you better be the
only one with access to the underlying OS</strong> (and have it fully encrypted),
lest you want your entire history worth of data readable by the company
running the instance for you. Or anyone with access to the system.</p>
<p>So, running this on GCP? Digital Ocean? Tlonâ€™s hosting? Only if youâ€™re
comfortable [potentially] washing your dirty laundry in public.</p>
<p>Urbit:real world â€“ 0:1</p>
<h2 id="lets-fail-together-over-the-air">Letâ€™s fail together over the air</h2>
<p>So say you run your Urbit securely on your Pi, you love the platform,
the UI, the whole shebang.</p>
<p>Great.</p>
<p>Nothing to fear then?</p>
<p>Yeah, maybe except the teeny tiny detail that if you want to stay up
to date, you need to configure OTA<sup><a href="#fn8" id="fnref8">8</a></sup>.</p>
<p>So you will be receiving updates to your Urbit instance from one of your
neighbors (one that you configure).</p>
<p>And you talk to your neighbors over an end to end encrypted channel.</p>
<p>Sounds great, since this is 2021, and surely the updates are signed.</p>
<p>Well, no. They are not. The transmission is, though. Big help!</p>
<p>So â€“ I guess it wouldnâ€™t be that hard for one rotten apple somewhere
on higher ranks of the network<sup><a href="#fn9" id="fnref9">9</a></sup> <em>(rogue operator, hacked machine, hacked
core devâ€™s machine)</em> to push a code update that exfiltrates all your data,
possibly including all your secrets (hey, remember the BTC integration)?</p>
<p>And imagine the fun of auditing Hoon for potential security holes in
an update, if you were paranoid. Just the thought is hilarious.</p>
<p>Urbit:security â€“ 0:1</p>
<h2 id="urbit-id--scarcity-creates-value-and-you-pay-a-premium-for-that">Urbit ID â€“ scarcity creates value, and you pay a premium for that</h2>
<p>So I watch in great amazement the booming ecosystem of cryptocurrencies
of different shapes and colors, and of all things blockchain.</p>
<p>Urbit ID is even better than all of them, though.</p>
<p>You see, the entire identity address space is artificially constrained
to 32bit integers<sup><a href="#fn10" id="fnref10">10</a></sup>.</p>
<p>And according to the Urbit promoters and backers, <em>scarcity creates value</em>.</p>
<p>Just like that.</p>
<p>No need for demand or anything. Itâ€™s scarce, hence it has value. Done<sup><a href="#fn11" id="fnref11">11</a></sup>.</p>
<p>The fact that a desperate enough person could do an equivalent of a hard
fork, and run it independently with a different Identity root isâ€¦
impossible?</p>
<p>Whatever.</p>
<p>But anyway, letâ€™s say you â€¦</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wejn.org/2021/02/urbit-good-bad-insane/">https://wejn.org/2021/02/urbit-good-bad-insane/</a></em></p>]]>
            </description>
            <link>https://wejn.org/2021/02/urbit-good-bad-insane/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26177720</guid>
            <pubDate>Thu, 18 Feb 2021 09:22:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[All your domain are belong to us]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26177583">thread link</a>) | @thomas-vds
<br/>
February 18, 2021 | https://thomasvds.com/all-your-domain-are-belong-to-us/ | <a href="https://web.archive.org/web/*/https://thomasvds.com/all-your-domain-are-belong-to-us/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
   Posted 18. February 2021.
   <strong>1 min read.</strong></p></div><div><div><p>I recently bumped again into one of the oldest memes out there - <a href="https://en.wikipedia.org/wiki/All_your_base_are_belong_to_us" target="_blank" rel="nofollow noopener noreferrer">All your base are belong to us</a>. Long story short, a 1992 English translation of the Japanese game Zero Wing got a bit screwed up and players were fast to pick this glitch up and elevate it to Internet meme status.</p>
<p><img src="https://thomasvds.com/assets/static/all-your-base.e8fe0bf.c8886729d38e6661f35d808255c4d465.png" width="608" alt="All your base meme" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 608 415' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-4551223bf1bc9ea35c20053c4844ed68'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-4551223bf1bc9ea35c20053c4844ed68)' width='608' height='415' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAsCAYAAADVX77/AAAACXBIWXMAAAsSAAALEgHS3X78AAAVV0lEQVRo3s1aaVRc15G%2b3UDT0CsNNNAsTdMLTQMNiB3EpkZsYhFaEQghhASSUNi0YCSwJKPVlmQL7VhCiy3Lduw4duJxxhknM8fZzngyniQ%2bMzk5mRwncZaJl2QyGY9jy/6m6jaNsR2fE9tSkh9X7/Z7991b9VXVV1UPiQijEWqNAUKlv3UjVA%2bdVge9Wg2dRgODVgtDWDj0dOV7%2btBQ6MLD5dwQFuYfISH%2bewYDTBER0OqNt1amPzFU4aw3/dOaF43P9ybganc8HtiQ8KnHte4EPLQxAWfaLHDnOJGyfAWsRYUwL8hCTH01HNnZsLe0Ir6jHSkLyxHX1gZLUzPM9Q2I6t0EV1UJ4uOjIUQwvIkaudc1lqk74TPJ9eFxdX08HutLwMZyM51F1trXHAdcdwEXncClzzD4/QdS8csDSXAuW4LUA/vgoWtCewts%2b8eQV1mMzOHtcI7vQXbbGmRtG4DNtwjJLQ2wX7%2bBnOFhWG0WEkpgkUsNXPmM8nzcuJ/GQy5cISCEggAYrY8Fph1466Qd75z69OOtkw7gXDJOb82A/nM7Yd22FbaiAlg3boL92FFkrlwOz6ZeuFsbkcPecOgg3NVlSE%2bzI71tJdJHR2F1OyQAtZl64LwTf2SZpj6bXB%2bV004gOHCmfRaAsYZYab2b9PC9059%2b3DzNAFixv2cBTKvaYd09CgeFgGtDN1L3jcOzpRdpO3fCu7oFzj27kVFZDnfdIljb2%2bGtXogF69YRAE4CQIG0uFD8770pwFnHZ5LpTw0GgT3hXMfHAIAzjk88JACnaD5tx13LrQh3pCJlDwGQmw3Phh7YTpyAfXwcyUeOI6ahAcn9Q7Bk5yKNOCB2%2bzBc/VuQV7MYkWYTVOow6MOC8IuDVvICB979lDJ9nJy3EQC/a923JglKvQmuLRuQWeeDrbeXwqAXzjt2wTfcjhNfPIzO9c1Ys6MJnju3QnnmLFy9fXBY4xCsUhEAamhDGYDkOQDeu0Ug3H4AaJ9ntiXB4PDAumULXLWL4R7cgaWdeZi%2b3oHrj0wCN38C4Fd443dfxzde%2bQrOf%2bcG9k2tgq/GhnCNFkp1OMpS1Lg55Zznuo5bAsItByAgHM8lAOdd%2bOGEFa6iHOhGBpG8sAw5Nfl47pud%2bOZ3ZnDh0kVS/hX8/n%2b%2bR9f/ovFbGr/Er14/h/W9Duj1OgRpjdhTSyR4g2Wx410OrTO3BoRbAkBgTcA6787G/3unKL1cteHHoxZkNdXDuGsHUjvXoaqoBBdmutC3bT3uv3yMFP4hXvzBPfjNq8/j7Xd%2bgbfe/hl%2b9dplXL6%2bGI7UaEmCTo0J1xrz8drdFAYXUj4Awl8UgPnsOd/VOTVJ0iOW5nTFaRQXEvHFlYXoUJQhraYN5sGtSK/wYdPm46htWAlf/TosX70Upy/djUtXDmDP/t144qkHCZA/4NU3voCLD1Qi2RYmCyEGQSssGDS14uWJVNrfNg8E%2b%2b0H4MOxF7CyVJiVneF4T8GblKp%2bSmz9zTEbjmf74BBemcc1ibEwjwzAbLGgpq4LAzsOoqOjDz0d3bjYWId9a3rw1HM38Morz%2bH5f34U918fwOh4CVzuSKl8qCoEQikQL%2bw4ErEVrx61zRLiX8AD5ixOh707a21p5UsO/OG%2bZPxgtxU32lMwVGiFz5wMuzoOZaFU2ooU2lD4B4FQQNYvXVQFa7ITE5OXccfEOZw4%2bSL6sysxMboTeyd7sLLTi2WVqRhqq0J7z2KUL0qExqSR70cKE0SQQKNowxer60nGeJLHebs9gBbNEs/NKYdEHZdc%2bCmVt3uqY9BsTodbaUeYiCIBk0hpK5pFI1kqbk7xwOjoGERT6wYkWF1Y3dmPTiqIxu%2baxPD4KZyf2YcNfXbceagJj546gi9c3IVd47nIrPVC7bJBI8JgEhGIUphgF26MRa/Cb6eoZD/juv0hIGON3fySDT8/kIyRaj0KwlxYKbpQKEphJaV9inLEKqJRqVgIDwnICquECrEiBmGKMPk71V2B/KJm2N0ebOo/h95td%2bPOA8cwsf8EXn/jW3jxpUN45%2baLxAH/jffwLewYK4QhMgJhGjUBrCYATHSGGS7hwc6oFfjtydsMwDuzHsCE86%2bjSZgociMuPIysm4oZMY0uZRu8inSMi11IEonQCS2WixapbJAIQqpwIkaY5zxAEaSEThctPWDj1kl09x0kD/gnPP33T5LSv8CvX7%2bC/3vre7Im%2bNrzgygpj4WG2ucwTRiUQin3NymMSCNeGY5aijfmAfDe7QCAGw8uZZ/qTsE60UGulyUVuaicwhVxQcbkbrETNaJa3l8i6sj6aXKeKBKIAO1ybhQGZIh06IVe/g4OVmHF6s1Yu2ET7r73BN5449/w5h9%2bjief2Yhfv8pg/Bqnp%2btgijZAQ3WAUqmU7zEIQQolfKIWvdHVeO1kzPsA/IkxP0V/XMr%2beADuZ4Z34rUT8VimLcc%2bcRdZUFAq0uCGuIIxsQPRFPd7xRhsIlkKuE60Qy1C5dxBBBhOcWsgpfPEAmQTeHqFH4CgYAXqGjvQsWEb/uNHz%2bDll5/F0XtW4/JDvfjJy1/GH9/%2bF2wfW4iQUDUU8zhEQdmAr5tEL5ZG5OF3U7Gy0Hp7yp%2bKb87yVODKofthMN4NpO3AoHeloS8GAFDPtsMX/IgNVevI8i48pLxI1xQpwAlxBFPiGEJECHaIQaST1TlG28Vq%2bZwVtwsbhYESXpEpvcIgdFIZRWIS7EUO1DblIq90Cb79wlW8%2bP3rePCRvXjmq8fw3D%2bewXe/fy86u91IWGBHiDX5A0SqEeFkjDHJA%2bOlDrw5RQ3SDPf0LrIiKTJDhdKlFH%2bfP%2b3PXAwGKyqbqHOBtS7/mhm6Tvu/XZzldnjug8gNt7xZlcJWC0WDaMA94hDFn1sqNCXuIS6woEIsxCJRQQI5sEaslELqSNlYEUuub5SWVxFQjkg3cvJ90DS3wG434MtPrUF%2baRoefPg8ufxPcfHKTvzwx9M0/y4uX%2bnC0cMe2NIioV%2b0GOHEO6Ehfs/i8%2b8Q2xFMHFMpatAck467m2Pw9e1mmYpP%2bNJwrNaOR9cn4Ed7yOpnqV64bPN/TLngxOv3JOMb2y14vNeMw81RGKgyYGZdFHDNgZmuBIgwrQFVHiP2Nhjx8IYYfH9PItbmGqgmF4iimK%2bleF8qmtAqmrFQFEseyCElFwsfNlJW8FtJI8ODidFGGcISmYRSXwNS01xIXbIE5lVLMXhyFUbG8tGzvpiU/hmN3%2bD3bz6LA/tzsPtgJcavDSB1XTsceQWIpyLKZvN7XyeF2RaxSc6TFYlkBBvyRSVWiRXEQcvQJnrIKycwRCFar/RhqyMXZ%2bs8ONIYixXZOji0EZKfQik0dZSq9ZS640nG1R4zVhUYIfgDpCI4dM7lMuNDcLnLhNHqSESo1P6D6aX9Yg82i40SgFDykNViOe4Ud8jnIVS6MgDMDeH0LCu3AgULKxAZY6La3gZHYR5MS8gT7j4IW38n9u9pwUv//gXsnViKhI1tyD44icSaGmRWFsISHwMjpcL0HC%2bC1SGYFqeJBCvlOcwvFYpS3KEYIk/zolRRgL3KXWhVLkGJIh9VtC5bFFKIFiKTjJVI2Sud1uULqi8UHkQrIqBXhsvwNJI365VREDqjDtawBJQrimBTJPk/SIoisngr6sjlEkS8LEic5PJnxL1UC7TKfJ8rcmQIRInIWeY3SvbX6LXILy5FQVkppUCyQFoyMquKkd3dhfTTx5B45D7ULMvC6VMLUNmSCfupi/DUVMHrTkBmrgexiRZow7XwlOWiIbIe18WMDDE%2bg0FuoaJrg1hHqXhUysBpt0xQCU0pOIUMkKlIQ4OyGkPKzTiq2Ef8dRgP0R5PikdwUZzBLjFMoPjrFn2ozg9AitomSYzzbpdiDe5RTJKLLZOxz0zMFuB5FhHcKXGc3EgnCZLz/qJZ6wQTcEyCBlMElixtQ23jOiSmpsFTUoi0kSF4hofhHR5A5bYRFFGX96Un25HfWoKKkTuQuawF6SU5EoCElERY4qwoqFmCSdUEBsQWWRCxfFspFE6LEzIU68RirBdrUUzWfk48jcfFQ9Ir68loHKLVokqC1UXpvJ%2byyKDYKusXNuLz4qtoEvUQKvL6CGMEwtXhMItodNOGnOfLqdpjyzPTs1KsKFueXXC7GJAEmEbuxeHA3BDwAh5qKmLqmzsxNHwvqla3I7nOB%2b/ucWRu7UdGcRFyd%2b1GWmsN9o%2bXw1NbBs/Bw8gYoK4xm8h2QQaSCICixT6sLRvEfZR91ivWysyyTfRhkmK9XaySnlAg8vAP4ss4KPYRYddKnhoU/cQLtVhBsnLm%2bpL4PJ4Wj2OCQrVClMmKlQl8gMA4L6YQozL7PcCuTiFEGiSx8SJWqFgUSCTZ3bnAYaU5FDoo9dUIn8z7vDaFLMMkFTpbDwRTEeNwZ6F15TYMDe5HcksTkkZH4BkdhbuA3L59LVz1PnR1uuFcWgtf/wDSVq5AOvGEJSkONocDvYMT2KEblrxzjFy4kazVJzZIqxtmiyu28NfE32FYbJNewN7LGYpdfJcYwefEZpk97hLjcr5RrJf6sGHZa5lcs1VePwCJ6oTZ3K2XLs%2bFDL/ApLaWOjF2Kz/ZhcjiZxW5GiteQgeze7JgfcTGauEnTWOEAXmFTVjXPYnW5ZtgaKyF01eJTAoH5%2bHD8LS3IzU1Gqmb%2b5C%2buRtZPRuR7LAiXBOOhuVd6CwfkEL3K3rJffvwgLiIr4gnSKFhsnyuVJgVXy6WUjMWK2XcT4qyIQ6IvbJY48KNwfgchRCHDletXpFBqbSMQmWFrGxXqZZBGI1GaNSaWZY1oIgsz7HElmaX443iuNOT2cAqN%2bSD3VQscSxyuLD1uSdg0ALFkzE6Bt7sOnR2TcDuzIDObIKzMAdZXevh2juBjMYWZK1YhfThIaQuXiTfiY93oKqpA6v0a2jfEtQqFuOyOI9z4j40aBthCDIjPjieGrJ88oBFUlY%2bm7mJz99GoB0VkzJzzIhzOEm1C4f0KHkEcwcDwcTJ3v6ouIZ%2bVR%2bEwWiASW2ifLpCMisv3imGJNPmzPYCPBhpVphdh9nfQqBw7LHS7DlsKUaWawN%2bV6fQyg8a1TU9KKIKkKvCWIcNbq8bGXU18NbVwltGnWRzIxU%2bfs/xZpciL68edUF1FOeRcp%2bqoHIIswppUXpUJ5igDguG0CplvcGZyUq1RyHxQRXFNnsik9sa4okh4oP7ifVfEi9QGB0iXbySwLmiZU9YILLhVWVSIWQMQ4m6SCpeSgpymcuFA/MAxzm7ObsNo8yux6zKyjMnbKG6gMmIm57jFKvsNWXkEXxgEhUtilABW0oGYi1WqvNDEGWOpNogCp5MF5zuFGTkeREVZZINT6haDQ2FY5wmTuZp9rYM6jx1FqoKFSF4Nt2Ol/fVYzw4CNoIk9yb%2b5SlxPQcouyRbFnmCjYQG4cV5Qz2bfF1XKVulr9ZXBJn8SClRa5YE1UJ76dBVpyF7xad0u3ZdXhwzEcQ%2bXGWYPcJJVLk3MsEs4JCgec9ZHXODpwpllFWSKe6nS2uUoVSh2fyd3ZEjmZLjIxzZ2aqZHxbagq1vuFwpaciLsEfZgZloJnKhNqghVEZTCAL/LgiBldztLiTGiah1UCn1cx6ZpysAZh/YkSMLHrYSzkrBHiJ%2bepF8S3KKkclxzGnHCSuiFHFQKiNavjUVRTvd1KM9Eo3Zk9gAmSW5/I2k1pb9oJAi8qkwyUyW4BdkA/geYAEA4P7%2bgAAPCxJFnJhNaJjiQAJhODgYCTYEhGbQH2EySgHr%2bNsE6GlOYF23G7GtaRoSmnhaAnTIs0cDS3tGTG7NvAhhstx9sQEqvC4ZymhYo5DoVks8f%2btkeT9T/GSDOVWAucnNLeriK/0Rj3i1HHyQbD8GitmP0boyPJGKQz39oFn3P5yypnfrooPtbCB%2b6xgELls4BlbPygoCMEhwRIIvqelyjEkJARqaoB4fWCtUsWFlUBPqhXLLVGkmICZZA1R8VoKF532I%2bf6DZIkyZw7VA7lACnzcw4VBodDmOuXaFWUvxAKoZr7wz34Jxmf5p2/hRFMIMs0GB4eDiURkUKhkLHK1yBlkLzHv9kjpKKK9xUNrA/cm/8s8Fu%2bq/zgvvPvyXVKxUfWzF8XxHMJspi7N3/MB1%2buJ7l5SB0U/ueB/UKUIe%2bvofY6NJSKtwjqBoOClLcEUYXik67/63pOMIcnf4TMyPDC56ulQsSKyspqJCXZ0NnZjcLCYtTWNtD9ZKru1Cgqcsy9nJ9fjIIC6sJc6YRqMHJzi%2baeMaB5eYU0ilBdXYuqqhqUlVUh1eXB8uVtdK8OsbF%2b1s/KWoCWlhWw21OxcGElVYjpJEsNiovL0dDQDIslfm7fkpJyWp9H79fTnovR3LwMaWnps2cGoa6uEb5FtViyZCnJU0DrK/wtfma21I/3Ky2toHkdKip8iIujvYOCQjAy0oW2tmqsXbsYV67sQcfaGjz22HE0Ni7CkSM70dRUCmuykRocn9wwKcmM%2b04O4MEH9%2bKuu3pJ%2bFicODGMCAIpeJb0du7swcMPH8P27etx6FA/rl8/jKGhNXj2q%2bdw9ux2Ei5XrhsaXkvPjmFqapjGACYnt2B0dDMuXNiF6elJ2ChL8DqXKxGnTg%2bRfBOYmRmj53vwxBOnCbQ8/0cZyjhXrx6id/bi6adPY9myepJpBCn2GJJlHSYmevD88w/ghRcewVNPncTRo0OoqSGj6XQGUiiSLErpLtOClJQIJCebyCuiYTSqyIoJ9Jx4QhNKaPv//47BEAa320zWsKCs3E5rqTwtSkJ6umUunOLjdbQmSl5zc%2bPhdJqQR2e43ZGkTCTt4W%2bebLYI8qwkeL2xcu7xmJGdbUFOjkXuGRdn8KdGE9UPzkh5Py0tWu5XXJxEV/Nc%2bLGsWVlxdLXQPrGkE/9OoPOi5DOnMwIOGl5vDHkv7x3h5wD%2bbH274vxW7HUrz5w/OHRlFggLC5OHKJWKWRYOzN%2b/%2bl9QzF05TjnOs7MXyBjj%2b8yq9hQXrFY7WaeUnuXOO0wxx/Dzye/D576fBRRz530wsyg%2bsGY%2bOPK3UvER2T/uvbksoFarPwFqfqGmpw/iwIERiusu7Ns3QCCGQkvl6e7dmzE21otjx/bTtY9CyiIJ6m%2bxDlCpVLPtMGUCrsL%2bnKFS%2bYumigo7WT6OsoaTGNnlr/pIUZ7X1KQhNy%2bJWNlDceiG2WySf/Lmiu/PPed2joAc7PnCYDCAQfgkg70mNFRDG%2bjIe7RyHnjGcx7h4ToCi9dQja7X0zvGT3zOX2L8P6stanIzAt/EAAAAAElFTkSuQmCC' /%3e%3c/svg%3e" data-srcset="/assets/static/all-your-base.e8fe0bf.c8886729d38e6661f35d808255c4d465.png 608w" data-src="/assets/static/all-your-base.e8fe0bf.c8886729d38e6661f35d808255c4d465.png" srcset="https://thomasvds.com/assets/static/all-your-base.e8fe0bf.c8886729d38e6661f35d808255c4d465.png 608w"></p>
<p>Being a DNS junkie at heart (see my past <a href="https://thomasvds.com/bing-and-brave-are-squatting-goo-gle-domains-so-i-joined-them/">Googlesquatting experiments</a>), the <code>us</code> word at the end of that sentence caught my eye. Let's see if the <code>allyourbasearebelongto.us</code> domain name is available ğŸ¤© !</p>
<p>The results got me really baffled. I checked both root and subdomains:</p>
<table>
<thead>
<tr>
<th><strong>Domain</strong></th>
<th><strong>Registered in</strong></th>
<th><strong>Target</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>allyourbasearebelongto.us</td>
<td>2019</td>
<td><a href="https://thomasvds.com/all-your-domain-are-belong-to-us/allyourbasearebelongto.us">DOMENE OG WEBHOTELL</a></td>
</tr>
<tr>
<td>all<code>.</code>yourbasearebelongto.us</td>
<td>2006</td>
<td>Old non-HTTPS site with Flash plugin</td>
</tr>
<tr>
<td>allyour<code>.</code>basearebelongto.us</td>
<td>2006</td>
<td>404</td>
</tr>
<tr>
<td>allyourbase<code>.</code>arebelongto.us</td>
<td>&nbsp;2016</td>
<td>No response</td>
</tr>
<tr>
<td>allyourbaseare<code>.</code>belongto.us</td>
<td>2002</td>
<td><a href="http://belongto.us/" target="_blank" rel="nofollow noopener noreferrer">Weird number cards</a></td>
</tr>
<tr>
<td>allyourbasearebelong<code>.</code>to.us</td>
<td>2002</td>
<td>No response</td>
</tr>
</tbody>
</table>

<p>This is a harsh reminder that <a href="https://www.reddit.com/r/Entrepreneur/comments/2dq7zv/how_do_you_get_past_the_feeling_that_everything/" target="_blank" rel="nofollow noopener noreferrer">everything has already been done on the Internet</a>. Still, none of these domains actually refers to the glorious meme - what a waste. IMHO, the folks owning the (probably priceless) <code>to.us</code> domain could have made a little effort here and put their domain to good use by hosting this meme.</p>
<p>A bit disappointed by these findings, I tried to come up with other ideas, like using the <code>.cat</code> extension because the guy in the meme is called CATS. But this one <a href="https://domini.cat/en/rules-of-the-cat-domain/" target="_blank" rel="nofollow noopener noreferrer">requires to publish in Catalan</a> ğŸ˜…, and it's not a well known TLD.</p>
<p>So I shuffled possibilites a bit more and came up with <a href="http://allyourbasearebe.longto.us/" target="_blank" rel="nofollow noopener noreferrer">allyourbasearebe.longto.us</a>. Bingo! This one was not taken. Finally, the beloved meme now has a site of its own that honors it.</p>
<p>ğŸ‘‰ Check it out at <a href="http://allyourbasearebe.longto.us/" target="_blank" rel="nofollow noopener noreferrer">allyourbasearebe.longto.us</a>.</p>
<p>See you next time for more DNS hype!</p>
</div></div></div>]]>
            </description>
            <link>https://thomasvds.com/all-your-domain-are-belong-to-us/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26177583</guid>
            <pubDate>Thu, 18 Feb 2021 09:04:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Distributed Sorting â€“ Google Interview Question â€“ Algorithm and System Design]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26177521">thread link</a>) | @soygul
<br/>
February 18, 2021 | https://quanticdev.com/algorithms/distributed-computing/distributed-sorting | <a href="https://web.archive.org/web/*/https://quanticdev.com/algorithms/distributed-computing/distributed-sorting">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <section id="main_content">
        
<p>If you were given 1 TB of data and asked to sort it using 1000 computers, how would you do it. This is a Google senior interview question, and below is a summary of the optimum solution. In this article, we will do the full 2-hour interview stages together and get hired!</p>

<video width="1920" height="1080" controls=""><source src="https://quanticdev.com/algorithms/distributed-computing/media/intro.mp4" type="video/mp4"></video>

<p>First off, letâ€™s check out the agenda for this writeup. We will start by visualizing the problem. Then we will continue with a concise design document. This is probably going to be on a whiteboard in a real interview, so we will keep it short. In the document, we will define the problem, do requirements analysis, do system design using a simple diagram, and finally do the complexity analysis. Then we will actually code and implement this system. Then weâ€™ll add some tests. And we will close it off with a discussion with the interviewers.</p>

<p>I will take you through the entire 2-hour interview in sections and do every section with an in-depth analysis. You are about to read the most in-depth late-stage senior interview analysis on the internet. So, sit back, relax, and turn up your brain to the max.</p>

<p>Table of contents:</p>
<ul>
  <li><a href="#resources">Resources</a></li>
  <li><a href="#overview">Overview</a></li>
  <li><a href="#problem-visualization">Problem Visualization</a></li>
  <li><a href="#design-document">Design Document</a>
    <ul>
      <li><a href="#problem-definition">Problem Definition</a></li>
      <li><a href="#requirements-analysis">Requirements Analysis</a></li>
      <li><a href="#system-design">System Design</a></li>
      <li><a href="#complexity-analysis">Complexity Analysis</a></li>
    </ul>
  </li>
  <li><a href="#implementation">Implementation</a></li>
  <li><a href="#tests">Tests</a></li>
  <li><a href="#discussion">Discussion</a></li>
  <li><a href="#conclusion">Conclusion</a></li>
</ul>

<h2 id="resources">Resources</h2>
<p>You can find the video version of this article on YouTube: <a href="https://www.youtube.com/watch?v=vgKjatRVtys" target="_blank" rel="noopener">https://www.youtube.com/watch?v=vgKjatRVtys</a></p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/vgKjatRVtys" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>The video is fully animated. If you want to read the comments or leave a comment, do so under the YouTube video. If you want to contribute to the article, make a pull request on GitHub.</p>

<p>My simplified distributed sorting algorithm implementation:</p>
<ul>
  <li><a href="https://github.com/soygul/QuanticDev/blob/master/algorithms/distributed-computing/distributed-sorting/distributed-sorting.js" target="_blank" rel="noopener">https://github.com/soygul/QuanticDev/blob/master/algorithms/distributed-computing/distributed-sorting/distributed-sorting.js</a></li>
</ul>

<p>My k-way merge and tournament tree implementations and their tests:</p>
<ul>
  <li><a href="https://github.com/soygul/QuanticDev/tree/master/algorithms/merge" target="_blank" rel="noopener">https://github.com/soygul/QuanticDev/tree/master/algorithms/merge</a></li>
  <li><a href="https://github.com/soygul/QuanticDev/tree/master/algorithms/trees/tournament-tree" target="_blank" rel="noopener">https://github.com/soygul/QuanticDev/tree/master/algorithms/trees/tournament-tree</a></li>
</ul>

<p>Chromium Project Design Document Template:</p>
<ul>
  <li><a href="https://docs.google.com/document/d/14YBYKgk-uSfjfwpKFlp_omgUq5hwMVazy_M965s_1KA/edit" target="_blank" rel="noopener">https://docs.google.com/document/d/14YBYKgk-uSfjfwpKFlp_omgUq5hwMVazy_M965s_1KA/edit</a></li>
</ul>

<p>My <a href="https://www.youtube.com/watch?v=Xo54nlPHSpg" target="_blank" rel="noopener">K-Way Merge</a> video, which explains k-way merge which is used extensively in this video.</p>

<p>My <a href="https://quanticdev.com/articles/software-engineer-compensation-guide" target="_blank" rel="noopener">Software Engineering Compensation Guide</a> article to help you estimate what you should be paid:</p>

<h2 id="overview">Overview</h2>
<p>Letâ€™s check out the problem in hand. In this question, you are given 1 TB of data sitting in a database, and 1000 computers each with 1.5 GB of RAM. And you are asked to sort this data as fast as possible.</p>

<p><img src="https://quanticdev.com/algorithms/distributed-computing/distributed-sorting/media/distributed_sort_problem_definition.png" alt="Distributed Sorting Interview Question by Google"></p>

<p>This is a distributed sorting question asked by Google in a senior engineer interview. This was asked during the final interview round, and it is a hard question. In addition to the question being hard, the discussion held with the interviewer around other possible solutions, possible improvements, and external factors that might affect the performance, will test your deeper understanding of the topic. The source of this question is Hacker News, and you can find several versions of this question being discussed by ex-Googlers on HN. Obviously, I cannot reveal the source directly, but I am keeping a record of these questions as I find them to see how frequently they are asked. Distributed computing questions seem very frequent at senior Google interviews. On a side note, the original question was asked to be implemented using Python or C++ on a Kubernetes cluster. Finally, 2 hours is allocated for this interview, including design, implementation, and discussion. We will look into multiple approaches to solve this problem and investigate different requirements along with other variants that you might be given in an interview situation.</p>

<h2 id="problem-visualization">Problem Visualization</h2>
<p>Letâ€™s start by visualizing the problem. When I am given a question, the first thing I do is to try to visualize it in my mind to investigate possible solutions quickly. I do this before jumping into the requirements analysis and start asking questions. If I am given a whiteboard, I will try to visualize the problem drawing a matrix, a diagram, or whatever might help me imagine possible solutions.</p>

<p>For this article, I will visualize this question using an animated diagram to help you understand it better. We start with our 1 TB of data in our database. Then comes our 1000 computers with 1.5 GB of RAM each. Letâ€™s say we make each computer read 1 GB portion of our data from our database. Now we are left with 1000 nodes with all our data in them.</p>

<video width="1920" height="1080" controls=""><source src="https://quanticdev.com/algorithms/distributed-computing/media/problem_visualization.mp4" type="video/mp4"></video>

<p>Next, what do we do with this much data and this many nodes? How do we utilize the CPU power of all the nodes at the same time? We can try to make all nodes sort the data that they have in them. Remember, they all have 1.5 GB of RAM, and we have only used 1 GB of it. This gives us 500 MB of auxiliary space to work with. Heapsort only requires O(1) auxiliary space, so it is perfect for this job. Quicksort also only requires O(logn) auxiliary space, so we might use that too. We can decide this in the design phase.</p>

<p>Once each node finishes sorting their data simultaneously, how do we merge them? Well, there is a method called k-way merge designed exactly for this purpose. We can definitely use that! It is possible to implement k-way (also known as multiway) merge using a heap, or even better, using tournament trees. We start by selecting one of the nodes as the leader, the leader pulls the first values from each other node and puts them in a tournament tree. The root of the tree will be our first winner and the very first sorted value. Then we pull a new value in place of the missing value, complete our tournament tree and get the root again. We can keep doing this to get a sorted stream of data and write it back to our database into another table. This seems like a very workable approach. But will it match the requirements? We will have to discover that by asking lots of questions to the interviewers. But this is a good visualization and good initial approach which should hopefully help us come up with lots of good questions in the requirements analysis phase.</p>

<h2 id="design-document">Design Document</h2>
<p>In a regular coding interview, I would directly jump to the requirements analysis to select the best algorithm for the question in hand. However, this is the final interview stage with 2 hours to go. This is where you show off with your software engineering skills. So, we treat this as a serious project and start with a design document. Typically, design documents are very long and detailed. A well-crafted design increases the odds of success of a project. However, for this occasion, we will keep it short. Short enough to fit into a single whiteboard, or a single page if you are given paper. If you want to see a complete example, I have the link to Chromium Projectâ€™s Design Document Template in the resources section above.</p>

<p><img src="https://quanticdev.com/algorithms/distributed-computing/distributed-sorting/media/chromium_design_document_template.png" alt="Chromium Project Design Document Template"></p>

<h3 id="problem-definition">Problem Definition</h3>
<p>The very first section of each design document is the problem definition. The problem in hand is distributed sorting (also known as external sorting) of a very large dataset with memory-constrained nodes.</p>

<h3 id="requirements-analysis">Requirements Analysis</h3>
<p>This is probably the most crucial part of the entire interview. This is where your future will be decided. If you ask the right questions in this section and proceed to implementation in full agreement with the interviewers, you will have a great chance of passing the interview. The question that we are given is very generic and is lacking many important details. It is clear to me that the interviewer expects us to ask for clarifications, so we will do that soon. I would argue that a software engineeringâ€™s prime function is gathering requirements, so it is common for interviewers to ask vague questions to test your investigative skills. This part also reveals your depth of understanding of the topic. Letâ€™s start with some important questions to the interviewer:</p>

<ul>
  <li><strong>Question: Is there any order, pattern, or uniform distribution in the initial data.</strong>
    <ul>
      <li>Their Answer: No.</li>
      <li>Comment: This means that we cannot take a shortcut by using specialized sorting techniques like bucket sort. If the given data had uniform distribution, we could simply partition it to all nodes and use bucket sort.</li>
    </ul>
  </li>
  <li><strong>Question: What shall I do with the final sorted data?</strong>
    <ul>
      <li>Their Answer: We will stream it to somewhere else for further processing.</li>
      <li>Comment: This is typical for data processing pipelines. We start with a set of nodes optimized for sorting and merging the data. Then we send the data to other nodes which are hardware optimized for other forms of processing.</li>
    </ul>
  </li>
  <li><strong>Question: What is the read speed of the database?</strong>
    <ul>
      <li>Their Answer: Letâ€™s say 20 GB/s.</li>
      <li>Comment: This happens a lot in interviews. This means that the interviewer does not have a specific number in mind but wants you to assume that you should not be concerned with the database performance and assume that it is sufficient.</li>
    </ul>
  </li>
  <li><strong>Question: Will we separately store the sorted data in the database?</strong>
    <ul>
      <li>Their Answer: No.</li>
      <li>Comment: Interviewer already said that we were going to send the final sorted data somewhere else. This question was just to be extra sure.</li>
    </ul>
  </li>
  <li><strong>Question: What is the network latency between each computer node?</strong>
    <ul>
      <li>Their Answer: Letâ€™s say not too bad.</li>
      <li>Comment: This means that you should not be concerned with the latency between the nodes. Maybe interviewers did not think of a scenario where you would want to use a distributed partitioning algorithm which would require a fast network.</li>
    </ul>
  </li>
  <li><strong>Question: Can we use all of 1.5 GB of memory in each node?</strong>
    <ul>
      <li>Their Answer: Yes.</li>
      <li>Comment: Again, this is good. When we have only 1 GB of data in each node, we can choose a sorting or partitioning algorithm that requires up to n/2 auxiliary space.</li>
    </ul>
  </li>
  <li><strong>Question: Do the computer nodes have disks or other persistent storage that we can write to?</strong>
    <ul>
      <li>Their Answer: No.</li>
      <li>Comment: This is expected. Involving persistent storage in our data processing would introduce yet another point of failure, so not so desirable.</li>
    </ul>
  </li>
</ul>

<p>I think this is enough questions for now. We clarified the task in hand quite â€¦</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://quanticdev.com/algorithms/distributed-computing/distributed-sorting">https://quanticdev.com/algorithms/distributed-computing/distributed-sorting</a></em></p>]]>
            </description>
            <link>https://quanticdev.com/algorithms/distributed-computing/distributed-sorting</link>
            <guid isPermaLink="false">hacker-news-small-sites-26177521</guid>
            <pubDate>Thu, 18 Feb 2021 08:55:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Asynchronous exceptions and interruptible operations in GHC (Haskell)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26177194">thread link</a>) | @coot
<br/>
February 17, 2021 | https://coot.me/posts/mask.html | <a href="https://web.archive.org/web/*/https://coot.me/posts/mask.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		

<div id="cb1"><pre><code><span id="cb1-1"><span>{-# LANGUAGE ScopedTypeVariables #-}</span></span>
<span id="cb1-2"><span>module</span> <span>Mask</span> <span>where</span></span></code></pre></div>
<div id="cb2"><pre><code><span id="cb2-1"><span>import</span> <span>Control.Concurrent.MVar</span></span>
<span id="cb2-2"><span>import</span> <span>Control.Exception</span></span>
<span id="cb2-3"><span>import</span> <span>System.FilePath</span> (<span>FilePath</span>)</span>
<span id="cb2-4"><span>import</span> <span>GHC.IO.Handle.Types</span> (<span>Handle__</span>)</span></code></pre></div>
<p>The base library explains asynchronous exceptions and masking quite well, but still this is one of the topics that is often misunderstood and some of its crucial parts like interruptible operations are not well enough documented to slip under the radar too often.</p>
<h2 id="synchronous-vs-asynchronous-exceptions">Synchronous vs Asynchronous exceptions</h2>
<p>There are two main ways of throwing exceptions in Haskell, either with <code><a href="https://hackage.haskell.org/package/base-4.14.1.0/docs/Control-Exception.html#v:throwIO">throwIO</a></code> or <code><a href="https://hackage.haskell.org/package/base-4.14.1.0/docs/Control-Exception.html#v:throwTo">throwTo</a></code>. <code>throwIO</code> throws an exception in the current thread in synchronous way, <code><a href="https://hackage.haskell.org/package/base-4.14.1.0/docs/Control-Exception.html#v:throwTo">throwTo</a></code> allows to throw an exception in some other thread, hence the name asynchronous exceptions. But letâ€™s start from the beginning, why we even need asynchronous exceptions? This is nicely answered in the paper <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/07/asynch-exns.pdf">Asynchronous Exceptions in Haskell</a>:</p>
<blockquote>
<ul>
<li>
<strong>Speculative computation.</strong> A parent thread might start a child thread to compute some value speculatively; later the parent thread might decide that it does not need the value so it may want to kill the child thread.
</li>
<li>
<strong>Timeouts</strong>: If some computation does not complete within a specified time budget, it should be aborted.
</li>
<li>
<strong>User interrupt.</strong> Interactive systems often need to cancel a computation that has already been started, for example when the user clicks on the â€œstopâ€ button in a web browser.
</li>
<li>
<strong>Resource exhaustion.</strong> Most Haskell implementations use a stack and heap, both of which are essentially finite resources, so it seems reasonable to inform the program when memory is running out, in order that it can take remedial action. Since such exceptions can occur at almost any program point, it is natural to treat them as asynchronous.
</li>
</ul>
</blockquote>
<p>Asynchronous exceptions can interrupt almost any computation, masking is provided as a way to make it predictable, so we can reason about it. Letâ€™s examine this standard example:</p>
<div id="cb3"><pre><code><span id="cb3-1"><span>withLockUnmasked ::</span> <span>MVar</span> () <span>-&gt;</span> <span>IO</span> a <span>-&gt;</span> <span>IO</span> a</span>
<span id="cb3-2">withLockUnmasked lock k <span>=</span> <span>do</span></span>
<span id="cb3-3">  takeMVar lock</span>
<span id="cb3-4">  a <span>&lt;-</span> <span>catch</span> k (\(<span>e ::</span> <span>SomeException</span>) <span>-&gt;</span> putMVar lock ()</span>
<span id="cb3-5">                                      <span>&gt;&gt;</span> throwIO e)</span>
<span id="cb3-6">  putMVar lock () </span>
<span id="cb3-7">  <span>return</span> a</span></code></pre></div>
<p>The problem with <code>withLockUnmasked</code> is that an asynchronous exception could be thrown just after <code>takeMVar</code> is executed but before the <code>catch</code> installs the handler. To be able to fix this, Haskell provides primitive operations which allow to mask asynchronous exceptions. Each thread keeps the following masking state (original haddocks preserved):</p>
<div id="cb4"><pre><code><span id="cb4-1"><span>-- | Describes the behaviour of a thread when an asynchronous</span></span>
<span id="cb4-2"><span>-- exception is received.</span></span>
<span id="cb4-3"><span>data</span> <span>MaskingState</span></span>
<span id="cb4-4">  <span>=</span> <span>Unmasked</span></span>
<span id="cb4-5">  <span>-- ^ asynchronous exceptions are unmasked (the normal state)</span></span>
<span id="cb4-6">  <span>|</span> <span>MaskedInterruptible</span></span>
<span id="cb4-7">  <span>-- ^ the state during 'mask': asynchronous exceptions are masked, but</span></span>
<span id="cb4-8">  <span>-- blocking operations may still be interrupted</span></span>
<span id="cb4-9">  <span>|</span> <span>MaskedUninterruptible</span></span>
<span id="cb4-10">  <span>-- ^ the state during 'uninterruptibleMask': asynchronous exceptions are</span></span>
<span id="cb4-11">  <span>-- masked, and blocking operations may not be interrupted</span></span></code></pre></div>
<p>Let us stress that in <code>MaskedInterruptible</code> state, which is a result of using <code><a href="https://hackage.haskell.org/package/base-4.14.1.0/docs/GHC-IO.html#v:mask">mask</a></code> function, asynchronous exceptions can be thrown, but only by interruptible operations. In the <code>MaskedUninterruptible</code> asynchronous exceptions cannot be thrown even by blocking / interruptible operations. <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/07/asynch-exns.pdf">Asynchronous Exceptions in Haskell</a> paper specifies interruptible operations as:</p>
<blockquote>
Any operation which may need to wait indefinitely for a resource (e.g.,takeMVar) may receive asynchronous exceptions even within an enclosing mask, but only while the resource is unavailable.Such operations are termed interruptible operations.
</blockquote>
The complete list of interruptible operations is astonishingly short:
<ul>
<li>
<code>takeMVar</code> when the <code>MVar</code> is empty,
</li>
<li>
<code>putMVar</code> when the <code>MVar</code> is non-empty,
</li>
<li>
<a href="https://hackage.haskell.org/package/stm/docs/Control-Monad-STM.html#v:retry"><code>retry :: STM a</code></a>,
</li>
<li>
<a href=""><code>throwTo</code></a>
</li><li>
<a href="https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/exts/ffi.html#interruptible-foreign-calls">interrutible ffi calls</a>.
</li>

</ul>
In particular none of the operations listed below are interruptible:
<ul>
<li>
<code>IORef</code> operations,
</li>
<li>
<code>safe</code> and <code>unsafe</code> foreign calls. There is a subtle difference between <code>safe</code> and <code>unsafe</code> ffi: when a safe ffi returns haskell thread will check if there are pending asynchronous exceptions while haskell rts does not know about <code>unsafe</code> ffi calls.
</li>
</ul>
<p>We have two ways of fixing <code>withLockUnamsked</code>:</p>
<div id="cb5"><pre><code><span id="cb5-1"><span>withLockMaskedInterruptible ::</span> <span>MVar</span> () <span>-&gt;</span> <span>IO</span> a <span>-&gt;</span> <span>IO</span> a</span>
<span id="cb5-2">withLockMaskedInterruptible lock k <span>=</span> mask <span>$</span> \unmask <span>-&gt;</span> <span>do</span></span>
<span id="cb5-3">  takeMVar lock</span>
<span id="cb5-4">  a <span>&lt;-</span> <span>catch</span> (unmask k)</span>
<span id="cb5-5">             (\(<span>e ::</span> <span>SomeException</span>) <span>-&gt;</span> putMVar lock ()</span>
<span id="cb5-6">                                    <span>&gt;&gt;</span> throwIO e)</span>
<span id="cb5-7">  putMVar lock () </span>
<span id="cb5-8">  <span>return</span> a</span>
<span id="cb5-9"></span>
<span id="cb5-10"><span>withLockMaskedUninterruptible ::</span> <span>MVar</span> () <span>-&gt;</span> <span>IO</span> a <span>-&gt;</span> <span>IO</span> a</span>
<span id="cb5-11">withLockMaskedUninterruptible lock k <span>=</span> uninterruptibleMask <span>$</span> \unmask <span>-&gt;</span> <span>do</span></span>
<span id="cb5-12">  takeMVar lock</span>
<span id="cb5-13">  a <span>&lt;-</span> <span>catch</span> (unmask k)</span>
<span id="cb5-14">             (\(<span>e ::</span> <span>SomeException</span>) <span>-&gt;</span> putMVar lock ()</span>
<span id="cb5-15">                                    <span>&gt;&gt;</span> throwIO e)</span>
<span id="cb5-16">  putMVar lock () </span>
<span id="cb5-17">  <span>return</span> a</span></code></pre></div>
<p>The difference between both of them is subtle. To get to the point we need to analyse which operations are blocking / interruptible. As specified in <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/07/asynch-exns.pdf">Asynchronous Exceptions in Haskell</a>, <code>takeMVar</code> is blocking only if <code>v :: MVar ()</code> is empty. We have two cases:</p>
<ul>
<li><p><em><code>v</code> is non-empty:</em> neither of the two can raise asynchronous exception while executing <code>takeMVar</code>. This means that both implementations will install the exception handler before an asynchronous exception is raised, and this is what we wanted.</p></li>
<li><p><em>if <code>v</code> is empty:</em> the semantics of <code>MVar</code> ensures that <code>takeMVar</code> is interruptible until it is empty, once <code>takeMVar</code> takes the value it becomes non-blocking. This ensure that asynchronous exceptions can be raised by <code>withLockMaskedInterruptible</code> only when <code>takeMVar</code> is blocked. This also means that <code>withLockMaskedInterruptible</code> will install the catch handler once <code>takeMVar</code> past the point of being interruptible.</p></li>
</ul>
<p>The crucial difference between <code>withLockMaskedInterruptible</code> and <code>withLockMaskedUninterruptible</code> is that the later will never throw an async exception while <code>takeMVar</code> is blocked while the lock is empty (e.g.&nbsp;taken by some other thread).</p>
<p>It seem that analysing the code which is using <code>mask</code> is more difficult than when using <code>uninterruptibleMask</code>, is it really so? The main problem with <code>withLockMaskedUninterruptible</code> is that it can potentially introduce deadlocks; a program might become unresponsive: interruptions like one delivered by signals (e.g.&nbsp;<code>CTRL-C</code>) are delivered using asynchronous exceptions; or it could introduce undeliverable timeouts, which in networking applications can introduce safety hazards. Because deadlocks are non-local properties there is actually no way to analyse if <code>withLockMaskedUninterruptible</code> is safe or not without its context, it depends on the program where it is used. For this reasons the documentation of <code>uninterruptibleMask</code> says in capital letters: THIS SHOULD BE USED WITH GREAT CARE. In my experience, debugging asynchronous exceptions is easier than debugging deadlocks. When logging is done right you can see asynchronous exceptions in the logs, but you will not see a bunch of threads being deadlocked.</p>
<p>Takeaways from this are:</p>
<ul>
<li><a href="https://hackage.haskell.org/package/base-4.14.1.0/docs/GHC-IO.html#v:mask">mask</a> masks asynchronous exceptions only in non-interruptible code allowing to raise asynchronous exceptions in blocking operations;</li>
<li><a href="https://hackage.haskell.org/package/base-4.14.1.0/docs/GHC-IO.html#v:uninterruptibleMask">uninterruptibleMask</a> masks asynchronous exceptions, but it can introduce deadlocks;</li>
<li><code>takeMVar</code> is only blocking if the <code>MVar</code> is empty.</li>
</ul>
<h2 id="base-and-safe-exceptions-unliftio">â€˜baseâ€™ and â€˜safe-exceptionsâ€™ / â€˜unliftioâ€™</h2>
<p>Both <a href="https://hackage.haskell.org/package/safe-exceptions">safe-exceptions</a> and <a href="https://hackage.haskell.org/package/unliftio">unliftio</a> are using <code>bracket</code> implementation which is masking using <code>uninterruptibleMask</code>, while <a href="https://hackage.haskell.org/package/base">base</a> package is using <code>mask</code>. Which one is more appropriate in a library?</p>
<p>This is <a href="https://hackage.haskell.org/package/base-4.14.1.0/docs/Control-Exception-Base.html#v:bracket">base</a>â€™s implementation of <code><a href="https://hackage.haskell.org/package/base-4.14.1.0/docs/Control-Exception-Base.html#v:bracket">bracket</a></code>:</p>
<div id="cb6"><pre><code><span id="cb6-1"><span>bracket ::</span> <span>IO</span> a</span>
<span id="cb6-2">        <span>-&gt;</span> (a <span>-&gt;</span> <span>IO</span> b)</span>
<span id="cb6-3">        <span>-&gt;</span> (a <span>-&gt;</span> <span>IO</span> c)</span>
<span id="cb6-4">        <span>-&gt;</span> <span>IO</span> c</span>
<span id="cb6-5">bracket before after thing <span>=</span></span>
<span id="cb6-6">  mask <span>$</span> \restore <span>-&gt;</span> <span>do</span></span>
<span id="cb6-7">    a <span>&lt;-</span> before</span>
<span id="cb6-8">    r <span>&lt;-</span> restore (thing a) <span>`onException`</span> after a</span>
<span id="cb6-9">    _ <span>&lt;-</span> after a</span>
<span id="cb6-10">    <span>return</span> r</span></code></pre></div>
<p>The version used by <a href="https://hackage.haskell.org/package/unliftio-0.2.13.1/docs/UnliftIO-Exception.html#v:bracket">unliftio</a> and <a href="https://hackage.haskell.org/package/safe-exceptions-0.1.7.1/docs/Control-Exception-Safe.html#v:bracket">safe-exceptions</a> are both implemented using <code>try</code> but the crucial difference is that they are using <code>uninterruptibleMask</code> when executing the <code>after</code> callback. Since they are using <code>uninterruptibleMask</code> they need to use <code>try</code> to avoid blocking exceptions when executing the <code>before</code> handler. This is to minimize time when a thread is in <code>MaskedUninterruptible</code> state.</p>
<p>Let us look at the most common resource handlers:</p>
<h4 id="file-handles">File Handles</h4>
<p>The <a href="https://hackage.haskell.org/package/base-4.14.1.0/docs/GHC-IO-Handle.html#t:Handle">base</a> package does not export <code>Handle</code> constructors, they are an implementation detail, so letâ€™s bring the definition here:</p>
<div id="cb7"><pre><code><span id="cb7-1"><span>data</span> <span>Handle</span></span>
<span id="cb7-2">  <span>=</span> <span>FileHandle</span>           <span>-- A normal handle to a file</span></span>
<span id="cb7-3">        <span>FilePath</span>         <span>-- the file (used for error messages</span></span>
<span id="cb7-4">                         <span>-- only)</span></span>
<span id="cb7-5">        <span>!</span>(<span>MVar</span> <span>Handle__</span>)</span>
<span id="cb7-6"></span>
<span id="cb7-7">  <span>|</span> <span>DuplexHandle</span>         <span>-- A handle to a read/write stream</span></span>
<span id="cb7-8">        <span>FilePath</span>         <span>-- file for a FIFO, otherwise some</span></span>
<span id="cb7-9">                         <span>--   descriptive string (used for error</span></span>
<span id="cb7-10">                         <span>--   messages only)</span></span>
<span id="cb7-11">        <span>!</span>(<span>MVar</span> <span>Handle__</span>) <span>-- The read side</span></span>
<span id="cb7-12">        <span>!</span>(<span>MVar</span> <span>Handle__</span>)</span></code></pre></div>
The <code><a href="https://hackage.haskell.org/package/base/docs/GHC-IO-Handle.html#v:hClose">hClose</a> :: Handle -&gt; IO ()</code> calls <code><a href="https://hackage.haskell.org/package/base/docs/src/GHC.IO.Handle.html#hClose%27">hCloseâ€™</a></code> which masks exceptions while calling <code>takeMVar</code> (in <code><a href="https://hackage.haskell.org/package/base/docs/src/GHC.IO.Handle.Internals.html#withHandle%27">withHandleâ€™</a></code>), and continues (while exceptions are masked) with <code><a href="https://hackage.haskell.org/package/base/docs/src/GHC.IO.Handle.Internals.html#hClose_help">hClose_help</a></code>, which does a few interesting things:
<ul>
<li>
flush a buffer,
</li>
<li>
close a decoder,
</li>
<li>
call <code><a href="https://hackage.haskell.org/package/base/docs/GHC-IO-Device.html#v:close">GHC.IO.Device.close</a></code> to close the file descriptor.
</li>
</ul>
<p>Flushing file handle buffer is done by either safe (non-threaded rts) or unsafe (threaded rts) ffi call (using <code><a href="https://hackage.haskell.org/package/base/docs/src/System.Posix.Internals.html#c_write">c_write</a></code> or <code><a href="https://hackage.haskell.org/package/base/docs/src/System.Posix.Internals.html#c_safe_write">c_safe_write</a></code>), and thus is uninterruptible. Closing the decoder is either a no-op (<code>return ()</code>) or an unsafe foreign call to <code>iconv_close</code>. We are left with analysing <code><a href="https://hackage.haskell.org/package/base/docs/GHC-IO-Device.html#v:close">GHC.IO.Device.close</a></code>. <code>Handle__</code> is using <code>IODevice</code> <code>FD</code> instance. On systems that support either <code>epoll</code>, <code>poll</code> or <code>kqueue</code> (e.g.&nbsp;on <code>Linux</code>, <code>MacOS</code>, <code>FreeBSD</code>, and alikes) it is done via event manager. On other operating systems (<code>Windows</code>) closing file handle is done by a direct foreign call (this might change in the future with the new <code>mio</code> Windows event manager based on I/O completion ports). When event manager is involved, the <code><a href="https://hackage.haskell.org/package/base/docs/GHC-Conc-IO.html#v:closeFdWith">closeFdWith</a></code> is used. I recently fixed a bug which made it interruptible, see <a href="https://gitlab.haskell.org/ghc/ghc/-/merge_requests/4942">PR #4942</a>. However, because calls which involve <code>epoll</code> are very fast all the blocking operations done by <code>closeFdWith</code> would block for a very short time, making it quite unlikely to be an issue â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://coot.me/posts/mask.html">https://coot.me/posts/mask.html</a></em></p>]]>
            </description>
            <link>https://coot.me/posts/mask.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26177194</guid>
            <pubDate>Thu, 18 Feb 2021 07:56:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reflections on Using Haskell for My Startup]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 16 (<a href="https://news.ycombinator.com/item?id=26176940">thread link</a>) | @_query
<br/>
February 17, 2021 | https://alistairb.dev/reflections-on-haskell-for-startup/ | <a href="https://web.archive.org/web/*/https://alistairb.dev/reflections-on-haskell-for-startup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Almost exactly one year ago I quit my job to create a Haskell startup as a solo developer. I had about 20 ideas, but eventually settled on the idea of dependency project health tracking with <a href="https://deadpendency.com/" target="_blank" rel="noopener">Deadpendency</a>.</p>

<p>This post describes the experience and evaluates Haskell and its ecosystem.</p>

<p><small>Disclaimer: This blog post contains a bunch of memes. They are trying to be humorous, not accurate or fair ğŸ˜‰.</small></p>

<h2 id="why-haskell">Why Haskell?</h2>

<p>Since about 2016 I have had a strong <del>obsession</del> love of Haskell. Prior to learning Haskell, I was an experienced OO style developer but I didnâ€™t really know how to keep improving my raw programming ability. Haskell introduced me to the world of functional programming (FP) which has an almost infinite depth of concepts to learn, which do actually help improve code quality and application architecture.</p>

<p><img width="400" src="https://i.imgflip.com/4x9eeq.jpg" alt="I should learn functional programming meme"></p>

<p>Haskell is challenging to learn, but extremely fun to write. For my own learning and pleasure, if my startup succeeds, I want to be doing Haskell.</p>

<p>Additionally, I think Haskell is the best general purpose programming language (that you can use in production). In particular, Haskell excels at writing â€˜boringâ€™ business applications which is typically what I work on. <a href="https://www.foxhound.systems/blog/why-haskell-for-production/" target="_blank" rel="noopener">â€˜Why Haskell For Productionâ€™</a> goes into more detail on the benefits Haskell offers.</p>

<p><img width="400" src="https://i.imgflip.com/4x9fwz.jpg" alt="Haskell is the best change my mind meme"></p>

<h2 id="the-setup-phase">The Setup Phase</h2>

<p>Probably the most challenging part was building out a skeleton architecture to hang my business logic on. I decided to go with, even within Haskell, fairly advanced libraries of <a href="https://docs.servant.dev/en/stable/" target="_blank" rel="noopener"><code>servant</code></a> and <a href="https://hackage.haskell.org/package/fused-effects" target="_blank" rel="noopener"><code>fused-effects</code></a>.</p>

<p>I spent a fair amount of time banging my head against a wall trying to get these libraries to work nicely together. This was primarily from a lack of Haskell ability on my part. I had prepared as best I could, but Haskell is deep and I needed to learn more to work day to day with it. I was lucky enough to eventually find <a href="https://github.com/mitchellwrosen/hspolls" target="_blank" rel="noopener">an example</a> that marries these two libraries together, which was a life saver. Iâ€™m sure I would have gotten there eventually, but I was in a bit over my head at that point.</p>

<p><img width="400" src="https://i.imgflip.com/4x9j14.jpg" alt="Haskell with servant fused-effects is hard meme"></p>

<p>Haskell is awesome, but like most languages there is cruft and legacy to be avoided. Haskell has a standard library known as <a href="https://hackage.haskell.org/package/base" target="_blank" rel="noopener"><code>base</code></a> which unfortunately has a fair amount of unsafe or unperformant functions included. As such I went with an alternative standard library <a href="https://hackage.haskell.org/package/relude" target="_blank" rel="noopener"><code>relude</code></a> that builds on and improves <code>base</code>. On top of this, there are many core libraries that are not part of the standard library I wanted to use and have nice patterns around.</p>

<p>Additionally, I was <a href="https://alistairb.dev/haskell-on-google-cloud-is-great">deploying to google cloud</a> and so needed to figure out good patterns for that integration from Haskell.</p>

<p>This setup effort was quite challenging. I spent most of it squinting at compiler errors. Yet it only took about 2 weeks to have a good foundation of code to start building my business logic upon.</p>

<h2 id="building-it-out">Building it Out</h2>

<p>This is when it started to get really fun. I had my core patterns set out and I could focus on building a pipeline. The day in day out of writing out my logic as small pure functions that I composed together was very nice.</p>

<p>Haskell has such impressive auto-magic code generation techniques that you spend much more time focused on the interesting logic of your application rather than boilerplate.</p>

<div><div><pre><code><span>data</span> <span>HappinessLevel</span> <span>=</span>
    <span>Miserable</span>
  <span>|</span> <span>Sad</span>
  <span>|</span> <span>Average</span>
  <span>|</span> <span>Happy</span>
  <span>|</span> <span>HaskellDeveloper</span>
  <span>deriving</span> <span>(</span><span>Show</span><span>,</span> <span>Eq</span><span>,</span> <span>Ord</span><span>,</span> <span>Bounded</span><span>,</span> <span>Enum</span><span>,</span> <span>ToJSON</span><span>,</span> <span>FromJSON</span><span>)</span> <span>-- magic code generation</span>

<span>-- ok not really magic, think 'convention over configuration'</span>
<span>-- where you can have generated sane defaults, or customise if you like</span>
</code></pre></div></div>

<p>And personally I think Haskell is quite beautiful to read and write. #notbiased</p>

<h3 id="parsing-libraries">Parsing Libraries</h3>

<p>A lot of the logic of Deadpendency is parsing. Either parsing dependency files or parsing various API responses. Haskell has many excellent parsing libraries, most notably <a href="https://hackage.haskell.org/package/aeson" target="_blank" rel="noopener"><code>aeson</code></a> for JSON.</p>

<p>Why is this nice in Haskell? The â€˜monadâ€™ abstraction is excellent for dealing with code with a lot of failure conditions (ie. parsing) and avoids â€˜pyramid of doomâ€™ type code. Haskell worked out really well in this key area.</p>

<p><img width="400" src="https://alistairb.dev/images/hadouken.jpeg" alt="Pyramid of doom meme"></p>

<h3 id="testing">Testing</h3>

<p>Another strong positive for writing Deadpendency was testing. Haskell has a lesser-known style of testing libraries that do â€˜property based testingâ€™ (PBT).</p>

<p>PBT allows you to write value generators for your data types, which you use to generate 100s or 1000s of test cases. Then, you run these generated values against some function and check that certain properties hold.</p>

<p>For example, part of the Deadpendency logic is generating an HTML report at the end. I had some <code>toHtml :: Report -&gt; HTML</code> function that I wanted to test. So I wrote a <code>fromHtml :: HTML -&gt; Report</code> function where it goes the other way (ok writing that was pretty painful). Then my PBT test will generate 100s of <code>Report</code> values and check that <code>report == fromHtml (toHtml report)</code> (this is known as â€˜roundtrip testingâ€™). With this single test I was able to find many edge case bugs with my HTML report generation logic.</p>

<p><img width="400" src="https://i.imgflip.com/4x9tqj.jpg" alt="Haskell with servant fused-effects is hard meme"></p>

<p>PBT exists in some other languages, but it originated (I believe?) in Haskell so the libraries are excellent.</p>

<h3 id="not-actively-maintained-libraries">Not Actively Maintained Libraries</h3>

<p>A big challenge of working with Haskell was the lack of well-maintained libraries. Ironically, of the 75 (!) packages I depend upon 19 are flagged by Deadpendency as unhealthy (deprecated or inactive). This means I often donâ€™t have the luxury of asking library maintainers to fix bugs. Even if I PR a fix, sometimes that PR will be ignored for months.</p>

<p>This I think is the reality of using a niche language like Haskell. To be clear, I do not think library developers owe me anything, but it is nonetheless a downside when compared to more popular languages.</p>

<p><img width="400" src="https://i.imgflip.com/4x9xjq.jpg" alt="Haskell not actively maintained meme"></p>

<p>Thankfully Haskell build tools have good support for loading a package from git. This means you can PR some bug fix or feature and immediately use your fork to work around the problem.</p>

<h3 id="compile-times-were-fine">Compile Times.. Were Fine</h3>

<p>I thought Iâ€™d call this out as it is a common complaint I see around Haskell. I followed some <a href="https://www.parsonsmatt.org/2019/11/27/keeping_compilation_fast.html" target="_blank" rel="noopener">good advice</a> which kept compilation fast (aside from <a href="https://twitter.com/AlistairBuzz/status/1253507016242294784" target="_blank" rel="noopener">one interesting edge case I resolved</a>).</p>

<ul>
  <li>Number of modules (Haskell source files) - 509</li>
  <li>Number of lines of Haskell - 20090</li>
  <li>Number of dependencies - 75</li>
  <li>Dell 9570 XPS Laptop - (Hex core - 8th-gen Intel Core i7-8750H CPU), 32GB memory</li>
</ul>

<p>So what are the numbers?</p>

<h4 id="compile-dependencies-from-scratch">Compile dependencies from scratch</h4>

<p>Time: 17m44s</p>

<p>This is compiling all application dependencies, which needs to be done before you can compile your application code. Rebuilding all from scratch rarely happens as both my dev machines and CI will cache and only rebuild what has changed.</p>

<p>You do sometimes update a very core package which triggers a lot of dependent packages to recompile which can take a while. Although, I usually do dependency updates at the start of the day while Iâ€™m sipping my coffee, so usually donâ€™t notice.</p>

<h4 id="compile-app-including-tests-in-development">Compile app (including tests) in development</h4>

<p>Time: 1m1s</p>

<p>Likewise, due to caching a full recompilation rarely happens. As such, most code edits do not trigger many modules to be recompiled and it is fast.</p>

<p>Additionally, Haskell has nice â€˜continuous compilationâ€™ tools that fire on save. Usually by the time I actually look at my terminal compilation is already done.</p>

<h4 id="compile-app-for-deployment">Compile app for deployment</h4>

<p>with <a href="https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/using-optimisation.html" target="_blank" rel="noopener">full optimisations</a> (-02).</p>

<p>Time: 2m53s</p>

<p>This typically runs in CI. It runs in parallel with a host of other checks such as running my tests, which also take a few minutes. Due to this, the time doesnâ€™t really impact the build + deploy time too much.</p>

<p><img width="400" src="https://i.imgflip.com/4xp4zu.jpg" alt="Compile times meme"></p>

<h3 id="refactoring-pain">Refactoring Pain</h3>

<p>Deadpendency is relatively simple in what it does, but there is a lot of hidden complexity to the problem. Which is to say, it is like 99% of applications ğŸ˜‰. When developing it I was constantly realising I had modelled things a bit too simplistically and would need to refactor.</p>

<p>Haskell is very safe to refactor thanks to the type safety the compiler brings, which is probably the most important thing. However, Haskell does not have great tools to help with refactoring, at least in terms of the restructuring changes I kept making. The <a href="https://hackage.haskell.org/package/apply-refact" target="_blank" rel="noopener">existing</a> <a href="https://hackage.haskell.org/package/retrie" target="_blank" rel="noopener">tools</a> seem more geared towards complex rewriting of common code, not restructuring modules or renaming identifiers.</p>

<p>As such I did it all manually with text search replace, or just change something and fix all the new compiler errors. This was a bit of a grind and it caused me to delay needed refactoring sometimes.</p>

<p>Itâ€™s a pity Haskell doesnâ€™t have the refactoring tools to help in this situation. The dream would be these tools integrated into an IDE.</p>

<p><img width="400" src="https://i.redd.it/dbdshzzflgd31.jpg" alt="Haskell had an IDE meme"></p>

<p>(Stolen from <a href="https://www.reddit.com/r/ProgrammerHumor/comments/cjtbfj/society_if_haskell_has_ide/" target="_blank" rel="noopener">reddit</a>)</p>

<p>Having said that, it should be noted that Haskell does have an excellent IDE now in the form of <a href="https://github.com/haskell/haskell-language-server" target="_blank" rel="noopener">Haskell Language Server</a> (HLS). The momentum around the project is insane and I applaud the developers. One fixed pain point from HLS is it does auto imports now, which used to greatly contribute to the friction of working with Haskell. Iâ€™m sure Haskell will get there eventually.</p>

<h3 id="waiting-for-new-ghc-versions-to-be-usable">Waiting for New GHC Versions to be Usable</h3>

<p>This is mostly me complaining for the sake of it, but as someone pretty obsessed with both new shiny versions of things and Haskell, waiting for new GHC (GHC is the Haskell compiler) versions to be usable has been painful. There is a long tail of libraries and platforms that need to be updated before I can use a new GHC version. Sometimes these updates can drag a lot.</p>

<p>For example GHC 9 was just released, but I still havenâ€™t been able to upgrade to GHC 8.10 yet which was first released in March 2020.</p>

<p><img width="500" src="https://i.imgflip.com/4xebid.jpg" alt="GHC releases meme"></p>

<h2 id="launching">Launching</h2>

<p>So after about 8 months of work I was ready to start getting users. I slowly soft launched, promoting it in a few small channels. How did my Haskell fair in prod?</p>

<h3 id="very-few-logic-bugs">Very Few Logic Bugs</h3>

<p>My core Haskell had very few logic bugs. This is because Haskell is very safe by default and I had opted into strict types that help catch edge cases.</p>

<p>For example, I was using a lot of <a href="https://hackage.haskell.org/package/base-4.14.1.0/docs/Data-List-NonEmpty.html" target="_blank" rel="noopener"><code>NonEmpty</code></a> lists which the compiler will guarantee is not empty. To use them you must specify how to handle the empty case. ie. what do I do if Deadpendency canâ€™t find any dependencies to check?</p>

<p>And of course, I had â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://alistairb.dev/reflections-on-haskell-for-startup/">https://alistairb.dev/reflections-on-haskell-for-startup/</a></em></p>]]>
            </description>
            <link>https://alistairb.dev/reflections-on-haskell-for-startup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26176940</guid>
            <pubDate>Thu, 18 Feb 2021 07:17:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Americentrism]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26176606">thread link</a>) | @jlelse
<br/>
February 17, 2021 | https://jlelse.blog/thoughts/2021/02/americentrism | <a href="https://web.archive.org/web/*/https://jlelse.blog/thoughts/2021/02/americentrism">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Wikipedia has an article on a phenomenon I often observe on the Internet, such as on Hacker News: <a href="https://en.wikipedia.org/wiki/List_of_countries_in_the_Americas_by_population" target="_blank" rel="noopener">Americentrism</a>.</p><blockquote><p><strong>Americentrism</strong>, also known as <em>American-centrism</em> or <em>US-centrism</em>, is a tendency to assume the culture of the United States is more important than those of other countries or to judge foreign cultures based on American cultural standards. It refers to the practice of viewing the world from an overly US-focused perspective, with an implied belief, either consciously or subconsciously, in the preeminence of American culture.</p></blockquote><p>But even that word in itself, I think (as an European), contains U.S. bias: America is equated with the USA, but there are <a href="https://en.wikipedia.org/wiki/List_of_countries_in_the_Americas_by_population" target="_blank" rel="noopener">so many more countries in America</a>.</p><p>Is it just me who thinks like that?</p></div></div>]]>
            </description>
            <link>https://jlelse.blog/thoughts/2021/02/americentrism</link>
            <guid isPermaLink="false">hacker-news-small-sites-26176606</guid>
            <pubDate>Thu, 18 Feb 2021 06:22:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advanced Git Features You Didnâ€™t Know You Needed]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26176469">thread link</a>) | @zdw
<br/>
February 17, 2021 | https://martinheinz.dev/blog/43 | <a href="https://web.archive.org/web/*/https://martinheinz.dev/blog/43">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://martinheinz.dev/blog/43</link>
            <guid isPermaLink="false">hacker-news-small-sites-26176469</guid>
            <pubDate>Thu, 18 Feb 2021 05:58:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TLS certificates specifying hosts via the CommonName field is more or less gone]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 21 (<a href="https://news.ycombinator.com/item?id=26176448">thread link</a>) | @zdw
<br/>
February 17, 2021 | https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificateCNMostlyGone | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificateCNMostlyGone">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>TLS certificates specifying hosts via their CommonName field is more or less gone</h2>

	<p><small>February 17, 2021</small></p>
</div><div><p><a href="https://en.wikipedia.org/wiki/Transport_Layer_Security">TLS</a>
certificates for hosts and domains must somehow identify what
hostname (or names) they're for. Historically <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificatesNamingHosts">there have been two
ways to do this</a>. The first way was a
specific sub-field, the <em>CN</em> or CommonName, of the certificate's
overall <em>Subject Name</em>. This had the problem that it could only
have one name. When people started wanting to have TLS certificates
that covered more than one name, they invented another mechanism,
the <em>Subject Alternative Name</em> (SAN) extension.</p>

<p>As a practical matter, all vaguely modern software that wants to
properly validate TLS certificates has supported (and often preferred)
Subject Alternative Names for some time. A great many TLS certificates
in the wild are for multiple hosts and it's generally unlikely that the
host you're connecting to is the one name that the system chose to put
in the CN field; software that only supports CN cannot validate those
TLS certificates. As a matter of timing, SANs have been theoretically
mandatory since 2002 and checking only SANs has been theoretically
required since 2011 (which means that since 2011 or earlier, the CN was
supposed to always be one of the SANs).</p>

<p>These days, any remaining support for looking at TLS certificate
CommonName to validate TLS certificates is getting more and more
extinct (and more so than I expected when I started writing this
entry). In the browser realm, <a href="https://www.chromestatus.com/feature/4981025180483584">Chrome apparently turned it off in
58, released in 2017</a>, and then
threw out the option to check it again in Chrome 65 (from the comment
on <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificatesNamingHosts">my old entry</a>, which was ironically
written shortly before Chrome did this). Firefox is said to have
removed support in version 48, from August of 2016. <a href="https://support.apple.com/en-ca/HT210176">Safari
apparently stopped looking at CommonName in iOS 13 and macOS 10.15</a>, which I believe date
from late 2019. <a href="https://go-review.googlesource.com/c/go/+/231379">This Go change</a> also talks about
how browsers removed it in 2019 ('last year' for a mid 2020 change).</p>

<p>In non-browser TLS code, Go started ignoring CN by default in
Go 1.15 (released in August of 2020) and this will be the only
option starting in Go 1.17 (to be released in August of 2021),
per <a href="https://golang.org/doc/go1.16#crypto/x509">here</a>. Since
Firefox doesn't support CN any more, I assume that <a href="https://en.wikipedia.org/wiki/Network_Security_Services">NSS</a> doesn't
either, since NSS is basically Firefox's underlying TLS implementation.
I have no idea what other TLS libraries are doing, but I would expect
that many of them will support CommonName for some time to come; TLS
libraries are historically behind browser practices.  Hopefully they
are all following the 2011 requirement to check only SANs when SANs are
present (which they should always be in public certificates).</p>

<p>Probably TLS certificates will continue to contain CommonName fields
for a long time to come. Having a <em>Subject Name</em> in general is
common (although apparently not actually required) and the CN is a
standard (although not required) part of the Subject Name, so you
might as well throw it in. Even Mozilla and Let's Encrypt (still)
have TLS certificates with CNs. However, since I checked this now,
the current <a href="https://cabforum.org/">CA/Browser Forum</a> <a href="https://cabforum.org/baseline-requirements-documents/">baseline
requirements</a>
(version 1.7.3) allow but don't require CommonName (section 7.1.4.2.2,
which says that it's 'discouraged, but not prohibited'). Given how
conservative most Certificate Authorities are, I expect them to be
issuing TLS certificates with CommonName fields until they're
required to stop.</p>

<p>(An interested party could scan Certificate Transparency logs to see if
there were very many issued certificates without CNs. Probably there are
some; someone must have tried it out at some point through an official
CA.)</p>

<p>PS: <a href="https://no-common-name.badssl.com/">no-common-name.badssl.com</a>
has a TLS certificate without a CN, or at least it's supposed to
(<a href="https://community.letsencrypt.org/t/how-to-obtain-a-cert-without-a-common-name/72807/6">via</a>),
but the TLS certificate is expired right now as I write this entry
so it's hard to test how client software behaves. <a href="https://community.letsencrypt.org/t/compatibility-testing-of-no-common-name/72863">See also</a>,
which pointed me to <a href="https://no-subject.labs.vu.nl/">no-subject.labs.vu.nl</a>,
which has a currently valid TLS certificate with no <em>Subject Name</em> at all.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificateCNMostlyGone</link>
            <guid isPermaLink="false">hacker-news-small-sites-26176448</guid>
            <pubDate>Thu, 18 Feb 2021 05:54:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building Consentful Tech Zine [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26176065">thread link</a>) | @conanxin
<br/>
February 17, 2021 | http://www.consentfultech.io/wp-content/uploads/2019/10/Building-Consentful-Tech.pdf | <a href="https://web.archive.org/web/*/http://www.consentfultech.io/wp-content/uploads/2019/10/Building-Consentful-Tech.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.consentfultech.io/wp-content/uploads/2019/10/Building-Consentful-Tech.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-26176065</guid>
            <pubDate>Thu, 18 Feb 2021 05:03:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The questionable use of AI for job applications]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26175871">thread link</a>) | @shirappu
<br/>
February 17, 2021 | https://web.br.de/interaktiv/ki-bewerbung/en/ | <a href="https://web.archive.org/web/*/https://web.br.de/interaktiv/ki-bewerbung/en/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://web.br.de/interaktiv/ki-bewerbung/en/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26175871</guid>
            <pubDate>Thu, 18 Feb 2021 04:38:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Extract Tables by Docsumo]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26175273">thread link</a>) | @amitness
<br/>
February 17, 2021 | https://docsumo.com/free-tools/extract-tables-from-pdf-images | <a href="https://web.archive.org/web/*/https://docsumo.com/free-tools/extract-tables-from-pdf-images">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-tool"><div><div><p>Automated table extraction from pdf &amp; images</p><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>It doesn't support in mobile view. <br>You can copy the link and view it in your desktop.</p></div><div id="rating-section"><div id="rating-block"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div></div></div></div></div><div><p>How it works?</p><div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5faa7831743ca77a6aa3ee11_Choose%20File.png" loading="lazy" width="93" alt=""></p><div><p>1. Choose File</p><p>Select or drop the files you want to convert.<br></p></div></div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5faa628aeb96926ffa789a4f_edit%20%20and%20review.png" loading="lazy" width="101" alt=""></p><div><p>2. Edit &amp; Review</p><p>Review the extracted information in the review panel and make changes if needed.</p></div></div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5faa629ae8714b4bf57f0719_Convert%20%26%20Download.png" loading="lazy" width="101" alt=""></p><div><p>3. Convert &amp; Download</p><p>Download the converted file. Right after that, the input file is removed from our server.</p></div></div></div></div><div><p>Extract tables from PDF/Images</p><p>Save your crucial time and prevent any error from occurring with Docsumo's free table extraction from a PDF/Image tool. With this tool, extract tables from PDF documents and images in real-time with 100% accuracy.</p></div><div><p>Questions we often hear</p><p>Let's look at the answers</p><div><div role="list"><div role="listitem"><div><div><div><h4>Why do I need to extract tables from a PDF document?</h4></div><p>Tables are cleaner data format, and often you need only the data from tables embedded in a pdf document. That's why, businesses find it useful to extract tables from pdf documents and process the data.</p></div></div></div><div role="listitem"><div><div><div><h4>Do I need to train this free table extractor from pdf tool?</h4></div><p>The efficiency of Artificial Intelligence and Machine Learning technology improves with number of sample documents processed. So, it is highly recommended to have at least couple of sample documents ready for training.</p></div></div></div><div role="listitem"><div><div><div><h4>What fields does it capture?</h4></div><p>The tool lets you capture any text based field. The tool allows you to review the extracted data before downloading the output.</p></div></div></div><div role="listitem"><div><div><div><h4>Can I convert my document without installing the software?</h4></div><p>Documo's free online OCR tool is capable of processing any document online with complete accuracy. So, there is no need to install the tool on your system.</p></div></div></div><div role="listitem"><div><div><div><h4>Is my data secure with Docsumo?</h4></div><p>Docsumo doesn't sell or share your data to any third-party person or organization. Your data is completely secure and confidential.</p></div></div></div><div role="listitem"><div><div><div><h4>Is there any limit on using the tool?</h4></div><p>There's no usage limit on our free tool. No payment required and no credit card details needed. Sign up with us to get access to more of our resources.</p></div></div></div></div></div></div><div><h2>What Our Customers Are Saying</h2><div><div data-animation="slide" data-nav-spacing="4" data-duration="500" data-infinite="1"><div><div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5f61bd1ba58812799fe2bd13_paysense.svg" loading="lazy" height="" alt=""></p><p>â€œWe are using Docsumoâ€™s APIs for automating data capture from bank statements and identity cards while on-boarding customers. It has reduced the time our operations team spends on data entry by manifolds while providing a much better customer experience.â€</p><p>Prashanth Ranganathan</p><p>CEO, Paysense.com</p></div></div><div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5f61bd1b531b085edc6c1cbf_Onez.jpeg" loading="lazy" height="" width="25" alt=""></p><p>Since the very beginning everything was fine, they always say â€œAsk anything even if you need support from our developers. The support for initial user was exceptional, even for small users like me.</p><div><p>Dario G</p><p>Operations Manager, Onerz</p></div></div></div><div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5f61bd1bf817cf304f90e758_dhanwise.svg" loading="lazy" height="" alt=""></p><p>"With Docsumo we were able to automate invoice processing completely. It has reduced invoice processing time from hours to minutes. Since there is no data entry required, our data extraction accuracy has improved. We highly recommend Docsumo to everyone. "</p><p>Subodh Malgonde</p><p>CEO, DhanWise.com</p></div></div></div></div></div><a href="https://docsumo.com/case-studies"><p>View more Customers Stories</p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5f62f7ab382b1fa34db4108a_arrow.svg" loading="lazy" height="" alt=""></a></div><div id="free-trial-form"><div><div><div><h2>Start your free trial</h2><p>Weâ€™d love to show you how you can increase your productivity, process your documents faster and save operations cost!</p></div></div><div><div><div id="formId"><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://docsumo.com/free-tools/extract-tables-from-pdf-images</link>
            <guid isPermaLink="false">hacker-news-small-sites-26175273</guid>
            <pubDate>Thu, 18 Feb 2021 03:29:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[40 Year History of Opposition to Nuclear Power in California]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 39 (<a href="https://news.ycombinator.com/item?id=26175253">thread link</a>) | @Lammy
<br/>
February 17, 2021 | https://www.energy-net.org/01NUKE/CALIF.HTM | <a href="https://web.archive.org/web/*/https://www.energy-net.org/01NUKE/CALIF.HTM">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="49%"> 
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2" color="#CC6600"><b><span size="3" color="#000000">40 
		Year History of Opposition to Nuclear Power in California </span></b></span> 
		<br>
	  </p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">California 
		citizens have made a unique stand concerning the attempts by Nuclear proponents 
		to make the state a premiere model for commercial nuclear energy. California's major 
		utilities, in particular Pacific Gas and Electric (PG&amp;E) has spent an
		enormous amount of money and political muscle in attempts to build reactors 
		across California but have mostly failed. PG&amp;E was supposedly involved in 
		the Atoms for Peace proposal made in 1953 and was 
		part of a coalition of american utilities that investigated the technical 
		potentials for building nuclear reactors as a source of electricity.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The following 
		is a brief summary of the battles against nuclear power that started here 
		in California in 1958.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Northern 
		California is the home of the first successful opposition to the promotion 
		and development of commercial nuclear reactors in the U.S. In the 1950's 
		northern and central California's privately Owned utility company, PG&amp;E 
		was planning to be one of the giants in the new field of nuclear energy. 
		It had helped design and build the Dresden I reactor in Illinois with 
		a consortium of 5 major companies, including General Electric(GE).</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">In conjunction 
		with GE, it built the vallecitos nuclear complex south of San Francisco 
		and then went it alone with their Humboldt reactor near Arcata. But their 
		luck took a turn for the worse when they tried to build the world's largest 
		nuclear facility 1000 feet from the fault that caused the 1906 earthquake.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Yes, PG&amp;E 
		even said they could build a reactor in downtown San Francisco! In 
		fact they were planning the construction of 63 reactors in California 
		during the early 1960's, one every 25 miles along the coast They even 
		 planned to build a floating reactor!!</span></p>
	  <h2><span face="Verdana, Arial, Helvetica, sans-serif" size="2"><b>The 
		Bodega Bay Duck Pond</b><br>
		</span></h2>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">When PG&amp;E 
		started pushing plans to build the reactors at Bodega Pay in 1958 a literal 
		groundswell of opposition erupted during the next 6 years to stop them 
		dead cold. The site they had chosen near the San Andreas Fault Zone was 
		just a few miles from the epicenter of the Great San Francisco Quake where 
		ground shifts of over 20 feet had occurred in 1906.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">PG&amp;E's 
		unethical plans to build the reactor is not new for this company, as they 
		have a history of unfair tactics that goes back to the company's birth. 
		Upon deciding that the Bodega Headlands would be an excellent site for the largest nuclear 
		facility in the world, PG&amp;E simply beat the state out in its plans 
		to make the area a state park. </span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The battle 
		started in 1958 when the Santa Rosa Press Democrat published the first 
		story on PG&amp;E's plans. The company's ignored their own geologist, who had warned 
		that the area was likely to be effected by strong shaking during a quake. 
		Concerned citizens started getting involved as PG&amp;E refused to acknowledge 
		publicly that they were actually going to build nuclear reactors at the 
		proposed site.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The 1957 
		windscale accident in England, where a small reactor had burned out of 
		control for more than a day, helped focus concerns about safety on this 
		new idea of nuclear power.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">In 1961, 
		after nearly 3 years of pushing their plan behind the scenes, PG&amp;E 
		announced plans to build the Atomic Park at the Bodega site. The ensuing battle 
		and PG&amp;E's nasty style started to backfire though as public concerns 
		grew.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Major opposition 
		came from within the ranks of the Sierra Club, but the board refused to 
		allow its active members the right to oppose the reactors on the issue 
		of earthquakes. When it came out that PG&amp;E had doctored fault maps 
		of the site, all hell broke loose.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">One of PG&amp;E's 
		major claims at the time was that they could build reactors that would 
		survive a great Earthguake. At one point they said that the reactors could 
		survive a quake 50 per cent bigger than the O6' quake by floating the 
		reactors on 3 feet of compressable material but when the public and the 
		Atomic Energy Commission (AEC) got a close-up view of the devastation 
		from the air of the quake in Alaska during the spring of 1964, support 
		for the reactor complex dried up.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Opponents 
		had "infiltrated" the federal government and were pushing 
		for closure. With the disclosure of the AEC's WASH 740 report, which documented 
		potential dangers to the bay area residents in case of an accident, opposition 
		finally reached all government levels.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">California 
		governor Pat Brown asked that PG&amp;E abandon the reactors. Two days 
		later PG&amp;E caved in and called the project off. The battle ended in 
		1964 with a $7 million duck pond as a living monunent to the future. (It 
		is still there today)</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">This experience 
		gave PG&amp;E a deadly lesson on how to overcome public concerns at their 
		next reactor site--Diablo Canyon.</span></p>
	  <h2><span face="Verdana, Arial, Helvetica, sans-serif" size="2"><b>The 
		Diablo Canyon Nightmare:</b><br>
		</span></h2>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The 25 year 
		battle over Diablo Canyon is a classic case of courage in the face of 
		the political power this utility unleashed in its drive to build a major 
		nuclear facility in California.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">PG&amp;E's 
		plans to build a mega facility shifted south to the less populated coastal 
		area near San Luis Obispo. The company purchased the Nipomo Dunes and 
		told environmental leaders that unless an acceptable site was chosen that 
		they would go ahead and build a facility at the popular beach area. The 
		wife of the Sierra Club president was selected to come up with an acceptable 
		site in secrecy with the company. </span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The site 
		chosen, Diablo Canyon, was California's second to last coastal wilderness 
		area, an area that had been proposed as a National Park due to its beauty. 
		Besides being a sacred Chumash burial ground, it was the home of one of 
		a kind 1,000 year old Oak trees (the largest in the world). It was also 
		the home of one of the state's largest populations of abalone and sea 
		otters.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">In the process 
		of getting permission to go ahead with Diablo, PG&amp;E suceeded in selling 
		the site to key members of the Sierra Club's board of directors. The Utility 
		had sympathetic board members flown over the Diablo site in Frank Sinatra's 
		Lear jet, with entertainment by Danny Kaye (Danny later came out against 
		the reactors).</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The first 
		slam-dunk by PG&amp;E came against the local farmer who had the right 
		of way access rights over the Diablo property. The company went to court 
		and had his rights removed. The beligerant act made the man a life-long 
		opponent of PG&amp;E's plan.</span></p>
	  <h2><span face="Verdana, Arial, Helvetica, sans-serif" size="2"><b>PG&amp;E 
		gets Cozy with Sierra Club Board Members</b><br>
		</span></h2>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The biggest 
		tactical plan was to focus on the Sierra Club. The company and the electric 
		industry already had the board's ear with their claims that nuclear power 
		could reduce air pollution that was caused by coal power plants. The utility, 
		with inside help then sought official support for Diablo Canyon when club's 
		only board member who knew about the site's natural value was in Europe. 
		The board went along with PG&amp;E, and in fact voted to block any Club 
		members or chapters opposition to the facility. This move enraged David 
		Brower, eventually resulting in the split up of the club and the creation 
		of Friends of the Earth by embittered Sierra Club members who were angered 
		by the actions of key Sierra Club Board members.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">PG&amp;E's 
		success within the Sierra Club was the culmination of 2 years of behind 
		the scenes work by Doris Leonard. She was the wife of the president of 
		the club. Her role in exchanging the Nipomo Dunes site for Diablo Canyon 
		was rewarded later when she was elected to PG&amp;E's board of directors. 
		</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The Sierra 
		Club refused to allow its local chapter near Diablo to use the club nane 
		in opposing the five proposed reactors at the site. The group was forced 
		to take on another name in 1966, the Shoreline Preservation Conference.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The group 
		was concerned about earthquake faults along the coast as locals were fully 
		aware of the 1927 quake that completely destroyed a nearby city. They 
		called for a full investigation into potential fault areas. Their efforts 
		were ignored by the government and the media.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">News of the 
		reactor siting was poorly covered by the Bay area's conservative media, 
		a tactic that made the issue invisible to bay area residents who had stopped 
		PG&amp;E's Bodega reactor plans.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Oil companies 
		chart the Hosgri Fault The Hosgri fault had been mapped by Shell oil geologists 
		during the 1960's, but not published until 1970. PG&amp;E claims to have 
		not found out about the fault until late 1972. The information was finally 
		publicized in November 1973 by an investigative reporter in Los Angeles. 
		In a suspicious turn of events, the lawyer who had been fighting the case 
		since 1965 was found dead in his car just after the announcement. Authorities 
		claimed it was suicide, with no other investigation to follow up.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">P&amp;GE's 
		bad memories of Bodega Bay helped fuel their push to ignore earthquake 
		concerns at Diabl Canyon. The same Seismic experts who had been involved 
		with the Bodega Bay facility were brought in to review the site for seismicity. 
		They pointed out major flaws in PG&amp;E's own $2,000 seismic study. A 
		state of the art study at the time would have cost $100,000)</span></p>
	  <h2><span face="Verdana, Arial, Helvetica, sans-serif" size="2"><b>The 
		Hosgri Fault Forces PG&amp;E to Rebuild Diablo Again</b><br>
		</span></h2>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">A storm of 
		controversy erupted around the facility as one of the units was reaching 
		completion. Even with the help of the Nuclear Regulatory Commission's 
		(NRC) predecessor, the AEC, PG&amp;E was finally forced after 3 years 
		of federal in-fighting to rebuild seismic bracing in 1976.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">In attempts 
		to stop a seismic retrofit, PG&amp;E even coined the Tao Effect which 
		said that the bigger the structure, the less damage a quake would have.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Seismic experts 
		for the concerned activists remained uninpressed, â€¦</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.energy-net.org/01NUKE/CALIF.HTM">https://www.energy-net.org/01NUKE/CALIF.HTM</a></em></p>]]>
            </description>
            <link>https://www.energy-net.org/01NUKE/CALIF.HTM</link>
            <guid isPermaLink="false">hacker-news-small-sites-26175253</guid>
            <pubDate>Thu, 18 Feb 2021 03:28:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[LAVO Hydrogen Battery for Home]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26175221">thread link</a>) | @throwaway888abc
<br/>
February 17, 2021 | https://lavo.com.au/lavo-hydrogen-battery/ | <a href="https://web.archive.org/web/*/https://lavo.com.au/lavo-hydrogen-battery/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        <p><label for="active-state--process">Inside the box</label>
            <label for="active-state--connectivity">How it works</label>
        </p>
        <p><span><p>LAVO<sup>â„¢</sup> acts as a solar sponge, integrating with rooftop solar to capture and store renewable energy for use when you need it.</p>
<ul>
<li><strong>Creates Hydrogen</strong> from water</li>
<li><strong>Stores Hydrogen</strong> into LAVOâ„¢â€™s patented metal hydride</li>
<li><strong>Generates Electricity</strong> by converting hydrogen into power</li>
<li><strong>Delivers Power</strong> at a regulated voltage to your home</li>
<li><strong>Monitors &amp; Controls</strong> performance via the LAVOâ„¢ app</li>
</ul>
</span></p><a href="https://lavo.com.au/#specs">
            Tech Specs            <svg width="59" height="10" viewBox="0 0 59 10" fill="none" xmlns="http://www.w3.org/2000/svg">
                <path d="M54 8.5L58 4.75M58 4.75L54 1M58 4.75H1" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
        </a>
        <a href="https://lavo.com.au/pricing">
            Pricing
            <svg width="59" height="10" viewBox="0 0 59 10" fill="none" xmlns="http://www.w3.org/2000/svg">
                <path d="M54 8.5L58 4.75M58 4.75L54 1M58 4.75H1" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
        </a>
    </div></div>]]>
            </description>
            <link>https://lavo.com.au/lavo-hydrogen-battery/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26175221</guid>
            <pubDate>Thu, 18 Feb 2021 03:23:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Turn Hacker News into an RSS Feed]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26175012">thread link</a>) | @MattyRad
<br/>
February 17, 2021 | https://soapstone.mradford.com/hn-rss-guide/ | <a href="https://web.archive.org/web/*/https://soapstone.mradford.com/hn-rss-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <br>
      <section>
        
  <article>
    <header>
      

      <time>
        
        February 03, 2021
      </time>

      
    </header>

    <h2 id="hn-hijacks-your-brain">HN hijacks your brain</h2>
<p>You're an engineer who looks at Hacker News 2-5 times a day. HN is a good way to <em>fill the gaps</em> in time. You scan the front page- repeatedly- for links of interest... reading titles, eyeing scores... often jumping directly to the (overtly contrarian) comments to see if a link is even worth the energy.</p>
<p>Sound familiar?</p>
<p>That cycle hits a sickening <strong>5</strong>/10 of Tristan Harris's <a href="https://medium.com/thrive-global/how-technology-hijacks-peoples-minds-from-a-magician-and-google-s-design-ethicist-56d62ef5edf3">list of mind hijacks</a>:</p>
<ul>
<li>(1)  Control the Menu, Control the Choices</li>
<li>(3)  Fear of missing something important</li>
<li>(4)  Social Approval (upvotes)</li>
<li>(6)  Bottomless bowl</li>
<li>(10) Forecasting</li>
</ul>
<blockquote>
<p>These hijacks  <a href="https://en.wikipedia.org/wiki/Hanlon%27s_razor">aren't</a> intentional, they're just a byproduct of link aggregation platforms.</p>
</blockquote>
<p>Stoics are turning in their graves, where instead of knowing what's important, the links on HN <em>become</em> what's important, no matter how trivial, pedantic, hyped, or irrelevant.</p>
<p>So if you want help breaking this negative feedback loop, I encourage you to reclaim your attention by turning HN into and RSS feed;</p>
<p>Get more <a href="https://medium.com/@bre/the-cult-of-done-manifesto-724ca1c2ff13">done</a>. Ignore the comments and the <a href="https://www.ribbonfarm.com/2020/01/16/the-internet-of-beefs/">mooks</a>. Set limits. It's incredibly liberating to finish your RSS feed and think to yourself, <em>now what</em>?</p>

<p>Declaring what deserves your attention is the defining feature of RSS, so it's important to declare what aspect of HN you like. Generally people look at high scores. Fortunately HN already has a url specifically for its most "important" (i.e. upvoted) links: <a href="https://news.ycombinator.com/best"><code>/best</code></a>.</p>
<p>So if we can subscribe to the links from that page, we'll get the bulk of the links that deserve our attention.</p>
<p>For me, it's critically important for RSS to be a self-hosted solution. No third parties <small>(I'm looking at <em>you</em>, Feedly)</small>.</p>
<p>Otherwise, what's the point of retaking control, you're just shunting control to yet another third party.</p>
<p>My personal setup goes like this:</p>
<ul>
<li>Get the Raspberry Pi you bought but never used</li>
<li>Install Docker</li>
<li>Run FreshRSS</li>
<li>Add HN <a href="https://news.ycombinator.com/best"><code>/best</code></a> as an RSS feed</li>
<li>(Optional) Port forwarding and DNS setup</li>
<li>(Optional) Pick out a smartphone app to sync with</li>
</ul>
<p>This is just the first thing that worked for me, so by no means is it the guaranteed best. Recommendations and alternatives are welcome! You can, of course, tailor the following guide if you'd like to use a VPS.</p>

<h3 id="prepare-the-pi">Prepare the Pi</h3>
<h4 id="install-git">Install git</h4>
<p>Do a standard Raspbian setup the with <a href="https://soapstone.mradford.com/raspberry-pi-automatic-wifi-and-ssh">internet/ssh/hostname</a>. Then install git:</p>
<pre><span>sudo</span><span> apt-get install git
</span></pre><h4 id="install-docker">Install Docker</h4>
<pre><span>curl -sSL</span><span> https://get.docker.com | </span><span>sh
</span></pre><pre><span>sudo</span><span> usermod</span><span> -aG</span><span> docker pi &amp;&amp; </span><span>sudo</span><span> reboot
</span></pre><h4 id="install-docker-compose">Install Docker-compose</h4>
<blockquote>
<p>This method is specifically for Raspbian, if you're using a VPS or non-ARM machine, install docker-compose the <a href="https://docs.docker.com/compose/install/">conventional</a> way.</p>
</blockquote>
<pre><span>sudo</span><span> apt-get install</span><span> -y</span><span> libffi-dev libssl-dev
</span><span>sudo</span><span> apt-get install</span><span> -y</span><span> python3 python3-pip
</span><span>sudo</span><span> apt-get remove python-configparser
</span><span>sudo</span><span> pip3 install docker-compose
</span></pre>
<pre><span>git</span><span> clone https://github.com/FreshRSS/FreshRSS

cd FreshRSS/Docker
</span></pre>
<p>We're using a Raspberry Pi, so you'll need to pick out the ARM image! Use your favorite editor to modify these lines of the <code>docker-compose.yml</code> file:</p>
<pre><span># docker-compose.yml
</span><span>-    image: freshrss/freshrss:latest
</span><span>+    image: freshrss/freshrss:arm
</span></pre>
<p>Now you're ready to execute FreshRSS:</p>
<pre><span>docker-compose</span><span> up</span><span> -d
</span></pre>
<p>Once that's complete, head to your Pi's IP address (or hostname, if you opted for that) on port <code>8080</code> in your laptop's/desktop's browser (something like http://1.2.3.4:8080), and go through the initial setup.</p>

<p>Add <code>https://hnrss.org/best</code> as an RSS feed (from <a href="https://hnrss.github.io/">hnrss.github.io</a>).</p>
<p>Congratulations! You've officially RSS-ified HN!</p>
<h3 id="optional-port-forwarding-and-dns-setup">(Optional) Port forwarding and DNS setup</h3>
<p>Unless you went with the VPS route, you're probably behind a LAN, so if you want to access your RSS outside your LAN, you'll need to set up port forwarding and/or DNS. That's beyond the scope of this guide, but there are many guides online that can get you there.</p>
<h3 id="optional-pick-out-an-app">(Optional) Pick out an app</h3>
<p>You could just expose the pi to the internet, and read RSS directly from the browser, but I think having an app is a nice touch.</p>
<p>First you'll need to enable API access in FreshRSS. Go to <code>Authentication</code> and check the box to allow API access:</p>
<p><img src="https://soapstone.mradford.com/freshrss-auth.png" alt="fresh-rss-screenshot1"></p>
<p>Then create an API key under <code>Profile</code>:</p>
<p><img src="https://soapstone.mradford.com/freshrss-profile.png" alt="fresh-rss-screenshot2"></p>
<p>Now you can use the API url and the API key in your selected app to pull data down locally. Nice!</p>
<p>Here's a non-exhaustive list of open-source (Android) apps to get you started.</p>
<ul>
<li><a href="https://github.com/readrops/Readrops">Readrops</a> - <a href="https://play.google.com/store/apps/details?id=com.readrops.app">play store</a></li>
<li><a href="https://github.com/nextcloud/news-android">New Android</a> - <a href="https://play.google.com/store/apps/details?id=de.luhmer.owncloudnewsreader&amp;pcampaignid=MKT-Other-global-all-co-prtnr-py-PartBadge-Mar2515-1">play store</a></li>
<li><a href="https://github.com/nilsbraden/ttrss-reader-fork">ttrss-reader-fork</a> - <a href="https://play.google.com/store/apps/details?id=org.ttrssreader">play store</a></li>
<li><a href="https://github.com/fistons/TinyTinyFeed">TinyTinyFeed</a> - <a href="https://play.google.com/store/apps/details?id=org.poopeeland.tinytinyfeed">play store</a></li>
</ul>
<blockquote>
<p>Truth be told, a lot of the closed source RSS apps I've checked out tend to be slightly higher in quality, so if you're willing to compromise on that front then they are worth exploring.</p>
</blockquote>
<h2 id="what-did-we-gain">What did we gain?</h2>
<p>It may not seem like it, but we've gained a <strong>lot</strong> by doing this!</p>
<ul>
<li><strong>Defeated the mind hijacks</strong>:
<ul>
<li><strike>(1)</strike> Gained leverage over the "menu"</li>
<li><strike>(3)</strike> Declared which things are important up front, and view them only <em>once</em></li>
<li><strike>(4)</strike> Ignore comments. Scores only matter in that they are relatively high</li>
<li><strike>(6)</strike> Created a bottom (of the bowl) by grabbing a limited number of links</li>
<li><strike>(10)</strike> Easily defer time intensive links for later</li>
</ul>
</li>
<li><strong>Time</strong>
<ul>
<li>Prevent re-reads of HN</li>
<li>Make it easier to pick out the most interesting links and discard irrelevant ones</li>
<li>If you <em>really</em> want to read comments, you'll need to go out of your way</li>
<li>Star or bookmark links to read more in-depth at a later time</li>
</ul>
</li>
<li><strong>Data sovereignty</strong>
<ul>
<li>We control our own data; no relying on third parties (e.g. Feedly)</li>
</ul>
</li>
<li><strong>Cloud Resilience</strong>
<ul>
<li>Lose a phone? Upgrade computers? Need to sync between phone and desktop? No problem!</li>
</ul>
</li>
<li><strong>The ability to add other RSS feeds</strong>
<ul>
<li>We've opened up the ability to use RSS in other feeds
<ul>
<li>For reddit, just <a href="https://www.howtogeek.com/320264/how-to-get-an-rss-feed-for-any-subreddit/">append</a> <code>.rss</code> to any url</li>
<li>For youtube, plug in the URL to any channel!</li>
</ul>
</li>
</ul>
</li>
<li><strong>Costs nothing</strong>
<ul>
<li>Put an otherwise dusty Raspberry Pi to good use</li>
</ul>
</li>
<li><strong>RSS adoption</strong>
<ul>
<li><em>If you really want an RSS resurgence, <strong>start using it</strong></em></li>
</ul>
</li>
</ul>


    
      
    
  </article>

      </section>
    </div></div>]]>
            </description>
            <link>https://soapstone.mradford.com/hn-rss-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26175012</guid>
            <pubDate>Thu, 18 Feb 2021 03:02:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eight Tips for Dealing with Hanging Pennies]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26174428">thread link</a>) | @oedmarap
<br/>
February 17, 2021 | https://shopify.engineering/eight-tips-for-hanging-pennies | <a href="https://web.archive.org/web/*/https://shopify.engineering/eight-tips-for-hanging-pennies">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p>Rounding is used to simplify the use of numbers that contain more decimal places than required. The perfect example is representing cash, money, dough. In the USA and Canada, the cent represents the smallest fraction of money. The US and Canadian dollar canâ€™t be transacted with more than 2 decimal places. When numbers represent money, we use rounding to replace an un-representable, un-transactable money amount with one that represents a cash tender.</p>
<p>The best way to introduce this blog is by asking you to watch a scene from one of my favorite movies, <em>Office Space</em>:</p>
<p><iframe width="560" height="315" src="https://www.youtube.com/embed/yZjCQ3T5yXo" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>In this scene, Peter describes to his girlfriend a program that compounds interest using high precision amounts. He explains that they simplify the calculations by rounding the amounts down and by doing that theyâ€™re left with hanging pennies that they transfer into their personal accounts.</p>
<p>This is exactly what we want to avoidâ€”we want to avoid having one developer aware of hanging pennies. We also want to avoid having many hanging pennies. And when faced with such a situation, we want to identify such calculations and put a plan in place on who to notify and what to do with them.&nbsp;</p>
<p>Before I explain this further, I want to tell you this story first. My father introduced banking software systems in the Middle East in the late 70â€™s. Rest assured he was bound to round. He faced the same issue Peter faced. He resolved it by accepting that he canâ€™t resolve it. So, he created an account where the extra pennies accumulated and later were given as bonuses to the IT team at the bank. It was a way of getting back at the rest of the employees at the bank that didnâ€™t want to move to using a software system and preferred pen and paper.</p>

<p>Okay, letâ€™s get back to breaking this problem down further with another example.</p>
<p>Letâ€™s assume we can only charge <strong>1</strong> total amount, even if this 1 amount consists of a summation of multiple rates.</p>
<p>Rate 1 is 2.4%<br>Rate 2 is 2.9%<br> Amount $10.10</p>
<p>When rounding individual rate amounts:<br> Rate 1 total = (rate /100) * $10.10 = 0.2424 = rounded = 0.24<br> Rate 2 total = (rate /100) * $10.10 = 0.2929 = rounded = 0.29<br> Total = 0.24 + 0.29 = <strong>0.53</strong></p>
<div><p>When rounding total of the rate amounts:<br> Rate 1 total = (rate /100) * $10.10 = 0.2424<br> Rate 2 total = (rate /100) * $10.10 = 0.2929</p><p> Total = 0.2424 + 0.2929 = 0.5353 = rounded = <strong>0.54</strong></p></div>
<p>The example above makes it clear that deciding when to round can either make you more money by collecting the loose penny or lose money by deciding to let go of it.</p>
<p>Rounding at different stages in the example above has more impact if there are currency conversions involved. As a rule of thumb, the more currency conversions (which also involve rounding) and more rounding, the more we lose precision along the way.&nbsp;</p>
<p>Rational numbers are natural products of various banking calculations: distributed payments, shared liabilities, and rates applied. So, youâ€™ll face other rounding encounters in many other places in financial software, most notably while calculating taxes or discounts and, just like in <em>Office Space</em>, while calculating interest.&nbsp;</p>
<p>Did it make <strong>cents</strong>? I hope you have a grasp on the problem. Now, is this avoidable? No, itâ€™s not. If youâ€™re working on financial software youâ€™ll eventually be bound to round. But, we can control where and how to handle the precision loss. Iâ€™m sharing 8 tips to make your precision obsessive compulsiveness a bit less troubling to you as a developer and to the company as a business.</p>
<h2>1. Notify Stakeholders</h2>
<p>Show and tell where the rounding happens within your calculations to the stakeholders of your project. Explain the impact of the rounding, document it, and keep talking about it until all leaders on your team and within your department are aware. You, as a developer, donâ€™t have to take the full burden of knowing that the company is making less than 1 cent on some transactions because of the calculations you put in place. Is a problem really a problem if itâ€™s everyoneâ€™s problem?!</p>
<h2>2. Use Bankerâ€™s Rounding</h2>
<p>There are many types of rounding. There are rounding methods that increase bias and rounding methods that decrease bias. <a href="https://www.sqlservercentral.com/articles/bankers-rounding-what-is-it-good-for" target="_blank" title="Bankerâ€™s Rounding. What is it good for?" rel="nofollow noopener noreferrer">Bankerâ€™s rounding</a> is the method proven to decrease rounding bias within calculations. Banking rounding deliberately distorts some of the rounded values to bring rounding totals of rounded numbers as close to the totals of the original numbers. Talking about why regular rounding taught in schools canâ€™t meet our needs and why Bankerâ€™s rounding is mostly used for financial calculations would turn this blog into a math lesson, and as much as I would love to do that, Iâ€™d probably lose many readers.</p>
<h2>3. Use Data Types That Hold the Most Precision</h2>
<p>Within your calculations, ensure that <strong><em>all</em></strong> variables used are data types that can hold as much precision as possible (can hold enough decimal points). For example, using a double instead of a float. Itâ€™s important to keep the precision wherever there isnâ€™t rounding involved as it reduces the amount of hanging pennies.&nbsp;</p>
<h2>4. Be Consistent</h2>
<p>I mean, this applies to a lot of things in life. When you and your team decide on which rounding methods to use, ensure that the same rounding method is used throughout your code.&nbsp;</p>
<h2>5. Be Explicit About Rounding</h2>
<p>When rounding within your calculation make it explicit by either adding comments or prefix rounded variables with â€œrounded_â€. This ensures that anyone reading your code understands where precision loss is happening. Link to documentation about rounding strategies within your code documentation.</p>
<h2>6. Refer to Government Rounding Standards</h2>
<figure><img alt="A photo of the 1040 U.S. Individual Income Tax Return form on a desk." data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/tax-forms.jpg?v=1613500314" src="https://cdn.shopify.com/s/files/1/0779/4361/files/tax-forms.jpg?v=1613500314">
<figcaption>The 1040 U.S. Individual Income Tax Return form</figcaption>
</figure>
<p>Losing precision is a universal problem and not only suffered by mathematicians. Refer to your governmentâ€™s ruling around rounding. When it comes to tax calculations, governments might have different rules. Refer to them and educate yourself and your team.</p>
<h2>7. Round Only When You Absolutely Have To</h2>
<p>Remember, only tender money amounts need to be rounded. Whenever you can avoid rounding, do so!</p>
<h2>8. Tell Your Users</h2>
<p>Please donâ€™t hide what rounding methods you use to your users. Many users will try to reverse engineer calculations on their own, and as a company you donâ€™t want to end up explaining this several times. Ensure rounding rules are explicitly written in your documentation and easily accessible.&nbsp;</p>
<figure>
<p><img alt="A circular logo with a Shopify shopping bag above the words &quot;Be Merchant Obsessed. What Shopify Values&quot;" data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/Be-Merchant-Obsessed.png?format=jpg&amp;quality=90&amp;v=1613501214" src="https://cdn.shopify.com/s/files/1/0779/4361/files/Be-Merchant-Obsessed.png?format=jpg&amp;quality=90&amp;v=1613501214"></p>
<figcaption>Be Merchant Obsessed</figcaption>
</figure>
<p>At Shopify, we are, of course, bound to round. If you are a Shopify merchant reading this post I want to assure you that in all our calculations, developers are biased towards benefiting our merchants. Not only are our support teams merchant obsessed, all Shopify developers are too.</p>
<p>Dana is a senior developer on the Money team at Shopify. Sheâ€™s been in software engineering since 2007. Her primary interests are back-end development, database design, and software quality management. She's contributed to a variety of products, and since joining Shopify she's been on the Shopify Payments and Balance teams. She recently switched to data development to deliver impactful money insights to our merchants.</p>
<hr>
<p>We're planning to DOUBLE our engineering team in 2021 by hiring 2,021 new technical roles (see what we did there?). Our platform handled record-breaking sales over BFCM and commerce isn't slowing down. <a href="https://www.shopify.com/careers/2021?itcat=EngBlog&amp;itterm=Post" target="_blank">Help us scale &amp; make commerce better for everyone</a>.</p>
</div></div>]]>
            </description>
            <link>https://shopify.engineering/eight-tips-for-hanging-pennies</link>
            <guid isPermaLink="false">hacker-news-small-sites-26174428</guid>
            <pubDate>Thu, 18 Feb 2021 01:42:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Demand-Side Thinking: Creating Pull for Your Products]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26174215">thread link</a>) | @luthfur
<br/>
February 17, 2021 | https://makingsmallercircles.com/uncategorized/demand-side-thinking-creating-pull-for-your-products/ | <a href="https://web.archive.org/web/*/https://makingsmallercircles.com/uncategorized/demand-side-thinking-creating-pull-for-your-products/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<!-- .entry-header -->


	<div>
		<main id="main">

		
<article id="post-368">
	
	<div>
		
<p>A great product tends to sell itself. Itâ€™s the obvious choice for the problem it solves, and it solve that problem very well. Such a product appears to have a natural pull. So how can you go about creating a product like that?</p>



<p>An approach that has caught my attention is what I like to call Demand-side Thinking. Itâ€™s based on Bob Moestaâ€™s work on<a href="https://amzn.to/3rWZDrk" target="_blank" rel="noopener"> Demand-side Sales</a>. In his book Moesta contrasts supply-side sales, a focus on products, features and benefits, with demand-side sale, which focuses on the buyerâ€™s world view and what causes them to make a purchase. It flips the perspective by trying to understand the world from the buyerâ€™s point of view.&nbsp; Instead of asking a supply-side question, how can I build and push a product to the customer, we ask a demand-side question: how can we build a product that the customer pulls into their world?&nbsp; It applies the <a href="https://www.christenseninstitute.org/jobs-to-be-done/" target="_blank" rel="noopener">â€œjobs to be doneâ€ theory</a> to product development, positioning and sales.</p>



<p>Jobs to be done theory emphasizes that people donâ€™t buy products, they hire them to make progress in their lives. Your productâ€™s role is to move your customer from his or her current circumstances towards a new,&nbsp; improved state. This desire for progress and associated challenges create a struggling moment for the customer.</p>



<p>This struggling moment is the spark that inspires a question in the mind: â€œis there a better way?â€. This simple, yet powerful question pushes the customer to invest time in searching and learning about possible solutions.&nbsp; As the late Clay Christensen had said â€œquestions are places in your mind where answers fitâ€. As a product developer the questions that arise from the customer struggles are opportunities for us to explore, define and develop the right solutions&nbsp; to help them make progress.</p>



<p>The customer is not looking for a long list of feature. A feature is no use to them if it doesnâ€™t contribute meaningful towards making progress for them. That means, your really great AI feature, or that nifty UX concept is of no value if doesnâ€™t resolve the customers struggles. On the other features that remove obstacles and move the customer forward towards their goals will be seen as delightful to use. This frame of thinking is complete customer centric. It will influence not just what you build, but also how you position it in the market. This is demand-side thinking.</p>



<p>It also changes how you interact with your customers to try and understand them. Customers usually have a hard time pin pointing the causes of their struggles. Consider the following example interaction from Moestaâ€™s book:</p>



<p>â€œI need a drill, because I want a hole.â€</p>



<p>â€œWhy?â€</p>



<p>â€œI need a hole, because I want a plug.â€</p>



<p>â€œWhy?â€</p>



<p>â€œI need a plug, because I want a lamp.â€</p>



<p>â€œWhy do you want a lamp?â€</p>



<p>â€œBecause itâ€™s hard to see, and I want to read better.â€</p>



<p>The job to be done in this example is to read better with a lamp, not drill a hole. Perhaps the solution that helps make progress here is a battery powered lamp. In that case neither a hole, nor a drill is required. Notice that uncovering this detail requires us to dig deep and ask several â€œwhyâ€â€˜s to get the bottom of things. Otherwise we will only hear the surface level need from the customer. This also illustrates why customers are often not the best people to look to for solutions. In many cases, they may not be diagnosing their problems clearly to begin with.</p>



<p>Demand-side approach gives us the tools to uncover the real need, the root cause and the actual demand from the customer.</p>



<p>While the struggling moment is the force that pushes the customer to start looking for improvements, there are three other forces at play that need to be considered:</p>



<ol><li>The magnetism of your offering: Does your product clearly resolve the customers struggling moment? This is a force that pulls the customer towards your product.</li><li>The anxiety of the new solution: Will your product fulfill and deliver on itâ€™s promise? There is an anxiety that pushes a customer back to status quo.</li><li>The habit of the present: People become accustomed to their struggles. There is a learned helplessness that prevents them from making progress.</li></ol>



<p>These forces can be framed and tackled as a sales problem. For example money back guarantees, access to community can help with addressing anxiety of trying a new solution.&nbsp; Others can be baked into the product, for example a clean onboarding experience that smoothly transitions the customer from their old habits to a new one.</p>



<p>Demand-side thinking takes you from asking what do I want to build, to asking what is the market craving for. It is the ultimate â€œblue ocean strategyâ€ that can reveal untapped opportunities and create real pull for your products.</p>



<p><strong>Further Reading:</strong></p>



<p><a href="https://amzn.to/3rWZDrk" target="_blank" rel="noopener">Demand-Side Sales 101: Stop Selling and Help Your Customers Make Progress by Bob Moesta</a></p>



<p><a href="https://amzn.to/3beMX8r" target="_blank" rel="noopener">Competing Against Luck: The Story of Innovation and Customer Choice  by Clayton Christensen</a></p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- .hentry -->

<!-- #comments -->

		</main><!-- #main -->

		
<!-- #secondary -->
	</div><!-- .container -->


	</div></div>]]>
            </description>
            <link>https://makingsmallercircles.com/uncategorized/demand-side-thinking-creating-pull-for-your-products/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26174215</guid>
            <pubDate>Thu, 18 Feb 2021 01:14:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SRE vs. Platform Engineering]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26174094">thread link</a>) | @rdli
<br/>
February 17, 2021 | https://blog.getambassador.io/the-rise-of-cloud-native-engineering-organizations-1a244581bda5 | <a href="https://web.archive.org/web/*/https://blog.getambassador.io/the-rise-of-cloud-native-engineering-organizations-1a244581bda5">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><h2 id="ceaa">DevOps, GitOps, and the Rise of Cloud-Native Engineering Organizations</h2><div><div><div><p><a href="https://medium.com/@datawire?source=post_page-----1a244581bda5--------------------------------" rel="noopener"><img alt="Datawire" src="https://miro.medium.com/fit/c/96/96/0*5hfCO2OGW1F4dFam.png" width="48" height="48"></a></p></div></div></div></div><p id="c8c6">Over the past decade, engineering and technology organizations have converged on a common set of best practices for building and deploying cloud-native applications. These best practices include continuous delivery, containerization, and building observable systems.</p><p id="0456">At the same time, cloud-native organizations have radically changed how theyâ€™re organized, moving from large departments (development, QA, operations, release) to smaller, independent development teams. These application development teams are supported by two new functions: site reliability engineering and platform engineering. SRE and platform engineering are spiritual successor of traditional operations teams, and bring the discipline of software engineering to different aspects of operations.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/8640/1*TV-rJk9Vh8IulePV8JiZmw.png" width="4320" height="2208" srcset="https://miro.medium.com/max/552/1*TV-rJk9Vh8IulePV8JiZmw.png 276w, https://miro.medium.com/max/1104/1*TV-rJk9Vh8IulePV8JiZmw.png 552w, https://miro.medium.com/max/1280/1*TV-rJk9Vh8IulePV8JiZmw.png 640w, https://miro.medium.com/max/1400/1*TV-rJk9Vh8IulePV8JiZmw.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*TV-rJk9Vh8IulePV8JiZmw.png?q=20"></p></div></div></div></figure><p id="4648">Platform engineering teams apply software engineering principles to <strong>accelerate software delivery</strong>. Platform engineers ensure application development teams are productive in all aspects of the software delivery lifecycle.</p><p id="e6b2">Site reliability engineering teams apply software engineering principles to <strong>improve reliability</strong>. Site reliability engineers minimize the frequency and impact of failures that can impact the overall reliability of a cloud application.</p><p id="0360">These two teams are frequently confused and the terms are sometimes used interchangeably. Indeed, some organizations consolidate SRE and platform engineering into the same function. This occurs because both roles apply a common set of principles:</p><ul><li id="a8ec">Platform as product. These teams should spend time understanding their internal customers, building roadmaps, having a planned release cadence, writing documentation, and doing all the things that go into a software product.</li><li id="5c9d">Self-service platforms. These teams build their platforms for internal use. In these platforms, best practices are encoded, so that the users of these platforms donâ€™t need to worry about it â€” they just push the button. In the <a href="https://puppet.com/resources/report/2020-state-of-devops-report/" rel="noopener">Puppet Labs 2020 State of DevOps report</a>, Puppet Labs found that High functioning DevOps organizations had more self-service infrastructure than low DevOps evolution organizations.</li><li id="84ae">A constant focus on <a href="https://sre.google/sre-book/eliminating-toil/" rel="noopener">eliminating toil</a>. As defined in the Google SRE book, toil is manual, repetitive, automatable, tactical work. The best SRE and platform teams identify toil, and work to eliminate it.</li></ul><p id="e1f2">Platform engineers constantly examine the entire software development lifecycle from source to production. From this introspective process, they build a workflow that enables application developers to rapidly code and ship software. A basic workflow typically includes a source control system connected with a continuous integration system, along with a way to deploy artifacts into production.</p><p id="a167">As the number of application developers using the workflow grows, the needs of the platform evolves. Different teams of application developers need similar but different workflows, so self-service infrastructure becomes important. Common platform engineering targets for self-service include CI/CD, alerting, and deployment workflows.</p><p id="9487">In addition to self-service, education and collaboration become challenges. Platform engineers find they increasingly spend time educating application developers on best practices and how to best use the platform. Application developers also find that they depend on other teams of application developers, and look to the platform engineering team to give them the tools to collaborate productively with different teams.</p><p id="c748">Site reliability engineers create and evolve systems to automatically run applications, reliably. The concept of site reliability engineering originated at Google, and is documented in detail in the <a href="https://sre.google/sre-book/introduction/" rel="noopener">Google SRE Book</a>. Ben Treynor Sloss, the SVP at Google responsible for technical operations, described SRE as â€œwhat happens when you ask a software engineer to design an operations team.â€</p><p id="8382">SREs define service level objectives and build systems to help services achieve these objectives. These systems evolve into a platform and workflow that encompass monitoring, incident management, eliminating single points of failure, failure mitigation, and more.</p><p id="5e14">A key part of SRE culture is to treat every failure as a failure in the reliability system. Rigorous post-mortems are critical to identifying the root cause of the failure, and corrective actions are introduced into the automatic system to continue to improve reliability.</p><p id="4756">One of us (Bjorn Freeman-Benson) managed the engineering organization at New Relic until 2015 as it grew from a handful of customers to tens of thousands of customers, all sending millions of requests per second into the cloud. New Relic had independent SRE and platform engineering teams that followed the general principles outlined above.</p><p id="ab4a">One of the reasons these teams were built separately was that the people who thrived in these roles differed. While both SREs and platform engineers need strong systems engineering skills in addition to classic programming skills, the roles dictate very different personality types. SREs tend to enjoy crisis management and get an adrenaline rush out of troubleshooting an outage. SRE managers thrive under intense pressure and are good at recruiting and managing similarly minded folks. On the other hand, platform engineers are more typical software engineers, preferring to work without interruption on big, complex problems. Platform engineering managers prefer to operate on a consistent cadence.</p><p id="f0f8">Over the past decade, DevOps has become a popular term to describe many of these practices. More recently, GitOps has also emerged as a popular term. How do DevOps and GitOps relate to platform and SRE teams?</p><p id="e90a">Both DevOps and GitOps are a loosely codified set of principles of how to manage different aspects of infrastructure. The core principles of both of these philosophies â€” automation, infrastructure as code, application of software engineering â€” are very similar.</p><p id="5ed9">DevOps is a broad movement that began with a focus on eliminating traditional silos between development and operation. Over time, strategies such as infrastructure automation and engineering applications with operations in mind have gained widespread acceptance as ways better build highly reliable applications.</p><p id="9db4">GitOps is an approach for application delivery. In GitOps, declarative configuration is used to codify the desired state of the application at any moment in time. This configuration is managed in a versioned source control system as the single source of truth. This ensures auditability, reproducibility, and consistency of configuration.</p><blockquote><p id="ccd3">In short: DevOps is a set of guiding principles for SRE, while GitOps is a set of guiding principles for platform engineering.</p></blockquote><p id="62fd"><a href="https://ctt.ac/Dbfff" rel="noopener">Tweet this.</a></p><p id="4a1d">Site reliability engineering and platform engineering are two functions that are critical to optimizing engineering organizations for building cloud-native applications. The SRE team works to deliver infrastructure for highly reliable applications, while the platform engineering team works to deliver infrastructure for rapid application development. Together, these two teams unlock the productivity of application development teams.</p></div></div></section></div></div>]]>
            </description>
            <link>https://blog.getambassador.io/the-rise-of-cloud-native-engineering-organizations-1a244581bda5</link>
            <guid isPermaLink="false">hacker-news-small-sites-26174094</guid>
            <pubDate>Thu, 18 Feb 2021 00:59:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to move from LastPass to Bitwarden in ten minutes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26174053">thread link</a>) | @jdauriemma
<br/>
February 17, 2021 | https://jdauriemma.com/misc/lastpass-to-bitwarden | <a href="https://web.archive.org/web/*/https://jdauriemma.com/misc/lastpass-to-bitwarden">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="main-content">
        <div>
          <article itemscope="" itemtype="http://schema.org/BlogPosting">
  
  <div itemprop="articleBody">
    <p>LastPass recently notified users that their free product will drastically
change on 2021-03-16 in
<a href="https://blog.lastpass.com/2021/02/changes-to-lastpass-free/">a recent blog post</a>.
I believe
this change is being made irresponsibly,
but you can read my opinion in a follow-up post I'm planning.
Many non-paying users are looking around
for alternatives.  <a href="https://bitwarden.com/">Bitwarden</a> fits the bill nicely
for me: it has desktop, mobile, and web apps with the same features as LastPass,
plus it has the benefit of being largely
<a href="https://github.com/bitwarden">open-source software</a>
distributed under GPL/AGPL licenses.</p>

<p>Bitwarden's help docs have a decent
<a href="https://bitwarden.com/help/article/import-from-lastpass/">guide to help users import data from LastPass</a>
but if you need some additional resources, please read on.</p>

<h2 id="export-your-lastpass-data">Export your LastPass data</h2>

<p>Before we get started, be aware that you will be downloading a file containing
all the username/password combinations you have stored in LastPass.  This
file will not be encrypted - the passwords will be in plain text.
Once you're done copying your data into Bitwarden, delete all the data you
downloaded from LastPass so that it is no longer available on your computer.</p>

<ol>
<li>On a desktop or laptop, log into LastPass.</li>
<li>Open the navigation panel on the left side of the screen.</li>
<li>Tap <strong>Advanced Options</strong>.  A new menu will appear to the right.</li>
<li>Tap <strong>Export</strong>.  You will be prompted to enter your master password.</li>
<li>The screen may appear unresponsive for a short time.  That is normal.</li>
</ol>

<figure>
  <div>
    <section>
      <img loading="lazy" decoding="async" alt="LastPass interface showing the left navigation bar open and 'Advanced Options' highlighted" src="https://jdauriemma.com/assets/images/posts/lastpass-to-bitwarden/desktop-1.png">
    </section>
    <section>
      <img loading="lazy" decoding="async" alt="LastPass interface showing the left navigation bar open and 'Export' highlighted" src="https://jdauriemma.com/assets/images/posts/lastpass-to-bitwarden/desktop-2.png">
    </section>
  </div>
  <figcaption>
    <span>
      Use the left navigation to drill down: <strong>Advanced Options</strong> ğŸ‘‰ <strong>Export</strong>
    </span>
  </figcaption>
</figure>

<ol start="6">
<li>The browser window will turn white and black text will appear.  This text contains all the usernames, passwords, etc. you store in LastPass.</li>
<li>Leave this window open for a moment.</li>
<li>Open a plain text editor.  If you're not sure what a plain text editor is,
don't worry.  You have one installed on your operating system.
<a href="https://www.fedoraoutlier.com/the-built-in-text-editors-on-windows-and-macs/">See this link</a>
for more information.</li>
<li>Highlight and copy all the text from the open LastPass window.  Paste
it into your text editor.</li>
<li>Save the file as <code>export.csv</code>.</li>
</ol>

<p>To avoid inadvertently pasting this sensitive information somewhere
else, copy some other text as a safeguard.</p>

<h2 id="sign-up-for-bitwarden">Sign up for Bitwarden</h2>

<p>Go to <a href="https://bitwarden.com/">bitwarden.com</a>.  Tap "Get Started" in the top
right corner.  You will be prompted to enter your email address and to set
a master password, much like LastPass.  I recommend using a password that
is different from your LastPass master password.</p>

<p>Once you have completed registration and confirmed your email address,
log into Bitwarden again.</p>

<ol>
<li>Tap <strong>Tools</strong> at the top of the window.</li>
<li>On the left, tap <strong>Import Data</strong>.</li>
<li>Under <strong>1. Select the format of the import file</strong>, select
"LastPass (csv)."</li>
<li>Under <strong>2. Select the import file</strong>, select the <code>export.csv</code> file you created earlier.  Tap the button labeled <strong>Import Data</strong>.</li>
</ol>

<figure>
  <div>
    <section>
      <img loading="lazy" decoding="async" alt="Text editor showing a file called 'export.csv' with data" src="https://jdauriemma.com/assets/images/posts/lastpass-to-bitwarden/desktop-3.png">
    </section>
    <section>
      <img loading="lazy" decoding="async" alt="Bitwarden interface showing the 'Tools' section open and 'Import Data' highlighted" src="https://jdauriemma.com/assets/images/posts/lastpass-to-bitwarden/desktop-4.png">
    </section>
  </div>
  <figcaption>
    <span>
      Copy the LastPass export into <code>exports.csv</code> using a plain text editor like Notepad, TextEdit, or Vim.  Tap <strong>Tools</strong> ğŸ‘‰  <strong>Import Data</strong> and upload <code>exports.csv</code>.
    </span>
  </figcaption>
</figure>

<p>Your data should now be available.  According to Bitwarden's documentation,
some users have experienced issues with the encoding of certain special
characters in passwords:</p>

<blockquote>
<p>Warning</p>

<p>Some users have reported a bug which changes special characters in your passwords (&amp;, &lt;, &gt;, etc.) to their HTML-encoded values (for example, <code>&amp;amp;</code> in the printed export.</p>

<p>If you observe this bug in your exported data, use a text editor to find and replace all altered values before importing into Bitwarden.</p>
</blockquote>

<p>I haven't come across anything like that yet, but I transitioned very recently.
I will update this post if I come across anything unusual.</p>

<h2 id="ios-users-update-autofill">iOS users: update AutoFill</h2>

<p>If you're not an iOS user, <a href="#delete-your-lastpass">skip this section</a>.</p>

<p>As an iOS user, I am accustomed to using LastPass to autofill passwords.
After installing the
<a href="https://apps.apple.com/us/app/bitwarden-password-manager/id1137397744">Bitwarden app</a>:</p>

<ol>
<li>Go into <strong>Settings</strong>.</li>
<li>Tap on <strong>Passwords</strong>.</li>
<li>Tap on <strong>AutoFill Passwords</strong>.</li>
<li>Tap on <strong>Bitwarden</strong>.</li>
<li>Follow the prompts.</li>
</ol>

<figure>
  <div>
    <section>
      <img loading="lazy" decoding="async" alt="iOS Settings menu with 'Passwords' highlighted" src="https://jdauriemma.com/assets/images/posts/lastpass-to-bitwarden/ios-1.jpg">
    </section>
    <section>
      <img loading="lazy" decoding="async" alt="iOS Passwords menu" src="https://jdauriemma.com/assets/images/posts/lastpass-to-bitwarden/ios-2.jpg">
    </section>
    <section>
      <img loading="lazy" decoding="async" alt="iOS AutoFill Passwords menu with Bitwarden selected" src="https://jdauriemma.com/assets/images/posts/lastpass-to-bitwarden/ios-3.jpg">
    </section>
  </div>
  <figcaption>
    <span>
      <strong>Settings</strong> ğŸ‘‰
      <strong>Passwords</strong> ğŸ‘‰
      <strong>Autofill Passwords</strong> ğŸ‘‰
      <strong>Bitwarden</strong>
    </span>
  </figcaption>
</figure>



<h2 id="delete-your-lastpass-after-a-while">Delete your LastPass (after a while)</h2>

<p>It's a good idea to hold onto your LastPass free account for a short time,
at least until you are reasonably certain Bitwarden is meeting your needs and
that all of your data was copied over successfully.  I haven't done this part
yet, but
<a href="https://lastpass.com/delete_account.php">the documentation</a>
makes it seem pretty simple.</p>

    
    <h3>Keep the conversation going</h3>
    <p>I really appreciate feedback from anyone and everyone who reads my posts, so please feel free to say hi at <a href="https://mastodon.social/@bignimbus" target="_blank"><span data-cfemail="67050e00090e0a051214270a06141308030809491408040e060b">[email&nbsp;protected]</span></a> and keep the conversation going.</p>
    
  </div>
  
</article>


        </div>
      </section></div>]]>
            </description>
            <link>https://jdauriemma.com/misc/lastpass-to-bitwarden</link>
            <guid isPermaLink="false">hacker-news-small-sites-26174053</guid>
            <pubDate>Thu, 18 Feb 2021 00:55:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building products â€“ Things I wish I knew when I started building products]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26173963">thread link</a>) | @gmays
<br/>
February 17, 2021 | https://amiltonpaglia.com/writing/building-products | <a href="https://web.archive.org/web/*/https://amiltonpaglia.com/writing/building-products">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><div><main><header></header><div><p>Nov 7, 2020, 21:00<!-- --> <svg width="16" height="16" style="position:relative;top:2px"><line x1="4" y1="16" x2="12" y2="2" style="stroke:#ccc"></line></svg> <time datetime="1604782800000">3 months ago</time></p></div><p>It's not a step by step guide but rather an attempt to synthesize my thinking about what it really matters to build great products.</p><p>I've been building products for the last 12 years. On this journey, I have been fortunate to have the opportunity to wear a lot of different hats in the making of a digital product.&nbsp;</p><p>I've worked as Interface designer, Front-end developer, UX Designer, Product Designer and lastly, as a Product Manager. All along the way, I've always had a close relationship with engineers, learning everything I could about development and understanding all the effort and creativity necessary to bring products to life.</p><p>To keep this valuable for a wider audience and range of professionals, I've tried to extract the essence of I believe to be essential to keep in mind when building products.</p><p>Loading...</p><h2>Purpose</h2><p><strong>Everything starts with a clear purpose.</strong></p><p>When building products, you have to be an<!-- --> <strong>eternal optimist about your missionâ€Š</strong> â€“ â€Što help you get through the rough times, and<!-- --> <strong>very pessimist about executionâ€Š</strong> â€“ â€Šit always takes way more time and effort to nail it.</p><p><strong>Build great products takes time; it's a long-term commitment.</strong> <!-- -->It's almost impossible (in my experience) to immerse yourself in a work whose purpose isn't aligned with your beliefs.</p><p>Without a clear purpose for you (and your team), it's tough to find an intrinsic motivation to keep iterating your product on a problem space.</p><p>Loading...</p><h2>Constraints</h2><blockquote>"...Here is one of the few effective keys to the Design problem: the ability of the Designer to recognize as many of the constraints as possible; his willingness and enthusiasm for working within these constraints. Constraints of price, of size, of strength, of balance, of surface, of time, and so forth. Each problem has its own peculiar list."<p>Charles &amp; Ray Eames</p></blockquote><p>I love this excerpt from an<!-- --> <a href="https://www.hermanmiller.com/stories/why-magazine/design-q-and-a-charles-and-ray-eames/">interview with Charles and Ray Eames</a> <!-- -->in 1972 about Design. This quote stayed on my mind since the first time I've read it.</p><p><strong>Embracing constraints is essential to creativity.</strong> The primary fuel to your problem-solving is to identify what restrictions you're dealing with.</p><p>Your purpose is what drives your "willingness and enthusiasm for working within these constraints." Once you have a clear purpose and goal in mind, you have to "identify as many constraints as possible" to have a clear problem space to tackle, and sometimes you need to enforce additional constraints.</p><p>I like to think about constraints in two spectrums:</p><ul><li>From <strong>hard constraints</strong> to<!-- --> <strong>self-imposed constraints</strong>;</li><li>From <strong>under constraint</strong> to<!-- --> <strong>over constraint</strong>;</li></ul><h3>Hard &amp; Self-imposed constraints</h3><p><strong>Hard constraints</strong> are the ones that you have little to no influence under it. It's time, resources, team, skills, funding, knowledge, market conditions, laws, available technology, and so on. It's the constraints that you'll have to work within, no matter what.</p><p><strong>Self-imposed constraints</strong> are the ones you set to have a clear problem space and increase your focus. It could come in different shapes. It could be your values, product principles, strategy, and everything else you and your team agree on that helps you stay on the right path. It's your conscious trade-offs.</p><h3>Under &amp; Over Constraints</h3><p><strong>An under constrained problem space will be too broad and challenging to narrow down what really matters.</strong> <!-- -->You'll see yourself drowned in the endless possibilities to solve problems. When you find yourself in this scenario, it's better to enforce new constraints and make trade-offs to eliminate noise.</p><p>On the other hand,<!-- --> <strong>when you over constrain it, you won't leave room for improvisation, innovation, and adaption when it's needed.</strong> <!-- -->You have to find a sweet spot on this spectrum to have the freedom to experiment.</p><p><strong>Identifying the right constraints and balancing them is an ongoing challenge.</strong> <!-- -->Your team will grow, new technologies will enable new solutions, markets, and users will continuously evolve.</p><p>You have to keep your eyes open to see what stays true and what helps you stay focused on what matters.<!-- --> </p><p>Loading...</p><h3>Shaping friction</h3><p><strong>Your goal when designing a product is to shape friction.</strong> <!-- -->You'll have to shape as many frictions as possible from your user's journey to achieve the desired outcome. Here are some examples:</p><ul><li><strong>Optimize your user acquisitionâ€Š</strong> â€“ remove friction from each step of the funnel;</li><li><strong>Improve engagementâ€Š</strong> â€“ remove friction to make core actions more intuitive and accessible;</li><li><strong>Reduce churnâ€Š</strong> â€“ â€Šremove friction that is keeping users away from their goals;</li><li><strong>Avoid unintended behaviorsâ€Š</strong> â€“â€Š Instagram adding features to avoid users (adding friction) to pos offensive content;</li><li>You got the pointâ€¦</li></ul><p><mark><strong>To identify which friction worth solving/shaping, you have to have a deep understating of your product and the people using it.</strong></mark> <!-- -->You'll have to know product goals and the user's job-to-be-done (context, objectives, functional and emotional needs).</p><p>In essence, your job is to continuously iterate, shape, and balance the right amount of friction on each part of the product.</p><h3>Prioritization &amp;&nbsp;Judgment</h3><p>Loading...</p><p><strong><mark>Prioritization is one of the most essential subjects in building products.</mark></strong></p><p>There are endless techniques, frameworks, mental models, and tools to help you make the right decisions when prioritizing your next move.</p><p>The truth is that it's tough to make the "best" decisions, even when you have lots of qualitative and quantitative insights (not the case for early-stage products) to inform your prioritization.</p><p><strong>Confident decision making takes time</strong>. When working on a high-growth startup, you'll have to be comfortable with the uncertainty, lack of time, data, and resources to make the right call.</p><p>Another critical factor to keep in mind is your (and your team's) biases. Even when you have plenty of data at your disposal, you and your team are always influenced by some bias (<a href="https://en.wikipedia.org/wiki/List_of_cognitive_biases" title="Cognitive biases" target="_blank">confirmation bias and others</a>).</p><p>There will be times when you won't have enough data, other times you won't have enough time, and most of the time, you won't be aware of your biases.</p><p>That leads me to my last point, <strong>judgment</strong>. Good judgment is extremely underrated these days, but I find it one of the most valuable traits.</p><blockquote>"Good Judgment depends mostly on experience, and experience usually comes from poor judgment."<p>Old saying</p></blockquote><p>Good judgment is also impossible to measure upfront, but<!-- --> <strong>it will be your judgment</strong> to assess the risk and time needed to make each decision<strong>that will lead you towards the best possible outcomes</strong> <!-- -->in times of uncertainty.</p></main></div></div></div>]]>
            </description>
            <link>https://amiltonpaglia.com/writing/building-products</link>
            <guid isPermaLink="false">hacker-news-small-sites-26173963</guid>
            <pubDate>Thu, 18 Feb 2021 00:44:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Is Naming Things Hard?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26173903">thread link</a>) | @r_singh
<br/>
February 17, 2021 | https://neilkakkar.com/why-is-naming-things-hard.html | <a href="https://web.archive.org/web/*/https://neilkakkar.com/why-is-naming-things-hard.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>An interesting shift happens once you realise youâ€™re writing code for humans to read, and not just for machines to execute.</p>

<p>One big change is that writing clearly takes priority over correct code.<sup id="fnref:1"><a href="#fn:1">1</a></sup></p>

<p>Reading code involves building up a mental model of what each thing should do, and how these things interact with each other. The best code, however, short-circuits reading everything. Instead of reading the implementation, you use variable and function names, comments, and other clues to figure things out.<sup id="fnref:3"><a href="#fn:3">2</a></sup></p>

<p>This is chunking. You combine things together, and remember them together. For example, a Chess Opening, like the Queenâ€™s Gambit, is a chunk. So is a <code>forEach</code> loop: just by the name, you can figure out that itâ€™s going to do something to every element of an array.</p>

<p>Once youâ€™ve built a chunk for a <code>forEach</code> loop, you donâ€™t have to read the implementation of <code>forEach</code> to understand what it will do. This is very powerful, since it allows you to come back to the code, without having to read the implementation of everything again.</p>

<p>Thus, a good name is a chunk that encodes important information about what the thing does.</p>

<p>Weâ€™re compressing information into the name. This is almost always a lossy compression. Further, the more lines to compress, the more losses you incur, since you want your names to be no longer than 80 characters.</p>

<p>The goal of good naming is to minimize this loss.</p>

<p>And naming things is hard because of this compression. English isnâ€™t precise like C++, so compressing from a precise to an ambiguous language increases losses. Another big reason is that choosing the most important things to include is hard. Youâ€™ll notice that most disagreements about naming fall on these two axes: either the name isnâ€™t just right for what you want to do (does it <code>assign</code> or <code>setup</code> or <code>link</code> or <code>mangle</code>?). Or the name doesnâ€™t capture important parts of the functionality.</p>

<p>I think this is the generating function for most best practices Iâ€™ve heard of, and thus lots more valuable than one specific guidance.</p>

<h2 id="generating-best-practices">Generating best practices</h2>

<!-- Keep names short: big chunks are difficult chunks -->

<ol>
  <li>
    <p>Make functions do one thing</p>

    <p>When a function does multiple things, the name needs to encode lots more information, like <code>link_user_to_trial_and_enable_downloads_and_set_charge_date()</code>. Thatâ€™s a long name, and a sign of losing too much information: what semantics should the name expose about the charge date, and enabling downloads?</p>

    <p>These side effects are hard to encode for in the name.</p>
  </li>
  <li>
    <p>Keep functions small</p>

    <p>Long functions, like functions doing lots of things, need to encode lots of information into the name. And since the name length is bounded, you lose a lot more information in compressing this long name, which leads to poorer names.</p>
  </li>
  <li>
    <p>Avoid meaningless names</p>

    <p>Since weâ€™re writing code to be read by humans, names that donâ€™t compress any information donâ€™t help us build chunks. This makes it harder to read, since you have to go down one layer of abstraction. You need to parse the implementation to understand what that piece of code does.</p>
  </li>
  <li>
    <p>Avoid too abstract names</p>

    <p><code>do_things()</code> is a suitable name for any function, but the compression is too lossy to be useful - you lose almost all information, and need to parse the body to figure out what it does. Not great. Itâ€™s almost a meaningless name.</p>
  </li>
  <li>
    <p>Be consistent</p>

    <p>When you build similar chunks throughout your code base, it becomes easier to go up another layer of abstraction, by chunking the chunks. For example, continuing the trial management system example, youâ€™ll have 3 things in place:</p>

    <ol>
      <li><code>link_user_to_trial_agreement_given_email()</code></li>
      <li><code>enable_research_downloads_for_user()</code></li>
      <li><code>set_charge_date_for_user()</code></li>
    </ol>

    <p><br>
 Since theyâ€™re operating in the same domain, you can go up one level to <code>setup_user_for_trial()</code> that does all three.</p>
  </li>
</ol>

<h2 id="disrupting-best-practices">Disrupting best practices</h2>

<p>The generator of best practices allows you to reason about cases where best practices arenâ€™t the best way forward.</p>

<p>For example, consider being consistent, and naming variables using camelCase. Your entire codebase uses camelCase. Youâ€™re writing a new function thatâ€™s very non-standard. It does arcane stuff that doesnâ€™t fit into your existing model. You need it, because legacy integration/business requirements/etc. In effect, you donâ€™t want anyone to gloss over it when they read it.</p>

<p>So, do you stay consistent, and keep it in camelCase? Or, do you switch to snake_case?</p>

<p>The goal is to keep things clear. I would switch to snake_case to show how itâ€™s different from the rest, and have some comments explaining the arcane things it does.<sup id="fnref:2"><a href="#fn:2">3</a></sup></p>

<h2 id="precision-with-words">Precision with words</h2>

<p>Spoken languages are very imprecise. Thereâ€™s lots of ambiguity, double meanings, and sentences that donâ€™t mean anything.</p>

<p>Code, however, needs to be precise. Like we saw above, this is a source of trouble, since weâ€™re trying to compress a precise language into an imprecise one, which makes searching for the right English words harder.</p>

<p>These ideas apply to naming things outside of code, too! When you have a name for something, it suddenly becomes legible.</p>

<p>Consider: You see some people around you who test if they can do something once, and drop it if they fail. Some others keep trying until they learn how to do it. The first group prizes its intelligence, while the second group prizes its hard work. Then, when you hear about the <a href="https://neilkakkar.com/story-of-stories.html#the-story-of-growth-vs-fixed-mindset">Fixed vs Growth mindset</a>, things immediately click.</p>

<p>Choosing the right name here is hard too. Every best practice that lost its nuance over time can be attributed to a name that didnâ€™t encode the necessary information. People passed these ideas on without explaining the nuances.</p>

<p>Or, consider equating two names. â€œAbortion is murderâ€ - equating two names that arenâ€™t the same creates an interesting dynamic between emotions and the truth. Each name has different connotations, and on combining them together, youâ€™re passing on the connotations of one onto the other. This isnâ€™t necessarily a good thing. You have to be very careful of the equality operator in an imprecise language.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Optimise for clear, easy to understand code. The cost of reading it is higher than the cost of executing it.</p>

<p>To do this, leverage chunking: write names that are meaningful, and encode as much information as possible into the name.</p>

<p>However, writing meaningful names is a lossy compression. Every naming maxim follows from minimising this loss.</p>

<p>And finally, the same idea applies to naming things in the real world. Except, itâ€™s even harder, since itâ€™s encoding from an imprecise to another imprecise language. Code, atleast, was unambiguous in its execution.</p>

<figure>
    
    <img src="https://neilkakkar.com/assets/images/divider.jpg" alt="">
    
    
    
</figure>

<blockquote>
  <p>Thanks to Soumya for reading drafts of this.</p>
</blockquote>

<p>Have feedback? You can <a href="https://twitter.com/neilkakkar/status/1361611070331305986" target="_blank" rel="noopener">reply to this post on Twitter</a>.</p>


    
  </div></div>]]>
            </description>
            <link>https://neilkakkar.com/why-is-naming-things-hard.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26173903</guid>
            <pubDate>Thu, 18 Feb 2021 00:35:36 GMT</pubDate>
        </item>
    </channel>
</rss>
