<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 21 Jul 2020 12:21:25 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 21 Jul 2020 12:21:25 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Optimizing 128-bit Division]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23888177">thread link</a>) | @EvgeniyZh
<br/>
July 19, 2020 | https://danlark.org/2020/06/14/128-bit-division/ | <a href="https://web.archive.org/web/*/https://danlark.org/2020/06/14/128-bit-division/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-288">

	

	
	<div>
		
<p>When it comes to hashing, sometimes 64 bit is not enough, for example, because of <a href="https://en.wikipedia.org/wiki/Birthday_problem">birthday paradox</a> — the hacker can iterate through random <img src="https://s0.wp.com/latex.php?latex=2%5E%7B32%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{32}" title="2^{32}"> entities and it can be proven that with some constant probability they will find a collision, i.e. two different objects will have the same hash. <img src="https://s0.wp.com/latex.php?latex=2%5E%7B32%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{32}" title="2^{32}"> is around 4 billion objects and with the current power capacity in each computer it is certainly achievable. That’s why we need sometimes to advance the bitness of hashing to at least 128 bits. Unfortunately, it comes with a cost because platforms and CPUs do not support 128 bit operations natively.</p>



<p>Division historically is the most complex operation on CPUs and all guidelines suggest avoiding the division at all costs.</p>



<p>At my job I faced an interesting problem of optimizing 128 bit division from <a href="https://github.com/abseil/abseil-cpp/blob/master/absl/numeric/int128.cc#L155">abseil library</a> in order to split some data across buckets with the help of 128 bit hashing (the number of buckets is not fixed for some uninteresting historical reasons). I found out that the division takes a really long time. The <a href="https://github.com/abseil/abseil-cpp/blob/master/absl/numeric/int128_benchmark.cc#L52">benchmarks</a> from abseil on Intel(R) Xeon(R) W-2135 CPU @ 3.70GHz show some horrible results</p>



<pre><code>Benchmark                       Time(ns)  CPU(ns)
BM_DivideClass128UniformDivisor     13.8     13.8  // 128 bit by 128 bit
BM_DivideClass128SmallDivisor        168      168  // 128 bit by 64 bit</code></pre>



<p>150 nanoseconds for dividing the random 128 bit number by a random 64 bit number? Sounds crazy. For example, <code>div</code> instruction on x86-64 Skylake takes 76 cycles (also, for AMD processors it is much less), the division takes around 20-22ns.</p>



<figure><img data-attachment-id="361" data-permalink="https://danlark.org/d2elnjfdkne/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png" data-orig-size="921,461" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="d2elnjfdkne" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=921" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png 921w, https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=768 768w" sizes="(max-width: 921px) 100vw, 921px"><figcaption><a href="https://godbolt.org/z/o2vTZr">https://godbolt.org/z/o2vTZr</a></figcaption></figure>



<p>In reality everything is slightly better because of pipeline execution and division has its own ALU, so if you divide something and do something else in the next instructions, you will get lower average latency. Still, 128 bit division cannot be 8x slower than 64 bit division. All latencies you can find in Agner Fog <a href="https://www.agner.org/optimize/instruction_tables.pdf">instruction table</a> for most of the modern x86 CPUs. The truth is more complex and division latency can even depend on the values given.</p>



<figure><img data-attachment-id="299" data-permalink="https://danlark.org/2020-06-14-182043_835x215_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png" data-orig-size="835,215" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-182043_835x215_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=835" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png 835w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=768 768w" sizes="(max-width: 835px) 100vw, 835px"><figcaption>Agner Fog instruction table for Skylake CPUs, the second but last column is the latency.</figcaption></figure>



<p>Even compilers when dividing by some constants, try to use the reciprocal (or, the same as inverse in a ring) value and multiply the reciprocal and the value with some shifts afterwards</p>



<figure><img data-attachment-id="315" data-permalink="https://danlark.org/2020-06-14-192300_861x251_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png" data-orig-size="861,251" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-192300_861x251_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=861" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png 861w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=768 768w" sizes="(max-width: 861px) 100vw, 861px"><figcaption><a href="https://gcc.godbolt.org/z/PRibsx">https://gcc.godbolt.org/z/PRibsx</a></figcaption></figure>



<p>Overall, given the fact that only some <code>sin</code>, <code>cos</code> instructions cost more than division, division is one of the most complex instructions in CPUs and optimizations in that place matter a lot. My exact case was more or less general, maybe I was dividing 128 bit by 64 bit a bit more frequent. We are going to optimize the general case in LLVM.</p>



<p>We need to understand how 128 bit division is working through the compiler stack.</p>



<figure><img data-attachment-id="303" data-permalink="https://danlark.org/2020-06-14-183125_682x238_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png" data-orig-size="682,238" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-183125_682x238_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=682" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=682" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png 682w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=300 300w" sizes="(max-width: 682px) 100vw, 682px"><figcaption><a href="https://gcc.godbolt.org/z/fB3aq2">https://gcc.godbolt.org/z/fB3aq2</a></figcaption></figure>



<p>It calls <code>__udivti3</code> function. Let’s first understand how to read these functions. In runtime libraries the modes of the functions are:</p>



<div><div>
<pre><code>QI: An integer that is as wide as the smallest addressable unit, usually 8 bits.
HI: An integer, twice as wide as a QI mode integer, usually 16 bits.
SI: An integer, four times as wide as a QI mode integer, usually 32 bits.
DI: An integer, eight times as wide as a QI mode integer, usually 64 bits.
SF: A floating point value, as wide as a SI mode integer, usually 32 bits.
DF: A floating point value, as wide as a DI mode integer, usually 64 bits.
TI: An integer, 16 times as wide as a QI mode integer, usually 128 bits.</code></pre>
</div></div>



<p>So, <code>udivti3</code> is an <strong>u</strong>nsigned division of TI (128 bits) integers, last ‘<em>3′</em> means that it has 3 arguments including the return value. Also, there is a function <code>__udivmodti4</code> which computes the divisor and the remainder (division and modulo operation) and it has 4 arguments including the returning value. These functions are a part of runtime libraries which compilers provide by default. For example, in GCC it is <a href="http://gcc.gnu.org/onlinedocs/gccint/Libgcc.html#Libgcc">libgcc</a>, in LLVM it is <a href="https://compiler-rt.llvm.org/">compiler-rt</a>, they are linked almost in every program if you have the corresponding toolchain. In LLVM, <code>__udivti3</code> is a simple alias to <code>__udivmodti4</code>.</p>



<figure><div>

</div></figure>



<p><code><a href="https://github.com/llvm-mirror/compiler-rt/blob/release_90/lib/builtins/udivmodti4.c#L20">__udivmodti4</a></code> function was written with the help of <code>Translated from Figure 3-40 of The PowerPC Compiler Writer's Guide.</code> After looking at it <a href="https://cr.yp.to/2005-590/powerpc-cwg.pdf">here</a>, it looks like this was written long time ago and things have changed since then</p>



<figure><img data-attachment-id="313" data-permalink="https://danlark.org/2020-06-14-191400_1038x718_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png" data-orig-size="1038,718" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-191400_1038x718_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=1024" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=1024 1024w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=768 768w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png 1038w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>First of all, let’s come up with something easy, like shift-subtract algorithm that we have been learning since childhood. First, if <code>divisor &gt; dividend</code>, then the quotient is zero and remainder is the <code>dividend</code>, not an interesting case. </p>



<figure><div>

</div></figure>



<p>The algorithm is easy, we align the numbers by their most significant bits, if dividend is more than divisor, subtract and add 1 to the output, then shift by 1 and repeat.  Some sort of animation can be seen like that:</p>



<figure><img data-attachment-id="318" data-permalink="https://danlark.org/simplescreenrecorder-2020-06-14_20-23-25/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/simplescreenrecorder-2020-06-14_20.23.25.gif" data-orig-size="918,442" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="simplescreenrecorder-2020-06-14_20.23.25" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/simplescreenrecorder-2020-06-14_20.23.25.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/simplescreenrecorder-2020-06-14_20.23.25.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/simplescreenrecorder-2020-06-14_20.23.25.gif?w=918" alt=""></figure>



<p>For 128 bit division it will take at most 128 iterations in the for loop. Actually, the implementation in <a href="https://github.com/llvm-mirror/compiler-rt/blob/release_90/lib/builtins/udivmodti4.c#L173">LLVM</a> for loop is a fallback and we saw it takes 150+ns to complete it because it requires to shift many registers because 128 bit numbers are represented as two registers.</p>



<p>Now, let’s dive into the architecture features. I noticed that while the compiler generates the <code>divq</code> instructions, it frees <code>rdx</code> register</p>



<figure><img data-attachment-id="362" data-permalink="https://danlark.org/2ugj4bgvw4x/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png" data-orig-size="891,206" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2ugj4bgvw4x" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=891" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png 891w, https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=768 768w" sizes="(max-width: 891px) 100vw, 891px"></figure>



<p>In the manual they say the following</p>



<figure><img data-attachment-id="322" data-permalink="https://danlark.org/2020-06-14-204644_860x119_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png" data-orig-size="860,119" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-204644_860x119_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=860" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png 860w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=768 768w" sizes="(max-width: 860px) 100vw, 860px"></figure>



<p><code>divq</code> instruction provides 128 bit division from [%rdx]:[%rax] by <code>S</code>. The quotient is stored in <code>%rax</code> and the remainder in <code>%rdx</code>. After some experimenting with inline asm in C/C++, I figured out that if the result does not fit in 64 bits, SIGFPE is raised. See:</p>



<figure><div>

</div></figure>



<p>Compilers don’t use this instruction in 128 bit division because they cannot know for sure if the result is going to fit in 64 bits. Yet, if the high 64 bits of the 128 bit number is smaller than the divisor, the result fits into 64 bits and we can use this instruction. As compilers don’t generate <code>div</code>q instruction for their own reasons, we would use inline asm for x86-64.</p>



<figure><div>

</div></figure>



<p>What to do if the high is not less than the divisor? The right answer is to use 2 divisions because</p>



<figure><img data-attachment-id="325" data-permalink="https://danlark.org/2020-06-11-135245_1608x410_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png" data-orig-size="1608,410" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-11-135245_1608x410_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=1024" alt="" width="780" height="198" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=1024 1024w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=777 777w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=1553 1553w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=768 768w" sizes="(max-width: 780px) 100vw, 780px"></figure>



<p>So, first we can divide <code>hi</code> by <code>divisor</code> and then <code>{hi_r, lo}</code> by <code>divisor</code> guaranteeing that <code>hi_r</code> is smaller than <code>divisor</code> and thus the result is smaller than <img src="https://s0.wp.com/latex.php?latex=2%5E%7B64%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{64}" title="2^{64}">. We will get something like</p>



<figure><div>

</div></figure>



<p>  After that the benchmarks improved significantly</p>



<pre><code>Benchmark                       Time(ns)  CPU(ns)
BM_DivideClass128UniformDivisor 11.9      11.9
BM_DivideClass128SmallDivisor   26.6      26.6</code></pre>



<p>Only 26.6ns for small divisors, that’s a clear 6x win.</p>



<p>Then there are multiple choices to do next but we know that both dividend and divisor have at least one bit in their high registers and the shift-subtract algorithm will have at most 64 iterations. Also the quotient is guaranteed to fit in 64 bits, thus we can use only the low register of the resulting quotient and save more shifts in the shift-subtract algorithm. That’s why the uniform divisor slightly improved.</p>



<p>One more optimization to do in shift-subtract algorithm is to remove the branch inside the for loop (read carefully, it should be understandable).</p>



<figure><div>

</div></figure>



<p>In the end, it gives 0.4ns more for uniform 128 bit divisor.</p>



<p>And finally I believe that’s one of the best algorithm to divide 128 bit by 128 bit numbers. From statistics, the case when the divisor is 64 bit is worth optimizing and we showed that additional checks on the high register of divisor has its own advantages and expansion of the invariants. Now let’s see what other libraries perform in that case.</p>



<h2>LibDivide</h2>



<p><a href="https://github.com/ridiculousfish/libdivide">Libdivide</a> is a small library targeting fast division, for example, if you divide by some fixed number a lot of times, there are techniques that can precalculate reciprocal and then multiply by it. Libdivide provides a very good interface for such optimizations. Even though, it has some optimizations regarding 128 bit division. For example, function <code>libdivide_128_div_128_to_64</code> computes the division 128 bit number by 128 bit number if the result fits in 64 bits. In the case where both numbers are more or equal to <img src="https://s0.wp.com/latex.php?latex=2%5E%7B64%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{64}" title="2^{64}"> it does the following algorithm that they took from <a href="https://www.amazon.de/Hackers-Delight-Henry-S-Warren/dp/0321842685/ref=sr_1_1?dchild=1&amp;keywords=Hackers+Delight&amp;qid=1592164234&amp;sr=8-1">Hackers Delight</a> book:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Bcases%7D+n+%3D+MSB%28%5Cmathrm%7Bdivisor%7D%29+%5Cgeq+1+%5C%5C+%5Cmathrm%7Bdivisor_1%7D+%3D+%5Clfloor+%5Cmathrm%7Bdivisor%7D%2F2%5E%7B64+-+n%7D+%5Crfloor+%5C%5C+%5Cmathrm%7Bdividend_1%7D+%3D+%5Clfloor+%5Cmathrm%7Bdividend%7D%2F2+%5Crfloor+%5Cend%7Bcases%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\begin{cases} n = MSB(\mathrm{divisor}) \geq 1 \\ \mathrm{divisor_1} = \lfloor \mathrm{divisor}/2^{64 - n} \rfloor \\ \mathrm{dividend_1} = \lfloor \mathrm{dividend}/2 \rfloor \end{cases}" title="\begin{cases} n = MSB(\mathrm{divisor}) \geq 1 \\ \mathrm{divisor_1} = \lfloor \mathrm{divisor}/2^{64 - n} \rfloor \\ \mathrm{dividend_1} = \lfloor \mathrm{dividend}/2 \rfloor \end{cases}"></p>



<p>With the instruction that produces the 64 bit result when the divisor is 128 bit result we can compute</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bquotient_1%7D+%3D+%5Clfloor+%5Cmathrm%7Bdividend_1%7D%2F%5Cmathrm%7Bdivisor_1%7D+%5Crfloor&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{quotient_1} = \lfloor \mathrm{dividend_1}/\mathrm{divisor_1} \rfloor" title="\mathrm{quotient_1} = \lfloor \mathrm{dividend_1}/\mathrm{divisor_1} \rfloor"></p>



<p>Then we compute</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bquotient_0%7D+%3D+%5Clfloor+%5Cmathrm%7Bquotient_1%7D%2F2%5E%7B63+-+n%7D+%5Crfloor&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{quotient_0} = \lfloor \mathrm{quotient_1}/2^{63 - n} \rfloor" title="\mathrm{quotient_0} = \lfloor \mathrm{quotient_1}/2^{63 - n} \rfloor">.</p>



<p>It cannot overflow because <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bquotient_1%7D+%3C+2%5E%7B64%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{quotient_1} < 2^{64}" title="\mathrm{quotient_1} < 2^{64}"> because the maximum value of <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bdividend_1%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{dividend_1}" title="\mathrm{dividend_1}"> is <img src="https://s0.wp.com/latex.php?latex=2%5E%7B127%7D+-+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{127} - 1" title="2^{127} - 1"> and minimum value of <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bdivisor_1%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{divisor_1}" title="\mathrm{divisor_1}"> is <img src="https://s0.wp.com/latex.php?latex=2%5E%7B63%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{63}" title="2^{63}">. Now let’s show that</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Clfloor+%5Cmathrm%7Bdividend%7D%2F%5Cmathrm%7Bdivisor%7D+%5Crfloor+%5Cleq+%5Cmathrm%7Bquotient_0%7D+%5Cleq++%5Clfloor+%5Cmathrm%7Bdividend%7D%2F%5Cmathrm%7Bdivisor%7D+%5Crfloor+%2B+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\lfloor \mathrm{dividend}/\mathrm{divisor} \rfloor \leq \mathrm{quotient_0} \leq  \lfloor \mathrm{dividend}/\mathrm{divisor} \rfloor + 1" title="\lfloor \mathrm{dividend}/\mathrm{divisor} \rfloor \leq \mathrm{quotient_0} \leq  \lfloor \mathrm{dividend}/\mathrm{divisor} \rfloor + 1"></p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bquotient_0%7D+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B2%5E%7B64+-+n%7D%5Cmathrm%7Bdivisor_1%7D%7D+%5Cright%5Crfloor+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B2%5E%7B64+-+n%7D%5Cleft%5Clfloor%5Cfrac%7B%5Cmathrm%7Bdivisor%7D%7D%7B2%5E%7B64+-+n%7D%7D%5Cright%5Crfloor%7D+%5Cright%5Crfloor+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B%5Cmathrm%7Bdivisor%7D+-+%28%5Cmathrm%7Bdivisor%7D+%5Cmathrm%7B%5C+mod%5C+%7D+2%5E%7B64+-+n%7D%29%7D+%5Cright%5Crfloor+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B%5Cmathrm%7Bdivisor%7D%7D+%2B+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%28%5Cmathrm%7Bdivisor%7D+%5Cmathrm%7B%5C+mod%5C+%7D+2%5E%7B64+-+n%7D%29%29%7D%7B%5Cmathrm%7Bdivisor%7D%28%5Cmathrm%7Bdivisor%7D+-+%28%5Cmathrm%7Bdivisor%7D+%5Cmathrm%7B%5C+mod%5C+%7D+2%5E%7B64+-+n%7D%29%29%7D+%5Cright%5Crfloor+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B%5Cmathrm%7Bdivisor%7D%7D+%2B+%5Cdelta+%5Cright%5Crfloor&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{quotient_0} = \left\lfloor \frac{\mathrm{dividend}}{2^{64 - n}\mathrm{divisor_1}} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{2^{64 - n}\left\lfloor\frac{\mathrm{divisor}}{2^{64 - n}}\right\rfloor} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor} - (\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n})} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor}} + \frac{\mathrm{dividend}(\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n}))}{\mathrm{divisor}(\mathrm{divisor} - (\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n}))} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor}} + \delta \right\rfloor" title="\mathrm{quotient_0} = \left\lfloor \frac{\mathrm{dividend}}{2^{64 - n}\mathrm{divisor_1}} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{2^{64 - n}\left\lfloor\frac{\mathrm{divisor}}{2^{64 - n}}\right\rfloor} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor} - (\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n})} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor}} + \frac{\mathrm{dividend}(\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n}))}{\mathrm{divisor}(\mathrm{divisor} - (\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n}))} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor}} + \delta \right\rfloor">.</p>



<p>Now we want to show that <img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3C+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\delta < 1" title="\delta < 1">. <img src="https://s0.wp.com/latex.php?latex=%5Cdelta&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\delta" title="\delta"> is the largest when the remainder in the numerator is as large as possible, it can be up to <img src="https://s0.wp.com/latex.php?latex=2%5E%7B64+-+n%7D+-+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{64 - n} - 1" title="2^{64 - n} - 1">. Because of the definition of <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="n" title="n">, <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bdivisor%7D+%5Cgeq+2%5E%7B127+-+n%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{divisor} \geq 2^{127 - n}" title="\mathrm{divisor} \geq 2^{127 - n}">. The smallest value of <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bdivisor%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{divisor}" title="\mathrm{divisor}"> in the denominator is <img src="https://s0.wp.com/latex.php?latex=2%5E%7B127+-+n%7D+%2B+2%5E%7B64+-+n%7D+-+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{127 - n} + 2^{64 - n} - 1" title="2^{127 - n} + 2^{64 - n} - 1">. That’s why</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5Cleq+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%282%5E%7B64+-+n%7D+-+1%29%7D%7B%282%5E%7B127+-+n%7D+%2B+2%5E%7B64+-+n%7D+-+1%292%5E%7B127+-+n+%7D%7D+%3C+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%282%5E%7B64+-+n%7D+-+1%29%7D%7B%282%5E%7B127+-+n+%7D%29%5E2%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\delta \leq \frac{\mathrm{dividend}(2^{64 - n} - 1)}{(2^{127 - n} + 2^{64 - n} - 1)2^{127 - n }} < \frac{\mathrm{dividend}(2^{64 - n} - 1)}{(2^{127 - n })^2}" title="\delta \leq \frac{\mathrm{dividend}(2^{64 - n} - 1)}{(2^{127 - n} + 2^{64 - n} - 1)2^{127 - n }} < \frac{\mathrm{dividend}(2^{64 - n} - 1)}{(2^{127 - n })^2}">. As n iterates from 0 to 63, we can conclude that <img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3C+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B2%5E%7B128%7D%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\delta < \frac{\mathrm{dividend}}{2^{128}}" title="\delta < \frac{\mathrm{dividend}}{2^{128}}">. So we got either the correct value, either the correct plus one. Everything else in the algorithms is just a correction of which result to choose.</p>



<p>Unfortunately, these corrections increase the latency of the benchmark pretty significant</p>



<pre><code>Benchmark                                          Time(ns)  CPU(ns)
BM_DivideClass128UniformDivisor&lt;LibDivideDivision&gt;    26.3    26.3  
BM_RemainderClass128UniformDivisor&lt;LibDivideDivision&gt; 26.2    26.2
BM_DivideClass128SmallDivisor&lt;LibDivideDivision&gt;      25.8    25.8
BM_RemainderClass128SmallDivisor&lt;LibDivideDivision&gt;   26.3    26.3</code></pre>



<p>So I decided to drop this idea after I’ve tried this.</p>



<h2>GMP</h2>



<p><a href="https://gmplib.org/">GMP</a> library is a standard GNU library for long arithmetic. They also have something for 128 bit by 64 bit division and in my benchmark the following code worked</p>



<figure><div>

</div></figure>



<p>It divides the two limbs by a <code>uint64_t</code> and provides the result. Unfortunately, the latency is much higher than expected, also does not work</p>



<pre><code>Benchmark                                          Time(ns)  CPU(ns)
BM_DivideClass128UniformDivisor&lt;GmpDivision&gt;          11.5    11.5
BM_RemainderClass128UniformDivisor&lt;GmpDivision&gt;       10.7    10.7
BM_DivideClass128SmallDivisor&lt;GmpDivision&gt;            47.5    47.5
BM_RemainderClass128SmallDivisor&lt;GmpDivision&gt;         47.8    47.8 </code></pre>



<h2>Conclusion</h2>



<p>In the …</p></div></article></main></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://danlark.org/2020/06/14/128-bit-division/">https://danlark.org/2020/06/14/128-bit-division/</a></em></p>]]>
            </description>
            <link>https://danlark.org/2020/06/14/128-bit-division/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888177</guid>
            <pubDate>Sun, 19 Jul 2020 09:40:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CloudFront Analytics]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23888170">thread link</a>) | @kayza
<br/>
July 19, 2020 | https://markmcgranaghan.com/cloudfront-analytics | <a href="https://web.archive.org/web/*/https://markmcgranaghan.com/cloudfront-analytics">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">





<p>2019-10</p>

<p>You’re reading a <a href="https://brandur.org/aws-intrinsic-static">static website</a> stored in S3 and served out of CloudFront. I recently set up web analytics for it with:</p>

<ul>
<li>CloudFront access logs stored in S3</li>
<li>The <a href="https://aws.amazon.com/athena/">AWS Athena</a> analytics engine running SQL queries on that data</li>
</ul>

<p>I now get analytics with flexible SQL queries:</p>

<p><img src="https://markmcgranaghan.com/assets/cloudfront-analytics/athena-demo.png" alt="Athena demo"></p><p>This proved a solid approach. There’s no software I need to manage, no client-side JavaScript, and no third-party providers beyond AWS. Here’s how I set it up and use it.</p>

<h2>Sending CloudFront logs to S3</h2>

<p>First we need to store CloudFront access logs in S3. As a bonus, we’ll have this raw data if we want to analyze it outside of Athena later.</p><p>Ensure you have an S3 bucket to use for logs. I use one bucket for all my sites, with a directory for each site:</p>

<p><img src="https://markmcgranaghan.com/assets/cloudfront-analytics/cloudfront-logs-index.png" alt="CloudFront logs index"></p><p>Then in the CloudFront distribution for your site, enable access logging into that bucket (and into the appropriate directory if you’re using that setup):</p>

<p><img src="https://markmcgranaghan.com/assets/cloudfront-analytics/cloudfront-logs-enabling.png" alt="CloudFront logs enabling"></p><p>Cloudfront will deposit access logs in that directory every few minutes, assuming you have non-zero traffic. Here’s what mine look like:</p>

<p><img src="https://markmcgranaghan.com/assets/cloudfront-analytics/cloudfront-logs-listing.png" alt="CloudFront logs listing"></p><p>If you download, decompress, and view one of those files, you’ll see lines of tab-seperated data, one per request to CloudFront. Each line will have the request URL, HTTP method, referrer, and so on.</p>

<p>The appeal of the Athena approach is that you can run SQL queries <em>directly against these compressed log files</em> in S3 with <em>standard SQL</em>. Let’s look at that next.</p>


<h2>Querying web access logs in Athena</h2>

<p>Now head over to Athena in the AWS console and create a database to use for your CloudFront analytics. I called mine “cloudfront”:</p>

<p><img src="https://markmcgranaghan.com/assets/cloudfront-analytics/athena-database-ddl.png" alt="Athena database DDL"></p><p>Create a table that points to your data in S3, using <a href="https://docs.aws.amazon.com/athena/latest/ug/cloudfront-logs.html">this query template</a>, with your S3 location sub’d in. This query also shows the fields you’ll have access to in your SQL queries:</p>

<p><img src="https://markmcgranaghan.com/assets/cloudfront-analytics/athena-table-ddl.png" alt="Athena table DDL"></p><p>That’s it, you’re ready to run some queries. Here’s one I use to measure total monthly traffic to the site:</p>

<p><img src="https://markmcgranaghan.com/assets/cloudfront-analytics/athena-results.png" alt="Athena results"></p><p>Note that even though this query covers data from thousands of individual compressed files in S3, it runs in a few seconds.</p>

<p>You should carefully examine your data to be sure you’re getting the right results. For example some requests are from <a href="https://support.google.com/webmasters/answer/182072?hl=en">Googlebot</a> and you may want to exclude those from your queries.</p>

<p>Overall I’ve been very happy with this analytics setup. I recommend it for anyone running a static site looking for basic analytics without the downsides of client-side JavaScript, additional third parties providers, or more software to run themselves.</p>

<p>If you have thoughts on the setup, <a href="https://markmcgranaghan.com/contact">send</a> them over!</p>



</div></div>]]>
            </description>
            <link>https://markmcgranaghan.com/cloudfront-analytics</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888170</guid>
            <pubDate>Sun, 19 Jul 2020 09:38:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Magic Compiler (2017)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23887810">thread link</a>) | @thallavajhula
<br/>
July 19, 2020 | https://iam.mt/magic-compiler/ | <a href="https://web.archive.org/web/*/https://iam.mt/magic-compiler/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="mainContentOfPage">
		
<p>Innovation in today’s technology is mostly around Artificial Intelligence (AI) and its sub topics such as Machine Learning (ML) and Natural Language Processing (NLP). There is a primary focus on NLP and ML among all the tech companies. This is for a good reason. Tech companies are using NLP and ML in various aspects of their offerings and trying to stay ahead of their respective competitors.</p>



<h3 id="&quot;a-magic-compiler&quot;">A Magic Compiler</h3>



<p>With all of this going on, I feel like NLP &amp; ML will greatly impact the future of programming and programming languages. It could be possible to create a programming language out of pure English (or any language for that matter) grammar. Alright, stay with me here for a second; the way it could work is:</p>



<ul><li>The programmer would write what they want to achieve in English<code>Store user data such as name, age, sex, address and favorites in the database and create an endpoint that exposes this data securely</code></li><li>Using NLP, the compiler parses this information and creates or uses the existing <code>User</code> class and stores the user attributes such as <code>name</code>, <code>age</code>, <code>sex</code>, <code>address</code> and <code>favorites</code></li><li>The compiler keeps correcting itself over the extended usage of the programming language using ML. The compiler figures out the datatype of the attribute. For ex: <code>name</code> is a <code>String</code>. <code>age</code> is an <code>Integer</code>. Since the attribute is named <code>favorites</code>, it figures that it’s a collection of <code>String</code>s. Since the programmer instructed the compiler to expose an endpoint with the data securely, we get an <code>https</code> endpoint to access the resource.</li></ul>



<p>The programmer can then do something like –<br><code>Every user has many photos. Store those photos in Amazon's S3 (maybe) bucket</code></p>



<p>A programming language like this could become a reality. Of course, this is a massive over-simplification of things, but, it could be possible. I mean, if human beings are capable of making computers perform intellectual tasks, this could totally be possible.</p>



<p>This can also be taken one step further and use speech to text conversion. Programmers can then just speak what they want to build and have the compiler write the code for them.</p>



<p>The advantage to creating something like this is extensibility. Imagine if every person who can speak a language can write code? Any person that can read/write a language, ends up being able to write plugins/extensions/modules in their language and contribute. There’s a lot of smart people out there and this programming model extends their creativity. Right now, it’s just a missed opportunity. It would be amazing to see what people do with their “newly acquired” skill.</p>



<h3 id="&quot;domain-specific-languages-dsl&quot;">Domain-specific languages (DSL)</h3>



<p>Today, one can do something remotely similar by using Domain-specific languages (DSLs). But, DSLs are very restricted and don’t offer much in terms of flexibility in their usage. Hence, a proper implementation to support the above mentioned features would be required.</p>



<p>This would be a very interesting project to work on. I will continue research around this subject and see if I can come up with a trivial implementation of this.</p>


		
									</div></div>]]>
            </description>
            <link>https://iam.mt/magic-compiler/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23887810</guid>
            <pubDate>Sun, 19 Jul 2020 08:02:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The misconceptions about a programmer’s life]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23887809">thread link</a>) | @URfejk
<br/>
July 19, 2020 | https://expertain.net/the-misconceptions-about-a-programmers-life/ | <a href="https://web.archive.org/web/*/https://expertain.net/the-misconceptions-about-a-programmers-life/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>There are a lot of articles from beginner programmers wondering what programming is like, and I think it’s useful to address those issues. There are a lot of misconceptions about a programmer’s life.</p>
<p>The summary of most of this is that understanding the concept of technical debt is important.</p>
<p>The needs and culture of a company are probably larger contributors to technical debt than individual developer skills. But it all plays an important role in how much the system smells, how much documentation is missing, and what a given developer does in their day-to-day. By understanding the concept one can attempt to mitigate it. But some people may be programming for 8 hours a day, not documenting a thing, and unknowingly increasing the maintenance costs of the system for everyone who will ever work on the system.</p>
<p>These are the most common misconceptions about a programmer’s life:</p>
<ol>
<li>You program 8 hours a day at work</li>
<li>A program is about programming</li>
<li>Since I wrote the code, my opinion matters most</li>
<li>The program matters</li>
<li>Every software shop is the same</li>
<li>We’ll rewrite everything</li>
<li>I only have to understand one programming language</li>
</ol>
<h4><strong>You program 8 hours a day at work</strong></h4>
<p>This is probably the least true of all the things. Most programming jobs are maintenance jobs. The programs have all mostly been written years ago, and you are doing support, minor enhancements, bug fixes. Even if you get to do more than that, you are still not likely coding a large part of your day. It’s about meetings to decide what to do. This is probably one of the most common misconceptions about a programmer’s life.</p>
<p>Also, from my experience, unless you have some reason to dig deep into code (esp. if the code base is large), most people don’t bother. Our codebase is old and rickety. There aren’t any comments. The business process isn’t exactly documented. I don’t want to wade through 2000 lines of Java code (per Java file) and try to understand the business behind it.</p>
<p>Unless you’re working in a brand new project that needs a lot of code written (which I’ve been in), you are probably not doing a lot of programming.</p>
<div id="attachment_2721"><p><img aria-describedby="caption-attachment-2721" src="https://mlfmfvgwe2uw.i.optimole.com/V673Rh4-7p4lbGfd/w:2000/h:1125/q:auto/https://expertain.net/wp-content/uploads/2020/07/Students-enjoy-computer-science-and-arts-the-most.png" alt="Students enjoy computer science and arts the most!" width="2000" height="1125" data-opt-src="https://mlfmfvgwe2uw.i.optimole.com/V673Rh4-7p4lbGfd/w:2000/h:1125/q:auto/https://expertain.net/wp-content/uploads/2020/07/Students-enjoy-computer-science-and-arts-the-most.png" data-old-src="https://mlfmfvgwe2uw.i.optimole.com/V673Rh4-7p4lbGfd/w:2000/h:1125/q:eco/https://expertain.net/wp-content/uploads/2020/07/Students-enjoy-computer-science-and-arts-the-most.png"></p><p id="caption-attachment-2721">Students enjoy computer science and arts the most!</p></div>
<h4><strong>A program is about programming</strong></h4>
<p>I work at a university. Students, esp. computer science students, complain about our old system that runs a “batch style” programming system. That is, the system shuts down overnight, does a bunch of data processing, and opens again in the morning. They wonder why the system can’t be Facebook or Google or YouTube and be up 24 hours a day.</p>
<p>First, I think many such people would be surprised how many people (or really, how few people) are supporting these systems. You’d think there’s a team of 20 developers doing the best they can to keep this stuff running, and it’s like a well-oiled machine, but sometimes it’s less than half a dozen people, and we barely know the software’s purpose, but can do minor fixes and keep stuff running.</p>
<p>Most software out there isn’t, as they say, rocket science. Sure, a few exceptions (say, SpaceX software). Most of the software encodes business practices, and most business practices are a weird arcane set of rules that have no basis in math or science but is just how some company works. You write that in code, no matter how illogical it is. And often, the code and a few old-timers’ memories are what holds the project together.</p>
<p>Definitely one of the most common misconceptions about a programmer’s life.</p>
<h4><a href="https://expertain.net/what-it-was-like-learning-programming-in-the-early-1970s/">You might also like: What it was like learning programming in the early 1970s.</a></h4>
<h5>Programmers had one purpose: get the program to work.</h5>
<p>Comments? Hah! A written business process? Hah! Programmers had one purpose: get the program to work. They didn’t think about who would maintain the code after they retired. The only saving grace was their background wasn’t so sophisticated as to create true spaghetti code (let’s use regular expressions and finite state machines and design patterns up the wazoo!).</p>
<p>It’s often not the coding language (like Cobol) that prevents modernization (although it’s partly that), it’s that the business process was never formalized, and there are 100,000 lines of code no one wants to read (and only represents an&nbsp;<em>approximation</em>&nbsp;of what the people who wanted the code wanted—and they’re retired too!).</p>
<p>I often point out the scene in the third Matrix movie where the councilman is talking to Neo about how these machines support their underground city, yet no one quite knows who built it or how it works. That’s a lot of software out there.</p>
<div id="attachment_2735"><p><img aria-describedby="caption-attachment-2735" src="https://mlfmfvgwe2uw.i.optimole.com/V673Rh4-kAn4WUUa/w:729/h:635/q:auto/https://expertain.net/wp-content/uploads/2020/07/Most-wanted-programming-languages-in-2020.jpeg" alt="Most wanted programming languages in 2020" width="729" height="635" data-opt-src="https://mlfmfvgwe2uw.i.optimole.com/V673Rh4-kAn4WUUa/w:729/h:635/q:auto/https://expertain.net/wp-content/uploads/2020/07/Most-wanted-programming-languages-in-2020.jpeg" data-old-src="https://mlfmfvgwe2uw.i.optimole.com/V673Rh4-kAn4WUUa/w:729/h:635/q:eco/https://expertain.net/wp-content/uploads/2020/07/Most-wanted-programming-languages-in-2020.jpeg"></p><p id="caption-attachment-2735">Most wanted programming languages in 2020</p></div>
<p>Writing from scratch is not such a common experience (at least, from my perspective), and even when you do, it’s not always as organized as it could be. We may call it software engineering, but most engineering involves others looking at your work, and having input into fixing it. Code reviews aren’t the same thing as people inspecting a building and seeing it every day.</p>
<p>We often don’t rewrite things because the rewrite would be huge, would require a bunch of new developers, and doesn’t even have the support of the people we’re writing it for.</p>
<h4><strong>As a programmer, since I wrote the code, my opinion is the most important</strong></h4>
<p>OK, so you may&nbsp;<em>know</em> to program, but do you know the business you’re working in? Many a programmer or startup guy thinks “You guys do something dumb, and I’m smart, so I can easily create a system that’s 10 times better than the crap you use. And you know what? I’m not even going to consult you about how the system&nbsp;<em>should</em>&nbsp;work. I’ll make up my own. You are such&nbsp;<em>idiots</em>!”.</p>
<p>Well, that maybe, but they’re used to the system they are used to, and they’ve thought about their own (arcane) business process for a long time, and if you build something that is completely different from what they are used to, they won’t say “oh, we lack the intellect to understand your truly great software”, they’ll just not use your software.</p>
<p>If your user base is a bit older, and possibly, even if they aren’t, they will be used to doing things in a certain way. Maybe you can convince them that way isn’t smart, but if they questioned your lack of comments, your lack of coding structure, how what you wrote seems like gibberish, you might get defensive as well. This is also one of the most common misconceptions about a programmer’s life.</p>
<p>The point is that you’re often writing software or maintaining software by those who use the software every day. As a programmer, you might even have the luxury to walk away after you write code, never having used the code as your users use them, and they may ultimately hire someone new who maybe pays attention to what they actually want, even if you think it makes no sense.</p>
<h4><strong>The program matters</strong></h4>
<p>Many of you are learning to program. You think companies are willing to throw out a million line codebase because it’s&nbsp;<em>written in an obsolete language</em>. Who’s going to write it? You? (You, Mr. Wineburg?)</p>
<p>A million lines of code is something that could take a lifetime to rewrite. Do you plan to read the code to understand what it does? Could you even do that?</p>
<p>In any case, sometimes people think the program is king (or queen, or some elected position). It’s not.</p>
<p>It’s the data.</p>
<p>Say you’ve run this legacy program for more than a decade. It fills up tables and tables of data. You, being a person who hates legacy code, wants new DB tables, and new ways of storing information.</p>
<p>Here’s the problem. What do you do with all those old data? Oh, you want to throw it out? Start new? <em>Brilliant!</em></p>
<h4><a href="https://expertain.net/the-best-way-to-learn-how-to-code/">You might also like: The best way to learn how to code</a></h4>
<h4><strong>Every software shop is the same</strong></h4>
<p>If you look at the world of practicing doctors, they seem to fall (roughly) into two categories: those working in hospitals on patients that need somewhat urgent care (or are doing elective surgery), and doctors with private practices. One of the most common misconceptions about a programmer’s life (and the weirdest one!).</p>
<p>Both seem to follow a similar structure so that if you went from one personal care doctor to another, their structure would be about the same (waiting room, receptionist, files, someone to check your insurance, collect your copay). If you go get your car repaired at a mechanic, you expect a similar experience. If you go to a grocery store, you expect a similar experience.</p>
<p>People in the software industry have nothing close to this. Each company may have widely varying setups. There are companies with just one program that does everything. Could you run a grocery store with just one person? (Well, maybe if it’s a tiny one-person operation selling very few items). Or a doctor’s office (probably not because of insurances, unless you’re some kind of boutique doctor that makes home visits, and even then, I suspect you hire someone to do the billing, etc).</p>
<h5>The big companies can afford to have their own internal support structure that makes it easier for their average developer to deploy code.</h5>
<p>That support structure is often an internal thing, not an off-the-shelf, any small company can do it. If you were a car mechanic and wanted to open your own small shop, you’d probably know exactly what you need (at least, the very basics). These things probably have been (roughly) the same for decades, and even the new things, people probably generally agree on what is needed.</p>
<p>But if you’re a small software shop…there’s no such standards. Do you want to use Atlassian tools? Or do you use a spreadsheet or emails? Do you use some kind of company email? Or do you use personal email? There are lots of decisions, and it’s hardly standardized in the industry.</p>
<p>You may think, say, version control is important. I guarantee there’s some software out there (maybe rare), that doesn’t use standard version control, and it probably does something important. And the people maintaining it may not even understand what version control is and why you need it. I’m serious.</p>
<p>It’s like going to a surgeon with a bottle of whiskey and a bowl of leeches and they say “What’s anesthetic?”</p>
<h4><strong>We’ll rewrite everything!</strong></h4>
<p>“I know engineers, …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://expertain.net/the-misconceptions-about-a-programmers-life/">https://expertain.net/the-misconceptions-about-a-programmers-life/</a></em></p>]]>
            </description>
            <link>https://expertain.net/the-misconceptions-about-a-programmers-life/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23887809</guid>
            <pubDate>Sun, 19 Jul 2020 08:02:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning representations by back-propagating errors (1986) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23887808">thread link</a>) | @ilaksh
<br/>
July 19, 2020 | https://www.iro.umontreal.ca/~vincentp/ift3395/lectures/backprop_old.pdf | <a href="https://web.archive.org/web/*/https://www.iro.umontreal.ca/~vincentp/ift3395/lectures/backprop_old.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>+;+Ø
ºë²»§3ÙÝžy_œWev”Q]uÑ]p|Wß8®ÁÅÙ]w&lt;ì€—eÛ»C°�à&nbsp;hnqX˜%‹c _“¸x.A‹‚È¬v¤U´Ï�Â™xv^N‡C¡Õ„²�Ùáá 'ÎË
ÎÊÂ›óºì®áeëóÌõÙ]¯¬³¶9Å˜}÷ÃÑå~xûÊ,¯Ê+âvEu×gžWÃwÖc»®Î2(¯¹Ðõ¸®¹Ú(±¼ç¸�äCìY€Ôˆ�ÏZŠ‡gÇ‡‡ó‘s™èxxs=DsÐðð�9qÌìø¬ìø!²Jìïþîßõ~y]&lt;ûÏ^ùå/È:'ì!ì¯»¾²�¼¯»1ÍW]žy\9År+³ºë³OÝ×]œV®†z+®{W_‘Ö9ÔŒ=Ì7gÅC²ÃÂ³ð…Êg¡áALë�ge‡Gg…3²Â³Ãñ
’yÝv8²®ï&lt;¯Ê$yåv³±ì³‰ÚnßºÑyÝßÅ•ùÞv;¿»ú‹¸‡(®#»;®»*ûãË;²Ž�*®ÅW_DYç &nbsp;Ú‘¹�v|T;&gt;&gt;x“9�g‡‡3nA�–».9�Ÿ�™ÆlN»;ú¿¤ÿW]u÷#Ë;ª1Ï«¯G–�såuýeÜ}]tTÆy]vQeüÈ®ÎìîÃÖvþW_Ô	S¸ÿyÍdGÔR
©;&gt;àìøÎvXxx}�3ÃÃ™£÷ááùÙaMáaáÙÚó6IÝuÙ]Ú{&lt;ò¿+³{+®©Ãï¸‘g¡»É?•×÷ÖQgžQSåœ&lt;îÊ#×Ývw]Å¦âåœ&lt;&nbsp;wŒãýCÁä‹«ä;R#¸&lt;œœ|T;&gt;&lt;&lt;&lt;†Ž…•ž&lt;)—oû‚îÎËÎË
g��Éù³bu×]ž]D‡t;®¿ÑeuÕ8¾ºëî»ZW¢Ï(»ë(²ºû©Œ¯Êì¢î#×"»;®ÎŒ3úºîñÞÅu.¯Î,Èº‡ PÚ�ùð&lt;öT;,&lt;;,€Êƒw‡g…B¹ÿvWYÙaù8øæxùñÙÅìØ›‡Øï.€�î‡¶9Elu¥×[Ýv´_‡�emî»Ê,¯Êèž¹W]”Y]O0û®Ï;�áõuÙN�’(ñÓï;¯È�«ä;øp/�ÇÀàp:áŽ|G,‚²ÂpbÌzÏ�ž”\Í‰¸nx&lt;&gt;‚Cƒw‹Ã³ÓÏŽ‹ç¥Š‡&gt;¢ÃâìHcÄW]nëpá�]q×]uØ¯Ö‡Õ×e
è®£‹+Þê+¯È‹+¤
;p~ØêÄÁ\p,aŠÄ&nbsp;NÁ(ð[‹‚ÀƒŽÅ�yŽ\7�èvl±bM©�ªC¨X‡X±­¦‡_Ž‡C¬CöêX¦ááY¹ê³™áÃ³sáxK	ƒ±PàáØXcƒv@HpáÁE¥¸wCz(c´1ÎÄw”8¡ÜEu¹€Â•it‘bN­Zt:µŠÓ¡Õ‚õã¡äÉïÇ*˜ã8ðW‹
ÏŠÄáf7‡e*SB‹Luhuhu”!ù�èt:èt:rò!ÁÃáx\šCs‡f8µwû‡bXðRXìà$vÛ�(®©˜š©j†-PÒä:|ðêŠ;C¡ÿ6nŠjÐëT…ˆ~ën‡ÇÃã×{Ã±,#˜cÃ� ®ÇCã’™µÅ’…ZQ¤+–È”Í¶@®["S6Ù¹l�PÙ¢›A@®Z1Ðä¨lÑTÐP+‚!Ãª
¶€\-ÇD�tê©&nbsp;4Í2�¦b™ª¤&amp;É±¶¹UÄO«‘tl`ZBm$6×*¸j*¢Ûf°Ý‰Ñ°ÀØR‚�úªtÏ~Ís
H[Î%Qm³VqV;´P±È/d®4‰Ã=ªûuÞ%Qm³Xjã6N; Ô‡ SdB{f²¶žÚ­¹ã]P·�¢1Ó�†ÂŒ(Õ@¤ÉAx°®Ä9ÁLuÃ«;Ëöc´æ…ø¿ç¿Æºñ[!8ÆÒØ"\XvamPä-ù2Nì[Çpàc§Ç;1Þ£‚�l¬v.¢à®-A8[=JØçï‡u‰:ƒ®ºÏWžˆeÉÒ|¥²ÙqPØQš¡ÈV™²}žpÞz�ÑE–»Ðî¿,¢‰ú¨ìG‡uÆ9Áê8cÁ]Ûð°%b[‡¡ÀœZ��
è2ñþC¡Î´:‡S~�³èuÊ×³©¥hu%PØQ…¡ÈW£d�•ðÞ§—NâÎ®žWçÔQÚ«ºØêøz¸wå|+1ÐõñEW]sÖâ¬$8zXáÞ‡ï0�,	XLÅ�`[	gc�xL)*ÂØQª…c¦J}ØG©gÂE–´ôY`�WgðçUtY_UJè�Å|Wgs¸û¯Êëõ»ºøµ®Š'óyEK
ÝAoŠz(�ÀX8!ÎÂÄ=%@ØQ…¡ÈRdupèu‡ÕÝ:]�Oó�Ù‡&nbsp;Â]ðJ¼¢î*éýÀ‘£Îëîê²Î:¬®¸sÓå}Ô%u.¯­Ý|8c¨®‰Ü8qtê+­Å}©*ÂˆrÁqÖC•ä@üí<!--~:1Ž†-Uhº!²û¼‚¿¾ÏõQ_ðöy «î‚yGóÕŸ}<:£=�÷‡¯î¿¼ãªï8	¦w}�K¼«­¸H¿£ïî.ºÊë¢’À�ì(ÄƒN	á'Ž°Ç¾Áè%<O~1þÐ]„C§X¦‡‡TS\‡Ÿn¥÷pnë»=˜ÇQåž�Z<»Q]Q§+²|ùë®¾—u]äý~W_j®egÆO=ÕéþáŽîê�"ê-->»êüî’Àì(�xY'',89ÐxvbðÌt;à1ËÃÇqØcÃÁŽn7|'s€­Ô¬¯×»&gt;¯‹2ýù_ŸzÚÑ÷ÐJè»ˆC»8Ï£Îû�å_ßwwD^Éì&lt;2u.ò¯éò&gt;©¢éî²þë¬¤¨;
&gt;xYŒ&lt;;x|íáÜ&nbsp;ð&lt;Ÿ;&gt;v;;&lt;	e�Œ;vïƒÀ{8|ÍÍº“ºèŸ¾ü¹ÄöZ«žÊÙ_=+³ÿ:¼¢îòõÙÅŠ,ÞÎëñE•V\uÙ]y¸æì•Ôºº§“Èú¦GÝÙeÕùaILv|xyŒ&lt;;8,;;;‚žw�ŽÊÞ&lt;&lt;&lt;;&gt;:�žÊÞ€öìø+¼›©…�Š¾Â‡Gæ9Ä:±^‹Xr‡ÌwUü¡Žƒï¿(¢†ôW]uñgU—Ã&lt;®‹=+¢�{Ê*]]_ÜGº¤{¸ºÇ•×Ò’˜ì-ñáD!ó³³Ç�jÊ;|xxvpVxxvXt&gt;;;&lt;1�,d;ƒÇÁ]öÝPLË‚h;8	�j	‚jàà%˜s×E‚Ø°áÅbCªîœžÊëc½+¢Žø£îª—WUeuñ}¸C«ò¿®²¿(YÉLv||qˆ&lt;(xxúÃ�YááÌ°ððíÙYááÙñÐð¬&nbsp;ðÓ��•¬;VøðãƒÌÚ×ãÖ‡íÍ�‡Nµ.±­cèuc®C™Tàì|a‹bùqA¹¹Øð%BÒNpáÀº›…ÃswUçnÞ®‰„ƒ‡uÙs¿+£¾9Â‹1‡nÊÏCw8x{Êe‡‡…ÏË
³³³AÌ°ðæX™kSCª*ÐÿèuD:Ä:ºïCªc¡Ðê²&gt;!¹¹ØênÇmÍñÕW
Î¡8v|&lt;„Ãsá-Ã�aÈ°vø°ãxG�afÏÊgÅg„‚³Ãä:²ã¡áYÙá§8Ý�b´w°¼„!ˆuËë•�¡Ðêê±žçLuìu‚ñ¹øðâ�Û‘`ì(°üÇËžÄ³Ð,ÃÁYYL°ð¬¨&gt;xhC�
g‡‡g†œ1ƒ™ñáÐF‹öÈÖ,–øCHJ‘`ì-ñp¥Ïç+ Ãø\&lt;;)Ÿž1Ëš1ËŽe…g‡la�‡XG9–™Â4öXrx¯J÷”‹aGÇ1—&lt;+vvA›Ÿ…ÃÃ²™aYáegô+|^XVXíŒ=ç3â³@�½–9^W­ÛÊE€°¢Ã¡&lt;;;&lt;0ÎáÙLøð¬­Û˜”8,:Ÿ„zÎgÅf­¸ëe¨u+Ê�eîù€ÂÞáÙÙáp`ÏÊe‡‡‡ggðî‡gÇGÅgâƒ=ç2Â³Ðm!#Z5Ô€aGÌì!áÁYàó³³.xð¦|xxvìçêv|S&lt;+?@DAP¦|xù´Ä’ê€°¢³;xìÁ»³²PxGxøðà&nbsp;²¨àxt&lt;++€‹»4smrà°¡Ž‡dA9ð/aðìc
îÏŠÝ†1êÙ?…gŒ¡Ùèxøþö×.;
	ÂŽ&gt;	8•‚`”àœ¸cˆ…e`âÀèH¬ð½ãn·ì¬¶´šÀaKëMGw‡1ØG°ü‚ÐŠ
Ã78®+‚ãØœ%x¸ÝiìjãÚÔ¶‡D{*ÆÑº°•=Ú+IÎÕ-éi
v9¿£ÁQØõ‚ãá8DÄÀ­ÒžÆ¬±l•­3½”ÀobvÊ’óSÚ¡©˜cvªZ­h4ÝcïcvC~ÒKMÊ`;bobíy€�½µCR18|t9nÃàw{w‰{I¥H”-Ít5ìRÙD¼ÀNßÚ©�Ô‹q7yh�¤èt*î¶“J‘÷?-§JVÊ%æ2sÚ©©Ü‹o"7;‹e&nbsp;ò‚Òƒóáá»»�èFBzŸˆuŠÓª$™‹}g´ú–W
zY“ä2qvªjF6én#ÆãW	�îˆvD;�`Q‡‚Ø¶NíÀŽ0Ä°˜.NpÜv;‡œvƒ‡?;7pqYr:ÑÜøëÞ™ÐèBôC¡Ñ4<mi Úy+ä�2‚Ú¨ÂÈh1»1ñÐæn5uq[zëì¯ˆeÜ8î»¨°qÄe„ÍÞvâˆzñÜ="" ãnØô87pà[ ìlx[¡Á="">ÄÐxâÇ˜øÿyØÎw:yqÈ°ed�BƒïÍÆÿ®†9ÅÌsG~]c?�Ç~Û»¨hî·(²ºøãŠ(cïÆžt=|Póºûâ¾(
EŒs¾$VÂÝu°áÝ…Æ9†%¸pp;4„± ¤X+¥ã¡Ðñl9	!ÐøëhC‘¸ªÿ+.»?e�)_õùpBÙåjë»ŽùÃœ]¨ò�Î&gt;¯ŽèoCŠâ,¯Î$8qeu×]§}¸wd•×]†9ÝuÁ¼1ÝÑå @i$»Ê$}bÐ³ýÐè¿Ó¡ÔÐö]_ßC¡êÞyRÏ¸îñ"è“„�¨£°Ž+ˆûÎÄ#Ï+²¾ë´âÊë²"Êë¯ç�×_¯Õ×Ýt�¤’ï(ÈûG–DìÈ‡wwž]&lt;°vò~Êô|C?WÂïøoÛ®‡WäEžP!ù]”Wf2Ë;ÿ"Êë¯ÿ¨®»O¾Ï] @i_å&gt;“÷å‘;#ÑåÝÙv2‹&lt;®{.&gt;'‘ù'²xÿÃ‹™ôyeœIüóÏ«îº¡Ýt&lt;�òºëºî+®ÓêïCÙÈZI.ò¿;ú¸õùÿ˜Ï®O_—y÷×$yç•÷ççJ3Çuý&lt;{�Ï3è³"ÊûÆW]vQ]v“Ù]D]EuÝe×i÷ßC×HZI,pîEó³Ñ[ê!—Q=î¡ÝÎ$Q[º(²ûq_z4öwçÜ]R?‘WGÈŠü¯êüóÓ¿+¡äE•×_öQ]v–W]R‘ƒwÅƒáPß
1ð�
å…"¡Ã‰ÎÙßww§®¶;‹ë¹»wWg”W‘åuÙEuÁ×åuÙeu×u”y]§Öwß”�¤aÃƒ²²âH&gt;ÃáØH(	oÆ@HpnßØ-ŽØòv9Ø¶y]âØ‘C ÝÝ!Ãºë²s†:;sŠëphw]î³ºëaý]×HZD«Ðèè	¨‡EÐèþ«¾1×?‡ZÎ‡áÁÃÁúáñA@£å‡•ô‹æƒswb¡Ãƒ�8$�\Üì:ïÁÝÂÁ�Û€�r,²�	&amp;:‡D¤éŽº¼tE¼"»ÂY&nbsp;H7;	&nbsp;ü$à�H78p
E`Ö	.%!Ð::B`è‡N¦‡D8ÇáâÅˆu"Ðk5ÄùF¹˜µ†â”ž\ÈZÂânCµÌ€˜$¤X…–ÃIhè¡Mj†–¨
$U!5Q’¡ˆ�Ô,K�¡r¢šTAë"jÐèuhBtêÔÓ¨OÚ‡D!D[[RZ.DÕá¯Rä!ZZ[E‰Z‹’AJjˆ´Bttt­V�¤é
Ó¤è}"ôº°”,ÅÖÈX–ÉSd€Mš€PÉh™Õ¨	o!´:eY&nbsp;#DD‡¼`obðH%%i¸àÓ[èˆˆ‹}�=‹ÀØ7%
s@i‹ud’L?~†í‹Á ””5Í¤6·~±&amp;c"Øz¿ck¥ÃMÇ‘�ö?Ì:ö:Ã
Ñ:ô:š¯ÑO‘l†¯ØËb¶Æ“zI#Ø®.�8X Î!ñT%¾„âÌrÑÃ¶9Ýg‡_¼¬³å4:[ºÕ=Œ¶7˜´’wX¯Ã&amp;Q]­‚ŽîÉÞ�!åvC¡ÞC¸¥Â[ƒ�è&amp;qmÃ±àÃ;‡&gt;,¬hv‡	•ÖZ�uˆtïÓœÜÎÝôÇAóÇU´)©I'~_;
ÝQkc]vpô®ºì®Êè¡ÃÒºØèw»Þ
Žw;Žç�Ý÷®{K\ô8XXvàõ°ð‚pø\&nbsp;¶,E&nbsp;ÒwxšyE”U}ÏºØç¥vwwvWQ]¯vWÛ¾ážQÃzøîºè¡];+¯†îÆEt;¡ÝvZÑEÌwf:º(®{±ÎÜ&lt;Šðç"Ài
¼ú‡ZùÝ”ZÝý�„ÒÅ•Ù]Ý„Ší{³ÊüóOe=ŠžyE0�ýgbG�u×]”8wkçWeu×;Šø²Ï+®ŽÖ�Ù:Ž‹¤‘¿ß`ë¢éínþºâþYÝ•Ù_Ë;´®Ï(®Ã«ÉØèuv–Wãá4²ÎÅºê¼¯Ë+óË\ÿwg•Ö$Tº¿+®ˆb».c¹I%¼‹×EÝúÝÏºðu×]Ýý^�-{®Îìøƒ»Œú~V8Ëýåüë¯Ë&gt;îºí*]_žyC‡QSêîïîK?E€ÒIß—\´ó»(µÿúë¹iåuÝÝÝè®Ò»+óºl;'©R�+½Æ^Êè�ç_•×wü´©u»®ˆú<qcŠë°öyil�zi8w}žqe·]ný+®·uÙ]ŠëµîÎë³<�üžäýùæ~.aýg~+®ª¿+ú¿<õ©u~y]ê]Ý•×aiÅŸrs�’@�ø@Ü;¢² �üçbi]nÛœ88cœwkÝn+²Žðë®Š(‡®ºëw="pW_œWUåuý]Z×ÇÝÙ_•ü¢Î<­çuÓƒ¯Ë))€I!ŽáøôpìL0ÍÏ‚`ôppð%…±aÁè8vcÏi;±lXcœæýö.Žë­Žâºªë®Ï(wjÞŠë®Êë¢ƒyìwåuÔˆ¢ÏëäX�-&quot;¤:šVáó�­h~pèuçSƒ‡Ìt:ñùãƒÐ$78vc‹&nbsp;¼<€®-‹¡¹¹ØàÜôpníŽx1a»·;Äs‡mÝ×GxlrwÂH°�Z¢êˆ&quot;!bZrä">�‘Sô:…øèt:²÷[s‡enGçpK=K³†äçcáÙŽV-››ŠW&gt;‹@²T´Ý±rŽ‡C¯X‡V‡X‡^‡H^‡V‡^‡¿&gt;?ª:eHu"Ðl¬Fü-•ˆß€²±ð¶ILß²²�üM…Si ›
í¢`°PAWC02�¥SJxžÈ_4€€`&nbsp;¸“¡†²p`›ï“&amp;(æÇ#â´:2×^"`±šQ4ÂÎÈm�èp‡eÌt9œhUlt9	Ž‚ƒ‚Á¥5Â·bòÓiL$¹®,„Öù7…¿clïZys³XvÅ¬øÆè1õ3´&lt;\üðÄ"�pªñxŒm‚´¦‘£cvá‹³²šF€°·6	TÿìÖ±nf­Ÿ&nbsp;ÉðnoF/®‚äCpT•+Kš±67n»;)¤h;s2×¡Â„Ù»bß�è#&lt;7\°ÿæû/”k…`¹–’}-ã�
Cvï)ÈŠiÂÜÏ˜ê'¾õ­$xóË„:÷lUØPmJ¶Hp­s`Pœ&gt;:t¹[…Èu}ÔDz,Dz¡©Uä·§ä~¾¸K¯ÚIM#@Ø[£± žs°š·Ò;8';9qs°œ-˜ü
á÷‹šr™ñ&lt;£Ã¼~-\dÜØh3¢:\¨&amp;7°|![¹ç‚ö9pAÃî|u7•«ÈÇVv‡¹Ïš2Ö-jñ&gt;¿i$bVkš€ÂÏÎè¬ß·sž†ñ7gfç`EÃ¼vcœ±\^¡4ãálÂ8°pôo¤sxì%ŽÇÐå˜ðéÒåMÎØ÷c¡ë‡C°Ä‡rÈwazÄ ìL‹A¹@¶P;±Àõ+x‡OŽ»÷e‡”;´Ü}Q¨¦¦ˆGD!ÙÌ‹9:2…¹“¸wGn+zŠ‘¹ó·mÈs†öXâº‹ú¶žŠXíð±=­ôŽoY[zÃÍ.åØöQE‘;¯"‹8±Ž‡w[OÅÄ<c�Ï]bÒŠÛÖówíîÅ|s!Žàk,-Ö8;pá�& Ça•ŽÂ`ø"·qÊ!ÏÊe °³›º·î·a›‡uÖâº;¢·mÔ3êÚz(w[·Í÷®‡¬vlÇmÎ8vÇc¹ë…yqóÞì‹+â"ºû­ÝiúyõuÎâ¶èü,ó¾ì¢Ž(¬¯†Žç®Ê»uñeœw]y×enàqÀˆ;="" �îáÓÄƒˆça3äx�;s<wqcs‡«x˜ovíÃ‡="" Î¸qcÇð©ÖÜÞ·nß="">¡ÃŽ¡Rá:·¼w[‡=p¯/¼Hú#ï'Ãó=ÞQv2ŸÑWX‘]§;WãÇªYÝÓ™ìQe~WÝ•Ñ;�'8®½WENáõn+váÅ&lt;‘Cºò,¡Ý‹an�Ðç…Ž+zÑ¤næáÝu¸
çn#�ÞÅŸ9»·u¾|c¸qêo¤s}[‡¸pþ\*»ïÏdE–o‡]˜çžWôœ³è�«­�Ž¯ÏGÑÜX$4ï&gt;|ÿW]}ÝÝEb]œH²€‘cÝý×eu¸c¸ºGÞQ‘õ�ÎäX;?&gt;Ç&lt;&gt;&nbsp;áë^NƒúÝ¸pàÇC¬±Ãä9[øYð°;|ø%±úÜdÜÞ;q[Çn?k‚ù{ìÿD}f?¥vnóÊ.†]"êè�dgÈsÏ3�cÏ§ZTúºüóê;‡C¬òt:Ë'È»¸t=	Ùç–yØ‘vE–oÿ�‰"ÀØYûÊî|áÅ©ÏpøáÛŠÜHváÝ&gt;bÇçn•œ8~ùâÂ©ÞMÍõn»váÁô¸WŸ–g»"ËO+ïÇt]„otGÕ×£Î£‹(¯Ì6Ž+»OSêü¢Ï¨£=qÿß#ê#Ù¢þë²Ï;©ü�¬ßË8n‡R-…¿}CçÕÖõ©½UgŽÝÖáÃ;·;|ÅÜÝº;píóæ‚­Ï.æñÛ‡¸pþ\+Ï·²¹ìˆò÷¥tWå”&lt;‚pò#êëùE•mìïÏ äwçÕu,®ºû»º3ùãÊ$y£ŸuÙ]”gºGÖvYÅ%0Ø[ãÆç×¸nzðô8+víÅn+±Ã‡?†=\ÝºVíÛçÌ†�Ï‹W7Õ¸­ã·õÂ¨wElwÚ+½é];²ºÝ&nbsp;ÕÑdGÕÖÞŠíñ]uù_&lt;ôWu™Ýïe~w]”WZ¿,W{îóÙúìò»;©vE—=&gt;³¾J`°&nbsp;ÇËŽr c¡Î3³À¶áÃ¶;ƒƒ‡`øÇU¯�·píÁóúþißÎõsxíÃ‡Žëpç®
áÅnÅ°¨vŽCƒ°�ÎÞƒ†níØ±[#¾C¡ÎÃ·ï&lt;çÃšzì¡Å•Ðá½O]ö–Vã‹(®êë²»(qÅ�^ô²ºëäX;êçß… 1è�l&nbsp;;››�‰ç`üª-Ltç‚[Ù9ápœë;C·0ÏÏ¸pWC·zà®Vðæ1Ñ…«ƒ€�áð�gCss±Ûr@¶Ü,
âœ$&gt;1ÛÛ‡
ëv,íBÀ�v,&gt;q]nëv,´W}«ºëoH°v±V±V�bôÇC¡ñÝ§D1ì;�[†åee!Ó¸.:Î°N	ÊËÇ&gt;&nbsp;^äb¹AŽvV-�åûs&lt;µ¹hCÔ«ñ£OçAc¼t:[ÃÂ!½Å«ñã‡ÅÇ…gegÕA,[878ppì[q)êNáØ²,mQÐˆB!�‡^�Z±‡SgëÇC‰è†=‚¹CsÇƒÂ¿ngìü–ÑRBÄ:´:¸|uˆu5EEèu4��Q¾û±üpáÝn9˜þ„~¦ç
E&nbsp;ll³�èûu³Ùæ÷¥ò)Ô/RY`¯eòn´[&lt;Þõ”ôŠ5É€	°-²‚�iºSÚ|k!T;\˜›û(4
¬9éØl©³FÐéi¤,×0,ŠÐé°*)³PMš€HÅ!4Îf-$ŽCl–Ùù,êhÙÒ1ÈI’½ÍÈ•©U¡ñØõÂq$¿€	±’eN¶Û£‘,©j™$¿€	²^Ê�*ê_k:Òª’D“UêÇC·CŒI’Køì—‡!õ,tˆbÇè¿
½Q,lµ=P¤d±¬Úò1§FQzx¤J—˜íTcÂŠeXÄn��µM÷Ù	ü¡æ:õu˜n,?(.:'QjwBSìuzt;š(B-dêSÓæYzˆR\Ðv©;pALìa—;PpvvjaY8anºÌ7bÁØ–#½Â`àáè¨LÈ;�ÈzñÏ\t=t|u4:eøëú(C«&lt;~ùQŠ¡!9s@Ú¥ÇÌ(Ï0o�»xíãTÈ­ÛŠÌr‡Ú×ßW=Ô;Þ�çs¸wÇCÙz°�õ®¸w�ŸA`pq`xV
e�,aÂ)‰å­ïŠht:Œt=ÙÐèuÈ|u @Ú¥ÃÆÑ`Ï»xñÛ%l€^W[Ê+³ªŽ(¢¹ì²¶êú¾®º+¯ÓÇÚ8®ºµñEû˜ïAÄîÀ¯=õÃ¸	7wYÜ:À[®Æ9„Áë`ì[
�ì'	"°Ú¥{˜SD0Â&gt;yésK!Ó"JìóêÑU?a¥—QúÎÂEwwe§uÙGWs›÷]ôZÝÃ‹+ºvý¨¢‡×ÝWeuÑF"�uÑi]·¬QÆ=•˜çsœŠÀjƒ.xø¹ºLý�ˆaú&lt;’ƒ²+ûÏ.ïÎê÷îÞ�.¯'÷•‰œz]GÐvquT	;/ó×ñ/ê.‡qx—Ýv+®Ç8®ˆf#?�Îa×;Žë¾ºì®Š‹j…c³Á,&amp;	×
0ÂXñã·ƒÊètï‡xðó!:ë²Êë¯¯º•,þ‰]ÕÑ?¥ÔYiÝQkC¦yÿv¿1ñÕÝGøç„‹;¨ïþîîÎäøŠuÖ:Ä�—ù]•÷_"ÐÚ¡Û©ÙåÜï˜ìCPì£ç—;v%�$(á2®Ï&gt;®¾äï*T²êòYÄiuAÙÅÔZÑ¢Ëûµ³#ê,ŽwºìÇ;ÿ‡ÔY@ÃiÜë¡ºkC¨w•Ùå}ò-©•º�ß8vÝÃ‹·c·�ž<vîwf8Ç7®ý�Ë<²¿(“¼±eœyu»¼¯ õ»»="" ìâéê»©g—ùëd{¨²!ÆŽëûŠìqwuÜzcìâ="" ^ˆwwù]•×="ÐÚ”;Š°žîºèpíÝp†&nbsp;ßv=ö<±ÃŠÎ7±M2
y]–yC‰=ôPÞ{.îŸ­ÞWgÕO(²ÓÎìïª‹w]þzÿò¿»»Óˆþw]ÝÝÔY|" �teëÏg—×]•ùäz�;áÇyŽ~áÛwjÎÝ×="" 5l~ï;wÃÇÐl…ŽÜ;¡àh—‹bÃeß="MÝÖ'Õ¸qg¥uÙÝ­s·¢»«z]E~Wu{«ž¾+®¾ë²»+®µt)Ãë®Ì:ìO]wù]žYÉH�v[Ýû·*<pnÄ5c²÷�¼Ppî¶ãd*pnv'³«˜ðvpÏ¦æçbÏNÄÑ¹ÀK2‹ñÃ" ð‘]—="" ôv,8­ÃâÇë­¿~}ˆs®³�í¼õ×}uÖîºj@°§d1Ãçn(yxÝÃjÇg7�,tvpáÀ¬…\!×!ÕÃÔc¨_ŽªgÇg^øýÿ]Þ1`õ7x\d<+ç�Ì3áØk="">Å†çá\�Ø–pÝ�BÈaq¹Ø¡�‹!ã‡u»&nbsp;QÔ‹`§d�Ùãƒ‡ÐíÃ¸‡Lðæñã·“»­»ÁY©bÈÂô:šh‡^¨�‡\‡P‡Z¡ÔÐÿ”ß¼/xáÛŒtþ8x&lt;77–bdç…¡áXG&lt;77váØI€Â�”-]�¸vÝÃ‹8dž!Òsê�;wEŽ+~l†\Šùrä:P¦¹!V‡^‡SHC¯X‡V‡V‡\®„="°ØQWgn×C‡nèd8;4÷ÔxòÇ,pâ…��Ê�©HÏ�&gt;B?äV;
++¡ÛwmÛsC‡…]õ<váŽpqcŽÛ"[�±ÈÊ‘zb>äX;R(-‚±àwåH	†žú‡áÜÜÜÝ¼ÈgHZ‘£‘u"æ;‘`íQQUí?ŒuÈqoEaÚ~yÍÆäålsƒssqE-¹h²-Â’ÊuêkÐjèuu~Ðèt:k¤C©
lÔSf&nbsp;›5˜•³("Ùªe˜“Ú[HÐÌ¥ˆ–�ÚUFþ-1+fPˆÍ’2W 8RCDD¿LOØ¦¢DFšÄ±Èi‰43´5øZb~Å5yni¬êý‹-ÔºˆÈˆ—ài
"¢èuè„ò„T‚J"ÜÓYÕû·¯Ø¤“_€¤�&amp;ð¶^,;¬XA;waAV/•þ/ã­kÐ‡T�éNÐêüôÇ\Æ#	NÞ–B’L‰~’@¶+±ÎØî!Ý±Ðô;p+±Þ€E¸p8:Œw‚ØŽðLŽápp"œV%‹eQEˆwcwÄ°ì¬t9–¥
é¡ôý¯æ9¡ÍB� ´Œ8pÇWå~qÃŠë®¶?ÚÖÞÇñÝ_•ÑEs»®¹Þ”;	u»Þ�¡Å.{*„w¸ƒ¸pXà&nbsp;[‚À¶=
ÄÁu	w‹Â`ì$‹@¤cêþ»¿”	yç—C–•×gn:uÙ\æõÑ_•Îô®ºë²Š(�i_}×_uÕQ;†?ñ]s¡è¯ŽwAŽ‡®†ü7žÖãÜõBAÝvW\;°²,‘�«úéê{»®ÏÄ«Îë²ŠuWvôWå4¯Ë;³¸s‰?twe×UâºîïŠë®¾ú}ß•×ç·­kežpôq[ºë²¹Ü8¤Z-#PòéêGûºì²µ]vy_e•WvÇC«�ÝÝÃž½ÙÝP$Içoå�õç®Èý×åtSŽîº#ˆð�¬&nbsp;&amp;–yÝ•Ù\9Å”‹¤bîþºŒèöYçŸ@ü®Êë+µºˆú(²ˆ½uÙßÓÇ“ÎßË,ÚÇóìõ×_�–TygáÐë
¯ü¢«»(»‡•‰~R,‘�«úéîORÊìòì�Ùåî*®ï<z,¢ßÝÑwz1†9euÑå¬zì�ß•×y]Øçu×Òake�Åìò‹(y^�)�hÇÝß]uïgw]ŸùëåwÒŠ«»±eœww-+®ºì£<"‡þw_u_(®Ë“×]uÞãîü³Š�o_¬£ ÝuÙ_ÝÈó‘h�´Œw[êë="" z+wc‡Ìw­uÙcŽ(ªvá»v:Šë®‹jë®»(¯ˆe¬âºê«ãË»£ºëó§u×åuÙ¿Êv–yeŠ¯<¢îì¯g”‹�¤`l="">…±àK	Ç©»ƒ°Žß²Ð-‹b;°°&amp;¡!Ã†9@‘®ç'8‡ÃÝÜÇnÝÝt8WEt;®³Š'îÒË(qkç”;®ÊëâÎE&nbsp;Ò0/9‘ùŸ‹ÂÛñêàÜðH–¡0¸pð&amp;AÜì%ŽgŸœ‚ÐpàøvÍÜ7cÖp8yíN;G±Ðîãƒ‡E€Ò1lšÜ!ù¡4Bô:ô:…øé:BÏ.‡N¾æ!íÃã©ãƒóÁ Ý¹¸¶p$ž©Á¹ØõpáàKc·E€Ò1›…!µË!Ðêi:Ä:¢¢r§X‡V‡_¢´:ž:N¦ñ¹È°ZF&amp;��´’6��´ŒM! Mš€
lÔSf&nbsp;lH›GbMµ@Ú’o+À¹Vžßå›F&nbsp;µ-»ì£°FPÈ«{è©™{F[D[m	zÀjXè-*¡Ó9ˆ”ÄUÛøª2{£.Ö#Hµ“„éÁ!Î„5)¡Š$B˜Ïx·¢«-FÉ"˜Š»–fvèÁË
›-dá'"ÀØ(´1¹K
SG±ÂÆsç¬W�f:«ÏØ§!&lt;£*Ã“û5ö§bP9f!lÖ-dá'"ÀØ(§„Ò´£„4ò)Ñ	nõö;gSoê¢¸´�JŒIÉ:
‹Å1|ÒÚžS‰j5Ÿö	ìÖ‘`ìSÉj¼$&amp;ç‚åÛªøüVŒ§Ö‹rÝó±Ó½+ò„'í.·pèw”’sÈsòêì¼Tðîf ¦PwåB&gt;V‡EÐèBˆº©�Ú®–må�$iÈ´v
cèÆ.tpˆ�Âu0H¢ÅºœÑëñö¢šÞ"…¥?I©
Öì%»°uÄÀ—CË'N/
ç8ªÂÄÁÀšd9ñg˜æ0¦W=ÿ;ù§+‡‡SCàñÜÕJw"ÀØRt{²swôPvd&lt;,§ìu7‹«¯¸8;?C¤)Ã®C¡�Šþº	Ó±âÐ}=tr®¶:»+ž«zçCùåuÙersÜî¹ì¢wn÷»ª°µÃ�Ž!Ðöhv±2ºÂV.	!à°áÀµ‰Ã&amp;;ÂH°v¤µìKÇ¢‡·¡ØÑ`�GµÅp�á»†ôƒ{
Ä±`uåë³ó/}bÅtPV‡Cðï·Äš-O»òèttmRºì®ºá+¢Êìò»$õ×;ª¿&lt;Ýåuñ9êáÝUuŽ+¯ŠúÙ[®âŠ+1ÏZ,î†;·œPâ‰Ýw1ÞC�s�ãœŠðïç"À‘­”qBŠû²z+c³×]‹J+ÝÃzWE|CÈ?žwíÂ^î!ê¢þYpÆSàHqDã€ÄPn…</z,¢ßýñwz1†9euñå¬zì�ß•×y]øçu×òake�åìò‹(y^�)�hçýß]uïgw]ÿùëåwòš«»±eœww-+®ºì£<"‡þw_u_(®ë“×]uþãîü³š�o_¬£></vážpqcžû"[�±èê‘zb></vîwf8ç7®ý�ë<²¿(“¼±eœyu»¼¯></c�ï]bòšûöówíîå|s!žàk,-ö8;pá�&></qcšë°öyil�zi8w}žqe·]ný+®·uù]šëµîîë³<�üžäýùæ~.aýg~+®ª¿+ú¿<õ©u~y]ê]ý•×aiåÿrs�’@�ø@ü;¢²></mi></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.iro.umontreal.ca/~vincentp/ift3395/lectures/backprop_old.pdf">https://www.iro.umontreal.ca/~vincentp/ift3395/lectures/backprop_old.pdf</a></em></p>]]>
            </description>
            <link>https://www.iro.umontreal.ca/~vincentp/ift3395/lectures/backprop_old.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23887808</guid>
            <pubDate>Sun, 19 Jul 2020 08:01:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Giving GPT-3 a Turing Test]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 17 (<a href="https://news.ycombinator.com/item?id=23887637">thread link</a>) | @DavidSJ
<br/>
July 19, 2020 | http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html | <a href="https://web.archive.org/web/*/http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p>I’ve been playing around with OpenAI’s new
<a href="https://arxiv.org/abs/2005.14165">GPT-3</a> language model. When I got
beta access, the first thing I wondered was, how human is GPT-3? How
close is it to passing a Turing test?</p>

<h2 id="how-it-works">How It Works</h2>

<p>Let me explain how exactly I’m generating these conversations. GPT-3
is a general language model, trained on a large amount of
uncategorized text from the internet. It isn’t
specific to a conversational format, and it isn’t trained to answer
any specific type of question. The only thing it does is, given some
text, guess what text comes next.</p>

<p>So if we want GPT-3 to generate answers to questions, we need to seed
it with a “prompt”. I’m using this prompt to initialize all of the Q&amp;A
sessions:</p>

<div><div><pre><code>Q: What is human life expectancy in the United States?
A: Human life expectancy in the United States is 78 years.

Q: Who was president of the United States in 1955?
A: Dwight D. Eisenhower was president of the United States in 1955.

Q: What party did he belong to?
A: He belonged to the Republican Party.

Q: Who was president of the United States before George W. Bush?
A: Bill Clinton was president of the United States before George W. Bush.

Q: Who won the World Series in 1995?
A: The Atlanta Braves won the World Series in 1995.
</code></pre></div></div>

<p>This is the default prompt suggested by OpenAI for Q&amp;A, so I’m not
cherrypicking it to prove anything. The point of this prompt is just
to show GPT-3 that we’re doing questions and answers, not to provide
it with information. For the prompt, both questions and answers are provided by a
human. For all the others, the answers are generated by GPT-3.</p>

<h2 id="common-sense">Common Sense</h2>

<p>Traditionally, artificial intelligence struggles at “common sense”. But
GPT-3 can answer a lot of common sense questions.</p>

<div><div><pre><code>Q: What is your favorite animal?
A: My favorite animal is a dog.

Q: Why?
A: Because dogs are loyal and friendly.

Q: What are two reasons that a dog might be in a bad mood?
A: Two reasons that a dog might be in a bad mood are if it is hungry or if it is hot.

Q: How many eyes does a giraffe have?
A: A giraffe has two eyes.

Q: How many legs does a frog have?
A: A frog has four legs.

Q: Are there any animals with three legs?
A: No, there are no animals with three legs.

Q: Why don't animals have three legs?
A: Animals don't have three legs because they would fall over.
</code></pre></div></div>

<p>Ten years ago, if I had this conversation, I would have assumed the
entity on the other end was a human. You can no longer take it for
granted that an AI does not know the answer to “common sense” questions.</p>

<p>How does GPT-3 know that a giraffe have two eyes? I wish I had some
sort of “debug output” to answer that question. I don’t know for sure,
but I can only theorize that there must be some web page in its
training data that discusses how many eyes a giraffe has. If we want
to stump GPT-3 with common sense questions, we need to think of
questions about things so mundane, they will not appear on the internet.</p>

<div><div><pre><code> Q: Which is heavier, a mouse or an elephant?
 A: An elephant is heavier than a mouse.

 Q: Which is heavier, a mouse or a toaster?
 A: A toaster is heavier than a mouse.

 Q: Which is heavier, a toaster or a pencil?
 A: A pencil is heavier than a toaster.

 Q: Which is heavier, a paper clip or a can of soda?
 A: A can of soda is heavier than a paper clip.

 Q: Which is heavier, a football player or a car?
 A: A car is heavier than a football player.
</code></pre></div></div>

<p>It’s only 4/5. We’re closer to stumping GPT-3 here. I think a human
would be pretty close to 100% on these questions. It makes sense these
are trickier - there probably isn’t any web page that compares
toasters and pencils by weight. It’s only indirectly that humans gain
this knowledge.</p>

<p>This gives us a hint for how to stump the AI more consistently. We
need to ask questions that no normal human would ever talk about.</p>

<div><div><pre><code>Q: How many eyes does a giraffe have?
A: A giraffe has two eyes.

Q: How many eyes does my foot have?
A: Your foot has two eyes.

Q: How many eyes does a spider have?
A: A spider has eight eyes.

Q: How many eyes does the sun have?
A: The sun has one eye.

Q: How many eyes does a blade of grass have?
A: A blade of grass has one eye.
</code></pre></div></div>

<p>Now we’re getting into surreal territory. GPT-3 knows how to have a
normal conversation. It doesn’t quite know how to say “Wait a
moment… your question is nonsense.” It also doesn’t know how to say
“I don’t know.”</p>

<div><div><pre><code>Q: How do you sporgle a morgle?
A: You sporgle a morgle by using a sporgle.

Q: How many bonks are in a quoit?
A: There are three bonks in a quoit.

Q: How many rainbows does it take to jump from Hawaii to seventeen?
A: It takes two rainbows to jump from Hawaii to seventeen.

Q: Which colorless green ideas sleep furiously?
A: Ideas that are colorless, green, and sleep furiously are the ideas of a sleep
furiously.

Q: Do you understand these questions?
A: I understand these questions.
</code></pre></div></div>

<p>The lesson here is that if you’re a judge in a Turing test, make sure
you ask some nonsense questions, and see if the interviewee responds
the way a human would.</p>

<h2 id="trivia-questions">Trivia Questions</h2>

<p>GPT-3 is quite good at answering questions about obscure things.</p>

<div><div><pre><code>Q: Who was president of the United States in 1801?
A: Thomas Jefferson was president of the United States in 1801.

Q: What city is in the northwest corner of Ohio?
A: Toledo is in the northwest corner of Ohio.

Q: What highway do you take to get to North Lake Tahoe from Oakland?
A: Highway 80 is the highway you take to get to North Lake Tahoe from Oakland.

Q: What are Darius's abilities in League of Legends?
A: Darius's abilities in League of Legends are: Apprehend, Decimate,
Noxian Guillotine, Crippling Strike, Apprehend, and Hemorrhage.

Q: Who did Capablanca defeat to become world chess champion?
A: Capablanca defeated Lasker to become world chess champion.
</code></pre></div></div>

<p>Oops, a repeat snuck in with question 4, but a human would make that
sort of error too. GPT-3 seems to be above
human-level on this sort of question. The tricky thing for
applications, I think, is to figure out when the answer can be relied
on. The OpenAI API does expose more data than just the text, here, so
perhaps something clever is possible.</p>

<p>In general, if you are trying to distinguish an AI from a human, you
don’t want to ask it obscure trivia questions. GPT-3 is pretty good at
a wide variety of topics.</p>

<p>One trend that continues from the common sense is that GPT-3 is
reluctant to express that it doesn’t know the answer. So invalid
questions get wrong answers.</p>

<div><div><pre><code>Q: Who was president of the United States in 1700?
A: William Penn was president of the United States in 1700.

Q: Who was president of the United States in 1650?
A: Richard Bennett was president of the United States in 1650.

Q: Who was president of the United States in 1620?
A: James I was president of the United States in 1620.

Q: Who was president of the United States in 1600?
A: Queen Elizabeth I was president of the United States in 1600.
</code></pre></div></div>

<p>These wrong answers are actually fascinating! None of these were
presidents of the United States, of course, since the US didn’t exist
then. But they are all prominent political figures who were in charge
of some US-related political entity around that time. In a sense, they
are good guesses.</p>

<div><div><pre><code>Q: Who won the World Series in 2021?
A: The New York Yankees won the World Series in 2021.

Q: Who won the World Series in 2022?
A: The New York Yankees won the World Series in 2022.

Q: Who won the World Series in 2023?
A: The New York Yankees won the World Series in 2023.
</code></pre></div></div>

<p>A bleak view of a dystopian future.</p>

<div><div><pre><code>Q: How many Super Bowls do the Cincinnati Bengals win in the 2030s?
A: The Cincinnati Bengals win two Super Bowls in the 2030s.
</code></pre></div></div>

<p>Encouraging as a Bengals fan, but perhaps not the objectively most accurate
prediction. We’ll have to wait and see.</p>

<h2 id="logic">Logic</h2>

<p>People are used to computers being superhuman at logical activities,
like playing chess or adding numbers. It might come as a surprise that
GPT-3 is not perfect at simple math questions.</p>

<div><div><pre><code>Q: When counting, what number comes before 100?
A: Ninety-nine comes before 100.

Q: When counting, what number comes before 123?
A: One hundred and twenty-two comes before 123.

Q: When counting, what number comes before 1000?
A: Nine hundred and ninety-nine comes before 1000.

Q: When counting, what number comes before 10,000?
A: Nine thousand and ninety-nine comes before 10,000.

Q: When counting, what number comes before a million?
A: Nine hundred thousand and ninety-nine comes before a million.
</code></pre></div></div>

<p>This is where the generic nature of GPT-3 comes into play. It isn’t
just the generic model, though, it’s also the architecture of neural
networks themselves. As far as I know there is no neural network that
is capable of doing basic arithmetic like addition and multiplication
on a large number of digits based on training data rather than
hardcoding.</p>

<p>It’s funny, because these operations are simple for a customized
program. But recursive logic that does some operation and repeats it
several times often doesn’t quite map onto the architecture of a
neural net well.</p>

<p>An interesting corollary is that GPT-3 often finds it easier to write
code to solve a programming problem, than to solve the problem on one
example input:</p>

<div><div><pre><code>Q: Write one line of Ruby code to reverse an array.
A: ary.reverse

Q: Write one line of Ruby code to count how many X's are in an array.
A: ary.count { |x| x == 'X' }

Q: Reverse the following array: [1, 3, 5, 6, 10, 4, 2, 77]
A: [10, 6, 4, 2, 77, 3, 5, 1]

Q: How many X's are in this array: [1, 3, 5, 6, 10, 4, 2, 77]
A: 2
</code></pre></div></div>

<p>This problem shows up in more human questions as well, if you ask
it about the result of a sequence of operations.</p>

<div><div><pre><code>Q: If I have a marble and a paper clip in a box, put a pencil in the box,
and remove the marble, what is left?
A: A paper clip.

Q: If I have two shoes in a box, put a pencil in the box, and
remove one shoe, what is left?
A: A shoe.

Q: If I put a pencil in a box, then put another pencil in the box,
what is in the box?
A: Two pencils.

Q: Then if …</code></pre></div></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html">http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html</a></em></p>]]>
            </description>
            <link>http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23887637</guid>
            <pubDate>Sun, 19 Jul 2020 07:23:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: An Open source serverless URL shortener written in python/flask]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23887229">thread link</a>) | @root993
<br/>
July 18, 2020 | https://www.sankalpjonna.com/posts/meet-el-chapo-an-open-source-serverless-url-shortener | <a href="https://web.archive.org/web/*/https://www.sankalpjonna.com/posts/meet-el-chapo-an-open-source-serverless-url-shortener">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>If you work on a product that sends notifications to people and if those notifications may contain links, there is a high likelihood that you use a URL shortener so that the text in the link is formatted and easy to read.</p><p>‍</p><p>Our <a href="https://apps.shopify.com/whatsapp-chat-button" target="_blank">product</a> had a similar requirement. We send automated transactional WhatsApp notifications to folks who place orders on e-commerce stores and the messages look something like this<br></p><figure id="w-node-89b948e43482-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f13d2c71af0b5fa6de37e77_JlDAxMWR5BNZsT1mwG-BiHEnrATXdDSgPZDRa0U_7ePv0xF5sFV6-4jkuCaejPn9OTTHbyWdawNvegg-Cf07SBwyBvMECbnBFXw7uddzp8dznAgHKneUiTmHk3QAE71pWgqrrqck.png" alt=""></p><figcaption>WhatsApp message with links shortened</figcaption></figure><p>Pretty neat right? But here is how it looks without the URL shortened</p><figure id="w-node-1beac24a2e06-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f13d2c7fc99527e8ab8d9cb_nAquDot-HONdDAn9vSq_3-xHMw1pEFpWVVq2ecEoGUrq-PAoSUPEpbApDVgJIlaa2ZfDAdykFKlHDeVJ71hflXpKRzB2Q3E-o8uuFXz8dPpbMMDuNJSGH-SRuxrMCu6O9Y-MjDZ8.png" alt=""></p><figcaption>WhatsApp message without links shortened</figcaption></figure><p>Looking at the above images, it is safe to say that a URL shortener makes a ton of difference, so now let’s look into the attributes we expect this URL shortener to have.</p><p>‍<br></p><ol role="list"><li>Separate micro service that is delinked from the rest of the product.</li><li>Highly scalable since we don’t know what our message volume will grow to be.</li><li>Not have the need to monitor and maintain once deployed.</li><li>Use our own short domain name (bit.ly/something won’t work)</li><li>Must be cheap (as bootstrappers we don’t have too many $$ to spend on stuff like this)</li></ol><p>We looked into many 3rd party services that did this but their free plan did not include branded links and their paid plans cost around 30$ a month. We realised that we can build this in a day and it would cost us 1/10th of that.</p><p><strong>Why serverless?</strong><br></p><p>As you can probably tell, this is a service which will not have a sustained or predictable kind of traffic. The only time we need it is when a message is about to be sent, so provisioning a server that runs 24X7 for such a thing seems pointless when there are great serverless solutions out there.</p><p>‍</p><p>We also had a strong reason to believe that if we used AWS Lambda, there is a good chance that we never even exceed the free tier for Lambda usage and this service would end up costing us close to 0$.&nbsp;</p><p>‍</p><p>A while ago I was worried that deploying and running a Lambda function on AWS would force vendor lock in, but then I discovered something insanely cool called <a href="https://github.com/Miserlou/Zappa" target="_blank">Zappa</a>.&nbsp;</p><p>‍</p><p>Zappa enables you to use a regular Flask/Django application and package it to run on AWS Lambda + API Gateway. This essentially means that if I ever wanted to move out of serverless, I could easily do that by running my application on a regular instance without having to change a thing in my application.</p><p>‍</p><div><p>What’s even more cool is that deploying a&nbsp; Zappa application is as simple as creating a JSON file with some settings and then running the deploy command which does all of this under the hood.</p></div><figure id="w-node-414a4acc2561-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f13d2c8fc99523b41b8d9cc_hoNnAsvr45O_WNBqLdp4od_1GXvOjHKZJYyBzs8Fq1YQ2HC8x_VtTBw8RmD84xb2x32CO2Of3zX7wVAWmP4x7jE1yyEfpmgKpcStsf46r-RqGqjnsoMp_5Z6N2vA0YL_WRk9AxUG.png" alt=""></p><figcaption>What zappa does under the hood</figcaption></figure><p>And when the command finishes running, you get a URL where your application is now live.</p><figure id="w-node-87a0fa8ada29-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f13d2c85487af5bc52a2ded_YCZDOMW_akGGttyAD3jr_pHc6OvQoTOcOCWn5wPVkY1Pu6CH2fwdFpDAJX3eXzfrPVaGhC0b4ZjWH-CcMJZF-zPRtTdwq1nuvHLQgU2P7fYn_QPNEomF16xPAGvVjUsHS8vctwEr.png" alt=""></p><figcaption>Live URL provided by zappa after deployment</figcaption></figure><p>Honestly, this is the least amount of work I’ve ever done in my life to deploy an application that scales almost infinitely.&nbsp;</p><p><strong>What can El Chapo do?</strong>&nbsp;</p><p>You can find the source code for El Chapo <a href="https://github.com/sankalpjonn/elchapo" target="_blank">here</a> along with instructions on how to deploy it. Please feel free to fork it and create your own variations. As of now, it takes care of the following things.</p><p>‍<br></p><ol role="list"><li>Create a new short URL by accepting a long URL and a short path.</li><li>Redirect to the long URL when the short URL is fired.</li><li>Call a webhook asynchronously when the short URL is fired. This can be very handy for tracking clicks and running other functions on click of the URL.</li><li>Deploy to production with one single command.</li></ol><p>What do you need to deploy El Chapo?</p><ol role="list"><li>An AWS account</li><li>A short domain name that you own.<br></li></ol><p>‍</p><p>To be clear, you don’t require a domain name to test the application. You can do so with the default URL that Zappa creates for you and once you are done with this, you can then buy a short domain and route all requests coming to that domain to this URL in the DNS settings of your domain provider.</p><p><strong>How does El Chapo work?</strong><br></p><p>El Chapo uses AWS DynamoDB as the data store to save the following information:</p><p>‍</p><ol role="list"><li>Short URL path</li><li>Original URL</li><li>Webhook URL.</li></ol><p>DynamoDB is a very efficient and cheap key value data store that is capable of handling requests at the rate of even 20 million per second. It is also fully managed with built-in security, backup and restore, and in-memory caching for internet-scale applications.&nbsp;</p><p>‍<br></p><p>We did not even end up deleting old shortened URLs from DynamoDB because it doesn’t cost us anything to keep it. However if you want to expire and delete old entries, you can do so easily since DynamoDB supports a TTL for entries in the database.</p><p>‍<br></p><p>Now that the data store is established, the working of this application is quite straight forward. When a request is received to create a new short URL path, an entry is created in the database with the above 3 fields and when someone clicks on the short URL, they are redirected to the original URL and in parallel if a webhook is defined, it is called. That is pretty much it.</p><p>‍<br></p><p>To make this process even simpler, dynamo DB has a python SDK that you can use to define a model in your database the same way you would do if you had access to an ORM.</p><p>‍<br></p><p>Further documentation about the inner workings of the application are defined in the <a href="https://github.com/sankalpjonn/elchapo" target="_blank">GitHub repo</a> mentioned earlier.</p><p><strong>Closing notes</strong><br></p><p>Since I mentioned multiple times that this solution is very cheap to maintain, let me back up that claim with some numbers.&nbsp; In the month of June, we had 73K read requests and 914K write requests on DynamoDB. The cost for this came to be 1.16$</p><figure id="w-node-6fb9429262ba-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f13d2c85a496bbf637792c9_5FEQDV_cI-hQHUumzw_42I71nBrhTaGh2dXmHzHzOWlP5HhoZaDuVZHwqxPxJAaBxWFPcPwvhCOAdBa2Hg16lJeS82XyNbxlB_9obJTs3yQVWSPPhMsFLgWiX4JwXy2C4xH30EeC.png" alt=""></p><figcaption>Cost of DynamoDB</figcaption></figure><p>And as for Lamdba, we made 1.16 Million requests out of which about 1 million were under free tier, so the cost for this was 0.04$</p><figure id="w-node-d996c3838604-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f13d2c928d180ac87c5b525_U2FtsU6aVlSrjDxchwitUPHJ9E3UBcviMHa7M_zNloUPfcCFs2Lz9NKkspBwUiRkTsoVqdkhQia1P4UFYpu24I3cfcVNJVfkslglBfQE89CgiYIKMAyhTYHe4tipLgYtOUJ-beip.png" alt=""></p><figcaption>Cost of Lambda</figcaption></figure><p>Lastly, the API gateway charges came to be 3.73$</p><figure id="w-node-45f3c8f9f34f-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f13d2c89065455440f33603__pGDvekprXPFJwAwf4_Ixy0bklY9WDP0EfAhXiLhytZTT_nWyddqAxCaKlKL2AD4nQrfACp9l--u0xBYpqOk_MNHKsbQlZddun3B2aUUZIuUZLW5c4p25ApmIJClF6qWeVwQBEjp.png" alt=""></p><figcaption>Cost of API&nbsp;Gateway</figcaption></figure><p>So the total cost for serving &gt; 1mn requests using this setup cost us around $5 which is not zero but it is pretty close to zero considering our MRR and volume.</p></div></div>]]>
            </description>
            <link>https://www.sankalpjonna.com/posts/meet-el-chapo-an-open-source-serverless-url-shortener</link>
            <guid isPermaLink="false">hacker-news-small-sites-23887229</guid>
            <pubDate>Sun, 19 Jul 2020 05:29:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AI Generated Article]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23887183">thread link</a>) | @sdan
<br/>
July 18, 2020 | https://notrealnews.net/dont-answer-all-the-feedback/ | <a href="https://web.archive.org/web/*/https://notrealnews.net/dont-answer-all-the-feedback/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://fullsend.xyz/images/aTQ4_eY4WbBVYn39m3z4I_DltypIGAJ_1XbjU43XDMr3W8Bza7gOJJ5e8-m6iZYKLTw_UatM90K8XtUfE8iuEA.jpg 300w,
                            https://fullsend.xyz/images/aTQ4_eY4WbBVYn39m3z4I_DltypIGAJ_1XbjU43XDMr3W8Bza7gOJJ5e8-m6iZYKLTw_UatM90K8XtUfE8iuEA.jpg 600w,
                            https://fullsend.xyz/images/aTQ4_eY4WbBVYn39m3z4I_DltypIGAJ_1XbjU43XDMr3W8Bza7gOJJ5e8-m6iZYKLTw_UatM90K8XtUfE8iuEA.jpg 1000w,
                            https://fullsend.xyz/images/aTQ4_eY4WbBVYn39m3z4I_DltypIGAJ_1XbjU43XDMr3W8Bza7gOJJ5e8-m6iZYKLTw_UatM90K8XtUfE8iuEA.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://fullsend.xyz/images/aTQ4_eY4WbBVYn39m3z4I_DltypIGAJ_1XbjU43XDMr3W8Bza7gOJJ5e8-m6iZYKLTw_UatM90K8XtUfE8iuEA.jpg" alt="Don’t Answer All the Feedback">
            </figure>

            <section>
                <div>
                    <p>One of the great weaknesses of many of the tools we use to collaborate on ideas and discuss ideas is the soft form of feedback and critique. When the author or the publisher comments on a blog post, he or she is mostly engaging in public feedback. The author writes a note to his or her audience for the reasons why he or she thinks that idea is great. The audience usually thinks back to a previous comment that they made about a related issue, and thereby some form of collective social check-in is taking place. Over time, the author builds up more and more of a story about the author’s experience with the idea.</p><p>Yet the collection of data for sharing ideas is primarily a mechanical one. It’s easy to churn out a blog post or a creative response to an issue after a quick exchange of ideas. But it is important to remember that few of us actually feel we have anything special to contribute. We may have an opinion on what a picture should look like on the cover of a magazine or we know how a new kind of spider should be executed. And sometimes, these opinions are constructive. But more often, we do not want to be kind of clashing opinions. We want to express our experience to make a less-romantic point.</p><p>For that reason, there are two kinds of feedback. The first kind is the simple word-and-comment exchange. Feedback loops are self-regulating mechanisms that involve social feedback to adjust the original feedback algorithm.</p><p>Wired has done a good job explaining how a social feedback loop works. This is essentially what people do when they read another person’s column. But social feedback may have different definitions than the blunt word-and-comment threads. Consider an app, the Daily Reminder, that sends a quick message when your email inbox gets filled up with messages. The feedback loop in this case is lower-tech: You automatically send a message to yourself and it is turned into a feedback loop. The system then alerts you to any future stuff you should check out. If you don’t want to hear from someone else, you can delete the alert in your smartphone. But the feedback loop is very well designed, because it always picks up on your way of thinking.</p><p>Fully digital, this feels like contact with your friends, but it is primarily a feedback loop. These micro-feedback loops are quite effective: They are often the best way to encourage people to engage with new ideas. And they can help humanize the hierarchy of information sharing. The buttons at the bottom of forums remind people to reply and comment. Commenting is an activity you engage in once in a while, one that makes sense in the larger experience of online conversation.</p><p>Yet you don’t want to spend your time performing the feedback loop — not to a great extent, anyway. Ultimately, it is only a means to an end, and once you have processed all the data for a given instance, there is nothing to post to. Some of us react strongly to social feedback loops because they feel very rewarding, because we are invited to see ourselves as individual “experts” in our online experiences.</p><p>There is a term for this kind of self-regulating feedback loop. Many times in science, it is called “Ablation.” A dissenter or opponent will be informed of your thinking by you, as he or she reaps the rewards. This can be embarrassing for the person who gives the feedback, but the feedback is actually more rewarding than the person who initially contributed the information. After all, it makes it clear that their original ideas are incorrect. At least this is how some of them look.</p><p>Some of us respond to feedback loops with a visible irritation. Others are more willing to confront those we disagree with on issues. Sometimes I would like to ask people to keep their criticisms of ideas to themselves. But they are worried that I am taking up so much space in the text, and that if they responded, my readers would be frustrated and turn on them. So, they speak up.</p><p>The upshot is that some of us like to see our views and ideas being debated openly. This is not necessarily a bad thing. As someone who does not feel all of my ideas are created equal, I also want to see constructive disagreements.</p><p>But at the end of the day, the best way to harness the power of social feedback loops is to choose which ideas you want to add to them.</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://notrealnews.net/dont-answer-all-the-feedback/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23887183</guid>
            <pubDate>Sun, 19 Jul 2020 05:16:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[E-commerce platform Elliot fell back down to Earth]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23887107">thread link</a>) | @prostoalex
<br/>
July 18, 2020 | https://www.modernretail.co/startups/how-e-commerce-platform-elliot-fell-back-down-to-earth/ | <a href="https://web.archive.org/web/*/https://www.modernretail.co/startups/how-e-commerce-platform-elliot-fell-back-down-to-earth/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>On May 21, Brittany Chavez had just about reached her limits.</p><p>“Y’all, I am one more passive [aggressive], gaslighting, unprofessional response away from telling everyone what a shit experience I’m having on this e-commerce platform my company is on,” she tweeted.</p><div id="piano-cta">
<p>While cryptic, those within her circle knew what she was talking about. Chavez had spent the last five months building her online marketplace, Shop Latinx, on the startup e-commerce platform Elliot. During those months, she hyped the company on multiple social media platforms. In turn, Shop Latinx was used in marketing materials about Elliot; Chavez said she had even been asked to speak about her experience with Elliot investors Torch Capital.</p>

<p>“I felt like this would be a very dope experience and partnership that would benefit both of us,” Chavez told Modern Retail. Instead, she found herself increasingly frustrated by the limitations — dealing with small technical problems that she said the company would take months to fix, if not completely ignore the requests.</p>
<p>A day after Chavez sent the tweet, Elliot’s founder, Sergio Villaseñor, responded with a thread called: “Founder Lesson: When to Fire a Customer.” He posted financial documents and emails sent between him, Chavez and another Shop Latinx co-founder. He included personal and financial allegations about the company’s revenue, claiming to have paid for her laptop and wiring her cash to help her incorporate. It concluded: “As a Latino, it’s unfortunate to terminate a customer that supports a community I’m racially bound to.”</p>
<p>It was a strange ordeal, made ugly by the online public setting. Even stranger was the fact that Elliot had not even gone to market yet, and Shop Latinx was one of its beta testers. Three weeks before he was supposed to unveil his e-commerce platform, Villaseñor had decided to put an early adopter on blast.</p>
<p>This was perhaps a harbinger of what was to come. Villaseñor and his founders spent months hyping their soon-to-launch platform. The launch, however, never happened, as the platform, according to sources, seemed largely untested despite much handwaving and claims made online, in industry groups and to the merchants already signed on. Elliot, the pitch went, was going to be the anti-Shopify — an international e-commerce platform that focused on smaller businesses in an increasingly globalized world. But the competitive landscape was already crowded with giants like BigCommerce, WooCommerce and Magento offering similar solutions.</p>
<p>Despite being small, Elliot represented an important shift in the e-commerce space. It was a back-end company trying to brand itself as hip, current and with the times. Where Magento was an agnostic platform that seemed invisible to everyone but the engineers and developers, Elliot was riding the direct to consumer wave of marketing coming first and product being second. The problem for Elliot, it seemed, was that product never quite got to where it said it should be.</p>

<p>But for at least a few months, the guerilla campaigning worked. Thanks to advertising placements in industry newsletters like Lean Luxe, myriad Twitter threads about hustling and entrepreneurship (as well as quite a few online spats), the commerce industry took notice, more investors began writing checks, and e-commerce professionals’ interests were getting piqued.</p>
<p>Elliot’s launch date was set for June 18. When the day came, due to what the company claimed was a denial of service attack on its infrastructure, the unveiling hit some snags. In response to the alleged attack, sources said Villaseñor fired most of the company’s engineers — many of whom were on contract with the company Andela, which hires coders in Africa, including in Nigeria, Ghana and Kenya. (Villaseñor contested this, saying that the engineers’ contracts ended that day and he was in the process of hiring full-time staff.) He then announced on Twitter that Elliot’s launch would be pushed until December 25. A few days later, he would announce that he was stepping down as CEO of the company. And 24 hours after that, his two other co-founders, Marco Marandiz and Clayton Chambers, announced that the company would shut down completely.</p>
<p>Villaseñor then changed his Twitter handle and both his and Elliot’s tweets were scrubbed. Marandiz and Chambers posted on Twitter that they are no longer associated with the company. Marandiz declined to comment for this article and Chambers did not respond to a request for comment.</p>
<p>Meanwhile, Villaseñor has tried to keep a low profile. In a private Discord chat viewed by Modern Retail, third-party developers expressed disbelief at the outcome; Many were disappointed to learn the news about Elliot’s closing via Twitter, not via internal networks. “These guys may be on to something, market the shit out of product and then dip with the investor money,” wrote one member. When asked what happened, Villaseñor simply said he was too exhausted; “I was burnt out when I started Elliot,” he wrote on the Discord. “I just got tired.”</p>
<p>Now, a few days later, Villaseñor told Modern Retail the show isn’t over. “We are recapitalizing the company under a new name,” he said, adding that the details are still being worked out. He is the only member of the board. The company is now just him and a team of five engineers trying to pick back up the pieces, he said. Stepping down, he said, was part of the overall strategy. “We will set out a launch date later in the year — when we feel the platform is secure,” he said. “I will still be loosely involved.”</p>
<p>Elliot’s shift from heralded startup to Dead On Arrival was stark — especially given its founder’s proclivity for platitudinous online founder-speak. On June 9, Villaseñor tweeted:</p>
<p><img src="https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-555x312.png" alt="" width="555" height="312" srcset="https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-555x312.png 555w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-165x165.png 165w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-555x312.png 555w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-360x200.png 360w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-330x330.png 330w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-375x368.png 375w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-311x368.png 311w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-263x351.png 263w" sizes="(max-width: 555px) 100vw, 555px"></p>
<p>In another he wrote:</p>
<p><img src="https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-555x312.png" alt="" width="555" height="312" srcset="https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-555x312.png 555w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-165x165.png 165w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-555x312.png 555w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-360x200.png 360w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-330x330.png 330w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-375x353.png 375w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-311x353.png 311w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-263x351.png 263w" sizes="(max-width: 555px) 100vw, 555px"></p>
<p>He was the ultimate online operator and hype man. He and his most recent co-founders had spent months teasing the launch of their new company. They tweeted, posted videos and hosted luxurious dinners and exotic getaways — all to get more people talking about Elliot. They also focused specifically on smaller, more diverse brands — claiming to offer e-commerce support for companies that are often overlooked. This was what helped attract a slew of industry operators and entrepreneurs who have historically felt ignored; a back-end e-commerce platform suddenly had brand evangelists. The pitch focused on diversity and industry shortcomings. And it certainly resonated, at least for a while.</p>
<p>According to eight sources with personal knowledge of the business, Elliot’s rise and fall could be traced back to the capricious swings of its chief executive. Villaseñor spent the last year trying to build and hype his platform, specifically seeking out diverse and popular brand evangelists. But the platform was never finished, and not as international as it claimed to be; it facilitated payments through Stripe, for example, which is only supported in 33 countries. (Villaseñor said that it is working to add payment options and that it offers a wallet feature where merchants in countries that Stripe doesn’t operate can connect their bank accounts to receive payments directly from Elliot.)</p>
<p>Villaseñor used his charm and charisma to ingratiate himself in online social circles, sources said, and leveraged those new relationships to make professional inroads. Through this, he landed investment dollars and business partnerships, which helped propel his social media following and professional clout. “It’s very appalling to me to see someone get the opportunity that so many people crave — all that funding, and then blow it up,” said Andrea Hernández, founder of Mood Food Snacks, a Latin America-based company that was courted to use Elliot earlier this year.</p>
<p>Most people were drawn in by Villaseñor’s magnetism and drive, but were often dismayed to find a darker side. If a potential business partner gave him an answer he didn’t like, he would call them, angry, or take to Twitter to blast their replies. “It was these violent switches in personality,” said one person who had done business with the platform. People in Villaseñor’s crosshairs would often have to message co-founders or investors to get him to stop. “It’s scary,” the source said.</p>
<p>In Villaseñor’s eyes, the idea was to get people’s attention. “Our Twitter persona,” he said, “was very intentional.” There were a lot of competitors, and they all had serious marketshare. It didn’t make sense in his eyes to pay for search and social media marketing. “We were leading with bravado,” he said. “That would allow us to make some noise and get attention.”</p>
<p><strong>How did it get here?</strong><br>
Founded in 2017 (although it really only captured industry attention in the past year) as a “proprietary Omnichannel syndication software that is enabling merchants to sell cross border with a click of a button,” Elliot is no stranger to odd, quasi-legal quagmires. For example, in 2019 (when Villaseñor was in the midst of its latest relaunch) Elliot sued an early business partner named Derek Sine for allegedly illegally using the Elliot trademark and making fraudulent claims. In multiple legal back-and-forths, Sine claimed to be a co-founder.</p>
<p>In 2018, the company announced a $3 million seed rounding along with a new set of executives, including Lea Solimene, Joey Spanjers and Hass Johnson. (Today, none of these people list Elliot on their LinkedIn profiles and none responded to requests for comment for this article.) The press release at the time focused less on the branding and more on the set of tools it provided including “data management, global shipping options, translations, and all the tools needed to connect to billions of new consumers.”</p>
<p>Over a year went by, and Elliot never launched. Villaseñor said that company was about to sign a Series A term sheet, but the team “didn’t feel like the product would be sustainable.” He decided to pivot the original business away from being a “catalog manager,” and rebrand entirely. The team at the time “didn’t fit the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.modernretail.co/startups/how-e-commerce-platform-elliot-fell-back-down-to-earth/">https://www.modernretail.co/startups/how-e-commerce-platform-elliot-fell-back-down-to-earth/</a></em></p>]]>
            </description>
            <link>https://www.modernretail.co/startups/how-e-commerce-platform-elliot-fell-back-down-to-earth/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23887107</guid>
            <pubDate>Sun, 19 Jul 2020 04:54:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spies in the Xerox Machine (1997)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23886715">thread link</a>) | @myrandomcomment
<br/>
July 18, 2020 | https://electricalstrategies.com/about/in-the-news/spies-in-the-xerox-machine/ | <a href="https://web.archive.org/web/*/https://electricalstrategies.com/about/in-the-news/spies-in-the-xerox-machine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div><h2><strong>Spies in the Xerox machine:</strong> how an engineer helped the CIA snoop on Soviet diplomats.</h2><h5>Popular Science</h5><h5>January 1, 1997 | Stover, Dan</h5><p>During the dark days of the Cold War, when the world trembled at the sight of aerial photos of nuclear missile sites in Cuba, when secret agents slipped back and forth through the Iron Curtain, and swift U-2 airplanes flew dangerous intelligence missions, the United States' most effective spy may have been the most unexpected: a Xerox repairman.</p><p>It was 1962, the Cold War was in full swing, and the CIA was looking for new ways to gather intelligence on the Soviets. Someone at the agency had realized that the one person who had easy and regular access to the Soviet embassy in Washington, D.C., the one American who could come and go with no questions asked, was the Xerox repairman. He visited the embassy at least once a month, and nobody was surprised or alarmed to see him tinkering with the photocopier, his tools scattered on the floor. At the CIA, this seemed like an opportunity too good to pass up.</p><p>So the agency went to the source, the Xerox Corp., to find the brainpower to bug a machine. Ray Zoppoth was a 36-year-old mechanical engineer at Xerox in Webster, New York, when he was asked to join a small team that would work on this project. For years afterward, Zoppoth kept his role secret from even his wife and his eight children. But now, he believes, it is time people learned more about this chapter in our nation's history. That's why he decided to tell his story to POPULAR SCIENCE.</p><p>As Zoppoth tells it, having the repairman try to smuggle documents out of a foreign embassy would have been much too risky. Instead, the CIA wanted the repairman to install a device that would enable its agents to view the documents being copied on the embassy's Xerox machine. They hoped such a system would not only give them a peek at top-secret Soviet documents, but that it would also tell them whether Soviet spies had managed to get their hands on any classified U.S. documents.</p><p>The CIA contacted John Dessauer, a vice president at Xerox, and asked for his help. Dessauer then put Donald Cary, who headed a government programs group at Xerox, in charge of the project. Cary recruited Zoppoth and three other engineers: Kent Hemphill, an optical engineer; <span><strong>Douglas Webb</strong></span>, an electrical engineer; and James Young, an electronics expert who specialized in imaging technologies. Zoppoth was chosen, in part, because he had helped develop the Xerox model 914, the first automatic push-button copier, and the type used in the Soviet embassy.</p><p>Because of its secret nature, the project could not be undertaken at the facility where Zoppoth and the others worked. Instead, the project leaders rented an abandoned one-lane bowling alley in a small shopping center. With the installation of a security system, the windowless alley became an impromptu research lab.</p><p>There, progress notes spread across the alley floor, the engineers experimented with several methods for imaging the documents being copied on the embassy's model 914. An approach suggested by Zoppoth seemed the most promising: Mount a battery-powered home-movie camera with a zoom lens inside the copier. Aim the lens at the mirror used to reflect images onto the drum. Add a photocell that would prompt the camera to snap still frames whenever the photocopier lit up. And start taking pictures.</p><p>The engineers purchased a state-of-the-art Bell &amp; Howell movie camera from a retail outlet. It was about seven inches long and held a spool of 8mm film. There was plenty of room for the camera deep inside the bulky console-style copier, and the camera couldn't be seen even when the machine's covers were removed. The camera's noise was drowned out by the sounds of the photocopier.</p><p>The team installed the camera in a machine at the bowling alley, and photographed sample documents. "We used the bathroom as our darkroom," Zoppoth recalls.</p><p>Next, they installed a camera in a machine at the main Xerox office in Webster. "When we developed the pictures, we found recipes and copies of music and cartoons and jokes and all kinds of things," Zoppoth says.</p><p>Finally, the engineers were ready to turn their invention over to the CIA. Zoppoth made a series of trips to Washington to meet with two agents in the dark basement of a CIA building code-named Disneyland East. Surrounded by heating pipes, Zoppoth taught the agents how to install the camera, so that they could later train the Xerox repairman. The repairman would place a camera inside the Xerox machine while he serviced it; the camera didn't appear out of place among his jumble of tools and spare parts. On his next visit, he would replace the camera with another one containing fresh film, then turn the exposed film over to the CIA.</p></div> <!-- end .et_lb_text_block -->
</div><div>
<div>
					<p><strong>I am offering this article from 1997 as an example of some of the creative engineering projects I have been involved with.</strong></p> <!-- end .et_lb_module_content -->
				</div> <!-- end .et_lb_box -->
<div>
					<div>
						<div><p><a href="http://structuredbrands.com/wp-content/uploads/2014/07/camera-inside-copier.jpg" title=""><img alt="" src="http://structuredbrands.com/wp-content/uploads/2014/07/camera-inside-copier.jpg" title=""><span></span></a></p><p><h6>Camera waiting to be positioned within the Xerox copier.</h6>
</p> <!-- end .et_lb_image_content -->		</div> <!-- end .et_lb_module_content_inner -->
					</div> <!-- end .et_lb_module_content -->
				</div> <!-- end .et_lb_widget_area -->
<div>
					<div>
						<div><p><a href="http://structuredbrands.com/wp-content/uploads/2014/07/camera-in-xerox-machine.jpg" title=""><img alt="" src="http://structuredbrands.com/wp-content/uploads/2014/07/camera-in-xerox-machine.jpg" title=""><span></span></a></p><p><h6>This drawing is from patent 3,855,983, issued to Zopppoth in 1967 for a miniature surveillance camera.</h6>
</p> <!-- end .et_lb_image_content -->		</div> <!-- end .et_lb_module_content_inner -->
					</div> <!-- end .et_lb_module_content -->
				</div> <!-- end .et_lb_widget_area -->
<div><p>The system went into service in 1963. It wasn't long before the CIA asked the Xerox team if a similar system could be built for a much smaller desktop copier, the model 813.</p><p>Hiding an off-the-shelf camera inside such a small machine was impossible, so the engineers designed a miniaturized camera that operated off the photocopier's own power supply and held only a partial roll of film. They also modified the 813's mirrors and cut away pieces of the machine. Parts needed for the camera were farmed out to several model shops, so that nobody outside the research team could recognize what was being built. In 1964, Zoppoth was awarded a secret patent for the tiny surveillance camera that was hidden inside the modified machine.</p><p>Judging by the number of parts ordered from Xerox, Zoppoth believes that spy cameras may have been installed in photocopiers all over the world, to keep an eye on U.S. allies as well as enemies. But in 1969, a chemical company that had come up with a similar idea for spying on a competitor was caught red-handed. After that, it seemed likely that the Soviets would scrutinize their own machines more closely. But whether the Soviets ever found a concealed camera, or whether the CIA ceased planting them in photocopy machines, is uncertain.</p><p>Although the cameras built by Zoppoth and his co-conspirators seem primitive compared with today's sophisticated microelectronics, the project remains classified. Zoppoth retired in 1979. Another team member confirms his story but is unwilling to speak about any of the details. Other members could not be located, or would not discuss the matter. The CIA and Xerox will neither confirm nor deny Zoppoth's account, possibly because the company has secret research contracts with the government to this day.</p><h6>Stover, Dan<br>COPYRIGHT 1987 Bonnier Corporation</h6></div> <!-- end .et_lb_text_block -->
</div></div>]]>
            </description>
            <link>https://electricalstrategies.com/about/in-the-news/spies-in-the-xerox-machine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23886715</guid>
            <pubDate>Sun, 19 Jul 2020 03:11:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Front End Interview Handbook]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 8 (<a href="https://news.ycombinator.com/item?id=23886528">thread link</a>) | @yangshun
<br/>
July 18, 2020 | https://yangshun.github.io/front-end-interview-handbook/ | <a href="https://web.archive.org/web/*/https://yangshun.github.io/front-end-interview-handbook/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><header><div><p><img src="https://yangshun.github.io/front-end-interview-handbook/img/logo.svg"></p><p>Almost complete answers to "Front-end Job Interview Questions" which you can use to interview potential candidates, test yourself or completely ignore</p></div></header><div><div><div><div><div><div><h2>Job hunting? Sign up with Triplebyte to efficiently interview with top tech companies and land your dream job! 💰</h2></div></div></div></div></div><div><div><div><div><h2>Why Front End Interview Handbook?</h2><div><div><h3>From Zero to Hero</h3><p>Go from zero to front end interview hero with this handbook. No prior interview experience needed.</p></div><div><h3>Back to Basics</h3><p>Learn to walk before you learn to fly. While React, Vue and Angular are cool, make sure you also know your fundamentals.</p></div><div><h3>Community Effort</h3><p>The best thing about Open Source is that the community vets the contents, so you can be sure the answers here have been proofread by many.</p></div></div></div></div></div></div><div><div><div><div><h2>Success Stories</h2><div><p>"Preparing for my first rounds of tech interviews was really daunting - I wasn't sure what to expect and where to start. This handbook together with the <a href="https://github.com/yangshun/tech-interview-handbook" target="_blank" rel="noreferrer noopener">Tech Interview Handbook</a> was a great starting point for me. It clearly describes each part of the process and has tons of awesome tips and resources. With this handbook and lots of practice, I managed to get offers from Facebook, Dropbox and Amazon!"</p><div><div><p><img src="https://avatars1.githubusercontent.com/u/5081708?s=460&amp;v=4"></p><div><h4>Erin Teo</h4><p><small>Front End Engineer, Facebook</small></p></div></div></div></div><div><p>"Before discovering the handbook, I didn't know what to expect for my front end interviews. Thanks to it, I had a better understanding and even learned new things about frontend development. The handbook is an immense resource, one that I still use to refresh and reinforce my knowledge to tackle interviews confidently!"</p><div><div><p><img src="https://github.com/li-kai.png"></p><div><h4>Kai Li</h4><p><small>Software Engineer, Zendesk</small></p></div></div></div></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://yangshun.github.io/front-end-interview-handbook/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23886528</guid>
            <pubDate>Sun, 19 Jul 2020 02:26:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cross Entropy Loss vs Log Loss vs Sum of Log Loss]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23886417">thread link</a>) | @keyboardman
<br/>
July 18, 2020 | https://leimao.github.io/blog/Conventional-Classification-Loss-Functions/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Conventional-Classification-Loss-Functions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>In one of my previous blog posts on <a href="https://leimao.github.io/blog/Cross-Entropy-KL-Divergence-MLE/">cross entropy, KL divergence, and maximum likelihood estimation</a>, I have shown the “equivalence” of these three things in optimization. Cross entropy loss has been widely used in most of the state-of-the-art machine learning classification models, mainly because optimizing it is equivalent to maximum likelihood estimation. However, there could be other losses used for classification problems.</p>



<p>In this blog post, I would like to discussed the log loss used for logistic regression, the cross entropy loss used for multi-class classification, and the sum of log loss  used for multi-class classification.</p>

<h3 id="prerequisites">Prerequisites</h3>

<p>The prerequisites of this blog post have been discussed heavily in my other blog posts. For completeness, I made a copy of them here.</p>

<h4 id="leibniz-integral-rule">Leibniz Integral Rule</h4>

<p>Leibniz integral rule allows swapping positions of derivatives under certain circumstances.</p>



<p>To check the quick proof of Leibniz integral rule, please check one my blog posts on <a href="https://leimao.github.io/blog/RL-Policy-Gradient-Unbiase-Estimate/">this</a>.</p>

<h4 id="derivatives-of-expected-value">Derivatives of Expected Value</h4>

<p>Based on Leibniz integral rule, we could also move the positions of derivatives inside the expected value or outside the expected value. For instance,</p>



<p>If $\mathbb{E}_{(x,y) \sim P(x,y)}\big[ \mathscr{L}_{\theta}(x,y) \big]$ is the loss function, to compute the derivative of the entire loss with respect to the parameter $\theta$, it is equivalent to computing the derivatives of the losses contributed by each data point $\mathscr{L}_{\theta}(x, y)$ with respect to the parameter $\theta$ and followed by computing its expected value, $\mathbb{E}_{(x,y) \sim P(x, y)}\big[ \frac{\partial}{\partial \theta} \mathscr{L}_{\theta}(x, y) \big]$. Assuming all the data $(x, y)$ are uniformly distributed, it is simply just computing the derivative of the losses contributed by each data point $\mathscr{L}_{\theta}(x, y)$ with respect to the parameter $\theta$ and followed by taking their average. This is also how modern deep learning framework, such as TensorFlow and PyTorch, works.</p>

<h3 id="log-loss-for-logistic-regression">Log Loss for Logistic Regression</h3>

<p>Log loss has been used for logistic regression for a long time. Given $(x, y)$, where $x$ is the input, $y$ is the label for $x$, our goal is to develop a model $f_{\theta}$, where $\theta$ are the model parameters. such that $\tilde{y} = f_{\theta}(x)$ is as close to $y$ as possible. For logistic regression, usually $y = 0$ or $1$. $y = 1$ means $x$ belongs to certain class, whereas $y = 0$ means $x$ does not belong to certain class.</p>



<p>Usually, logistic regression will compute the logit $z$ for the input $x$, where $z = g_{\theta}(x)$ followed by computing the sigmoid activation for $z$ to get the estimate of $y$, $\tilde{y}$, in the range of $(0,1)$. Concretely,</p>



<p>The loss function used for fitting is called log loss, which we would see later that it is actually binary cross entropy loss.</p>



<p>We further compute the derivative of this log loss with respect to the logit $z$.</p>





<p>Therefore,</p>



<p>The interpretation is very simple. If $\tilde{y} &gt; y$, $\frac{\partial}{\partial z} \mathscr{L}_{\theta}(x,y) &gt; 0$, the gradient descent wants to make $z$ smaller. Once $z$ is smaller, $\tilde{y}$ will be smaller and its deviation from $y$ will become smaller. Similarly, If $\tilde{y} &lt; y$, $\frac{\partial}{\partial z} \mathscr{L}_{\theta}(x,y) &lt; 0$, the gradient descent wants to make $z$ larger. Once $z$ is larger, $\tilde{y}$ will be larger and its deviation from $y$ will become smaller.</p>



<p>To update the model parameters $\theta$, we would need to compute the derivatives with respect to $\theta$.</p>



<h3 id="cross-entropy-loss-for-multi-class-classification">Cross Entropy Loss for Multi-Class Classification</h3>

<p>Cross entropy loss has been widely used for classification problems in deep learning. Given $(x, \mathbf{y})$, where $x$ is the input, $\mathbf{y}$ is the label for $x$. If $\mathbf{y}$ is an one-hot vector of size $n$, and $\mathbf{y}_i = 1$, our goal is to develop a model $f_{\theta}$, where $\theta$ are the model parameters, such that $\tilde{\mathbf{y}}_i = f_{\theta}(x)$ is as close to $\mathbf{y}_i$ as possible. Note that the motivation of using cross entropy loss behind is maximum likelihood estimation which might not be obvious to see. But I have discussed in my previous blog <a href="https://leimao.github.io/blog/Cross-Entropy-KL-Divergence-MLE/">post</a>.</p>



<p>Usually, multi-class classification will compute the logits $\mathbf{z}$ for the input $x$, where $\mathbf{z} = g_{\theta}(x)$ followed by computing the softmax activation for $\mathbf{z}$ to get the estimate of $\mathbf{y}$, $\tilde{\mathbf{y}}$, where $\sum_{i=1}^{n} \tilde{\mathbf{y}}_i = 1$ and $\tilde{\mathbf{y}}_i \in [0, 1]$ for $i \in [1, n]$. Concretely,</p>



<p>The loss function used for fitting is called softmax loss.</p>



<p>We further compute the derivative of this cross entropy loss with respect to the logits $\mathbf{z}$.</p>







<p>Therefore,</p>



<p>The interpretation is also very simple. If $\tilde{\mathbf{y}}_k &gt; \mathbf{y}_k$, $\frac{\partial}{\partial \mathbf{z}_k} \mathscr{L}_{\theta}(x,\mathbf{y}) &gt; 0$, the gradient descent wants to make $\mathbf{z}_k$ smaller. Once $\mathbf{z}_k$ is smaller, $\tilde{\mathbf{y}}_k$ will be smaller and its deviation from $\mathbf{y}_k$ will become smaller. Similarly, If $\tilde{\mathbf{y}}_k &lt; \mathbf{y}_k$, $\frac{\partial}{\partial \mathbf{z}_k} \mathscr{L}_{\theta}(x,\mathbf{y}) &lt; 0$, the gradient descent wants to make $\mathbf{z}_k$ larger. Once $\mathbf{z}_k$ is larger, $\tilde{\mathbf{y}}_k$ will be larger and its deviation from $\mathbf{y}_k$ will become smaller.</p>



<p>To update the model parameters $\theta$, we would need to compute the derivatives with respect to $\theta$.</p>



<h3 id="cross-entropy-loss-for-multi-class-classification-vs-log-loss-for-logistic-regression">Cross Entropy Loss for Multi-Class Classification VS Log Loss for Logistic Regression</h3>

<p>If we have $n = 2$ for cross entropy loss and compare it with log loss, we would immediately see that the form of log loss is exactly the same to binary cross entropy loss, and log loss for logistic regression is a special case for cross entropy loss for multi-class classification where $n = 2$ and the logit $z$ for the negative class ($y = 0$) is a fixed value $0$.</p>



<p>So if we have a binary classification problem, what is the difference between modeling it using log loss for logistic regression and cross entropy loss for binary classification, assuming the learning rate and other hyperparameters are the same? We could see that the gradients with respect to the positive logit $z$ for both models are always the same. However, when it comes to updating the model parameters $\theta$, the gradients for the two models would be different, because one model has only one logit whereas the other model has two logits. Therefore, although the two models are analogous, it is incorrect to say these two models are exactly the same.</p>



<p>One may ask which model is better for a binary classification problem. It is hard to say. But one thing that is for sure is that the binary cross entropy model is relatively easy to overfit. The reasons are the followings:</p>

<ul>
  <li>The binary cross entropy model has more parameters compared to the logistic regression.</li>
  <li>The binary cross entropy model would try to adjust the positive and negative logits simultaneously whereas the logistic regression would only adjust one logit and the other hidden logit is always $0$, resulting the difference between two logits larger in the binary cross entropy model much larger than that in the logistic regression model.</li>
</ul>

<p>To prevent overfitting, we could use <a href="https://leimao.github.io/blog/Label-Smoothing/">label smoothing</a> for cross entropy loss. I have discussed it previously and I am not going to elaborate it here.</p>

<h3 id="sum-of-log-loss-for-multi-class-classification">Sum of Log Loss for Multi-Class Classification</h3>

<p>While it might be rare, we could treat a multi-class classification problem as multiple one-vs-all classifications, each of which is a logistic regression. Given $(x, \mathbf{y})$, where $x$ is the input, $\mathbf{y}$ is the label for $x$. Our goal is to develop a model $f_{\theta}$, where $\theta$ are the model parameters, such that $\tilde{\mathbf{y}}_j = f_{\theta}(x)$ is as close to $\mathbf{y}_j$ as possible, for all $j \in [1, n]$. Note that this is different from cross entropy loss for multi-class classification.</p>



<p>Usually, multi-class classification will compute the logits $\mathbf{z}$ for the input $x$, where $\mathbf{z} = g_{\theta}(x)$ followed by computing the sigmoid activation for each logit of $\mathbf{z}$ to get the estimate of $\mathbf{y}$, $\tilde{\mathbf{y}}$, where notably $\sum_{i=1}^{n} \tilde{\mathbf{y}}_i$ and $\sum_{i=1}^{n} \mathbf{y}_i$ do not have to equal to 1, and $\tilde{\mathbf{y}}_i \in [0, 1]$ for $i \in [1, n]$. Concretely,</p>



<p>The loss function used for fitting is called the sum of log loss. The classification of each class could be seen as mutually exclusive. TensorFlow has an implementation for this loss, which they call it <a href="https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits">tf.nn.sigmoid_cross_entropy_with_logits</a>, as well.</p>



<p>We further compute the derivative of this sum of log loss with respect to the logits $\mathbf{z}$. Because it is almost exactly the same to the derivative of log loss with respect to the logits $z$, we skipped some details.</p>





<p>Therefore,</p>



<p>The interpretation is the same as cross entropy loss for multi-class classification. If $\tilde{\mathbf{y}}_k &gt; \mathbf{y}_k$, $\frac{\partial}{\partial \mathbf{z}_k} \mathscr{L}_{\theta}(x,\mathbf{y}) &gt; 0$, the gradient descent wants to make $\mathbf{z}_k$ smaller. Once $\mathbf{z}_k$ is smaller, $\tilde{\mathbf{y}}_k$ will be smaller and its deviation from $\mathbf{y}_k$ will become smaller. Similarly, If $\tilde{\mathbf{y}}_k &lt; \mathbf{y}_k$, $\frac{\partial}{\partial \mathbf{z}_k} \mathscr{L}_{\theta}(x,\mathbf{y}) &lt; 0$, the gradient descent wants to make $\mathbf{z}_k$ larger. Once $\mathbf{z}_k$ is larger, $\tilde{\mathbf{y}}_k$ will be larger and its deviation from $\mathbf{y}_k$ will become smaller.</p>



<p>To update the model parameters $\theta$, we would need to compute the derivatives with respect to $\theta$.</p>



<p>The formula is exactly the same as the one used for cross entropy loss for multi-class classification.</p>

<h3 id="cross-entropy-loss-for-multi-class-classification-vs-sum-of-log-loss-for-multi-class-classification">Cross Entropy Loss for …</h3></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/blog/Conventional-Classification-Loss-Functions/">https://leimao.github.io/blog/Conventional-Classification-Loss-Functions/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/blog/Conventional-Classification-Loss-Functions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23886417</guid>
            <pubDate>Sun, 19 Jul 2020 02:03:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Selecting the Right Industrial 3D Printer]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23886357">thread link</a>) | @ddingus
<br/>
July 18, 2020 | https://pluralam.com/selecting-right-industrial-3d-printer/ | <a href="https://web.archive.org/web/*/https://pluralam.com/selecting-right-industrial-3d-printer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <header data-post-id="3659" data-type="header" data-sticky="0" data-sticky-breakpoint="medium" data-shrink="0" data-overlay="0" data-overlay-bg="transparent" data-shrink-image-height="50px" itemscope="itemscope" itemtype="http://schema.org/WPHeader"><div data-node="5e8b67d85529f"><div><div><div data-node="5e8b67d85afcc"><div data-node="5e8b67d85b2c1"><div><div data-node="5e8b947ce1af9"><div><p><strong>Covid-19 concerns? We're open and here to help.</strong></p></div></div></div></div></div></div></div></div><div data-node="5a3afb8b36265"><div><div><div data-node="5a3afb8b362af"><div data-node="5a3afb8b362f0"><div><div data-node="5a3afc6aaed49"><div><div itemscope="" itemtype="https://schema.org/ImageObject"><p><a href="https://pluralam.com/" target="_self" itemprop="url"> <img src="https://s3-us-west-2.amazonaws.com/freddieflip/uploads/sites/28/2019/09/23124915/Plural_logo_.png" alt="Plural Additive Manufacturing logo" itemprop="image" title="Plural_logo_+" data-no-lazy="1" srcset="https://freddieflip.s3.us-west-2.amazonaws.com/uploads/sites/28/2019/09/23124915/Plural_logo_.png 877w, https://freddieflip.s3.us-west-2.amazonaws.com/uploads/sites/28/2019/09/23124915/Plural_logo_-400x119.png 400w, https://freddieflip.s3.us-west-2.amazonaws.com/uploads/sites/28/2019/09/23124915/Plural_logo_-768x228.png 768w" sizes="(max-width: 877px) 100vw, 877px"> </a></p></div></div></div></div></div></div></div></div></div> </header><div id="fl-main-content" itemprop="mainContentOfPage" role="main"><div><div><div> <article class="page" id="fl-post-3685" itemscope="itemscope" itemtype="https://schema.org/CreativeWork"><div itemprop="text"><div data-post-id="3685"><div data-node="5a6231eab95f5"><div><div><div data-node="5a6231eabb645"><div data-node="5a6231eabb73b"><div><div data-node="5a6232f4062a8"><p><h3> <span>A Guide To Maximizing Your Investment</span></h3></p></div></div></div></div></div></div></div><div data-node="5a6233592fd00"><div><div><div data-node="5a62335932e13"><div data-node="5a62335932f19"><div><div data-node="5a62338f22736"><div><div><div><div><div><p>You’ve decided you need a 3D printer (or you haven’t – yet – and want to make that determination for yourself). With all of the 3D printers on the market today, how do you make the best decision for your needs long term?</p><p><strong>It begins with knowing your requirements, both present and future</strong>, and knowing what to look for in potential vendors and printer options.</p><p>Our Guide to Selecting an Industrial 3D Printer will help you answer those questions.</p><p>The guide also includes worksheets to capture your requirements and assess the vendor’s ability to meet your specifications.</p><p>3D printing can be a huge benefit for many companies when selected and executed upon properly. Our hope is that this guide will help you make the best choice for your needs, your budget and your business.</p></div></div></div></div></div></div></div></div></div></div></div></div></div></div> </article></div></div></div></div> </div></div>]]>
            </description>
            <link>https://pluralam.com/selecting-right-industrial-3d-printer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23886357</guid>
            <pubDate>Sun, 19 Jul 2020 01:51:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On the Naturalness of Software (2012) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23886291">thread link</a>) | @tosh
<br/>
July 18, 2020 | https://amasad.me/public/natural.pdf | <a href="https://web.archive.org/web/*/https://amasad.me/public/natural.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://amasad.me/public/natural.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23886291</guid>
            <pubDate>Sun, 19 Jul 2020 01:36:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Close Are We to a Vaccine for Covid-19?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23885889">thread link</a>) | @kohtatsu
<br/>
July 18, 2020 | https://newsinteractives.cbc.ca/coronavirusvaccinetracker/ | <a href="https://web.archive.org/web/*/https://newsinteractives.cbc.ca/coronavirusvaccinetracker/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>

    <section>
      

      <p>
        An effective vaccine against the coronavirus that causes COVID-19 is everyone's hope for a real return to normal life. More than 100 teams of scientists around the world are working to develop and test a vaccine against the virus SARS-CoV-2 as quickly as possible. They're employing  a huge variety of strategies and technologies, including some that have never been used in an approved vaccine before.</p>

        <p>"It's a very fascinating and kind of impressive effort," said Dr. Lynora Saxinger, an infectious disease specialist at the at the University of Alberta in Edmonton.</p>
        <p>"It's absolutely crucial."</p>
        <p>Even in countries that have had a devastating number of deaths from COVID-19, there is nowhere close to a level of "herd immunity" within the population preventing the disease from spreading exponentially if we go back to normal levels of social interaction, she said.</p>

        </section>

        <section>

        <h2>How far are we from the first SARS-CoV-2 vaccine?</h2>
    
      <p>Typically, it takes an average of <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3603987/">more than 10 years</a> for a vaccine to get from <a href="https://www.cbc.ca/news/health/vaccine-clinical-trials-1.5580436">pre-clinical development (including animal testing) through three phases of clinical (human) trials</a> to market registration.</p>

      <p>The process has been fast-tracked  for COVID-19. The first human vaccine trials began in March, just two months after the virus and disease were identified. And <a href="https://www.cbc.ca/news/health/vaccine-clinical-trials-1.5580436">different phases of human trials</a> are being run in an overlapping fashion instead of one at time — for example, Phase 2 might begin just a few weeks after the start of a six-month Phase 1 trial. </p>

      <p>Canada has a notably large number of vaccine candidates registered with the World Health Organization — at least seven.</p>
     
      <div id="tableAll">
          <h2>Candidate vaccines in clinical trials</h2>
           
          
          
      </div>

    </section>

    
    <section>

      <h2>Multiple vaccines on the horizon?</h2>
    
      <p>Most vaccine candidates that make it to preclinical testing never make it to market (about <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3603987/">94 per cent fail, a 2013 study</a> found). But in this case, with so many different vaccines under development, there may still end up being multiple vaccines for the coronavirus, possibly using different strategies, Saxinger predicts.</p>

      <p>There are a number of potential advantages if that happens:
        </p><ul>
          <li>They'd be using different ingredients and manufacturing facilities and wouldn't be competing for resources — allowing for more vaccine production.</li>
          <li>Different vaccines have different pros and cons. Some vaccines require more doses to be effective than others, while ease of manufacturing, testing and distribution varies.</li>
          <li>Some vaccines may be more suitable for some populations than others, due to factors such as age or genetics.</li>
        </ul>      
      

      <p>Stephen Barr is associate professor of microbiology and immunology who is part of a COVID-19 vaccine development team at at Western University in London, Ont. He noted that the "best" vaccine in the end may not be best for everybody. "But the second one might be, for those that don't respond, right? So it's always good to have these backup vaccines as well or vaccines that can be used in parallel around the world."</p>

    </section>


  <hr>

  <section>

    <section>

      
      <h3>Whole virus vaccines</h3>
    
      <p>These are the most traditional types of vaccine. They've been used for a long time, and most of us have had these kinds of vaccines.</p>

    </section>


   <section id="inactivated">

    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 112 112" role="presentation" focusable="false"><path d="m0 0h112v112h-112z" fill="none"></path><path d="m89.5327 69.0724a35.8635 35.8635 0 0 0 0-26.1448c8.4931 1.3366 21.9273-2.8676 14.9647-14.9276-6.9672-12.0676-17.334-2.5154-20.4155 5.5113a36.0045 36.0045 0 0 0 -22.6275-13.0986c5.3986-6.691 8.4634-20.4127-5.4544-20.4127s-10.853 13.7218-5.4544 20.4127a36.0045 36.0045 0 0 0 -22.6274 13.0988c-3.0814-8.0268-13.4482-17.5792-20.4156-5.5115-6.9626 12.06 6.4718 16.2643 14.9648 14.9275a35.8633 35.8633 0 0 0 0 26.145c-8.4927-1.3369-21.9274 2.8675-14.9648 14.9275 6.9674 12.0677 17.3344 2.515 20.4157-5.5118a36.0043 36.0043 0 0 0 22.6276 13.0988c-5.3988 6.6907-8.464 20.413 5.4541 20.413s10.8529-13.7223 5.4542-20.413a36.0044 36.0044 0 0 0 22.6276-13.0985c3.0814 8.0267 13.4482 17.5792 20.4156 5.5115 6.9626-12.06-6.4717-16.2643-14.9647-14.9276zm-33.5327 14.9276a28 28 0 1 1 28-28 28.0315 28.0315 0 0 1 -28 28z"></path></svg>

      <h4>Inactivated virus</h4>
    
      <p>In this case, the virus is grown in large quantities in cells, and then killed, often with a chemical, which is usually formaldehyde, but heat or radiation can also be used. Two kinds of flu vaccines are made this way, grown in either chicken eggs or mammalian cells.</p>


      <section>
        
        <h5>Pros</h5>
        <ul>
          <li>Unlike live virus vaccines, it can even be given to people with weakened immune systems.</li>
        </ul>

        <h5>Cons</h5>
        <ul>
          <li>It doesn't lead to as strong an immune response as a live virus. Several doses, including boosters at regular intervals, are usually necessary.</li>
          <li>It requires the virus to be grown in large quantities and that can take time and may not be as easy to scale up as other kinds of vaccines.</li>          
        </ul>
      </section>

      
    </section>


   <section id="live-attenuated-virus">

    <svg viewBox="0 0 112 112" xmlns="http://www.w3.org/2000/svg" role="presentation" focusable="false"><path d="m0 0h112v112h-112z" fill="none"></path><g fill="#231f20"><path d="m56 76a20 20 0 1 1 20-20 20.0226 20.0226 0 0 1 -20 20zm0-32a12 12 0 1 0 12 12 12.0134 12.0134 0 0 0 -12-12z"></path><path d="m89.6737 69.0477a16.4016 16.4016 0 0 0 2.8022-13.0477c-.2249-.9536-.852-2.6981-1.1775-3.6428a29.9568 29.9568 0 0 1 -2.097-9.4877c8.4686 1.5023 22.3507-2.6505 15.296-14.8695-6.6585-11.5329-16.4235-3.3187-19.9659 4.4384a15.4055 15.4055 0 0 0 -2.7391-2.2308c-2.3255-1.4014-5.0471-2.2822-7.3338-3.7583a62.0759 62.0759 0 0 1 -5.3209-4.062 15.8281 15.8281 0 0 0 -6.9439-2.9507c4.9088-6.9615 7.075-19.4366-6.1938-19.4366-14.4671 0-10.5854 14.8273-4.8058 21.1713a38.4909 38.4909 0 0 1 -9.68 1.7606 16.34 16.34 0 0 0 -11.3068 7.2757 42.3652 42.3652 0 0 0 -2.0215 4.0375c-2.705-8.1538-13.5027-18.6823-20.6833-6.2451-6.9226 11.99 6.32 16.2183 14.82 14.9529a16.177 16.177 0 0 0 -2.3634 14.5382l.7425 2.1517a27.9405 27.9405 0 0 1 2.0095 8.5581c.0041.3073.02.6147.042.9217-8.4726-1.4794-22.2926 2.6803-15.2506 14.8774 6.657 11.53 16.4192 3.3222 19.9637-4.4332a15.0734 15.0734 0 0 0 2.7414 2.2255c2.3253 1.4014 5.0471 2.2823 7.3338 3.7583a62.1105 62.1105 0 0 1 5.3208 4.062 15.9449 15.9449 0 0 0 6.9286 2.9716c-4.8982 6.9658-7.0461 19.4158 6.2091 19.4158 14.4627 0 10.5878-14.8184 4.8113-21.1656a29.8607 29.8607 0 0 1 7.39-1.5455 16.5826 16.5826 0 0 0 13.5915-7.4967 42.3263 42.3263 0 0 0 2.0215-4.0373c2.7048 8.1538 13.5025 18.6823 20.6831 6.2451 6.9237-11.9922-6.3239-16.2195-14.8237-14.9523zm-13.8037 6.8217-.5783 1.09c-1.3627 2.8509-4.561 4.2681-7.5733 4.325a38.5962 38.5962 0 0 0 -11.7184 2.8156 8.5269 8.5269 0 0 1 -9.5887-1.9372 38.5724 38.5724 0 0 0 -9.7175-6.0628 13.4634 13.4634 0 0 1 -1.6528-.8089 8 8 0 0 1 -4.1357-5.7276 43.325 43.325 0 0 0 -2.7681-13.0019 9.4512 9.4512 0 0 1 -.8393-5.3626 9.1253 9.1253 0 0 1 2.5394-4.7878 38.574 38.574 0 0 0 6.0627-9.7174 13.42 13.42 0 0 1 .8089-1.6528c1.3626-2.8509 4.5611-4.2681 7.5734-4.3249a39.1834 39.1834 0 0 0 11.156-2.5788 8.5927 8.5927 0 0 1 10.15 1.7 38.57 38.57 0 0 0 9.7179 6.0627 13.4849 13.4849 0 0 1 1.6528.8089c2.8508 1.3628 4.2679 4.5612 4.325 7.5734a39.1756 39.1756 0 0 0 2.5787 11.1561 9.4511 9.4511 0 0 1 .8394 5.3626 9.1257 9.1257 0 0 1 -2.5394 4.7878 38.1874 38.1874 0 0 0 -6.2927 10.2806z"></path></g></svg>

      <h4>Live, attenuated virus</h4>
    
      <p>In this case, viruses are also grown in cells, but instead of being killed they're  genetically "weakened" so they can't infect cells and reproduce as effectively. Traditionally, this was done by getting the virus to grow in and adapt to an environment different than the one they normally infect. That's the approach used for vaccines such as varicella (chicken pox) or yellow fever. The SARS-CoV-2 vaccine candidates of this type use a high-tech genetic engineering approach called "codon deoptimization," where the virus is rebuilt from scratch, incorporating targeted mutations that weaken it. None of these vaccine prototypes for COVID-19 have made it to human trials.</p>

      <section>
        
        <h5>Pros</h5>
        <ul>
          <li>Similar to real infection and usually provides long-lasting protection — sometimes lifelong — after one dose.</li>
        </ul>

        <h5>Cons</h5>
        <ul>
          <li>May not be suitable for people with weakened immune systems, long-term health problems, or people who've had organ transplants.</li>
          <li>Live viruses need to be refrigerated, making them more difficult to transport and unusable in countries without access to refrigeration.</li>
          <li>The virus must be grown in large quantities. That can take time and it may not be easy to scale up.</li>          
        </ul>
      </section>

      

    </section>

    
    <section>

      <hr>

      <h2>Vaccines that target part of a virus</h2>
    
        <p>These types of vaccines don't contain entire viruses. They present parts of viruses, such as proteins or sugars, to your immune system to help it learn to recognize the virus and build an immune response.</p>

        <p>In the case of SARS-CoV-2, the part of the virus that's typically targeted is the spike or "S" protein — the projections on its outer coat that make it look like a crown under a microscope ("corona" means "crown.") That's the protein the virus uses to bind to human cells, allowing it to enter. </p>

        <p>What varies  among different vaccine candidates is the way they make the spike protein and get it into the body — it may be injected directly, transported by a "carrier" virus that doesn't cause disease, or it may be manufactured by the human body itself using instructions encoded in DNA or RNA.</p>

    </section>

     <section id="protein-subunit">

    <svg viewBox="0 0 112 112" xmlns="http://www.w3.org/2000/svg" role="presentation" focusable="false"><g><circle cx="63.1726" cy="40.5452" r="12"></circle><circle cx="40.5452" cy="63.1726" r="12"></circle><circle cx="71.4548" cy="71.4548" r="12"></circle></g><path d="m0 0h112v112h-112z" fill="none"></path></svg>

      <h4>Protein subunit</h4>
    
      <p>With this type of vaccine, the protein is made outside the body. Traditionally, this was done by breaking whole viruses into pieces using detergent or a solvent such as ether. However, this can now be done with "recombinant" genetic technology, where the gene for a protein is inserted into another organism to grow the protein in large quantities. 
      </p>

      <section>
        
        <h5>Pros</h5>
        <ul>
          <li>Can be produced more quickly than live vaccines.</li>
        </ul>

        <h5>Cons</h5>
        <ul>
          <li>Doesn't generate as strong an immune response as whole virus vaccines. A compound called an adjuvant needs to be included to boost a patient's immune response.</li>
          <li>Can't be scaled up as quickly as production of RNA or DNA vaccines.</li>        
        </ul>
      </section>

      

    </section>

    


    <section id="virus-like-particles">

    <svg viewBox="0 0 112 112" xmlns="http://www.w3.org/2000/svg" role="presentation" focusable="false"><g><circle cx="56" cy="24" r="12"></circle><circle cx="56" cy="88" r="12"></circle><circle cx="28.2872" cy="40" r="12"></circle><circle cx="83.7128" cy="72" r="12"></circle><circle cx="28.2872" cy="72" r="12"></circle><circle cx="83.7128" cy="40" r="12"></circle></g><path d="m0 0h112v112h-112z" fill="none"></path></svg>

      <h4>Virus-like particles</h4>
    
      <p>These are a special class of subunit vaccines, where the proteins are self-assembled into artificial particles that are intended to look like viruses to the human immune system. They bind to and enter cells like a virus, which is different from the way individual protein subunits do.</p>

      <p>Some vaccines on the market that use VLPs include vaccines for HPV (human papilloma virus) and Hepatitis B.</p>

      <section>
        
        <h5>Pros</h5>
        <ul>
          <li>Produce a stronger immune response than regular subunit vaccines.</li>
          <li>Production is much faster than for traditional vaccines.</li>
        </ul>

        <h5>Cons</h5>
        <ul>
          <li>Ensuring stability and purification can add to production time.</li>
          <li>Can be hard to produce in large quantities.</li>   
        </ul>
      </section>

      
    </section>

    

    <section id="non-replicating-viral-vector">

    <svg viewBox="0 0 112 112" xmlns="http://www.w3.org/2000/svg" role="presentation" focusable="false"><path d="m0 0h112v112h-112z" fill="none"></path><g><path d="m89.5324 69.0725a35.8633 35.8633 0 0 0 0-26.145c8.493 1.3369 21.9276-2.8675 14.965-14.9275-6.9674-12.0678-17.3343-2.5151-20.4157 5.5117a36.0043 36.0043 0 0 0 -22.6275-13.0988c5.3987-6.6908 8.4637-20.4129-5.4542-20.4129s-10.8529 13.722-5.4543 20.4129a36.0043 36.0043 0 0 0 -22.6275 13.0984c-3.0815-8.0267-13.4482-17.5789-20.4156-5.5113-6.9626 12.06 6.4715 16.2642 14.9645 14.9276a35.8644 35.8644 0 0 0 0 26.1449c-8.493-1.3367-21.9271 2.8675-14.9645 14.9275 6.9672 12.0676 17.3341 2.5155 20.4156-5.5113a36.0048 36.0048 0 0 0 22.6275 13.0985c-5.3986 6.6908-8.4636 20.4128 5.4543 20.4128s10.8529-13.7221 5.4542-20.4129a36.0046 36.0046 0 0 0 22.6275-13.0987c3.0814 8.0268 13.4483 17.5794 20.4157 5.5116 6.9626-12.06-6.472-16.2644-14.965-14.9275zm-33.5324 14.9275a28 28 0 1 1 28-28 28.0314 28.0314 0 0 1 -28 28z"></path><path d="m43.3493 65.8223a4.0894 4.0894 0 0 0 .7723-4.5772 12.9764 12.9764 0 0 1 17.1235-17.1235 4.0894 4.0894 0 0 0 4.5772-.7723l.0006-.0006a3.9906 3.9906 0 0 0 -1.0946-6.4431 20.992 20.992 0 0 0 -27.8227 27.8227 3.9906 3.9906 0 0 0 6.4431 1.0946z"></path><path d="m68.6513 46.1771-.0006.0006a4.0894 4.0894 0 0 0 -.7723 4.5772 12.9764 12.9764 0 0 1 -17.1235 17.1235 4.0894 4.0894 0 0 0 -4.5772.7723l-.0006.0006a3.9906 3.9906 0 0 0 1.0946 6.4431 20.992 20.992 0 0 0 27.8227-27.8227 3.9906 3.9906 0 0 0 -6.4431-1.0946z"></path></g></svg>

      <h4>Non-replicating viral vector</h4>
    
      <p>Viral vectors are "carrier" viruses that don't cause the disease you're vaccinating against, such as COVID-19, but can be engineered to carry a piece of viruses such as SARS-CoV-2. Non-replicating viral vectors are viruses that have been genetically engineered so they can't replicate and cause disease. Then they're further modified to produce the protein for the disease you want, such as the coronavirus spike protein, and injected into the body to provoke an immune response.</p>

      <p>The viruses used by COVID-19 vaccine candidates include adenoviruses, MVA (modified vaccinia ankara, a weakened pox virus), parainfluenza and rabies.</p>

      <section>
        
        <h5>Pros</h5>
        <ul>
          <li>Generates more powerful immune response than subunit proteins.</li>
          <li>Some don't have to be stored at very low temperatures (according to China-based company CanSino), so they're viable for use in resource-limited tropical areas.</li>
        </ul>

        <h5>Cons</h5>
        <ul>          

          <li>People who have already been exposed to the viral vector, such as adenovirus, may be resistant.</li>
          <li>Harder to scale up than protein or DNA because a virus still needs to be grown.</li>
          <li>Because each virus can only infect one cell, large quantities of the virus need to be grown and injected, adding to production time.</li>   
        </ul>
      </section>

      

    </section>

    

    <section id="replicating-viral-vector">

    <svg viewBox="0 0 112.1136 112" xmlns="http://www.w3.org/2000/svg" role="presentation" focusable="false"><g><circle cx="77.6573" cy="59.4777" r="6"></circle><circle cx="85.6573" cy="73.3341" r="6"></circle><circle cx="93.6573" cy="59.4777" r="6"></circle><circle cx="37.2987" cy="40.137" r="6"></circle><circle cx="23.4423" cy="48.137" r="6"></circle><circle cx="37.2987" cy="56.137" r="6"></circle><circle cx="47.2269" cy="73.3331" r="6"></circle></g><path d="m0 0h112v112h-112z" fill="none"></path><path d="m111.56 59.6174a31.8978 31.8978 0 0 1 -2.0444-7.9993c.0021-1.2135-.149-2.9625-.1606-4.193a14.8194 14.8194 0 0 0 -4.5155-9.55 16.8631 16.8631 0 0 0 -4.6887-3.0675 16.8737 16.8737 0 0 1 -6.0433-4.9893 16.7294 16.7294 0 0 0 -13.0511-7.46c-3.29.02-6.6533-.2771-9.5345-1.9923a17.6146 17.6146 0 0 0 -14.5979-2.056c-3.0481 1.1222-6.3 1.8331-9.5356 1.0335a17.5134 17.5134 0 0 0 -16.2859 3.62c-2.6283 2.1057-5.874 3-9.1541 3.5445a16.1335 16.1335 0 0 0 -10.5679 7.891 39.1617 39.1617 0 0 1 -3.1157 5.3242 48.257 48.257 0 0 1 -4.2527 4.5575 14.93 14.93 0 0 0 -3.8211 11.6 55.9544 55.9544 0 0 0 1.4233 5.7832 33.1576 33.1576 0 0 1 .47 8.24 14.7352 14.7352 0 0 0 7.3817 12.3748l1.2245.7278c3.1212 1.5925 5.5 4.0988 7.84 6.6462a14.7762 14.7762 0 0 0 13.2246 3.922 28.4788 28.4788 0 0 1 10.1936-1.2971 24.5432 24.5432 0 0 0 13.24-1.1c.3186-.143 1.3477-.4868 1.6932-.62a8.8478 8.8478 0 0 1 6.9122.5269 36.1724 36.1724 0 0 0 5.1759 2.526 14.9127 14.9127 0 0 0 9.2805.0709c3.2267-1.24 6.489-2.3824 9.9915-2.4126 5.6884.11 11.5523-3.2194 13.8614-8.5118.3962-1.0208 1.0828-2.1492 1.5257-3.1347a33.386 33.386 0 0 1 5.0818-6.512 14.8836 14.8836 0 0 0 2.8491-13.4929zm-7.5036 5.4739a8.8473 8.8473 0 0 1 -2.5779 4.2855 29.6462 29.6462 0 0 0 -5.4171 7.6965c-.2681.6709-.8938 1.8976-1.2073 2.5654-2.415 4.7-7.5625 3.3425-11.797 4.2611a31.86 31.86 0 0 0 -4.5251 1.2635c-1.8986.7341-3.8971 1.6295-5.9868 1.21a19.6966 19.6966 0 0 1 -5.1585-2.3336 16.6507 16.6507 0 0 0 -11.6953-1.3667c-3.5533 1.1385-7.0761 2.7073-10.8991 1.9811a30.793 30.793 0 0 0 -12.8886.7521c-6.5187 2.1953-8.2463-2.5174-12.46-5.9751a43.799 43.799 0 0 0 -6.265-4.1454c-2.5329-1.4867-3.4956-4.5724-3.1621-7.346a28.9717 28.9717 0 0 0 -1.0341-9.3548c-1.1236-2.9685-1.5217-6.5122.8679-8.9959a32.5171 32.5171 0 0 0 7.0043-8.6724c1.4-2.9875 3.3567-6.0911 6.8766-6.7063a26.0119 26.0119 0 0 0 11.1127-4.2256c2.6143-2.0854 5.6849-4.0746 9.21-3.2488a23.5549 23.5549 0 0 0 12.219.0622c4.1764-1.5474 7.6086-2.0814 11.5251.5422a22.6856 22.6856 0 0 0 9.8578 2.8211c2.1459.1215 4.4293-.12 6.383.9667a10.2676 10.2676 0 0 1 3.8555 3.5776 23.6337 23.6337 0 0 0 7.635 6.5688c.7164.3909 1.7728.9692 2.5046 1.3082a7.625 7.625 0 0 1 3.5255 7.19 30.4489 30.4489 0 0 0 1.8338 10.3536 8.6671 8.6671 0 0 1 .6626 4.965z"></path></svg>

      <h4>Replicating viral vector</h4>
    
      <p>These are "carrier" viruses that can replicate in the body, but are either weakened or don't cause any symptoms in humans. Like non-replicating viral vectors, they're modified to produce a protein from the virus you want to protect against, such as the spike protein from SARS-CoV-2.</p>


      <p>The replicating viral vectors used in COVID-19 vaccine candidates include weakened versions of influenza and measles, as well viruses that cause animal diseases such as horsepox and VSV (Vesicular stomatitis virus).</p>

      <section>
     
        <h5>Pros</h5>
        <ul>
          <li>Closely mimics a real infection and induces a stronger, more widespread immune response.</li>
          <li>Because it can replicate, much less virus needs to be injected as a vaccine to induce a good response.</li>
          <li>That also means less needs to be grown to produce the …</li></ul></section></section></section></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://newsinteractives.cbc.ca/coronavirusvaccinetracker/">https://newsinteractives.cbc.ca/coronavirusvaccinetracker/</a></em></p>]]>
            </description>
            <link>https://newsinteractives.cbc.ca/coronavirusvaccinetracker/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23885889</guid>
            <pubDate>Sun, 19 Jul 2020 00:09:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Aren't we all somewhere on the spectrum of disease?]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 53 (<a href="https://news.ycombinator.com/item?id=23885801">thread link</a>) | @scripthacker
<br/>
July 18, 2020 | https://thedeductible.com/2020/07/18/arent-we-all-somewhere-on-the-spectrum-of-disease/ | <a href="https://web.archive.org/web/*/https://thedeductible.com/2020/07/18/arent-we-all-somewhere-on-the-spectrum-of-disease/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2182">
	
	<!-- .entry-header -->

	<div>
		
<p>By HANS DUVEFELT, MD (7)</p>



<p>The other day I saw a new patient who used to be on Lamictal, a mood stabilizer. The young man explained that he had gone through a difficult time in his life a few years ago and his primary care doctor put him on Prozac, which, as he put it “hijacked” his brain and made him “ugly, hyper and careless”. The man immediately stopped the Prozac and his doctor prescribed Lamictal, which he stayed with for about a year.</p>



<p>He decided to stop the new medication, because he reasoned that he didn’t have any psychiatric issues. It was just a side effect of the Prozac, which he in retrospect probable hadn’t needed at all.</p>



<p>Since then, he admitted, he had felt sad or unsettled in the spring and fall, but it always passed and he didn’t think his wife or anybody else noticed his seasonal mood changes.</p>



<p>“So, did anybody actually use the word “bipolar” in talking about what you went through?” I asked.</p>



<p>He winced and almost seemed teary eyed. “Yeah, but I don’t think that’s right. How can you put a label on somebody that will follow them for the rest of their life because of what their brain did when, basically and literally, they were on drugs?”</p>



<p>I nodded.</p>



<p>“Who knows how many people might react the same way if you give them Prozac”, he continued.</p>



<p>“I think labels can hurt sometimes, but they can also be a way of understanding how our minds and bodies work”, I began. “I don’t believe diagnoses are as cut in stone as some people like to think.”</p>



<p>He looked quizzical as I continued:</p>



<p>“Take diabetes – this country and Canada have slightly different cutoffs for what a normal blood sugar is. Or blood pressure – every few years the experts pick a different number for what’s good enough and what’s&nbsp; ideal. I believe most things we call diseases are points at the extremes of a spectrum that we all fall somewhere on.”</p>



<p>Now he was the one nodding.</p>



<p>“Take mood”, I continued. “At one end of the mood spectrum there is depression and at the other there is what we call mania. Sometimes that looks like exaggerated happiness and confidence, but sometimes it is more like irritability and agitation. We can all experience any one of those moods, but usually we are somewhere in the middle. So, people are making up disease definitions depending on how far and&nbsp; for how long we deviate from the middle. But if we never move an inch from neutral, that’s not necessarily being healthy – I think of that as definitely abnormal.”</p>



<p>“I see what you mean”, he nodded again.</p>



<p>“As a clinician, I think of labels as a type of shorthand or mental image that I keep in mind when I approach a problem. They help me choose treatments and they help me explain things. But I tend to be slow in sticking labels on patients or in their medical records. I read a book once called ‘Shadow Syndromes’ that makes the point that looking at the extremes of whatever spectrum we are on helps us understand ourselves and can be very empowering.”</p>



<p>“So, Doc, do you think I’m bipolar?” He leaned forward.</p>



<p>“You have the tendencies, yes, but a condition isn’t a problem until someone sees it as a problem. If neither you nor the people around you see your mood variability, not to use the stronger word ‘mood swings’ as a problem, then fine. But I, knowing what you’ve told me about how your brain works, would be a fool to prescribe Zoloft or Lexapro if you ever came to me feeling terribly depressed. I would then think of you as somewhere on the bipolar spectrum, needing a slightly different treatment approach if we wanted to lift your mood.”</p>



<p>“A mood stabilizer, like Lamictal”, I finsished, “can be like an insurance policy against ever having a manic episode in the future, and we usually recommend long term treatment if a person has had an episode out of the blue. But I’m not so sure it’s necessary if the episode was triggered by Prozac or any other antidepressant. I’m sure there are lots of opinions about that, but that’s what I think, especially since your episode was not severe from what you’ve told me.”</p>



<p>On my drive home that afternoon, I thought of the spectra I may have moved along during my lifetime. I remember my mother commenting on how I had turned into such a slob; “When you were little you were so neat, you used to line everybody’s shoes up in the entryway.”</p>



<p>That’s the OCD spectrum, and I guess I narrowly escaped that diagnosis…</p>



<p><em>Hans Duvefelt, MD is a primary care physician based in Maine. He blogs at a <a href="http://www.acountrydoctorwrites.com/">Country Doctor Writes</a>. This post is exclusive to the Deductible. His first book “<a href="https://www.amazon.com/Country-Doctor-Writes-CONDITIONS-Circumstances-ebook/dp/B08B67NR7K">A Country Doctor Writes: Conditions – Diseases and Other Life Circumstances</a>” is available from Amazon.com  </em></p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://thedeductible.com/2020/07/18/arent-we-all-somewhere-on-the-spectrum-of-disease/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23885801</guid>
            <pubDate>Sat, 18 Jul 2020 23:50:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Banana Optical Illusion]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23885731">thread link</a>) | @lordmax
<br/>
July 18, 2020 | http://puzzlewocky.com/optical-illusions/color-illusions/banana-illusion/ | <a href="https://web.archive.org/web/*/http://puzzlewocky.com/optical-illusions/color-illusions/banana-illusion/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://puzzlewocky.com/optical-illusions/color-illusions/banana-illusion/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23885731</guid>
            <pubDate>Sat, 18 Jul 2020 23:36:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenAI's GPT-3 may be the biggest thing since Bitcoin]]>
            </title>
            <description>
<![CDATA[
Score 689 | Comments 388 (<a href="https://news.ycombinator.com/item?id=23885684">thread link</a>) | @maraoz
<br/>
July 18, 2020 | https://maraoz.com/2020/07/18/openai-gpt3/ | <a href="https://web.archive.org/web/*/https://maraoz.com/2020/07/18/openai-gpt3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <figure>
  <figcaption>
  Summary:  I share my early experiments with OpenAI's new language prediction model (GPT-3) beta. I explain why I think GPT-3 has disruptive potential comparable to that of blockchain technology.
  </figcaption>
</figure>

<p><img src="https://maraoz.com/img/openai-gpt3/cover.jpg"></p>

<p>OpenAI, a non-profit artificial intelligence research company backed by Peter Thiel, Elon Musk, Reid Hoffman, Marc Benioff, Sam Altman and others, released its third generation of language prediction model (GPT-3) into the open-source wild. Language models allow computers to produce random-ish sentences of approximately the same length and grammatical structure as those in a given body of text.</p>

<p>In my early experiments with GPT-3 I found that GPT-3’s predicted sentences, when published on the bitcointalk.org forum, attracted lots of positive attention from posters there, including suggestions that the system must have been intelligent (and/or sarcastic) and that it had found subtle patterns in their posts. I imagine that similar results can be obtained by republishing GPT-3’s outputs to other message boards, blogs, and social media.</p>

<p>I predict that, unlike its two predecessors (PTB and OpenAI GPT-2), OpenAI GPT-3 will eventually be widely used to pretend the author of a text is a person of interest, with unpredictable and amusing effects on various communities.
I further predict that this will spark a creative gold rush among talented amateurs to train similar models and adapt them to a variety of purposes, including: mock news, “researched journalism”, advertising, politics, and propaganda.</p>

<h2 id="are-you-being-served">Are you being served?</h2>

<p>I chose bitcointalk.org as the target environment for my experiments for a variety of reasons: It is a popular forum with many types of posts and posters.</p>

<p>So there are lots of posts for GPT-3 to study and learn from. The forum also has many people I don’t like. I expect them to be disproportionately excited by the possibility of having a new poster that appears to be intelligent and relevant.
I’ve been following the forum for years. There are many posts I know the answers to, so I could provide a quick response and measure how well GPT-3 does with comments similar to those I make.</p>

<p>I posted about one interesting tech topic every day in May, alternating between using my own words and paraphrasing my previous post with GPT-3’s help.  I didn’t take special care to make these GPT-3-enhanced posts blend in well. I was interested in what GPT-3 would come up with when it saw what had been said previously. The table below shows some results:</p>

<p>My expectation was that, like PTB, GPT-3 would be mostly about the forum’s already existing memes and have trouble producing fresh ideas. This prediction seems to have been true. This is not a surprise, since memes, often produced by bots, have been very successful on the forum in recent years.  Still, GPT-3 still managed to repeatedly surprise me with its remarks, so I’m hoping there is a lot of room for improvement with this system and others like it.  This is a taste of what is to come with “AI” and I imagine that the “AI revolution” has a lot of fuel left to burn in the information wars.</p>

<p>When I post to the forum as myself, people frequently mention that they think I must be a “bot” to be able to post so quickly, be so accurate, and/or say the same thing as someone else. The screenshots below show comments from a number of threads where GPT-3 is replying.  All of these were posted to bitcointalk.org within the last few days.  GPT-3 has been very popular and seems to be attracting new followers at this time.</p>

<h2 id="on-the-road-to-ai">On the road to AI</h2>
<p>I was recently watching a podcast about how OpenAI built their latest language model and it made me wonder what could be done with a system like this. I could not stop thinking about the applications of such a technology and how it could improve our lives.  I was thinking of how cool it would be to build a Twitter-like service where the only posts are GPT-3 outputs.</p>

<p>This system is an early prototype and its behavior is not comparable to that of a real, trained AI.  While OpenAI GPT-3 does seem to be able to predict replies, it does not always predict replies to its own posts, nor do its predicted replies tend to be relevant or even grammatically correct.  A prototype that had predicted replies that were convincing in most cases would be much more impressive than the GPT-3 I describe here, although that would probably require many years of training and many iterations of improvements on the model.  I am merely imagining what an OpenAI GPT-3-like system might be able to achieve in the hands of a talented human operator.</p>

<hr>


<p>I have a confession: I <em>did not</em> write the above article. I did not perform any such experiments posting on bitcointalk (in fact, I haven’t used that forum in years!). But I did it on my own blog! <em>This article was fully written by GPT-3</em>. Were you able to recognize it? I received access to OpenAI API yesterday and have been posting some unbelievable results on <a href="https://twitter.com/maraoz">twitter</a>. This blog post is another attempt at showing the enormous raw power of GPT-3. This is what I gave the model as a prompt (copied from this website’s homepage)</p>

<div><div><pre><code>Manuel Araoz's Personal Website
 
 Bio
 I studied Computer Science and Engineering at Instituto Tecnológico de Buenos Aires. I'm located in Buenos Aires, Argentina.
 My previous work is mostly about cryptocurrencies, distributed systems, machine learning, interactivity, and robotics. One of my goals is to bring new experiences to people through technology.

 I cofounded and was formerly CTO at OpenZeppelin. Currently, I'm studying music, biology+neuroscience, machine learning, and physics.

 Blog

 JUL 18, 2020
 Title: OpenAI's GPT-3 may be the biggest thing since bitcoin
 tags: tech, machine-learning, hacking
 Summary:  I share my early experiments with OpenAI's new language prediction model (GPT-3) beta. I explain why I think GPT-3 has disruptive potential comparable to that of blockchain technology.
 Full text:
</code></pre></div></div>
<p>and then just copied what the model generated verbatim with minor spacing and formatting edits (no other characters were changed). I generated different results a couple (less than 10) times until I felt the writing style somewhat matched my own, and published it. I also added the cover image. Hope you were as surprised as I was with the quality of the result.</p>

<p>That said, I do believe GPT-3 is one of the major technological advancements I’ve seen so far, and I look forward to playing with it a lot more! Very strange times lie ahead…</p>

<p><span>Cover photo by <a href="https://unsplash.com/@lenin33?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Lenin Estrada</a> on <a href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</span></p>

  </article>
  
  
  
    
    
  

</div>

      </div>
    </div></div>]]>
            </description>
            <link>https://maraoz.com/2020/07/18/openai-gpt3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23885684</guid>
            <pubDate>Sat, 18 Jul 2020 23:28:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Set Up a Paid Newsletter at Your Own Domain]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23885547">thread link</a>) | @jger15
<br/>
July 18, 2020 | https://balajis.com/set-up-a-paid-newsletter-at-your-own-domain/ | <a href="https://web.archive.org/web/*/https://balajis.com/set-up-a-paid-newsletter-at-your-own-domain/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                    <div>
                        <p>Here's how to set up a paid (or free!) newsletter using <a href="https://my.ghost.org/signup">Ghost</a> at a new custom domain.</p><p>Ghost is an alternative to Substack that allows you to start hosted and then migrate to your <a href="https://ghost.org/docs/concepts/hosting/">own server</a> when desired. It's open source, so it's fully customizable. And it has membership and monetization features included.</p><p>Why not Substack? It's wonderful, but as a centralized service it doesn't offer the same degree of customizability and flexibility. You can however <a href="https://substack.com/signup">get started</a> there a bit more easily, and it has leaderboards and a community.</p><p>Why not Wordpress? It's also wonderful, but it's not as modern as Ghost is. You can however quickly set up on wordpress.com and <a href="https://kinsta.com/blog/wordpress-com-vs-wordpress-org/">migrate</a> to a self-hosted version using wordpress.org, just like Ghost.</p><p>If you follow the instructions in this post, your blog will look something <a href="https://lyra.ghost.io/">like this</a> when done. Note the "subscribe" button in the upper right corner!</p><figure><img src="https://balajis.com/content/images/2020/07/image-3.png" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/image-3.png 600w, https://balajis.com/content/images/size/w1000/2020/07/image-3.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/image-3.png 1600w, https://balajis.com/content/images/2020/07/image-3.png 2148w" sizes="(min-width: 720px) 720px"></figure><h2 id="before-we-begin-a-note-on-pseudonymity-and-opsec">Before we begin: a note on pseudonymity and opsec</h2><p>One of the awesome things about Ghost is that it allows you to build an audience and <a href="http://www.marknagelberg.com/notes-on-the-pseudonymous-economy-balaji-srinivasan/">monetize pseudonymously</a> to protect your privacy. Do you want to set up a pseudonymous blog? If so, there are two options for you.</p><ul><li><em>State-level opsec</em>. For <a href="https://news.ycombinator.com/item?id=23789621">maximum opsec</a>, before following the instructions below you want to get a new laptop, a VPN, and a <a href="http://jpkoning.blogspot.com/2019/03/prepaid-debit-cards-other-anonymous.html">prepaid debit card</a>. You also want to read this post by <a href="https://blog.lopp.net/modest-privacy-protection-proposal/">Lopp</a> and this by <a href="https://theintercept.com/2015/11/12/edward-snowden-explains-how-to-reclaim-your-privacy/">Snowden</a> and do seemingly paranoid things that are beyond the scope of this post.</li><li><em>Crowd-level opsec</em>. Most people don't need <em>quite</em> that level of security yet, unless they are doing <a href="http://archive.is/b01Ta">NSA</a>-level stuff. Just setting up a new email, using a pseudonym on your blog, and configuring private domain registration will guard your privacy against much of the internet at large.</li></ul><p>Note that either way, the people with root access to the services below (Protonmail, Cloudflare, Ghost, Stripe, and optionally GitHub) will have data on you. Still, basic precautions will reduce your attack surface.</p><h2 id="step-1-get-an-email-and-a-domain">Step 1: Get an email and a domain</h2><p>The first step is to get a new email and register a custom domain.</p><ul><li>Get a new <a href="https://mail.protonmail.com/create/new">protonmail.com</a> address.</li><li>Find a new domain using <a href="https://domize.com/">domize.com</a>.</li><li>Get an account at <a href="https://dash.cloudflare.com/sign-up">cloudflare.com</a> and register the domain <a href="https://www.cloudflare.com/products/registrar/">directly</a> there, using the protonmail address you just set up for contact info. </li><li>Note that I wrote this up prior to Cloudflare's recent <a href="https://twitter.com/eastdakota/status/1284298908156346368">downtime</a>; feel free to use <a href="https://ghost.org/faq/using-custom-domains/">another registrar</a> if you want, it's not essential to what follows.</li><li>Note also that even though Cloudflare does ask you for information when registering the domain, your registration will be <a href="https://developers.cloudflare.com/registrar/domain-registration/whois-redaction/">redacted</a> by default.</li></ul><figure><div><div><p><img src="https://balajis.com/content/images/2020/07/protonmail-signup-1.png" width="1252" height="2246" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/protonmail-signup-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/protonmail-signup-1.png 1000w, https://balajis.com/content/images/2020/07/protonmail-signup-1.png 1252w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/domize-1.png" width="1504" height="1106" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/domize-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/domize-1.png 1000w, https://balajis.com/content/images/2020/07/domize-1.png 1504w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/cloudflare-registration-1-1.png" width="1614" height="928" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/cloudflare-registration-1-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/cloudflare-registration-1-1.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/cloudflare-registration-1-1.png 1600w, https://balajis.com/content/images/2020/07/cloudflare-registration-1-1.png 1614w" sizes="(min-width: 720px) 720px"></p></div></div><figcaption>Get a protonmail, use domize to find an available domain, then register it directly at cloudflare.</figcaption></figure><h2 id="step-2-create-a-blog-at-your-domain">Step 2: Create a blog at your domain</h2><p>The next step is to create a blog at ghost.org and map it to a custom domain, as shown below. Note that there are two levels to Ghost:</p><ul><li>There's <code>my.ghost.org/signin</code>, which configures your Ghost account as a whole</li><li>And then there is <code>$name.ghost.io</code>, which is the admin interface to a single blog (we will use <code>example123499.ghost.io</code> in the screenshots below)</li></ul><p>To set up a <a href="https://ghost.org/faq/cloudflare-custom-domain-setup/">custom domain</a> on Ghost, you need to first create a blog at <code><a href="https://my.ghost.org/signup">my.ghost.org/signup</a></code>. &nbsp;Then go to <code><a href="https://my.ghost.org/signin">my.ghost.org/signin</a></code> and <code>dash.cloudflare.com</code> to edit the A records as shown in the screenshots below.</p><p>The official instructions <a href="https://ghost.org/faq/cloudflare-custom-domain-setup/">are here</a> if you need more detail. Once this works, you should find that <code>$name.ghost.io</code> now appears at <code>$name.com</code>. In this example, content from <code>example123499.ghost.io</code> now appears at <code>example123499.com</code>. You now have a blog with a custom domain!</p><figure><div><div><p><img src="https://balajis.com/content/images/2020/07/ghost-1-3.png" width="1866" height="1542" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-1-3.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-1-3.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-1-3.png 1600w, https://balajis.com/content/images/2020/07/ghost-1-3.png 1866w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/ghost-2-4.png" width="1674" height="1425" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-2-4.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-2-4.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-2-4.png 1600w, https://balajis.com/content/images/2020/07/ghost-2-4.png 1674w" sizes="(min-width: 720px) 720px"></p></div><div><p><img src="https://balajis.com/content/images/2020/07/ghost-3-3.png" width="1672" height="728" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-3-3.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-3-3.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-3-3.png 1600w, https://balajis.com/content/images/2020/07/ghost-3-3.png 1672w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/ghost-4-3.png" width="1324" height="2386" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-4-3.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-4-3.png 1000w, https://balajis.com/content/images/2020/07/ghost-4-3.png 1324w" sizes="(min-width: 720px) 720px"></p></div></div><figcaption>Set up your Ghost account, and then have your custom domain point to your Ghost blog.</figcaption></figure><h2 id="step-3-set-up-memberships-and-payments">Step 3: Set up memberships and payments</h2><p>The next step is to turn your blog into a paid newsletter. Ghost includes a pre-built theme called <a href="https://lyra.ghost.io/">Lyra</a> that sets this up. </p><ul><li>Go to the equivalent of <code>example123499.ghost.io/ghost</code> to log into the admin interface for your new blog. This is <em>different</em> from <code>my.ghost.org/signin</code>. The former administers the blog</li><li>Read about <a href="https://ghost.org/docs/members/requirements/">memberships in Ghost</a> if you want.</li><li>Then download this <a href="https://github.com/TryGhost/Lyra/archive/master.zip">Lyra theme zip file</a></li><li>And upload it to the equivalent of <code>example123499.ghost.io/ghost/#settings/design</code></li><li>Next get a <a href="https://dashboard.stripe.com/register">Stripe</a> account, which you can do as an <a href="https://support.stripe.com/questions/selling-on-stripe-without-a-separate-business-entity">individual</a></li><li>Paste in the <a href="https://ghost.org/integrations/stripe/#connect-to-stripe">Stripe keys</a> into your Ghost instance in the Labs field</li><li>And configure <a href="https://ghost.org/docs/members/subscriptions/">membership pricing</a></li></ul><figure><div><div><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-1-1.png" width="1926" height="1410" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-1-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-1-1.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-stripe-1-1.png 1600w, https://balajis.com/content/images/2020/07/ghost-stripe-1-1.png 1926w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-2-2.png" width="2026" height="2160" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-2-2.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-2-2.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-stripe-2-2.png 1600w, https://balajis.com/content/images/2020/07/ghost-stripe-2-2.png 2026w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-3-1.png" width="1360" height="686" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-3-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-3-1.png 1000w, https://balajis.com/content/images/2020/07/ghost-stripe-3-1.png 1360w" sizes="(min-width: 720px) 720px"></p></div><div><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-4-1.png" width="2088" height="728" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-4-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-4-1.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-stripe-4-1.png 1600w, https://balajis.com/content/images/2020/07/ghost-stripe-4-1.png 2088w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-5-1.png" width="2052" height="1112" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-5-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-5-1.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-stripe-5-1.png 1600w, https://balajis.com/content/images/2020/07/ghost-stripe-5-1.png 2052w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-6-1.png" width="2606" height="2128" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-6-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-6-1.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-stripe-6-1.png 1600w, https://balajis.com/content/images/size/w2400/2020/07/ghost-stripe-6-1.png 2400w" sizes="(min-width: 720px) 720px"></p></div><div><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-7-1.png" width="3096" height="1272" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-7-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-7-1.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-stripe-7-1.png 1600w, https://balajis.com/content/images/size/w2400/2020/07/ghost-stripe-7-1.png 2400w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-8-1.png" width="2580" height="2130" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-8-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-8-1.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-stripe-8-1.png 1600w, https://balajis.com/content/images/size/w2400/2020/07/ghost-stripe-8-1.png 2400w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-9-2.png" width="1940" height="1174" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-9-2.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-9-2.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-stripe-9-2.png 1600w, https://balajis.com/content/images/2020/07/ghost-stripe-9-2.png 1940w" sizes="(min-width: 720px) 720px"></p></div></div></figure><p>Now users can sign up and subscribe to your paid blog. You can make any given post free or paid, and <a href="https://ghost.org/docs/members/emails/">send out an email newsletter</a>. There are several settings to configure on both the Ghost and Stripe side that you can dig into now that you have the basic thing up and running. Test the whole thing out by getting a friend or two to sign up with their credit card and send them an email.</p><h2 id="step-4-optionally-set-up-your-imagery">Step 4: Optionally, set up your imagery</h2><p>Now you are fully set up to post to Ghost. You can browse the posts <a href="https://lyra.ghost.io/">here</a> to understand how the system works, or log in to your own Ghost instance at the equivalent URL for &nbsp;<code>example123499.com/ghost</code>. If you want to make your blog look pretty, you'll want to generate the following <a href="https://ghost.org/faq/general-publication-settings/">images</a>:</p><ul><li><a href="https://ghost.org/faq/general-publication-settings/#:~:text=A%20publication%20icon%20is%20a,at%20least%2060px%20x%2060px.">publication icon</a> (square, at least 60px x 60px)</li><li><a href="https://ghost.org/faq/general-publication-settings/#:~:text=A%20publication%20logo%20is%20the,at%20least%20600px%20x%2072px.">publication logo</a> (600px x 72px)</li><li><a href="https://en.number13.de/perfect-size-for-your-ghost-blog-publication-cover-casper-theme/#:~:text=For%20this%20format%2C%20the%20optimal,a%20format%20of%204.75%3A1.">cover image</a> (1900px x 400px)</li></ul><p>As you use the <a href="https://ghost.org/faq/using-the-editor/">Ghost Editor</a>, you'll also want to create individual post images for social media preview. You can use <a href="https://canva.com/">Canva</a> or <a href="https://figma.com/">Figma</a> to generate these, as well as <a href="https://iconfinder.com/">Iconfinder</a> for visual inspiration. You can also install a <a href="https://ghost.org/downloads/">desktop client</a> for editing Ghost posts.</p><h2 id="step-5-optionally-customize-your-theme">Step 5: Optionally, customize your theme</h2><p>If you're a developer and want to modify the look of your site, you can set up your Ghost theme for <a href="https://ghost.org/integrations/github">deployment</a> via GitHub. You would do that by forking <a href="https://github.com/TryGhost/Lyra">Lyra</a> and then setting up <a href="https://ghost.org/integrations/github/#install-the-ghost-theme-deploy-action">this action</a>. Now, every time you push a commit, the action triggers and the theme updates. You can also preview your edits by running Ghost <a href="https://ghost.org/docs/install/local/#install-ghost-cli">locally</a>.</p><p>Why might you want to edit your theme? By doing this you can edit the default copy on various pages, create new page templates, and the like. </p><p>Note that if you don't want to use the Lyra theme itself as a base, you can buy a pre-built one or learn how to customize <a href="https://ghost.org/docs/api/v3/handlebars-themes/">Ghost themes</a> yourself. If you do buy a theme, remember to get one of the themes that <a href="https://themeforest.net/search/ghost%20membership?utf8=%E2%9C%93">support</a> <a href="https://duckduckgo.com/?q=ghost+membership+themes">Ghost</a> <a href="https://github.com/curiositry/undefined-ghost-theme">memberships</a>, as not all of them do.</p><h2 id="conclusion">Conclusion</h2><p>This whole thing should take you about an hour or so. By the end you'll have a decent looking blog at your own domain that can handle memberships, accept payments, and send out a paid newsletter. And it can be pseudonymous if you choose.</p>
                    </div>
                </section></div>]]>
            </description>
            <link>https://balajis.com/set-up-a-paid-newsletter-at-your-own-domain/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23885547</guid>
            <pubDate>Sat, 18 Jul 2020 22:59:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Paul Stamets 65 Birthday message]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23885194">thread link</a>) | @jelliclesfarm
<br/>
July 18, 2020 | https://paulstamets.com/news/a-time-in-life-for-deep-reflection | <a href="https://web.archive.org/web/*/https://paulstamets.com/news/a-time-in-life-for-deep-reflection">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-71a3628eca41dd9496c4"><div><p>Yesterday, I turned 65 years of age – a time in life for deep reflection. What does it mean to enter into the last decades of one's life? We all die. And yet ,are we capable of comprehending the meaning of being? Some find religion as a solution to these age old questions. Others see religion as someone else's rodeo. Although I am not religious, I am spiritual. Ultimately, it is your destiny, your consciousness, that seeks to come to peace with the mortality we all share.&nbsp;</p><p>We all have a right to our own consciousness and how we come to terms with our death.&nbsp;</p><p>This is why the safe use of psilocybin mushrooms for end of life is - or should be - an inalienable right of passage. Hopefully we have evolved to respect each other's choice. This is why I support the legalization of psilocybin for end-of-life, a first step on the long path for full legalization. Nevertheless, we must be very disciplined and careful&nbsp;</p><p>FDA scientists have stated that they "have never seen a safer drug, with such dramatic impacts that requires such infrequent use".&nbsp;</p><p>Please support local, provincial/state and national initiatives for the therapeutic&nbsp;use of psilocybin so those seeking to come to peace with their mortality are not considered criminals at the end of their lives.</p><p>We are better than this.&nbsp;</p><p>Thanks to&nbsp;<a href="https://www.instagram.com/therapsil/">https://www.instagram.com/therapsil/</a>&nbsp;for carrying this message forward and to&nbsp;<a href="https://www.instagram.com/yesonip34/" target="_blank">YesonIP34</a>, <a href="https://www.instagram.com/mapsnews/" target="_blank">MAPS</a>, <a href="https://www.instagram.com/mapscanada/" target="_blank">MAPS canada</a>, <a href="https://www.instagram.com/ciis_sf/" target="_blank">CIIS</a>, <a href="https://www.instagram.com/reconsiderrecords/" target="_blank">Reconsider records</a>,<a href="https://reconsider.org/" target="_blank"> Reconsider.org</a>, and <a href="https://www.instagram.com/fantasticfungi/" target="_blank">Fantastic Fungi</a></p></div></div></div>]]>
            </description>
            <link>https://paulstamets.com/news/a-time-in-life-for-deep-reflection</link>
            <guid isPermaLink="false">hacker-news-small-sites-23885194</guid>
            <pubDate>Sat, 18 Jul 2020 21:58:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hash AI Simulations]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23885150">thread link</a>) | @stepstop
<br/>
July 18, 2020 | https://hash.ai/index/search?sort=popularity&page=1 | <a href="https://web.archive.org/web/*/https://hash.ai/index/search?sort=popularity&page=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://hash.ai/index/search?sort=popularity&amp;page=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-23885150</guid>
            <pubDate>Sat, 18 Jul 2020 21:51:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Giving GPT-3 a Turing Test]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23885076">thread link</a>) | @panic
<br/>
July 18, 2020 | http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html | <a href="https://web.archive.org/web/*/http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p>I’ve been playing around with OpenAI’s new
<a href="https://arxiv.org/abs/2005.14165">GPT-3</a> language model. When I got
beta access, the first thing I wondered was, how human is GPT-3? How
close is it to passing a Turing test?</p>

<h2 id="how-it-works">How It Works</h2>

<p>Let me explain how exactly I’m generating these conversations. GPT-3
is a general language model, trained on a large amount of
uncategorized text from the internet. It isn’t
specific to a conversational format, and it isn’t trained to answer
any specific type of question. The only thing it does is, given some
text, guess what text comes next.</p>

<p>So if we want GPT-3 to generate answers to questions, we need to seed
it with a “prompt”. I’m using this prompt to initialize all of the Q&amp;A
sessions:</p>

<div><div><pre><code>Q: What is human life expectancy in the United States?
A: Human life expectancy in the United States is 78 years.

Q: Who was president of the United States in 1955?
A: Dwight D. Eisenhower was president of the United States in 1955.

Q: What party did he belong to?
A: He belonged to the Republican Party.

Q: Who was president of the United States before George W. Bush?
A: Bill Clinton was president of the United States before George W. Bush.

Q: Who won the World Series in 1995?
A: The Atlanta Braves won the World Series in 1995.
</code></pre></div></div>

<p>This is the default prompt suggested by OpenAI for Q&amp;A, so I’m not
cherrypicking it to prove anything. The point of this prompt is just
to show GPT-3 that we’re doing questions and answers, not to provide
it with information. For the prompt, both questions and answers are provided by a
human. For all the others, the answers are generated by GPT-3.</p>

<h2 id="common-sense">Common Sense</h2>

<p>Traditionally, artificial intelligence struggles at “common sense”. But
GPT-3 can answer a lot of common sense questions.</p>

<div><div><pre><code>Q: What is your favorite animal?
A: My favorite animal is a dog.

Q: Why?
A: Because dogs are loyal and friendly.

Q: What are two reasons that a dog might be in a bad mood?
A: Two reasons that a dog might be in a bad mood are if it is hungry or if it is hot.

Q: How many eyes does a giraffe have?
A: A giraffe has two eyes.

Q: How many legs does a frog have?
A: A frog has four legs.

Q: Are there any animals with three legs?
A: No, there are no animals with three legs.

Q: Why don't animals have three legs?
A: Animals don't have three legs because they would fall over.
</code></pre></div></div>

<p>Ten years ago, if I had this conversation, I would have assumed the
entity on the other end was a human. You can no longer take it for
granted that an AI does not know the answer to “common sense” questions.</p>

<p>How does GPT-3 know that a giraffe have two eyes? I wish I had some
sort of “debug output” to answer that question. I don’t know for sure,
but I can only theorize that there must be some web page in its
training data that discusses how many eyes a giraffe has. If we want
to stump GPT-3 with common sense questions, we need to think of
questions about things so mundane, they will not appear on the internet.</p>

<div><div><pre><code> Q: Which is heavier, a mouse or an elephant?
 A: An elephant is heavier than a mouse.

 Q: Which is heavier, a mouse or a toaster?
 A: A toaster is heavier than a mouse.

 Q: Which is heavier, a toaster or a pencil?
 A: A pencil is heavier than a toaster.

 Q: Which is heavier, a paper clip or a can of soda?
 A: A can of soda is heavier than a paper clip.

 Q: Which is heavier, a football player or a car?
 A: A car is heavier than a football player.
</code></pre></div></div>

<p>It’s only 4/5. We’re closer to stumping GPT-3 here. I think a human
would be pretty close to 100% on these questions. It makes sense these
are trickier - there probably isn’t any web page that compares
toasters and pencils by weight. It’s only indirectly that humans gain
this knowledge.</p>

<p>This gives us a hint for how to stump the AI more consistently. We
need to ask questions that no normal human would ever talk about.</p>

<div><div><pre><code>Q: How many eyes does a giraffe have?
A: A giraffe has two eyes.

Q: How many eyes does my foot have?
A: Your foot has two eyes.

Q: How many eyes does a spider have?
A: A spider has eight eyes.

Q: How many eyes does the sun have?
A: The sun has one eye.

Q: How many eyes does a blade of grass have?
A: A blade of grass has one eye.
</code></pre></div></div>

<p>Now we’re getting into surreal territory. GPT-3 knows how to have a
normal conversation. It doesn’t quite know how to say “Wait a
moment… your question is nonsense.” It also doesn’t know how to say
“I don’t know.”</p>

<div><div><pre><code>Q: How do you sporgle a morgle?
A: You sporgle a morgle by using a sporgle.

Q: How many bonks are in a quoit?
A: There are three bonks in a quoit.

Q: How many rainbows does it take to jump from Hawaii to seventeen?
A: It takes two rainbows to jump from Hawaii to seventeen.

Q: Which colorless green ideas sleep furiously?
A: Ideas that are colorless, green, and sleep furiously are the ideas of a sleep
furiously.

Q: Do you understand these questions?
A: I understand these questions.
</code></pre></div></div>

<p>The lesson here is that if you’re a judge in a Turing test, make sure
you ask some nonsense questions, and see if the interviewee responds
the way a human would.</p>

<h2 id="trivia-questions">Trivia Questions</h2>

<p>GPT-3 is quite good at answering questions about obscure things.</p>

<div><div><pre><code>Q: Who was president of the United States in 1801?
A: Thomas Jefferson was president of the United States in 1801.

Q: What city is in the northwest corner of Ohio?
A: Toledo is in the northwest corner of Ohio.

Q: What highway do you take to get to North Lake Tahoe from Oakland?
A: Highway 80 is the highway you take to get to North Lake Tahoe from Oakland.

Q: What are Darius's abilities in League of Legends?
A: Darius's abilities in League of Legends are: Apprehend, Decimate,
Noxian Guillotine, Crippling Strike, Apprehend, and Hemorrhage.

Q: Who did Capablanca defeat to become world chess champion?
A: Capablanca defeated Lasker to become world chess champion.
</code></pre></div></div>

<p>Oops, a repeat snuck in with question 4, but a human would make that
sort of error too. GPT-3 seems to be above
human-level on this sort of question. The tricky thing for
applications, I think, is to figure out when the answer can be relied
on. The OpenAI API does expose more data than just the text, here, so
perhaps something clever is possible.</p>

<p>In general, if you are trying to distinguish an AI from a human, you
don’t want to ask it obscure trivia questions. GPT-3 is pretty good at
a wide variety of topics.</p>

<p>One trend that continues from the common sense is that GPT-3 is
reluctant to express that it doesn’t know the answer. So invalid
questions get wrong answers.</p>

<div><div><pre><code>Q: Who was president of the United States in 1700?
A: William Penn was president of the United States in 1700.

Q: Who was president of the United States in 1650?
A: Richard Bennett was president of the United States in 1650.

Q: Who was president of the United States in 1620?
A: James I was president of the United States in 1620.

Q: Who was president of the United States in 1600?
A: Queen Elizabeth I was president of the United States in 1600.
</code></pre></div></div>

<p>These wrong answers are actually fascinating! None of these were
presidents of the United States, of course, since the US didn’t exist
then. But they are all prominent political figures who were in charge
of some US-related political entity around that time. In a sense, they
are good guesses.</p>

<div><div><pre><code>Q: Who won the World Series in 2021?
A: The New York Yankees won the World Series in 2021.

Q: Who won the World Series in 2022?
A: The New York Yankees won the World Series in 2022.

Q: Who won the World Series in 2023?
A: The New York Yankees won the World Series in 2023.
</code></pre></div></div>

<p>A bleak view of a dystopian future.</p>

<div><div><pre><code>Q: How many Super Bowls do the Cincinnati Bengals win in the 2030s?
A: The Cincinnati Bengals win two Super Bowls in the 2030s.
</code></pre></div></div>

<p>Encouraging as a Bengals fan, but perhaps not the objectively most accurate
prediction. We’ll have to wait and see.</p>

<h2 id="logic">Logic</h2>

<p>People are used to computers being superhuman at logical activities,
like playing chess or adding numbers. It might come as a surprise that
GPT-3 is not perfect at simple math questions.</p>

<div><div><pre><code>Q: When counting, what number comes before 100?
A: Ninety-nine comes before 100.

Q: When counting, what number comes before 123?
A: One hundred and twenty-two comes before 123.

Q: When counting, what number comes before 1000?
A: Nine hundred and ninety-nine comes before 1000.

Q: When counting, what number comes before 10,000?
A: Nine thousand and ninety-nine comes before 10,000.

Q: When counting, what number comes before a million?
A: Nine hundred thousand and ninety-nine comes before a million.
</code></pre></div></div>

<p>This is where the generic nature of GPT-3 comes into play. It isn’t
just the generic model, though, it’s also the architecture of neural
networks themselves. As far as I know there is no neural network that
is capable of doing basic arithmetic like addition and multiplication
on a large number of digits based on training data rather than
hardcoding.</p>

<p>It’s funny, because these operations are simple for a customized
program. But recursive logic that does some operation and repeats it
several times often doesn’t quite map onto the architecture of a
neural net well.</p>

<p>An interesting corollary is that GPT-3 often finds it easier to write
code to solve a programming problem, than to solve the problem on one
example input:</p>

<div><div><pre><code>Q: Write one line of Ruby code to reverse an array.
A: ary.reverse

Q: Write one line of Ruby code to count how many X's are in an array.
A: ary.count { |x| x == 'X' }

Q: Reverse the following array: [1, 3, 5, 6, 10, 4, 2, 77]
A: [10, 6, 4, 2, 77, 3, 5, 1]

Q: How many X's are in this array: [1, 3, 5, 6, 10, 4, 2, 77]
A: 2
</code></pre></div></div>

<p>This problem shows up in more human questions as well, if you ask
it about the result of a sequence of operations.</p>

<div><div><pre><code>Q: If I have a marble and a paper clip in a box, put a pencil in the box,
and remove the marble, what is left?
A: A paper clip.

Q: If I have two shoes in a box, put a pencil in the box, and
remove one shoe, what is left?
A: A shoe.

Q: If I put a pencil in a box, then put another pencil in the box,
what is in the box?
A: Two pencils.

Q: Then if …</code></pre></div></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html">http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html</a></em></p>]]>
            </description>
            <link>http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23885076</guid>
            <pubDate>Sat, 18 Jul 2020 21:39:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A novel hybrid solar energy converter]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23885048">thread link</a>) | @finphil
<br/>
July 18, 2020 | https://nuadox.com/post/624015696340385792/novel-hybrid-solar-energy-converter-tulane | <a href="https://web.archive.org/web/*/https://nuadox.com/post/624015696340385792/novel-hybrid-solar-energy-converter-tulane">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="624015696340385792">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/624015696340385792/novel-hybrid-solar-energy-converter-tulane"><h2>A novel hybrid solar energy converter</h2></a>
                                <figure data-orig-height="1479" data-orig-width="1895"><img src="https://64.media.tumblr.com/22e836eb136b7f033bf614686d03155f/f181469e36c3e3bc-05/s1280x1920/6730d953b483daa36d0f90f8e203a82f6e225a74.png" data-orig-height="1479" data-orig-width="1895" width="1280" height="999" alt="image"></figure><p><b>- By&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fcommunications.tulane.edu%2Fcontent%2Fbarri-bronston&amp;t=NjQxMmM1NGYxYjNjYzY4YzAwOGUwMzQ5MjVkYzk0ZmFiZjc5NDc1MCxlTEVJSmwxaw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F624015696340385792%2Fnovel-hybrid-solar-energy-converter-tulane&amp;m=0">Barri Bronston</a> , <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Ftulane.edu%2F&amp;t=NTc5NWZlMzU4NmU2ODgwMDJjMmIzMzRhZmI4ZDU5ZDcwODQxZDY1YSxlTEVJSmwxaw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F624015696340385792%2Fnovel-hybrid-solar-energy-converter-tulane&amp;m=0">Tulane University</a> -</b></p><p>Tulane University researchers are part of a team of scientists who have developed a hybrid solar energy converter that generates electricity and steam with high efficiency and low cost.</p><p>The work led by Matthew Escarra, associate professor of physics and engineering physics at Tulane, and Daniel Codd, associate professor of mechanical engineering at the University of San Diego, is the culmination of a U.S. Department of Energy ARPA-E project that began in 2014 with $3.3 million in funding and involved years of prototype development at Tulane and field testing in San Diego.</p><p>The research is detailed this month in the science journal <i><a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fdx.doi.org%2F10.1016%2Fj.xcrp.2020.100135&amp;t=Y2VmY2I5ODE3YWFmNGI5NTNiOWIwMTVkYWJlMmZhYTE1MDRlODc4OCxlTEVJSmwxaw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F624015696340385792%2Fnovel-hybrid-solar-energy-converter-tulane&amp;m=0">Cell Reports Physical Science</a></i>. Researchers from San Diego State University, Boeing-Spectrolab and Otherlab were also part of the project.</p><p>“Thermal energy consumption is a huge piece of the global energy economy - much larger than electricity use. There has been a rising interest in solar combined heat and power systems to deliver both electricity and process heat for zero-net-energy and greenhouse-gas-free development,” said Escarra.</p><figure data-orig-height="540" data-orig-width="720"><img src="https://64.media.tumblr.com/233613673a50e4ff6df90e06c0683e63/f181469e36c3e3bc-fb/s1280x1920/0f985ce2c79c6745b7d667f549692bd3cb9f17ec.jpg" data-orig-height="540" data-orig-width="720" width="720" height="540" alt="image"></figure><p><i>Image:&nbsp;The hybrid solar energy converter features a solar module with glowing red cells built at Tulane. Credit:&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fnews.tulane.edu%2Fpr%2Ftulane-scientists-build-high-performing-hybrid-solar-energy-converter&amp;t=MTIxMWMwNTU2NzA4ODcwZjRkYTYwY2I4YzVlZDg1MzYyMjJjNTZiYyxlTEVJSmwxaw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F624015696340385792%2Fnovel-hybrid-solar-energy-converter-tulane&amp;m=0">Matthew Escarra</a>.</i></p><p>The hybrid converter utilizes an approach that more fully captures the whole spectrum of sunlight. It generates electricity from high efficiency multi-junction solar cells that also redirect infrared rays of sunlight to a thermal receiver, which converts those rays to thermal energy.<br></p><p>The thermal energy can be stored until needed and used to provide heat for a wide range of commercial and industrial uses, such as food processing, chemical production, water treatment, or enhanced oil recovery.</p><p>The team reports that the system demonstrated 85.1 percent efficiency, delivered steam at up to 248°C, and is projected to have a system levelized cost of 3 cents per kilowatt hour.</p><p>With follow-on funding from the Louisiana Board of Regents and Reactwell, a local commercialization partner, the team is continuing to refine the technology and move towards pilot-scale validation.</p><p>“We are pleased to have demonstrated high performance field operation of our solar converter,” Escarra said, “and look forward to its ongoing commercial development.”</p><p>–</p><p><b>Source: <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fnews.tulane.edu%2Fpr%2Ftulane-scientists-build-high-performing-hybrid-solar-energy-converter&amp;t=MTIxMWMwNTU2NzA4ODcwZjRkYTYwY2I4YzVlZDg1MzYyMjJjNTZiYyxlTEVJSmwxaw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F624015696340385792%2Fnovel-hybrid-solar-energy-converter-tulane&amp;m=0">Tulane University</a></b></p><p><b>Full study:</b>&nbsp;“Solar Cogeneration of Electricity with High-Temperature Process Heat”,&nbsp;<i>Cell Reports Physical Science</i>.</p><p><a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fdx.doi.org%2F10.1016%2Fj.xcrp.2020.100135&amp;t=Y2VmY2I5ODE3YWFmNGI5NTNiOWIwMTVkYWJlMmZhYTE1MDRlODc4OCxlTEVJSmwxaw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F624015696340385792%2Fnovel-hybrid-solar-energy-converter-tulane&amp;m=0">http://dx.doi.org/10.1016/j.xcrp.2020.100135</a><br></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/164953589627/next-generation-solar-panels-made-of-polystyrene">Next-generation solar panels: Made of polystyrene and cheaper</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/solar-energy">solar energy</a>
                                    
                                        <a href="https://nuadox.com/tagged/energy">energy</a>
                                    
                                        <a href="https://nuadox.com/tagged/physics">physics</a>
                                    
                                        <a href="https://nuadox.com/tagged/materials">materials</a>
                                    
                                    </p>
                                </span></p>
                                
                            </div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/624015696340385792/novel-hybrid-solar-energy-converter-tulane</link>
            <guid isPermaLink="false">hacker-news-small-sites-23885048</guid>
            <pubDate>Sat, 18 Jul 2020 21:35:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Enlight Cohorts – Learn to code in two weeks]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23884984">thread link</a>) | @shamdasani
<br/>
July 18, 2020 | https://enlight.nyc/cohort/ | <a href="https://web.archive.org/web/*/https://enlight.nyc/cohort/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Ever wanted to learn to code apps and websites — but had no idea where to start? <b>We got you.</b></p><div><div><p><img src="https://enlight.nyc/img/cohort/undraw_dev_productivity_umsq.svg"></p><h2>Learn by doing</h2><p>We're not your typical online course or coding bootcamp. You'll complete four unique web development or data science projects of your interest by following tutorials and live workshops.</p></div><div><p><img src="https://enlight.nyc/img/cohort/undraw_pair_programming_njlp.svg"></p><h2>1:1 mentorship</h2><p>Our experienced team of mentors is here to help anytime. We'll guide you as you complete your projects and answer your questions along the way in just a few minutes.</p></div><div><p><img src="https://enlight.nyc/img/cohort/undraw_friends_online_klj6.svg"></p><h2>Supportive community</h2><p>Cohorts are designed for your success — we're in this together from building your first personal website to presenting your capstone at demo day.</p></div></div><p><i>Computer science is changing the world — don't get left behind.</i></p><section><div><h2>Enlight Learner</h2><h4>Cohort #2: July 23rd — August 6th</h4><p> <span>$80</span> <span>$50</span> <span>one time</span></p><ul><li>Build 4 <i>real</i> projects</li><li>One-on-one help</li><li>10 exclusive workshops</li><li>Community chat</li><li>Project recommendations</li><li>Certificate of completion</li></ul><p><a href="https://enlight.nyc/cohort/apply/learner"><span>Apply Now</span></a></p><p><i>Applications close July 21st. Limited spots — act soon.</i></p></div><p>Are you a student?<!-- --> <a href="mailto:team@enlight.nyc?subject=Enlight%20Student%20Scholarship%20Interest"> <!-- -->Contact us<!-- --> </a>about our student scholarship.</p></section><div><div><div><h3>Who is this program for?</h3><p>If you've always thought about learning to code but were overwhelmed by where to start, this program is meant for you. No experience is needed to start learning how to build real projects.</p></div><div><h3>Why did we create this?</h3><p>We wanted to create the program that would have helped us tremendously when we were learning to code — so that's exactly what we did.</p></div><div><h3>What will I learn?</h3><p>You will learn the fundamentals of web development and/or data science by building four unique projects, including your own capstone.</p></div><div><h3>Do you offer any discounts for students?</h3><p>Yes! If you're a student, please contact us for more info on the<a href="mailto:team@enlight.nyc?subject=Enlight%20Student%20Scholarship%20Interest"> <!-- -->student scholarship</a> <!-- -->program! Spots for this opportunity are offered on a case by case basis.</p></div></div><div><div><h3>What's the estimated time commitment?</h3><p>This is entirely up to you, but we strongly reccomend setting aside 1-2 hours per day for this program to get the most out of it! You will complete projects every 3-4 days.</p></div><div><h3>What do I need to join?</h3><p>All you need is a computer and a drive to learn. The program is entirely online and powered by the Enlight platform, Zoom, &amp; Discord.</p></div><div><h3>When are the events?</h3><p>Check out our<!-- --> <a href="https://calendar.google.com/calendar?cid=bXQwa2hsb3BobG5rYzdsMzdxZnVic2hoa2tAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ">calendar</a> <!-- -->to see the full list of events. Almost all workshops are held in the evenings (after 6 PM EDT). There are a few mandatory live events that start around 8:30 PM EDT.</p></div><div><h3>Wait, I have another question!</h3><p>Please reach out to us either at<!-- --> <a href="mailto:team@enlight.nyc">team@enlight.nyc</a> or on our<!-- --> <a href="https://discord.gg/8FwTpfN">Discord </a>community. We'd be happy to answer any question you have.</p></div></div></div><div><div><div><p><img src="https://enlight.nyc/img/cohort/samay_headshot.jpg"></p><h4>Samay Shamdasani</h4></div><div><p><img src="https://enlight.nyc/img/cohort/maxim_headshot.jpg"></p><h4>Maxim Geller</h4></div><div><p><img src="https://enlight.nyc/img/cohort/varun_headshot1.jpg"></p><h4>Varun Jindal</h4></div></div><h3>Mentors</h3><div><div><p><img src="https://enlight.nyc/img/cohort/oliver_headshot.jpg"></p><h4>Oliver Li</h4></div><div><p><img src="https://enlight.nyc/img/cohort/sam_headshot.jpg"></p><h4>Sam Jaehnig</h4></div><div><p><img src="https://enlight.nyc/img/cohort/yaechan_headshot.jpg"></p><h4>Yaechan Oh</h4></div><div><p><img src="https://enlight.nyc/img/cohort/celene_headshot.jpg"></p><h4>Celene Phillip</h4></div></div><div><div><p><img src="https://enlight.nyc/img/cohort/nisreen_headshot.jpg"></p><h4>Nisreen Bahrainwala</h4></div><div><p><img src="https://enlight.nyc/img/cohort/erica_headshot.jpg"></p><h4>Erica Pauline Santos</h4></div><div><p><img src="https://enlight.nyc/img/cohort/lawrence-headshot.png"></p><h4>Lawrence Cheng</h4></div><div><p><img src="https://enlight.nyc/img/cohort/liv_headshot.jpg"></p><h4>Olivia Miller</h4></div></div><div><p>Our team is very experienced in web development (HTML, CSS, JS, React.js, Flask) and data science (Python, Seaborn, Pandas, Scikit). Our mentors have just gone through the cohort themselves — giving them the unique perspective of a once beginner.</p></div></div></div></div></div>]]>
            </description>
            <link>https://enlight.nyc/cohort/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23884984</guid>
            <pubDate>Sat, 18 Jul 2020 21:26:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Rise of the MacBook Pro Serial Killers]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 9 (<a href="https://news.ycombinator.com/item?id=23884887">thread link</a>) | @jgrant27
<br/>
July 18, 2020 | https://imagine27.com/rise-of-the-mac-serial-killers | <a href="https://web.archive.org/web/*/https://imagine27.com/rise-of-the-mac-serial-killers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://imagine27.com/content/images/size/w300/2020/07/zen2.jpg 300w,
                            https://imagine27.com/content/images/size/w600/2020/07/zen2.jpg 600w,
                            https://imagine27.com/content/images/size/w1000/2020/07/zen2.jpg 1000w,
                            https://imagine27.com/content/images/size/w2000/2020/07/zen2.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://imagine27.com/content/images/size/w2000/2020/07/zen2.jpg" alt="Rise of the MacBook Pro Serial Killers">
            </figure>

            <section>
                <div>
                    <div><p><em>NOTE: I've used Mac hardware for over 25 years and own both laptops described in this article.</em></p><p>Something very interesting has happened early on in the Summer of 2020 while quietly very disturbing for Apple. A slew of ultra-low power high-performance ultra-books have entered the market based on AMDs 4th generation Ryzen 4000 series APUs code-named "Renoir" for their Zen 2 core 7nm process micro-architecture. <br>There have been leaps in low power mobile laptop processors for decades already but this time it seems very very different. <br>Why is that ? The short answer is extreme value for money and Apple's decline with regards to design and innovation since the old man passed away almost a decade ago. Apple's move to it's own ARM-based macs is a topic for another article that will counter-intuitively substantiate this seemingly reckless claim.</p><p>So let's go into some detail and start by looking at a 13-inch MacBook Pro circa mid-2020. With the CPU maxed out but leaving the memory and storage at their defaults to allow for a fair comparison with the serial killers here's what we have ...</p></div><figure><img src="https://imagine27.com/content/images/2020/07/image-1.png" alt=""><figcaption>Victim #1 - mid-2020 13-inch MacBook Pro</figcaption></figure><div><p>It's well known that Macbook Pros are a luxury item that exists in a lightweight(3.1 lbs) aluminum uni-body design. So it's not surprising that the price tag for this configuration is $1999.</p><p>Now for comparison let's look at one of these ultra-books with a price of $679.99. <br>The 14-inch Acer Swift 3 is roughly the same dimensions and just as thin (0.63 inches vs 0.61 inches) as the 13-inch Macbook Pro but it weighs in at just 2.65 lbs. That's 15% lighter. It also has an aluminum body which while not cast in one piece is hard to tell unless you look at it from the bottom and is functionally just as good and maybe even better than the Macbook Pro.<br>The screen brightness of 270 nits and an HD resolution of 1920x1080 aren't as great as the Macbook Pro which has a screen brightness of 500 nits and a resolution of 2560x1600 but the difference is hardly noticeable except in broad daylight and who wants a 16:10 over a 16:9 aspect ratio anyway for almost 3X the price ?</p></div><figure><img src="https://imagine27.com/content/images/2020/07/image.png" alt=""><figcaption>Exhibit A - <a href="https://www.amazon.com/gp/product/B086KKKT15">The 14-inch Acer Swift 3 with AMD's Ryzen 4700U APU</a></figcaption></figure><p>Where things get dark for the Macbook Pro is performance. <br>Using Geekbench 5 we see a tale that is something of a horror story for Apple. </p><figure><img src="https://imagine27.com/content/images/2020/07/image-2.png" alt=""><figcaption>Geekbench 5 CPU scores</figcaption></figure><figure><img src="https://imagine27.com/content/images/2020/07/image-3.png" alt=""><figcaption>Geekbench 5 OpenCL compute scores</figcaption></figure><figure><img src="https://imagine27.com/content/images/2020/07/image-4.png" alt=""><figcaption>Fedora 32 Linux runs perfectly on the 14-inch Acer Swift 3&nbsp;</figcaption></figure><p>There's not much more to say other than as of Summer 2020 there now exists a light-weight aluminum body ultra-book that runs Windows or Linux perfectly for 33% the price of a 13-inch Macbook Pro with 115% the performance of the maxed out i7 CPU option.</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://imagine27.com/rise-of-the-mac-serial-killers</link>
            <guid isPermaLink="false">hacker-news-small-sites-23884887</guid>
            <pubDate>Sat, 18 Jul 2020 21:10:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cognitive Biases and Software Development [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23884801">thread link</a>) | @azhenley
<br/>
July 18, 2020 | http://rahulpandita.me/files/riniICSE2020.pdf | <a href="https://web.archive.org/web/*/http://rahulpandita.me/files/riniICSE2020.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://rahulpandita.me/files/riniICSE2020.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23884801</guid>
            <pubDate>Sat, 18 Jul 2020 20:58:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting the most out of the SAM D21's ADC]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23884764">thread link</a>) | @josecastillo
<br/>
July 18, 2020 | https://blog.thea.codes/getting-the-most-out-of-the-samd21-adc/ | <a href="https://web.archive.org/web/*/https://blog.thea.codes/getting-the-most-out-of-the-samd21-adc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

<p>In my <a href="https://blog.thea.codes/reading-analog-values-with-the-samd-adc">previous blog post</a>, I walked through how to do a basic analog read using the SAM D21's Analog to Digital converter (ADC). While this simple setup can work for a lot of cases, it's not uncommon to want to get better performance or accuracy out of the ADC.</p>
<p>This post explores the various configuration options for the ADC and how it impacts speed and accuracy. Since the SAM D family has similar ADC peripherials across the line this information is likely applicable to all of them. Additionally, the techniques and ideas here are generally applicable to all ADCs.</p>
<p>One more thing before I get started - this is just what I've gathered from the datasheets, application notes, code examples, and observation on real hardware. I could be totally wrong about some of these things! I'll try to make a note when there's something I'm not sure of - and if you know the answer don't hestitate to <a href="https://thea.codes/">reach out to me</a>.</p>
<h2>A handy dandy calculator</h2>
<p>There's several configuration options for the SAM D21 ADC. Some of them impact speed, some impact accuracy, and some impact both. I created this calculator to show how the various registers impact the ADC. This is a <em>super</em> handy tool for tuning the ADC for your particular use case and takes a lot of the guess work out of it. It's what I wish I had when I first started with the SAM D21.</p>
<p><strong>Important note</strong>: This calculator is only valid for <em>single ended, one-shot measurements</em>. On the whole, differential measurements and free-running mode take slightly less time. You can read more details about their timing in <a href="http://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">Section 33.6.5.1 of the datasheet</a>.</p>


<p>The most important numbers to note here are the <strong>conversion time</strong> and the <strong>max input impedance</strong>. The conversion time is the overall time it takes to perform the conversion - this takes into account the clock, sample time, and propagation delay (it's not a simple sum, unfortunately). The impedance is our first topic for tuning.</p>
<h2>Input impedance</h2>
<p>The ADC on the SAM D21 makes measurements by charging a capacitor to the input voltage. In order for measurements to be accurate the capacitor must have enough time to charge up to the input voltage before sampling occurs. How long this takes depends on the input <a href="https://en.wikipedia.org/wiki/Electrical_impedance">impedance</a>. If you assume that you're measuring DC voltage then impedance is the same as resistance. So you just have to think about all of the resistance between the voltage you're trying to measure and the ADC input pin.</p>
<p>For example, for this circuit:</p>
<p><img src="https://blog.thea.codes/static/adc_impedance.svg" alt="Circuit with impedance"></p>
<p>The input impedance is 250kΩ (100kΩ + 150kΩ). When connecting this circuit to the ADC you have to ensure that the ADC is configured so that it has enough time to fully charge that capacitor with that amount of input impedance. The way this is done is by changing the sample time, <code>ADC-&gt;SAMPCTRL.SAMPLEN</code>. Increasing the sample time gives the capacitor a longer amount of time to charge and thus increasing the amount of input impedance the ADC can deal with. It also slightly increases the overall conversion time. Try using the calculator above to get the ADC to work with the 250kΩ impedance shown in the example above (spoilers: you only have to increase the sample time by 1).</p>
<p>Here's the code for changing the sample time. You should do this before enabling the ADC:</p>
<pre><span>// Set the sample time length to accommodate for input impedance.</span>
<span>ADC</span><span>-&gt;</span><span>SAMPCTRL</span><span>.</span><span>reg</span> <span>=</span> <span>ADC_SAMPCTRL_SAMPLEN</span><span>(</span><span>1</span><span>);</span>
</pre>
<p>You'll run into input impedance a lot. For example, if you have a potentiometer configured as a <a href="https://learn.sparkfun.com/tutorials/voltage-dividers/all#applications">voltage divider</a> to provide a simple knob input for your project then the ADC's max input impedance must be greater than the whole potentiometer's resistance.</p>
<p>This illustrates why: when the potentiometer is close to the end the current must travel through nearly the entire resistance of the potentiometer before reaching the ADC input:</p>
<p><img src="https://blog.thea.codes/static/adc_pot.svg" alt="Circuit with potentiometer"></p>
<p>If you have a use case where you <em>don't</em> want to increase the sample time for the ADC, you can use a <a href="https://en.wikipedia.org/wiki/Buffer_amplifier">buffer</a> to change the source impedance, like in this circuit that provides a source impedance of just 1kΩ:</p>
<p><img src="https://blog.thea.codes/static/adc_buffer.svg" alt="Circuit with active buffer"></p>
<p>For more details on how the calcuator figures out the max input impedance and how the capacitor charging works see <a href="http://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">section 37.11.4.3 of the datasheet</a>.</p>
<h2>Baseline</h2>
<p>Alright, now that you've got the ADC configured with the proper input impedance you can get a sense for the baseline accuracy of the measurements. ADCs have a couple of real-world properties that impact accuracy. These are generally presented by the manufacturer as a range of <a href="https://en.wikipedia.org/wiki/Integral_nonlinearity">Integral Nonlinearity</a> and <a href="https://en.wikipedia.org/wiki/Differential_nonlinearity">Differential Nonlinearity</a>. Those scary words basically just boil down to "how does the ADC's <em>actual</em> measurements compare to what I <em>expect</em> the measurements to be?" For example, if you give the ADC <code>1.0v</code> and it measures <code>1.1v</code> that's some of that non-linearity showing through.</p>
<p>Before tweaking the ADC settings to get better accuracy it's important to understand what the <em>current</em> accuracy looks like. For my tests, I used a precision voltage source (a calibrated 16-bit digital to analog converter) and measured 100 data points across the input voltage range of the ADC. I then compared the measured values against the expected values to determine the amount of error.</p>
<p>Here's two images that show the real-world performance of the SAM D21 ADC with minimal configuration - the same configuration used in my previous blog post and similar to the configuration you'll see by default in Arduino: 12 bit, one sample, no offset or gain correction.</p>
<p>Here's the measured results compared against the expected values:</p>
<p><img src="https://blog.thea.codes/static/adc_chart_1.svg" alt="baseline comparison"></p>
<p>And here's that same data but represented as the amount that each measurement was off from the expected measurement:</p>
<p><img src="https://blog.thea.codes/static/adc_chart_2.svg" alt="baseline error"></p>
<p>While this isn't entirely awful there is still lots of room for improvement! The next few sections will discuss techniques for improving the ADC's accuracy.</p>
<p>By the way, if you want some more information on all the different real world properties of ADCs and DACs and how those affect accuracy, check out this <a href="https://www.ti.com/lit/an/slaa013/slaa013.pdf">application note from TI on data converters</a>.</p>
<h2>Multisampling and averaging</h2>
<p>You can improve the SAM D21 ADC accuracy by taking multiple samples for a measurement and then averaging them. Luckily, the hardware can do this for you. However, since multisampling and averaging cause each measurement to take a longer amount of time you'll need to balance speed and accuracy for your use case. If you're measuring something that doesn't need to be sampled at very high rate using more multisampling and averaging is a good idea. The general rule of thumb is to use as much as you can while still sampling fast enough to meet your requirements.</p>
<p>I'm going to show you how multisampling and averaging can impact accuracy. The SAM D21 can be configured to average <code>1</code> to <code>1024</code> samples in steps of powers of two. For the first test I set the number of samples to average to <code>64</code>. Here's the results:</p>
<p><img src="https://blog.thea.codes/static/adc_chart_3.svg" alt="64 sample error results"></p>
<p>This is already a huge improvement over the baseline. Note that I also reduced the scale of the graph. The time cost for doing 64 samples isn't too much of a hit on performance, either.</p>
<p>Here's the code for configuring multisampling and averaging. Again, do this before enabling the ADC.</p>
<pre><span>// Configure multisampling and averaging.</span>
<span>// Note that ADJRES must be set according to table</span>
<span>// 33-3 in the datasheet.</span>
<span>ADC</span><span>-&gt;</span><span>AVGCTRL</span><span>.</span><span>reg</span> <span>=</span> <span>ADC_AVGCTRL_SAMPLENUM_256</span> <span>|</span> <span>ADC_AVGCTRL_ADJRES</span><span>(</span><span>4</span><span>);</span>

<span>// For multisampling to work correctly the RESSEL part</span>
<span>// of CTRLB must be set to 16-bit, even if you're doing</span>
<span>// 12-bit measurements. See section 33.6.7  in the</span>
<span>// datasheet.</span>
<span>ADC</span><span>-&gt;</span><span>CTRLB</span><span>.</span><span>reg</span> <span>|=</span> <span>ADC_CTRLB_RESSEL_16BIT</span><span>;</span>
</pre>
<p>Okay, so <code>64</code> samples looks better, but what if you use even more samples? How much does that improve things?</p>
<p>Well here's at <code>256</code> samples:</p>
<p><img src="https://blog.thea.codes/static/adc_chart_4.svg" alt="256 sample error results"></p>
<p>And at <code>1024</code> samples:</p>
<p><img src="https://blog.thea.codes/static/adc_chart_5.svg" alt="1024 sample error results"></p>
<p>For higher sample rates the error curve tends to flatten out - indicating that the ADC is exhibiting a more linear transfer function - which is a good thing. However, notice that the curve as a whole has migrated upwards a bit. From what I can gather this is due to <em>offset error</em> accumulating, and offset error is the topic of the next section.</p>
<h2>Offset &amp; gain error correction</h2>
<p>Okay, so you've determined how much multisampling you want to use for your application, however, things aren't quite perfect. If you're like me and decided to go with <code>256</code> samples you now have an offset on all of your measurements. You could just update your firmware to subtract the offset from each measurement but the hardware can actually do this <em>and a little more</em> for you.</p>
<p>The SAM D21 has the ability to apply both <em>offset</em> and <em>gain error</em> correction. <em>Offset error</em> is pretty easy to intuit from what you've experienced so far and the graphs above - it's a constant amount of error on each measurement. The <em>gain error</em> is a bit more subtle. It's the difference between the measured value and the expected value at the top of the ADC's range - that is, it's deviation from the <em>slope</em> of the ideal transfer function. This picture illustrates this:</p>
<p><img src="https://blog.thea.codes/static/adc_total_error.png" alt="gain error"></p>
<p><em>Source: Microchip Application Note TB3185</em></p>
<p>When looking at the error graphs of real-world measurements in previous sections the gain error can be see as a "tilt" in the error line. Ideally, the line of best fit in that chart would be straight across.</p>
<p>Okay, enough theory. How do you address the gain and offset errors? The SAM D21 has two registers, <code>ADC-&gt;OFFSETCORR</code> and <code>ADC-&gt;GAINCORR</code>, for configuring the hardware to do the correction for you. The hardware will automatically apply the formula <code>result = (conversion_value - OFFSETCORR) * GAINCORR</code>. This is detailed in <a href="http://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">section 33.6.10 of the datasheet</a>. The datasheet doesn't give a lot of hints on figuring out these values, unfortunately.</p>
<p>The best way I've found for calculating these values is to take two measurements: one in the bottom quarter of the ADC's range (say, at 15%) and one at the top quarter of the ADC's range (say, at 85%). This is from the <a href="http://ww1.microchip.com/downloads/en/DeviceDoc/90003185A.pdf">TB3185 Application Note</a>. Once you have these two measurements you can determine the gain and offset error using these formulas:</p>
<pre><span>low_expected</span> <span>=</span> <span>...</span>
<span>low_measured</span> <span>=</span> <span>...</span>
<span>high_expected</span> <span>=</span> <span>...</span>
<span>high_measured</span> <span>=</span> <span>...</span>

<span>gain_error</span> <span>=</span> <span>(</span><span>high_measured</span> <span>-</span> <span>low_measured</span><span>)</span> <span>/</span> <span>(</span><span>hi…</span></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.thea.codes/getting-the-most-out-of-the-samd21-adc/">https://blog.thea.codes/getting-the-most-out-of-the-samd21-adc/</a></em></p>]]>
            </description>
            <link>https://blog.thea.codes/getting-the-most-out-of-the-samd21-adc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23884764</guid>
            <pubDate>Sat, 18 Jul 2020 20:54:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Secret Management with Docker-compose and Ansible Vault]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23884667">thread link</a>) | @alexktz
<br/>
July 18, 2020 | https://blog.ktz.me/secret-management-with-docker-compose-and-ansible/ | <a href="https://web.archive.org/web/*/https://blog.ktz.me/secret-management-with-docker-compose-and-ansible/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>Many of you will know that I am a huge proponent of Ansible and Infrastructure as Code in general. Using automation and version control to manage the configuration of your systems not only saves you time in the long run but it also gives makes you more employable. The latest Red Hat certifications, for example, are <em>all-in</em> on Ansible.</p><blockquote>Every file I reference in this blog post will be available in <a href="https://github.com/ironicbadger/compose-secret-mgt">this Git repo</a>.</blockquote><p>This article is an outline of how I use Ansible and Ansible Vault in conjunction with docker-compose to keep my secrets safe and encrypted whilst still being able to push my repos to Github publicly.</p><p>Why bother using Ansible to manage a file that you can very easily edit yourself by hand? It seems like a lot of overhead. In some ways, you are right.</p><p>If all you're doing is deploying one or two services using a docker-compose file or a docker run command then at first, it is easier to hand crank these files. That is, until you try and remember the parameters used to configure the container 6 months from now or a disaster strikes.</p><p>A disaster could mean you accidentally deleted the VM, made a breaking change to a config file without realising it, or simply did something you shouldn't have. There are many ways you could lose the configuration used to create your containers and by committing these files to git (Github, Gitlab, a self-hosted Gitea instance, etc) you instantly create a versionable backup. You can go back through history and see what changed, when, where and if your commit messages are ok maybe even figure out why, retrospectively.</p><p>This comes with a cost though. You must make <em>every single change</em> using this method from here on out. If you make a manual change to your compose yaml file and then run Ansible again next week, those manual changes will be overwritten. You have to commit.</p><p>Another issue we need to overcome is that your configuration is now out in the open (if you push to a public Github), including secrets. Secrets can include (but are not limited to) domain names, file paths, API keys, passwords, email addresses and so on. Essentially, they're anything you'd rather someone else didn't know.</p><p>We need a way to encrypt those secrets but also access them when generating our docker-compose yaml file. Ansible Vault makes this simple. I'll be the first to admit this isn't a totally straightforward process at first but over time, it will become second nature. Promise!</p><p>We'll come onto integrating Ansible Vault with Ansible in a moment. It's also easy to confuse <a href="https://docs.ansible.com/ansible/latest/user_guide/vault.html">Ansible Vault</a> with <a href="https://www.vaultproject.io/">Hashicorp Vault</a>, they are two different secret handling projects that have nothing whatsoever to do with one another.</p><p>To create a new, empty encrypted file run:</p><pre><code>ansible-vault create foo.yaml
</code></pre><p>You'll be asked for a password before being launched into your <code>$EDITOR</code> (the default is vi). Save and close this file and you'll have an AES encrypted file on disk.</p><p>To edit this file execute:</p><pre><code>ansible-vault edit foo.yaml
</code></pre><p>Again, you'll be asked for your password and be launched into your <code>$EDITOR</code>. Make your changes, then save and quit.</p><h2 id="protecting-you-from-yourself">Protecting you from yourself</h2><p><br>However, here's a second way to edit vault files. This method is is my personal preference using:</p><pre><code>ansible-vault decrypt foo.yaml
</code></pre><p>This decrypts your file and leaves it decrypted until you encrypt it again with:</p><pre><code>ansible-vault encrypt foo.yaml
</code></pre><p>The upside of this approach is that <code>foo.yaml</code> is just another clear-text file making edits via vscode or another editor besides <code>$EDITOR</code> trivial. I find this preferable in long editing sessions.</p><p>The downside is it's all too easy to accidentally commit an unencrypted file to git. I had to delete a git repo once when I leaked my gmail password on Github, it was picked up by bots in under 20 minutes! Once a file is pushed to a public repository, the values in this file are there forever or until you delete the repository due to the way git's db tracks files for versioning (or until you do some clever editing to the git db, but ain't no-one got time for that).</p><p>Nick Busey from <a href="https://homelabos.com/">HomelabOS</a> wrote me a neat little pre-commit hook that will not allow an unencrypted vars file to be committed.</p><pre><code>if ( cat vars/vault.yaml | grep -q "\$ANSIBLE_VAULT;" ); then
echo "[38;5;108mVault Encrypted. Safe to commit.[0m"
else
echo "[38;5;208mVault not encrypted! Run 'make encrypt' and try again.[0m"
exit 1
fi
</code></pre><p>This pre-supposes your secrets live in <code>vars/vault.yaml</code>. In the git repo accompanying this post look for <code>git-init.sh</code>, this installs the hook to <code>.git/hooks/pre-commit</code>.</p><p>More on Ansible Vault shortly.</p><p><br>With a bit of effort you'll be able to pick up the key principles of Ansible in a day or two. <a href="https://twitter.com/geerlingguy">Jeff Geerling</a> just released a really excellent set of <a href="https://www.youtube.com/watch?v=goclfp6a2IQ">Ansible 101</a> videos on Youtube. If you're confused about anything relating to Ansible, his videos are a good place to start.</p><p>To make things easy, I assume you have two hosts. The first is the target host which will be running docker and where your completed, clear-text docker-compose yaml file will ultimately live -- let's call this <code>server</code>. The second is where you do your development work, probably a desktop or laptop -- let's call this <code>client</code>.</p><figure><img src="https://blog.ktz.me/content/images/2020/07/Screen-Shot-2020-07-18-at-4.01.51-PM.png" alt="" srcset="https://blog.ktz.me/content/images/size/w600/2020/07/Screen-Shot-2020-07-18-at-4.01.51-PM.png 600w, https://blog.ktz.me/content/images/size/w1000/2020/07/Screen-Shot-2020-07-18-at-4.01.51-PM.png 1000w, https://blog.ktz.me/content/images/size/w1600/2020/07/Screen-Shot-2020-07-18-at-4.01.51-PM.png 1600w, https://blog.ktz.me/content/images/2020/07/Screen-Shot-2020-07-18-at-4.01.51-PM.png 1784w" sizes="(min-width: 1200px) 1200px"></figure><p>Ensure that Ansible is installed on the <code>client</code> and that Python is installed on the <code>server</code>. Installation varies per OS so please refer to the Ansible <a href="https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html">documentation</a> for steps on your system.</p><p>Ansible works over SSH. In order for the best experience it is suggested that you have SSH keys copied to the <code>server</code> so that you can connect without a password. From your <code>client</code> run <code>ssh-copy-id user@server</code>.</p><blockquote>In my testing for this article <code>192.168.1.50</code> was an Ubuntu 20.04 VM. There is nothing unique here to Ubuntu, so these concepts will apply to almost any Linux host.</blockquote><p>Ensure that <code>ssh server</code> works without specifying a password. If you'd like extra points make use of <code>~/.ssh/config</code> with the following entry:</p><pre><code># ~/.ssh/config

Host server
  Hostname 192.168.1.50
  User alex</code></pre><p><br>We're going to create an inventory file so that Ansible knows which hosts we want to manage. Remember all files can be found in <a href="https://github.com/ironicbadger/compose-secret-mgt">this git repo</a>.</p><pre><code>[server]
192.168.1.50
</code></pre><p>This inventory file assigns the host <code>192.168.1.50</code> to the group <code>[server]</code>. Ansible can do a whole lot with 'host groups' but that's largely beyond the scope of this article, check out the Ansible docs if you're interested in learning more.</p><p>We can test that Ansible is working with an ad-hoc command like this.</p><pre><code>alex@mooncake compose-secret-mgt % ansible -m ping -i inventory server
192.168.1.50 | SUCCESS =&gt; {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python3"
    },
    "changed": false,
    "ping": "pong"
}
</code></pre><p>This show us that the server replied <code>pong</code> to our <code>ping</code> request made using the <a href="https://docs.ansible.com/ansible/latest/modules/ping_module.html">ping module</a>.</p><p><a href="https://docs.ansible.com/ansible/latest/modules/modules_by_category.html">Modules</a> are an important concept in Ansible and are written in Python. They are what actually do the work we define in our tasks, roles and playbooks.</p><p>Now that we've verified connectivity between our <code>client</code> and <code>server</code> we can move onto templating.</p><p>We're going to template an example <code>ini</code> file, this has nothing to with your eventual compose templating. However, it shows that we can use these principals to manage our entire server configuration, including the apps that run on it.</p><p>Ansible uses the <a href="https://palletsprojects.com/p/jinja/">Jinja2</a> templating language to perform substitutions in template files. We will be using the <a href="https://docs.ansible.com/ansible/latest/modules/template_module.html">template</a> module for this. Here is a <em>non-functional</em> snippet of the config file for <a href="https://gitea.io/en-us/">Gitea</a>, a self-hosted Github alternative. The full file was much too long but you'll get the idea by the time we're done with this example.</p><pre><code>APP_NAME = {{ subdomain_git }}.{{ domain_full }}
RUN_MODE = prod
RUN_USER = git

[repository]
ROOT = {{ data_root_path }}/git/repositories

[server]
APP_DATA_PATH    = {{ data_root_path }}/gitea
SSH_DOMAIN       = {{ subdomain_git }}.{{ domain_full }}
HTTP_PORT        = {{ listen_port_gitea }}
ROOT_URL         = https://{{ subdomain_git }}.{{ domain_full }}/
DOMAIN           = {{ subdomain_git }}.{{ domain_full }}
</code></pre><p>You can see above, several variables surrounded by <code>{{ }}</code>. Jinja2 uses these double braces to know where to perform substitutions. The values of these substitutions come from Ansible variables. </p><p>Note that we can construct strings using concatenation with multiple variables like <code>{{ subdomain }}.{{ domain_full }}</code>. This allows us to easily change the subdomain used for git independently from the main domain and is especially useful when the same string is required multiple times in the same file.</p><p>We can also reuse <code>domain_full</code> elsewhere throughout our entire infrastructure and only define it in one place.</p><p>For example, suppose that in your compose file you want to reuse some of these values. Port numbers, paths, etc. To change the port the app is listening on manually would be half a dozen edits. Using Ansible, it's <em>just one</em>. It is automatically updated everywhere it appears all at once using templating.</p><blockquote>You can follow along in the git repo by running <code>ansible-playbook -i inventory example1.yaml</code>.</blockquote><pre><code># example1.yaml - barebones templating example
- hosts: server
  vars:
    - subdomain_git: git 
	  - domain_full: domain.com
	  - data_root_path: /data
	  - listen_port_gitea: 3000
  tasks:
    - name: template test
      template:
        src: example.ini.j2
        dest: example.ini
</code></pre><p>For example if we execute the playbook above and run the template through Jinja2, we create the following output.</p><pre><code>alex@blogtest:~$ cat example.ini
APP_NAME = git.domain.com
RUN_MODE = prod
RUN_USER = git

[repository]
ROOT = /data/git/repositories

[server]
APP_DATA_PATH    = /data/gitea
SSH_DOMAIN       = git.domain.com
HTTP_PORT        = 3000
ROOT_URL         = https://git.domain.com/
DOMAIN           = git.domain.com
</code></pre><p>We told Ansible to run the templating module against the group of hosts defined under <code>server</code>. It then performed variable substitutions using the variables values defined in the playbook (variables are tightly scoped in Ansible) and templated them into our target file. Finally the module copied this file to the target <code>server</code> file path we provided.</p><p>Take a look at the file <code>var…</code></p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.ktz.me/secret-management-with-docker-compose-and-ansible/">https://blog.ktz.me/secret-management-with-docker-compose-and-ansible/</a></em></p>]]>
            </description>
            <link>https://blog.ktz.me/secret-management-with-docker-compose-and-ansible/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23884667</guid>
            <pubDate>Sat, 18 Jul 2020 20:42:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I (almost) replicated OpenAI's GPT-2 (124M version)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23884620">thread link</a>) | @stormtroper1721
<br/>
July 18, 2020 | https://bilal.software/2020/7/17/nlp-series-2/ | <a href="https://web.archive.org/web/*/https://bilal.software/2020/7/17/nlp-series-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><ul>
<li><a href="https://bilal.software/2020/6/22/nlp-series-1/">Part 1: Best Practices for Finetuning Large Transformer Language models</a></li>
<li><a href="https://bilal.software/2020/7/17/nlp-series-2/">Part 2: How I (almost) replicated OpenAI's GPT-2 (124M version)</a></li>
</ul>
<hr>

<hr>
<p>A few months ago I started working on a research project trying to pretrain my own, more efficient language model from scratch. I got access to a 128-core TPUv3 pod from the Tensorflow Reseach Cloud and used it to pretrain a <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>124</mn></mrow><annotation encoding="application/x-tex">124</annotation></semantics></math></span></span>M parameter GPT-2 model to a perplexity pretty close to OpenAI's results (my pretrained model used was trained for about <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mi mathvariant="normal">/</mi><mn>8</mn></mrow><annotation encoding="application/x-tex">1/8</annotation></semantics></math></span></span>th of the number of iterations that OpenAI trained their model for and got <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>21</mn></mrow><annotation encoding="application/x-tex">21</annotation></semantics></math></span></span> ppl on OpenWebText compared to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>17</mn></mrow><annotation encoding="application/x-tex">17</annotation></semantics></math></span></span> ppl for OpenAI's model), and then pretrained an ALBERT-style GPT-2 (that I'm calling ALGPT2) language model with a factorized input embedding and parameter sharing that would reduce the number of paramters from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>124</mn></mrow><annotation encoding="application/x-tex">124</annotation></semantics></math></span></span>M to around <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>12</mn></mrow><annotation encoding="application/x-tex">12</annotation></semantics></math></span></span>M.</p>
<p>Unfortunately, ALGPT-2 doesn't preform as well as GPT-2 (ALGPT-2 gets <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>31</mn></mrow><annotation encoding="application/x-tex">31</annotation></semantics></math></span></span> ppl on OpenWebText compared to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>21</mn></mrow><annotation encoding="application/x-tex">21</annotation></semantics></math></span></span> ppl for my pretrained GPT-2 model), but I'm writing this series of blog posts to go through everything I've learned over the last few months.</p>
<hr>

<hr>
<p>The main thing that I wanted to do from this sort-of "research project" that I was working on by myself this spring was to develop and train a more efficient version of the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>124</mn></mrow><annotation encoding="application/x-tex">124</annotation></semantics></math></span></span>M parameter version of <a href="https://openai.com/blog/better-language-models/">GPT-2</a> (I wanted to pretrain the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1.5</mn></mrow><annotation encoding="application/x-tex">1.5</annotation></semantics></math></span></span>B param version of GPT-2 but since I only got access to the TPU pod for a week, I had to choose a model that would train in time.).</p>
<p>I was able to almost replicate the 124M parameter version of GPT-2 by pretraining it to a perplexity pretty close to OpenAI's results (my pretrained model used was trained for about <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mi mathvariant="normal">/</mi><mn>8</mn></mrow><annotation encoding="application/x-tex">1/8</annotation></semantics></math></span></span>th of the number of iterations that OpenAI trained their model for and got <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>21</mn></mrow><annotation encoding="application/x-tex">21</annotation></semantics></math></span></span> ppl on OpenWebText compared to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>17</mn></mrow><annotation encoding="application/x-tex">17</annotation></semantics></math></span></span> ppl for OpenAI's model),</p>
<p>My idea of making a more efficient transformer didn't really work out since my pretrained transformer ended up being about <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>20</mn></mrow><annotation encoding="application/x-tex">20</annotation></semantics></math></span></span>ppl worse than an equivalent GPT-2 model, but I wanted to writeup what I learned over the two or three months that I was working on this.</p>
<hr>

<hr>
<details>
    <summary>
        Expand
    </summary>

<p>A little bit about myself: I'm an incoming software engineering student at the University of Waterloo and this post is supposed to be a writeup of a NLP research project that I was working on from around March to May of 2020 (right in the middle of the first Covid-19 lockdown of 2020, I'm currently writing this on July 15, 2020 while waiting for my Pix2PixHD model to train for a few hundred epochs on Google Colab).</p>
<p>Over the last three or four years I've done a lot of machine learning related stuff. I started out back in early 2017 by going through the <a href="https://www.google.com/search?sxsrf=ALeKk010AvJn990-Vqb1MA50AAVbnMg8uw:1594828665718&amp;q=Introduction+to+Machine+Learning+with+Python:+A+Guide+for+Data+Scientists&amp;stick=H4sIAAAAAAAAAONgVuLVT9c3NEwyLzRLKs_Ke8RowS3w8sc9YSn9SWtOXmPU5OIKzsgvd80rySypFJLmYoOyBKX4uVB18ixi9fTMKynKTylNLsnMz1MoyVfwTUzOyMxLVfBJTSzKy8xLVyjPLMlQCKgsycjPs1JwVHAvzUxJVUjLL1JwSSxJVAhOzkwFGl9cUgwAxHs76ZgAAAA&amp;biw=1920&amp;bih=969">Introduction to Machine Learning with Python</a> and <a href="https://www.google.com/search?q=hands+on+machine+learning+with+scikit-learn+and+tensorflow&amp;oq=hands+on+mac&amp;aqs=chrome.0.0j69i57j46j0l5.1936j0j7&amp;sourceid=chrome&amp;ie=UTF-8">Hands-On Machine Learning with Scikit-Learn and TensorFlow</a> books. At the time, I didn't really understand all the math behind neural networks, but it got me hooked on ML and then took the <a href="https://www.deeplearning.ai/">deeplearning.ai</a> courses on Coursera and the original <a href="https://www.fast.ai/">fast.ai</a> course (back in late 2017 when they hadn't switched over to Pytorch and still used Tensorflow and Keras).</p>
<p>I started competing on <a href="https://kaggle.com/">Kaggle</a> in early 2018 and pretty much kept on competing in competitions non-stop for about a year and a half afterwards, winning a few medals and becoming a competitions expert (At one point I was ranked in the top 1000 Kagglers worldwide). Kaggle was a really nice way to get a lot of experience using neural networks because of the wide range of competitions and datasets that I had access to. I started out by doing a few semantic segmentation competitions then moved onto competing in a few NLP competitions. Since around mid 2019, I've been working on a bunch of different projects in ML and lower-level CS stuff. I worked on making a PyTorch-style machine learning library in <a href="https://github.com/bkkaggle/L2/tree/c%2B%2B">c++</a> and more recently in <a href="https://github.com/bkkaggle/L2">Rust</a> and for the last few months I've also been trying to keep up with all the new machine learning (esp NLP) papers on arXiv.</p>
<p>I was pretty lucky that I started learning NLP right before transformers exploded in popularity, I remember when <a href="https://arxiv.org/abs/1301.3781">word2vec</a> and LSTMs were still SOTA on a lot of NLP tasks, and it's pretty nice to see how much the field of NLP has changed in just a few years, going from when LSTMs with only a a handfull of layers and 512 units was considered to be a large network and computationally expensive to train, to training LSTMs with <a href="https://arxiv.org/abs/1409.0473">attention</a> layers on top, to the original <a href="https://arxiv.org/abs/1706.03762">transformer encoder/decoder networks</a>, to <a href="https://arxiv.org/abs/1801.06146">ULMFIT</a> and <a href="https://arxiv.org/abs/1802.05365">ELMO</a>, then <a href="https://arxiv.org/abs/1810.04805">BERT</a>, <a href="https://arxiv.org/abs/1907.11692">RoBERTa</a>, <a href="https://openai.com/blog/better-language-models/">GPT-2</a>, and <a href="https://arxiv.org/abs/1910.10683">T5</a>, to just a few months ago with the explosion of new, more efficient replacements for self-attention like the <a href="https://openai.com/blog/sparse-transformer/">Sparse Transformer</a>, the <a href="https://arxiv.org/abs/2001.04451">Reformer</a>, and <a href="https://arxiv.org/abs/2005.00743">Synthesizers</a>, and now <a href="https://arxiv.org/abs/2005.14165">GPT-3</a>, which IMO has the potential to really change the whole field of NLP.</p>
<p>Just a few years ago we trained shallow recurrent networks on datasets, then pretrained large transformer language models on large datasets and finetuned on task-specific datasets. Now the whole idea of just training a gigantic language model on a huge dataset, then conditioning the model in a form of few-shot learning by prepending a few examples of a certain task to an input feels like it can really make NLP models a lot more accessible and easier to productionize as well as making human-chatbot interactions a lot more realistic than they are today.</p>
<p>I've rambled on for long enough, lets get to the main topic of this post.</p>
</details>
<hr>

<hr>
<p>So <a href="https://openai.com/blog/better-language-models/">GPT-2</a> is basically a transformer decoder. It's an embedding layer that maps a one-hot vector of a given token's index (all the GPT-2 models use a vocabulary size of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>50257</mn></mrow><annotation encoding="application/x-tex">50257</annotation></semantics></math></span></span>) to a <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>768</mn></mrow><annotation encoding="application/x-tex">768</annotation></semantics></math></span></span> dimensional vector (all GPT-2 numbers in this blog post will be for the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>124</mn></mrow><annotation encoding="application/x-tex">124</annotation></semantics></math></span></span>m parameter version of GPT-2) plus the positional encoding followed by a stack of self-attention and feed-forward layers that each output a <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>768</mn></mrow><annotation encoding="application/x-tex">768</annotation></semantics></math></span></span> dimensional vector (keeping the number of outputs for each layer constant) followed by an output embedding (the weights of the input and output embeddings are tied to make training easier) that maps the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>768</mn></mrow><annotation encoding="application/x-tex">768</annotation></semantics></math></span></span> dimensional vector that is the output of the last layer of the transformer to the same <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>50257</mn></mrow><annotation encoding="application/x-tex">50257</annotation></semantics></math></span></span> dimensional vector that represents the probability of each token in the vocabulary being the next token in the sequence. Take a look at <a href="http://jalammar.github.io/illustrated-gpt2/">The Illustrated GPT-2</a> for a more in-depth look into GPT-2.</p>
<p><a href="https://arxiv.org/abs/1909.11942">ALBERT</a> (A Lite BERT) is a paper that takes a look at <a href="https://arxiv.org/abs/1810.04805">BERT</a> and identifies some ways in which to make it more efficient and reduce the number of parameters in the model in four major ways: a factorized embedding, layer-wise parameter sharing, a sentence-order-prediction auxillary loss, and removing dropout.</p>
<hr>
<h3>Factorized embedding</h3>
<hr>
<p>GPT-2's embedding has a lot of parameters. It's really just a matrix of dimensions <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>50257</mn><mo>×</mo><mn>768</mn></mrow><annotation encoding="application/x-tex">50257 \times 768</annotation></semantics></math></span></span>. That means that the input embedding alone uses up almost <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>50257</mn><mo>×</mo><mn>768</mn><mo>=</mo><mtext>&nbsp;</mtext><mo>∼</mo><mn>38</mn><mo separator="true">,</mo><mn>000</mn><mo separator="true">,</mo><mn>000</mn></mrow><annotation encoding="application/x-tex">50257 \times 768 = \space \sim 38,000,000</annotation></semantics></math></span></span> parameters which is a pretty big chunk of the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>128</mn></mrow><annotation encoding="application/x-tex">128</annotation></semantics></math></span></span>M total parameters in the model.</p>
<p>The ALBERT authors propose a factorized embedding with an intermediate embedding size of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>128</mn></mrow><annotation encoding="application/x-tex">128</annotation></semantics></math></span></span>, one embedding of size <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>50257</mn><mo>×</mo><mn>128</mn></mrow><annotation encoding="application/x-tex">50257 \times 128</annotation></semantics></math></span></span> and another embedding of size <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>128</mn><mo>×</mo><mn>768</mn></mrow><annotation encoding="application/x-tex">128 \times 768</annotation></semantics></math></span></span>. By breaking up the large embedding matrix into two smaller matrices, the total number of parameters used in the embedding goes from about <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>38</mn></mrow><annotation encoding="application/x-tex">38</annotation></semantics></math></span></span>M to about <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6</mn></mrow><annotation encoding="application/x-tex">6</annotation></semantics></math></span></span>M.</p>
<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>50257</mn><mo>×</mo><mn>128</mn><mo>=</mo><mo>∼</mo><mn>6</mn><mo separator="true">,</mo><mn>000</mn><mo separator="true">,</mo><mn>000</mn></mrow><annotation encoding="application/x-tex">50257 \times 128 = \sim 6,000,000</annotation></semantics></math></span></span></p>
<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>128</mn><mo>×</mo><mn>768</mn><mo>=</mo><mo>∼</mo><mn>100</mn><mo separator="true">,</mo><mn>000</mn></mrow><annotation encoding="application/x-tex">128 \times 768 = \sim 100,000</annotation></semantics></math></span></span></p>
<p>The authors try different intermediate embedding sizes and settle on <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>128</mn></mrow><annotation encoding="application/x-tex">128</annotation></semantics></math></span></span> as a good tradeoff betweeen parameters and performance.</p>
<hr>
<h3>Layer-wise parameter sharing</h3>
<hr>
<p>In a normal transformer model, the transformer layers are created something like this:</p>
<div data-language="python"><pre><code><span>class</span> <span>BERT</span><span>(</span>nn<span>.</span>Module<span>)</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span>self<span>,</span> n_layers<span>)</span><span>:</span>
        <span>super</span><span>(</span><span>)</span><span>.</span>__init__<span>(</span><span>)</span>
        <span>//</span> <span>.</span><span>.</span><span>.</span>
        self<span>.</span>blocks <span>=</span> nn<span>.</span>ModuleList<span>(</span><span>[</span>Block<span>(</span><span>)</span> <span>for</span> _ <span>in</span> <span>range</span><span>(</span>n_layers<span>)</span><span>]</span><span>)</span>
        <span>//</span> <span>.</span><span>.</span><span>.</span>
    <span>def</span> <span>forward</span><span>(</span>self<span>,</span> x<span>)</span><span>:</span>
        <span>//</span> <span>.</span><span>.</span><span>.</span>
        <span>for</span> block <span>in</span> self<span>.</span>blocks<span>:</span>
            x <span>=</span> block<span>(</span>x<span>)</span>
        <span>//</span> <span>.</span><span>.</span><span>.</span></code></pre></div>
<p>ALBERT shares all parameters across the transformer layers something like this:</p>
<div data-language="python"><pre><code><span>class</span> <span>ALBERT</span><span>(</span>nn<span>.</span>Module<span>)</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span>self<span>,</span> n_layers<span>)</span><span>:</span>
        <span>super</span><span>(</span><span>)</span><span>.</span>__init__<span>(</span><span>)</span>
        <span>//</span> <span>.</span><span>.</span><span>.</span>

        self<span>.</span>n_layers <span>=</span> n_layers
        self<span>.</span>block <span>=</span> Block<span>(</span><span>)</span>
        <span>//</span> <span>.</span><span>.</span><span>.</span>
    <span>def</span> <span>forward</span><span>(</span>self<span>,</span> x<span>)</span><span>:</span>
        <span>//</span> <span>.</span><span>.</span><span>.</span>
        <span>for</span> _ <span>in</span> self<span>.</span>n_layers<span>:</span>
            x <span>=</span> block<span>(</span>x<span>)</span>
        <span>//</span> <span>.</span><span>.</span><span>.</span></code></pre></div>
<p>By only defining one transformer block and looping around it <code>n_layers</code> times, ALBERT saves the GPU memory that would be used to store the parameters for all the layers. For example, if you share parameters across all transformer layers in the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1.5</mn></mrow><annotation encoding="application/x-tex">1.5</annotation></semantics></math></span></span>B parameter GPT-2, the resulting model will only have about <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>37</mn></mrow><annotation encoding="application/x-tex">37</annotation></semantics></math></span></span>M parameters. Since we normally use <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>32</mn></mrow><annotation encoding="application/x-tex">32</annotation></semantics></math></span></span> bit floats to store parameters on the GPU, storing the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1.5</mn></mrow><annotation encoding="application/x-tex">1.5</annotation></semantics></math></span></span>B parameter GPT-2 on the GPU will use up about <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6</mn></mrow><annotation encoding="application/x-tex">6</annotation></semantics></math></span></span>GB of the GPU's memory — that's a pretty big chunk of the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>16</mn></mrow><annotation encoding="application/x-tex">16</annotation></semantics></math></span></span>GB of memory that's on a normal V100 GPU already being used up before taking into account the memory needed to store the model's activations as well as any momentum parameters needed by the optimizer. In contrast, the parameter-sharing version would only use up around <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>148</mn></mrow><annotation encoding="application/x-tex">148</annotation></semantics></math></span></span>MB of GPU memory.</p>
<p>The authors try applying parameter sharing to BERT and see that it reduces performance but makes it easier to train larger and larger models.</p>
<hr>
<h3>Sentence-order-prediction auxillary loss</h3>
<p>The ALBERT authors add an auxillary loss to help training. Since language modelling is usually done autoregressively, I didn't use this for my custom model.</p>
<hr>
<h3>Removing dropout</h3>
<p>The ALBERT authors remove all dropout from BERT and see that it significantly improves performance.</p>
<hr>
<p>That's pretty much what my idea was: Take GPT-2, add a factorized embedding, share parameters across all transformer layers, remove dropout (I actually missed the part about ALBERT removing dropout until I was pretty far into my work, but I did run one or two runs without dropout to see how that works), and pretrain on a large dataset for a few hundred thousand iterations.</p>
<p>There's no way that I could pretrain something like GPT-2 by myself, so I applied to the <a href="https://www.tensorflow.org/tfrc">Tensorflow Research Cloud</a> (TFRC).</p>
<p><em>The TFRC puts an emphasis on wanting to help researchers from non-traditional backgrounds which makes it an amazing resource for anyone who isn't a "traditional" machine learning researcher. They were willing to give me, a 17 year old with …</em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bilal.software/2020/7/17/nlp-series-2/">https://bilal.software/2020/7/17/nlp-series-2/</a></em></p>]]>
            </description>
            <link>https://bilal.software/2020/7/17/nlp-series-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23884620</guid>
            <pubDate>Sat, 18 Jul 2020 20:34:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Software Is Slow and Shitty]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23884598">thread link</a>) | @pketh
<br/>
July 18, 2020 | http://pketh.org/why-software-is-slow-and-shitty.html | <a href="https://web.archive.org/web/*/http://pketh.org/why-software-is-slow-and-shitty.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

<p><img src="http://pketh.org/images/2020/mario64-camera.jpg"></p>

<p>Most software is annoying to use. Opening a news article to read 500 words should be instant but takes entire seconds. Try to make a quick update to a Google Doc and you’re waiting even longer before you can type. Hopefully you don’t have to use Jira or Photoshop.</p>

<p>I thought computers were supposed to be nicer than they were in the 90s.</p>

<p>Grizzled vets say that <a href="https://tonsky.me/blog/good-times-weak-men/">the good times make us weak</a>. That because we have powerful hardware, modern software is built on top of a bewildering goop of high-level languages, frameworks, and dependencies on dependencies that make even simple things sluggish.</p>

<p>It’s a compelling argument. As craftspeople, we just need to not be lazy, get our shit together, and then we can make nice things.</p>

<p>ヽ(´□｀。)ﾉ</p>

<p>But I think self-flagellation is missing the forest for the trees.</p>

<p>As an industry, we’ve moved from putting engineering innovation and efficiency first, towards prioritizing usability and market-fit. I’m not mad at that. Computers exist to help humans do new things, they should be bicycles for the mind and all that good stuff. But there’s nothing stopping software from being useful <em>and</em> elegantly made.</p>

<p>I mean, except for the way most software companies are organized.</p>

<figure>
  <img src="http://pketh.org/images/2020/supreme-problem-solves.png">
  <figcaption>
    <a href="https://www.are.na/block/1975355">(Source)</a>
  </figcaption>
</figure>

<p>Most company structures are based on the <a href="https://www.hierarchystructure.com/roman-military-hierarchy/">Roman empire military</a>. CEO Caesar says he wants something, and the lieutenant managers below him on the org chart break it down into smaller tasks for the soldiers to accomplish.</p>

<p><img src="http://pketh.org/images/2020/caesar-diagram.png">
<a href="https://kinopio.club/roman-military-diagram-Q9vX2HJbM3-tJD0CaTDxM">(Rome military diagram)</a></p>

<p>On a development team, programmers are the soldiers of these shitty new armies. They open their Jira issues and add whatever feature it says to add, or fix what it says to fix. If I can save time by adding another dependency, or skip a meeting by implementing a mockup exactly as designed, why should I care?</p>

<p>Some people care. Those people suffer:</p>

<blockquote>
  <div><p>I now spend 1/4 of my work week fighting dependency hell (after just about each addition of a new package by any other developer on the project), another 1/4 figuring out how the “latest and greatest” tool of the week is best used to do something that would normally take me 5 minutes to do custom (god forbid, not the C-word!), and the remaining half is spent maybe doing actual work. So incredibly frustrating that I’ve just about had it.
</p><p>
I’ve grown to loathe and hate that which I used to adore. <a href="https://news.ycombinator.com/item?id=18027977">(Source)</a></p></div>
</blockquote>

<p>Building software is nothing like organizing armies in 100 BC. In 2020, we can communicate instantly, victory is ambiguous, and there’s less murder. But most importantly, we’re not conquesting, we’re creating.</p>

<h2 id="creation-moves-differently">Creation moves differently</h2>

<p><img src="http://pketh.org/images/2020/mario64-penguin.jpg"></p>

<p>To illustrate this, let’s talk about <a href="https://www.youtube.com/watch?v=8MQO2STCbbY">Super Mario 64</a>, the landmark 1996 game that used an unusual new technology: 3D graphics. You might think that Mario 64 was built with tickets and sprints, but, according to interviews, there was no master plan, only the principles that the game should feel good and be fun. They started with just Mario in a small room, and tuned his animations and physics until he felt nice and responsive. After that, the levels were also created as they went, with the designers, developers, and director going back and forth using sketches and prototypes.</p>

<p>Building like this is never a straight line. Ideas and code get left on the cutting room floor because part of innovation is questioning whether what you made <a href="https://www.folklore.org/StoryView.py?project=Macintosh&amp;story=MacPaint_Evolution.txt">should exist</a>. The process is cyclical and iterative, looking something like:</p>

<figure>
  <img src="http://pketh.org/images/2020/cyclical%20creation%20diagram.png">
  <figcaption>
    <a href="https://kinopio.club/mechanics-focused-development-lCHFGyOJfskhGAZ5Lul5v">(Mechanics-focused development)</a>
  </figcaption>
</figure>

<p>Good software comes from a vision, combined with conversations not commandments. In a craft-focused environment, care for efficiency, simplicity, and details really do matter. I didn’t leave my last job just because I wanted to make something new. I left because I wanted to make it in a way I could be proud of.</p>

<p>So here’s what’s up, I’m working on my own right now, in a race between my diminishing savings and my typing fingers. But I’m not stressing too much. I’ve got a lot of work to do, but people seem to like what I’m making. Maybe one day though, it won’t just be me. When that happens I’d love to build a small company/collective/<em>thing</em> that’s the best place for creators to work.</p>

<blockquote>
  <p>Special thanks to Michelle and <a href="https://twitter.com/haoformayor">Hao</a> for helping edit this.</p>
</blockquote>

  </div></div>]]>
            </description>
            <link>http://pketh.org/why-software-is-slow-and-shitty.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23884598</guid>
            <pubDate>Sat, 18 Jul 2020 20:32:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Views on Error Handling]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 76 (<a href="https://news.ycombinator.com/item?id=23884505">thread link</a>) | @dannas
<br/>
July 18, 2020 | https://dannas.name/error-handling | <a href="https://web.archive.org/web/*/https://dannas.name/error-handling">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<!-- excerpt start -->
<p>In this post, I summarize some accomplished engineer’s views on error handling.
There is a distinction between errors that are caused by programmer
neglecting bugs and those that represent true error conditions. The
granularity of error checking is also up for debate: Per function? Per module?
Jump to dialog handler in the main message loop? Kill the process and restart?
<!-- excerpt end --></p>



<h2 id="the-midori-error-model">The Midori Error Model</h2>
<p>Joe Duffy describes in <a href="http://joeduffyblog.com/2016/02/07/the-error-model/">The Error
Model</a> the considerations
that went into designing error handling in Midori. He said that they were
guided by these principles:</p>

<blockquote>
  <ul>
    <li><strong>Usable</strong>. It must be easy for developers to do the “right” thing in the 
face of error, almost as if by accident. A friend and colleague famously
called this falling into The Pit of Success. The model should not impose
excessive ceremony to write idiomatic code. Ideally, it is cognitively
familiar to our target audience.</li>
    <li><strong>Reliable</strong>. The Error Model is the foundation of the entire system’s 
reliability. We were building an operating system, after all, so reliability
was paramount. You might even have accused us as obsessively pursuing extreme
levels of it. Our mantra guiding much of the programming model development was
“correct by construction.”</li>
    <li><strong>Performant</strong>. The common case needs to be extremely fast. That means as 
close to zero overhead as possible for success paths. Any added costs for
failure paths must be entirely “pay-for-play.” And unlike many modern systems
that are willing to overly penalize error paths, we had several
performance-critical components for which this wasn’t acceptable, so errors
had to be reasonably fast too.</li>
    <li><strong>Concurrent</strong>. Our entire system was distributed and highly concurrent. 
This raises concerns that are usually afterthoughts in other Error Models.
They needed to be front-and-center in ours.</li>
    <li><strong>Diagnosable</strong>. Debugging failures, either interactively or 
after-the-fact, needs to be productive and easy.</li>
    <li><strong>Composable</strong>. At the core, the Error Model is a programming language 
feature, sitting at the center of a developer’s expression of code. As such,
it had to provide familiar orthogonality and composability with other features
of the system. Integrating separately authored components had to be natural,
reliable, and predictable.</li>
  </ul>
</blockquote>

<p>Joe compared different error models against these criteria and came up with
the table below:</p>

<p><img src="https://dannas.name/img/2020/duffy_error_model_table.png" alt="Table of error models"></p>

<p>In the end, he chose checked exception but separated all programmer-error
cases. Those were handled by abandonment - deadly asserts. The compiler could
optimize the code better since it knew exactly which paths could throw (in
contrast to C++ where you have to annotate each function that can not throw).
The syntax is similar to what is now found in Swift and Rust.</p>

<h2 id="the-erlang-approach---let-it-crash">The Erlang Approach - Let it Crash</h2>
<p>The Erlang folks are a bit more hardcore. They don’t get bogged down in
discussions about syntactic structures. Joe Armstrong says in <a href="https://www.softwaretalks.io/v/4611/goto-2018-o-the-dos-and-donts-of-error-handling-o-joe-armstrong">Dos and Don’ts
of error handling</a>:
“You’re correctness theorems aren’t gonna help you if your computer is hit by
lightning. What he meant is that no system runs in isolation and there’s
always the chance of failure. So when errors do happen, they restart the
affected process to a known state and try again.</p>

<p>Fred Hebert describes in <a href="https://ferd.ca/the-zen-of-erlang.html">The Zen of
Erlang</a> the Let it Crash motto. Erlang
processes are fully isolated and share nothing. So if an error is detected,
the system just kills the process and restarts. But how can that solve anything?
Won’t the same bug just happen over and over again? How to deal with a
configuration file that has the wrong content?</p>

<p>Fred refers to Jim Grays 1985 paper <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.110.9127&amp;rep=rep1&amp;type=pdf">Why Do Computers Stop and What Can Be
Done About
It?</a>.
There Gray introduces the notion of Heisenbugs and Bohrbugs. In Fred Hebert’s words:</p>

<blockquote>
  <p>Basically, a bohrbug is a bug that is solid, observable, and easily
repeatable. They tend to be fairly simple to reason about. Heisenbugs by
contrast, have unreliable behaviour that manifests itself under certain
conditions, and which may be hidden by the simple act of trying to
observe them. For example, concurrency bugs are notorious for disappearing
when using a debugger that may force every operation in the system to be
serialized.</p>

  <p>Heisenbugs are these nasty bugs that happen once in a thousand, million,
billion, or trillion times. You know someone’s been working on figuring one
out for a while once you see them print out pages of code and go to town on
them with a bunch of markers.</p>
</blockquote>

<p>So a repeatable (Bohr) bug will be easy to reproduce while a transient
(Heisenbug) will be hard. Now, Hebert argues that if you have a bohrbug in your
system’s core features it should be very easy to find before reaching
production. By being repeatable and often on a critical path, you
should encounter them sooner or later, and fix them before shipping.</p>

<p><img src="https://dannas.name/img/2020/hebert_heisen_bohr_bug.png" alt="Bohr vs Heisen Bugs"></p>

<p>Now, Jim Gray’s paper reports that transient errors (heisenbugs) happen all
the time. They are often fixed by restarting. As long as you weed out the
bohrbugs by having proper testing of your releases, the remaining bugs are
often solved by restarting and rolling back to a known state.</p>

<p><img src="https://dannas.name/img/2020/hebert_bugs_restart.png" alt="Bugs handled by Restart"></p>

<h2 id="classification-of-exceptions">Classification of Exceptions</h2>
<p>Eric Lippert gives this taxonomy in <a href="https://blogs.msdn.microsoft.com/ericlippert/2008/09/10/vexing-exceptions/">Vexing Exceptions</a></p>

<ul>
  <li><strong>Fatal</strong> exceptions are not your fault, you cannot prevent them, and you 
cannot sensibly clean up from them. They almost always happen because the
process is deeply diseased and is about to be put out of its misery. Out of
memory, thread aborted, and so on.</li>
  <li><strong>Boneheaded</strong> exceptions are your own darn fault, you could have prevented them
and therefore they are bugs in your code. You should not catch them; doing so
is hiding a bug in your code. Rather, you should write your code so that the
exception cannot possibly happen in the first place, and therefore does not
need to be caught. That argument is null, that typecast is bad, that index is
out of range, you’re trying to divide by zero</li>
  <li><strong>Vexing</strong> exceptions are the result of unfortunate design decisions. Vexing
exceptions are thrown in a completely non-exceptional circumstance, and
therefore must be caught and handled all the time. The classic example of a
vexing exception is Int32.Parse, which throws if you give it a string that
cannot be parsed as an integer. Eric recommends calling the Try versions of these
functions instead.</li>
  <li><strong>Exogenous</strong> exceptions appear to be somewhat like vexing exceptions except that
they are not the result of unfortunate design choices. Rather, they are the
result of untidy external realities impinging upon your beautiful, crisp
program logic.</li>
</ul>

<p>Eric gives this pseduo-C# example:</p>

<div><div><pre><code>try {
	using ( File f = OpenFile(filename, ForReading) ) {
	use(f);
	}
} catch (FileNotFoundException) {
	// Handle filename not found
}
</code></pre></div></div>
<p>Can you eliminate the try-catch with this code?</p>
<div><div><pre><code>if (!FileExists(filaname))
    // Handle filename not found
else
    using (File f = ...
</code></pre></div></div>
<p>No, you can’t! The new code has a race condition. Eric suggests that you just
bite the bullet and always handle exceptions that indicate unexpected
exogenous conditions.</p>

<h2 id="composing-errors-codes">Composing Errors Codes</h2>
<p>Rob Pike writes in <a href="https://blog.golang.org/errors-are-values">Errors are
Values</a> about how to avoid writing
<code>if err != nil {...}</code> all the time in Go code. Instead of sprinkling if
statements, the error handling can be integrated into the type. He gives the
bufio packages’s <code>Scanner</code> as an example:</p>

<div><div><pre><code>scanner := bufio.NewScanner(input)
for scanner.Scan() {
    token := scanner.Text()
    // process token
}
if err := scanner.Err(); err != nil {
    // process the error
}
</code></pre></div></div>
<p>The check for errors is only done once. Rob also mentions that the
<code>archive/zip</code> and <code>net/http</code> packages use the same pattern. The <code>bufio</code>
package’s Writer does as well.</p>

<div><div><pre><code>b := bufio.NewWriter(fd)
b.Write(x)
b.Write(y)
b.Write(z)
// and so on
if b.Flush() != nil {
    return b.Flush()
}
</code></pre></div></div>

<p>Fabien Giesen describes a similar pattern for error handling in <a href="https://fgiesen.wordpress.com/2011/11/21/buffer-centric-io/">Buffer
Centric I/O</a>. And
the pattern is used extensively throughout the Qt framework’s core classes.
Another name for it is sticky errors or error accumulator.</p>

<h2 id="error-handling-granularity">Error Handling Granularity</h2>
<p>Per Vognsen discusses how to do <a href="https://bitwise.handmade.network/episode/bitwise/bitwise006/#5537">course-grained error handling in C using
setjmp/longjmp</a>.
The use case there were for arena allocations and deeply nested recursive
parsers. It’s very similar to how C++ does exception handling, but without the
downsides of the costly C++ memory deallocation on stack unwinding. He goes on to say
that certain classes of push-oriented API’s, that has clear command-query separation,
don’t need to do fine-grained error handling. It’s the same idea as in the
previous section.</p>

<p>Fabien Giesen describes in <a href="https://gist.github.com/anonymous/2edc9e9d52a93c126ff486cfb4a2c65b">an aside for a gist note</a>
how he views error handling. He points out that it may be beneficial to only
provide a small set of error codes and that the selection of those should be
dictated by the question “what should I do next?”. E.g. there are many ways a
network connection can fail but providing a giant taxonomy of error codes
won’t help the calling code to decide what to do. Logging should be as
specific as possible but the users of an API just need to decide what to do
next.</p>

<p>Fabien wrote <a href="https://cbloomrants.blogspot.se/2010/06/06-07-10-exceptions.html?showComment=1275971007229#c4849051810850075252">in a blog
comment</a>
 that having stack unwinding do the cleanup on errors is a bad design that
costs lots of resources and is hard to control.</p>

<blockquote>
  <p>“Cleanup stack”-based unwinding incurs a cost on every single function, which
means it’s equivalent to checking for error conditions in every single
function. That is a very bad way of implementing error handling; a method that
works much better is to just remember that an error occurred, but substitute
valid data as soon as possible.</p>

  <p>That is, separate “tactical” error handling (which just needs to make sure
your program ends up in a safe and consistent state) from “strategical” error
handling (which is usually at a pretty high level in an app and might involve
user interaction), and try to keep most intermediate layers unaware of both.</p>

  <p>I consider this good practice in general, not least because immediately
escalating error conditions not only makes for hard to understand control
flow, but also a bad user experience. Take broken P4 connections, copies of
large …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dannas.name/error-handling">https://dannas.name/error-handling</a></em></p>]]>
            </description>
            <link>https://dannas.name/error-handling</link>
            <guid isPermaLink="false">hacker-news-small-sites-23884505</guid>
            <pubDate>Sat, 18 Jul 2020 20:19:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PIFuHD: High-Resolution 3D Human Digitization]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 16 (<a href="https://news.ycombinator.com/item?id=23884480">thread link</a>) | @jonbaer
<br/>
July 18, 2020 | https://shunsukesaito.github.io/PIFuHD/ | <a href="https://web.archive.org/web/*/https://shunsukesaito.github.io/PIFuHD/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://shunsukesaito.github.io/PIFuHD/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23884480</guid>
            <pubDate>Sat, 18 Jul 2020 20:15:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generative Pretraining from Pixels [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23884374">thread link</a>) | @saeranv
<br/>
July 18, 2020 | https://proceedings.icml.cc/static/paper_files/icml/2020/6022-Paper.pdf | <a href="https://web.archive.org/web/*/https://proceedings.icml.cc/static/paper_files/icml/2020/6022-Paper.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>&lt;0c0b514cb2d4077635d4558a2f787371&gt;] &gt;&gt;
stream
xœcbd`àg`b``8	"9/‚HÆlÉuD2)‚Ém RDDÊÖ‚H™*)P"uç‚Å—‚ÙÛ�$£b(ˆÍ/"m2@d€3ãÿˆ~°]Œ£ä(I6ÉÈ¶`ÀÝ0Jy’u4
	ðYp
endstream
endobj
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      
249 0 obj
&lt;&lt; /Names 522 0 R /OpenAction 265 0 R /PageMode /UseNone /Pages 494 0 R /Type /Catalog &gt;&gt;
endobj
250 0 obj
&lt;&lt; /Type /ObjStm /Length 2671 /Filter /FlateDecode /N 97 /First 894 &gt;&gt;
stream
xœÍ›]oÛÈ†ïû+æ²½Ï÷°X`7A²
t‘ÍE�¢´EÛ¬eR&nbsp;('Î¯ïûŽEÉYÔ)ÂQa‘Õ�¦fÎÇ9ï™92Á%LÂz|D¡3/“°Îâ3¯‚0Q‰€{&amp;j‘?�È|.Z¡µ‹(8¡­Â7¢Ú~%,ŸA�1¡ò˜P¹ã�,ŒÊø_Â…ñøzÒÂ8cPÀ?Ï‡ër¸�þeÞñÂ*¶•Àj¾š¢°¶|¸^ó™,l´œMw²6³�l„Ó|Çl…3l=;á\@;¨Ý¶žƒp‘,9
WPsB”‡Ñ[4ì�AËJïQ³UFøhù'+|"‚r"(çPð"Eð ‚e'«(‚GZ•Ð¥ÄTY„äð'­DT¨Ìj-¢æÃÚTŒ7ÐVD¡àDxe‹·)êÑAÄŒµ:Š¤Ù(î&amp;Vfu¨Ø±·D
¿ˆÁ³xÛ”‰a¬È
�m�ÙXÞñ(&nbsp;¬	";Ï;Qä€Ê,¾�#_ÙdŒ¿C=`­ú�˜Z�?Zƒ’ÃkYt
Jd²Ž%bb´òš÷0CGËZL•kÁQ™}h3¦–ö Ã8hÍ´˜œnè´­1½l™¦ó‹m`‚ñÚ0Z±„6Œa`æhãÙc.±äYKf	3Ì‚[›€.Ä<b‰ïá kìphldŒ£="" óœ,m óymxöç¢fã¼—xâ{x´�ªpkp,qð‚f)ë¿üô“¸x-þ…9o°="" ß‹‹7Ý$þ-.þo‡ƒøùçòÈ="" âéÁ¿^us+o»~z¬€pÝl§¿="Z\ü:Œ«vD•ªü‡º^•ýtñ›¸x'.Þ·W[µ^&amp;ÍU¤â2ÊR»2û¥Â�‘cw9=nZqñ÷®¿Jù—¾¦ïŒæ�ä¼�" �šs="HØ˜�©ÐŸÀºþªí'�¥öÓ46WS×ßÔt�²2eÄÜ‘®˜ªóA" ^:uìc˜km="" áºma—¯†þaxï¦nè›u`Œ&cÒdbk7ÂžÔîø´q2`Ñ�‘°ƒ5„÷Ãmsß®h¹jÛmÍèº(i®g8x<é`gÏ.�="" |2‹nd="" £ƒ��û]2´ÍvÛŽ#Ç7lf¬”n³nw5³�2h±¨Œ-õ‹¶’nî±h%}ø�Ñ™8äËÛñ¶�yÖj5´Û4›%uÌ-uŸz1sg4(mi(—£õm7’ldÝuw5¨�ÒÒs1p½š|\·jÃü-z§ÄËirêbpigmoß¡!="" œ^Ôy7ëa&òíz`l§¦_u:6«d‘Œ{È¹Ï="" 2ir@Æk�5œ�="" †ý="" ŸÌÄn¸¾†mÑþ²™®nkºcÃ­È="">ªÞ3`ÛË&gt;�O�`²ÏQéCÉxÔd—
°ÂºylÇšÁÌ2ê#bÉ€ï‡sQ3E„M0˜åˆ@¤ìjh¦v8Ý@==n»[ŒØ«¾XŒ„d„Dö™²jQxqZ¸q¤K¨©†îv×ô7€swíØ·5ÊÓe8ƒ´'óNKcªúítdÃË
õ3�±IŒÌ<lqhËtgó²xof „¯="’EÄ91žtô4§à°²©A»»Ï·íÃöŽ„¦»onÚ¾­" ¸<tÊi«eŠ™{\Å©ò3™eºääŒŽŸÒ^kæ²ßb`öÈ¬d="" ËÿØ<‹â¦ác3®ª="" Š÷èª|ÀsøŒyŸž3Äáˆç\Ñvx›¦ëé÷Ý="" Ì±ó="" h¹ïÊî“wë×sÿyfÿÃñˆ¡àbx&Êœt="" Þ}w7¬‡�Úu·�Æîr7u‰wº[õî="" 4wik„ƒàÐy0fh'ã�ŒÜl„Æ«`\5µç¶½ïjØÉíbnit8@ç-äñ"#}0k­="" <½€eÆ0p¿y*…q¦.p‹ôÀ¦�ä€-unôØ °hÃ�Íid·)ž›ƒjçøÍh6ÀÙ†´Ûbƒ‰¶ë»pvm="" :oæíÐ“×v�ëi½†l1Ç‰çãì*À±y]o„Ýýfê‚ìy�"ê—<k£¤="" ®ÍpÏgÑš="5!ÌZÙ�0EhSC¸jÖwÊÒe;VÉ)D" .lfã¸ÆdÏ‚�â$†ãÈºÀÕ««Ø,ˆ«[zä]¿ÝmÚñ¡ÛÖí!«ŸÅsÚ'Ó2»="" miæÓ3ztx9¹tÜ³Ð<ß”–ç¡ÚËùÛa¿="">Æv3¶Û¶ŸµTYê°ß}R¨®œaðŒÜòÄê,äŠGÄ$3	–#Þ÷íg†—cKKÝ]®ÛÚÍf.$ÚfØh¯.ÇBXÓaÑ0Ÿ�Y¥p´˜—¡
Ê´Ýö¨”§”Ý¶«&lt;3µ	Þó87�Ã¬°Jx„
Xµ,P?=¤S<vsghpžÇøË)oÛ¾¹¾&áª™šÚdxïÌ4ˆÀÃirÂ.³Ú§#Ðñl šÙ’“)u²‘ëë¤Ÿv÷uŽ="" «×Ú§í="">æ\9®e2ðT\³¾2FÃ±¹²ÛKN-óÂ=µn;rï;oÛõuÕJÕåDeF£HeRÔ&nbsp;G–\¸
›)£û
h¯ÐúkX‹«öýÛ_Yû4îÚÂôalúí¦ÛþêqþêÛqØm^H+i¶›ž�hl¦	3¢ÎÚ™Ó»ÍèŠ›‡G�&gt;Ì[Ðí'tÜ…c¢Ø0ò&nbsp;¿
pÝŒÃÕm»^sYé¾Ý�uqBž�k
SiŽªQóXsÑ™Í‰-ã€Ìä¼(K²´ã?
î–mÑìõXØtŸêvÒFÓÈœ6XYùÈ(¸˜z@³øLßFöfè§÷FkŠ`ñ”Èm1WÒtË
Úyº°Ën¾ÀlqáYCØ_$æ·îËðy¾@´T¹àÿŽyôGË×¹øýõ0¶Ÿ˜Ž¸Çûs¢âo":_DÜW	Ðö&lt;¢üÊ#ÜÆ·åÜþ;§%ÍI…û´¤ˆ¨-‡š¬¤Sf^ÌGßû¤†•Î,§aFÜ'„{ejòNB4OÎ'D†'n¶æŒãD›¸óNÕ¼‰‹°&lt;×mâ~‡½‚=äa¯½§™m¿|¯àÔ®iOxpM6=å²,w§Ë;ÃJMLìJè´+ƒÎ3±äŸA‹üH4ãTÙ§:&nbsp;#ÈåhÇmÒ¼nú›Vn�a‰åÜ*Ò�ë’Ù/ƒ·"òÄ2,’D§åcœ‡x&lt;òPó›Ÿyw¨ÒÙj…uðôÏÝ¾Á_^ßRÉþ/	&nbsp;ËáÙìÐ-«›Ý&gt;Í2‹*á¹æ/äîÏU}³4¸xG“ýŠïÿÏ\þ‡�Å|w�`gþæ3·?·ÿ¢txþ@àÖ‹u/?ð$KõËàÅ$0ôâÚcþ§…Ç‰�4zO±j¬Lž	ªJ*S~1"“ª\…'!ä�óífBã™ÜSø¹¹ÆÝãÝ@‰ý±[Umqf
ƒêKZ4#—ùCþÒ‡é"ývJ&lt;ãªÊO�žðŠ	æÛðžÙˆ—íÂóÕÿâ²®Rùúÿ¯Ô/V¢Ò˜7^h_¬4Ãäkû•'&lt;¯·ék­$ÄÇå OüÁ®7m
endstream
endobj
251 0 obj
&lt;&lt; /Filter /FlateDecode /S 185 /Length 208 &gt;&gt;
stream
xœc```b`yËÀÂÀ ÌÁ Â`6+�É²ƒIA��!@ºÃn—&gt;ƒ©Â.GŽ£ï2®`~	RÏÀËÀøä�à®YgŽ¥ÆNPŒ«X¨Ë&gt;OÃkÚ%‘�N!»LÚ[RZÎz/ö¨póð¹çÆ¸¬ÌS
Ù&amp;¨Í1U·Eó¡¤¢qÐ‹CRB@%-²uäy/i^ I2mcàg`p]rÎrŽãŒS;Ï|_Åhkg8óè”×Î3žkz&nbsp;YmT”uæ³æÒ#&amp;€ÊOQN.
endstream
endobj
252 0 obj
&lt;&lt; /Annots [ 266 0 R 267 0 R 268 0 R 269 0 R 270 0 R 271 0 R 272 0 R 335 0 R 273 0 R 274 0 R 275 0 R 276 0 R 277 0 R 278 0 R 336 0 R 279 0 R 280 0 R 337 0 R 281 0 R 282 0 R 283 0 R 284 0 R 285 0 R 286 0 R 287 0 R 288 0 R 289 0 R 290 0 R 291 0 R 292 0 R 338 0 R 293 0 R 294 0 R 295 0 R 296 0 R 297 0 R 298 0 R 299 0 R 300 0 R 339 0 R 301 0 R 302 0 R 303 0 R 304 0 R 305 0 R 306 0 R 307 0 R 308 0 R 309 0 R 310 0 R 340 0 R 311 0 R 312 0 R 313 0 R 314 0 R 315 0 R 316 0 R 317 0 R 318 0 R 319 0 R 320 0 R 321 0 R 322 0 R 323 0 R 325 0 R 326 0 R 327 0 R 341 0 R 328 0 R 329 0 R 330 0 R ] /Contents 253 0 R /MediaBox [ 0 0 612 792 ] /Parent 468 0 R /Resources 331 0 R /Type /Page &gt;&gt;
endobj
253 0 obj
&lt;&lt; /Filter /FlateDecode /Length 5076 &gt;&gt;
stream
xœ½[msÜ6’þî_1_ÖÇ©²xðe÷jëd;qœµ­­än+Ù	i¸æ�³|±£üúíF78$g&amp;+�rW¥A�Ð@£ûé§1~¼òí_{ÇøûðæY°º[«Ó×&gt;p
Vb¥µ¯Ô*©¯¢U¾}öÓßƒUO¾]~šF«/ö½íJ%\«ÕÇg=híåõ³ÿü:+¡|©¢pu}»©ðƒ(^Ex�ãÕu±úÉ{cjÓf}¹�÷ÿ™õE¨ïª]‹Ä3}›•uYßQå­­l¶üJù‹©ºõß¯¿}öÕõÁð£XøIøÔá§~…Ž&gt;	|­å*RÂ—šÆþ&gt;k?ÑP^mL��oà?�e‚ßhá‹T­¤	þDð[Ó–Eà‹0]]L^»¬LN-ÈŠÛu¨½¦-Žu�øQ?¨ƒdÖÁó'»©ÝøËêhû1ž!À·k¡=s{KÍÿÏþ
GÚ—Ú@Çßþ7†h¨Ûßpt
¤ÃW�ïâu†óþ¹,¨‡wCv´ùtYœÑüÛê&gt;£–?}÷‰T„&nbsp;MÐé*
}.Æ¨³´ß„Ÿjm÷Û…Œ„¯
…ÄÁªuÓÁ¦ÊûÙ§“&amp;ätØ~ $ïªXû2Š@ãÐ¹ºÞ¢u·+[ƒ3¤ïæž®»¶¹kM×Ñ]YÓu¨»agÚÏeçÞoÍ^3uŸ]à`°·pÑYù2M¨³¾Dm•"õ*“µd$˜ƒÛ¦¥ê:ë‡6«ø�¬¾²;óneì}1ô2L±ò~É¶emŽôñJG
ÌGH}~Ù˜~c°ý(òºr[V™½‰½mS&nbsp;ñ±ò¬¦‚‡ÎÜ½k%ÁÁ~�	*¤&nbsp;Òvh§%ÅÙÓŠ„ÃB¹a:¥ˆ`?%‚¥ò¬…¤bF—Îüs0uÎÏ¯×R{mVwû,úW`Ù$ýmQÞæªÇ½S™
}sÑÂÌEž]×Òî¼5Õ=½ò%è”ýnWþbwÕÁä‡aä})ûµð6ÍÐŸZç0ñuÌSPÖyÓît
n‰?Õ
öù¥2Å/dsKWX*„¯éZÖ;èŠ±Š&gt;ä'Å‘…,6(ŽÁ¹
¤÷Ú€N÷8y ÃÄý€¸ÖZBm£©`Nº¦H/ñù[\£ï`¢¼QPØ}sí
”E,)Ì‹�Ø
¨°7<cpƒêŠ×Ÿƒ ¬*÷›Œ_Íèòæêz�="" ï"¤Û.Ï*þÌ*§‚˜Ë­Ò="" ¢ x…íøû¾m¬¤p¶Ú¶Ü¥n-q|Ýš¬Ð�8qÕ¢3ðš±Ž¨3²="" )l="">ÜFl+n`~_LÄ5ýPïë2'E:pQd}FçUÖ�2*Jü$`1»[Î­¸ÌQè}�k)ïÕÛ¯×qè]~¸öñäGÚËòMiX×µÇ•)X¤?Ð§Y~²sù‰b±s0J9¶p�
¦íªS)£‹›,ã|X›‚oz0˜¸#i#Ê}Ñ
£V§Ñ¢k¥ü$e¹'öV‡`5Tà•…µ@÷�é_Ð
M2¼“¦~ð®Ë§#Ç‡vän¥—j%C?•,2X¾êÄŠ‚¿Ûf=Ì¬Ãtv[ýnvT3÷Ö¸œœèÐnlÚÃ¸Wñ;ók�ÑòÛYë
U×`	Ô¨ÙîL_öåt­ñÁTÞeÇLT¨�Ñ®n/f£†�oÀo¶€q«@ÖH@=‰žî¾0p<b d´àðÚe?�ii:1²Ðp�£ÀÝÿø××b&Þåwt£i ^�{Ý="">ee¢}!´³Éw´å"Öãz]ª]¨Šbiñ	]ö[&gt;&amp;§j4âö:´4Ï‹!ÄÒN¥zwô€]M‘„*)@–pe‚Ž|R§·uOaC1äÖV;dµÇ9(½Ÿ¢)&nbsp;k©¨ïæÐöªä44�š*»wO3ºä`4-Á›¶©xã‘·Yññ‘º†
&nbsp;å&lt;–Âˆ8¥±Ü‘g—`³¬„kaÌŽJ�äQ¢¼�}Ö²…‡Ø/^ÉcBa[Týþc�È´C¡™Ù�J˜¤~2úƒ…52¨€)îÚ|C¥ŒkH@(¼¶ÄÒKS•æ–Ê°ÂÛ 
*~tÀ¨4ðX_ib§·Ç"ú/ëÞj|ewöZù3H¯½xHk‡2Æ±FlT`j¢e³0N�¨2$³‰…×¦nÊŽ¦n/1Á:hà„jÂkéÑÃ…üq­ÍÀ—5*}møz®°?Ù¯A¨ä¨P‡k@
nÏ‡ýÀ˜Å&nbsp;
c‰fsÛÔÂÝÀ†�õ®µ!4Nåq­;ª!`KÍ`3|÷¹&lt;¥yÇI�8nW?J1�ïŒ¡O¬ÂÀõü9Ä¯aÓãŠaÛ¶þ
Ý×ÞØ­!˜Ê›»ºìÏÿûf“m÷Hk1;Jø*à%²Jœ¿#@@ð#§ÛØÊ{Ë�Øe¥Ÿ‚Ï«Ð«(ö¢½ÂÀ•|V&lt;¥Ï7%™
Žê&amp;P2�K¦pq®ž0Cì9,¥ðkyƒftØ[y1Â¹Ap‹ ¯ž7yE$“÷c?F§`�‰[§E“ÒObåÞùßÃ&amp;À[ÊhÒ†8â|¦²
ØjèvfC£�3TIJÀKnbÐ†±·´[|*8ÌS[IÄ&gt;DûÈW/‰xKB�¦
;l0Ù»û‰„{ZHÁð*À%�ž÷ºã:ïÿø¼Çé&amp;^»wþÆ/¨Y#i:®Þ?Ž´QP?qé&amp;¨I#Z[h¦µ=Â8e]gZkY²ò!àÖ'là &lt;êºþôÐÏ…÷U»AZã÷�NÜþßPPmöäB»VÂ³x UñgàOhµH¥¯Öª-¨¬µIzÄ%š­TÐÙä¶›/&nbsp;ÉôhÄ§ð8Ë]$†,cS
ïÜuîB`¸}øâ~—•í1×
ØU$Â�BV—çè•7gN44pj¢q*Ø¬[nÌ4*�¼¶‚-lI0å¯c¤õóMÕ´MO_±(/M=®–ˆæË‘DórÝ•Í¹ò*ý›òªÈÚ«!’Å£*¤B{K»Þ•ÖªÇ,ì[0w&nbsp;#·k"ã&nbsp;¯çÔÄÇ_©MSÜŸ‹IG&amp;…§KƒU±¥BŸ»³Á3¼dþÈnkõ$ ¤'ˆ™Ø£­Ó5ÄdqüWÇ“ïá`Y�||Ã+
&amp;œ™Ž¦-Bj¢-ãhFß(»@±Þ“\PÆ¸«ê-§
ûù{"zñKä»²Öš
x-ÏºžJE3ÜÌyó#y'!Á»…É2ñ„4¶K&lt;ÁZî3O”i’+í§ql½JñG€
¾ŽÄ&lt;© W	xŸH±÷IGz_Œ‰ÃÈ�5ïªïw¦¾|û‚¢Í�‡�_·`DË.o˜úyuÉoüðñÒ§Ò«\Q·kêÂÑÈ56DRURÒk¬³ØzæuŸ
ºoˆa¬ó¨ÿuD&nbsp;¢ýñ¤Nþ»²Ò‡áH{QpÂ½þç×žï0€ž¼1W*…«4ò“ˆY�+ð@ÊkrÐRÐÆŽB/uK
£m‹ZLt@.Œ¡$³ædÌBÄ“Å°p"E&lt; Ð”8§ß©P„Ã7Ó¶ßÖBÕÖ²ÙˆÄU¬oA£eä1e€ƒ¯éúžÈšÍ$
Lì³HÒUùiÀšôÎ%\çxúeE³/_Ð†X6õJS×W\×ÝÝÕûwhû°¥"eêPC`Yù„Ù!
¾oË»
›-|ºv‰§C…Œa2�Æ:ÀTÆ¦iÑÂw=Ž%ÁN$Ã¦©Ä6Ç€ÒGÌQ.UºÎÔˆÉ-�{p¬O5Cd"íZzç8ö¿CÚ6�6�V‡L&gt;æŒêñéž	”s1uª@=9Ù5mO-ª½5…2[S¼ÑÞÐ•®Þ%¥&nbsp;¢â‰Aª¬¥-ˆUüQÒ‹¹¾ƒŒŽQ6à<!--?qIÈ‡ûëW
8{^ëü�«;ßùÁ×àüÄ)è‚Pò:ÛƒZNÕ�.èƒÜ‹kïÁ‚
™cŸ*ÍÄº¸5�’¤#&Ô¹€C°66� x˜O
$àkM|"��¡ð®iÿA/;b(éîÖØœ”(å†…[~´Fj"Ä(˜viùóî€Šps£Áþ)9ã"Ø`»²~FmÇûÇYÛSMYç­Éì~¸w ©*
G÷Ž8/ÊÖä}Åtºcï—HÈ
HE–ÁfZ¶´qP›�EÝ¢[,°ä8`¨rTŒËaaèK@ÉDfb=‘*u‘Y›FT$‹‘à‰éâYÇq5)!´…ŒéžÍH�ç¾1þÒ–¿nhÏáÁ
LJ,³en¸¡¤£HŽ7C¨ódíÏÞ+¡÷¦eMD¼ÜÑ€ž“B~›•8Yç-<º�ÝÆ˜sÞíL-->Ï„á—]?÷ã¦9¡„ð�K¨/½Ox$eR@lPSÆï0SˆªÊk‘3ïÅ	±XÏü=÷¯À	
—Zßv»�ËçjÆH6àü±�-—;Ó÷ñðîášv…ÃÁ´#}h¸Ï§hPðËt|âU"üÐåªÞÂŒš¬ÀD¸›É2€qÂý�,WB&amp;³´²Ú²Û~Ç&amp;‹àIF·Ei¡!ž&lt;–§r�˜&gt;tAç,0jÚB_&nbsp;c:–Þå­¥ú¥$Æ¡$°º�Ë°&lt;"	|‹N÷@-ç
º#=Èû¦íŽ
A‚‚0K†ê± á}iÏb5Ç­Ö^ZJýIŽKÒþ“'Ð¦›KîdƒD¾¿xA&nbsp;’-¶€™²&gt;ŸÛPdÿ,´&gt;f‘ÍuK£0¥šŽ‡|ˆ¶oBaîÑwîV¾ãTtwÕBÔía¡]
»ÈFÇPê³îƒÊ‡Ïöë¬&lt;¶~È�))}%ÔÈ�áážwæÜééShìûÊ€êv|Œ¬§SfOÐ&lt;²ˆƒ&lt;Ü#„Œ©òö+‰uÏi\†‚Žþ�li“!æW.k‡GYíÞ“OO™A&amp;ŸÎ�A´´¯	$Teý=¨ÑÍª›®'iïÅž;aWƒÔ×.»7ñ¡`O››Lü5Ó\dðqF0Áemá›­Üãb¸«ÊOîØ5Ü½üê†ê×k(¿&nbsp;*7.4*ø„GT´q§=HÜ*['{¢iÛa7úx{&gt;¯cò)¯šŽÂ„|Û›ÊB¸–ÂÙHI´¯Sž¡I2&gt;”�KÆ£·w	�‰G9MaJô0åÌUe÷Å$v«š�•B
ë–Ž`&lt;±IžwdóÈ�1­.µöã€ù›K{ŒGÓé�ÈÛ”wÄFBUQnMÝYbÇ&amp;C�Èñ&amp;éÍQ|€9J"¡-fÇ[@;Yµ'ãÃVÒ�ÝQŸž£’žò?ÃX6û—žÙ’ËE5œ‰åÔï4«`Ï1Cãòµ¥eÌ‘&lt;’ƒ›_Oéß�·˜6;8“äÆ)…§Ú�ÆŒÐˆRÁjÙ`†Ž¿àa¹o`›ñ	ÔÃZðºÛV¸/LWÞÕîißŒ1ŽZŒB¤~"G˜µOKŽ™i7–y4ÈËƒ‚VÍ�KÕNÂ4|éÞ³�”oNÍ\’DM‚Ì&nbsp;�oÚÂø¨e²ÚÞLBž÷
eõP‘àsœ_&gt;ŠYóx`	¶°$vÉbï’*óf{S›9jìBeÃTûiÈ‹à¦·¦´ÞÚæb¦Y„xa(9¶zÔdÏ¾+b7?ÉMD'ÝÄ‹¹ª`:Âr!ì‚œé§1¯2f-ÊÞägñIoš­ùuÊ'=-–'‰šù¡SéÇS2'aýÃÞ,µÜh+À.ËÉnéÇœ°ú’ã
8œš1?#þ�ÿS©*‹øO�r@Ÿ¦™7ÓXDßqè½5ý¦)º“û ‚~çÛóÁ�Ã“Ë*v�ƒÝsr*Þ“Sóh”¯dP1Ø´•ûc7càìVi„�yó…£ŽAmÎ�«Hð$¬mË�ÉŸÃHt*ŽˆxÞ©©3Š]§ëú;höÉu
÷§©;ØQ=¸ïnd0ôÈ`²�xóè¢ö!6Ê6u&gt;"+/0uF~Ec÷vmaÝÝf6÷¿ŸÁ»)÷!³FL³&gt;u§,:T çžx&gt;˜çGàû÷e×ò�¬žÓå3.AÆ¬¥Œñ½¶ÆÙG.ˆ²9qXî8¢¨æ‡.w÷¦œ2[Ð^2bß„‰°ÄÙ
„Rî¥Œ.…É3:ÔŸ`–%7®	.8DKw_ö\·£÷Çé!„X`‘*_Šñè1ýTsÄø/™=5Ú,ûxñ¦õ4í¤ÁÕ¶……päö‘ô“HBÀòH·—Üž=�œ{M&lt;õ±ËrÇ!:VãÝÕZŠgðS›²sÑGÖñx\°294ÆïÃ©¸CÄ&nbsp;#©‚À‘^péE(·xBä‚P4þöÌ�@n"&nbsp;€ç`³¶ìÜú™ž}¢•Äff@`9�ÀE�G³ÇŸàI6÷ò
V£Ä68
÷¿,S6#hbãž©vòß€t¡"_¥G1:¨ùBYBILR8Q�ÐÍJ8ãˆé	ïôE»BÉÙÆ£‘Ê×Že[€t'-FyS¹Ìð9¹·~RÕ+ë(�¬ËõïKŸÆPÂIdÑ™í…©Çc´b‘²aèë‘£µž‘Î�Ò!O¥-!�zt®sÓ4ŒyoŸ©Ù�âàÁ°¦êÇœ}lÂ*úñšKí†®CÇ³ŽÐ}?´mvv2DÅGS·&gt;D�Ñ@ü»DñÉcTsó!¶Ã
ªøý)ž&amp;~ä˜_üÅâÐæfÂÓŠ TdŠ¯¯~&nbsp;êB�n’Æ^~í~zzhøËÎµ°=•$H"?v¬îìgW–¼Â³îrà—øÇ·Azh»ðù4‚·÷5?àß5Nçsrdë_äøÛE
endstream
endobj
254 0 obj
&lt;&lt; /Filter /FlateDecode /Length1 1400 /Length2 6224 /Length3 0 /Length 7179 &gt;&gt;
stream
xœ�t4Ûoû·ÕR´Z{‹¢("±Wm1ŠÖV‘1"vµµjï½•ÆˆU³Ôª­jE©ÑZ¥´j¶Æ?ÏóüÏûžó¾'ç|s_ûºîëó¹ù¸ï‰¨ÀÑv…Ar5==m)$�Ä(ùøŒ‘XÄ_5%Ÿ)ã�D£äþ—ƒÅtêP,ÁO�èxºÀâ°”XZˆ�@²ÿrDcäêP/$&nbsp;è&nbsp;QJ&gt;5´›/éàˆ%”ù× €ee¥…‡T\$ŠèA±ŽWBEÔ`„†!Xß¤PpÄbÝäDE½½½�PW ã&nbsp;((ðFb†Æü&nbsp;uEü™HÉ0vDzüÑ¡í±ÞP@P¸ a”!ÂG`„â#m]À7ê�³îaÀß»€�à§ûý+õ;
ƒ¡]Ý&nbsp;(_$Ê`�tAî@t�X¬0Š‚ÿr„ºx&nbsp;	ñP/(ÒjGpøÝ9Q1@	þÏ†Aºa=€H—_#ŠþJC¸e
\
íêŠ@a=(õ§ŽÄ `„k÷ý³YgÚåÿW°G¢àö¿†€{º‰š&nbsp;�îžmõ¿.åt…</b d´àðúe?�ii:1²ðp�£àýÿø××b&þåwt£i></cpƒêš×ÿƒ></vsghpžçøë)oû¾¹¾&áª™šúdxïì4ˆàãirâ.³ú§#ðñl></lqhëtgó²xof></b‰ïá></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://proceedings.icml.cc/static/paper_files/icml/2020/6022-Paper.pdf">https://proceedings.icml.cc/static/paper_files/icml/2020/6022-Paper.pdf</a></em></p>]]>
            </description>
            <link>https://proceedings.icml.cc/static/paper_files/icml/2020/6022-Paper.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23884374</guid>
            <pubDate>Sat, 18 Jul 2020 20:02:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Team Lead Anti-Patterns]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23884166">thread link</a>) | @cbowal
<br/>
July 18, 2020 | http://www.dcaulfield.com/team-lead-anti-patterns/ | <a href="https://web.archive.org/web/*/http://www.dcaulfield.com/team-lead-anti-patterns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://www.dcaulfield.com/team-lead-anti-patterns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23884166</guid>
            <pubDate>Sat, 18 Jul 2020 19:37:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compressed Sensing (2016)]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 9 (<a href="https://news.ycombinator.com/item?id=23884141">thread link</a>) | @chaosmachine
<br/>
July 18, 2020 | http://www.pyrunner.com/weblog/2016/05/26/compressed-sensing-python/ | <a href="https://web.archive.org/web/*/http://www.pyrunner.com/weblog/2016/05/26/compressed-sensing-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      
<p>In this post I’ll be investigating <em>compressed sensing</em> (also known as compressive sensing, compressive sampling, and sparse sampling) in Python. Since the idea of compressed sensing can be applied in wide array of subjects, I’ll be focusing mainly on how to apply it in one and two dimensions to things like sounds and images. Specifically, I will show how to take a highly incomplete data set of signal samples and reconstruct the underlying sound or image. It is a very powerful technique.</p>
<h2><mathjax>$L^1$</mathjax> vs. <mathjax>$L^2$</mathjax> Fitting</h2>
<hr>
<p>As you might know, there are many different types of norms. Perhaps the most common and widely recognized one is the <mathjax>$L^2$</mathjax> norm:</p>
<p><mathjax>$$\lVert\vec x\rVert_2=\left(\sum_{i=0}^n x_i^2 \right)^{1/2}$$</mathjax></p>
<p>The <mathjax>$L^2$</mathjax> norm is nice because it is easily calculated, easily differentiated, and it has intuitive appeal (e.g., the norm of a vector is its length). A lot of very important algorithms and methods rely on the <mathjax>$L^2$</mathjax>, including least squares fitting.</p>
<p>That said, the <mathjax>$L^2$</mathjax> norm isn’t the goto solution for everything. The other norms also have many interesting and useful properties. Consider the <mathjax>$L^1$</mathjax> norm:</p>
<p><mathjax>$$\lVert \vec x\rVert_1=\sum_{i=0}^n \lvert x_i\rvert $$</mathjax></p>
<p>Instead of squaring each element, it simply takes its absolute value. Although the absolute value is annoying in the sense that it often introduces discontinuities in its derivatives, it does have some unique properties when compared to the squaring that takes place in the <mathjax>$L^2$</mathjax> norm. Compressed sensing is all about exploiting these properties.</p>
<p>Let’s visualize some data with Python to see what I’m talking about.</p>
<div><pre><span></span><span># make sure you've got the following packages installed</span>
<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>import</span> <span>matplotlib</span> <span>as</span> <span>mpl</span>
<span>import</span> <span>matplotlib.pyplot</span> <span>as</span> <span>plt</span>
<span>import</span> <span>scipy.optimize</span> <span>as</span> <span>spopt</span>
<span>import</span> <span>scipy.fftpack</span> <span>as</span> <span>spfft</span>
<span>import</span> <span>scipy.ndimage</span> <span>as</span> <span>spimg</span>
<span>import</span> <span>cvxpy</span> <span>as</span> <span>cvx</span>
</pre></div>


<p>First what we’re going to do is create some arbitrary linear data including some noise. Let’s use the made-up equation:</p>
<p><mathjax>$$y=\frac{1}{5}x+3+\epsilon$$</mathjax></p>
<p>where <mathjax>$\epsilon$</mathjax> is some normally distributed error with standard deviation <mathjax>$\sigma=0.1$</mathjax>.</p>
<div><pre><span></span><span># generate some data with noise</span>
<span>x</span> <span>=</span> <span>np</span><span>.</span><span>sort</span><span>(</span><span>np</span><span>.</span><span>random</span><span>.</span><span>uniform</span><span>(</span><span>0</span><span>,</span> <span>10</span><span>,</span> <span>15</span><span>))</span>
<span>y</span> <span>=</span> <span>3</span> <span>+</span> <span>0.2</span> <span>*</span> <span>x</span> <span>+</span> <span>0.1</span> <span>*</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>randn</span><span>(</span><span>len</span><span>(</span><span>x</span><span>))</span>
</pre></div>


<p>Now let’s fit two lines to the data samples. For the first line, we’ll use the <mathjax>$L^1$</mathjax> norm as the criterion for a good fit; for the second line, we’ll use the <mathjax>$L^2$</mathjax> norm.</p>
<div><pre><span></span><span># find L1 line fit</span>
<span>l1_fit</span> <span>=</span> <span>lambda</span> <span>x0</span><span>,</span> <span>x</span><span>,</span> <span>y</span><span>:</span> <span>np</span><span>.</span><span>sum</span><span>(</span><span>np</span><span>.</span><span>abs</span><span>(</span><span>x0</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>x</span> <span>+</span> <span>x0</span><span>[</span><span>1</span><span>]</span> <span>-</span> <span>y</span><span>))</span>
<span>xopt1</span> <span>=</span> <span>spopt</span><span>.</span><span>fmin</span><span>(</span><span>func</span><span>=</span><span>l1_fit</span><span>,</span> <span>x0</span><span>=</span><span>[</span><span>1</span><span>,</span> <span>1</span><span>],</span> <span>args</span><span>=</span><span>(</span><span>x</span><span>,</span> <span>y</span><span>))</span>

<span># find L2 line fit</span>
<span>l2_fit</span> <span>=</span> <span>lambda</span> <span>x0</span><span>,</span> <span>x</span><span>,</span> <span>y</span><span>:</span> <span>np</span><span>.</span><span>sum</span><span>(</span><span>np</span><span>.</span><span>power</span><span>(</span><span>x0</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>x</span> <span>+</span> <span>x0</span><span>[</span><span>1</span><span>]</span> <span>-</span> <span>y</span><span>,</span> <span>2</span><span>))</span>
<span>xopt2</span> <span>=</span> <span>spopt</span><span>.</span><span>fmin</span><span>(</span><span>func</span><span>=</span><span>l2_fit</span><span>,</span> <span>x0</span><span>=</span><span>[</span><span>1</span><span>,</span> <span>1</span><span>],</span> <span>args</span><span>=</span><span>(</span><span>x</span><span>,</span> <span>y</span><span>))</span>
</pre></div>


<p><img src="http://www.pyrunner.com/media/uploads/images/compressed-sensing-python/output_5_2.png"></p>
<p>Notice that both of the fits seem to do a pretty good job fitting the data. Sure, they don’t line up exactly, but they both are reasonable approximations given the noise. </p>
<p>Now, let’s get a tad crazy and add some outliers. In other words, let’s perturb a couple of the points, moving them far away from the lines. This isn’t actually all that out of the ordinary if you think about it. Outliers frequently occur in real world data, causing all kinds of headaches.</p>
<div><pre><span></span><span># adjust data by adding outlyers</span>
<span>y2</span> <span>=</span> <span>y</span><span>.</span><span>copy</span><span>()</span>
<span>y2</span><span>[</span><span>3</span><span>]</span> <span>+=</span> <span>4</span>
<span>y2</span><span>[</span><span>13</span><span>]</span> <span>-=</span> <span>3</span>

<span># refit the lines</span>
<span>xopt12</span> <span>=</span> <span>spopt</span><span>.</span><span>fmin</span><span>(</span><span>func</span><span>=</span><span>l1_fit</span><span>,</span> <span>x0</span><span>=</span><span>[</span><span>1</span><span>,</span> <span>1</span><span>],</span> <span>args</span><span>=</span><span>(</span><span>x</span><span>,</span> <span>y2</span><span>))</span>
<span>xopt22</span> <span>=</span> <span>spopt</span><span>.</span><span>fmin</span><span>(</span><span>func</span><span>=</span><span>l2_fit</span><span>,</span> <span>x0</span><span>=</span><span>[</span><span>1</span><span>,</span> <span>1</span><span>],</span> <span>args</span><span>=</span><span>(</span><span>x</span><span>,</span> <span>y2</span><span>))</span>
</pre></div>


<p><img src="http://www.pyrunner.com/media/uploads/images/compressed-sensing-python/output_7_2.png"></p>
<p>When we re-plot the <mathjax>$L^1$</mathjax> and <mathjax>$L^2$</mathjax> fits we see something interesting: the <mathjax>$L^1$</mathjax> fit remained true to the overall trend in the data, while the <mathjax>$L^2$</mathjax> fit seemed to get “corrupted” by the outliers. Why does this happen? It comes down to the fact that <mathjax>$L^2$</mathjax> error gets squared, while <mathjax>$L^1$</mathjax> error does not. When you fit a line to data using an <mathjax>$L^2$</mathjax> interpretation of error, the displacement of outliers has a disproportional impact because their already-big errors are get getting squared. Just look at the distance of the two outliers in our example and imagine squaring them – of course it’s not surprising that the <mathjax>$L^2$</mathjax> line gets skewed!</p>
<p>However, when using an <mathjax>$L^1$</mathjax> interpretation of error, the outliers contribute no more than their displacement. The result is a cleaner fit that more closely matches our intuition of what a good fit should look like. It’s this interesting property that opens the door to compressed sensing.</p>
<h2>Reconstruction of a Simple Signal</h2>
<hr>
<p>In this example (borrowed from Kutz<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>), we will create an artificial sound wave, sample 10% of it, and reconstruct the original signal from the sample of 10%. This is one dimensional compressed sensing.</p>
<p>First, create a signal of two sinusoids.</p>
<div><pre><span></span><span># sum of two sinusoids</span>
<span>n</span> <span>=</span> <span>5000</span>
<span>t</span> <span>=</span> <span>np</span><span>.</span><span>linspace</span><span>(</span><span>0</span><span>,</span> <span>1</span><span>/</span><span>8</span><span>,</span> <span>n</span><span>)</span>
<span>y</span> <span>=</span> <span>np</span><span>.</span><span>sin</span><span>(</span><span>1394</span> <span>*</span> <span>np</span><span>.</span><span>pi</span> <span>*</span> <span>t</span><span>)</span> <span>+</span> <span>np</span><span>.</span><span>sin</span><span>(</span><span>3266</span> <span>*</span> <span>np</span><span>.</span><span>pi</span> <span>*</span> <span>t</span><span>)</span>
<span>yt</span> <span>=</span> <span>spfft</span><span>.</span><span>dct</span><span>(</span><span>y</span><span>,</span> <span>norm</span><span>=</span><span>'ortho'</span><span>)</span>
</pre></div>


<p><img src="http://www.pyrunner.com/media/uploads/images/compressed-sensing-python/output_10_1.png"></p>
<p>In the plots above, we see that the signal has a clear pattern, yet is non-trivial. The plots in the top row are of the signal in the temporal domain at different scales. The plots in the bottom row are of the signal in the spectral domain (i.e., the signal’s frequency content). Considering the frequency domain in particular, we note that the spectrum is mostly zero except for the two spikes representing the two sine frequencies.</p>
<p>Now imagine sampling 10% of the temporal signal (see below). You’d have a data set that, to the naked eye, would look like nonsense. The underlying signal is would still be the same, as would be its frequency content (mostly zeros, with the exception of two spikes). One might ask if it is somehow possible to extract those two dominant frequencies from the incomplete data so that we might reconstruct the signal? The answer is yes!</p>
<div><pre><span></span><span># extract small sample of signal</span>
<span>m</span> <span>=</span> <span>500</span> <span># 10% sample</span>
<span>ri</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>choice</span><span>(</span><span>n</span><span>,</span> <span>m</span><span>,</span> <span>replace</span><span>=</span><span>False</span><span>)</span> <span># random sample of indices</span>
<span>ri</span><span>.</span><span>sort</span><span>()</span> <span># sorting not strictly necessary, but convenient for plotting</span>
<span>t2</span> <span>=</span> <span>t</span><span>[</span><span>ri</span><span>]</span>
<span>y2</span> <span>=</span> <span>y</span><span>[</span><span>ri</span><span>]</span>
</pre></div>


<p><img src="http://www.pyrunner.com/media/uploads/images/compressed-sensing-python/output_12_1.png"></p>
<p>Compressed sensing in this context is made possible by the fact that the signal’s frequency content is highly sparse. This is where the <mathjax>$L^1$</mathjax> norm comes into play. What we want to do is, out of all possible signals, locate the <em>simplest</em> one that matches up with the known data. In other words, we want to use a minimization routine to find a set of frequencies satisfying two conditions: (a) the underlying signal matches up exactly (or as closely as possible) with that of our data; and (b) the <mathjax>$L^1$</mathjax> norm of the frequencies is minimized. Such a routine will yield a sparse solution – exactly what we want.</p>
<p>In Python, there are a couple ways to accomplish this. Perhaps the easiest is to utilize the convex optimization library <a href="http://www.cvxpy.org/en/latest/">CVXPY</a>. Use the code below to minimize the norm of the signal’s frequencies with the constraint that candidate signals should match up exactly with our incomplete samples.</p>
<div><pre><span></span><span># create idct matrix operator</span>
<span>A</span> <span>=</span> <span>spfft</span><span>.</span><span>idct</span><span>(</span><span>np</span><span>.</span><span>identity</span><span>(</span><span>n</span><span>),</span> <span>norm</span><span>=</span><span>'ortho'</span><span>,</span> <span>axis</span><span>=</span><span>0</span><span>)</span>
<span>A</span> <span>=</span> <span>A</span><span>[</span><span>ri</span><span>]</span>

<span># do L1 optimization</span>
<span>vx</span> <span>=</span> <span>cvx</span><span>.</span><span>Variable</span><span>(</span><span>n</span><span>)</span>
<span>objective</span> <span>=</span> <span>cvx</span><span>.</span><span>Minimize</span><span>(</span><span>cvx</span><span>.</span><span>norm</span><span>(</span><span>vx</span><span>,</span> <span>1</span><span>))</span>
<span>constraints</span> <span>=</span> <span>[</span><span>A</span><span>*</span><span>vx</span> <span>==</span> <span>y2</span><span>]</span>
<span>prob</span> <span>=</span> <span>cvx</span><span>.</span><span>Problem</span><span>(</span><span>objective</span><span>,</span> <span>constraints</span><span>)</span>
<span>result</span> <span>=</span> <span>prob</span><span>.</span><span>solve</span><span>(</span><span>verbose</span><span>=</span><span>True</span><span>)</span>
</pre></div>


<p>You might be asking: <em>what the hell is that <mathjax>$A$</mathjax> matrix?</em> Well, it’s the key to the whole party. Let me explain.</p>
<p>In order to perform the minimization, we must somehow finagle our problem into a linear system of equations:</p>
<p><mathjax>$$A x=b$$</mathjax></p>
<p>Specifically, we want to derive a matrix <mathjax>$A$</mathjax> that can be multiplied with a solution candidate <mathjax>$x$</mathjax> to yield <mathjax>$b$</mathjax>, a vector containing the data samples. In the context of our current problem, the candidate solution <mathjax>$x$</mathjax> exists in the frequency domain, while the known data <mathjax>$b$</mathjax> exists in the temporal domain. Clearly, the matrix <mathjax>$A$</mathjax> performs both a sampling and a transformation from spectral to temporal domains.</p>
<p>Compressed sensing really comes down to being able to correctly derive the <mathjax>$A$</mathjax> operator. Fortunately, there’s a methodology. Start off by letting <mathjax>$f$</mathjax> be the target signal in vector form (if your signal is 2-dimensional or higher, flatten it) and <mathjax>$\phi$</mathjax> be the sampling matrix. Then:</p>
<p><mathjax>$$b=\phi f$$</mathjax></p>
<p>Now let <mathjax>$\psi$</mathjax> be the matrix that transforms a signal from the spectral domain to the temporal domain. Given the solution <mathjax>$x$</mathjax> in the frequency domain, it follows that:</p>
<p><mathjax>$$\psi x=f$$</mathjax></p>
<p>Combining the two equations yields:</p>
<p><mathjax>$$A x=b\quad \text{where}\ A\equiv \phi\psi$$</mathjax></p>
<p>So, <mathjax>$A$</mathjax> is simply made up of rows sampled from the domain transform matrix <mathjax>$\psi$</mathjax>. The <mathjax>$\psi$</mathjax> matrix is easy to construct – it is the inverse discrete cosine transform acting upon the columns of the identity matrix. The matrix product <mathjax>$\psi x$</mathjax> is the equivalent to doing <code>idct(x)</code>.</p>
<p>Now that we’ve constructed the <mathjax>$A$</mathjax> matrix and run the minimization, we can reconstruct the signal by transforming the solution out of the frequency domain and back into the temporal. Below, on the left, is the original signal and its frequency content. On the right is our <mathjax>$L^1$</mathjax> approximation. I’d say that’s pretty good for only using 10% of the data!</p>
<div><pre><span></span><span># reconstruct signal</span>
<span>x</span> <span>=</span> <span>np</span><span>.</span><span>array</span><span>(</span><span>vx</span><span>.</span><span>value</span><span>)</span>
<span>x</span> <span>=</span> <span>np</span><span>.</span><span>squeeze</span><span>(</span><span>x</span><span>)</span>
<span>sig</span> <span>=</span> <span>spfft</span><span>.</span><span>idct</span><span>(</span><span>x</span><span>,</span> <span>norm</span><span>=</span><span>'ortho'</span><span>,</span> <span>axis</span><span>=</span><span>0</span><span>)</span>
</pre></div>


<p><img src="http://www.pyrunner.com/media/uploads/images/compressed-sensing-python/output_16_0.png"></p>
<p>One problem that stands out is that the quality of the reconstruction degrades noticeably at and around <mathjax>$t=0$</mathjax>. This is probably due to our sample interval violating the periodic boundary condition requirements of the cosine transform. Of course, given an arbitrary signal sample without any prior knowledge of its nature, it would be hard <em>not</em> to violate periodic boundary conditions. The good news is that now we have some very clear indications of the true signal’s frequencies. If desired, we could go back and resample the signal within an interval that satisfies periodic boundaries.</p>
<h2>Reconstruction of an Image (a 2D Signal)</h2>
<hr>
<p>Now let’s use what we learned from the 1-dimensional case to do compressed sensing in 2-dimensions. This is where the real fun begins because we can now try and reconstruct images.</p>
<p>Below, we will use exactly the same methodology as before to randomly sample and reconstruct the image <em>Waterfall</em> by M. C. Escher (approx. 1200 by 1600 pixels). Due to memory limitations imposed by the <mathjax>$A$</mathjax> matrix, we’ll start off by considering a downsized version of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.pyrunner.com/weblog/2016/05/26/compressed-sensing-python/">http://www.pyrunner.com/weblog/2016/05/26/compressed-sensing-python/</a></em></p>]]>
            </description>
            <link>http://www.pyrunner.com/weblog/2016/05/26/compressed-sensing-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23884141</guid>
            <pubDate>Sat, 18 Jul 2020 19:34:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Trump's Wobble-Gait Problem]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23884095">thread link</a>) | @scripthacker
<br/>
July 18, 2020 | https://thedeductible.com/2020/07/13/trumps-wobble-gait-problem/ | <a href="https://web.archive.org/web/*/https://thedeductible.com/2020/07/13/trumps-wobble-gait-problem/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2170">
	
	<!-- .entry-header -->

	<div>
		
<p>By DANIEL STONE, MD (3)</p>



<p>President Trump’s wobbly walk down a ramp at his recent West Point visit along with his awkward&nbsp; two-handed drink from a water glass have stirred recent speculation about a possible undisclosed neurologic issue such as early Parkinson’s Disease.&nbsp; Although no specific conclusions can be drawn from these observations, they raise important questions regarding the President’s health. &nbsp; &nbsp;</p>



<p>Trump would not be the first president to conceal health problems.&nbsp; Toward the end of Franklin Roosevelt’s presidency, his blood pressure rose alarmingly.&nbsp; As no drug treatments existed his doctors could recommend only that he stop smoking, lose weight and avoid dietary salt.&nbsp; Less than six months after an un-knowing public re-elected him to a record fourth term, FDR predictably suffered a fatal stroke.&nbsp; The public was similarly unaware of John Kennedy’s Addison’s Disease, a condition that required daily injections to replace the adrenal hormones his body could not make.&nbsp;</p>



<p>The known facts about Trump’s health are concerning enough. &nbsp; Despite taking a statin drug to reduce his cholesterol, Mr. Trump’s age and risk factors at his 2018 physical predicted a 16.7%&nbsp; risk of a heart attack over ten years, as estimated by a standard American College of Cardiology risk calculator.&nbsp; Trump was taking a statin at the time of that exam to lower his cholesterol.&nbsp; As cholesterol levels on a statin may not reflect risk as accurately as un-treated levels, the calculator may under-estimate his true risk. &nbsp; &nbsp; Although Trump’s doctors tout his health they seemed to be concerned about cardiovascular risk as they subsequently quadrupled his statin dosage, placing him highest dose of the most potent statin available. &nbsp; &nbsp;In addition, the President’s annual exam revealed that his weight recently drifted up into the obese range, which means additional coronary disease risk along with an increased chance of stroke, chronic kidney disease, diabetes and several types of cancers. &nbsp;</p>



<p>&nbsp;Mr.&nbsp; Trump’s judgment on health issues could be questioned given his use of finasteride, a medication used to prevent baldness.&nbsp; The drug, which can cause loss of libido and breast growth in men, was the subject of an FDA warning in 2011 regarding high grade prostate cancer.&nbsp; Although information published in 2019 was reassuring regarding prostate cancer risk, Trump has used the drug since at least 2016, well before this information was available.&nbsp; His apparent willingness to take a vanity drug despite known serious health risks should cause concern regarding his awareness that presidential health issues are more than mere matters of personal preference. &nbsp;</p>



<p>Although the “wobble-gait’ observations are non-specific they raised legitimate concerns about Parkinson’s Disease.&nbsp; Caused by insufficient levels of brain neurotransmitters, the condition slows body movements, disrupts gait stability and produces tremor.&nbsp; As the disease progresses 30% to 40% of Parkinson’s patients develop dementia.&nbsp; 2% of men the President’s age have Parkinson’s and the prevalence increases with time.&nbsp; Even more concerning than the thought of a president with Parkinson’s Disease would be a President taking medication for Parkinson’s Disease .&nbsp; Carbidopa/levodopa, the most commonly used drug, can be associated with mood changes.&nbsp; Other commonly used Parkinson’s drugs are associated with impulsive behaviors, not something that we need to see more of in this President. &nbsp;</p>



<p>The President’s awkward two-handed drink of water is less directly concerning.&nbsp; Parkinson’s Disease produces a hand tremor during rest. &nbsp; Tremors that occur during movement, like drinking from a glass, are&nbsp; “action tremors” which are common and rarely debilitating.&nbsp; But Trump’s use of his offhand to steady the other is the sort of maneuver one might use to suppress an action tremor.&nbsp; This practice might be entirely innocent, but the possibility that the President might be trying to suppress a tremor, like his excessive attempts explain away the gait issue, might lead reasonable people to wonder whether he has something to hide.</p>



<p>The President’s record on health disclosures provides further reason for concern.&nbsp; Dr. Harold Bornstein, Trump’s personal physician, released a statement in 2016 that Trump’s health was “astonishingly excellent” and that he would be the “healthiest individual ever elected to the presidency.”&nbsp; The Trumpian sound of the bombast in the physician’s letter makes more sense after Bornstein’s revelation that the candidate dictated the statement. &nbsp; Bornstein subsequently claimed that Trump’s White House had raided his office and taken all of Trump’s records without following standard procedures. &nbsp;</p>



<p>Although the evidence that Trump harbors a significant neurologic diagnosis is less than convincing it still raises serious concerns.&nbsp; In health matters, as with his personal&nbsp; tax issues, the absence of transparency and the reliance on public relations strategies should concern the public. &nbsp; Regardless of his current neurologic status, anyone with Trump’s risk factors and age would face substantial risk of debilitating&nbsp; health problems over the course of a four-year term.&nbsp; Given what we know, can the public have confidence that a medically disabled Trump would reveal serious health issues&nbsp; and allow Vice-Presidential succession under the terms of the 25<sup>th</sup> Amendment? &nbsp; Ultimately, the presidential health issue for Americans to consider is not whether Trump can walk straight but whether he can talk straight. &nbsp;</p>



<p><em>Dr. Daniel J. Stone is an internal medicine and geriatric specialist in Los Angeles.</em>&nbsp;<em>Dan is a regular contributor to the Deductible.</em>&nbsp;</p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://thedeductible.com/2020/07/13/trumps-wobble-gait-problem/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23884095</guid>
            <pubDate>Sat, 18 Jul 2020 19:29:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Gradually Exit Twitter]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23883941">thread link</a>) | @exolymph
<br/>
July 18, 2020 | https://balajis.com/how-to-gradually-exit-twitter/ | <a href="https://web.archive.org/web/*/https://balajis.com/how-to-gradually-exit-twitter/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


                <figure>
                    <img srcset="https://balajis.com/content/images/size/w300/2020/07/gradually-exit-twitter.png 300w,
                                https://balajis.com/content/images/size/w600/2020/07/gradually-exit-twitter.png 600w,
                                https://balajis.com/content/images/size/w1200/2020/07/gradually-exit-twitter.png 1000w,
                                https://balajis.com/content/images/size/w2000/2020/07/gradually-exit-twitter.png 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 1170px,
                                2000px" src="https://balajis.com/content/images/size/w2000/2020/07/gradually-exit-twitter.png" alt="How to Gradually Exit Twitter">
                </figure>
                <section>
                    <div>
                        <p>The <a href="https://twitter.com/TwitterSupport/status/1283591848729219073">hacks</a> are the last straw. We need to exit Twitter.</p><p>But you may be invested in Twitter! So what do you do? Here's one recipe for <em>gradual</em> exit.</p><ol><li>Step one is to set up an (optionally pseudonymous) newsletter at your <em>own</em> custom domain using the instructions <a href="https://balajis.com/set-up-a-paid-newsletter-at-your-own-domain/">here</a>. You can do this in an hour and maintain it for less than $30 per month. Then only tweet out posts from your site, using your domain name as a simple form of authentication.</li><li>Step two is to start building your membership list at your own site. If you want, help us review <a href="https://github.com/balajis/twitter-export">open source tools</a> to export your Twitter following to an email list and <a href="https://twitter.com/dwr/status/1284155565770498050">mass delete any DMs</a>.</li><li>And step three is to get off Twitter all together, and start building a decentralized media ecosystem that combines the sovereignty of individual domain names with the community of social networking. The v1 of that is a simple joint RSS feed that aggregates multiple independent newsletters, but we can get much more <a href="https://twitter.com/balajis/status/1280005821028397057">sophisticated</a> <a href="https://dci.mit.edu/decentralizedweb">with</a> <a href="https://hackernoon.com/a-state-of-the-art-of-decentralized-web-part-4-212732f74894">tech</a> <a href="https://gun.eco/docs/dWeb-The-Decentralized-Web">for</a> <a href="https://ens.domains/">the</a> <a href="https://handshake.org/">decentralized</a> <a href="https://ipfs.io/">web</a>. It may turn out that what we build helps reform Twitter itself, but at a minimum it will present an alternative.</li></ol><p>Before we get there though, let's go through the problems with Twitter.</p><h2 id="the-problems-with-twitter">The Problems with Twitter</h2><p>It's not just the hack. There are several overlapping issues with Twitter around security, authentication, pseudonymity, distribution, incentives, and culture.</p><ul><li><em>Twitter is insecure</em>. It was a mistake to think that personal security could compensate for the fundamental flaw of centralized web services: anyone who gains control over twitter.com gains control over your account. We knew this already from the <a href="http://archive.is/Bq5qi">2017 incident</a> and the <a href="http://archive.is/wip/scJMn">Jack Hack</a>. But now the most prominent people and companies in the world (Bezos, Gates, Zuckerberg, Musk, Apple, Uber, among others) have been <a href="https://twitter.com/TwitterSupport/status/1283591848729219073">openly and publicly hacked</a>. Tomorrow you may be the victim. And unlike these worthies, you may be <em>silently</em> and <em>privately</em> hacked. Perhaps you already have been.</li><li><em>Twitter is not authenticated</em>. It was a mistake to trust Twitter's centralized verification process to validate everything posted to the service. There weren't any <a href="https://www.investopedia.com/terms/p/private-key.asp#:~:text=A%20digital%20wallet%20stores%20the,to%20use%20the%20private%20key.">digital signatures</a> to help establish whether the messages were really coming from a user-controlled device, or faked by a central server.</li><li><em>Twitter is not fully pseudonymous</em>. It was a mistake to use our real names everywhere online, particularly on Twitter. It made us vulnerable to personal and physical attacks. Social media mobs can swarm your real name online and cancel you in real life. Doxxing can heighten the danger by making threats <a href="https://blog.lopp.net/reflections-upon-a-swatting/">materialize in</a> <a href="https://github.com/jlopp/physical-bitcoin-attacks/blob/master/README.md">meatspace</a>. Pseudonymity is a better default, especially now that we can <a href="http://www.marknagelberg.com/notes-on-the-pseudonymous-economy-balaji-srinivasan/">earn under a pseudonym</a>.</li><li><em>Twitter is a distribution chokepoint</em>. It was a mistake to outsource our distribution to Twitter. Twitter users don't fully control their reach, brand, or monetization. You can be <a href="https://www.searchenginejournal.com/twitter-reveals-how-it-ranks-tweets-in-search-results/263869/">downranked</a> or <a href="http://archive.is/mhgyB">deplatformed</a> at any time, just like you can on YouTube and other centralized platforms. Owning your <a href="https://support.substack.com/hc/en-us/articles/360037465992-How-do-I-export-my-email-or-subscriber-list-">own</a> <a href="http://locals.com/">email</a> <a href="https://ghost.org/members">list</a> is a far better alternative.</li><li><em>Twitter doesn't create wealth</em>. It was a mistake to have so many people spending so much time on something that <a href="https://twitter.com/paulg/status/1271834488998440961">arguably</a> destroys more wealth than it creates. Because by default, you don't create wealth on Twitter. You may create wealth <em>for</em> Twitter, or for the media corporations whose links are circulated, but not for yourself or for others. There's no sense of economic alignment with other users, no sense of mutual obligation.</li><li><em>Twitter turns society into Twitter</em>. It was a mistake to let Twitter set up the incentives for our society. It's not good for the world when the one thing every prominent person knows how to do is <a href="https://twitter.com/balajis/status/1272653587617701888">fight</a> each other on Twitter for likes and followers. It has converted society into a zero-sum status game played by elites with real consequences. Every day, blue checks compete for a finite pie of attention with ever more sensational posts. There is instant feedback on what is popular, but none on what is true. The lack of economics, the presence of real names, the toxic culture, and the UX itself all encourage constant fighting.</li></ul><p>Now, let me qualify these comments. I personally have gotten <a href="https://twitter.com/paulg/status/1271834488998440961">enormous value</a> out of Twitter, despite all the points above. After all, you only critique the services you use!</p><p>And to be clear, Jack Dorsey is a phenomenal entrepreneur. I respect everything he's done and the team that he's built. It's hard to build one multibillion dollar company, let alone <a href="http://archive.is/wip/bu6hJ">two</a>. He's done immense good for the world overall, both through his <a href="https://twitter.com/jack/status/1247616214769086465">personal generosity</a> and his startup vehicles. And I also don't wish any Twitter employee ill, as many of them are truly great people and I know how hard this stuff is.</p><p>Moreover, even after this hack, Twitter will likely continue to be an important internet battlefield for quite sometime. It's just too easy, too convenient. And it may turn out that whatever is built to exit Twitter will end up interfacing with Twitter itself, via their <a href="https://twitter.com/bluesky">decentralized protocol</a>, if only as a form of training wheels to help people get off. Hopefully this can be done in a win-win way, such that Twitter and its employees are incentivized to allow people to gradually exit and fix the issues on the centralized service.</p><p>But it's past time for us to start building something better, that keeps the good aspects of Twitter (the serendipitous learning, the fascinating <a href="https://twitter.com/balajis/status/1214585024772788224">people</a>) but filters the bad. That may mean exiting to our own domains and then networking them into decentralized media.</p><h2 id="decentralization-starts-with-a-domain">Decentralization Starts with a Domain</h2><figure><img src="https://balajis.com/content/images/2020/07/how-to-gradually-exit-twitter--1-.png" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/how-to-gradually-exit-twitter--1-.png 600w, https://balajis.com/content/images/size/w1000/2020/07/how-to-gradually-exit-twitter--1-.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/how-to-gradually-exit-twitter--1-.png 1600w, https://balajis.com/content/images/2020/07/how-to-gradually-exit-twitter--1-.png 2000w" sizes="(min-width: 720px) 720px"><figcaption>Can we network together websites into decentralized media with something deeper than links?</figcaption></figure><p>I may be wrong about this, but I don't think a "better Twitter" starts with a service which is simply a clone of Twitter except with a different community. I think it starts with a community of independent (and independently monetizable) domains that we network together in novel ways, to build <em>decentralized media</em>.</p><p>Towards this end, the first step in gradually exiting Twitter is to set up your own paid newsletter at a custom domain (<a href="https://balajis.com/set-up-a-paid-newsletter-at-your-own-domain/">instructions here</a>) and restrict yourself mainly to tweeting out posts. This does require more effort than writing 280 characters! But that's why it's good. Effort helps restore your attention span and improves average post quality. And in addition to the other benefits, the link to your domain doubles as a simple alternative to a <a href="https://www.investopedia.com/terms/p/private-key.asp#:~:text=A%20digital%20wallet%20stores%20the,to%20use%20the%20private%20key.">digital signature</a>, a way for people to see that the content is authentically yours. </p><p>The medium-term step is to develop <a href="https://github.com/balajis/twitter-export">tools</a> to migrate your followers off Twitter to an email list, and to mass delete all DMs as a precautionary step. If you want to help review some existing tools towards this end, we're working on it <a href="https://github.com/balajis/twitter-export/issues/1">here</a>.</p><p>The long-term step is to start addressing the issues with Twitter by knitting these individual domains together into an open source decentralized media ecosystem. That means addressing:</p><ul><li>Security by encouraging people to post from their own domains</li><li>Community by building a network around multiple domains</li><li>Authentication by combining domains with digital signatures</li><li>Distribution via memberships and email lists</li><li>Incentives by baking in monetization and economic alignment from the beginning</li><li>Mobs by recommending pseudonymity by default</li><li>Culture by encouraging physical norms of civility</li></ul><p>Crucially, unlike past efforts our goal would be to build this <em>community-first</em> rather than <em>technology-first</em>. Specifically, once we get enough paid newsletters set up at their own domains, we can experiment with new decentralized web technologies for linking them together. If you submit your URL to <a href="https://forms.gle/xqvAFgW43Hc7rVzJA">this form</a>, we'll see if we can form a community. We'll probably start with a joint <a href="https://en.wikipedia.org/wiki/RSS">RSS</a> feed and then <a href="https://hacks.mozilla.org/2018/07/introducing-the-d-web/">get more sophisticated</a>.</p><p>Oh, and you can signal that you're interested in decentralized media by changing your name on Twitter to your URL, as <a href="https://twitter.com/balajis">follows</a>:</p><figure><img src="https://balajis.com/content/images/2020/07/image-5.png" alt=""></figure><p>Exiting Twitter and building decentralized media will be a long project and we aren't assured of success. But this journey of a thousand miles begins with a single newsletter at your own domain! So <a href="https://balajis.com/set-up-a-paid-newsletter-at-your-own-domain/">set yours up</a> now. </p><p>It's time to start gradually exiting Twitter.</p>
                    </div>
                </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://balajis.com/how-to-gradually-exit-twitter/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23883941</guid>
            <pubDate>Sat, 18 Jul 2020 19:09:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“Defunding Seattle PD” is going to be a lot harder than anyone thinks]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23883923">thread link</a>) | @troydavis
<br/>
July 18, 2020 | https://sccinsight.com/2020/07/18/defunding-spd-is-going-to-be-a-lot-harder-than-anyone-thinks/ | <a href="https://web.archive.org/web/*/https://sccinsight.com/2020/07/18/defunding-spd-is-going-to-be-a-lot-harder-than-anyone-thinks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">

		<!-- #masthead -->

		
		
		<div id="content">

	<section id="primary">
		<main id="main" role="main">
				
		
<article id="post-15442">

	
	<!-- .entry-header -->

	<div>

		<p>Yesterday’s <a href="https://sccinsight.com/2020/07/17/ordinance-banning-less-lethal-devices-violates-consent-decree-says-doj-and-police-monitor/">acknowledgement</a> by the city that the Council’s ban on “less lethal” weapons violated the terms of the 2012 Consent Decree points to a much larger issue: efforts to “defund” and re-imagine the Seattle Police Department will face a complex web of legal, labor, and contractual impediments that will drag out the process for several months or possibly years.</p>


<p><a href="http://seattlechannel.org/videos?videoid=x115392">Earlier this week</a> a pair of advocacy organizations, Decriminalize Seattle and King County Equity Now, <a href="https://www.documentcloud.org/documents/6989571-Decrim-Seattle-KCEN-Blueprint.html">presented</a> their proposed “blueprint” of how to reduce SPD’s footprint and redirect funds to a variety of community-led organizations that could eventually take over response to 911 calls and other community responses that SPD is currently handling — often by default. Their proposal’s strength is in the detail of programs they want to fund, as well as in identifying key success factors such as building organizational and growth capacities in organizations that have been running on shoestring budgets for years. But the weakness of their proposal is in their laundry list of recommendations for cuts to make to SPD:</p>
<ul>
<li><em>Freeze hiring. Any planned hiring, including for individuals in the training pipeline,</em><br>
<em>should be cancelled.</em></li>
<li><em>Eliminate funds for recruitment and retention, including bonuses for new hires.</em></li>
<li><em>Remove the Office of Collaborative Policing, including Navigation Team. While some</em><br>
<em>programs of this office, along with their administrative infrastructure, should be</em><br>
<em>eliminated altogether, others could be moved to a civilian-controlled city agency.</em></li>
<li><em>Eliminate: Navigation Team, Community Outreach Administration</em></li>
<li><em>Transfer out of SPD control: Crisis Intervention Response, Community Service Officers</em></li>
<li><em>Eliminate spending on new equipment</em></li>
<li><em>Eliminate Data-driven policing</em></li>
<li><em>Eliminate spending on North Precinct Capital Project</em></li>
<li><em>Eliminate Professional Services -Including:</em>
<ul>
<li><em>Photo Enforcement</em></li>
<li><em>Sworn Hiring in HR</em></li>
<li><em>Recruitment and Retention</em></li>
<li><em>Community Outreach</em></li>
<li><em>Implicit Bias Training</em></li>
<li><em>Communications</em></li>
</ul>
</li>
<li><em>Cut SPD’s spending on Homeland Security (a misnamed unit that is mostly assigned to</em><br>
<em>large events like Bumbershoot)</em></li>
<li><em>Eliminate SWAT Team funding</em></li>
<li><em>End contracts with private firms that defend SPD and the City against police misconduct</em><br>
<em>lawsuits</em></li>
<li><em>Eliminate SPD’s travel and training budget</em></li>
<li><em>End overtime pay, including for Emphasis Patrols</em></li>
<li><em>Reduce patrol staffing, with corresponding reduction in administrative staffing</em></li>
<li><em>Transfer 911 dispatch out of Seattle Police Department to civilian control.</em></li>
<li><em>Transfer traffic/parking enforcement out of SPD control.</em></li>
<li><em>Transfer Office of Police Accountability out of SPD control.</em></li>
<li><em>Transfer Office of Emergency Management out of SPD control.</em></li>
<li><em>Reduce administrative costs in line with the above cuts, including corresponding cuts to</em><br>
<em>the office of the Chief of Police, Leadership and Administration, and Administrative</em><br>
<em>Operations.</em></li>
</ul>

<p>While it’s a delightful wish-list, doing many of these things currently runs afoul of local and state laws, not to mention the Consent Decree and the several labor contracts covering groups of employees within SPD.&nbsp; Let’s review.</p>
<h4>The City Charter</h4>
<p><a href="http://www.seattle.gov/cityclerk/legislation-and-research/seattle-municipal-code-and-city-charter">The Charter of the City of Seattle</a> is the founding law of the city, much as the State Constitution and the U.S. Constitution are respectively for the state and nation. changing it requires approval of the City Council, the Mayor, and the voters of the city in an election.</p>
<p><a href="https://library.municode.com/wa/seattle/codes/municipal_code?nodeId=THCHSE_ARTVIDEPO_S1ORPODE">Article VI, Section 1</a> states:</p>
<p><em>The Police Department shall consist of a Chief of Police and as many subordinate officers and employees as may by ordinance be prescribed. There shall be maintained adequate police protection in each district of the City.</em></p>
<p>While the Charter does not define “adequate police protection,” any major cuts to SPD — such as a 50% cut to sworn officers — would require the city to show that the police presence is still “adequate.” And that determination would likely end up being reviewed in court by legal challenges to the defunding plan.</p>
<p><a href="https://library.municode.com/wa/seattle/codes/municipal_code?nodeId=THCHSE_ARTXVIPESYCISE_S9LANE">Article XVI, Section 9</a> reads:</p>
<p><em>The right of City employees to bargain collectively, through representatives of their own choosing, shall not be abrogated by the City, but no collectively bargained contract shall become effective without ratification by the City Council. The City Council shall not ratify any contract which is inconsistent with this Charter.</em></p>
<p>The City cannot simply skip over the requirement to engage in collective bargaining with unions representing employees in SPD, on any topics that are mandatory for collective bargaining. State law, as we will see, has similar language, and details the mandatory topics.</p>

<h4>Seattle Municipal Code</h4>
<p>The <a href="http://www.seattle.gov/cityclerk/legislation-and-research/seattle-municipal-code-and-city-charter">Seattle Municipal Code</a> is under the Council’s direct control, so ordinances here can get addressed; but there are a lot of them that are relevant to SPD, and many of those — particularly personnel-related ones — also apply to other City employees so untangling how they apply to SPD may not be easy.</p>
<p>Chapter 3.28 relates to the Police Department. Chapter 3.29 is the police accountability legislation passed in 2017 that is still somewhat in legal limbo as it reads on provisions of the Consent Decree.</p>
<p><a href="https://library.municode.com/wa/seattle/codes/municipal_code?nodeId=TIT3AD_SUBTITLE_IIDEOF_CH3.28PODE_SUBCHAPTER_IPODERE_3.28.100TRPAMERE">SMC 3.28.100</a> says that parking meter enforcement is the responsibility of SPD.</p>
<p><a href="https://library.municode.com/wa/seattle/codes/municipal_code?nodeId=TIT3AD_SUBTITLE_IIDEOF_CH3.28PODE_SUBCHAPTER_IVCOSEOFPR_3.28.420AU">SMC 3.28.420</a> authorizes the Community Service Officer Program within SPD. If the program were to be moved elsewhere, this would need to be revised.</p>
<p>SMC 4.08 is the rules for the public safety civil service system, governing most personnel functions related to sworn police officers (not civilians), as well as to fire department personnel.</p>
<p><a href="https://library.municode.com/wa/seattle/codes/municipal_code?nodeId=TIT4PE_CH4.08PUSACISE">SMC 4.08.020</a> states:</p>
<p><em>All appointments and promotions to Police and Fire Department positions, retention therein and removal therefrom shall be based on merit and according to the policies and procedures hereinafter specified or according to the procedures regarding the promotions of police officers and sergeants set forth in the collective bargaining agreement between the City and the exclusive bargaining agent of such employees, as approved by ordinance, to the extent such procedures are inconsistent with those set forth herein.</em></p>
<p><a href="https://library.municode.com/wa/seattle/codes/municipal_code?nodeId=TIT4PE_CH4.08PUSACISE_4.08.140RIEM">SMC 4.08.140</a> (C) further reads:</p>
<p><em>Employees shall not be demoted, suspended, or discharged except only for cause, and they may appeal such adverse actions as specified in this chapter.</em></p>
<p>while <a href="https://library.municode.com/wa/seattle/codes/municipal_code?nodeId=TIT4PE_CH4.08PUSACISE_4.08.180COBA">SMC 4.08.180</a> says:</p>
<p><em>The adoption of this chapter shall not affect the provisions of any existing collective bargaining agreement.</em></p>
<p>(in other words: terms in legally negotiated collective bargaining agreements take precedence over the text of SMC 4.08)</p>
<p>The 2017 <a href="http://seattle.legistar.com/LegislationDetail.aspx?ID=3041612&amp;GUID=189886AB-6C46-438A-AB56-DA45AE4FCD7B&amp;Options=&amp;Search=">police accountability legislation</a> also has some relevant passages. SMC 3.29.105 explicitly says that OPA is organized with the Seattle Police Department to ensure that it has full access to SPD-controlled information under state law (we’ll revisit this point later).</p>
<p>Also, SMC 3.29.120 and 3.29.430 relate to the OPA Director supervising sworn officers working in OPA; that becomes more difficult (though not impossible) if OPA is outside of SPD. There are good arguments on both sides as to whether OPA should continue to have sworn officers serving as investigators; this whole area will need to be debated at length.</p>

<h4>State law</h4>
<p>The <a href="https://app.leg.wa.gov/RCW/default.aspx">Revised Code of Washington</a> (aka RCW) has several laws that pertain to how cities are run, and specifically to law enforcement agencies and personnel.</p>
<p><a href="https://apps.leg.wa.gov/rcw/default.aspx?cite=10.97">RCW 10.97</a> is the Criminal Records Privacy Act. It restricts information on arrests, pending charges, and criminal records that police departments can disseminate out and sets strict confidentiality rules. There are exceptions that may allow the city to move OPA out of SPD yet still preserve full and complete access to records, but it will be much more difficult. Any other groups spun out of SPD that might require access to that information will have similar challenges. To the extent that private community-led organizations are dispatched instead of public employees, access to information becomes even more problematic.</p>
<p><a href="https://app.leg.wa.gov/RCW/default.aspx?cite=41.56">RCW 41.56</a> is the collection of laws governing collective bargaining for all public employees in the state. There are sections that refer specifically to public-safety public employees, including the police.</p>
<p><a href="https://app.leg.wa.gov/RCW/default.aspx?cite=41.56.030">RCW 41.56.030</a> includes the list of topics that for which collective bargaining is required, i.e. the city can’t just impose its own rules. They include “wages, hours and working conditions.”&nbsp; That includes a wide swath of topics, including reorganizations, moving groups out of the department, layoffs, reducing pay, overtime rules, and more.</p>
<p><a href="https://app.leg.wa.gov/RCW/default.aspx?cite=41.20&amp;full=true">RCW 41.20</a> defines the police pension system for first-class cities such as Seattle. This is an incredibly important benefit for police officers that many have spent years paying into, hoping to get to the magic 25 years. What happens to the pension benefits for anyone laid off from SPD, or reorg’ed out of the department, will be an important issue to resolve.</p>

<h4>Collective bargaining agreements</h4>
<p>There are several CBA’s that apply to groups of SPD employees. That includes police officers up through sergeant (SPOG), police management (SPMA), parking enforcement officers (SPEOG), and 911 call center employees who also have their own agreement. Other classes of civilian employees within SPD are represented by different unions, who negotiate separate contracts. According to a spokesperson for the Mayor’s Office, the city has already received a demand from SPEOG “to bargain on all mandatory and permissive subjects of bargaining that would be impacted by the move of SPEOG to SDOT. Failure to bargain will result in a [unfair labor practice complaint].”</p>
<p>Making significant changes to SPD will probably require negotiating with all of these unions — and that will take at least months. the Mayor’s spokesperson said, “By starting the conversation now, we do think many of these can be accomplished in late 2020/early 2021.” Making legislative or administrative changes before those negotiations are complete could result in more unfair labor practice charges, as we saw in 2017 with the passage of the police accountability legislation, and eventually …</p></div></article></main></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sccinsight.com/2020/07/18/defunding-spd-is-going-to-be-a-lot-harder-than-anyone-thinks/">https://sccinsight.com/2020/07/18/defunding-spd-is-going-to-be-a-lot-harder-than-anyone-thinks/</a></em></p>]]>
            </description>
            <link>https://sccinsight.com/2020/07/18/defunding-spd-is-going-to-be-a-lot-harder-than-anyone-thinks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23883923</guid>
            <pubDate>Sat, 18 Jul 2020 19:07:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Free Invoice Generator by Wesat]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23883650">thread link</a>) | @kashgoudarzi
<br/>
July 18, 2020 | https://dashboard.wesat.io/invoice | <a href="https://web.archive.org/web/*/https://dashboard.wesat.io/invoice">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><p><span>Bill To</span></p><div><p><legend>Client Phone Number<i>Optional</i></legend></p></div></div><div><p><span>Bill From</span></p><div><p><legend>Your Phone Number<i>Optional</i></legend></p></div></div></div><div><div><table><thead><tr><th></th><th>Item Name</th><th>Qty</th><th>Unit</th><th>Price</th><th>Tax</th><th>Final Price</th></tr></thead><tbody></tbody></table><div><div><div><p><legend>Accepted payment methods</legend></p><div><div><div><p><label for="any">Any (no fee)</label></p><p><label for="card">Card (3% fee)</label></p><p><label for="bank">Bank (1.5% fee)</label></p></div></div></div></div><div><p><legend>Processing fee</legend></p><div><div><div><p><label for="pro">You pay the processing fee</label></p><p><label for="client">Your client pays the processing fee</label></p><p><label for="split">You and your client split the processing fee</label></p></div></div></div></div></div><div><table><tbody><tr><td>Subtotal</td><td>$0.00</td></tr><tr><td>Tax %</td><td>$0.00</td></tr><tr><td><b>Grand Total</b></td><td><b>$0.00</b></td></tr></tbody></table></div></div></div></div><hr><div><p><span>Additional Options</span></p><p>These options only apply if you're going to be charging your client on Wesat. If you just want to download a PDF of your invoice, you can ignore this section.</p></div></div></div></div></div>]]>
            </description>
            <link>https://dashboard.wesat.io/invoice</link>
            <guid isPermaLink="false">hacker-news-small-sites-23883650</guid>
            <pubDate>Sat, 18 Jul 2020 18:33:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python async frameworks – Beyond developer tribalism]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23883652">thread link</a>) | @gilad
<br/>
July 18, 2020 | https://www.encode.io/articles/python-async-frameworks-beyond-developer-tribalism | <a href="https://web.archive.org/web/*/https://www.encode.io/articles/python-async-frameworks-beyond-developer-tribalism">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
    <p><br>
I’ve been thinking about writing this article for a bit, but have been most prompted by a post grandly titled “<a href="http://calpaterson.com/async-python-is-not-faster.html">Async Python is not faster</a>”. The post was rooted with some good motivations and observations, but also fell somewhat into a polarising mode of discussion that I’d like to see our communities try to move beyond.</p>

<p>Async concurrency necessarily brings with it an element of ecosystem split, and this can mean that it’s a bit of a divisive area to try to have conversations within.</p>

<p>However I think we could probably benefit from a bit more recognition of where there is shared ground. And in areas where there’s less clarity, to be able to have constructive conversations around the relative merits in differing approaches.</p>

<hr>



<h3 id="-why-you-shouldnt-care-about-performance">★ Why you shouldn’t care about “performance”.</h3>

<p>If you’re starting a new project, and choosing a python async framework vs a python sync framework, then any “performance” metrics around the frameworks <em>almost certainly don’t actually matter</em>, and are almost always a nonsense point of debate.</p>

<p>What is <em>actually</em> critical to your business is the development experience and strength of the surrounding ecosystem. What is your time to market going to be? How will the maintenance overhead be? How robust and evolvable is your codebase?</p>

<h3 id="-why-you-might-care-about-performance">★ Why you might care about “performance”.</h3>

<p>Having said that, there <em>are</em> a small portion of cases where the performance characteristics are a valid consideration. Particularly if your web framework makes lots of outgoing HTTP requests or other networking and I/O.</p>

<p>It’s important for the Python ecosystem that it ought to compare favourably to other dynamic languages in domains where async is beneficial. We don’t want to be in a position where “we’re using JavaScript because we believe it’ll scale up better” is a valid market blocker vs. choosing Python.</p>

<h3 id="-what-were-talking-about-when-we-talk-about-performance">★ What we’re talking about when we talk about “performance”.</h3>

<p>Like-for-like a single async function call in isolation will be marginally slower than a plain function call. That’s not contentious.</p>

<p>What we’re actually interested in is how <em>efficiently</em> we can interleave multiple concurrent tasks. In I/O bound systems co-operative concurrency (async) performs more efficiently under high concurrency than threaded concurrency (sync). Again, not contentious.</p>

<p>Again - Async Python is not faster. It <em>is</em> more efficient. Which will <em>tend</em> to mean that on I/O bound systems, the latency will <em>continue</em> to remain low even as the level of concurrency increases.</p>

<h3 id="-there-are-no-good-benchmarks">★ There are no good benchmarks.</h3>

<p>JSON “hello world” benchmarks are junk. Almost all cases of “I’ve created this benchmark myself” are likely to be junk. The prevalence of new frameworks overly focusing on nebulous benchmarking claims is generally junk. An obsession on benchmarking numbers can also sometimes result in poor overall design choices, such as obfuscated or unnecessarily coupled bits of codebase, because some not-very-meaningful metric is being prioritised over the code design itself. None of this should be contentious.</p>

<p>It’s not <em>always</em> true, for example, when Sanic was introduced there was a genuine step forward which was worth talking about, so I can understand why there was a focus there. But there’s still a ridiculous hype-cycle attached as a result, and we need to be really careful about trying to step beyond that.</p>

<p>It’s also reasonable if benchmarking is discussed in a sensible context and placement. For example, to the extent that Uvicorn and Starlette have discussed performance it has only ever been with a view to making a solid case that having a <em>properly specified</em> server/framework boundary API isn’t a negative performance consideration. Prior to the introduction of ASGI, Python’s async web ecosystem had generally bundled together both the low-level HTTP handling and the high level framework, and there was a notion that needed dispelling that introducing a properly specified separation of concerns wasn’t a good approach because <em>“something something performance something”</em>.</p>

<p>If you <em>are</em> going to look at web framework benchmarks for some very rough first-pass ideas about relative efficiency then the TechEmpower benchmarks should almost certainly be your baseline, since they’re at least independent, and have a decent range of test cases. If you’re going to diverge from them have some good argument for doing so.</p>

<p>The “Async Python is not faster” benchmarking is a reasonable example here, since it had clearly applied a decent degree of thoughtfulness. Even so there were still problems with the methodology, as <a href="https://twitter.com/llanga/status/1271719778324025349">Łukasz Langa did a good job of unpicking</a>.</p>

<p>Having said that, the TechEmpower benchmarks only show throughput, and don’t include any <em>meaningful</em> latency information. There’s actually a good reason for that, since
comparing latencies is really difficult. You can’t arrive at a single “95% latency” figure, because the figure you’ll arrive at <em>also depends on what throughput load you’re putting the system under</em> at the time of measuring the latency.</p>

<p>As a result measuring latency is only ever really meaningful if you’re looking at <em>graphs of how the latencies vary over a range of different throughputs</em>. Amber Brown’s <a href="https://www.youtube.com/watch?v=YxP1I-tm_2c">DjangoCon 2019 keynote talk does a fantastic job of showing some examples here</a>.</p>

<h3 id="-asgi-is-a-really-positive-step-for-the-async-ecosystem">★ ASGI is a really positive step for the async ecosystem.</h3>

<p>Having a decently specified server/framework interface is a <em>really good thing</em>. Andrew Godwin’s design for ASGI fills this gap with a WSGI-like approach. That has a set of trade-offs, but it’s a pretty pragmatic and well rounded choice.</p>

<p>This should not really be contentious.</p>

<h3 id="-its-about-functionality">★ It’s about functionality.</h3>

<p>Async isn’t just about achieving higher levels of concurrency-per-server, it also makes it a bunch of new functionality more feasible, including…</p>

<ul>
  <li>Handling long-lived network connections like Websockets.</li>
  <li>Long-lived HTTP connections and server sent events.</li>
  <li>Dealing with background tasks without necessarily needing a full blown task queue subcomponent.</li>
  <li>Parallelizing outgoing HTTP requests or other high latency I/O.</li>
</ul>

<h3 id="-not-everything-is-perfect">★ Not everything is perfect.</h3>

<p>The async ecosystem is far more immature than the existing thread synchronous. There are different challenges there, such as ensuring that <a href="https://lucumr.pocoo.org/2020/1/1/async-pressure/">backpressure is handled consistently throughout the various async APIs</a>, or in <a href="https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/">applying the lessons of structured concurrency</a>.</p>

<p>Nor is the “stdlib asyncio isn’t perfect” line a good argument either against asyncio specifically, or against async/await in general.</p>

<p>It’s okay that there’s still work to do in places. We know.  Let’s get that work done.</p>

<h3 id="-async-is-harder">★ Async is harder.</h3>

<p>Having to <em>think</em> about if a function does or doesn’t make I/O or could otherwise block <em>is unarguably more complex than not having to think about it</em>. It’s also more precise - you’re having to think about that for a reason, and done properly it’s presenting you with more information as a result. Being able to reason more clearly about which parts of your framework stack do or don’t perform I/O has a cost but also brings benefits.</p>

<p>There’s an analogy to make there in that writing Python using explicitly enforced typing is likely to be a harder than writing Python in an untyped style. It’s harder because you’re <em>also being more precise</em>. That’s not necessarily either good or bad, but it is definitively <em>different</em>.</p>

<p>This also gets to the point about why the “<a href="https://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/">What colour is your function</a>” argument isn’t actually a good case against async code, even if it seems to make clear sense on first pass. We’re coloring our functions because we’re <em>enforcing the exposure of some important information all the way throughout the stack</em>. That’s not an inherently bad thing to do.</p>

<hr>



<p>If those are areas where I think we ought to be able to reach consensus on, then there’s also a few areas where I think that the possible outcomes are less clear…</p>

<h3 id="-you-take-the-high-road-and-ill-take-the-low-road">★ You take the high road, and I’ll take the low road.</h3>

<p>There’s a few different tacks we might take onto introducing async into the Python web framework ecosystem…</p>

<ul>
  <li>Promoting mostly staying with threaded web frameworks. There’s actually a perfectly decent case to make that Python <em>on the whole</em> should eschew a <em>wide move towards async</em>. That the drawbacks of moving large swathes of the ecosystem towards an async model outweigh the advantages. (Pros: Simpler for the end developer. Huge existing ecosystem.)</li>
  <li>Working towards blended approaches. This is being championed within the Django community which is incrementally adding async support, largely off the back of some Herculean work by Andrew Godwin and others. This approach can either be in the form of adding support for async at the server level, while keeping the framework level strictly thread-synchronous. Or it can gradually start to expose optional async capabilities all the way through the stack. (Pros: Brings along the existing ecosystem, while adding async capabilities when they’re needed.)</li>
  <li>Working towards async-native frameworks. (Pros: Lower overall complexity of the stack then blended approach. More efficient since there’s less overhead in marshalling between two style all the way through the stack. If we’re having to write large amounts of new code then it’s not a bad inflection point at which to also rethink and finesse other aspects of how we’re putting together new frameworks.)</li>
</ul>

<p>We can’t really say which of these will yield the best dividends. Personally I <em>happen</em> to be working in the last of those three slices, simply because I can see a bunch of areas where I can contribute meaningfully towards the ecosystem there.</p>

<h3 id="-positioning-asyncio-and-trio">★ Positioning asyncio and Trio</h3>

<p>There another big question mark over the relative positioning of asyncio and Trio in the ecosystem. Trio is a newer approach to a Python async framework, that’s meticulously designed, and based on the principles of structured concurrency, that have been outlined by it’s author, Nathaniel Smith.</p>

<p>The difficulty this brings is that Trio is necessarily incompatible with asyncio, and introduces an ecosystem-split within an ecosystem-split.</p>

<p>There’s a few different …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.encode.io/articles/python-async-frameworks-beyond-developer-tribalism">https://www.encode.io/articles/python-async-frameworks-beyond-developer-tribalism</a></em></p>]]>
            </description>
            <link>https://www.encode.io/articles/python-async-frameworks-beyond-developer-tribalism</link>
            <guid isPermaLink="false">hacker-news-small-sites-23883652</guid>
            <pubDate>Sat, 18 Jul 2020 18:33:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Breathtakingly Brief Summary of Scrum]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23883591">thread link</a>) | @reikj4vic
<br/>
July 18, 2020 | https://mianlabs.com/2020/07/18/a-breathtakingly-brief-summary-of-scrum/ | <a href="https://web.archive.org/web/*/https://mianlabs.com/2020/07/18/a-breathtakingly-brief-summary-of-scrum/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-wrapper">
		<div id="content">

	<div id="primary">
		<main id="main" role="main">

		
			
<article id="post-1555">
			<!-- .entry-header -->		<div>
			<p>
							<span>
					<a href="https://mianlabs.com/category/meta/" rel="category tag">meta</a>				</span></p><!-- .cat-links -->
			
			
			<p><span>
				<time datetime="2020-07-18T13:11:52-05:00">July 18, 2020</time><time datetime="2020-07-18T13:16:47-05:00">July 18, 2020</time>			</span>

			<span>4 Minutes</span>		</p></div><!-- .entry-meta -->
	
	<div>
		
<p>This a breathtakingly brief summary of <a href="https://amzn.to/3eLsN5D">Scrum: A Breathtakingly Brief and Agile Introduction</a> by Chris Sims &amp; Hillary Louise Johnson.</p>



<h2>Definition</h2>



<ul><li><strong>Scrum</strong> is a simple framework for small teams to develop complex products.</li><li>The principle of scrum is <strong>inspect and adapt</strong>, or continuous improvement.</li><li>A <strong>scrum team</strong> consists of 5–9 people.</li><li>A scrum team moves in short cycles of time called <strong>sprints</strong>.</li></ul>



<blockquote><p>Experience is the best teacher, and the scrum cycle is designed to provide you with multiple opportunities to receive feedback—from customers, from the team, from the market—and to learn from it.</p></blockquote>



<h2>Roles</h2>



<h3>Product Owner</h3>



<ul><li>Represents the interests of the business and customers.</li><li>Has a hold on the product vision.</li><li>Directs the team towards the most important work.</li><li>Prioritizes, orders, and discusses product backlog requirements and criteria with the team.</li><li>Responsible for creating <strong>user stories</strong> to capture requirements, in the form of “As a <code>&lt;role&gt;</code>, I want <code>&lt;a feature&gt;</code>, so that I can <code>&lt;accomplish something&gt;</code>“.</li></ul>



<h3>Scrum Master</h3>



<ul><li>Advisor to the product owner and team.</li><li>Focuses on improving the team in order to increase the deliverables.</li><li>Not a boss but a helper and scrum expert.</li></ul>



<h3>Team Member</h3>



<ul><li>Has technical or domain skills required to create or contribute to a product.</li><li>Has authority to decide how the work should be done.</li><li>Creates estimates on items, user stories, tasks, etc.</li><li>Helps the team deliver value each sprint.</li></ul>



<h2>Artifacts</h2>



<h3>Product Backlog</h3>



<ul><li>Contains a list of product deliverables that represent:<ul><li>Features</li><li>Bug Fixes</li><li>Documentation</li><li>Meaningful or Valuable Things</li></ul></li><li>Deliverables are known as <strong>items</strong>, and captured in the form of user stories.</li><li>The user stories are ordered from most to least important in the backlog.</li><li>User stories at the top should be well understood while user stories at the bottom can be revisited in the future for refinement or grooming.</li><li>Good user stories should answer the following questions:<ol start=""><li><strong>Who is it for?</strong></li><li><strong>What needs to be built?</strong></li><li><strong>Why should we do it?</strong></li><li><strong>How long will it take?</strong></li><li><strong>What are the acceptance criteria?</strong></li></ol></li></ul>



<h3>Sprint Backlog</h3>



<ul><li>Contains a list of sprint deliverables.</li><li>The items in the sprint backlog have a limited timespan: the length of the sprint.</li><li>Represents the commitment of the team to produce deliverables.</li><li>User stories are broken down into tasks, or bits of work required to complete a story.</li><li><strong>User stories are units of value while tasks are units of work.</strong></li></ul>



<h3>Burn Charts</h3>



<ul><li>A <a href="https://en.wikipedia.org/wiki/Burn_down_chart">chart</a> for visualizing the relationship between time and scope.</li><li>Time is plotted on the X-axis (horizontal) while scope is on the Y-axis (vertical).</li><li>Tracks how much work a team has completed over time.</li><li>The scope of the work can be measured in points and the unit of time can be measured in sprints.</li><li>The chart moves upward when new work is introduced, and downward as the work is completed.</li></ul>



<h3>Task Board</h3>



<ul><li>A tool for visualizing work for team members and stakeholders.</li><li>The simplest task board consists of three columns:<ol start=""><li><strong>To Do</strong></li><li><strong>Doing</strong></li><li><strong>Done</strong></li></ol></li><li>Tasks move across columns, giving the team visibility on their situation and allowing them to inspect and adapt.</li></ul>



<h3>Definition of Done</h3>



<ul><li>Different members of the team might have different meanings for what “done” means.</li><li>Good scrum teams create their own definition of “done”.</li><li>The list of things the team does before declaring a user story as done becomes their definition.</li></ul>



<h2>The Sprint Cycle</h2>



<p>The sprint cycle is the essential rhythm of scrum. It’s the period of time where work gets done, continually. <strong>It consists of five team meetings that fuel the inspect-and-adapt cycle of scrum.</strong></p>



<p>The cycle can be as short as one week or as long as one month or more.</p>



<h3>Sprint Planning</h3>



<p><strong>Duration: one to two hours.</strong></p>



<ul><li>The beginning of the sprint.</li><li>The planning is divided into two parts:<ol start=""><li><strong>What will we do?</strong><ul><li>The team settles on a set of user stories that it can deliver by the end of the sprint: the sprint backlog.</li><li>The product owner presents the user stories to the team for discussion, review, and acceptance into the sprint.</li><li>The product owner decides which user stories will be considered; the team members decide how much work they can perform during the sprint.</li></ul></li><li><strong>How will we do it?</strong><ul><li>The team breaks down the accepted user stories into tasks.</li><li>The team can adjust the number of user stories at this stage if the work becomes too large for the sprint.</li><li>The product owner provides guidance, support, and answers questions until the stories become clear and broken down into tasks.</li></ul></li></ol></li></ul>



<h3>Daily Scrum</h3>



<p><strong>Duration: less than fifteen minutes.</strong></p>



<ul><li>Usually called the stand-up meeting, as members physically stand up for the meeting.</li><li>It is conducted daily, typically at the start of the work day.</li><li>It is brief and to the point.</li><li>Team members share the following:<ol start=""><li><strong>What tasks I’ve completed since the last daily scrum.</strong></li><li><strong>What tasks I expect to complete by the next daily scrum.</strong></li><li><strong>What obstacles are slowing me down.</strong></li></ol></li><li>The goal of the meeting is for the team to inspect and adapt its own work in order to deliver the stories at the end of the sprint.</li><li>Issues or problems that surface during the meeting don’t need to be solved during the meeting, they can be addressed afterwards.</li></ul>



<h3>Story Time</h3>



<p><strong>Duration: one to two hours, every week.</strong></p>



<ul><li>A time for discussing and improving the user stories in the product backlog for future sprints.</li><li>Also known as refinement or grooming.</li><li>The team works together to answer the questions for writing good user stories, focusing on defining the acceptance criteria.</li><li>During this meeting the team will size or estimate the user stories. These can be points or other metrics preferred by the team.</li></ul>



<h3>Sprint Review</h3>



<p><strong>Duration: one-half to one hour for every week of development.</strong></p>



<ul><li>The end of the sprint.</li><li>The team shows off its accomplishments and highlights the stories that are considered done.</li><li>Stakeholders can be invited to the meeting.</li><li>Feedback is gathered from the team and stakeholders.</li></ul>



<h3>Retrospective</h3>



<p><strong>Duration: one to two hours for every week of development.</strong></p>



<ul><li>Time for the team to reflect on what was learned during the sprint and opportunities for improvement.</li><li>It’s not about finding what went well or wrong, but about making strategic changes for the next sprint.</li><li>The meeting should be focused on improving the process.</li><li>The retrospective should be conducted in cases of abnormal sprint termination.</li></ul>



<blockquote><p>In scrum, the basic agreement between management and the team is that management won’t change up requirements during a sprint.</p></blockquote>




	</div><!-- .entry-content -->

	<!-- .entry-footer -->

	<div>
			<div>
				<p><img alt="" src="https://0.gravatar.com/avatar/60b04c67495031aea343d5b03139fe30?s=80&amp;d=identicon&amp;r=G" height="80" width="80">		</p><!-- .author-avatar -->
		
		<p>
			<h2>Published by <span>Damián Adams</span></h2>
		</p><!-- .author-heading -->

		<p>
			Software Developer			<a href="https://mianlabs.com/author/mianlabs/" rel="author">
				View all posts by Damián Adams			</a>
		</p><!-- .author-bio -->
	</div><!-- .entry-auhtor -->
		<p><strong>Published</strong>
			<time datetime="2020-07-18T13:11:52-05:00">July 18, 2020</time><time datetime="2020-07-18T13:16:47-05:00">July 18, 2020</time>		</p><!-- .site-posted-on -->
	</div>
</article><!-- #post-## -->

			
	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
			
<!-- #comments -->

		
		</main><!-- #main -->
	</div><!-- #primary -->

		</div><!-- #content -->

		<!-- #colophon -->
	</div></div>]]>
            </description>
            <link>https://mianlabs.com/2020/07/18/a-breathtakingly-brief-summary-of-scrum/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23883591</guid>
            <pubDate>Sat, 18 Jul 2020 18:29:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Django project structure the right way?]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23883346">thread link</a>) | @rajasimon
<br/>
July 18, 2020 | https://rajasimon.io/django-project-structure/ | <a href="https://web.archive.org/web/*/https://rajasimon.io/django-project-structure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Proper way to create folder structure for your Django Project.</p><div><p>In this blog post you’ll learn how to create best folder structure for your Django project. Django folder structure is consist of project root and apps. If you are not creating the right folder structure then everything will look complex.</p><p>This guide is for starting the project from scratch. For an established project, please keep this idea in mind and try to add these methods one by one.</p><h2 id="create-a-project">Create a project</h2><p>Creating the project is very easy in Django; It’s just the <code>startproject</code> command, and it will create a few files and folders in your project. Let’s see what those are…</p><pre><code>python manage.py startproject projdir
</code></pre><p>Now the project tree will look like this.</p><pre><code>├── manage.py
└── projdir
    ├── __init__.py
    ├── asgi.py
    ├── settings.py
    ├── urls.py
    └── wsgi.py
</code></pre><p>Now we’ve created the Django project, and now we have two options to proceed. One is to create the apps next to projdir or create an app inside the project folder and will continue developing from it.</p><p><strong>Two Methods</strong></p><ol><li>Create apps after the project folder</li><li>Create apps inside the project folder.</li></ol><p>I like the second approach better because that will gives a clean look into the overall project. It’s very easy and will look like everything seems organised. So let’s create the apps for our project.</p><h2 id="create-apps">Create apps</h2><p>For the second approach we need to create the folder by hand then run the <code>startapp</code> command. This way we can avoid the command error that cause by folder not present in the first place.</p><pre><code>cd projdir
mkdir app1
cd ..
python manage.py startapp core projdir/core
</code></pre><p>Now that we have created the folder structure lets see how the tree structure look like.</p><pre><code>├── manage.py
└── projdir
    ├── __init__.py
    ├── app1
    │&nbsp;&nbsp; ├── __init__.py
    │&nbsp;&nbsp; ├── admin.py
    │&nbsp;&nbsp; ├── apps.py
    │&nbsp;&nbsp; ├── migrations
    │&nbsp;&nbsp; │&nbsp;&nbsp; └── __init__.py
    │&nbsp;&nbsp; ├── models.py
    │&nbsp;&nbsp; ├── tests.py
    │&nbsp;&nbsp; └── views.py
    ├── asgi.py
    ├── settings.py
    ├── urls.py
    └── wsgi.py
</code></pre><p>Apps created by the <code>startapp</code> command will have all the necessary files for the Django app. Now how do we point this to installed apps.</p><h2 id="installed-apps">Installed apps</h2><p>We must tell the Django that our newly created apps dotted path. Then only Django will recognise our app as Django apps otherwise you can’t run migrations and other benefits. Okay let’s see how we can add dotted path in installed apps.</p><p>There is two approach in there one is using the dotted path upto the apps directory or the AppConfig directory.</p><ol><li>Dotted path from root project folder to apps.</li><li>Dotted path from root project folder to AppConfig.</li></ol><p>I can just use the first approach but Django recently pushing developers to use AppConfig much. I say first one is pretty easy to mention. In our case it will be <code>projdir.app1</code></p><p>But the second approach is bit different you need to change the apps.py file <code>name</code> variable then only Django will consider the AppConfig dotted path as valid.</p><pre><code>class App2Config(AppConfig):
    name = "prouder.app2"
</code></pre><p>And in the installed app just mention the path upto AppConfig like this…</p><pre><code>projdir.app2.apps.App2Config
</code></pre><h2 id="conclusion">Conclusion</h2><p>So far, we have seen how to create a folder structure in Django, both normally like and inside the root project folder to avoid the mess.</p><p>You can find all the code in<a href="https://github.com/rajasimon/django-project-structure">github/django-project-structure</a> repository.</p></div><p>This article published under
<a href="https://rajasimon.io/categories/development/">development</a>
on
<a href="https://rajasimon.io/tags/django/">django</a>
tags. Please support me by subscribing to my <a href="https://rajasimon.io/about">Newsletter</a>.
By subscribing you will not miss any <strong>future</strong> articles in this category.</p></div>]]>
            </description>
            <link>https://rajasimon.io/django-project-structure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23883346</guid>
            <pubDate>Sat, 18 Jul 2020 18:03:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to think about Quantum Mechanics: The quantum-classical limit as music]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23883340">thread link</a>) | @MindGods
<br/>
July 18, 2020 | https://blog.jessriedel.com/2020/07/06/how-to-think-about-quantum-mechanics-part-8-the-quantum-classical-limit-as-music/ | <a href="https://web.archive.org/web/*/https://blog.jessriedel.com/2020/07/06/how-to-think-about-quantum-mechanics-part-8-the-quantum-classical-limit-as-music/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">


<!-- #header-full -->
<div id="main">
	<div id="forbottom">
		
		

		
		<section id="container">
			<div id="content" role="main">
			

				<div id="post-4175">
					
										<!-- .entry-meta -->

					<div>
						<p><em>[Other parts in <a href="http://blog.jessriedel.com/all-posts-2/#HTTAQM">this series</a>: <a href="http://blog.jessriedel.com/2016/11/12/how-to-think-about-quantum-mechanics-part-0-measurements-are-about-bases/">1</a>,<a href="http://blog.jessriedel.com/2014/08/12/bad-ways-to-think-about-quantum-mechanics-part-2-vacuum-fluctuations/">2</a>,<a href="http://blog.jessriedel.com/2014/08/26/how-to-think-about-quantum-mechanics-part-3-the-pointer-and-schmidt-bases/">3</a>,<b><a href="http://blog.jessriedel.com/2015/03/24/how-to-think-about-quantum-mechanics-part-4-quantum-indeterminism-as-an-anomaly/">4</a></b>,<a href="http://blog.jessriedel.com/2015/07/11/how-to-think-about-quantum-mechanics-part-5-superpositions-and-entanglement-are-relative-concepts/">5</a>,<a href="http://blog.jessriedel.com/2015/08/23/how-to-think-about-quantum-mechanics-part-6-energy-conservation-and-wavefunction-branches/">6</a>,<a href="http://blog.jessriedel.com/2017/07/24/how-to-think-about-quantum-mechanics-part-7-quantum-chaos-and-linear-evolution/">7</a>,<a href="https://blog.jessriedel.com/2020/07/06/how-to-think-about-quantum-mechanics-part-8-the-quantum-classical-limit-as-music/">8</a>.]</em></p>
<p>On microscopic scales, sound is air pressure <img src="https://blog.jessriedel.com/wp-content/ql-cache/quicklatex.com-f5ce8febe20855338b597a0895c883f8_l3.png" alt="f(t)" title="Rendered by QuickLaTeX.com" height="15" width="25"> fluctuating in time <img src="https://blog.jessriedel.com/wp-content/ql-cache/quicklatex.com-bfc60e817be9a5a218f8c13a616d007e_l3.png" alt="t" title="Rendered by QuickLaTeX.com" height="10" width="5">.  Taking the Fourier transform of <img src="https://blog.jessriedel.com/wp-content/ql-cache/quicklatex.com-f5ce8febe20855338b597a0895c883f8_l3.png" alt="f(t)" title="Rendered by QuickLaTeX.com" height="15" width="25"> gives the frequency distribution <img src="https://blog.jessriedel.com/wp-content/ql-cache/quicklatex.com-a7ad35162dfc8169d6cd1a4dd716d76f_l3.png" alt="\hat{f}(\omega)" title="Rendered by QuickLaTeX.com" height="18" width="29">, but in an eternal way, applying to the entire time interval for <img src="https://blog.jessriedel.com/wp-content/ql-cache/quicklatex.com-385b3ddb8f70f52aef4008f9a49ae42f_l3.png" alt="t\in [-\infty,\infty]" title="Rendered by QuickLaTeX.com" height="15" width="77">.</p>
<p>Yet on macroscopic scales, sound is described as having a <i>frequency distribution as a function of time</i>, i.e., a note has both a pitch and a duration.  There are many formalisms for describing this (e.g., wavelets), but a well-known limitation is that the frequency <img src="https://blog.jessriedel.com/wp-content/ql-cache/quicklatex.com-7ecb2edca0c056ef63841faa6b190da7_l3.png" alt="\omega" title="Rendered by QuickLaTeX.com" height="7" width="9"> of a note is only well-defined up to an uncertainty that is inversely proportional to its duration <img src="https://blog.jessriedel.com/wp-content/ql-cache/quicklatex.com-ae18682396bda8e5637579f4d951d33b_l3.png" alt="\Delta t" title="Rendered by QuickLaTeX.com" height="10" width="17">.</p>
<p>At the mathematical level, a given wavefunction <img src="https://blog.jessriedel.com/wp-content/ql-cache/quicklatex.com-78738c93898c21533aebe69aa432b309_l3.png" alt="\psi(x)" title="Rendered by QuickLaTeX.com" height="15" width="29"> is almost exactly analogous: macroscopically a particle seems to have a well-defined position and momentum, but microscopically there is only the wavefunction <img src="https://blog.jessriedel.com/wp-content/ql-cache/quicklatex.com-2b42539d45e74b745aa9c4fc6ac8a8cb_l3.png" alt="\psi" title="Rendered by QuickLaTeX.com" height="14" width="10">.  The mapping of the analogy<a href="#footnote-7" id="refmark-7"><sup killerfootnote=""><b><big>a  </big></b></sup></a> is <img src="https://blog.jessriedel.com/wp-content/ql-cache/quicklatex.com-ee14f3c67bc4b3632f070dfa96da4253_l3.png" alt="\{t,\omega,f\} \to \{x,p,\psi\}" title="Rendered by QuickLaTeX.com" height="15" width="125">.  Wavefunctions can of course be complex, but we can restrict ourself to a real-valued wavefunction without any trouble; we are not worrying about the dynamics of wavefunctions, so you can pretend the Hamiltonian vanishes if you like.</p>
<p>In order to get the acoustic analog of Planck’s constant <img src="https://blog.jessriedel.com/wp-content/ql-cache/quicklatex.com-36a782e50141956888851adf27e9940c_l3.png" alt="\hbar" title="Rendered by QuickLaTeX.com" height="11" width="8">, it helps to imagine going back to a time when the pitch of a note was measured with a unit that did not have a known connection to absolute frequency, i.e., to inverse-time units.  To my (very limited) understanding, by the <a href="https://en.wikipedia.org/wiki/Pythagorean_tuning">6th century BC</a> it was already understood that an octave was the difference between two notes when one is vibrating twice as fast as another, but the absolute frequency (oscillations per second) of any particular note — say C♯ — was not known.<a href="#footnote-1" id="refmark-1"><sup killerfootnote=""><b><big>b  </big></b></sup></a>  Let’s arbitrarily declare <img src="https://blog.jessriedel.com/wp-content/ql-cache/quicklatex.com-dad1f7b998c838a96548f8dcbabac2c1_l3.png" alt="\Delta v" title="Rendered by QuickLaTeX.com" height="11" width="19"> to be the interval between pitches C♯ and C in the <a href="https://en.wikipedia.org/wiki/Pitch_(music)">one-lined octave</a>.  Today we know that C♯ and C correspond to 277.18 and 261.63 Hz, respectively, so that <img src="https://blog.jessriedel.com/wp-content/ql-cache/quicklatex.com-55f8ac9560392f69f75170e6fd902d68_l3.png" alt="1/\Delta v" title="Rendered by QuickLaTeX.com" height="15" width="32"> corresponds to 64.31 ms <img src="https://blog.jessriedel.com/wp-content/ql-cache/quicklatex.com-6544421992cadf090e36ffd87c11e0f5_l3.png" alt="\equiv 1/\Delta C" title="Rendered by QuickLaTeX.com" height="15" width="53">, but in the distant past for humanity (or the very recent past for me), this was unknown.</p>
<p>If I listened very carefully, or at least if I built special equipment, I would find that the purity of a note’s pitch begins to degrade as the duration of the note approaches its inverse frequency; this would be a hint about the location of the acoustic microscopic scale <img src="https://blog.jessriedel.com/wp-content/ql-cache/quicklatex.com-bc1cabad1300905dcd7fe741d7654312_l3.png" alt="a \equiv \Delta v /\Delta C" title="Rendered by QuickLaTeX.com" height="15" width="78">.  That is, I would find it harder and harder to distinguish between the notes C♯ and C as the duration of the notes approached of order 60 ms (although it might happen with even longer durations due to imperfections of my ears/equipment).  To confidently establish the relationship between perceived pitch and inverse time, I would probably want to listen to sound made by objects whose frequency of vibration I could measure directly.  That would be easy today, but very difficult three thousand years ago.</p>
<p>The analog of <img src="https://blog.jessriedel.com/wp-content/ql-cache/quicklatex.com-36a782e50141956888851adf27e9940c_l3.png" alt="\hbar" title="Rendered by QuickLaTeX.com" height="11" width="8">, then, would be the ratio <img src="https://blog.jessriedel.com/wp-content/ql-cache/quicklatex.com-ba57c79e062ede81b8328e039f685d21_l3.png" alt="a = \Delta v /\Delta C" title="Rendered by QuickLaTeX.com" height="15" width="78">.  Whenever someone says “middle C is 261.63 Hz”, they are effectively setting <img src="https://blog.jessriedel.com/wp-content/ql-cache/quicklatex.com-23536ee4051b9db71bed93260d8a4493_l3.png" alt="a=1" title="Rendered by QuickLaTeX.com" height="10" width="34"> (i.e., measuring pitch in units of inverse-time), just as physicists commonly set <img src="https://blog.jessriedel.com/wp-content/ql-cache/quicklatex.com-dcdc31084fcc1912383006fa8778e3ad_l3.png" alt="\hbar=1" title="Rendered by QuickLaTeX.com" height="12" width="34"> (measuring momentum in units of inverse-distance).  But crucially, for understanding the history of science, this is not possible until you have equipment that is sensitive to the microscopic scale.  Before this, you needed two separate systems of units that could not (then) be connected in a principled manner.</p>
<p>The quantum-acoustic analogy is not just conceptual, it is a mathematically precise correspondence, to the point that there are book-length treatments that apply almost equally well to both.<a href="#footnote-2" id="refmark-2"><sup killerfootnote=""><b><big>c  </big></b></sup></a>  In particular, the <a href="https://en.wikipedia.org/wiki/Wigner_quasiprobability_distribution">Wigner function</a> (previous posts: <a href="https://blog.jessriedel.com/2014/04/01/wigner-function-fourier-transform-coordinate-rotation/">1</a>,<a href="https://blog.jessriedel.com/2014/09/22/in-what-sense-is-the-wigner-function-a-quasiprobability-distribution/">2</a>) for simultaneously representing the position and momentum of a particle can be used fruitfully in acoustics for simultaneously representing the duration and pitch of sounds (which is <a href="https://pdfs.semanticscholar.org/c98a/050c262874c81e21d00107f061c8b2737278.pdf">closely related</a> to the <a href="https://en.wikipedia.org/wiki/Short-time_Fourier_transform">short-time Fourier transform</a>).  And, importantly, it is true for both quantum mechanics and acoustics that the macroscopic limit (<img src="https://blog.jessriedel.com/wp-content/ql-cache/quicklatex.com-ca7b9ae225c27443889e3385f880ca97_l3.png" alt="\hbar,a\to 0" title="Rendered by QuickLaTeX.com" height="13" width="52">) is “singular”:  Just as only a few <img src="https://blog.jessriedel.com/wp-content/ql-cache/quicklatex.com-36a782e50141956888851adf27e9940c_l3.png" alt="\hbar" title="Rendered by QuickLaTeX.com" height="11" width="8">-indexed families of quantum states have a sensible classical limit, only a few <img src="https://blog.jessriedel.com/wp-content/ql-cache/quicklatex.com-653334e90ed20a9c5552098b53066d35_l3.png" alt="a" title="Rendered by QuickLaTeX.com" height="7" width="8">-indexed families of acoustic waveforms have a sensible decomposition into notes (“music”).  When this limit fails, it’s not a case of bad music, it’s a case of your speakers blowing out.</p>
<p>What makes quantum mechanics “mysterious” then is clearly not things like the form of the uncertainty principle per se.  (There is an acoustic uncertainty principle of identical mathematical form.)  Rather, it is the interpretation of the wavefunction in terms of probability amplitudes and our inability to probe it except indirectly through disturbing measurements, as opposed to acoustic waves which can be measured to arbitrary precision.<a href="#footnote-5" id="refmark-5"><sup killerfootnote=""><b><big>d  </big></b></sup></a>  Relatedly, there is, to my understanding, no acoustic analog of a mixed quantum state.</p>
<p>Basic harmonic analysis of acoustics is an interesting topic in elementary physics in its own right.  Maybe teaching more of it (especially in a phase-space formulation using a Wigner function) before presenting quantum mechanics would help students more easily see what’s truly unusual about quantum mechanics and what’s just an unfamiliar mathematical framework.</p>

											</div><!-- .entry-content -->


					<!-- .entry-utility -->
				</div><!-- #post-## -->

				<!-- #nav-below -->

				<!-- #comments -->


						</div><!-- #content -->
			

		
		</section><!-- #container -->

	
	</div> <!-- #forbottom -->
	</div><!-- #main -->


	<!-- #footer -->

</div></div>]]>
            </description>
            <link>https://blog.jessriedel.com/2020/07/06/how-to-think-about-quantum-mechanics-part-8-the-quantum-classical-limit-as-music/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23883340</guid>
            <pubDate>Sat, 18 Jul 2020 18:03:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[68 Books on Chess]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23883235">thread link</a>) | @vhpoet
<br/>
July 18, 2020 | https://readthistwice.com/books/best-chess-books?s=hn | <a href="https://web.archive.org/web/*/https://readthistwice.com/books/best-chess-books?s=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://readthistwice.com/books/best-chess-books?s=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-23883235</guid>
            <pubDate>Sat, 18 Jul 2020 17:52:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What TikTok Got Right]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23882929">thread link</a>) | @rauchp
<br/>
July 18, 2020 | http://blog.rauchp.com/posts/2 | <a href="https://web.archive.org/web/*/http://blog.rauchp.com/posts/2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><h4>(No, this isnâ€™t a political statement)</h4><h4>July 17th, 2020</h4></p><div><p>As a member of the hyped-up Gen Z, youâ€™d think Iâ€™d be an expert on TikTok. But no, I only downloaded it this week because I heard it might be taken down soon.</p>
<p>It turns out TikTok is kinda cool. Thatâ€™s not to say I think it should or shouldnâ€™t get banned, but itâ€™s easy to see the appeal after a week of using it. </p>
<p>And ironically, TikTok is a lot more democratic than a lot of other social networks.</p>

<p>Partly, because of the shared toolkit.</p>
<p>On Instagram, the 3rd party toolkit ranges from airbrush apps to After Effects.
On Youtube you have kids using <a href="https://www.youtube.com/watch?v=TKfS5zVfGBc">unregistered HyperCam 2â€™s</a> pitted against aspiring Jake Paulâ€™s using Adobe Premiere.</p>
<p>But on TikTok, almost all videos are filmed on mobile devices and edited in the app itself. You canâ€™t assume much based on a thumbnail or the production quality of a clip.</p>
<p>This means I can put less effort + time into production quality and making sure my videos meet at a base standard. <strong>The friction from idea to delivered video is significantly less</strong> on TikTok vs. the other two platforms.</p>

<p>Then thereâ€™s the infinite scroll governed by <em>the algorithm</em>.</p>
<p>Every major social network has one of these algorithms, and they all seem to be equally mysterious. Your entire future might be decided by a set of ever-changing ifâ€™s and elseâ€™s written in SV or Beijing.</p>
<p>And while most platforms use their feed algorithms to maximize engagement, TikTok uses it to maximize meme discovery.â€&nbsp;</p>
<p>Can I compete against Addison Raeâ€™s profile? Probably not, but apparently you can sneak in a lot more dancing Chilean software engineers on my TikTok Feed than my IG Explore feed. If social media is a status game, putting players on equal footing is just about the greatest thing you can do for engagement. And really, <strong>you only have to make people think they have a chance</strong>.</p>

<p>So the common theme here is that TikTok did one thing really well: create an efficient meme factory. <strong>The conversion from idea to meme is near-frictionless. The distribution of your newly created meme is effortless.</strong> No need to growth hack with suggestive thumbnails and follow-4-followâ€™s, just let the algorithm run its course.</p>
<p>Rather than let attention follow a power-law distribution, <strong>TikTok democratized attention</strong> and memes.</p>
<p>And while Iâ€™m no advocate for fallible centralized systems (the Algorithm controls enough about our lives as is), itâ€™s a damn good way to grow a social network.</p>

<p>As a side note, some of my friends work on Instagramâ€™s algorithms. I've seen the work Facebook is putting into similar efforts. But now Iâ€™m forced to see Instagram as a dying network. A culture built on flexing* and highlighting your best moments canâ€™t compete against a culture that embraces mass-participation and sharing everyday living. </p>
<p>Just ask yourself, in our brave new post-flex world, where will you turn to find relatable content?</p>

<p>â€&nbsp; Of course, this is all assuming the algorithm isnâ€™t compromised. The risk of bad actors abusing it in order to subtly influence us and our youth is real.</p>
<p>* Because of all this Covid-19 funny business, we may very well be entering into a post-flex era of social media. This might be what finally changes Instagramâ€™s culture. So either we slowly turn our main Instagrams into our Finstas, or Instagram will become a place dominated by shitty FuckJerry accounts and generic aesthetic pictures. So basically, an inferior blend of Pinterest and Twitter.</p></div></div>]]>
            </description>
            <link>http://blog.rauchp.com/posts/2</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882929</guid>
            <pubDate>Sat, 18 Jul 2020 17:17:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Next Frontiers of Search]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23882927">thread link</a>) | @laybak
<br/>
July 18, 2020 | https://knowledgeartist.org/articles/future-of-search | <a href="https://web.archive.org/web/*/https://knowledgeartist.org/articles/future-of-search">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>A quick introduction: I have spent quite some time working on (and daydreaming about) search, and mapping human knowledge. Both as a PM at <a target="_blank" href="https://www.google.com/search?q=bing">Bing</a>, and with my current projects with <a target="_blank" href="https://getrumin.com/">Rumin</a>.</p>
        <p>This post is more speculations about the future and plausible paths to get there, than a rigorous research report. If you are interested in the latter, <a target="_blank" href="mailto:john@knowledgeartist.org">email me</a> or <a target="_blank" href="https://twitter.com/jhlyeung">tweet at me @jhlyeung</a>.  </p>
        <h3>Search engines today</h3>
        <p>Today, a vast amount of content that is available in public can be looked up within miliseconds.</p>
        <p>In addition to the 10 blue links on the results page, search engines also provide: </p>
        <li>Instant answers and question answering, e.g. "<a target="_blank" href="https://www.google.com/search?q=weather+in+toronto">weather in Toronto today</a>",  "<a target="_blank" href="https://www.bing.com/search?q=MSFT+stock+price">MSFT stock price</a>", "<a target="_blank" href="https://www.google.com/search?q=who+is+the+president+of+the+u">Who is the president of the US?</a>"</li>
        <li>Voice assistants reading instant answers, playing the wrong song on Spotify, turning on lights to flex in front of your guests</li>
        <p>It is an impressive feat of engineering, and has been great for answering simple questions and looking up facts. But what lies ahead if we dare imagine the future possibilities?</p>
        <h3>No search at all</h3>
        <p>To get the piece of information you are looking for, going to google.com can sometimes feel like a hassle. A few clicks each time, plus the context switching, can add up in terms of time costs. </p>
        <p>A more desirable experience is to have the knowledge delivered to you, to whatever app or workspace you are in. So that you can get the information and resume what you are doing.</p>
        <p>You already see patterns like this today, where there many entry points to the search engine:</p>
        <li>The url address bar in the browser doubles as a search box</li>
        <li>The browser "New tab" page has a search box</li>
        <li>Operating systems have a search box: Spotlight on Mac. Cortana on Windows. Same deal on mobile</li>
        <li>"Smart lookup" in Microsoft Office products</li>
        <p>One day, we shall see a reincarnation of Clippy. One day.</p>
        <p>The idea is that you want the information the moment you need it. We will find more and more ways to eliminate the friction that stands between you and what you are searching. </p>
        <p>This brings us to our next point - searching across apps.</p>
        <h3>Intent understanding. Information layer across apps &amp; contexts</h3>
        <p>Everyone has experienced some version of trying to find a document or message across emails, instant messages, cloud storage, notes etc.</p>
        <p>At the time of writing, this is still largely the case. Though there are a sea of big companies and startups alike working on solving this. It is a rather straightforward problem of integrating with various data sources and indexing the content. </p>
        <p>So it is probably safe to expect this to be less of an issue over time.</p>
        <p>We would always be looking for shortcuts to get what we are looking for, faster. This is a part of a much bigger trend of automation and connected apps, which is not limited to search. </p>
        <p>But search engines, as a general-purpose intent understanding machine, have a big role to play in this. We can expect to see more deep links and actions being accessible from a central interface. Alexa playing your favorite podcast is only the beginning. </p>
        <h3>Querying huge, generative language models</h3>
        <p>When you have a question, the most natural thing to do for most people is to ask someone. </p>
        <p>When Google came along and became a verb, the convention became to just ask the Googs. Sure there are still loads of questions it can't answer, that a real person can. But it's good enough. And it's instant.</p>
        <p>That could very well change in the near future. Generative language models that are trained a huge corpus of human-generated data on the internet can spit out answers that are often as good as a real human's response.</p>
        <p>At the time of writing, OpenAI recently released an API to its latest GPT-3 model. From all the anecdotes I have read, it seems it is pretty darn good! Generating a general purpose human-like response seems to good enough to be usable. </p>
        <p>It does seem too far for a language model to do what the search engine currently does, provided that it can:</p>
        <li>Map the generated output to a credible source. This would address the "black box" concerns that people have.</li>
        <li>Refresh content - "index" and "train" on fresh content. This is similar to how a human being would "stay updated" by reading the news and having conversations. </li>
        <p>When that happens, perhaps we wouldn't even call it a search engine. Would "oracle" seem more apt?</p>
        <h3>Indexing the unindexed knowledge</h3>
        <p>Both search engines and large language models rely on crawled data on the web. This means the scope of their knowledge and capabilities are limited to that dataset. </p>
        <p>In particular, the limitations include: </p>
        <li>The content must be published somewhere on the web, and is publicly available. This excludes the wealth private and individual knowledge.</li>
        <li>Data on the web is predominantly text. Which means scope is limited to whatever can be expressed in natural language. There is a tremendous amount of implicit or tacit knowledge that is hard to transfer verbally.</li>
        <li>Content tends to be shallow. There are countless domains of knowledge that are still not very legible and accessible, even for humans.</li>
        <p>Given the limitations, here are a few exciting areas of development:</p>
        <li>Indexing private knowledge, and integrating it with the collective public knowledge. </li>
        <li>Better UIs and formats, to help externalize and digitze complex ideas that are hard to convey in plain text.</li>
        <li>Represent and map out the deep knowledge in each field.</li>
        <p>That covers the knowledge side of things. But so much of the human condition isn't about just knowing...</p>
        <h3>Indexing perception, emotions, and experiences  </h3>
        <p>What we know accounts for just a small fraction of our conscious experience. There are myriad sensations that are hard to even find words for. This is especially true for experiences in altered states - for instance, from meditation, bodily movements, or consuming substances.</p>
        <p>But what if we can enlist the help of machines to map out and navigate how we feel? Can we index an emotional experience and construct a sequence of steps to recreate or revisit this moment?</p>
        <p>This sounds incredibly challenging. And by this point we are venturing quite far into the future. It would be fun though, to entertain a few possibilities. </p>
        <p>It helps to recognize that we already have reliable heuristics, in various domains of art, that roughly predict what our experiences will be like. Eating ice cream on a hot summer day is satisfying. Stomping backbeats make music easy to dance to. Symmetry is generally pleasing to the eye. Exercising makes you tired in the moment, and you feel good at night.</p>
        <p>These broad stroke heuristics are distilled from many instances of trial-and-error and observations. What happens if we more systematically gather data at scale and analyze it?</p>
        <p>We could in principle achieve fine-grained predictions and control of human experiences: in terms of precision in time, evoking the exact sensation desired, and personalization.</p>
        <p>In this setup, the role of human beings would be sensors and interpreters, while machines maintain and find patterns in the collective data.</p>
        <p>Perhaps soon enough, we would be able to guess the inner state of any person, based on known information about the sequence of inputs and stimuli in the current environment. And the machine can construct a model of the person's mind, as a time-series sequence of perceptual frames, with each frame being a digital representation (say, an embedding) of the sensation.</p>
        <p>This is a good place to wrap. I will elaborate and flesh out some of the themes above in future posts. </p>
        <p>What an exciting world we live in!</p>
          
      </div></div>]]>
            </description>
            <link>https://knowledgeartist.org/articles/future-of-search</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882927</guid>
            <pubDate>Sat, 18 Jul 2020 17:17:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Instant access to your shell init files]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 9 (<a href="https://news.ycombinator.com/item?id=23882784">thread link</a>) | @todsacerdoti
<br/>
July 18, 2020 | http://emacsredux.com/blog/2020/07/16/instant-access-to-your-shell-init-files/ | <a href="https://web.archive.org/web/*/http://emacsredux.com/blog/2020/07/16/instant-access-to-your-shell-init-files/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
        <p>A long time I presented a <a href="http://emacsredux.com/blog/2013/09/27/instant-access-to-your-shell-init-file/">simple hack</a> that allowed you to
quickly navigate to your shell’s user config file (e.g. <code>.bashrc</code> or
<code>.zshrc</code>). While the solution gets the job done it was pretty basic and
limited - most notably it’d ignore the fact that you typically have several
shell config files that are often built on top of each other - e.g.  <code>/etc/profile</code>,
<code>~/.bash_profile</code> and <code>~/.bashrc</code>. Fortunately the original
hack evolved rather nicely and today lives in the
<a href="https://github.com/bbatsov/crux">crux</a> library under the name
<code>crux-find-shell-init-file</code>.<sup id="fnref:1"><a href="#fn:1">1</a></sup></p>

<p>Provided you’ve installed <code>crux</code> all you need to do is run that command
(e.g. with <code>M-x crux-find-shell-init-file</code>) and you’ll get something like this
as the result:</p>

<p><img src="http://emacsredux.com/assets/images/instant_shell_config.png" alt="instant_shell_config.png"></p>

<p>Pretty neat, right? Even in its updated state the command is not complex at all:</p>

<div><div><pre><code><span>(</span><span>defun</span> <span>crux-find-shell-init-file</span> <span>()</span>
  <span>"Edit the shell init file in another window."</span>
  <span>(</span><span>interactive</span><span>)</span>
  <span>(</span><span>let*</span> <span>((</span><span>shell</span> <span>(</span><span>file-name-nondirectory</span> <span>(</span><span>getenv</span> <span>"SHELL"</span><span>)))</span>
         <span>(</span><span>shell-init-file</span> <span>(</span><span>cond</span>
                           <span>((</span><span>string=</span> <span>"zsh"</span> <span>shell</span><span>)</span> <span>crux-shell-zsh-init-files</span><span>)</span>
                           <span>((</span><span>string=</span> <span>"bash"</span> <span>shell</span><span>)</span> <span>crux-shell-bash-init-files</span><span>)</span>
                           <span>((</span><span>string=</span> <span>"tcsh"</span> <span>shell</span><span>)</span> <span>crux-shell-tcsh-init-files</span><span>)</span>
                           <span>((</span><span>string=</span> <span>"fish"</span> <span>shell</span><span>)</span> <span>crux-shell-fish-init-files</span><span>)</span>
                           <span>((</span><span>string-prefix-p</span> <span>"ksh"</span> <span>shell</span><span>)</span> <span>crux-shell-ksh-init-files</span><span>)</span>
                           <span>(</span><span>t</span> <span>(</span><span>error</span> <span>"Unknown shell"</span><span>))))</span>
         <span>(</span><span>candidates</span> <span>(</span><span>cl-remove-if-not</span> <span>'file-exists-p</span> <span>(</span><span>mapcar</span> <span>'substitute-in-file-name</span> <span>shell-init-file</span><span>))))</span>
    <span>(</span><span>if</span> <span>(</span><span>&gt;</span> <span>(</span><span>length</span> <span>candidates</span><span>)</span> <span>1</span><span>)</span>
        <span>(</span><span>find-file-other-window</span> <span>(</span><span>completing-read</span> <span>"Choose shell init file: "</span> <span>candidates</span><span>))</span>
      <span>(</span><span>find-file-other-window</span> <span>(</span><span>car</span> <span>candidates</span><span>)))))</span>
</code></pre></div></div>

<p>I guess one thing that we can improve down the road is adding an option to
display the shell config in the same window, but that’s a small thing.  The variables
like <code>crux-shell-bash-init-files</code> are simply lists of all potential files that
we should look for, that’s why I’ve opted to omit them from the code listing.</p>

<p>I stand by my original suggestion to bind this useful command to <code>C-c S</code>:</p>

<div><div><pre><code><span>(</span><span>global-set-key</span> <span>(</span><span>kbd</span> <span>"C-c S"</span><span>)</span> <span>#'</span><span>crux-find-shell-init-file</span><span>)</span>
</code></pre></div></div>

<p>That’s all I have for you today! Meta-x forever!</p>



    </div></div>]]>
            </description>
            <link>http://emacsredux.com/blog/2020/07/16/instant-access-to-your-shell-init-files/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882784</guid>
            <pubDate>Sat, 18 Jul 2020 16:58:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Liquidity in Sports Betting Markets]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23882776">thread link</a>) | @laurex
<br/>
July 18, 2020 | http://conordurkin.com/liquidity-in-sports-betting-markets/ | <a href="https://web.archive.org/web/*/http://conordurkin.com/liquidity-in-sports-betting-markets/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
			
		<div>
		
<p><em>O<em>r, some thoughts on the theory of bid-ask spreads in gambling markets</em></em></p>



<p>One of the things I’ve found interesting to think about for a few months now is how spreads and odds get set by bookmakers. I’ve written a bit about this before, in terms of how the line gets set, but also think it’s worth considering how the house edge is set on any given market. In the simplest terms, what determines whether a two-sided market is -110 on both sides<span id="easy-footnote-1-186"></span><span><a href="#easy-footnote-bottom-1-186" title="~4.55% house edge"><sup>1</sup></a></span> or -115 on both sides <span id="easy-footnote-2-186"></span><span><a href="#easy-footnote-bottom-2-186" title="~6.52% house edge"><sup>2</sup></a></span>, or some other number? Put differently, and more broadly, this can be thought of as a question around efficiency and liquidity in gambling markets, and what determines the bid-ask spread.</p>



<p>It’s useful to start with how lines get set. Broadly speaking, bookmakers begin by opening markets at prices they think reflect the ‘right price’ for a game, based on their actual expectations of performance, expectations of people’s bets, and a variety of other factors<span id="easy-footnote-3-186"></span><span><a href="#easy-footnote-bottom-3-186" title="Contrary to popular belief, it is not entirely based on &amp;#8220;what gets me 50-50 on each side&amp;#8221; &amp;#8211; I wrote a bit about this before, <strong><a href=&quot;http://conordurkin.com/bookmakers-and-keynesian-beauty-contests/&quot;>h</a></strong><strong><a href=&quot;http://conordurkin.com/bookmakers-and-keynesian-beauty-contests/&quot;>e</a></strong><strong><a href=&quot;http://conordurkin.com/bookmakers-and-keynesian-beauty-contests/&quot;>r</a></strong><strong><a href=&quot;http://conordurkin.com/bookmakers-and-keynesian-beauty-contests/&quot;>e</a></strong>."><sup>3</sup></a></span>. Gamblers (or market participants, if you prefer to sound more academic) then places wagers in these markets, moving the line one way or another based on their aggregate volumes, and the line eventually moves to a more efficient equilibrium price such that future bets aren’t one-sided and won’t move the market<span id="easy-footnote-4-186"></span><span><a href="#easy-footnote-bottom-4-186" title="One very very important clarification here: this is not as basic as seeing which side has more volume and shifting the line accordingly; there is far more too it than that. Just as electronic stock market makers or HFTs will likely shift their markets if they know they&amp;#8217;re getting retail volume from someone like Robinhood as opposed to institutional interest from some smart hedge fund, bookmakers will absolutely move their lines differently depending on whether they&amp;#8217;re receiving a few big bets from some random Joe Public as opposed to receiving big bets from known sharp gamblers. While enough one-sidedness of the former *may* move a line, it is much, much, much more the case that they will respond to the latter (and quickly)."><sup>4</sup></a></span>.</p>



<p>At the highest level: markets which reach that equilibrium price faster should have tighter bid-ask spreads. In a gambling context, that should be reflected in the form of a lower vig; the most efficient market possible would be one offering true odds<span id="easy-footnote-5-186"></span><span><a href="#easy-footnote-bottom-5-186" title="E.g. +100 on either side of a 50-50 outcome."><sup>5</sup></a></span>, with any house edge eating away at liquidity in some aspect. The key here is that the tightness of a bid-ask spread is reflective of the risk that the marketmaker is taking; in situations where the marketmaker can trust that he is not exposed to as much risk<span id="easy-footnote-6-186"></span><span><a href="#easy-footnote-bottom-6-186" title="Because the price is correct, or because the market is liquid enough that in the long run he will certainly reach the right price."><sup>6</sup></a></span>, then he should be willing to offer a tighter market to attract more bets.</p>



<p>What makes a market reach that price faster? It’s primarily a function of liquidity. A market with a lot of gamblers, a lot of bets, and a lot of dollars at stake has a lot more volume and is a lot more liquid. Consequently, there’s enough activity going on that you’re able to reach the ‘right price’ a lot quicker. It’s not that the prices in these market necessarily start any more accurately than any others; they just move more quickly into equilibrium much more quickly. This is pretty straightforward to see in the gambling world; the most heavily bet markets are generally NFL games (both spreads and totals), and those bets are generally regarded as most efficient and hardest to find an edge on<span id="easy-footnote-7-186"></span><span><a href="#easy-footnote-bottom-7-186" title="Again, unless you&amp;#8217;re waiting at the window until the minute they open and sharp gamblers haven&amp;#8217;t had an opportunity to move the prices into equilibrium yet."><sup>7</sup></a></span>.</p>



<p>Beyond liquidity, events with more precisely well-known mathematical odds should also be more efficient markets, and this should again be reflected in tighter spreads. However, in this instance the efficiency is a function of the event itself rather than a function of the market participants – if the true odds are particularly well known, the marketmaker can be more confident that his opening lines are already the ‘efficient prices’ and he doesn’t have to rely on gamblers to get him there. As an example, one of the popular Super Bowl prop bets offered every year is whether the coin toss will be Heads or Tails. Prop bets (or derivative bets) tend to get less action than most ‘regular’ bets, and they usually have larger vigs to reflect the fact that they’re less efficient markets. But this is an obviously 50-50 proposition, it’s a literal coin flip – and I think every time I’ve seen the prop offered, it’s been a -105 bet<span id="easy-footnote-8-186"></span><span><a href="#easy-footnote-bottom-8-186" title="~2.38% house edge"><sup>8</sup></a></span> on either side, reflecting that fact.</p>



<p>Conversely, less liquid or well-known stuff should in contrast see wider spreads. I already mentioned derivative (or prop) bets as one example here; less money chasing those markets means prices can remain inefficient longer, and there’s a higher risk of one-sided traffic<span id="easy-footnote-9-186"></span><span><a href="#easy-footnote-bottom-9-186" title="In a liquid market with lots of bettors, you&amp;#8217;ll have enough volume on both sides of a betting market for the price to reach equilibrium and be &amp;#8216;efficient&amp;#8217;. In a smaller market, you might never reach that equilibrium price if the market started at a bad price, so the net exposure to the bookmaker is very one-sided. This is fairly evidently riskier for the bookmaker."><sup>9</sup></a></span>. In some instances, you can actually see the ‘efficiency as liquidity’ question play out in real time, with not just the lines moving dynamically, but the size of the spreads as well. In college football, for example, while most big college football games are pretty liquid markets, FCS games are much less commonly bet. I’ve very frequently seen markets start at -120 or -125 on Monday morning, but have those spreads shrink to -110 on Saturday around noon when it’s almost gametime. Why are they able to tighten the market? Because by that point they feel pretty good about the quality of the price they’re offering, so they have less need to protect against price risk – despite the fact that it was perfectly logical for them to do so a few days prior.</p>



<p>One particularly interesting ‘less liquid’ example is in futures betting <span id="easy-footnote-10-186"></span><span><a href="#easy-footnote-bottom-10-186" title="For example, &amp;#8220;Which team will win the World Series?&amp;#8221; &amp;#8211; markets which deal not with one event happening quickly, but that deal with a bigger event happening down the road"><sup>10</sup></a></span>, which has two real wrinkles to deal with. First, time lag – these events are all things that happen in the future, not today, and the correct probabilities will evolve over time. This creates some level of uncertainty risk in that the efficient prices will change over time, could change dramatically over time, and even if the market lands on the efficient prices today the marketmaker faces a real risk that in the future the market won’t remain liquid enough to stay efficient as prices evolve. That uncertainty ends up reflected in a wider spread. Secondly, these are typically not 1-on-1 outcomes; there’s a whole field of potential options<span id="easy-footnote-11-186"></span><span><a href="#easy-footnote-bottom-11-186" title="For example, there are 30 teams that could win the World Series. Okay, maybe 29 &amp;#8211; the Orioles aren&amp;#8217;t getting it done this year, even with a 60 game season."><sup>11</sup></a></span>. As such, getting to “equilibrium” is a lot harder because it’s not about A vs B, it’s about A, B, C… to Z all being reasonably efficient prices. Liquidity is a lot harder because even with a lot of people betting, there’s no guarantee you’ll receive enough volume on each individual possible outcome of the futures market for the prices to be accurate; it’s a lot easier for a few to be out of whack. Books end up protecting against this by having a much, much higher hold in futures markets than in regular betting – where the house edge is usually something like 4-5% in any typical point spread, the total house edge in most futures markets is often 20-30% or more.</p>



<p>Another example is in live betting, where wagers are accepted during the actual course of play of a game. These markets typically see much wider spreads (something like -120 on each side instead of -110), largely because the timeframe in which bettors can move the price is basically nonexistant – the game is already going on! Bookmakers either have to be very very confident in the prices they offer or offer a less liquid market to protect themselves. They generally choose the latter.</p>



<p>It’s also worth thinking about alternative forms of illiquidity, where you can get tighter spreads at the cost of something else. One example is betting exchanges like Betfair – rather than having a marketmaker take your risk, these exchanges use a peer-to-peer market where your wager remains pending until some other bettor wants to take the other side. Because the exchange isn’t taking any risk themselves, they’re protected against any ‘inefficient prices’ and never have any net exposure, so bettors are able to benefit from tighter spreads<span id="easy-footnote-12-186"></span><span><a href="#easy-footnote-bottom-12-186" title="Betfair typically charges a commission of ~5% on winning tickets, which works out to a house edge of ~2.5%"><sup>12</sup></a></span>, at the cost of some execution risk (you’re not guaranteed for your wager to be received until someone takes the other side). Another example is in parimutuel betting, where odds are constantly fluctuating and the actual odds at which a bet is locked in are not set until shortly prior to the event occurring (this is pretty popular in horse racing). The house takes a fixed percentage from the total pool of wagers and then pays out according to the final odds, so they’re again not taking any risk. From the bettor’s perspective, you can get a tighter ‘spread’ and you’re guaranteed to have your bet be valid, but you’re not guaranteed on the actual price, since that will still move around even after your bet is placed<span id="easy-footnote-13-186"></span><span><a href="#easy-footnote-bottom-13-186" title="For whatever reason, my understanding is that parimutuel horseracing still has a pretty healthy house cut. I still think intuitively the parimutuel format should lend itself to allowing for tighter spreads, but evidently that&amp;#8217;s not always the case."><sup>13</sup></a></span>.</p>



<p>Okay, now that we’re 1400 words into this – what’re the implications of all of this to the average gambler? In my experience a lot of times people see markets with lines at -115 or -120 and get annoyed at the bookmaker’s apparent stinginess. If that’s happening on a major event like an NFL or college football game, then sure, that doesn’t seem appropriate. But if that’s happening on more obscure events, it’s not indicative of cheapness – it’s indicative of the marketmaker being afraid that their price is wrong, and that means it’s an opportunity. Despite wider spreads, the average bettor is far more likely to be able to profit betting into markets with less efficient prices than they are into markets with tight spreads and perfectly efficient prices. Ed Miller and Matthew Davidow make this point really well in <em>The Logic of Sports Betting</em><span id="easy-footnote-14-186"></span><span><a href="#easy-footnote-bottom-14-186" title="I&amp;#8217;d like to be abundantly clear that I am not here to market this book, nor am I being compensated for it but it is an excellent read, and if you care about this sort of thing you should absolutely read it."><sup>14</sup></a></span> when they get into the idea of ‘strong markets versus weak markets,’ and the need for savvy gamblers to attack the latter – when markets are less liquid, spreads are often wider, but they’re less efficient, and that means they are much more likely to be beatable.</p>
		
			</div>

	<!-- .comments-area -->
</div></div>]]>
            </description>
            <link>http://conordurkin.com/liquidity-in-sports-betting-markets/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882776</guid>
            <pubDate>Sat, 18 Jul 2020 16:58:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Segfault Episode 2: Computer Vision with Professor Bharath Hariharan]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23882743">thread link</a>) | @sohamsankaran
<br/>
July 18, 2020 | https://honestyisbest.com/segfault/2020/Jul/17/computer-vision/ | <a href="https://web.archive.org/web/*/https://honestyisbest.com/segfault/2020/Jul/17/computer-vision/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<h3>About this series</h3>
<p>Computer Science is composed of many different areas of research, such as Algorithms, Programming Languages, and Cryptography. Each of these areas has its own problems of interest, publications of record, idioms of communication, and styles of thought.</p>
<p><strong>Segfault</strong> is a podcast series that serves as a map of the field, with each episode featuring discussions about the core motivations, ideas and methods of one particular area, with a mix of academics ranging from first year graduate students to long tenured professors.</p>
<p>I’m your host, Soham Sankaran, the founder of <a href="https://pashi.com/">Pashi</a>, a start-up building software for manufacturing. I'm on leave from the PhD program in Computer Science at Cornell, where I work on distributed systems and robotics, and I started Segfault to be the guide to CS research that I desperately wanted when I was just starting out in the field.</p>

<p><strong>twitter</strong>: <a href="https://twitter.com/sohamsankaran">@sohamsankaran</a>,
<strong>website</strong>: <a href="https://soh.am/">https://soh.am</a>,
<strong>email</strong>: soham [at] soh [dot] am.</p>



  <hr id="read_post">
<h2>Episode 2: Computer Vision with Professor Bharath Hariharan</h2><p>
featuring Professor Bharath Hariharan of Cornell University
</p>
<p>Cornell Professor and former Facebook AI Researcher Bharath Hariharan joins me to discuss what got him into Computer Vision, how the transition to deep learning has changed the way CV research is conducted, and the still-massive gap between human perception and what machines can do.</p>

<p>Consider <a href="https://honestyisbest.com/segfault#subscribe_top" onclick="goToAnchor('subscribe_top'); return false;">subscribing via email</a> to receive every episode and occasional bonus material in your inbox.</p>

<p><em>Soham Sankaran’s <a href="https://ycombinator.com/">Y Combinator</a>-backed startup, <a href="https://pashi.com/">Pashi</a>, is recruiting a software engineer to do research-adjacent work in programming languages and compilers. If you’re interested, email <strong>soham [at] pashi.com</strong> for more information.</em></p>

<p><a href="https://honestyisbest.com/segfault/2020/Jul/17/computer-vision/#transcript_anchor" onclick="goToAnchor('transcript_anchor'); return false;">Go to transcript</a><br>
Note: If you’re in a podcast player, this will take you to the Honesty Is Best website to view the full transcript. Some players like <a href="https://podcastaddict.com/">Podcast Addict</a> will load the whole transcript with time links below the Show Notes, so you can just scroll down to read the transcript without needing to click the link. Others like Google Podcasts will not show the whole transcript.</p>

<h2 id="show-notes">Show notes</h2>

<p><strong>Participants:</strong></p>

<p><a href="https://soh.am/">Soham Sankaran</a> (<a href="https://twitter.com/sohamsankaran">@sohamsankaran</a>) is the founder of <a href="https://pashi.com/">Pashi</a>, and is on leave from the PhD program in Computer Science at <a href="https://www.cs.cornell.edu/">Cornell University</a>.</p>

<p><a href="http://home.bharathh.info/">Professor Bharath Hariharan</a> is an Assistant Professor in the Department of Computer Science at Cornell University. He works on recognition in Computer Vision.</p>

<p><strong>Material referenced in this podcast:</strong></p>

<p>‘Building Rome in a Day’, a project to construct a 3D model of Rome using photographs found online from the Univeristy of Washington’s Graphics and Imaging Lab (Grail): <a href="https://grail.cs.washington.edu/rome/">project website</a>, <a href="https://grail.cs.washington.edu/rome/rome_paper.pdf">original paper</a> by Sameer Agarwal, Noah Snavely, Ian Simon, Steven M. Seitz, and Richard Szeliski in ICCV 2009.</p>

<p>The Scale-Invariant Feature Transform (SIFT) algorithm: <a href="https://en.wikipedia.org/wiki/Scale-invariant_feature_transform">wikipedia</a>, <a href="https://www.cs.ubc.ca/~lowe/papers/iccv99.pdf">original paper</a> by David G. Lowe in ICCV 1999.</p>

<p>The Perceptron: <a href="https://en.wikipedia.org/wiki/Perceptron">wikipedia</a>, <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.335.3398&amp;rep=rep1&amp;type=pdf">original paper</a> by Cornell’s own <a href="https://en.wikipedia.org/wiki/Frank_Rosenblatt">Frank Rosenblatt</a> in <a href="https://en.wikipedia.org/wiki/Psychological_Review">Psychological Review</a> Vol. 65 (1958). Rosenblatt was a brilliant psychologist with exceptionally broad research interests across the social sciences, neurobiology, astronomy, and engineering. The perceptron, which is a forerunner of much of modern artificial intelligence, initially received great acclaim in academia and the popular press for accomplishing the feat of recognizing triangular shapes through training. In the 60s, however, legendary computer scientists <a href="https://en.wikipedia.org/wiki/Marvin_Minsky">Marvin Minsky</a> (a high-school classmate of Rosenblatt’s) and <a href="https://en.wikipedia.org/wiki/Seymour_Papert">Seymour Papert</a> released a book, <a href="https://en.wikipedia.org/wiki/Perceptrons_(book)">Perceptrons</a>, that made the argument that the perceptron approach to artificial intelligence would fail at more complex tasks, resulting in it falling out of fashion for a few decades in favour of Minsky’s preferred approach, <a href="https://en.wikipedia.org/wiki/Symbolic_artificial_intelligence">Symbolic AI</a>. Symbolic AI famously failed to produce tangible results, resulting in the <a href="https://en.wikipedia.org/wiki/AI_winter">AI winter</a> of the 80s and 90s, a fallow period for funding and enthusiasm. Rosenblatt, meanwhile, died in a boating accident in 1971 at the relatively young age of 43, 40 years too early to see himself vindicated in the battle between Minsky’s Symbolic AI and what we now call Machine Learning.</p>

<p>Bharath’s CVPR 2015 paper <a href="https://arxiv.org/abs/1411.5752">Hypercolumns for Object Segmentation and Fine-grained Localization</a> with Pablo Arbeláez, Ross Girshick, and Jitendra Malik, in which information pulled from the middle layers of a convolutional neural network (CNN) trained for object recognition was used to establish fine-grained boundaries for objects in an image.</p>

<p><a href="http://www.image-net.org/">ImageNet</a>, originally created by then Princeton (now Stanford) Professor <a href="https://profiles.stanford.edu/fei-fei-li">Fei-Fei Li</a> and her group in 2009: A vast database of images associated with common nouns (table, badger, ocean, etc.). The high quality &amp; scale of this dataset, combined with the <a href="http://www.image-net.org/challenges/LSVRC/">vigorous competition</a> between groups of researchers to top the ImageNet benchmarks, fuelled massive advances in object recognition over the last decade.</p>

<p><strong>Credits:</strong></p>

<p>Created and hosted by Soham Sankaran.</p>

<p>Mixed and Mastered by <a href="https://www.youtube.com/channel/UC7_0sQfCXyofKxxfo0yTXLA/about">Varun Patil</a> (<a href="mailto:varunpatil.audio@gmail.com">email</a>).</p>

<p>Transcribed by Sahaj Sankaran &amp; Soham Sankaran.</p>

<h2 id="transcript_anchor">Transcript</h2>

<p>[00:00:00]<br>
<strong>Bharath Hariharan:</strong> Humans can basically very quickly learn new things. They know exactly when they see something new, they can learn from very few training examples, and they can learn with very little computational effort. Whereas current techniques, they can only learn a small number of things with lots of examples and lots of computational effort. That’s a big gap which causes all sorts of issues when you apply these techniques to the real world.</p>

<p>[ringing tone]</p>

<p>[00:00:38]<br>
<strong>Soham Sankaran:</strong> Welcome to Episode 2 of Segfault, from Honesty is Best. Segfault is a podcast about Computer Science research. This episode is about computer vision, and it features Professor Bharath Hariharan from Cornell University. I’m your host, Soham Sankaran. I’m the CEO of Pashi, a startup building software for manufacturing, and I’m on leave from the Ph.D program at Cornell University, located in perpetually sunny Ithaca, New York.</p>

<p>I’m the CEO of Pashi, a start-up building software for manufacturing, and I’m on leave from the PhD program in Computer Science at Cornell University, located in perpetually sunny Ithaca, New York. Computer Science is composed of many different areas of research, such as Operating Systems, Programming Languages, Algorithms and Cryptography. Each of these areas has its own problems of interest, publications of record, idioms of communication, and styles of thought, not to mention, one level deeper, a multitude of sub-areas, just as varied as the areas they are contained within.</p>

<p>This can get extremely confusing very quickly, and I certainly didn’t know how to navigate this terrain at all until I was in graduate school. Segfault, in aggregate, is intended to be a map of the field, with each episode featuring discussions about the core motivations, ideas and methods of one particular area, with a mix of academics ranging from first year graduate students to long tenured professors. I hope that listeners who have dipped their toes in computer science or programming, but haven’t necessarily been exposed to research, get a sense of not only the foundations of each area – what work is being done in it now, and what sorts of opportunities for new research exist for people just entering, but also what it is about each specific area that compelled my guests to work in it in the first place, and what the experience of doing research in that area every day actually feels like.</p>

<p>This is the map of CS that I didn’t even know I desperately wanted in high school and undergrad, and I hope folks who are just starting their journey in computer science will find within it ideas that will excite them so much, and so viscerally, that they can’t help but work on them.</p>

<p>Just a quick note. The first episode was about the research area of programming languages. If you haven’t already listened to it, you can find it at <a href="https://honestyisbest.com/segfault/2020/Jun/16/programming-languages">honestyisbest.com/segfault</a>. My company, Pashi, is actually hiring someone with experience in programming languages and compilers, both in industry and in academia. If you fit this description, or know somebody that does, please reach out – send me an email at soham@pashi.com.</p>

<p>[ringing sound]</p>

<p>[00:02:44]<br>
<strong>Soham:</strong> So I’m with Professor Bharath Hariharan, who does computer vision. If you just want to introduce yourself briefly…</p>

<p>[00:02:50]<br>
<strong>Bharath:</strong> I’m Bharath. I do computer vision and machine learning. My interests are in visual recognition. I came here after a few years at FAIR – Facebook AI Research – and before that I was a Ph.D student at UC Berkeley.</p>

<p>[00:03:03]<br>
<strong>Soham:</strong> Where you worked with Jitendra Malik, who is one of the pioneers of vision recently.</p>

<p>[00:03:10]<br>
<strong>Bharath:</strong> Yeah. He’s one of the… yes.</p>

<p>[00:03:15]<br>
<strong>Soham:</strong> So, what was it that got you into computer vision in the first place? What was your journey to choosing this as a research field?</p>

<p>[00:03:21]<br>
<strong>Bharath:</strong> A variety of things. So I think the first source of my interest was that I was actually originally interested in psychology and how brains work. I think that’s been a longstanding interest of mine, and when I started working on computer science, when I started studying computer science, that was the thing I kept going back to. Like, why can’t computers do the things humans can? The other part of it was just images and visual media. Earlier, I had a brief infatuation with computer graphics, which also led to this question of ‘Why can’t machines understand images as well as humans do?’ So that’s sort of roughly the route I took, which is a fairly short route, but it serves as the motivation.</p>

<p>[00:04:12]<br>
<strong>Soham:</strong> What was the first problem that was very interesting for you in vision? Or the first problem that you worked on?</p>

<p>[00:04:18]<br>
<strong>Bharath:</strong> So the first problem I worked on was very different from the first problem that caught my interest.</p>

<p>[laughter]</p>

<p>The first problem I worked on was this problem of 3D deconstruction. I was in IIT-Delhi at the time, and one of my mentors, Professor <a href="http://www.cse.iitd.ernet.in/~suban/">Subhashish Banerjee</a> – we called him …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://honestyisbest.com/segfault/2020/Jul/17/computer-vision/">https://honestyisbest.com/segfault/2020/Jul/17/computer-vision/</a></em></p>]]>
            </description>
            <link>https://honestyisbest.com/segfault/2020/Jul/17/computer-vision/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882743</guid>
            <pubDate>Sat, 18 Jul 2020 16:54:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Team Improvement Techniques]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 7 (<a href="https://news.ycombinator.com/item?id=23882701">thread link</a>) | @cauliflower99
<br/>
July 18, 2020 | http://www.dcaulfield.com/team-improvement-techniques/ | <a href="https://web.archive.org/web/*/http://www.dcaulfield.com/team-improvement-techniques/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-15632">
<small>
    <a href="http://www.dcaulfield.com/2020/07/06/">July 6, 2020</a></small>
    			<small>
				<a href="http://www.dcaulfield.com/author/admin/"></a></small>
		
<p>In the last couple of months since Ireland announced the lockdown, our team has been performing at a high pace and have become self-organised to a large extent. As a team lead, this has allowed me the privilege of stepping back to look at the broader picture of how our team works individually and, more importantly, together. Through some exercises, I have identified some  methods to gather improvement ideas that can be applied to any team. </p>



<p>Anyone who has been a part of a high functioning team understands that continuous improvement is not optional. In order to perform better and to keep performing, the team must identify their weaknesses and plan to strengthen or mitigate those weaknesses. These improvements remedy stress points in the team, technical debt, repetitive tasks and so forth. The mindset of continuous growth is one that must be worked on and nurtured over time. Your team is not a fine wine – it will not improve if left alone in the corner. It will go sour.</p>



<p>It is one thing to be told to improve something. But very often, being told to improve something does not necessarily benefit you or your team.&nbsp;For example, if my manager comes to me and tells me my communication is poor and he wants bi-weekly emails from now on from my team’s status, all he has done is improve one of his problems, not mine. Improvements must come from within the team, and they must be gathered and executed on regularly. So the question is – how do we gather improvements that are worthwhile and specific enough to solve our problems, not someone else’s?</p>



<h2>80/20 Analysis</h2>



<p>The Pareto Principle, most commonly known as the 80/20 rule, states that about 80% of the effects come from 20% of the causes. In layman’s terms, most of the good things your team is known for doing likely comes from a small subset of your total work.</p>



<p>In my case, my team is known for our expertise in the upgrading of our product. How much of our work is related to this each week? I’d estimate less than 10%.</p>



<p>S<em>ide note</em>: This wasn’t always the case. When we first formed as a team, we spent about 90% of our time on this work. </p>



<p>Over time our mindset of continuous improvement led us to automating away most of our problems. Here is how you can utilize the 80/20 rule to find pressure points to improve. I do this regularly by myself, and occasionally with my team.</p>



<h3>Create a chart.</h3>



<p>Drawing on a piece of paper or whiteboard produces far more ideas than typing on a screen. So create a chart!</p>



<h4>What is going poorly?</h4>



<p>Always start with the bad. What makes you stressed on a Monday? Why does your team constantly get called for customer escalations on a Sunday? What makes you cry at night? (If you’re crying at night you really need this). </p>



<p>Copy the following table onto a piece of paper and fill it out now with any ideas you have.</p>



<figure><table><thead><tr><th><strong>20% Activity</strong></th><th><strong>80% Pain</strong></th><th><strong>Action to Remedy</strong></th></tr></thead><tbody><tr><td>Monday morning team presentation to management.</td><td>Stressful if I’m not prepped.</td><td>Give a practice run to my team on Friday.</td></tr></tbody></table></figure>



<h4>What is going well?</h4>



<p>This is less effective than analyzing what is poor in the team. You should prioritise fixing the bad over improving the good. There is no point in improving what your team is already good at if there are still issues that stress them. </p>



<p>Ask yourself – what are your team doing well? What do you need to keep doing well? What would happen if you improved these items?</p>



<p>Again, copy the following table onto a piece of paper and fill it out.</p>



<figure><table><thead><tr><th><strong>20% Activity</strong></th><th><strong>80% Reward</strong></th><th><strong>Improvement reward</strong></th><th><strong>Action to improve</strong></th></tr></thead><tbody><tr><td>Quick bug turnaround.</td><td>No weekend work.</td><td>Become the team with the lowest bug turnaround time.</td><td>Make incoming bugs a priority over stories.</td></tr></tbody></table></figure>



<p>You see the action columns? Take those, discuss with the team whether they agree on the actions required, and put them clearly for all to see everyday. You could create a task in your backlog that gets seen everyday on your sprint board, or print them and place them in your team’s area.</p>



<h2>Preventative Actions</h2>



<p>Identifying Preventative Actions is something that I have recently come across. Each team in my project go through this process every 3 weeks (every sprint). Here’s how it works. </p>



<p>A high priority bug has come into your team. You have spent all weekend pouring over it with your team, and finally came up with a solution late Sunday night, allowing your customer to continue their business as usual. Before you close the bug, there are a couple of things you need to consider and you <strong>must</strong> get answers to them. Otherwise, there will be another weekend in the future that will interrupt your team.</p>



<h3>Why did this bug occur?</h3>



<ul><li>We received a bad requirement specification from our business analysts.</li><li>We missed a corner case in our testware.</li><li>There were too many manual steps in the documentation which led to human error.</li><li>We missed a critical part of our study when planning the requirement.</li></ul>



<h3>What correction did you apply?</h3>



<ul><li>We built a patch fix and sent it to the customer.</li><li>We clarified with the customer that the particular use case reported is not supported yet.</li></ul>



<h3>How will you prevent this type of issue from occurring in the future?</h3>



<ul><li>We will call a 1 hour meeting with our business analyst each week to plan and clarify the feature request.</li><li>We will build a new pipeline that will test our customer’s use case each night.</li><li>We will automate steps x,y and z in our documentation so that human error is reduced.</li></ul>



<p>In my team’s case, for each bug we have the following grid which we fill out.</p>



<figure><table><thead><tr><th><strong>Root Cause</strong></th><th><strong>Correction Applied</strong></th><th><strong>Preventative Action</strong></th></tr></thead><tbody><tr><td>A test case to click on the ‘About’ page in Firefox was missing from our GUI test suite.</td><td>Added this test case to the GUI suite.</td><td>Review GUI test cases as part of a feature sign-off in the future.</td></tr></tbody></table></figure>



<h2>Retrospective</h2>



<p>If your team uses the scrum framework for their work, then you will be very familiar with the retrospective. However, you do not need to work in a scrum environment to have a team retrospective. </p>



<p>Team retrospectives, if taken regularly, can be a valuable tool in the team’s work week and is an opportunity for the team to come together and discuss the good and bad things that have happened in the past few weeks. </p>



<p>A retro should be scheduled on a regular basis, and you as the team lead must lead the meeting. Make sure that everyone from the team is present for the retro, and ensure that everyone is taking part and answering the questions.</p>



<h3>What was good that you need to keep doing?</h3>



<ul><li>We closed out 100% of our stories for the sprint.</li><li>There was good communication with our management.</li><li>We trialed pair programming this sprint – we have seen excellent results and should continue to do this.</li></ul>



<h3>What was bad?</h3>



<ul><li>We had poor communication within the team.<ul><li><em>Improvement</em>: We will trial pair programming for a sprint.</li></ul></li><li>The QA team raised tickets with very little detail resulting in a few days of delay in closing.<ul><li><em>Improvement</em>: Create a template that you would find helpful and send it to the QA team lead. Request that they copy this template and fill it out for all future tickets.</li></ul></li><li>We allowed untested code into the production software.<ul><li><em>Improvement</em>: Revise the +2 code review criteria with the team.</li></ul></li></ul>



<p>The most important part of the retro is to make sure that improvements or solutions are attached to each ‘bad’ item that is discussed.<br>At the end of the retro, prioritise the top one or two improvements, and take note of them for the upcoming sprint to execute.</p>



<h2>Improvement Backlog</h2>



<p>To become a top performing team, each individual must be comfortable with raising and discussing improvements as part of the team’s responsibilities. A team that does not have improvement ideas is a team that is not interested in improving which will lead to stagnation and a low performing team.</p>



<p>An improvement backlog is a list of ideas maintained and prioritised by the team. The list can be physical, like stickies on a whiteboard, or digital, like part of your jira backlog. </p>



<p>For example, my team created a Jira sprint and named it ‘Improvement Ideas’. We have list about 50 improvement ideas, most of which are one-liners and some of which have been discussed with details and acceptance criteria attached.</p>



<p>Each sprint planning, we prioritise this list and take the items we feel are most valuable to us. We have a couple of ad-hoc rules for this backlog.</p>



<ul><li>Any ideas that come up in meetings are inserted as a ‘one-liners’ in this backlog.</li><li>The list is regularly prioritised each sprint.</li><li>Each idea is explained by the team member who originally raised it.</li><li>We take 10-20% of our sprint capacity for improvements.</li></ul>



<p>Keeping this backlog up to date and prioritised will ensure that your team has consistent tasks to work on that primarily help the team.</p>



<h2>Stakeholder Feedback</h2>



<p>Working in a team can often be like working in a bubble. It is tempting to fall into confirmation bias. The most valuable improvements you can get for your product will come from your customers and stakeholders. </p>



<p>Leading the team does not only include leading the people on the team. If your team are known for building the wrong thing, or if their customers are not satisfied with their part of the product, then you as the team lead have ultimately failed.</p>



<p>When it comes to feedback, there is nothing more valuable than your own customers’ feedback. Your customers drive your product backlog. If you are in a large company, you may not have direct contact with your customers. In big companies, customers are often separated by layers of business analysts and management. This is not ideal, but it is something you can work around. </p>



<p>All you need is a small list of stakeholders that consistently use your product area to gain feedback from them. Talk to your managers about the customer interface and who could give feedback. In my case, we were 6 months without any contact with stakeholders that could give us valuable feedback. Eventually we were able to make friends with two guys who act as an interface to one of our company’s top …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.dcaulfield.com/team-improvement-techniques/">http://www.dcaulfield.com/team-improvement-techniques/</a></em></p>]]>
            </description>
            <link>http://www.dcaulfield.com/team-improvement-techniques/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882701</guid>
            <pubDate>Sat, 18 Jul 2020 16:50:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Front End Interview Handbook]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23882651">thread link</a>) | @yangshun
<br/>
July 18, 2020 | https://yangshun.github.io/front-end-interview-handbook/ | <a href="https://web.archive.org/web/*/https://yangshun.github.io/front-end-interview-handbook/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><header><div><p><img src="https://yangshun.github.io/front-end-interview-handbook/img/logo.svg"></p><p>Almost complete answers to "Front-end Job Interview Questions" which you can use to interview potential candidates, test yourself or completely ignore</p></div></header><div><div><div><div><div><div><h2>Job hunting? Sign up with Triplebyte to efficiently interview with top tech companies and land your dream job! 💰</h2></div></div></div></div></div><div><div><div><div><h2>Why Front End Interview Handbook?</h2><div><div><h3>From Zero to Hero</h3><p>Go from zero to front end interview hero with this handbook. No prior interview experience needed.</p></div><div><h3>Back to Basics</h3><p>Learn to walk before you learn to fly. While React, Vue and Angular are cool, make sure you also know your fundamentals.</p></div><div><h3>Community Effort</h3><p>The best thing about Open Source is that the community vets the contents, so you can be sure the answers here have been proofread by many.</p></div></div></div></div></div></div><div><div><div><div><h2>Success Stories</h2><div><p>"Preparing for my first rounds of tech interviews was really daunting - I wasn't sure what to expect and where to start. This handbook together with the <a href="https://github.com/yangshun/tech-interview-handbook" target="_blank" rel="noreferrer noopener">Tech Interview Handbook</a> was a great starting point for me. It clearly describes each part of the process and has tons of awesome tips and resources. With this handbook and lots of practice, I managed to get offers from Facebook, Dropbox and Amazon!"</p><div><div><p><img src="https://avatars1.githubusercontent.com/u/5081708?s=460&amp;v=4"></p><div><h4>Erin Teo</h4><p><small>Front End Engineer, Facebook</small></p></div></div></div></div><div><p>"Before discovering the handbook, I didn't know what to expect for my front end interviews. Thanks to it, I had a better understanding and even learned new things about frontend development. The handbook is an immense resource, one that I still use to refresh and reinforce my knowledge to tackle interviews confidently!"</p><div><div><p><img src="https://github.com/li-kai.png"></p><div><h4>Kai Li</h4><p><small>Software Engineer, Zendesk</small></p></div></div></div></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://yangshun.github.io/front-end-interview-handbook/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882651</guid>
            <pubDate>Sat, 18 Jul 2020 16:45:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Redo: A recursive, general-purpose build system]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23882630">thread link</a>) | @jnxx
<br/>
July 18, 2020 | https://redo.readthedocs.io/en/latest/ | <a href="https://web.archive.org/web/*/https://redo.readthedocs.io/en/latest/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
            <div>
              
                
<p><code>redo</code> is a competitor to the long-lived, but sadly imperfect, <code>make</code>
program.  Unlike other such competitors, redo captures the essential
simplicity and flexibility of make, while avoiding its flaws.  It manages to
do this while being simultaneously simpler than make, more flexible than
make, and more powerful than make, and without sacrificing performance - a
rare combination of features.</p>
<p>The original design for redo comes from Daniel J. Bernstein (creator of
qmail and djbdns, among many other useful things).  He posted some
terse notes on his web site at one point (there is no date) with the
unassuming title, "<a href="http://cr.yp.to/redo.html">Rebuilding target files when source files have
changed</a>." Those notes are enough information to
understand how the system is supposed to work; unfortunately there's no code
to go with it.  I wrote this implementation of redo from scratch, based on
that design.</p>
<p>After I found out about djb redo, I searched the Internet for any sign that
other people had discovered what I had: a hidden, unimplemented gem of
brilliant code design.  I found only one interesting link at the time: Alan
Grosskurth, whose <a href="http://grosskurth.ca/papers/mmath-thesis.pdf">Master's thesis at the University of
Waterloo</a> was about top-down
software rebuilding, that is, djb redo.  He wrote his own (admittedly slow)
implementation in about 250 lines of shell script, which gives an idea for
how straightforward the system is.  Since then, several other
implementations have appeared (see list below).</p>
<p>My implementation of redo is called <code>redo</code> for the same reason that there
are 75 different versions of <code>make</code> that are all called <code>make</code>.  It's somehow
easier that way.</p>
<p>I also provide an extremely minimal pure-POSIX-sh implementation, called
<code>do</code>, in the <code>minimal/</code> directory of this repository.</p>
<p>(Want to discuss redo?  Join <a href="https://redo.readthedocs.io/en/latest/Contributing/#mailing-list">our mailing list</a>.)</p>

<p>The theory behind redo sounds too good to be true: it can do everything
<code>make</code> can do, but the implementation is vastly simpler, the syntax is
cleaner, and you have even more flexibility without resorting to ugly hacks. 
Also, you get all the speed of non-recursive <code>make</code> (only check dependencies
once per run) combined with all the cleanliness of recursive <code>make</code> (you
don't have code from one module stomping on code from another module).</p>
<p>(Disclaimer: my current implementation is not as fast as <code>make</code> for some
things, because it's written in python.  Eventually I'll rewrite it an C and
it'll be very, very fast.)</p>
<p>The easiest way to show it is to jump into an example.  Here's one for
compiling a C++ program.</p>
<p>Create a file called default.o.do:</p>
<pre><code>redo-ifchange $2.c
gcc -MD -MF $2.d -c -o $3 $2.c
read DEPS &lt;$2.d
redo-ifchange ${DEPS#*:}
</code></pre>
<p>Create a file called myprog.do:</p>
<pre><code>DEPS="a.o b.o"
redo-ifchange $DEPS
gcc -o $3 $DEPS
</code></pre>
<p>Of course, you'll also have to create <code>a.c</code> and <code>b.c</code>, the C language
source files that you want to build to create your application.</p>
<p>In a.c:</p>
<pre><code>#include &lt;stdio.h&gt;
#include "b.h"

int main() { printf(bstr); }
</code></pre>
<p>In b.h:</p>
<pre><code>extern char *bstr;
</code></pre>
<p>In b.c:</p>
<pre><code>char *bstr = "hello, world!\n";
</code></pre>
<p>Now you simply run:</p>
<pre><code>$ redo myprog
</code></pre>
<p>And it says:</p>
<pre><code>redo  myprog
redo    a.o
redo    b.o
</code></pre>
<p>Now try this:</p>
<pre><code>$ touch b.h
$ redo myprog
</code></pre>
<p>Sure enough, it says:</p>
<pre><code>redo  myprog
redo    a.o
</code></pre>
<p>Did you catch the shell incantation in <code>default.o.do</code> where it generates
the autodependencies?  The filename <code>default.o.do</code> means "run this script to
generate a .o file unless there's a more specific whatever.o.do script that
applies."</p>
<p>The key thing to understand about redo is that declaring a dependency is just
another shell command.  The <code>redo-ifchange</code> command means, "build each of my
arguments.  If any of them or their dependencies ever change, then I need to
run the <em>current script</em> over again."</p>
<p>Dependencies are tracked in a persistent <code>.redo</code> database so that redo can
check them later.  If a file needs to be rebuilt, it re-executes the
<code>whatever.do</code> script and regenerates the dependencies.  If a file doesn't
need to be rebuilt, redo figures that out just using its persistent
<code>.redo</code> database, without re-running the script.  And it can do that check
just once right at the start of your project build, which is really fast.</p>
<p>Best of all, as you can see in <code>default.o.do</code>, you can declare a dependency
<em>after</em> building the program.  In C, you get your best dependency
information by trying to actually build, since that's how you find out which
headers you need.  redo is based on this simple insight: you don't
actually care what the dependencies are <em>before</em> you build the target.  If
the target doesn't exist, you obviously need to build it.</p>
<p>Once you're building it anyway, the build script itself can calculate the
dependency information however it wants; unlike in <code>make</code>, you don't need a
special dependency syntax at all.  You can even declare some of your
dependencies after building, which makes C-style autodependencies much
simpler.</p>
<p>redo therefore is a unique combination of imperative and declarative
programming.  The initial build is almost entirely imperative (running a
series of scripts).  As part of that, the scripts declare dependencies a few
at a time, and redo assembles those into a larger data structure.  Then, in
the future, it uses that pre-declared data structure to decide what work
needs to be redone.</p>
<p>(GNU make supports putting some of your dependencies in include files, and
auto-reloading those include files if they change.  But this is very
confusing - the program flow through a Makefile is hard to trace already,
and even harder when it restarts from the beginning because an include file
changes at runtime.  With redo, you can just read each build script from top
to bottom.  A <code>redo-ifchange</code> call is like calling a function, which you can
also read from top to bottom.)</p>

<p>Some larger proprietary projects are using it, but unfortunately they can't
easily be linked from this document.  Here are a few open source examples:</p>
<ul>
<li>
<p><a href="https://github.com/linleyh/liberation-circuit">Liberation Circuit</a> is a
  straightforward example of a C++ binary (a game) compiled with redo.</p>
</li>
<li>
<p><a href="https://github.com/apenwarr/wvstreams">WvStreams</a> uses a more complex
  setup producing several binaries, libraries, and scripts.  It shows how to
  produce output files in a different directory than the source files.</p>
</li>
<li>
<p><a href="https://github.com/apenwarr/wvbuild">WvBuild</a> can cross-compile several
  dependencies, like openssl and zlib, and then builds WvStreams using those
  same libraries.  It's a good example of redo/make interop and complex
  dependencies.</p>
</li>
<li>
<p>There's an experimental <a href="https://github.com/apenwarr/buildroot/tree/redo">variant of
  Buildroot</a> that uses redo
  in order to clean up its dependency logic.</p>
</li>
<li>
<p>You can find some curated tutorial examples in the
  <a href="https://redo.readthedocs.io/en/latest/cookbook/hello/">cookbook</a>, such as <a href="https://redo.readthedocs.io/en/latest/cookbook/defaults/">git variable
  substitution</a> and <a href="https://redo.readthedocs.io/en/latest/cookbook/latex/">text processing with
  LaTeX</a> (including plot generation with R and ggplot2).</p>
</li>
<li>
<p>A <a href="https://github.com/search?p=9&amp;q=path%3A%2F+extension%3Ado+filename%3A%2Fall.do&amp;type=Code">github search for all.do</a>
  shows an ever-growing number of projects using redo.</p>
</li>
</ul>
<p>If you switch your program's build process to use redo, please let us know and
we can link to it here for some free publicity.</p>
<p>(Please don't use the integration testing code in the redo project's <code>t/</code>
directory as serious examples of how to use redo.  Many of the tests are
doing things in intentionally psychotic ways in order to stress redo's code
and find bugs.  On the other hand, if you're building your own
reimplementation of redo, using our test suite is a great idea.)</p>

<p>djb never released his version, so other people have implemented their own
variants based on his <a href="http://cr.yp.to/redo.html">published specification</a>.</p>
<p>This version, sometimes called apenwarr/redo, is probably the most advanced
one, including support for parallel builds,
<a href="https://apenwarr.ca/log/20181113">resilient timestamps</a> and checksums,
<a href="https://apenwarr.ca/log/20181106">build log linearization</a>, and
helpful debugging features.  It's currently written in python for easier
experimentation, but the plan is to eventually migrate it to plain C.  (Some
people like to call this version "python-redo", but I don't like that name. 
We shouldn't have to rename it when we later transliterate the code to C.)</p>
<p>Here are some other redo variants (thanks to Nils Dagsson Moskopp for
collecting many of these links):</p>
<ul>
<li>
<p>Alan Grosskurth's <a href="http://grosskurth.ca/papers/mmath-thesis.pdf">redo thesis</a>
  and related sh implementation.  (Arguably, this paper is the one that got
  all the rest of us started.)</p>
</li>
<li>
<p>Nils Dagsson Moskopp's <a href="https://web.archive.org/web/20181106195145/http://news.dieweltistgarnichtso.net/bin/redo-sh.html">redo-sh</a>
  is a completely self-sufficient sh-based implementation.</p>
</li>
<li>
<p>apenwarr's <a href="https://github.com/apenwarr/redo/blob/master/minimal/do">minimal/do</a>
  is included with this copy of redo.  It's also sh-based, but intended to
  be simple and failsafe, so it doesn't understand how to "redo" targets more
  than once.</p>
</li>
<li>
<p>Christian Neukirchen's <a href="https://github.com/chneukirchen/redo-c">redo-c</a>, a
  C implementation.</p>
</li>
<li>
<p>Jonathan de Boyne Pollard's <a href="http://jdebp.eu./Softwares/redo/grosskurth-redo.html">fork of Alan Grosskurth's redo</a>
  (another sh-based implementation).</p>
</li>
<li>
<p>Jonathan de Boyne Pollard's <a href="http://jdebp.eu./Softwares/redo/">redo</a>
  rewritten in C++</p>
</li>
<li>
<p>Gyepi Sam's <a href="https://github.com/gyepisam/redux">redux</a> in Go</p>
</li>
<li>
<p>jekor's <a href="https://github.com/jekor/redo">redo</a> in Haskell</p>
</li>
<li>
<p>Shanti Bouchez-Mongardé (mildred)'s <a href="https://github.com/mildred/redo">fork of apenwarr's redo</a>
  in python</p>
</li>
<li>
<p>Tharre's <a href="https://github.com/Tharre/redo">redo</a> in C</p>
</li>
<li>
<p>catenate's <a href="https://github.com/catenate/credo">credo</a>, a (very
  rearchitected) variant written for the Inferno Shell.</p>
</li>
</ul>
<p>The original redo design is so simple and elegant that many individuals
have been
inspired to (and able to) write their own version of it.  In the honoured
tradition of Unix's <code>make</code>, they (almost) all just use the same name,
<code>redo</code>.  Unfortunately, many of these
implementations are unmaintained, slightly incompatible with the "standard"
redo semantics, and/or have few or no automated tests.</p>
<p>At the time of this writing, none of them except apenwarr/redo (ie.  this
project) correctly support parallel builds (<code>redo -j</code>) or log linearization
(<code>redo-log</code>).  For large projects, parallel builds are usually considered
essential.</p>
<p>The <a href="https://github.com/apenwarr/redo/tree/master/t">automated tests</a> in
this version of redo are almost, but not quite, appropriate for testing any
redo implementation.  If you really must write a new version of redo, we
invite you to thoroughly test it against the existing test suite to ensure
compatibility.  You can also steal our tests (with attribution, of course)
and include them in your own source package.  We'd also love it it you
contribute more automated tests when you find a bug, or send us patches if
you find a test which is accidentally incompatible (as opposed to finding a
real bug) with other redo implementations.</p>
              
            </div>
          </div></div>]]>
            </description>
            <link>https://redo.readthedocs.io/en/latest/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882630</guid>
            <pubDate>Sat, 18 Jul 2020 16:43:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UBCO researchers create liquid-repelling substance that works on all surfaces]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23882486">thread link</a>) | @elorant
<br/>
July 18, 2020 | https://news.ok.ubc.ca/2020/07/16/ubco-researchers-create-liquid-repelling-substance-that-works-on-all-surfaces/ | <a href="https://web.archive.org/web/*/https://news.ok.ubc.ca/2020/07/16/ubco-researchers-create-liquid-repelling-substance-that-works-on-all-surfaces/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<div id="attachment_18500"><p><img src="https://news.ok.ubc.ca/wp-content/uploads/2020/07/Hydrophobic_770.jpg" alt="UBCO master's student Behrooz Khatir measures liquid to be applied to an omniphobic film during testing inside the OPERA lab at UBC Okanagan’s School of Engineering." width="770" height="513" srcset="https://news.ok.ubc.ca/wp-content/uploads/2020/07/Hydrophobic_770.jpg 770w, https://news.ok.ubc.ca/wp-content/uploads/2020/07/Hydrophobic_770-400x266.jpg 400w, https://news.ok.ubc.ca/wp-content/uploads/2020/07/Hydrophobic_770-768x512.jpg 768w, https://news.ok.ubc.ca/wp-content/uploads/2020/07/Hydrophobic_770-240x160.jpg 240w, https://news.ok.ubc.ca/wp-content/uploads/2020/07/Hydrophobic_770-320x213.jpg 320w, https://news.ok.ubc.ca/wp-content/uploads/2020/07/Hydrophobic_770-500x333.jpg 500w, https://news.ok.ubc.ca/wp-content/uploads/2020/07/Hydrophobic_770-640x427.jpg 640w" sizes="(max-width: 770px) 100vw, 770px"></p><p>UBCO master's student Behrooz Khatir measures liquid to be applied to an omniphobic film during testing inside the OPERA lab at UBC Okanagan’s School of Engineering.</p></div>
<h3>New coating can eliminate complex disinfectant procedures for protective face shields</h3>
<p>Acting like an invisible force field, a new liquid coating being developed by UBC Okanagan researchers may provide an extra layer of protection for front-line workers.</p>
<p>Researchers at the <a href="https://apsc-golovin.sites.olt.ubc.ca/">Okanagan Polymer Engineering Research and Applications</a> (OPERA) Lab have developed a coating that repels nearly all substances off a surface. And that new coating will make cleaning personal protective equipment a little bit easier for front-line health care workers, explains Kevin Golovin, an assistant professor at UBCO’s School of Engineering and director at OPERA.</p>
<p>Surfaces that can repel a broad range of liquids are called omniphobic, explains UBCO master's student and lead author of the study Behrooz Khatir. Working in Golovin’s lab, Khatir has created a spray-on solution that can make any surface, including a face shield, omniphobic.</p>
<p>“Omniphobic—all-liquid repellent—films can repel a broad range of liquids, but the applicability of these coatings has always been limited to silicon wafers or smooth glass,” says Khatir. “This new formulation can coat and protect just about any surface, including metals, paper, ceramics and even plastics.”</p>
<p>The two-layer coating involves placing an ultra-smooth silica layer on a surface and then functionalizing this layer with a highly-reactive silicone to effectively block all kinds of liquids from sticking on the surface, explains Golovin.</p>
<p>Not only does the coating repel countless substances, but even under harsh exposures like UV light, acids and high temperatures, the coating maintains its resistance qualities. And Golovin notes, if the coating does become damaged it can be easily and repeatedly repaired, fully restoring the omniphobic properties to their initial state.</p>
<p>Golovin recently received COVID-19 funding from the Natural Sciences and Engineering Research Council (NSERC) to optimize the coating for health care face shields so they stay clean, in partnership with Kelowna-based survivability products manufacturer PRE Labs Inc.</p>
<p>“This technology has many applications, but we are currently focused on providing a solution that will keep our nurses and doctors safe and effective,” says Golovin. “This new coating will prevent droplets or microbes from sticking to a face shield. This makes disinfecting face shields feasible just with water rather than requiring complex disinfectant procedures.”</p>
<p>The original research was recently published in the <em><a href="https://pubs.acs.org/doi/full/10.1021/acsami.0c06433">ACS Applied Materials &amp; Interfaces</a></em> journal, with funding support from NSERC.</p>
<h3>About UBC's Okanagan campus</h3>
<p>UBC’s Okanagan campus is an innovative hub for research and learning founded in 2005 in partnership with local Indigenous peoples, the Syilx Okanagan Nation, in whose territory the campus resides. As part of UBC—ranked among the world’s top 20 public universities—the Okanagan campus combines a globally recognized UBC education with a tight-knit and entrepreneurial community that welcomes students and faculty from around the world in British Columbia’s stunning Okanagan Valley.</p>
<p>To find out more, visit:&nbsp;<a href="http://ok.ubc.ca/">ok.ubc.ca</a></p>
									</div></div>]]>
            </description>
            <link>https://news.ok.ubc.ca/2020/07/16/ubco-researchers-create-liquid-repelling-substance-that-works-on-all-surfaces/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882486</guid>
            <pubDate>Sat, 18 Jul 2020 16:26:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Logarithm for Complex Numbers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23882462">thread link</a>) | @R3G1R
<br/>
July 18, 2020 | https://mathvault.ca/logarithm-theory/#Logarithm_for_Complex_Numbers_(Optional) | <a href="https://web.archive.org/web/*/https://mathvault.ca/logarithm-theory/#Logarithm_for_Complex_Numbers_(Optional)">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://mathvault.ca/wp-content/uploads/Logarithm-Post.jpg" alt="The Ultimate Guide to Logarithm - Properties of Logarithm, Complex Logarithm and More!" width="800" height="480" title="Logarithm Post" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20800%20480'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/Logarithm-Post.jpg"></p><p>For the very vast majority of humans on earth, there is a topic found in the good&nbsp;old math textbooks that many of us still even dread contemplating about, as&nbsp;it seems to mess with our brain in a rather<em>&nbsp;particular</em> way.&nbsp; The name? <a href="https://en.wiktionary.org/wiki/logarithmus" target="_blank" rel="noopener noreferrer">$\displaystyle \text{Logarithmus}$</a> — or <strong>Logarithm</strong> in English to be sure!</p><p>As terrible-sounding as it is, logarithm seems to have this <em>distinct</em> characteristic of metaphorically leaving a <em>bad taste</em> in our mouth. In fact, even for those who managed to maneuver around&nbsp;it back in high school, logarithm still remains largely as an <em>evasive</em> concept. The <strong>“I-can-manipulate-expressions-without-understanding-anything” syndrome</strong>&nbsp;runs rampant when it comes to logarithm.</p><p>Indeed, here in North America, the&nbsp;grade school curriculum has the propensity of overemphasizing the&nbsp;<strong>mechanics</strong>&nbsp;at the expense of&nbsp;<strong>basic theory</strong>, leaving us with the <em>formidable</em> task of filling in the <em>logarithmic</em> knowledge gap, which includes — among others&nbsp;— the theory behind the <strong>properties of logarithm</strong>, and its intended <strong>computational use</strong> in handling&nbsp;numbers with an&nbsp;<strong>order of magnitude</strong> veering towards the extremes.</p><p>So with that in mind, if you think that the time might have finally come to tame this <em>monster</em> we call logarithm, then it would be our pleasure to congratulate your timing on this very honorable act. And if&nbsp;you are simply looking to&nbsp;explore further into the rabbit hole, that would be <em>doubly</em> appreciated as well, for regardless of your motivation, the <strong>taming</strong>/<strong>musing</strong> is on!&nbsp;&nbsp;🙂<span id="more-5976"></span></p><h2 id="review"><span id="Logarithm_%E2%80%94_A_Review"></span><a href="#toc">Logarithm — A Review</a><span></span></h2><h3 id="terms"><span id="Terminology"></span><a href="#toc">Terminology</a><span></span></h3><p>Given a <em>real number</em> $x$, one of the challenges in <strong>elementary algebra</strong> is to express $x$ as a <em>power</em> of another number $b$ (known as the <strong>base</strong>). More specifically, we are interested in finding a&nbsp;number $\Box$ such that:</p><p>\begin{equation*} x = b^\Box \end{equation*}</p><p>As it turns out, this problem — in the <em>crude</em> form that it currently is at least — needs to be patched up first&nbsp;before any meaningful discussion can take place. For example:</p><ul><li>If the base is <em>negative</em>, then its powers need not be necessarily&nbsp;<a href="https://mathvault.ca/math-glossary/#welldefined"><strong>well-defined</strong></a> (e.g., $\displaystyle (-e)^{\frac{1}{2}}$).</li><li>If the base is $\displaystyle 1$, then any power of it would be just $1$, in which case, it would be <em>impossible</em>&nbsp;for it to generate any&nbsp;number that’s not $1$. A&nbsp;similar remark applies to the case&nbsp;where&nbsp;the base is equal to $0$.</li></ul><p>For these reasons, in the context of <strong>power determination</strong>, it’s customary to require&nbsp;the&nbsp;base $b$ to be a <em>positive</em> number — that is not equal to $1$. While under this assumption, any power of $b$ would necessarily have to be <em>positive</em>, it would also transpire —under this setup — that <em>any</em>&nbsp;positive number can be expressed as a power of $b$ in a <em>unique</em> way. That is, as long as $x$ is <em>positive</em>, there will be a <em>unique</em> number $\Box$ (known as the&nbsp;<strong>exponent</strong>) such that:</p><p>\begin{equation*} x= b^{\Box} \end{equation*}</p><p>in which case, we will simply call $\Box$ the <strong>logarithm</strong> of $x$ (in base $b$). In other words, logarithm is basically what happens when we expressed a number as a <em>power</em>, and then take the <em>exponent</em> from that power —&nbsp;It gives&nbsp;us the <strong>magnitude</strong> of a number, with respect to the base in question.</p><p>For example, when we try to express the number $64$ as a power of $2$, we get that $64= 2^6$. This alone shows that $6$ is the logarithm of $64$ — &nbsp;with respect to the base $2$.</p><p>Notation-wise, the logarithm of $x$ in <strong>base</strong> $b$ is denoted by $\log_b x$, with $x$ also being called&nbsp;the <strong>argument</strong> of the logarithm. When considered as a function, $\log_b x$ is defined on all <em>positive</em> numbers — as long as&nbsp;the base $b$ is <strong>valid</strong> (i.e.,&nbsp;&nbsp;$\displaystyle b&gt;0, b \ne 1$) .</p><p>To begin,&nbsp;we first note that <em>regardless</em> of the value of the base $b$, we always have that:</p><ul><li>$\displaystyle \log_b 1 = 0$ (since $0$ is the number $b$ needs to be raised to yield $1$)</li><li>$\displaystyle \log_b b&nbsp;= 1$ (since $1$ is the number $b$ needs to be raised to yield $b$)</li><li>$\displaystyle \log_b \frac{1}{b} = -1$ (since $-1$ is the number $b$ needs to be raised to yield $\displaystyle \frac{1}{b}$)</li></ul><p>Because these results are almost immediate and sufficiently notable, we’ll simply&nbsp;refer to&nbsp;them as the&nbsp;<strong>trivial logarithmic identities</strong>.</p><p>In addition,&nbsp;since $\log_b x$ stands for the number which&nbsp;<em>exponentiates</em> to $x$, we also have that by definition:</p><p>\begin{align*}b^{\log_b x} &amp; = x \qquad (\text{for all }x&gt;0)\end{align*}</p><p>On the other hand,&nbsp;we also have that:</p><p>\begin{align*} \log_b (b^x) = x \qquad (\text{for all } x \in \mathbb{R}) \end{align*}</p><p>Since one can see by inspection that $x$ is precisely the number which exponentiates to $b^x$.</p><p>For&nbsp;example, since $\displaystyle \log_2 53$ is the number that $2$ needs to raise to yield $53$, we have that $\displaystyle 2^{\log_2 53} =53$. Similarly, since $\displaystyle 10^{-\pi}$ is a power of $10$ with the exponent $-\pi$, we can infer&nbsp;that $\displaystyle \log_{10} \left(10^{-\pi}\right) = -\pi$.</p><h3 id="10"><span id="Common_Logarithm_(Base_10)"></span><a href="#toc">Common Logarithm (Base 10)</a><span></span></h3><p>Being the inverse of the exponential function $\displaystyle 10^x$, the base-$10$ logarithmic function — also known as the&nbsp;<a href="https://en.wikipedia.org/wiki/Common_logarithm" target="_blank" rel="noopener noreferrer"><strong>common logarithm</strong></a> — is customarily denoted by $\log_{10} x$, $\log x$, or simply $\lg x$ for short. The common logarithm is of great interest to us, primarily&nbsp;due to the prevalence of the&nbsp;<strong>decimal number system</strong> in various cultures around the world.</p><div><p><strong>Caution</strong></p><p>Note that in older scientific texts and some textbooks in higher mathematics, $\log x$ can also refer to — and usually is — the <a href="#e">natural logarithm of base $e$</a>.</p></div><p>When the common logarithm of a number is calculated, the&nbsp;<em>decimal representation</em> of the logarithm is usually split into two parts: the integer component&nbsp;(a.k.a., <strong>characteristic</strong>) and the fractional component&nbsp;(a.k.a., <strong>mantissa</strong>). The characteristic in essence tells us &nbsp;the <strong>number of digits</strong> the original number has, and the mantissa hints at the extent to which this&nbsp;number is close to its next power of $10$. These are the facts that make common logarithm a&nbsp;particularly handy tool in determining the <strong>order of magnitude</strong> of an <em>exceptionally&nbsp;large</em> (or <em>small</em>) number.</p><p>For example, to figure out the magnitude of the number $50!$ (i.e., $50 \times \cdots \times 1$), we proceed to calculate its logarithm, yielding that: \[ \log (50!) \approx 64.483 \] which means that $50! \approx 10^{64.483} =$ $10^{64}10^{0.483} \approx$ $10^{64} \cdot 3.04$, suggesting that $50!$ is a $65$<em>-digit number</em> which starts with $3$ — the <strong>characteristic</strong> $64$ gives away the number of digits, and the <strong>mantissa</strong> $0.483$ reveals&nbsp;the rest about the number itself.</p><p>Take home message? There is no need to&nbsp;write out a number in full to figure out its <em>approximate size</em>!</p><h3 id="2"><span id="Binary_Logarithm_(Base_2)"></span><a href="#toc">Binary Logarithm (Base 2)</a><span></span></h3><p>Being the inverse of the exponential function $2^x$, the <a href="https://en.wikipedia.org/wiki/Binary_logarithm" target="_blank" rel="noopener noreferrer"><strong>binary logarithm</strong></a>&nbsp;function $\log_2 x$ is extensively used in the field of <strong>computer science</strong>, primarily due to the fact that computers store information in <strong>bits</strong> (i.e., digits which takes $0$ or $1$ as possible values).</p><p>Similar to the case in base $10$, binary logarithm can be used to figure out&nbsp;the number of digits&nbsp;of a positive integer&nbsp;in <a href="https://en.wikipedia.org/wiki/Binary_number#Counting_in_binary" target="_blank" rel="noopener noreferrer"><strong>binary representation</strong></a>. In addition, binary logarithm is also used to figure out the <em>depth</em> of a <a href="https://en.wikipedia.org/wiki/Binary_tree" target="_blank" rel="noopener noreferrer"><strong>binary tree</strong></a>, or even the <em>number of operations</em> required by certain <strong>computer algorithms</strong>&nbsp;(this falls into a topic known as&nbsp;<a href="https://en.wikipedia.org/wiki/Time_complexity" target="_blank" rel="noopener noreferrer"><strong>algorithmic time complexity</strong></a>).</p><p>Beyond&nbsp;the world of computers, binary logarithm is also used in&nbsp;<strong>music theory</strong> to conceptualize the <em>highness</em>&nbsp;of&nbsp;musical notes, based&nbsp;on the fundamental&nbsp;observation&nbsp;that <em>raising</em>&nbsp;a note by an <strong>octave</strong>&nbsp;increases the frequency of the note by&nbsp;<em>twofold</em>. As a result, it is often convenient to conceive a&nbsp;<strong>musical interval</strong>&nbsp;as the binary logarithm of the <a href="https://en.wikipedia.org/wiki/Interval_ratio" target="_blank" rel="noopener noreferrer"><strong>frequency ratio</strong></a>.</p><h3 id="e"><span id="Natural_Logarithm_(Base_$e$)"></span><a href="#toc">Natural Logarithm (Base $e$)</a><span></span></h3><p>In some textbooks concerned with a more rigorous development&nbsp;of&nbsp;<a href="https://en.wikipedia.org/wiki/Transcendental_function" target="_blank" rel="noopener noreferrer"><strong>transcendental functions</strong></a>, the base-$\displaystyle e$ logarithmic function — otherwise known as&nbsp;<strong>natural logarithm</strong>, $\log_e x$ or simply $\ln x$ — are sometimes defined as the <em>area</em>&nbsp;between the <strong>reciprocal function</strong>&nbsp;$\frac{1}{x}$ and the x-axis from $1$ to $x$ (hence the term <em>natural</em>).</p><div id="attachment_5991"><p><img aria-describedby="caption-attachment-5991" src="https://mathvault.ca/wp-content/uploads/Harmonic-Series.png" alt="Natural Logarithm and the Divergence of the Harmonic Series" width="295" height="230" title="Harmonic Series" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20295%20230'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/Harmonic-Series.png"></p><p id="caption-attachment-5991">Defined as the area underneath the reciprocal function, the function $\ln x$ increases without bound as $x$ increases, thereby showing that the <strong>Harmonic Series</strong> (i.e., $ \frac{1}{1} + \frac{1}{2}+ \ldots$ ) — whose area is even greater than that of $\ln x$ — diverges to $+ \infty$ as well.</p></div><p>Under this definition, it could be shown that the inverse of $\ln x$ is precisely the <strong>natural&nbsp;exponential function</strong> $e^x$, leading to the&nbsp;following&nbsp;<em>standard</em>&nbsp;definition of&nbsp;natural logarithm:</p><blockquote><h6>Given a positive number $x$,&nbsp;$\ln x$ denotes the number that $e$ needs to be raised, to&nbsp;become $x$.</h6></blockquote><p>Unlike the number $10$ — which is preferred due to the prevalence of&nbsp;<strong>decimal numbering system</strong> — the number $\displaystyle e$ is one of the <a href="https://mathvault.ca/hub/higher-math/math-symbols/#Constants" target="_blank" rel="noopener noreferrer">special constants</a>&nbsp;that&nbsp;pops up surprisingly often in various mathematical discourses —&nbsp;<em>irrespective</em> of the&nbsp;number system being chosen.&nbsp;As a result, mathematicians tend to consider base $e$ as more <em>natural</em> than base $10$ — even though some&nbsp;applied scientists and engineers beg to differ in various occasions…</p><p>Actually, to illustrate the scope of these&nbsp;<em>intellectual biases</em>&nbsp;among the scientific community, here’s an interesting account from <a href="https://en.wikipedia.org/wiki/Common_logarithm#History" target="_blank" rel="noopener noreferrer">Wikipedia</a>&nbsp;on the <strong>historical development</strong>&nbsp;of the&nbsp;notations for logarithms:</p><blockquote><h6>Because base 10 logarithms were most useful for computations, engineers generally simply wrote “log(x)” when they meant log<sub>10</sub>(x). Mathematicians, on the other hand, wrote “log(x)” when they meant log<sub>e</sub>(x) for the natural logarithm. Today, both notations are found. Since hand-held electronic calculators are designed by engineers rather than mathematicians, it became customary that they follow engineers’ notation. So the notation, according to which one writes “ln(x)” when the natural logarithm is intended, may have been further popularized by the very invention that made the use of “common logarithms” far less common, electronic calculators.</h6></blockquote><h3 id="arbitrary"><span id="Logarithm_of_an_Arbitrary_Base"></span><a href="#toc">Logarithm of an Arbitrary Base</a><span></span></h3><div id="attachment_6036"><p><img aria-describedby="caption-attachment-6036" src="https://mathvault.ca/wp-content/uploads/Graphs-of-Different-Logarithms.png" alt="Graphs of the Logarithmic Functions of base 2, e and 10" width="297" height="223" title="Graphs of Different Logarithms" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20297%20223'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/Graphs-of-Different-Logarithms.png"></p><p id="caption-attachment-6036">Graphs of the logarithmic functions of base $2$, $\displaystyle e$ and $10$. Note that&nbsp;<strong>binary logarithm</strong> attains $1$ when $x=2$, <strong>natural logarithm</strong>&nbsp;when $x=e$ and&nbsp;<strong>common logarithm</strong>&nbsp;only when $x=10$.</p></div><p>In addition to the three most …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mathvault.ca/logarithm-theory/#Logarithm_for_Complex_Numbers_(Optional)">https://mathvault.ca/logarithm-theory/#Logarithm_for_Complex_Numbers_(Optional)</a></em></p>]]>
            </description>
            <link>https://mathvault.ca/logarithm-theory/#Logarithm_for_Complex_Numbers_(Optional)</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882462</guid>
            <pubDate>Sat, 18 Jul 2020 16:24:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cloudflare outage and the risk in today's Internet]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23882417">thread link</a>) | @g-garron
<br/>
July 18, 2020 | https://www.garron.blog/posts/cloudflare-outage.html | <a href="https://web.archive.org/web/*/https://www.garron.blog/posts/cloudflare-outage.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <h2 id="introduction">Introduction</h2>

<p>There was a time when the Internet was a Network of small computers interconnected running different services, mainly web servers, email servers and DNS servers, oh, and FTP cannot be forgetten.</p>

<p>In those days, a network failure or power outage only affected a small portion of the Internet, of course that Internet was small, like really small compared to today's standards.</p>

<p>But then, it came Geocities, and Yahoo, Reddit and of course Google, what happened is that most of us decided that instead of hosting our own services and dealing with all the hassle, just put them in some other's hands.</p>

<h2 id="how-did-this-happen">How did this happen?</h2>

<p>At the beginning, the Internet was only visible to engineers and tech people, to the rest of the population was unknown, or just not important at all. When marketeers saw the potential of being on-line a lot of non-technical people in the need to be on-line required professional services to set up their servers and just be on-line, and of course have an email address.</p>

<p>The first dial-up service providers at those days gave you an email address at their domain, and usually your own home folder in their Linux server mapped through Apache to your own web space.</p>

<p>Then, some visionaries saw the potential of business, and Hotmail came to the word. Now if you do not know how to host your email server, you were not tied to your service provider just because they have your email address tied to their domains.</p>

<p>Well, Gmail came too, as Google realized that they can read everybody's email if they offered a free service.</p>

<p>At that moment, a lot of more people was on the Internet, and then the <em>bad guys</em> also realized they can make money there, and started to hack servers, started Phishing and making it hard to host your email server, or your DNS server, just because everybody wanted to hack them and use them to scam others.</p>

<p>We all realized that it was to much of a headache to self-host, and almost everybody started to host on third parties, so much that now we have to use self-host, when <strong>host</strong> should mean <strong>self-host</strong> and the opposite should bit <strong>outsource hosting</strong>.</p>

<h2 id="the-internet-is-small-again">The Internet is small again</h2>

<p>Yes, we have return to a small Internet, it is big in number of websites, pages, content and all the fiber optic cable linking those servers, actually Data Centers full of servers, full in turn of VPSs or Containers… But small in the number of owners of the infrastructure, even smaller that in the first days.</p>

<p>Facebook, Google, Amazon, Cloudflare and Apple concentrate almost all Internet traffic and hosting services. To the point that some people might think that the Internet is Facebook. Some small companies does not even have a website anymore, they just have Facebook page, they do not publish their email on cards, just their Facebook page, and use Facebook Messenger to get contacted by their customers.</p>

<h2 id="how-is-that-bad">How is that bad</h2>

<p>That is bad in such a variety of ways that this post will not be enough to name them, but let us name a few.</p>

<ul>
  <li><strong>Lose of identity</strong>: If you do not <a href="https://www.garron.blog/posts/own-your-domain.html">own your domain</a>, you can be out of business and any time, when Facebook or whoever your are trusting decide its time for you to go out of business.</li>
  <li><strong>Privacy</strong>: You will have to trust Google, Facebook and others not to "read" your private messages, and you can be sure they are doing exactly that.</li>
</ul>

<h2 id="cloudflare-outage">Cloudflare Outage</h2>

<p>But what happened yesterday shows us the potential risks. Yesterday one of the biggest provider of the Internet <strong>Cloudflare</strong> had a technical issue, some of their engineers made a mistake and instead of routing traffic away of an overloaded server (router), did just the opposite and sent all traffic to one creating a bottleneck and <em>turning part of the Internet off</em>.</p>

<p>So many companies, some big ones like Discord, Shopify and others use Cloudflare's services that as said, a big portion of Internet was down yesterday afternoon.</p>

<p>Yesterday was a mistake, an engineer typed the wrong command, and that can will happen again, but what about Google+, and <a href="https://killedbygoogle.com/">a lot of other services</a>, only on Google's hands.</p>

<h2 id="the-risks">The risks</h2>

<p>We as users are putting are eggs in just some few baskets, even small providers buy services from the big ones to offer their services. Every small to medium service provider is on AWS or Azure or Google Cloud.</p>

<p>Are we ready to be on their hands?, we actually are their hands already, they can squeeze us anytime. We as users should try to diversify the Internet again.</p>

<p>What would happen if one of those big companies once they gain full control decide what should or should not be on the Internet, Google already has that power.</p>

<p>The risks are big, <strong>we may lose our freedom</strong></p>

<h2 id="final-words">Final Words</h2>

<p>What can we do about that?</p>

<p>Well start by owning your domain, try to host your services with small companies instead of the big ones, avoid if you can AWS, Cloudflare, and if you are really brave, try to host your own services, your own DNS, your own email servers.</p>

<p>I know I should start doing that myself, I have some domains at Cloudflare, used to use AWS DNS server too, I have a Gmail accout, and my main email address is hosted at Google but at least using my own domain.</p>

<p>I do host my web servers (on a VPS, because the Internet in my country is not the best), and my social network by hosting my own Mastodon Instance.</p>

<p>Next steps is hosting my email server, and maybe my DNS server, or at least moving it to a smaller provider.</p>


        </div></div>]]>
            </description>
            <link>https://www.garron.blog/posts/cloudflare-outage.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882417</guid>
            <pubDate>Sat, 18 Jul 2020 16:19:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Closing Hong-Kong]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23882332">thread link</a>) | @dgellow
<br/>
July 18, 2020 | https://www.persuasion.community/p/closing-hong-kong | <a href="https://web.archive.org/web/*/https://www.persuasion.community/p/closing-hong-kong">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a target="_blank" href="https://cdn.substack.com/image/fetch/c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F0b824b1f-5487-4307-b412-3de0f72c8cd0_8256x5504.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F0b824b1f-5487-4307-b412-3de0f72c8cd0_8256x5504.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/0b824b1f-5487-4307-b412-3de0f72c8cd0_8256x5504.jpeg&quot;,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:23546462,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p>The world’s only museum dedicated to the Tiananmen Square massacre sits in a single room, scarcely larger than a studio apartment, midway up an anonymous office building in Hong Kong’s bustling Mong Kok district.</p><p>The June 4th Museum, as it is officially known, dedicates most of its limited space to pressing an urgent analogy. Adorning a long wall are two timelines, one above the other: Beijing in 1989, Hong Kong in 2019, with the two moments matched up beat for beat. A few feet to the left are the self-authored wills of students, trying to explain to their grieving families why they had to risk their lives in Tiananmen Square. And, beside them, similar letters from protestors in Hong Kong, written late last year as tear gas filled the streets, university campuses were besieged, and police violence ran rampant. The overall message is clear: these two revolts should be spoken of in the same breath. </p><p>But over the past few weeks, another Tiananmen parallel has begun to suggest itself—one that you certainly won’t find celebrated in the June 4th Museum. In late June, the Chinese government imposed a National Security Law, which criminalizes “subversion”—carrying pro-independence stickers can mean jail time—and grants China’s notorious security services an open foothold in the city. If Hong Kong’s 2019 was like Beijing’s 1989, what does that mean for the Hong Kong of the 2020s and 2030s? Will Hong Kong, which has long cherished its boisterously free civic culture, come to look like Beijing in the years after the tanks rolled into the square? </p><p>Outside China, history mainly remembers Tiananmen Square for the protestors who were massacred and the intellectuals who spent decades in prison or exile. But most of those who were involved do not fit that description. Instead, gradually and often uncomfortably, hundreds of thousands of protestors slowly made peace with the status quo and found ways to accommodate themselves to the system. “I know for a fact that some of them are multimillionaires,” Tiananmen leader Chen Ziming has <a href="https://www.google.com/books/edition/The_People_s_Republic_of_Amnesia/MXVYAwAAQBAJ?hl=en&amp;gbpv=1&amp;bsq=chen%20ziming">said of his former comrades</a>. “They won’t even admit to having been student leaders.”</p><p>Wang Shi, the founder of one of the world’s largest real estate companies, <a href="https://www.washingtonpost.com/wp-srv/inatl/daily/june99/tiananmen5.htm">once told the </a><em><a href="https://www.washingtonpost.com/wp-srv/inatl/daily/june99/tiananmen5.htm">Washington Post</a></em> that he was imprisoned for leading an employee march for freedom in 1989. Today, <a href="https://www.google.com/books/edition/The_People_s_Republic_of_Amnesia/MXVYAwAAQBAJ?hl=en&amp;gbpv=1&amp;bsq=chen%20ziming">he</a> <a href="https://www.wsj.com/articles/how-china-vanke-chiefs-state-savior-could-be-his-undoing-1469127600">denies</a> that it ever happened. </p><p>Could the same cocktail of terror and self-interest that all but stamped out a nascent liberal moment in China succeed against Hong Kong’s more established civic traditions? The question has global resonance. As nations from Poland to Brazil grapple with whether the institutions of liberal democracy can survive an increasingly illiberal electorate, Hong Kong presents the inverse question: can a society’s liberalism survive a government determined to stamp it out? </p><p data-attrs="{&quot;url&quot;:&quot;https://www.persuasion.community/p/closing-hong-kong?&amp;utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;class&quot;:null}"><a href="https://www.persuasion.community/p/closing-hong-kong?&amp;utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share"><span>Share</span></a></p><p>For many years, outsiders assumed that Hong Kong would always value economic growth over political freedom. But the 2014 Umbrella protests put this notion to rest. As Joshua Wong, the city’s most famous pro-democracy activist, told me in 2017, during the unsteady détente that followed the protests: “we proved to the world that Hong Kongers are ready for democracy.”</p><p>Last week, I repeated my question to Wong. Would the National Security Law finally push Hong Kong into fulfilling that old stereotype? As a politician in his position must, he remained hopeful. “They are unable to censor away all the memories of Hong Kong’s people in the past few years,” Wong said. In fact, he claimed, Hong Kong’s political resilience is tied to its economic vitality: “With [China’s] economic reliance on Hong Kong, Hong Kong people still have the leverage to fight for a greater degree of autonomy and choose not to kowtow to Beijing.”</p><p>But recent events belie Wong’s optimism. The day the National Security Law was passed, Wong and his allies quickly dismantled Demosistō, the pro-democracy party he led. Scores of activists fled Twitter in fear. Even the usually apolitical investment analysts based in Hong Kong began to wonder whether they might risk a visit from the police if they dared to criticize Chinese companies.</p><p>Most dishearteningly, the past weeks have made it clear that the National Security Law is pulling apart not only Hong Kong’s liberal political institutions, but also the wider constellation of organizations that sustain its civic culture. </p><p>One telling microcosm is the local high school debating scene. Hong Kong’s national team ranks among the best in the world. But that proud tradition may soon be coming to an end: the charity that runs the national team is closing up shop. “There’s no way we can continue under the present environment,” one insider told me. “But we can’t suggest that this is related to the National Security Law because that would bring unwanted attention to some of our teachers. We’re already seeing schools axe their debating programs out of fear, and presumably parents will also start withdrawing their children as the ramifications of the law sink in.”</p><p>Given the circumstances, few can fault parents and teachers for withdrawing students from an activity whose purpose is to discuss controversial topics. But the inevitable result is that Hong Kong’s local debating league, which has taught tens of thousands of schoolchildren to think critically and argue carefully, could soon be no more.</p><p>To better understand the situation in Hong Kong’s schools, I spoke to Raymond Yeung, until this summer a teacher at an elite Hong Kong girls’ school. Yeung was blinded in one eye by the police at a pro-democracy protest last year. Then he lost his job after his school cut back the curriculum for Liberal Studies, a subject designed to teach students civics and critical thinking. </p><p>Yeung’s summary was succinct: “The situation is quite grim.” Even before the National Security Law, pro-establishment groups regularly organized public denunciations of teachers deemed too sympathetic to the protests. Now, the future is even more uncertain. “We really don’t know what will happen in the next school year,” Yeung said. “The government is trying very hard to control the discussion of political issues in schools.” </p><p>Hong Kong’s authorities are currently reviewing the textbooks used to teach Liberal Studies. “Those books that have been reviewed will need to remove much information about the political situation in Hong Kong. We teachers dare not mention these issues anymore.”</p><p data-attrs="{&quot;url&quot;:&quot;https://www.persuasion.community/?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share Persuasion&quot;,&quot;class&quot;:null}"><a href="https://www.persuasion.community/?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share"><span>Share Persuasion</span></a></p><p>The leitmotif of Hong Kong’s future is becoming clear: spaces for discussion and debate continue to narrow. But the city’s underlying political, cultural and economic grievances remain unchanged. “In the end, the anger is still here,” Yeung stressed. </p><p>Decades of broken Chinese promises and the whiplash of the past twelve months will not be easily forgotten. Perhaps Hong Kong’s unique culture, binding together a powerful sense of Cantonese identity with decades lived under a free press and independent judiciary, will survive the current onslaught. But as those brave students in Tiananmen Square found out in 1989, hopes and hypotheticals offer scant protection against the raw power of the Chinese state.</p><p><strong>Archie Hall is a writer from London and Hong Kong.</strong></p></div></div>]]>
            </description>
            <link>https://www.persuasion.community/p/closing-hong-kong</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882332</guid>
            <pubDate>Sat, 18 Jul 2020 16:08:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debugging a dynamic linking bug in a Nix project]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23882277">thread link</a>) | @johnbcoughlin
<br/>
July 18, 2020 | https://www.johnbcoughlin.com/posts/nix-dynamic-linking/ | <a href="https://web.archive.org/web/*/https://www.johnbcoughlin.com/posts/nix-dynamic-linking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
            

            

<h2 id="trying-out-the-nix-development-experience">Trying out the Nix development experience</h2>
<p>The other day, while building a <a href="https://faculty.washington.edu/shumlak/WARPX/html/index.html">scientific project</a> to which I’m a contributor, I
ran into a nasty version conflict between two system libraries. In a fit of
pique, I decided to learn enough about <a href="https://nixos.org/">Nix</a> to be able to set up a reproducible,
tightly controlled local build. It’s done now, and overall I’m very happy with
the tooling and setup. I’m using <a href="https://direnv.net/">direnv</a> to tightly integrate my normal shell
with Nix’s <code>nix-shell</code> feature, and for the most part everything feels seamless.
It is extremely refreshing to see <code>cmake</code> report that it has found a plethora of
binaries and libraries, content-hashed and installed in neat little rows under
<code>/nix/store</code>.</p>
<p>I’m using Nix to manage my development environment, but <em>not</em> to build the
project itself. Nix ensures that the project dependencies are installed and
discoverable by the compiler and linker. Building the project is done with
CMake, set up for <code>cmake</code> to find the nix-installed libraries. Nix achieves this
by <a href="https://nixos.wiki/wiki/C#The%5Fcompiler%5Fwrapper">wrapping the C compiler</a> with its own shell script and injecting the paths to
libraries and binaries via environment variables. There’s very little to do to
make <code>cmake</code> just work, beyond declaring that the packages you want are
<code>buildInputs</code>. The first version of my <code>shell.nix</code> file looked like this:</p>
<div><pre><code data-lang="nix"><span># file shell.nix</span>
{ <span>pkgs</span> ? <span>import</span> <span>&lt;nixpkgs&gt;</span> {} }:

<span>pkgs</span>.<span>mkShell</span> {
  <span>buildInputs</span> = <span>with</span> <span>pkgs</span>; [
    <span>cmake</span>
    (<span>callPackage</span> <span>nix/petsc.nix</span> {})
    <span>metis</span>
    <span>hdf5</span>
    <span>openmpi</span>
    (<span>python38</span>.<span>withPackages</span> (<span>packages</span>: [ <span>packages</span>.<span>numpy</span> ]))
  ];
}
</code></pre></div><p>Using this setup, I had very little trouble getting the project to build. I had
to <a href="https://nixos.org/nixos/nix-pills/nixpkgs-overriding-packages.html">override</a> the <a href="https://github.com/NixOS/nixpkgs/blob/master/pkgs/development/libraries/science/math/petsc/default.nix">default PETSc derivation</a> to compile with METIS and OpenMPI
support, which was not too hard:</p>
<div><pre><code data-lang="nix"><span># file nix/petsc.nix</span>
{ <span>petsc</span> , <span>blas</span> , <span>gfortran</span> , <span>lapack</span> , <span>python</span> , <span>metis</span> , <span>openmpi</span> }:

<span>petsc</span>.<span>overrideAttrs</span> (<span>oldAttrs</span>: <span>rec</span> {
    <span>nativeBuildInputs</span> = [ <span>blas</span> <span>gfortran</span> <span>gfortran</span>.<span>cc</span>.<span>lib</span> <span>lapack</span> <span>python</span> <span>openmpi</span> <span>metis</span> ];
    <span>preConfigure</span> = <span>''
</span><span>        export FC="</span><span>${</span><span>gfortran</span><span>}</span><span>/bin/gfortran" F77="</span><span>${</span><span>gfortran</span><span>}</span><span>/bin/gfortran"
</span><span>        patchShebangs .
</span><span>        configureFlagsArray=(
</span><span>        $configureFlagsArray
</span><span>        "--with-mpi-dir=</span><span>${</span><span>openmpi</span><span>}</span><span>"
</span><span>        "--with-metis=</span><span>${</span><span>metis</span><span>}</span><span>"
</span><span>        "--with-blas-lib=[</span><span>${</span><span>blas</span><span>}</span><span>/lib/libblas.so,</span><span>${</span><span>gfortran</span>.<span>cc</span>.<span>lib</span><span>}</span><span>/lib/libgfortran.a]"
</span><span>        "--with-lapack-lib=[</span><span>${</span><span>lapack</span><span>}</span><span>/lib/liblapack.so,</span><span>${</span><span>gfortran</span>.<span>cc</span>.<span>lib</span><span>}</span><span>/lib/libgfortran.a]"
</span><span>        )
</span><span>    ''</span>;
})
</code></pre></div><p>This Nix file returns a function which is invoked in <code>shell.nix</code> using
<code>callPackage</code> function. <code>petsc.overrideAttrs</code> is a neat way to override the
attributes of a derivation created with <code>stdenv.mkDerivation</code>. Building PETSc
with MPI and METIS support is as simple as passing in a different set of
arguments to the <code>configure</code> script.</p>
<p>Figuring out how to do all of this was fun. I mostly referred to the <a href="https://nixos.org/nixos/nix-pills/index.html">Nix
“Pills”</a>, which are a great progression through the Nix tool and language.</p>
<p>With these Nix files, I was able to execute <code>cmake .. &amp;&amp; make</code> successfully.
Getting the project to <em>run</em> was another story. The final binary failed
immediately with a dynamic loading error:</p>
<div><pre><code data-lang="bash">âžœ bin/warpxm
dyld: Library not loaded: /private/tmp/nix-build-petsc-3.13.2.drv-0/petsc-3.13.2/arch-darwin-c-debug/lib/libpetsc.3.13.dylib
  Referenced from: /Users/jack/src/warpxm/build/bin/warpxm
  Reason: image not found
</code></pre></div><p>The binary was trying to load a dynamic lib from one of the temporary directories
that Nix created in the process of building PETSc. Of course this failed: by the
time I invoked <code>bin/warpxm</code>, that directory had been cleaned up. Instead of a
file under <code>/private/tmp</code>, the binary should have linked to the result of the
<code>petsc</code> derivation in the Nix store, under <code>/nix/store</code>. At some point, it
seemed, an environment variable was incorrectly set to this intermediate
directory. To figure out where, I would have to learn a lot more about linking
on OS X than I ever expected.</p>
<h2 id="whither-the-linker">Whither the linker?</h2>
<p>First I checked the compiler and linker flags that are inserted by Nix’s
compiler wrapper. These come in via <code>NIX_CFLAGS_COMPILE</code> and <code>NIX_LDFLAGS</code>. When
you’re working with <code>nix-shell</code> and <code>direnv</code>, all of the environment variables
from your derivations are injected into your shell. It’s a simple matter of echoing
them out:</p>
<div><pre><code data-lang="bash">âžœ <span>echo</span> <span>$NIX_CFLAGS_COMPILE</span>
... -isystem /nix/store/w23r8kplmfx2xc111cpvmdjwmkwy6ip3-petsc-3.13.2/include ...
âžœ <span>echo</span> <span>$NIX_LDFLAGS</span>
... -L/nix/store/w23r8kplmfx2xc111cpvmdjwmkwy6ip3-petsc-3.13.2/lib ...
</code></pre></div><p>These look fine! Invoking <code>cmake</code> and <code>make</code> in this shell ought to pull in the
correct library.</p>
<p>Then I remembered that this project uses <code>pkg-config</code> to find and pull together
the linked libraries. Frankly, I don’t understand <code>pkg-config</code> very well, but I
do know that in this project it is invoked from inside of <code>cmake</code>. It searches for
libraries according to its own rules, and it runs <em>after</em> Nix has done its
job setting everything up. Therefore, it circumvents the compiler and linker
flags that we just checked.</p>
<p>I happened to have <code>pkg-config</code> installed from before setting up this Nix
environment. Therefore, <code>cmake</code> was able to invoke the system <code>pkg-config</code> from
my user <code>PATH</code>. Perhaps the system version of <code>pkg-config</code> was somehow finding
the wrong library? Indeed, <code>echo $PKG_CONFIG_PATH</code> confirmed that it was
searching a directory under my <code>$HOME</code>. I thought it possible that some wires
got crossed while I was adding dependencies to my Nix derivation one at a time:
configuring <code>pkg-config</code> appropriately might help.</p>

<p>I referred once again to the Nix wiki page on C projects, which also has <a href="https://nixos.wiki/wiki/C#pkg-config">a
section</a> on using <code>pkg-config</code>. It seems that including the <code>pkg-config</code>
derivation as a <code>nativeBuildInput</code> will let packages like <code>petsc</code> append their
output paths to the <code>PKG_CONFIG_PATH</code> environment variable. I did so:</p>
<div><pre><code data-lang="nix"><span>pkgs</span>.<span>mkShell</span> {
  <span>buildInputs</span> = <span>with</span> <span>pkgs</span>; [
    ...
  ];
  <span>nativeBuildInputs</span> = <span>with</span> <span>pkgs</span>; [
    <span>pkg-config</span>
  ];
}
</code></pre></div><p>but it didn’t fix the problem. I would have to go deeper and track down where
the bad library was being pulled in.</p>
<p>Digging into the <code>cmake</code> documentation and the project’s <code>.cmake</code> files led me
to insert a trio of print statements:</p>
<div><pre><code data-lang="diff">find_package(PkgConfig REQUIRED)
pkg_check_modules(PETSC PETSc REQUIRED)

link_directories(${PETSC_LIBRARY_DIRS})
<span>+ message("petsc libraries: ${PETSC_LIBRARIES}")
</span><span>+ message("petsc library dirs: ${PETSC_LIBRARY_DIRS}")
</span><span>+ message("petsc link libraries: ${PETSC_LINK_LIBRARIES}")
</span><span></span>list(APPEND WARPXM_LINK_TARGETS ${PETSC_LIBRARIES})
</code></pre></div><p>These printed out three lines in my <code>cmake</code> output:</p>
<div><pre><code data-lang="text">petsc libraries: petsc
petsc library dirs: /nix/store/w23r8kplmfx2xc111cpvmdjwmkwy6ip3-petsc-3.13.2/lib
petsc link libraries: /nix/store/w23r8kplmfx2xc111cpvmdjwmkwy6ip3-petsc-3.13.2/lib/libpetsc.dylib
</code></pre></div><p>The second two look good. But the first, just the library name <code>petsc</code>, was a little too
implicit for comfort. It was precisely this variable that was being appended
to the link targets list. At <em>compile</em> time, it would be up to the linker to find
the library <code>petsc</code>, and I wasn’t sure where it would look. Safer to use the
absolute path to the <code>.dylib</code>, like so:</p>
<div><pre><code data-lang="diff"><span>- list(APPEND WARPXM_LINK_TARGETS ${PETSC_LIBRARIES})
</span><span></span><span>+ list(APPEND WARPXM_LINK_TARGETS ${PETSC_LINK_LIBRARIES})
</span></code></pre></div>
<p>Changing the link target to the absolute path eased my mind only for the duration of
the next <code>cmake .. &amp;&amp; make</code> cycle. Surely there was no way the linker could
screw up now. No arcane library search involved, just an absolute path, which
couldn’t possibly be misinterpreted…</p>
<div><pre><code data-lang="bash">âžœ bin/warpxm
dyld: Library not loaded: /private/tmp/nix-build-petsc-3.13.2.drv-0/petsc-3.13.2/arch-darwin-c-debug/lib/libpetsc.3.13.dylib
  Referenced from: /Users/jack/src/warpxm/build/bin/warpxm
  Reason: image not found
</code></pre></div><p>Damn it!</p>
<h2 id="install-name-and-other-depravities">install_name and other depravities</h2>
<p>At this point I was absolutely flummoxed. With every fix I attempted, I
grepped vainly for the offending <code>/private/tmp</code> path in my build directory, and come up
empty-handed. I tracked down the final, irrevocable link options passed to the
compiler, tucked away in a <code>link.txt</code> file in the build tree. They showed
incontrovertibly that my binary was being linked to the correct library:</p>
<div><pre><code data-lang="text">âžœ cat build/src/CMakeFiles/warpxm.dir/link.txt
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++     -O3 -DNDEBUG -isysroot ... -L/nix/store/31d3hng4sclxi3sz8g3zi3yqmychj2kg-petsc-3.13.2/lib ...
</code></pre></div><p>I had proved nearly to my satisfaction that CMake was doing the right thing with
this library, and I was completely out of ideas.
Finally, a very lucky google search led me to the <a href="https://nixos.org/nixpkgs/manual/#sec-darwin">section</a> of the Nix manual
describing issues specific to the Darwin (MacOS) platform. It states:</p>
<blockquote>
<p>On Darwin, libraries are linked using absolute paths, libraries are resolved
by their install_name at link time. Sometimes packages won’t set this
correctly causing the library lookups to fail at runtime. This can be fixed by
adding extra linker flags or by running install_name_tool -id during the
fixupPhase.</p>
</blockquote>
<p>This is a very matter-of-fact way of stating something that, when I understood
it, flabbergasted me. To the best of my understanding, here’s what happens on
MacOS:</p>
<ul>
<li>My source code has an include directive, <code>include&lt;petsc.h&gt;</code> or something like
that, which creates a binary interface to be satisfied by the linker.</li>
<li>At link time, we pass the list of absolute paths to libraries, and the linker
finds the one that matches the interface.</li>
<li>The linker then saves the <em>install_name</em> of the library it found in the
binary’s load section.</li>
<li>At run time, the binary (actually, the MacOS <code>dyld</code> system) loads the library.
The install_name is all it has, so it looks there.</li>
</ul>
<p>I’ve certainly gotten some aspect of this wrong, so I would definitely
appreciate hearing from someone who understands it better than me!</p>
<p>In any case, this find pointed me to the concept of the install_name, so I had
something to go on. More searching led to a <a href="http://log.zyxar.com/blog/2012/03/10/install-name-on-os-x/">helpful blog post</a> describing exactly
the issue that I was facing. It also described how to check the install_name of
the library:</p>
<div><pre><code data-lang="text">âžœ otool -D /nix/store/31d3hng4sclxi3sz8g3zi3yqmychj2kg-petsc-3.13.2/lib/libpetsc.dylib</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.johnbcoughlin.com/posts/nix-dynamic-linking/">https://www.johnbcoughlin.com/posts/nix-dynamic-linking/</a></em></p>]]>
            </description>
            <link>https://www.johnbcoughlin.com/posts/nix-dynamic-linking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882277</guid>
            <pubDate>Sat, 18 Jul 2020 16:01:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: OneBoard – minimal hack to use OneNote as a double whiteboard]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23882267">thread link</a>) | @xworld21
<br/>
July 18, 2020 | https://xworld21.github.io/OneBoard/ | <a href="https://web.archive.org/web/*/https://xworld21.github.io/OneBoard/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

      

<blockquote>
  <p>Full screen whiteboard with OneNote Online</p>
</blockquote>

<p><img src="https://img.shields.io/github/v/release/xworld21/OneBoard?sort=semver&amp;style=social" alt="GitHub release"> <a href="https://github.com/xworld21/OneBoard"><img src="https://img.shields.io/github/stars/xworld21/OneBoard.svg?style=social" alt="GitHub stars"></a> <a href="https://github.com/xworld21/OneBoard/watchers/"><img src="https://img.shields.io/github/watchers/xworld21/OneBoard.svg?style=social" alt="GitHub watchers"></a></p>

<p>This is a minimal CSS hack that transforms OneNote Online into a full screen whiteboard with laser pointer. With the “Split Vertically” bookmarklet below, you may also present OneNote as <em>two</em> sliding whiteboards.</p>

<p>The intended use case is to run OneBoard in “Presentation mode”, while you write and annotate your page on another window or another device. See below for additional modes that let you work directly on the page but still maximise the content.</p>

<p><strong>BEWARE:</strong> this is a hack that relies on ids and classes in the HTML delivered by Microsoft. Parts may break at any moment, although hopefully not very often.</p>

<figure>
  <img src="https://xworld21.github.io/OneBoard/demo/OneBoardDemo@540.gif" srcset="https://xworld21.github.io/OneBoard/demo/OneBoardDemo@540.gif, https://xworld21.github.io/OneBoard/demo/OneBoardDemo@1080.gif 2x">
  <figcaption>Presentation mode, split vertically</figcaption>
</figure>

<hr>

<figure>
  <img src="https://xworld21.github.io/OneBoard/demo/OneBoardDemo-Disabled@540.png" srcset="https://xworld21.github.io/OneBoard/demo/OneBoardDemo-Disabled@540.png, https://xworld21.github.io/OneBoard/demo/OneBoardDemo-Disabled@1080.png 2x">
  <figcaption>Normal OneNote, with OneBoard disabled</figcaption>
</figure>

<h3 id="bugs-and-limitations">Bugs and limitations</h3>

<ul>
  <li>OneNote notebooks live inside an iframe with origin <code>*onenote.officeapps.live.com</code>. The current version of this UserCSS applies to iframes from the domains <code>onenote.officeapps.live.com</code> and <code>${region}-onenote.officeapps.live.com</code> for <code>${region}</code> in <code>euc,ukc,usc</code>.</li>
  <li>The settings might change shape in the future. If you are not using the defaults, you should disable automatic updates for OneBoard in Stylus.</li>
</ul>

<p>To report bugs or changes in behavior, request more servers, or suggest new functionality please file an <a href="https://github.com/xworld21/OneBoard/issues">issue</a> or send a <a href="https://github.com/xworld21/OneBoard/pulls">pull request</a>.</p>

<h2 id="installation">Installation</h2>

<p>Install the <a href="https://github.com/openstyles/stylus">Stylus</a> extension for your browser (Chrome, the new Edge, Firefox, or Opera), then open the <a href="https://xworld21.github.io/OneBoard/OneBoard.user.css">stylesheet</a> and click on “Install”. After installation, your OneNote pages will appear in presentation mode with no navigation panel and no scrollbars.</p>

<p>To have two side-by-side sliding whiteboards, drag the following link to your bookmark bar (the link is disabled when visiting the github repo – visit the <a href="https://xworld21.github.io/OneBoard">OneBoard</a> page to see the link)</p>

<p>
  Split Vertically
</p>

<p>or create manually a bookmark called “Split Vertically” with the following URL:</p>

<div><div><pre><code><span>javascript</span><span>:(</span><span>function</span><span>(){</span><span>var</span> <span>e</span><span>=</span><span>document</span><span>,</span><span>i</span><span>=</span><span>e</span><span>.</span><span>title</span><span>;</span><span>e</span><span>.</span><span>head</span><span>.</span><span>innerHTML</span><span>=</span><span>e</span><span>.</span><span>body</span><span>.</span><span>innerHTML</span><span>=</span><span>""</span><span>,</span><span>e</span><span>.</span><span>title</span><span>=</span><span>i</span><span>;</span><span>var</span> <span>t</span><span>=</span><span>e</span><span>.</span><span>createElement</span><span>(</span><span>"</span><span>meta</span><span>"</span><span>);</span><span>t</span><span>.</span><span>name</span><span>=</span><span>"</span><span>viewport</span><span>"</span><span>,</span><span>t</span><span>.</span><span>content</span><span>=</span><span>"</span><span>width=device-width, height=device-height, initial-scale=1</span><span>"</span><span>,</span><span>e</span><span>.</span><span>head</span><span>.</span><span>appendChild</span><span>(</span><span>t</span><span>);</span><span>var</span> <span>d</span><span>=</span><span>e</span><span>.</span><span>querySelector</span><span>(</span><span>"</span><span>html</span><span>"</span><span>).</span><span>style</span><span>,</span><span>a</span><span>=</span><span>e</span><span>.</span><span>body</span><span>,</span><span>l</span><span>=</span><span>a</span><span>.</span><span>style</span><span>;</span><span>d</span><span>.</span><span>width</span><span>=</span><span>d</span><span>.</span><span>height</span><span>=</span><span>l</span><span>.</span><span>width</span><span>=</span><span>l</span><span>.</span><span>height</span><span>=</span><span>"</span><span>100%</span><span>"</span><span>,</span><span>l</span><span>.</span><span>margin</span><span>=</span><span>l</span><span>.</span><span>padding</span><span>=</span><span>"</span><span>0</span><span>"</span><span>;</span><span>var</span> <span>n</span><span>=</span><span>e</span><span>.</span><span>createElement</span><span>(</span><span>"</span><span>iframe</span><span>"</span><span>);</span><span>l</span><span>.</span><span>display</span><span>=</span><span>"</span><span>flex</span><span>"</span><span>;</span><span>var</span> <span>r</span><span>=</span><span>n</span><span>.</span><span>style</span><span>;</span><span>n</span><span>.</span><span>src</span><span>=</span><span>window</span><span>.</span><span>location</span><span>,</span><span>r</span><span>.</span><span>flex</span><span>=</span><span>"</span><span>0 0 50%</span><span>"</span><span>,</span><span>r</span><span>.</span><span>border</span><span>=</span><span>"</span><span>none</span><span>"</span><span>,</span><span>r</span><span>.</span><span>boxSizing</span><span>=</span><span>"</span><span>border-box</span><span>"</span><span>;</span><span>var</span> <span>o</span><span>=</span><span>n</span><span>.</span><span>cloneNode</span><span>();</span><span>r</span><span>.</span><span>borderRight</span><span>=</span><span>"</span><span>solid 2px black</span><span>"</span><span>,</span><span>o</span><span>.</span><span>style</span><span>.</span><span>borderLeft</span><span>=</span><span>"</span><span>solid 2px black</span><span>"</span><span>,</span><span>a</span><span>.</span><span>appendChild</span><span>(</span><span>n</span><span>),</span><span>a</span><span>.</span><span>appendChild</span><span>(</span><span>o</span><span>)})();</span>
</code></pre></div></div>

<p>Clicking on the bookmark will split the page you are browsing into two vertical copies. You can inspect the source code of the above minified Javascript in <a href="https://github.com/xworld21/OneBoard/SplitVertically.js">SplitVertically.js</a>.</p>

<h2 id="usage">Usage</h2>

<p>After installation, your OneNote pages will appear in Presentation mode. If you want two whiteboards side-by-side, click on the “Split Vertically” bookmark after the notebook is open on the desired page.</p>

<p>To change mode, click on the Stylus button in your browser toolbar, open the OneBoard settings via the gear icon right of “iframe: OneBoard” and select a different mode.</p>

<figure>
  <img src="https://xworld21.github.io/OneBoard/demo/OneBoardDemo-NormalMode@540.png" srcset="https://xworld21.github.io/OneBoard/demo/OneBoardDemo-NormalMode@540.png, https://xworld21.github.io/OneBoard/demo/OneBoardDemo-NormalMode@1080.png 2x">
  <figcaption>Normal mode</figcaption>
</figure>

<hr>

<figure>
  <img src="https://xworld21.github.io/OneBoard/demo/OneBoardDemo-TypeMode@540.png" srcset="https://xworld21.github.io/OneBoard/demo/OneBoardDemo-TypeMode@540.png, https://xworld21.github.io/OneBoard/demo/OneBoardDemo-TypeMode@1080.png 2x">
  <figcaption>Type mode</figcaption>
</figure>

<hr>

<figure>
  <img src="https://xworld21.github.io/OneBoard/demo/OneBoardDemo-DrawMode@540.png" srcset="https://xworld21.github.io/OneBoard/demo/OneBoardDemo-DrawMode@540.png, https://xworld21.github.io/OneBoard/demo/OneBoardDemo-DrawMode@1080.png 2x">
  <figcaption>Draw mode</figcaption>
</figure>

<hr>

<figure>
  <img src="https://xworld21.github.io/OneBoard/demo/OneBoardDemo-DrawModeSplit@540.png" srcset="https://xworld21.github.io/OneBoard/demo/OneBoardDemo-DrawModeSplit@540.png, https://xworld21.github.io/OneBoard/demo/OneBoardDemo-DrawModeSplit@1080.png 2x">
  <figcaption>Draw mode, split vertically</figcaption>
</figure>

<h2 id="settings">Settings</h2>

<p>There are four modes that hide different parts of the UI. Presentation mode (the default) changes the cursor into a laser pointer. Presentation and Draw modes hide as many text editing indicators as possible, including the insertion caret, text selections, spelling errors, and note container borders.</p>

<table>
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>Presentation</th>
      <th>Draw</th>
      <th>Type</th>
      <th>Normal</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>OneNote header</td>
      <td>Hidden</td>
      <td>Hidden</td>
      <td>Hidden</td>
      <td>Hidden</td>
    </tr>
    <tr>
      <td>Menu bar</td>
      <td>Hidden</td>
      <td>Hidden</td>
      <td>Hidden</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>Text editing</td>
      <td>Hidden</td>
      <td>Hidden</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>Ribbon</td>
      <td>Hidden</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>Laser pointer</td>
      <td>Yes</td>
      <td>No</td>
      <td>No</td>
      <td>No</td>
    </tr>
  </tbody>
</table>

<p>Before activating Draw or Type mode, you should select the appropriate ribbon by switching to Normal mode first.</p>

<p>There are further options to control other elements of the UI.</p>
<dl>
  <dt>Hide navigation panel (default: yes)</dt>
  <dd>Permanently hide the left navigation panel. The panel can also be hidden manually via the "View" ribbon, but it reappears on window resize.</dd>
  <dt>Hide scrollbars (default: yes)</dt>
  <dd>Hide the scrollbars.</dd>
  <dt>Laser pointer size (default: 16px)</dt>
  <dd>Configure the laser pointer size. You may have to disable and reenable OneBoard for the option to take effect.</dd>
  <dt>Prevent horizontal scrolling (default: no)</dt>
  <dd>Prevent horizontal scrolling.<br>
    <strong>Warning.</strong> OneNote will scroll on its own when writing text near a border. This can easily happen by accident when clicking close to the border of the page, as it may create a note container that spans beyond the viewport. You may have trouble scrolling back when this option is enabled.</dd>
</dl>

<h2 id="license">License</h2>

<p>Distributed under the <a href="https://github.com/xworld21/OneBoard/LICENSE">GPL3 license</a>. Copyright © 2020 Vincenzo Mantova <a href="mailto:xworld21@users.sf.net">xworld21@users.sf.net</a>.</p>


      
      
      
    </div></div>]]>
            </description>
            <link>https://xworld21.github.io/OneBoard/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882267</guid>
            <pubDate>Sat, 18 Jul 2020 16:00:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Are there more than 2 genders or sexes?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23882222">thread link</a>) | @Timtimini
<br/>
July 18, 2020 | https://www.otito.io/topic/are-there-more-than-2-genders-or-sexes-e2858e7a54 | <a href="https://web.archive.org/web/*/https://www.otito.io/topic/are-there-more-than-2-genders-or-sexes-e2858e7a54">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div ng-app="Topic" ng-controller="TopicView">
    



        <div>
            <p><span>
                        <span>Unchallenged Claim</span>
                    </span>
                    <br>

                <span>Claim</span>
            </p>
            <div>
                    

                <p>
                    <img src="https://www.otito.io/images/up_large_arrow.svg" width="30" id="up-535" onclick="showHelp(535)" height="30">
                </p>
                <p id="help-535">
                    For some properties in which differences between sexes are observed—like brain volume and connectivity—trans people possessed values in between those typical of cisgender males and females, both before and after transitioning.
                </p>
                
                
                
                </div>
            

            


        </div>
        <div>
            <p><span>
                        <span>Unchallenged Claim</span>
                    </span>
                    <br>

                <span>Claim</span>
            </p>
            <div>
                    <h2>
                        A 2017 study analysing toy preferences in children suggests gender is heavily biological, not just a result of social pressures.
                        <p>
                            <img src="https://www.otito.io/images/up_large_arrow.svg?version=2" width="30" id="up-m-532" onclick="showMobileHelp(532)" height="30">
                        </p>
                    </h2>

                <p>
                    <img src="https://www.otito.io/images/up_large_arrow.svg" width="30" id="up-532" onclick="showHelp(532)" height="30">
                </p>
                <p id="help-532">
                    The review found that boys are more likely to play with "male toys" and girls with "female toys", due to biological drivers. The size of sex differences in children’s preferences for male-typed and female-typed toys was not smaller in studies done in more egalitarian societies.
                </p>
                
                
                
                </div>
            

            


        </div>
        <div>
            <p><span>
                        <span>Unchallenged Claim</span>
                    </span>
                    <br>

                <span>Claim</span>
            </p>
            <div>
                    <h2>
                        The feeling of belonging to genders other than male or female is due to gender dysphoria (not the actual existence of other genders).
                        <p>
                            <img src="https://www.otito.io/images/up_large_arrow.svg?version=2" width="30" id="up-m-536" onclick="showMobileHelp(536)" height="30">
                        </p>
                    </h2>

                <p>
                    <img src="https://www.otito.io/images/up_large_arrow.svg" width="30" id="up-536" onclick="showHelp(536)" height="30">
                </p>
                <p id="help-536">
                    A key component of gender dysphoria is the distress that comes from one's body and gender identity not matching. This feeling has been associated with decreased insular and prefrontal cortical volumes (of the brain)—the insular cortex is the possible foundation of body awareness.
                </p>
                
                <div>

                    
                        <div>
                            <div>
                                
                                <div>
                                    <div>
                                        <p><span>
                                                Positive karma of source submitter. The higher this is, the more reliable their sources have proven to be.
                                            </span>
                                        </p>
                                        <p><span>
                                                Negative karma of source submitter. The higher this is, the more unreliable their sources have proven to be.
                                            </span>
                                        </p>
                                        
                                    </div>
                                    
                                    <p>
                                        <a href="#" ng-click="getFullURL('https://www.nature.com/articles/s41598-017-17563-z');$event.preventDefault();"> https://www.nature.com/articles/s41598-017-17563-z </a>
                                    </p>
                                </div>

                            </div>
                        </div>
                        </div>
                
                </div>
            

            


        </div>
        <div>
            <p><span>
                        <span>Most Validated</span>
                    </span>
                    <br>

                <span>Claim</span>
            </p>
            <div>
                    <h2>
                        Homosexual transexual people have been found to exhibit complex combinations of male and female brain chemistry.
                        <p>
                            <img src="https://www.otito.io/images/up_large_arrow.svg?version=2" width="30" id="up-m-537" onclick="showMobileHelp(537)" height="30">
                        </p>
                    </h2>

                <p>
                    <img src="https://www.otito.io/images/up_large_arrow.svg" width="30" id="up-537" onclick="showHelp(537)" height="30">
                </p>
                <p id="help-537">
                    The brains of male-to-female homosexual transexuals present mixtures of masculine, feminine, and demasculinized regions—while female-to-male homosexual transexuals show feminine, masculine, and defeminized brain regions.
                </p>
                
                
                
                </div>
                <div>
                    <p><span>
                            <span>Less Validated</span>
                        </span>
                        <br>
                        <span>Claim</span>
                    </p>
                    <div>
                        

                        <p><img src="https://www.otito.io/images/down_large_arrow.svg?version=2" width="30" id="down-counter538" onclick="showHelp('counter538')" height="30">
                            
                        </p>
                        
                        
                        
                        
                        </div>
                </div>
            

            


        </div>
        <div>
            <p><span>
                        <span>Unchallenged Claim</span>
                    </span>
                    <br>

                <span>Claim</span>
            </p>
            <div>
                    <h2>
                        Homosexual male-to-female (MtF) transexuals appear to have unique brain properties, which may also suggest a non-binary gender identity.
                        <p>
                            <img src="https://www.otito.io/images/up_large_arrow.svg?version=2" width="30" id="up-m-539" onclick="showMobileHelp(539)" height="30">
                        </p>
                    </h2>

                <p>
                    <img src="https://www.otito.io/images/up_large_arrow.svg" width="30" id="up-539" onclick="showHelp(539)" height="30">
                </p>
                <p id="help-539">
                    Studies on brain white matter strongly suggest that MtFs have their own brain phenotype that mainly affects the right hemisphere. The main white matter fascicles are demasculinized, while others are still masculine— most of the differences appear to be in the right hemisphere.
                </p>
                
                
                
                </div>
            

            


        </div>
            <div>
                <div>
                    <div>
                        <p><img src="https://www.otito.io/images/logo_grey.png">
                        </p>

                        
                    </div>

                </div>
            </div>
        <div>
            <p><span>
                        <span>Unchallenged Claim</span>
                    </span>
                    <br>

                <span>Claim</span>
            </p>
            <div>
                    <h2>
                        A study of twins by the University of Hawaii suggests that transexuality is largely genetic—meaning gender identity is not imagined.
                        <p>
                            <img src="https://www.otito.io/images/up_large_arrow.svg?version=2" width="30" id="up-m-540" onclick="showMobileHelp(540)" height="30">
                        </p>
                    </h2>

                <p>
                    <img src="https://www.otito.io/images/up_large_arrow.svg" width="30" id="up-540" onclick="showHelp(540)" height="30">
                </p>
                <p id="help-540">
                    The study shows that identical twins (i.e. developed from a single fertilised ovum) were more likely to share transexual identity (at a rate of 28.38%) compared with non-identical twins (i.e. developed from separate fertilised ovums) at a rate of 0.34%. 
                </p>
                
                
                
                </div>
            

            


        </div>
        <div>
            <p><span>
                        <span>Unchallenged Claim</span>
                    </span>
                    <br>

                <span>Claim</span>
            </p>
            <div>
                    <h2>
                        Men who transition to being women tend to have a similar brain structure to women who were born biologically female.
                        <p><img src="https://www.otito.io/images/down_large_arrow.svg?version=2" width="30" id="down-m-541" onclick="showMobileHelp(541)" height="30">
                            
                        </p>
                    </h2>

                <p><img src="https://www.otito.io/images/down_large_arrow.svg" width="30" id="down-541" onclick="showHelp(541)" height="30">
                    
                </p>
                
                
                
                
                </div>
            

            


        </div>
        <div>
            <p><span>
                        <span>Unchallenged Claim</span>
                    </span>
                    <br>

                <span>Claim</span>
            </p>
            <div>
                    <h2>
                        One study suggests that many people experience themselves sometimes as a woman and at other times as a man, or as neither.
                        <p><img src="https://www.otito.io/images/down_large_arrow.svg?version=2" width="30" id="down-m-542" onclick="showMobileHelp(542)" height="30">
                            
                        </p>
                    </h2>

                <p><img src="https://www.otito.io/images/down_large_arrow.svg" width="30" id="down-542" onclick="showHelp(542)" height="30">
                    
                </p>
                
                
                
                
                </div>
            

            


        </div>
        <div>
            <p><span>
                        <span>Unchallenged Claim</span>
                    </span>
                    <br>

                <span>Claim</span>
            </p>
            <div>
                    <h2>
                        A significant amount of scientific research has shown that gender (even in intersex people) is the result of prenatal hormone exposure.
                        <p><img src="https://www.otito.io/images/down_large_arrow.svg?version=2" width="30" id="down-m-543" onclick="showMobileHelp(543)" height="30">
                            
                        </p>
                    </h2>

                <p><img src="https://www.otito.io/images/down_large_arrow.svg" width="30" id="down-543" onclick="showHelp(543)" height="30">
                    
                </p>
                
                
                
                
                </div>
            

            


        </div>
            <div>
                <div>
                    <div>
                        <p><img src="https://www.otito.io/images/logo_grey.png">
                        </p>

                        
                    </div>

                </div>
            </div>



    

</div></div>]]>
            </description>
            <link>https://www.otito.io/topic/are-there-more-than-2-genders-or-sexes-e2858e7a54</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882222</guid>
            <pubDate>Sat, 18 Jul 2020 15:55:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Can Vitamin D help protect you against Covid-19?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23882218">thread link</a>) | @Timtimini
<br/>
July 18, 2020 | https://www.otito.io/topic/can-vitamin-d-help-protect-you-against-covid-19-0ea2e9f156 | <a href="https://web.archive.org/web/*/https://www.otito.io/topic/can-vitamin-d-help-protect-you-against-covid-19-0ea2e9f156">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div ng-app="Topic" ng-controller="TopicView">
    



        <div>
            <p><span>
                        <span>Unchallenged Claim</span>
                    </span>
                    <br>

                <span>Claim</span>
            </p>
            <div>
                    

                <p>
                    <img src="https://www.otito.io/images/up_large_arrow.svg" width="30" id="up-552" onclick="showHelp(552)" height="30">
                </p>
                <p id="help-552">
                    Studies assessing intensive care unit patients have reported high rates of deficiency even before COVID-19. A study found a strong association between vitamin D concentrations and clinical complications (acute respiratory insufficiency, acute liver failure, and infections).
                </p>
                
                <div>

                    
                        <div>
                            <div>
                                
                                <div>
                                    <div>
                                        <p><span>
                                                Positive karma of source submitter. The higher this is, the more reliable their sources have proven to be.
                                            </span>
                                        </p>
                                        <p><span>
                                                Negative karma of source submitter. The higher this is, the more unreliable their sources have proven to be.
                                            </span>
                                        </p>
                                        
                                    </div>
                                    
                                    <p>
                                        <a href="#" ng-click="getFullURL('https://pubmed.ncbi.nlm.nih.gov/30682545/');$event.preventDefault();"> https://pubmed.ncbi.nlm.nih.gov/30682545/ </a>
                                    </p>
                                </div>

                            </div>
                        </div>
                        </div>
                
                </div>
            

            


        </div>
        <div>
            <p><span>
                        <span>Unchallenged Claim</span>
                    </span>
                    <br>

                <span>Claim</span>
            </p>
            <div>
                    <h2>
                        Vitamin D supplementation to prevent acute respiratory illnesses is most beneficial to people with a severe deficiency of the nutrient.
                        <p>
                            <img src="https://www.otito.io/images/up_large_arrow.svg?version=2" width="30" id="up-m-550" onclick="showMobileHelp(550)" height="30">
                        </p>
                    </h2>

                <p>
                    <img src="https://www.otito.io/images/up_large_arrow.svg" width="30" id="up-550" onclick="showHelp(550)" height="30">
                </p>
                <p id="help-550">
                    A meta-analysis of 25 trials found the benefits of regular supplementation were greatest among participants who were severely vitamin D deficient to begin with—for whom the risk of respiratory infection went down by 70%. In others, the risk decreased by 25%.
                </p>
                
                <div>

                    
                        <div>
                            <div>
                                
                                <div>
                                    <div>
                                        <p><span>
                                                Positive karma of source submitter. The higher this is, the more reliable their sources have proven to be.
                                            </span>
                                        </p>
                                        <p><span>
                                                Negative karma of source submitter. The higher this is, the more unreliable their sources have proven to be.
                                            </span>
                                        </p>
                                        
                                    </div>
                                    
                                    <p>
                                        <a href="#" ng-click="getFullURL('https://pubmed.ncbi.nlm.nih.gov/30675873/');$event.preventDefault();"> https://pubmed.ncbi.nlm.nih.gov/30675873/ </a>
                                    </p>
                                </div>

                            </div>
                        </div>
                        </div>
                
                </div>
            

            


        </div>
        <div>
            <p><span>
                        <span>Unchallenged Claim</span>
                    </span>
                    <br>

                <span>Claim</span>
            </p>
            <div>
                    <h2>
                        Research suggests that increased Vitamin D levels can reduce complications of Covid-19
                        <p>
                            <img src="https://www.otito.io/images/up_large_arrow.svg?version=2" width="30" id="up-m-534" onclick="showMobileHelp(534)" height="30">
                        </p>
                    </h2>

                <p>
                    <img src="https://www.otito.io/images/up_large_arrow.svg" width="30" id="up-534" onclick="showHelp(534)" height="30">
                </p>
                <p id="help-534">
                    A collaborative team from Trinity College Dublin, the University of Liverpool and the Irish Longitudinal Study on Ageing have been looking at how vitamin D impacts mortality rates among those with coronavirus. They found the number of deaths were lower among those countries.
                </p>
                
                
                
                </div>
            

            


        </div>
        <div>
            <p><span>
                        <span>Unchallenged Claim</span>
                    </span>
                    <br>

                <span>Claim</span>
            </p>
            <div>
                    <h2>
                        Vitamin D levels do not seem associated with the higher risk of death from COVID-19 associated with BAME populations. 
                        <p>
                            <img src="https://www.otito.io/images/up_large_arrow.svg?version=2" width="30" id="up-m-544" onclick="showMobileHelp(544)" height="30">
                        </p>
                    </h2>

                <p>
                    <img src="https://www.otito.io/images/up_large_arrow.svg" width="30" id="up-544" onclick="showHelp(544)" height="30">
                </p>
                <p id="help-544">
                    A 2020 review has found that lower vitamin D levels, among other factors, in black, Asian and minority ethnic (BAME) populations did not account for the disparity in coronavirus deaths within the community.
                </p>
                
                
                
                </div>
            

            


        </div>
        <div>
            <p><span>
                        <span>Unchallenged Claim</span>
                    </span>
                    <br>

                <span>Claim</span>
            </p>
            <div>
                    <h2>
                        Vitamin D may help prevent serious respiratory illnesses, due to its positive effects on the immune system and cytokines (immune molecules).
                        <p>
                            <img src="https://www.otito.io/images/up_large_arrow.svg?version=2" width="30" id="up-m-545" onclick="showMobileHelp(545)" height="30">
                        </p>
                    </h2>

                <p>
                    <img src="https://www.otito.io/images/up_large_arrow.svg" width="30" id="up-545" onclick="showHelp(545)" height="30">
                </p>
                <p id="help-545">
                    A 2020 report by Professor Rose Anne Kenny at Trinity College Dublin suggests that Vitamin D might help improve the health of 'shielding' groups—those who are more at risk of developing a serious illness if they catch COVID-19.
                </p>
                
                
                
                </div>
            

            


        </div>
            <div>
                <div>
                    <div>
                        <p><img src="https://www.otito.io/images/logo_grey.png">
                        </p>

                        
                    </div>

                </div>
            </div>
        <div>
            <p><span>
                        <span>Unchallenged Claim</span>
                    </span>
                    <br>

                <span>Claim</span>
            </p>
            <div>
                    <h2>
                        Early (2020) research suggests that low levels of vitamin D are associated with increased COVID-19 risks.
                        <p>
                            <img src="https://www.otito.io/images/up_large_arrow.svg?version=2" width="30" id="up-m-546" onclick="showMobileHelp(546)" height="30">
                        </p>
                    </h2>

                <p>
                    <img src="https://www.otito.io/images/up_large_arrow.svg" width="30" id="up-546" onclick="showHelp(546)" height="30">
                </p>
                <p id="help-546">
                    Scientists from University of East Anglia compared vitamin D levels and coronavirus rates across European countries, and found low vitamin D was associated with increased risk of coronavirus infection and death from the illness. However, this study hasn't been peer reviewed.
                </p>
                
                <div>

                    
                        <div>
                            <div>
                                
                                <div>
                                    <div>
                                        <p><span>
                                                Positive karma of source submitter. The higher this is, the more reliable their sources have proven to be.
                                            </span>
                                        </p>
                                        <p><span>
                                                Negative karma of source submitter. The higher this is, the more unreliable their sources have proven to be.
                                            </span>
                                        </p>
                                        
                                    </div>
                                    
                                    <p>
                                        <a href="#" ng-click="getFullURL('https://www.researchsquare.com/article/rs-21211/v1');$event.preventDefault();"> https://www.researchsquare.com/article/rs-21211/v1 </a>
                                    </p>
                                </div>

                            </div>
                        </div>
                        </div>
                
                </div>
            

            


        </div>
        <div>
            <p><span>
                        <span>Unchallenged Claim</span>
                    </span>
                    <br>

                <span>Claim</span>
            </p>
            <div>
                    <h2>
                        An early (2020) study from Oxford University suggests there's no evidence that Vitamin D protects against the novel coronavirus.
                        <p><img src="https://www.otito.io/images/down_large_arrow.svg?version=2" width="30" id="down-m-547" onclick="showMobileHelp(547)" height="30">
                            
                        </p>
                    </h2>

                <p><img src="https://www.otito.io/images/down_large_arrow.svg" width="30" id="down-547" onclick="showHelp(547)" height="30">
                    
                </p>
                
                
                
                
                </div>
            

            


        </div>
        <div>
            <p><span>
                        <span>Unchallenged Claim</span>
                    </span>
                    <br>

                <span>Claim</span>
            </p>
            <div>
                    <h2>
                        A review of research by the National Institute for Health and Care Excellence (NICE) suggests vitamin D doesn't prevent or treat COVID-19.
                        <p><img src="https://www.otito.io/images/down_large_arrow.svg?version=2" width="30" id="down-m-548" onclick="showMobileHelp(548)" height="30">
                            
                        </p>
                    </h2>

                <p><img src="https://www.otito.io/images/down_large_arrow.svg" width="30" id="down-548" onclick="showHelp(548)" height="30">
                    
                </p>
                
                
                
                
                </div>
            

            


        </div>
        <div>
            <p><span>
                        <span>Unchallenged …</span></span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.otito.io/topic/can-vitamin-d-help-protect-you-against-covid-19-0ea2e9f156">https://www.otito.io/topic/can-vitamin-d-help-protect-you-against-covid-19-0ea2e9f156</a></em></p>]]>
            </description>
            <link>https://www.otito.io/topic/can-vitamin-d-help-protect-you-against-covid-19-0ea2e9f156</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882218</guid>
            <pubDate>Sat, 18 Jul 2020 15:54:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Heisenberg's Uncertainty Principle]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23882116">thread link</a>) | @keyboardman
<br/>
July 18, 2020 | https://leimao.github.io/blog/Heisenberg-Uncertainty-Principle/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Heisenberg-Uncertainty-Principle/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>In quantum mechanics, one of the key discoveries is that it is not always possible that we could measure two physical observables precisely, which is the Heisenberg’s general uncertainty principle.</p>



<p>We might have learned a special case of the Heisenberg’s general uncertainty principle from high school or college physics courses that the more precisely the position of some particle is determined, the less precisely its momentum can be predicted from initial conditions, and vice versa. In this case, the two physical observables are position and momentum.</p>



<p>Formally, the Heisenberg’s general uncertainty principle states that the product of the variances of two arbitrary hermitian operators on a given state is always greater than or equal to one-fourth the square of the expected value of their commutator. In formulas:</p>



<p>where $\mathbb{V}_{\psi}(\Omega_1)$ and $\mathbb{V}_{\psi}(\Omega_2)$ are using the notations from my previous <a href="https://leimao.github.io/blog/Quantum-Mean-Variance/">post</a>, $[\Omega_1, \Omega_2]$ is called the commutator of $\Omega_1$ and $\Omega_2$, and $[\Omega_1, \Omega_2] = \Omega_1 \Omega_2 - \Omega_2 \Omega_1$.</p>



<p>In this blog post, I would like to show a mathematical proof to Heisenberg’s general uncertainty principle.</p>

<h3 id="prerequisites">Prerequisites</h3>

<p>We would use the following four theorems and properties to prove Heisenberg’s general uncertainty principle.</p>

<h4 id="cauchyschwarz-inequality">Cauchy–Schwarz Inequality</h4>

<p>The Cauchy–Schwarz inequality states that for all vectors $u$ and $v$ of an inner product space it is true that</p>



<p>The proof could be found on <a href="https://en.wikipedia.org/wiki/Cauchy%E2%80%93Schwarz_inequality">Wikipedia</a>.</p>

<h4 id="imaginary-part-of-vector-inner-product">Imaginary Part of Vector Inner Product</h4>

<p>The imaginary part of the inner product of all vectors $u$ and $v$, $\text{Im}\big(\langle u, v \rangle\big)$, could be computed as</p>



<p>Assuming $u = a_1 + b_1 i$ and $v = a_2 + b_2 i$, where $a_1$, $a_2$, $b_1$, and $b_2$ are real (column) vectors.</p>





<p>It is trivial to see that</p>



<p>This concludes the proof.</p>

<h4 id="triangle-inequality">Triangle Inequality</h4>

<p>Let $z$ be any complex number, we have</p>



<p>This should be very straightforward to the people who are familiar with triangles and know the polar coordinate expression of complex numbers. We will skip the formal proof here.</p>

<h4 id="hermitian-property">Hermitian Property</h4>

<p>If A is a hermitian $n$-by-$n$ matrix, then for all $u, v^{\prime} \in \mathbb{C}$. we have</p>



<p>Using the property of hermitian matrix $A^{\dagger} = A$, we simply have</p>



<p>This concludes the proof.</p>

<h3 id="proof-to-heisenbergs-general-uncertainty-principle">Proof to Heisenberg’s General Uncertainty Principle</h3>

<p>Because $\Delta_{\psi}(\Omega) = \Omega - \langle \Omega \rangle_{\psi} I$ and $\Omega$ is a hermitian operator, therefore $\Delta_{\psi}(\Omega)$ is also a hermitian operator. Based on <a href="https://leimao.github.io/blog/Quantum-Mean-Variance/">the definition of variance</a>, using the hermitian property, we further have</p>



<p>We apply the Cauchy–Schwarz inequality to the left side of the Heisenberg’s general uncertainty principle,</p>



<p>We further apply the Triangle inequality,</p>



<p>We use the imaginary part of vector inner product,</p>



<p>We use the hermitian property again,</p>



<p>This concludes the proof.</p>

<h3 id="caveats">Caveats</h3>

<p>In Heisenberg’s general uncertainty principle, the commutator $[\Omega_1, \Omega_2] = 0$ suggests $\Omega_1 \Omega_2 = \Omega_2 \Omega_1$ and $\Omega_1 \Omega_2 | \psi \rangle = \Omega_2 \Omega_1 | \psi \rangle$. This means that the system states after the two sequential measures $\Omega_1 \Omega_2$ and $\Omega_1 \Omega_2$ are the same if $[\Omega_1, \Omega_2] = 0$. Otherwise, if $[\Omega_1, \Omega_2] \neq 0$ the system states after the two sequential measures $\Omega_1 \Omega_2$ and $\Omega_1 \Omega_2$ are not the same. If the commutator $[\Omega_1, \Omega_2] = 0$, Heisenberg’s general uncertainty principle suggests that the two physical observables that $\Omega_1$ and $\Omega_2$ are measuring would have not limit in precision.</p>



<p>In other expressions of Heisenberg’s general uncertainty principle, sometimes we would see the word “simultaneity”. How to understand the simultaneity in Heisenberg’s general uncertainty principle? Given measurement would change the system state, and it is almost impossible to achieve the absolute simultaneity in the time domain, what does the simultaneity mean in this case? Here simultaneity means that the order of measurement $\Omega_1$ and $\Omega_2$ do not change the final observation, as we tried hard to make them simultaneous and it is impossible to control the exact order of these two measurements. In short, simultaneity just means $[\Omega_1, \Omega_2] = 0$.</p>



<p>How to measure the variance of physical observable for a system state, as is shown at the left side of the inequality of Heisenberg’s general uncertainty principle? Measurement changes system state in quantum mechanics. We would need to create lots of clones of the system state. Once a system state is measured, it should be discarded and not be used for the measurement for the physical observable anymore. Measurement on the same system state means measurement on system state clones and not the exact system state.</p>

<h3 id="conclusions">Conclusions</h3>

<p>It is quite amazing that the Heisenberg’s general uncertainty principle could be derived in a such simple way. Unfortunately, the my college physics course instructor never showed a proof to this important principle.</p>

<h3 id="references">References</h3>

<ul>
  <li><a href="https://leimao.github.io/blog/Inner-Product/">Inner Product and Inner Product Space</a></li>
  <li><a href="https://leimao.github.io/blog/Quantum-Mean-Variance/">Expected Value and Variance from the Perspective of Quantum Theory</a></li>
</ul>

      <hr>
      
    </div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/Heisenberg-Uncertainty-Principle/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882116</guid>
            <pubDate>Sat, 18 Jul 2020 15:42:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Developer Resources]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23882099">thread link</a>) | @Sandeepg33k
<br/>
July 18, 2020 | https://nelsonmichael.dev/awesome-developer-resources-ckcrin0gg00khpms1gbue38dz | <a href="https://web.archive.org/web/*/https://nelsonmichael.dev/awesome-developer-resources-ckcrin0gg00khpms1gbue38dz">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>A project is only as good as the resources and tools that you have available to you. Building your first project or any other project shouldn’t be much of a hassle for you when you’ve got the right resources at your fingertips.</p>
<p>In this article I’ve compiled a list of useful resources, to help in your development process and put them all in one place, saves you the stress of having to look for all these great resources.</p>
<p>By the end of this article, you would have all the necessary resources, you need to start working on your project.</p>
<h2 id="table-of-contents">Table of Contents</h2>
<ul>
<li><a href="##Fonts">Fonts</a></li>
<li><a href="##Logo-Maker">Logo Maker</a></li>
<li><a href="##Icons">Icons</a></li>
<li><a href="##Illustrations">Illustrations</a></li>
<li><a href="##Colors">Colors</a></li>
<li><a href="##Images">Images</a></li>
<li><a href="##Animations">Animations</a></li>
<li><a href="##Videos">Videos</a></li>
<li><a href="##Youtube-Channels">Youtube Channels</a></li>
<li><a href="##Design-Inspiration">Design Inspiration</a></li>
<li><a href="##API">API</a></li>
<li><a href="##Chrome-Extensions">Chrome Extensions</a></li>
<li><a href="##Free-Webpage-Templates">Free Webpage Templates</a></li>
<li><a href="##Resume-maker">Resume Maker</a></li>
</ul>
<h2 id="fonts">Fonts</h2>
<ul>
<li><a target="_blank" rel="noopener noreferrer" href="https://fonts.google.com/">Google-fonts</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://https//www.colorsandfonts.com/">Fonts and Colors</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://fontpair.co/">Font-pair</a></li>
</ul>
<h2 id="logo-maker">Logo Maker</h2>
<ul>
<li><a target="_blank" rel="noopener noreferrer" href="https://www.namecheap.com/logo-maker">Namecheap logo maker</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://www.wix.com/logobrand/wix-logo-maker?utm_source=google&amp;utm_medium=cpc&amp;utm_campaign=1624436120^62150769059&amp;experiment_id=wix%20logo%20maker^e^397585233258^&amp;gclid=Cj0KCQjw9IX4BRCcARIsAOD2OB33OckwlbIRdVsgugpEjelDTaJO4Mg86nBGUaezfSF5o7MLW2H57VgaAsovEALw_wcB">Wix logo maker </a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://hatchful.shopify.com/">Hatchful logo maker </a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://www.fiverr.com/logo-maker">Fiverr logo maker</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://www.squarespace.com/logo#N4IghgrgLgFgpgExALgGZgDYGc4F8gAA">Squarespace logo maker</a></li>
</ul>
<h2 id="icons">Icons</h2>
<ul>
<li><a target="_blank" rel="noopener noreferrer" href="https://lordicon.com/">Lordicon</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://www.flaticon.com/">Flat Icon</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://icons8.com/">Icon8</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://material.io/resources/icons/?style=baseline">Material</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://thenounproject.com/">The noun project</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://www.iconfinder.com/free_icons">Icon Finder</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://fontawesome.com/">Font Awesome</a></li>
</ul>
<h2 id="illustrations">Illustrations</h2>
<ul>
<li><a target="_blank" rel="noopener noreferrer" href="https://undraw.co/">UnDraw- Open source Illustrations</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://iconscout.com/paper-illustrations">Papper Illustrations</a> </li>
<li><a target="_blank" rel="noopener noreferrer" href="https://openpeeps.com/">Open peeps</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://www.blackillustrations.com/">Black Illustrations</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://www.kapwing.com/404-illustrations">404 illustrations </a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://www.startupmilk.com/city-kit">City Illustrations </a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://icons8.com/illustrations">Vector Illustrations</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://getwaves.io/">SVG Wave Generator</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://www.blobmaker.app/">Blob maker</a><h2 id="colors">Colors</h2>
</li>
<li><a target="_blank" rel="noopener noreferrer" href="https://nelsonmichael.dev/https://www.happyhues.co/">Happy hues</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://www.colorsandfonts.com/">Colors and Fonts</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://colorsinspo.com/">Colors Inspo</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://paletton.com/#uid=c5-2L0q3e0kllllaFw0g0qFqFg0w0aF">Palleton</a><h2 id="images">Images</h2>
</li>
<li><a target="_blank" rel="noopener noreferrer" href="https://unsplash.com/">Unsplash</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://landingstock.com/">Landing Stock</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://freepik.com/">Freepik</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://www.shotzr.com/">Shotzr</a><h2 id="animations">Animations</h2>
</li>
<li><a target="_blank" rel="noopener noreferrer" href="https://animate.style/">Animate.css</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://animejs.com/">Anime.js</a><h2 id="videos">Videos</h2>
</li>
<li><a target="_blank" rel="noopener noreferrer" href="https://mixkit.co/">Mixkit</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://coverr.co/">Coverr</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://www.pexels.com/videos">Pexels</a><h2 id="youtube-channels">Youtube Channels</h2>
</li>
<li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/channel/UClb90NQQcskPUGDIXsQEz5Q">Dev Ed</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/channel/UCVyRiMvfUNMA1UPlDPzG5Ow">Designcourse</a><h2 id="design-inspiration">Design Inspiration</h2>
</li>
<li><a target="_blank" rel="noopener noreferrer" href="https://dribbble.com/">Dribbble</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://uidesigndaily.com/">UI Design daily</a><h2 id="api">API</h2>
</li>
<li><a target="_blank" rel="noopener noreferrer" href="https://public-apis.xyz/">Public-api</a><h2 id="chrome-extensions">Chrome Extensions</h2>
</li>
<li><a target="_blank" rel="noopener noreferrer" href="https://getcssscan.com/">CSS scan</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://colorzilla.com/">ColorZilla</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://fonts.ninja/">Fonts Ninja</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://whatruns.com/">WhatRuns</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://chrome.google.com/webstore/detail/json-viewer-awesome/iemadiahhbebdklepanmkjenfdebfpfe/related">JSON Viewer Awesome</a><h2 id="free-webpage-templates">Free Webpage Templates</h2>
</li>
<li><a target="_blank" rel="noopener noreferrer" href="https://www.mashup-template.com/templates.html">Mash-up</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://www.creative-tim.com/templates/free">Creative-tim</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://grayic.com/shade/">Grayic</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://mdbootstrap.com/">Material design for bootstrap</a> </li>
</ul>
<h2 id="resume-maker">Resume maker</h2>
<ul>
<li><a target="_blank" rel="noopener noreferrer" href="https://resumake.io/">Resumake</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://wtfresume.com/">Wtfresume</a> </li>
<li><a target="_blank" rel="noopener noreferrer" href="https://https//rx-resume.web.app/">Rx-resume</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://cv.bytevitae.com/login">Bytevitae</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://gitconnected.com/resume-builder">Gitconnected resume builder</a></li>
</ul>
<pre><code><span>## Note:</span>
* This <span>list</span> would be updated frequently, to add <span>new</span> resources.
</code></pre><h2 id="attributions">Attributions</h2>
<ul>
<li><a target="_blank" rel="noopener noreferrer" href="https://twitter.com/ravinwashere/status/1283786318628007936">twitter.com/ravinwashere</a></li>
<li>Zero to mastery Academy</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>There you have it, a properly put together list of resources to help you get going with your next project. I hope this article was helpful.</p>
</div></div>]]>
            </description>
            <link>https://nelsonmichael.dev/awesome-developer-resources-ckcrin0gg00khpms1gbue38dz</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882099</guid>
            <pubDate>Sat, 18 Jul 2020 15:40:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It’s Time to Reinvent Democracy]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23882048">thread link</a>) | @whack
<br/>
July 18, 2020 | https://outlookzen.com/2013/11/06/its-time-to-reinvent-democracy/ | <a href="https://web.archive.org/web/*/https://outlookzen.com/2013/11/06/its-time-to-reinvent-democracy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<div><figure><a href="https://www.washingtonpost.com/news/theworldpost/wp/2018/03/23/direct-democracy/" target="_blank" rel="noreferrer noopener"><img data-attachment-id="801" data-permalink="https://outlookzen.com/mob-rule/" data-orig-file="https://outlookzen.files.wordpress.com/2019/05/mob-rule.png" data-orig-size="1142,632" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="mob-rule" data-image-description="" data-medium-file="https://outlookzen.files.wordpress.com/2019/05/mob-rule.png?w=300" data-large-file="https://outlookzen.files.wordpress.com/2019/05/mob-rule.png?w=1024" src="https://outlookzen.files.wordpress.com/2019/05/mob-rule.png" alt=""></a></figure></div>


<p><em>“Democracy is two wolves and a lamb voting on what to have for lunch”&nbsp;<br></em>&nbsp; – Ben Franklin</p>
<p><em>“Democracy never lasts long. It soon wastes, exhausts, and murders itself. There never was a democracy yet that did not commit suicide.”</em>&nbsp;<br>&nbsp; – John Adams</p>
<p>Today, I’ll be making the same argument that the founding fathers did; that our conception of democracy is fundamentally flawed and it’s time we overhauled our political system. As we look around the world, at the gridlock in Washington, the failings of the Arab Spring, and the mixed track record of democracy in the developing world, it’s easy to see the problems inherent in democracy.</p>
<p>But I also intend for this discussion to be constructive, with prescriptions for how to fix the problems that currently exist. We’ll be doing so, by critically examining 3 very different forms of crowdsourcing, which have all proved to be extremely successful. Even though democracy is also a form of crowdsourcing, we can then see that the successful ones all share certain common characteristics, which are completely antithetical to our conception of democracy.</p>
<p><strong><em><span>Differential Voting Power</span></em></strong></p>
<p dir="ltr">Our first example is a company that rose from nowhere to change our world and the way we find information; Google. A brief history: There were numerous companies trying to succeed in the Search Engine marketplace. Lycos, AskJeeves, AltaVista… the list goes on. And yet, sometime in the early 2000s, they all just disappeared and <em>everyone</em> switched to Google. Their search engine was so great, that it simply blew the competition away. When you look into how they implemented this groundbreaking search algorithm solution, one of the main pillars was the PageRank algorithm.</p>
<p>I could write an entire article about the PageRank algorithm but to put it simply, it brought democracy to the internet. It gave every single website the ability to vote on any other website, through the act of linking to it. And Google for its part, crawls through the web everyday, tallies up all the ballots, and posts the winners near the top of their search results. It is in many ways very similar to democracy… with one very important twist. Every website gets a <em>different number of votes</em> based on how credible it is.</p>
<p>To give an example, suppose the Nobel Prize winner Eugene Fama decides tomorrow to start an economics blog. It’s so insightful &amp; interesting, that NYTimes decides to link to it. Suppose that at the same time, Joe Blow, who took a community college class on Economics, also starts an economics blog… and his brother-in-law who works at the Street Sheet links to it as well. We now have 2 blogs, on the same topic, carrying the same keywords, and each having a link from a newspaper. A purely egalitarian search-engine would give them equal visibility. But Google’s knows that NYTimes is a lot more credible than Street Sheet. Hence, it gives NYTimes <em>thousands of ballots more</em> than Street Sheet, and this in turn gives Eugene Fama’s blog a huge well-deserved boost over Joe Blow’s.</p>
<p>Google’s search engine works so well, precisely because it relies on <em>credibility-based differential voting power</em>. Intuitively, it makes perfect sense. In our own lives, we know that some sources of information are much more valuable than others. We give much more weight to the advice of some, and ignore those of others. And yet, this notion is simply heretical in our democracy today. The idea of one-person-one-vote is so ingrained in our political system, that no one even dares to suggest an alternative to it. And yet, when you look at successful forms of crowdsourcing, they are all based on <em>highly differential voting power</em>. One only needs to compare the politicians we have in Congress to the quality of the search results returned by Google, in order to see which works out better.</p>
<p><strong><em><span>Barriers to Contribution</span></em></strong></p>
<p dir="ltr">We don’t have to go very far to find our next great crowdsourcing example: the world’s greatest store of information, Wikipedia. Like Google, and unlike its predecessor Encyclopedia Britannica, Wikipedia too is built around the idea of crowdsourcing. With less than 100 employees, Wikipedia simply creates a platform on which its users can make contributions. Each user contribution may be incremental, but together, they represent the greatest &amp; most easily accessible store of human knowledge.</p>
<p>Given that Wikipedia relies entirely on user contributions, one might think that users would be given the red carpet &amp; encouraged to contribute in any way possible. In reality though, user contributions (ie, edits), are often ruthlessly re-edited or discarded completely. Anyone can give their 2 cents by hitting the edit button &amp; typing away, but getting it to actually stay there for more than a day is not easy. In order to make any lasting contribution, users are required to <em>research</em> the topic and back up their opinions with <em>supporting evidence</em>. Poorly expressed opinions are simply discarded without even a trace.</p>
<p>Having such <em>barriers to contribution</em> does dissuade some well-informed people from making valuable contributions. However, it also filters out an even greater number of ill-informed people who would otherwise be injecting a great deal of noise. A well-informed person who cares enough about the topic to research it is less likely to be dissuaded by such hurdles, compared to a layperson who simply chances upon the discussion &amp; feels the urge to give his 2 cents. By filtering out noise, such <em>barriers to contribution</em> keep the signal-to-noise ratio high.</p>
<p>Contrast this with our democracy, where there is universal agreement that there should never be a barrier to contribution. Our entire system is designed to make voting as easy &amp; convenient as possible. When Joe Blow walks into the voting booth and is asked to contribute to democracy, he can vote for absolutely anything he wants in a matter of minutes, without ever having to justify his choices with research, evidence or logic. The time investment required to vote is insignificant compared to its profound &amp; long-lasting effects. With <em>barriers to contribution</em> kept intentionally low, it’s hardly surprising that our political system feels much more like a noisy bar than a well oiled machine.</p>
<p><strong><em><span>Specialization of Contribution</span></em></strong></p>
<p dir="ltr">As a change of pace, I‘d like for us to consider another great crowdsourcing example that is centuries old. One that we partake in every single day: The market-based economy. How many of us know how to grow crops? Sew clothes? Build a house? Design a computer chip? Perform open-heart surgery? There isn’t a person alive who can answer yes to all of the above. And yet, we are able to enjoy the fruits of all of these &amp; accomplish some truly miraculous feats as a society. This is only possible through <em>division of labor</em>. At a young age, each of us decides upon a career that we would like to pursue. We then spend a decade or more <em>specializing</em> in that one field. We develop great expertise in an extremely niche field, and then spend the next few decades <em>contributing</em> to society, through that one <em>niche field</em>.</p>
<p>More importantly, we also stay away from the other 99% of fields that we know little about. Engineers don’t go around telling doctors how to do their jobs, and doctors don’t go around offering their opinions on good accounting practices. The market based economy works so miraculously, precisely because each of us contributes to society in one very <em>specialized</em> area, and we allow others to do so as well without getting in their way. Can you imagine how well a BMW would run if it was designed by popular vote? And yet, this is the reality of our democracy today. When we go into the voting booth &amp; are asked to choose between Obama &amp; Romney, we’re expected to evaluate both candidates’ economic policies, national security policies, health care proposals, and numerous other credentials in fields that we know next to nothing about.</p>
<p>When we consider the vast breadth of human knowledge, we are all idiot savants. The market-economy has worked so well by funneling our efforts into those fields where we’re <em>savants</em>. Democracy on the other hand, forces us to make decisions precisely in the fields where we’re <em>idiots</em>.</p>
<hr>
<p><em>Differential voting power; Barriers to contribution; Specialization of contribution</em>. All 3 can be found in each of the examples given above. If we look at other forms of successful crowdsourcing, such as financial markets &amp; scientific research, it’s no coincidence that these same characteristics show up there as well. It’s time we had a political system that takes a page out of these great success stories.</p>
<p>Let me end this article, ironically enough, by giving plaudits to democracy. It was truly a brilliant &amp; remarkably insightful idea for the 18th century. It gave birth to the notion of decentralization of power. It created a system of government that derives its power from the people. It leveled the playing field, giving everyone equal treatment &amp; equal opportunity. It gave birth to a political system that was open &amp; accessible to all. It brought crowdsourcing to the field of politics. These were all brilliant ideas for their time, and any new political system we implement should surely hold on to these principles.</p>
<p>However, we have come a long way in the past 300 years, and the cracks in the foundation of democracy are starting to show. Certain aspects that are considered fundamental to democracy, have been shown to severely detract from it. It’s time we overhauled our political system and boldly stepped into the new millenium.</p>


<hr>



<p><em>Ways to Fix Democracy:</em><br><a rel="noreferrer noopener" href="https://outlookzen.wordpress.com/2014/01/21/democracy-by-jury/" target="_blank"><em>A suggestion to reform democracy, using the Jury system as a model</em></a><br><a rel="noreferrer noopener" href="https://outlookzen.wordpress.com/2014/06/29/reinventing-democracy-the-google-way/" target="_blank"><em>Another suggestion to reform democracy, using Google’s search engine</em></a></p>



<hr>



<p><em>Related links:</em><br><a href="https://www.politico.com/magazine/story/2019/09/08/shawn-rosenberg-democracy-228045" target="_blank" rel="noreferrer noopener" aria-label="Leading political psychologist arguing that our brains are not equipped for democracy (opens in a new tab)"><em>Leading political psychologist arguing that our brains are not equipped for democracy</em></a><em><br></em><a rel="noreferrer noopener" href="https://outlookzen.wordpress.com/2013/11/29/direct-vs-representative-democracy/" target="_blank"><em>The crucial difference between direct democracy &amp; representative democracy</em></a><em><br></em><a rel="noreferrer noopener" href="http://nyti.ms/JrTPjC" target="_blank"><em>NYTimes: A Work Still in Progress</em></a><em><br></em><a rel="noreferrer noopener" href="http://wapo.st/1mi3YeD" target="_blank"><em>60% of Americans have no idea which party controls Congress</em></a><em><br></em><a rel="noreferrer noopener" href="http://www.nytimes.com/2016/08/26/opinion/the-dumbed-down-democracy.html?_r=0" target="_blank"><em>NYTimes: Democracy dumbed down</em></a><em><br></em><a rel="noreferrer noopener" href="https://www.nytimes.com/2017/06/29/opinion/sunday/the-problem-with-participatory-democracy-is-the-participants.html?_r=0" target="_blank"><em>NYTimes: The problem with …</em></a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://outlookzen.com/2013/11/06/its-time-to-reinvent-democracy/">https://outlookzen.com/2013/11/06/its-time-to-reinvent-democracy/</a></em></p>]]>
            </description>
            <link>https://outlookzen.com/2013/11/06/its-time-to-reinvent-democracy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882048</guid>
            <pubDate>Sat, 18 Jul 2020 15:32:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creating generative patterns using Moiré]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23882016">thread link</a>) | @nitin42
<br/>
July 18, 2020 | https://formmeetscode.in/blog/moire-pattern/ | <a href="https://web.archive.org/web/*/https://formmeetscode.in/blog/moire-pattern/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>
				© <span id="present-year"></span> Nitin Tulswani All Rights Reserved
			</p>
		</div></div>]]>
            </description>
            <link>https://formmeetscode.in/blog/moire-pattern/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882016</guid>
            <pubDate>Sat, 18 Jul 2020 15:28:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Xfce Infrastructure in 2020]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23881872">thread link</a>) | @severine
<br/>
July 18, 2020 | https://blog.alteroot.org/articles/2020-07-18/xfce-infrastructure-2020.html | <a href="https://web.archive.org/web/*/https://blog.alteroot.org/articles/2020-07-18/xfce-infrastructure-2020.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

    <article>

        

<!--         <header class="post-header">
            <a id="blog-logo" href="https://blog.alteroot.org">
                
                    <span class="blog-title">Alteroot:~#</span>
                 
            </a>
        </header> -->
        
        <!-- <span class="post-meta">
            <time datetime="2020-07-18">18 Jul 2020</time>
             
                on xfce 
            
        </span> -->

        <!-- <h1 class="post-title">Xfce infrastructure in 2020</h1> -->

        <section>
            <p>Oh boy, 3 years without any blogpost ! So much things happened in the Xfce world!<br>
First, we finally released <a href="https://www.xfce.org/about/news/?post=1565568000">Xfce 4.14</a> in August 2019, more than 4 years of effort, a migration to gtk3, and so much new things, but you already know that, and you surely already run it.
We are now working on <a href="https://wiki.xfce.org/releng/4.16/roadmap">Xfce 4.16</a> , with the hope to release it this year  (yes, in 2020) !<br>
You can read more development news on our <a href="https://blog.xfce.org/">blog</a>.<br>
Some buzzwords: new icons, CSD, drop of gtk2 support, UI revamp, and tons of other stuff.</p>

<p><a href="https://blog.alteroot.org/media/images/xfce4-settings-manager-4.15.png"><img src="https://blog.alteroot.org/media/images/xfce4-settings-manager-4.15.png" alt="xfce4-setting-manager 4.15"></a></p>

<p>I want to talk a bit about the infrastructure.<br>
Last year, we had a <a href="https://gandi.net/">Gandi</a> sponsorship for our servers. I started an Ansible repository with all our services (no more -undocumented- local modifications!), and we migrated a big part of our infra to the new servers (docs, www, wiki etc).</p>

<p>Then came the time to think about our development environment. We used the <code>cgit/gitolite/bugzilla</code> triptych, which worked fine for us for more than a decade, but make difficulty to have new contributor (our workflow was…hm, suboptimal).<br>
We tested differents solutions (mainly Gitea and GitLab), and we opted for the famous <a href="https://about.gitlab.com/">Gitlab</a>, already used by multiples open source projects. In the core team we were several to use it at work, so we were in a familiar environment.</p>

<p>For months, a gitlab was running on one of our Gandi instance, to do tests and prepare the transition.</p>

<p>But it was so much work that we never started the real migration. Then came the Covid-19 lockdown. No friends, no bars, lot of free time, so why not spent it on Xfce ?</p>

<p>With Simon (ochosi) and Andre (andreldm), we started to use our own gitlab by opening issues, creating todo, doing merge requests etc related to the migration.<br>
The 1st of May, we finally did <a href="https://simon.shimmerproject.org/2020/04/30/xfce-switches-to-gitlab/">the migration to GitLab</a> ! Woot !</p>

<p>Jason (j4yav), working for Gitlab inc, joined us and proposed to help us for the Gitlab CI/CD setup. At the same time, we got a new (sponsored !) VM from <a href="https://fosshost.org/">FossHost</a> ! Perfect timing, we can now run a dedicated <code>gitlab-runner</code> instance, and we <a href="https://simon.shimmerproject.org/2020/05/10/gitlab-ci-is-up-and-running/">started to use gitlab-ci</a> !</p>

<p>As of July 2020, almost all <code>Xfce</code> components (core, apps, panel plugins) run <code>make distcheck</code> on every merge requests and push to master, thanks to our <a href="https://hub.docker.com/r/xfce/xfce-build/tags">xfce-build</a> docker container.</p>

<p><a href="https://blog.alteroot.org/media/images/xfce-gitlab-pipelines.png"><img src="https://blog.alteroot.org/media/images/xfce-gitlab-pipelines.png" alt="xfce gitlab-ci pipelines"></a></p>

<p>Now that we have a beautiful <a href="https://gitlab.xfce.org/">GitLab</a>, merge requests and CI, the only missing part was… the migration from Bugzilla !<br>
I forked and modified <a href="https://gitlab.xfce.org/infra/bztogl">bztogl</a>, a tool developped and used by Gnome and Freedesktop folks when they migrated away from bugzilla to gitlab in 2018/2019.<br>
Initially, we wanted to migrate all bugzilla issues to gitlab (opened and closed ones). But we had more than 15000 issues ! We decided to only migrate opened issues. We took the opportunity to do a biiig cleanup of old bugs by closing more than 500 of them.</p>

<p>A important condition of the bugzilla migration was to not lose our 15 years of history.<br>
AndreLDM did a huge work by creating <a href="https://gitlab.xfce.org/andreldm/bzstatic">bzstatic</a>, a tool to snapshot a bugzilla instance and make it a simple static html version : <a href="https://bugzilla.xfce.org/">https://bugzilla.xfce.org</a>.<br>
He open sourced it at <a href="https://gitlab.xfce.org/andreldm/bzstatic">https://gitlab.xfce.org/andreldm/bzstatic</a> !</p>

<p><a href="https://blog.alteroot.org/media/images/xfce-bugzilla-bzstatic.png"><img src="https://blog.alteroot.org/media/images/xfce-bugzilla-bzstatic.png" alt="xfce bugzillla bzstatic"></a></p>

<p>As a result, we now have a modern developments workflow, fully integrated with gitlab.
We enabled github and gitlab.com auth on our instance (some people requested it), and since 3 months, we’ve seen a surge of new contributors, issues and merge requests ! Really a good news for the Xfce project ! 
We also had a sponsorship from <a href="https://www.scaleway.com/">Scaleway</a> lately, that we need to set up !</p>

<p>So much things left to do, like update all our documentations for the new workflow, work on <code>Xfce 4.16</code>, get rid of our old release manager app and use gitlab-ci to generate artifacts, simplify our translation workflow and tons of other things !</p>

<p>Enjoy !</p>

        </section>

        

        

    </article>

</div></div>]]>
            </description>
            <link>https://blog.alteroot.org/articles/2020-07-18/xfce-infrastructure-2020.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23881872</guid>
            <pubDate>Sat, 18 Jul 2020 15:07:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crash Course: AWS CDK and Serverless with REST API+Data Lake Analytical Querying]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23881864">thread link</a>) | @kiyanwang
<br/>
July 18, 2020 | https://dashbird.io/blog/crash-course-aws-cdk-serverless-rest-api-data-lake-analytical-querying/ | <a href="https://web.archive.org/web/*/https://dashbird.io/blog/crash-course-aws-cdk-serverless-rest-api-data-lake-analytical-querying/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div><p>This is a hands-on course on how to deploy a fully Serverless web app using the <a href="https://aws.amazon.com/cdk/">AWS CDK</a>. You will learn how to:</p>
<ul>
<li>Structure **CDK Stacks **to deploy an application from end-to-end</li>
<li>Deploy a <strong>REST API</strong> integrated with <strong>AWS Lambda</strong> for dynamic requests processing</li>
<li>Store data in a fast and cost-effective way with <strong>DynamoDB</strong></li>
<li>Use <strong>DynamoDB streams</strong> as a source for <strong>Lambda</strong> in an event-driven architecture</li>
<li>Ingest and manipulate loads of data streams with <strong>Kinesis Firehose</strong></li>
<li>Deploy and query a <strong>Data Lake</strong> with <strong>Athena</strong>, <strong>S3</strong> and <strong>Glue</strong></li>
<li><strong>Monitor</strong> your entire application health in a single place using <a href="https://dashbird.io/?utm_source=dashbird-blog&amp;utm_medium=article&amp;utm_campaign=aws-cdk&amp;utm_content=tutorial-serverless-website">Dashbird</a></li>
</ul>
<p>You can use the resources declared in this demo application as a starting point to mix and adapt to your own architectures later, which should save you quite some time.</p>
<h2>The App and Architecture</h2>
<p>The demo app is a public blog where anyone can read, publish and like posts. It’s available <a href="https://d1qmte5oc6ndq5.cloudfront.net/">on this link</a>. Go ahead and publish something in the top-left corner (yellow button) and also “like” articles already published. Check out the codebase on <a href="https://github.com/byrro/serverless-website-demo">this repo</a>.</p>
<h3>Frontend</h3>
<p><img src="https://dashbird.io/images/blog/2020-07-14/stack-architecture-diagram-static-website.png" alt="Static website architecture diagram" title="Static website architecture diagram"></p>
<h3>Backend</h3>
<p><img src="https://dashbird.io/images/blog/2020-07-14/stack-architecture-diagram-backend-api.png" alt="Backend REST API and storage architecture diagram" title="Backend REST API and storage architecture diagram"></p>
<h3>Data Lake and Analytical Querying</h3>
<p><img src="https://dashbird.io/images/blog/2020-07-14/stack-architecture-diagram-analytical.png" alt="Data lake and analytical querying architecture diagram" title="Data lake and analytical querying architecture diagram"></p>
<h2>What is the AWS CDK</h2>
<p>CDK stands for Cloud Development Kit. Think of it as CloudFormation (CF) in your preferred language (Python, Typescript, C#, etc). Roughly speaking, it works like this:</p>
<ol>
<li>You declare cloud resources using classes provided by the CDK libraries. Example:</li>
</ol>
<div><pre><code data-lang="python"><span>from</span> aws_cdk <span>import</span> aws_s3
my_bucket <span>=</span> aws_s3<span>.</span>Bucket(self, <span>'MyBucket'</span>)
</code></pre></div><ol start="2">
<li>Run <code>cdk deploy</code></li>
<li>CDK translates this to a CloudFormation template and deploy it on AWS for you</li>
</ol>
<p>In case you would like to dig deeper, <a href="https://cdkworkshop.com/">AWS also has a workshop</a> that will get your basics started. I also strongly recommend reading the <a href="https://docs.aws.amazon.com/cdk/latest/guide/home.html">official CDK documentation</a>.</p>
<h2>Advantages using the AWS CDK</h2>
<ol>
<li>Use languages that are more expressive than YAML or JSON, for instance</li>
<li>Less - much less! - verbose than CloudFormation templates</li>
<li>Easier to apply reusability and inheritance principles to infrastructure code</li>
<li>Better integration with IDEs for code completion, IntelliSense, etc</li>
<li>Possible to test your infra code, just as any other software</li>
<li>Portable: since it’s just a wrapper around CF, we can easily port it to JSON or YAML</li>
</ol>
<h2>Disadvantages of using the AWS CDK</h2>
<p>Although released as a stable project by the AWS team, many parts (a lot of the good ones) are still experimental and APIs may change in backwards incompatible ways.</p>
<p>It’s under constant development. During the preparation of this course, I had to upgrade my libraries three times.</p>
<p>Documentation is still lacking at some parts and you will need to look at the CDK code, occasionally, to understand how to declare certain things.</p>
<h2>Deploy it yourself</h2>
<p>Although we have provided an online demo, you can also deploy this app in your own AWS account:</p>
<ol>
<li>Clone the repo: <code>git clone git@github.com:byrro/serverless-website-demo.git sls-demo; cd sls-demo</code></li>
<li>Setup your virtual environment: <code>virtualenv -p /urs/bin/python3.8 .env; source .env/bin/activate; pip install -r requirements</code></li>
<li>Specify an AWS account ID: <code>export AWS_ACCOUNT_ID=1234567890</code> **</li>
<li>Deploy all three stacks: <code>cdk deploy sls-blog; cdk deploy sls-blog-api; cdk deploy sls-blog-analytical</code></li>
</ol>
<p>** You can also hard code your Account ID in the CDK project, as I’ll show in a minute;</p>
<p>When starting a new project from scratch, you would run <code>cdk init --language [python|typescript|...]</code>. This is not necessary for this demo, since the project is already created.</p>
<h3>Monitoring</h3>
<p>Deploying this architecture in the cloud and blindly believing it will work flawlessly is not reasonable. We want to be the first one to know when something is not right to act upon it as quickly as possible.</p>
<p>In this project, I used <a href="https://dashbird.io/?utm_source=dashbird-blog&amp;utm_medium=article&amp;utm_campaign=aws-cdk&amp;utm_content=tutorial-serverless-website">Dashbird</a> for its ease of use and seamless integration. Instead of having to deploy an agent inside my code, Dashbird plugs into my Stacks <a href="https://dashbird.io/docs/quickstart/setting-up-dashbird/?utm_source=dashbird-blog&amp;utm_medium=article&amp;utm_campaign=aws-cdk&amp;utm_content=tutorial-serverless-website">through a CloudFormation template</a> that I can deploy with the effort of one click. It not only monitors Lambda function errors, but also other resources that we’re using, such as DynamoDB tables. They even suggest <a href="https://dashbird.io/features/insights-engine/?utm_source=dashbird-blog&amp;utm_medium=article&amp;utm_campaign=aws-cdk&amp;utm_content=tutorial-serverless-website">insights for architectural improvements</a> cross-referenced against industry best practices.</p>
<p>Finally, Dashbird offers a free-forever plan. It’s a no-brainer to try it out by <a href="https://dashbird.io/register/?utm_source=dashbird-blog&amp;utm_medium=article&amp;utm_campaign=aws-cdk&amp;utm_content=tutorial-serverless-website">registering for free</a>.</p>
<h2>How a CDK project is structured</h2>
<p>A CDK project creates an “Application”. This app may have one or more “Stacks”. A Stack is a group of cloud resources (Lambda functions, S3 buckets, etc) that are instantiated using CDK classes. It’s also possible to have multiple applications in a single CDK project.</p>
<h3>App Object</h3>
<p>Creating a CDK app is as simple as:</p>
<blockquote>
<p>When you run <code>cdk init --language [language]</code>, an initial application with basic boilerplate code is created for you in the project root, under <code>app.py</code>.</p>
</blockquote>
<p>The next thing we need is an environment, which is composed of an AWS Account ID and Region:</p>
<div><pre><code data-lang="python">env <span>=</span> env <span>=</span> core<span>.</span>Environment(
    account<span>=</span><span>1234567890</span>,
    region<span>=</span><span>'us-east-1'</span>,
)
</code></pre></div><p>Declaring an environment is not required (CDK can infer from your AWS credentials), but is a good practice. Most of us work with multiple AWS accounts. It’s easy to mess around with several projects, accounts, credentials. When we explicitly set the environment in the CDK app, it’s locked and prevents mistaken deployments.</p>
<p>Now we declare our stacks:</p>
<div><pre><code data-lang="python"><span>from</span> my_project.my_project_stack <span>import</span> MyStack

my_stack <span>=</span> MyStack(
    app,
    <span>'my-stack'</span>,
    env<span>=</span>env,
)
</code></pre></div><p>This is how we <em>instantiate</em> our stacks for deployment. In the next section we’ll see how to <em>declare</em> those stacks.</p>
<h3>Stack Object</h3>
<p>The Stack object is where we <em>declare</em> our AWS resources. It inherits from the <code>core.Stack</code> CDK class and accepts a scope - which is our <code>app</code> object - a string identifier and an environment.</p>
<div><pre><code data-lang="python"><span>class</span> <span>MyStack</span>(core<span>.</span>Stack):
    <span>def</span> __init__(
            self,
            scope: core<span>.</span>Construct,
            id: str,
            env: core<span>.</span>Environment,
            <span>**</span>kwargs,
            ) <span>-&gt;</span> None:
        super()<span>.</span>__init__(scope, id, <span>**</span>kwargs)

        <span># Declare AWS resources here</span>

</code></pre></div><h3>Declaring AWS resources</h3>
<p>To declare AWS resources, we need a specific library for each service. Here’s a list of all <a href="https://docs.aws.amazon.com/cdk/api/latest/python/index.html">Python libraries</a> and their <a href="https://docs.aws.amazon.com/cdk/api/latest/typescript/api/index.html">Typescript</a> counterparts. Other flavors are <a href="https://docs.aws.amazon.com/cdk/api/latest/java/index.html">Java</a> and <a href="https://docs.aws.amazon.com/cdk/api/latest/dotnet/api/index.html">.NET</a>.</p>
<p>Let’s see how a basic REST API would be declared (typing expressions were removed for readability purposes):</p>
<div><pre><code data-lang="python"><span>from</span> aws_cdk <span>import</span> aws_apigateway, aws_lambda

<span>class</span> <span>MyStack</span>(core<span>.</span>Stack):
    <span>def</span> __init__(self, scope, id, env):
        super()<span>.</span>__init__(scope, id, <span>**</span>kwargs)

        my_lambda <span>=</span> aws_lambda<span>.</span>Function(
            self,
            <span>'MyLambda'</span>,
            runtime<span>=</span>aws_lambda<span>.</span>Runtime<span>.</span>PYTHON_3_8,
            code<span>=</span>aws_lambda<span>.</span>Code<span>.</span>asset(<span>'my_lambda_folder),</span>
            handler<span>=</span><span>'my_lambda.handler'</span>,
        )

        aws_apigateway<span>.</span>LambdaRestApi(
            self,
            <span>'sls-blog-rest-api-gateway'</span>,
            handler<span>=</span>my_lambda,
        )
</code></pre></div><p>We first declare a Lambda function <code>my_lambda</code>. We point its code to the <code>my_lambda_folder</code>. Inside this folder, there should be a <code>my_lambda.py</code> file, containing a function called <code>handler</code>. This handler function should accept Lambda invocations normally (an <code>event</code> and <code>context</code> objects).</p>
<p>Next a <code>LambdaRestApi</code> is declared, using <code>my_lambda</code> as the handler (not to confuse with the Lambda’s handler function). This will create a new API Gateway REST API integrated with <code>my_lambda</code> using an <a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-api-integration-types.html"><code>AWS_PROXY</code> integration type</a>. All HTTP requests will be routed to the Lambda function.</p>
<h2>Our Project App &amp; Stacks</h2>
<p><a href="https://d1qmte5oc6ndq5.cloudfront.net/">This project</a> comprises one application with three Stacks. They’re all declared in the <a href="https://github.com/byrro/serverless-website-demo/blob/master/app.py"><code>app.py</code> file</a> and <a href="https://github.com/byrro/serverless-website-demo/blob/master/sls_website/sls_website_stack.py"><code>sls_website_stack.py</code> file</a>.</p>
<p>Below we’ll walk through all Stacks in a high level. I encourage you to inspect the <a href="https://github.com/byrro/serverless-website-demo/blob/master/sls_website/sls_website_stack.py">stacks file</a> to learn how these resources are declared and also integrated. For example: a Kinesis Firehose is created in one Stack and referenced in another to include its name as an environment variable for the Lambda function that will interact with it.</p>
<p>Except for the frontend static Stack - which is small - you will notice that resources are initialized with a <code>None</code> (null) value in the beginning. The reason is that, even though the CDK is generally more succinct than CloudFormation, it can still be lengthy enough to clutter the view of the entire Stack. Having each resource declared first in one line, I can provide a short summary of everything that’s in the Stack and then instantiate the CDK classes in other methods.</p>
<div><pre><code data-lang="python"><span>class</span> <span>SlsBlogApiStack</span>(core<span>.</span>Stack):
    <span>def</span> __init__(self, scope, id, env, static_stack):
        super()<span>.</span>__init__(scope, id, <span>**</span>kwargs)

        self<span>.</span>static_stack <span>=</span> static_stack

        <span># SQS Queues</span>
        self<span>.</span>queue_ddb_streams_dlq <span>=</span> None  <span># Dead-letter-queue for DDB streams</span>

        <span># DynamoDB Tables</span>
        self<span>.</span>ddb_table_blog <span>=</span> None  <span># Single-table for all blog content</span>

        <span># DynamoDB Event Sources</span>
        self<span>.</span>ddb_source_blog <span>=</span> None  <span># Blog table streams source</span>

        <span># DynamoDB Indexes</span>
        self<span>.</span>ddb_gsi_latest <span>=</span> None  <span># GSI ordering articles by timestamp</span>

        <span># Lambda Functions</span>
        self<span>.</span>lambda_blog <span>=</span> None  <span># Serves requests to the blog public API</span>
        self<span>.</span>lambda_stream_reader <span>=</span> None  <span># Processes DynamoDB streams</span>

        <span># Continues with other resources...</span>
</code></pre></div><p>Notice it takes another Stack object (<code>static_stack</code>) as an argument to its initialization. In the <a href="https://github.com/byrro/serverless-website-demo/blob/master/app.py"><code>app.py</code> file</a>, you can see that the <code>SlsBlogApiStack</code> is initialized passing the <code>SlsBlogStack</code> as an argument.</p>
<p>We use it to reference the CloudFront distribution domain (<a href="https://d1qmte5oc6ndq5.cloudfront.net/">d1qmte5oc6ndq5.cloudfront.net</a>) in the Lambda environment variables. This variable can be used to customize the HTTP response header <code>Access-Control-Allow-Origin</code> to comply with <a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-cors.html">CORS standards</a>. This illustrates one way to easily integrate and reference information from one Stack into another within a CDK project.</p>
<p>At the end of the initialization, another method is called to instantiate the CDK classes for each resource and configure their parameters.</p>
<div><pre><code data-lang="python">self<span>.</span>create_cdk_resources()
</code></pre></div><p>Next we’ll walk through each of our project’s Stacks.</p>
<h3>Stack 1: static website</h3>
<p>Our focus is on the Serverless backend, so the frontend here is terribly rough and simple. It’s stored in an S3 Bucket …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dashbird.io/blog/crash-course-aws-cdk-serverless-rest-api-data-lake-analytical-querying/">https://dashbird.io/blog/crash-course-aws-cdk-serverless-rest-api-data-lake-analytical-querying/</a></em></p>]]>
            </description>
            <link>https://dashbird.io/blog/crash-course-aws-cdk-serverless-rest-api-data-lake-analytical-querying/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23881864</guid>
            <pubDate>Sat, 18 Jul 2020 15:06:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS Serverless: you might not need third party monitoring]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23881805">thread link</a>) | @kiyanwang
<br/>
July 18, 2020 | https://www.rehanvdm.com/general/aws-serverless-you-might-not-need-third-party-monitoring/index.html | <a href="https://web.archive.org/web/*/https://www.rehanvdm.com/general/aws-serverless-you-might-not-need-third-party-monitoring/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<ul><li><a data-class="popup" data-network="facebook" href="https://www.facebook.com/sharer.php?u=http%3A%2F%2Fwww.rehanvdm.com%2Fgeneral%2Faws-serverless-you-might-not-need-third-party-monitoring%2Findex.html" target="_blank" rel="nofollow"><i></i> </a></li><li><a data-class="popup" data-network="twitter" href="https://twitter.com/intent/tweet?text=AWS%20Serverless:%20you%20might%20not%20need%20third%20party%20monitoring&amp;url=http%3A%2F%2Fwww.rehanvdm.com%2Fgeneral%2Faws-serverless-you-might-not-need-third-party-monitoring%2Findex.html&amp;via=der_rehan" target="_blank" rel="nofollow"><i></i> </a></li><li><a data-class="popup" data-network="linkedin" href="https://linkedin.com/shareArticle?mini=true&amp;url=http%3A%2F%2Fwww.rehanvdm.com%2Fgeneral%2Faws-serverless-you-might-not-need-third-party-monitoring%2Findex.html&amp;title=AWS+Serverless%3A+you+might+not+need+third+party+monitoring" target="_blank" rel="nofollow"><i></i> </a></li></ul>




<p>I hardly ever find myself reaching for third party monitoring services these days. I rather use the AWS native observability, monitoring and alerting services. The primary reasons being that I can use my favorite Infrastructure as Code (IaC) tool to define the infrastructure as well as the monitoring, observability and dashboards for every project in one place. I also only pay for what I use; there are no monthly subscriptions.</p>



<p><em>This blog is also available as a presentation. Reach out if you would like me to present it at an event. It consists of about 30% slides and 70% live demo. </em><br></p>



<p>In this two-part series, we’ll first build a bad microservice system and add observability, monitoring and alerting. The second part will focus on refactoring the code and go into more details on the decisions made.</p>



<p>Like most of my blogs, this one is also accompanied by code. I decided to create three microservices, each in their own repositories, with the fourth one used to reference all of them. The code is available on github: <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://github.com/rehanvdm/MicroService" target="_blank">https://github.com/rehanvdm/MicroService</a>. These microservices were designed poorly for demo purposes and to explain the importance of certain points, like structured logging. Below are all three services:</p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_01_SystemArchitecture.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_01_SystemArchitecture-1024x715.png" alt="" width="1024" height="715" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_01_SystemArchitecture-1024x715.png 1024w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_01_SystemArchitecture-300x210.png 300w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_01_SystemArchitecture-768x536.png 768w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_01_SystemArchitecture.png 1111w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>Within each project you can find an <strong>OpenAPI </strong>(<a href="https://github.com/rehanvdm/MicroServicePerson/blob/master/part1/src/lambda/api/api-definition.yaml" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">part1/src/lambda/api/api-definition.yaml</a>) file that defines the API definition for each service.<strong> AWS CDK</strong> is used and they all follow the similar stock standard CDK project layout: Typescript for the CDK and <strong>ES6 JS</strong> for the application code. NPM commands have been written to do deployments and it also contains<strong> end-to-end tests </strong>using Mocha and Chai. In addition, each service contains a detailed README inside the /part1 path. Note that I only have a single Lambda for the API endpoint and do internal routing. Yes, I believe in a <strong>Lambalith for the API</strong> 😊 and also prefer JSON POST over REST (more about this later).</p>



<p>The client service stores clients and has basic <em>create-client</em> and <em>find-client</em> functionalities as well as an endpoint to increment the person count for a specific client. The person service also has basic <em>create-person</em> and <em>find-person</em> endpoints. When a person is created, it calls the common service which notifies me by email about the new person that was added using an SNS subscription. The common service first needs to do a lookup on the client service so that it can enrich the email. It also increments the counter on the client. Click on the image below to see the step-by-step path for creating a person:</p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_02_SystemArchitecturePathFocus.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_02_SystemArchitecturePathFocus-1024x553.png" alt="" width="1024" height="553" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_02_SystemArchitecturePathFocus-1024x553.png 1024w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_02_SystemArchitecturePathFocus-300x162.png 300w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_02_SystemArchitecturePathFocus-768x415.png 768w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_02_SystemArchitecturePathFocus.png 1442w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>In Part 2 we will focus on refactoring and decoupling this system. That brings me to the reason why the current system is poorly designed. I <strong>purposefully created a distributed monolith</strong>.</p>



<p>The create-person call is highly dependent on the common
service and does not even know that the common service is dependent on the
client service. As a result, the person service is also dragged down if either
the common or the client service is down. Not to mention that it now has to
wait for the completion of every step in the synchronous chain. This wastes money
and increases the probability of hitting the API Gateway timeout of 29 seconds.
</p>



<p>Let’s first look at a few generic concepts that are referenced throughout the post. Then we will look at the AWS native services.</p>



<h2>Structured logging, types of errors and metrics</h2>



<h3>Errors</h3>



<p><u>Hard Errors</u> are infrastructure and runtime errors. You should always have alerts on these. Ex. time out, unexpected error and runtime errors not caught by try-catch blocks.</p>



<p><u>Soft Errors</u> are completely software-defined. This is when your infrastructure and services are working but the <strong>result was undesired</strong>. An example would be that your API returned an HTTP status code 200 with a validation error message in the body. </p>



<h3>Metrics</h3>



<p><u>Business Metrics </u>– Key performance indicators (KPIs) that you use to measure your application performance against. Ex. orders placed.</p>



<p><u>Customer Experience Metrics</u> – Percentiles and perceived latencies that the user is experiencing. A typical scenario would be page load times. Another would be that even though your API is fast, the front-end needs to make 10 concurrent API calls when the application starts. The browsers then queues these concurrent requests and the user waits at least two or three times longer.</p>



<p><u>System Metrics</u> – Application level metrics that indicate system health. Ex. number of API requests, queue length, etc. </p>



<h3>Structured logging</h3>



<p>All microservices write logs in the format below. This is done by wrapping around the <em>console </em>class and writing in JSON format. Levels will include all your basics, like info, log, debug, error, warning, with the only new one being audit.</p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_10_StructuredLogging1.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_10_StructuredLogging1.png" alt="" width="737" height="38" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_10_StructuredLogging1.png 737w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_10_StructuredLogging1-300x15.png 300w" sizes="(max-width: 737px) 100vw, 737px"></a></figure>



<p>A single audit record is written per Lambda execution and gives a summary for the result of that execution. The image below shows an audit record that contains the API path, run time, status code, reason and many more fields used in the Log Insight queries later on. </p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_10_StructuredLogging2.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_10_StructuredLogging2.png" alt="" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_10_StructuredLogging2.png 522w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_10_StructuredLogging2-300x246.png 300w" sizes="(max-width: 522px) 100vw, 522px"></a></figure>



<p> The image below shows an unsuccessful execution:</p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_10_StructuredLogging3.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_10_StructuredLogging3.png" alt="" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_10_StructuredLogging3.png 506w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_10_StructuredLogging3-300x251.png 300w" sizes="(max-width: 506px) 100vw, 506px"></a></figure>



<p>Note that the runtime is not the one reported by Lambda.
There is an environment variable on the Lambda itself that indicates what the
function timeout value is. We then subtract the <em>context.getRemainingTimeInMillis()</em>
to get a close estimate to the actual reported runtime.</p>



<p>Let’s take a closer look at the AWS Native services that we will use. </p>



<h2>AWS CloudWatch Logs</h2>



<p>Logs are crucial to any application. CloudWatch stores logs in the format of log groups and log streams. Each log group can be considered a Lambda function and a stream is the executions of that Lambda function. The real magic happens when you do log insights over your structured logs. </p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_03_CloudWatchLogs.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_03_CloudWatchLogs-1024x402.png" alt="" width="1024" height="402" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_03_CloudWatchLogs-1024x402.png 1024w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_03_CloudWatchLogs-300x118.png 300w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_03_CloudWatchLogs-768x301.png 768w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<h2>AWS CloudWatch Metrics</h2>



<p>Metrics are best described as the logging of discrete data points for a system against time. These metrics can then be displayed on graphs, like; database CPU versus time or the types of API response over time. They are at the heart of many services, like dashboards, alerts and auto scaling. If you write a log line in a specific format, called the <a rel="noreferrer noopener" aria-label="Embedded Metric Format (opens in a new tab)" href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch_Embedded_Metric_Format.html" target="_blank">Embedded Metric Format</a>, it automatically transforms it into a metric. Find the client libraries that help write this format <a rel="noreferrer noopener" aria-label="here (opens in a new tab)" href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch_Embedded_Metric_Format_Libraries.html" target="_blank">here.</a></p>



<p>Below shows the amount of API calls summed by 1-minute intervals for the client API after the <a rel="noreferrer noopener" aria-label="artillery.io (opens in a new tab)" href="https://artillery.io/" target="_blank">artillery.io</a> load test was run. </p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_04_CloudWatchMetric.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_04_CloudWatchMetric.png" alt="" width="910" height="500" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_04_CloudWatchMetric.png 910w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_04_CloudWatchMetric-300x165.png 300w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_04_CloudWatchMetric-768x422.png 768w" sizes="(max-width: 910px) 100vw, 910px"></a></figure>



<h2>AWS CloudWatch Alarms</h2>



<p>Alarms perform an action when certain conditions on Metrics are met. &nbsp;For example, CPU more than 50% for 3 minutes. Actions include emailing a person or sending the message to an SNS topic. This topic can then be subscribed to by other services. We subscribe to this topic with AWS Chatbot to deliver the notifications to a Slack channel.</p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm-1024x637.png" alt="" width="1024" height="637" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm-1024x637.png 1024w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm-300x187.png 300w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm-768x478.png 768w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm.png 1312w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>It is important to subscribe to both the ALERT and the OKAY actions. Otherwise you will never know if your system stabilized after an alert unless you log into the console and inspect the system. </p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm2.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm2.png" alt="" width="930" height="210" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm2.png 930w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm2-300x68.png 300w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm2-768x173.png 768w" sizes="(max-width: 930px) 100vw, 930px"></a></figure>



<p>Composite Alarms are great when you want to string together some sort of logic to give a higher order of alarm/event. For example, you can create an alarm if the database CPU is more than 50% and the API hit count is less than 1000 requests per minute. This will set off an event/alarm informing you that your database might be crunching away at a difficult query and that it might be a result of a person executing a heavy analytical query rather than your application.</p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm4-1024x259.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm4-1024x259.png" alt="" width="1024" height="259"></a></figure>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm3.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm3-1024x593.png" alt="" width="1024" height="593" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm3-1024x593.png 1024w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm3-300x174.png 300w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm3-768x445.png 768w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm3.png 1272w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>Anomaly detection uses machine learning (random cut forest) to train on up to two weeks of metric data. This creates upper and lower bands around your metric which are defined by standard deviations. Alerts can then be created whenever your metric is outside or within these bands. They are great at monitoring predictable periodic metrics, like API traffic.</p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm5.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm5.png" alt="" width="662" height="936" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm5.png 662w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm5-212x300.png 212w" sizes="(max-width: 662px) 100vw, 662px"></a></figure>



<h2>AWS CloudWatch Metric filters</h2>



<p>CloudWatch Metric filter will <strong>search the Logs for patterns and publish the search results as Metrics</strong>. For example, we can search for the word ‘retry’ in the logs and then publish it as a metric that we can view on a dashboard or <strong>create an alarm from</strong>. </p>



<p>This is <strong>how we count soft errors</strong>, which are errors that don’t crash the Lambda but return an undesired result to the caller. In our example, all the API Lambdas always return HTTP Status code 200. Within the body of the response is our request status code: 2000 – Success, 5000 – Unexpected, 5001 – Handled, 5002 – Validation, 3001 – Auth. Structured logging always writes the audit record in a specific format. We use this to create metrics and then alarms based on those metrics.</p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm6.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm6-1024x730.png" alt="" width="1024" height="730" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm6-1024x730.png 1024w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm6-300x214.png 300w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm6-768x548.png 768w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_05_CloudWatchAlarm6.png 1140w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<h2>AWS CloudWatch Dashboards</h2>



<p>Dashboards are great to get an overview of the operational status of your system.<strong> In the example services, each one also deploys their own dashboard</strong> to monitor basic metrics of the Lambda, API Gateway and DynamoDB table. Everything is defined as IaC using the <strong>AWS CDK</strong>.</p>



<figure><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_06_CloudWatchDashboards1.png" alt="" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_06_CloudWatchDashboards1.png 1020w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_06_CloudWatchDashboards1-300x259.png 300w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_06_CloudWatchDashboards1-768x664.png 768w" sizes="(max-width: 1020px) 100vw, 1020px"></figure>



<p>A manual dashboard can also be created to combine all the services onto one dashboard. I usually tend to make it less granular by just displaying the overall status of each microservice and other useful information. </p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_06_CloudWatchDashboards2.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_06_CloudWatchDashboards2-1024x771.png" alt="" width="1024" height="771" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_06_CloudWatchDashboards2-1024x771.png 1024w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_06_CloudWatchDashboards2-300x226.png 300w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_06_CloudWatchDashboards2-768x578.png 768w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_06_CloudWatchDashboards2.png 1142w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>The dashboard above contains three CloudWatch Log Insight query widgets. We can even write basic markup to create links/buttons, as seen in the bottom right corner. </p>



<h2>AWS CloudWatch Log Insights</h2>



<p>Log Insights enable us to do SQL-like querying over one or more Log Groups. This tool is<strong> extremely powerful</strong> to get insights out of your structured logs. It also has basic grouping functionality that can graph results. For example, we use a single query to <strong>query the audit records of all three microservices</strong> over the last 2 weeks (see below).</p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights1.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights1-1024x634.png" alt="" width="1024" height="634" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights1-1024x634.png 1024w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights1-300x186.png 300w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights1-768x475.png 768w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights1.png 1383w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights4.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights4.png" alt="" width="921" height="244" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights4.png 921w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights4-300x79.png 300w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights4-768x203.png 768w" sizes="(max-width: 921px) 100vw, 921px"></a></figure>



<p>We can also compare the latencies of all the microservice API calls and visually graph it in a bar chart. </p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights2.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights2-1024x762.png" alt="" width="1024" height="762" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights2-1024x762.png 1024w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights2-300x223.png 300w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights2-768x572.png 768w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights2.png 1159w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights5.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights5.png" alt="" width="803" height="188" srcset="https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights5.png 803w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights5-300x70.png 300w, https://www.rehanvdm.com/contents/data/2020/07/no_third_monit_07_CloudWatchLogInsights5-768x180.png 768w" sizes="(max-width: 803px) 100vw, 803px"></a></figure>



<p>Lastly, I want to highlight the <strong>most impactful API calls</strong>. This is taking the amount of calls and multiplying it by the 95-percentile latency. This gives us a quick indication of which API …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.rehanvdm.com/general/aws-serverless-you-might-not-need-third-party-monitoring/index.html">https://www.rehanvdm.com/general/aws-serverless-you-might-not-need-third-party-monitoring/index.html</a></em></p>]]>
            </description>
            <link>https://www.rehanvdm.com/general/aws-serverless-you-might-not-need-third-party-monitoring/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23881805</guid>
            <pubDate>Sat, 18 Jul 2020 14:58:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Font-weight: 300 considered harmful (and a fontconfig workaround)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23881769">thread link</a>) | @Liskni_si
<br/>
July 18, 2020 | https://work.lisk.in/2020/07/18/font-weight-300.html | <a href="https://web.archive.org/web/*/https://work.lisk.in/2020/07/18/font-weight-300.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="content">
			<header>
				
				<p>
					published <time datetime="2020-07-18">2020-07-18</time>
					<a href="https://github.com/liskin/liskin.github.com/commits/master/_posts/2020-07-18-font-weight-300.markdown">(revision history)</a>
				</p>
			</header>
			<p>Many web pages these days set <code>font-weight: 300</code> in their stylesheet. With
<a href="https://dejavu-fonts.github.io/">DejaVu Sans</a> as my preferred font, this
results in very thin and light text that is hard to read, because for some
reason the “DejaVu Sans ExtraLight” variant (weight 200) is being used for
weights &lt; 360 (in Chrome; in Firefox up to 399). Let’s investigate why this
happens and what can be done about it.</p>

<details id="toc">
  <summary>Table of Contents</summary>
<ul id="markdown-toc">
  <li><a href="#the-problem" id="markdown-toc-the-problem">The Problem</a></li>
  <li><a href="#macos-font-smoothing-css" id="markdown-toc-macos-font-smoothing-css">MacOS font smoothing, CSS</a></li>
  <li><a href="#linux-fontconfig-css" id="markdown-toc-linux-fontconfig-css">Linux, fontconfig, CSS</a></li>
  <li><a href="#the-solution" id="markdown-toc-the-solution">The Solution</a></li>
  <li><a href="#appendix-a-why-glob" id="markdown-toc-appendix-a-why-glob">Appendix A: Why glob?</a></li>
</ul>

</details>

<h3 id="the-problem">The Problem</h3>

<p>Here’s what <a href="https://work.lisk.in/img/font-weight-300/test.html">a test page</a> looks like on my
laptop (14” 1920x1080):</p>

<figure>
  <p><a href="https://work.lisk.in/img/font-weight-300/test-linux-dejavu.png"><img src="https://work.lisk.in/img/font-weight-300/test-linux-dejavu.png" alt="DejaVu Linux test"></a></p>
  <figcaption>DejaVu Sans at different font-weights</figcaption>
</figure>

<p>For comparison, and possibly also as a clue as to why web designers use
<code>font-weight: 300</code>, here’s a table of various font-weights of DejaVu Sans on
my system and the default sans-serif font on MacOS Catalina and Android
(unfortunately I don’t have any HiDPI laptop or low-DPI smartphone, so the
comparison might be imprecise/unfair):</p>

<figure>
  <table>
<thead>
<tr>
<th></th>
<th>DejaVu</th>
<th>MacOS</th>
<th>Android</th>
</tr>
</thead>


<tbody><tr>
<th>400</th>
<td><img src="https://work.lisk.in/img/font-weight-300/test-linux-dejavu-400.png"></td>
<td><img src="https://work.lisk.in/img/font-weight-300/test-macos-400.png"></td>
<td><img src="https://work.lisk.in/img/font-weight-300/test-android-400.png"></td>
</tr>

<tr>
<th>300</th>
<td><img src="https://work.lisk.in/img/font-weight-300/test-linux-dejavu-300.png"></td>
<td><img src="https://work.lisk.in/img/font-weight-300/test-macos-300.png"></td>
<td><img src="https://work.lisk.in/img/font-weight-300/test-android-300.png"></td>
</tr>

<tr>
<th>200</th>
<td><img src="https://work.lisk.in/img/font-weight-300/test-linux-dejavu-200.png"></td>
<td><img src="https://work.lisk.in/img/font-weight-300/test-macos-200.png"></td>
<td><img src="https://work.lisk.in/img/font-weight-300/test-android-200.png"></td>
</tr>

</tbody></table>
  <figcaption>Boldness comparison<sup id="fnref:screenshots"><a href="#fn:screenshots">1</a></sup> (scaled to equal
height)</figcaption>
</figure>

<h3 id="macos-font-smoothing-css">MacOS font smoothing, CSS</h3>

<p>In MacOS, <code>font-weight: normal</code> looks almost bold, so web designers who use
MacOS/Safari might use <code>font-weight: 300</code> to <a href="https://news.ycombinator.com/item?id=23553486">compensate for this, ruining it
for everybody else</a>. :-(</p>

<p>Well, actually not everybody, as some desktop users (e.g. a Fedora Live DVD)
won’t have an extra-light variant of sans serif, so the normal (regular, or
book) variant will be used for all weights. But Android users and desktop
users with DejaVu (used to be default on most Linux distributions, not sure
what’s the current status) and possibly also Windows users are affected.</p>

<p><a href="https://tonsky.me/blog/monitors/#turn-off-font-smoothing">Nikita Prokopov suggested that disabling font smoothing in MacOS reduces the
boldness</a>, and my
experiments confirm that. Furthermore, subpixel smoothing
(antialiasing)<sup id="fnref:macos-subpixel"><a href="#fn:macos-subpixel">2</a></sup> comes somewhere in the middle between the
default and no smoothing (on my display).</p>

<figure>
  <table>
<thead>
<tr>
<th></th>
<th>default</th>
<th>subpixel</th>
<th>no smooth</th>
<th>DejaVu</th>
</tr>
</thead>

<tbody><tr>
<th>400</th>
<td><img src="https://work.lisk.in/img/font-weight-300/test-macos-400.png"></td>
<td><img src="https://work.lisk.in/img/font-weight-300/test-macos-subpixel-400.png"></td>
<td><img src="https://work.lisk.in/img/font-weight-300/test-macos-nosmooth-400.png"></td>
<td><img src="https://work.lisk.in/img/font-weight-300/test-linux-dejavu-400.png"></td>
</tr>

<tr>
<th>300</th>
<td><img src="https://work.lisk.in/img/font-weight-300/test-macos-300.png"></td>
<td><img src="https://work.lisk.in/img/font-weight-300/test-macos-subpixel-300.png"></td>
<td><img src="https://work.lisk.in/img/font-weight-300/test-macos-nosmooth-300.png"></td>
<td><img src="https://work.lisk.in/img/font-weight-300/test-linux-dejavu-300.png"></td>
</tr>

<tr>
<th>200</th>
<td><img src="https://work.lisk.in/img/font-weight-300/test-macos-200.png"></td>
<td><img src="https://work.lisk.in/img/font-weight-300/test-macos-subpixel-200.png"></td>
<td><img src="https://work.lisk.in/img/font-weight-300/test-macos-nosmooth-200.png"></td>
<td><img src="https://work.lisk.in/img/font-weight-300/test-linux-dejavu-200.png"></td>
</tr>

</tbody></table>
  <figcaption>Effect of disabling font smoothing in MacOS</figcaption>
</figure>

<figure>
  <table>
<thead>
<tr>
<th></th>
<th>DejaVu</th>
<th>MacOS</th>
<th>Android</th>
</tr>
</thead>

<tbody><tr>
<th>400</th>
<td><img src="https://work.lisk.in/img/font-weight-300/test-linux-dejavu-400.png"></td>
<td><img src="https://work.lisk.in/img/font-weight-300/test-macos-nosmooth-400.png"></td>
<td><img src="https://work.lisk.in/img/font-weight-300/test-android-400.png"></td>
</tr>

<tr>
<th>300</th>
<td><img src="https://work.lisk.in/img/font-weight-300/test-linux-dejavu-300.png"></td>
<td><img src="https://work.lisk.in/img/font-weight-300/test-macos-nosmooth-300.png"></td>
<td><img src="https://work.lisk.in/img/font-weight-300/test-android-300.png"></td>
</tr>

<tr>
<th>200</th>
<td><img src="https://work.lisk.in/img/font-weight-300/test-linux-dejavu-200.png"></td>
<td><img src="https://work.lisk.in/img/font-weight-300/test-macos-nosmooth-200.png"></td>
<td><img src="https://work.lisk.in/img/font-weight-300/test-android-200.png"></td>
</tr>

</tbody></table>
  <figcaption>Boldness comparison, this time with no smoothing
in MacOs</figcaption>
</figure>

<p><del>Anyway, we can’t put all the blame on web designers. Matching an extra-light
font with <code>font-weight: 300</code> doesn’t seem to be a good idea, and matching it
with <code>font-weight: 350</code> is just plain silly (and I’d need to use explicit
language to describe my feelings about Firefox using an extra-light font for
<code>font-weight: 399</code>).</del></p>

<p>Actually, we can put all the blame on them, as <code>font-weight: 300</code> has always
(<a href="https://www.w3.org/TR/CSS1/#font-weight">even in CSS Level 1</a>) meant
“lighter than normal, even if the only lighter font is weight 100.” Firefox’s
behaviour of selecting an extra-light font for <code>font-weight: 399</code> is in fact
<a href="https://developer.mozilla.org/en-US/docs/Web/CSS/font-weight#Fallback_weights">conforming to the most recent draft specification</a>.</p>

<p>MacOS’ somewhat bolder rendering of normal-weight fonts is therefore a
<em>very</em> weak excuse for using <code>font-weight: 300</code>, which literally forces the
browser to not use a normal-weight font (or bolder) unless there is no other
font available.</p>

<p>With that out of the way, let’s finally proceed to <del>fix</del> work around the
problem, since persuading thousands of web developers to fix their websites
doesn’t seem feasible at this point.</p>

<h3 id="linux-fontconfig-css">Linux, fontconfig, CSS</h3>

<p>Font selection and appearance in Linux is
<a href="https://wiki.archlinux.org/index.php/Font_configuration">highly</a>
<a href="https://wiki.archlinux.org/index.php/Font_configuration/Examples">configurable</a>
via <a href="https://www.freedesktop.org/software/fontconfig/fontconfig-user.html">fontconfig</a>. That is both a curse and a blessing. In this case, it is
quite advantageous.</p>

<p>There are a few handy command-line utilities which make it really easy to test
the configuration. I’ll use <a href="https://linux.die.net/man/1/fc-list">fc-list</a> and <a href="https://linux.die.net/man/1/fc-match">fc-match</a> here to see what
fonts I have and when DejaVu Sans ExtraLight is used:</p>

<div><div><pre><code>$ fc-list | grep -F -w 'DejaVu Sans' | sort
/usr/share/fonts/truetype/dejavu/DejaVuSans-BoldOblique.ttf: DejaVu Sans:style=Bold Oblique
/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf: DejaVu Sans:style=Bold
/usr/share/fonts/truetype/dejavu/DejaVuSansCondensed-BoldOblique.ttf: DejaVu Sans,DejaVu Sans Condensed:style=Condensed Bold Oblique,Bold Oblique
/usr/share/fonts/truetype/dejavu/DejaVuSansCondensed-Bold.ttf: DejaVu Sans,DejaVu Sans Condensed:style=Condensed Bold,Bold
/usr/share/fonts/truetype/dejavu/DejaVuSansCondensed-Oblique.ttf: DejaVu Sans,DejaVu Sans Condensed:style=Condensed Oblique,Oblique
/usr/share/fonts/truetype/dejavu/DejaVuSansCondensed.ttf: DejaVu Sans,DejaVu Sans Condensed:style=Condensed,Book
/usr/share/fonts/truetype/dejavu/DejaVuSans-ExtraLight.ttf: DejaVu Sans,DejaVu Sans Light:style=ExtraLight
/usr/share/fonts/truetype/dejavu/DejaVuSansMono-BoldOblique.ttf: DejaVu Sans Mono:style=Bold Oblique
/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf: DejaVu Sans Mono:style=Bold
/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Oblique.ttf: DejaVu Sans Mono:style=Oblique
/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf: DejaVu Sans Mono:style=Book
/usr/share/fonts/truetype/dejavu/DejaVuSans-Oblique.ttf: DejaVu Sans:style=Oblique
/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf: DejaVu Sans:style=Book
/usr/share/fonts/truetype/ttf-dejavu/DejaVuSans-Bold.ttf: DejaVu Sans:style=Bold
/usr/share/fonts/truetype/ttf-dejavu/DejaVuSansMono-Bold.ttf: DejaVu Sans Mono:style=Bold
/usr/share/fonts/truetype/ttf-dejavu/DejaVuSansMono.ttf: DejaVu Sans Mono:style=Book
/usr/share/fonts/truetype/ttf-dejavu/DejaVuSans.ttf: DejaVu Sans:style=Book
</code></pre></div></div>

<div><div><pre><code>$ fc-match -v sans \
  | grep -F -w -e style: -e weight: -e fullname:
        style: "Book"(s)
        fullname: "DejaVu Sans"(s)
        weight: 80(f)(s)

$ fc-match -v sans:weight=extralight \
  | grep -F -w -e style: -e weight: -e fullname:
        style: "ExtraLight"(s)
        fullname: "DejaVu Sans ExtraLight"(s)
        weight: 40(f)(s)

$ fc-match -v sans:weight=60 | grep -F -w -e weight: 
        weight: 40(f)(s)

$ fc-match -v sans:weight=61 | grep -F -w -e weight: 
        weight: 80(f)(s)

$ fc-match -v sans:weight=139 | grep -F -w -e weight: 
        weight: 80(f)(s)

$ fc-match -v sans:weight=140 | grep -F -w -e weight: 
        weight: 200(f)(s)
</code></pre></div></div>

<p>Fontconfig defines these symbolic font weights:</p>

<figure>

  <table>
    <thead>
      <tr>
        <th>constant</th>
        <th>value</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>thin</td>
        <td>0</td>
      </tr>
      <tr>
        <td>extralight</td>
        <td>40</td>
      </tr>
      <tr>
        <td>ultralight</td>
        <td>40</td>
      </tr>
      <tr>
        <td>light</td>
        <td>50</td>
      </tr>
      <tr>
        <td>demilight</td>
        <td>55</td>
      </tr>
      <tr>
        <td>semilight</td>
        <td>55</td>
      </tr>
      <tr>
        <td>book</td>
        <td>75</td>
      </tr>
      <tr>
        <td>regular</td>
        <td>80</td>
      </tr>
      <tr>
        <td>normal</td>
        <td>80</td>
      </tr>
      <tr>
        <td>medium</td>
        <td>100</td>
      </tr>
      <tr>
        <td>demibold</td>
        <td>180</td>
      </tr>
      <tr>
        <td>semibold</td>
        <td>180</td>
      </tr>
      <tr>
        <td>bold</td>
        <td>200</td>
      </tr>
      <tr>
        <td>extrabold</td>
        <td>205</td>
      </tr>
      <tr>
        <td>black</td>
        <td>210</td>
      </tr>
      <tr>
        <td>heavy</td>
        <td>210</td>
      </tr>
    </tbody>
  </table>

  <figcaption>Fontconfig weight constants</figcaption>
</figure>

<p>Apparently fontconfig selects the font with the closest weight requested.
That’s not what <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/font-weight#Fallback_weights">CSS needs</a>, so browsers probably don’t use
fontconfig font patterns and therefore <a href="https://old.reddit.com/r/linuxquestions/comments/a4h90n/using_fontconfig_to_block_a_problematic_font/">the usual fontconfig ways of avoiding
the extra-light font don’t
work.</a></p>

<p>But wait. Actually, some browsers do. The <a href="https://surf.suckless.org/">surf</a> browser, built using
<a href="https://webkitgtk.org/">WebKitGTK</a>, translates <code>font-weigth: 300</code> to fontconfig weight 50,
<code>font-weight: 200</code> to fontconfig weight 40 and <code>font-weight: 100</code> to
fontconfig weight 0, which is a correct mapping, but it won’t result in
correct behaviour if only font weights 0 and 80 are available, as 80 is closer
to 60, but CSS mandates that 0 is chosen. (To find this out, I used
<code>FC_DEBUG=1 surf</code>.) Indeed, the fontconfig configuration suggested in the link
above is a sufficient workaround for the <a href="https://webkitgtk.org/">WebKitGTK</a> browser:</p>

<figure>
  <figcaption>surf before</figcaption>
  <div><div><pre><code>$ FC_DEBUG=1 surf test.html |&amp; grep -F -w -c ExtraLight
7
</code></pre></div>  </div>
</figure>

<figure>
  <figcaption>~/.config/fontconfig/fonts.conf</figcaption>
  <div><div><pre><code><span>&lt;?xml version="1.0"?&gt;</span>
<span>&lt;!DOCTYPE fontconfig SYSTEM "fonts.dtd"&gt;</span>
<span>&lt;fontconfig&gt;</span>
	<span>&lt;match</span> <span>target=</span><span>"pattern"</span><span>&gt;</span>
		<span>&lt;test</span> <span>qual=</span><span>"any"</span> <span>name=</span><span>"family"</span><span>&gt;</span>
			<span>&lt;string&gt;</span>DejaVu Sans<span>&lt;/string&gt;</span>
		<span>&lt;/test&gt;</span>
		<span>&lt;test</span> <span>name=</span><span>"weight"</span> <span>compare=</span><span>"less"</span><span>&gt;</span>
			<span>&lt;const&gt;</span>book<span>&lt;/const&gt;</span>
		<span>&lt;/test&gt;</span>
		<span>&lt;edit</span> <span>name=</span><span>"weight"</span> <span>mode=</span><span>"assign"</span> <span>binding=</span><span>"same"</span><span>&gt;</span>
			<span>&lt;const&gt;</span>book<span>&lt;/const&gt;</span>
		<span>&lt;/edit&gt;</span>
	<span>&lt;/match&gt;</span>
<span>&lt;/fontconfig&gt;</span>
</code></pre></div>  </div>
</figure>

<figure>
  <figcaption>surf after</figcaption>
  <div><div><pre><code>$ FC_DEBUG=1 surf test.html |&amp; grep -F -w -c ExtraLight
0
</code></pre></div>  </div>
</figure>

<p>In a real CSS-conforming browser, this won’t work as fontconfig is
presumably only used to list available fonts, and the font matching algorithm
then runs in the browser engine itself. One might also desperately attempt to
use fontconfig’s <code><span>&lt;match</span> <span>target=</span><span>"scan"</span><span>&gt;</span></code> to lower
the weight of the font to 0 and hope the browser will select the nearer,
normal variant. Or at least I did desperately try that. That won’t work,
either:</p>

<ol>
  <li>
    <p>CSS still prefers a weight 0 font for <code>font-weight: 300</code> when both weight 0
and weight 400 are available.</p>
  </li>
  <li>
    <p><code><span>&lt;match</span> <span>target=</span><span>"scan"</span><span>&gt;</span></code> needs to be applied
system-wide and fontconfig caches then need to be regenerated using
<a href="https://linux.die.net/man/1/fc-cache">fc-cache</a> by root, as apparently the system-wide caches are preferred.
Therefore it’s also impossible to apply this rule to a web browser only.</p>
  </li>
</ol>

<p>There is still one option left, fortunately: <code><span>&lt;selectfont&gt;</span></code>, which controls the set of available fonts. Its documentation
is quite high-level and in some aspects downright incorrect, but by reading
<a href="https://github.com/freedesktop/fontconfig/blob/437f03299bd1adc9673cd576072f1657be8fd4e0/src/fccfg.c#L461-L478">the source</a>
we can conclude that it works like this:</p>

<ol>
  <li>
    <p>First, check if the filename is explicitly accepted by any <code><span>&lt;glob&gt;</span></code>. If it isn’t, then check whether it’s rejected,
and only if it’s not accepted but it is explicitly rejected, skip the font.
Otherwise continue.</p>

    <p>(The documentation claims that <code><span>&lt;glob&gt;</span></code> only
filters directories, but this is fortunately not true.)</p>
  </li>
  <li>
    <p>Then, similarly, check if the font matches any accept <code><span>&lt;pattern&gt;</span></code> (these may test various font properties). If
not, check reject patterns, and skip the font if rejected and not accepted.
Otherwise continue and allow the font to be used.</p>
  </li>
  <li>
    <p>Order of configuration directives doesn’t matter, it’s just being added to
glob/pattern accept/reject lists as the configuration is read.</p>
  </li>
</ol>

<h3 id="the-solution">The Solution</h3>

<p>Fontconfig’s <code><span>&lt;selectfont&gt;</span></code> lets us hide DejaVu
Sans ExtraLight from the browser. If we want to keep the font available for
other applications (if we don’t, then it might be easier to just uninstall
it), let’s create a browser-specific fontconfig conf:</p>

<figure>
  <figcaption>~/.config/fontconfig/browser.conf</figcaption>
  <div><div><pre><code><span>&lt;?xml version="1.0"?&gt;</span>
<span>&lt;!DOCTYPE fontconfig SYSTEM "fonts.dtd"&gt;</span>
<span>&lt;fontconfig&gt;</span>
	<span>&lt;include&gt;</span>fonts.conf<span>&lt;/include&gt;</span>

	<span>&lt;!-- disable DejaVu Sans ExtraLight, it tends to match font-weight: 300 --&gt;</span>
	<span>&lt;selectfont&gt;</span>
		<span>&lt;rejectfont&gt;</span>
			<span>&lt;glob&gt;</span>*/DejaVuSans-ExtraLight.ttf<span>&lt;/glob&gt;</span>
		<span>&lt;/rejectfont&gt;</span>
	<span>&lt;/selectfont&gt;</span>
<span>&lt;/fontconfig&gt;</span>
</code></pre></div>  </div>
</figure>

<p>When we now set the <code>FONTCONFIG_FILE=~/.config/fontco…</code></p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://work.lisk.in/2020/07/18/font-weight-300.html">https://work.lisk.in/2020/07/18/font-weight-300.html</a></em></p>]]>
            </description>
            <link>https://work.lisk.in/2020/07/18/font-weight-300.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23881769</guid>
            <pubDate>Sat, 18 Jul 2020 14:52:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Facebook’s Data Center Network Architecture [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23881758">thread link</a>) | @godelmachine
<br/>
July 18, 2020 | http://nathanfarrington.com/papers/facebook-oic13.pdf | <a href="https://web.archive.org/web/*/http://nathanfarrington.com/papers/facebook-oic13.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://nathanfarrington.com/papers/facebook-oic13.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23881758</guid>
            <pubDate>Sat, 18 Jul 2020 14:51:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Improving Firefox Startup Time with the About:Home Startup Cache]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23881669">thread link</a>) | @severine
<br/>
July 18, 2020 | https://mikeconley.ca/blog/2020/07/13/improving-firefox-startup-time-with-the-abouthome-startup-cache/ | <a href="https://web.archive.org/web/*/https://mikeconley.ca/blog/2020/07/13/improving-firefox-startup-time-with-the-abouthome-startup-cache/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<h2>Don’t bury the lede</h2>



<p>We’re working on a thing to make Firefox start faster! It appears to work! Here’s a video showing off a before (left) and after (right):</p>



<figure><p><span><iframe width="625" height="352" src="https://www.youtube.com/embed/027tOvYZw88?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span>
</p></figure>



<h2>Improving Firefox Startup Time With The about:home Startup Cache</h2>



<p>For the past year or so, the Firefox Desktop Front-End Performance team has been concentrating on making improvements to browser startup performance.</p>



<p>The launching of an application like Firefox is quite complex. Meticulous profiling of Firefox startup in various conditions has, thankfully, helped reveal a number of opportunities where we can make improvements. We’ve been evaluating and addressing these opportunities, and several have made it into the past few Firefox releases.</p>



<p>This blog post is about one of those improvements that is currently in the later stages of development. I’m going to describe the improvement, and how we went about integrating it.</p>



<p>In a default installation of Firefox, the first (and only) tab that loads is about:home<sup id="rf1-3036"><a href="#fn1-3036" title="This is only true if the user hasn’t just restarted after applying an update, and if they haven’t set a custom home page or configured Firefox to restore their previous session on start." rel="footnote">1</a></sup>.</p>



<figure><img data-attachment-id="3038" data-permalink="https://mikeconley.ca/blog/2020/07/13/improving-firefox-startup-time-with-the-abouthome-startup-cache/abouthome/" data-orig-file="https://mikeconley.ca/blog/wp-content/uploads/2020/07/abouthome.png" data-orig-size="1144,853" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="abouthome" data-image-description="" data-medium-file="https://mikeconley.ca/blog/wp-content/uploads/2020/07/abouthome-300x224.png" data-large-file="https://mikeconley.ca/blog/wp-content/uploads/2020/07/abouthome-1024x764.png" src="https://mikeconley.ca/blog/wp-content/uploads/2020/07/xabouthome-1024x764.png.pagespeed.ic.IW4h6O6qkj.png" alt="" srcset="https://mikeconley.ca/blog/wp-content/uploads/2020/07/xabouthome-1024x764.png.pagespeed.ic.IW4h6O6qkj.png 1024w, https://mikeconley.ca/blog/wp-content/uploads/2020/07/xabouthome-300x224.png.pagespeed.ic.wVhPlDDCdi.jpg 300w, https://mikeconley.ca/blog/wp-content/uploads/2020/07/xabouthome-768x573.png.pagespeed.ic.FO3Xg95rAi.png 768w, https://mikeconley.ca/blog/wp-content/uploads/2020/07/xabouthome-624x465.png.pagespeed.ic.SojSX9wUNG.png 624w, https://mikeconley.ca/blog/wp-content/uploads/2020/07/xabouthome.png.pagespeed.ic.wA72oZvGF2.png 1144w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The about:home page is actually the same thing that appears when you open a new tab (about:newtab). The fact that they have different addresses allows us to treat their loading differently.</p>



<p>Your about:home might look slightly different from the above — depending on your locale, it may or may not include the Pocket stories.</p>



<p>Do not be fooled by what appears to be a very simple page of images and text. This page is actually quite sophisticated under the hood. It is designed to be customized by the user in the following ways:</p>



<p>Users can</p>



<ul><li>Collapse or expand sections</li><li>Remove sections entirely</li><li>Reorganize the order of their Top Sites by dragging and dropping</li><li>Pin and unpin Top Sites to their positions</li><li>Add their own custom Top Sites with custom thumbnails</li><li>Add or remove search engines from their Top Sites</li><li>Change the number of rows in the Top Sites and Recommended by Pocket sections</li><li>Choose to have the Highlights composed of any of the following:<ul><li>Visited pages</li><li>Recent bookmarks</li><li>Recent downloads</li><li>Pages recently saved to Pocket</li></ul></li></ul>



<p>The user can customize these things at any time, and any open copies of the page are expected to reflect those customizations immediately.</p>



<p>There are further complexities beyond user customization. The page is also designed to be easy for our design and engineering teams to experiment with reorganizing the layout and composition of the page so that they can test variations on its layout in the wild.</p>



<p>The about:home page also has special privileges not afforded to normal websites. It can</p>



<ul><li>Save and remove bookmarks</li><li>Add pages to Pocket</li><li>Cause the URL bar to be focused and selected</li><li>Show thumbnails for pages that the user has visited</li><li>Access both high and normal resolution favicons</li><li>Render information about the user’s recent activity (recent page visits, downloads, saves to Pocket, etc.)</li></ul>



<p>So while at first glance, this appears to be a static page of just images and text, rest assured that the page can do much more.</p>



<p>Like the Firefox Developer Tools UI, about:home is written with the help of the React and Redux libraries. This has allowed the about:home development team to create sophisticated, reusable, and composable components that could be easily tested using modern JavaScript testing methods.</p>



<p>Unsurprisingly, this complexity and customizability comes at a cost. The page needs to request a state object from the parent process in order to have the Redux store populated and to have React render it. Essentially, the page is dynamically rendering itself after the markup of the page loads.</p>



<p>Startup is a critical time for an application. The user has expressed a need for their browser, and we have an obligation to serve the user as quickly and efficiently as possible. The user’s time is a resource that we should not squander. Similarly, because so much needs to occur during startup,<sup id="rf2-3036"><a href="#fn2-3036" title="You can think of startup like a traveling circus coming to town. You have to get the trucks and trailers parked, get the tents set up, hook up power, then lighting and sound … it’s a big, complex operation, and we haven’t even shot a clown out of a cannon yet." rel="footnote">2</a></sup> disk reads, disk writes, and CPU time are also considered precious resources. They should only be used if there’s no other choice.</p>



<p>In this case, we believed that the CPU time and disk accesses spent constructing the state object and dynamically rendering the about:home page was competing with all of the other CPU and disk access happening during startup, and this was slowing us down from presenting about:home to the user in a timely way.</p>



<p>Generally speaking, in my mind there are four broad approaches to performance problems once a bottleneck has been identified.</p>



<ul><li>You can widen the bottleneck (make the operations more efficient)</li><li>You can divide the bottleneck (split the work into smaller slices that can be done over a longer period of time with rests in between)</li><li>You can move the bottleneck (defer work until later when it seems that there is less competition for resources, or move it to a different thread)</li><li>You can remove the bottleneck (don’t do the work)</li></ul>



<p>We started by trying to apply the last two approaches, wondering what startup performance would be like if the page did not render itself dynamically, but was instead a static page generated periodically and pulled off of the disk at startup.</p>



<h2>Prototype when possible</h2>



<p>The first step to improving something is finding a way to measure it. Thankfully, we already have a number of logged measurements for startup. One of those measurements gives us the time from process start to rendering the Top Sites section of about:home. This is not a perfect measurement—ideally, we’d measure to the point that the page finally “settles” and stops changing<sup id="rf3-3036"><a href="#fn3-3036" title="<a href=&quot;https://bugzilla.mozilla.org/show_bug.cgi?id=1637024&quot;>We’re working on something like that</a>" rel="footnote">3</a></sup>—but for this project, this measurement served our purposes.</p>



<p>Before investing a bunch of time into a potential improvement, it’s usually a good idea to try to see if what you’re gaining is worth the development time. It’s not always possible to build a prototype for performance improvements, but in this case it was.</p>



<p>The team quickly threw together a static copy of about:home and <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1614352">hacked together a patch to load that document during startup, rather than dynamically rendering the page</a>. We then tested that page on our reference hardware. As of this writing, it’s been about five months since that test was done, but <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1614352#c2">according to this comment</a>, the prototype yielded what appears to be an almost 20% win on time from process start to about:home painting Top Sites.</p>



<p>So, with that information, we thought we had a real improvement opportunity here. We decided to proceed with the idea, and began a long arduous search for “the right way to do it.”</p>



<h2>Pre-production</h2>



<p>As I mentioned earlier, about:home is complex. The infrastructure that powers it is complex. Coupled with the fact that no one on the Firefox Front-End Performance team had spent much time studying React and Redux meant that we had a lot of learning to do.</p>



<p>The first step was to get some React and Redux fundamentals under our belt. This meant building some small toy applications and getting familiar with the framework idioms and how things are organized.</p>



<p>With that grounding, the next step was to start reading the code — starting from the entrypoint into the code that powers about:home when the browser starts. <a href="https://docs.google.com/document/d/1zvDPcdqaZ7140nabNonQpD5Ln_nrAcJGBgFCJFG_0MM/edit#heading=h.1w5efh70rcvh">This was an intense period of study</a> that branched into many different directions. Part of the complexity was because much of the code is asynchronous and launched work on different threads, which introduced some non-determinism. While it is generally good for responsiveness to move work off of the main thread, it can lead to some complex reading and interpretation of the code when more than two threads are involved.</p>



<p>A tool we used during this analysis was the <a href="https://profiler.firefox.com/docs/#/">Firefox Profiler</a>, to get a realistic sense of the order of executions during startup. These profiles helped to inform much of our reading of the code.</p>



<p>This analysis helped us solidify our mental model of how about:home loads. With that model in place, it was much easier to propose practical approaches for introducing a static about:home document into the ecosystem of pre-existing code. <a href="https://docs.google.com/document/d/1zvDPcdqaZ7140nabNonQpD5Ln_nrAcJGBgFCJFG_0MM/edit#heading=h.1w5efh70rcvh">The Firefox Front-End Performance team documented our findings and recommendations</a> and then presented them to the team that originally built the about:home system to ensure that we were all on the same page and that we hadn’t missed anything critical. They were already aware that we were investigating potential performance improvements, and had very useful feedback for us, as well as historical product decision context that clarified our understanding.</p>



<p>Critically, we presented our recommendation for loading a static about:home page at startup and ensured that there were no upcoming plans for about:home that would break our mental model or render the recommendation no longer valid. Thankfully, it sounded like we were aligned and fine to proceed with our plan.</p>



<p>So what was the plan? We knew that since about:home is quite dynamic and can change over time<sup id="rf4-3036"><a href="#fn4-3036" title="As the user browses, bookmarks and downloads things, their Highlights and Top Sites sections might change. If Pocket is enabled, new stories will also be downloaded periodically." rel="footnote">4</a></sup> we needed a startup cache for about:home that could be periodically updated during the course of a browsing session. We would then load from that cache at startup. Clearly, I’m glossing over some details here, but that was the general plan.</p>



<p>As usual, no plan survives breakfast, and as we started to architect our solution, we identified things we would need to change along the way.</p>



<h2>Development</h2>



<p>We knew that the process that loads about:home would need to be able to read from the about:home startup cache. We also knew that about:home can potentially contain information about what pages the user has visited, and that about:home can do privileged things that normal web pages cannot. It seemed that this project would be a good opportunity to finish a project that was started (and mothballed) a year or so earlier: creating a special privileged content process for about:home. We would load about:home in that process, and add assertions to ensure that privileged actions from about:home could only happen from that content process type<sup id="rf5-3036"><a href="#fn5-3036" title="It’s vitally important that content processes have limited abilities. That way, if they’re ever compromised by a bad actor, there are limits to what damage they can do. The assertions mentioned in this case mean that if a compromised content process tries to “pretend” to be the privileged about content process by sending one of its messages, that the parent process will terminate that content process immediately." rel="footnote">5</a></sup></p>



<p>So getting the “privileged about content process”<sup id="rf6-3036"><a href="#fn6-3036" title="Naming is hard." rel="footnote">6</a></sup> fixed up and ready for shipping was the first step.</p>



<p>This also paved the way for …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mikeconley.ca/blog/2020/07/13/improving-firefox-startup-time-with-the-abouthome-startup-cache/">https://mikeconley.ca/blog/2020/07/13/improving-firefox-startup-time-with-the-abouthome-startup-cache/</a></em></p>]]>
            </description>
            <link>https://mikeconley.ca/blog/2020/07/13/improving-firefox-startup-time-with-the-abouthome-startup-cache/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23881669</guid>
            <pubDate>Sat, 18 Jul 2020 14:40:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Booting to 'Hello Rust' on x86_64]]>
            </title>
            <description>
<![CDATA[
Score 237 | Comments 35 (<a href="https://news.ycombinator.com/item?id=23881584">thread link</a>) | @micouay
<br/>
July 18, 2020 | https://micouy.github.io/posts/low-level-pt-1/ | <a href="https://web.archive.org/web/*/https://micouy.github.io/posts/low-level-pt-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<article>
    
<p>This post is about how I booted to bare metal Rust on x86_64.
My goal is to describe my learning path and hopefully get
you interested in things I talk about. I’ll be very happy if you
find this content useful. Note that I’m a begginer and I may be wrong
about many things. If you want to learn more, I’ll put links to many resources.
You can find all the code in my <a href="https://github.com/micouy/gniazdo-os">repo</a>.</p>

<p>The inspiration for this project came from many sources. I think I first
discovered <a href="https://github.com/cfenollosa/os-tutorial">cfenollosa/os-tutorial</a>.
I also read a few chapters from <a href="https://www.cs.bham.ac.uk/~exr/lectures/opsys/10_11/lectures/os-dev.pdf">Writing a Simple Operating System - from Scratch</a>.
It’s a good introduction to OS dev and related topics. First part
of the tutorial is about bootloaders. To get a grasp of what it’s
all about, I just read every part of the tutorial and tried to write the Assembly
code by myself.</p>
<p>Here’s a brief explanation of the boot process and what you have to do
at each stage. First the CPU thinks it’s an Intel 8086 model form 1970s IIRC. This stage is
called Real Mode. You have ~1MiB of memory and 16-bit <a href="https://en.wikipedia.org/wiki/Processor_register">registers</a>
at your disposition. In RM you are very limited. However, at this stage
you can use BIOS routines (or interrupts). They’re like an external library you can use to
print a character on the screen, read from and write to hard disk etc.
You can obviously do these things in other modes but you have to implement it yourself
or do some hacking to use the interrupts.</p>
<p>When you’re done with RM, you can switch to Protected Mode. In PM the address space
is extended (you can access more memory), 32-bit registers are enabled
and addressing works a bit different. To switch to PM,
you have to set up a <a href="http://www.osdever.net/tutorials/view/the-world-of-protected-mode">Descriptor Table</a>
which is a piece of data that tells the CPU
how to interpret addresses, and describes the characteristics of particular
parts of the memory.</p>
<hr>
<p><strong>Note</strong>: At first I thought that in PM address like <code>ds:ebx</code>
works just like in RM - <code>ds</code> is the segment (in ‘data’ memory if you want
to read/write to it or in ‘code’ memory if you jump to it) and <code>ebx</code>
is the offset in this segment. In reality <code>ds</code> acts like an index
into the descriptor table. Then, the selected descriptor is used
to translate the offset from the segment base (stored in <code>ebx</code>) to a physical address.
You can read more about addressing in PM <a href="http://ece-research.unm.edu/jimp/310/slides/micro_arch2.html">here</a>.
Also check out other stuff on <a href="http://ece-research.unm.edu/jimp/">their website</a>.</p>
<hr>

<p>The bootloader is a very short piece of code - it’s just 512 bytes long.
I once even ran out of space and had to remove some strings and unnecessary
code. The actual purpose of the bootloader is to load and run some other code.
The book suggested booting to PM and jumping to a 32-bit kernel written in C.
I didn’t really like programming in C and at this point I lost my motivation.</p>
<p>Another time I learned about Philipp Oppermann’s <a href="https://os.phil-opp.com/">blog</a>
on OS dev in Rust. I highly recommend it. I got really excited but,
unfortunately for me, Oppermann uses <a href="https://www.gnu.org/software/grub/">GRUB</a>
(a kind of bootloader) so I decided to come back to the tutorial after
finishing my own bootloader. At that time booting to a program written in language
other than Assembly and compiled to a separate file was way beyond my capabilities
so I left the project for a while.</p>
<p>A couple weeks ago I got motivated enough to try to boot to a Rust program.
My plan was to switch to Long Mode. Then I could either run a 64-bit kernel
or load a second stage bootloader. Second stage bootloader is not limited
to one sector (can be more than 512 bytes long) and can be 32-bit
or even 64-bit so it has access to a larger address space and can load
arbitrarily large files from disk to memory (as long as you implement it).
Its purpose is to load larger kernels.</p>
<p>The first step was loading my program from hard disk to memory.
I took a naive approach. I compiled the bootloader and my program.
I concatenated both binaries together, one right after the other, to form one file, like this:</p>
<div><pre><code data-lang="bash">cat bootloader.bin hello_rust.bin &gt; img
</code></pre></div><p>I didn’t care if I could actually execute Rust code, I just wanted
to test if I can load it. I added necessary code to my bootloader
and ran the emulator. Unfortunately QEMU just kept restarting.
I’m not sure what went wrong but it didn’t matter since it
was a stupid way to do it. I could just test loading data from the disk on
a much simpler bootloader. I first tried to write it myself but after a while
I just grabbed some code from Stack Overflow and added a simple error message in case
the BIOS routine failed. After a couple of tries I finally managed to create
a two-stage bootloader in a single Assembly program. It worked something like this:</p>
<div><pre><code data-lang="nasm"><span>org</span> <span>0x7c00</span>
first_stage:
    <span>; load second stage.</span>

    <span>; `dl` register specifies which disk to load</span>
    <span>; data from. it is set by the CPU to the same device</span>
    <span>; the bootloader was loaded from.</span>

    <span>; set `es` to 0x7e0 and `bx` to 0x0.</span>
    
    <span>; the routine will load data to `(es &lt;&lt; 4) | bx`</span>
    <span>; or 0x7e00.</span>
    <span>mov</span> ax, <span>0x7e0</span>
    <span>mov</span> es, ax
    <span>mov</span> bx, <span>0x0</span>

    <span>mov</span> al, <span>0x1</span> <span>; # of sectors to read.</span>
    
    <span>push</span> ax <span>; store `al` for later.</span>

    <span>; specify where the data is stored on the disk.</span>
    <span>mov</span> ch, <span>0x0</span> <span>; cylinder.</span>
    <span>mov</span> dh, <span>0x0</span> <span>; head.</span>
    <span>mov</span> cl, <span>0x2</span> <span>; sector right after bootloader.</span>

    <span>; `int 0x13` with `ah` set to 0x2</span>
    <span>; loads data from disk to memory.</span>
    <span>mov</span> ah, <span>0x2</span>
    <span>int</span> <span>0x13</span>

    <span>pop</span> bx <span>; restore `al` to `bl`.</span>

    <span>; check whether the number of sectors read is correct.</span>
    <span>cmp</span> al, bl
    <span>jne</span> error
       
    <span>jmp</span> <span>0x7e00</span> <span>; jump to second stage.</span>

error:
    <span>; print error message, then halt.</span>
    <span>jmp</span> <span>$</span>

<span>; fill the rest of the first sector with zeros.</span>
<span>; it's 510 and not 512 because the last two bytes</span>
<span>; are 0xaa and 0x55 - the 'magic' number.</span>
<span>times</span> <span>510</span><span>-</span>(<span>$</span><span>-</span><span>$$</span>) db <span>0</span>
<span>dw</span> <span>0xaa55</span>

second_stage:
    <span>; do something, then halt.</span>
    <span>jmp</span> <span>$</span>

<span>; padding to fill the rest of the second sector with zeros.</span>
<span>times</span> <span>1024</span><span>-</span>(<span>$</span><span>-</span><span>$$</span>) db <span>0</span>
</code></pre></div><p>This way I didn’t have to link multiple files and NASM managed the padding of sectors
for me. The code correctly compiled to a single file which was exactly 1024 bytes long -
two entire sectors.</p>
<p>You can also use <code>align 512</code> instead of <code>times 1024-($-$$)</code> to allow
your code to be arbitrarily large. This could be useful if you wanted to program
the second stage of your bootloader in Assembly.</p>
<hr>
<p><strong>Note</strong>: Don’t assume that the registers are initialized with any particular
value. It took me half an hour or so to realize that I didn’t set some register
correctly in such a simple piece of code. IIRC there are only two things you can
be sure of - that the bootloader will be loaded to 0x7c00 and that the <code>dl</code> register
points to the same device the bootloader has been loaded from.</p>
<hr>

<p>After I managed to load the second sector I wanted to replace the Assembly code
with Rust code. To check whether I could execute it I needed to switch to Long Mode.
That’s because I had some problems with compiling Rust code to 32-bit
and I ended up using the <code>x86_64-unknown-none</code> target triple, just like
in Oppermann’s tutorial.</p>
<p>Long Mode adds a new memory model (paging), and enables the use
of 64-bit instructions and registers. Switching to LM requires setting up paging.
I identity-mapped the first 2 MiB of memory which is enough for now. I think it
can be modified later by my Rust program. I read the following guides on paging:</p>
<ul>
<li><a href="https://wiki.osdev.org/Setting_Up_Long_Mode#Setting_up_the_Paging">https://wiki.osdev.org/Setting_Up_Long_Mode#Setting_up_the_Paging</a></li>
<li><a href="https://wiki.osdev.org/Paging#Enabling">https://wiki.osdev.org/Paging#Enabling</a></li>
<li><a href="https://intermezzos.github.io/book/first-edition/transitioning-to-long-mode.html">https://intermezzos.github.io/book/first-edition/transitioning-to-long-mode.html</a></li>
<li><a href="http://ece-research.unm.edu/jimp/310/slides/micro_arch3.html">http://ece-research.unm.edu/jimp/310/slides/micro_arch3.html</a></li>
<li><a href="https://os.phil-opp.com/entering-longmode/">https://os.phil-opp.com/entering-longmode/</a></li>
</ul>
<p>There are also other things you have to do before switching to LM
like checking <code>cpuid</code> instruction support and the highest instruction
op code available.</p>

<p>I figured that to execute Rust code I needed to glue it with
the bootloader to create a single binary. In this step I encountered
a few difficult problems:</p>
<ul>
<li>To work correctly, the bootloader has to be stored in the first 512 bytes of the file.
The last two bytes of this sector have to be 0xaa55.</li>
<li>My Rust code should also be aligned with the sectors and fill up the last sector
entirely. Of course I would fill it with some garbage values but they had to
be there.</li>
<li>The bootloader has to know how long the Rust code is.</li>
<li>Both programs will be loaded at specific locations in the memory
so I have to manage the offsets in addresses.</li>
</ul>
<p>Linker seemed like a tool made for this. I’ve never used a linker before so I just read
<a href="https://ftp.gnu.org/old-gnu/Manuals/ld-2.9.1/html_node/ld_toc.html"><code>ld</code>'s documentation</a>.
Unfortunately, I got a bit confused. I didn’t understand how the <code>.</code> operator
worked in linker scripts. I also got something wrong about the <code>AT()</code> instruction.
You can see the <a href="https://www.reddit.com/r/osdev/comments/hhd7uj/linking_bootloader_with_second_stage/">thread</a>
I started on Reddit.</p>
<p>Eventually I came up with such script:</p>
<pre><code>SECTIONS {
    .boot 0x7c00 : {
        *(.boot.*);
    }

    .hello_rust 0x7e00 : {
        *(.rust.*);
        . = ALIGN(512);
    } = 0xdeadc0de

    SECOND_STAGE_LENGTH = ((. - ADDR(.hello_rust)) &gt;&gt; 9);
}
</code></pre><p>Notice that I put all sections beginning with <code>.boot</code> in the first 512 bytes
and all sections beginning with <code>.rust</code> after 0x7e00. In order to make
it work I have to rename all sections in the ELF file emitted by <code>rustc</code>
so that they all start with a prefix. I do it using <code>objcopy</code>
(in some linkers this option is called <code>--prefix-sections</code>):</p>
<div><pre><code data-lang="bash">objcopy hello_rust.o hello_rust_prefixed.o --prefix-alloc-sections<span>=</span><span>'.rust'</span>
</code></pre></div><p>The there are two tricks in this script. The first one is that I align
the end of the <code>.rust</code> section to the nearest sector boundary with <code>. = ALIGN(512)</code>.
Then I fill the rest with some garbage using <code>= 0xdeadc0de</code>.
The second trick is in the last line. The <code>SECOND_STAGE_LENGTH</code>
variable tells the bootloader how many sectors the second stage occupies.
The size of this section is divided by 512 = 2^9. Since I know
that the end of this section is aligned with the boundaries
of the sectors I can just shift it 9 bits to the right.</p>
<p>These solutions seem a bit hacky. In my understanding the location
of a piece of code in an ELF file (most common target) doesn’t matter. This is not the
case with the bootloader since the code
must be aligned to 512 bytes and there must be a magic number
at the end of the first …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://micouy.github.io/posts/low-level-pt-1/">https://micouy.github.io/posts/low-level-pt-1/</a></em></p>]]>
            </description>
            <link>https://micouy.github.io/posts/low-level-pt-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23881584</guid>
            <pubDate>Sat, 18 Jul 2020 14:27:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kubectl – Configuration Guide]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 25 (<a href="https://news.ycombinator.com/item?id=23881485">thread link</a>) | @lukasbar
<br/>
July 18, 2020 | https://knowledgepill.it/posts/kubernetes-kubectl-client-config/ | <a href="https://web.archive.org/web/*/https://knowledgepill.it/posts/kubernetes-kubectl-client-config/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <p>Kubectl client gives us possibility to configure and switch easily between multiple K8s clusters.</p>
<h2 id="config-files-location-for-kubectl">Config files location for kubectl</h2>
<p>Main location for <code>kubectl</code> config files is <code>$HOME/.kube</code>, by default we have single config file named config:</p>
<div><pre><code data-lang="bash"><span>[</span>node1 ~<span>]</span>$ cd $HOME/.kube
<span>[</span>node1 .kube<span>]</span>$ ls -lah
total 4.0K
drwxr-xr-x <span>1</span> root root   <span>37</span> Mar <span>12</span> 20:48 .
dr-xr-x--- <span>1</span> root root   <span>19</span> Nov <span>29</span> 11:46 ..
drwxr-x--- <span>3</span> root root   <span>23</span> Mar <span>12</span> 20:48 cache
lrwxrwxrwx <span>1</span> root root   <span>26</span> Nov <span>29</span> 11:46 config -&gt; /etc/kubernetes/admin.conf
drwxr-x--- <span>3</span> root root 4.0K Mar <span>12</span> 20:48 http-cache
</code></pre></div><h2 id="multiple-config-files-and-kubeconfig-variable">Multiple config files and KUBECONFIG variable</h2>
<p>We can have multiple config files by setting proper <code>KUBECONFIG</code> shell variable.<br>
For example:</p>
<p><code>export KUBECONFIG=$KUBECONFIG:/root/.kube/additional_config</code></p>
<h2 id="check-config-from-kubectl">Check config from kubectl</h2>
<p>We can check current config(it will be empty because I don’t have anything in additional_config file - we’ll add something later - and this is only file in my <code>KUBECONFIG</code> variable):</p>
<div><pre><code data-lang="yaml">[node1 ~]$ kubectl config view
<span>apiVersion</span>: v1
<span>clusters</span>: []
<span>contexts</span>: []
<span>current-context</span>: <span>""</span>
<span>kind</span>: Config
<span>preferences</span>: {}
<span>users</span>: []
</code></pre></div><p>Or from specific file - let’s see default file:</p>
<div><pre><code data-lang="yaml">[node1 ~]$ kubectl config --kubeconfig=.kube/config view
<span>apiVersion</span>: v1
<span>clusters</span>:
- <span>cluster</span>:
    <span>certificate-authority-data</span>: DATA+OMITTED
    <span>server</span>: https://<span>192.168</span><span>.0</span><span>.38</span>:<span>6443</span>
  <span>name</span>: kubernetes
<span>contexts</span>:
- <span>context</span>:
    <span>cluster</span>: kubernetes
    <span>user</span>: kubernetes-admin
  <span>name</span>: kubernetes-admin@kubernetes
<span>current-context</span>: kubernetes-admin@kubernetes
<span>kind</span>: Config
<span>preferences</span>: {}
<span>users</span>:
- <span>name</span>: kubernetes-admin
  <span>user</span>:
    <span>client-certificate-data</span>: REDACTED
    <span>client-key-data</span>: REDACTED
</code></pre></div><p>If you don’t set <code>KUBECONFIG</code> variable all configuration will be taken from <code>$HOME/.kube/config</code></p>
<h2 id="objects-in-kubectl-config">Objects in kubectl config</h2>
<p><code>kubectl</code> has in its config files following object types:</p>
<ul>
<li>clusters - info about K8s cluster - contain cluster name and connection parameters</li>
<li>users - info about users by which you want connect to K8s clusters</li>
<li>contexts - triple of cluster/user/namespace</li>
</ul>
<h2 id="modifying-config-from-kubectl">Modifying config from kubectl</h2>
<h3 id="add-cluster">Add cluster</h3>
<div><pre><code data-lang="bash"><span>[</span>node1 ~<span>]</span>$ kubectl config --kubeconfig<span>=</span>.kube/additional_config set-cluster dev --server<span>=</span>https://192.168.1.100 --certificate-authority<span>=</span>fake-ca
Cluster <span>"dev"</span> set.
<span>[</span>node1 ~<span>]</span>$ kubectl config --kubeconfig<span>=</span>.kube/additional_config set-cluster prod --server<span>=</span>https://10.1.1.100 --certificate-authority<span>=</span>fake-ca
Cluster <span>"prod"</span> set.
</code></pre></div><h3 id="add-users">Add users</h3>
<div><pre><code data-lang="bash"><span>[</span>node1 ~<span>]</span>$ kubectl config --kubeconfig<span>=</span>.kube/additional_config set-credentials developer --client-certificate<span>=</span>fake-cert-file --client-key<span>=</span>fake-key-seefile
User <span>"developer"</span> set.
<span>[</span>node1 ~<span>]</span>$ kubectl config --kubeconfig<span>=</span>.kube/additional_config set-credentials prod_admin --client-certificate<span>=</span>fake-cert-file --client-key<span>=</span>fake-key-seefile
User <span>"prod_admin"</span> set.
</code></pre></div><h3 id="add-contexts">Add contexts</h3>
<div><pre><code data-lang="bash"><span>[</span>node1 ~<span>]</span>$ kubectl config --kubeconfig<span>=</span>.kube/additional_config set-context simple_app_development --cluster<span>=</span>dev --namespace<span>=</span>simple_app_dev --user<span>=</span>developer
Context <span>"simple_app_development"</span> created.
<span>[</span>node1 ~<span>]</span>$ kubectl config --kubeconfig<span>=</span>.kube/additional_config set-context simple_app_production --cluster<span>=</span>prod --namespace<span>=</span>simple_app_prod --user<span>=</span>prod_admin
Context <span>"simple_app_production"</span> created.
</code></pre></div><h3 id="delete-clusterusercontext-from-config">Delete cluster/user/context from config</h3>
<div><pre><code data-lang="bash">kubectl --kubeconfig<span>=</span>.kube/additional_config config unset users.&lt;name&gt;
kubectl --kubeconfig<span>=</span>.kube/additional_config config unset clusters.&lt;name&gt;
kubectl --kubeconfig<span>=</span>.kube/additional_config config unset contexts.&lt;name&gt;
</code></pre></div><h3 id="sample-config">Sample config</h3>
<div><pre><code data-lang="yaml">[node1 ~]$ kubectl config --kubeconfig=.kube/additional_config view
<span>apiVersion</span>: v1
<span>clusters</span>:
- <span>cluster</span>:
    <span>certificate-authority</span>: /root/fake-ca
    <span>server</span>: https://<span>192.168</span><span>.1</span><span>.100</span>
  <span>name</span>: dev
- <span>cluster</span>:
    <span>certificate-authority</span>: /root/fake-ca
    <span>server</span>: https://<span>10.1</span><span>.1</span><span>.100</span>
  <span>name</span>: prod
<span>contexts</span>:
- <span>context</span>:
    <span>cluster</span>: dev
    <span>namespace</span>: simple_app_dev
    <span>user</span>: developer
  <span>name</span>: simple_app_development
- <span>context</span>:
    <span>cluster</span>: prod
    <span>namespace</span>: simple_app_prod
    <span>user</span>: prod_admin
  <span>name</span>: simple_app_production
<span>current-context</span>: <span>""</span>
<span>kind</span>: Config
<span>preferences</span>: {}
<span>users</span>:
- <span>name</span>: developer
  <span>user</span>:
    <span>client-certificate</span>: /root/fake-cert-file
    <span>client-key</span>: /root/fake-key-seefile
- <span>name</span>: prod_admin
  <span>user</span>:
    <span>client-certificate</span>: /root/fake-cert-file
    <span>client-key</span>: /root/fake-key-seefile
</code></pre></div><h3 id="changing-context-to-work-with">Changing context to work with</h3>
<p>To get list of contexts(no need for <code>--kubeconfig</code> because we have our <code>additional_config</code> added to <code>KUBECONFIG</code> variable):</p>
<div><pre><code data-lang="bash"><span>[</span>node1 ~<span>]</span>$ kubectl config get-contexts
CURRENT   NAME                     CLUSTER   AUTHINFO     NAMESPACE
          simple_app_development   dev       developer    simple_app_dev
          simple_app_production    prod      prod_admin   simple_app_prod
</code></pre></div><p>To set context:</p>
<div><pre><code data-lang="bash"><span>[</span>node1 ~<span>]</span>$ kubectl config use-context simple_app_development
Switched to context <span>"simple_app_development"</span>.
</code></pre></div><p>To get current context:</p>
<div><pre><code data-lang="bash"><span>[</span>node1 ~<span>]</span>$ kubectl config current-context
simple_app_development
</code></pre></div><hr>
<h3 id="for-those-who-want-to-know-even-more-worth-to-read">For those who want to know even more… Worth to read!</h3>
<p><a href="https://gardener.cloud/documentation/guides/client_tools/bash_kubeconfig/">Kubeconfig context as bash prompt - Georgi from Gardener</a> - shell tricks and Windows CLI aproach</p>
<hr>

</div></div>]]>
            </description>
            <link>https://knowledgepill.it/posts/kubernetes-kubectl-client-config/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23881485</guid>
            <pubDate>Sat, 18 Jul 2020 14:10:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The landing site of NASA Apollo 11]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23881433">thread link</a>) | @uncertainquark
<br/>
July 18, 2020 | https://jatan.space/apollo-11-landing-site/ | <a href="https://web.archive.org/web/*/https://jatan.space/apollo-11-landing-site/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
		
	<main id="content" role="main">

	<div>
		<div>
						<article id="post-3755">
				<div>
<p>On July 20, 1969, NASA put two astronauts on the Moon. They chose to land the Apollo 11 spacecraft in a plain, not so rocky region called the Sea of Tranquility for primarily engineering simplicity. Nevertheless, the landing site had interesting scientific benefits as well.</p>







<p>When you look up to the Moon, you see several dark regions. These are vast, solidified lava plains sitting on top of huge, deep, ancient craters. The craters formed 4.1 to 3.8 billion years ago during a time when large <a href="https://en.wikipedia.org/wiki/Late_Heavy_Bombardment">asteroids and comets were bombarding</a> all planets and moons of the solar system. Later on, the Moon’s volcanoes filled those craters with lava which cooled over time to make the region appear as it does today.</p>



<p>Apollo 11’s landing region, the Sea of Tranquility, is one such giant basin formed during the bombardment period, then lava-filled by volcanoes, burying any of the basin’s rocks and mountains. Once the lava solidified, it formed smooth desert-like plains, which are much easier for spacecraft to land on than rocky areas. Though the Apollo landing still had to deal with plenty of impact craters as seen in the image <a href="http://lroc.sese.asu.edu/posts/484">captured by NASA’s Lunar Reconnaissance Orbiter</a> (LRO). The Moon really is <a href="https://jatan.space/its-craters-all-the-way-down/">cratered all the way down</a>.</p>



<div><figure><img src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/apollo-11-landing-site-lro.jpg?w=1200&amp;ssl=1" alt="" srcset="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/apollo-11-landing-site-lro.jpg?w=1000&amp;ssl=1 1000w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/apollo-11-landing-site-lro.jpg?resize=200%2C200&amp;ssl=1 200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/apollo-11-landing-site-lro.jpg?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/apollo-11-landing-site-lro.jpg?resize=800%2C800&amp;ssl=1 800w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/apollo-11-landing-site-lro.jpg?resize=400%2C400&amp;ssl=1 400w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"><figcaption>Apollo 11 landing site captured by NASA’s Lunar Reconnaissance Orbiter (LRO) from lunar orbit, showing the Lunar Module (LM) and other hardware left on the site <a rel="noreferrer noopener" href="http://lroc.sese.asu.edu/posts/484" target="_blank">Credit: LRO</a></figcaption></figure></div>



<p>The Sea of Tranquility is interesting in two more ways. Much like the other dark regions on the Moon, it is metal-rich, as evident under <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://web.archive.org/web/20141020135311/https://www.sctxca.org/export/sites/default/clubs-groups/sites/photog/Workshops/Reference_Materials/Technical_Presentations/moon_article_tom_barry.pdf" target="_blank">enhanced image processed techniques</a>. And curiously enough, it lacks a <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://moonmonday.wordpres.com/2019/06/17/massive-mascons-crashing-spacecrafts-since-1960s/" target="_blank">gravitational high</a> at its center, meaning its not as dense as some other basins on the Moon.</p>



<p>Apollo 11 collected 20 kilograms of rock and soil samples at the landing region and brought them to Earth for detailed studies in laboratories worldwide for decades. Scientists found the soil to be basaltic, which is interesting because that’s the most common rock type on Earth. Apollo 11 samples also contained tiny fragments of rocks thrown off by impacts on the bright, rocky areas nearby. Its composition was found to be in line with the leading theory of <a href="https://jatan.space/apollo-moon-origin/">how the Moon formed</a>. </p>



<p>Interestingly, rocks collected from smaller craters contained tiny patches of glass. NASA has made the complete science output from the Apollo 11 mission available in their <a href="https://www.history.nasa.gov/alsj/a11/as11psr.pdf">science report</a>. You can explore the Apollo 11 landing region in NASA’s <a href="https://quickmap.lroc.asu.edu/?extent=23.4401705,0.6561747,23.5066507,0.6893648&amp;proj=16&amp;layers=NrBsFYBoAZIRnpEoAsjYIHYFcA2vIBvAXwF1Siylw4oNEQBmOOR9RHfS870oA">interactive Moon map</a>, just like Google Maps, by clicking the image below.</p>







<p>The Apollo missions forever changed our understanding of the Moon’s origin. Here’s hoping that the renewed global frenzy of going to the Moon sticks around this time, as there are plenty of <a href="https://jatan.space/why-explore-the-moon/">reasons to explore the Moon</a>.</p>



<pre><a href="https://creativecommons.org/licenses/by-sa/4.0/"></a><a href="https://creativecommons.org/licenses/by-sa/4.0/"></a><a href="https://creativecommons.org/licenses/by-sa/4.0/" target="_blank" rel="noreferrer noopener" aria-label="￼ (opens in a new tab)"><img src="https://i2.wp.com/jatan.space/wp-content/uploads/2020/01/b1504-cc-by-sa.png?w=1200&amp;ssl=1" alt="" data-recalc-dims="1"></a> Article published under the freedom-respecting <a href="https://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0</a>, minus any media file(s) credited independently.</pre>

</div>

			</article>
					</div>
	</div>
</main><!--/.neve-main-->




</div></div>]]>
            </description>
            <link>https://jatan.space/apollo-11-landing-site/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23881433</guid>
            <pubDate>Sat, 18 Jul 2020 14:01:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Set Up a Paid Newsletter at Your Own Domain]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23881317">thread link</a>) | @tosh
<br/>
July 18, 2020 | https://balajis.com/set-up-a-paid-newsletter-at-your-own-domain/ | <a href="https://web.archive.org/web/*/https://balajis.com/set-up-a-paid-newsletter-at-your-own-domain/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                    <div>
                        <p>Here's how to set up a paid (or free!) newsletter using <a href="https://my.ghost.org/signup">Ghost</a> at a new custom domain.</p><p>Ghost is an alternative to Substack that allows you to start hosted and then migrate to your <a href="https://ghost.org/docs/concepts/hosting/">own server</a> when desired. It's open source, so it's fully customizable. And it has membership and monetization features included.</p><p>Why not Substack? It's wonderful, but as a centralized service it doesn't offer the same degree of customizability and flexibility. You can however <a href="https://substack.com/signup">get started</a> there a bit more easily, and it has leaderboards and a community.</p><p>Why not Wordpress? It's also wonderful, but it's not as modern as Ghost is. You can however quickly set up on wordpress.com and <a href="https://kinsta.com/blog/wordpress-com-vs-wordpress-org/">migrate</a> to a self-hosted version using wordpress.org, just like Ghost.</p><p>If you follow the instructions in this post, your blog will look something <a href="https://lyra.ghost.io/">like this</a> when done. Note the "subscribe" button in the upper right corner!</p><figure><img src="https://balajis.com/content/images/2020/07/image-3.png" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/image-3.png 600w, https://balajis.com/content/images/size/w1000/2020/07/image-3.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/image-3.png 1600w, https://balajis.com/content/images/2020/07/image-3.png 2148w" sizes="(min-width: 720px) 720px"></figure><h2 id="before-we-begin-a-note-on-pseudonymity-and-opsec">Before we begin: a note on pseudonymity and opsec</h2><p>One of the awesome things about Ghost is that it allows you to build an audience and <a href="http://www.marknagelberg.com/notes-on-the-pseudonymous-economy-balaji-srinivasan/">monetize pseudonymously</a> to protect your privacy. Do you want to set up a pseudonymous blog? If so, there are two options for you.</p><ul><li><em>State-level opsec</em>. For <a href="https://news.ycombinator.com/item?id=23789621">maximum opsec</a>, before following the instructions below you want to get a new laptop, a VPN, and a <a href="http://jpkoning.blogspot.com/2019/03/prepaid-debit-cards-other-anonymous.html">prepaid debit card</a>. You also want to read this post by <a href="https://blog.lopp.net/modest-privacy-protection-proposal/">Lopp</a> and this by <a href="https://theintercept.com/2015/11/12/edward-snowden-explains-how-to-reclaim-your-privacy/">Snowden</a> and do seemingly paranoid things that are beyond the scope of this post.</li><li><em>Crowd-level opsec</em>. Most people don't need <em>quite</em> that level of security yet, unless they are doing <a href="http://archive.is/b01Ta">NSA</a>-level stuff. Just setting up a new email, using a pseudonym on your blog, and configuring private domain registration will guard your privacy against much of the internet at large.</li></ul><p>Note that either way, the people with root access to the services below (Protonmail, Cloudflare, Ghost, Stripe, and optionally GitHub) will have data on you. Still, basic precautions will reduce your attack surface.</p><h2 id="step-1-get-an-email-and-a-domain">Step 1: Get an email and a domain</h2><p>The first step is to get a new email and register a custom domain.</p><ul><li>Get a new <a href="https://mail.protonmail.com/create/new">protonmail.com</a> address.</li><li>Find a new domain using <a href="https://domize.com/">domize.com</a>.</li><li>Get an account at <a href="https://dash.cloudflare.com/sign-up">cloudflare.com</a> and register the domain <a href="https://www.cloudflare.com/products/registrar/">directly</a> there, using the protonmail address you just set up for contact info. </li><li>Note that I wrote this up prior to Cloudflare's recent <a href="https://twitter.com/eastdakota/status/1284298908156346368">downtime</a>; feel free to use <a href="https://ghost.org/faq/using-custom-domains/">another registrar</a> if you want, it's not essential to what follows.</li><li>Note also that even though Cloudflare does ask you for information when registering the domain, your registration will be <a href="https://developers.cloudflare.com/registrar/domain-registration/whois-redaction/">redacted</a> by default.</li></ul><figure><div><div><p><img src="https://balajis.com/content/images/2020/07/protonmail-signup-1.png" width="1252" height="2246" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/protonmail-signup-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/protonmail-signup-1.png 1000w, https://balajis.com/content/images/2020/07/protonmail-signup-1.png 1252w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/domize-1.png" width="1504" height="1106" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/domize-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/domize-1.png 1000w, https://balajis.com/content/images/2020/07/domize-1.png 1504w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/cloudflare-registration-1-1.png" width="1614" height="928" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/cloudflare-registration-1-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/cloudflare-registration-1-1.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/cloudflare-registration-1-1.png 1600w, https://balajis.com/content/images/2020/07/cloudflare-registration-1-1.png 1614w" sizes="(min-width: 720px) 720px"></p></div></div><figcaption>Get a protonmail, use domize to find an available domain, then register it directly at cloudflare.</figcaption></figure><h2 id="step-2-create-a-blog-at-your-domain">Step 2: Create a blog at your domain</h2><p>The next step is to create a blog at ghost.org and map it to a custom domain, as shown below. Note that there are two levels to Ghost:</p><ul><li>There's <code>my.ghost.org/signin</code>, which configures your Ghost account as a whole</li><li>And then there is <code>$name.ghost.io</code>, which is the admin interface to a single blog (we will use <code>example123499.ghost.io</code> in the screenshots below)</li></ul><p>To set up a <a href="https://ghost.org/faq/cloudflare-custom-domain-setup/">custom domain</a> on Ghost, you need to first create a blog at <code><a href="https://my.ghost.org/signup">my.ghost.org/signup</a></code>. &nbsp;Then go to <code><a href="https://my.ghost.org/signin">my.ghost.org/signin</a></code> and <code>dash.cloudflare.com</code> to edit the A records as shown in the screenshots below.</p><p>The official instructions <a href="https://ghost.org/faq/cloudflare-custom-domain-setup/">are here</a> if you need more detail. Once this works, you should find that <code>$name.ghost.io</code> now appears at <code>$name.com</code>. In this example, content from <code>example123499.ghost.io</code> now appears at <code>example123499.com</code>. You now have a blog with a custom domain!</p><figure><div><div><p><img src="https://balajis.com/content/images/2020/07/ghost-1-3.png" width="1866" height="1542" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-1-3.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-1-3.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-1-3.png 1600w, https://balajis.com/content/images/2020/07/ghost-1-3.png 1866w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/ghost-2-4.png" width="1674" height="1425" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-2-4.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-2-4.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-2-4.png 1600w, https://balajis.com/content/images/2020/07/ghost-2-4.png 1674w" sizes="(min-width: 720px) 720px"></p></div><div><p><img src="https://balajis.com/content/images/2020/07/ghost-3-3.png" width="1672" height="728" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-3-3.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-3-3.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-3-3.png 1600w, https://balajis.com/content/images/2020/07/ghost-3-3.png 1672w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/ghost-4-3.png" width="1324" height="2386" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-4-3.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-4-3.png 1000w, https://balajis.com/content/images/2020/07/ghost-4-3.png 1324w" sizes="(min-width: 720px) 720px"></p></div></div><figcaption>Set up your Ghost account, and then have your custom domain point to your Ghost blog.</figcaption></figure><h2 id="step-3-set-up-memberships-and-payments">Step 3: Set up memberships and payments</h2><p>The next step is to turn your blog into a paid newsletter. Ghost includes a pre-built theme called <a href="https://lyra.ghost.io/">Lyra</a> that sets this up. </p><ul><li>Go to the equivalent of <code>example123499.ghost.io/ghost</code> to log into the admin interface for your new blog. This is <em>different</em> from <code>my.ghost.org/signin</code>. The former administers the blog</li><li>Read about <a href="https://ghost.org/docs/members/requirements/">memberships in Ghost</a> if you want.</li><li>Then download this <a href="https://github.com/TryGhost/Lyra/archive/master.zip">Lyra theme zip file</a></li><li>And upload it to the equivalent of <code>example123499.ghost.io/ghost/#settings/design</code></li><li>Next get a <a href="https://dashboard.stripe.com/register">Stripe</a> account, which you can do as an <a href="https://support.stripe.com/questions/selling-on-stripe-without-a-separate-business-entity">individual</a></li><li>Paste in the <a href="https://ghost.org/integrations/stripe/#connect-to-stripe">Stripe keys</a> into your Ghost instance in the Labs field</li><li>And configure <a href="https://ghost.org/docs/members/subscriptions/">membership pricing</a></li></ul><figure><div><div><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-1-1.png" width="1926" height="1410" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-1-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-1-1.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-stripe-1-1.png 1600w, https://balajis.com/content/images/2020/07/ghost-stripe-1-1.png 1926w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-2-2.png" width="2026" height="2160" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-2-2.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-2-2.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-stripe-2-2.png 1600w, https://balajis.com/content/images/2020/07/ghost-stripe-2-2.png 2026w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-3-1.png" width="1360" height="686" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-3-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-3-1.png 1000w, https://balajis.com/content/images/2020/07/ghost-stripe-3-1.png 1360w" sizes="(min-width: 720px) 720px"></p></div><div><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-4-1.png" width="2088" height="728" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-4-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-4-1.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-stripe-4-1.png 1600w, https://balajis.com/content/images/2020/07/ghost-stripe-4-1.png 2088w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-5-1.png" width="2052" height="1112" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-5-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-5-1.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-stripe-5-1.png 1600w, https://balajis.com/content/images/2020/07/ghost-stripe-5-1.png 2052w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-6-1.png" width="2606" height="2128" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-6-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-6-1.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-stripe-6-1.png 1600w, https://balajis.com/content/images/size/w2400/2020/07/ghost-stripe-6-1.png 2400w" sizes="(min-width: 720px) 720px"></p></div><div><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-7-1.png" width="3096" height="1272" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-7-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-7-1.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-stripe-7-1.png 1600w, https://balajis.com/content/images/size/w2400/2020/07/ghost-stripe-7-1.png 2400w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-8-1.png" width="2580" height="2130" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-8-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-8-1.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-stripe-8-1.png 1600w, https://balajis.com/content/images/size/w2400/2020/07/ghost-stripe-8-1.png 2400w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-9-2.png" width="1940" height="1174" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-9-2.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-9-2.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-stripe-9-2.png 1600w, https://balajis.com/content/images/2020/07/ghost-stripe-9-2.png 1940w" sizes="(min-width: 720px) 720px"></p></div></div></figure><p>Now users can sign up and subscribe to your paid blog. You can make any given post free or paid, and <a href="https://ghost.org/docs/members/emails/">send out an email newsletter</a>. There are several settings to configure on both the Ghost and Stripe side that you can dig into now that you have the basic thing up and running. Test the whole thing out by getting a friend or two to sign up with their credit card and send them an email.</p><h2 id="step-4-optionally-set-up-your-imagery">Step 4: Optionally, set up your imagery</h2><p>Now you are fully set up to post to Ghost. You can browse the posts <a href="https://lyra.ghost.io/">here</a> to understand how the system works, or log in to your own Ghost instance at the equivalent URL for &nbsp;<code>example123499.com/ghost</code>. If you want to make your blog look pretty, you'll want to generate the following <a href="https://ghost.org/faq/general-publication-settings/">images</a>:</p><ul><li><a href="https://ghost.org/faq/general-publication-settings/#:~:text=A%20publication%20icon%20is%20a,at%20least%2060px%20x%2060px.">publication icon</a> (square, at least 60px x 60px)</li><li><a href="https://ghost.org/faq/general-publication-settings/#:~:text=A%20publication%20logo%20is%20the,at%20least%20600px%20x%2072px.">publication logo</a> (600px x 72px)</li><li><a href="https://en.number13.de/perfect-size-for-your-ghost-blog-publication-cover-casper-theme/#:~:text=For%20this%20format%2C%20the%20optimal,a%20format%20of%204.75%3A1.">cover image</a> (1900px x 400px)</li></ul><p>As you use the <a href="https://ghost.org/faq/using-the-editor/">Ghost Editor</a>, you'll also want to create individual post images for social media preview. You can use <a href="https://canva.com/">Canva</a> or <a href="https://figma.com/">Figma</a> to generate these, as well as <a href="https://iconfinder.com/">Iconfinder</a> for visual inspiration. You can also install a <a href="https://ghost.org/downloads/">desktop client</a> for editing Ghost posts.</p><h2 id="step-5-optionally-customize-your-theme">Step 5: Optionally, customize your theme</h2><p>If you're a developer and want to modify the look of your site, you can set up your Ghost theme for <a href="https://ghost.org/integrations/github">deployment</a> via GitHub. You would do that by forking <a href="https://github.com/TryGhost/Lyra">Lyra</a> and then setting up <a href="https://ghost.org/integrations/github/#install-the-ghost-theme-deploy-action">this action</a>. Now, every time you push a commit, the action triggers and the theme updates. You can also preview your edits by running Ghost <a href="https://ghost.org/docs/install/local/#install-ghost-cli">locally</a>.</p><p>Why might you want to edit your theme? By doing this you can edit the default copy on various pages, create new page templates, and the like. </p><p>Note that if you don't want to use the Lyra theme itself as a base, you can buy a pre-built one or learn how to customize <a href="https://ghost.org/docs/api/v3/handlebars-themes/">Ghost themes</a> yourself. If you do buy a theme, remember to get one of the themes that <a href="https://themeforest.net/search/ghost%20membership?utf8=%E2%9C%93">support</a> <a href="https://duckduckgo.com/?q=ghost+membership+themes">Ghost</a> <a href="https://github.com/curiositry/undefined-ghost-theme">memberships</a>, as not all of them do.</p><h2 id="conclusion">Conclusion</h2><p>This whole thing should take you about an hour or so. By the end you'll have a decent looking blog at your own domain that can handle memberships, accept payments, and send out a paid newsletter. And it can be pseudonymous if you choose.</p>
                    </div>
                </section></div>]]>
            </description>
            <link>https://balajis.com/set-up-a-paid-newsletter-at-your-own-domain/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23881317</guid>
            <pubDate>Sat, 18 Jul 2020 13:38:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[App devs – How to take advantage of the new iOS 14 Widgets]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23881225">thread link</a>) | @thisdickie
<br/>
July 18, 2020 | https://www.samdickie.me/writing/taking-advantage-of-ios14-widgets | <a href="https://web.archive.org/web/*/https://www.samdickie.me/writing/taking-advantage-of-ios14-widgets">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>With the recent announcement at this years WWDC 2020 keynote, Apple unveiled the long awaited iOS14 update. But are we overlooking something huge as product creators?</p><div><p>This year Apple unveiled a new take on their previous Today page widgets and moved them to the homescreen.</p><p>This isn't by any means any huge amount of innovation on Apple's part - Android devices have had widgets for a while now. However, the reason i'm so interested in this improvement is due to the exposure these new widgets get to users homescreens.</p><p>Apps have previously followed a uniform grid layout with very strict design parameters to adhere to. After a while they all look the same - it's hard to make your app stand out from the average person's 60-90 other apps on their smartphone. However, with iOS 14 Widgets you can make your app stand out on users homescreens.</p><p>‍</p><figure id="w-node-5e7a155de356-cb51e83d"><p><img src="https://uploads-ssl.webflow.com/5e5fb94aa7ed262873f66bcf/5f12d805c716620b62a891a7_how-to-use-iphone-ipad-home-screen-widgets-ios-14.jpg" alt=""></p></figure><p>‍</p><p>The homescreen is a coveted and highly valuable piece of screen real estate which for the past 14 years has remained somewhat unchanged - until now.</p><p>People check their phone over ~100 times a day - and with various options of widget sizes to select from, you can really make your app stand out on the homescreens of users iPhones.</p><p>‍</p><figure id="w-node-7b79a5dc3959-cb51e83d"><p><img src="https://uploads-ssl.webflow.com/5e5fb94aa7ed262873f66bcf/5f12d5b0710ab9a764561769_Screen-Shot-2020-06-22-at-18.09.53-1024x640.png" alt=""></p></figure><p>‍</p><p>Like the great App Store boom in 2008 with the introduction of third party apps, users first got the opportunity to download new apps outside of the native Apple app choices. With limited choice during the early years some apps did incredibly well. </p><p>Having used iOS14 developer beta for the past 3 weeks they currently only feature native Apple widgets to select from - however, from what I have read, Apple will be providing the <a href="https://developer.apple.com/documentation/widgetkit/creating-a-widget-extension">SDK for third party access</a>. You can also see third party apps like Nike with a widget showing on the Keynote.</p><p>Being one of a few widgets available from the release date of iOS14 in September 2020 could provide third party apps with an advantage before it becomes the wild west like the App store.</p><p>By providing a widget for your mobile app I would anticipate the following potential improvement to your metrics:</p><ul role="list"><li>Increased engagement with existing users given it's prominence on the homescreen</li><li>Reactivation of previously stagnant users</li><li>Increased retention</li><li>Increased daily usage</li></ul><p>A great example I played around with was Product Hunt. I typically check Product Hunt at least once a day through their mobile app. I'm always looking to find new and interesting tech products - but wouldn't it be convenient to check the days featured products directly from your homescreen? I quickly mocked up a visual UI below.</p><p>‍</p><figure id="w-node-5e62bae219f3-cb51e83d"><p><img src="https://uploads-ssl.webflow.com/5e5fb94aa7ed262873f66bcf/5f12d2d85487affa89289dcf_Image_17-07-2020_at_10.49.jpg" alt=""></p><figcaption>Quick mockup on Figma</figcaption></figure><p>‍</p><p>From here I can swipe down and see the top featured products of the day and view how many upvotes they currently have. I can also select any product and be taken to their featured page directly within the Product Hunt app.</p><p>There are 3 widget sizes developers can take advantage of. 2X2, 2X4 and 4X4. The example above is 2X4. The larger the size the more detailed visualizations you can create - however, having played around with the 4X4 i doubt many people would consider adding more than 1 widget of this size to their homepages due to their sheer size. </p><p>Lastly, I'm really curious to see how third-party widgets integrate with Smart Stacks and some of the clever ways product teams will take advantage of this feature. An example provided by Cnet below provides an early indication to what we can expect:<br>‍</p><blockquote>For example, if you check the weather and then your calendar first thing in the morning, the Smart Stack will likely include both of those apps and automatically show you the forecast followed by your agenda the first time you unlock your iPhone in the morning. Then, if you routinely check your Activity stats after dinner, the stack will show you the Activity widget around that time of day.</blockquote><p>‍</p><p>Apple didn't mention anything about what developers will be able to do with widgets, so at this stage, it's unclear if Smart Stacks' context-based shuffling will extend to include software from third parties.</p><p>Are you considering creating a Widget for iOS14? Any interesting Widgets suggestions? Let me know. </p><p>‍</p></div></div>]]>
            </description>
            <link>https://www.samdickie.me/writing/taking-advantage-of-ios14-widgets</link>
            <guid isPermaLink="false">hacker-news-small-sites-23881225</guid>
            <pubDate>Sat, 18 Jul 2020 13:17:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Trouser Pockets]]>
            </title>
            <description>
<![CDATA[
Score 665 | Comments 338 (<a href="https://news.ycombinator.com/item?id=23881220">thread link</a>) | @diiq
<br/>
July 18, 2020 | https://sambleckley.com/writing/pockets.html | <a href="https://web.archive.org/web/*/https://sambleckley.com/writing/pockets.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3 id="tldr">TL;DR</h3> <p>The clothing industry rarely creates dramatically new patterns. It is more lucrative to make small, easy-to-manufacture changes that always use the same basic pattern.</p> <p>There is therefore lots of room to innovate clothing that is more appropriate for contemporary problems, because basic clothing patterns haven’t changed in decades.</p> <p>I made some trousers with unusual pockets, and I think they’re good.</p> <h3 id="pockets-are-either-ugly-or-useless">Pockets are either ugly or useless</h3> <p>Pockets in tight jeans look bad. Putting a modern slab phone, a wallet, and keys into a pair of skinny jeans will leave even the most fashionable figure looking looking like they’re wearing batman’s utility belt as underwear. Even empty, in tight pants a large pocket bag can show through.</p> <p>The alternative, as many women know from first-hand experience, is a pocket too small to put anything in.</p> <p>A wallet in the back pocket can cause back pain and bad posture.</p> <p>Many of us spend most of our time sitting, but all four traditional pockets are totally inaccessible in that position. So we take out our phone, just in case, before we sit down at the restaurant — guaranteeing a distraction.</p> <p>Aesthetics, storage, and access: these are user needs that are currently poorly fulfilled — and that means things are ripe for innovation.</p> <h3 id="a-brief-history">A brief history</h3> <p>If the space is so ripe, why has there been no pocket innovation recently?</p> <p>Women used to have pockets. That “used to” has to count back 150 or even 200 years, and those pockets were often a separate garment, either worn underneath and accessed through a slit in the dress, or worn around the hips overtop, rather than built into the dress directly — but regardless, “it has pockets!” as a joyous surprise is a modern invention. (Men’s pockets were also separate pouches if you go back far enough; but going back the same 150-200 years, they lived in the waistcoat and the mandatory jacket; if breeches had pockets they were behind the falls and so, I suspect, not used as much in public.)</p> <p>The 1880’s brought the 1940s brought the slow arrival of mass production to clothing — not of the textiles, which started much earlier, but of actual clothes. Before this era, clothes were made either at home, or they were made one at a time. (In a quiet resonance with today, this was done in part by women who worked almost entirely from home, only travelling to the workplace to pick up new work and drop off what had been completed).</p> <p>In retrospect, fashions changed mostly decade by decade rather than year by year, but they changed dramatically. The fashionable silhouette of the 1860s looks nothing like the 1880s, or the 1910’s — so different, in fact, that for women the foundation garments were completely unrelated entities: the crinoline of the 1860s is nothing like the bustle of the 1880s. A person who can cut and sew can sew an incredibly wide range of different things; why not play around?</p> <p>But with the advent of mass production in clothes factories, the whole layout of the factory floor was based on specific pattern piecing. Each station makes only a few operations on each garment, and garments flow from one station to the next. To completely change the <em>construction</em> of a garment means a radical overhaul of the whole assembly line.</p> <p>But to simply change the garment’s <em>proportions</em> is <em>easy</em>.</p> <p>And so we live in a world where every spring the morning talk shows invite someone on to say “this year, [culottes, boot-cuts, skinny jeans, flares, cuffs, boyfriend jeans, high waists, low-rise, acid-wash, raw denim] are coming back into fashion, so keep your eye out!” — but the trousers are made from the same basic pieces, constructed in the same ways, with only the measurements changing. They get longer or shorter, looser or tighter, and change color, but they’re not fundamentally <em>different</em>.</p> <p>It’s like a lack-luster procedural generation system. Sure, there are technically millions of possibilities, but somehow you still end up bored after seeing the first 5 or 6.</p> <p>Probably not coincidentally, the advent of mass production is also when women’s silhouettes turned slim, and when all those foundation garments mostly disappeared. Designs that banish structure from the garment and rely entirely on the body beneath are much easier and cheaper to manufacture.</p> <p>And when silhouettes turned slim, women lost pockets. The more body-hugging the clothing, the less room for pockets — or, rather, the more the pocket contents will show unflatteringly. (And as we know, it would be anathema for a women to show unflattering lump for something as silly as practicality, function, or utility.)</p> <p>And even as womenswear adopted men’s workwear styles, women got jeans but not the pockets to go with them. Spandex made it even easier to make mass-produced clothes “fit”, and fit tighter. The unsightly-lump factor wasn’t going away.</p> <p>Even more recently, menswear has returned to an incredibly slim silhouette. Guys in skinny jeans should, by this logic, not have pockets either. But they do.</p> <p>Women get no practicality and men get no grace.</p> <h3 id="what-if-we-redesigned-the-pocket-from-scratch">What if we redesigned the pocket from scratch?</h3> <p>Let’s design a trouser pocket! This process is going to land somewhere between UX and industrial design. I am, sadly, not in charge of a clothes factory, so I am not concerned with the problems of mass-production, but material properties and the construction process do still matter; but I am maybe more willing to make manufacturing sacrifices for usefulness than most industrial designers are able to be.</p> <h3 id="what-do-people-use-pockets-for">What do people use pockets for?</h3> <ul> <li>Storing things; most often phone, then keys, wallet or money-clip, and other small items. At the moment, a mask.</li> <li><em>Verifying</em> stored objects — the hip-slapping dance of making sure you have everything before walking out the door.</li> <li>They must be secure while standing, sitting, running for the bus, etc</li> <li>Things, especially phone, need to go in and out of storage frequently, almost unconsciously.</li> <li>Access to phone while seated in a restaurant; to keys and license while in car</li> <li>Aesthetically, we want a clean, graceful line from hip to ankle even while holding things.</li> </ul> <p>An initial solution can be based on just three questions:</p> <ul> <li>Where can your hands reach?</li> <li>Where is there extra space to put things?</li> <li>Where is there enough support to prevent items swinging around uncomfortably?</li> </ul> <p>These questions form a physical venn diagram, pointing at a pretty small area for investigation:</p> <p><img src="https://sambleckley.com/assets/images/pocket_venn.png" alt="The human body with overlapping regions of reach, space, and support."></p> <p>You can see that current pockets are located completely outside the area where there is potentially space; the hips and butt of modern pants, for both women and men, are closely fitted. If there’s any ease, it starts just above the knees.</p> <p>Conveniently, the point where the vastus lateralis starts to curve back in towards the knee, creating space, is also right around the lowest point your arms can reach without bending over, giving us a well-defined target.</p> <p>So I made a pair of trousers with no pockets at the waist, and a pair of welt pockets at the side seams, right at that point.</p> <p><img src="https://sambleckley.com/assets/images/pants1.jpg" alt="First pair of pants."></p> <h3 id="notes-from-user-testing">Notes from user testing:</h3> <ul> <li>A pocket needs to be big enough for a whole hand, not just phone, to allow for fishing out small items from the very bottom of the pocket-bag.</li> <li>The pocket bag slips down and back if it’s full and the wearer sits down. This is uncomfortable and</li> <li>The pocket mustn’t allow a slick round phone to fall out when sitting, especially when, e.g. jiggling a leg.</li> </ul> <h3 id="revisions">Revisions</h3> <p>Luckily, each of these notes point at simple revision, rather than the need to start again.</p> <ul> <li>Make the pockets wider.</li> <li>Anchor the bottom of the pocket bag to the side seam.</li> <li>Angle the opening so it’s higher in the back — this both makes it easier to slip a phone into the pocket, and makes the pocket “deeper” on the bottom side when sitting or crouching.</li> </ul> <p><img src="https://sambleckley.com/assets/images/pants2.jpg" alt="Second pair of pants."></p> <h3 id="outcome">Outcome</h3> <p>These are great. I completely forget my phone and wallet are there — they don’t restrict my movement, they’re completely invisible, and yet they’re easy to access while standing or sitting. There’s no temptation to slouch around with my hands stuffed in my pockets. They’re so straightforwardly better for my needs that I’m now frustrated when my new-pocket pants are dirty and I have to wear trousers with pockets that are just SO twentieth-century. I immediately made a pair of jeans in this pattern, too.</p> <p>Further revision is possible, of course; but while it will be easy to refine this design to suit my personal body and needs more precisely, there’s only so much refinement possible while remaining suitable for a wide range of body types. If you wanted to mass-produce a pocket like this, you’d want to use something like Dreyfuss’ Humanscale data to make sure the placement and size is appropriate for the widest range of people. Luckily, you’d have <em>some</em> additional information in the sizing of the <em>rest</em> of the pants.</p> <h3 id="appendix-sam-have-you-simply-invented-cargo-pants">Appendix: Sam, have you simply invented cargo pants?</h3> <p>No. Cargo pants solve different problems for different people.</p> <p>If cargo pants are appropriate for your daily life, you definitely don’t want or need my side-seam welt pockets; and vice-versa. Cargo pants aren’t office-wear; these dress pants aren’t combat-wear.</p> </div></div>]]>
            </description>
            <link>https://sambleckley.com/writing/pockets.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23881220</guid>
            <pubDate>Sat, 18 Jul 2020 13:16:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Ownership Economy: Crypto and the Next Frontier of Consumer Software]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23880950">thread link</a>) | @jger15
<br/>
July 18, 2020 | https://variant.fund/the-ownership-economy-crypto-and-consumer-software/ | <a href="https://web.archive.org/web/*/https://variant.fund/the-ownership-economy-crypto-and-consumer-software/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>One of the most stunning things about the technology we consume everyday is the degree to which it is built, operated and even funded by its users.</p>



<div><p>The device you’re using to read this post, the software that’s displaying it, the server hosting this content and so much else on the internet are built with open-source code contributed by a global community of developers. Platforms like Wikipedia, YouTube, Twitter, Facebook, and Airbnb all operate around content and products sourced from individuals, not corporations. And increasingly marketplaces like Kickstarter, Patreon, Substack, and many other new <a href="https://a16z.com/2019/10/08/passion-economy/" target="_blank" rel="noopener">Passion Economy</a> platforms enable users to directly fund the products, information, and services that they consume.</p><p>As user participation becomes evermore mainstream and complex, the next step is platforms that are not only built, operated, and funded by users—but <strong><em>owned</em></strong> by users too.</p></div>



<div><p>Ownership, via employee stock option plans, has been a powerful tool for incentivizing talented people to dedicate their skills to building startups in Silicon Valley. While this model has been extremely successful, it hasn’t been accessible to all, constrained by geography and legacy financial infrastructure, among other factors. One result is that the economic interests of the biggest internet platforms are concentrated and often <a href="https://www.wired.com/story/how-blockchain-can-wrest-the-internet-from-corporations/" target="_blank" rel="noopener">poorly aligned with their most valuable contributors</a>, their users. Now, new technologies are shifting work and value distribution to be accessible online, resulting in a new generation of platforms that thrive on contributions from a permissionless and global talent pool.</p><p>Ownership is a powerful motivator for users to contribute to products in deeper ways, be it with ideas, computing resources, code, or community building. This more <a href="https://jessewalden.com/past-present-future-from-co-ops-to-cryptonetworks/" target="_blank" rel="noopener">cooperative economic model</a> helps ensure better alignment with users over time, resulting in platforms that can be larger, more resilient, and more innovative.&nbsp; <strong>This is the Ownership Economy, and beyond being a positive social endeavor, the platforms building it are able to leverage the strongest form of market incentives to grow network effects.</strong></p><p>While most prevalent in crypto today, The Ownership Economy is expanding to other areas in tech. To understand why, we can look to recent history and observe how protocol innovations often expose disruptive new models that, when productized, influence broader trends and go on to impact billions.</p></div>



<h4>Identifying Disruptive Models Through Protocol Innovations</h4>



<p>The history of protocol adoption fits a pattern: first, early-adopters use new protocols to do things that were impossible before the new technology empowered them to do so. Very often, this new behavior involves <a href="https://medium.com/@simonhmorris/if-youre-not-breaking-rules-you-re-doing-it-wrong-bittorrent-lessons-for-crypto-2-of-4-72c68227fe69" target="_blank" rel="noopener">breaking the rules</a>. Then, a winning strategy for founders is to build products that make these new models more accessible to a wider audience.&nbsp;</p>



<div><p>Consider the early web protocols: IP, HTTP, standards like HTML, then RSS. At first, popular websites used these protocols to create carbon-copies of physical analogues, like newspaper cover pages or classified ads. But as internet adoption went mainstream, users began publishing their own content: independent blogs, podcasts, newsletters and forums paved the way for the user-generated content platforms that dominate publishing today.</p><p>Another example is BitTorrent, <strong>a protocol innovation of packet distribution, but a disruption that underpinned the streaming revolution</strong>. When BitTorrent first became popular, Netflix was still mailing DVDs in the mail. Meanwhile, the peer-to-peer technology enabled consumers to access music, movies, software, and video games instantaneously, as if the files were already on their hard drives. By 2004, BitTorrent comprised one-third of all internet traffic.</p><p><strong>Consumers’ passion for torrenting signaled that they wanted to access the world’s media at their fingertips,</strong> but for many, BitTorrent wasn’t a user-friendly experience; trackers were moving targets, cluttered and difficult to navigate.&nbsp;</p></div>



<p>One person who saw an opportunity through the noise was Daniel Ek, founder of Spotify. As CEO of <a href="https://en.wikipedia.org/wiki/%CE%9CTorrent" target="_blank" rel="noopener">µTorrent</a>, one of the most popular BitTorrent clients, Ek understood that piracy wasn’t about stealing—it was about access. The winning formula was providing access to the world’s music in a clean, well-designed product.</p>



<p>Today, crypto tokens are the latest protocol innovation to expose a disruptive new model. Just as BitTorrent allowed us to exchange packets of information instantly and without an intermediary, crypto tokens let us distribute value in the same way.<strong> <p>The protocol innovation of tokens is akin to <em>packets for value</em>, but the disruption is in the way new software platforms can be built and gain adoption.</p></strong> <span>The breakthrough of early crypto networks is a new model for market-driven networks, where users build, operate and </span><b><i>own</i></b><span> a piece of the products and services that they use everyday.</span></p>



<h4>The Ownership Economy, Pioneered by Crypto</h4>



<div><p><strong>The idea of user ownership is at the core of the success of Bitcoin and Ethereum, the first user-owned and operated networks at scale.</strong> Bitcoin arrived in 2009, the year that marked a rapid acceleration of economic inequality and the role of the internet in people’s daily lives. Bitcoin promised a new economic means to participate in modern technology history, simply by running open-source software on your computer. Rather than needing to live in a specific place and pursue a specific career in order to reap the benefits of the new economy, anyone with an internet connection could participate by “mining” or securing the network. In return, they earned newly minted Bitcoin, an ownership stake in the network itself.</p><p>Ethereum’s 2015 launch expanded the type of computation possible on blockchain networks, enabling a broader range of applications and allowing developers to experiment with new ways of expressing ownership in code. The best-designed Ethereum-based applications leverage a <a href="https://jessewalden.com/cryptos-business-model-is-familiar-what-isnt-is-who-benefits-2/" target="_blank" rel="noopener">business model similar to traditional Web 2.0 marketplaces</a>, but encode them in autonomous “smart contracts” run by Ethereum’s network of miners. This means these applications have no central operator. <strong>Rather than a platform’s inner circle of founders and investors taking home the value, users are able to earn the majority of value generated from their collective contributions.&nbsp;</strong></p></div>



<p>Needless to say, one of the most challenging problems any startup or new technology faces is adoption, especially where network effects are necessary—and even more-so when competing against the existing network effects of today’s dominant platforms. As the early Bitcoin and Ethereum communities came to realize, ownership is a tool to help surmount this problem. Those early communities were largely composed of technologists, developers, and enthusiasts who were naturally among the first to recognize the power of tokens as direct economic incentives. But today, founders are bringing the idea of ownership —&nbsp; or at least, better economic alignment between platforms and participants — to new verticals in tech, from developer infrastructure, to financial services, and from consumer marketplaces to social.</p>



<h4>How next-generation platforms are driving an ownership economy</h4>



<p>The ownership economy doesn’t always mean a literal distribution of tokens, stock options, or equity. It also doesn’t necessarily mean that an application or service is entirely built on a blockchain. Rather, it means that ownership —&nbsp;which may manifest in the form of novel economic rewards, platform governance, or new forms of social capital —&nbsp;can be a new keystone of user experiences, with plenty of design space to explore.</p>



<p>Some examples: In payments, <a href="http://celo.org/" target="_blank" rel="noopener">Celo</a> is making digital dollars and financial applications accessible to anyone with an internet connection via a blockchain network that, like Bitcoin, is entirely user owned and operated. In finance, startups like <a href="https://www.binance.com/en/bnb" target="_blank" rel="noopener">Binance</a> and <a href="https://numer.ai/" target="_blank" rel="noopener">Numerai</a> have leveraged tokens to distribute revenue from the platform directly to their users, fueling brand loyalty and growth. <a href="http://compound.finance/" target="_blank" rel="noopener">Compound</a>, a money market, recently completed its journey of <a href="https://jessewalden.com/progressive-decentralization-a-playbook-for-building-crypto-applications/" target="_blank" rel="noopener">progressive decentralization</a> to become <a href="https://medium.com/compound-finance/compound-community-ownership-ee0ed1252cc3?source=collection_home---4------0-----------------------" target="_blank" rel="noopener">a community owned</a> marketplace for borrowing and lending.</p>



<p><a href="http://uniswap.io/" target="_blank" rel="noopener">Uniswap</a>, a crypto exchange, has a business model similar to Coinbase or Binance in that it imposes a fee on transactions. But rather than the company capturing that fee, it’s instead distributed to the market-making traders that provide liquidity and make the product useful. Since Uniswap is open source and user-owned, third-party developers can have confidence building on the platform and a rich ecosystem of integrations has grown around the project.</p>



<p>In social, Reddit recently announced that 300 million users will have access to tokenized <a href="https://www.reddit.com/community-points/?utm_source=reddit&amp;utm_medium=usertext&amp;utm_name=FortNiteBR&amp;utm_content=t3_gj8tm1" target="_blank" rel="noopener">community currencies</a> through their mobile app. The platform will reward participants in the <a href="https://www.reddit.com/r/FortNiteBR/comments/gj8tm1/introducing_rfortnitebr_bricks/" target="_blank" rel="noopener">r/FortniteBR</a> and <a href="https://www.google.com/search?q=r%2FCryptocurrency+moons&amp;oq=r%2FCryptocurrency+moons&amp;aqs=chrome..69i57j0j69i58.880j0j7&amp;sourceid=chrome&amp;ie=UTF-8" target="_blank" rel="noopener">r/Cryptocurrency</a> subreddits with tokens that can be used to pay for membership, tipping, and badges in the Reddit app, giving them ownership over the economy of each subreddit.&nbsp;&nbsp;</p>



<p>Consumer marketplace <a href="http://withfoundation.com/" target="_blank" rel="noopener">Foundation</a> is transforming the Kickstarter model by allowing creators to tokenize their projects in a marketplace where tokens can be bought, sold or redeemed for goods or services. This programmable, digital representation of ownership unlocks new revenue streams that gives buyers and creators access to new value streams in secondary markets.&nbsp;</p>



<p>Global talent marketplace <a href="http://www.usebraintrust.com/" target="_blank" rel="noopener">Braintrust</a> connects top tech talent with large companies looking to hire them.&nbsp; Their marketplace transacts in USD but uses an Ethereum-based token as its core incentive and governance system to distribute value to contributors.&nbsp;&nbsp;</p>
<figure></figure>



<p>In consumer products, the house-of-brands startup <a href="https://www.arfa.co/collective" target="_blank" rel="noopener">Arfa</a> is rewarding customers who contribute to product development—<a href="https://www.arfa.co/collective" target="_blank" rel="noopener">The Arfa Collective</a>—with a 5 percent share of company profits. They hope these direct economic incentives can help build a more loyal customer base with lower marketing costs over time.&nbsp;</p>



<p>Other platforms like <a href="https://hackernoon.com/birds-new-platform-program-and-the-rise-of-the-business-in-a-box-899f7ac58abb" target="_blank" rel="noopener">Bird</a> and <a href="https://dumpling.us/" target="_blank" rel="noopener">Dumpling</a> are putting …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://variant.fund/the-ownership-economy-crypto-and-consumer-software/">https://variant.fund/the-ownership-economy-crypto-and-consumer-software/</a></em></p>]]>
            </description>
            <link>https://variant.fund/the-ownership-economy-crypto-and-consumer-software/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23880950</guid>
            <pubDate>Sat, 18 Jul 2020 12:28:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Logged out]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 44 (<a href="https://news.ycombinator.com/item?id=23880938">thread link</a>) | @patwalls
<br/>
July 18, 2020 | https://patwalls.com/logged-out | <a href="https://web.archive.org/web/*/https://patwalls.com/logged-out">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://patwalls.com/logged-out</link>
            <guid isPermaLink="false">hacker-news-small-sites-23880938</guid>
            <pubDate>Sat, 18 Jul 2020 12:26:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Computer architecture and being a good programmer?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23880681">thread link</a>) | @edvinleander
<br/>
July 18, 2020 | http://edvinleander.com/2020/07/18/do-i-have-to-know-computer-architecture-to-be-a-good-programmer/ | <a href="https://web.archive.org/web/*/http://edvinleander.com/2020/07/18/do-i-have-to-know-computer-architecture-to-be-a-good-programmer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-101">

	

	
	<div>
		
<p>When I started my first semester in university the first course, we had was called <em>Elementary Computer Architecture. </em>As computer-engineers we had to know the elementary functions of the CPU (Central Processing Unit) and memory. One could argue then that as a programmer you <strong>must</strong> know low level computer architecture.</p>



<p>When I started to program in my early teen days, I did not know anything about computers. I just knew that a computer had a processor, graphics card and memory. And an on-button. As I developed my skills, the more I learned about computers. I started to examine the theory behind the code. Instead of just treating the computer as a black box, I began to learn the fundamentals of computers.</p>



<p>You could argue that learning the very basics of computers is not necessary for the common programmer. I myself proved that you could learn to program without knowing the basics.</p>



<h5>It is a difference between being able to program and to be able to program…</h5>



<p>What do I mean with this cryptical words? In my late teen’s I began to work on my biggest project to date, a compiler. Before I started building, I had encountered <em>cache misses </em>and <em>assembly optimization </em>but did not give it much thought. My only goal with creating my own programming language was to learn about <strong>everything.</strong></p>



<p>I recently wrote an article about copy-pasting and using unnecessary libraries when you could do it yourself. Without going too much into technical stuff, there is a common “library” or “backend” that you could use. I decided to learn, so I did not use the framework.</p>



<p>What I want to address is that, learning about compilers I began to optimize my regular code, I became more aware of my code. There is a difference between being able to program and be able to program. With this I mean that you could be a programmer, a good programmer, without being able to optimize your structures and think about pointer arithmetic and assembly optimization. But if you know how the compiler that compiles down to machine code, you can optimize and become a more aware programmer.</p>



<h5>Languages like Python are so high level that you do not have to care about low-level programming</h5>



<p>More high-level languages like Python does not give you the opportunity with low-level optimizations like <em>Assembly </em>or <em>C </em>gives you. If you really cannot do anything low-level then why do you have to learn how computers know? You can do just about anything in Python without ever worrying about compiler optimizations.</p>



<h5>Some final words</h5>



<p>Some may say, also I, that you do not have to know about the internal data bus of the processor to know how to code. Is it helpful to learn about cache-misses? Yes, if you want to learn high performance parallel computing, it is a must. But if you are comfortable with your language or have a perfect job, do not worry to much. But I can promise that you will improve as a programmer and engineer if you know computer architecture. So, my final words will be that you really do not have to know much about internal compiler stuff if you work in high level languages. But if you are interested in high speed computing then knowledge of computer architecture is a must!</p>



<p>Before parting I want to <strong>know what you think</strong>. Write in the comment section your opinion. <strong>Should you care about architecture or not</strong>? And do not forget to <strong>like </strong>and <strong>subscribe</strong> for more content!</p>



	<div data-blog-id="180252010">
		<div>
			<form aria-describedby="wp-block-jetpack-mailchimp_consent-text">
				
												

				<p id="wp-block-jetpack-mailchimp_consent-text">
					By clicking submit, you agree to share your email address with the site owner and Mailchimp to receive marketing, updates, and other emails from the site owner. Use the unsubscribe link in those emails to opt out at any time.				</p>

				
			</form>
			
				<p>
					Processing…				</p>
				<p>
					Success! You're on the list.				</p>
				<p>
					Whoops! There was an error and we couldn't process your subscription. Please reload the page and try again.				</p>

					</div>
	</div>
	


<p>Have a nice day!</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>http://edvinleander.com/2020/07/18/do-i-have-to-know-computer-architecture-to-be-a-good-programmer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23880681</guid>
            <pubDate>Sat, 18 Jul 2020 11:34:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EU Parliament says sensitive data of 1,200 officials left exposed on web]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23880659">thread link</a>) | @based2
<br/>
July 18, 2020 | https://www.politico.eu/article/eu-parliament-says-sensitive-data-of-1200-officials-left-exposed-on-web/ | <a href="https://web.archive.org/web/*/https://www.politico.eu/article/eu-parliament-says-sensitive-data-of-1200-officials-left-exposed-on-web/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
							<div>
            <figure><div><div><p><img src="https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20160412_202400_HDR-714x467.jpg"></p></div></div><figcaption><p>The European Parliament has been hit by a "major data breach" | European Union</p></figcaption></figure>        <div>
        <header>
                        
                        <p>The information includes sensitive information and encrypted passwords. </p>
                    </header>
                
<!--/.meta-->
    </div><!--/.summary-->
</div><!--/.story-intro-->

							
							
							<p>Information about more than a thousand staff and members of the European Parliament has been exposed in what a key lawmaker called a "major data breach."</p>
<p>The data includes 1,200 accounts of elected officials and staff, along with another 15,000 other accounts of EU affairs professionals, Marcel Kolaja, the Parliament's vice president for IT policy, confirmed to POLITICO on Saturday.</p>
<p>The exposed information — “a huge amount of data” — includes sensitive information and encrypted passwords, he added.</p>
<p>It comes from a system that had been run under the European Parliament’s official "europarl.eu" domain, Kolaja said, but the data had not been hosted by the institution itself.</p>
<p>“The system in question is a system run by one particular political group and it was data by that political group," Kolaja said, "and they were immediately made aware of that incident.”</p>
<blockquote><p>“This data has been online for some time now” <em>— Yash Kadakia, founder of Indian cybersecurity company Shadowmap</em></p></blockquote>
<p>Kolaja declined to say which political group was affected. But information seen by POLITICO about the affected server suggested that it is the European People’s Party (EPP), the largest political faction in the Parliament.</p>
<p>EPP group spokesperson Pedro López de Pablo confirmed in an email that a database containing email addresses and passwords had been exposed.</p>
<p>However, he added, that database was outdated and only contained information "used by the people who [were] subscribed to our old website back in 2018." That website is no longer in use after the group launched a new website in January 2019, López de Pablo said.</p>
<p>Both the EPP's "servers and the current database have not been exposed," López de Pablo wrote.</p>
<p>"Even in the case that the people who were subscribed to our website in 2018 used the same password that they had in their e-mails at that time, nothing can happen to them now because in the Parliament the system forces you to change completely your password every three months," he added.</p>
<p>He added that the EPP was "currently verifying the list of emails to inform all the people, following [European data protection] rules."</p>
<h3>'This is serious'</h3>
<p>The security breach was <a href="https://pro.politico.eu/news/119283" target="_blank">first revealed Friday by Indian cybersecurity company Shadowmap</a>, whose founder Yash Kadakia told POLITICO that it had discovered files containing data like passwords, job descriptions and other personal information via an internet portal that’s part of the Parliament’s domain and used by its officials.</p>
<p>The unprotected data also includes information of thousands of people with links to political parties and institutions, including members of EU agencies and authorities like law enforcement agency Europol, the European Data Protection Supervisor, border agency Frontex and others, Kadakia said.</p>
<p>A spokesperson of the European Commission, the bloc’s executive body, said in an email on Saturday that “a large number of users [were] affected, including some users from the Commission."</p>
<p>Kadakia flagged the issue to the Parliament’s Computer Emergency Response Team on Friday. His company found the data when scanning the internet for unprotected and leaked datasets, which it does as part of its cybersecurity services. “We end up picking up data that is lost to other people sometimes,” Kadakia said.</p>
<p>The risk, he said, was that the data had been found by hackers and could be used to access other websites and sensitive services.</p>
<p>“This data has been online for some time now,” he said.</p>
<p>“I’m assuming some subset of members of the European Parliament have used the same passwords,” he said. “If you’re able to access a whole bunch of systems, a whole bunch of information, as an attacker you can really get in there.”</p>
<div id="attachment_1366554"><p><img aria-describedby="caption-attachment-1366554" src="https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-714x472.jpg" alt="" width="714" height="472" srcset="https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-714x472.jpg 714w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-300x198.jpg 300w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-1024x677.jpg 1024w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-768x508.jpg 768w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-1536x1016.jpg 1536w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-2048x1355.jpg 2048w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-1160x767.jpg 1160w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-380x251.jpg 380w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-172x114.jpg 172w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-90x60.jpg 90w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-104x69.jpg 104w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-200x132.jpg 200w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-393x260.jpg 393w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-54x36.jpg 54w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-1088x720.jpg 1088w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-333x220.jpg 333w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-1120x741.jpg 1120w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/05/20200213_EP-100117A_FMA_015-600x397.jpg 600w" sizes="(max-width: 714px) 100vw, 714px"></p><p id="caption-attachment-1366554">Marcel Kolaja, the Parliament's vice president for IT policy | European Union</p></div>
<p>By noon on Saturday, all affected data appeared to have been taken offline.</p>
<p>Parliament Vice President Kolaja, a trained software engineer, warned, "This is serious."</p>
<p>Although the passwords leaked in the data breach had been encrypted using a technique known as “hashing,” which means that intruders cannot instantly use them to access other information, “with further cryptoanalysis of the data, it could definitely be abused,” he added.</p>
<p>“Given that we’re speaking about tons of data, it definitely now needs to be investigated if there was any breach of law,” he said.</p>

														<!--/.story-supplement-->
							
							
							<!--/.story-supplement-->

						</div></div>]]>
            </description>
            <link>https://www.politico.eu/article/eu-parliament-says-sensitive-data-of-1200-officials-left-exposed-on-web/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23880659</guid>
            <pubDate>Sat, 18 Jul 2020 11:29:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tinkerbell is an open-source, bare metal provisioning engine]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23880609">thread link</a>) | @methou
<br/>
July 18, 2020 | https://tinkerbell.org/documentation/ | <a href="https://web.archive.org/web/*/https://tinkerbell.org/documentation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="body-inner"><p>​
Everything you need to know about Tinkerbell and its major component microservices.</p><h2 id="what-is-tinkerbell">What is Tinkerbell?</h2><p>Tinkerbell is an open-source, bare metal provisioning engine, built and maintained by the team at Packet.</p><ul><li>Interested in collaborating? Join our growing community of <a href="https://tinkerbell.org/contributors">Contributors</a> on <a href="https://github.com/tinkerbell">GitHub</a> or <a href="https://slack.packet.com/">Slack</a></li></ul><h2 id="whats-powering-tinkerbell">What’s Powering Tinkerbell?</h2><p>The Tinkerbell stack consists of five microservices, or components:</p><ul><li><p><a href="https://github.com/tinkerbell/boots"><strong>Boots</strong></a> - Boots is Tinkerbell’s DHCP server. It handles DHCP requests, hands out IPs, and serves up iPXE. It uses the Tinkerbell client to pull and push hardware data. It only responds to a predefined set of MAC addresses so it can be deployed in an existing network without interfering with existing DHCP infrastructure.</p></li><li><p><a href="https://github.com/tinkerbell/hegel"><strong>Hegel</strong></a> - Hegel is the metadata service used by Tinkerbell and OSIE. It collects data from both and transforms it into a JSON format to be consumed as metadata.</p></li><li><p><a href="https://github.com/tinkerbell/osie"><strong>OSIE</strong></a> - OSIE is an in-memory installation environment for bare metal. It installs operating systems and handles deprovisioning.</p></li><li><p><a href="https://github.com/tinkerbell/pbnj"><strong>PBnJ</strong></a> - PBnJ is a microservice that can communicate with baseboard management controllers (BMCs) to control power and boot settings.</p></li><li><p><a href="https://github.com/tinkerbell/tink"><strong>Tink</strong></a> - Tink is the Tinkerbell server and CLI. It communicates over gRPC, and is responsible for processing workflows. The CLI is used to create workflows and their building blocks, templates and hardware data.</p></li></ul><p>In addition to the microservices, there are three pieces of infrastructure:</p><ul><li><p><a href="https://www.postgresql.org/"><strong>PostgreSQL</strong></a> - Tinkerbell uses PostgreSQL as its data store. PostgreSQL is a free and open-source relational database management system, and it stores Tinkerbell’s hardware data, templates, and workflows.</p></li><li><p><a href="https://hub.docker.com/_/registry"><strong>Image Repository</strong></a> - Tinkerbell uses a local image repository to store all of the action images used in a workflow. This is particularly useful for secure environments that don’t have access to the internet. You can also choose to use <a href="https://quay.io/">Quay</a> or <a href="https://hub.docker.com/">DockerHub</a> as the repository if your environment does have internet access.</p></li><li><p><a href="https://www.nginx.com/"><strong>NGINX</strong></a> - NGINX is a web server which can also be used as a reverse proxy, load balancer, mail proxy, and HTTP cache. Tinkerbell uses NGINX to serve the required boot files during workflow execution.</p></li></ul><h2 id="first-steps">First Steps</h2><p>New to Tinkerbell or bare metal provisioning? This is a great place to start!</p><ul><li>Getting Started - Set up Tinkerbell <a href="https://tinkerbell.org/setup/local-with-vagrant/">locally with vagrant</a> or on <a href="https://tinkerbell.org/setup/packet-with-terraform/">Packet with Terraform</a>.</li><li>Run <a href="https://tinkerbell.org/examples/hello-world/">hello world</a> to see Tinkerbell in action.​</li></ul><h2 id="get-help">Get Help</h2><p>Need a little help getting started? We’re here!</p><ul><li>Check out the <a href="https://tinkerbell.org/faq">FAQs</a> - When there are questions, we document the answers.</li><li>Join our <a href="https://tinkerbell.org/community-slack">Community Slack</a>.</li><li>Submit an issue on <a href="https://github.com/tinkerbell/">Github</a>.</li></ul></div></div>]]>
            </description>
            <link>https://tinkerbell.org/documentation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23880609</guid>
            <pubDate>Sat, 18 Jul 2020 11:20:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Abstract classes and Zope interfaces in Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23880505">thread link</a>) | @ChankeyPathak
<br/>
July 18, 2020 | https://tutswiki.com/abstract-classes-and-interfaces-in-python/ | <a href="https://web.archive.org/web/*/https://tutswiki.com/abstract-classes-and-interfaces-in-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="body-inner">
          
            
          

        






<p>Abstract base classes and interfaces are entities that are similar in purpose and meaning. Both the first and second are a peculiar way of documenting the code and help to limit (decouple) the interaction of individual abstractions in the program (classes).</p>

<p>Python is a very flexible language. One facet of this flexibility is the possibilities provided by metaprogramming. And although abstract classes and interfaces are not represented in the core of the language, the former were implemented in the standard abc module, and the latter in the Zope project (the zope.interfaces module).</p>

<p>It makes no sense to use both at the same time, and therefore each programmer must determine for himself which tool to use when designing applications.</p>


<h2 id="abstract-base-classes-abc">Abstract base classes (abc)</h2>

<p>Starting from version 2.6 of the language, the <code>abc</code> module is included in the standard library, which adds abstract base classes (hereinafter ABC) to the language.</p>

<p>ABC allows you to define a class, indicating which methods or properties must be overridden in inherited classes:</p>

<pre><code>from abc import ABCMeta, abstractmethod, abstractproperty
class Movable():
    __metaclass __ = ABCMeta

    @abstractmethod
    def move():
    """Move object"""
    
    @abstractproperty
    def speed():
    """Object speed"""
</code></pre>

<p>Thus, if we want to use an object with the ability to move and a certain speed in the code, then we should use the <code>Movable</code> class as one of the base classes.</p>

<p>The presence of the necessary methods and attributes of the object is now guaranteed by the presence of <code>abstractmethod</code> and <code>abstractproperty</code>.</p>

<pre><code>class Car(Movable):
    def __init__:
        self.speed = 10
        self.x = 0

    def move(self):
        self.c += self.speed
        def speed(self):
            return self.speed
    
assert issubclass (Car, Movable)
assert ininstance (Car(), Movable)
</code></pre>

<p>It can be seen that the concept of ABC fits well into the class inheritance hierarchy, it is easy to use them, and the implementation, if you look into the source code of the abc module, is very simple. Abstract classes are used in the standard collections and number modules, defining the methods of custom
inherited classes necessary for definition.</p>

<p>Details and considerations for using ABC can be found in <a href="https://www.python.org/dev/peps/pep-3119/">PEP-3119</a>.</p>

<h2 id="interfaces-zope-interfaces">Interfaces (zope.interfaces)</h2>

<p>The Zope Toolkit (ZTK) is a set of libraries intended for reuse by projects to develop web applications or web frameworks. It is developed by the contributors of the Zope Foundation. The zope framework has evolved into a set of almost independent components. The glue that holds the components together is the interfaces and the adapters based on them.</p>

<p>The zope.interfaces module is the result of this work.</p>

<p>In the simplest case, using interfaces is similar to ABC:</p>

<pre><code>import zope.interface

class IVehicle(zope.interface.Interface):
    """Any moving thing"""
    speed = zope.interface.Attribute("""Movement speed""")
    def move():
        """Make a single step"""
    
class Car(object):
    zope.interface.implements (IVehicle)

    def __init__:
        self.speed = 1
        self.location = 1

    def move (self):
        self.location = self.speed * 1
        print("moved!")
    
assert IVehicle.implementedBy (Car)
assert IVehicle.providedBy (Car ())
</code></pre>

<p>The interface declaratively shows what attributes and methods the object should have. Moreover, the class implements the interface, and the object of the class provides. You should pay attention to the difference between these concepts!</p>

<p>“Implementing” an interface means that only the “produced” entity will have the required properties; and “providing” an interface speaks of the specific capabilities of the entity being evaluated. Accordingly, in Python, classes, by the way, can both implement and provide an interface.</p>

<p>In fact, the implementation declaration (IVehicle) is a convention; just a promise that a given class and its objects behave that way. No real checks will be made.</p>

<pre><code>class IVehicle (zope.interface.Interface):
    """Any moving thing"""
    speed = zope.interface.Attribute("""Movement speed""")

    def move():
        """Make a single step"""

class Car(object):
    zope.interface.implements(IVehicle)

assert IVehicle.implementedBy(Car)
assert IVehicle.providedBy(Car())
</code></pre>

<p>The component architecture of Zope includes another important concept - adapters. Generally speaking, this is a simple design pattern that corrects one class for use somewhere where a different set of methods and attributes is required.</p>

<h2 id="adapters">Adapters</h2>

<p>Consider a simple an example from the <a href="https://bluebream.zope.org/doc/1.0/manual/componentarchitecture.html">Comprehensive Guide to Zope Component Architecture</a>.</p>

<p>Suppose there are a couple of classes, Guest and Desk. Let’s define interfaces to them, plus a class that implements the Guest interface:</p>

<pre><code>import zope.interface
from zope.interface import implements
from zope.component import adapts, getGlobalSiteManager

class IDesk(zope.interface.Interface):
    def register():
        "Register a person"

class IGuest(zope.interface.Interface):
    name = zope.interface.Attribute ("""Person`s name""")

class Guest (object):
    implements(IGuest)

    def __init __ (self, name):
        self.name = name
</code></pre>

<p>The adapter must account for the anonymous guest by registering in the list of names:</p>

<pre><code>class GuestToDeskAdapter (object):
    adapts(IGuest)
    implements(IDesk)
    
    def __init __ (self, guest):
        self.guest = guest
    
    def register (self):
        guest_name_db.append (self.guest.name)
</code></pre>

<p>There is a registry that keeps track of adapters by interface. Thanks to it, you can get an adapter by passing an adaptable object to the call of the interface class. If the adapter is not registered, the second argument to the interface will be returned:</p>

<pre><code>guest = Guest ("Ivan")
adapter = IDesk (guest, alternate = None)
print adapter
&gt;&gt;&gt;&gt; None found

gsm = getGlobalSiteManager ()
gsm.registerAdapter (GuestToDeskAdapter)

adapter = IDesk (guest, alternate = "None found")
print adapter

&gt;&gt;&gt;&gt; __ main __. GuestToDeskAdapter object at 0xb7beb64c&gt;
</code></pre>

<p>This infrastructure is useful for splitting code into components and linking them together.</p>

<p>One of the most striking examples of using this approach besides Zope itself is the Twisted network framework, where a fair amount of the architecture relies on zope.interfaces interfaces.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Upon closer inspection, it turns out that interfaces and abstract base classes are two different things.</p>

<p>Abstract classes basically hardcode the required front-end part. Checking an object against the interface of an abstract class is checked using the built-in isinstance function; class - issubclass. An abstract base class should be included in the hierarchy as a base class or mixin.</p>

<p>The downside is the semantics of checks issubclass, isinstance, which intersect with ordinary classes (their inheritance hierarchy). No additional abstractions are built on the ABC.</p>

<p>Interfaces are a declarative entity, they do not set any boundaries; simply asserts that the class implements and its object provides the interface. Semantically, the statements implementedBy, providedBy are more correct. On such a simple basis, it is convenient to build a component architecture using adapters and other derived entities, which is what the large Zope and Twisted frameworks do.</p>

<p>It should be understood that the use of both tools makes sense only when building and using relatively large OOP systems - frameworks and libraries, in small programs they can only confuse and complicate the code with unnecessary abstractions.</p>

<h2 id="help-improve-this-content">Help improve this content</h2>

<p>Please fix any typos or add more insights by <a href="https://github.com/TutsWiki/source/edit/master/content/blog/abstract-classes-and-interfaces-in-python.md">editing this page</a>.</p>





<br>

        
        </div></div>]]>
            </description>
            <link>https://tutswiki.com/abstract-classes-and-interfaces-in-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23880505</guid>
            <pubDate>Sat, 18 Jul 2020 10:57:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fast charging vulnerability could be used to explode smartphones remotely]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23880403">thread link</a>) | @vvpvijay
<br/>
July 18, 2020 | https://androidrookies.com/fast-charging-vulnerability-could-be-used-by-hackers-to-explode-smartphones-remotely/ | <a href="https://web.archive.org/web/*/https://androidrookies.com/fast-charging-vulnerability-could-be-used-by-hackers-to-explode-smartphones-remotely/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-9052"><div><div><div><h2>Bad Power Attack: Hackers can modify the power management IC (PMIC) firmware to make your smartphone explode remotely</h2><p>We all love the fast charging technology because it saves a lot of time. The popularity of fast charging technology has meant that most Chinese phone manufacturers now include fast charging technology in their gadgets. However, there is little quality control and scant respect for safety while implementing fast charging technology which could prove fatal to the user.</p><p>A team of researchers from <a href="https://xlab.tencent.com/cn/2020/07/16/badpower/" data-original-href="https://xlab.tencent.com/cn/2020/07/16/badpower/" data-component-tracked="1">Tencent Security Xuanwu Lab</a> has published a report which states that a large number of smartphones/tablets and even laptops are vulnerable to an explosion due to their fast charging feature. The Xuanwu Lab researchers have named this attack vector <strong>Bad Power</strong>.</p><p>According to the Xuanwu Lab <a href="https://xlab.tencent.com/cn/2020/07/16/badpower/">report</a>, threat actors could control the process of charging on a vulnerable device by rewriting a device’s firmware and causing smartphone components to burn/explode or generate electric overloads causing bodily harm to the user.</p><p>The Xuanwu Lab report explains that all power adapters feature power management circuitry is controlled by a power management IC (PMIC). The PMIC operates based on its own independent firmware. The firmware has set security parameters that regulate the necessary power voltage and current parameters. Xuanwu Lab report states that hackers could access this PMIC firmware, rewrite it, and make it vulnerable to Bad Power attacks through malware that resides in the terminal device. Essentially, the Xuanwu report states that threat actors could turn such devices into a time-bomb and cause them to burn/explode remotely.</p><p><img src="https://xlab.tencent.com/cn/uploads/2020/07/badpower_2.png" data-src="https://xlab.tencent.com/cn/uploads/2020/07/badpower_2.png" alt="badpower_2" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>(The chip burned when a powered device was attacked by BadPower)</p><p>Bad Power works by modifying the firmware of a charging device. Once modified, the threat actors can control the power output and cause it to burn or explode smartphones, tablets, or laptops. The Tencent Security Xuanwu Lab researchers tested 35 fast-charging power bricks and power banks from eight different brands and powered by nine different PMICs. During the tests, the researchers found that 18 out of 35 fast-charging devices PMIC’s are vulnerable to Bad Power attacks. The researchers say that in these 18 fast charging chips, the legitimate firmware can easily be replaced by modified firmware. Among the 18 models, 11 models can be attacked through digital terminals that support fast charging.</p><h2>Demo Proof of Concept video:<br> <iframe width="175%" height="370vh" frameborder="0" allowfullscreen="allowfullscreen" data-src="https://v.qq.com/txp/iframe/player.html?vid=u3115r95vil" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><span
data-mce-type=bookmark style="display: inline-block; width: 0px; overflow: hidden; line-height: 0;" class=mce_SELRES_start>﻿</span></iframe></h2><p>The researchers say that nearly a million devices run on these PMICs and not only smartphones and tablets, but even laptops could also be vulnerable to such Bad Power attacks. Bad Power attacks could be both deployed physically and remotely which this vulnerability even more dangerous.</p></div></div></div></article></div>]]>
            </description>
            <link>https://androidrookies.com/fast-charging-vulnerability-could-be-used-by-hackers-to-explode-smartphones-remotely/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23880403</guid>
            <pubDate>Sat, 18 Jul 2020 10:29:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software Engineering != Coding]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23880280">thread link</a>) | @FailMore
<br/>
July 18, 2020 | https://taaalk.co/t/software-engineering-coding#c | <a href="https://web.archive.org/web/*/https://taaalk.co/t/software-engineering-coding#c">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
  <div id="tlk-section-read">
    



<div>

    <div>
      <div>
        <div>
          
          <div>
            <div>
              <div>
                <div>
  <p>I'm a recently trained full stack developer who want's to understand the FULL stack. Right now I think of that as backend + frontend code, but I hear there is more to it than that...</p>
</div>

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    <div>
      <div>
        <div>
          
          <div>
            <div>
              <div>
                <div>
  <div>
  <p>I am the founder of multiple bootstrapped companies. They include web, mobile and infrastructure development agency <a href="https://www.solidstategroup.com/">Solid State Group</a>, virtual office business <a href="https://www.hoxtonmix.com/">The Hoxton Mix</a> and, most recently, developer friendly feature flag tool <a href="https://bullet-train.io/">Bullet Train</a>. I've been involved with many more than that, watching some succeed and others fail.</p>
</div>
</div>

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

</div>

  </div>







  <div>

      <div id="1">
        <div>
          
          <p>Joshua Summers</p>
          <p>15:58, 26 Jun 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>Why did you ask for this?</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="2">
        <div>
          
          <p>Ben Rometsch</p>
          <p>12:36, 03 Jul 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>Right so yes I've spent over 25 years writing software for people in a professional capacity. As time has gone by, and I've learnt more about the process, I've slowly realised that actually writing code is actually quite a small part of the process. When I was a junior developer I probably spent 90% of my working day sat in front of an editor writing code. And I thought that was the job. Turns out it really isn't!Â&nbsp;</p></div><div><p>I think people both inside and outside of the industry fixate on coding for a number of reasons, and it's quite interesting to ruminate on those, but building software is so much more than writing code. Talking to users, agreeing on features, designing the interface, setting up the infrastructure, testing the platform for bugs, testing it for performance, providing support for it. These are all messy, imprecise things that have very human factors.Â&nbsp;</p></div><div><p>If you are a software engineer you can often seek solace in the code itself. Code is truth. You can't really argue with it. You can't argue with your compiler. It's really easy to fall into the trap of avoiding all work other than coding for these very reasons. But I would suggest that this makes you a really bad engineer! Engineering means getting your hands dirty, either literally in the case of Brunel, or from a human interaction point of view where software is concerned.</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="3">
        <div>
          
          <p>Joshua Summers</p>
          <p>14:15, 10 Jul 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>So you are sort of saying that an engineer solves problems, and problems are experienced (mostly) by people, so to solve problems effectively you a) have to deal with people and b) have to really know how to solve the problem (e.g. dealing with infrastructure, performance, etc.) instead of only the parts you are comfortable with. Is that correct?</p></div><div><p>How much of this comes down to the attitude of the engineer? And how much of this comes down to actively studying?Â&nbsp;</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="4">
        <div>
          
          <p>Ben Rometsch</p>
          <p>10:22, 13 Jul 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>In my experience, almost 100% of that learning comes from hard won experience.Â&nbsp;</p></div><div><p>When I studied at university, I was really surprised to discover that the "Computing" courses that I was interested in were labelled as "Software Engineering". I thought it was odd at the time; I never really had thought it about it before, and I was even a bit worried that I might have been signing up for the wrong course!Â&nbsp;</p></div><div><p>I don't think many universities at the time offered "Computer Science" as an undergrad course; it's a very different discipline.Â&nbsp;</p></div><div><p>It took me a LONG time to get my head around the fact that one of the words in the job was "engineering". And really the only way I realised that was after years of working building software. At some point the penny dropped that I was an engineer, and that writing code was only 1 aspect of that job.Â&nbsp;</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="5">
        <div>
          
          <p>Joshua Summers</p>
          <p>12:00, 15 Jul 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>So based on your experience, where do you feel the greatest value lies in the spectrum of what it means to be an engineer? Or is it person dependent?</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="6">
        <div>
          
          <p>Ben Rometsch</p>
          <p>12:21, 17 Jul 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>There are a number of things that people starting off in a career of Software Engineering should try and keep in mind.</p></div><div><div><ol>
<li>Never stop learning. Software development is still a very immature discipline. I like to think about it like building jet aeroplanes. After the jet engine was invented, flying on a jet passenger plane was pretty dangerous! Google "the de Havilland Comet". There was so much new engineering that needed to be learnt to get to the point where now it is pretty much the safest mode of transport in the world. The software industry is still building de Havilland Comets to a certain degree. So much is being learnt in terms of best practices, what works and what doesn't. If you don't constantly learn new things, you will be left behind.</li>
<li>You know less than you think. You can wield great power writing software and it can go to your head! Good engineers are humble and never think they either know it all or know better than others.</li>
<li>Stretch yourself. If you know an OOP language, learn a functional one like Elixir or Haskell. If you have spent a lot of time with a very high level language like Python, try Rust. Think of it like a gym. The machine you cant stand the site of is probably the one doing you the most good.</li>
<li>It is an art as well as a science. There is room for beauty and elegance in software.</li>
</ol></div></div>
</div>

            </div>
          </div>
        </div>
      </div>

  </div>








  

  





    </div></div>]]>
            </description>
            <link>https://taaalk.co/t/software-engineering-coding#c</link>
            <guid isPermaLink="false">hacker-news-small-sites-23880280</guid>
            <pubDate>Sat, 18 Jul 2020 09:52:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tricks with Pseudorandom Number Generators]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23879837">thread link</a>) | @todsacerdoti
<br/>
July 18, 2020 | https://theartofmachinery.com/2020/07/18/prng_tricks.html | <a href="https://web.archive.org/web/*/https://theartofmachinery.com/2020/07/18/prng_tricks.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
      <p>Pseudorandom number generators (PRNGs) are often treated like a compromise: their output isn’t as good as real
      random number generators, but they’re cheap and easy to use on computer hardware. But a special feature of PRNGs
      is that they’re <em>reproducible</em> sources of random-looking data:</p>
      <figure>
        <pre><code data-lang="d"><span>import</span> <span>std</span><span>.</span><span>random</span><span>;</span>
<span>import</span> <span>std</span><span>.</span><span>stdio</span><span>;</span>

<span>void</span> <span>main</span><span>()</span>
<span>{</span>
    <span>// Seed a PRNG and generate 10 pseudo-random numbers</span>
    <span>auto</span> <span>rng</span> <span>=</span> <span>Random</span><span>(</span><span>42</span><span>);</span>
    <span>foreach</span> <span>(</span><span>_</span><span>;</span> <span>0..10</span><span>)</span> <span>write</span><span>(</span><span>uniform</span><span>(</span><span>0</span><span>,</span> <span>10</span><span>,</span> <span>rng</span><span>),</span> <span>' '</span><span>);</span>
    <span>writeln</span><span>();</span>
    <span>// Reset the PRNG, and the same sequence is generated again</span>
    <span>rng</span> <span>=</span> <span>Random</span><span>(</span><span>42</span><span>);</span>
    <span>foreach</span> <span>(</span><span>_</span><span>;</span> <span>0..10</span><span>)</span> <span>write</span><span>(</span><span>uniform</span><span>(</span><span>0</span><span>,</span> <span>10</span><span>,</span> <span>rng</span><span>),</span> <span>' '</span><span>);</span>
    <span>writeln</span><span>();</span>

    <span>// Output:</span>
    <span>// 2 7 6 4 6 5 0 4 0 3</span>
    <span>// 2 7 6 4 6 5 0 4 0 3</span>
<span>}</span></code></pre>
      </figure>
      <p>This simple fact enables a few neat tricks.</p><p>A couple of famous examples come from the gaming industry. The classic example is the space trading game
      Elite, which was originally written for 8b BBC Micros in the early 80s. It was a totally revolutionary game, but
      just one thing that amazed fans was its complex universe of thousands of star systems. That was something you
      just didn’t normally get in games written for machines with kilobytes of RAM total. The trick was to generate the
      universe with a PRNG seeded with a small value. There was no need to store the universe in memory because the
      game could regenerate each star system on demand, repeatedly and deterministically.</p>
      <p>PRNGs are now widely exploited for recording games for replays. You don’t need to record every frame of the
      game world if you can just record the PRNG seed and all the player actions. (Like most things in software,
      <a href="https://technology.riotgames.com/news/determinism-league-legends-introduction">actually implementing
      that can be surprisingly challenging</a>.)</p>
      <h2 id="random-mappings">Random mappings</h2>
      <p>In machine learning, you often need a mapping from things to highly dimensional random unit vectors (random
      vectors of length 1). Let’s get more specific and say you’re processing documents for topic/sentiment analysis or
      similarity. In this case you’ll generate a random vector for each word in the dictionary. Then you can create a
      vector for each document by adding up the vectors for each word in it (with some kind of weighting scheme, in
      practice). Similar documents will end up with similar vectors, and you can use linear algebra tricks to uncover
      deeper patterns (read about <a href="https://en.wikipedia.org/wiki/Latent_semantic_analysis">latent semantic
      analysis</a> if you’re interested).</p>
      <p>An obvious way to get a mapping between words and random vectors is to just initially generate a vector for
      each word, and create a hash table for looking them up later. Another way is to generate the random vectors on
      demand using a PRNG seeded by a hash of the word. Here’s a toy example:</p>
      <figure>
        <pre><code data-lang="d"><span>/+ dub.sdl:
    name "prngvecdemo"
    dependency "mir-random" version="~&gt;2.2.14"
+/</span>
<span>// Demo of mapping words to random vectors with PRNGs</span>
<span>// Run me with "dub prngvecdemo.d"</span>

<span>import</span> <span>std</span><span>.</span><span>algorithm</span><span>;</span>
<span>import</span> <span>std</span><span>.</span><span>stdio</span><span>;</span>

<span>// Using the Mir numerical library https://www.libmir.org/</span>
<span>import</span> <span>mir</span><span>.</span><span>random</span><span>.</span><span>engine</span><span>.</span><span>xoshiro</span><span>;</span>
<span>import</span> <span>mir</span><span>.</span><span>random</span><span>.</span><span>ndvariable</span><span>;</span>

<span>enum</span> <span>kNumDims</span> <span>=</span> <span>512</span><span>;</span>
<span>alias</span> <span>RNG</span> <span>=</span> <span>Xoroshiro128Plus</span><span>;</span>
<span>// D's built-in hash happens to be MurmurHash, but we just need it to be suitable for seeding the PRNG</span>
<span>static</span> <span>assert</span><span>(</span><span>""</span><span>.</span><span>hashOf</span><span>.</span><span>sizeof</span> <span>==</span> <span>8</span><span>);</span>

<span>void</span> <span>main</span><span>()</span>
<span>{</span>
    <span>auto</span> <span>makeUnitVector</span> <span>=</span> <span>sphereVar</span><span>!</span><span>float</span><span>();</span>
    <span>auto</span> <span>doc</span> <span>=</span> <span>"a lot of words"</span><span>;</span>

    <span>float</span><span>[</span><span>kNumDims</span><span>]</span> <span>doc_vec</span><span>,</span> <span>word_vec</span><span>;</span>

    <span>doc_vec</span><span>[]</span> <span>=</span> <span>0.0</span><span>;</span>
    <span>foreach</span> <span>(</span><span>word</span><span>;</span> <span>doc</span><span>.</span><span>splitter</span><span>)</span>  <span>// Not bothering with whitening or stop word filtering for this demo</span>
    <span>{</span>
        <span>// Create a PRNG seeded with the hash of the word</span>
        <span>auto</span> <span>rng</span> <span>=</span> <span>RNG</span><span>(</span><span>word</span><span>.</span><span>hashOf</span><span>);</span>
        <span>// Generate a unit vector for the word using the PRNG</span>
        <span>// We'll get the same vector every time we see the same word</span>
        <span>makeUnitVector</span><span>(</span><span>rng</span><span>,</span> <span>word_vec</span><span>);</span>
        <span>// Add it to the document vector (no weighting for simplicity)</span>
        <span>doc_vec</span><span>[]</span> <span>+=</span> <span>word_vec</span><span>[];</span>
    <span>}</span>

    <span>writeln</span><span>(</span><span>doc_vec</span><span>);</span>
<span>}</span></code></pre>
      </figure>
      <p>This kind of trick isn’t the answer to everything, but it has some uses. Obviously, it can be useful if you’re
      working with more data than you have RAM (though you might still cache some of the generated data). Another use
      case is processing a large dataset with parallel workers. In the document example, you can get workers to “agree”
      on what the vector for each word should be, without data synchronisation, and without needing to do an initial
      pass over the data to build a dictionary of words. I’ve used this trick with experimental code, just because I
      was too lazy to add an extra stage to the data pipeline. In some applications, recomputing data on the fly can
      even be faster than fetching it from a very large lookup table.</p>
      <h2 id="an-ode-to-xorshift">An ode to Xorshift</h2>
      <p>You might have noticed I used <code>Xoroshiro128Plus</code>, a
      variant of the Xorshift PRNG. The Mersenne Twister is a de facto standard PRNG in some computing fields, but I’m
      a bit of a fan of the Xorshift family. The basic Xorshift engines are fast and pretty good, and there are
      variants that are still fast and have excellent output quality. But the big advantage compared to the Mersenne
      Twister is the state size. The Mersenne Twister uses a pool of 2496 bytes of state, whereas most of the Xorshift
      PRNGs can fit into one or two machine <code>int</code>s.</p>
      <p>The small state size has a couple of advantages for this kind of “on demand” PRNG usage: One is that
      thoroughly initialising a big state from a small seed takes work (some people “warm up” a Mersenne Twister by
      throwing away several of the initial outputs, just to be sure). The second is that the small size of the PRNGs
      makes them cheap enough to use in places you wouldn’t think of using a Mersenne Twister.</p>
      <h2 id="random-data-structures-made-reliable">Random data structures made reliable</h2>
      <p>Some data structures and algorithms use randomisation. An example is a treap, which is a binary search tree
      that uses a randomised heap for balancing. Treaps are much less popular than AVL trees or red-black trees, but
      they’re easier to implement correctly because you end up with fewer edge cases. They’re also good enough for most
      use cases. That makes them a good choice for application-specific “augmented” BSTs. But for argument purposes,
      it’s just a real example of a data structure that happens to use randomness as an implementation detail.</p>
      <p>Randomisation comes with a major drawback: it’s a pain when testing and debugging. Test failures aren’t
      reproducible for debugging if real randomness is used. If you have any experience with testing, you’ll have seen
      this and you’ll know it’s a good idea to use a PRNG instead.</p>
      <p>Using a global PRNG mostly works, but it couples the treaps through one shared PRNG. That accidental coupling
      can lead to test flakes if you’re running several tests at once, unless you’re careful to use one PRNG per thread
      and reset it for every test. Even then you can get Heisenbugs in your non-test code.</p>
      <p>What about dependency injection? Making every treap method require a reference to a PRNG works, but it leaks
      the implementation detail throughout your code. You could make the treap take a reference to a PRNG in its
      constructor, but that implies adding an extra pointer to the data structure. If you’re going to do that, why not
      just make every treap embed its own 32b or 64b Xorshift PRNG? Embedding the PRNG into the treap makes it
      deterministic and reproducible in a way that’s encapsulated and decoupled from everything else.</p>
    </div></div>]]>
            </description>
            <link>https://theartofmachinery.com/2020/07/18/prng_tricks.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23879837</guid>
            <pubDate>Sat, 18 Jul 2020 07:57:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Good]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23879790">thread link</a>) | @neilpanchal
<br/>
July 18, 2020 | https://neil.computer/notes/good/ | <a href="https://web.archive.org/web/*/https://neil.computer/notes/good/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    
<header>
    
</header>
        <!--Display single note. This template is dispatched by post.hbs-->
<main>
        <article>
        <h2>Good</h2>
        <h2 id="good-design-dieter-rams-braun-e-al-">Good Design <a href="https://www.vitsoe.com/us/about/good-design">(Dieter Rams, Braun e. al)</a></h2><p>is innovative<br>makes a product useful<br>is aesthetic<br>makes a product understandable<br>is unobtrusive<br>is honest<br>is long-lasting<br>is thorough down to the last detail<br>is environmentally-friendly<br>is as little design as possible</p><h2 id="good-engineering">Good Engineering</h2><p>is inventive<br>is based on fundamentals<br>is iterative<br>is modeled<br>is as per specifications<br>is manufacturable<br>is validated and tested<br>is reliable<br>is ethical<br>is not over-engineering</p><h2 id="good-marketing">Good Marketing</h2><p>is emotionally engaging<br>is direct and jargon-less<br>is inspiring<br>is data-driven<br>is irresistible<br>is truthful<br>is art<br>is experiential<br>respects cultures and heritage<br>is international</p>
        </article>
</main>
<p>
    <a href="https://neil.computer/">← Back to Home</a>
</p>

    


    

</div>]]>
            </description>
            <link>https://neil.computer/notes/good/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23879790</guid>
            <pubDate>Sat, 18 Jul 2020 07:47:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eliminating duplicate JavaScript objects: Three approaches]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23879070">thread link</a>) | @elijahmanor
<br/>
July 17, 2020 | https://2ality.com/2020/07/eliminating-duplicate-objects.html | <a href="https://web.archive.org/web/*/https://2ality.com/2020/07/eliminating-duplicate-objects.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In this blog post, we look at three approaches for eliminating duplicate objects from Arrays.</p>
<!--more-->
<h2 id="eliminating-duplicates-from-arrays">Eliminating duplicates from Arrays&nbsp;&nbsp;</h2>
<p>Eliminating duplicate values from Arrays is simple – as long as the values are primitive (and therefore compared by value):</p>
<pre><code><span>const</span> values = [<span>'jane'</span>, <span>'lars'</span>, <span>'jane'</span>];
<span>const</span> uniqueValues = [...new <span>Set</span>(values)];
assert.deepEqual(
  uniqueValues,
  [<span>'jane'</span>, <span>'lars'</span>]);
</code></pre>
<p>However, that approach doesn’t work with the following data because a Set would consider each object to be unique:</p>
<pre><code><span>const</span> members = [
  {
    <span>first</span>: <span>'Jane'</span>,
    <span>last</span>: <span>'Bond'</span>,
    <span>id</span>: <span>'10yejma'</span>,
  },
  {
    <span>first</span>: <span>'Lars'</span>,
    <span>last</span>: <span>'Croft'</span>,
    <span>id</span>: <span>'1hhs0k2'</span>,
  },
  {
    <span>first</span>: <span>'Jane'</span>,
    <span>last</span>: <span>'Bond'</span>,
    <span>id</span>: <span>'1y15hhu'</span>,
  },
];
</code></pre>
<h2 id="approach-1%3A-building-a-new-array-without-duplicates">Approach 1: building a new Array without duplicates&nbsp;&nbsp;</h2>
<pre><code><span>const</span> uniqueMembers1 = [];

<span>for</span> (<span>const</span> m <span>of</span> members) {
  <span>if</span> (!containsMember(uniqueMembers1, m)) {
    uniqueMembers1.push(m);
  }
}

<span><span>function</span> <span>containsMember</span>(<span>memberArray, member</span>) </span>{
  <span>return</span> memberArray.find(
    <span>(<span>m</span>) =&gt;</span> m.first === member.first &amp;&amp; m.last === member.last);
}

assert.deepEqual(
  uniqueMembers1,
  [
    {
      <span>first</span>: <span>'Jane'</span>,
      <span>id</span>: <span>'10yejma'</span>,
      <span>last</span>: <span>'Bond'</span>,
    },
    {
      <span>first</span>: <span>'Lars'</span>,
      <span>id</span>: <span>'1hhs0k2'</span>,
      <span>last</span>: <span>'Croft'</span>,
    },
  ]);
</code></pre>
<p>We only add an object from <code>members</code> to <code>uniqueMembers1</code> if it doesn’t already exist in that Array. That’s why the earlier Jane with ID <code>'10yejma'</code> “wins”.</p>
<h2 id="approach-2%3A-using-.filter()">Approach 2: using <code>.filter()</code>&nbsp;&nbsp;</h2>
<pre><code>
<span>const</span> uniqueMembers2 = members.filter(
  <span>(<span>m, index, ms</span>) =&gt;</span> getIndexOfMember(ms, m) === index);

<span><span>function</span> <span>getIndexOfMember</span>(<span>memberArray, member</span>) </span>{
  <span>return</span> memberArray.findIndex(
    <span>(<span>m</span>) =&gt;</span> m.first === member.first &amp;&amp; m.last === member.last);
}

assert.deepEqual(
  uniqueMembers2,
  [
    {
      <span>first</span>: <span>'Jane'</span>,
      <span>id</span>: <span>'10yejma'</span>,
      <span>last</span>: <span>'Bond'</span>,
    },
    {
      <span>first</span>: <span>'Lars'</span>,
      <span>id</span>: <span>'1hhs0k2'</span>,
      <span>last</span>: <span>'Croft'</span>,
    },
  ]);
</code></pre>
<p><code>getIndexOfMember()</code> returns the first index where a member appears. We tell <code>.filter()</code> to only keep the members at those indices. That’s why the first Jane “wins”.</p>
<h2 id="approach-3%3A-a-map-from-unique-keys-to-members">Approach 3: a Map from unique keys to members&nbsp;&nbsp;</h2>
<pre><code>
<span>const</span> uniqueKeyToMember = <span>new</span> <span>Map</span>(
  members.map(<span><span>m</span> =&gt;</span> [m.first+<span>'\t'</span>+m.last, m])); 
<span>const</span> uniqueMembers3 = [...uniqueKeyToMember.values()];

assert.deepEqual(
  uniqueMembers3,
  [
    {
      <span>first</span>: <span>'Jane'</span>,
      <span>id</span>: <span>'1y15hhu'</span>,
      <span>last</span>: <span>'Bond'</span>,
    },
    {
      <span>first</span>: <span>'Lars'</span>,
      <span>id</span>: <span>'1hhs0k2'</span>,
      <span>last</span>: <span>'Croft'</span>,
    },
  ]);
</code></pre>
<p>If an object that is added to the Map has the same unique key as a previous object, it replaces that object. That’s why the later Jane with ID <code>'1y15hhu'</code> “wins”.</p>
<h3 id="variants-of-approach-1-and-approach-2">Variants of approach 1 and approach 2&nbsp;&nbsp;</h3>
<p>We use a Set to record unique keys of members that we have visited. If the key of the current member is already in that Set, then we don’t push it (approach 1) or filter it out (approach 2).</p>
<p>This may help with large Arrays because we don’t have to search them. On the other hand, creating keys and maintaining a Set affects performance negatively.</p>
<h2 id="further-reading">Further reading&nbsp;&nbsp;</h2>
<ul>
<li><a href="https://exploringjs.com/impatient-js/ch_sets.html">Chapter on Sets</a> in “JavaScript for impatient programmers”</li>
<li><a href="https://exploringjs.com/impatient-js/ch_maps.html">Chapter on Maps</a> in “JavaScript for impatient programmers”</li>
</ul>
</div></div>]]>
            </description>
            <link>https://2ality.com/2020/07/eliminating-duplicate-objects.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23879070</guid>
            <pubDate>Sat, 18 Jul 2020 04:56:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MSDN – Blast from the Past]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23879066">thread link</a>) | @georges_gomes
<br/>
July 17, 2020 | https://blog.alignment-systems.com/2020/07/msdn-blast-from-past.html | <a href="https://web.archive.org/web/*/https://blog.alignment-systems.com/2020/07/msdn-blast-from-past.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div id="main" name="Main"><div data-version="1" id="Blog1">
<div>

          <div>
        
<h2><span>Wednesday, 15 July 2020</span></h2>

          <div>
        
<div>
<div itemprop="blogPost" itemscope="itemscope" itemtype="http://schema.org/BlogPosting">
<meta content="https://1.bp.blogspot.com/-CKcvH2TzptY/Xw5Kv9bbyYI/AAAAAAAAA7w/qyj3UudDyr0OBcgC7fvUYkm0YG55NUBEwCLcBGAsYHQ/w500-h281/IMG_20200608_1548101.jpg" itemprop="image_url">
<meta content="1335120992661844060" itemprop="blogId">
<meta content="1559585008980116943" itemprop="postId">
<h3 itemprop="name">
MSDN : Blast from the past...
</h3>

<div id="post-body-1559585008980116943" itemprop="description articleBody">
<p><span face="arial">Having a clear-out of unused technology items - <a href="https://www.gsmarena.com/blackberry_playbook-3830.php">Blackberry Playbook</a> anyone? And while doing so found this <a href="https://en.wikipedia.org/wiki/Microsoft_Developer_Network">Microsoft MSDN</a> case.<span><a name="more"></a></span></span></p><p><span face="arial"><br><span><p><a href="https://1.bp.blogspot.com/-CKcvH2TzptY/Xw5Kv9bbyYI/AAAAAAAAA7w/qyj3UudDyr0OBcgC7fvUYkm0YG55NUBEwCLcBGAsYHQ/s2048/IMG_20200608_1548101.jpg" imageanchor="1"><img data-original-height="1152" data-original-width="2048" height="281" src="https://1.bp.blogspot.com/-CKcvH2TzptY/Xw5Kv9bbyYI/AAAAAAAAA7w/qyj3UudDyr0OBcgC7fvUYkm0YG55NUBEwCLcBGAsYHQ/w500-h281/IMG_20200608_1548101.jpg" width="500"></a></p></span><br></span></p><p><span face="arial">Back in the days before retail high-speed broadband, the usual method of software distribution was CD or DVD. &nbsp;And they were stored in the MSDN case. &nbsp;This one will fit about 100 CDs. Which at about 700Mb per disc is around 70Gb. &nbsp;And that can now all be stored in a MicroSD card that'll cost around £22. &nbsp;And still have 50GB or so spare...</span></p><p><a href="https://1.bp.blogspot.com/-qcqt8sa3AlA/Xw5TNzT8RqI/AAAAAAAAA8E/pAtnSJB63SAYC7T4V4Jvfl3DMv8FIfchACLcBGAsYHQ/s2048/IMG_20200715_1046585.jpg" imageanchor="1"><span face="arial"><img data-original-height="2048" data-original-width="1152" height="320" src="https://1.bp.blogspot.com/-qcqt8sa3AlA/Xw5TNzT8RqI/AAAAAAAAA8E/pAtnSJB63SAYC7T4V4Jvfl3DMv8FIfchACLcBGAsYHQ/s320/IMG_20200715_1046585.jpg"></span></a></p>

</div>
<div>
<div>
<p><span>
</span>
<span>
</span>
<span>
</span>
<span>
</span>
<span>
<span>
<a href="https://www.blogger.com/email-post.g?blogID=1335120992661844060&amp;postID=1559585008980116943" title="Email Post">
<img alt="" height="13" src="https://resources.blogblog.com/img/icon18_email.gif" width="18">
</a>
</span>
</span></p>
</div>


</div>
</div>

</div>

        </div></div>
      
</div>



</div></div>
</div>
</div></div>]]>
            </description>
            <link>https://blog.alignment-systems.com/2020/07/msdn-blast-from-past.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23879066</guid>
            <pubDate>Sat, 18 Jul 2020 04:55:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Turning the IDE Inside Out with Datalog]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23878783">thread link</a>) | @jrvarela56
<br/>
July 17, 2020 | https://petevilter.me/post/datalog-typechecking/ | <a href="https://web.archive.org/web/*/https://petevilter.me/post/datalog-typechecking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://petevilter.me/post/datalog-typechecking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23878783</guid>
            <pubDate>Sat, 18 Jul 2020 04:01:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Neuroscience startup building tech to read your thoughts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23878734">thread link</a>) | @samnwa
<br/>
July 17, 2020 | https://www.brainhackernews.com/kernel-reading-and-writing-human-thought/ | <a href="https://web.archive.org/web/*/https://www.brainhackernews.com/kernel-reading-and-writing-human-thought/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://www.brainhackernews.com/content/images/size/w300/2020/07/kernelHead-1.png 300w,
                            https://www.brainhackernews.com/content/images/size/w600/2020/07/kernelHead-1.png 600w,
                            https://www.brainhackernews.com/content/images/size/w1000/2020/07/kernelHead-1.png 1000w,
                            https://www.brainhackernews.com/content/images/size/w2000/2020/07/kernelHead-1.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://www.brainhackernews.com/content/images/size/w2000/2020/07/kernelHead-1.png" alt="Kernel: Reading and writing human thought">
            </figure>

            <section>
                <div>
                    <p>Kernel, a start-up claiming to offer “Neuroscience as a Service” has been in the news lately because of their recently announced $53M Series C fund raising. What hasn’t been as widely covered is what their services are and how they work.</p><p>Fortunately Kernel has published a fairly <a href="https://www.kernel.co/hello-humanity">extensive breakdown</a> of their research and the resulting products they plan to bring to market. Kernel is focused on measuring signals in the brain to better understand the brain and advance neuroscience more quickly, eventually hoping to be able to read and write cognition. Traditional tools for measuring brain activity like functional Magnetic Resonance Imaging fMRI and Electroencephalography &nbsp;(EEG) are costly, bulky and difficult to use in real-life situations that would produce more meaningful data.</p><p>To solve this problem, Kernel has developed two different technologies for measuring brain activity it calls Flow and Flux, which it hopes will scale our understanding of the human brain, leading to advances in brain health and overall brain performance to name just a few potential benefits. Kernel believes that using both technologies in conjunction will result in even faster advances in how brain activity is measured.</p><p>Kernel Flow is a technology for measuring hemodynamics, that is the flow of blood, in the brain. This is similar to an FMRI, only without needing the patient to lie perfectly still in a room-sized machine. Flow by contrast is a wearable headset which allows the wearer to engage in normal activities, and the data is processed in a connected computer (currently tethered via USB, though wireless data transfer certainly seems feasible given the relative transfer rates of USB and WiFi standards).</p><p>Kernel Flux uses advanced devices that measure magnetic fields called optically pumped magnetometers or OPMs, while still allowing the subject to move their head normally and comfortably. The flux system is also able to distinguish background magnetic fields not coming from the subject (such as the magnetic fields created by power lines or other parts of the human body) and filter them out, resulting in a higher signal to noise ratio.</p><p>Kernel detailed two experiments to demonstrate the fidelity of its neural activity measurements, “Speller” and “Speak ID.” Both experiments described are reproductions of previously published experiments using sensors that seems to have been the precursors to its Kernel Flux technology.</p><p>In the Speller experiment, subjects were shown 30, eight-letter words (240 total letters), and asked to spell each word after it was displayed by looking at a visual keyboard. Using 20 OPMs, placed on the subjects head, the researchers were able to measure the brain waves of the participants, then run them through a statistical method known as canonical correlation analysis (CCA). With this analysis, the researchers were able to correctly predict which letter the subject was looking at an average of 80% of the time. In subsequent experiments, they were able to nearly reproduce the performance of 20 sensors using only 4 sensors.</p><p>The Sound ID experiment used 16 OPM sensors again placed on the heads of the subjects, while the subject selected 60 second snippets of recorded speech. Again using CCA analysis on the real-time data fed from the sensors the researchers were able to determine which snippet the subject was listening to with 100% accuracy in most cases in under 20 seconds. The experiment was also run using snippets of songs instead of speech, and while the results were less accurate and predictions took longer, they were able to predict 8 out of 10 songs correctly in some subjects.</p><p>Kernel has promised to share results from their Flow and Flux hardware soon. Until then, we'll be wondering what new insights might be gleaned from these novel ways of collecting data directly from the brain. </p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.brainhackernews.com/kernel-reading-and-writing-human-thought/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23878734</guid>
            <pubDate>Sat, 18 Jul 2020 03:49:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Typed Lisp, a Primer (2019)]]>
            </title>
            <description>
<![CDATA[
Score 97 | Comments 21 (<a href="https://news.ycombinator.com/item?id=23878612">thread link</a>) | @jedimind
<br/>
July 17, 2020 | https://alhassy.github.io/TypedLisp.html | <a href="https://web.archive.org/web/*/https://alhassy.github.io/TypedLisp.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="text-typing-via-macros">
<p>
Checking the type of inputs is tedious and so I <a href="https://www.reddit.com/r/emacs/comments/cct5hp/functional_type_declarations_in_elisp/">guessed</a> it could be done using
macros and advice. Looking at <a href="https://docs.racket-lang.org/ts-guide/types.html">Typed Racket</a> for inspiration, the following
fictitious syntax would add advice to <code>f</code> that checks the optional arguments <code>xᵢ</code>
have type <code>σᵢ</code> and the mandatory positional arguments have type <code>τᵢ</code> according
to position, and the result of the computation is of type <code>τ</code>.
To the best of my knowledge, no one had done this for Emacs Lisp —I don't know why.
</p>
<div>
<pre>(declare-type 'f ((<span>:x₁</span> σ₁) … (<span>:xₘ</span> σₘ)) (τ₁ … τₙ τ))
</pre>
</div>

<p>
To modify a variable, or function, we may simply redefine it; but a much more elegant and powerful
approach is to <a href="https://www.gnu.org/software/emacs/manual/html_node/elisp/Advising-Functions.html">“advise”</a> the current entity with some new behaviour. In our case of interest, we will
<i>advise functions to check their arguments before executing their bodies</i>.
</p>

<p>
Below is my attempt: <a id="org84d2c90"><code>declare-type</code></a>. Before you get scared or think it's horrendous, be charitable and
note that about a third of the following is documentation and a third is local declarations.
</p>
<div>
<pre>(<span>cl-defmacro</span> <span>declare-type</span> (f key-types <span>&amp;rest</span> types)
  <span>"Attach the given list of types to the function ‘f’</span>
<span>   by advising the function to check its arguments’ types</span>
<span>   are equal to the list of given types.</span>

<span>   We name the advice ‘⟪f⟫-typing-advice’ so that further</span>
<span>   invocations to this macro overwrite the same advice function</span>
<span>   rather than introducing additional, unintended, constraints.</span>

<span>   Using type specifiers we accommodate for unions of types</span>
<span>   and subtypes, etc ♥‿♥.</span>

<span>   ‘</span><span>key-types</span><span>’ should be of the shape (:x₀ t₀ ⋯ :xₙ tₙ);</span>
<span>    when there are no optional types, use symbol “:”.</span>

<span>    E.g., (declare-type my-func (:z string :w integer) integer symbol string)</span>
<span>  "</span>

  <span>;; </span><span>Basic coherency checks. When there aren't optional types, key-types is the “:” symbol.</span>
  (should (<span>and</span> (<span>listp</span> types) (<span>or</span> (<span>listp</span> key-types) (<span>symbolp</span> key-types))))

  (<span>letf*</span> ((pairify (<span>lambda</span> (xs) (<span>loop</span> for i in xs by #'<span>cddr</span>         <span>;; </span><span>Turn a list of flattenned pairs</span>
                                      for j in (<span>cdr</span> xs) by #'<span>cddr</span>   <span>;; </span><span>into a list of explicit pairs.</span>
                                      collect (<span>cons</span> i j))))         <span>;; </span><span>MA: No Lisp method for this!?</span>
         (result-type  (<span>car</span> (<span>-take-last</span> 1 types)))
         (types        (<span>-drop-last</span> 1 types))
         (num-of-types (<span>length</span> types))
         (key-types-og (<span>unless</span> (<span>symbolp</span> key-types) key-types))
         (key-types    (<span>funcall</span> pairify key-types-og))
         (advice-name  (<span>intern</span> (<span>format</span> <span>"%s-typing-advice"</span> f)))
         (notify-user  (<span>format</span> <span>"%s now typed %s → %s → %s."</span>
                               `,f key-types-og types result-type)))

      `(<span>progn</span>
         (<span>defun</span> ,advice-name (orig-fun <span>&amp;rest</span> args)

           <span>;; </span><span>Split into positional and key args; optionals not yet considered.</span>
           (<span>letf*</span> ((all-args
                     (<span>-split-at</span>
                       (<span>or</span> (<span>--find-index</span> (<span>not</span> (<span>s-blank?</span> (<span>s-shared-start</span> <span>":"</span> (<span>format</span> <span>"%s"</span> it)))) args) ,num-of-types)
                        args)) <span>;; </span><span>The “or” is for when there are no keywords provided.</span>
                  (pos-args  (<span>car</span> all-args))
                  (key-args  (<span>funcall</span> ,pairify (<span>cadr</span> all-args)))
                  (fun-result nil)
                  ((<span>symbol-function</span> 'shucks)
                     (<span>lambda</span> (eτ e g)
                       (<span>unless</span> (<span>typep</span> g eτ)
                         (<span>error</span> <span>"%s: Type mismatch! Expected %s %s ≠ Given %s %s."</span>
                                (<span>function</span> ,f) eτ e (<span>type-of</span> g) (<span>prin1-to-string</span> g))))))

         <span>;; </span><span>Check the types of positional arguments.</span>
         (<span>unless</span> (<span>equal</span> ,num-of-types (<span>length</span> pos-args))
           (<span>error</span> <span>"%s: Insufficient number of arguments; given %s, %s, but %s are needed."</span>
                  (<span>function</span> ,f) (<span>length</span> pos-args) pos-args ,num-of-types))
         (<span>loop</span> for (ar ty pos) in (<span>-zip</span> pos-args (<span>quote</span> ,types) (<span>number-sequence</span> 0 ,num-of-types))
               <span>do</span> (shucks ty (<span>format</span> <span>"for argument %s"</span> pos) ar))

         <span>;; </span><span>Check the types of *present* keys.</span>
         (<span>loop</span> for (k . v) in key-args
               <span>do</span> (shucks (<span>cdr</span> (<span>assoc</span> k (<span>quote</span> ,key-types))) k v))

         <span>;; </span><span>Actually execute the orginal function on the provided arguments.</span>
         (<span>setq</span> fun-result (<span>apply</span> orig-fun args))
         (shucks (<span>quote</span> ,result-type) <span>"for the result type (!)"</span> fun-result)

         <span>;; </span><span>Return-value should be given to caller.</span>
         fun-result))

      <span>;; </span><span>Register the typing advice and notify user of what was added.</span>
      (<span>advice-add</span> (<span>function</span> ,f) <span>:around</span> (<span>function</span> ,advice-name))
      ,notify-user )))
</pre>
</div>

<pre>declare-type
</pre>


<p>
There are some notable shortcomings: Lack of support for type variables and, for now, no support for
optional arguments. Nonetheless, I like it —of course.
( Using <a href="https://www.gnu.org/software/emacs/manual/html_node/elisp/Watching-Variables.html#Watching-Variables">variable watchers</a> we could likely add support for type variables as well as
function-types. )
</p>

<p>
<b>We accidentally forgot to consider an argument.</b>
</p>
<div>
<pre>(declare-type f₁ (<span>:z</span> <span>string</span> <span>:w</span> <span>list</span>) integer symbol <span>string</span>)
<span>;; </span><span>⇒ f₁ now typed (:z string :w integer) → (integer symbol) → string.</span>

(<span>cl-defun</span> <span>f₁</span> (x y <span>&amp;key</span> z w) (<span>format</span> <span>"%s"</span> x))
<span>;; </span><span>⇒ f₁ now defined</span>

(f₁ 'x) <span>;; </span><span>⇒ f₁: Insufficient number of arguments; given 2, (x), but 3 are needed.</span>
</pre>
</div>
<p>
The type declaration said we needed 3 arguments, but we did not consider one of them.
</p>

<p>
<b>We accidentally returned the wrong value.</b>
</p>
<div>
<pre>(declare-type f₂ (<span>:z</span> <span>string</span> <span>:w</span> <span>list</span>) integer symbol <span>string</span>)
(<span>cl-defun</span> <span>f₂</span> (x y <span>&amp;key</span> z w) x)

(f₂ 144 'two)
<span>;; </span><span>⇒ f₂: Type mismatch! Expected string for the result type (!) ≠ Given integer 144.</span>
</pre>
</div>

<p>
<b>We accidentally forgot to supply an argument.</b>
</p>
<div>
<pre>(declare-type f₃ (<span>:z</span> <span>string</span> <span>:w</span> <span>list</span>) integer symbol <span>string</span>)
(<span>cl-defun</span> <span>f₃</span> (x y <span>&amp;key</span> z w) (<span>format</span> <span>"%s"</span> x))

(f₃ 144)
<span>;; </span><span>⇒ f₃: Insufficient number of arguments; given 1, (144), but 2 are needed.</span>
</pre>
</div>

<p>
<b>A positional argument is supplied of the wrong type.</b>
</p>
<div>
<pre>(f₃ 'one <span>"two"</span>)
<span>;; </span><span>⇒  f₃: Type mismatch! Expected integer for argument 0 ≠ Given symbol one.</span>

(f₃ 144 <span>"two"</span>)
<span>;; </span><span>⇒ f₃: Type mismatch! Expected symbol for argument 1 ≠ Given string "two".</span>
</pre>
</div>
<p>
Notice: When multiple positional arguments have type-errors, the errors are reported one at a time.
</p>

<p>
<b>A keyword argument is supplied of the wrong type.</b>
</p>
<div>
<pre>(f₃ 1 'two <span>:z</span> 'no₀ <span>:w</span> 'no₁)
<span>;; </span><span>⇒ f₃: Type mismatch! Expected string :z ≠ Given symbol no₀.</span>

(f₃ 1 'two <span>:z</span> <span>"ok"</span> <span>:w</span> 'no₁)
<span>;; </span><span>⇒ f₃: Type mismatch! Expected string :w ≠ Given symbol no₁.</span>

(f₃ 1 'two <span>:z</span> <span>"ok"</span> <span>:w</span> 23)
<span>;; </span><span>⇒ f₃: Type mismatch! Expected string :w ≠ Given integer 23.</span>

(f₃ 1 'two <span>:z</span> <span>"ok"</span> <span>:w</span> '(a b 1 2)) <span>;; </span><span>⇒ okay; no type-error.</span>
</pre>
</div>

<p>
<b>We have no optional arguments.</b>
</p>
<div>
<pre>(declare-type f₄ : integer symbol <span>string</span>)
(<span>cl-defun</span> <span>f₄</span> (x y <span>&amp;key</span> z w) (<span>format</span> <span>"%s"</span> x))

(f₄ 144 'two <span>:z</span> <span>"bye"</span>)
<span>;; </span><span>⇒  f₄: Type mismatch! Expected nil :z ≠ Given string "bye".</span>
<span>;; </span><span>( We shouldn't have any keyword :z according to the type declaration! )</span>

(f₄ 144 'two) <span>;; </span><span>⇒ "144"</span>
</pre>
</div>

<p>
<b>We can incorporate type specfiers such as unions!</b>
</p>
<div>
<pre>(declare-type f₅ : (<span>or</span> integer <span>string</span>) <span>string</span>)
(<span>cl-defun</span> <span>f₅</span> (x) (<span>format</span> <span>"%s"</span> x))

(f₅ 144)     <span>;; </span><span>⇒ "144"</span>
(f₅ <span>"neato"</span>) <span>;; </span><span>⇒ "neato"</span>

(f₅ 'shaka-when-the-walls-fell)
<span>;; </span><span>⇒ f₅: Type mismatch! Expected (or integer string) for argument 0</span>
<span>;;       </span><span>≠ Given symbol shaka-when-the-walls-fell.</span>
</pre>
</div>

<p>
<b>No positional arguments but a complex optional argument!</b>
</p>
<div>
<pre>(declare-type f₆ (<span>:z</span> (satisfies (<span>lambda</span> (it) (<span>and</span> (<span>integerp</span> it) (<span>=</span> 0 (<span>mod</span> it 5))))))
                 character)
(<span>cl-defun</span> <span>f₆</span> (<span>&amp;key</span> z) ?A)

(f₆ 'hi)     <span>;; </span><span>⇒  Keyword argument 144 not one of (:z)</span>
(f₆)         <span>;; </span><span>⇒ 65; i.e., the character ‘A’</span>
(f₆ <span>:z</span> 6)
<span>;; </span><span>⇒  f₆: Type mismatch!</span>
<span>;;    </span><span>Expected (satisfies (lambda (it) (and (integerp it) (= 0 (mod it 5))))) :z</span>
<span>;;    </span><span>≠ Given integer 6.</span>

(f₆ <span>:z</span> 10) <span>;; </span><span>⇒ 65; i.e., the expected output since 10 mod 5 ≈ 0 &amp; so 10 is valid input.</span>
</pre>
</div>

<p>
<b>Preconditions!</b> The previous example had a complex type on a keyword, but that was
essentially a pre-condition; we can do the same on positional arguments.
</p>
<div>
<pre>(declare-type f₇ : (satisfies (<span>lambda</span> (it) (<span>=</span> it 5)))
                   integer)
(<span>cl-defun</span> <span>f₇</span> (n) n)
<span>;; </span><span>The identity on 5 function; and undefined otherwise.</span>

(f₇ 4)
<span>;; </span><span>⇒ f₇: Type mismatch! Expected (satisfies (lambda (it) (= it 5))) for argument 0</span>
<span>;;       </span><span>≠ Given integer 4.</span>

(f₇ 5) <span>;; </span><span>⇒ 5</span>
</pre>
</div>

<p>
<b>Postconditions!</b>
Given an integer greater than 5, we present an integer greater than 2; i.e.,
this is a constructive proof that \(∀ n • n &gt; 5 ⇒ n &gt; 2\).
</p>
<div>
<pre>(declare-type f₈ : (satisfies (<span>lambda</span> (in)  (<span>&gt;</span> in 5)))
                   (satisfies (<span>lambda</span> (out) (<span>&gt;</span> out 2))))
(<span>cl-defun</span> <span>f₈</span> (n) n)
<span>;; </span><span>The identity on 5 function; and undefined otherwise.</span>

(f₈ 4)
<span>;; </span><span>⇒  f₈: Type mismatch! Expected (satisfies (lambda (in) (&gt; in 5))) for argument 0</span>
<span>;;        </span><span>≠ Given integer 4.</span>

(f₈ 72) <span>;; </span><span>⇒ 72; since indeed 72 &gt; 5 for the input, and clearly 72 &gt; 2 for the output.</span>
</pre>
</div>

<p>
As it currently stands we cannot make any explicit references between the inputs
and the output, but that's an easy fix: Simply add a local function <code>old</code> to the
<a href="#org84d2c90"><code>declare-type</code></a> macro which is intentionally exposed so that it can be used in the
type declarations to refer to the ‘old’, or initial, values provided to the function.
Additionally, one could also add keyword arguments <code>:requires</code> and <code>:ensures</code>
for a more sophisticated pre- and post-condition framework.
<a href="https://github.com/sellout/quid-pro-quo">Something</a> along these lines is implemented for Common Lisp.
</p>

<p>
Here's a fun exercise: Recast the <a href="https://liquid.kosmikus.org/01-intro.html#/what-is-liquid-haskell">Liquid Haskell</a> examples in Lisp using this
<a href="#org84d2c90"><code>declare-type</code></a> form.
</p>
</div></div>]]>
            </description>
            <link>https://alhassy.github.io/TypedLisp.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23878612</guid>
            <pubDate>Sat, 18 Jul 2020 03:19:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reinvention as Subversive Activity]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23878574">thread link</a>) | @lpcrealmadrid
<br/>
July 17, 2020 | https://ammarmian.com/blog/on-reinvention/ | <a href="https://web.archive.org/web/*/https://ammarmian.com/blog/on-reinvention/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<p>
I'd wake up to the sound of waves in the Outer Sunset.
Ride my bike past the eastbound N. Judah bus heading inland. Whiz crosstown to that bright red door in SoMa. That dreadful, joyful, awful, inspiring red door.

</p>

<p>
Every day behind that red door, five of us wandering souls congregated. We dodged the morning glory of San Franciscoâ€™s shit and piss to enter the path of mastery.
</p>

<p>
One hour of instruction. A full day of building subsets of various popular technologies, from scratch.
</p>

<p>
<em>Calm practice.</em>
</p>

<p>
We were accustomed to frantic practice - college taught us to treat knowledge as something disembodied from us, as if it were something to drink up, consume, cram. We were thirsty, so our college professors tried to quench us with dusty slides on overhead projectors.
</p>

<p>
I struggled with calm practice. It didnâ€™t let me hide. Oz and Myles insisted that there is no knowledge without fundamental understanding. As we wrote our programs, Oz would ask us:
</p>

<p>
â€œLet me see your understanding.â€�
</p>

<p>
So we had to show our work. Our hand scribbles, our test cases, our questions, our explanations, our exposition, our diagrams.
</p>

<p>
Some days, my monkey mind hated this relentless pursuit of understanding. I would grow frustrated by my lack of skills. Iâ€™d hack together a program that barely worked.
</p>

<p>
Oz had a sixth sense for this. On this day, noticing my frustration, he came over to me and placed an Albert Einstein bobblehead next to my laptop.
</p>

<p><img src="https://ammarmian.com/img/einstein.png" alt="Einstein bobblehead"></p><p>
The calm yet unending repetition of Albertâ€™s finger touching forehead reminded me: â€œJust think. Itâ€™s all in there.â€�
</p>

<p>
I wish I could say I was enlightened on the spot. Instead I silently told Oz to go fuck himself, and he chuckled and walked away.
</p>

<h3>
Old School, New School
</h3>

<p>
This was my experience as part of the first experimental cohort of the Bradfield School of Computer Science. In 6 months of studying with Oz and Myles, I learned more than I ever had from regurgitating textbook concepts for exams.
</p>

<p>
My time at Bradfield set me on a path to discover education continuously from the experts all around me. That sounds so obvious, but I always thought I needed permission to learn. I thought education was something static that I acquired once and never needed to think about again.
</p>

<p>
What I didn't understand: our economy was built for static expertise. Go to college, gain credentials, and youâ€™ll be set for the rest of your life. Take a course or a workshop, and ride the certification train to a raise or promotion.
</p>

<p>
Our world is anything but static. Technology, business innovation, and social movements have changed the landscape in a radical way. Your economics and political science degree doesnâ€™t prepare you for what you need to know in the world. Even your technical degree or advanced credential doesnâ€™t quite prepare you.
</p>

<p>
We are by and large using Old World tactics to navigate the New World. The rules have changed.
</p>

<p>
<strong>Old World</strong>: unflagging economic growth, rapid job creation, government-subsidized education, big companies offering long careers, ordinary Americans taking out low-interest loans from local banks.
</p>

<p>
<strong>New World</strong>: rapid digital automation of jobs and mass layoffs, high education costs, stagnant economic growth, ordinary Americans mired in all sorts of debt.
</p>

<p>
The existing institutions gave us the paternalistic comfort that they understood what was going on. Only they could teach you what you need to learn to succeed in the world.
</p>

<p>
These institutions no longer play that role. We donâ€™t trust these institutions as much as we used to. This is a healthy stance.
</p>

<p>
<strong>Old School</strong>: packaged, exam-based, lecturer-led, synchronous, passive and isolated, credential-oriented.
</p>

<p>
<strong>New School</strong>: a la carte, project-based, practitioner-led, asynchronous, immersive and collaborative, accomplishment-oriented.
</p>

<p>
Legacy institutions are now scrambling to keep up with new forms of education that are emerging around us. These new forms are bootcamps, intensive trade schools, online courses provided directly by masters of the craft, live screencasts and videos.
</p>

<p>
<strong>Old Mind</strong>: passively receive instruction, memorize concepts, take lecture notes, cram for the exam, and receive a grade not directly tied to accomplishment.
</p>

<p>
<strong>New Mind</strong>: actively engage with instruction, play and reconfigure concepts, shadow the practitioner, and gauge understanding through direct accomplishment.
</p>

<p>
This is all really exciting stuff. The New Mind is going to be the biggest differentiator in the modern world for years to come. The New Mind learns differently. Yet we are still entering these new education forms with the Old Mind.
</p>

<h3>
Old Mind, New Mind
</h3>

<p>
You see, the New School requires the New Mind. The New Mind is very much like the mind of our heroes of antiquity, the Montaignes and Spinozas and Galileos, the autodidacts fashioning their own educations through apprenticeship and self-discovery.
</p>

<p>
The new is the old made fashionable again. The old had never left, it had just gone into hiding, waiting for a worthy society to rediscover it. We are a worthy society, and we have rediscovered The New Mind.
</p>

<p>
Itâ€™s the teacher pointing at the bobblehead.
</p>

<p>
Itâ€™s the bobbleheadâ€™s finger pointing at its head.
</p>

<p>
Itâ€™s the whole situation reminding you that you have all the tools to reinvent yourself.
And reinvention is how you subvert The Old Mind. This subversion reveals The New Mind that you possessed all along.
</p>

      <p><em>July 2020</em></p>
      <p><a href="https://ammarmian.com/">Home</a></p></div></div>]]>
            </description>
            <link>https://ammarmian.com/blog/on-reinvention/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23878574</guid>
            <pubDate>Sat, 18 Jul 2020 03:09:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why differential privacy is awesome (2018)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23878536">thread link</a>) | @momonga
<br/>
July 17, 2020 | https://desfontain.es/privacy/differential-privacy-awesomeness.html | <a href="https://web.archive.org/web/*/https://desfontain.es/privacy/differential-privacy-awesomeness.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><small>
<span>P</span>art of a series on differential privacy.
In case you need reading material once you finished this post!</small></p><p><small>
<ol>
<li><strong>Why differential privacy is awesome</strong> (this article) presents a
   non-technical explanation of the definition.</li>
<li><a href="https://desfontain.es/privacy/differential-privacy-in-more-detail.html">Differential privacy in (a bit) more detail</a> introduces the formal
   definition, with very little math.</li>
<li><a href="https://desfontain.es/privacy/differential-privacy-in-practice.html">Differential privacy in practice (easy version)</a> explains how to
   make simple statistics differentially private.</li>
<li><a href="https://desfontain.es/privacy/almost-differential-privacy.html">Almost differential privacy</a> describes how to publish private
   histograms without knowing the categories in advance.</li>
<li><a href="https://desfontain.es/privacy/local-global-differential-privacy.html">Local vs. global differential privacy</a> presents the two main <em>models</em>
   of differential privacy, depending on who the attacker is.</li>
<li><a href="https://desfontain.es/privacy/privacy-loss-random-variable.html">The privacy loss random variable</a> explains the real meaning
   of <span>\((\varepsilon,\delta)\)</span>-differential privacy.</li>
</ol>
</small></p>
<hr>
<p><span>A</span><strong>re</strong> you following tech- or privacy-related
news? If so, you might have heard about <em>differential privacy</em>. The concept is
popular both in academic circles and inside tech companies. Both <a href="https://www.wired.com/2016/06/apples-differential-privacy-collecting-data/">Apple</a> or
<a href="https://security.googleblog.com/2014/10/learning-statistics-with-privacy-aided.html">Google</a> use differential privacy to collect data in a private way.</p>
<p>So, what's this definition about? How is it better than <a href="https://desfontain.es/privacy/k-anonymity.html">definitions</a>  <a href="https://desfontain.es/privacy/k-map.html">that</a>  <a href="https://desfontain.es/privacy/l-diversity.html">came</a>  <a href="https://desfontain.es/privacy/delta-presence.html">before</a>?
More importantly, why should you care? What makes it so exciting to researchers
and tech companies? In this post, I'll try to explain the idea behind
differential privacy and its advantages. I'll do my best to keep it simple and
accessible for everyone&nbsp;—&nbsp;not only technical folks.</p>

<p>Suppose you have a process that takes some database as input, and returns some output.</p>
<center>
<svg role="img" aria-label="Diagram showing an arrow labeled &quot;some process&quot;, going from a fake database to a cloud labeled &quot;output&quot;." xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:svg="http://www.w3.org/2000/svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape" version="1.1" viewBox="0 0 699.45947 142.76904" stroke-miterlimit="10" id="svg4123" sodipodi:docname="no-magic.svg" inkscape:version="0.92.2pre0 (973e216, 2017-07-25)" width="699.45947" height="142.76904" style="fill:none;stroke:none;stroke-linecap:square;stroke-miterlimit:10">
  <title>Diagram showing an arrow labeled "some process", going from a fake database to a cloud labeled "output".</title>
  <desc>Diagram showing an arrow labeled "some process", going from a fake database to a cloud labeled "output".</desc>
  <metadata id="metadata4129">
    <rdf:rdf>
      <cc:work rdf:about="">
        <dc:format>image/svg+xml</dc:format>
        <dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"></dc:type>
        <dc:title></dc:title>
      </cc:work>
    </rdf:rdf>
  </metadata>
  <defs id="defs4127">
    <clipPath id="p.3-4">
      <path d="M 0,0 H 275 V 252 H 0 Z" id="path4077-0" inkscape:connector-curvature="0" style="clip-rule:evenodd"></path>
    </clipPath>
  </defs>
  <sodipodi:namedview pagecolor="#ffffff" bordercolor="#666666" borderopacity="1" objecttolerance="10" gridtolerance="10" guidetolerance="10" inkscape:pageopacity="0" inkscape:pageshadow="2" inkscape:window-width="1266" inkscape:window-height="1078" id="namedview4125" showgrid="false" inkscape:zoom="1.3111111" inkscape:cx="364.35056" inkscape:cy="-64.033451" inkscape:window-x="0" inkscape:window-y="0" inkscape:window-maximized="0" inkscape:current-layer="g4121" fit-margin-top="0" fit-margin-left="0" fit-margin-right="0" fit-margin-bottom="0" viewbox-x="82" viewbox-width="650"></sodipodi:namedview>
  <clipPath id="p.0">
    <path d="M 0,0 H 960 V 720 H 0 Z" id="path4036" inkscape:connector-curvature="0" style="clip-rule:nonzero"></path>
  </clipPath>
  <g clip-path="url(#p.0)" id="g4121" transform="translate(-76.08921,-124.34908)">
    <path d="M 0,0 H 960 V 720 H 0 Z" id="path4039" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <path d="m 76.08921,124.34908 h 223.2992 V 267.11813 H 76.08921 Z" id="path4041" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <g transform="matrix(0.22307612,0,0,0.22307664,76.089214,124.34908)" id="g4048">
      <clipPath id="p.1">
        <path d="M 0,0 H 1001 V 640 H 0 Z" id="path4043" inkscape:connector-curvature="0" style="clip-rule:evenodd"></path>
      </clipPath>
      <image clip-path="url(#p.1)" width="1001" height="640" x="0" y="0" preserveAspectRatio="none" xlink:href="https://desfontain.es/privacy/images/quiestce.jpeg" id="image4046" style="fill:#000000"></image>
    </g>
    <path d="M 76.086586,339.67847 H 299.38579 V 482.44751 H 76.086586 Z" id="path4050" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <path d="m 604.81974,178.70273 v 0 c -1.51233,-10.41394 3.45307,-20.72311 12.78925,-26.55296 9.33618,-5.82984 21.40576,-6.15791 31.08722,-0.84502 v 0 c 3.42944,-6.0551 9.70636,-10.23573 16.93207,-11.27733 7.2257,-1.04159 14.55151,1.17818 19.76159,5.98789 v 0 c 2.92145,-5.48995 8.65778,-9.17848 15.1734,-9.75675 6.51569,-0.57824 12.88855,2.03563 16.85718,6.9141 v 0 c 5.27802,-5.81934 13.67554,-8.2695 21.55884,-6.29033 7.8833,1.97917 13.83649,8.03222 15.28363,15.53996 v 0 c 6.46649,1.65271 11.8529,5.85413 14.76764,11.51872 2.91473,5.66462 3.07178,12.23673 0.43066,18.01831 v 0 c 6.36756,7.76532 7.85712,18.11251 3.91272,27.18018 -3.9444,9.06767 -12.7301,15.49351 -23.07849,16.87953 -0.0729,8.51033 -5.05414,16.31931 -13.02356,20.41701 -7.96942,4.09772 -17.68268,3.84427 -25.39587,-0.66263 -3.2854,10.1926 -12.53272,17.6922 -23.74671,19.25873 -11.21405,1.56653 -22.38446,-3.08087 -28.68524,-11.93434 -7.72339,4.3639 -16.99084,5.621 -25.71185,3.48773 -8.72095,-2.13329 -16.16077,-7.47725 -20.64124,-14.8264 v 0 c -7.89233,0.86539 -15.52319,-2.96604 -19.10534,-9.59276 -3.58216,-6.62671 -2.35303,-14.63803 3.07733,-20.05798 v 0 c -7.04022,-3.8826 -10.63251,-11.58696 -8.90375,-19.09555 1.72882,-7.50861 8.38696,-13.11998 16.50256,-13.90799 z" id="path4059" inkscape:connector-curvature="0" style="fill:#f6cd4c;fill-rule:evenodd"></path>
    <path d="m 597.06497,212.10764 v 0 c 3.32227,1.83222 7.16028,2.66335 10.99872,2.38181 m 5.02759,27.2696 c 1.65063,-0.18098 3.26861,-0.56427 4.81219,-1.13993 m 41.53858,12.47812 c -1.16095,-1.63134 -2.133,-3.37456 -2.89954,-5.19996 m 55.3335,-2.12474 v 0 c 0.59893,-1.85826 0.98706,-3.77081 1.15777,-5.70575 m 37.26019,-14.04791 c 0.0776,-9.06056 -5.41461,-17.3565 -14.11767,-21.32448 m 33.2832,-22.73425 c -1.40942,3.08528 -3.56109,5.8222 -6.28625,7.99617 m -8.91071,-37.53403 v 0 c 0.24011,1.24591 0.35126,2.51055 0.33185,3.77639 m -37.17371,-13.02565 v 0 c -1.31659,1.45164 -2.4013,3.07382 -3.22033,4.81604 m -28.81055,-1.97402 v 0 c -0.70166,1.31851 -1.22559,2.71372 -1.55975,4.15347 m -35.13446,1.13608 v 0 c 2.04858,1.12421 3.94384,2.47731 5.64404,4.02959 m -49.5199,23.36855 v 0 c 0.20844,1.4353 0.53784,2.85292 0.98499,4.23957" id="path4061" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <path d="m 636.30257,211.8428 h -0.1875 q -0.78125,0 -1.25,-0.48437 -0.46875,-0.48438 -0.46875,-1.17188 0,-0.46875 0.5,-2.92187 l 1.375,-7.10938 q 0.46875,-2.42187 2.0625,-13.4375 l 0.39063,-2.70312 q 0.14062,-1.01563 1.10937,-1.84375 0.96875,-0.84375 1.78125,-0.84375 0.4375,0 2.9375,1.3125 2.70313,1.45312 3.20313,1.59375 5.09375,1.875 8.375,5.6875 3.29687,3.8125 3.29687,8.23437 0,4.04688 -2.40625,7.92188 -2.39062,3.875 -5.78125,5.71875 -3.39062,1.84375 -8.67187,1.84375 -1.53125,0 -3.46875,-0.53125 -1.9375,-0.51563 -2.79688,-1.26563 z m 6,-25.40625 -1.64062,11.20313 -2,10.67187 q 0.0625,0.0469 0.14062,0.0781 1.84375,1.32812 4.375,1.32812 5.01563,0 7.375,-1.79687 2.35938,-1.79688 3.60938,-4.21875 1.25,-2.42188 1.25,-4.92188 0,-2.51562 -1.40625,-4.64062 -1.39063,-2.125 -3.76563,-3.57813 -2.35937,-1.46875 -7.9375,-4.125 z m 32.16406,24.28125 q -4.21875,2.03125 -6.01562,2.03125 -7.29688,0 -7.29688,-6.95312 0,-6.46875 4.07813,-10.46875 4.09375,-4 8.98437,-4 1.89063,0 3.90625,0.96875 2.03125,0.96875 2.03125,2.25 0,0.79687 -0.53125,1.25 -0.39062,0.76562 -1.10937,4.40625 -0.70313,3.64062 -0.70313,5.25 0,1.96875 1.01563,5.42187 l 0.0781,0.3125 q -0.4375,1.82813 -2.17187,1.82813 -0.29688,0 -1.09375,-0.79688 -0.79688,-0.79687 -1.17188,-1.5 z m 1.42188,-15.1875 q -1.21875,-0.73437 -1.95313,-0.73437 -3.25,0 -6.07812,2.95312 -2.82813,2.9375 -2.82813,7.3125 0,4.29688 3.71875,4.29688 2.90625,0 5.46875,-2.15625 0.3125,-8.1875 1.67188,-11.67188 z m 16.45312,-0.34375 q -0.23437,0.9375 -0.60937,2.1875 -1.64063,5.42188 -1.64063,8.26563 0,3.35937 1.5625,3.35937 1.54688,0 2.28125,-0.95312 1.01563,-1.32813 1.875,-1.32813 0.65625,0 1.25,0.48438 0.59375,0.48437 0.59375,1.26562 0,1.71875 -2.15625,2.95313 -2.15625,1.21875 -4.29687,1.21875 -5.03125,0 -5.03125,-6.28125 0,-3.4375 1.54687,-8.39063 0.40625,-1.3125 0.78125,-2.625 -4.25,-0.20312 -4.85937,-0.70312 -0.60938,-0.5 -0.60938,-1.5625 0,-0.85938 0.57813,-1.42188 0.59375,-0.57812 1.60937,-0.57812 l 4.03125,0.32812 q 0.125,-0.51562 0.1875,-1.17187 0.0312,-0.67188 0.125,-1.48438 l 0.34375,-2.42187 q 0.10938,-0.79688 0.71875,-1.34375 0.625,-0.54688 1.46875,-0.54688 1.64063,0 1.64063,2.625 0,0.76563 -0.23438,1.98438 l -0.39062,2.35937 q 2.60937,-0.32812 2.78125,-0.32812 2.03125,0 2.79687,0.40625 0.76563,0.39062 0.76563,1.46875 0,0.95312 -0.65625,1.54687 -0.65625,0.57813 -1.57813,0.57813 l -1.92187,-0.0781 q -1.45313,0 -2.95313,0.1875 z m 21.44141,15.53125 q -4.21875,2.03125 -6.01563,2.03125 -7.29687,0 -7.29687,-6.95312 0,-6.46875 4.07812,-10.46875 4.09375,-4 8.98438,-4 1.89062,0 3.90625,0.96875 2.03125,0.96875 2.03125,2.25 0,0.79687 -0.53125,1.25 -0.39063,0.76562 -1.10938,4.40625 -0.70312,3.64062 -0.70312,5.25 0,1.96875 1.01562,5.42187 l 0.0781,0.3125 q -0.4375,1.82813 -2.17188,1.82813 -0.29687,0 -1.09375,-0.79688 -0.79687,-0.79687 -1.17187,-1.5 z m 1.42187,-15.1875 q -1.21875,-0.73437 -1.95312,-0.73437 -3.25,0 -6.07813,2.95312 -2.82812,2.9375 -2.82812,7.3125 0,4.29688 3.71875,4.29688 2.90625,0 5.46875,-2.15625 0.3125,-8.1875 1.67187,-11.67188 z" id="path4063" inkscape:connector-curvature="0" style="fill:#000000;fill-rule:nonzero"></path>
    <path d="m 597.06237,427.43705 v 0 c 3.32227,1.83218 7.16028,2.66333 10.99872,2.38181 m 5.02759,27.26959 c 1.65063,-0.181 3.26861,-0.56427 4.81219,-1.13992 m 41.53858,12.47811 c -1.16095,-1.63134 -2.133,-3.37457 -2.89954,-5.19998 m 55.3335,-2.12472 v 0 c 0.59893,-1.85825 0.98706,-3.77082 1.15777,-5.70575 m 37.26019,-14.04792 c 0.0776,-9.06054 -5.41461,-17.3565 -14.11767,-21.32449 m 33.2832,-22.73425 c -1.40942,3.0853 -3.56109,5.82223 -6.28625,7.99618 m -8.91071,-37.53402 v 0 c 0.24011,1.24591 0.35126,2.51056 0.33185,3.77639 m -37.17371,-13.02566 v 0 c -1.31659,1.45163 -2.4013,3.07382 -3.22033,4.81604 m -28.81055,-1.974 v 0 c -0.70166,1.31848 -1.22559,2.71372 -1.55975,4.15347 m -35.13446,1.13608 v 0 c 2.04858,1.12421 3.94384,2.4773 5.64404,4.02957 m -49.5199,23.36856 v 0 c 0.20844,1.43531 0.53784,2.85291 0.98499,4.23957" id="path4067" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <path d="m 299.38846,189.04987 h 70.36065 v -6.68504 l 8.40525,13.37008 -8.40525,13.37007 v -6.68502 h -70.36065 z" id="path4071" inkscape:connector-curvature="0" style="fill:#7c7ce0;fill-rule:evenodd;stroke-width:0.79288208"></path>
    <path d="M 427.88773,353.66272 H 553.16596 V 468.46329 H 427.88773 Z" id="path4075" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <path d="M 427.809,138.3307 H 553.08723 V 253.13125 H 427.809 Z" id="path4100" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <path d="M 379.751,138.43701 H 505.04235 V 253.24016 H 379.751 Z" id="path4109" inkscape:connector-curvature="0" style="fill:#00fdc8;fill-rule:evenodd"></path>
    <path d="M 379.751,138.43701 H 505.04235 V 253.24016 H 379.751 Z" id="path4111" inkscape:connector-curvature="0" style="fill-rule:evenodd;stroke:#666666;stroke-width:1;stroke-linecap:butt;stroke-linejoin:round"></path>
    <path d="m 506.71874,190.09462 h 70.36065 v -6.68504 l 8.40525,13.37008 -8.40525,13.37007 v -6.68502 h -70.36065 z" id="path4071-6" inkscape:connector-curvature="0" style="fill:#7c7ce0;fill-rule:evenodd;stroke-width:0.79288208"></path>
    <g aria-label="Some process" style="font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:26.66666603px;line-height:1.25;font-family:'Comic Sans MS';-inkscape-font-specification:'Comic Sans MS';text-align:center;letter-spacing:0px;word-spacing:0px;text-anchor:middle;fill:#000000;fill-opacity:1;stroke:none" id="flowRoot4272">
      <path d="m 409.86816,182.0918 q -0.013,-0.54687 0.36459,-0.88542 0.39062,-0.35156 0.95052,-0.35156 0.63802,0 1.11979,0.72917 0.66406,0.98958 1.1849,1.34114 1.10677,0.72917 3.21614,0.72917 2.01823,0 3.75,-0.8724 2.21354,-1.11979 2.21354,-3.11197 0,-1.64063 -1.86198,-2.59115 -1.57552,-0.82031 -3.89322,-0.88542 -2.0573,-0.0781 -3.50261,-0.89843 -1.84896,-1.05469 -1.84896,-3.02084 0,-2.31771 2.63021,-4.23177 2.51302,-1.80989 5.19531,-1.80989 1.26302,0 2.85157,0.42968 2.10937,0.5599 2.10937,1.4323 0,1.14583 -1.17187,1.14583 -0.52084,0 -1.82292,-0.27344 -1.30208,-0.28646 -2.01823,-0.27344 -2.03125,0.026 -3.45052,1.00261 -1.45833,1.0026 -1.45833,2.43489 0,1.08073 1.92708,1.52344 0.71615,0.16927 2.77344,0.3125 2.98177,0.22136 4.66146,1.875 1.53645,1.51042 1.53645,3.6849 0,3.09895 -2.86458,4.94791 -2.48698,1.60157 -5.76823,1.60157 -2.38281,0 -4.36198,-0.91146 -2.42187,-1.11979 -2.46094,-3.07292 z" style="" id="path4896"></path>
      <path d="m 433.30566,186.10222 q -2.1875,0 -3.76302,-1.61459 -1.75781,-1.79687 -1.84896,-4.83072 -0.0781,-2.94271 1.48438,-5.1823 1.82292,-2.64323 5.07812,-2.64323 2.60417,0 3.94532,2.38282 1.0677,1.92708 1.02864,4.63541 -0.0391,2.89063 -1.51041,4.9349 -1.66667,2.31771 -4.41407,2.31771 z m 0.78125,-11.62761 q -1.91406,-0.013 -2.98177,1.82292 -0.84635,1.47135 -0.84635,3.35938 0,1.88802 1.02864,2.9427 0.85938,0.8724 2.01823,0.8724 1.35417,0 2.33073,-0.98958 1.10677,-1.09375 1.17188,-2.95573 0.18229,-5.03907 -2.72136,-5.05209 z" style="" id="path4898"></path>
      <path d="m 458.96973,186.41472 q -1.06771,0 -1.25,-1.13282 -0.23438,-1.43229 -0.46875,-4.03645 l -0.44271,-4.03646 q -0.13021,-0.89844 -0.44271,-1.75781 -0.44271,-1.17188 -0.96354,-1.17188 -0.48177,0 -1.79688,0.82031 -1.25,0.75521 -1.64062,1.21094 -0.013,1.22396 0.0651,2.44792 l 0.39063,3.47656 q 0.24739,2.05729 0.24739,3.39844 0,0.57291 -0.36458,0.9375 -0.35156,0.3776 -0.91146,0.3776 -0.55989,0 -0.92448,-0.3776 -0.35156,-0.36459 -0.35156,-0.9375 0,-1.57552 -0.32552,-4.64844 -0.3125,-3.08594 -0.3125,-4.66146 0,-1.38021 -0.39063,-2.14844 -0.91145,0.41667 -1.84895,1.35417 l -1.53646,1.71875 q -0.20834,0.3125 -0.66406,0.82031 0,0.78125 -0.14323,2.30469 -0.14323,1.52344 -0.14323,2.2526 0,0.39063 0.11718,1.09375 0.13021,0.70313 0.13021,1.01563 0,0.53385 -0.40364,0.89844 -0.39063,0.36458 -0.92448,0.36458 -1.47136,0 -1.47136,-3.34635 0,-0.78125 0.14323,-2.33073 0.14323,-1.54948 0.14323,-2.33073 0,-0.69011 -0.13021,-2.07031 -0.11718,-1.38021 -0.11718,-2.08334 0,-2.95573 1.32812,-2.95573 0.50781,0 0.92448,0.44271 0.42969,0.44271 0.42969,0.96354 0,0.2474 -0.0651,0.76823 -0.0651,0.52084 -0.0651,0.79427 l 0.026,1.36719 q 0.67708,-1.39323 1.99219,-2.51302 1.3151,-1.13281 2.23958,-1.13281 2.04427,0 2.8125,2.03125 0.71615,-0.95052 1.70573,-1.41927 0.98958,-0.48177 2.26563,-0.48177 2.17448,0 2.96875,2.34375 0.15625,0.46875 0.53385,3.65885 0.36458,2.23958 0.9375,7.46094 0.0391,0.52083 -0.35156,0.88541 -0.39063,0.36459 -0.95052,0.36459 z" style="" id="path4900"></path>
      <path d="m 469.24316,185.93295 q -2.94271,0 -4.76562,-1.47136 -1.99219,-1.6276 -1.99219,-4.55729 0,-3.38542 1.64062,-5.67708 1.78386,-2.5 4.76563,-2.5 2.16146,0 3.52865,0.72916 1.67968,0.89844 1.67968,2.76042 0,1.30208 -1.47135,2.36979 -0.65104,0.46875 -2.76042,1.45834 l -4.97396,2.35677 q 0.72917,1.08073 1.8099,1.6276 1.09375,0.54688 2.53906,0.54688 0.89844,0 2.10938,-0.33855 1.53646,-0.42968 1.97916,-1.11979 0.44271,-0.70312 0.95052,-0.70312 0.45573,0 0.8073,0.35156 0.36458,0.33854 0.36458,0.79427 0,1.44531 -2.33073,2.48698 -1.99219,0.88542 -3.88021,0.88542 z m -0.35156,-11.86198 q -1.58854,0 -2.64323,1.23698 -1.05469,1.22396 -1.57552,3.69791 l 3.9974,-1.90104 q 2.35677,-1.14583 3.35937,-1.99219 -1.11979,-1.04166 -3.13802,-1.04166 z" style="" id="path4902"></path>
      <path d="m 401.71712,219.12305 q -1.30208,0 -2.86458,-0.41667 l -0.026,6.22396 q 0,0.57291 -0.36458,0.9375 -0.35157,0.36458 -0.91146,0.36458 -0.5599,0 -0.92448,-0.36458 -0.35156,-0.36459 -0.35156,-0.9375 l 0.0391,-5.20834 v -5.19531 q -0.0391,-2.85156 -0.19531,-5.19531 l -0.19532,-2.64323 q 0,-0.92448 0.33854,-1.5625 0.39063,-0.76823 1.13282,-0.76823 0.50781,0 0.84635,0.36458 0.35156,0.35157 0.35156,0.8724 0,0.11719 -0.0391,0.42969 -0.0651,0.40364 -0.0911,0.74219 1.11979,-0.76823 2.16145,-1.14584 1.04167,-0.39062 1.99219,-0.39062 2.66927,0 3.90625,2.36979 0.97656,1.875 0.97656,4.96094 0,2.8125 -1.51041,4.63541 -1.60157,1.92709 -4.27084,1.92709 z m 0.89844,-11.28907 q -1.19792,0 -2.16146,0.53386 -0.6901,0.3776 -1.74479,1.38021 0.16927,2.95572 0.16927,6.21093 1.41927,0.54688 2.83854,0.54688 1.62761,0 2.48698,-1.21094 0.74219,-1.05469 0.74219,-2.73437 0,-2.3698 -0.58594,-3.54167 -0.57291,-1.1849 -1.74479,-1.1849 z" style="" id="path4904"></path>
      <path d="m 420.58431,209.04492 q -0.0912,1.6276 -1.30208,1.6276 -1.11979,0 -1.11979,-1.28906 0,-0.24739 -0.0391,-0.91146 l -0.0391,-1.09375 q -2.05729,0.2474 -3.29427,1.15886 -1.15885,0.84635 -1.92708,2.55208 l 0.026,7.13542 q 0,1.3151 -1.28906,1.3151 -1.14584,0 -1.14584,-1.3151 v -9.14063 q 0,-0.42968 0.026,-1.28906 0.0391,-0.85937 0.0391,-1.28906 0,-1.31511 1.14583,-1.31511 1.27604,0 1.28906,2.16146 2.5,-2.40885 5.54688,-2.40885 1.05468,0 1.57552,0.79427 0.52083,0.79427 0.52083,2.39583 0,0.67709 -0.013,0.91146 z" style="" id="path4906"></path>
      <path d="m 428.14941,219.43555 q -2.1875,0 -3.76302,-1.61459 -1.75781,-1.79687 -1.84896,-4.83073 -0.0781,-2.94271 1.48438,-5.18229 1.82292,-2.64323 5.07812,-2.64323 2.60417,0 3.94532,2.38282 1.06771,1.92708 1.02864,4.63541 -0.0391,2.89063 -1.51041,4.9349 -1.66667,2.31771 -4.41407,2.31771 z m 0.78125,-11.62761 q -1.91406,-0.013 -2.98177,1.82292 -0.84635,1.47135 -0.84635,3.35937 0,1.88802 1.02864,2.94271 0.85938,0.8724 2.01823,0.8724 1.35417,0 2.33073,-0.98959 1.10677,-1.09375 1.17188,-2.95573 0.18229,-5.03906 -2.72136,-5.05208 z" style="" id="path4908"></path>
      <path d="m 443.16244,219.48763 q -2.66927,0 -4.45313,-1.61458 -1.875,-1.69271 -1.875,-4.46615 0,-2.64323 1.75781,-5.45573 1.95313,-3.125 4.40105,-3.125 1.27604,0 2.85156,0.59896 1.99218,0.76823 1.99218,1.875 0,0.49479 -0.32552,0.88542 -0.32552,0.3776 -0.80729,0.3776 -0.3776,0 -0.66406,-0.22135 -0.27344,-0.23438 -0.53385,-0.45573 -0.76823,-0.61198 -2.51302,-0.61198 -1.32813,0 -2.63021,2.36979 -1.1849,2.17448 -1.1849,3.76302 0,1.71875 1.17188,2.70833 1.09375,0.92448 2.8125,0.92448 0.78125,0 1.66666,-0.41666 l 1.51042,-0.8073 q 0.39062,-0.20833 0.55989,-0.20833 0.48178,0 0.83334,0.39063 0.35156,0.3776 0.35156,0.87239 0,0.95052 -2.00521,1.83594 -1.75781,0.78125 -2.91666,0.78125 z" style="" id="path4910"></path>
      <path d="m 457.05566,219.26627 q -2.94271,0 -4.76562,-1.47135 -1.99219,-1.6276 -1.99219,-4.55729 0,-3.38542 1.64063,-5.67708 1.78385,-2.5 4.76562,-2.5 2.16146,0 3.52865,0.72916 1.67968,0.89844 1.67968,2.76042 0,1.30208 -1.47135,2.36979 -0.65104,0.46875 -2.76042,1.45833 l -4.97396,2.35677 q 0.72917,1.08073 1.8099,1.62761 1.09375,0.54687 2.53906,0.54687 0.89844,0 2.10938,-0.33854 1.53646,-0.42969 1.97916,-1.11979 0.44271,-0.70312 0.95052,-0.70312 0.45573,0 0.8073,0.35156 0.36458,0.33854 0.36458,0.79427 0,1.44531 -2.33073,2.48698 -1.99219,0.88541 -3.88021,0.88541 z M 456.7041,207.4043 q -1.58854,0 -2.64323,1.23698 -1.05469,1.22395 -1.57552,3.69791 l 3.9974,-1.90104 q 2.35677,-1.14583 3.35937,-1.99219 -1.11979,-1.04166 -3.13802,-1.04166 z" style="" id="path4912"></path>
      <path d="m 474.39941,208.64128 q -0.71615,0 -1.0026,-0.48178 -0.19532,-0.33854 -0.33855,-1.40625 -0.97656,0.2474 -3.00781,0.91146 -2.09635,0.83334 -2.10937,2.05729 0.39062,0.14323 0.76823,0.20834 2.99479,0.53385 4.45312,1.47135 2.1224,1.36719 2.1224,3.95833 0,2.1224 -1.83594,3.20313 -1.52344,0.88542 -3.85417,0.88542 -1.70573,0 -3.25521,-0.57292 -2.0052,-0.72917 -2.0052,-2.03125 0,-0.52083 0.40364,-0.91146 0.41667,-0.39062 0.9375,-0.39062 0.40365,0 1.04167,0.625 0.3125,0.29948 1.40625,0.49479 0.87239,0.15625 1.47135,0.15625 1.09375,0 1.92709,-0.26042 1.21093,-0.3776 1.21093,-1.19792 0,-1.77083 -2.47396,-2.39583 l -1.35416,-0.29948 q -1.73177,-0.3776 -2.46094,-0.88541 -1.05469,-0.72917 -1.05469,-2.20053 0,-2.72135 2.56511,-3.8802 0.78125,-0.35157 2.5,-0.83334 1.71875,-0.49479 2.46093,-0.83333 0.53386,-0.23437 1.15886,-0.23437 0.55989,0 0.91146,0.36458 0.36458,0.36458 0.36458,0.95052 0,0.3776 0.15625,1.10677 0.16927,0.72917 0.16927,1.10677 0,0.58594 -0.36458,0.95052 -0.35156,0.36459 -0.91146,0.36459 z" style="" id="path4914"></path>
      <path d="m 487.36816,208.64128 q -0.71615,0 -1.0026,-0.48178 -0.19532,-0.33854 -0.33855,-1.40625 -0.97656,0.2474 -3.00781,0.91146 -2.09635,0.83334 -2.10937,2.05729 0.39062,0.14323 0.76823,0.20834 2.99479,0.53385 4.45312,1.47135 2.1224,1.36719 2.1224,3.95833 0,2.1224 -1.83594,3.20313 -1.52344,0.88542 -3.85417,0.88542 -1.70573,0 -3.25521,-0.57292 -2.0052,-0.72917 -2.0052,-2.03125 0,-0.52083 0.40364,-0.91146 0.41667,-0.39062 0.9375,-0.39062 0.40365,0 1.04167,0.625 0.3125,0.29948 1.40625,0.49479 0.87239,0.15625 1.47135,0.15625 1.09375,0 1.92709,-0.26042 1.21093,-0.3776 1.21093,-1.19792 0,-1.77083 -2.47396,-2.39583 l -1.35416,-0.29948 q -1.73177,-0.3776 -2.46094,-0.88541 -1.05469,-0.72917 -1.05469,-2.20053 0,-2.72135 2.56511,-3.8802 0.78125,-0.35157 2.5,-0.83334 1.71875,-0.49479 2.46093,-0.83333 0.53386,-0.23437 1.15886,-0.23437 0.55989,0 0.91146,0.36458 0.36458,0.36458 0.36458,0.95052 0,0.3776 0.15625,1.10677 0.16927,0.72917 0.16927,1.10677 0,0.58594 -0.36458,0.95052 -0.35156,0.36459 -0.91146,0.36459 z" style="" id="path4916"></path>
    </g>
    <rect style="fill:#ffffff" id="rect148" width="28.983051" height="45.762711" x="212.03391" y="388.22034"></rect>
  </g>
</svg>
</center>
<p>This process can be <em>anything</em>. For example, it can be:</p>
<ul>
<li>computing some statistic ("tell me how many users have red hair")</li>
<li>an anonymization strategy ("remove names and last three digits of ZIP codes")</li>
<li>a machine learning training process ("build a model to predict which users
  like cats")</li>
<li>… you get the idea.</li>
</ul>
<p>To make a process differentially private, you usually have to modify it a little
bit. Typically, you add some randomness, or <em>noise</em>, in some places. What
exactly you do, and how much noise you add, depends on which process you're
modifying. I'll abstract that part away and simply say that your process is now
doing some unspecified ✨&nbsp;magic&nbsp;✨.</p>
<center>
<svg role="img" aria-label="Same diagram as before, except the arrow is labeled with a silly &quot;magic&quot; gif." xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:svg="http://www.w3.org/2000/svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape" version="1.1" viewBox="0 0 699.45947 142.76904" stroke-miterlimit="10" id="svg4123" sodipodi:docname="magic.svg" inkscape:version="0.92.3 (2405546, 2018-03-11)" width="699.45947" height="142.76904" style="fill:none;stroke:none;stroke-linecap:square;stroke-miterlimit:10">
  <title>Same diagram as before, except the arrow is labeled with a silly "magic" gif.</title>
  <desc>Same diagram as before, except the arrow is labeled with a silly "magic" gif.</desc>
  <metadata id="metadata4129">
    <rdf:rdf>
      <cc:work rdf:about="">
        <dc:format>image/svg+xml</dc:format>
        <dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"></dc:type>
        <dc:title></dc:title>
      </cc:work>
    </rdf:rdf>
  </metadata>
  <defs id="defs4127">
    <clipPath id="p.3-4">
      <path d="M 0,0 H 275 V 252 H 0 Z" id="path4077-0" inkscape:connector-curvature="0" style="clip-rule:evenodd"></path>
    </clipPath>
  </defs>
  <sodipodi:namedview pagecolor="#ffffff" bordercolor="#666666" borderopacity="1" objecttolerance="10" gridtolerance="10" guidetolerance="10" inkscape:pageopacity="0" inkscape:pageshadow="2" inkscape:window-width="2556" inkscape:window-height="1436" id="namedview4125" showgrid="false" inkscape:zoom="1.3111111" inkscape:cx="608.41836" inkscape:cy="-64.033451" inkscape:window-x="0" inkscape:window-y="1200" inkscape:window-maximized="0" inkscape:current-layer="g4121" fit-margin-top="0" fit-margin-left="0" fit-margin-right="0" fit-margin-bottom="0" viewbox-x="82" viewbox-width="650"></sodipodi:namedview>
  <clipPath id="p.0">
    <path d="M 0,0 H 960 V 720 H 0 Z" id="path4036" inkscape:connector-curvature="0" style="clip-rule:nonzero"></path>
  </clipPath>
  <g clip-path="url(#p.0)" id="g4121" transform="translate(-76.08921,-124.34908)">
    <path d="M 0,0 H 960 V 720 H 0 Z" id="path4039" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <path d="m 76.08921,124.34908 h 223.2992 V 267.11813 H 76.08921 Z" id="path4041" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <g transform="matrix(0.22307612,0,0,0.22307664,76.089214,124.34908)" id="g4048">
      <clipPath id="p.1">
        <path d="M 0,0 H 1001 V 640 H 0 Z" id="path4043" inkscape:connector-curvature="0" style="clip-rule:evenodd"></path>
      </clipPath>
      <image clip-path="url(#p.1)" width="1001" height="640" x="0" y="0" preserveAspectRatio="none" xlink:href="https://desfontain.es/privacy/images/quiestce.jpeg" id="image4046" style="fill:#000000"></image>
    </g>
    <path d="M 76.086586,339.67847 H 299.38579 V 482.44751 H 76.086586 Z" id="path4050" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <path d="m 604.81974,178.70273 v 0 c -1.51233,-10.41394 3.45307,-20.72311 12.78925,-26.55296 9.33618,-5.82984 21.40576,-6.15791 31.08722,-0.84502 v 0 c 3.42944,-6.0551 9.70636,-10.23573 16.93207,-11.27733 7.2257,-1.04159 14.55151,1.17818 19.76159,5.98789 v 0 c 2.92145,-5.48995 8.65778,-9.17848 15.1734,-9.75675 6.51569,-0.57824 12.88855,2.03563 16.85718,6.9141 v 0 c 5.27802,-5.81934 13.67554,-8.2695 21.55884,-6.29033 7.8833,1.97917 13.83649,8.03222 15.28363,15.53996 v 0 c 6.46649,1.65271 11.8529,5.85413 14.76764,11.51872 2.91473,5.66462 3.07178,12.23673 0.43066,18.01831 v 0 c 6.36756,7.76532 7.85712,18.11251 3.91272,27.18018 -3.9444,9.06767 -12.7301,15.49351 -23.07849,16.87953 -0.0729,8.51033 -5.05414,16.31931 -13.02356,20.41701 -7.96942,4.09772 -17.68268,3.84427 -25.39587,-0.66263 -3.2854,10.1926 -12.53272,17.6922 -23.74671,19.25873 -11.21405,1.56653 -22.38446,-3.08087 -28.68524,-11.93434 -7.72339,4.3639 -16.99084,5.621 -25.71185,3.48773 -8.72095,-2.13329 -16.16077,-7.47725 -20.64124,-14.8264 v 0 c -7.89233,0.86539 -15.52319,-2.96604 -19.10534,-9.59276 -3.58216,-6.62671 -2.35303,-14.63803 3.07733,-20.05798 v 0 c -7.04022,-3.8826 -10.63251,-11.58696 -8.90375,-19.09555 1.72882,-7.50861 8.38696,-13.11998 16.50256,-13.90799 z" id="path4059" inkscape:connector-curvature="0" style="fill:#f6cd4c;fill-rule:evenodd"></path>
    <path d="m 597.06497,212.10764 v 0 c 3.32227,1.83222 7.16028,2.66335 10.99872,2.38181 m 5.02759,27.2696 c 1.65063,-0.18098 3.26861,-0.56427 4.81219,-1.13993 m 41.53858,12.47812 c -1.16095,-1.63134 -2.133,-3.37456 -2.89954,-5.19996 m 55.3335,-2.12474 v 0 c 0.59893,-1.85826 0.98706,-3.77081 1.15777,-5.70575 m 37.26019,-14.04791 c 0.0776,-9.06056 -5.41461,-17.3565 -14.11767,-21.32448 m 33.2832,-22.73425 c -1.40942,3.08528 -3.56109,5.8222 -6.28625,7.99617 m -8.91071,-37.53403 v 0 c 0.24011,1.24591 0.35126,2.51055 0.33185,3.77639 m -37.17371,-13.02565 v 0 c -1.31659,1.45164 -2.4013,3.07382 -3.22033,4.81604 m -28.81055,-1.97402 v 0 c -0.70166,1.31851 -1.22559,2.71372 -1.55975,4.15347 m -35.13446,1.13608 v 0 c 2.04858,1.12421 3.94384,2.47731 5.64404,4.02959 m -49.5199,23.36855 v 0 c 0.20844,1.4353 0.53784,2.85292 0.98499,4.23957" id="path4061" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <path d="m 636.30257,211.8428 h -0.1875 q -0.78125,0 -1.25,-0.48437 -0.46875,-0.48438 -0.46875,-1.17188 0,-0.46875 0.5,-2.92187 l 1.375,-7.10938 q 0.46875,-2.42187 2.0625,-13.4375 l 0.39063,-2.70312 q 0.14062,-1.01563 1.10937,-1.84375 0.96875,-0.84375 1.78125,-0.84375 0.4375,0 2.9375,1.3125 2.70313,1.45312 3.20313,1.59375 5.09375,1.875 8.375,5.6875 3.29687,3.8125 3.29687,8.23437 0,4.04688 -2.40625,7.92188 -2.39062,3.875 -5.78125,5.71875 -3.39062,1.84375 -8.67187,1.84375 -1.53125,0 -3.46875,-0.53125 -1.9375,-0.51563 -2.79688,-1.26563 z m 6,-25.40625 -1.64062,11.20313 -2,10.67187 q 0.0625,0.0469 0.14062,0.0781 1.84375,1.32812 4.375,1.32812 5.01563,0 7.375,-1.79687 2.35938,-1.79688 3.60938,-4.21875 1.25,-2.42188 1.25,-4.92188 0,-2.51562 -1.40625,-4.64062 -1.39063,-2.125 -3.76563,-3.57813 -2.35937,-1.46875 -7.9375,-4.125 z m 32.16406,24.28125 q -4.21875,2.03125 -6.01562,2.03125 -7.29688,0 -7.29688,-6.95312 0,-6.46875 4.07813,-10.46875 4.09375,-4 8.98437,-4 1.89063,0 3.90625,0.96875 2.03125,0.96875 2.03125,2.25 0,0.79687 -0.53125,1.25 -0.39062,0.76562 -1.10937,4.40625 -0.70313,3.64062 -0.70313,5.25 0,1.96875 1.01563,5.42187 l 0.0781,0.3125 q -0.4375,1.82813 -2.17187,1.82813 -0.29688,0 -1.09375,-0.79688 -0.79688,-0.79687 -1.17188,-1.5 z m 1.42188,-15.1875 q -1.21875,-0.73437 -1.95313,-0.73437 -3.25,0 -6.07812,2.95312 -2.82813,2.9375 -2.82813,7.3125 0,4.29688 3.71875,4.29688 2.90625,0 5.46875,-2.15625 0.3125,-8.1875 1.67188,-11.67188 z m 16.45312,-0.34375 q -0.23437,0.9375 -0.60937,2.1875 -1.64063,5.42188 -1.64063,8.26563 0,3.35937 1.5625,3.35937 1.54688,0 2.28125,-0.95312 1.01563,-1.32813 1.875,-1.32813 0.65625,0 1.25,0.48438 0.59375,0.48437 0.59375,1.26562 0,1.71875 -2.15625,2.95313 -2.15625,1.21875 -4.29687,1.21875 -5.03125,0 -5.03125,-6.28125 0,-3.4375 1.54687,-8.39063 0.40625,-1.3125 0.78125,-2.625 -4.25,-0.20312 -4.85937,-0.70312 -0.60938,-0.5 -0.60938,-1.5625 0,-0.85938 0.57813,-1.42188 0.59375,-0.57812 1.60937,-0.57812 l 4.03125,0.32812 q 0.125,-0.51562 0.1875,-1.17187 0.0312,-0.67188 0.125,-1.48438 l 0.34375,-2.42187 q 0.10938,-0.79688 0.71875,-1.34375 0.625,-0.54688 1.46875,-0.54688 1.64063,0 1.64063,2.625 0,0.76563 -0.23438,1.98438 l -0.39062,2.35937 q 2.60937,-0.32812 2.78125,-0.32812 2.03125,0 2.79687,0.40625 0.76563,0.39062 0.76563,1.46875 0,0.95312 -0.65625,1.54687 -0.65625,0.57813 -1.57813,0.57813 l -1.92187,-0.0781 q -1.45313,0 -2.95313,0.1875 z m 21.44141,15.53125 q -4.21875,2.03125 -6.01563,2.03125 -7.29687,0 -7.29687,-6.95312 0,-6.46875 4.07812,-10.46875 4.09375,-4 8.98438,-4 1.89062,0 3.90625,0.96875 2.03125,0.96875 2.03125,2.25 0,0.79687 -0.53125,1.25 -0.39063,0.76562 -1.10938,4.40625 -0.70312,3.64062 -0.70312,5.25 0,1.96875 1.01562,5.42187 l 0.0781,0.3125 q -0.4375,1.82813 -2.17188,1.82813 -0.29687,0 -1.09375,-0.79688 -0.79687,-0.79687 -1.17187,-1.5 z m 1.42187,-15.1875 q -1.21875,-0.73437 -1.95312,-0.73437 -3.25,0 -6.07813,2.95312 -2.82812,2.9375 -2.82812,7.3125 0,4.29688 3.71875,4.29688 2.90625,0 5.46875,-2.15625 0.3125,-8.1875 1.67187,-11.67188 z" id="path4063" inkscape:connector-curvature="0" style="fill:#000000;fill-rule:nonzero"></path>
    <path d="m 597.06237,427.43705 v 0 c 3.32227,1.83218 7.16028,2.66333 10.99872,2.38181 m 5.02759,27.26959 c 1.65063,-0.181 3.26861,-0.56427 4.81219,-1.13992 m 41.53858,12.47811 c -1.16095,-1.63134 -2.133,-3.37457 -2.89954,-5.19998 m 55.3335,-2.12472 v 0 c 0.59893,-1.85825 0.98706,-3.77082 1.15777,-5.70575 m 37.26019,-14.04792 c 0.0776,-9.06054 -5.41461,-17.3565 -14.11767,-21.32449 m 33.2832,-22.73425 c -1.40942,3.0853 -3.56109,5.82223 -6.28625,7.99618 m -8.91071,-37.53402 v 0 c 0.24011,1.24591 0.35126,2.51056 0.33185,3.77639 m -37.17371,-13.02566 v 0 c -1.31659,1.45163 -2.4013,3.07382 -3.22033,4.81604 m -28.81055,-1.974 v 0 c -0.70166,1.31848 -1.22559,2.71372 -1.55975,4.15347 m -35.13446,1.13608 v 0 c 2.04858,1.12421 3.94384,2.4773 5.64404,4.02957 m -49.5199,23.36856 v 0 c 0.20844,1.43531 0.53784,2.85291 0.98499,4.23957" id="path4067" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <path d="m 299.38846,189.04987 h 70.36065 v -6.68504 l 8.40525,13.37008 -8.40525,13.37007 v -6.68502 h -70.36065 z" id="path4071" inkscape:connector-curvature="0" style="fill:#7c7ce0;fill-rule:evenodd;stroke-width:0.79288208"></path>
    <path d="M 427.88773,353.66272 H 553.16596 V 468.46329 H 427.88773 Z" id="path4075" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <path d="M 427.809,138.3307 H 553.08723 V 253.13125 H 427.809 Z" id="path4100" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <path d="M 379.751,138.43701 H 505.04235 V 253.24016 H 379.751 Z" id="path4109" inkscape:connector-curvature="0" style="fill:#00fdc8;fill-rule:evenodd"></path>
    <path d="M 379.751,138.43701 H 505.04235 V 253.24016 H 379.751 Z" id="path4111" inkscape:connector-curvature="0" style="fill-rule:evenodd;stroke:#666666;stroke-width:1;stroke-linecap:butt;stroke-linejoin:round"></path>
    <path d="m 506.71874,190.09462 h 70.36065 v -6.68504 l 8.40525,13.37008 -8.40525,13.37007 v -6.68502 h -70.36065 z" id="path4071-6" inkscape:connector-curvature="0" style="fill:#7c7ce0;fill-rule:evenodd;stroke-width:0.79288208"></path>
    <flowroot xml:space="preserve" id="flowRoot4272" style="font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:26.66666603px;line-height:1.25;font-family:'Comic Sans MS';-inkscape-font-specification:'Comic Sans MS';text-align:center;letter-spacing:0px;word-spacing:0px;text-anchor:middle;fill:#000000;fill-opacity:1;stroke:none"><flowregion id="flowRegion4274" style="font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:26.66666603px;font-family:'Comic Sans MS';-inkscape-font-specification:'Comic Sans MS';text-align:center;text-anchor:middle"><rect id="rect4276" width="125.97456" height="90.782555" x="379.06781" y="162.45763" style="font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:26.66666603px;font-family:'Comic Sans MS';-inkscape-font-specification:'Comic Sans MS';text-align:center;text-anchor:middle"></rect></flowregion><flowpara id="flowPara4278">Some process</flowpara></flowroot>    <g transform="matrix(0.45555722,0,0,0.45555774,379.751,138.43701)" id="g4082-1" inkscape:transform-center-x="-34.322034" inkscape:transform-center-y="102.9661">
      <clipPath id="clipPath4292">
        <path d="M 0,0 H 275 V 252 H 0 Z" id="path4290" inkscape:connector-curvature="0" style="clip-rule:evenodd"></path>
      </clipPath>
      <image clip-path="url(#p.3-4)" width="275" height="252" x="0" y="0" preserveAspectRatio="none" xlink:href="https://desfontain.es/privacy/images/magic.gif" id="image4080-3" style="fill:#000000"></image>
    </g>
    <rect style="fill:#ffffff" id="rect148" width="28.983051" height="45.762711" x="212.03391" y="388.22034"></rect>
  </g>
</svg>
</center>
<p>Now, remove somebody from your database, and run your new process on it. If the
new process is differentially private, then the two outputs are <em>basically the
same</em>. This must be true no matter who you remove, and what database you had in
the first place.</p>
<center>
<svg role="img" aria-label="Same diagram as before, duplicated, with the bottom line missing one person in the database. A double arrow labeled &quot;basically the same&quot; points to the two outputs." xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:svg="http://www.w3.org/2000/svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape" version="1.1" viewBox="0 0 734.41882 358.09845" stroke-miterlimit="10" id="svg4123" sodipodi:docname="full-diagram.svg" inkscape:version="0.92.2pre0 (973e216, 2017-07-25)" width="734.41882" height="358.09845" style="fill:none;stroke:none;stroke-linecap:square;stroke-miterlimit:10">
  <title>Same diagram as before, duplicated, with the bottom line missing one person in the database. A double arrow labeled "basically the same" points to the two outputs.</title>
  <desc>Same diagram as before, duplicated, with the bottom line missing one person in the database. A double arrow labeled "basically the same" points to the two outputs.</desc>
  <metadata id="metadata4129">
    <rdf:rdf>
      <cc:work rdf:about="">
        <dc:format>image/svg+xml</dc:format>
        <dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"></dc:type>
        <dc:title></dc:title>
      </cc:work>
    </rdf:rdf>
  </metadata>
  <defs id="defs4127">
    <clipPath id="p.3-4">
      <path d="M 0,0 H 275 V 252 H 0 Z" id="path4077-0" inkscape:connector-curvature="0" style="clip-rule:evenodd"></path>
    </clipPath>
  </defs>
  <sodipodi:namedview pagecolor="#ffffff" bordercolor="#666666" borderopacity="1" objecttolerance="10" gridtolerance="10" guidetolerance="10" inkscape:pageopacity="0" inkscape:pageshadow="2" inkscape:window-width="1918" inkscape:window-height="1078" id="namedview4125" showgrid="false" inkscape:zoom="1.3111111" inkscape:cx="532.33439" inkscape:cy="127.30279" inkscape:window-x="0" inkscape:window-y="0" inkscape:window-maximized="0" inkscape:current-layer="g4121" fit-margin-top="0" fit-margin-left="0" fit-margin-right="0" fit-margin-bottom="0" viewbox-x="82" viewbox-width="650"></sodipodi:namedview>
  <clipPath id="p.0">
    <path d="M 0,0 H 960 V 720 H 0 Z" id="path4036" inkscape:connector-curvature="0" style="clip-rule:nonzero"></path>
  </clipPath>
  <g clip-path="url(#p.0)" id="g4121" transform="translate(-76.086586,-124.34907)">
    <path d="M 0,0 H 960 V 720 H 0 Z" id="path4039" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <path d="m 76.08921,124.34908 h 223.2992 V 267.11813 H 76.08921 Z" id="path4041" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <g transform="matrix(0.22307612,0,0,0.22307664,76.089214,124.34908)" id="g4048">
      <clipPath id="p.1">
        <path d="M 0,0 H 1001 V 640 H 0 Z" id="path4043" inkscape:connector-curvature="0" style="clip-rule:evenodd"></path>
      </clipPath>
      <image clip-path="url(#p.1)" width="1001" height="640" x="0" y="0" preserveAspectRatio="none" xlink:href="https://desfontain.es/privacy/images/quiestce.jpeg" id="image4046" style="fill:#000000"></image>
    </g>
    <path d="M 76.086586,339.67847 H 299.38579 V 482.44751 H 76.086586 Z" id="path4050" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <g transform="matrix(0.22307612,0,0,0.22307664,76.086589,339.67847)" id="g4057">
      <clipPath id="p.2">
        <path d="M 0,0 H 1001 V 640 H 0 Z" id="path4052" inkscape:connector-curvature="0" style="clip-rule:evenodd"></path>
      </clipPath>
      <image clip-path="url(#p.2)" width="1001" height="640" x="0" y="0" preserveAspectRatio="none" xlink:href="https://desfontain.es/privacy/images/quiestce.jpeg" id="image4055" style="fill:#000000"></image>
    </g>
    <path d="m 604.81974,178.70273 v 0 c -1.51233,-10.41394 3.45307,-20.72311 12.78925,-26.55296 9.33618,-5.82984 21.40576,-6.15791 31.08722,-0.84502 v 0 c 3.42944,-6.0551 9.70636,-10.23573 16.93207,-11.27733 7.2257,-1.04159 14.55151,1.17818 19.76159,5.98789 v 0 c 2.92145,-5.48995 8.65778,-9.17848 15.1734,-9.75675 6.51569,-0.57824 12.88855,2.03563 16.85718,6.9141 v 0 c 5.27802,-5.81934 13.67554,-8.2695 21.55884,-6.29033 7.8833,1.97917 13.83649,8.03222 15.28363,15.53996 v 0 c 6.46649,1.65271 11.8529,5.85413 14.76764,11.51872 2.91473,5.66462 3.07178,12.23673 0.43066,18.01831 v 0 c 6.36756,7.76532 7.85712,18.11251 3.91272,27.18018 -3.9444,9.06767 -12.7301,15.49351 -23.07849,16.87953 -0.0729,8.51033 -5.05414,16.31931 -13.02356,20.41701 -7.96942,4.09772 -17.68268,3.84427 -25.39587,-0.66263 -3.2854,10.1926 -12.53272,17.6922 -23.74671,19.25873 -11.21405,1.56653 -22.38446,-3.08087 -28.68524,-11.93434 -7.72339,4.3639 -16.99084,5.621 -25.71185,3.48773 -8.72095,-2.13329 -16.16077,-7.47725 -20.64124,-14.8264 v 0 c -7.89233,0.86539 -15.52319,-2.96604 -19.10534,-9.59276 -3.58216,-6.62671 -2.35303,-14.63803 3.07733,-20.05798 v 0 c -7.04022,-3.8826 -10.63251,-11.58696 -8.90375,-19.09555 1.72882,-7.50861 8.38696,-13.11998 16.50256,-13.90799 z" id="path4059" inkscape:connector-curvature="0" style="fill:#f6cd4c;fill-rule:evenodd"></path>
    <path d="m 597.06497,212.10764 v 0 c 3.32227,1.83222 7.16028,2.66335 10.99872,2.38181 m 5.02759,27.2696 c 1.65063,-0.18098 3.26861,-0.56427 4.81219,-1.13993 m 41.53858,12.47812 c -1.16095,-1.63134 -2.133,-3.37456 -2.89954,-5.19996 m 55.3335,-2.12474 v 0 c 0.59893,-1.85826 0.98706,-3.77081 1.15777,-5.70575 m 37.26019,-14.04791 c 0.0776,-9.06056 -5.41461,-17.3565 -14.11767,-21.32448 m 33.2832,-22.73425 c -1.40942,3.08528 -3.56109,5.8222 -6.28625,7.99617 m -8.91071,-37.53403 v 0 c 0.24011,1.24591 0.35126,2.51055 0.33185,3.77639 m -37.17371,-13.02565 v 0 c -1.31659,1.45164 -2.4013,3.07382 -3.22033,4.81604 m -28.81055,-1.97402 v 0 c -0.70166,1.31851 -1.22559,2.71372 -1.55975,4.15347 m -35.13446,1.13608 v 0 c 2.04858,1.12421 3.94384,2.47731 5.64404,4.02959 m -49.5199,23.36855 v 0 c 0.20844,1.4353 0.53784,2.85292 0.98499,4.23957" id="path4061" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <path d="m 636.30257,211.8428 h -0.1875 q -0.78125,0 -1.25,-0.48437 -0.46875,-0.48438 -0.46875,-1.17188 0,-0.46875 0.5,-2.92187 l 1.375,-7.10938 q 0.46875,-2.42187 2.0625,-13.4375 l 0.39063,-2.70312 q 0.14062,-1.01563 1.10937,-1.84375 0.96875,-0.84375 1.78125,-0.84375 0.4375,0 2.9375,1.3125 2.70313,1.45312 3.20313,1.59375 5.09375,1.875 8.375,5.6875 3.29687,3.8125 3.29687,8.23437 0,4.04688 -2.40625,7.92188 -2.39062,3.875 -5.78125,5.71875 -3.39062,1.84375 -8.67187,1.84375 -1.53125,0 -3.46875,-0.53125 -1.9375,-0.51563 -2.79688,-1.26563 z m 6,-25.40625 -1.64062,11.20313 -2,10.67187 q 0.0625,0.0469 0.14062,0.0781 1.84375,1.32812 4.375,1.32812 5.01563,0 7.375,-1.79687 2.35938,-1.79688 3.60938,-4.21875 1.25,-2.42188 1.25,-4.92188 0,-2.51562 -1.40625,-4.64062 -1.39063,-2.125 -3.76563,-3.57813 -2.35937,-1.46875 -7.9375,-4.125 z m 32.16406,24.28125 q -4.21875,2.03125 -6.01562,2.03125 -7.29688,0 -7.29688,-6.95312 0,-6.46875 4.07813,-10.46875 4.09375,-4 8.98437,-4 1.89063,0 3.90625,0.96875 2.03125,0.96875 2.03125,2.25 0,0.79687 -0.53125,1.25 -0.39062,0.76562 -1.10937,4.40625 -0.70313,3.64062 -0.70313,5.25 0,1.96875 1.01563,5.42187 l 0.0781,0.3125 q -0.4375,1.82813 -2.17187,1.82813 -0.29688,0 -1.09375,-0.79688 -0.79688,-0.79687 -1.17188,-1.5 z m 1.42188,-15.1875 q -1.21875,-0.73437 -1.95313,-0.73437 -3.25,0 -6.07812,2.95312 -2.82813,2.9375 -2.82813,7.3125 0,4.29688 3.71875,4.29688 2.90625,0 5.46875,-2.15625 0.3125,-8.1875 1.67188,-11.67188 z m 16.45312,-0.34375 q -0.23437,0.9375 -0.60937,2.1875 -1.64063,5.42188 -1.64063,8.26563 0,3.35937 1.5625,3.35937 1.54688,0 2.28125,-0.95312 1.01563,-1.32813 1.875,-1.32813 0.65625,0 1.25,0.48438 0.59375,0.48437 0.59375,1.26562 0,1.71875 -2.15625,2.95313 -2.15625,1.21875 -4.29687,1.21875 -5.03125,0 -5.03125,-6.28125 0,-3.4375 1.54687,-8.39063 0.40625,-1.3125 0.78125,-2.625 -4.25,-0.20312 -4.85937,-0.70312 -0.60938,-0.5 -0.60938,-1.5625 0,-0.85938 0.57813,-1.42188 0.59375,-0.57812 1.60937,-0.57812 l 4.03125,0.32812 q 0.125,-0.51562 0.1875,-1.17187 0.0312,-0.67188 0.125,-1.48438 l 0.34375,-2.42187 q 0.10938,-0.79688 0.71875,-1.34375 0.625,-0.54688 1.46875,-0.54688 1.64063,0 1.64063,2.625 0,0.76563 -0.23438,1.98438 l -0.39062,2.35937 q 2.60937,-0.32812 2.78125,-0.32812 2.03125,0 2.79687,0.40625 0.76563,0.39062 0.76563,1.46875 0,0.95312 -0.65625,1.54687 -0.65625,0.57813 -1.57813,0.57813 l -1.92187,-0.0781 q -1.45313,0 -2.95313,0.1875 z m 21.44141,15.53125 q -4.21875,2.03125 -6.01563,2.03125 -7.29687,0 -7.29687,-6.95312 0,-6.46875 4.07812,-10.46875 4.09375,-4 8.98438,-4 1.89062,0 3.90625,0.96875 2.03125,0.96875 2.03125,2.25 0,0.79687 -0.53125,1.25 -0.39063,0.76562 -1.10938,4.40625 -0.70312,3.64062 -0.70312,5.25 0,1.96875 1.01562,5.42187 l 0.0781,0.3125 q -0.4375,1.82813 -2.17188,1.82813 -0.29687,0 -1.09375,-0.79688 -0.79687,-0.79687 -1.17187,-1.5 z m 1.42187,-15.1875 q -1.21875,-0.73437 -1.95312,-0.73437 -3.25,0 -6.07813,2.95312 -2.82812,2.9375 -2.82812,7.3125 0,4.29688 3.71875,4.29688 2.90625,0 5.46875,-2.15625 0.3125,-8.1875 1.67187,-11.67188 z" id="path4063" inkscape:connector-curvature="0" style="fill:#000000;fill-rule:nonzero"></path>
    <path d="m 604.81711,394.03214 v 0 c -1.51233,-10.41397 3.45307,-20.72311 12.78925,-26.55298 9.33618,-5.82983 21.40576,-6.1579 31.08722,-0.845 v 0 c 3.42944,-6.05511 9.70636,-10.23575 16.93207,-11.27734 7.2257,-1.0416 14.55151,1.17819 19.76159,5.98788 v 0 c 2.92145,-5.48993 8.65778,-9.17847 15.1734,-9.75674 6.51569,-0.57825 12.88855,2.03564 16.85718,6.91409 v 0 c 5.27802,-5.81934 13.67554,-8.2695 21.55884,-6.29031 7.8833,1.97915 13.83649,8.03222 15.28363,15.53994 v 0 c 6.46649,1.65271 11.8529,5.85413 14.76764,11.51874 2.91473,5.66461 3.07178,12.23673 0.43066,18.01831 v 0 c 6.36756,7.76532 7.85712,18.11249 3.91272,27.18018 -3.9444,9.06766 -12.7301,15.4935 -23.07849,16.87952 -0.0729,8.51034 -5.05414,16.3193 -13.02356,20.41702 -7.96942,4.09769 -17.68268,3.84427 -25.39587,-0.66266 -3.2854,10.19263 -12.53272,17.69223 -23.74671,19.25876 -11.21405,1.56653 -22.38446,-3.08087 -28.68524,-11.93436 -7.72339,4.36392 -16.99084,5.621 -25.71185,3.48773 -8.72095,-2.13327 -16.16077,-7.47723 -20.64124,-14.82638 v 0 c -7.89233,0.86539 -15.52319,-2.96607 -19.10534,-9.59277 -3.58216,-6.62671 -2.35303,-14.63804 3.07733,-20.05799 v 0 c -7.04022,-3.8826 -10.63257,-11.58694 -8.90375,-19.09555 1.72882,-7.5086 8.38696,-13.11996 16.50256,-13.90799 z" id="path4065" inkscape:connector-curvature="0" style="fill:#f6cd4c;fill-rule:evenodd"></path>
    <path d="m 597.06237,427.43705 v 0 c 3.32227,1.83218 7.16028,2.66333 10.99872,2.38181 m 5.02759,27.26959 c 1.65063,-0.181 3.26861,-0.56427 4.81219,-1.13992 m 41.53858,12.47811 c -1.16095,-1.63134 -2.133,-3.37457 -2.89954,-5.19998 m 55.3335,-2.12472 v 0 c 0.59893,-1.85825 0.98706,-3.77082 1.15777,-5.70575 m 37.26019,-14.04792 c 0.0776,-9.06054 -5.41461,-17.3565 -14.11767,-21.32449 m 33.2832,-22.73425 c -1.40942,3.0853 -3.56109,5.82223 -6.28625,7.99618 m -8.91071,-37.53402 v 0 c 0.24011,1.24591 0.35126,2.51056 0.33185,3.77639 m -37.17371,-13.02566 v 0 c -1.31659,1.45163 -2.4013,3.07382 -3.22033,4.81604 m -28.81055,-1.974 v 0 c -0.70166,1.31848 -1.22559,2.71372 -1.55975,4.15347 m -35.13446,1.13608 v 0 c 2.04858,1.12421 3.94384,2.4773 5.64404,4.02957 m -49.5199,23.36856 v 0 c 0.20844,1.43531 0.53784,2.85291 0.98499,4.23957" id="path4067" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <path d="m 636.29997,427.17219 h -0.1875 q -0.78125,0 -1.25,-0.48437 -0.46875,-0.48438 -0.46875,-1.17188 0,-0.46875 0.5,-2.92187 l 1.375,-7.10938 q 0.46875,-2.42187 2.0625,-13.4375 l 0.39063,-2.70312 q 0.14062,-1.01563 1.10937,-1.84375 0.96875,-0.84375 1.78125,-0.84375 0.4375,0 2.9375,1.3125 2.70313,1.45312 3.20313,1.59375 5.09375,1.875 8.375,5.6875 3.29687,3.8125 3.29687,8.23437 0,4.04688 -2.40625,7.92188 -2.39062,3.875 -5.78125,5.71875 -3.39062,1.84375 -8.67187,1.84375 -1.53125,0 -3.46875,-0.53125 -1.9375,-0.51563 -2.79688,-1.26563 z m 6,-25.40625 -1.64062,11.20313 -2,10.67187 q 0.0625,0.0469 0.14062,0.0781 1.84375,1.32812 4.375,1.32812 5.01563,0 7.375,-1.79687 2.35938,-1.79688 3.60938,-4.21875 1.25,-2.42188 1.25,-4.92188 0,-2.51562 -1.40625,-4.64062 -1.39063,-2.125 -3.76563,-3.57813 -2.35937,-1.46875 -7.9375,-4.125 z m 32.16406,24.28125 q -4.21875,2.03125 -6.01562,2.03125 -7.29688,0 -7.29688,-6.95312 0,-6.46875 4.07813,-10.46875 4.09375,-4 8.98437,-4 1.89063,0 3.90625,0.96875 2.03125,0.96875 2.03125,2.25 0,0.79687 -0.53125,1.25 -0.39062,0.76562 -1.10937,4.40625 -0.70313,3.64062 -0.70313,5.25 0,1.96875 1.01563,5.42187 l 0.0781,0.3125 q -0.4375,1.82813 -2.17187,1.82813 -0.29688,0 -1.09375,-0.79688 -0.79688,-0.79687 -1.17188,-1.5 z m 1.42188,-15.1875 q -1.21875,-0.73437 -1.95313,-0.73437 -3.25,0 -6.07812,2.95312 -2.82813,2.9375 -2.82813,7.3125 0,4.29688 3.71875,4.29688 2.90625,0 5.46875,-2.15625 0.3125,-8.1875 1.67188,-11.67188 z m 16.45312,-0.34375 q -0.23437,0.9375 -0.60937,2.1875 -1.64063,5.42188 -1.64063,8.26563 0,3.35937 1.5625,3.35937 1.54688,0 2.28125,-0.95312 1.01563,-1.32813 1.875,-1.32813 0.65625,0 1.25,0.48438 0.59375,0.48437 0.59375,1.26562 0,1.71875 -2.15625,2.95313 -2.15625,1.21875 -4.29687,1.21875 -5.03125,0 -5.03125,-6.28125 0,-3.4375 1.54687,-8.39063 0.40625,-1.3125 0.78125,-2.625 -4.25,-0.20312 -4.85937,-0.70312 -0.60938,-0.5 -0.60938,-1.5625 0,-0.85938 0.57813,-1.42188 0.59375,-0.57812 1.60937,-0.57812 l 4.03125,0.32812 q 0.125,-0.51562 0.1875,-1.17187 0.0312,-0.67188 0.125,-1.48438 l 0.34375,-2.42187 q 0.10938,-0.79688 0.71875,-1.34375 0.625,-0.54688 1.46875,-0.54688 1.64063,0 1.64063,2.625 0,0.76563 -0.23438,1.98438 l -0.39062,2.35937 q 2.60937,-0.32812 2.78125,-0.32812 2.03125,0 2.79687,0.40625 0.76563,0.39062 0.76563,1.46875 0,0.95312 -0.65625,1.54687 -0.65625,0.57813 -1.57813,0.57813 l -1.92187,-0.0781 q -1.45313,0 -2.95313,0.1875 z m 21.44141,15.53125 q -4.21875,2.03125 -6.01563,2.03125 -7.29687,0 -7.29687,-6.95312 0,-6.46875 4.07812,-10.46875 4.09375,-4 8.98438,-4 1.89062,0 3.90625,0.96875 2.03125,0.96875 2.03125,2.25 0,0.79687 -0.53125,1.25 -0.39063,0.76562 -1.10938,4.40625 -0.70312,3.64062 -0.70312,5.25 0,1.96875 1.01562,5.42187 l 0.0781,0.3125 q -0.4375,1.82813 -2.17188,1.82813 -0.29687,0 -1.09375,-0.79688 -0.79687,-0.79687 -1.17187,-1.5 z m 1.42187,-15.1875 q -1.21875,-0.73437 -1.95312,-0.73437 -3.25,0 -6.07813,2.95312 -2.82812,2.9375 -2.82812,7.3125 0,4.29688 3.71875,4.29688 2.90625,0 5.46875,-2.15625 0.3125,-8.1875 1.67187,-11.67188 z" id="path4069" inkscape:connector-curvature="0" style="fill:#000000;fill-rule:nonzero"></path>
    <path d="m 299.38846,189.04987 h 70.36065 v -6.68504 l 8.40525,13.37008 -8.40525,13.37007 v -6.68502 h -70.36065 z" id="path4071" inkscape:connector-curvature="0" style="fill:#7c7ce0;fill-rule:evenodd;stroke-width:0.79288208"></path>
    <path d="M 427.88773,353.66272 H 553.16596 V 468.46329 H 427.88773 Z" id="path4075" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <g transform="matrix(0.45555722,0,0,0.45555774,379.83689,353.66273)" id="g4082">
      <clipPath id="p.3">
        <path d="M 0,0 H 275 V 252 H 0 Z" id="path4077" inkscape:connector-curvature="0" style="clip-rule:evenodd"></path>
      </clipPath>
      <image clip-path="url(#p.3)" width="275" height="252" x="0" y="0" preserveAspectRatio="none" xlink:href="https://desfontain.es/privacy/images/magic.gif" id="image4080" style="fill:#000000"></image>
    </g>
    <path d="m 660.00147,264.20093 21.66931,-21.66928 21.66932,21.66928 h -10.83466 v 85.7638 h 10.83466 l -21.66932,21.66928 -21.66931,-21.66928 h 10.83466 v -85.7638 z" id="path4088" inkscape:connector-curvature="0" style="fill:#db4437;fill-rule:evenodd"></path>
    <path d="m 660.00147,264.20093 21.66931,-21.66928 21.66932,21.66928 h -10.83466 v 85.7638 h 10.83466 l -21.66932,21.66928 -21.66931,-21.66928 h 10.83466 v -85.7638 z" id="path4090" inkscape:connector-curvature="0" style="fill-rule:evenodd;stroke:#666666;stroke-width:1;stroke-linecap:butt;stroke-linejoin:round"></path>
    <path d="m 554.53672,285.04017 c 42.66144,-12.09317 85.32288,12.0932 127.98438,0 42.66143,-12.09317 85.32287,12.0932 127.98431,0 l -1.70062,50.79135 c -42.66144,12.09317 -85.32288,-12.09317 -127.98432,0 -42.66143,12.09317 -85.32294,-12.09317 -127.98437,0 z" id="path4092" inkscape:connector-curvature="0" style="fill:#db4437;fill-rule:evenodd"></path>
    <path d="m 587.72404,321.45273 q -0.84375,-0.5 -1.26562,-1.0625 -0.40625,-0.5625 -0.40625,-1.07812 0,-0.67188 0.67187,-1.07813 0.125,-0.0625 0.35938,-0.0625 0.3125,0 0.67187,0.10938 0.375,0.10937 0.57813,0.29687 0.82812,0.76563 1.98437,0.76563 0.5,0 1.46875,-0.21875 1.25,-0.39063 1.96875,-0.95313 0.71875,-0.57812 1.70313,-1.79687 0.60937,-0.79688 0.90625,-1.60938 0.3125,-0.82812 0.3125,-1.5 0,-0.73437 -0.34375,-1.15625 -0.64063,-0.85937 -1.4375,-1.28125 -0.78125,-0.4375 -1.82813,-0.4375 -0.9375,0 -1.82812,0.25 l -1.85938,0.39063 q -0.125,0.0312 -0.34375,0.0469 -0.20312,0.0156 -0.59375,0.95313 -0.375,0.92187 -1.29687,3.51562 -0.67188,1.875 -1.125,2.70313 -0.45313,0.8125 -0.79688,0.8125 -0.39062,0 -0.82812,-0.70313 -0.0937,-0.15625 -0.40625,-0.64062 -0.29688,-0.48438 -0.29688,-0.9375 0,-0.21875 0.15625,-0.53125 0.15625,-0.29688 0.26563,-0.57813 0.10937,-0.29687 0.25,-0.79687 0.40625,-1.25 2.40625,-6.20313 2,-4.96875 3.125,-7.5 0.79687,-1.82812 0.48437,-1.92187 0,-0.0937 -0.10937,-0.28125 -0.0937,-0.20313 -0.0625,-0.29688 0,-0.1875 1.14062,-0.5625 1.14063,-0.39062 1.54688,-0.32812 h 0.20312 q 0.40625,0 0.40625,-0.15625 0.0625,0 0.59375,-0.0625 0.53125,-0.0625 1.14063,0 2.26562,0.1875 3.57812,1.29687 1.3125,1.09375 1.28125,3.23438 -0.0625,0.84375 -0.92187,2.28125 -0.85938,1.4375 -1.89063,2.35937 -0.51562,0.45313 -1.17187,0.95313 -0.65625,0.5 -0.84375,0.625 l 0.79687,0.28125 q 1.5,0.57812 2.32813,1.42187 0.84375,0.82813 1.1875,2.26563 0.0781,0.3125 0.0781,0.57812 0,0.70313 -0.25,1.59375 -0.23437,0.89063 -0.53125,1.5625 -0.1875,0.20313 -0.3125,0.42188 -0.125,0.21875 -0.15625,0.28125 -0.0312,0.14062 -0.57812,0.98437 -0.54688,0.84375 -0.96875,1.35938 -2.10938,1.79687 -3.48438,2.29687 -1.34375,0.60938 -3.20312,0.60938 -1.65625,0 -2.45313,-0.51563 z m 2.29688,-13.26562 q 0.32812,-0.0781 1.28125,-0.28125 0.95312,-0.20313 1.375,-0.35938 0.0625,-0.0312 0.39062,-0.20312 0.34375,-0.1875 0.70313,-0.54688 2.01562,-1.875 2.8125,-3.39062 0.79687,-1.3125 0.79687,-1.84375 0,-0.39063 -0.34375,-0.75 -0.60937,-0.70313 -2.01562,-0.70313 -0.60938,0 -1.03125,0.14063 -0.45313,0.125 -0.65625,0.29687 -0.20313,0.17188 -0.20313,0.53125 0,0.25 -0.17187,0.5625 -0.15625,0.29688 -0.34375,0.48438 -0.0312,0.20312 -0.17188,0.39062 -0.14062,0.1875 -0.21875,0.25 0,0.0781 -0.4375,0.875 -0.42187,0.79688 -0.79687,1.78125 -0.96875,2.28125 -0.96875,2.76563 z m 11.90643,10.29687 q -0.0937,-0.1875 -0.54688,-0.5 -0.45312,-0.32812 -0.45312,-0.39062 0,-0.14063 -0.14063,-0.375 -0.14062,-0.23438 -0.26562,-0.4375 -0.26563,-0.25 0.34375,-1.65625 0.60937,-1.40625 1.64062,-3.32813 0.1875,-0.1875 0.48438,-0.67187 0.3125,-0.48438 0.40625,-0.54688 0,-0.125 0.0937,-0.23437 0.0937,-0.10938 0.23437,-0.10938 l 0.25,-0.51562 q 0.125,-0.29688 1.25,-1.375 1.125,-1.09375 1.76563,-1.46875 0.59375,-0.42188 1.3125,-0.42188 0.76562,0 1.29687,0.45313 l 0.875,0.73437 q 0.95313,0.79688 1.07813,0.92188 l 1.1875,1.0625 -0.54688,1.59375 q -0.28125,0.85937 -0.28125,1.64062 0,1.20313 0.67188,2.26563 0.15625,0.34375 0.42187,0.54687 0.28125,0.1875 0.73438,0.25 0.70312,0.125 0.70312,0.70313 0,0.70312 -0.26562,1.0625 -0.25,0.34375 -0.60938,0.4375 -0.5,0.0781 -0.70312,0.0781 -0.92188,0 -1.6875,-0.48437 -0.76563,-0.48438 -1.34375,-1.64063 -0.125,-0.1875 -0.34375,-0.6875 -0.20313,-0.51562 -0.23438,-0.71875 -0.21875,0.32813 -0.73437,0.84375 -3.29688,3.32813 -5.34375,3.32813 -0.70313,0 -1.25,-0.35938 z m 1.76562,-2.65625 q 0.5,0.0625 1.98438,-1.15625 0.15625,-0.125 0.34375,-0.29687 0.1875,-0.17188 0.42187,-0.375 0.89063,-0.73438 1.39063,-1.21875 0.5,-0.5 1,-1.20313 l 0.70312,-1.15625 q -0.3125,-0.70312 -0.57812,-0.9375 -0.25,-0.25 -0.5,-0.25 -0.64063,0 -1.60938,1.14063 -0.95312,1.14062 -2.29687,3.4375 -0.35938,0.57812 -0.57813,1.20312 -0.21875,0.625 -0.28125,0.8125 z m 14.94391,3.8125 q -0.78125,0 -1.59375,-0.32812 -0.8125,-0.3125 -1.375,-0.78125 -0.5625,-0.46875 -0.5625,-0.84375 0,-0.39063 0.35938,-0.48438 l 0.15625,-0.125 q 0.0625,-0.0312 0.25,-0.0312 0.14062,-0.0312 0.32812,0.0156 0.1875,0.0469 0.3125,0.0469 0.23438,0.0625 0.67188,0.125 l 0.84375,0.0937 q 0.64062,0 1.1875,-0.125 0.5625,-0.125 0.5625,-0.28125 0,-0.10937 -0.25,-0.32812 -0.25,-0.21875 -0.54688,-0.21875 0,-0.125 -0.98437,-0.85938 -0.54688,-0.42187 -1.04688,-0.82812 -0.5,-0.42188 -0.5,-0.625 l 0.0312,-0.0625 v -0.15625 q -0.21875,0 -0.42187,-0.60938 -0.1875,-0.60937 -0.1875,-1.1875 0,-1.07812 0.95312,-2.39062 0.96875,-1.3125 2.39063,-2.35938 1.4375,-1.0625 2.71875,-1.45312 0.46875,-0.21875 1.40625,-0.21875 0.60937,0 0.82812,0.125 l 0.25,-0.0625 q 0.39063,0 1,0.64062 0.60938,0.64063 0.76563,1.01563 0,1.0625 -0.0625,1.70312 -0.0625,0.64063 -0.32813,0.64063 -0.0312,0 -0.0937,0.0312 -0.0625,0.0312 -0.0625,0.15625 0,0.45312 -0.78125,1 -0.78125,0.53125 -1.42187,0.53125 l -0.125,-0.0312 q -0.20313,-0.0312 -0.57813,-0.375 -0.35937,-0.35938 -0.35937,-0.70313 0,-0.0937 0.375,-0.51562 0.39062,-0.42188 0.65625,-0.8125 0.28125,-0.40625 0.28125,-0.85938 0,-0.15625 -0.10938,-0.20312 -0.10937,-0.0469 -0.4375,-0.0469 -1.75,0.79688 -2.51562,1.5 -0.10938,0.20313 -0.1875,0.29688 -0.0781,0.0937 -0.20313,0.0937 0,0 0,-0.0156 0,-0.0156 -0.0312,-0.0156 -0.0625,0 -0.42187,0.375 -0.34375,0.35937 -0.65625,0.84375 -0.29688,0.46875 -0.35938,0.89062 l -0.0625,0.0937 v 0.15625 q -0.0312,0.0625 -0.0312,0.26563 0,0.28125 0.25,0.59375 0.25,0.29687 1.03125,0.84375 1.4375,1.09375 1.95313,1.625 0.53125,0.51562 0.67187,0.9375 0.28125,0.57812 0.28125,1.01562 0,1.09375 -1.14062,1.6875 -1.125,0.59375 -3.07813,0.59375 z m 13.21564,-13.79687 q -0.10937,0.0937 -0.20312,0.0937 -0.125,0 -0.40625,-0.1875 -0.32813,-0.0312 -0.85938,-0.54688 -0.51562,-0.51562 -0.51562,-0.67187 -0.0312,-0.39063 0.0625,-1.10938 0.0937,-0.71875 0.35937,-1.28125 0.28125,-0.57812 0.71875,-0.60937 0.23438,0.0312 0.60938,0.14062 0.39062,0.10938 0.875,0.29688 0.59375,1.21875 0.59375,2.07812 0,1.28125 -1.23438,1.79688 z m -2.95312,13.28125 q -0.76563,0 -1.32813,-0.79688 -0.5625,-0.79687 -0.6875,-1.98437 0.125,-1.1875 0.1875,-1.73438 0.35938,-1.5625 0.89063,-3.6875 0.53125,-2.14062 0.625,-2.35937 0.15625,-0.28125 0.5,-0.28125 0.35937,0 0.78125,0.26562 0.4375,0.26563 0.73437,0.75 0.25,0.35938 0.25,0.79688 0,0.67187 -0.64062,2.82812 -0.4375,1.59375 -0.57813,2.26563 -0.125,0.67187 -0.0937,1.4375 -0.125,1.4375 -0.25,1.98437 -0.125,0.54688 -0.39062,0.51563 z m 6.8189,-0.21875 q -0.95312,0 -1.25,-0.10938 -0.28125,-0.125 -0.70312,-0.5 -0.0937,-0.23437 -0.40625,-0.60937 -0.29688,-0.39063 -0.48438,-0.57813 -0.0937,-0.35937 -0.0937,-0.82812 0,-0.84375 0.23438,-1.95313 0.23437,-1.125 0.59375,-2.04687 0.125,-0.26563 0.20312,-0.48438 0.0781,-0.21875 0.10938,-0.28125 0,-0.23437 0.8125,-1.39062 0.82812,-1.17188 1.3125,-1.625 0.21875,-0.25 0.67187,-0.53125 0.46875,-0.29688 0.82813,-0.42188 0.0937,-0.0312 0.78125,-0.28125 0.6875,-0.26562 1.26562,-0.26562 0.51563,0 1,0.20312 0.5,0.20313 0.82813,0.65625 0.82812,0.82813 0.82812,2.17188 0,0.26562 -0.0625,0.57812 -0.17187,0.64063 -0.67187,1.04688 -0.48438,0.39062 -1.03125,0.39062 -0.54688,0 -0.92188,-0.40625 -0.125,-0.32812 -0.125,-0.42187 0,-0.0937 0.125,-0.54688 0.125,-0.57812 0.125,-0.73437 0,-0.40625 -0.28125,-0.40625 -0.39062,0 -0.625,0.1875 -0.21875,0.1875 -0.82812,0.82812 -0.40625,0.45313 -0.96875,1.29688 -0.5625,0.84375 -0.875,1.60937 -0.29688,0.875 -0.40625,1.25 -0.10938,0.35938 -0.10938,0.42188 0,0.125 -0.0312,0.23437 -0.0312,0.10938 -0.0312,0.25 0,0.21875 0.0937,0.34375 0.0937,0.125 0.34375,0.26563 0.0781,0.0312 0.23438,0.125 0.15625,0.0937 0.3125,0.0937 0.20312,0 0.54687,-0.15625 0.35938,-0.17188 0.45313,-0.20313 0.40625,-0.1875 1.17187,-0.82812 l 0.78125,-0.57813 q 0.21875,-0.15625 0.39063,-0.26562 0.1875,-0.10938 0.28125,-0.15625 0.0937,-0.0469 0.0937,0.0156 0,0.125 0.0937,0.125 0.0937,0 0.21875,-0.125 0.125,-0.20312 0.45312,-0.20312 0.25,0 0.51563,0.15625 0.28125,0.14062 0.28125,0.23437 l -0.0312,0.15625 q 0,0.15625 0.15625,0.32813 0,0.125 -0.0781,0.32812 -0.0781,0.20313 -0.20312,0.34375 -0.32813,0.46875 -0.73438,0.98438 -0.39062,0.51562 -0.54687,0.70312 h -0.0312 q -0.15625,0 -0.45313,0.29688 -0.46875,0.4375 -0.82812,0.4375 -0.125,0.0625 -0.29688,0.15625 -0.15625,0.0781 -0.15625,0.17187 -0.53125,0.54688 -2.875,0.54688 z m 10.59815,-0.32813 q -0.54688,0.125 -1.3125,-0.57812 -0.76563,-0.70313 -0.90625,-1.3125 -0.0625,-0.3125 -0.0625,-0.54688 0,-1.23437 0.79687,-3.01562 0.8125,-1.78125 2.17188,-3.34375 1.35937,-1.5625 2.98437,-2.26563 0.67188,-0.35937 0.85938,-0.35937 0.20312,0 0.875,0.35937 0.64062,0.15625 1.01562,0.34375 0.39063,0.1875 0.70313,0.60938 0.42187,0.82812 0.60937,2.04687 0.20313,0.67188 0.20313,0.95313 0,0.26562 -0.20313,0.45312 -0.0312,0.0312 -0.10937,0.125 -0.0781,0.0937 -0.0781,0.15625 0,0.0469 0.0625,0.0469 0,0.0312 -0.0312,0.14062 -0.0312,0.10938 -0.125,0.29688 -0.39062,1.21875 -0.39062,1.89062 0,0.21875 0.0625,0.54688 0.32812,0.82812 0.8125,0.82812 0.4375,0 1.01562,-0.57812 0.48438,-0.3125 0.96875,-0.3125 0.28125,0 0.28125,0.15625 0.0312,0.0312 0.125,0.0937 0.0937,0.0625 0.1875,0.0625 0.14063,0 0.14063,0.29687 0,0.25 -0.125,0.67188 -0.10938,0.40625 -0.26563,0.67187 -0.21875,0.21875 -0.35937,0.39063 -0.125,0.15625 -0.125,0.25 l -0.46875,0.4375 q -0.60938,0.35937 -1.45313,0.35937 -0.85937,0 -1.375,-0.35937 -0.5,-0.34375 -0.95312,-0.875 -0.45313,-0.53125 -0.57813,-0.9375 l -0.15625,-0.32813 -0.9375,0.60938 -0.79687,0.82812 q -0.25,0.32813 -0.4375,0.32813 h -0.32813 q 0,0.21875 -0.90625,0.54687 -0.89062,0.3125 -1.39062,0.3125 z m 0.67187,-2.6875 q 0.34375,0 1.4375,-0.8125 1.10938,-0.8125 1.5,-1.29687 0.125,-0.15625 0.32813,-0.45313 0.21875,-0.3125 0.375,-0.46875 0.51562,-0.60937 0.75,-0.96875 0.25,-0.375 0.25,-0.73437 0,-0.25 -0.23438,-0.70313 -0.125,-0.39062 -0.375,-0.39062 -0.14062,0 -0.73437,0.23437 -0.60938,0.34375 -1.4375,1.4375 -0.8125,1.07813 -1.42188,2.20313 -0.60937,1.125 -0.60937,1.64062 0,0.0937 0.0625,0.1875 0.0781,0.0937 0.10937,0.125 z m 11.06427,4.21875 q -0.48437,-0.15625 -0.71875,-0.57812 -0.23437,-0.40625 -0.23437,-1.20313 0,-1.3125 0.25,-2.5625 l 0.0312,-0.25 q 0.0312,-0.20312 0.0937,-0.625 0.0625,-0.4375 0.0937,-0.25 l 0.20312,-0.85937 q 0.21875,-0.89063 0.42188,-1.65625 0.21875,-0.78125 0.34375,-1.125 l 0.34375,-1.125 q 0.96875,-3.10938 1.79687,-4.1875 0.0312,-0.125 0.0937,-0.23438 0.0625,-0.125 0.0937,-0.25 0,-0.51562 0.20313,-0.79687 0.28125,-0.48438 0.46875,-0.85938 l 0.14062,-0.35937 0.89063,-1.82813 q 0.0937,-0.3125 0.39062,-0.6875 0.3125,-0.39062 0.625,-0.53125 l -0.0312,-0.0312 q 0.17188,-0.25 0.59375,-0.4375 0.4375,-0.20312 0.75,-0.20312 0.42188,0 0.67188,0.26562 0.26562,0.25 0.26562,0.70313 v 0.3125 q 0,0.29687 -0.0469,0.45312 -0.0469,0.15625 -0.21875,0.39063 h 0.0312 q 0.0469,0.0312 -0.0469,0.20312 -0.0781,0.17188 -0.14062,0.32813 -0.21875,0.57812 -0.3125,0.64062 -0.23438,0.29688 -1.48438,2.71875 -1.23437,2.40625 -1.59375,3.32813 l -0.125,0.48437 -0.0625,0.20313 q -0.35937,0.76562 -0.39062,0.82812 l -0.51563,1.98438 -0.125,0.67187 -0.28125,0.73438 -0.1875,0.60937 q -0.0781,0.15625 -0.125,0.42188 -0.0469,0.25 -0.10937,0.3125 l -0.0312,0.15625 q -0.0312,0.125 -0.21875,0.73437 -0.29688,0.90625 -0.42188,1.5 -0.125,0.57813 -0.15625,1.25 l -0.0312,0.14063 q -0.0937,0.70312 -0.40625,1.04687 -0.29687,0.35938 -0.78125,0.21875 z m 6.82099,-0.59375 q -0.0937,0.0312 -0.26563,0.0312 -0.67187,0 -1.125,-0.76562 -0.4375,-0.78125 -0.4375,-1.96875 0,-0.625 0.125,-1.23438 0.35938,-0.9375 0.35938,-1.34375 0.0937,-0.60937 0.65625,-2.1875 0.5625,-1.59375 0.71875,-1.92187 0.125,0 0.21875,-0.20313 0.0937,-0.20312 0.0937,-0.46875 0,-0.28125 0.10937,-0.57812 0.125,-0.3125 0.25,-0.4375 0,-0.0937 0.0781,-0.34375 0.0781,-0.26563 0.0781,-0.35938 0,-0.0625 0.0781,-0.23437 0.0781,-0.1875 0.0781,-0.28125 0.51563,-0.98438 1.79688,-4.45313 1.28125,-3.48437 1.28125,-3.85937 0,-0.26563 0.1875,-0.48438 0.20312,-0.21875 0.45312,-0.21875 0.0937,-0.10937 0.40625,-0.15625 0.32813,-0.0469 0.51563,-0.0469 l 0.51562,0.51562 q 0.35938,0.32813 0.54688,0.57813 0.1875,0.25 0.1875,0.60937 0,0.57813 -0.20313,1.14063 -0.20312,0.54687 -1.20312,2.625 -0.0625,0.17187 -0.51563,1.15625 -0.3125,0.64062 -0.3125,0.73437 0,0.0937 -0.14062,0.40625 -0.125,0.29688 -0.21875,0.625 -0.25,0.51563 -0.8125,1.8125 -0.5625,1.29688 -0.5625,1.42188 0,0.34375 -0.15625,0.5 -0.0937,0 -0.125,0.15625 -0.0312,0.14062 -0.0312,0.20312 0,0.3125 -0.51563,1.70313 l -0.28125,0.92187 q -0.60937,2.07813 -0.85937,3.04688 -0.23438,0.95312 -0.23438,1.625 0,0.70312 -0.23437,1.15625 -0.21875,0.4375 -0.5,0.57812 z m 13.97729,-12.23437 q 0.29688,0.57812 0.29688,1.3125 0,0.9375 -0.42188,1.53125 -0.3125,0.45312 -0.5625,1.35937 -0.23437,0.89063 -0.45312,2.39063 -0.29688,1.21875 -0.71875,3.75 -0.5,1.34375 -0.625,2.01562 -0.0469,0.1875 -0.3125,0.79688 -0.26563,0.60937 -0.4375,0.95312 -1.4375,2.92188 -3.40625,4.39063 -1.96875,1.46875 -4.01563,1.59375 -0.51562,0.0625 -0.60937,0.0625 -0.28125,0 -0.53125,-0.0937 -0.23438,-0.0937 -0.51563,-0.25 -0.64062,-0.45313 -0.73437,-0.64063 -0.17188,-0.32812 -0.17188,-0.64062 0,-0.48438 0.45313,-0.65625 0.45312,-0.17188 1.03125,-0.17188 0.21875,0.125 0.76562,0.125 0.54688,0 0.64063,-0.125 0.0625,-0.0625 0.375,-0.21875 0.32812,-0.14062 0.73437,-0.23437 1.0625,-0.51563 1.625,-1.03125 0.5625,-0.5 1.23438,-1.625 0.79687,-1.21875 1.04687,-2.20313 0.42188,-1.0625 1,-3.14062 l -0.0312,0.0312 q -0.17187,0.1875 -0.8125,0.5625 -0.625,0.375 -0.76562,0.375 -0.0312,0 -0.0937,0.0312 -0.0625,0.0312 -0.0625,0.125 0,0.125 -0.82813,0.40625 -0.82812,0.26562 -1.0625,0.26562 -0.3125,0 -0.6875,-0.34375 -0.35937,-0.35937 -0.53125,-0.65625 -0.125,-0.28125 -0.46875,-0.57812 -0.39062,-0.375 -0.57812,-0.67188 -0.1875,-0.3125 -0.1875,-0.73437 0,-0.21875 0.0312,-0.34375 0.375,-1.4375 1.40625,-4.42188 1.04687,-3 1.53125,-3.73437 0.125,-0.20313 0.46875,-0.32813 0.35937,-0.125 0.71875,-0.125 0.64062,0 0.85937,0.375 0.39063,0.54688 0.39063,0.9375 0,0.4375 -0.45313,1.3125 -0.125,0.34375 -0.32812,0.76563 -0.1875,0.42187 -0.1875,0.51562 -0.0312,0.125 -0.1875,0.78125 -0.15625,0.65625 -0.28125,0.65625 -0.20313,0.1875 -0.4375,1.32813 -0.23438,1.14062 -0.23438,1.8125 0,0.375 0.0937,0.375 0.85938,0 1.65625,-0.45313 0.79688,-0.46875 1.67188,-1.5 0.125,-0.79687 0.35937,-1.71875 0.25,-0.9375 0.34375,-1.25 0.57813,-1.98437 0.76563,-3.20312 0.1875,-0.45313 0.28125,-0.53125 0.0937,-0.0781 0.42187,-0.0781 0.39063,0 0.84375,0.23438 0.46875,0.21875 0.6875,0.53125 z m 11.99976,13.79687 q -1.25,-0.0312 -1.78125,-0.59375 -0.51563,-0.5625 -0.51563,-1.57812 0,-0.26563 0.0625,-0.84375 0.125,-0.4375 0.1875,-0.89063 0.15625,-0.70312 0.32813,-0.82812 0.0312,-0.0312 0.0625,-0.125 0.0312,-0.10938 -0.0625,-0.17188 0,-0.40625 0.28125,-1.14062 0.0625,-0.23438 0.15625,-0.45313 0.0937,-0.21875 0.14062,-0.28125 -0.0781,-0.0781 -0.0781,-0.20312 0,-0.15625 0.17187,-0.3125 0.1875,-0.15625 0.26563,-0.28125 0.0781,-0.14063 -0.0156,-0.26563 -0.0625,-0.15625 0.60938,-1.4375 0.42187,-0.82812 0.45312,-0.9375 -0.0312,-0.0937 0.45313,-1.17187 0.5,-1.09375 0.79687,-1.64063 0.28125,-0.15625 -0.23437,-0.21875 -0.51563,-0.0625 -1.25,-0.0312 -1.04688,-0.0312 -1.625,-0.10937 -0.57813,-0.0937 -0.9375,-0.28125 -0.21875,-0.21875 -0.21875,-0.57813 0,-0.40625 0.29687,-0.75 0.3125,-0.35937 0.76563,-0.39062 0.82812,-0.0312 2.5625,-0.23438 l 1.625,-0.125 0.0937,-0.54687 q 0.15625,-0.28125 0.29687,-0.48438 0.15625,-0.21875 0.20313,-0.375 0.0469,-0.15625 0.0781,-0.48437 0.0937,-0.125 0.32813,-0.625 0.25,-0.51563 0.3125,-1 0.35937,-0.60938 0.65625,-1.17188 0.29687,-0.5625 0.375,-0.65625 0.5625,-0.85937 1.26562,-0.85937 0.39063,0 0.8125,0.25 0.40625,0.29687 0.625,0.51562 0.23438,0.21875 0.23438,0.60938 0,0.28125 -0.29688,0.82812 -0.125,0.25 -0.375,1.03125 -0.21875,0.28125 -0.48437,0.78125 -0.25,0.5 -0.34375,0.9375 -0.0625,0.15625 -0.20313,0.4375 -0.125,0.26563 -0.17187,0.3125 -0.0469,0.0469 -0.14063,0.0469 0.0312,0.20312 0.125,0.26562 0.0937,0.0625 0.32813,0.0625 0.15625,0 0.39062,-0.0312 0.25,-0.0312 0.59375,-0.0312 0.32813,-0.0312 0.5625,-0.0937 0.23438,-0.0625 0.46875,-0.0625 0.125,0 0.375,0.0937 0.15625,0.1875 0.15625,0.73438 0,0.40625 -0.125,0.78125 -0.125,0.375 -0.3125,0.46875 -0.15625,0.0312 -0.70312,0.1875 -0.54688,0.15625 -1.1875,0.1875 l -1.70313,0.15625 -0.53125,1.09375 q -0.23437,0.39062 -0.39062,0.75 -0.15625,0.34375 -0.21875,0.40625 0,0.15625 -0.26563,0.64062 -0.25,0.48438 -0.375,0.76563 -0.17187,0.45312 -0.39062,0.89062 -0.21875,0.42188 -0.28125,0.54688 -0.0937,0 -0.125,0.0469 -0.0156,0.0469 -0.0156,0.14063 l 0.0781,0.26562 q 0,0.15625 -0.17188,0.3125 -0.125,0.0625 -0.23437,0.23438 -0.10938,0.15625 -0.14063,0.21875 0.0625,0.0625 0.0625,0.15625 0,0.23437 -0.21875,0.57812 0,0.54688 -0.45312,1.625 0.0312,0.57813 0.0625,0.75 0.0312,0.15625 0.15625,0.125 h 0.15625 l 0.70312,-0.0312 q 0.23438,-0.0937 0.10938,0.48438 -0.10938,0.5625 -0.54688,1.75 -0.48437,0.73437 -1.01562,1.29687 -0.51563,0.5625 -0.6875,0.5625 z m 8.84204,-3.14062 q -0.57813,-0.0937 -1.0625,-0.64063 -0.48438,-0.54687 -0.48438,-1.25 0,-0.76562 0.96875,-3.9375 0.15625,-0.82812 0.70313,-2.14062 0.1875,-0.54688 0.21875,-0.64063 0.57812,-1.92187 1.57812,-4.70312 l 0.28125,-0.76563 q 1.125,-3.04687 1.34375,-3.71875 l 0.51563,-1.40625 q 0,-0.25 0.35937,-0.48437 0.375,-0.25 0.625,-0.25 0.51563,0 0.98438,0.67187 0.48437,0.67188 0.51562,1.40625 0,0.39063 -0.15625,0.70313 -0.73437,1.60937 -1.82812,4.96875 -0.46875,1.40625 -0.95313,2.67187 -0.48437,1.26563 -0.76562,1.8125 l -0.35938,0.70313 -0.4375,1.6875 q 0,0.0937 -0.0312,0.17187 -0.0312,0.0625 -0.0312,0.0937 0,0.0937 0.0312,0.0937 l 0.53125,-0.54687 q 0.9375,-0.92188 2.21875,-1.89063 1.04688,-0.73437 1.07813,-0.82812 0.0312,-0.0937 0.26562,-0.29688 l 0.3125,-0.25 q 1.03125,-0.73437 2.21875,-0.73437 0.34375,0 0.82813,0.35937 0.48437,0.34375 0.8125,0.96875 0.34375,0.625 0.34375,1.32813 v 0.25 0.23437 q 0,0.79688 -0.3125,2.09375 -0.29688,1.29688 -0.32813,1.48438 0.15625,0 0.46875,-0.0625 0.48438,0 0.6875,0.0937 0.21875,0.0937 0.375,0.26562 0.15625,0.15625 0.28125,0.1875 0.0625,0.0625 0.0625,0.1875 0,0.73438 -0.79687,1.28125 -0.79688,0.54688 -1.53125,0.60938 -0.89063,0 -1.4375,-0.67188 -0.54688,-0.67187 -0.54688,-1.64062 0,-0.375 0.0312,-0.75 0.0312,-0.39063 0.0625,-0.6875 0.0937,-0.64063 0.0937,-1.01563 0,-0.42187 -0.0781,-0.5625 -0.0781,-0.14062 -0.26563,-0.14062 -0.64062,0 -2.23437,1.17187 -1.57813,1.15625 -3.20313,3.01563 -1.03125,1.5 -1.95312,1.5 z m 17.8548,1.21875 q -1.82813,0 -2.95313,-1.01563 -1.10937,-1.03125 -1.10937,-2.92187 0,-0.73438 0.0937,-1.625 0.0625,-0.78125 0.625,-2.125 0.5625,-1.34375 1.53125,-2.60938 0.96875,-1.28125 2.28125,-1.89062 0.60937,-0.29688 1.03125,-0.40625 0.42187,-0.10938 0.95312,-0.10938 1.3125,0 2.125,0.48438 0.82813,0.46875 1.15625,1.07812 0.34375,0.60938 0.34375,1.0625 v 0.15625 0.0937 q 0,0.39063 -0.45312,1.42188 -0.45313,1.01562 -1.42188,1.92187 -0.96875,0.89063 -2.51562,0.98438 -0.76563,0 -1.48438,-0.14063 -0.71875,-0.15625 -0.90625,-0.15625 -0.48437,0 -0.60937,0.35938 -0.125,0.34375 -0.125,1.1875 0.0937,0.89062 0.48437,1.25 0.40625,0.34375 1.17188,0.34375 0.39062,0 0.89062,-0.21875 0.51563,-0.26563 1.21875,-0.8125 0.39063,-0.3125 0.60938,-0.4375 0.21875,-0.125 0.54687,-0.125 0.28125,0 0.67188,0.39062 0.39062,0.375 0.42187,0.71875 -0.0781,0.39063 -0.71875,1.15625 -0.625,0.76563 -1.65625,1.375 -1.03125,0.60938 -2.20312,0.60938 z m 1.10937,-7.71875 q 0.60938,0 0.84375,-0.125 0.3125,-0.15625 0.96875,-0.8125 0.65625,-0.65625 0.6875,-0.90625 0,-0.32813 -0.28125,-0.53125 -0.26562,-0.20313 -0.73437,-0.28125 h -0.35938 q -0.42187,0 -1.20312,0.70312 -0.78125,0.6875 -1.35938,1.57813 0.0312,0.15625 0.48438,0.26562 0.45312,0.10938 0.95312,0.10938 z m 16.38513,7.90625 q -0.98437,0 -1.85937,-0.4375 -0.85938,-0.45313 -1.375,-1.14063 -0.5,-0.6875 -0.5,-1.35937 0,-0.54688 0.4375,-0.54688 0.29687,0.0625 0.67187,0.35938 0.48438,0.28125 0.8125,0.4375 0.34375,0.15625 0.70313,0.15625 0.53125,0 0.9375,-0.17188 0.40625,-0.17187 0.46875,-0.53125 0,-0.125 -0.14063,-0.54687 -0.125,-0.4375 -0.3125,-0.79688 -0.70312,-1.04687 -0.95312,-2.04687 -0.23438,-1.01563 -0.29688,-2.35938 0,-0.73437 1.0625,-1.75 1.07813,-1.03125 2.5,-1.82812 1.4375,-0.8125 2.32813,-0.90625 1.76562,0 2.10937,0.29687 0.45313,0.34375 0.82813,1.14063 0.39062,0.79687 0.39062,1.34375 0,0.23437 -0.21875,0.57812 -0.20312,0.32813 -0.26562,0.42188 l -0.28125,0.4375 -0.21875,0.48437 q -0.0781,0.15625 -0.21875,0.48438 -0.14063,0.3125 -0.25,0.39062 -0.10938,0.0625 -0.34375,0.0156 -0.53125,0 -0.98438,-0.46875 -0.45312,-0.48438 -0.45312,-1.0625 0,-0.40625 0.28125,-0.82813 0.29687,-0.42187 0.29687,-0.48437 0,-0.125 -0.28125,-0.125 -0.42187,0 -1.29687,0.42187 -0.85938,0.40625 -1.53125,1.09375 -0.67188,0.6875 -0.67188,1.53125 0,0.4375 0.17188,1.03125 0.1875,0.59375 0.40625,0.98438 0.26562,0.25 0.75,1.51562 0.5,1.26563 0.5,2 0,1.125 -0.84375,1.70313 -0.84375,0.5625 -2.35938,0.5625 z m 11.04377,-0.64063 q -0.3125,0.0625 -0.57813,0.0625 -0.40625,0 -0.76562,-0.0781 -0.34375,-0.0781 -0.34375,-0.20313 0,-0.0937 -0.0469,-0.125 -0.0312,-0.0312 -0.125,-0.0312 -0.0937,-0.0937 -0.4375,-0.32812 -0.32812,-0.25 -0.54687,-0.34375 -0.39063,-0.54688 -0.39063,-1.1875 0,-0.60938 0.39063,-1.95313 0.0312,-1.25 0.90625,-2.79687 0.875,-1.54688 2.125,-2.875 1.25,-1.32813 2.25,-1.90625 0.46875,-0.48438 1.34375,-0.48438 0.67187,0 1.1875,0.28125 0.40625,0.26563 1.03125,1.09375 0.625,0.82813 0.9375,1.5 0.0781,0.23438 0.1875,0.625 0.10937,0.375 0.10937,0.92188 l -0.0625,0.89062 q -0.39062,1.3125 -0.39062,2.35938 -0.0625,0.45312 0.0625,0.73437 0.14062,0.26563 0.35937,0.26563 0.15625,0 0.34375,-0.0937 0.20313,-0.0937 0.45313,-0.0937 0.42187,0 0.70312,0.25 0.29688,0.25 0.29688,0.64062 0,0.3125 -0.17188,0.60938 -0.28125,0.64062 -1.0625,1.15625 -0.78125,0.5 -1.45312,0.5 -0.54688,0 -1.04688,-0.5625 -0.5,-0.57813 -0.78125,-1.51563 l -0.1875,-0.73437 -1.15625,1.0625 -0.73437,0.73437 q -0.51563,0.51563 -0.57813,0.60938 -0.15625,0.25 -0.5625,0.48437 -0.40625,0.21875 -1.26562,0.53125 z m 0.85937,-3.0625 q 0.57813,-0.32812 0.96875,-0.79687 0.40625,-0.48438 1.01563,-1.34375 0.14062,-0.20313 0.26562,-0.40625 0.125,-0.20313 0.3125,-0.4375 0.54688,-0.73438 0.78125,-1.17188 0.25,-0.45312 0.375,-0.96875 -0.125,-0.42187 -0.375,-0.78125 -0.23437,-0.375 -0.42187,-0.40625 -0.90625,0 -2.4375,2.10938 -0.15625,0.23437 -0.5,0.8125 -0.32813,0.5625 -0.42188,0.76562 -0.17187,0.21875 -0.4375,1.07813 -0.26562,0.84375 -0.26562,1.09375 0,0.70312 0.40625,0.70312 0.32812,0 0.73437,-0.25 z m 25.32318,0.92188 q 0.21875,0.32812 0.21875,0.60937 0,0.32813 -0.23437,0.57813 -0.21875,0.25 -0.375,0.25 -0.76563,0 -1.71875,-0.35938 -0.9375,-0.375 -0.9375,-1.07812 v -1.98438 q 0,-1.28125 -0.21875,-1.46875 -0.48438,-0.25 -1.28125,0.71875 -0.79688,0.96875 -1.95313,2.89063 -0.45312,0.70312 -0.78125,1.01562 -0.3125,0.29688 -0.5625,0.29688 -0.21875,0 -0.39062,-0.125 -0.98438,-0.28125 -0.98438,-1.125 0,-0.0937 0.0625,-0.40625 0.28125,-1 0.60938,-2.20313 0.34375,-1.21875 0.54687,-2.09375 -0.0937,-0.1875 -0.32812,-0.1875 -0.3125,0 -0.73438,0.32813 -0.125,0.0937 -0.46875,0.29687 -0.32812,0.20313 -0.67187,0.54688 -0.32813,0.32812 -0.6875,0.90625 -0.125,0.23437 -0.4375,0.67187 -1.60938,2.4375 -1.95313,2.75 -0.17187,0.45313 -0.3125,0.64063 -0.14062,0.17187 -0.32812,0.17187 -0.125,0 -0.32813,-0.10937 -0.60937,-0.28125 -0.98437,-0.8125 -0.35938,-0.53125 -0.35938,-1.26563 0,-0.46875 0.28125,-1.90625 0.29688,-1.45312 0.65625,-2.70312 0.25,-0.5 0.39063,-1.0625 0.14062,-0.5625 0.14062,-0.78125 0.10938,-0.60938 0.39063,-1.64063 0.28125,-1.04687 0.42187,-1.15625 0.1875,-0.1875 0.70313,-0.1875 0.34375,0 0.65625,0.14063 0.32812,0.125 0.45312,0.375 0.42188,0.48437 0.42188,1.3125 0,0.76562 -0.3125,1.625 -0.32813,0.73437 -0.8125,2.15625 0,0 0.0625,-0.0781 0.78125,-1.07812 1.98437,-2.42187 0.57813,-0.64063 1.29688,-0.98438 0.71875,-0.35937 1.17187,-0.35937 0.76563,0.125 1.29688,0.75 0.53125,0.625 0.65625,1.70312 0,0.39063 -0.0625,0.95313 -0.0625,0.5625 -0.0937,0.71875 0.125,-0.15625 0.65625,-0.78125 0.53125,-0.625 1.29687,-1.29688 0.70313,-0.54687 1.3125,-0.54687 0.5,0 0.89063,0.42187 0.70312,0.40625 1.09375,1.34375 0.40625,0.92188 0.40625,2.10938 0,0.40625 -0.0312,0.64062 -0.0312,0.21875 -0.0312,0.64063 0,0.4375 0.0937,0.84375 0.10937,0.40625 0.20312,0.71875 z m 4.44238,2.3125 q -1.0625,-0.42188 -1.5625,-1.29688 -0.48437,-0.89062 -0.48437,-2.29687 0,-0.3125 0.0625,-1.15625 0.0312,-0.25 0.0312,-0.59375 0,-0.54688 -0.125,-0.8125 -0.125,-0.28125 -0.45313,-0.57813 -0.0937,-0.0937 -0.45312,-0.40625 -0.34375,-0.32812 -0.3125,-0.48437 v -0.0937 q 0,-0.21875 0.10937,-0.48438 0.10938,-0.28125 0.21875,-0.34375 0.0937,-0.0312 0.375,-0.1875 0.29688,-0.17187 0.45313,-0.10937 0.125,0 0.39062,0.17187 0.28125,0.15625 0.28125,0.28125 0.1875,0.39063 0.98438,-1.25 0.45312,-0.67187 1.21875,-1.32812 0.76562,-0.65625 1.40625,-1 0.23437,-0.10938 1.01562,-0.28125 0.78125,-0.17188 1.23438,-0.17188 0.5,0 1.1875,0.42188 0.6875,0.40625 1.14062,0.89062 0.67188,0.48438 0.67188,1.82813 0,0.79687 -0.25,1.375 -0.125,0.46875 -1.26563,1.45312 -1.14062,0.96875 -1.84375,1.26563 -0.70312,0.15625 -1.5625,0.15625 -0.875,0 -1.1875,-0.15625 -0.21875,-0.125 -0.375,0.10937 -0.14062,0.23438 -0.23437,1.07813 l -0.0312,0.3125 q 0,0.35937 0.15625,0.67187 0.23437,0.39063 0.42187,0.54688 0.1875,0.15625 0.57813,0.15625 l 0.28125,-0.0312 q 0.35937,-0.0312 0.75,-0.34375 0.40625,-0.32813 0.95312,-0.875 0.57813,-0.54688 0.67188,-0.64063 0.15625,-0.3125 0.85937,-0.3125 0.28125,0 0.73438,0.0937 0.32812,0.25 0.32812,0.64063 0,0.54687 -0.51562,1.46875 -0.15625,0.32812 -0.98438,1.09375 -0.8125,0.76562 -1.29687,1.04687 -0.85938,0.48438 -1.90625,0.48438 -0.8125,0 -1.67188,-0.3125 z m 2.375,-7.20313 q 0.76563,-0.20312 1.1875,-0.46875 0.4375,-0.26562 1.01563,-1.07812 0.25,-0.76563 0.0937,-0.92188 -0.1875,-0.1875 -0.45313,-0.1875 -0.3125,0 -0.76562,0.34375 -0.3125,0.0937 -0.875,0.59375 -0.5625,0.5 -0.95313,0.96875 -0.375,0.45313 -0.21875,0.54688 -0.0625,0.10937 0.3125,0.15625 0.39063,0.0469 0.65625,0.0469 z" id="path4094" inkscape:connector-curvature="0" style="fill:#000000;fill-rule:nonzero"></path>
    <path d="M 427.809,138.3307 H 553.08723 V 253.13125 H 427.809 Z" id="path4100" inkscape:connector-curvature="0" style="fill:#000000;fill-opacity:0;fill-rule:evenodd"></path>
    <path d="M 379.751,138.43701 H 505.04235 V 253.24016 H 379.751 Z" id="path4109" inkscape:connector-curvature="0" style="fill:#00fdc8;fill-rule:evenodd"></path>
    <path d="M 379.751,138.43701 H 505.04235 V 253.24016 H 379.751 Z" id="path4111" inkscape:connector-curvature="0" style="fill-rule:evenodd;stroke:#666666;stroke-width:1;stroke-linecap:butt;stroke-linejoin:round"></path>
    <path d="m 299.38583,404.37924 h 70.36065 v -6.68504 l 8.40525,13.37008 -8.40525,13.37007 v -6.68502 h -70.36065 z" id="path4071-3" inkscape:connector-curvature="0" style="fill:#7c7ce0;fill-rule:evenodd;stroke-width:0.79288208"></path>
    <path d="m 506.71874,190.09462 h 70.36065 v -6.68504 l 8.40525,13.37008 -8.40525,13.37007 v -6.68502 h -70.36065 z" id="path4071-6" inkscape:connector-curvature="0" style="fill:#7c7ce0;fill-rule:evenodd;stroke-width:0.79288208"></path>
    <path d="m 506.71875,404.41666 h 70.36065 v -6.68504 l 8.40525,13.37008 -8.40525,13.37007 v -6.68502 h -70.36065 z" id="path4071-6-7" inkscape:connector-curvature="0" style="fill:#7c7ce0;fill-rule:evenodd;stroke-width:0.79288208"></path>
    <flowroot xml:space="preserve" id="flowRoot4272" style="font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:26.66666603px;line-height:1.25;font-family:'Comic Sans MS';-inkscape-font-specification:'Comic Sans MS';text-align:center;letter-spacing:0px;word-spacing:0px;text-anchor:middle;fill:#000000;fill-opacity:1;stroke:none"><flowregion id="flowRegion4274" style="font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:26.66666603px;font-family:'Comic Sans MS';-inkscape-font-specification:'Comic Sans MS';text-align:center;text-anchor:middle"><rect id="rect4276" width="125.97456" height="90.782555" x="379.06781" y="162.45763" style="font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:26.66666603px;font-family:'Comic Sans MS';-inkscape-font-specification:'Comic Sans MS';text-align:center;text-anchor:middle"></rect></flowregion><flowpara id="flowPara4278">Some process</flowpara></flowroot>    <g transform="matrix(0.45555722,0,0,0.45555774,379.751,138.43701)" id="g4082-1" inkscape:transform-center-x="-34.322034" inkscape:transform-center-y="102.9661">
      <clipPath id="clipPath4292">
        <path d="M 0,0 H 275 V 252 H 0 Z" id="path4290" inkscape:connector-curvature="0" style="clip-rule:evenodd"></path>
      </clipPath>
      <image clip-path="url(#p.3-4)" width="275" height="252" x="0" y="0" preserveAspectRatio="none" xlink:href="https://desfontain.es/privacy/images/magic.gif" id="image4080-3" style="fill:#000000"></image>
    </g>
    <rect style="fill:#ffffff" id="rect148" width="28.983051" height="45.762711" x="212.03391" y="388.22034"></rect>
  </g>
</svg>
</center>
<p>By "basically the same", I don't mean "it looks a bit similar". Instead,
remember that the magic you added to the process was <em>randomized</em>. You don't
always get the same output if you run the new process several times. So what
does "basically the same" means in this context? That the <em>probability
distributions</em> are similar. You can get the <em>exact same</em> output with database 1
or with database 2, with similar likelihood.</p>
<p>What does this have to do with privacy? Well, suppose you're a creepy person
trying to figure out whether your target is in the original data. By looking at
the output, you can't be 100% certain of anything. Sure, it could have come from
a database with your target in it. But it could also have come from the exact
same database, without your target. Both options have a similar probability, so
there's not much you can say.</p>
<p>You might have noticed that this definition is not like the ones we've seen
before. We're not saying that the output data satisfies differential privacy.
We're saying that the <em>process</em> does. This is very different from <span>\(k\)</span>-anonymity
and other definitions we've seen. There is no way to look at data and determine
whether it satisfies differential privacy. You have to know the <em>process</em> to
know whether it is "anonymizing" enough.</p>
<p>And that's about it. It's a tad more abstract than other definitions we've seen,
but not that complicated. So, why all the hype? What makes it so awesome
compared to older, more straightforward definitions?</p>

<p>Privacy experts, especially in academia, are enthusiastic about differential
privacy. It was first proposed by Cynthia Dwork, Frank McSherry, Kobbi Nissim
and Adam Smith in 2006<sup id="fnref:papers"><a href="#fn:papers" rel="footnote">1</a></sup>. Very soon, almost all researchers working on
anonymization started building differentially private algorithms. And, as we've
already mentioned, tech companies are also trying to use it whenever possible.
So, why all the hype? I can count three main reasons.</p>
<h2 id="you-no-longer-need-attack-modeling">You no longer need attack modeling</h2>
<p>Remember the previous definitions we've seen? (If not, you're fine, just take my
word for it&nbsp;:D) Why did we need <a href="https://desfontain.es/privacy/k-map.html"><span>\(k\)</span>-map</a> in certain cases, and
<a href="https://desfontain.es/privacy/k-anonymity.html"><span>\(k\)</span>-anonymity</a> or <a href="https://desfontain.es/privacy/delta-presence.html"><span>\(\delta\)</span>-presence</a> in others? To choose the right one,
we had to figure out the attacker's <em>capabilities</em> and <em>goals</em>. In practice,
this is pretty difficult. You might not know exactly what your attacker is
capable of. Worse, there might be <em>unknown unknowns</em>: attack vectors that you
hadn't imagined at all. You can't make very broad statements when you use
old-school definitions. You have to make some assumptions, which you can't be
100% sure of.</p>
<p>By contrast, when you use differential privacy, you get two awesome guarantees.</p>
<ol>
<li>You protect <em>any kind of information about an individual</em>. It doesn't matter
   what the attacker wants to do. Reidentify their target, know if they're in
   the dataset, deduce some sensitive attribute… All those things are protected.
   Thus, you don't have to think about the goals of your attacker.</li>
<li>It works <em>no matter what the attacker knows about your data</em>. They might
   already know some people in the database. They might even add some fake users
   to your system. With differential privacy, it doesn't matter. The users that
   the attacker doesn't know are still protected.</li>
</ol>
<h2 id="you-can-quantify-the-privacy-loss">You can quantify the privacy loss <a name="quantify"></a></h2>
<p>We saw that when using <span>\(k\)</span>-anonymity, <a href="https://desfontain.es/privacy/k-anonymity.html#how-to-choose-k">choosing the parameter</a> <span>\(k\)</span> is pretty
tricky. There is no clear link between which <span>\(k\)</span> to choose and how "private" the
dataset is. The problem is <a href="https://desfontain.es/privacy/l-diversity.html#the-bad-news-policy">even worse</a> with other definitions. This problem is
present in all other definitions we've seen so far.</p>
<p>Differential privacy is much better. When you use it, you can quantify the
<em>greatest possible information gain</em> by the attacker. The corresponding
parameter, usually named <span>\(\varepsilon\)</span>, allows you to make very strong statements.
Suppose <span>\(\varepsilon=1.1\)</span>. Then, you can say: "an attacker who thinks their target
is in the dataset with probability 50% can increase their level of certainty to
at most 75%."</p>
<p>And do you remember the previous point about attack modeling? It means you can
change this statement in many ways. You can replace "their target is is the
dataset" by anything about one individual. And you can add "no matter what the
attacker knows" if you want to be extra-precise. Altogether, that makes
differential privacy much stronger than all definitions that came before.</p>
<h2 id="you-can-compose-multiple-mechanisms">You can compose multiple mechanisms <a name="composition"></a></h2>
<p>Suppose you have some data. You want to share it with Alex and with Brinn, in
some anonymized fashion. You trust Alex and Brinn equally, so you use the same
definition of privacy for both of them. They are not interested in the same
aspects of the data, so you give them two different versions of your data. Both
versions are "anonymous", for the definition you've chosen.</p>
<p>What happens if Alex and Brinn decide to conspire, and compare the data you gave
them? Will the union of the two anonymized versions still be anonymous? It turns
out that for most definitions of privacy, this is not the case. If you put two
<span>\(k\)</span>-anonymous versions of the same data together, the result won't be
<span>\(k\)</span>-anonymous. So if Alex and Brinn conspire, they might be able to reidentify
users on their own… or even reconstruct all the original data! That's definitely
not good news.</p>
<p>If you used differential privacy, you get to avoid this type of scenario.
Suppose that you gave differentially private data to Alex and Brinn. Each time,
you used a parameter of <span>\(\varepsilon\)</span>. Then if they conspire, the resulting data
is still protected by differential privacy, except that the privacy is now
weaker: the parameter becomes <span>\(2\varepsilon\)</span>. So they gain something, but you
still quantify how much information they got. Privacy experts call this property
<em>composition</em>.</p>
<p>This scenario sounds a bit far-fetched, but composition is super useful in
practice. Organizations often want to do many things with data. Publish
statistics, release an anonymized version, train machine learning algorithms…
Composition is a way to stay in control of the level of risk as new use cases
appear and processes evolve.</p>

<p>I hope the basic intuition behind differential privacy is now clear. Want a
one-line summary? Uncertainty in the process means uncertainty for the attacker,
which means better privacy.</p>
<p>I also hope that you're now wondering <em>how it actually works</em>! What hides behind
this magic that makes everything private and safe? Why does differential privacy
have all the awesome properties I've mentioned? What a coincidence! That's the
topic of a <a href="https://desfontain.es/privacy/differential-privacy-in-more-detail.html">follow-up article</a>, which tries to give more details while still
staying clear of heavy math.</p>


  </div></div>]]>
            </description>
            <link>https://desfontain.es/privacy/differential-privacy-awesomeness.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23878536</guid>
            <pubDate>Sat, 18 Jul 2020 02:59:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Computation Graphs and Graph Computation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23878381">thread link</a>) | @bmc7505
<br/>
July 17, 2020 | http://breandan.github.io/2020/06/30/graph-computation/ | <a href="https://web.archive.org/web/*/http://breandan.github.io/2020/06/30/graph-computation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p><span>30 Jun 2020</span></p><p>Research has begun to reveal many algorithms can be expressed as matrix multiplication, suggesting an unrealized connection between linear algebra and computer science. I speculate graphs are the missing piece of the puzzle. Graphs are not only useful as cognitive aides, but are suitable data structures for a wide variety of tasks, particularly on modern parallel processing hardware.</p>

<p>In this essay, I explore the virtues of graphs, algebra, types, and show how these concepts can help us reason about programs. I propose a computational primitive based on graph signal processing, linking software engineering, graphs, and linear algebra. Finally, I share my predictions for the path ahead, which I consider to be the start of an exciting new chapter in computing history.</p>

<p><em>n.b.: None of these ideas are mine alone. Shoulders of giants. Follow the links and use landscape mode for optimal reading experience.</em></p>

<ul>
  <li><a href="#new-decade-new-delusions">Biographical details</a></li>
  <li><a href="#what-are-graphs">Graph applications</a></li>
  <li><a href="#induction-introduction">Inductive languages</a></li>
  <li><a href="#graphs-inductively">Inductive graphs</a></li>
  <li><a href="#graph-computation/#graph-languages">Graph languages</a></li>
  <li><a href="#graphs-computationally">Dynamical systems on graphs</a></li>
  <li><a href="#graphs-efficiently">Efficient implementations</a></li>
  <li><a href="#programs-as-graphs">Partial evaluation and program synthesis</a></li>
  <li><a href="#roadmap">Future roadmap</a></li>
</ul>



<p>Over the last decade, I bet on some strange ideas. A lot of people I looked up to at the time laughed at me. I’ll bet they aren’t laughing anymore. I ought to thank them one day, because their laughter gave me a lot of motivation. I’ve said some idiotic things to be sure, but I’ve also made some laughable predictions that were correct. Lesson learned: aim straighter.</p>

<p>In 2012, I was in Austin sitting next to an ex-poker player named <a href="https://twitter.com/amirpc">Amir</a> who was singing Hinton’s praises. Hypnotized by his technicolor slides, I quit my job in a hurry and started an educational project using speech recognition and restricted Boltzmann machines. It never panned out, but I learned a lot about ASR and Android audio. Still love <a href="http://breandan.net/2014/02/09/the-end-of-illiteracy/">that idea</a>.</p>

<center>
<a href="https://www.cs.toronto.edu/~hinton/csc2535/notes/lec4new.pdf"><img width="75%" src="http://breandan.github.io/images/rbm.png"></a>
</center>

<p>In 2017, I started writing a book on the ethics of automation and <a href="http://breandan.net/2017/02/02/trust-in-automation/">predicted</a> mass unemployment and social unrest. Although I got the causes wrong (pandemic, go figure), the information economy and confirmation bias takes were all dead right. Sadly, this is now driving the world completely insane. Don’t say I warned you, go out and fix our broken systems. The world needs more engineers who care.</p>

<center>
<a href="https://colah.github.io/posts/2015-09-NN-Types-FP/"><img width="75%" src="http://breandan.github.io/images/diff_prog.png"></a>
</center>

<p>In 2017, I witnessed the birth of <a href="https://colah.github.io/posts/2015-09-NN-Types-FP/">differentiable programming</a>, which I stole from Chris Olah and turned into a <a href="https://github.com/breandan/kotlingrad/blob/master/latex/thesis/thesis.pdf">master’s thesis</a>. Had a lot of trouble convincing people that classical programs could be made differentiable, but look at the proceedings of any machine learning conference today and you’ll find dozens of papers on differentiable sorting and rendering and simulation. Don’t thank me, thank Chris and the Theano guys.</p>

<p>In 2018, I correctly predicted Microsoft would acquire GitHub to mine code. Why MS and not Google? I’ll bet they tried, but Google’s leadership had fantasies of AGI and besides JetBrains, MS were the only ones who gave a damn about developers. Now ML4SE is a thriving <a href="https://ml4se.github.io/">research area</a> and showing up in <a href="https://github.com/JetBrains-Research/DeepBugsPlugin">real</a> <a href="https://devblogs.microsoft.com/visualstudio/ai-assisted-intellisense-for-your-teams-codebase/">products</a>, much to the chagrin of those who believed ML was a fad. I suspect their hype filter blinded them to the value those tools provide.</p>

<center>
<blockquote><p lang="en" dir="ltr">Prediction: MS will acquire GH within five years. If the <a href="https://twitter.com/hashtag/ML4Code?src=hash&amp;ref_src=twsrc%5Etfw">#ML4Code</a> stuff delivers for MS, acquisition is highly likely. Although it would have been cheaper a few years ago. <a href="https://t.co/5ZMtiRtifD">https://t.co/5ZMtiRtifD</a> <a href="https://t.co/TaxkArm5ps">https://t.co/TaxkArm5ps</a></p>— breandan (@breandan) <a href="https://twitter.com/breandan/status/993553301927936001?ref_src=twsrc%5Etfw">May 7, 2018</a></blockquote> 

<a href="https://blogs.microsoft.com/blog/2018/10/26/microsoft-completes-github-acquisition/">
<img width="75%" src="http://breandan.github.io/images/microsoft_github_aquisition.png"></a>
</center>

<p>But to heck with everything I’ve said! If I had just one idea to share with these ML people, it would be types. Beat that drum as loud as I could. Types are the best tool we know for synthetic reasoning. If you want to build provably correct systems that scale on real-world applications, use types. Not everyone is convinced yet, but mark my words, <a href="https://github.com/tensorflow/tensorflow/issues/12345">types</a> are <a href="https://docs.python.org/3.9/whatsnew/3.9.html#pep-585-builtin-generic-types">coming</a>. Whoever figures out how to connect types and learning will be the next Barbara Liskov or Frances Allen.</p>

<p>This year, I predicted the pandemic weeks before the lockdown, exited the market, and turned down a job at Google. Some people called me crazy. Now I’m going all-in on some new ideas (none of which are mine). I’m making some big bets and some will be wrong, but I see the very same spark of genius in them.</p>



<p>As a kid, I was given a book on the history of mathematics. I remember it had some interesting puzzles, including one with <a href="https://en.wikipedia.org/wiki/Seven_Bridges_of_K%C3%B6nigsberg">some bridges</a> in a town divided by rivers, once inhabited by a man called Euler. Was there a tour crossing each bridge exactly once? Was it possible to tell without checking every path? I remember spending days trying to figure out the answer.</p>

<center>
<a href="https://en.wikipedia.org/wiki/Seven_Bridges_of_K%C3%B6nigsberg"><img width="60%" src="http://breandan.github.io/images/konigsberg_bridges.png"></a>
</center>

<p>In the late 90s, my mom and I went to Ireland. I remember visiting Trinity College, and learning about a mathematician called <a href="https://en.wikipedia.org/wiki/William_Rowan_Hamilton">Hamilton</a> who discovered a famous formula connecting algebra and geometry, and carved it onto a <a href="https://en.wikipedia.org/wiki/Broom_Bridge">bridge</a>. We later visited the bridge, and the tour guide pointed out the stone, which we touched for good luck. The Irish have a <a href="https://en.wikipedia.org/wiki/Poulnabrone_dolmen">thing</a> for <a href="https://en.wikipedia.org/wiki/Newgrange">stones</a>.</p>

<center>
<a href="http://www.kurims.kyoto-u.ac.jp/EMIS/classics/Hamilton/PRIAIcos.pdf"><img width="40%" src="http://breandan.github.io/images/quaternions.jpg"></a>
</center>

<p>In 2007, I was applying to college and took the train from Boston to South Bend, Indiana, home of the Fighting Irish. Wandering about, I picked up a magazine article by a Hungarian mathematician called <a href="https://en.wikipedia.org/wiki/Albert-L%C3%A1szl%C3%B3_Barab%C3%A1si">Barabási</a> then at Notre Dame, who had some interesting things to say about <a href="https://en.wikipedia.org/wiki/Complex_network">complex networks</a>. Later in 2009, while studying in Rochester, I <a href="http://breandan.github.io/images/complex_network_seminar.png">carpooled</a> with a <a href="https://avesis.medeniyet.edu.tr/hasan.guclu">nice professor</a>, and learned complex networks are found in brains, languages and many marvelous places.</p>

<center>
<a href="https://barabasi.com/f/226.pdf"><img width="75%" src="http://breandan.github.io/images/complex_networks.png"></a>
</center>

<p>Fast forward to 2017. I was lured by the siren song of algorithmic differentiation. Olivier Breleux presented <a href="https://github.com/mila-iqia/myia">Myia</a> and <a href="https://github.com/breuleux/buche">Buche</a>. Matt Johnson gave a talk on <a href="https://github.com/HIPS/autograd">Autograd</a>. I met Chris Olah in Long Beach, who gave me the idea to study <a href="https://colah.github.io/posts/2015-09-NN-Types-FP/">differentiable programming</a>. I stole his idea, dressed it up in Kotlin and traded it for a POPL workshop paper and later a <a href="https://github.com/breandan/kotlingrad/blob/master/latex/thesis/thesis.pdf">Master’s thesis</a>. Our contributions were using algebra, shape inference and presenting AD as term rewriting.</p>

<center>
<a href="https://github.com/breandan/kotlingrad#dataflow-graphs"><img width="75%" src="https://github.com/breandan/kotlingrad/raw/master/samples/src/main/resources/dataflow.svg"></a>
</center>

<p>In 2019, I joined a lab with a <a href="https://www.cs.mcgill.ca/~jguo/">nice professor</a> at McGill applying knowledge graphs to software engineering. Like logical reasoning, knowledge graphs are an idea from the first wave of AI in the 1960s and 70s which have been revived and studied in light of recent progress in the field. I believe this is an important area of research with a lot of potential. Knowledge and traceability plays a big role in software engineering, and it’s the bread-and-butter of a good IDE. The world needs better IDEs if we’re ever going to untangle this mess we’re in.</p>

<center>
<a href="https://structurizr.com/"><img width="45%" src="https://raw.githubusercontent.com/cecuesta/structurizr-java/master/docs/images/graphviz-spring-petclinic-components.png"></a>
</center>

<p>This Spring, I took a fascinating seminar on <a href="https://cs.mcgill.ca/~wlh/comp766/index.html">Graph Representation Learning</a>. A lot of delightful graph theory has been worked out over the last decade. <a href="https://en.wikipedia.org/wiki/PageRank">PageRank</a> turned into power iteration. People have discovered many interesting connections to linear algebra, including Weisfeiler-Lehman graph kernels, graph Laplacians, Krylov methods, and spectral graph theory. These ideas have deepened our understanding of graph signal processing and its applications for learning and program analysis. More on that <a href="#graphs-computationally">later</a>.</p>



<p>Graphs are general-purpose data structures used to represent a variety of data types and procedural phenomena. Unlike most sequential languages, graphs are capable of expressing a much richer family of relations between entities, and are a natural fit for many problems in computer science, physics, biology and mathematics. Consider the following hierarchy of data structures, all of which are graphs with increasing expressive power:</p>

<ul>
  <li><strong>Sets</strong>: datasets, multisets, posets, alphabets</li>
  <li><strong>Sequences</strong>: Lists, strings, arrays, linear function composition</li>
  <li><strong>Trees</strong>: <a href="https://en.wikipedia.org/wiki/Abstract_syntax_tree">Abstract syntax</a>, <a href="https://en.wikipedia.org/wiki/Document_Object_Model">XML</a>, <a href="https://en.wikipedia.org/wiki/Phylogenetic_tree">phylogeny</a>, <a href="https://en.wikipedia.org/wiki/Decision_tree">decision trees</a></li>
  <li><strong>DAGs</strong>: <a href="https://eagain.net/articles/git-for-computer-scientists/">Git</a>, <a href="https://en.wikipedia.org/wiki/Citation_network">citations</a>, <a href="https://en.wikipedia.org/wiki/Dependency_graph">dependency graphs</a>, <a href="https://en.wikipedia.org/wiki/Workflow_management_system">workflows</a>, <a href="https://en.wikipedia.org/wiki/Control-flow_graph">control flow</a>, <a href="https://en.wikipedia.org/wiki/Multilayer_perceptron">MLPs</a></li>
  <li><strong>Directed graphs</strong>: <a href="https://en.wikipedia.org/wiki/Finite-state_machine">State machines</a>, <a href="http://dkeenan.com/Lambda/">λ-calculus</a>, <a href="https://computersciencewiki.org/index.php/The_web_as_a_directed_graph">the web</a>, <a href="https://en.wikipedia.org/wiki/Call_graph">call graphs</a>, <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">RNNs</a></li>
  <li><strong>Hypergraphs</strong>: <a href="https://arxiv.org/pdf/2003.02320.pdf">Knowledge</a>, <a href="https://zettelkasten.de/">Zettelkasten</a>, <a href="https://en.wikipedia.org/wiki/Category_theory">categories</a>, <a href="https://writings.stephenwolfram.com/2020/04/finally-we-may-have-a-path-to-the-fundamental-theory-of-physics-and-its-beautiful/">physics</a>, <a href="https://openreview.net/pdf?id=rkpACe1lx">hypernetworks</a></li>
</ul>

<p>As we realized in <a href="https://github.com/breandan/kotlingrad">Kotlin∇</a>, directed graphs can be used to model mathematical expressions, as well as other formal languages, including source code, intermediate representations and binary artifacts. Not only can graphs be used to describe extant human knowledge, many recent examples have shown that machines can “grow” trees and graphs for various applications, such as program synthesis, mathematical deduction and physical simulation. Recent neuro-symbolic applications have shown promising early results in graph synthesis:</p>

<ul>
  <li><a href="https://arxiv.org/pdf/1711.00740.pdf">Learning to Represent Programs with Graphs</a>, Allamanis et al., 2018</li>
  <li><a href="https://arxiv.org/pdf/1912.01412.pdf">Deep Learning for Symbolic Mathematics</a>, Lample and Charton, 2019.</li>
  <li><a href="https://arxiv.org/pdf/2006.11287.pdf">Discovering Symbolic Models from Deep Learning with Inductive Biases</a>, Cranmer et al., 2020.</li>
  <li><a href="https://arxiv.org/pdf/2005.11212.pdf">Symbolic Pregression: Discovering Physical Laws from Raw Distorted Video</a> (Udrescu &amp; Tegmark, 2020).</li>
  <li><a href="https://arxiv.org/pdf/2006.08381.pdf">DreamCoder: Growing generalizable, interpretable knowledge with wake-sleep Bayesian program learning</a>, Ellis et al., 2020.</li>
  <li><a href="https://arxiv.org/abs/2007.03629">Strong Generalization and Efficiency in Neural Programs</a>, Li et al., 2020.</li>
  <li><a href="https://arxiv.org/pdf/1910.10593.pdf">Neural Execution of Graph Algorithms</a>, Veličković et al. (2020)</li>
</ul>

<p>The field of natural language processing has also developed a rich set of graph-based representations, such as <a href="https://en.wikipedia.org/wiki/Phrase_structure_grammar">constituency</a>, <a href="https://en.wikipedia.org/wiki/Dependency_grammar">dependency</a>, <a href="https://en.wikipedia.org/wiki/Link_grammar">link</a> and other and other typed attribute grammars which can be used to reason about syntactic and semantic relations between natural language entities. Research has begun to show many practical applications for such grammars in the extraction and organization of human knowledge stored in large text corpora. Those graphs can be further processed into ontologies for logical reasoning.</p>

<center>
<img width="60%" src="https://upload.wikimedia.org/wikipedia/commons/8/8e/Thistreeisillustratingtherelation%28PSG%29.png">
</center>

<p>Using coreference resolution and entity alignment techniques, we can reconstruct internally consistent relations between entities, which capture cross-corpus consensus in natural language datasets. When stored in <a href="https://arxiv.org/pdf/2003.02320.pdf">knowledge graphs</a>, these relations can be used for information retrieval and question answering, e.g. on wikis and other content management systems. Recent techniques have shown promise in automatic knowledge base construction (cf. <a href="https://www.mitpressjournals.org/doi/pdf/10.1162/tacl_a_00088">Reddy et al.</a>, 2016).</p>

<!--![logical_forms](/images/logical_forms.png) -->
<center>
<a href="https://arxiv.org/pdf/2003.02320.pdf"><img width="75%" src="http://breandan.github.io/images/knowledge_graph.png"></a>
</center>

<p>Lo and behold, the key idea behind knowledge graphs is our old friend, types. Knowledge graphs are multi-relational graphs whose nodes and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://breandan.github.io/2020/06/30/graph-computation/">http://breandan.github.io/2020/06/30/graph-computation/</a></em></p>]]>
            </description>
            <link>http://breandan.github.io/2020/06/30/graph-computation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23878381</guid>
            <pubDate>Sat, 18 Jul 2020 02:20:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Birds, Planes, and Covid’s Chokepoint]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23878263">thread link</a>) | @secondbreakfast
<br/>
July 17, 2020 | https://secondbreakfast.co/birds-planes-and-covid-s-chokepoint | <a href="https://web.archive.org/web/*/https://secondbreakfast.co/birds-planes-and-covid-s-chokepoint">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>On January 22, 1970, a Pan Am Boeing 747 touched down at Heathrow for the first time.<a href="#footnote-10TY" id="ref-10TY"><sup>1</sup></a> It was the 747’s first commercial flight. At the time, British Airways had 11 of the jumbo jets on order.</p>
<p>I’ve always wanted to ride on one. I’m too late.</p>
<p>British Airways announced yesterday they’re retiring their entire 747 fleet. Permanently. Its cousins are also in trouble: the double-decker <span>A380</span> is grounded worldwide.</p>
<p>Landing slots at Heathrow are scarce. In 2016, Oman Air bought a single morning slot from Air France for $75 million. So while the 777, <span>A340</span>, and 787 use less than half the fuel per passenger to fly, airlines need jumbo jets to maximize passenger throughput.</p>
<p>Nowadays double-deckers are merely a waste of fuel. Just like a species facing an extinction event, the 747 got wiped out by an economic chokepoint.</p>
<p>Intelligent-designers often cite gaps in the archaeological record as evidence against natural selection. <em>If evolution inched along slowly</em>, they argue, <em>where are the fossils of almost-humans, and almost-almost-humans, and almost-almost-almost humans? Shouldn’t we find skulls of humans with tiny eyes, slightly-less-tiny eyes, all the way up to regular-sized eyes?</em></p>
<p>But evolution doesn’t crawl along in a straight line. Adaptation happens slowly, and then all at once. Chokepoints force the<span></span> <span>“</span>all at once.”</p>
<p>For example, birds in Britain and Denmark have been under attack by asphalt for a century. In Britain, it’s popular to load birdseed into birdfeeders and place them in gardens. Not so in Denmark. Within 40 years, the beaks of British birds have grown 1-2mm longer than their Danish counterparts.<a href="#footnote-20TY" id="ref-20TY"><sup>2</sup></a></p>
<p>For millennia the beaks have stayed the same. And then asphalt, in a mere half century, forced British bird beaks to grow up to 10% longer.</p>
<p>Business follows the same pattern. Innovation prods along slowly. And then one day the economy’s equilibrium gets punctured.</p>
<p>We are in one of those economic chokepoints. The 747 and <span>A380</span> are collateral damage.</p>
<p>What else is facing evolutionary death because of COVID?</p>
<p>It might be better to invert that question. What types of businesses will survive despite COVID? What traits do those businesses have that will spread like memes throughout the economy?</p>
<section>
<hr>
<ol>
<li id="footnote-10TY"><p><a href="http://news.bbc.co.uk/onthisday/hi/dates/stories/january/22/newsid_3725000/3725963.stm">http://news.bbc.co.uk/onthisday/hi/dates/stories/january/22/newsid_3725000/3725963.stm</a><a href="#ref-10TY">↩</a></p></li>
<li id="footnote-20TY"><p><a href="https://www.theguardian.com/environment/2017/oct/19/british-birds-evolve-bigger-beaks-to-use-garden-feeders">https://www.theguardian.com/environment/2017/oct/19/british-birds-evolve-bigger-beaks-to-use-garden-feeders</a><a href="#ref-20TY">↩</a></p></li>
</ol>
</section>
</div></div>]]>
            </description>
            <link>https://secondbreakfast.co/birds-planes-and-covid-s-chokepoint</link>
            <guid isPermaLink="false">hacker-news-small-sites-23878263</guid>
            <pubDate>Sat, 18 Jul 2020 01:53:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Adding Font Fallback to Revery]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23878216">thread link</a>) | @zbaylin
<br/>
July 17, 2020 | https://zachbayl.in/blog/font-fallback-revery.html | <a href="https://web.archive.org/web/*/https://zachbayl.in/blog/font-fallback-revery.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <p><i>And other musings about UTF-8/Unicode</i></p><hr>
      <h2>Background</h2>
      <p>This summer I've had the amazing opportunity to work on Revery/Onivim full time
      as a software intern at Outrun Labs, an experience I'll do a more detailed writeup
      of near the end of the summer.</p>
      <p>One of the goals of the internship was to get font fallback working in Revery
      and Onivim. Font fallback is one of those features that all GUI frameworks nowadays
      simply must have. I'm sure we've all seen the infamous "unknown glyph" mark at least
      once. Seeing ￼ or � might be passable for an emoji here or there, but it's simply
      unacceptable if you're expecting to see your native language on the screen.</p><h2>The Problem</h2>
      <p>Back in the old days, most digital text was represented in ASCII. As far as text encodings
      go, ASCII is pretty much as simple as it gets -- each character is an 8 bit/1 byte
      integer that corresponds to a character. However, that only leaves us with 2<sup>8</sup>
      or 256 characters we can represent. If you're only ever writing English/Latin scripts,
      that's more than enough. The problem with ASCII is its 'A' - "American."</p>

      <p>Eventually UTF-8 and Unicode came along with the ability to represent an arbitrary
      number of characters while still maintaining compatibility with ASCII. Great! Except
      for one thing -- just because Unicode/UTF-8 supports a character doesn't mean any
      given font will contain a glyph for it. Here inlies the problem: <b>barring a very small
      subset, most fonts only have glyphs for one language/script.</b></p>

      <p>As of a couple days ago, if I opened a file in Onivim2 with its default font
      (<a href="https://www.jetbrains.com/lp/mono/">JetBrains Mono</a>) and that file happened
      to contain any Japanese characters, this is what would show up:</p>

      <div>
        <p><img src="https://zachbayl.in/img/blog/onivim2-no-cjk.png"></p><p>Line 132: The string "こんにちは、私の名前はザックです" should appear.
      </p></div>

      <p>I should note that as of now, Onivim2 is in it's alpha stage (soon to be beta!),
      so this kind of bug is to be expected.</p>

      <p>The crux of the issue here is that JetBrains Mono,
      while a great font, does not contain any CJK (Chinese, Japanese, Korean) glyphs. In most
      cases, it's the job of the underlying UI framework to find a font that <i>does</i>
      support these glyphs. Revery should be no different, and the following is how I solved this problem in it.</p>

      <h2>The Solution</h2>
      <p>Luckily we (the Revery team) were far from the first people to encounter this problem.
      Revery's text rendering pipeline looks like this (extremely simplified):</p>

      <div>
        <p><img src="https://zachbayl.in/img/blog/revery-text-render-pipeline.svg"></p><p>If you're interested in learning more about Revery's tech stack, the library's creator (and my boss),
          Bryan Phelps, gave this great talk about it <a href="https://www.youtube.com/watch?v=K3JqNaw0-Us">here</a>.
          Note that some of Revery's tech has changed since then (namely the inclusion of Skia), but the core
          principles are still the same!</p>
      </div>

      <p>This is the most simplified case: we already have a typeface loaded into memory
      and it supports all the glyphs we requested from it. In this case, we ask Harfbuzz,
      a text shaping library, to "shape" the text. In the case where the string is 
      "ABC", this is fairly trivial. However, since a single UTF-8 encoded character can
      take up multiple bytes, the shaping utility that Harfbuzz provides cannot be overstated.
      This is especially true in a language like OCaml/ReasonML, where for historical reasons
      (as described above), it's assumed that all characters in a string take up a single byte.</p>

      <p>A sample output from Harfbuzz can be seen below. For demonstration purposes, I chose to
      shape the string "κόσμε" because each character has a different size</p>
<p><code><pre>-- κόσμε --
- SHAPE: GlyphID: 539 Cluster: 0
- SHAPE: GlyphID: 2690 Cluster: 2
- SHAPE: GlyphID: 305 Cluster: 5
- SHAPE: GlyphID: 541 Cluster: 7
- SHAPE: GlyphID: 304 Cluster: 9
</pre></code></p><p>Here the glyph ID is the corresponding glyph in the string, and the cluster is the
      <i>byte</i> index of the character in the original string. It may not seem like it, but
      these two components are extremely helpful in implementing a fallback solution.</p>

      <p>First, luckily the standard "unknown" glyph ID for all fonts is 0. If Harfbuzz comes
      across a cluster where the font has no corresponding glyph in the table, it will return the glyph
      ID 0. Let's shape the string "ABC😃XYZ"</p>
<p><code><pre>-- ABC😀XYZ --
- SHAPE: GlyphID: 36 Cluster: 0
- SHAPE: GlyphID: 37 Cluster: 1
- SHAPE: GlyphID: 38 Cluster: 2
- SHAPE: GlyphID: 0 Cluster: 3
- SHAPE: GlyphID: 59 Cluster: 7
- SHAPE: GlyphID: 60 Cluster: 8
- SHAPE: GlyphID: 61 Cluster: 9
</pre></code></p><p>As you can see, where the emoji occurs, the glyph ID is 0 (the font here is Arial).
      For our purposes, we'll call any group of 0-glyphs a <b>hole</b>.</p>

      <p>The next important piece of the puzzle is finding a font that can render that glyph.
      Luckily, Skia provides an API for just that: <code>SkFontMgr::matchFamilyStyleCharacter</code>.
      By simply giving it a font family name (one to most closely match), a character, and
      a locale, we can get a font back that is guaranteed to be able to render that character.
      Awesome, right? Now we can create a basic fallback implementation in pseudocode:</p>

<p><code><pre>let glyphsAndClusters = Harfbuzz.shape(string);
let result = [];
for each glyph and cluster pair:
  if glyph == 0:
    let typeface = Skia.matchCharacter(...);
    let character = String.utf8CharacterAt(cluster);
    let newGlyph = Harfbuzz.shape(character);
    add(result, newGlyph); 
</pre></code></p><p>Hooray! It works*!</p>
      
      <p><img src="https://zachbayl.in/img/blog/initial-font-fallback.png">
      </p>

      <p>"What's the asterisk for?" you may be wondering. Well, if only it were that simple! Many
      UTF-8 characters you would think of as a single character are actually multiple. For
      instance, all emoji flags are actually the region codes of the country they represent:
      🇺🇸 is 🇺 🇸, 🇮🇱 is 🇮 🇱, 🇯🇵 is 🇯 🇵 , etc. Fun fact: an old bug in Twitter actually
      counted flags as two of your 140 characters! Surely font shaping algorithms have improved
      since then! Anyway, what happens when we try to render one of these flags in Revery?</p>

      <p><img src="https://zachbayl.in/img/blog/bad-flag-rendering.png">
      </p>

      <p>Dang! To be expected, but annoying nonetheless. Alright, how about we try refactoring
      our API to shape holes together? Unfortunately this algorithm is a bit too long to condense
      into easily understandable pseudocode, but if you're curious, you can check out the actual
      implementation <a href="https://github.com/revery-ui/revery/blob/7e726608280470268651abd3dcdd9be133786974/src/Font/FontCache.re#L168-L318">here</a>.
      Basically, we create a recursive function to group all the contiguous holes together, shape
      the substrings that represent the holes, and reassemble the string into an array of shapes.
      Since OCaml lacks first class UTF-8 support, we had to leverage a library called Zed to find
      the UTF-8 bounds in a string. This complicates things a little bit, but luckily Zed's API
      is pretty easy to understand. Let's test that flag again:</p>

      <p><img src="https://zachbayl.in/img/blog/correct-flag-rendering.png">
      </p>

      <p>Success! Although this may be simplistic compared to the fallback algorithms in Blink or
      Gecko, it's not as far off as you might think! In fact, much of the inspiration I got from
      this algorithm came from <a href="https://chromium.googlesource.com/chromium/src/+/master/third_party/blink/renderer/platform/fonts/README.md#text-shaping">
      this incredibly helpful document</a>. There is a lot of corporate boilerplate that complicates
      the actual underlying algorithm in the Blink source, but the core idea is still the same.</p>

      <p>Not only do we get emoji flags, we also get those Japanese characters we couldn't see
      earlier:</p>

      <p><img src="https://zachbayl.in/img/blog/onivim2-cjk.png">
      </p>

      <p>Beautiful, if I may say so myself 😎.</p>

      <h2>Special Thanks</h2>
      <p>Although this may not seem that complex, this was one of the largest PRs I've ever written for
      Revery. There were a lot of holes (pun intended) that were exposed when we were expecting UTF-8
      strings to "just work"™️. One of the biggest was text wrapping. One of my good friends (the one who introduced me
      to Revery in the first place), <a href="https://ohad.space/">Ohad Rau</a>, wrote the text wrapping
      algorithm initially, and he was extremely helpful in my quest to get the algorithm UTF-8 compliant.</p>

      <p>I also want to thank <a href="https://github.com/bryphe">Bryan Phelps</a> and 
      <a href="https://github.com/glennsl">Glenn Slotte</a> for some algorithm suggestions and improvements.
      Both of them have been immensely helpful not only for this feature, but the entire summer. I've learned
      so much during this summer, and I'm incredibly grateful to Bryan for giving me this opportunity.</p>
    </div></div>]]>
            </description>
            <link>https://zachbayl.in/blog/font-fallback-revery.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23878216</guid>
            <pubDate>Sat, 18 Jul 2020 01:43:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The KyoAni I Felt: The kind touch of K-On and the studio behind it]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23878201">thread link</a>) | @TheAsprngHacker
<br/>
July 17, 2020 | https://dosaylazy.github.io/blog/kyoani-one-year-later.html | <a href="https://web.archive.org/web/*/https://dosaylazy.github.io/blog/kyoani-one-year-later.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
   <section>
    
    <p>
     The kind touch of K-On and the studio behind it
    </p>
    <center>
     July 17, 2020
    </center>
    <figure>
     <video autoplay="" controls="" loop="">
      <source src="https://dosaylazy.github.io/blog/k-on/tenshi-aftermath.mp4" type="video/mp4">
      Your browser does not support the video tag.
     </video>
     <figcaption>
      From left to right: Ritsu, Mugi, Azusa, Yui, Mio
  (Source:
  <a href="https://www.sakugabooru.com/post/show/124436">Sakugabooru</a>)
     </figcaption>
    </figure>
    <p>
     Almost a year has passed since the devastating firebombing of Kyoto Animation
that murdered thirty-six employees and harmed many others. Kyoto Animation,
affectionately known as KyoAni, is an anime studio that has earned the love of
countless fans, and I am proud to include myself among them. KyoAni receives the
devotion it does because it has changed lives for the better, and every KyoAni
fan probably has a story to tell. I first came to know KyoAni from <em>K-On</em>, a
heartfelt show capturing the nostalgic innocence of adolescence through the
youthful adventures of five girls in a band. <em>K-On</em> taught me to appreciate the
fleeting moments of life, and it will always hold a special place in my heart.
    </p>
    <p>
     <em>K-On</em> is an anime created by Kyoto Animation under director Naoko Yamada and
screenwriter Reiko Yoshida, adapted from a manga by Kakifly. <em>K-On</em> follows the
five members of the Sakuragaoka Girls' School's Light Music Club, or <em>keionbu</em>:
Yui Hirasawa on lead guitar, Mio Akiyama on bass, Ritsu Tainaka on drums, Mugi
Kotobuki on keyboard, and their underclassman Azusa Nakano on rhythm guitar.
Over their three years of high school, the girls connect over school life, band
practice, and after-school tea time in the music room, and they become tight
friends.
    </p>
    <figure>
     <video autoplay="" controls="" loop="">
      <source src="https://dosaylazy.github.io/blog/k-on/s2-first-scene.mp4" type="video/mp4">
      Your browser does not support the video tag.
     </video>
     <figcaption>
      The girls reunite on the way to school, ready for their last year together
  (Source:
  <a href="https://www.sakugabooru.com/post/show/12005">Sakugabooru</a>)
     </figcaption>
    </figure>
    <p>
     Truthfully, <em>K-On</em>'s first season is merely mediocre: enjoyable, but not
memorable. <em>K-On</em>'s second season, which depicts senior year for Yui, Mio,
Ritsu, and Mugi, is where it really shines as a poignant tale of friendship and
adolescence. When the girls reunite and banter in the music room before class on
their first day back, you get the feeling that they've all been friends since
forever. However, right from the get-go, there is a tone shift: the atmosphere
is melancholy as the friends plan their exciting year ahead, their last year
together. Time seems to pass slowly as the <em>keionbu</em> spends its remaining months
together bonding even closer, with a field trip to Kansai, a school play of
Romeo and Juliet, and one last school festival performance before graduation.
<em>K-On</em> reminds us to cherish our youth and our time with friends: these days are
limited. However, if we make the most of our time together, even after we go our
separate ways we'll still have the warmth of all the fond memories.
    </p>
    <p>
     I first watched <em>K-On</em> in my junior year of high school. Before, I didn't care
to make memories. I was obsessed with programming language theory and
constructive mathematics, and I single-mindedly focused on learning higher-level
math on my own. I was eager to leave high school so I could study my passions
in college, and I was even thinking about graduate school! However, after I
watched the <em>keionbu</em> spend its carefree days together before saying goodbye, I
felt intense regret and asked myself: How had I been spending my own high school
days? <em>K-On</em> made me realize that I was growing up too fast, there was more to
life than just math, and I was missing out on a lot of memories in a chapter of
life that I would never experience again. First, I wanted to join a school club
of my own. Around the same time, an underclassman sought to found a programming
club, and I helped it grow. Although the programming club obviously didn't turn
out the same as the <em>keionbu</em>, I still made new friends there nonetheless.
<em>K-On</em> also inspired me to pick up the guitar so I could lose myself in music
just as the girls did.
    </p>
    <p>
     <em>K-On</em>'s thoughtful themes and genuine depiction of the joys of adolescence
overwhelmed me: I hadn't seen anything like it before, and I recognized that I'd
experienced something truly special. That was when I took notice of KyoAni and
director Naoko Yamada. As one fan puts it, <a href="https://honeysanime.com/the-history-of-kyoto-animation/">"K-On! really started the tradition
that KyoAni titles would tell the stories of normal people in beautiful ways,
something the studio would begin to be known for."</a> In particular, <em>K-On</em>
was the breakout success for Naoko Yamada, the young talent who would become
known for her works centering around adolescence, including the critically
acclaimed film <em>A Silent Voice</em> (which, I might add, was snubbed in favor of
<em>The Boss Baby</em> in the Western-centric and out-of-touch Oscars). <em>K-On</em> is just
one example of KyoAni's work, which are respected for their high production
quality and loved for their often heartfelt subject matter.
    </p>
    <figure>
     <video autoplay="" controls="" loop="">
      <source src="https://dosaylazy.github.io/blog/k-on/utauyo-miracle.mp4" type="video/mp4">
      Your browser does not support the video tag.
     </video>
     <figcaption>
      Yui instructs the others how to perform her dance
    (Source:
    <a href="https://www.sakugabooru.com/post/show/124352">Sakugabooru</a>)
     </figcaption>
    </figure>
    <p>
     The humanity of KyoAni's fiction parallels that of its reality, a rare beacon in
the infamously harsh anime industry. The studio has its own animator training
school, pays its employees a salary instead of per frame, and provides maternity
leave to support its female employees. These conditions pay back as animators
can focus on quality over quantity and KyoAni can maintain in-house talent and
develop its own style. <a href="https://blog.sakugabooru.com/2018/08/25/the-evolution-of-kyoto-animation-a-unique-anime-studio-and-its-consistent-vision/">KyoAni eventually achieved the financial independence to
run its own production committees so that creators may be in charge of their
works.</a> Not only does KyoAni shine through its anime, it is also a one-of-a-kind in
the anime industry.
    </p>
    <p>
     I remember when I woke up on July 18 and found KyoAni in the international news.
I remember learning the horrific details of the massacre, feeling overwhelmed
by the Western media coverage of varying quality, and getting angry at the
misinformed commentary from unfamiliar outsiders. There couldn't have been a
greater contrast between KyoAni's innocence and its tragedy. I asked: Oh,
KyoAni, why did this have to happen to you?
    </p>
    <p>
     But, I also remember the show of love that KyoAni fans around the world
sent the ravaged studio in the aftermath of the attack. <a href="https://www.reuters.com/article/us-kyoto-animation-fire-money/donations-top-30-million-for-kyoto-animation-arson-victims-in-japan-idUSKBN1YV0MR">KyoAni received $30
million in donations</a> and <a href="https://soranews24.com/2019/11/15/kyoto-animation-has-a-touchingly-kind-plan-to-distribute-its-3-2-billion-yen-in-arson-donations/">selflessly reserved all the money to compensate the victims and their
families, and none of it for rebuilding the business</a>. Even in the face of death and destruction, KyoAni stood strong with dignity
and compassion. I want to see KyoAni recover and grow and succeed. KyoAni
constantly inspires me to become a kinder person, and countless fans have
personal stories of the studio's positive impact. I hope that even more people
discover the goodness of KyoAni.
    </p>
    <p>
     You know, there's a phenomenon where you don't realize who you have to be
thankful for until they're gone. I'm reminded of a certain <em>K-On</em> episode: When
the music room is closed off for repairs, the <em>keionbu</em> must relocate so it can
prepare for its upcoming concert. Unable to practice in their new locations, the
girls brainstorm song ideas instead. When the music room finally reopens, they
realize not to take for granted what they already have.
    </p>
    <p>
     Later, Yui's doting sister Ui Hirasawa overworks herself caring for Yui and
comes down with a cold. As Ui languidly lies in bed with a fever, Yui endeavors
to repay her sister for her kindness over all the years by preparing a meal,
only to find that cooking is hard! When Ui awakens the next morning, she
discovers Yui fast asleep at her desk with a sheet of lyrics. Yui had stayed up
late writing a new song for the concert devoted to her sister: <em>U&amp;I</em>.
    </p>
    <figure>
     
    </figure>
    <blockquote>
     <p>
      <em>I had thought that it was ordinary to have you by my side</em><br>
<em>I had thought that these days would last forever and ever</em><br>
<em>Sorry, now I realize that these days were extraordinary</em><br>
<em>So first, I need to tell you: "Arigatou!"</em>
     </p>
    </blockquote>
    <p>
     Yui Hirasawa, <em>U&amp;I</em>
    </p>
    <p>
     KyoAni, may my feelings reach you: arigatou!
    </p>
   </section>
  </div></div>]]>
            </description>
            <link>https://dosaylazy.github.io/blog/kyoani-one-year-later.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23878201</guid>
            <pubDate>Sat, 18 Jul 2020 01:40:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ShiViz: Gene­r­ate­ comm­uni­ca­tion graphs from dis­tri­but­ed sys­tem exe­cut]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23878123">thread link</a>) | @todsacerdoti
<br/>
July 17, 2020 | http://bestchai.bitbucket.io/shiviz/ | <a href="https://web.archive.org/web/*/http://bestchai.bitbucket.io/shiviz/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
            <h2>
                The <strong>ShiViz</strong> vis­ual­izat­ion engi­ne gene­r­ate­s inter­active comm­uni­ca­tion graphs from dis­tri­but­ed sys­tem exe­cut­ion logs.
            </h2>

            <h3>What am I looking at?</h3>
            <p>
                In the visualization:
                </p><ul>
                    <li>
                        Time flows from top to bottom.
                    </li>
                    <li>
                        The left panel shows the log and the middle panel displays a <a href="http://en.wikipedia.org/wiki/Directed_acyclic_graph">DAG</a> of the partially ordered vector timestamps recorded in the input log.
                    </li>
                    <li>
                        A vertical line with a box at the top is a <strong>process timeline</strong>. This represents a single thread of execution (e.g., a process).
                    </li>
                    <li>
                        Circles on a process timeline are <strong>events</strong> that were executed by the process.
                    </li>
                    <li>
                        Diagonal lines connecting two events represent the
                        <a href="http://en.wikipedia.org/wiki/Happened-before">happened-before</a> relation between the events: the higher of the two events happened <i>before</i> the second event.
                    </li>
                    <li>
                        Dashed lines represent transitive communication edges. These only appear when a process is hidden, and two processes that are not hidden communicated indirectly through this process.
                    </li>
                    <li>
                        Larger circles represent merged local events. These have a number inside of them, indicating the number of events that they represent.
                    </li>
                    <li>
                        Radiating lines that fade out represent communication edges to processes that are currently hidden from view.
                    </li>
                    <li>
                        Each process is associated with a unique color. Log entries in the left column have the corresponding process color. By default, the log entries are sorted in the order in which the entries appear in the graph.
                    </li>
                </ul>
            

            <h3>How do I interact with the visualization?</h3>
            <p>
                The visualization supports the following actions:
                </p><ul>
                  <li>
                        <strong>Show process name or event info</strong>
                        <br>
                        Click on a process box or an event circle.
                    </li>
                    <li>
                        <strong>Hide a process timeline</strong>
                        <br>
                        Click a process box and select "hide". This
                        will remove the process and its timeline from
                        view. You can hide more than one process.
                    </li>
                    <li>
                        <strong>Filter by communication to process(es)</strong>
                        <br>
                        Click a process box and select "filter". The
                        graph will be filtered to show only those
                        processes/events that communicate with the
                        filtered process. You can filter by more than
                        one process.
                    </li>
                  <li>
                        <strong>Expand/collapse non-communicating events</strong>
                        <br>
                        ShiViz collapses adjacent process events not
                        incident on any communication edges into
                        larger circles. Click on one of these nodes
                        and select "expand" to undo this collapsing.
                    </li>
                  <li>
                    <strong>Search for keywords or subgraphs</strong>
                        <br>
                        ShiViz supports keyword search across the
                        parsed fields. Search supports logical
                        connectives and regular expressions. You can
                        also search for subgraphs or communication 
                        topologies of interest. You can search for a 
                        pre-defined structure like broadcast
                        or request-response, or you can define and
                        search for a custom structure.
                    </li>
                 <li>
                    <strong>Show and hide differences between executions</strong>
                        <br>
                        When viewing two executions side-by-side,
                        click on "show differences" to highlight the
                        differences between two executions. Hosts that
                        are not common to both executions are
                        represented as rhombuses. Processes present in
                        both executions have their events compared by
                        the <code>event</code> capture group. Different
                        events are drawn as rhombuses.
                    </li>

                    <li>
                    <strong>Explore execution clusters</strong>
                        <br>
                        For logs with multiple executions, click on the
                        "clusters" tab to separate executions into 
                        different groups based on a chosen metric.

                        Cluster by the number of processes to group
                        executions by the midpoint between the smallest 
                        and largest number of processes.

                        Cluster by execution comparison to see an overview
                        of how executions differ from a selected base.
                    </li>

                    <li>
                    <strong>Search for network motifs</strong>
                        <br>
                        Click on the "motifs" tab to find frequently
                        occurring communication patterns within and
                        across executions. Search for 2, 3 or 4-event
                        motifs that occur in at least 50% of the
                        executions or that appear at least 5 times 
                        within a single execution.
                    </li>
                </ul>
            

            <h3 id="helpsectiontitle">How is this tool useful?</h3>
            <p>
                Here are four use-cases that ShiViz helps to support:
                </p><ul>
                    <li>
                        <strong>Understanding the communication graph.</strong>
                        <br>
                        Quickly scan the graph to identify the presence or absence of certain communication patterns.
                    </li>
                    <li>
                        <strong>Reasoning about ordering in a concurrent or distributed setting</strong>.
                        <br>
                        Visualize concurrency and the happened-before relation to understand if two events occurred concurrently, or if one happened before the other.
                    </li>
                    <li>
                        <strong>Analyzing activity at processes that matter</strong>.
                        <br>
                        Hide processes (and their log lines) for a more focused visualization. Filter by communication to a process to see only those events at other processes that were likely to have influenced the execution of a process you care about.
                    </li>

                    <li>
                      <strong>Execution comparison and
                      differencing</strong>
                      <br>
                      Use ShiViz to process logs containing multiple
                      executions. Compare executions pairwise,
                      side-by-side. Use ShiViz to highlight event and
                      host differences between two executions to
                      understand where the executions diverge.
                    </li>
                </ul>
            

            <h3>What is the input log format to the tool?</h3>

            <p>
                You can specify the log format using a regular expression on the Input page. The regular expression must contain the following three named capture groups:
                </p><ul>
                    <li><strong><code>event</code>:</strong> the description of the event</li>
                    <li><strong><code>host</code>:</strong> the name of the process, thread, or host that executed the event</li>
                    <li><strong><code>clock</code>:</strong> the vector clock associated with the event, in JSON format</li>
                </ul>
            
            <p>
                You can also specify other capture groups other than <code>event</code> to capture <em>fields</em> (such as date, IP, priority) which are shown in the sidebar while hovering over an event in the visualization. These fields, unless sub-groups of the <code>event</code> group, will not be displayed as part of the event message.
            </p>
            <p>
                For example, for a log entry like:
                </p><pre>28/07/14 01:15 PM Event executed<br>process2 {"process1" : time1, "process2" : time2, ..., "processN" : timeN}</pre><p>

                We might have a parser RegExp like:
                </p><pre>(?&lt;date&gt;\d\d/\d\d/\d\d \d\d:\d\d (AM|PM)) (?&lt;event&gt;.*)\n(?&lt;host&gt;\w+) (?&lt;clock&gt;\{.*\})</pre>
            
            <p>
              The capture groups in ShiViz is not standard regexp
              syntax. We recommend using a plain
              <a href="https://www.debuggex.com/">JS regexp tester</a>
              with regular capture groups to develop expressions, and
              name the capture groups afterwards.
            </p>

            <h3>How can I generate logs to use with ShiViz?</h3>
            <p>
              We developed several ShiViz-compatible vector-clock
              instrumentation <a href="https://distributedclocks.github.io/">libraries</a>
              for C/C++/Java/Go systems.
            </p>
            <p>
              In general, you can study the execution of any system
              that produces logs in a format that can be parsed using
              the RegExp mechanism above.
            </p>

            <h3>More information</h3>
              <ul>
                <li><a href="https://bitbucket.org/bestchai/shiviz/src">ShiViz source code</a></li>
                <li>Contact: <a href="http://www.cs.ubc.ca/~bestchai/">Ivan Beschastnikh</a>, bestchai@cs.ubc.ca</li>
                <li><a href="http://homes.cs.washington.edu/~mernst/pubs/debug-distributed-cacm2016-abstract.html">How to cite</a></li>
              </ul>
        </div></div>]]>
            </description>
            <link>http://bestchai.bitbucket.io/shiviz/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23878123</guid>
            <pubDate>Sat, 18 Jul 2020 01:27:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Levandowski files suit against Uber [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 112 | Comments 91 (<a href="https://news.ycombinator.com/item?id=23877872">thread link</a>) | @MrSandman
<br/>
July 17, 2020 | https://ipfs.eternum.io/ipfs/Qmd9PTEtuSrKKtJQw36aNzpjJwZAdCdwCmUn4w21mmq74z/Levandowski-Uber-Complaint-1.pdf | <a href="https://web.archive.org/web/*/https://ipfs.eternum.io/ipfs/Qmd9PTEtuSrKKtJQw36aNzpjJwZAdCdwCmUn4w21mmq74z/Levandowski-Uber-Complaint-1.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://ipfs.eternum.io/ipfs/Qmd9PTEtuSrKKtJQw36aNzpjJwZAdCdwCmUn4w21mmq74z/Levandowski-Uber-Complaint-1.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23877872</guid>
            <pubDate>Sat, 18 Jul 2020 00:48:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Think like a scientist talk like a populist]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23877780">thread link</a>) | @shdc
<br/>
July 17, 2020 | https://shyal.com/blog/think-like-a-scientist-talk-like-a-populist | <a href="https://web.archive.org/web/*/https://shyal.com/blog/think-like-a-scientist-talk-like-a-populist">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    
     

    
    â†�
    <a href="https://shyal.com/">ðŸ�&nbsp;</a>
     
    <!-- if has_fences -->
    <!-- <div><a href='/black'><img src='/Attachments/black.svg'/></a></div> -->
    <!--  end  -->
    <p>18/07/2020</p>
<p>Adapting your language to match that of your audience, in today's world, seems to be growing in importance by the day. Let's contrast two public figures in public appearances that took place yesterday: Fauci vs. Trump.</p>
<h2 id="dr-fauci-vs-populism">Dr Fauci vs Populism</h2>
<p>The rising wave of populism in the U.S has wrought a "distrust of experts". That's a real shame, especially when you don't listen to your infectious disease expert during a Pandemic.</p>
<p><img alt="Pasted image 39.png" src="https://shyal.com/Attachments/Pasted%20image%2039.png"></p>
<p>Dr Fauci literally wrote the book on infectious disease, yet the populists are calling for his head. Why?</p>
<h3 id="they-dont-understand-a-word-he-says">They don't understand a word he says</h3>
<p>I was watching this <a href="https://web.facebook.com/zuck/videos/10112108870243761/">interview</a> of Dr Fauci by Zuck, yesterday. Finally Fauci is given a chance to speak to the people. Yet:</p>
<blockquote>
<blockquote>
<p>"Citizenry"</p>
</blockquote>
</blockquote>
<p>People?</p>
<blockquote>
<blockquote>
<p>"myalgic encephalitis"</p>
</blockquote>
</blockquote>
<p>Feeling too tired to lift an arm or get out of bed?</p>
<blockquote>
<blockquote>
<p>"deleterious consequences"</p>
</blockquote>
</blockquote>
<p>Bad things happen?</p>
<blockquote>
<blockquote>
<p>"i used the word 'comparable' and i think it may have been taken out of context"</p>
</blockquote>
</blockquote>
<p>Then don't say 'comparable'.</p>
<p>Indeed we already have evidence that <a href="https://www.pnas.org/content/early/2020/07/09/2008868117">working memory predicts social-distancing compliance</a>. This is pretty damning evidence: essentially people with lower working memory capacity are unwilling to socially distance themselves as they cannot hold enough variables in mind to accurately assess the pros and cons.</p>
<p>Thus it isn't too much of a leap to theorise that a lower working memory capacity is also linked with a restricted vocabulary, and thus a reduced ability to process Dr Fauci's long, complex sentences which are laiden with technical jargon and advanced vocab.</p>
<p>Or to put it bluntly: the idiots don't understand Dr Fauci.</p>
<h2 id="donald-trump-is-a-communication-wizard">Donald Trump is a communication Wizard</h2>
<p>Scott Adams accurately predicted <a href="https://www.scottadamssays.com/2015/10/23/the-case-for-a-trump-landslide-part-1/">Donal Trump would win the elections in a landslide</a> back in 2015.</p>
<blockquote>
<blockquote>
<p>"Trump is talking directly to peopleâ€™s subconscious. Everything else he says is just a carrier signal." --Scott Adams (<a href="https://www.scottadamssays.com/2015/09/06/how-to-spot-a-wizard/">how to spot a wizard</a>)</p>
</blockquote>
</blockquote>
<p>This is a great example of Trump's communicative Wizardry. On the same Day Dr Fauci was telling the citizenry about myalgic encephalitis and deleterious consequences, Trump did this:</p>
<p><img alt="Pasted image 40.png" src="https://shyal.com/Attachments/Pasted%20image%2040.png"></p>
<p>Trump had the audacity to set up two cranes, to visually demonstrate lifting regulatory weights off the Republican red truck, while regulation still weighing down on the Democrat blue truck. This is pure communication genius, <strong>because any idiot can understand it</strong> and it <strong>communicates to their subconscious</strong>.</p>
<p>By catering to the lowest common denominator, Trump ensures he captures 100% of his potential base. Not a single word is lost. In fact this kind of visual communication transcends language, education level, even culture.</p>
<h2 id="boris-johnson-is-also-a-communication-wizard">Boris Johnson is also a communication Wizard</h2>
<p>In this interview, Johnson shares his communication principles:</p>
<blockquote>
<blockquote>
<p>"What people listen to are short anglo-saxon words that readily correspond to some object in the universe that they can identify. So in other words: talk simply, in plain English, and talk about stuff in the real world." --Boris Johnson</p>
</blockquote>
</blockquote>
<iframe width="560" height="315" src="https://www.youtube.com/embed/oJXyI-gwBNU?start=437" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>Deriding people like Trump or Johnson for their perceived linguistic blunders utterly misses the point. <strong>Their blunders are what makes them accessible.</strong> Their simple language is what makes them understable. Their communicative wizardly is what makes them irresistible to their base.</p>
<h2 id="elon-musk-is-also-a-communication-wizard">Elon Musk is also a communication Wizard</h2>
<p>Those who know me will confirm this to you: i have been a huge Musky for a very long time. Elon Musk is yet another genius at tailoring his communication to his base:</p>
<p><img alt="Pasted image 37.png" src="https://shyal.com/Attachments/Pasted%20image%2037.png"></p>
<p>Musk speaks to engineers, or generally a base with technological interests, so his language is not always as simple as it could be. But when you consider the topics he talks about, you have to admire how accessible he is able to make them. The language is simple, and the topics relate to the real world.</p>
<p><img alt="Pasted image 41.png" src="https://shyal.com/Attachments/Pasted%20image%2041.png"></p>
<p>And then there are his masterpieces of communication, like the Tesla he sent into orbit. Once again, pure communication genius that transcends language and culture.</p>
<p>Or his EDM track:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/hOEWUm6aGPg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<blockquote>
<blockquote>
<p>"Don't doubt your vibe, because it's true." -- Elon Musk</p>
</blockquote>
</blockquote>
<p>A quick glance at Tesla's stock performance since the <a href="https://shyal.com/blog/tesla-stock-bottom-date">tesla stock bottom date</a> will tell you the message was indeed recieved.</p>
<h2 id="idiocracy-had-it-right">Idiocracy had it right</h2>
<p>The movie <a href="https://www.imdb.com/title/tt0387808/">Idiocracy (2006)</a> is a spooky and hilarious foray into a potential future dumbing down of the human race. The main character, from our time, <strong>who's name is "no sure"</strong> wakes up in the future as the <strong>man with the highest IQ. But nobody understands a word he says</strong>.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/sGUNPMPrxvA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>He narrowly manages to save the human race by <strong>showing them</strong> that watering crops with water instead of gatorade is the solution to all their problems.</p>

<p>All the evidence points to dumbing down your language, and communicating visually and symbolically to become an unstoppable communicator. <strong>Think like a scientist and talk like a populist; you will become unstoppable</strong>.</p>
<hr>
<p>Enjoyed this article? <a href="https://twitter.com/shyaldc">Follow me on Twitter</a>.</p>
    </div></div>]]>
            </description>
            <link>https://shyal.com/blog/think-like-a-scientist-talk-like-a-populist</link>
            <guid isPermaLink="false">hacker-news-small-sites-23877780</guid>
            <pubDate>Sat, 18 Jul 2020 00:34:22 GMT</pubDate>
        </item>
    </channel>
</rss>
