<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 28 Aug 2020 12:31:10 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 28 Aug 2020 12:31:10 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Atomic Habits: How to Create Good Habits and Break Bad Ones [audio]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24280805">thread link</a>) | @nonoesp
<br/>
August 26, 2020 | https://gettingsimple.com/atomic-habits | <a href="https://web.archive.org/web/*/https://gettingsimple.com/atomic-habits">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <article>
      
            <div>

                <p>August 26, 2020</p>

                

                

<p>How to create good habits and break bad ones.</p>

<p>This episode is part of the Habits series. In this excerpt from my interview with Scott Mitchell (episode 29), Scott and I discuss what atomic habits are, how to use them to create good habits and break bad ones, how I started implementing them in my daily routine more than a year ago, the difference between flow and deliberate practice, and why you should schedule your leisure time.</p>

<br>
<h2>Links</h2>

<ul>
<li>
<a target="_blank" href="https://docs.google.com/spreadsheets/d/1x2XBeOXjS6tWmF9i_XKaaODwi8Ba69lid2k3YKeLZpo/edit?usp=sharing">Habit tracker sheets template</a>
</li>
<li>
<a target="_blank" href="https://en.wikipedia.org/wiki/Flow_(psychology)">Flow</a>
</li>
<li>
<a target="_blank" href="https://en.wikipedia.org/wiki/Practice_(learning_method)#Deliberate_practice">Deliberate practice</a>
</li>
<li>
<a target="_blank" href="https://jamesclear.com/three-steps-habit-change">How To Start New Habits That Actually Stick</a> by James Clear</li>
<li>
<a target="_blank" href="https://sketch.nono.ma/">Nono's sketches</a>
</li>
</ul>
<h2>Books</h2>

<ul>
<li>
<a target="_blank" href="https://jamesclear.com/atomic-habits">Atomic Habits</a> by James Clear</li>
<li>
<a target="_blank" href="https://www.calnewport.com/books/digital-minimalism/">Digital Minimalism</a> by Cal Newport</li>
<li>
<a href="https://gettingsimple.com/scott-young-ultralearning">Ultralearning</a> by Scott Young</li>
</ul>
<h2>People mentioned</h2>

<ul>
<li>
<a target="_blank" href="https://gettingsimple.com/scott-mitchell">Scott Mitchell</a>
</li>
<li>
<a target="_blank" href="https://jamesclear.com/">James Clear</a>
</li>
<li>
<a target="_blank" href="https://www.scotthyoung.com/">Scott Young</a>
</li>
<li>
<a target="_blank" href="http://calnewport.com/">Cal Newport</a>
</li>
<li>
<a target="_blank" href="https://en.wikipedia.org/wiki/Mihaly_Csikszentmihalyi">Mihaly Csikszentmihalyi</a>
</li>
<li>
<a target="_blank" href="https://en.wikipedia.org/wiki/K._Anders_Ericsson">Anders Ericsson</a>
</li>
</ul>
<h2>Topics</h2>

<ul>
<li>Intro. [0:00]</li>
<li>Atomic habits. [0:43]</li>
<li>How to create good habits (and break bad ones). [2:59]</li>
<li>Don't break the chain. [3:57]</li>
<li>Meditation. [5:41]</li>
<li>Writing. [6:08]</li>
<li>Sketching. [6:32]</li>
<li>Why? [6:53]</li>
<li>Discipline, flow, and deliberate practice. [8:15]</li>
<li>Scheduling your leisure time. [9:47]</li>
<li>Things are not obvious. [11:15]</li>
<li>Outro. [11:57]</li>
</ul>
<p>If you enjoy the podcast, would you please consider <a target="_blank" href="https://itunes.apple.com/us/podcast/getting-simple/id1319158020">leaving a short review</a> on Apple Podcasts/iTunes? It takes less than 60 seconds and really helps.</p>

<p>Theme and exit songs, <em>Sleep</em> and <em>A Loop to Kill For</em>, by Steve Combs under CC BY 4.0.</p>
        
            </div>
        
            </article>
    </div></div>]]>
            </description>
            <link>https://gettingsimple.com/atomic-habits</link>
            <guid isPermaLink="false">hacker-news-small-sites-24280805</guid>
            <pubDate>Wed, 26 Aug 2020 09:40:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vim-Like Layer for Xorg and Wayland]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24280413">thread link</a>) | @ceda_ei
<br/>
August 26, 2020 | https://cedaei.com/posts/vim-like-layer-for-xorg-wayland/ | <a href="https://web.archive.org/web/*/https://cedaei.com/posts/vim-like-layer-for-xorg-wayland/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
        
<h2 id="insert-mode">Insert Mode<a href="#insert-mode" arialabel="Anchor">⌗</a> </h2>
<p><img src="https://cedaei.com/images/insert_mode.jpg" alt="Insert Mode: A keyboard layout similar to normal QWERTYlayout"></p>
<h2 id="normal-mode">Normal Mode<a href="#normal-mode" arialabel="Anchor">⌗</a> </h2>
<p><img src="https://cedaei.com/images/normal_mode.jpg" alt="Normal Mode: A keyboard layout with the alphabet keys replaced with shortcutkey"></p>
<p>Inspired by vim, I wanted to create a layer on top of my keyboard which worked
like a shortcut layer. So, to start off, I found out about XKB<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>. XKB is the
Xorg Keyboard Extension which tells Xorg on how to react to input from
keyboard.  After reading through some source code, I found out that Xorg has
support for function keys F1 - F35<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>. The general idea here was:</p>
<ul>
<li>Create an insert mode layout for text input.</li>
<li>Replace keys with relevant keys in normal mode (e.g. replace j with Down) and
for keys that require executing a command, replace then with a function key
above F12 (e.g. replace q with F13).</li>
<li>Bind all the function keys above F12 to the respective functions.</li>
</ul>
<p>To start off, I began a fresh Xorg session with nothing modifying the keys
(removed <code>xmodmap</code> from startup) and first dumped the current layout into a
file.</p>
<div><pre><code data-lang="bash">xkbcomp $DISPLAY ~/.xkb/insert.xkb
</code></pre></div><p>This was my starting point. I made changes to this file which were common to
both Insert and Normal mode. e.g. replaced <code>Caps Lock</code> with <code>Ctrl</code> and made
<code>Shift+Caps Lock</code> <code>Caps Lock</code>. Also, I unbound <code>Alt_R</code> as a modifier so that I
could use that as a switch between Normal and Insert Mode.</p>
<p>Here is a diff between the original layout and Insert mode.</p>
<pre><code>1323c1321
&lt;     key &lt;CAPS&gt; {         [       Caps_Lock ] };
---
&gt;     key &lt;CAPS&gt; {         [       Control_L,       Caps_Lock ] };
1551c1549
&lt;     modifier_map Lock { &lt;CAPS&gt; };
---
&gt;     modifier_map Control { &lt;CAPS&gt; };
1555d1552
&lt;     modifier_map Mod1 { &lt;RALT&gt; };
</code></pre><p>Next, I copied <code>~/.xkb/insert.xkb</code> to <code>~/.xkb/normal.xkb</code>. I replaced keys as
per the plan.</p>
<p>Here is a diff between Insert mode and Normal mode.</p>
<div><pre><code data-lang="diff">1200c1200
&lt;         symbols[Group1]= [               q,               Q ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F13]
1204c1204
&lt;         symbols[Group1]= [               w,               W ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F14]
1208c1208
&lt;         symbols[Group1]= [               e,               E ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F15]
1212c1212
&lt;         symbols[Group1]= [               r,               R ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F16]
1216c1216
&lt;         symbols[Group1]= [               t,               T ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F17]
1220c1220
&lt;         symbols[Group1]= [               y,               Y ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F18]
1224c1224
&lt;         symbols[Group1]= [               u,               U ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F19]
1228c1228
&lt;         symbols[Group1]= [               i,               I ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Alt_R]
1232c1232
&lt;         symbols[Group1]= [               o,               O ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F20]
1236c1236
&lt;         symbols[Group1]= [               p,               P ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F21]
1244c1244
&lt;         symbols[Group1]= [               a,               A ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F22]
1248c1248
&lt;         symbols[Group1]= [               s,               S ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Delete]
1252c1252
&lt;         symbols[Group1]= [               d,               D ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [BackSpace]
1256c1256
&lt;         symbols[Group1]= [               f,               F ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Home]
1260c1260
&lt;         symbols[Group1]= [               g,               G ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [End]
1264c1264
&lt;         symbols[Group1]= [               h,               H ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Left]
1268c1268
&lt;         symbols[Group1]= [               j,               J ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Down]
1272c1272
&lt;         symbols[Group1]= [               k,               K ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Up]
1276c1276
&lt;         symbols[Group1]= [               l,               L ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Right]
1285c1285
&lt;         symbols[Group1]= [               z,               Z ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F23]
1289c1289
&lt;         symbols[Group1]= [               x,               X ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F24]
1293c1293
&lt;         symbols[Group1]= [               c,               C ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F25]
1297c1297
&lt;         symbols[Group1]= [               v,               V ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F26]
1301c1301
&lt;         symbols[Group1]= [               b,               B ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F27]
1305c1305
&lt;         symbols[Group1]= [               n,               N ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Next]
1309c1309
&lt;         symbols[Group1]= [               m,               M ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Prior]
</code></pre></div><p>At this point, <code>normal.xkb</code> file defines the following layout.</p>
<p><img src="https://cedaei.com/images/normal_mode_unbound.jpg" alt="Normal Mode: A keyboard "></p>
<p>Now, we need a script that switches between layouts. To load an layout in Xorg, we use</p>
<div><pre><code data-lang="bash">xkbcomp ~/.xkb/normal.xkb <span>"</span>$DISPLAY<span>"</span>
</code></pre></div><p>Sway supports this via the input command in the following form.</p>
<div><pre><code data-lang="bash">swaymsg input <span>'*'</span> xkb_file ~/.xkb/normal.xkb
</code></pre></div><p>The following script cycles through the layouts when it is called. It also
allows to add more layouts later (just add them to layouts array and it will
cycle in the order of the array).</p>
<div><pre><code data-lang="bash"><span>#!/usr/bin/env bash
</span><span></span><span># Usage: xkb_swapper.sh [layout_name]</span>

<span>function</span> set_layout<span>()</span> <span>{</span>
	echo <span>"Setting layout to </span>$1<span>"</span>
	<span>if</span> <span>[[</span> -v WAYLAND_DISPLAY <span>]]</span>; <span>then</span>
		swaymsg input <span>'*'</span> xkb_file ~/.xkb/<span>"</span>$1<span>"</span>.xkb
	<span>else</span>
		xkbcomp ~/.xkb/<span>"</span>$1<span>"</span>.xkb <span>"</span>$DISPLAY<span>"</span>
	<span>fi</span>
	echo <span>"</span>$1<span>"</span> &gt; ~/.cache/xkb-curr-<span>"</span>$DISPLAY<span>"</span>
<span>}</span>
layouts<span>=(</span>insert normal<span>)</span>
current_layout<span>=</span><span>$(</span>cat ~/.cache/xkb-curr-<span>"</span>$DISPLAY<span>"</span> <span>||</span> echo <span>""</span><span>)</span>

<span>if</span> <span>[[</span> $1 !<span>=</span> <span>""</span> <span>]]</span>; <span>then</span>
	set_layout <span>"</span>$1<span>"</span>
	exit
<span>fi</span>
<span>if</span> <span>[[</span> $current_layout <span>==</span> <span>""</span> <span>]]</span>; <span>then</span>
	echo <span>"No current layout found!"</span>
	set_layout <span>"</span><span>${</span>layouts[0]<span>}</span><span>"</span>
<span>fi</span>

i<span>=</span><span>0</span>
<span>while</span> <span>[[</span> $i -lt <span>${#</span>layouts[@]<span>}</span> <span>]]</span>; <span>do</span>
	<span>if</span> <span>[[</span> $current_layout <span>==</span> <span>"</span><span>${</span>layouts[$i]<span>}</span><span>"</span> <span>]]</span>; <span>then</span>
		new_idx<span>=</span><span>"</span><span>$((</span>i+1<span>))</span><span>"</span>
		<span>if</span> <span>[[</span> $new_idx -eq <span>${#</span>layouts[@]<span>}</span> <span>]]</span>; <span>then</span>
			set_layout <span>"</span><span>${</span>layouts[0]<span>}</span><span>"</span>
		<span>else</span>
			set_layout <span>"</span><span>${</span>layouts[$new_idx]<span>}</span><span>"</span>
		<span>fi</span>
		exit
	<span>fi</span>
	<span>((</span>i++<span>))</span>
<span>done</span>

echo <span>"Current Layout doesn't exist!"</span>
set_layout <span>"</span><span>${</span>layouts[0]<span>}</span><span>"</span>
</code></pre></div><p>The above script works with all Xorg based DE/WMs as well as Sway (wayland
compositor). I saved it as <code>xkb_swapper.sh</code> in my <code>PATH</code>. Calling the script
without any argument cycles through the layouts. If arguments are passed, the
first argument is taken as layout name and layout is changed to that.</p>
<p>The last step is binding the function keys and <code>Alt_R</code> to commands to execute.
Here are some of the parts of my i3 config that bind the function keys.</p>
<pre><code>bindsym Alt_R exec xkb_swapper.sh
bindsym 0xffca kill
bindsym 0xffcf exec volchange -5
bindsym 0xffd0 exec volchange +5
bindsym 0xffd1 exec brightness -200
bindsym 0xffd2 exec brightness +200
bindsym 0xffcb exec mpc prev
bindsym 0xffcc exec mpc toggle
bindsym 0xffcd exec mpc next
</code></pre><p><code>i3</code> doesn’t seem to accept <code>F13</code> - <code>F35</code> as keynames however it accepts the
keycodes<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.  Here is a small list for easy access.</p>
<pre><code>0xffbe   F1
0xffbf   F2
0xffc0   F3
0xffc1   F4
0xffc2   F5
0xffc3   F6
0xffc4   F7
0xffc5   F8
0xffc6   F9
0xffc7   F10
0xffc8   F11
0xffc9   F12
0xffca   F13
0xffcb   F14
0xffcc   F15
0xffcd   F16
0xffce   F17
0xffcf   F18
0xffd0   F19
0xffd1   F20
0xffd2   F21
0xffd3   F22
0xffd4   F23
0xffd5   F24
0xffd6   F25
0xffd7   F26
0xffd8   F27
0xffd9   F28
0xffda   F29
0xffdb   F30
0xffdc   F31
0xffdd   F32
0xffde   F33
0xffdf   F34
0xffe0   F35
</code></pre>
<p>The script stores the mode in <code>~/.cache/xkb-curr-$DISPLAY</code>. <code>cat</code> that and
wrap in your bar’s config. Here is my config for
<a href="https://github.com/greshake/i3status-rust">i3status-rust</a>.</p>
<div><pre><code data-lang="toml">[[<span>block</span>]]
<span>block</span> = <span>"custom"</span>
<span>command</span> = <span>"echo -en '\\uf11c '; cat ~/.cache/xkb-curr-$DISPLAY"</span>
<span>interval</span> = <span>0.5</span>
</code></pre></div><section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>As always, the <a href="https://wiki.archlinux.org/index.php/X_keyboard_extension">Arch Wiki page on XKB</a> is a nice place to start. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>You can find all the defined keys in <code>/usr/include/X11/keysymdef.h</code>. <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

      </div></div></div>]]>
            </description>
            <link>https://cedaei.com/posts/vim-like-layer-for-xorg-wayland/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24280413</guid>
            <pubDate>Wed, 26 Aug 2020 08:34:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine Learning in Haskell]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24280339">thread link</a>) | @bulla
<br/>
August 26, 2020 | https://tonyday567.github.io/posts/learning/ | <a href="https://web.archive.org/web/*/https://tonyday567.github.io/posts/learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
  <section>
    <article>
      <header>
        
        <div>
          <p><span>
              <i></i>
              <time datetime="2020-07-28T00:00:00+10:00">
                July 28, 2020
              </time>
            </span>
            <span>
              <i></i>
              4-minute read
            </span>
          </p>
          
          

        </div>
      </header>

      <div>
        
        <p>Much advocacy of Haskell, in general, boils down to type-safety and elimination of bugs. How boring. My personal experience is that bugs are trickier in Haskell and I can write bad code in an extraordinary variety of ways.</p>
<p>I don’t code in Haskell to help eliminate bugs. That seems a goal unlikely to produce joy in my code. I write Haskell primarily because in enables me to name things a bit better.</p>
<h2 id="what-is-learning">What is Learning?</h2>
<p>As an example, I came across this quote within the first few pages of a popular online course on machine learning:</p>
<blockquote>
<p>A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E. ~ Tom Mitchell</p>
</blockquote>
<p>Here’s how I unpacked this into types:</p>
<div><pre><code data-lang="haskell"><span>-- | learning is to use experience to change the performance of a task.</span>
<span>newtype</span> <span>Learn</span> f e p <span>=</span>
  <span>Learn</span> { change <span>::</span> (<span>Foldable</span> f) <span>=&gt;</span> <span>Experience</span> f e <span>-&gt;</span> <span>Task</span> e p <span>-&gt;</span> <span>Task</span> e p }

</code></pre></div><p>A common approach to newtypes is to label the unwrapping as a reversal of the newtype (such as <code>unlearn</code> or <code>unLearn</code>) but this misses an important naming opportunity: to use a Learn is to change.</p>
<div><pre><code data-lang="haskell"><span>-- | An experience is set of e's</span>
<span>newtype</span> <span>Experience</span> f e <span>=</span> <span>Experience</span> { set <span>::</span> f e }
</code></pre></div><div><pre><code data-lang="haskell"><span>-- | A task takes an e and measures performance.</span>
<span>newtype</span> <span>Task</span> e p <span>=</span> <span>Task</span> { measure <span>::</span> e <span>-&gt;</span> p } <span>deriving</span> (<span>Profunctor</span>)
</code></pre></div><p>This could be thought of (and coded) as an ordinary function with type (e -&gt; p). The advantage of using a newtype, however, is to highlight the two ways that a task can change:</p>
<ul>
<li>changing the way a task is performed (the <code>e</code>).</li>
<li>changing the way a task is measured (the <code>p</code>).</li>
</ul>
<p>Acting on a learning, you can change the way a task is performed, such as changing parameters of a function, or change the way you view what performance is.</p>
<p>To change the way a task is performed, taking experience into account, is to make progress. Progress is made one step at a time.</p>
<div><pre><code data-lang="haskell"><span>-- | To progress, is to transduce a Task, via a carrier</span>
<span>newtype</span> <span>Progress</span> e p <span>=</span> <span>Progress</span> { step <span>::</span> e <span>-&gt;</span> <span>Task</span> e p <span>-&gt;</span> <span>Task</span> e p}
</code></pre></div><p>Putting these above types together in a useful way, to learn, is then to repeatedly apply a progressive step to a set of experiences.</p>
<div><pre><code data-lang="haskell"><span>-- | to learn, is to make Progress from an Experience.</span>
<span>learn</span> <span>::</span> <span>Progress</span> e p <span>-&gt;</span> <span>Learn</span> f e p
<span>learn</span> p <span>=</span> <span>Learn</span> $ <span>\</span>(<span>Experience</span> e) task <span>-&gt;</span> foldr (step p) task e
</code></pre></div><p>To <code>machine learn</code>, we change the way a <code>machine</code> does a task, based on learning, measuring whether performance improves, and adopt the new way to do a task if it does.</p>
<div><pre><code data-lang="haskell"><span>-- | to improve, given a way to change a task by experience, </span>
<span>--</span>
<span>-- you need to choose the better performace way over an experience set.</span>
<span>improve</span> <span>::</span>
  (<span>Ord</span> (f p), <span>Foldable</span> f, <span>Functor</span> f) <span>=&gt;</span>
  <span>Progress</span> e p <span>-&gt;</span>
  <span>Experience</span> f e <span>-&gt;</span>
  <span>Task</span> e p <span>-&gt;</span>
  <span>Task</span> e p
<span>improve</span> progress es task <span>=</span>
  bool task task' (p' &gt; p)
  <span>where</span>
    task' <span>=</span> change (learn progress) es task
    p <span>=</span> measure task &lt;$&gt; set es
    p' <span>=</span> measure task' &lt;$&gt; set es
</code></pre></div><p>The constraints contained in the above code are mostly based on suggestions from ghc to get a compile, and I didn’t think about them much in drafting. Type constraints provide useful guide-rails for future development of these ideas.</p>
<h2 id="machine-learning-in-haskell">Machine Learning in Haskell?</h2>
<p>In the above example of improving we are left with an <code>Ord (f p)</code> constraint - that the performance over an experience set is ordinal. If we narrow the constraint to a <code>Num (f p)</code>, in other words, assume that the size of the <code>f p</code> is meaningful, then we have wandered in to the traditional numerical methods domain, and can, for example, start to think about gradients to speed up our improvement.</p>
<p>By insisting on useful and concrete names (aka types), Haskell supplies a constrained domain we can further explore.  For example, are there machine learning examples that don’t fit the candidate types and constraints?</p>
<p>Naming things is hard, and other ways of coding tend to avoid the task. Types bring me joy and I shall keep them, thank you very much, and continue to curate collections of them, for fun and profit. In this example, I now have as good a definition of machine learning as you’ll find out in the wild, and my progress on machine learning will be more comprehensive, faster and safer than bashing away in python.</p>
<p>And yet, to a first degree, machine learning in Haskell does not exist, swamped by the easiness of dynamic types. If the promises being made by ML are to be eventually honoured, however, it may need less code bashing and better naming.</p>

      </div>

      
    </article>

    
  
  
  
  </section>

      </div></div>]]>
            </description>
            <link>https://tonyday567.github.io/posts/learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24280339</guid>
            <pubDate>Wed, 26 Aug 2020 08:21:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[German government plans stricter controls for dog owners and breeders]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24280333">thread link</a>) | @jiehong
<br/>
August 26, 2020 | https://www.iamexpat.de/expat-info/german-expat-news/german-government-plans-stricter-controls-dog-owners-and-breeders | <a href="https://web.archive.org/web/*/https://www.iamexpat.de/expat-info/german-expat-news/german-government-plans-stricter-controls-dog-owners-and-breeders">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <!--?xml version="1.0" encoding="UTF-8"?--><p>In future, a dog’s right to exercise could be enshrined in German law. That’s if a new draft ordinance issued by the Federal Ministry of Agriculture is passed. The law also seeks to improve conditions during the transportation of farm animals.</p><h2>New rules for dog owners, breeders and farm animals in Germany</h2><p>According to the draft regulation, which was seen by the German newspaper Rheinische Post, in future dog owners will have to ensure that their animals are walked at least twice a day, for a total of one hour. They will no longer be permitted to leave their dogs home alone all day or keep them chained up outside; a carer will need to check in on the animal “several times a day”.</p><p>Further rules will also apply specifically to dog breeders. The draft law stipulates that breeders be allowed to look after no more than three bitches with puppies at the same time. There will also be new regulations regarding the size and temperature of whelping boxes.&nbsp;</p><p>Shows with dogs that have been overbred to such an extent that they are in pain or no longer able to “behave appropriately” will be banned, as will those featuring animals whose body parts (such as ears or tail) have been “completely or partially amputated” in a manner contrary to animal welfare.&nbsp;</p><p>For farm animals, the new law stipulates that livestock transports within Germany may not exceed four and a half hours if the animals are directly exposed to temperatures of more than 30 degrees.</p><h2>Animals need movement and environmental stimuli</h2><p>The draft law cites “new scientific knowledge about the needs of dogs” as a justification for the stricter rules. Accordingly, animals should be given “a sufficient degree of movement and contact with environmental stimuli.” Federal Agriculture Minister Julia Klöckner said, “<a href="https://www.iamexpat.de/lifestyle/pets-information-germany">Pets</a> are not cuddly toys.”</p><p>When asked how the new laws will be enforced, especially for private dog owners, a spokesperson for the Agriculture Ministry said that the federal states would be responsible - but that they certainly wouldn’t be ringing the doorbell of every dog owner to check up on them. The law is primarily targeting those who keep their dogs outside in kennels. The draft now needs to be coordinated with the 16 federal states and professional associations.&nbsp;</p>
    </div><div>

        
        <div>
            
            <p>
                By clicking subscribe, you agree that we may process your information in accordance with our privacy policy. For more information, please
                <a href="https://www.iamexpat.de/legal/privacy/">visit this page</a>.
            </p>
        </div>
    </div></div>]]>
            </description>
            <link>https://www.iamexpat.de/expat-info/german-expat-news/german-government-plans-stricter-controls-dog-owners-and-breeders</link>
            <guid isPermaLink="false">hacker-news-small-sites-24280333</guid>
            <pubDate>Wed, 26 Aug 2020 08:20:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: AWS Lambda TypeScript Middleware]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24280237">thread link</a>) | @dbartholomae
<br/>
August 26, 2020 | https://dbartholomae.github.io/lambda-middleware/ | <a href="https://web.archive.org/web/*/https://dbartholomae.github.io/lambda-middleware/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
      <section id="main_content">
        <p><img src="https://dbartholomae.github.io/lambda-middleware/assets/lambda-middleware-logo.png" alt="@lambda-middleware"></p>

<p><a href="https://github.com/dbartholomae/lambda-middleware/issues"><img src="https://img.shields.io/github/issues-raw/dbartholomae/lambda-middleware.svg" alt="open issues"></a>
<a href="https://github.com/visionmedia/debug#readme"><img src="https://img.shields.io/badge/debug-blue.svg" alt="debug"></a>
<a href="https://github.com/dbartholomae/lambda-middleware/actions?query=workflow%3A.github%2Fworkflows%2Fbuild.yml"><img src="https://github.com/dbartholomae/lambda-middleware/workflows/.github/workflows/build.yml/badge.svg?branch=main" alt="build status"></a>
<a href="https://codecov.io/gh/dbartholomae/lambda-middleware"><img src="https://codecov.io/gh/dbartholomae/lambda-middleware/branch/main/graph/badge.svg" alt="codecov"></a></p>

<p>This monorepo is a collection of middleware for AWS lambda functions.</p>

<h2 id="middlewares">Middlewares</h2>

<ul>
  <li><a href="https://dbartholomae.github.io/lambda-middleware/packages/class-validator">@lambda-middleware/class-validator</a>: A validation middleware for AWS http lambda functions
based on class-validator.</li>
  <li><a href="https://dbartholomae.github.io/lambda-middleware/packages/compose">@lambda-middleware/compose</a>: A compose function for functional lambda middleware.</li>
  <li><a href="https://dbartholomae.github.io/lambda-middleware/packages/http-error-handler">@lambda-middleware/http-error-handler</a>: An error handler middleware for AWS http lambda
functions.</li>
  <li><a href="https://dbartholomae.github.io/lambda-middleware/packages/ie-no-open">@lambda-middleware/ie-no-open</a>: A middleware for adding the download options no-open header to
AWS lambdas.</li>
  <li><a href="https://dbartholomae.github.io/lambda-middleware/packages/json-serializer">@lambda-middleware/json-serializer</a>: A middleware for AWS http lambda functions to
serialize JSON responses.</li>
  <li><a href="https://dbartholomae.github.io/lambda-middleware/packages/jwt-auth">@lambda-middleware/jwt-auth</a>: A middleware for AWS http lambda functions to verify JWT auth
tokens inspired by express-jwt.</li>
  <li><a href="https://dbartholomae.github.io/lambda-middleware/packages/middy-adaptor">@lambda-middleware/middy-adaptor</a>: An adaptor to use middy middleware as functional
middleware.</li>
  <li><a href="https://dbartholomae.github.io/lambda-middleware/packages/no-sniff">@lambda-middleware/no-sniff</a>: A middleware for adding the content type options no-sniff header
to AWS lambdas.</li>
  <li><a href="https://dbartholomae.github.io/lambda-middleware/packages/http-header-normalizer">@lambda-middleware/http-header-normalizer</a>: Middleware for AWS lambdas that
normalizes headers to lower-case.</li>
  <li><a href="https://dbartholomae.github.io/lambda-middleware/packages/do-not-wait">@lambda-middleware/do-not-wait</a>: AWS lambda middleware to prevent Lambda from timing out
because of processes running after returning a value.</li>
  <li><a href="https://dbartholomae.github.io/lambda-middleware/packages/cors">@lambda-middleware/cors</a>: AWS lambda middleware for automatically adding CORS headers.</li>
</ul>

<h2 id="other-packages">Other packages</h2>

<p>Furthermore there is utility collection available at <a href="https://dbartholomae.github.io/packages/utils">@lambda-middleware/utils</a>.</p>

<h2 id="usage">Usage</h2>

<p>Each middleware is a higher-order function that can be wrapped around the handler function.</p>

<div><div><pre><code><span>export</span> <span>const</span> <span>handler</span> <span>=</span> <span>someMiddleware</span><span>()(()</span> <span>=&gt;</span> <span>{</span>
  <span>return</span> <span>{</span>
    <span>body</span><span>:</span> <span>''</span><span>,</span>
    <span>statusCode</span><span>:</span> <span>200</span>
  <span>}</span>
<span>})</span>
</code></pre></div></div>

<p>Each middleware is build as</p>
<div><div><pre><code><span>(</span><span>options</span><span>)</span> <span>=&gt;</span> <span>(</span><span>handler</span><span>)</span> <span>=&gt;</span> <span>(</span><span>event</span><span>,</span> <span>context</span><span>)</span> <span>=&gt;</span> <span>Response</span>
</code></pre></div></div>

<p>This means that middleware can be composed and piped like any other function with only one parameter (the handler).
This library contains <a href="https://dbartholomae.github.io/lambda-middleware/packages/compose">a helper for composing</a>, but <a href="https://lodash.com/docs/4.17.15#flowRight">any</a>
<a href="https://ramdajs.com/docs/#compose">other</a> <a href="https://github.com/tc39/proposal-pipeline-operator">implementation</a> should
work as well.</p>

<div><div><pre><code><span>export</span> <span>const</span> <span>handler</span> <span>=</span> <span>compose</span><span>(</span>
  <span>someMiddleware</span><span>(),</span>
  <span>someOtherMiddleware</span><span>(),</span>
  <span>aThirdMiddleware</span><span>()</span>
<span>)(()</span> <span>=&gt;</span> <span>{</span>
  <span>return</span> <span>{</span>
    <span>body</span><span>:</span> <span>''</span><span>,</span>
    <span>statusCode</span><span>:</span> <span>200</span>
  <span>}</span>
<span>})</span>
</code></pre></div></div>

<p>Composing middleware is equivalent to calling it nested:</p>
<div><div><pre><code><span>export</span> <span>const</span> <span>handler</span> <span>=</span>
  <span>someMiddleware</span><span>()(</span>
    <span>someOtherMiddleware</span><span>()(</span>
      <span>aThirdMiddleware</span><span>()(()</span> <span>=&gt;</span> <span>{</span>
        <span>return</span> <span>{</span>
          <span>body</span><span>:</span> <span>''</span><span>,</span>
          <span>statusCode</span><span>:</span> <span>200</span>
        <span>}</span>
      <span>})</span>
    <span>)</span>
  <span>)</span>
</code></pre></div></div>

<p>The order of composition can be relevant. When using a helper to do the composition, check, in which order the functions
are applied. Most of the time TypeScript should be able to warn you, if the order is wrong.</p>

<p>Imagine middleware as an onion around your function: The outermost middleware will get called first before the handler
starts, and last after the handler finishes or throws an error. In our example above the order in which middleware gets
executed therefore would be:</p>
<div><div><pre><code>someMiddleware
  someOtherMiddleware
    aThirdMiddleware
      the handler
    aThirdMiddleware
  someOtherMiddleware
someMiddleware
</code></pre></div></div>
<p>This means that middleware which transforms the input for the handler will be executed top to bottom, while middleware
that transforms the response will be called bottom to top.</p>

<h2 id="writing-your-own-middleware">Writing your own middleware</h2>

<p>If you want to write your own middleware, check the existing examples and feel free to borrow some of the tests for
inspiration. The general idea for a middleware is the following:</p>
<div><div><pre><code><span>const</span> <span>myMiddleware</span> <span>=</span> <span>(</span><span>optionsForMyMiddleware</span><span>)</span> <span>=&gt;</span> <span>(</span><span>handler</span><span>)</span> <span>=&gt;</span> <span>async</span> <span>(</span><span>event</span><span>,</span> <span>context</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>try</span> <span>{</span>
    <span>const</span> <span>modifiedEvent</span> <span>=</span> <span>doSomethingBeforeCallingTheHandler</span><span>(</span><span>event</span><span>)</span>
    <span>const</span> <span>response</span> <span>=</span> <span>await</span> <span>handler</span><span>(</span><span>modifiedEvent</span><span>,</span> <span>context</span><span>)</span>
    <span>const</span> <span>modifiedResponse</span> <span>=</span> <span>doSomethingAfterCallingTheHandler</span><span>(</span><span>response</span><span>)</span>
    <span>return</span> <span>modifiedResponse</span>
  <span>}</span> <span>catch</span> <span>(</span><span>error</span><span>)</span> <span>{</span>
    <span>const</span> <span>modifiedError</span> <span>=</span> <span>doSomethingInCaseOfAnError</span><span>(</span><span>error</span><span>)</span>
    <span>throw</span> <span>modifiedError</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>
<p>Usually the same middleware should not need to do something before the handler, after the handler and on error.
Creating separated middlewares for these cases keeps them more versatile. But cases that require multiple steps are
supported as well.</p>

<p>Since the middlewares only uses function composition, TypeScript can offer extensive typing support to let you know
how the middleware changed. When adding your own middleware it is recommended to use generics to avoid losing type
information.</p>

<p>Instead of</p>
<div><div><pre><code><span>const</span> <span>bodyParser</span> <span>=</span> <span>()</span> <span>=&gt;</span>
  <span>(</span><span>handler</span><span>:</span> <span>PromiseHandler</span><span>&lt;</span><span>Omit</span><span>&lt;</span><span>APIGatewayProxyEvent</span><span>,</span> <span>body</span><span>&gt;</span> <span>&amp;</span> <span>{</span> <span>body</span><span>:</span> <span>object</span><span>},</span> <span>APIGatewayProxyResult</span><span>&gt;</span><span>):</span> <span>PromiseHandler</span><span>&lt;</span><span>APIGatewayProxyEvent</span><span>,</span> <span>APIGatewayProxyResult</span><span>&gt;</span> <span>=&gt;</span>
  <span>async</span> <span>(</span><span>event</span><span>:</span> <span>E</span><span>,</span> <span>context</span><span>:</span> <span>Context</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>return</span> <span>handler</span><span>({</span> <span>...</span><span>event</span><span>,</span> <span>body</span><span>:</span> <span>JSON</span><span>.</span><span>parse</span><span>(</span><span>event</span><span>.</span><span>body</span><span>)</span> <span>},</span> <span>context</span><span>)</span>
<span>}</span>
</code></pre></div></div>
<p>use</p>
<div><div><pre><code><span>const</span> <span>bodyParser</span> <span>=</span> <span>()</span> <span>=&gt;</span>
  <span>&lt;</span><span>E</span> <span>extends</span> <span>APIGatewayProxyEvent</span><span>&gt;</span><span>(</span><span>handler</span><span>:</span> <span>PromiseHandler</span><span>&lt;</span><span>Omit</span><span>&lt;</span><span>E</span><span>,</span> <span>body</span><span>&gt;</span> <span>&amp;</span> <span>{</span> <span>body</span><span>:</span> <span>object</span><span>},</span> <span>APIGatewayProxyResult</span><span>&gt;</span><span>):</span> <span>PromiseHandler</span><span>&lt;</span><span>E</span><span>,</span> <span>APIGatewayProxyResult</span><span>&gt;</span> <span>=&gt;</span>
  <span>async</span> <span>(</span><span>event</span><span>:</span> <span>E</span><span>,</span> <span>context</span><span>:</span> <span>Context</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>return</span> <span>handler</span><span>({</span> <span>...</span><span>event</span><span>,</span> <span>body</span><span>:</span> <span>JSON</span><span>.</span><span>parse</span><span>(</span><span>event</span><span>.</span><span>body</span><span>)</span> <span>},</span> <span>context</span><span>)</span>
<span>}</span>
</code></pre></div></div>
<p>so that if multiple middlewares change the event, the resulting type will have all changes and not just the latest.</p>

<h2 id="contributing">Contributing</h2>

<p>If you want to contribute to the project, please read our <a href="https://dbartholomae.github.io/lambda-middleware/CONTRIBUTING.md">contributing guidelines</a> first.</p>

      </section>
    </div></div>]]>
            </description>
            <link>https://dbartholomae.github.io/lambda-middleware/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24280237</guid>
            <pubDate>Wed, 26 Aug 2020 08:01:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thoughts on 2 Years as a Remote Robotics Consultant]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24280204">thread link</a>) | @msadowski
<br/>
August 26, 2020 | https://msadowski.github.io/2-years-remote-consulting/ | <a href="https://web.archive.org/web/*/https://msadowski.github.io/2-years-remote-consulting/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
            <p><img src="https://msadowski.github.io/images/M_consulting_cropped.png" alt="Thoughts on 2 Years as a Remote Robotics Consultant">
              
            </p>
        
      
      <p>It’s that time of year again when I’m thinking back on the journey I set up for myself by deciding to go into Robotics Consulting. This article is a follow up to the blog post I wrote <a href="https://msadowski.github.io/one-year-of-robotics-consulting/">last year</a>. This year, I’ve decided to try and cover the most important aspects of what I’m doing, and how it has been working out for me.</p>

<!-- more -->

<h2 id="the-work-i-had">The work I had</h2>

<p>I’m very grateful for the kind of work that I do - it feels amazing doing what I love and getting paid for it. I would never change my work for anything else. Every single one of my clients has an interesting problem to solve, and I’m yet to get my first negative experience working with someone. Looking back on all my clients, I’ve worked with many interesting people all around the world, mostly helping them to develop software for mobile robots and drones.</p>

<figure>
    <img src="https://msadowski.github.io/images/2_yr_consulting/clients.png" alt="Map with 22 Clients I had all over the world">
    <figcaption>A world map of the 22 clients I've worked with over the past 2 years</figcaption>
</figure>

<figure>
    <img src="https://msadowski.github.io/images/2_yr_consulting/clients_europe.png" alt="Image showing 8 of my clients in Europe">
    <figcaption>My European clients</figcaption>
</figure>

<p>The duration of the projects I take on are between half a day and 2.5 years long. Everything depends on the client and what they require. Most of my projects kick off with a consultation - helping the client to solve a particular problem by sharing my expertise and experience. After this initial phase, some of the clients decide to hire me as a contractor, helping their technical team solve the challenges they face, while others are happy to carry on working by themselves with the advice received.</p>

<p>As a tangent to the consultations, I also help evaluate robotics funding proposals, as a reviewer in EU technological funding projects <a href="http://www.esmera-project.eu/welcome/">ESMERA</a> and <a href="https://trinityrobotics.eu/">TRINITY</a>, making sure your tax euros are spent on truly cutting-edge projects.</p>

<h3 id="putting-myself-in-my-clients-shoes">Putting myself in my clients’ shoes</h3>

<p>Every project I take on, I treat as my own. This results in me trying to solve issues before they happen, and sometimes even pushing back on client’s decisions - “How about we don’t remove this safety feature?”. Another side effect of treating the project as my own is that I put the client first, before my own business interest, meaning I might earn less for the project overall.</p>

<p>As an example, I was hired to test the idea a client had for a robotic project. The idea turned out to be borderline feasible, with currently available technology, but potentially requiring lots of R&amp;D work. If I sold the project as “no problem, it’s totally doable”, I would definitely get more work supporting the R&amp;D work required. By putting the project and client’s interests first, however, we finished the project after the feasibility study, having realised the extent of R&amp;D work needed.</p>

<p>Since terminating such a project before going to an R&amp;D phase is something I would do, I’m content and the client is most likely even more so, since they don’t have to spend lots of money, not understanding the R&amp;D effort required. Instead, they can decide whether to pursue the idea further. If the client does decide to take a risk, they know that I’ll be there, ready to treat their project as my own, and providing honest advice, even if it means I get less work from it.</p>

<h3 id="the-hardware">The hardware</h3>

<p>Working with hardware is one of the most enjoyable parts of my job. This year, I’ve been focusing a lot on RTK solutions (I have one blog post in the works on a neat RTK setup). Also this year, I finally got my hands on a multi-plane LiDAR, something I’ve been very keen on ever since Velodyne revealed their first multi-plane units.</p>

<figure>
    <img src="https://msadowski.github.io/images/2_yr_consulting/hardware.png" alt="Hardware units I've worked with">
    <figcaption> Some of the hardware I've worked with since I started working as a Remote Robotics Consultant</figcaption>
</figure>

<h2 id="the-work-i-did-not-win">The Work I Did Not Win</h2>

<h3 id="the-dream-project">The dream project</h3>

<p>At one point, I was approached by a client who wanted to create a certain type of robot that I’ve always dreamt of working with. The task would require me to liaise with manufacturers and developers to get the robot ready, and enable support for autonomous navigation in various terrain types. In short, a hugely challenging project that would immensely help me grow, whilst being super fun at the same time. When discussing the project in more detail, I noticed that the budget for this client was not an issue - any platform for any price was OK, as long as it met the requirements. However, when asking follow up questions, it became clear that the project target was to equip robots with weapons.</p>

<figure>
<video controls="controls">
    <source src="https://msadowski.github.io/images/2_yr_consulting/bd.mp4" type="video/mp4">
</video>
<figcaption>The kind of project I’m not keen to work on. Source: <a href="https://www.youtube.com/watch?v=y3RIHnK0_NE">Bosstown Dynamics</a> (Corridor Digital)
</figcaption>
</figure>

<p>When I was applying to University, I promised myself I would not work on weapons, even if these projects have a virtually unlimited budget. I figured that even if I was to fold my consultancy, I would rather do that than compromise on my values.</p>

<h3 id="the-bargain">The bargain</h3>

<p>In the two years working as a Robotics Consultant, I’ve noticed a pattern: the more a potential client bargains before starting the job, the more bargaining and complaining will follow, resulting in an unpleasant experience for everyone involved. In the same bucket as bargaining clients are the UpWork projects that want you to create a SLAM library from scratch for a fixed price of $50. These days, I tend to reject these types of clients and contracts straight away, saving everyone’s time.</p>

<h3 id="watch-out-for-the-legal-stuff">Watch out for the legal stuff</h3>

<p>If I’m receiving 25 pages of legal documents to review before engaging with a customer, it’s a  potential red flag. I don’t mind reading legal documents, but I would rather not involve a lawyer before even starting a project. For me, a huge red flag is when a potential client adds a very vaguely described 3-year non-compete clause, covering a whole industry. I find such terms too restrictive and would never take a project on like this, unless the project also paid for a 3 year holiday after wrapping everything up!</p>

<h3 id="the-lack-of-expertise">The lack of expertise</h3>

<p>As much as I would love to know everything about Robotics, it’s not likely to happen anytime soon. I will never take on projects that fall outside of my expertise (for example, algorithms for soft robotics), unless the client is persistent and understands an R&amp;D process. My go-to advice in such cases is that it’s not feasible to pay my high rates for me to catch up on the topic. In a hypothetical situation, if the project falls outside of my expertise, but it’s in an area I’m planning to pursue, I’d offer a very low rate for the project, highlighting that I will need to do some catching up.</p>

<h2 id="remote-robotics">Remote Robotics</h2>

<p>People often ask me how I work on robotics projects remotely (I’ve been doing this since day 1 of my consultancy). When I’m doing some high level work, it’s usually not an issue. It only becomes slightly more problematic with hardware-oriented projects. The options I’ve tested so far are:</p>

<ul>
  <li>For ROS systems, working with bag files, and in the case of drones, working with log files</li>
  <li>Clients shipping the hardware to me</li>
  <li>Travelling to the client’s location</li>
  <li>Remote control</li>
</ul>

<figure>
    <img src="https://msadowski.github.io/images/2_yr_consulting/office.jpg" alt="My office in the times of pandemic">
    <figcaption>Me and my partner's office in the time of the COVID-19 pandemic</figcaption>
</figure>

<p>ROS is absolutely the best thing that happened to people like me - I can easily review things online and even develop software with just <a href="http://wiki.ros.org/rosbag">bagfiles</a>. However, it’s not always feasible to work with bags, especially if you need to do some work related to sensors and actuators. In these cases, clients will often ship their hardware to me, so that I can integrate it locally. A very convenient way to work with clients in this way is to use a temporary import - it saves you the risk of paying taxes and duties for the expensive robotics parts, and as far as I know when doing a temporary import, you can keep the items for up to a year.</p>

<p>Travelling to the client’s location usually results in a couple of days of a hackathon solving issue. I love these, as it allows me to put the faces to Slack usernames, and I like the dynamics of these kinds of projects. On the flip side, the last time I did it, I ended up doing about 60 hours of work in 5 days - not very feasible, especially as you need to rest for a couple of days afterwards, but I would do it again!</p>

<p>Remote control of the client’s desktop is something that I try to avoid as much as possible when working with hardware. I find that not having physical access to the components is often very limiting (“can you please unplug the cable for me?”) and I estimate that in the worst cases, you are 20-40% less productive by working on robotics in this way.</p>

<h2 id="other-thoughts-on-consultancy-and-self-employment">Other Thoughts on Consultancy and Self-Employment</h2>

<h3 id="freedom">Freedom</h3>

<p>Freedom is one of the most important aspects of what I do. If I don’t work with hardware for a project, then I can usually work from whatever place I want. If I have a day when I don’t feel like working, or can’t work, then taking a day off is not an issue. To an extent, I can choose whichever projects to work on (or at least to which I can say “no” to).</p>

<figure>
    <img src="https://msadowski.github.io/images/2_yr_consulting/outdoors.jpg" alt="A mountain view">
    <figcaption>Having a possibility to go out into the mountains in the middle of the week is something I appreciate a lot</figcaption>
</figure>

<p>This freedom, however, comes with a price attached to it - if I’m not working, then I’m not making money. I don’t get bank holidays and if I get sick and can’t work, then I’m not earning either. These are the main reasons why I think working for oneself is not for everybody, especially when having no projects lined up, as it can become quite stressful.</p>

<p>Being self-employed means that you are at the centre of your business. For me, this means that my physical and mental health are my number one priorities. Examples of how I exercise these are:</p>
<ul>
  <li>Three times a week, around 4pm, I do sports (normally, I go to the gym, but during the pandemic, I’ve been going for a run)</li>
  <li>Practising meditation as the first thing I do in the morning</li>
  <li>In case of health issues, I look to fix them without thinking twice about the money (being located in Europe is a huge advantage here as I know no doctor’s visit will ruin me, financially)</li>
</ul>

<h3 id="upwork">Upwork</h3>

<p>Over the past year, most of my work has come from Upwork (you can see my profile <a href="https://www.upwork.com/freelancers/~0196b3ccb97605e632">here</a>). I won’t repeat the things I said <a href="https://msadowski.github.io/one-year-of-robotics-consulting/#upwork">last year</a> - I’ve grown to appreciate the service. I realised that the 20% fee for …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://msadowski.github.io/2-years-remote-consulting/">https://msadowski.github.io/2-years-remote-consulting/</a></em></p>]]>
            </description>
            <link>https://msadowski.github.io/2-years-remote-consulting/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24280204</guid>
            <pubDate>Wed, 26 Aug 2020 07:57:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[High-Resolution Controllable Face Aging with Generative Adversarial Networks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24280145">thread link</a>) | @Despoisj
<br/>
August 26, 2020 | https://despoisj.github.io/AgingMapGAN/ | <a href="https://web.archive.org/web/*/https://despoisj.github.io/AgingMapGAN/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <h2 id="agingmapgan-amgan-high-resolution-controllable-face-aging-with-spatially-aware-conditional-gans">AgingMapGAN (AMGAN): High-Resolution Controllable Face Aging with Spatially-Aware Conditional GANs</h2>



<p>
  <img width="40%" src="https://despoisj.github.io/AgingMapGAN/img/loreal_research.png">
</p>

<h2 id="video-summary">Video Summary</h2>
<iframe width="840" height="472.5" src="https://www.youtube.com/embed/HMZiSVKXkWo" frameborder="0" allow="encrypted-media; picture-in-picture" allowfullscreen=""></iframe>

<h2 id="abstract">Abstract</h2>
<p>Existing approaches and datasets for face aging produce results skewed towards the mean, with individual variations and expression wrinkles often invisible or overlooked in favor of global patterns such as the fattening of the face. Moreover, they offer little to no control over the way the faces are aged and can difficultly be scaled to large images, thus preventing their usage in many real-world applications. To address these limitations, we present an approach to change the appearance of a high-resolution image using ethnicity-specific aging information and weak spatial supervision to guide the aging process. We demonstrate the advantage of our proposed method in terms of quality, control, and how it can be used on high-definition images while limiting the computational overhead.</p>

<h3 id="paper--supplementary-materials">Paper &amp; Supplementary Materials</h3>
<div>
    <p><a href="https://arxiv.org/abs/2008.10960" target="_blank">
            <img src="https://despoisj.github.io/AgingMapGAN/img/paper_thumbnail.jpg">
        </a>
    </p>
    <div>
        <p><span>J. Despois, F. Flament, M. Perrot</span><br>
            <span>
                <b>AgingMapGAN (AMGAN): High-Resolution Controllable Face Aging with Spatially-Aware Conditional GANs.</b>
            </span>
            <br>
            <span>ECCV, 2020 (AIM Workshop Oral)</span>
            <span><a href="https://arxiv.org/abs/2008.10960" target="_blank">[arXiv]</a>&nbsp;<a href="https://despoisj.github.io/AgingMapGAN/bibtex.txt" target="_blank">[BibTeX]</a>&nbsp;<a href="https://despoisj.github.io/AgingMapGAN/supplementary_materials.pdf" target="_blank">[Supplementary Materials]</a></span>
        </p>
    </div>
</div>

<h2 id="model">Model</h2>
<p>Our model takes a patch <em>p</em> from the input image <em>I</em>, a target aging map <em>A</em>, and two orthonogal gradient images <em>X</em> and <em>Y</em>. The image patch <em>I<sub>p</sub></em> is then transformed according to the local aging information contained in the map <em>A<sub>p</sub></em>, while the orthogonal gradients <em>X<sub>p</sub></em> and <em>Y<sub>p</sub></em> provide the coordinates of the patch in a fully-convolutional manner. The conditions are injected in the generator via the SPADE block to preserve the spatial information. Finally, the generator uses an attention mechanism to only change relevant parts of the image, thus preserving the clothes, earrings and other facial features unrelated to aging.</p>

<p>
  <img width="70%" src="https://despoisj.github.io/AgingMapGAN/img/model_hd.jpg">
</p>

<h2 id="training">Training</h2>
<p>To train our model, we use four different losses: <em>L<sub>Age</sub></em> to penalize the aging map estimation, <em>L<sub>Loc</sub></em> for the patch localization, <em>L<sub>WGAN</sub></em> for the realism of the generated images, and <em>L<sub>Cyc</sub></em> for the fidelity to the original image.</p>

<p>
  <img width="70%" src="https://despoisj.github.io/AgingMapGAN/img/training_hd.jpg">
</p>

<h2 id="results">Results</h2>
<h3 id="supervised-high-resolution-standardized-dataset">Supervised: High-Resolution Standardized Dataset</h3>
<p>We have labeled 7000 images, using 15 clinical aging signs for each image, in order to build accurate ethnicity-specific aging maps for each individual. On this dataset, our model is able to generate aged and rejuvenated faces with complete control over the localization and amount of aging.</p>

<p>We recommend viewing the videos in full-screen to see the generated HD images (1024px).</p>
<p>
    <video controls="">
      <source src="https://despoisj.github.io/AgingMapGAN/img/cau.mov">
    Your browser does not support the video tag.
    </video>
    <video controls="">
      <source src="https://despoisj.github.io/AgingMapGAN/img/ind.mov">
    Your browser does not support the video tag.
    </video>
    <video controls="">
      <source src="https://despoisj.github.io/AgingMapGAN/img/aam.mov">
    Your browser does not support the video tag.
    </video>
    <video controls="">
      <source src="https://despoisj.github.io/AgingMapGAN/img/chi.mov">
    Your browser does not support the video tag.
    </video>
</p>

<p>We recommend opening the images in a new tab to see the details.</p>
<p>
  <img width="100%" src="https://despoisj.github.io/AgingMapGAN/img/ours_chi1_cropped.jpg">
</p>
<p>
  <img width="100%" src="https://despoisj.github.io/AgingMapGAN/img/ours_cau1_cropped.jpg">
</p>

<h3 id="weakly-supervised-ffhq">Weakly-Supervised: FFHQ</h3>
<p>To train our model on the FFHQ dataset, we have created labels in a weakly-supervised fashion, using regression models trained on our labeled dataset. Despite this and the challenging poses, occlusions and lighting conditions of the dataset, our approach successfully ages and rejuvenates images in high-definition.</p>

<p>We recommend opening the images in a new tab to see the details.</p>
<p>
  <img width="49%" src="https://despoisj.github.io/AgingMapGAN/img/ffhq_cau1.jpg">
  <img width="49%" src="https://despoisj.github.io/AgingMapGAN/img/ffhq_chi1.jpg">
</p>
<p>
  <img width="49%" src="https://despoisj.github.io/AgingMapGAN/img/ffhq_afr1.jpg">
  <img width="49%" src="https://despoisj.github.io/AgingMapGAN/img/ffhq_cau5.jpg">
</p>
<p>
  <img width="49%" src="https://despoisj.github.io/AgingMapGAN/img/ffhq_cau3.jpg">
  <img width="49%" src="https://despoisj.github.io/AgingMapGAN/img/ffhq_afr2.jpg">
</p>

<h3 id="other-works">Other works</h3>
<p>Check out our other paper presented at AIM (ECCV 2020): <a href="https://robinkips.github.io/CA-GAN/" target="_blank">https://robinkips.github.io/CA-GAN/</a></p>


      
    </section></div>]]>
            </description>
            <link>https://despoisj.github.io/AgingMapGAN/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24280145</guid>
            <pubDate>Wed, 26 Aug 2020 07:47:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You shouldn't skimp on your design phase?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24279956">thread link</a>) | @samzer
<br/>
August 26, 2020 | https://blog.saitamasolutions.com/why-you-shouldnt-skimp-on-your-design-phase/ | <a href="https://web.archive.org/web/*/https://blog.saitamasolutions.com/why-you-shouldnt-skimp-on-your-design-phase/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.saitamasolutions.com/content/images/size/w300/2020/08/Screen_Shot_2020-08-21_at_17.10.12-1.png 300w,
                            https://blog.saitamasolutions.com/content/images/size/w600/2020/08/Screen_Shot_2020-08-21_at_17.10.12-1.png 600w,
                            https://blog.saitamasolutions.com/content/images/size/w1000/2020/08/Screen_Shot_2020-08-21_at_17.10.12-1.png 1000w,
                            https://blog.saitamasolutions.com/content/images/size/w2000/2020/08/Screen_Shot_2020-08-21_at_17.10.12-1.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.saitamasolutions.com/content/images/size/w2000/2020/08/Screen_Shot_2020-08-21_at_17.10.12-1.png" alt="Why you shouldn't skimp on your design phase?">
            </figure>

            <section>
                <div>
                    <figure><img src="https://blog.saitamasolutions.com/content/images/2020/08/Untitled.png" alt=""></figure><blockquote>												source:<a href="https://xkcd.com/2021/">https://xkcd.com/2021/</a></blockquote><p>If you are constructing a building, a blueprint of the building is mandatory before laying the foundation. It forms the basis for estimating the resources required, the number of construction workers, the time it will take to complete the construction and a direction that will guide the civil engineers. The same methodology also applies to digital products.</p><p>The design phase of a product is critical, and this phase will affect the resources and duration of the project, which in turn affects the cost involved. Making wrong decisions and assumptions during the design phase can increase the cost incurred significantly because of the rework required.</p><h2 id="what-are-low-fidelity-and-high-fidelity-wireframes">What are low fidelity and high fidelity wireframes?</h2><p>A low fidelity wireframe contains basic visuals and content. It is static and non-interactive. It is easy and quick to create. You don't require expertise, and it can be created quickly.</p><figure><img src="https://blog.saitamasolutions.com/content/images/2020/08/Screen_Shot_2020-08-21_at_15.41.24.png" alt=""></figure><p>A high fidelity wireframe contains advanced visuals with colours, fonts etc. It has complex interactions and looks close to the final design that the developer gets.</p><figure><img src="https://blog.saitamasolutions.com/content/images/2020/08/Screen_Shot_2020-08-21_at_15.53.01-1.png" alt="" srcset="https://blog.saitamasolutions.com/content/images/size/w600/2020/08/Screen_Shot_2020-08-21_at_15.53.01-1.png 600w, https://blog.saitamasolutions.com/content/images/size/w1000/2020/08/Screen_Shot_2020-08-21_at_15.53.01-1.png 1000w, https://blog.saitamasolutions.com/content/images/2020/08/Screen_Shot_2020-08-21_at_15.53.01-1.png 1283w" sizes="(min-width: 720px) 720px"></figure><p>source: <a href="https://bit.ly/3aLNPkr">https://bit.ly/3aLNPkr</a></p><h2 id="why-start-low">Why start low?</h2><p>Low fidelity wireframes are an essential step of the design process and the following are the reasons why -</p><ul><li><strong>Focus on the bigger picture:</strong> Looking at high fidelity wireframes can be distracting as it can take the focus away from the functional aspect of the product and completely miss out on the larger picture of <em>"Is the design in the right direction?"</em></li><li><strong>Avoids confusion:</strong> If the first design seen by a client is a high fidelity design, then it can create confusion because they might think that this is the final design and it is not what they were expecting.</li><li><strong>Stimulates creativity:</strong> The primary purpose of a low fidelity design is to learn from the audience - client and end-users. It helps in receiving feedback that can be used to create new solutions that align closer to what the audience wants. It also enables the client to provide their ideas as low fidelity designs feel less intimidating.</li><li><strong>Rapid prototyping:</strong> One of the most significant advantages of low fidelity design is that anyone in almost no time can create it, and it is also easily discardable. It accelerates the pace of iteration, getting feedback and aligning the product closer to the client's vision and user's need.</li><li><strong>Resource-saving:</strong> It does not take much expertise nor time for someone to do low fidelity design. The best part of going through a proper low fidelity design process is that it reduces the probability of error that can take place in the development cycle. If wrong assumptions are made, and the product has been built halfway, then it can be very costly in terms of money to correct the direction and also time-consuming.</li></ul><h2 id="what-are-the-ups-of-going-high">What are the ups of going high?</h2><ul><li><strong>Validate complex user interactions:</strong> You can observe how the users are interacting with the product and get feedback on the functionality and navigation of the product. This will help in understanding if there are any confusions faced by the users</li><li><strong>Test out the aesthetics:</strong> You can also observe the how the users respond to the aesthetics of the app - layout, spacing, font styles, illustrations etc. - , and how they feel about it.</li><li><strong>Final branding:</strong> Test out whether your product's personality appeals to your target customers</li><li><strong>Designer developer handoff:</strong> Gives a better idea for the developer on how the overall product will look like. Plus from here you can start giving measurements and specs to the developer for each design element.</li><li><strong>Reduce human error:</strong> High Fidelity wireframes helps to test out the user interactions, aesthetics of the screen which in turn reduces human error that can be from assumptions by the designer, communication from the stakeholders or feedback from the users</li></ul><p>For low fidelity design, you can use -</p><p><strong>Paper/whiteboard:</strong> Yep, it can be as simple as sketching it on a paper or whiteboard it out in a meeting room</p><p><strong><a href="https://balsamiq.cloud/">Balsamiq</a>:</strong> It is a popular tool that has been there since 2008, and it provides basic constructs to build your low fidelity designs. You can also collaborate with your team members online.</p><figure><img src="https://blog.saitamasolutions.com/content/images/2020/08/Screen_Shot_2020-08-21_at_17.10.12.png" alt="" srcset="https://blog.saitamasolutions.com/content/images/size/w600/2020/08/Screen_Shot_2020-08-21_at_17.10.12.png 600w, https://blog.saitamasolutions.com/content/images/2020/08/Screen_Shot_2020-08-21_at_17.10.12.png 810w" sizes="(min-width: 720px) 720px"></figure><p><strong><a href="https://miro.com/">Miro</a>:</strong> It is an online collaborative whiteboard that can be used for multiple use cases; one of the use cases is "design" too. It also has the basic design constructs that can be leveraged effectively to create your designs.</p><figure><img src="https://blog.saitamasolutions.com/content/images/2020/08/Screen_Shot_2020-08-21_at_17.16.48-1.png" alt="" srcset="https://blog.saitamasolutions.com/content/images/size/w600/2020/08/Screen_Shot_2020-08-21_at_17.16.48-1.png 600w, https://blog.saitamasolutions.com/content/images/2020/08/Screen_Shot_2020-08-21_at_17.16.48-1.png 692w"></figure><p>For high fidelity design, you can use</p><p><strong><a href="https://www.invisionapp.com/">Invision</a>:</strong> Its a powerful design tool with lots of powerful features and you can use it to create complex interactions</p><figure><img src="https://blog.saitamasolutions.com/content/images/2020/08/Screen_Shot_2020-08-21_at_17.23.30.png" alt="" srcset="https://blog.saitamasolutions.com/content/images/size/w600/2020/08/Screen_Shot_2020-08-21_at_17.23.30.png 600w, https://blog.saitamasolutions.com/content/images/2020/08/Screen_Shot_2020-08-21_at_17.23.30.png 668w"></figure><p><strong><a href="https://www.figma.com/">Figma</a>:</strong> In the past few years, Figma has become a popular choice among designers. It provides a simple interface which can be used to create complex constructs. It has multiplayer editing which is very powerful for collaboration as well as presenting the design to someone</p><figure><img src="https://blog.saitamasolutions.com/content/images/2020/08/Screen_Shot_2020-08-21_at_17.28.22.png" alt="" srcset="https://blog.saitamasolutions.com/content/images/size/w600/2020/08/Screen_Shot_2020-08-21_at_17.28.22.png 600w, https://blog.saitamasolutions.com/content/images/size/w1000/2020/08/Screen_Shot_2020-08-21_at_17.28.22.png 1000w, https://blog.saitamasolutions.com/content/images/size/w1600/2020/08/Screen_Shot_2020-08-21_at_17.28.22.png 1600w, https://blog.saitamasolutions.com/content/images/2020/08/Screen_Shot_2020-08-21_at_17.28.22.png 1642w" sizes="(min-width: 720px) 720px"></figure><p><strong>Honorable mentions:</strong> <a href="https://www.sketch.com/">Sketch</a> and <a href="https://www.adobe.com/in/products/xd.html">AdobeXD</a></p><h2 id="final-thoughts">Final Thoughts</h2><p>If you are the business owner, then skipping the design phase will cost you not only in monetary terms but also your product missing the mark with the target audience.</p><p>If you are the designer, then you might be comfortable in designing high fidelity wireframes rapidly and skipping on the low fidelity wireframes. The goal should not be to showcase your skill and speed but to deliver on the product that resonates with the user.</p><p>If you are the developer, then getting requirement with not much of design effort will increase the development effort in terms of time and redoing requirements multiple times.</p><p>Design is important towards product development, and skimping it will create cost down the line.</p><figure><img src="https://blog.saitamasolutions.com/content/images/2020/08/planning.png" alt=""></figure><p>												source: <a href="https://xkcd.com/1539/" rel="noopener noreferrer">https://xkcd.com/1539/</a></p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.saitamasolutions.com/why-you-shouldnt-skimp-on-your-design-phase/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24279956</guid>
            <pubDate>Wed, 26 Aug 2020 07:10:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unit Testing – The Freedom to Fail]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24279859">thread link</a>) | @fazlerocks
<br/>
August 25, 2020 | https://blog.manivelnagarajan.com/unit-testing-the-freedom-to-fail-cke8l1tw70056ecs1923xcnwf | <a href="https://web.archive.org/web/*/https://blog.manivelnagarajan.com/unit-testing-the-freedom-to-fail-cke8l1tw70056ecs1923xcnwf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1598260527724/vTQ2VswEq.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><p>In software engineering space, we often face a situation where we developers, demand for full app revamp for numerous reasons. The codebase becomes fragile. More regression bugs popping up after every release. It takes a long time to add new features and even to resolve small bugs. Everyone is afraid of making changes to the giant beast classes. While revamping looks like a viable option in the developer's eyes, the businesses cannot hold on to building new features. Sometimes, it is impossible to afford regressions in the existing features since the customers are already used to the product.</p>
<p>Now, Is it possible to revamp once in every two or three years? The very obvious answer is a big NO! Now, what exactly went wrong? It could be the Bad software design,</p>
<ul>
<li>Giant beast classes</li>
<li>Modules are tightly coupled</li>
<li>No unit tests</li>
</ul>
<h3 id="no-unit-tests">No unit tests</h3>
<p>In this article, we are going to see only the consequences of not having unit tests and how we can prepare ourselves to write our first unit test. If you see, we might not face any of these problems while starting a new project from scratch. Everyone loves to work on a new project. As your application grows, your confidence level starts to dip down and you might not able to ship features as fast as you were. The codebase is becoming legacy very quickly without tests.</p>
<blockquote>
<p>"Legacy code is the code without tests" - Micheal Feathers in 'Working Effectively with Legacy code'.</p>
</blockquote>
<h4 id="excuse-me">Excuse me ☝️</h4>
<p>We find many excuses for not writing unit tests,</p>
<ul>
<li>Writing tests slows down the development process</li>
<li>Don't have enough time</li>
<li>Anyway, we need to do E2E testing (End to End)</li>
<li>Not sure what to test</li>
<li>Don't know how to write unit tests</li>
</ul>
<p>Well, these are misconceptions we have in our minds because we really don't understand what unit testing is for. If you're also the one finding these excuses, then it is time to understand what is unit testing and automation testing pyramid.</p>
<h4 id="what-is-unit-testing">What is unit testing?</h4>
<p>Unit Testing is a level of software testing where individual units/ components of software are tested. The purpose is to validate that each unit of the software performs as designed. A unit is the smallest testable part of any software. </p>
<h4 id="automation-testing-pyramid">Automation Testing Pyramid:</h4>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598184303373/MtdF5St73.png?auto=format&amp;q=60" alt="testpyramid.png">
If you notice, writing unit tests are cheaper and faster than E2E testing. Though, unit testing cannot replace E2E testing, unit testing holds the major importance in the pyramid space. Unit testing is the base of the test pyramid. As we know clearly that a weak base can topple down the entire building and software development is no exception. And that's when we are demanding to revamp. 
I cannot resist mentioning this funny dialogue(Tamil) by Vadivelu - that explains the weak basement quite well 🥴😂
<img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598188481226/hVrZpDYbR.png?auto=format&amp;q=60" alt="basement_weak-uh.png">
If you're still wondering that unit tests are not that prominent in SDLC, you must know the benefits of writing them.</p>
<h4 id="why-unit-tests">Why unit tests?</h4>
<p>Writing unit tests allows us,</p>
<ul>
<li>To Speed up the development process in the long run and deliver new features with better confidence (I know this is opposite to what I wrote in the excuses list)</li>
<li>To Refactor with confidence </li>
<li>To get Instant feedback, much faster than running the entire application and test visually every time</li>
<li>To keep the codebase maintainable. Remember that we may not be able to write effective unit tests on a codebase that is designed badly</li>
<li>To keep the various modules and components loosely coupled</li>
<li>Unit tests tell you how it behaves. Yes, it is a kind of passive documentation for your code</li>
<li>To debug the issues easily</li>
<li>Identify breaking changes in development stage itself</li>
</ul>
<h4 id="not-sure-what-to-test">Not sure what to test?</h4>
<p>Ideally, everything! But we aren't in the ideal world. While it is a good idea to aim for 100% code coverage, we might have some classes in our application that talk to External frameworks. Our objective for writing unit testing is not to test the external frameworks and that is the reason we should keep these classes as thin as possible. If your codebase doesn't have any tests and you're beginning to write, then I would recommend you start with the core feature of your application. Most often, it is not that easy to write effective tests on your core features. The chances are that they are the giant beast classes. In this case, You might want to do refactoring before writing tests. Remember, </p>
<blockquote>
<p>The more complex the class, the more you want to write tests. </p>
</blockquote>
<h4 id="how-to-write-unit-tests">How to write unit tests?</h4>
<p>AAA (Arrange, Act, Assert) is a popular pattern that suggests to divide the test method into 3 sections,</p>
<p>There are three steps we need to follow for every unit test,</p>
<ol>
<li><strong>Arrange:</strong> This section initializes objects and sets the value of the data that is passed to the method under test. This involves topics such as Test Doubles, Dependency Injection, etc</li>
<li><strong>Act:</strong> This section invokes the method under test with the arranged parameters</li>
<li><strong>Assert:</strong> This section verifies that the action of the method under test behaves as expected</li>
</ol>
<p>Consider we are testing the class <code>Stack</code>, You must have come across the term <strong><em>SUT</em></strong> which stands for 'System Under Test'. Well, in our case <code>Stack</code> is our SUT.</p>
<pre><code><span>final</span> <span><span>class</span> <span>StackTests</span>: <span>XCTestCase</span> </span>{

    <span>var</span> sut: <span>Stack</span>&lt;<span>String</span>&gt; = <span>Stack</span>()

    <span><span>func</span> <span>test_push</span><span>()</span></span> {
        
        sut = <span>Stack</span>()
        sut.push(<span>"Hello"</span>)

        
        sut.push(<span>"Reader"</span>)

        
        <span>XCTAssertTrue</span>(sut.top.data == <span>"Reader"</span>)
    }

    <span><span>func</span> <span>test_pop</span><span>()</span></span> {
        
        sut = <span>Stack</span>()
        sut.push(<span>"Hello"</span>)
        sut.push(<span>"Reader"</span>)

        
        sut.pop()

        
        <span>XCTAssertTrue</span>(sut.top.data == <span>"Hello"</span>)
    }
}
</code></pre><p>Yeah, we are now ready to kick start our unit testing journey, I mean it. Unit testing is not a destination but a continuous journey. As our application grows, we should keep writing tests. The more unit test coverage you have, the more benefit you get. Always remember that unit tests are first-class citizens in our project and they are equally important as our production source code. So it is important to plan and structure the unit test classes as well. I've chosen a simple example but when we start writing tests to our actual code, we may encounter problems in creating mocks for a complex class, testing asynchronous code, private methods, UI Components. I will cover a separate article to address the common problems in writing tests.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598211932437/JogyCZjQv.png?auto=format&amp;q=60" alt="unit-test-meme.png"></p>
<p>Thank you for reading this article! Let's start doing more of <code>CMD+U</code>(Test) than <code>CMD+R</code>(Run). </p>
<p>Happy coding!</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.manivelnagarajan.com/unit-testing-the-freedom-to-fail-cke8l1tw70056ecs1923xcnwf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24279859</guid>
            <pubDate>Wed, 26 Aug 2020 06:54:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Common Challenges in Continuous Testing]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24279832">thread link</a>) | @AnuGeorge
<br/>
August 25, 2020 | https://testsigma.com/blog/common-challenges-in-continuous-testing/ | <a href="https://web.archive.org/web/*/https://testsigma.com/blog/common-challenges-in-continuous-testing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<h2><strong>Introduction</strong></h2>



<p>Continuous Testing is the process of testing at all stages of software development – one after the another- without any human intervention. <a href="https://testsigma.com/continuous-testing" target="_blank" rel="noopener noreferrer">Continuous Testing</a> is key to faster delivery of Agile products to the market. </p>



<p>Continuous Testing makes it possible to eliminate testing as a bottleneck for faster software development and delivery. But the path to achieving Continuous Testing has its own challenges, most common of which are mentioned below.</p>



<h2><strong>Common Challenges</strong></h2>



<p><strong>1. Lack of Testability Support in Products:</strong> A test automation system is a very basic requirement for Continuous Testing. To achieve strong automated testing for a product, you need to have almost all of your test cases automated. But does the product have the testability support required to automate all test cases? Not always! If products are not designed, keeping testability in mind, achieving continuous testing may become a distant dream.</p>



<p>Achieving continuous testing for new feature work done in legacy products becomes more difficult if the product didn’t have testability support initially. Adding testability support to such products is expensive and may not always get prioritized as compared to other items on the product roadmap, draining down the efforts for Continuous Testing.</p>



<p><strong>2. Lack of Standard Tools:</strong> For a variety of products, standard tools to achieve continuous testing don’t exist. Teams often resort to using in-house test automation tools or frameworks which are neither well-documented nor well-maintained. This adds to the woes of the testing team as they now have to struggle with the issues of the tool/framework also.</p>



<p>With in-house tools/frameworks, you have the benefit of code-ownership. You can make changes to the tool/framework to get desired behaviour, but that is a costly affair in terms of resources. You are now investing your resources to evolve the tool/framework rather than the product. Practically, teams don’t have the luxury to customize the testing tool/framework for their needs when they need to deliver a quality product on an impending timeline.</p>



<p><strong>3. Lack of Faster Feedback Loops:</strong> To leverage Continuous Testing, it is important to incorporate feedback on an on-going basis. To incorporate feedback on a continuous basis, you need feedback loops in the system that can help you gather feedback in real-time. Lack of such feedback loops introduce a delay in action, later affecting the quality of the product.</p>



<p>For example, if one of the test environments used to run automation tests is down, an alert message for the same helps you act timely to rectify it rather than digging into the cause of the non-arrival of the test report for scheduled test automation run.&nbsp;</p>



<p>Similarly, it helps to have a real-time dashboard for performance which depicts the performance metrics over a period of time rather than digging into logs and code-profiler reports every time you want to check on a product’s performance. When such dashboards are accessible to everyone on the team, it helps in bringing critical issues to the table and gets them prioritized.&nbsp;</p>



<p><strong>4. Lack of Testing Infrastructure:</strong> Often, organizations embark on the path of embracing Continuous Testing, without realizing the budgetary needs for it.</p>



<p>To implement Continuous Testing, you might need additional test environments that need to be maintained and kept up and running round the clock. You might also need advanced tools to incorporate faster feedback loops.&nbsp;</p>



<p>Although these costs aren’t significant as compared to the cost incurred due to the poor quality of the product, there is a need for organizational commitment. A half-way journey to continuous testing without adequate infrastructure only adds to the woes of the testing team and doesn’t help anyone.&nbsp;&nbsp;</p>



<p><strong>5. Lack of Enough Testers:</strong> Most product teams don’t have enough testers, which sometimes creates bottlenecks for achieving continuous testing. Continuous testing is an on-going journey and requires high initial investments in terms of setup, which may create extra workload for testers.</p>



<p>Until continuous testing reaches the stage where it can replace the need for traditional testing, testers are often caught in balancing the efforts required for switching to continuous testing and their regular testing tasks that usually have a high priority w.r.t product needs. This adds to the pending backlogs for achieving continuous testing, creating a chicken-and-egg situation, where continuous testing can reduce the testing time but there is no time to set up continuous testing.</p>



<p><strong>6. <a href="https://testsigma.com/blog/why-test-data-management-is-more-important-than-you-think/" target="_blank">Test Data Management</a>:</strong> Depending on the product and its testing needs, test data management sometimes becomes a bottleneck for continuous testing.</p>



<p>Test data when stored locally for testing environments may result in different versions of test data which may be difficult to maintain. Maintaining test data in a central repository and then accessing it from different test environments may ease this problem but may introduce other issues like network latency in tests.</p>



<p><strong>7. Increased Complexity:</strong> As the scope for the product grows, so does the scope for continuous testing.</p>



<p>With a large number of tests added to the system, it becomes a challenge to make the tests execute quickly. If tests take too long to run, it defeats the whole purpose of continuous testing as quick feedback is not available. If not all tests are run, it seems like a compromise on the quality of the product. Also, if not all tests are run, it makes the effort of adding all those tests to the system go in vain.</p>



<p><strong>8. Scalability Issues:</strong> Not all testing frameworks/tools may be suitable for scaling purposes.</p>



<p>Lack of support for large concurrent test sessions and slow test executions can become serious bottlenecks for your dream of achieving Continuous Testing.</p>



<p>Such scalability issues aren’t always noticeable in the beginning. They become clearly visible only after a significant amount of tests have been added to the system and the test system starts to get highly loaded. This makes the situation worse as at such a stage, it’s even more difficult to switch to a different tool/framework.</p>



<p><strong>9. Inefficient Processes:</strong> Sometimes, the processes followed in the team/organization are not conducive for achieving Continuous Testing. Let’s check:</p><p><strong>i. Change in Requirements:</strong> If requirement specifications keep on changing frequently, it creates a lot of rework for the team, especially the testing team as tests may need to be updated every time there is a change in the requirements. This may adversely impact the efforts for continuous testing.</p><p><strong>ii. Unclear Roles and Responsibilities of Team Members:</strong> If the roles and responsibilities of team members are not clearly defined, it may result in ambiguous ownership of tasks. Such ambiguity can lead to redundant efforts on some tasks and some tasks getting totally ignored. Clear ownership of tasks is important in achieving Continuous Testing.</p><p><strong>iii. Excluding Testing Team in Initial Discussions:</strong> If the testing team is not included in all product-related discussions from the beginning, it would create gaps in the understanding which may impact continuous testing. Also, it would require additional processes such as hand-offs from Developers to Testers from time to time, adding inefficiency to the whole system.&nbsp;</p><p><strong>iv. Bureaucratic Approvals:</strong> If your team/organization functions with heavy bureaucracy and approvals are needed for every small thing, it can add inefficiency to the whole system which can make it hard to achieve continuous testing.&nbsp;</p>



<p>For example, if a test environment has gone down and you don’t have the required access privileges to bring it back up and need to wait on some other team/person for this, it can lead to inefficiency in the continuous testing pipeline.&nbsp;</p>



<h2><strong>Suggestions for Resolving Some Common Challenges</strong></h2>



<p>Most of the common challenges discussed above can be worked around with the help of some suggestions discussed below.</p>



<p><strong>1. Include Testability from Beginning:</strong></p><p><strong>i. </strong>Testability should be part of the low-level design for the product.</p><p><strong>ii. </strong>Any feature developed for the product should not be considered complete unless it has the required testability support for Continuous Testing.</p>



<p><strong>2. Evaluate Tools/Frameworks before Including them in the System:</strong></p><p><strong>i. </strong>It’s good to evaluate any testing tool/framework for required support before getting bound to it by making it part of the system.</p><p><strong>ii. </strong>The right combination of open source and paid test frameworks/tools can be used rather than relying solely on open-source test frameworks/tools.</p><p><strong>iii. </strong>Having a defined set of parameters to capture results of experiments with new tools can help in a better evaluation of tools/frameworks in a much-organized way.</p>



<p><strong>3. Evaluate Budget Requirements before Embracing Continuous Testing:</strong> Implementing Continuous Testing may need a significant budget for test environments and tools/frameworks.</p>



<p>Evaluating budget requirements before starting on the path of Continuous Testing helps in making informed decisions early rather than being stuck in the middle of the path due to budgetary constraints.</p>



<p><strong>4. Leveraging Cloud-based Virtual Infrastructure:</strong> Cloud-based test environments can be made accessible instantaneously on demand. They also save testing teams from most of the headache associated with managing and maintaining traditional test environments. Leveraging cloud-based virtual environments can help resolve a lot of issues related to the availability of test environments for Continuous Testing.&nbsp;&nbsp;</p>



<p> Using test automation tools that support test automation workflows on the cloud can further add to these benefits. Testsigma is one such tool.</p>



<div>
<p><b>
Completely hosted on the cloud, Testsigma saves you from any installation and configuration issues. You are ready to start automating soon after signup.
</b></p>

</div>



<p><strong>5. Have Enough Testers:</strong> Continuous Testing is an on-going journey and testers are the major contributors to make this journey successful. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://testsigma.com/blog/common-challenges-in-continuous-testing/">https://testsigma.com/blog/common-challenges-in-continuous-testing/</a></em></p>]]>
            </description>
            <link>https://testsigma.com/blog/common-challenges-in-continuous-testing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24279832</guid>
            <pubDate>Wed, 26 Aug 2020 06:47:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bypassing MS Credential Guard to recover plaintext credentials]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24279792">thread link</a>) | @a5withtrrs
<br/>
August 25, 2020 | https://teamhydra.blog/2020/08/25/bypassing-credential-guard/ | <a href="https://web.archive.org/web/*/https://teamhydra.blog/2020/08/25/bypassing-credential-guard/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-47">

	

	
	<div>
		
<p>In ye old days, a [hacker, red teamer, penetration tester, motivated child] would compromise a host, use an exploit to elevate or laterally move, and then Mimikatz their way to glory (ok, maybe not <em>just</em> in the old days).&nbsp; This is becoming increasingly more complicated to achieve.  Many new technologies have been implemented to prevent or restrict access to credentials on a compromised host.&nbsp; Last year, Adam Chester (@_xpn_) wrote an <a href="https://blog.xpnsec.com/exploring-mimikatz-part-1/">excellent blog post</a> on memory patching wdigest.dll to enable UseLogonCredentials.  This is done without dropping files to disk or changing registry keys.&nbsp; I will touch on this briefly, but I strongly recommend reading his post before reading through this.&nbsp;</p>



<p>After reading XPN’s post, myself and a co-worker started exploring other possibilities for bypassing / disabling protections using memory patching. &nbsp;Windows Defender Credential Guard seemed like an excellent target for this type of attack.</p>



<p><em>TL/DR &amp;&amp; (POC || GTFO)</em><br><em>Wdigest can be enabled on a system with Credential Guard by patching the values of g_fParameter_useLogonCredential and g_IsCredGuardEnabled in memory. <a href="https://gist.github.com/N4kedTurtle/8238f64d18932c7184faa2d0af2f1240" target="_blank" rel="noreferrer noopener">PoC located here</a>.</em></p>



<blockquote><p>“Introduced in Windows&nbsp;10 Enterprise and Windows Server 2016, Windows Defender Credential Guard uses virtualization-based security to isolate secrets so that only privileged system software can access them. Unauthorized access to these secrets can lead to credential theft attacks, such as Pass-the-Hash or Pass-The-Ticket. Windows Defender Credential Guard prevents these attacks by protecting NTLM password hashes, Kerberos Ticket Granting Tickets, and credentials stored by applications as domain credentials.” </p><cite><a href="https://docs.microsoft.com/en-us/windows/security/identity-protection/credential-guard/credential-guard" rel="nofollow">https://docs.microsoft.com/en-us/windows/security/identity-protection/credential-guard/credential-guard</a></cite></blockquote>



<p>Currently, the most common way to overcome Cred Guard is to register a new Security Support Provider (SSP) (<a href="https://twitter.com/gentilkiwi/status/1044715664823308289">Mimikatz memssp</a> or a custom one).&nbsp; This is generally loaded into memory and then captures and writes any credentials entered.&nbsp; This can <a href="https://blog.xpnsec.com/exploring-mimikatz-part-2/">be modified </a> (seriously, @_xpn_ is a beast) to improve opsec but we wanted to see if there was a simpler and hopefully less identifiable way to do this.</p>



<p>The first thing we should check is if we can just enable UseLogonCredential on a system with Credential Guard enabled.&nbsp; <a href="https://docs.microsoft.com/en-us/windows/security/identity-protection/credential-guard/credential-guard-protection-limits">Per MSDN</a>:</p>



<blockquote><p>“When Windows Defender Credential Guard is enabled, neither Digest nor CredSSP have access to users’ logon credentials. This implies no Single Sign-On use for these protocols.”</p></blockquote>



<p>This <em>suggests </em>that enabling UseLogonCredential on a system with Credential Guard will not have any impact on an attacker’s ability to get credentials from memory since Digest will not have access even if enabled.&nbsp; It still seems worth testing, just in case.</p>



<p>First, we identify the offset of g_fParameter_useLogonCredential.&nbsp; It should be noted that this will change between versions of wdigest.dll (but is static between systems with the same version).&nbsp; This can easily be done with any debugger.</p>



<figure><img data-attachment-id="50" data-permalink="https://teamhydra.blog/uselogoncred/" data-orig-file="https://teamhydradotblog.files.wordpress.com/2020/08/uselogoncred.png" data-orig-size="1016,309" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="uselogoncred" data-image-description="" data-medium-file="https://teamhydradotblog.files.wordpress.com/2020/08/uselogoncred.png?w=300" data-large-file="https://teamhydradotblog.files.wordpress.com/2020/08/uselogoncred.png?w=750" src="https://teamhydradotblog.files.wordpress.com/2020/08/uselogoncred.png?w=1016" alt="" srcset="https://teamhydradotblog.files.wordpress.com/2020/08/uselogoncred.png 1016w, https://teamhydradotblog.files.wordpress.com/2020/08/uselogoncred.png?w=150 150w, https://teamhydradotblog.files.wordpress.com/2020/08/uselogoncred.png?w=300 300w, https://teamhydradotblog.files.wordpress.com/2020/08/uselogoncred.png?w=768 768w" sizes="(max-width: 1016px) 100vw, 1016px"></figure>



<p>We can see wdigest!g_fParameter_useLogonCredential is 0x36124 bytes from the base of wdigest.dll (we are testing on Windows 10 Enterprise version 1909).&nbsp; With this information we can easily find and patch wdigest in memory on the host.</p>



<p>Let’s boot up our system and ensure that Credential Guard is enabled.</p>



<div><figure><img data-attachment-id="53" data-permalink="https://teamhydra.blog/cropped_credguardonsystem/" data-orig-file="https://teamhydradotblog.files.wordpress.com/2020/08/cropped_credguardonsystem.png" data-orig-size="1128,555" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="cropped_credguardonsystem" data-image-description="" data-medium-file="https://teamhydradotblog.files.wordpress.com/2020/08/cropped_credguardonsystem.png?w=300" data-large-file="https://teamhydradotblog.files.wordpress.com/2020/08/cropped_credguardonsystem.png?w=750" src="https://teamhydradotblog.files.wordpress.com/2020/08/cropped_credguardonsystem.png?w=1024" alt="" srcset="https://teamhydradotblog.files.wordpress.com/2020/08/cropped_credguardonsystem.png?w=1024 1024w, https://teamhydradotblog.files.wordpress.com/2020/08/cropped_credguardonsystem.png?w=150 150w, https://teamhydradotblog.files.wordpress.com/2020/08/cropped_credguardonsystem.png?w=300 300w, https://teamhydradotblog.files.wordpress.com/2020/08/cropped_credguardonsystem.png?w=768 768w, https://teamhydradotblog.files.wordpress.com/2020/08/cropped_credguardonsystem.png 1128w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>



<p>Now, run our PoC that patches UseLogonCredential.</p>



<div><figure><img data-attachment-id="54" data-permalink="https://teamhydra.blog/cropped_patchlogoncredentials/" data-orig-file="https://teamhydradotblog.files.wordpress.com/2020/08/cropped_patchlogoncredentials.png" data-orig-size="568,181" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="cropped_patchlogoncredentials" data-image-description="" data-medium-file="https://teamhydradotblog.files.wordpress.com/2020/08/cropped_patchlogoncredentials.png?w=300" data-large-file="https://teamhydradotblog.files.wordpress.com/2020/08/cropped_patchlogoncredentials.png?w=568" src="https://teamhydradotblog.files.wordpress.com/2020/08/cropped_patchlogoncredentials.png?w=568" alt="" srcset="https://teamhydradotblog.files.wordpress.com/2020/08/cropped_patchlogoncredentials.png 568w, https://teamhydradotblog.files.wordpress.com/2020/08/cropped_patchlogoncredentials.png?w=150 150w, https://teamhydradotblog.files.wordpress.com/2020/08/cropped_patchlogoncredentials.png?w=300 300w" sizes="(max-width: 568px) 100vw, 568px"></figure></div>



<p>Finally, log in with a new user and see if we got credentials…..</p>



<div><figure><img data-attachment-id="55" data-permalink="https://teamhydra.blog/failed_mimi/" data-orig-file="https://teamhydradotblog.files.wordpress.com/2020/08/failed_mimi.png" data-orig-size="442,132" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="failed_mimi" data-image-description="" data-medium-file="https://teamhydradotblog.files.wordpress.com/2020/08/failed_mimi.png?w=300" data-large-file="https://teamhydradotblog.files.wordpress.com/2020/08/failed_mimi.png?w=442" src="https://teamhydradotblog.files.wordpress.com/2020/08/failed_mimi.png?w=442" alt="" srcset="https://teamhydradotblog.files.wordpress.com/2020/08/failed_mimi.png 442w, https://teamhydradotblog.files.wordpress.com/2020/08/failed_mimi.png?w=150 150w, https://teamhydradotblog.files.wordpress.com/2020/08/failed_mimi.png?w=300 300w" sizes="(max-width: 442px) 100vw, 442px"></figure></div>



<p>Unsurprisingly, we are still unable to get new credentials.&nbsp; However, it seems like there may be more here to investigate, so we return to looking at wdigest.dll and see what other variables exist that could be of interest to us.</p>



<div><figure><img data-attachment-id="57" data-permalink="https://teamhydra.blog/globalvars/" data-orig-file="https://teamhydradotblog.files.wordpress.com/2020/08/globalvars.png" data-orig-size="696,647" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="globalvars" data-image-description="" data-medium-file="https://teamhydradotblog.files.wordpress.com/2020/08/globalvars.png?w=300" data-large-file="https://teamhydradotblog.files.wordpress.com/2020/08/globalvars.png?w=696" src="https://teamhydradotblog.files.wordpress.com/2020/08/globalvars.png?w=696" alt="" srcset="https://teamhydradotblog.files.wordpress.com/2020/08/globalvars.png 696w, https://teamhydradotblog.files.wordpress.com/2020/08/globalvars.png?w=150 150w, https://teamhydradotblog.files.wordpress.com/2020/08/globalvars.png?w=300 300w" sizes="(max-width: 696px) 100vw, 696px"></figure></div>



<p>g_IsCredGuardEnabled is set to 1 when Cred Guard is enabled on a system.&nbsp; Unsetting this value seems to be worth trying.</p>



<p>&nbsp;Using the same technique as we used previously to get the offset to UseLogonCredential, we find the offset for g_IsCredGuardEnabled (here it is 0x35b88) and patch. &nbsp;Sadly, setting this value to 0 seemed to have no impact on anything relevant to our purposes.&nbsp; It turns out that the SpAcceptCredentials function in wdigest.dll checks both UseLogonCredential and IsCredGuardEnabled values to determine how to handle caching credentials. (We noticed later that XPN pointed out this value in his blog, but never goes farther into it).</p>



<p>So, what happens when we patch wdigest to enable UseLogonCredentials and unset IsCredGuardEnabled?&nbsp;</p>



<div><figure><img data-attachment-id="60" data-permalink="https://teamhydra.blog/credguardbypass_exe_final/" data-orig-file="https://teamhydradotblog.files.wordpress.com/2020/08/credguardbypass_exe_final.png" data-orig-size="631,223" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="credguardbypass_exe_final" data-image-description="" data-medium-file="https://teamhydradotblog.files.wordpress.com/2020/08/credguardbypass_exe_final.png?w=300" data-large-file="https://teamhydradotblog.files.wordpress.com/2020/08/credguardbypass_exe_final.png?w=631" src="https://teamhydradotblog.files.wordpress.com/2020/08/credguardbypass_exe_final.png?w=631" alt="" srcset="https://teamhydradotblog.files.wordpress.com/2020/08/credguardbypass_exe_final.png 631w, https://teamhydradotblog.files.wordpress.com/2020/08/credguardbypass_exe_final.png?w=150 150w, https://teamhydradotblog.files.wordpress.com/2020/08/credguardbypass_exe_final.png?w=300 300w" sizes="(max-width: 631px) 100vw, 631px"></figure></div>



<p>And now after we log in with a new session….</p>



<div><figure><img data-attachment-id="58" data-permalink="https://teamhydra.blog/final_after-fullbypass-cat_-password-plaintext/" data-orig-file="https://teamhydradotblog.files.wordpress.com/2020/08/final_after.fullbypass.cat_.password.plaintext.png" data-orig-size="777,228" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="final_after.fullbypass.cat_.password.plaintext" data-image-description="" data-medium-file="https://teamhydradotblog.files.wordpress.com/2020/08/final_after.fullbypass.cat_.password.plaintext.png?w=300" data-large-file="https://teamhydradotblog.files.wordpress.com/2020/08/final_after.fullbypass.cat_.password.plaintext.png?w=750" src="https://teamhydradotblog.files.wordpress.com/2020/08/final_after.fullbypass.cat_.password.plaintext.png" alt=""></figure></div>



<p>Clear text credentials!&nbsp; Note, this is NOT disabling Credential Guard but instead circumventing it by enabling wdigest.</p>



<p>As Credential Guard exists explicitly to help prevent elevated attackers from obtaining credentials from LSASS I reported this to Microsoft on principle.</p>



<p>Their response:</p>



<p>“After investigating this issue, we do not believe this is a Credential Guard bypass. Credential Guard is meant to protect credentials that were cached while the feature is enabled. If a privileged user disables Credential Guard, then the feature cannot protect subsequent logons. We’ll update our public documentation to clarify this behavior”</p>



<p>Given this response, I suspect this will be a reliable method of gaining clear text credentials on systems with Credential Guard enabled for the foreseeable future.</p>



<p>Memory patching host-based defenses has become a major aspect of modern red teaming.&nbsp; It is used to bypass AMSI, disable ETW, blind EDRs, and get cleartext credentials.&nbsp; This is just one more minor addition to the application of this type of technique. &nbsp;Hopefully posts like this will lead to increased visibility and better mitigation for this type of post-compromise action.</p>



<p>OPERATIONAL CONSIDERATIONS</p>



<p>The PoC provided IS NOT OPSEC SAFE.&nbsp; It is meant to demonstrate the concept.&nbsp; One of the biggest issues with this technique is that you are interacting directly with LSASS which is often looked for by EDRs (especially WriteProcessMemory).&nbsp; There have been many great posts about overcoming some of these hurdles (<a href="https://medium.com/@fsx30/bypass-edrs-memory-protection-introduction-to-hooking-2efb21acffd6">unhooking</a> and using <a href="https://outflank.nl/blog/2019/06/19/red-team-tactics-combining-direct-system-calls-and-srdi-to-bypass-av-edr/">direct syscalls</a>) but I leave it to you to pursue implementing this technique operationally.</p>



<p>DETECTION AND PREVENTION</p>



<p>Not much to say here that hasn’t been said before.&nbsp; Monitoring LSASS, limiting administrators, network segmentation, all the usual suspects apply.&nbsp; A motivated and knowledgeable adversary that gains SYSTEM on a machine in your network will probably be able to accomplish what they need to on THAT system.&nbsp; The goal is to increase the cost in time, effort, and tooling to achieve that goal thus making your network less appealing as a target and increasing opportunities for detection and response. </p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://teamhydra.blog/2020/08/25/bypassing-credential-guard/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24279792</guid>
            <pubDate>Wed, 26 Aug 2020 06:38:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[YC Software Startups: Value and Initial Programming Language Used]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 63 (<a href="https://news.ycombinator.com/item?id=24279611">thread link</a>) | @charliereese
<br/>
August 25, 2020 | https://charliereese.ca/article/top-50-y-combinator-tech-startups | <a href="https://web.archive.org/web/*/https://charliereese.ca/article/top-50-y-combinator-tech-startups">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

			<div>

				<p>This article contains a list of the top 50 YC software startups (sourced from the October 2019 <a href="https://www.ycombinator.com/topcompanies/">YC Top Companies</a> page). It also contains aggregated statistics for valuations and back-end programming languages used.</p>
<p>Values in this article are sourced, but I cannot guarantee their accuracy.</p>
<p>Follow me on Twitter <a href="https://twitter.com/charlieinthe6">@charlieinthe6</a> for similar content. <a href="https://news.ycombinator.com/item?id=24279611">View article comments on HackerNews</a>.</p>
<p>☕</p>
<p><strong>Table of Contents:</strong></p>
<ol>
<li><a href="#top-50">Top 50 Software Startups</a></li>
<li><a href="#stats">Aggregated Stats</a></li>
</ol>
<h3 id="top-50">1. Top 50 Software Startups:</h3>
<table>
<thead>
<tr>
<th>Company</th>
<th>Latest val ($MM)</th>
<th>Initial back-end language(s)</th>
<th>DataSci / LowLv</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://stripe.com/">Stripe</a>: <br>Payment / economic infrastructure for internet</td>
<td>36,000 <small> <a href="https://detroit.cbslocal.com/2020/08/11/general-motors-cfo-exits-suddenly-for-silicon-valley/">source</a> </small></td>
<td>Ruby <small> <a href="https://qr.ae/pN2pJk">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://getcruise.com/">Cruise</a>: <br>Building self-driving car tech</td>
<td>19,000 <small> <a href="https://www.thedrive.com/tech/27872/gm-cruise-divisions-new-1b-investment-sets-valuation-at-staggering-19b">source</a> </small></td>
<td>C++, Python <small> <a href="https://angel.co/company/cruise-automation/jobs/757823-staff-deep-learning-optimization-engineer">source</a>, <a href="https://angel.co/company/cruise-automation/jobs/841627-staff-software-engineer-c-frameworks">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://airbnb.com/">Airbnb</a>: <br>Marketplace to rent someone’s room</td>
<td>18,000 <small> <a href="https://sanfrancisco.cbslocal.com/2020/08/11/airbnb-ipo-reportedly-close-to-filing-wsj/">source</a> </small></td>
<td>Ruby <small> <a href="https://www.forbes.com/sites/quora/2018/02/20/what-technology-stack-does-airbnb-use/#448ff4184025">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://doordash.com/">DoorDash</a>: <br>Food delivery</td>
<td>16,000 <small> <a href="https://www.cnn.com/2020/06/18/tech/doordash-funding-valuation/index.html">source</a> </small></td>
<td>Python <small> <a href="https://medium.com/@DoorDash/implementing-rest-apis-with-embedded-privacy-a2394dc4dceb">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://twitch.tv/">Twitch</a>: <br>Gaming video platform / community</td>
<td>15,000 <small> <a href="https://www.cnbc.com/2020/06/16/amazon-media-assets-worth-500-billion-almost-as-much-as-aws-needham.html#:~:text=To%20get%20to%20%24500%20billion,business%20is%20at%20%243.8%20billion.">source</a> </small></td>
<td>C++, Ruby <small> <a href="https://blog.twitch.tv/en/2015/12/18/twitch-engineering-an-introduction-and-overview-a23917b71a25/">source</a> (founded before Go)</small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://instacart.com/">Instacart</a>: <br>Grocery pick-up / delivery</td>
<td>13,700 <small> <a href="https://techcrunch.com/2020/06/11/instacart-raises-225-million-at-13-7-billion-valuation/">source</a> </small></td>
<td>Ruby <small> <a href="https://stackshare.io/posts/the-tech-behind-instacarts-grocery-delivery-service">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://dropbox.com/">Dropbox</a>: <br>File hosting / syncing</td>
<td>8000 (market cap @ Aug 2020) <small> <a href="https://finance.yahoo.com/quote/DBX?p=DBX">source</a> </small></td>
<td>Python <small> <a href="https://eranki.tumblr.com/post/27076431887/scaling-lessons-learned-at-dropbox-part-1">source</a> </small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://coinbase.com/">Coinbase</a>: <br>Cryptocurrency exchange</td>
<td>8,000 <small> <a href="https://www.coindesk.com/coinbase-existing-valuation-doesnt-need-ipo-lawyer-says">source</a> </small></td>
<td>Ruby <small> <a href="https://blog.coinbase.com/scaling-connections-with-ruby-and-mongodb-99204dbf8857">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://gusto.com/">Gusto</a>: <br>Employee payroll and benefits</td>
<td>3,800 <small> <a href="https://www.forbes.com/sites/donnafuscaldo/2019/07/24/gusto-amasses-3-8-billion-valuation-with-latest-fundraising-round/#50e7fa8d2820">source</a> </small></td>
<td>Ruby <small> <a href="https://boards.greenhouse.io/gusto/jobs/1337386?t=bae6d7cd1">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://rappi.com/">Rappi</a>: <br>On-demand delivery</td>
<td>3,500 <small> <a href="https://techcrunch.com/2020/04/08/ifood-merges-with-delivery-heros-domicilios-com-to-challenge-rappi-in-colombia/">source</a> </small></td>
<td>Go, Node, Python, Java <small> <a href="https://www.rappi.com/jobs/position-detail?id=b88ad33f-7ad5-4e3b-8ecb-f13a3cce3a6a&amp;lang=lang">source</a> (may have used PHP - no source)</small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://flexport.com/">Flexport</a>: <br>Freight forwarding platform</td>
<td>3,200 <small> <a href="https://www.joc.com/technology/wework-spanner-flexports-works_20191021.html">source</a> </small></td>
<td>Ruby <small> <a href="https://stackshare.io/posts/how-flexport-builds-software-to-move-over-1-billion-dollars-in-merchandise">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://reddit.com/">Reddit</a>: <br>Online network of communities</td>
<td>3,000 <small> <a href="https://techcrunch.com/2019/02/11/reddit-300-million/">source</a> </small></td>
<td>Lisp <small> <a href="http://www.aaronsw.com/weblog/rewritingreddit">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://about.gitlab.com/">GitLab</a>: <br>DevOps platform</td>
<td>2,750 <small> <a href="https://www.forbes.com/sites/alexkonrad/2019/09/17/gitlab-doubles-valuation-to-nearly-3-billion/#483591ce1794">source</a> </small></td>
<td>Ruby <small> <a href="https://about.gitlab.com/blog/2018/10/29/why-we-use-rails-to-build-gitlab/">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://brex.com/">Brex</a>: <br>Corporate credit cards</td>
<td>2,750 <small> <a href="https://techcrunch.com/2020/05/19/brex-brings-on-150m-in-new-cash-in-case-of-an-extended-recession/">source</a> </small></td>
<td>Elixir <small> <a href="https://medium.com/brexeng/why-brex-chose-elixir-fe1a4f313195">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://pagerduty.com/">PargerDuty</a>: <br>SaaS incident response platform</td>
<td>2,270 <small> <a href="https://www.google.com/search?tbm=fin&amp;q=NYSE:+PD&amp;stick=H4sIAAAAAAAAAONgecRowS3w8sc9YSn9SWtOXmPU5OIKzsgvd80rySypFJLmYoOyBKX4uXj10_UNDdOyCwszkotLeBaxcvhFBrtaKQS4AAASRGHASAAAAA&amp;sa=X&amp;ved=2ahUKEwjCtra68ZbrAhUYXc0KHdn_DoAQ3ecFMAB6BAhqEBc&amp;biw=1278&amp;bih=968#scso=_Z4c0X5TmCsjOtQbEu5zQAQ1:0">source</a> </small></td>
<td>Ruby <small> <a href="https://www.pagerduty.com/blog/elixir-at-pagerduty/">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://checkr.com/">Checkr</a>: <br>Background checks</td>
<td>2,200 <small> <a href="https://www.forbes.com/sites/bizcarson/2019/09/19/checkr-background-funding-round/#552c8c845460">source</a> </small></td>
<td>Ruby <small> <a href="https://engineering.checkr.com/yet-another-attempt-at-faster-builds-caching-db-schema-efe63d367f5">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://podium.com/">Podium</a>: <br>Interaction management platform</td>
<td>1,500 <small> <a href="https://techcrunch.com/2020/04/07/utahs-podium-raises-125m-series-c-led-by-yc-after-reaching-100m-arr/">source</a> </small></td>
<td>Ruby <small> <a href="https://devchat.tv/elixir-mix/emx-072-people-centered-solutions-with-travis-elnicky/">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://segment.com/">Segment</a>: <br>Customer data platform</td>
<td>1,500 <small> <a href="https://www.bloomberg.com/news/articles/2019-04-02/startup-segment-is-worth-1-5-billion-thanks-to-companies-troves-of-customer-data">source</a> </small></td>
<td>Go, JS <small> <a href="https://www.workatastartup.com/companies/88">source</a>, <a href="https://angel.co/company/segment/jobs/348613-senior-software-engineer">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://docker.com/">Docker</a>: <br>Build / deliver software in containers</td>
<td>1000 est. <small> <a href="https://techcrunch.com/2019/11/13/mirantis-acquires-docker-enterprise/">source</a>, <a href="https://techcrunch.com/2018/10/15/docker-has-raised-92-million-in-new-funding/">source</a> </small></td>
<td>Go <small> <a href="https://thenewstack.io/go-programming-language-helps-docker-container-ecosystem/">source</a>, <a href="https://techcrunch.com/2019/11/13/after-selling-enterprise-biz-docker-lands-35m-investment-and-new-ceo/">source</a> </small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://scale.com/">Scale</a>: <br>Training / validation data for ML</td>
<td>1,000 <small> <a href="https://www.forbes.com/sites/stevenli1/2019/12/22/scale-ai-growth-story/#3360214b6f4a">source</a> </small></td>
<td>Python, JS <small> <a href="https://scale.com/careers/41e05b90-7e65-4dac-8676-50be9c1afc27">source</a>, <a href="https://scale.com/careers/37b0c485-cd77-4170-ac07-a8521b9a10fc">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://amplitude.com/">Amplitude</a>: <br>Product / customer analytics</td>
<td>1,000 <small> <a href="https://www.forbes.com/sites/davidjeans/2020/05/20/amplitude-now-valued-1-billion-backed-sequoia-benchmark/#68a1ad2041c7">source</a> </small></td>
<td>Python, Java <small> <a href="https://news.ycombinator.com/item?id=13301832&amp;p=2">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://zapier.com/">Zapier</a>: <br>Connect apps and automate workflows</td>
<td>1000 est. (20x 2018 ARR) <small> <a href="https://www.drift.com/blog/how-zapier-grew/">source</a> </small></td>
<td>Python <small> <a href="https://zapier.com/blog/zapier-tech-stack/">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://faire.com/">Faire</a>: <br>B2B wholesale marketplace</td>
<td>1,000 <small> <a href="https://www.forbes.com/sites/laurendebter/2019/10/30/faire-wholesale-marketplace-series-d-1-billion-valuation/#21c2bdfb7aa9">source</a> </small></td>
<td>Java <small> <a href="https://boards.greenhouse.io/faire/jobs/4187498002">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://plangrid.com/">PlanGrid</a>: <br>Construction software</td>
<td>875 <small> <a href="https://techcrunch.com/2018/11/20/autodesk-agrees-to-buy-plangrid-for-875-million/#:~:text=Autodesk%20announced%20plans%20to%20acquire%20PlanGrid%20for%20%24875%20million%20today.">source</a> </small></td>
<td>Python <small> <a href="https://stackoverflow.com/jobs/companies/plangrid">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://mixpanel.com/">Mixpanel</a>: <br>User analytics</td>
<td>865 <small> <a href="https://www.forbes.com/pictures/feki45efhmk/mixpanel/#71dc3892190f">source</a> </small></td>
<td>Python<small> <a href="https://boards.greenhouse.io/mixpanel/jobs/1545756?gh_jid=1545756">source</a> (founded before Go)</small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://benchling.com/">Benchling</a>: <br>Biotech research</td>
<td>850 <small> <a href="https://www.forbes.com/sites/amyfeldman/2020/05/28/biotech-rd-software-startup-benchling-started-by-mit-undergrads-scores-850-million-valuation-amid-coronavirus-pandemic/#5de0e0c61dcd">source</a> </small></td>
<td>Python <small> <a href="https://www.workatastartup.com/companies/445">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://meesho.com/">Meesho</a>: <br>Social commerce platform</td>
<td>700 <small> <a href="https://economictimes.indiatimes.com/small-biz/startups/newsbuzz/meesho-raised-125-mn-from-naspers-and-others/articleshow/70641492.cms">source</a> </small></td>
<td>Java <small> <a href="https://angel.co/company/meesho/jobs/596045-software-development-engineer-iii">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://optimizely.com/">Optimizely</a>: <br>Digital experience optimization / testing</td>
<td>600 <small> <a href="https://pitchbook.com/newsletter/optimizely-brings-in-50m#:~:text=Optimizely%2C%20which%20operates%20an%20optimization,with%20participation%20from%20Accenture%20Ventures">source</a> </small></td>
<td>Python <small> <a href="https://news.ycombinator.com/item?id=2647003">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://algolia.com/">Algolia</a>: <br>Search service</td>
<td>578 <small> <a href="https://www.bizjournals.com/sanfrancisco/news/2019/10/15/fast-growing-san-francisco-search-company-scores.html">source</a> </small></td>
<td>C++, Ruby <small> <a href="https://www.algolia.com/doc/faq/why/what-architecture-does-algolia-use-to-provide-an-high-performance-search-engine/">source</a>, <a href="https://stackshare.io/posts/how-algolia-built-their-realtime-search-as-a-service-product">source</a> </small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://goat.com/">Goat</a>: <br>Sneaker marketplace</td>
<td>550 <small> <a href="https://www.forbes.com/sites/kurtbadenhausen/2019/02/07/foot-locker-invests-100-million-in-secondary-sneaker-firm-goat/#3b07b65e568d">source</a> </small></td>
<td>Ruby <small> <a href="https://www.workatastartup.com/jobs/20990">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://standard.ai/">StandardCognition</a>: <br>Autonomous checkout</td>
<td>535 <small> <a href="https://techcrunch.com/2019/07/25/standard-cognition-lands-35m-at-535m-valuation-to-battle-amazon-go/">source</a> </small></td>
<td>Python <small> <a href="https://jobs.lever.co/standard/9b874041-7cfe-4e0a-a459-fcd66451ee75">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://people.ai/">People.ai</a>: <br>Intelligent CRM</td>
<td>500 <small> <a href="https://techcrunch.com/2019/05/21/people-ai-the-predictive-sales-startup-raises-60m-at-around-500m-valuation/#:~:text=People.ai%2C%20the%20predictive%20sales,around%20%24500M%20valuation%20%7C%20TechCrunch">source</a> </small></td>
<td>Python <small> <a href="https://www.workatastartup.com/companies/1299">source</a>, <a href="https://news.ycombinator.com/item?id=16974829">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://razorpay.com/">Razorpay</a>: <br>Digital payments</td>
<td>450 <small> <a href="https://www.pymnts.com/news/investment-tracker/2019/razorpay-sequoia-india-ribbit-capital/#:~:text=With%20the%20funding%2C%20Razorpay%20is,Razorpay%20X%20neo%2Dbanking%20platform.">source</a> </small></td>
<td>PHP <small> <a href="https://news.ycombinator.com/item?id=12407955">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://equipmentshare.com/">EquipmentShare</a>: <br>Equipment rentals</td>
<td>400 est. <small> <a href="https://www.forbes.com/sites/alexkonrad/2019/11/18/softbank-looks-to-invest-equipmentshare-unicorn/#48a6b2d779b8">source</a> </small></td>
<td>Python <small> <a href="https://news.ycombinator.com/item?id=16492994&amp;p=2">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://weebly.com/">Weebly</a>: <br>Website builder</td>
<td>365 <small> <a href="https://techcrunch.com/2018/04/26/square-acquires-weebly/">source</a> </small></td>
<td>PHP <small> <a href="https://news.ycombinator.com/item?id=2839742">source</a>, <a href="https://news.ycombinator.com/item?id=5729035">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://webflow.com/">Webflow</a>: <br>Website builder</td>
<td>350 <small> <a href="https://growthhackers.com/articles/how-webflow-quietly-grew-without-vc-money?r=latest">source</a> </small></td>
<td>JS <small> <a href="https://boards.greenhouse.io/webflow/jobs/1838218">source</a>, <a href="https://www.workatastartup.com/companies/566">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://matterport.com/">Matterport</a>: <br>3D technology platform</td>
<td>325 <small> <a href="https://techcrunch.com/2019/03/05/matterport-2/#:~:text=Matterport%20had%20raised%20just%20under,DCM%2C%20Qualcomm%20Ventures%20and%20more.">source</a> </small></td>
<td>C++ <small> <a href="https://news.ycombinator.com/item?id=3300290">source</a>, <a href="https://news.ycombinator.com/item?id=5186626">source</a> </small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://influxdata.com/">InfluxData</a>: <br>InfluxDB creator</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/influxdb/company_financials">source</a> </small></td>
<td>Go <small> <a href="https://github.com/influxdata/influxdb">source</a> </small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://embarktrucks.com/">Embark</a>: <br>Self-driving trucks</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/embark-trucks/company_financials">source</a> </small></td>
<td>Python, C++ <small> <a href="https://jobs.lever.co/embark/25999d12-5d82-45fc-b3e4-0ebc335f6f59">source</a> </small></td>
<td>Y / Y</td>
</tr>
<tr>
<td><a href="https://sendbird.com/">SendBird</a>: <br>Chat / calls as a service</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/sendbird/company_financials">source</a> </small></td>
<td>Python <small> <a href="https://sendbird.com/careers/4317963002">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://rescale.com/">Rescale</a>: <br>Cloud simulation platform</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/rescale/company_financials">source</a> </small></td>
<td>Java, Python <small> <a href="https://news.ycombinator.com/item?id=5828217">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://gocardless.com/">GoCardless</a>: <br>Direct debit payments</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/gocardless/company_financials">source</a> </small></td>
<td>Ruby <small> <a href="https://news.ycombinator.com/item?id=14978103">source</a>, <a href="https://news.ycombinator.com/item?id=16283469">source</a>, <a href="https://news.ycombinator.com/item?id=4596703">source</a>, <a href="https://boards.greenhouse.io/gocardless/jobs/2282283">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://rigetti.com/">Rigetti Computing</a>: <br>Quantum computing</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/rigetti-computing/company_financials">source</a> </small></td>
<td>Python, Lisp, C <small> <a href="https://news.ycombinator.com/item?id=16968407">source</a> </small></td>
<td>Y / Y</td>
</tr>
<tr>
<td><a href="https://messagebird.com/">MessageBird</a>: <br>Omnichannel customer communication</td>
<td>300 <small> <a href="https://www.fool.com/investing/2020/03/13/twilio-investors-keep-tabs-on-startup-messagebird.aspx">source</a> </small></td>
<td>Go, PHP, Python, Java <small> <a href="https://careers.sh/uk/kompaniya/messagebird/robochi-mistsya/71009">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://ironcladapp.com/">Ironclad</a>: <br>Digital contracting platform</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/ironclad/company_financials">source</a> </small></td>
<td>JS, Java <small> <a href="https://jobs.lever.co/ironcladapp/2d6616e3-27b8-4138-a6fc-238e46757822">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://sift.com/">Sift</a>: <br>Digital safety and fraud detection</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/sift-science/company_financials">source</a> </small></td>
<td>Java, Ruby <small> <a href="https://news.ycombinator.com/item?id=6657091">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://mattermost.com/">Mattermost</a>: <br>Open source Slack alternative</td>
<td>250 est. <small> <a href="https://app.dealroom.co/companies/mattermost">source</a> </small></td>
<td>Go <small> <a href="https://github.com/mattermost/mattermost-server">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://xendit.co/">Xendit</a>: <br>Digital payments</td>
<td>150 est. <small> <a href="https://www.ycombinator.com/topcompanies/">source</a> </small></td>
<td>JS <small> <a href="https://www.workatastartup.com/companies/938">source</a>, <a href="https://www.xendit.co/en/careers/job-application/?gh_jid=4114942003">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://easypost.com/">EasyPost</a>: <br>Logistics software</td>
<td>150 est. <small> <a href="https://www.ycombinator.com/topcompanies/">source</a> </small></td>
<td>Ruby <small> <a href="https://news.ycombinator.com/item?id=6231587">source</a>, <a href="https://news.ycombinator.com/item?id=13542390">source</a>, <a href="https://www.linkedin.com/jobs/view/senior-software-engineer-at-easypost-1669977835/">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://newfrontinsurance.com/">Newfront</a>: <br>Insurance platform</td>
<td>150 est. <small> <a href="https://www.ycombinator.com/topcompanies/">source</a> </small></td>
<td>JS, Go <small> <a href="https://www.keyvalues.com/newfront">source</a>, <a href="https://news.ycombinator.com/item?id=21683554">source</a> </small></td>
<td>N / N</td>
</tr>
</tbody>
</table>
<p><small>
<p>Note: Ginkgo Bioworks, Boom Supersonic, Grin, Memebox, Helion Energy, North, RelativitySpace, and The Athletic were excluded from the below list; I didn't feel they were primarily software businesses. Feel free to disagree with my judgement.</p>
<p>Note: values current as of August 15, 2020.</p>
<p>Note: if one language was the primary language used to build the initial product, one language is listed above. If it was not clear which language was primary, multiple languages are listed above.</p>
<p>Note: if I couldn't find which language was used to build the startup initially, I referenced the oldest job posting I could find.</p>
<p>Note: valuations are approximate and predominantly sourced from recent articles online. Where I couldn't find an indication of value, ~$150M is assumed; startups listed above were all worth +$150M as of October 2019, as per the <a href="https://www.ycombinator.com/topcompanies/">YC Top Companies</a> page.</p>
<p>Note: "Y" and "N" values in the "DataSci / LowLv" column describe a startup's primary product (i.e. ML startups would have a "Y" for DataSci). It was included to provide additional colour on why initial back-end language(s) may have been used / selected. The values in this column are based entirely on my own judgement. Feel free to disagree with them or ignore them.</p>
<p>Note: Ruby and ruby on rails was a popular choice for YC startups around 2010 - 2012. Anecdotally, ~40% of YC startups used ruby during its peak popularity.</p>
</small></p>

<h3 id="stats">2. Aggregated Stats:</h3>

<p><strong>Startups with one (initial) primary back-end language:</strong> </p>
<table>
<thead>
<tr>
<th>Language</th>
<th>Count</th>
<th>Total Valuation ($BN)</th>
</tr>
</thead>
<tbody>
<tr>
<td>All</td>
<td>35 (70%)</td>
<td>132.1 (75%)</td>
</tr>
<tr>
<td>Ruby</td>
<td>13 (26%)</td>
<td>92.4 (52%)</td>
</tr>
<tr>
<td>Python</td>
<td>11 (22%)</td>
<td>29.9 (17%)</td>
</tr>
<tr>
<td>Lisp</td>
<td>1 (2%)</td>
<td>3.0 (2%)</td>
</tr>
<tr>
<td>Elixir</td>
<td>1 (2%)</td>
<td>2.8 (2%)</td>
</tr>
<tr>
<td>Java</td>
<td>2 (4%)</td>
<td>1.7 (1%)</td>
</tr>
<tr>
<td>Go</td>
<td>3 (6%)</td>
<td>1.6 (1%)</td>
</tr>
<tr>
<td>PHP</td>
<td>2 (4%)</td>
<td>0.8 (0%)</td>
</tr>
<tr>
<td>JS</td>
<td>2 (4%)</td>
<td>0.5 (0%)</td>
</tr>
<tr>
<td>C++</td>
<td>1 (2%)</td>
<td>0.3 (0%)</td>
</tr>
</tbody>
</table>

<p><strong>Startups with multiple (initial) primary back-end languages:</strong> </p>
<table>
<thead>
<tr>
<th>Language</th>
<th>Count</th>
<th>Total Valuation ($BN)</th>
</tr>
</thead>
<tbody>
<tr>
<td>All</td>
<td>15 (30%)</td>
<td>44.4 (25%)</td>
</tr>
<tr>
<td>C++ is one</td>
<td>4 (8%)</td>
<td>34.9 (20%)</td>
</tr>
<tr>
<td>Python is one</td>
<td>8 (16%)</td>
<td>25.7 (15%)</td>
</tr>
<tr>
<td>Ruby is one</td>
<td>3 (6%)</td>
<td>15.9 (9%)</td>
</tr>
<tr>
<td>JS is one</td>
<td>5 (10%)</td>
<td>6.5 (4%)</td>
</tr>
<tr>
<td>Java is one</td>
<td>6 (12%)</td>
<td>5.7 (3%)</td>
</tr>
<tr>
<td>Go is one</td>
<td>4 (8%)</td>
<td>5.5 (3%)</td>
</tr>
<tr>
<td>Lisp is one</td>
<td>1 (2%)</td>
<td>0.3 (0%)</td>
</tr>
<tr>
<td>C is one</td>
<td>1 (2%)</td>
<td>0.3 (0%)</td>
</tr>
<tr>
<td>PHP is one</td>
<td>1 (2%)</td>
<td>0.3 (0%)</td>
</tr>
</tbody>
</table>
<p><small>Note: "Startups with multiple (initial) primary back-end languages" table doesn't add to 100% because multiple languages were used for startups.</small></p>

<p><strong>All startups:</strong> </p>
<table>
<thead>
<tr>
<th>Language</th>
<th>Count</th>
<th>Total Valuation ($BN)</th>
</tr>
</thead>
<tbody>
<tr>
<td>All</td>
<td>50 (100%)</td>
<td>176.5 (100%)</td>
</tr>
<tr>
<td>Ruby is one</td>
<td>16 (32%)</td>
<td>108.3 (61%)</td>
</tr>
<tr>
<td>Python is one</td>
<td>19 (38%)</td>
<td>55.6 (32%)</td>
</tr>
<tr>
<td>C++ is one</td>
<td>5 (10%)</td>
<td>35.2 (20%)</td>
</tr>
<tr>
<td>Java is one</td>
<td>8 (16%)</td>
<td>7.4 (4%)</td>
</tr>
<tr>
<td>Go is one</td>
<td>7 (14%)</td>
<td>7.0 (4%)</td>
</tr>
<tr>
<td>JS is one</td>
<td>7 (14%)</td>
<td>7.0 (4%)</td>
</tr>
<tr>
<td>Lisp is one</td>
<td>2 (4%)</td>
<td>3.3 (2%)</td>
</tr>
<tr>
<td>Elixir is one</td>
<td>1 (2%)</td>
<td>2.8 (2%)</td>
</tr>
<tr>
<td>PHP is one</td>
<td>3 (6%)</td>
<td>1.1 (1%)</td>
</tr>
<tr>
<td>C is one</td>
<td>1 (2%)</td>
<td>0.3 (0%)</td>
</tr>
</tbody>
</table>
<p><small>Note: "All startups" table doesn't add to 100% because multiple languages were used for some startups.</small></p>
				
			</div>

		</article></div>]]>
            </description>
            <link>https://charliereese.ca/article/top-50-y-combinator-tech-startups</link>
            <guid isPermaLink="false">hacker-news-small-sites-24279611</guid>
            <pubDate>Wed, 26 Aug 2020 06:03:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fast.ai Released a New Free Deep Learning Course]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24279146">thread link</a>) | @yadavrohit
<br/>
August 25, 2020 | https://www.analyticsdrift.com/a-new-free-deep-learning-course-by-fast-ai/ | <a href="https://web.archive.org/web/*/https://www.analyticsdrift.com/a-new-free-deep-learning-course-by-fast-ai/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                    <!-- .entry-header -->

                
                        <div>
                                    <p><img width="740" height="474" src="https://i0.wp.com/www.analyticsdrift.com/wp-content/uploads/2020/08/deep-learning-courses-online.jpg?fit=740%2C474&amp;ssl=1&amp;is-pending-load=1" alt="deep learning course" loading="lazy" data-lazy-srcset="https://i0.wp.com/www.analyticsdrift.com/wp-content/uploads/2020/08/deep-learning-courses-online.jpg?w=740&amp;ssl=1 740w, https://i0.wp.com/www.analyticsdrift.com/wp-content/uploads/2020/08/deep-learning-courses-online.jpg?resize=300%2C192&amp;ssl=1 300w" data-lazy-sizes="(max-width: 740px) 100vw, 740px" data-lazy-src="https://i0.wp.com/www.analyticsdrift.com/wp-content/uploads/2020/08/deep-learning-courses-online.jpg?fit=740%2C474&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">                </p>
            
                                            </div>

            

        <!-- end slider-section -->
                                    

    <div>
        <div>
            
<p>fast.ai — an independent research center that makes superior solutions for easy accessibility of deep learning — has released a free course, along with the book. The course — <a href="https://course.fast.ai/videos/?lesson=1" target="_blank" rel="noreferrer noopener">Practical Deep Learning for Coders</a> — is aimed at the introduction to machine learning and deep learning, and production and deployment of models.</p>



<p>Practical Deep Learning Course by fast.ai covers the material from the book <a href="https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527" target="_blank" rel="noreferrer noopener">PyTorch: AI Applications Without a PhD</a>. Every video lesson covers one chapter of the book that is also freely available if you do not want to purchase it from Amazon. PyTorch: AI Applications Without a PhD. is hosted on GitHub, where you can access the book in a freely available interactive <a href="https://github.com/fastai/fastbook" target="_blank" rel="noreferrer noopener">Jupyter Notebooks</a>.</p>



<p><strong>Also Read:</strong> <a href="https://www.analyticsdrift.com/amazon-makes-its-machine-learning-course-free-for-all/" target="_blank" rel="noreferrer noopener">Amazon Makes Its Machine Learning Course Free For All</a></p>



<p>However, the entire book is not covered in this Practical Deep Learning for Coders course. In the future, fast.ai will release the second part of the course that will complete the book’s remaining lessons.</p>



<p>Unlike most of the free courses and short-term courses, this deep learning course by fast.ai covers an end-to-end data science workflow as it also provides lessons on the deployment of models and data ethics. This makes it a must for aspirants who want to learn advanced techniques and make themselves relevant to the industry.</p>



<p><strong>What you will learn:</strong></p>



<p>1.<strong> </strong>Optimize models to get exceptional results in computer vision, NLP, recommenders, and more</p>



<p>2. How to turn your models into web applications, and deploy them</p>



<p>3. How to enhance your models’ accuracy, speed, and reliability&nbsp;</p>



<p>4. Ethical implementation while making models</p>



<p>5. Other techniques such as random forests and gradient boosting, parameters and activations, random initialization and transfer learning, among others</p>



<p>Over the years, fast.ai has been releasing some of the best deep learning courses online for aspirants to learn for free; Last week, it released a course on ethics — <a href="https://ethics.fast.ai/videos/?lesson=1" target="_blank" rel="noreferrer noopener">Practical Data Ethics</a>.</p>



<p><strong>Note:</strong> Please do not make the <a href="https://github.com/fastai/fastbook" target="_blank" rel="noreferrer noopener">Jupyter Notebook</a> version of the book into PDF and distribute it to respect the provider’s generosity. Use it only for your education or learning if you cannot buy it on Amazon.</p>



<p><strong>Subscribe to our newsletter for free to get the most-read stories every week.</strong>&nbsp;<strong>Provide your email id below.</strong>&nbsp;<strong>We never sell your information.</strong></p>


  <!-- .wpforms-container -->                <div>
                    
                                        
        <div>

                <p><a href="https://www.analyticsdrift.com/author/analyticsdriftgmail-com/"><img alt="" src="https://secure.gravatar.com/avatar/b4013be20eaee509a78cd792d7474854?s=150&amp;r=g" srcset="https://secure.gravatar.com/avatar/b4013be20eaee509a78cd792d7474854?s=300&amp;r=g 2x" height="150" width="150" loading="lazy" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a>
                </p>
                
        </div>

                                            </div>
                                            
                        
	<nav role="navigation" aria-label="Continue Reading">
		<h2>Continue Reading</h2>
		
	</nav>                    </div><!-- .entry-content -->
    </div>
                        </div></div>]]>
            </description>
            <link>https://www.analyticsdrift.com/a-new-free-deep-learning-course-by-fast-ai/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24279146</guid>
            <pubDate>Wed, 26 Aug 2020 04:33:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PCI Express Retimers vs. Redrivers: An Eye-Popping Difference (2019)]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 19 (<a href="https://news.ycombinator.com/item?id=24278760">thread link</a>) | @tragiclos
<br/>
August 25, 2020 | https://www.asteralabs.com/2019/06/26/pci-express-retimers-vs-redrivers-an-eye-popping-difference/ | <a href="https://web.archive.org/web/*/https://www.asteralabs.com/2019/06/26/pci-express-retimers-vs-redrivers-an-eye-popping-difference/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Retimers and redrivers have enabled longer physical channels in servers and storage systems since Peripheral Component Interface Express (PCIe) 3.0 was first introduced almost 10 years ago. Now that PCIe 4.0 is ramping up and PCIe 5.0 is just around the corner, how do these reach extension tools stack up in the face of new challenges in high-speed connectivity?</p>
<p>A redriver is a mostly analog reach extension device designed to boost the high-frequency portions of a signal to counteract the frequency-dependent attenuation caused by the interconnect: the central processing unit (CPU) package, system board, connectors and so on. A redriver’s data path typically includes a continuous time linear equalizer (CTLE), a wideband gain stage and a linear driver. In addition, redrivers often have input loss-of-signal threshold and output receiver (Rx) detection capability. Figure 1 illustrates a typical redriver block diagram.</p>
<p><a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer"><img src="https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block.jpg" alt="" width="731" height="419" srcset="https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block.jpg 731w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-300x172.jpg 300w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-260x150.jpg 260w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-523x300.jpg 523w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-200x115.jpg 200w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-564x323.jpg 564w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-600x344.jpg 600w" sizes="(max-width: 731px) 100vw, 731px"></a></p>
<p><a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer">Figure 1: Redriver block diagram [1]</a></p>
<p>A retimer is a mixed signal analog/digital device that is protocol-aware and has the ability to fully recover the data, extract the embedded clock and retransmit a fresh copy of the data using a clean clock. In addition to the CTLE and wideband gain stages also found in a redriver, retimers contain a clock and data recovery (CDR) circuit, a decision feedback equalizer (DFE) and a transmit (Tx) finite impulse response (FIR) driver. Finite state machines (FSMs) and/or a microcontroller typically manage the automatic adaptation of the CTLE, wideband gain, DFE and FIR driver, and implement the PCIe link training and status state machine (LTSSM). Figure 2 illustrates a typical retimer block diagram.</p>
<p><a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer"><img src="https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block.jpg" alt="retimer-block" width="787" height="440" srcset="https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block.jpg 787w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-300x168.jpg 300w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-768x429.jpg 768w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-260x145.jpg 260w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-537x300.jpg 537w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-200x112.jpg 200w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-564x315.jpg 564w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-600x335.jpg 600w" sizes="(max-width: 787px) 100vw, 787px"></a></p>
<p><a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer">Figure 2: Retimer block diagram [1]</a></p>
<p>In simple terms, a redriver amplifies a signal, whereas a retimer retransmits a fresh copy of the signal. Figure 3 illustrates this and shows how an attenuated eye opening is boosted by a redriver and completely regenerated by a retimer.</p>
<p><img src="https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-1024x238.png" alt="eye-attenuated" width="1024" height="238" srcset="https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-1024x238.png 1024w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-300x70.png 300w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-768x178.png 768w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-1536x357.png 1536w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-260x60.png 260w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-800x186.png 800w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-200x46.png 200w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-564x131.png 564w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-600x139.png 600w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated.png 1658w" sizes="(max-width: 1024px) 100vw, 1024px"></p>
<p>Figure 3: Example of an eye attenuated by a channel (left), the eye after a redriver (middle) and the eye after a retimer (right)</p>
<p>The PCIe 4.0 specification took the unprecedented step of formally defining the terms “retimer,” “redriver” and the superset term “repeater,” all of which are types of extension devices or components whose purpose is to extend the physical length of a link. The definitions are:</p>
<ul>
<li><strong>Repeater</strong>: An imprecise term for an extension device [2]. (This term causes confusion … please don’t use it!)</li>
<li><strong>Redriver</strong>: A non-protocol-aware software-transparent extension device [2].</li>
<li><strong>Retimer</strong>: A physical layer protocol-aware, software-transparent extension device that forms two separate electrical link segments [2].</li>
</ul>
<h3>Use Cases for Retimers and Redrivers</h3>
<p>Reach extension devices are necessary whenever the channel – the electrical path between the root complex (RC) and endpoint (EP) – is longer than the PCIe specification allows. The specification defines the maximum channel length in terms of insertion loss at the Nyquist frequency (an informative specification, but easy to validate) and in terms of a reference receiver’s ability to sufficiently equalize and recover the data assuming a worst-case link partner transmitter (a normative specification, but time-consuming to validate).</p>
<p>Suffice it to say, at PCIe 4.0 speeds, reach extension devices are necessary for:</p>
<ul>
<li>Multiconnector topologies.</li>
<li>Cabled topologies.</li>
<li>Single-connector add-in card (AIC) topologies with baseboard channels longer than 9.5 inches.</li>
</ul>
<p>Figure 4 shows an example of a two-connector “riser card” topology, which ordinarily would exceed the PCIe 4.0 loss budget of 28 dB. A redriver or retimer will enable reliable, error-free communication between the RC and EP. But how do you choose which one is the right tool for the job? Well, it helps to know more about the fundamental differences in their capabilities.</p>
<p><img src="https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-1024x391.png" alt="redriver" width="1024" height="391" srcset="https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-1024x391.png 1024w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-300x115.png 300w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-768x293.png 768w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-260x99.png 260w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-785x300.png 785w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-200x76.png 200w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-564x216.png 564w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-600x229.png 600w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver.png 1120w" sizes="(max-width: 1024px) 100vw, 1024px"><br>
Figure 4: Example of redriver (top) and retimer (bottom) used in a two-connector topology</p>
<h3>Comparing Retimer and Redriver Capabilities</h3>
<p>Not all redrivers and retimers are the same. There are many distinctions between the two, which are universally true for all PCIe reach extension devices. For example:</p>
<p><strong>Retimers actively participate in the PCIe protocol; redrivers do not.</strong> The PCIe base specification spells out how and to what extent retimers participate in the protocol during Detect, Recovery, L0 and other LTSSM states. Equalization to the L0 and L1 link states requires value-added functionality from the retimer (handshakes, timeouts, bit manipulation, etc.). Redrivers are unaware of and unparticipating in the protocol. If the link works reliably the first time, that’s great! But if the link experiences marginality of any sort, it becomes exceedingly difficult to pinpoint whether the problem is physically before the redriver or after it, since the redriver’s role in link formation is undefined and unknown to its link partners.</p>
<p><strong>Retimers reset the jitter and insertion loss budgets; redrivers do not.</strong> A retimer’s CDR fully recovers the data stream and retransmits it on a clean clock. Starting with a fresh copy of the data enables the extension of the channel to twice the original specification. Without a CDR, the best a redriver can do is attenuate (not reset) the data-dependent jitter (DDJ) caused by intersymbol interference (ISI). A redriver cannot attenuate uncorrelated or random jitter (RJ). In fact, a redriver will always add to RJ due to its own device thermal noise in a root-mean-square (RMS) manner <a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer">[1]</a>.</p>
<p><strong>Retimers have a DFE; redrivers do not.</strong> A DFE compensates for reflections in the channel response caused by impedance discontinuities in board vias, connectors and package socket-board interfaces. The nice thing about a DFE is that it is unaffected by crosstalk. The DFE equalizes just as well in the presence of crosstalk, and once the data is sampled by the retimer’s CDR, crosstalk is eliminated for good. Redrivers use a CTLE that boosts both the signal and the noise <a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer">[1]</a>. Crosstalk is not eliminated or even attenuated through a redriver; in fact, it gets amplified.</p>
<p><strong>Retimers automatically adapt their receive and transmit equalizers to match the characteristics of the channel and the link partner’s needs; redrivers do not.</strong> A retimer will examine the signal it receives and adjust the CTLE and DFE to minimize its own bit error rate (BER). Likewise, the retimer’s transmitter will adjust its de-emphasis and pre-shoot equalization to minimize the link partner’s BER according to PCIe equalization protocol. A redriver, conversely, operates with a static equalizer setting. The optimal setting (which can be different for every channel in the system) is often painstakingly selected following an exhaustive search in Input/Output Buffer Information Specification (IBIS) algorithmic modeling interface (AMI) simulations and again in lab testing – a process fondly referred to as “tuning.”</p>
<p><strong>Retimers have built-in features to help diagnose link issues (both electrical and protocol); redrivers do not.</strong> Retimers have tools for assessing the electrical performance (internal eye monitors, pattern generators, pattern checkers) and protocol performance (link state history monitors, timeout adjustments). Redrivers cannot offer such diagnostic features because they are neither protocol-aware nor aware of the actual data passing through. Redrivers do not know what state the link is in.</p>
<p><strong>Retimers correct for lane-to-lane skew; redrivers do not.</strong> PCIe has a tight requirement on the physical skew between lanes on a board (1.6 ns for PCIe 4.0), typically caused by mismatches in channel routing length [3]. Retimers are required to compensate and reset any lane-to-lane skew, effectively doubling the specification budget. Redrivers cannot compensate for lane-to-lane skew, and what’s worse is that they may degrade the skew depending on how symmetric the redriver package is across all lanes.</p>
<p><strong>Retimers can be placed anywhere between two PCIe-compliant channels; redrivers cannot.</strong> By definition, retimers extend the total PCIe channel reach by two times the specification. A redriver’s reach extension, however, depends on where it is placed in the channel – how much loss is before the redriver versus how much is after <a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer">[1]</a>. The specific placement of a redriver must be carefully determined by IBIS-AMI simulation and experimentation. Too close to the root complex transmitter, and the redriver’s CTLE will enter nonlinear operation and will have limited benefit. Placed too far from the transmitter, the redriver’s device noise may significantly degrade the signal-to-noise ratio (SNR) of the data signal.</p>
<p>It’s not all bad news for redrivers. They do have lower power consumption and lower input-to-output latency compared to retimers. But if the link does not form in the first place or if the BER is too high, none of that matters!</p>
<p><img src="https://www.asteralabs.com/wp-content/uploads/2020/02/comparision.png" alt="comparision" width="809" height="527" srcset="https://www.asteralabs.com/wp-content/uploads/2020/02/comparision.png 809w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-300x195.png 300w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-768x500.png 768w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-230x150.png 230w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-461x300.png 461w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-200x130.png 200w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-564x367.png 564w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-600x391.png 600w" sizes="(max-width: 809px) 100vw, 809px"></p>
<p>Table 1: Comparison of retimer and redriver capabilities and usage</p>
<h3>Outlook for PCIe 4.0 Systems</h3>
<p>Looking ahead to the upcoming PCIe 4.0 systems, all signs are pointing to an increased need for reach extension devices – and retimers in particular – due to several trends and challenges:</p>
<ul>
<li>CPUs have more PCIe lanes per socket (&gt;100 in some cases [4]) compared to PCIe 3.0. This leads to a greater number of PCIe slots and riser cards, denser routing, and an increased use of multiconnector topologies.</li>
<li>PCIe is shifting from an I/O bus to a multipurpose system interconnect. This means that more servers will be designed to be modular, allowing an array of compute, storage and networking resources to plug in to an increasing number of PCIe slots. This type of open, “plug anything in and it will work” server architecture requires a reach extension solution that is PCIe compliant with plug-and-play interoperability.</li>
<li>The disaggregation of resources such as modular servers, storage trays and accelerator trays is pushing endpoints physically away from CPUs, requiring cables or carrier cards to connect everything together. These longer physical topologies will increasingly need reach …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.asteralabs.com/2019/06/26/pci-express-retimers-vs-redrivers-an-eye-popping-difference/">https://www.asteralabs.com/2019/06/26/pci-express-retimers-vs-redrivers-an-eye-popping-difference/</a></em></p>]]>
            </description>
            <link>https://www.asteralabs.com/2019/06/26/pci-express-retimers-vs-redrivers-an-eye-popping-difference/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24278760</guid>
            <pubDate>Wed, 26 Aug 2020 03:20:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Cover BLM protestor faces with a black fist]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24278757">thread link</a>) | @aliabd
<br/>
August 25, 2020 | https://www.gradio.app/hub/hub-blm | <a href="https://web.archive.org/web/*/https://www.gradio.app/hub/hub-blm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.gradio.app/hub/hub-blm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24278757</guid>
            <pubDate>Wed, 26 Aug 2020 03:19:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Netflix's Top List Should Be Taken with a Large Grain of Salt]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24278727">thread link</a>) | @ponderingfish
<br/>
August 25, 2020 | https://ottverse.com/netflix-top-10-movies-list-should-be-taken-with-a-huge-grain-of-salt/ | <a href="https://web.archive.org/web/*/https://ottverse.com/netflix-top-10-movies-list-should-be-taken-with-a-huge-grain-of-salt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>As you might have already seen on the Twitter-verse and in <a href="https://www.bloomberg.com/news/articles/2020-07-15/netflix-most-popular-original-movies">Bloomberg</a>, Netflix released its top 10 movies and Extraction topped that list. The numbers in the data represent the number of views that a movie has gathered in the first 4 weeks of its release.</p><p><img src="https://ottverse.com/images/netflix-top-10-movies.png" alt="Top 10 list from Netflix"></p><p>Looks great, right? 99M viewers for Extraction - that’s a huge win for Netflix.</p><p><img src="https://ottverse.com/images/the-extraction-randeep-hooda-chris-hemsworth.png" alt="Extraction from Netflix"></p><p>But, wait. Can we trust these numbers right off the bat?</p><h2 id="netflixs-data-and-reporting-methodologies">Netflix’s Data and Reporting Methodologies</h2><p>The problem with Netflix is that they guard their data religiously and have never released their data in its entirety to the public. So, if they tell you that a movie was watched 100M times in Japan, you just have to take their word for it and break out a bottle of champagne if you were the producer or actor in that film.</p><p>When Netflix’s data says that “Extraction” starring “Thor” Chris Hemsworth and Bollywood star Randeep Hooda garnered 99 million views within the first 4 weeks of its release, does it mean that the movie was truly exceptional and beat every other release on Netflix in terms of audience numbers?</p><p>Well, to be honest, I really can’t say because Netflix’s data is opaque, their methodology is unknown, and their definition of a movie’s popularity using only their “starters” metric is odd to say the least.</p><p>Let me explain why.</p><h2 id="how-does-netflix-quantify-their-audience">How does Netflix Quantify Their Audience</h2><p>The first step in decoding the data that Netflix released is understanding the definitions of their metrics.</p><p>Here is what Netflix shared with the <a href="http://data.parliament.uk/writtenevidence/committeeevidence.svc/evidencedocument/communications-committee/public-service-broadcasting-in-the-age-of-video-on-demand/written/104558.html">United Kingdom’s House of Lords’ Communications Committee</a>:</p><blockquote><p>The information we give them mainly consists of “starters” (i.e. households that watch two minutes of a film or one episode) and “completers” (i.e. households that watch 90% of a film or season of a series) for the first seven and 28 days on Netflix. We believe that these two metrics will give our creative partners a broader understanding of how members engage with their title from start to finish. We also selectively share “watchers” (i.e. households that watch 70% of a film or single episode of a series) with both the public and with creators. Depending on how useful our partners find this data, we will consider sharing it in more countries outside Europe and North America.</p></blockquote><p>Distilling this into the main classifications, we get:-</p><ul><li><strong>starters</strong>: households that watch two minutes of a film or one episode</li><li><strong>watchers</strong>: households that watch 70% of a film or single episode of a series</li><li><strong>completers</strong>: households that watch 90% of a film or season of a series</li></ul><p>Only 2 mins? Which 2 minutes - from the beginning, in the middle, or from the point they left off the previous day?</p><p>In the <a href="https://s22.q4cdn.com/959853165/files/doc_financials/2019/q4/FINAL-Q4-19-Shareholder-Letter.pdf">Q4 2019 letter shared by Netflix to its shareholders</a>, Netflix reveals their definition of a view and its impact on its data reports. I’ve copy-pasted the relevant section here and highlighted the important parts.</p><blockquote><p>As we’ve expanded our original content, we’ve been working on how to best share content highlights that demonstrate popularity. <strong>Given that we now have titles with widely varying lengths - from short episodes (e.g. ​Special​ at around 15 minutes) to long films (e.g. ​The Highwaymen​ at 132 minutes), we believe that reporting households viewing a title based on 70% of a single episode of a series or of an entire film, which we have been doing, makes less sense.</strong> We are now reporting on households (accounts) that chose to watch a given title . Our new methodology is similar to the BBC iPlayer in their rankings​ based on “requests” for the title, “most popular” articles on the New York Times which include those who opened the articles, and YouTube view counts. <strong>This way, short and long titles are treated equally, leveling the playing field for all types of our content including interactive content, which has no fixed length. The new metric is about 35% higher on average than the prior metric.</strong> For example, 45m member households chose to watch ​Our Planet​ under the new metric vs. 33m under the prior metric.</p></blockquote><p>Buried in a footnote on the same page in the <a href="https://s22.q4cdn.com/959853165/files/doc_financials/2019/q4/FINAL-Q4-19-Shareholder-Letter.pdf">Q4 2019 shareholder letter</a> is an explanation of what “chose to watch a given title” means -</p><blockquote><p>Chose to watch and did watch for at least 2 minutes – long enough to indicate the choice was intentional – is the precise definition</p></blockquote><p>Netflix says that this method of reporting is similar to what the BBC and YouTube do, and so, they aren’t doing anything funny here.</p><p>Well, summarizing everything till now, it appears that Netflix counts how many sessions lasted at least 2 minutes and this metric is used to quantify their audience.</p><h2 id="the-issue-with-reporting-based-on-starters">The Issue with Reporting Based on “starters”</h2><p>Portraying a movie’s popularity based solely on “starters” is where things begin to get weird for me.</p><p>Having spent a few years in the video analytics industry, I can say with absolute confidence that a large number of views does not * <strong>always</strong> * translate to popularity. There are caveats one has to consider and some amount of data cleansing and outlier removal is needed before drawing broad conclusions.</p><p>When I look at such viewership statistics, a few questions come to mind immediately.</p><ul><li>How long was each view (beyond the 2 minute minimum i.e.)?</li><li>When did each view begin and end (i.e., start and end times)?</li><li>How many views or sessions did a person take to completely watch a movie?</li></ul><p>Note: “completely” generally means 90% of the playtime of a movie and this is considered as an acceptable threshold in the industry because people generally skip the credits.</p><p>Now, let’s understand with the help of a few examples of why these questions are important in making sense of an audience’s engagement.</p><h3 id="problem-1-if-a-person-watches-only-2-minutes-that-should-not-count-towards-the-movies-popularity">Problem 1: if a person watches only 2 minutes, that should not count towards the movie’s popularity.</h3><p><strong>Example 1:</strong> if a person began to watch Extraction, watched it for 2 mins, found it utterly boring, and decided to bail on it after just 3 minutes, then do you count it as a view or a starter? Well, logically speaking - he did start the movie, but, when you take this number without context (the viewer dropped out after 3 minutes) and use it to justify a movie’s “popularity”, it’s not right.</p><p><strong>Example 2:</strong> Let’s assume that Netflix acquires the “Oceans” franchise and decides to produce the “Oceans 21” with 21 A-Listers from Hollywood. And by a cruel twist-of-fate, they produce a movie with the worst possible storyline and direction. However, what they do get right is marketing! Netflix pulls out all the stops and does a brilliant job at marketing the movie and building up excitement for Oceans 21.</p><p>On the day of release, Oceans 21 gets millions of hits because people are excited to see George Clooney and Brad Pitt crush it! But, what’s happening?</p><ul><li>10 minutes into the movie, most of the viewers realize that the movie sucks and stop watching. But, they are added to the movie’s popularity count because they watched 2 mins, right?</li><li>a section of Netflix’s subscribers who haven’t (yet) heard that the movie sucks end up watching at least 10 mins of the movie before bleeding out of their eyes. But, they too are added to the “watch” count because they watched 2 mins, right?</li><li>and, the die-hard fans of the Oceans’ franchise will watch it no matter what the critics say and of course, they are going to be added to the “watch” count.</li></ul><h3 id="problem-2-multiple-viewing-sessions-from-the-same-subscriber-arent-considered">Problem 2: Multiple Viewing Sessions from the Same Subscriber Aren’t Considered</h3><p>The definition of “starter” also does not take consider multiple viewing sessions and this is an issue. Let’s take a simple example to understand more.</p><p><strong>Case A:</strong> I might have watched a single movie over a period of 10 days watching 10-15 mins each day, because I need to split my day between work, babysitting my toddlers, yard-work, etc.</p><p><strong>Case B:</strong> Now consider another situation where I had the entire Saturday night to myself and watched an entire 1.5 hour movie in one sitting.</p><p>So, is A more popular than B? It will under Netflix’s algorithm because A had 10 “starters” and B had only one.</p><p>Sounds wrong, doesn’t it? Okay, now let’s look at the problem from a different angle.</p><h2 id="does-netflixs-data-translate-to-imdb-and-rotten-tomato-ratings">Does Netflix’s data Translate to IMDB and Rotten Tomato ratings?</h2><p>Take a look at the IMDB and Rotten Tomato ratings for Netflix’s Top 10 list because these ratings play a huge role in a movie’s continued - importantly, after the marketing hype has died down.</p><p>We compiled the IMDB and Rotten Tomato ratings (as of July 16th 2020 at 6 am UTC) and here is what the data shows.</p><p><img src="https://ottverse.com/images/netflix-top10-imdb-rottentomato.png" alt=""></p><p>At first glance, you might think that IMDB appears to agree with Netflix’s popularity chart, but, The Irishman throws a curveball coming in at 7.9 in IMDB and 96% in Rotten Tomato while languishing at #6 in Netflix. The same goes for The Platform which has great ratings from both IMDB and Rotten Tomato, but is at the 9th position in Netflix’s data.</p><p>Let’s look at this data in a different perspective.</p><p><img src="https://ottverse.com/images/ranking-of-movies-netflix-imdb-rottentomato.png" alt=""></p><p>Below is a table where we have ranked the movie based on the audience’s ratings/reviews on IMDB and Rotten Tomato. We have highlighted three movies in particular - Extraction, The Irishman, The Platform to show how different they are ranked based on the data from Netflix, IMDB, and Rotten Tomato.</p><p>Quit different, eh?</p><p>The Platform’s ranking goes to show that a movie might not have the same number of views as more “popular” movies, but, can be highly rated by the audience. So, does Netflix’s methodology have flaws?</p><h2 id="what-data-from-netflix-will-help">What Data from Netflix Will Help?</h2><ul><li><strong>Viewing Trends for 4 weeks:</strong> Instead of providing a single, aggregated number, it will be great if a trendline of the number of “watch"s is released.
This will help us understand the influence of the first few days of release on the overall aggregated figure and how a movie fares after the initial hype has died down.</li><li><strong>Number of Sessions Required to achieve a “Complete” Watch:</strong> How many sessions does the average user take to watch a movie completely? If the average viewer take 3 attempts to watch a movie fully, and if the movie has 30 million views, it probably is safe to assume that the movie wasn’t watched fully 30 million times. Right?</li><li><strong>Session Durations as a function of the length of the Content:</strong> preferably represented as a histogram.</li><li><strong>Internal Ratings:</strong> Can Netflix tell …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ottverse.com/netflix-top-10-movies-list-should-be-taken-with-a-huge-grain-of-salt/">https://ottverse.com/netflix-top-10-movies-list-should-be-taken-with-a-huge-grain-of-salt/</a></em></p>]]>
            </description>
            <link>https://ottverse.com/netflix-top-10-movies-list-should-be-taken-with-a-huge-grain-of-salt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24278727</guid>
            <pubDate>Wed, 26 Aug 2020 03:14:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kopia v0.6.0]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24278622">thread link</a>) | @hrez
<br/>
August 25, 2020 | https://kopia.io/docs/release-notes/v0.6.0/ | <a href="https://web.archive.org/web/*/https://kopia.io/docs/release-notes/v0.6.0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	
	
	<p>We are very excited to announce the 0.6 release of Kopia! This is a big milestone on the way to an upcoming 1.0 release and there have not only been a large number of changes across the stack but also growth of the community.</p>
<p>This version brings manny performance, usability and stability improvements listed below, adds supports for new providers and CLI options and introduces major new features described below:</p>
<ul>
<li><a href="https://kopia.io/docs/maintenance/">Maintenance Tasks</a></li>
<li><a href="https://kopia.io/docs/repository-server/">Repository Server</a></li>
<li><a href="https://kopia.io/docs/repository-synchronization/">Repository Synchronization</a></li>
</ul>
<h3 id="upgrade-notes">Upgrade notes</h3>
<ul>
<li>Upgrading from 0.5.x is supported and should be automatic</li>
<li>Upgrading from 0.4.0 or earlier is not officially supported, it may work but use at your own risk. It’s strongly recommended to create new repository using v0.6.0 and migrate existing snapshots as outlined in the documentation. After v0.6.0 the deprecated encryption and hashing schemes from v0.4.0 will be removed.</li>
</ul>
<h3 id="key-changes">Key Changes</h3>
<h4 id="core">Core</h4>
<ul>
<li>big performance improvements when snapshotting large directories <a href="https://github.com/kopia/kopia/pull/331">#331</a></li>
<li>improvements for dealing with eventually-consistent stores (S3) <a href="https://github.com/kopia/kopia/pull/437">#437</a></li>
<li>GC safety improvements to resolve race condition when content is re-referenced when about to be deleted <a href="https://github.com/kopia/kopia/pull/420">#420</a></li>
<li>added OpenCensus <a href="https://github.com/kopia/kopia/pull/339">#339</a></li>
<li>introduced explicit maintenance operations that perform periodic repository cleanup/compaction <a href="https://github.com/kopia/kopia/pull/411">#411</a></li>
<li>disabled automatic compaction on repository opening - moved to maintenance tasks</li>
<li>added AsyncWrites to ObjectWriter, which improves performance… <a href="https://github.com/kopia/kopia/pull/369">#369</a></li>
<li>object: ensure that all I objects have a content prefix which improves locality by putting them in q packs</li>
<li>deduplicate multiple policies for the same source in policy manager, fixes #391</li>
<li>fixed race condition during Open() where we may read incomplete file</li>
<li>deprecated NONE algorithm, will not be available for new repositories <a href="https://github.com/kopia/kopia/pull/395">#395</a></li>
<li>server: automatically flush the repository after setting or deleting a policy <a href="https://github.com/kopia/kopia/pull/489">#489</a></li>
<li>snapshot checkpointing <a href="https://github.com/kopia/kopia/pull/410">#410</a></li>
<li>moved creating cache directory from connect to first use <a href="https://github.com/kopia/kopia/pull/450">#450</a></li>
<li>persist relative path to cache if possible, this allows config directory to be partially portable</li>
<li>server: implemented ‘flush’ and ‘refresh’ API</li>
<li>experimental support for remote repository <a href="https://github.com/kopia/kopia/pull/427">#427</a></li>
<li>repo: refactored public API <a href="https://github.com/kopia/kopia/pull/318">#318</a></li>
</ul>
<h4 id="kopiaui">KopiaUI</h4>
<ul>
<li>support for multiple repositories + portability <a href="https://github.com/kopia/kopia/pull/398">#398</a></li>
<li>highlight snapshot errors <a href="https://github.com/kopia/kopia/pull/376">#376</a></li>
</ul>
<h4 id="providers">Providers</h4>
<ul>
<li>support for gather writes <a href="https://github.com/kopia/kopia/pull/373">#373</a></li>
<li>b2: added provider for backblaze b2</li>
<li>sftp: add missing options for configuring sftp known_hosts</li>
<li>s3: add CLI option for disabling tls verification while connecting to s3</li>
<li>filesystem: added retry which addresses the macOS race condition</li>
</ul>
<h4 id="cli-improvements">CLI Improvements</h4>
<ul>
<li>added flags to control progress output</li>
<li>‘kopia server’ made –ui default <a href="https://github.com/kopia/kopia/pull/452">#452</a></li>
<li>allow override of snapshot start time and end time</li>
<li>improved ‘snapshot delete’ usage <a href="https://github.com/kopia/kopia/pull/436">#436</a></li>
<li>Remove legacy flags from snapshot create command <a href="https://github.com/kopia/kopia/pull/441">#441</a></li>
<li>support for zip, tar and tar.gz restore outputs <a href="https://github.com/kopia/kopia/pull/482">#482</a></li>
<li>support for synchronizing repositories <a href="https://github.com/kopia/kopia/pull/522">#522</a></li>
<li>auto-ignore kopia cache directories when creating snapshots <a href="https://github.com/kopia/kopia/pull/524">#524</a></li>
</ul>
<h4 id="infrastructure">Infrastructure</h4>
<ul>
<li>macOS and Windows KopiaUI builds are now signed</li>
<li>robustness testing framework</li>
<li>testing: added blob.Storage wrapper that simulates eventual consistency <a href="https://github.com/kopia/kopia/pull/434">#434</a></li>
<li>switched back to using v-prefixed tag names.</li>
<li>tests: added smoke test that exercises all combinations of encryption and hashing</li>
</ul>
<p>See full change log on <a href="https://github.com/kopia/kopia/releases/tag/v0.6.1">GitHub</a>.</p>

	
		
<h2>Feedback</h2>
<p>Was this page helpful?</p>
<p>
  Glad to hear it! Please <a href="https://github.com/kopia/kopia/issues/new">tell us how we can improve</a>.
</p>
<p>
  Sorry to hear that. Please <a href="https://github.com/kopia/kopia/issues/new">tell us how we can improve</a>.
</p>


	
	
</div></div>]]>
            </description>
            <link>https://kopia.io/docs/release-notes/v0.6.0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24278622</guid>
            <pubDate>Wed, 26 Aug 2020 02:56:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Simple Program to Get Thousands of Stocks’ Data]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24278512">thread link</a>) | @cshad
<br/>
August 25, 2020 | https://handsoffinvesting.com/a-simple-program-to-get-thousands-of-stocks-data/ | <a href="https://web.archive.org/web/*/https://handsoffinvesting.com/a-simple-program-to-get-thousands-of-stocks-data/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-247">
      <div>
    <section>
            <div>
        
<h3>Effortlessly obtain the historical data of over a thousand stocks. For free.</h3>



<figure><img data-attachment-id="257" data-permalink="https://handsoffinvesting.com/a-simple-program-to-get-thousands-of-stocks-data/wordcloud/" data-orig-file="https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?fit=4096%2C3072&amp;ssl=1" data-orig-size="4096,3072" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="wordcloud" data-image-description="" data-medium-file="https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?fit=1024%2C768&amp;ssl=1" loading="lazy" width="1024" height="768" src="https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?resize=1024%2C768&amp;ssl=1" alt="" srcset="https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?resize=2048%2C1536&amp;ssl=1 2048w, https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?w=2280&amp;ssl=1 2280w, https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?w=3420&amp;ssl=1 3420w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?resize=2048%2C1536&amp;ssl=1 2048w, https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?w=2280&amp;ssl=1 2280w, https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?w=3420&amp;ssl=1 3420w" data-lazy-src="https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?resize=1024%2C768&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>







<h2 id="16bb">Anyone Can Do This</h2>



<p>Beginners welcome. I’ve created this guide for Python developers of all skill levels. Maybe you don’t even know what Python is, and that’s okay! I’ve got you. </p>



<p>If you’ve read any of <a href="https://handsoffinvesting.com/guides/" target="_blank" rel="noreferrer noopener">my articles</a> about automating the stock analysis process, you’ve probably seen this code before. I figured that since this program is so integral for algorithmic investing, I need to break it down further and make sure that everyone understands how to use it!</p>



<p>After running this program you’ll be left with a folder on your device that contains the historical data of any number of stocks. Also, I’ve simplified the code by breaking it into sections and giving a description of what each part of the code does.</p>



<p id="bc40">If this is your first time using Python (or coding in general), I’d recommend reading&nbsp;<a href="https://www.codecademy.com/articles/install-python" target="_blank" rel="noreferrer noopener">this article</a>&nbsp;for a simple walk-through of the installation and startup process. And don’t worry, everybody learns how to code through practice. This is a great place to start learning!</p>



<figure><blockquote><p>Programming is a skill best acquired by practice rather than from books. — Alan Turing</p></blockquote></figure>



<hr>



<h2 id="0a66">Libraries</h2>



<p>They make life so much easier. These libraries are going to help us make quick work of the data importing process. Using them, we’ll be able to:</p>



<ol><li>Filter through all of the stocks in the NYSE, NASDAQ, and AMEX. </li><li>Create and delete a file on our local machine (computer) to store the stock data.</li><li>Pull and save historical stock data from Yahoo Finance.</li></ol>



<p id="29d1">Importing the necessary libraries can be done in two simple lines of code.</p>



<div><pre data-lang="Python"><code>import yfinance as yf, pandas as pd, shutil, os
from get_all_tickers import get_tickers as gt</code></pre></div>



<p>Here are the use-cases for each library, as well as where you can go to learn more.</p>



<ul><li><a href="https://pypi.org/project/yfinance/" target="_blank" rel="noreferrer noopener">Yfinance</a>: Gather historical/ relevant data on each stock.</li><li><a href="https://pandas.pydata.org/docs/reference/index.html" target="_blank" rel="noreferrer noopener">Pandas</a>: Work with large sets of data.</li><li><a href="https://docs.python.org/3/library/shutil.html" target="_blank" rel="noreferrer noopener">Shutil</a> and&nbsp;<a href="https://docs.python.org/3/library/os.html" target="_blank" rel="noreferrer noopener">OS</a>: Accessing, creating, and deleting folders/files on the computer.</li><li><a href="https://github.com/shilewenuw/get_all_tickers" target="_blank" rel="noreferrer noopener">Get_All_Tickers</a>: Filter through all stocks to get the list you desire.</li></ul>



<hr>



<h2>The List of Stocks (Tickers)</h2>



<p>The library “<a href="https://github.com/shilewenuw/get_all_tickers" target="_blank" rel="noreferrer noopener">get-all-tickers</a>“, allows us to filter through all of the stocks in the NYSE, NASDAQ, and AMEX. Doing this gives us a list of stock tickers that we can then analyze one at a time. </p>



<p>Currently, the library supports filtering stocks by their <strong>region</strong>, <strong>sector</strong>, <strong>market cap</strong>, and <strong>exchange</strong>. For this example I am looking at companies that have a market cap between $150,000 and $10,000,000 (in millions). You will notice that I also included a line of code to print the number of tickers we are using. </p>



<p><strong><span>This is very important</span></strong><span>:</span></p>



<p>You will need to be sure that you are not targeting more than 2,000 tickers, because the Yfinance API has a 2,000 API calls per hour limit.</p>



<div><pre data-lang="Python"><code>tickers = gt.get_tickers_filtered(mktcap_min=150000, mktcap_max=10000000)
print("The amount of stocks chosen to observe: " + str(len(tickers)))</code></pre></div>



<p><br>I would recommend using this library because it allows for our list of observable stocks to be dynamic. But if it better suits your analysis, here is an alternative line of code that allows you to type in the stocks you would like to have the program analyze.</p>



<div><pre data-lang="Python"><code>tickers = ["FB", "AMZN", "APPL"]</code></pre></div>



<hr>



<h2>Data Storage</h2>



<p>You need to create a file location on your device to store all of the stock data, but it’s not that simple. This file need to remove old stock data and hold in order to hold only data from the latest iteration of this program.</p>



<p>To do this, <strong>first create the file manually on your computer</strong>. Don’t worry, this is the only time you will have to do this. Then add this code to your program.</p>



<div><pre data-lang="Python"><code>shutil.rmtree("C:\\Users\\Your Path to Desired File Location")
os.mkdir("C:\\Users\\Your Path to Desired File Location")</code></pre></div>



<p>These two lines of code will then remove and recreate that file each time you run this program. Doing this allows for you to clear out the old stock data and make room for the most recent data.</p>



<hr>



<h2>Measure Success</h2>



<p>These two basic lines of code create variables that we are going to use in the next section to gauge the success of your program. </p>



<p>Sometimes Yahoo Finance can fail to retrieve the data for all of the stocks. This does not happen <span>often </span>(maybe once in a thousand stocks), but we still want to know if it does. </p>



<div><pre data-lang="Python"><code>Stock_Failure = 0
Stocks_Not_Imported = 0</code></pre></div>



<h2>Pull From Yahoo Finance</h2>



<p>This section of code may look daunting if you’re new to coding, but don’t worry<span>:</span> it’s not too complicated. Here is a high-level overview of what this code is doing.</p>



<ol><li>Create a while loop to iterate over each stock in our list of tickers (also ensuring that we are making less than 1800 calls).</li><li>Try statement. <ol><li>We tell Yahoo Finance which stock we want to get the data for.</li><li>Specify what kind of data we want about the stock (in this example it is all of the historical price data).</li><li>Pull the data and save it as a csv in the folder specified in the above section.</li><li>Force the program to pause for two seconds so that we don’t overwhelm Yahoo Finance and get kicked out.</li><li>Tell our program the process was successful and then iterate to the next stock.</li></ol></li><li>Catch Statement (to catch value errors that Yahoo Finance might throw, otherwise our program will prematurely end).<ol><li>Print that there was an error.</li><li>Check if the observed stock has failed more than 5 times (this threshold is up to you).</li><li>If it has, move on to the next stock.</li><li>If it has not, try again.</li></ol></li><li>We’re done. Print out how many stocks were successfully imported, and how many were not.</li></ol>



<p>If you’re still confused with a section of this code, I added some comments (words after #) to alleviate any confusion.</p>



<div><pre data-lang="Python"><code>i=0
while (i &lt; len(tickers)) and (Amount_of_API_Calls &lt; 1800):
    try:
        stock = tickers[i]  # Gets the current stock ticker
        temp = yf.Ticker(str(stock))  # Instantiate the ticker as a stock with Yahoo Finance
        Hist_data = temp.history(period="max")  # Tells yfinance what kind of data we want about this stock (In this example, all of the historical data)
        Hist_data.to_csv("C:\\Users\\Your Desired Path to File")  # Saves the historical data in csv format for further processing later
        time.sleep(2)  # Pauses the loop for two seconds so we don't cause issues with Yahoo Finance's backend operations
        Amount_of_API_Calls += 1 
        Stock_Failure = 0
        i += 1  # Iteration to the next ticker
    except ValueError:
        print("Yahoo Finance Back-end Error, Attempting to Fix")  # An error occurred on Yahoo Finance's back-end. We will attempt to retreive the data again
        if Stock_Failure &gt; 5:  # Move on to the next ticker if the current ticker fails more than 5 times
            i+=1
            Stocks_Not_Imported += 1
        Amount_of_API_Calls += 1
        Stock_Failure += 1
print("The amount of stocks we successfully imported: " + str(i - Stocks_Not_Imported))</code></pre></div>



<hr>



<h2>The End?</h2>



<p>That’s it. You now have a dynamic way of filtering through all of the stocks in the NYSE, NASDAQ, and AMEX<span>, p</span>ulling each of the company’s historic price data<span>, a</span>nd saving all of it to a new folder on your device. All <span>at </span>the click of a button. </p>



<p><strong>It’s completely hands-off.</strong></p>



<p>But <span>this isn’t</span> the end. There is so much more of the investing process that you can make hands-off. And why wouldn’t you? It makes life so much easier and investing so much more successful. <strong><a href="https://handsoffinvesting.com/" target="_blank" rel="noreferrer noopener">Everything you need is right here!</a></strong></p>



<p>If you enjoyed this article (or not), feel free to leave a comment and let me know what you thought. I would love to hear your feedback or questions!<span> </span><span>And </span>if you enjoy learning about automating your trading strategies, subscribe to our blog. We post new content and guides twice a week!</p>







<p>Also, connect with me on LinkedIn&nbsp;<a href="http://www.linkedin.com/in/cameron-shadmehry" target="_blank" rel="noreferrer noopener">here</a>. I’m always happy to make some new connections!</p>
		
		
		
      </div>
      
    </section><!-- .entry-content -->
  </div><!-- .post-entry -->
  </article></div>]]>
            </description>
            <link>https://handsoffinvesting.com/a-simple-program-to-get-thousands-of-stocks-data/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24278512</guid>
            <pubDate>Wed, 26 Aug 2020 02:34:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Intro to ONNX by Chinmay Jog – Venice Computer Vision Meetup 07/20/2020]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24278494">thread link</a>) | @nchafni
<br/>
August 25, 2020 | https://social.trueface.ai/vcv-intro-to-onnx | <a href="https://web.archive.org/web/*/https://social.trueface.ai/vcv-intro-to-onnx">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://social.trueface.ai/vcv-intro-to-onnx</link>
            <guid isPermaLink="false">hacker-news-small-sites-24278494</guid>
            <pubDate>Wed, 26 Aug 2020 02:31:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New model can detect deepfake images by looking at subtle visual artifacts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24278435">thread link</a>) | @happy-go-lucky
<br/>
August 25, 2020 | https://chail.github.io/patch-forensics/ | <a href="https://web.archive.org/web/*/https://chail.github.io/patch-forensics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			

        <p id="authors">
            <a href="http://people.csail.mit.edu/lrchai/">Lucy Chai</a>
						<a href="https://people.csail.mit.edu/davidbau/home/">David Bau</a>
						<a href="https://scholar.google.com/citations?user=HX0BfLYAAAAJ&amp;hl=en">Ser-Nam Lim</a>
            <a href="http://web.mit.edu/phillipi/">Phillip Isola</a><br>
            <!-- <strong>MIT Computer Science and Artificial Intelligence Laboratory</strong> -->
            MIT Computer Science and Artificial Intelligence Laboratory
        </p>
				<p><span size="+2">
					<p>
						<a href="http://arxiv.org/abs/2008.10588" target="_blank">[Paper]</a> &nbsp;&nbsp;&nbsp;&nbsp;
						<a href="https://github.com/chail/patch-forensics" target="_blank">[Code]</a> 
						<!--
						<a href="TODO: youtube link?" target="_blank">[Video]</a>
						-->
					</p>
					</span></p><p>
            <img src="https://chail.github.io/patch-forensics/img/classifier.001.jpeg">
        </p>

        <p>The quality of image generation and manipulation is reaching impressive levels, making it increasingly difficult for a human to distinguish between what is real and what is fake. However, deep networks can still pick up on the subtle artifacts in these doctored images. We seek to understand what properties of fake images make them detectable and identify what generalizes across different model architectures, datasets, and variations in training. We use a patch-based classifier with limited receptive fields to visualize which regions of fake images are more easily detectable. We further show a technique to exaggerate these detectable properties and demonstrate that, even when the image generator is adversarially finetuned against a fake image classifier, it still leaves detectable artifacts in certain image patches.</p>


        <br clear="all">
    </div><div id="Summary">
				<p><span size="+2">
					<p>
						A Brief Summary:
					</p>
					</span>
					We train classifiers in a fully convolutional manner by truncating a standard deep network architecture after various intermediate layers. This classifier is trained to distinguish between real images and fake or manipulated images, but since it is fully convolutional, it provides us with a prediction of how "real" or "fake" it predicts a given patch of the image to be. One subtle caveat was that we had to be careful with image preprocessing -- we tried to create our dataset so that "real" and "fake" image collections are as similar as possible in terms any resizing done and file format, as we found that a classifier could easily learn these differences rather than the actual task.</p><p>
					<img src="https://chail.github.io/patch-forensics/img/preprocess.001.jpeg"></p><p>
					We train the classifier on fake faces from Progressive GAN, and real faces from the CelebA-HQ dataset afer performing the preprocessing steps above. We then evaluate the truncated classifiers at different receptive field sizes, where higher block number corresponds to larger receptive field/larger patch size, across different synthetic face generators, as well as generators trained on the more diverse FFHQ face datset. Oftentimes, a model with a smaller receptive field can outperform one with a larger receptive field on this task.</p><p>
					<img src="https://chail.github.io/patch-forensics/img/graphs.001.jpeg"></p><p>
					Patch-based predictors give use a natural way to visualize model decisions, as the same model weights are applied over each patch in a sliding fashion. By using a pretrained face segmentation model, we can categorize the most predictive patch in each image to investigate what types of features the patch classifier uses in making a decision.</p><p>
					<img src="https://chail.github.io/patch-forensics/img/visualize.001.jpeg"></p><p>
					One of the dangers of image synthesis is that the generators are constantly evolving and getting better, so we investigate how patch cues change as a result of changes in the generator. We finetune the generator and recompute the most predictive patches, and we also use the generator as a tool to exaggerate what makes images look fake by optimizing against the classifier in latent space.</p><p>
					<img src="https://chail.github.io/patch-forensics/img/exaggerate.001.jpeg"></p></div><div id="references">

        <h2>Reference</h2>

				<p>L Chai, D Bau, SN Lim, P Isola. What makes fake images detectable? Understanding properties that generalize. <br>European Conference on Computer Vision, 2020.</p>

        <p><code>
			@inproceedings{patchforensics,<br>
				&nbsp;&nbsp;title={What makes fake images detectable? Understanding properties that generalize},<br>
				&nbsp;&nbsp;author={Chai, Lucy and Bau, David and Lim, Ser-Nam and Isola, Phillip},<br>
				&nbsp;&nbsp;booktitle={European Conference on Computer Vision},<br>
				&nbsp;&nbsp;year={2020}<br>
			 }
				</code>
    </p></div><p><strong>Acknowledgements</strong>:
					 We would like to thank Antonio Torralba, Jonas Wulff, Jacob Huh, Harry Yang, and Richard Zhang for helpful discussions. This work was supported by a National Science Foundation Graduate Research Fellowship under Grant No. 1122374 to L.C. and DARPA XAI FA8750-18-C000-4 to D.B.
					 Recycling a familiar <a href="https://ali-design.github.io/gan_steerability/">template</a>.
    </p></div>]]>
            </description>
            <link>https://chail.github.io/patch-forensics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24278435</guid>
            <pubDate>Wed, 26 Aug 2020 02:23:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Fennel programming language: rationale]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24278430">thread link</a>) | @todsacerdoti
<br/>
August 25, 2020 | https://fennel-lang.org/rationale | <a href="https://web.archive.org/web/*/https://fennel-lang.org/rationale">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<header>

</header>
<p>Fennel is a programming language that runs on the Lua runtime.</p>
<h2 id="why-lua">Why Lua?</h2>
<p>The Lua programming language is an excellent and very underrated tool. Is it remarkably powerful yet keeps a very small footprint both conceptually as a language and in terms of the size of its implementation. (The reference implementation consists of about nineteen thousand lines of C and compiles to 278kb.) Partly because it is so simple, Lua is also extremely fast. But the most important thing about Lua is that it’s specifically designed to be put in other programs to make them reprogrammable by the end user.</p>
<p>The conceptual simplicity of Lua stands in stark contrast to other “easy to learn” languages like JavaScript or Python–Lua contains very close to the minimum number of ideas needed to get the job done; only Forth and Scheme offer a comparable simplicity. When you combine this aggressive simplicity with the emphasis on making programs reprogrammable, the result is a powerful antidote to prevailing trends in technology of treating programs as black boxes out of the control of the user.</p>
<h2 id="and-yet">And yet…</h2>
<p>So if Lua is so great, why not just use Lua? In many cases you should! But there are a handful of shortcomings in Lua which over time have shown to be error-prone or unclear. Fennel runs on Lua, and the runtime semantics of Fennel are a subset of Lua’s, but you can think of Fennel as an alternate notation you can use to write Lua programs which helps you avoid common pitfalls. This allows Fennel to focus on doing one thing very well and not get dragged down with things like implementing a virtual machine, a standard library, or profilers and debuggers. Any tool that already works for Lua will work just as well for Fennel.</p>
<p>The most obvious difference between Lua and Fennel is the parens-first syntax; Fennel belongs to the Lisp family of programming languages. You could say that this removes complexity from the grammar; the paren-based syntax is more regular and has fewer edge cases. Simply by virtue of being a lisp, Fennel removes from Lua:</p>
<ul>
<li>statements (everything is an expression),</li>
<li>operator precedence (there is no ambiguity about what comes first), and</li>
<li>early returns (functions always return in tail positions).</li>
</ul>
<h2 id="variables">Variables</h2>
<p>One of the most common legitimate criticisms leveled at Lua is that it makes it easy to accidentally use globals, either by forgetting to add a <code>local</code> declaration or by making a typo. Fennel allows you to use globals in the rare case they are necessary but makes it very difficult to use them by accident.</p>
<p>Fennel also removes the ability to reassign normal locals. If you declare a variable that will be reassigned, you must introduce it with <code>var</code> instead. This encourages cleaner code and makes it obvious at a glance when reassignment is going to happen. Note that Lua 5.4 introduced a similar idea with <code>&lt;const&gt;</code> variables, but since Fennel started from a clean slate it was able to make the cleaner choice be the default rather than opt-in.</p>
<h2 id="tables-and-loops">Tables and Loops</h2>
<p>Lua’s notation for tables (its data structure) feels somewhat dated. It uses curly brackets for both sequential (array-like) and key/value (dictionary-like) tables, while Fennel uses the much more familiar notation of using square brackets for sequential tables and curly brackets for key/value tables.</p>
<p>In addition Lua overloads the <code>for</code> keyword for both numeric “count from X to Y” style loops as well as more generic iterator-based loops. Fennel uses <code>for</code> in the first case and introduces the <code>each</code> form for the latter.</p>
<h2 id="functions">Functions</h2>
<p>Another common criticism of Lua is that it lacks arity checks; that is, if you call a function without enough arguments, it will simply proceed instead of indicating an error. Fennel allows you to write functions that work this way (<code>fn</code>) when it’s needed for speed, but it also lets you write functions which check for the arguments they expect using <code>lambda</code>.</p>
<h2 id="other">Other</h2>
<p>If you’ve been programming in newer languages, you are likely to be spoiled by pervasive destructuring of data structures when binding variables, as well as by pattern matching to write more declarative conditionals. Both these are missing from Lua and included in Fennel.</p>
<p>Finally Fennel includes a macro system so that you can easily extend the language to include new syntactic forms. This feature is intentionally listed last because while lisp programmers have historically made a big deal about how powerful it is, it is relatively rare to encounter situations where such a powerful construct is justified.</p>
<hr>
<p><a href="https://git.sr.ht/~technomancy/fennel-lang.org">source for this site</a></p>


</div>]]>
            </description>
            <link>https://fennel-lang.org/rationale</link>
            <guid isPermaLink="false">hacker-news-small-sites-24278430</guid>
            <pubDate>Wed, 26 Aug 2020 02:23:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Read Kubernetes Secrets]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24278361">thread link</a>) | @aogl
<br/>
August 25, 2020 | https://ao.gl/how-to-read-kubernetes-secrets/ | <a href="https://web.archive.org/web/*/https://ao.gl/how-to-read-kubernetes-secrets/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>  <p>Kubernetes secrets is a great way to store secret values that only Kubernetes can access in your hosted applications.</p> <p>There are times when you might need to view these secrets in plain-text. This is probably because you want to validate the value or use it manually elsewhere.</p> <p>In this tutorial we will go through how to achieve this and read Kubernetes secrets using <code>kubectl</code> for the command-line.</p> <p><strong>tl;dr</strong></p> <pre title="">kubectl get secret &lt;SECRET_NAME&gt; -o jsonpath="{.data.&lt;DATA&gt;}" | base64 --decode
</pre> <p>In the above sample code, simply replace <code>&lt;SECRET_NAME&gt;</code>&nbsp;and&nbsp;<code>&lt;DATA&gt;</code> with your own values.</p> <h2 id="authenticate-with-your-kubernetes-cluster">Authenticate with your Kubernetes cluster</h2> <p>Start by authenticating into your Kubernetes cluster, you may need to first use an <code>assume-role</code> or <code>awsume</code>.</p> <pre title="">eval $(assume-role &lt;PROFILE&gt;)
</pre> <p>If you are using AWS EKS, do this to update your local kubeconfig file:</p> <pre title="">aws eks --region &lt;AWS_REGION&gt; update-kubeconfig --name &lt;CLUSTER_NAME&gt;
</pre> <p>If all else fails, it may be useful to check these&nbsp;<a href="https://kubernetes.io/docs/reference/access-authn-authz/authentication/" rel="noreferrer noopener" target="_blank">authentication strategies</a>.</p>  <p>Now you will need to confirm the context:</p> <pre title="">kubectl config current-context
</pre> <h2 id="list-read-and-decode-secret-data">List, read, and decode secret data</h2> <p>Let’s pretend that we want to read a secret called <code>yoursecret</code>. To do this we can use the below command to see the names of all the secrets, in order to narrow down what exists.</p> <p>Let’s find our what our secret is called:</p> <pre title="">kubectl get secrets

NAME                            TYPE                                  DATA      AGE
yoursecret                      Opaque                                2         3d
</pre> <p>Now that we know what our secret is called, we can issue the next command and view it’s value.</p> <p>Use the describe keyword to view the secret:</p> <pre title="">kubectl describe secret yoursecret

Name:         yoursecret
Namespace:    default
Labels:       &lt;none&gt;
Annotations:  
Type:         Opaque

Data
====
username: 20 bytes
password: 20 bytes
</pre> <p>We now that the data contained in the secret contains a <code>username</code> and <code>password</code>.</p> <p>This is where we use <code>kubectl</code> to get the outputs to YAML. This data is shown to us in a Base64 encoded string.</p> <pre title="">kubectl get secret yoursecret -o yaml

apiVersion: v1
data:
  username: YWJjZGVmZ2hpamtsbW5vcHFyc3QK
  password: MTIzNDU2Nzg5MDEyMzQ1Njc4OTAK
...
</pre> <p>Use the below command on the command-line to decode the Base64 value back to plain-text:</p>  <pre title="">echo "YWJjZGVmZ2hpamtsbW5vcHFyc3QK" | base64 --decode

abcdefghijklmnopqrst
</pre> <h2 id="a-shortcut-to-decoding-secret-data">A shortcut to decoding secret data</h2> <p>While the above is more of a tutorial on the steps to get this done, we can simplify these steps below into a single command:</p> <pre title="">kubectl get secret yoursecret -o jsonpath="{.data.username}" | base64 --decode

abcdefghijklmnopqrst
</pre>    </div></div>]]>
            </description>
            <link>https://ao.gl/how-to-read-kubernetes-secrets/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24278361</guid>
            <pubDate>Wed, 26 Aug 2020 02:11:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[1930s Household Refrigerators (2013)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24278184">thread link</a>) | @userbinator
<br/>
August 25, 2020 | https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/ | <a href="https://web.archive.org/web/*/https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<p>The evolution of the household refrigerator is not a well known story. &nbsp;There seems to be few people interested in the subject. &nbsp;Perhaps it is not as romantic as the development of the automobile. &nbsp;Nonetheless, a concerted effort was put forth in the 1920s and 1930s to produce a cheap, reliable, efficient domestic refrigerator. &nbsp;From books I’m reading on the subject, the great diversity of refrigerator manufacturers in the United States that existed in the 1920s, seems to be boiled down to a handful of companies in the depression era. &nbsp;In the most recent book, “Household Electric Refrigeration” by John F. Wostrel and John G. Praetz 1938; the models described were made by manufacturers, many still around today (or owned by yet larger companies) including General Electric, Frigidaire, Kelvinator, Norge, Grunow, Crosley, Sparton, Hotpoint, Coldspot, Copeland, Ice-O-Matic and Westinghouse.</p>
<p><a href="https://musingsonentropy.files.wordpress.com/2013/04/norge_operation.jpg"><img data-attachment-id="4086" data-permalink="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/norge_operation/" data-orig-file="https://musingsonentropy.files.wordpress.com/2013/04/norge_operation.jpg" data-orig-size="2343,2202" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SCH-I535&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1365067280&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.7&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.0012468827930175&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Norge_Operation" data-image-description="" data-medium-file="https://musingsonentropy.files.wordpress.com/2013/04/norge_operation.jpg?w=300" data-large-file="https://musingsonentropy.files.wordpress.com/2013/04/norge_operation.jpg?w=605" alt="Norge_Operation" src="https://musingsonentropy.files.wordpress.com/2013/04/norge_operation.jpg?w=605&amp;h=568" srcset="https://musingsonentropy.files.wordpress.com/2013/04/norge_operation.jpg?w=605&amp;h=568 605w, https://musingsonentropy.files.wordpress.com/2013/04/norge_operation.jpg?w=1210&amp;h=1136 1210w, https://musingsonentropy.files.wordpress.com/2013/04/norge_operation.jpg?w=150&amp;h=141 150w, https://musingsonentropy.files.wordpress.com/2013/04/norge_operation.jpg?w=300&amp;h=282 300w, https://musingsonentropy.files.wordpress.com/2013/04/norge_operation.jpg?w=768&amp;h=722 768w, https://musingsonentropy.files.wordpress.com/2013/04/norge_operation.jpg?w=1024&amp;h=962 1024w" sizes="(max-width: 605px) 100vw, 605px"></a></p>
<p>One of the most noticeable differences between refrigerators in the mid 1930s and today was the refrigerants they used and the refrigerants charges required for operation. &nbsp;A very common refrigerant, Sulpher Dioxide had been in use fora number of years and still appeared to dominate the market at this time, not to say that proprietary chemical refrigerants weren’t beginning to take a large part of the market. &nbsp;F-12 was one of these proprietary substances that would later dominate the refrigerator industry. &nbsp;It was stable up to high temperatures, didn’t stink like SO2 when it leaked, was relatively safe if exposure to it was kept to a minimum, and it has a much lower boiling point than several common refrigerants at the time which means that systems operating F-12 remained in a positive pressure state throughout the cycle. &nbsp;Refrigerators with F-114, SO2, Isobutane and Methyl Formate required a vacuum in the low side of a vapor compression system. &nbsp;This was generally viewed as problematic seeing that if a leak formed in the low side of the system, for instance, around the packing seal of an open drive compressor, atmosphere would leak into the system, bringing non-condensable gases and water vapor. &nbsp;This leads to high head pressures, oil contamination, possible acid formation, corrosion and refrigerant control freeze ups. &nbsp;A curious refrigerant used rarely was Carrene, also known as Dichloromethane which has a boiling point of 104 degrees F at atmospheric pressure. &nbsp;This means both the suction and discharge sides of a system would operate in a vacuum state. &nbsp;Very curious. &nbsp;As I said, the refrigerant charges were unusual as well. &nbsp;The compressors of these systems were rated not much &nbsp;larger than modern day compressors from 1/16 HP up to 1/4 HP, but they had typical charges of 1# to perhaps 3.5# &nbsp;and more depending on the manufacturer. &nbsp;Modern refrigerators have charges measured in ounces, perhaps, 4 oz.. Most of these machines had liquid receivers that held excess refrigerant and ensured a pure liquid supply to the refrigerant control. &nbsp;That excess refrigerant would have allowed continued operation with minor leaks in the system. &nbsp;Another reason for the large charges is the construction of the evaporator which was commonly gravity flooded; a vessel and series of tubes holding refrigerant under low pressure, boiling away to vapor as heat is absorbed from the refrigerated cabinet.<span id="more-4087"></span></p>
<p><a href="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_lsf_evaporator.jpg"><img data-attachment-id="4080" data-permalink="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/frigidaire_lsf_evaporator/" data-orig-file="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_lsf_evaporator.jpg" data-orig-size="2219,1522" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SCH-I535&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1365067405&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.7&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.00095419847328244&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Frigidaire_LSF_Evaporator" data-image-description="" data-medium-file="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_lsf_evaporator.jpg?w=300" data-large-file="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_lsf_evaporator.jpg?w=605" alt="Frigidaire_LSF_Evaporator" src="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_lsf_evaporator.jpg?w=605&amp;h=415" srcset="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_lsf_evaporator.jpg?w=605&amp;h=415 605w, https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_lsf_evaporator.jpg?w=1210&amp;h=830 1210w, https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_lsf_evaporator.jpg?w=150&amp;h=103 150w, https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_lsf_evaporator.jpg?w=300&amp;h=206 300w, https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_lsf_evaporator.jpg?w=768&amp;h=527 768w, https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_lsf_evaporator.jpg?w=1024&amp;h=702 1024w" sizes="(max-width: 605px) 100vw, 605px"></a></p>
<p>Above, is one of these low side float assemblies. &nbsp;These seemed to be falling out of favor by the mid 1930s for various reason having to do with expense and reliability. &nbsp;The float valve simply regulated the volume of liquid refrigerant within the evaporator shell which was maintained at suction pressure. &nbsp;As the refrigerant boiled away and was carried to the compressor, the ball would drop, valve open and additional high pressure liquid would be admitted. &nbsp;When implemented properly, the low side float gravity flooded evaporator has many advantages over the high side float or the dry type evaporator. &nbsp;It was very important that these machines were properly leveled when installed. &nbsp;They definitely had a minimum charge volume below which the float valve would continually call for more refrigerant and when it was not available, the valve would remain open, leaving very little pressure drop between the high and low side resulting in little to no refrigerating effect. &nbsp;A large refrigerant charge could simply be handled with a sufficiently sized liquid receiver. &nbsp;(Also read <a href="https://musingsonentropy.wordpress.com/2013/04/18/the-great-gravity-flooded-evaporator/" target="_blank">The Great Gravity Flooded Evaporator</a>)</p>
<p><a href="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_low_side_float.jpg"><img data-attachment-id="4079" data-permalink="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/frigidaire_low_side_float/" data-orig-file="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_low_side_float.jpg" data-orig-size="2298,1181" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SCH-I535&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1365067395&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.7&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.00068870523415978&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Frigidaire_Low_Side_Float" data-image-description="" data-medium-file="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_low_side_float.jpg?w=300" data-large-file="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_low_side_float.jpg?w=605" alt="Frigidaire_Low_Side_Float" src="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_low_side_float.jpg?w=605&amp;h=310" srcset="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_low_side_float.jpg?w=603&amp;h=310 603w, https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_low_side_float.jpg?w=1206&amp;h=620 1206w, https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_low_side_float.jpg?w=150&amp;h=77 150w, https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_low_side_float.jpg?w=300&amp;h=154 300w, https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_low_side_float.jpg?w=768&amp;h=395 768w, https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_low_side_float.jpg?w=1024&amp;h=526 1024w" sizes="(max-width: 605px) 100vw, 605px"></a>Nearly the same valve assembly, but removed from the evaporator housing. &nbsp;The baffle plate depicted helped to prevent the violent, boiling liquid refrigerant from being carried back the suction tube to the compressor. &nbsp;Some compressor oils would form a thin film on top of the refrigerant and would need carried back to the compressor. &nbsp;Various methods for this were devised; this Frigidaire obviously had a carefully placed hole in the suction tube for the purpose.</p>
<p><a href="https://musingsonentropy.files.wordpress.com/2013/04/bucket_float_valve.jpg"><img data-attachment-id="4074" data-permalink="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/bucket_float_valve/" data-orig-file="https://musingsonentropy.files.wordpress.com/2013/04/bucket_float_valve.jpg" data-orig-size="2216,965" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SCH-I535&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1365067430&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.7&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.0012787723785166&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Bucket_Float_Valve" data-image-description="" data-medium-file="https://musingsonentropy.files.wordpress.com/2013/04/bucket_float_valve.jpg?w=300" data-large-file="https://musingsonentropy.files.wordpress.com/2013/04/bucket_float_valve.jpg?w=605" alt="Bucket_Float_Valve" src="https://musingsonentropy.files.wordpress.com/2013/04/bucket_float_valve.jpg?w=605&amp;h=262" srcset="https://musingsonentropy.files.wordpress.com/2013/04/bucket_float_valve.jpg?w=602&amp;h=262 602w, https://musingsonentropy.files.wordpress.com/2013/04/bucket_float_valve.jpg?w=150&amp;h=65 150w, https://musingsonentropy.files.wordpress.com/2013/04/bucket_float_valve.jpg?w=300&amp;h=131 300w, https://musingsonentropy.files.wordpress.com/2013/04/bucket_float_valve.jpg?w=768&amp;h=334 768w" sizes="(max-width: 605px) 100vw, 605px"></a>Another low side float valve assembly. &nbsp;It’s a beautiful illustration isn’t it? &nbsp;I read a patent on this type, and one of the advantages cited was that with an open, floating pan, the whole device is under equal pressure, there is no worry of it’s reliable operation, unlike&nbsp;a sealed ball float. &nbsp;The other use of the pan, as I think is well illustrated, is it’s use to collect oil vapors and collect them in the bottom for return to the compressor via the suction tube. &nbsp;I believe this float valve needle and valve seat can be removed and serviced without taking out the entire float assembly.</p>
<p><a href="https://musingsonentropy.files.wordpress.com/2013/04/norge_cycle_color.jpg"><img data-attachment-id="4085" data-permalink="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/norge_cycle_color/" data-orig-file="https://musingsonentropy.files.wordpress.com/2013/04/norge_cycle_color.jpg" data-orig-size="2865,2300" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SCH-I535&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1365067913&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.7&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.0012787723785166&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Norge_Cycle_Color" data-image-description="" data-medium-file="https://musingsonentropy.files.wordpress.com/2013/04/norge_cycle_color.jpg?w=300" data-large-file="https://musingsonentropy.files.wordpress.com/2013/04/norge_cycle_color.jpg?w=605" alt="Norge_Cycle_Color" src="https://musingsonentropy.files.wordpress.com/2013/04/norge_cycle_color.jpg?w=605&amp;h=485" srcset="https://musingsonentropy.files.wordpress.com/2013/04/norge_cycle_color.jpg?w=605&amp;h=485 605w, https://musingsonentropy.files.wordpress.com/2013/04/norge_cycle_color.jpg?w=1208&amp;h=970 1208w, https://musingsonentropy.files.wordpress.com/2013/04/norge_cycle_color.jpg?w=150&amp;h=120 150w, https://musingsonentropy.files.wordpress.com/2013/04/norge_cycle_color.jpg?w=300&amp;h=241 300w, https://musingsonentropy.files.wordpress.com/2013/04/norge_cycle_color.jpg?w=768&amp;h=617 768w, https://musingsonentropy.files.wordpress.com/2013/04/norge_cycle_color.jpg?w=1024&amp;h=822 1024w" sizes="(max-width: 605px) 100vw, 605px"></a></p>
<p>A color illustration from “Modern Electric and Gas Refrigeration” by Althouse and Turnquist, 1933. &nbsp;Notable features: &nbsp;Pan Type Low SIde Float, Open Drive Rotary Compressor.</p>
<p><a href="https://musingsonentropy.files.wordpress.com/2013/04/electrolux_cycle_color.jpg"><img data-attachment-id="4077" data-permalink="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/electrolux_cycle_color/" data-orig-file="https://musingsonentropy.files.wordpress.com/2013/04/electrolux_cycle_color.jpg" data-orig-size="2067,2794" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SCH-I535&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1365068022&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.7&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.0013227513227513&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Electrolux_Cycle_Color" data-image-description="" data-medium-file="https://musingsonentropy.files.wordpress.com/2013/04/electrolux_cycle_color.jpg?w=222" data-large-file="https://musingsonentropy.files.wordpress.com/2013/04/electrolux_cycle_color.jpg?w=605" alt="Electrolux_Cycle_Color" src="https://musingsonentropy.files.wordpress.com/2013/04/electrolux_cycle_color.jpg?w=605&amp;h=817" srcset="https://musingsonentropy.files.wordpress.com/2013/04/electrolux_cycle_color.jpg?w=605&amp;h=817 605w, https://musingsonentropy.files.wordpress.com/2013/04/electrolux_cycle_color.jpg?w=1210&amp;h=1634 1210w, https://musingsonentropy.files.wordpress.com/2013/04/electrolux_cycle_color.jpg?w=111&amp;h=150 111w, https://musingsonentropy.files.wordpress.com/2013/04/electrolux_cycle_color.jpg?w=222&amp;h=300 222w, https://musingsonentropy.files.wordpress.com/2013/04/electrolux_cycle_color.jpg?w=768&amp;h=1038 768w, https://musingsonentropy.files.wordpress.com/2013/04/electrolux_cycle_color.jpg?w=758&amp;h=1024 758w" sizes="(max-width: 605px) 100vw, 605px"></a>From the same 1933 book, this Electrolux diagram has some neat features. &nbsp;It’s an open drive reciprocating compressor probably with a fan cooled condenser. &nbsp;Most domestic units were fan cooled by this time. &nbsp;Early in the 20s, the higher head pressures associated with atmospheric condensers made water cooled condensers more common. &nbsp;WIth the addition of condenser cooling fins and the increased air flow from fans tied to higher speed electric motors, air cooling became more practical. &nbsp;This unit has a curious evaporator. &nbsp;All though it has a low side float, the evaporator coil is one continuous loop like a dry type evaporator. &nbsp;This could lead to vapor pockets forming and elevated pressures over the suction pressure, decreasing the rate of ebullition. &nbsp;Another interesting feature being the extra loop or two in the suction line to vaporize any liquid refrigerant in the suction line.</p>
<p><a href="https://musingsonentropy.files.wordpress.com/2013/04/crane_ge_monitor_top.jpg"><img loading="lazy" data-attachment-id="4076" data-permalink="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/crane_ge_monitor_top/" data-orig-file="https://musingsonentropy.files.wordpress.com/2013/04/crane_ge_monitor_top.jpg" data-orig-size="1237,2413" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SCH-I535&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1365067582&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.7&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.00074626865671642&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Crane_GE_Monitor_Top" data-image-description="" data-medium-file="https://musingsonentropy.files.wordpress.com/2013/04/crane_ge_monitor_top.jpg?w=154" data-large-file="https://musingsonentropy.files.wordpress.com/2013/04/crane_ge_monitor_top.jpg?w=525" alt="Crane_GE_Monitor_Top" src="https://musingsonentropy.files.wordpress.com/2013/04/crane_ge_monitor_top.jpg?w=314&amp;h=614" width="314" height="614" srcset="https://musingsonentropy.files.wordpress.com/2013/04/crane_ge_monitor_top.jpg?w=314&amp;h=614 314w, https://musingsonentropy.files.wordpress.com/2013/04/crane_ge_monitor_top.jpg?w=628&amp;h=1225 628w, https://musingsonentropy.files.wordpress.com/2013/04/crane_ge_monitor_top.jpg?w=77&amp;h=150 77w, https://musingsonentropy.files.wordpress.com/2013/04/crane_ge_monitor_top.jpg?w=154&amp;h=300 154w" sizes="(max-width: 314px) 100vw, 314px"></a>A common GE Monitor Top type refrigerator. &nbsp;This “package type” construction was common where the entire refrigerating apparatus was modular in that it could be easily removed from the cabinet for service or replacement.</p>
<p><a href="https://musingsonentropy.files.wordpress.com/2013/04/coldspot_refrigerator_unit.jpg"><img data-attachment-id="4075" data-permalink="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/coldspot_refrigerator_unit/" data-orig-file="https://musingsonentropy.files.wordpress.com/2013/04/coldspot_refrigerator_unit.jpg" data-orig-size="2299,1912" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SCH-I535&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1365066974&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.7&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.0011627906976744&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Coldspot_Refrigerator_Unit" data-image-description="" data-medium-file="https://musingsonentropy.files.wordpress.com/2013/04/coldspot_refrigerator_unit.jpg?w=300" data-large-file="https://musingsonentropy.files.wordpress.com/2013/04/coldspot_refrigerator_unit.jpg?w=605" alt="Coldspot_Refrigerator_Unit" src="https://musingsonentropy.files.wordpress.com/2013/04/coldspot_refrigerator_unit.jpg?w=605&amp;h=503" srcset="https://musingsonentropy.files.wordpress.com/2013/04/coldspot_refrigerator_unit.jpg?w=605&amp;h=503 605w, https://musingsonentropy.files.wordpress.com/2013/04/coldspot_refrigerator_unit.jpg?w=1210&amp;h=1006 1210w, https://musingsonentropy.files.wordpress.com/2013/04/coldspot_refrigerator_unit.jpg?w=150&amp;h=125 150w, https://musingsonentropy.files.wordpress.com/2013/04/coldspot_refrigerator_unit.jpg?w=300&amp;h=249 300w, https://musingsonentropy.files.wordpress.com/2013/04/coldspot_refrigerator_unit.jpg?w=768&amp;h=639 768w, https://musingsonentropy.files.wordpress.com/2013/04/coldspot_refrigerator_unit.jpg?w=1024&amp;h=852 1024w" sizes="(max-width: 605px) 100vw, 605px"></a></p>
<p>This Coldspot has some features worth discussing. &nbsp;For one, it is the package type as described before with the compressor and condensing unit mounted atop the insulated cabinet top with the motor and compressor supported my springs to dampen vibration and noise. &nbsp;The evaporator is of the dry type where the refrigerant is fed to a long coil of tube or series of tubes at approximately the rate in which it is vaporized by the heat of the refrigerated cabinet. &nbsp;Some of the more crude early versions of this used a fixed orifice called a “restrictor”, having a fixed, triangle shaped opening to pass high pressure liquid refrigerant to the evaporator. &nbsp;Before the capillary tube came into use (invented in the late 20s) was the Automatic Expansion Valve which is little more than a pressure regulating valve maintaing a constant pressure within the evaporator coil, often with an adjustable spring compression. &nbsp;This knob or screw would often go out of adjustment because of the constant freeze/thaw occurring at these valves. &nbsp;They were often equipped with a rubber cap or boot to keep moisture from interfering with the adjustment. &nbsp;These AXVs work well in constant load conditions, but under high load tend to starve the evaporator of refrigerant and risk slugging liquid back to the compressor under low load. &nbsp;The improvement to these valves came with the addition of a thermostatic element or “sensor bulb” strapped to the suction line, the temperature of which alters the pressure within the the bulb and in turn, operates a diaphragm inside the valve to properly feed the correct amount of refrigerant to the coil given the conditions. &nbsp;This type of valve would be called a Thermostatic Expansion Valve.</p>
<p><a href="https://musingsonentropy.files.wordpress.com/2013/04/axv_dry_type.jpg"><img data-attachment-id="4073" data-permalink="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/axv_dry_type/" data-orig-file="https://musingsonentropy.files.wordpress.com/2013/04/axv_dry_type.jpg" data-orig-size="2146,2484" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SCH-I535&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1365067368&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.7&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.0011574074074074&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="AXV_Dry_Type" data-image-description="" data-medium-file="https://musingsonentropy.files.wordpress.com/2013/04/axv_dry_type.jpg?w=259" data-large-file="https://musingsonentropy.files.wordpress.com/2013/04/axv_dry_type.jpg?w=605" alt="AXV_Dry_Type" src="https://musingsonentropy.files.wordpress.com/2013/04/axv_dry_type.jpg?w=605&amp;h=700" srcset="https://musingsonentropy.files.wordpress.com/2013/04/axv_dry_type.jpg?w=605&amp;h=700 605w, https://musingsonentropy.files.wordpress.com/2013/04/axv_dry_type.jpg?w=1210&amp;h=1400 1210w, https://musingsonentropy.files.wordpress.com/2013/04/axv_dry_type.jpg?w=130&amp;h=150 130w, https://musingsonentropy.files.wordpress.com/2013/04/axv_dry_type.jpg?w=259&amp;h=300 259w, https://musingsonentropy.files.wordpress.com/2013/04/axv_dry_type.jpg?w=768&amp;h=889 768w, https://musingsonentropy.files.wordpress.com/2013/04/axv_dry_type.jpg?w=885&amp;h=1024 885w" sizes="(max-width: 605px) 100vw, 605px"></a></p>
<p>A very simple dry type evaporator with and AXV. &nbsp;Notice the Thermostatic Control Switch. &nbsp;This has nothing to do with the refrigerant supply, but simply controls the electrical current to the compressor and allows the operator to adjust the cabinet temperature. &nbsp;These worked with a thermostatic bulb strapped to the evaporator, suction line or somewhere else in the cabinet. &nbsp;The Thermostat was a great improvement over the controls of the 20s which sometimes used a pressure operated switch tied into the suction line. &nbsp;The service or replacement of these complicated switches could involved breaking the sealed refrigerant line.</p>
<p><a href="https://musingsonentropy.files.wordpress.com/2013/04/axv_brine_chiller.jpg"><img data-attachment-id="4072" data-permalink="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/axv_brine_chiller/" data-orig-file="https://musingsonentropy.files.wordpress.com/2013/04/axv_brine_chiller.jpg" data-orig-size="2251,1545" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SCH-I535&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1365066923&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.7&quot;,&quot;iso&quot;:&quot;125&quot;,&quot;shutter_speed&quot;:&quot;0.033333333333333&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="AXV_Brine_Chiller" data-image-description="" data-medium-file="https://musingsonentropy.files.wordpress.com/2013/04/axv_brine_chiller.jpg?w=300" data-large-file="https://musingsonentropy.files.wordpress.com/2013/04/axv_brine_chiller.jpg?w=605" alt="AXV_Brine_Chiller" src="https://musingsonentropy.files.wordpress.com/2013/04/axv_brine_chiller.jpg?w=605&amp;h=415" srcset="https://musingsonentropy.files.wordpress.com/2013/04/axv_brine_chiller.jpg?w=605&amp;h=415 605w, https://musingsonentropy.files.wordpress.com/2013/04/axv_brine_chiller.jpg?w=1210&amp;h=830 1210w, https://musingsonentropy.files.wordpress.com/2013/04/axv_brine_chiller.jpg?w=150&amp;h=103 150w, https://musingsonentropy.files.wordpress.com/2013/04/axv_brine_chiller.jpg?w=300&amp;h=206 300w, https://musingsonentropy.files.wordpress.com/2013/04/axv_brine_chiller.jpg?w=768&amp;h=527 768w, https://musingsonentropy.files.wordpress.com/2013/04/axv_brine_chiller.jpg?w=1024&amp;h=703 1024w" sizes="(max-width: 605px) 100vw, 605px"></a></p>
<p>An AXV on a dry type coil, but rather than direct expansion, this is a brine tank. &nbsp;The refrigerant tube passes through of a low freezing point brine which in turn froze ice cubes and chilled the space. &nbsp;These had the advantage of having a holdover effect to keep the cabinet cold and prevent short cycling of the compressor and also had a more constant loading effect on the AXV which made for more consistent and predictable performance. &nbsp;The down side of a brine system is the possible corrosive effects of the brine, extra cabinet space taken and the lower evaporator temperatures possibly needed to chill the brine to a temperature that it could in turn chill the refrigerator.</p>
<p><a href="https://musingsonentropy.files.wordpress.com/2013/04/ge_ck.jpg"><img data-attachment-id="4083" data-permalink="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/ge_ck/" data-orig-file="https://musingsonentropy.files.wordpress.com/2013/04/ge_ck.jpg" data-orig-size="2176,2571" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SCH-I535&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1365067164&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.7&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.0014285714285714&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="GE_CK" data-image-description="" data-medium-file="https://musingsonentropy.files.wordpress.com/2013/04/ge_ck.jpg?w=254" data-large-file="https://musingsonentropy.files.wordpress.com/2013/04/ge_ck.jpg?w=605" alt="GE_CK" src="https://musingsonentropy.files.wordpress.com/2013/04/ge_ck.jpg?w=605&amp;h=715" srcset="https://musingsonentropy.files.wordpress.com/2013/04/ge_ck.jpg?w=605&amp;h=715 605w, https://musingsonentropy.files.wordpress.com/2013/04/ge_ck.jpg?w=1210&amp;h=1430 1210w, https://musingsonentropy.files.wordpress.com/2013/04/ge_ck.jpg?w=127&amp;h=150 127w, https://musingsonentropy.files.wordpress.com/2013/04/ge_ck.jpg?w=254&amp;h=300 254w, https://musingsonentropy.files.wordpress.com/2013/04/ge_ck.jpg?w=768&amp;h=907 768w, https://musingsonentropy.files.wordpress.com/2013/04/ge_ck.jpg?w=867&amp;h=1024 867w" sizes="(max-width: 605px) 100vw, 605px"></a></p>
<p>A GE Monitor Top style refrigerating unit. &nbsp;A hermetic system with what looks like a rotary compressor and oil pump lubricating pump. &nbsp;The …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/">https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/</a></em></p>]]>
            </description>
            <link>https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24278184</guid>
            <pubDate>Wed, 26 Aug 2020 01:40:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alberta government to support feasibility study for Edmonton-Calgary hyperloop]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24278095">thread link</a>) | @GnarlyWhale
<br/>
August 25, 2020 | https://www.cbc.ca/news/canada/calgary/transpod-alberta-hyperloop-mou-1.5697848 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/calgary/transpod-alberta-hyperloop-mou-1.5697848">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Toronto-based TransPod has signed an agreement with the Alberta government that will see the province support the firm's early efforts to advance development of an&nbsp;ultra-high-speed transportation line between Calgary and Edmonton.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.4443903.1513038371!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/transpod-hyperloop.jpg"></p></div><figcaption>An illustration of what TransPod's hyperloop system might look like running beside a highway.<!-- --> <!-- -->( Radio-Canada/TransPod Hyperloop)</figcaption></figure><p><span><p>Canadian hyperloop&nbsp;company TransPod has signed an agreement with the Alberta government that will see the province support the firm's early efforts to advance development of an&nbsp;ultra-high-speed transportation line between Calgary and Edmonton.</p>  <p>Though the concept may still sound like&nbsp;science fiction, the company's ultimate goal is&nbsp;to have Albertans shuttling between Calgary and Edmonton in train-like pods — at speeds up to 1,000 kilometres an hour — through&nbsp;magnetic tubes by 2030.</p>  <p>On Tuesday, Toronto-based TransPod&nbsp;took a step forward by&nbsp;announcing it's&nbsp;inked&nbsp;a memorandum of understanding (MOU) with the province&nbsp;that will support the company in further studying the feasibility of the technology in Alberta, share transportation data and identify suitable land for a test track.</p>  <p>Alberta Transportation will also take part&nbsp;in discussions with potential large institutional investors "where suitable," according to the company.</p>  <p>The government hasn't made any&nbsp;financial commitments or endorsements.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5376040.1574898063!/fileImage/httpImage/image.jpeg_gen/derivatives/original_300/sebastien-gendron.jpeg 300w,https://i.cbc.ca/1.5376040.1574898063!/fileImage/httpImage/image.jpeg_gen/derivatives/original_460/sebastien-gendron.jpeg 460w,https://i.cbc.ca/1.5376040.1574898063!/fileImage/httpImage/image.jpeg_gen/derivatives/original_620/sebastien-gendron.jpeg 620w,https://i.cbc.ca/1.5376040.1574898063!/fileImage/httpImage/image.jpeg_gen/derivatives/original_780/sebastien-gendron.jpeg 780w,https://i.cbc.ca/1.5376040.1574898063!/fileImage/httpImage/image.jpeg_gen/derivatives/original_1180/sebastien-gendron.jpeg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5376040.1574898063!/fileImage/httpImage/image.jpeg_gen/derivatives/original_780/sebastien-gendron.jpeg"></p></div><figcaption>Sebastien Gendron, co-founder and CEO of Transpod, says the new agreement signed with the Alberta government is a "huge" step.<!-- --> <!-- -->(Tony Seskus/CBC)</figcaption></figure></span></p>  <p>TransPod's&nbsp;chief&nbsp;executive said in an interview he sees the MOU as key. The announcement comes less than year after the company urged the UCP government <a href="https://www.cbc.ca/news/canada/calgary/alberta-hyperloop-calgary-edmonton-1.5375476">to climb aboard the idea.</a></p>  <p><em>"</em>It's actually the first, I would say,&nbsp;official support from the government of a province which belongs to a G7 country," said CEO Sebastien&nbsp;Gendron, "which is kind of a huge step to confirm the path to commercialization."</p>  <p>Transportation Minister Ric McIver said he's hopeful that TransPod's work will lead to the development of new technology that's put into&nbsp;practice in Alberta, creating new opportunities for job creation.</p>    <p>"I am excited about the possibilities," McIver said in an interview. <em>"</em>TransPod [wants] a chance to prove what they can do and I think Alberta is the place where we should let them prove it."</p>  <p>McIver said there's no commitment to provide&nbsp;government money, but he added that if TransPod&nbsp;proves the technology, they will "certainly help them tell their story<em>.</em>"</p>  <p>"We're going to try to be facilitators for them," he said.</p>  <p>If privately held TransPod realizes its vision, its hyperloop system&nbsp;could move passengers or cargo between Calgary and Edmonton in about&nbsp;half an hour. The cost of a one-way ticket would range between $40 to $60, Gendron said.</p>  <p>To build the full line, however, would cost between $6 billion and $10 billion, he said.&nbsp;The company's goal&nbsp;is to attract private investment by showing that it's economically viable, Gendron added.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.4216746.1500667597!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/transpod-calgary-skyline.jpg 300w,https://i.cbc.ca/1.4216746.1500667597!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/transpod-calgary-skyline.jpg 460w,https://i.cbc.ca/1.4216746.1500667597!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/transpod-calgary-skyline.jpg 620w,https://i.cbc.ca/1.4216746.1500667597!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/transpod-calgary-skyline.jpg 780w,https://i.cbc.ca/1.4216746.1500667597!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/transpod-calgary-skyline.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.4216746.1500667597!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/transpod-calgary-skyline.jpg"></p></div><figcaption>An artist's rendering of the TransPod hyperloop against the Calgary skyline. <!-- --> <!-- -->(TransPod)</figcaption></figure></span></p>  <p>TransPod&nbsp;aims to demonstrate to large institutional investors that there's<em>&nbsp;</em>enough ridership for passengers, as well as goods.</p>  <p>"The second aspect is to do a really detailed cost analysis of the infrastructure," Gendron said.&nbsp;</p>  <p>"That will confirm the amount of investment we need to build the full line, which includes not only the infrastructure, but also the stations and the land acquisition."</p>    <p>Should things progress, TransPod&nbsp;would like to begin construction of a $500-million test track in Alberta in 2022. The final step would be to start construction of the full line, currently targeted to begin&nbsp;in&nbsp;2025.</p>  <p>The former NDP government had allocated 10 kilometres of land between Calgary and Edmonton to&nbsp;TransPod to build a test track. Gendron said they're looking at using the same area but would need to confirm once the feasibility study is complete.</p>  <p>Gendron said the company is also&nbsp;in the design and development phase for a testing facility in France.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5176459.1560541966!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/ric-mciver.jpg 300w,https://i.cbc.ca/1.5176459.1560541966!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/ric-mciver.jpg 460w,https://i.cbc.ca/1.5176459.1560541966!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/ric-mciver.jpg 620w,https://i.cbc.ca/1.5176459.1560541966!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/ric-mciver.jpg 780w,https://i.cbc.ca/1.5176459.1560541966!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/ric-mciver.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5176459.1560541966!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/ric-mciver.jpg"></p></div><figcaption>Transportation Minister Ric McIver said he's hopeful that TransPod's work will lead to the development of new technology that's put into&nbsp;practice in Alberta, spurring further job creation. The company estimates the project would create 38,000 jobs over the next 10 years.<!-- --> <!-- -->(Mike Symington/CBC)</figcaption></figure></span></p>  <p>Unlike trains, hyperloop&nbsp;systems don't use rails. Instead, they propel&nbsp;vehicles through a vacuum&nbsp;in sealed tubes at high speeds&nbsp;made possible by the extremely low friction inside the tube.</p>  <p>Tesla founder&nbsp;Elon Musk first outlined his vision for the hyperloop concept in 2013. Since then, it's also attracted the attention of billionaire Richard Branson, founding chairman of&nbsp;<a href="https://www.reuters.com/article/us-virgin-spirit-aerosystm-hyperloop/floating-on-air-virgin-hyperloop-signs-deal-with-key-jet-parts-maker-idUSKBN23W1OJ">Virgin Hyperloop One</a>.</p>  <p>Virgin Hyperloop's goal is to launch commercial routes by 2029.</p>  <p>Transpod and Spain's Zeleros are also competing to&nbsp;upend traditional passenger and freight networks with&nbsp;technology they say will slash travel times and&nbsp;congestion.</p>  <p>The discussion around&nbsp;hyperloop technology&nbsp;has been received with both excitement and&nbsp;skepticism over the years.</p>  <p>A Boeing executive last year rejected the suggestion&nbsp;hyperloop travel&nbsp;<a href="https://www.cnbc.com/2019/11/18/hyperloop-to-threaten-aviation-not-in-my-lifetime-says-boeing-exec.html">could threaten aviation within his lifetime</a>. The&nbsp;cost, complexity, regulation and safety of hyperloop&nbsp;systems have also been identified as challenges.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/calgary/transpod-alberta-hyperloop-mou-1.5697848</link>
            <guid isPermaLink="false">hacker-news-small-sites-24278095</guid>
            <pubDate>Wed, 26 Aug 2020 01:23:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running X Client Using Virtual X Server Xvfb]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24278084">thread link</a>) | @keyboardman
<br/>
August 25, 2020 | https://leimao.github.io/blog/Running-X-Client-Using-Virtual-X-Server-Xvfb/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Running-X-Client-Using-Virtual-X-Server-Xvfb/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main">
  <div>
    
	<p><img src="https://leimao.github.io/images//author_images/Lei-Bio-Medium.jpg" alt="Lei Mao bio photo"></p><h3>Lei Mao</h3>
<p>Machine Learning, Artificial Intelligence, Computer Science.</p>
<p>

<a href="http://facebook.com/dukeleimao" target="_blank"><i></i> Facebook</a>
<a href="http://linkedin.com/in/lei-mao" target="_blank"><i></i> LinkedIn</a>


<a href="http://github.com/leimao" target="_blank"><i></i> GitHub</a>
<a href="http://scholar.google.com/citations?user=R2VUf7YAAAAJ" target="_blank"><i></i>&nbsp; G. Scholar</a>






<a href="mailto:dukeleimao@gmail.com" target="_blank"><i></i> E-Mail</a>

<a href="https://leimao.github.io/feed.xml" target="_blank"> RSS</a>
  </p></div>
  <article>
    <!--/ .headline-wrap -->
    <div>
      <h3 id="introduction">Introduction</h3>

<p>Sometimes, when I run some programs, which normally run on a local computer with a graphical display, in Docker container, they would somehow fail. Sometimes, I need to run many simulations that have GUIs simultaneously, and I don’t want to see those GUIs at all. Is there any virtual display which allows me to put the graphics into? The answer is yes and we could use X virtual framebuffer, Xvfb.</p>



<p>In this blog post, I would like to take you to glimpse the X server-client architecture for displaying graphics, and discuss how to use Xvfb.</p>

<h3 id="x-server-client">X Server-Client</h3>

<p>In computing, the X Window System, commonly known as X11 or X, is a network-transparent windowing system for bitmap displays. X uses a client-server model. An X server program runs on a computer with a graphical display and communicates with various client programs.</p>

<div>
<figure>
    <img src="https://leimao.github.io/images/blog/2020-07-01-Running-X-Client-Using-Virtual-X-Server-Xvfb/2000px-X_client_server_example.svg.png">
    <figcaption>X Server-Client Architecture</figcaption>
</figure>
</div>

<p>Any application that requires GUI and interacts with X server program is called X client. X client typically includes applications such as OS GUI, web browser, most of the games, and so on. Without X server, some of those programs would fail to run.</p>



<p>X server requires a graphical display. Without a graphical display, X server will not start and thus all the X clients that must run on a X server would fail.</p>



<p>In some scenarios where X server is not started or there is no display, we would still like to run X clients, we should use a virtual X server to host the X clients. Instead of outputting signals to screen, the virtual X server outputs signals to memory. This will be very useful for running programs, especially those whose display graphics are not important, in Docker container or on remote servers. For example, if you would like to watch a live streaming on a remote server without graphical display and take some snapshots routinely every 5 minutes, virtual X server will be very helpful. In fact, some libraries, such as Matplotlib (without using agg backend) and TikZ requires to be hosted on X server. If there is no display, say in a Docker container, running the programs that use those libraries will fail.</p>

<h3 id="x-virtual-framebuffer-xvfb">X Virtual Framebuffer (Xvfb)</h3>

<p>Xvfb or X virtual framebuffer is a display server implementing the X11 display server protocol. In contrast to other display servers, Xvfb performs all graphical operations in virtual memory without showing any screen output.</p>



<p>To install Xvfb, please run the following commands in the terminal.</p>

<div><div><pre><code><span>$ </span><span>sudo </span>apt update
<span>$ </span><span>sudo </span>apt <span>install </span>xvfb ghostscript
</code></pre></div></div>



<p>Once the <code>xvfb</code> and <code>ghostscript</code> are installed, we could start any X client in the terminal using <code>xvfb-run</code>.</p>

<div><div><pre><code><span>$ </span>xvfb-run firefox
<span>$ </span>xvfb-run python plot.py
</code></pre></div></div>

<h3 id="conclusions">Conclusions</h3>

<p>Xvfb would be very useful for a lot of GUI based simulations running in Docker container or remote server.</p>

<h3 id="references">References</h3>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Xvfb">Wikipedia - Xvfb</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Xvfb">Wikipedia - X Window System Protocols and Architecture</a></li>
  <li><a href="http://manpages.ubuntu.com/manpages/trusty/man1/xvfb-run.1.html">xvfb-run</a></li>
</ul>

      <hr>
      
    </div><!-- /.article-wrap -->
  
    <!-- /#disqus_thread -->
  
  </article>
</div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/Running-X-Client-Using-Virtual-X-Server-Xvfb/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24278084</guid>
            <pubDate>Wed, 26 Aug 2020 01:21:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The catalyst for the next speculative crypto bubble]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24277841">thread link</a>) | @simplertms
<br/>
August 25, 2020 | https://4thquadrant.io/freearticles/the-catalyst-for-the-next-speculative-crypto-bubble/ | <a href="https://web.archive.org/web/*/https://4thquadrant.io/freearticles/the-catalyst-for-the-next-speculative-crypto-bubble/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-td-block-uid="tdi_28_910">

<div>
<p>In 2017/18 cryptocurrencies went through a speculative bubble that saw its flagship currency Bitcoin reach peaks of $20,089 and a market cap of $320 billion. At the height of euphoria, the total market cap of all cryptocurrencies reached $790 billion. While Bitcoin and other cryptocurrencies (known as altcoins) have been around since 2009, it was the consolidation of mindshare and public interest in 2017 and 2018 that has made it a mainstay for alternative investors. But the fact remains that we are yet to see the adoption event that will make it a mainstay for all investors.</p>



<p>Most recently Cryptocurrencies have once again found a place in the news cycle following two years of dormancy post the bubble. The central trend appears to be around the phenomenon of decentralised finance otherwise known as DeFi. The quantity of activity and community participation in DeFi and related activities have been pointed to as potential indicators of a return to the speculative mania that took place in 2017. By the end of July, the total value locked up in DeFi related projects was $4 billion. A somewhat marginal amount given that Bitcoin is now over $200 billion in valuation and the whole market for cryptocurrencies is approaching $350 billion.</p>



<p>Regardless, DeFi represents a strong use case for cryptocurrencies as a means to provide lending and borrowing capabilities and is also geared to attract significant speculative interest. One of the most basic and pervasively engaged features of DeFi at present is yield farming. Cryptocurrency assets can earn or ‘farm’ yields in three main forms:</p>



<ol><li>Participating in financial products as one would in traditional markets</li><li>Locking up some cryptocurrency liquidity in return for an interest-like reward.</li><li>Staking cryptocurrency (like collateral) to fortify the security of a Proof-of-Stake based blockchain platform, where ‘staking’ some tokens prevents malicious activity similar to how a collateralized loan prevents default risk.</li></ol>



<p>However, the attention decentralised finance (DeFi) is getting right now, looks more like a bubble than a catalyst for adoption, where volatility (price, scams, hacks etc) of the industry hasn’t been solved.</p>



<p>The question then is, what is a catalyst for adoption? Given that financial products (form 1) on any platforms, blockchain or otherwise, can provide yields through participation, let us focus on yield farming native to the nature of blockchain (forms 2 &amp; 3), Proof-of-Stake – where providing security/liquidity returns yields.</p>



<p>Proof-of-Stake is simply the mechanism whereby a decentralised platform is able to provide security against attacks on the immutability of the ledger on the blockchain. The name holds the key to understanding this mechanism where ‘staking’ (locking up) the currency on the platform, is the means by which you are able to validate transactions on the ledger (the state of the blockchain) and add to the ledger. The game theory of securing the chain via staking is tied to rewards for being a good actor and penalties for being a bad actor. These rewards represent the yields earned for securing the chain.</p>



<p>What is particularly interesting as the speculation starts to ramp up once more is that Proof-of-Stake based platforms are gaining more attention because of their ability to provide yields in return for a financial stake in the platform. Yields on a Proof-of-Stake network represents a passive income avenue for a spectrum of individual/retail investors all the way to institutional players. This differs from the Proof-of-Work mechanism, most popularly represented by Bitcoin, which consumes electricity (mining) to secure the ledger. Where mining BTC is more difficult and less accessible to the spectrum of investors (currently there are a few large mining farms that make this their primary occupation) most BTC investors will make capital gain returns based on price appreciation through adoption. In the absence of BTC becoming a true global currency it will depend on a series of consolidating speculative bubbles to edge toward adoption – a chicken and egg problem perhaps sped along by the more consistent rewards associated with Proof-of-Stake.</p>



<h3>Yields: A Ponzi scheme or a catalyst for cryptocurrency adoption?</h3>



<p>Thus far the speculation on the future potential of blockchain technology, and cryptocurrencies by extension, is what gives the industry the large valuation it holds, even as use cases seem scarce or utilised by few.</p>



<p>In such a case, providing yields for no inherent value due to lack of use case, appears more like a Ponzi scheme than investment in a nascent technology. The idea is that when more people take a financial stake in the platform and lock up those funds for yields, all the prior participants will continue to benefit, not only from the yields but also from the price appreciation of the currency and market capitalisation of the platform. Of course, the integrity of the platform will only be realised when the use cases are actualised at some point in the future. In the interim, the Ponzi characteristics are exacerbated by the lucrative yield returns (often ranging from 5-20% per annum) made available by Proof-of-Stake networks, in comparison to traditionally available yield/interest earning financial products. It’s important to note that platforms vary in risk and reliability, we can liken it to investing in financial products across different tranches – some more junk-like than others.</p>



<p>Bitcoin, on the other hand, provides an entirely different avenue of investment in blockchain but comes with its own set of challenges – namely the chicken and egg problem we discussed above. Bitcoin requires the expense of electricity through mining activities to secure the network and ‘earn’ Bitcoin. While the rewards for mining on a Proof-of-Work network can be equated to the yields earned for staking on a Proof-of-Stake network, the ‘work’ performed for Proof-of-Work (cost of time and initial investment) makes it impossible for it to operate like a Ponzi scheme. Essentially, this means that Bitcoin can’t propagate its adoption through the mechanism of mining, where mining does not lend itself to the low-effort traits of Proof-of-Stake currently attracting attention to the DeFi bubble.</p>



<p>The lower effort in work required to secure the Proof-of-Stake network allows more users to participate meaningfully and earn yields. This is the beginning of a solution to the chicken and egg problem, where increased participation can bolster the market capitalisation required for widespread traction. In summary, easier participation increases the likelihood of network effect for a platform, where earning yields becomes the initial use case for the platform – as risky or unreliable as it may seem. Increased traction over time is very capable of evolving the volatile and Ponzi-like DeFi space into a mature financial structure supporting the blockchain ecosystem.</p>



<p>During 2017/18 the prevailing narrative of Proof-of-Work and crypto’s use case as a currency was not substantiated and resulted in a bubble rather than an adoption event. While it gained attention on the global stage, the widely held perception was that there was no immediately apparent use case that could sustain and grow its valuation beyond pure speculation. In the last couple of years following the bust of the speculative bubble, Proof-of-Stake has become a more significant narrative for the industry. The most marked indicator being Ethereum (currently Proof-of-Work), the second largest cryptocurrency, indicating its intent to transition to a Proof-of-Stake network.</p>



<p>The narrative of Proof-of-Stake is ballooning out quite rapidly, popularly considered to be propagated by the perceived benefits for scaling transaction capacity. However, what we have identified is that the use case of earning yields has the potential to catalyse the next boom cycle similar to 2017/ 18, and perhaps even to a greater extent. Even in the absence of yields as a catalyst for the next boom cycle, it represents a solid use case as a financial ecosystem to sustain speculative value and drive cryptocurrencies closer to mainstream use.</p>



<div id="slimcalltoaction"><p>This is box title</p><p>If you enjoyed this article, take advantage of our 14 days free trial to explore our exclusive content. Or sign-up for our free weekly newsletters. View our subscription options <a href="https://4thquadrant.io/subscribe">here.</a></p></div>
</div></div><div data-td-block-uid="tdi_29_cc5">

<div><h3><span>CONTACT THE EDITOR</span></h3>
<p>We welcome thoughtful discourse on all our content. If you would like to further explore or discuss any of the ideas covered in this article please contact our editors directly.<br><span>Contact Details</span></p>
</div></div></div>]]>
            </description>
            <link>https://4thquadrant.io/freearticles/the-catalyst-for-the-next-speculative-crypto-bubble/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24277841</guid>
            <pubDate>Wed, 26 Aug 2020 00:31:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Embrace Beginner's Mind; Avoid the Wrong Way to Be an Expert]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24277832">thread link</a>) | @7d7n
<br/>
August 25, 2020 | https://eugeneyan.com/writing/beginners-mind/ | <a href="https://web.archive.org/web/*/https://eugeneyan.com/writing/beginners-mind/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>When we learn something new, such as a programming language, we start as beginners. We can learn and follow the rules and apply them in a narrow context. However, we don’t understand the bigger picture and get lost outside of that specific context.</p>

<p>Imagine that I enroll in a <a href="https://en.wikipedia.org/wiki/Massive_open_online_course" target="_blank">MOOC</a> on <code>R</code> and learn about statistical analysis, machine learning, and <a href="https://rstudio.github.io/shinydashboard/" target="_blank"><code>Shiny</code></a> dashboards. As part of machine learning, I learn that I should <a href="https://www.rdocumentation.org/packages/caret/versions/6.0-86/topics/createDataPartition" target="_blank">split the data into train and test</a> sets. I apply this in assignments and Kaggle and everything works fine—this is the <em>narrow</em> context.</p>

<p>Then, perhaps I get the opportunity to apply my new skills in a <em>wider</em> context—I build a model, validate it (via random train-test split), and deploy it. However, the offline and online (i.e., A/B test) metrics don’t match up. Eventually, I figure out that I should use a <a href="https://www.fast.ai/2017/11/13/validation-sets/" target="_blank">time-based split</a> so future data doesn’t <em>leak</em> into the training set.</p>

<p>With the benefit of the wider context, I encountered challenges and failures (read: lessons) that were not part of the MOOC assignments. As a result, I got to see the bigger picture; I know there’s still lots to learn. Thus, I continue to learn and progress through the stages of beginner, intermediate, and so on.</p>

<blockquote>
  <p>The more I learn, the more I realise how much I don’t know. – Albert Einstein</p>
</blockquote>

<h2 id="from-beginner-to--expert-beginner">From beginner to … expert beginner</h2>

<p>But what happens if I <em>don’t</em> see the bigger picture?</p>

<p>Let’s assume I work in the HR department of a widget manufacturer. Everything—from headcount to payroll to vacation balance—is run in Excel. I apply my newfound <code>R</code> skills to automate my work via one-off scripts. This involves calculating statistics on factory sites and displaying it via a <code>Shiny</code> dashboard on the department desktop. In the eyes of my manager and team, I’m an absolute rockstar ninja wizard. I get showered with praise and am promoted to manager of HR data science.</p>

<p>I might not know about proper ML validation, deployment, unit tests, or even version control. I certainly haven’t done any of that. But who cares? We don’t need it. I’m now the manager of HR data science. I’m now… an “expert”.</p>

<p>To those in the know, I’m clearly still a beginner. But my context is narrow and I don’t see the bigger picture. Thus, I don’t know that there’s still lots to learn, lots to do. However, because I’ve achieved a modicum of success (through <em>narrow</em> applications of what I learned) and others call me an expert, I now view myself as an expert. As a result, I stop learning. I’m now stuck at a local optima. <strong>I’ve become an <a href="https://daedtech.com/how-developers-stop-learning-rise-of-the-expert-beginner/" target="_blank">expert beginner</a></strong>.</p>

<p>Suppose I stay in that same role, within HR, for 10 years. At the end of it, do I have 10 years of experience, or one year of experience repeated 10 times?</p>

<details><summary>An army of expert beginners led by an expert beginner</summary>
<div>

<p>As head of HR data science, I hire a team of data scientists. Eventually, some team members will suggest new technology (e.g., Python, Docker) or practices (e.g., version control, unit testing).</p>

<p>However, I’m the most experienced (read: longest tenure) and the expert-est expert. I dismiss ideas and technology that I’m unfamiliar with. “Oh, I see you’re new here. Yes, Python sounds like a good idea but the Chief HR Officer really likes the <code><span>Shiny</span></code> dashboard that I built.” “Haha, we don’t need unit tests! I live and breathe this code every day—there’s no need to test it”.</p>

<p>Team members who can see the bigger picture are disappointed by the outdated technology and incorrect practices. They see no room for learning and growth. As a result, <strong>the most talented and ambitious leave</strong> (if they know what’s best for them). For those who stay—hurray! There’s less competition. They’ll toe the line and one day, they’ll be a <em>senior</em> expert beginner and teach new joiners their “expert” ways.</p>

<p>This leads to the <a href="http://brucefwebster.com/2008/04/11/the-wetware-crisis-the-dead-sea-effect/" target="_blank">Dead Sea effect</a> where you’re <strong>left with your least talented and effective</strong> people. They’re grateful to have a job and settle in for a couple of years (or decades). Now, the team has (d)evolved into an army of expert beginners who follow the directions of the top expert beginner.</p>

<p><img src="https://eugeneyan.com/assets/dead-sea.jpg" title="The expert beginners are entrenched and can’t be replace" alt="The expert beginners are entrenched and can’t be replace"></p>
<p>The expert beginners are entrenched and can’t be replaced (source: <a href="https://eugeneyan.com/writing/beginners-mind/(https://dilbert.com/strip/2010-12-02)">Scott Adams</a>)</p>

<p>Because expert beginners have learned “everything” there is to learn, tried “everything” there is to try, and done “everything” there is to do, there’s nothing new to learn, try, and do. The team stops trying new ideas—“Oh we don’t use Docker here. We have VMs!”—and the organization stops innovating.</p>

<p>This partly explains some industries getting disrupted. The iPhone disrupting Nokias and Blackberrys, AWS disrupting on-premise hardware, Stripe disrupting payment processing, Tesla disrupting… you get the idea.</p>

</div>
</details>

<p><img src="https://eugeneyan.com/assets/climbed-it-all.jpg" title="The expert beginner doesn't see the bigger picture and is thus stuck" alt="The expert beginner doesn't see the bigger picture and is thus stuck"></p>
<p>The expert beginner doesn't see the bigger picture; thus, he is stuck.</p>

<h2 id="the-beginners-mind-is-always-a-student">The beginner’s mind is always a student</h2>

<p>How do we prevent stagnation (and possibly becoming an expert beginner)? How do we stay open-minded and constantly learning and experimenting?</p>

<p><strong>One way is <a href="https://en.wikipedia.org/wiki/Shoshin" target="_blank">Shoshin</a> (beginner’s mind)</strong>. It’s a concept from Zen Buddhism on having an attitude of openness, eagerness, and no preconceptions, even when our knowledge of the subject is advanced. In other words, to think <em>just</em> like a beginner.</p>

<blockquote>
  <p>In the beginner’s mind there are many possibilities, but in the expert’s there are few. – Shunryu Suzuki</p>
</blockquote>

<p>With beginner’s mind, regardless of your experience and expertise, you <strong>stay curious and approach new ideas and experiences as a student</strong>. Even when new technology or methods don’t fit your paradigm, you’re open to learning and trying it. Students don’t say “That’s not how we do things here”.</p>

<p>Sometimes, when others view us as experts, we let it get to us. We stay within our narrow subject matter expertise and stop exploring new ideas and possibilities. We avoid newer, bigger challenges so we don’t make mistakes; we stick to what has worked in the past. This helps preserve our expert identity.</p>

<blockquote>
  <p>The most dangerous phrase in the language is, “We’ve always done it this way.” – Grace Hopper</p>
</blockquote>

<p>But this doesn’t make sense. In my field of data science, new tools (e.g., Spark, Docker, Airflow) and methods (e.g., embeddings, attention, pre-training) constantly improve on the state of the art (SOTA)—it’s useful, if not essential, to keep up to date. (That said, fundamental techniques like regression and decision trees are often a solid baseline.)</p>

<h2 id="the-beginners-mind-keeps-on-pedalling">The beginner’s mind keeps on pedalling</h2>

<p>Learning is like cycling. When we start pedalling (from a standstill), it takes effort and time to gain momentum. Nonetheless, we’ll pick up speed and begin gaining distance.</p>

<p>We might look back at where we started and think “Wow, I’ve come a long way. Perhaps I don’t have to pedal as hard; perhaps I don’t have to pedal at all.” If we stop pedalling, the initial momentum might carry us slightly further, but eventually, we’ll come to a standstill. While we don’t lose the distance covered, we’re not gaining distance either. (Though in fast-paced fields like tech, if you don’t move forward, <em>you begin to move backward</em>.)</p>

<p>Here, distance is knowledge (and achievements); momentum is learning. While distance is correlated with expertise, the relationship is not as strong as we think (e.g., one year of experience repeated 10 times). I think momentum (the ability to learn and adapt quickly) is part of expertise as well. The experts I know are often reading or hacking. At work, they can synthesize their mental prototypes and tailor solutions based on context.</p>

<p>To maintain momentum, <strong>the beginner’s mind continues to pedal regardless of the distance they’ve covered</strong>. It’s not surprising that many successful people are—and continue to be—voracious readers and learners. Warren Buffet, Bill Gates, Elon Musk, just to name a few. Do you know any successful person that doesn’t read or learn?</p>

<blockquote>
  <p>The illiterate of the 21st century will not be those who cannot read and write, but those who cannot learn, unlearn, and relearn. – Alvin Toffler</p>
</blockquote>

<details><summary>Note: Not all knowledge is the same</summary>
<div>

<p>There’s knowledge that we gain from books and courses—we’re tested on this in exams. Then, there’s <a href="https://commoncog.com/blog/the-tacit-knowledge-series/" target="_blank">(tacit) knowledge</a> that we gain from practice—we’re tested on this in life.</p>

<div>

<blockquote><div lang="en" dir="ltr"><p>You cannot get educated by this self-propagating system in which people study to pass exams, and teach others to pass exams, but nobody knows anything.</p><p>You learn something by doing it yourself, by asking questions, by thinking, and by experimenting. 🧠</p></div>— Richard Feynman (@ProfFeynman) <a href="https://twitter.com/ProfFeynman/status/1295411496407556096?ref_src=twsrc%5Etfw">August 17, 2020</a></blockquote>

</div>

<p>For example, learning to ride a bicycle. We can’t learn to ride a bike by reading a textbook. The <strong>only way to learn is by actually doing it</strong>. We’re going to lose balance and fall, but eventually, we’ll figure it out. Also, our ability to ride a bike is <strong>transferable</strong> to other two-wheeled transport. Once we learn how to ride a regular bike, we’ll have a gentler learning curve on mountains bikes, tandem bikes, and even e-scooters.</p>

<p>Similarly, some skills and knowledge <strong>can only be gained through practice</strong>. They’re usually <strong>transferable</strong> across multiple domains too. For example, what’s the most suitable way to <a href="https://bugra.github.io/posts/2020/5/25/how-to-serve-model/" target="_blank">serve models in production</a>? There are some common patterns: compute offline and cache, serve via microservice, embed in the main app. Do these patterns differ across domains? Not much. Which is the best approach for our use case? Well, it depends—knowing the answer is tacit knowledge.</p>



<p>Often, such skills and knowledge are <strong>fundamental</strong> and can be thought of as building blocks (or <a href="https://jamesclear.com/first-principles" target="_blank">first principles</a>). For example, in programming, we learn about conditionals, iteration, and data structures. In distributed data processing, we learn about map, reduce, and shuffle. Once we understand these fundamentals, it’s easier to pick up another programming language or distributed processing framework. It also helps us write more effective software and <a href="https://en.wikipedia.org/wiki/Extract,_transform,_load" target="_blank">ETL</a> jobs.</p>

<p>Mastering the fundamentals also helps with the <a href="https://commoncog.com/blog/to-get-good-go-after-the-metagame/" target="_blank">metagame</a>. The meta (i.e., higher-order factors) changes constantly. For example, <a href="https://eugeneyan.com/writing/nlp-supervised-learning-survey/" target="_blank">natural language processing</a> has evolved rapidly from recurrent models to embeddings to attention to …</p></div></details></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://eugeneyan.com/writing/beginners-mind/">https://eugeneyan.com/writing/beginners-mind/</a></em></p>]]>
            </description>
            <link>https://eugeneyan.com/writing/beginners-mind/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24277832</guid>
            <pubDate>Wed, 26 Aug 2020 00:28:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cardboard Wolfenstein 3D Telepresence Game]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24277779">thread link</a>) | @ruined
<br/>
August 25, 2020 | https://thecraftyrobot.net/blogs/projects/cardboard-wolfenstein-3d-telepresence-robot-fp-nazi-punch-game | <a href="https://web.archive.org/web/*/https://thecraftyrobot.net/blogs/projects/cardboard-wolfenstein-3d-telepresence-robot-fp-nazi-punch-game">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      
<p><span>﻿<iframe width="560" height="315" src="https://www.youtube.com/embed/tjIRY2DMgMI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></span></p>
<p>Drive a little robot around an actual cardboard&nbsp;Wolfenstein labyrinth and punch cardboard Nazis.</p>
<p><img alt="Looping video of a small robot with a smartphone with a mans face moving around a cardboard labyrinth punching cardboard Nazis " src="https://cdn.shopify.com/s/files/1/1041/4014/files/RossRampageGIF2_1024x1024.gif?v=1598349667"></p>
<p>You can play Smartistein3D during the hours listed below, in your browser at <a href="https://thecraftyrobot.github.io/smartistein3D/pilot.html?botName=sxblgrdtqnw" target="_blank" title="Smartistein3D" rel="noopener noreferrer">this link</a>. You can control the robot using either the buttons on the screen or arrow keys and space bar.</p>
<p>Tue Aug 25: 11:30 to 18:30 BST</p>
<p>Wed Aug 26: 9:30 to 18:30 BST</p>
<p>Wed Sep 2: 9:30 to 18:30 BST</p>
<p>Thur Sep 3:&nbsp;9:30 to 18:30 BST</p>
<p><img alt="Looping video showing the the robot's perspective as it drives up and punches a cardboard Nazi" src="https://cdn.shopify.com/s/files/1/1041/4014/files/PunchFPV2_1024x1024.gif?v=1598398833"></p>
<h2>Play a first person game with a robot</h2>
<p><img alt="Looping video of a cardboard robot carrying a smartphone with a man's face on it moving from side to side" src="https://cdn.shopify.com/s/files/1/1041/4014/files/Wiggle1_1024x1024.gif?v=1598350839"></p>
<p>We've created a new expansion for <a href="https://thecraftyrobot.net/" title="Meet Smartibot">Smaribot</a> that allows you to build a telepresence robot that works with your phone. It's called <a href="https://www.kickstarter.com/projects/rossatkin/smartipresence-cardboard-telepresence-robot" target="_blank" title="Smartipresence on Kickstarter" rel="noopener noreferrer">Smartipresence</a> and&nbsp;to make it all work slickly&nbsp;we've built a telepresence system.</p>
<p><img alt="Looping video. First section shows a cardboard robot carrying a smartphone driving towards a small child. Second section shows the robot's point of view with buttons at the side moving it." src="https://cdn.shopify.com/s/files/1/1041/4014/files/ChasingChild5_1024x1024.gif?v=1598350981"></p>
<p>Driving the robot around from somewhere else feels a bit like playing a first person game and made me wonder what it would be like to build an actual game around it.</p>
<p>It felt appropriate to&nbsp;go back to the&nbsp;origin of the first person shooter genre and do Wolfenstein 3D. I think many of us miss the chunky pixels and moral clarity that Nazis are bad.&nbsp;</p>
<h2>Cardboard computer game</h2>
<p><img alt="Loping video of a small robot punching a cardboard Nazi in a cardboard labrynth" src="https://cdn.shopify.com/s/files/1/1041/4014/files/PunchGif2_1024x1024.gif?v=1598351095"></p>
<p>Because&nbsp;Wolfenstein 3D had 2D sprites (enemy characters) in a 3D world I thought it would probably transfer to cardboard quite nicely. I wanted to build it all on a table which limited space a bit, meaning I wasn't going to build a robot that could shoot (probably a good decision anyway) so I settled on a compact cardboard labyrinth and a robot that could punch.</p>
<h2>Punching robot</h2>
<p><img alt="Looping video of a close up of a cardboard fist punching a cardboard Nazi" src="https://cdn.shopify.com/s/files/1/1041/4014/files/PunchCloseUp1_1024x1024.gif?v=1598351227"></p>
<p>I used to live&nbsp;around the corner from&nbsp;the <a href="https://www.theguardian.com/artanddesign/2016/sep/25/the-full-history-of-the-cable-street-mural">Cable Street mural</a>,&nbsp;which&nbsp;is a great argument for punching Nazis, so this seemed good. I&nbsp;designed a compact 3D printed Smartibot chassis that could hold a smartphone and a 9g servo to operate the punch mechanism, to which I attached a nice pixelated fist. (files on Thingiverse).</p>
<h2>A game engine on your table</h2>
<p>I got a friend who's worked for many years creating computer games&nbsp;to test this out and she said "you've made a game engine", which wasn't really something I'd considered before but it makes sense.</p>
<p>Game engines (software frameworks that handle things like in-game physics and graphics) have allowed games producers to focus on the creative aspects of game making and opened up the field to many less technical people.</p>
<p>Using a small telepresence robot (like Smartipresence) in this way&nbsp;makes game creation even easier, all you need is a table (or bit of floor) to build your environment on, some things for the player to interact with and a clear idea of how the game mechanics should work. The physical world provides your physics and graphics engine and your hands handle the game mechanics.</p>
<p>I think this could be a <strong>really fun</strong> way for kids to interact with their loved ones remotely.</p>
<p><img alt="Looping video of a small purple circuit board with a smiling face on it connected to 14 motors all of which are moving back and fourth" src="https://cdn.shopify.com/s/files/1/1041/4014/files/AllTheMotors_1024x1024.gif?v=1598352223"></p>
<p>The robot I&nbsp;built to play Smartistein3D uses only three motors (the two that come in the Smartibot kit to drive the wheels and move it around plus the little servo for the punch) but because Smartibot is so flexible (and can control up to 14 motors) you could build more complicated robots for more complicated game mechanics (you could use almost any of the robots in the projects section as the character). Plus, if you've got&nbsp;strong enough internet, there's no reason not to have multiple players controlling multiple robots. ALSO, you could probably use <a href="https://thecraftyrobot.net/blogs/projects/simple-programming-with-the-a-i-getting-your-smartibot-to-run-away-from-people-but-still-chase-other-things" title="Smartibot A.I. programming">Smartibot's A.I.</a> mode to create enemies that move around and respond to the player characters automatically ... I&nbsp;doubt&nbsp;this&nbsp;will the last game I'll make with Smartipresence.</p>


    </div></div>]]>
            </description>
            <link>https://thecraftyrobot.net/blogs/projects/cardboard-wolfenstein-3d-telepresence-robot-fp-nazi-punch-game</link>
            <guid isPermaLink="false">hacker-news-small-sites-24277779</guid>
            <pubDate>Wed, 26 Aug 2020 00:17:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You're not landing job interviews thanks to new technologies]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24277713">thread link</a>) | @hollaur
<br/>
August 25, 2020 | https://www.thevectorimpact.com/how-to-apply-for-jobs-online/ | <a href="https://web.archive.org/web/*/https://www.thevectorimpact.com/how-to-apply-for-jobs-online/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

						
						<article id="post-2564">

							
							<section itemprop="articleBody">

								
<span itemprop="reviewBody"><p><i><span><img title="how to apply for jobs online 2020 meme" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-meme.jpg" alt="meme: &quot;When does season 2 of 2020 start? I do not like season 1.&quot;" width="1200" height="1200" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-meme.jpg 1200w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-meme-300x300.jpg 300w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-meme-1024x1024.jpg 1024w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-meme-150x150.jpg 150w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-meme-768x768.jpg 768w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-meme-125x125.jpg 125w" sizes="(max-width: 1200px) 100vw, 1200px">Can I get an Amen?</span></i></p>
<p>Whether you’re lucky enough to be employed or currently out of work, it’s no secret that <strong>landing a job in 2020 is harder than ever before.</strong></p>
<p><span>And while it’s easy to blame coronavirus and wallow in our job-seeker sorrow—and believe me, I’m not ignoring the very real challenges of our current economy—my research suggests there’s more to it than that.</span></p>
<p><span>A friend of mine had been applying to jobs prior to the pandemic, and he hadn’t landed a single interview.&nbsp;</span></p>
<p><span>I thought I’d have the solution to his problem in all of five minutes (I used to be </span>p<span>retty good at applying for jobs online</span><span>), but it turns out he was already doing everything </span><i><span>“right.”</span></i><span>&nbsp;</span></p>
<p><span>His resume listed quantified bullet point after quantified bullet point. The formatting looked good. He tailored his cover letters to the position descriptions. His online presence is superb; he owns the front page of Google results for his name. And LinkedIn rated his profile as an “All-Star.” Oh yeah, he’s also gainfully employed.</span></p>
<p><span>You might be thinking, “Well, if he applied through job boards, that’s his first problem.”&nbsp;</span></p>
<p><span>And I’m thinking, “He used to apply through job boards and land interviews more than 60 percent of the time just a few years ago, so what’s changed?”&nbsp;</span></p>
<p><span>Turns out, A LOT. And I would’ve never known if it wasn’t for my friend stumping me with his seemingly simple quandary. I’m flabbergasted by how out of touch I was with the modern job hunt, which is why I couldn’t </span><b>not</b><span> write this post.&nbsp;</span></p>
<p><strong>With the average job tenure lasting just one year on average, it’s extremely likely you’ll need to understand <i>why</i> in the near future.&nbsp;</strong></p>
<p><span>I wrote this post to demystify the modern recruiting process and help qualified candidates figure out how to apply for jobs online. So if you’re ready to make it past the initial resume screening process and score an interview—and ultimately land the opportunity you deserve—then keep reading.</span></p>

<h2><span id="Why_is_landing_a_job_so_hard"></span><span>Why is landing a job so hard?</span><span></span></h2>
<p><span><img title="how to apply for jobs online landing a job is hard" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-landing-a-job-is-hard.jpg" alt="" width="1200" height="600" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-landing-a-job-is-hard.jpg 1200w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-landing-a-job-is-hard-300x150.jpg 300w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-landing-a-job-is-hard-1024x512.jpg 1024w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-landing-a-job-is-hard-768x384.jpg 768w" sizes="(max-width: 1200px) 100vw, 1200px">Yes, we’re in the midst of a <a href="https://www.npr.org/series/812054919/the-coronavirus-crisis">global pandemic</a> and <a href="https://fortune.com/2020/07/12/how-is-us-economy-doing-2020-recession-unemployment-rate-benefits-consumer-spending-job-losses-state-by-state-pmi-coronavirus-pandemic/">record unemployment</a>, and that undoubtedly makes the job market more competitive than ever.&nbsp;</span></p>
<p><span>Yet, even prior to the world turning upside down, the lamest of job ads received an insane amount of applications. The consensus seems to be about </span><a href="http://www.inc.com/peter-economy/19-interesting-hiring-statistics-you-should-know.html"><span>250 applications per job listing</span></a><span>, on average.&nbsp;</span></p>
<p><span><img title="how to apply for jobs online job applications 02" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-job-applications-02.png" alt="Breaking down job applications infographic. Out of 250 applications, 4-6 will be interviewed, and only 1 will receive an offer." width="2084" height="1244" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-job-applications-02.png 2084w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-job-applications-02-300x179.png 300w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-job-applications-02-1024x611.png 1024w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-job-applications-02-768x458.png 768w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-job-applications-02-1536x917.png 1536w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-job-applications-02-2048x1223.png 2048w" sizes="(max-width: 2084px) 100vw, 2084px">Of course, super-competitive positions get a lot more… supposedly anyway.&nbsp;</span></p>
<p><span><a href="https://twitter.com/jasonfried/status/1147166154089213953"><img title="how to apply for jobs online jason fried tweet" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-jason-fried-tweet.jpg" alt="tweet by Jason Fried: &quot;Out of everyone who applied for the Basecamp Head of Marketing job, only one person used an ad on LinkedIn to get an extra ounce of notice.&quot;" width="1000" height="802" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-jason-fried-tweet.jpg 1000w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-jason-fried-tweet-300x241.jpg 300w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-jason-fried-tweet-768x616.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></a>And you know what they say… </span><b>ain’t no recruiter got time for that.</b></p>



<p><strong>But seriously, <i>they don’t</i></strong><span>—not in a metrics-driven world, where companies are obsessed with automating everything to do things as fast as possible, even at the cost of quality.&nbsp;</span></p>

<h3><span id="Applicant_Tracking_Systems_What_you_need_to_know"></span><span>Applicant Tracking Systems: What you need to know</span><span></span></h3>
<p><span><img title="how to apply for jobs online applicant tracking systems" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-applicant-tracking-systems.jpg" alt="" width="1000" height="667" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-applicant-tracking-systems.jpg 1000w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-applicant-tracking-systems-300x200.jpg 300w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-applicant-tracking-systems-768x512.jpg 768w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-applicant-tracking-systems-360x240.jpg 360w" sizes="(max-width: 1000px) 100vw, 1000px">Enter the </span><span><a href="https://www.reportsanddata.com/report-detail/applicant-tracking-system-ats-market">$1.3 billion recruiting technology/software industry</a>.&nbsp;</span></p>
<p><span>While there are a variety of modern recruitment tools for each stage of the hiring process, the one that will affect you the most is the </span><a href="https://fairygodboss.com/career-topics/applicant-tracking-systems"><span>Applicant Tracking System (ATS)</span></a><span>.&nbsp;</span></p>
<p><span><img title="how to apply for jobs online 2020 applicant tracking system process 02" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-applicant-tracking-system-process-02.png" alt="Applicant tracking system process" width="2085" height="3088" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-applicant-tracking-system-process-02.png 2085w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-applicant-tracking-system-process-02-203x300.png 203w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-applicant-tracking-system-process-02-691x1024.png 691w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-applicant-tracking-system-process-02-768x1137.png 768w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-applicant-tracking-system-process-02-1037x1536.png 1037w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-applicant-tracking-system-process-02-1383x2048.png 1383w" sizes="(max-width: 2085px) 100vw, 2085px">It’s pretty much guaranteed that your application is going through an ATS any time you apply for a job online, since at least </span><a href="https://www.jobscan.co/blog/fortune-500-use-applicant-tracking-systems/"><span>98 percent of Fortune 500 companies use one</span></a><span>.&nbsp;</span></p>
<p><span>TLDR: ATS help recruiters/hiring managers collect, sort, and organize a large number of applications.&nbsp;</span></p>

<h4><span>Most Common ATS Features</span></h4>
<p><span>Rather than manually reviewing each resume, recruiters and hiring managers search for resumes based on keywords, or have the system filter or automatically rank applicants.&nbsp;</span></p>
<p><span>In many cases, recruiters use the technology to do a first pass of resumes, meaning you can be removed from consideration </span><b>by an algorithm without ever being reviewed by a human</b><span>.&nbsp;</span></p>
<p><span><img title="how to apply for jobs online what happens to your resume ats 02" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-what-happens-to-your-resume-ats-02.png" alt="Infographic: What happens to your resume in an applicant tracking system" width="2501" height="10553" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-what-happens-to-your-resume-ats-02.png 2501w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-what-happens-to-your-resume-ats-02-71x300.png 71w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-what-happens-to-your-resume-ats-02-243x1024.png 243w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-what-happens-to-your-resume-ats-02-768x3241.png 768w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-what-happens-to-your-resume-ats-02-364x1536.png 364w" sizes="(max-width: 2501px) 100vw, 2501px">While there </span><a href="https://blog.ongig.com/applicant-tracking-system/top-ats-systems-used-by-the-fortune-500-2019"><span>hundreds of ATS on the market</span></a><span>, most of them list the same features. Understanding them is key to landing an interview. Here are the big ones that will determine whether a human ever sees your resume.</span></p>

<h5><span>Automatic Applicant Ranking/Scoring</span></h5>
<p><span>Many ATS provide an automatic “match rank” or score for each applicant.&nbsp;</span><span><a href="https://www.jobscore.com/features/submit-resume/"><img title="how to apply for jobs online ats ranking scoring" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring.jpg" alt="candidate match score example on Job Score website" width="982" height="400" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring.jpg 982w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring-300x122.jpg 300w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring-768x313.jpg 768w" sizes="(max-width: 982px) 100vw, 982px"></a>The system will take and parse the information from your resume, and compare it with the job description, looking for specific keywords, then provide a score from 0 to 100, or one to 10, that tells recruiters how qualified a candidate is for said job, based on the criteria set by the hiring manager.&nbsp;</span></p>
<p><span><a href="https://www.jobscore.com/features/submit-resume/"><img title="how to apply for jobs online ats ranking scoring 02" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring-02.jpg" alt="ATS extracts contact info, employment and education history from resumes" width="1000" height="420" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring-02.jpg 1000w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring-02-300x126.jpg 300w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring-02-768x323.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></a>They’ll also score you based on the answers you submit via the online form, aka “knockout questions.”&nbsp;</span></p>
<p><span><a href="https://www.jobscore.com/features/submit-resume/"><img title="how to apply for jobs online ats ranking scoring 03" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring-03.jpg" alt="Job Score website, qualifying questions" width="1000" height="763" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring-03.jpg 1000w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring-03-300x229.jpg 300w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring-03-768x586.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></a></span></p>
<p><span>For example, job posts that ask for your location are likely using that information as a filter that will alter your overall qualification score.&nbsp;</span></p>

<h5><span>Comprehensive Candidate Profiles</span></h5>
<p><span>Many ATS will automatically create a comprehensive, wildly detailed profile of you based on your digital footprint and other “public” information. All they need is your email address to populate every piece of available content about you online.&nbsp;</span></p>
<p><span>According to </span><a href="https://resources.workable.com/tutorial/important-applicant-tracking-system-features"><span>Workable</span></a><span>, aggregating candidates’ public information is a way to “humanize” the process, and they list it as a must-have feature for today’s ATS. Here’s how they describe it:</span></p>
<p><i><span>“I want to see faces dammit. And tweets. And maybe other stuff that humanizes this record.”</span></i></p>
<p><span>(In my opinion, that’s just a recipe for complete and total bias, as we know </span><a href="https://www.crowdstaffing.com/blog/hidden-bias-that-affect-the-hiring-process"><span>there’s A LOT of it in recruiting</span></a><span>, even if it’s subconscious.)&nbsp;</span></p>
<p><span>Many <a href="https://www.entelo.com/products/platform/search/">recruitment tools</a> even go so far as to make predictions about candidates based on the information they surface about them online.&nbsp;</span></p>
<p><a href="https://www.entelo.com/products/platform/search/"><span><img title="how to apply for jobs online ats candidate profiles" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-candidate-profiles.png" alt="Profile of senior product designer at Acme and predictions about his performance, fit, and longevity." width="1010" height="958" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-candidate-profiles.png 1010w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-candidate-profiles-300x285.png 300w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-candidate-profiles-768x728.png 768w" sizes="(max-width: 1010px) 100vw, 1010px"></span></a></p>
<p><span>In </span><a href="https://recruitingtools.com/boolean-strings-network/"><span>one of the first posts I read by a recruiter</span></a><span> on this topic, she tells hiring managers to search data enrichment tools/databases, like Pipl, Jigsaw and Zoominfo.&nbsp;</span></p>
<p><span>Pipl’s main use case is for “investigations.”&nbsp;</span></p>
<p><i><span>“</span></i><a href="https://pipl.com/investigation-and-research"><i><span>Pipl’s identity resolution engine</span></i></a><i><span> cross-references global data from the Internet, public records, listings, directories, archives and exclusive sources to show the connections between people and the world.”</span></i></p>
<p><span>ZoomInfo is more for B2B data enrichment. Check out the screenshot below to see how they collect your information.&nbsp;</span></p>
<p><span><a href="https://www.zoominfo.com/business/our-data?utm_campaign=branded"><img title="how to apply for jobs online candidate profiles zoominfo 02" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-candidate-profiles-zoominfo-02.jpg" alt="ZoomInfo" width="1000" height="899" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-candidate-profiles-zoominfo-02.jpg 1000w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-candidate-profiles-zoominfo-02-300x270.jpg 300w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-candidate-profiles-zoominfo-02-768x690.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></a>Pretty scary, huh?&nbsp;</span></p>

<h5><span>Resume Parsing</span></h5>
<p><span>This is sort-of a feature of the “Automatic Applicant Ranking/Score” section, but it’s also important to mention on its own.&nbsp;</span></p>
<p><span>Resume parsing refers to how ATS extracts and organizes your resume into “structured data,” so they can do stuff like rank/score you automatically.&nbsp;</span></p>
<p><span>This means that many times submitting a PDF, or using creative typography, will hurt you, because the ATS can’t read the data well, if at all.&nbsp;</span></p>

<h5><span>Resume Storage</span></h5>
<p><span>Even if you’re rejected for a position, the ATS will store your resume in its system, because every time there’s a new role to fill, they’ll start with searching their databases to see who might be a match, which leads me to the next feature.&nbsp;</span></p>

<h5><span>Search and Filters</span></h5>
<p><span>ATS allows hiring managers to search by any keyword, and often with </span><a href="https://recruitingtools.com/boolean-strings-network/"><span>Boolean search</span></a><span>, which connects keywords using AND, OR, NOT and NEAR.</span></p>
<p><span>Some tools will even let you filter by those it labels “not job hoppers,” etc.&nbsp;</span></p>
<p><span>Filters may include the job seeker’s location, application source, age of your profile, and whether or not you’re an employee referral.&nbsp;</span></p>

<h4><span>Recruiters’ dirty little secrets&nbsp;</span></h4>
<h5><span>Backchanneling / Backdoor references</span></h5>
<p><span>If the recruiter actually sees your resume and is interested in interviewing you, she’ll likely visit your LinkedIn profile to make sure everything checks out.&nbsp;</span></p>
<p><span>She may even message any mutual connections you have to see what they’ll say about you. This is illegal but it happens all the time from </span><a href="https://www.glassdoor.com/blog/8-secrets-recruiters-wont-tell-you/"><span>what I read</span></a><span>.</span></p>
<p><i><span>“This phenomenon is even more prevalent in the last five years or so because of LinkedIn’s growing popularity. Even if you choose not to give anybody there as a reference, backdoor references can reveal the skeletons in your closet. Backdoor references can be especially common when you’re looking for a job in sectors like tech.”</span></i></p>

<h5><span>Cyberstalking</span></h5>
<p><span>Another potentially discriminatory and sometimes illegal practice includes cyberstalking you.&nbsp;</span></p>
<p><i><span>“A lot of recruiters—most that I know—will Google candidates who make it pretty far [in the hiring process], and then use Google image results, and also blog posts, tweets, and open Facebook accounts to judge someone’s character and credibility.” (</span></i><a href="https://www.fastcompany.com/40441093/former-recruiters-reveal-the-industrys-dark-secrets-that-cost-you-job-offers"><i><span>Source</span></i></a><i><span>)</span></i></p>

<h5><span>[Subconscious] Bias</span></h5>
<p><span>Whether it’s subconscious or downright discriminatory, hiring managers usually have a </span><a href="https://www.fastcompany.com/40441093/former-recruiters-reveal-the-industrys-dark-secrets-that-cost-you-job-offers"><span>preconceived picture</span></a><span> of what the perfect candidate looks like, which often is based on stereotypes.</span></p>

<p><b>Bias 1: Being overweight</b></p>
<p><span>Weight bias is still especially prevalent, according to one recruiter, who says being overweight can make people think the person is lazy or lacks motivation.</span></p>

<p><b>Bias 2: “Diversity”</b></p>
<p><span>“Diversity in Silicon Valley’s mind is the picture of Phylicia Rashad,” (the actress who portrayed Clair Huxtable on The Cosby Show), said another recruiter </span><a href="https://www.fastcompany.com/40441093/former-recruiters-reveal-the-industrys-dark-secrets-that-cost-you-job-offers"><span>via the same article</span></a><span>.&nbsp;</span></p>
<p><span>According to the post, she sees African-American women considered more readily for roles as diversity/inclusion chiefs, while white men more often lead the pack to head up sales teams.</span></p>
<p><span>Another recruiter bolsters her experience:&nbsp;</span></p>
<p><i><span>“There’s a penchant to see more diversity, but the definition is narrow,” typically reduced to race and gender; it was common to tout a candidate for being a “visible minority.” “It’s the only way to highlight that for the client on a call,” he explains, since “we can’t put it in our documentation.”</span></i></p>

<p><b>Bias 3: Looking “too young”&nbsp;&nbsp;</b></p>
<p><span>The same recruiter from above said he also sees a lot of ageism in the hiring process.&nbsp;</span></p>
<p><span>For example, there’s kind-of a sweet spot in terms of age for C-level positions, he said.&nbsp;</span></p>
<p><span>“My boss would say things like, ‘Did they have enough gray hair?’—not literally, but are they seasoned enough, do they have enough experience where they could be credible?”&nbsp;</span></p>
<p><span>There were occasions when recruiters would nominate younger, well-qualified candidates for senior leadership roles, Mark recalls, but “I’d say 20% of the time they’re open to meeting with that person.”</span></p>

<p><b>Bias 4: Expensive degrees</b></p>
<p><span>At the beginning of the recruitment process, recruiters are dealing with so many resumes that they use a prestigious degree as a quick way to filter down the candidate pool.&nbsp;</span></p>
<p><span>According to a recruiter from that FastCompany article I mentioned …</span></p></span></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thevectorimpact.com/how-to-apply-for-jobs-online/">https://www.thevectorimpact.com/how-to-apply-for-jobs-online/</a></em></p>]]>
            </description>
            <link>https://www.thevectorimpact.com/how-to-apply-for-jobs-online/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24277713</guid>
            <pubDate>Wed, 26 Aug 2020 00:06:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What's it like as a Senior Engineer?]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24277414">thread link</a>) | @benkwokcy
<br/>
August 25, 2020 | https://www.zainrizvi.io/blog/whats-it-like-as-a-senior-engineer/ | <a href="https://web.archive.org/web/*/https://www.zainrizvi.io/blog/whats-it-like-as-a-senior-engineer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<!-- .cover -->


				<div>
					<p>When I started working at Microsoft, fresh out of college, coding was my life. Writing code was the easiest way to build any cool thing that my brain could imagine. &nbsp;When I thought about what I’d want to do for the rest of my life I thought that I just wanted to keep coding. </p><p>During the next 11 years I became a Senior Engineer at Microsoft and moved on to work at Google and later Stripe. At these higher levels I still get to build, but I use a very different set of tools to do it. There’s a huge mindset shift needed when you go from junior to senior. Writing code becomes a minor part of the job. </p><p>Ever built a tool no one used? I have. It sucked. At the senior levels most of your time goes into identifying <strong>what </strong>needs to be built and <strong>how </strong>to build it. You have to research what the problem looks like. You talk to others and get everyone to agree on what needs to be done. </p><p>These are your new tools:</p><ul><li>Research the problem</li><li>Design the solution</li><li>Build consensus</li></ul><h2 id="research-like-a-detective">Research like a Detective</h2><p>Fresh out of college you get handed tasks where the right answer is pretty straightforward. There isn’t much disagreement on what to do other than the occasional feedback in code reviews.</p><p>As you get more experienced your problems become more ambiguous. The path looks hazy. There are multiple routes you could take, but each one hides its own dragons. It’s not about coding anymore. Most of your work goes into research, and you can’t google the answer.</p><p>Research can take many forms. It usually involves a combination of reading code, reading documentation, and talking to people. Yes, actual human beings. In fact, that’s where most of the information you’ll need is locked away. Did you ever see Sherlock Holmes using search engines? </p><figure><img src="https://lh3.googleusercontent.com/8zyhAq2HSKAYAzysnJfbR_m6ZCBloCL5jbUmlwLEnJnmErsiHzd6gOEPtMpJZIp961AlNxUrdloY4B3cFFpVca5iH7Xb3wJgj0rFG7TLO60IGey4TaOJGZITimTXGv7U9hXqh-Pp" alt=""></figure><p>There often is no single person who knows the answer you need. Five different people might hold five different pieces of the puzzle you’re assembling. And you don’t know who those five people are. And they don’t know which pieces you need.</p><p><em>You </em>have to find them. Find them and ask the right questions to sift through their brains, uncovering the nuggets you need.</p><h6 id="sifting-for-nuggets">Sifting for nuggets</h6><p>At Google Cloud Platform, customers would often contact the Technical Solutions Engineers for help when they ran into issues. Those TSEs dug into the problems and fixed them. </p><p>My manager had an idea: “Wouldn’t it be great if we could use AI to automate that process?” We had no clue how to do it. Didn’t even know if it was possible. Heck, we weren’t even sure what kind of problems customers were asking for help with. But that was the challenge my manager offered.</p><p>I accepted.</p><p>Now any AI solution for this kind of a problem requires lots of data. The AI needs to see many broken environments to understand what they look like. And as I searched around I realized we didn’t have that data, it was all locked away in the brains of those TSEs. You can’t train AI with that. </p><p>I had to find the patterns. Maybe chatting with the TSEs would reveal something...</p><p>Me: “So, what type of problem do you usually face?”</p><p>TSE: “Eh, it’s something different every time”</p><p>Darn it, The AI future was looking bleak. </p><p>Me: “Well, what do you do to solve it?”</p><p>TSE: “It depends. Based on the problem, we’ll query one database or another. Then that’ll point us somewhere else, and we keep digging until we find what’s wrong. Then we fix it.”</p><p>No solid data on what problems they solve. No repeatable way to fix them. I was ready to give up.</p><p>Wait a second.</p><p>“Tell me more about these queries you run?”</p><p>What if I changed the problem? Maybe I didn’t have to fix those customer issues right off the bat. What if I helped TSEs debug the problems faster? I could automatically run the hundreds of queries they might run and suggest “Hey, this one had a suspicious result. Maybe dig a bit deeper there?” That’s a lot of debugging the TSEs could avoid.</p><p>I could even extend this to collect the data needed for an actual an AI system. This had potential! The TSEs were excited. My team was excited. My manager was excited. We began coding.</p><h2 id="design-the-art-of-balance">Design: The Art of Balance</h2><p>With ambiguous problems there is no single right answer anymore. There might not be any answer. What you have is a pain point. It could be your customers’s pains, your team’s pains, or even your own pain. The existence of that pain is the problem. Your job is to remove that pain without introducing even greater pains.</p><p>There’s a funny thing about ambiguous problems: they don’t have a clear right answer. Every solution offers certain benefits and has certain downsides. The more of those you discover, the better you’ll be at balancing the tradeoffs you have to make. Some common trade offs to consider:</p><ul><li>How long will it take to develop the solution?</li><li>What’s the opportunity cost?</li><li>How risky is it? What happens if that thing fails?</li><li>How much work will it be to maintain this going forwards?</li><li>How far will it scale? How far does it need to?</li></ul><p>With these ambiguous problems, sometimes the best answer can be “keep doing the thing we’ve been doing.” That was a tough lesson to learn. </p><h6 id="young-and-naive">Young and Naive</h6><p>When I was a wee lad four years out of college, I had been asked to come up with a way to make our database upgrades less risky. The team would manually review all the planned changes to make sure they were safe, but once in a while a bug would slip though and the sound of pagers going off would fill the room as everyone frantically tried to fix it.</p><p>“Can we build a tool to catch those risky changes?” my manager asked me. Woah, this was a super open ended problem. Sweet! I was determined to not let him down. This required digging deep into database upgrade best practices (I even read a whole <a href="https://martinfowler.com/books/refactoringDatabases.html">book on it</a> cover to cover). I spent the winter holidays toiling away developing a prototype that could do upgrades safely. And it worked! Kinda.</p><p>When I showed my creation to my manager he was worried: “You know what, let’s just stick with doing things the way we do right now.” </p><p>Ouch. </p><p>It was a tough lesson on risk management, but he made the right call. A bug in my tool could have brought our entire service down. It wasn’t worth the risk.</p><figure><img src="https://lh6.googleusercontent.com/-SpPwF1sWOPZD0HnYx0IqqluusAVritix1g7_NToe3s93jEmkPTsYhCTHJdPh7axMdLIN6gZ0fJ1_01AiPDputH2wPnMBXTDmgfxYIFAicsQeyAlq8Y9fRTxBFljmx9FZYi1Pdcy" alt=""></figure><p>There were multiple lessons I learned that day:</p><ul><li>Consider how much risk any new project might add to the system</li><li>It’s okay to fail. If you never fail then you’re not stretching yourself</li><li>Get feedback early! </li></ul><p>To get that feedback communication is crucial. Tell people what you’re going to build before you build it and let them warn you about any pitfalls before you step into one. If I had shared that design with my manager before building it we would have cancelled the project weeks earlier. And I would have had a relaxing winter break.</p><p>But collecting feedback requires a soft skill: empathy.<strong> </strong>Can you understand why people disagree with you? What are they valuing differently?</p><p>You may not always agree with the feedback, but you have to understand it. Only then can you move forward with a new vision that everyone can get behind.</p><h2 id="build-consensus">Build Consensus</h2><p>Getting that feedback and agreeing on the plan grows more important as your projects get bigger.</p><p>You may start off just having to get your manager to agree (he’s the one who gave you that ambiguous task). But you’ll need to build consensus with the rest of your team and even people outside your team who have a stake in your work. </p><p>This requires communication skills, both to understand and be understood.</p><p>Once I was tasked with creating the next generation of our internal database management system. This was something many teams depended on, and our current solution would stop scaling a year or two down the line. My team had seven different people with eight different opinions about what the system should look like. That included my manager and skip level. Oy vey. </p><p>First step was talking to them all to really understand their concerns and priorities. But there was another voice I wanted to hear from: our customers! This was meant to be a system for other engineering teams, how could I build a solution for them without understanding their problems? &nbsp;It took a bit of digging to even figure out who those users were. This required another soft skill: The art of finding the person you need to talk to.</p><p>Eventually I got into a room with them. There they dropped the bombshell “We can’t really justify the work to migrate to any new system. The current one works well enough for us right now and we have more urgent problems to fix.” I talked to three different teams and got the same answer each time. Damn, what’s the point of building a solution if no one will use it?</p><p>A migration had to happen, soon the current system would stop meeting our reliability standards. There were a couple routes forwards:</p><ul><li><em>Politics</em>: Get my management chain to convince their management chain to force the teams to migrate. Yuck</li><li><em>Persuasion</em>: Teach those teams why this pain that they won’t feel for a few years is more important to fix than the pains they’re facing today. That’s a hard thing to prove, and we’d have to make this case to many, many teams. That doesn’t scale well</li></ul><p>There was a third option: change the constraints. What if I said ‘no’ to some of the features I’d been asked to add? Removing that let me design the system in a way that we could migrate all our customers automatically. There would be zero work required from them to migrate. We’d swap the engine with the car still zooming down the highway.</p><p>This was much more palatable. And by highlighting our user’s push back I convinced the other stakeholders to change drop those constraints as well.</p><figure><img src="https://lh5.googleusercontent.com/uQ8pUq_dwFP6BBDO1d66HKZNGs5DrxtbLCoKc0NxnrsvpHOlh_C_Pi9yUcoU7XLi9TiYkRKy_4QItN3s3pWBVlNCfm2MZYyECTrdEHaJsQVTVxqmV4GPVzEFXJaRxpS5wqloltjj" alt=""></figure><p>That’s the general flow of any project you work on at the senior levels: You research the problem, gather the pieces, understand the world better. You design a solution, collect feedback and adjust course as needed. Then the implementation begins.</p><p>So how do you learn all these skills? Experience. Jump out of the nest and flap your wings. If an opportunity shows up, take it. You won’t feel ready, no one does, but that’s what makes it a learning experience.</p><p>Ask for help. Listen to the answers you get. Keep trying. At the end of the project ask for …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.zainrizvi.io/blog/whats-it-like-as-a-senior-engineer/">https://www.zainrizvi.io/blog/whats-it-like-as-a-senior-engineer/</a></em></p>]]>
            </description>
            <link>https://www.zainrizvi.io/blog/whats-it-like-as-a-senior-engineer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24277414</guid>
            <pubDate>Tue, 25 Aug 2020 23:20:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A programming language to make concurrent programs easy to write]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24277289">thread link</a>) | @pombo
<br/>
August 25, 2020 | https://alan-lang.org/why_alan.html | <a href="https://web.archive.org/web/*/https://alan-lang.org/why_alan.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<!-- Provide site root to javascript -->


<!-- Work around some values being stored in localStorage wrapped in quotes -->


<!-- Hide / unhide sidebar before it is displayed -->


<!-- Old school interval to adjust the carousel status if a carousel is present on this page -->


<nav id="sidebar" aria-label="Table of contents">
  
  
</nav>

<div id="page-wrapper">

    <div class="page">
      
      
        
        
          
        

        <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
        
        <div id="content">
            <main>
                
<p><strong>14 August 2020 | David Ellis, Luis F. De Pombo</strong></p>
<p>We created a programming language to be able to write concurrent algorithms and business logic without having to explicitly program how it should be parallelized. Alan makes people more productive by managing IO and computational parallelism for them in the same way languages from the 90s like Java and Python made people more productive, when compared to C or C++, by managing memory for them.</p>
<p>Why the name? Alan is named in honor of Alan Turing. We find great inspiration in the magnitude of his intellectual contributions.</p>
<h4><a href="#implicit-parallelization-over-arrays-events-and-io" id="implicit-parallelization-over-arrays-events-and-io">Implicit parallelization over arrays, events and IO</a></h4>
<p>Alan is <a href="https://alan-lang.org/alan_overview.html#implicitly-parallel">implicitly parallel</a> because its compiler and runtime exploits opportunities for parallelization across the computing resources available without being told to do so. We have <a href="https://alan-lang.org/alan_overview.html#parallel-computation-and-the-problem-of-turing-completeness">constrained the language a bit</a> to provide better opportunities to do this. This results in nimbler codebases than those built with languages or frameworks that use parallel programming constructs such as threads, actors, channels, locks, futures, promises etc.</p>
<h4><a href="#no-race-conditions-and-fewer-runtime-errors" id="no-race-conditions-and-fewer-runtime-errors">No race conditions and fewer runtime errors</a></h4>
<p>Deadlocks, livelocks, undefined variables, divide-by-zero, integer under/overflow, array out-of-bounds access, etc, are not possible in Alan. Only out-of-memory errors persist, but they are impossible to avoid. This makes Alan codebases easier to maintain and develop in because <a href="https://alan-lang.org/alan_overview.html#statically-compiled-benefits-and-compile-time-safety">runtime errors are nearly always caught at compile time</a>.</p>
<h4><a href="#granular-third-party-permissions" id="granular-third-party-permissions">Granular third party permissions</a></h4>
<p>Alan's module resolution mechanism, with mocking built-in, allows you to <a href="https://alan-lang.org/alan_overview.html#third-party-module-permission-system">prevent specific third-party dependencies from having access to  specific standard libraries</a> that they should not have access to.</p>
<h4><a href="#no-gc-pauses" id="no-gc-pauses">No GC pauses</a></h4>
<p>Alan’s runtime manages memory allocation, access, and deallocation for you like Java, Python, or Javascript. However, Alan’s static event system and <a href="https://alan-lang.org/alan_overview.html#memory-management">automatic event-oriented memory model</a> does so without garbage collector pauses.</p>
<h4><a href="#join-us" id="join-us">Join Us</a></h4>
<p>There is still a ways to go for Alan to become a worthy abstraction to automatically parallelize software, but if you are moved by the vision please try it out, give us your feedback and help us shape it.</p>

            </main>

            <nav aria-label="Page navigation">
              <!-- Mobile navigation buttons -->
              
                <a rel="prev" href="https://alan-lang.org/blog.html" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                  <i></i>
                </a>
              

              
                <a rel="next" href="https://alan-lang.org/alan_overview.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                  <i></i>
                </a>
              

              
            </nav>
        </div>
    </div>

</div>






<!-- Analytics Tag -->



    



    



    
    
    
    
    


<!-- BigInt is not defined in Safari. Define it before loading bundle.js -->

<!-- Custom JS scripts -->

    

    

    







</div>]]>
            </description>
            <link>https://alan-lang.org/why_alan.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24277289</guid>
            <pubDate>Tue, 25 Aug 2020 23:04:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mural Raises $118M Series B to expand remote collaboration]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24277265">thread link</a>) | @sebikul
<br/>
August 25, 2020 | https://www.mural.co/press-releases/series-b | <a href="https://web.archive.org/web/*/https://www.mural.co/press-releases/series-b">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>Enterprise teams worldwide turn to MURAL to innovate through visual thinking and remote collaboration, driving growth of more than a million monthly active users in Q2 alone and 3x revenue year over year.</em></p><div><p>SAN FRANCISCO, CA — AUGUST 25, 2020 — <a href="http://www.mural.co/">MURAL</a>, the leading digital workspace for visual collaboration in the enterprise, has closed $118 million in Series B funding, led by Insight Partners and joined by Tiger Global, Slack Fund, World Innovation Lab, and existing investor Gradient Ventures. Numerous other investors participated in the funding, including Ryan Smith, CEO and co-founder of Qualtrics; Bill Veghte, CEO of AthenePartners, former Microsoft SVP and former HP COO; and Allison Pickens, former COO of Gainsight. Jeff Lieberman, managing director at Insight Partners, has joined MURAL’s Board of Directors and Insight Partners managing director, Nikhil Sachdev, has joined the Board as an observer.</p><p>“MURAL has repeatedly supported massive implementations and met the exacting specifications of global enterprises,” said Jeff Lieberman of Insight Partners. “The company has shifted from a startup to a scaleup, not only growing revenue through rapid expansion within Fortune 500 companies, but also onboarding new enterprise customers and consulting partners at high velocity. Insight Partners looks forward to helping to accelerate market adoption of MURAL to support the future of team collaboration.”</p><p>Enterprise teams and consulting leaders use MURAL to generate common understanding and solve problems through visual collaboration. More than an online whiteboard, MURAL enables innovation at scale. It is a digital workspace for product strategy and planning, research and design collaboration, facilitated workshops that use agile and design thinking methodologies, and sales and consulting engagements. MURAL integrates with Slack, Microsoft Teams, Dropbox, JIRA, Google Drive, and GitHub, among other platforms.</p><p>The Series B capital will enable MURAL to expand adoption to new types of teams and use cases within enterprises; extend its go-to-market operations globally; accelerate development of new enterprise-ready features; and deepen its community engagement initiatives that support facilitators, design thinkers, and agile experts as they advance the way teams work together.</p><p>“Slack Fund invests in companies that are reinventing the future of work, especially those addressing the unique challenges presented by distributed teams,” said Jason Spinell, director, Slack Fund. “As the system of record for visual productivity, MURAL gives teams the ability to develop ideas in real-time to enhance innovation and collaboration at enterprise scale. We have seen that when integrated with the Slack platform, MURAL’s solution transforms how distributed teams interact and imagine together to get work done.”</p><p>“Imagination at work is key to innovation. The visual methods made popular to collaborate on ideas are here to guide us,” said Mariano Suarez-Battan, MURAL’s co-founder and CEO. “Early adopters in some of the largest organizations in the world realized that they don't need to be in the same room to turn imagination into innovation through visual collaboration. They now feel comfortable doing product strategy, improving processes, and engaging customers remotely. Today, everybody else is rushing to develop this level of remote work fluency. With this funding and the expansion of our team, we are ready to support teams all over the world in their journey."</p><p>MURAL has tripled annual revenue year over year, doubled headcount, and added more than a million monthly active users around the world so far this year. Enterprises such as IBM, Autodesk, Intuit, GitHub, and Atlassian each have up to tens of thousands of MURAL members collaborating with the product each month.</p><p>Learn more about MURAL and try it free for 30 days by visiting <a href="http://www.mural.co/">www.mural.co</a>. In addition, MURAL is offered free for <a href="https://www.mural.co/education">classroom use</a> as well as to consultants through the <a href="https://www.mural.co/consultants">MURAL Consultant Network</a>.<strong>‍</strong></p></div><p>‍</p><p><strong>ABOUT MURAL</strong></p><p><strong>‍</strong>MURAL is the leading digital workspace for visual collaboration in the enterprise. Teams depend on MURAL to understand and solve problems and build consensus using visual methods. More than an online whiteboard, MURAL enables innovation at scale by providing a platform for everything from product strategy and planning to leading immersive workshops using agile and design thinking methodologies. Industry-leading teams at companies including IBM, IDEO, Autodesk, Intuit, GitHub, and Atlassian use MURAL to work together — at any time and from anywhere. Learn more at <a href="https://www.mural.co/">www.mural.co</a>.</p><p>‍</p><p>‍<strong>ABOUT INSIGHT PARTNERS</strong>‍</p><p>Insight Partners is a leading global venture capital and private equity firm investing in high-growth technology and software ScaleUp companies that are driving transformative change in their industries. Founded in 1995, Insight Partners has invested in more than 400 companies worldwide and has raised through a series of funds more than $30 billion in capital commitments. Insight’s mission is to find, fund, and work successfully with visionary executives, providing them with practical, hands-on software expertise to foster long-term success. Across its people and its portfolio, Insight encourages a culture around a belief that ScaleUp companies and growth create opportunity for all. For more information on Insight and all its investments, visit <a href="http://www.insightpartners.com/">www.insightpartners.com</a> or follow us on Twitter @insightpartners.<strong>‍</strong></p><p>‍</p><p><strong>Media Contact:</strong>‍</p><p>Leah Taylor, Public Relations for MURAL<a href="mailto:leaht@mural.co">‍</a></p><p><a href="mailto:leaht@mural.co">leaht@mural.co</a>‍</p><p>Press Kit: <a href="https://tinyurl.com/y5922rcn">https://tinyurl.com/y5922rcn</a><br></p></div></div>]]>
            </description>
            <link>https://www.mural.co/press-releases/series-b</link>
            <guid isPermaLink="false">hacker-news-small-sites-24277265</guid>
            <pubDate>Tue, 25 Aug 2020 23:01:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You want people to do the right thing? Save them the guilt trip]]>
            </title>
            <description>
<![CDATA[
Score 212 | Comments 121 (<a href="https://news.ycombinator.com/item?id=24277190">thread link</a>) | @canada_random1
<br/>
August 25, 2020 | https://psyche.co/ideas/you-want-people-to-do-the-right-thing-save-them-the-guilt-trip | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/you-want-people-to-do-the-right-thing-save-them-the-guilt-trip">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>Major global problems </strong>such as racial injustice or climate change often seem insurmountable. Itâ€™s hard to believe that our individual actions can make any real difference. Yet we know that many social dilemmas are overcome only through collective action. They call for people to make behavioural changes without any direct personal benefits â€“ in fact, these changes often come at a personal cost. So what might motivate people to adopt such a â€˜prosocialâ€™ mindset?</p>
<p>Researchers have explored a range of answers to this puzzle. A central line of enquiry relates to emotions and self-perception. Thereâ€™s a close link between emotions and behaviour: feelings motivate us to pursue goals, seek positive reinforcement and avoid punishment. But which emotional route is the most promising â€“ to make people feel bad about their shortcomings, or to encourage them to have a positive self-image because theyâ€™ve done â€˜the right thingâ€™?</p>
<p>There are good arguments both ways. Guilt can be a powerful motivator for action; the feeling of wanting to â€˜make upâ€™ for something can lead to reparative action. On the other hand, feeling good about our actions and what they reflect about who we are can elicit positive emotions. These feelings can then provide us with the energy and mental resources to engage in difficult problems, or to â€˜give to othersâ€™.</p>
<p>Itâ€™s important to distinguish here between guilt that arises internally, and guilt thatâ€™s externally induced. If we feel guilty about failing to recycle our plastics or adopt a vegetarian diet, we might be motivated to engage in reparative action. But if someone buttonholes us over dinner and tries to make us feel bad about our lifestyle choices, the picture might look very different; we might become defensive and try to justify our actions, which drives us further away from changing the way we behave. These scenarios then raise doubts about whether negative self-directed emotional appeals will be effective at promoting prosociality.</p>
<p>In a <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0188781">study</a> that my colleagues and I conducted at Columbia University in New York, we set out to test the consequences of positive versus negative self-directed emotions. Participants were prompted to think about either how guilty they felt about non-environmentally friendly behaviour, or how proud they might be for acting to preserve the environment. They were then asked a range of questions, such as whether they would pay increased rent to have more energy-efficient appliances, how likely they were to take public transport, and whether theyâ€™d be willing to use reusable shopping bags and mugs. Those participants who had been thinking of how proud they would feel about themselves chose to have a higher number of energy-efficient appliances compared with those participants who had been asked to think about personal guilt. Furthermore, participants in the pride group expressed higher intentions to engage in green behaviours compared with those in the guilt group. These findings suggest that inducing people to consider positive rather than negative self-directed emotions might recruit more people to a climate-change mitigation agenda, and to prosocial behaviour more broadly.</p>
<p>This potential advantage â€“ of appealing to positive emotions over negative ones â€“ links up with what we know about human self-perception. Having a positive self-image about who we are and what we do is a fundamental human need. When weâ€™re balanced and on good terms with ourselves, we are more energetic and have greater cognitive and emotional resources. By contrast, when we feel bad about ourselves, itâ€™s much more difficult to be prosocial â€“ especially if those feelings and actions arenâ€™t geared towards friends and family, but a removed, impersonal â€˜greater goodâ€™. Satisfying our important internal needs as emotional creatures can help us free up prosocial resources for others.</p>
<p>Research on self-affirmation supports this picture. In one <a href="https://academiccommons.columbia.edu/doi/10.7916/D84J1XJH">study</a>, we prompted one set of participants to engage in a self-affirming exercise. This involved reflecting on the values and behaviours that were important to them, and that they appreciated in themselves. Another group completed an unrelated exercise, describing the layout of the store at which they shop most frequently. This second â€˜controlâ€™ group allowed us to quantify the effect of the self-affirmation exercise.</p>
<p>Feeling good about ourselves can translate into acts of kindness towards others, for the benefit of society at large</p>
<p>Both groups were entered into a raffle to win a $10 bonus, and were given the option to either keep the money for themselves or to donate all or a portion to a selection of charities with varying missions and beneficiaries. The â€˜affirmationâ€™ group reported feeling more positively about themselves and more at peace with themselves â€“ and whatâ€™s more, these positive self-directed emotions translated into increased levels of charitable giving compared with those participants who had engaged in the unrelated exercise.</p>
<p><strong>My colleagues and</strong> I were curious about whether the effects of a positive self-image would extend to more challenging contexts, such as when the beneficiaries of prosociality were members of a marginalised group. In a field <a href="https://spssi.onlinelibrary.wiley.com/doi/full/10.1111/josi.12374">study</a> in Nigeria, we investigated how the public felt about enhanced social support for ex-prisoners. Like many other nations, Nigeria has high rates of recidivism. Social stigma means that those released from prison often struggle to secure jobs or have a supportive social network, which feeds into a cycle of reoffending. Interventions that reduce stigma and enhance social support can help ex-offenders to successfully reintegrate into society.</p>
<p>For the study, members of the general public in Nigeria were asked to engage in the self-affirming exercise prior to answering a range of survey questions. The results were striking. The self-affirmed participants showed more prosocial intentions and decreased discriminatory tendencies, compared with participants in the control group. They were more comfortable with having an ex-prisoner as their neighbour, for instance, and indicated stronger intentions to help an ex-prisoner whose employer was discriminating against them. They also expressed more willingness to invest personal time and effort to provide social support, such as participating in a tutoring programme for ex-prisoners.</p>
<p>Follow-up research in the United States replicated these results. Obtaining these findings in two studies and two different countries suggests that these effects can be generalised. The fact that a positive self-image can enhance prosociality doesnâ€™t seem to depend on a particular culture but could be an intrinsic part of human behaviour more generally. Feeling good about ourselves doesnâ€™t just enhance individual wellbeing by fulfilling a fundamental human psychological need; it can also translate into acts of kindness towards others, for the benefit of society at large.</p>
<p>A positive self-image can create a flywheel effect, in which the resulting prosocial behaviour sends a social signal to others. If others discriminate less, we are less likely to do so; if people in our social groups recycle more and watch their carbon footprint, we are more likely to do so. Getting a critical mass to â€˜join inâ€™ and acknowledging problems can, over time, help to shift norms â€“ which are drivers, not just inhibitors, of human behaviour.</p>
<p>The potential of positive self-directed emotions has largely not been embraced by activists. The worry could be that it might make those engaging in the cause appear self-satisfied or selfish. But these studies suggest that, instead of focusing on â€˜doom and gloomâ€™ messaging that zooms in on peopleâ€™s shortcomings and risks alienating them, policymakers and strategists might find that positive messaging, speaking to peopleâ€™s positive sense of self, might be a more powerful lever of behavioural change.</p></div></div></div>]]>
            </description>
            <link>https://psyche.co/ideas/you-want-people-to-do-the-right-thing-save-them-the-guilt-trip</link>
            <guid isPermaLink="false">hacker-news-small-sites-24277190</guid>
            <pubDate>Tue, 25 Aug 2020 22:50:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Squeak Smalltalk on a PostmarketOS Cellphone]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24276883">thread link</a>) | @tonyg
<br/>
August 25, 2020 | https://eighty-twenty.org/2020/08/25/postmarketos-smalltalk | <a href="https://web.archive.org/web/*/https://eighty-twenty.org/2020/08/25/postmarketos-smalltalk">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Back in 2007, when <a href="https://en.wikipedia.org/wiki/Openmoko">Openmoko</a>
was first a thing, I
<a href="https://leastfixedpoint.com/tonyg/kcbbs/openmoko-info.html">wrote an Erlang-based userland</a>
that got to the point of being able to take and make calls and receive
and send SMS. The project stalled: the Openmoko GTA01 was too slow,
its power-management too primitive, and Erlang’s GUI facilities too
rudimentary to make further work worthwhile.</p>

<p>Modern cellphone hardware is <em>much</em> more capable. Is it time to have
another run at the idea of a mobile personal computer?</p>

<figure>
<p><a href="https://leastfixedpoint.com/pictures/openmoko-erlang-ui.png"><img src="https://leastfixedpoint.com/pictures/openmoko-erlang-ui.png" alt="Erlang OpenMoko userland (2008)"></a>
Erlang OpenMoko userland (2008)</p>

<p><a href="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213231.jpg"><img src="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213231.jpg" alt="PostmarketOS on my cellphone"></a>
PostmarketOS on my cellphone</p>

<p><a href="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213240.jpg"><img src="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213240.jpg" alt="PostmarketOS Weston demo"></a>
PostmarketOS <a href="https://wiki.postmarketos.org/wiki/Weston">Weston</a> demo</p>

</figure>

<h3 id="postmarketos-is-awesome">PostmarketOS is awesome</h3>

<p>Last week, I installed <a href="http://postmarketos.org/">PostmarketOS</a> on my
previous cellphone, a Samsung Galaxy S7 (using PostmarketOS’s
<a href="https://wiki.postmarketos.org/wiki/Samsung_Galaxy_S7_(samsung-herolte)">samsung-herolte</a>
configuration).</p>

<p>PostmarketOS turns out to be a beautifully engineered system that’s
easy to understand and modify. The basics of kernel and Alpine Linux
userland installed cleanly and easily on the phone, and it’s running
well as a development platform. I’m looking forward to getting into
PostmarketOS more deeply.</p>

<figure>
<p><a href="https://eighty-twenty.org/images/pm-htop-20200825.png"><img src="https://eighty-twenty.org/images/pm-htop-20200825.png" alt="htop running on my cellphone"></a>
<code>htop</code> running on my cellphone. Six cores!</p>
</figure>

<p>Running <code>htop</code> on the phone shows what an <em>amazing</em> little machine it
is! So much power. Loads of cores, lots of RAM. Plenty of space to
explore alternative visions of mobile personal computing.</p>

<p>However, the built-in demos, such as the
<a href="https://wiki.postmarketos.org/wiki/Weston">Weston</a> demo (shown above
at right), currently leave quite a bit to be desired. Perhaps some of
the other
<a href="https://wiki.postmarketos.org/wiki/User-Interfaces">user interface options</a>
included with PostmarketOS could get me closer to a day-to-day usable
cellphone - but I’m interested in running my own software! Let’s get
hacking.</p>

<h3 id="running-my-own-programs">Running my own programs</h3>

<p>PostmarketOS is a plain, clean Alpine Linux distribution. You can SSH
into it initially
<a href="https://wiki.postmarketos.org/wiki/USB_Network">via USB networking</a>.
From there, you can
<a href="https://wiki.postmarketos.org/wiki/WiFi#Using_NetworkManager">configure wifi using nmcli</a>,
set up SSH keys, and then access it directly using SSH over wifi.</p>

<figure>
<p><a href="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213419.jpg"><img src="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213419.jpg" alt="lflow: Framebuffer demo"></a>
<code>lflow</code>: Framebuffer demo</p>
</figure>

<p>Building software is just as simple:</p>

<figure><pre><code data-lang="shell"><span></span>apk add alpine-sdk</code></pre></figure>

<p>To experiment with drawing to the framebuffer and reading touchscreen
input via <code>/dev/input</code>, I compiled and ran an old
<a href="https://github.com/tonyg/mac-display-hacks/blob/a1fde2054f00588076218b76d7ecf34764e5f99e/lflow.c">quick and dirty framebuffer hack</a>
I wrote years ago. The results (shown at left) were encouraging: the
program effortlessly animates tens of thousands of points at 30 frames
per second, responding to touch inputs. Display is via brute-force
pixel output to the <code>mmap</code>‘d frame buffer. It doesn’t even use a full
core.</p>

<p>PostmarketOS turns a phone into a fully capable Linux machine, with
total control over the attached hardware, and with everything
accessible to the developer in the usual places using the usual tools.</p>

<p>But Unix tools are inappropriate for a mobile personal computing
platform. We’ll need something else.</p>

<h3 id="a-smalltalk-phone">A Smalltalk phone</h3>

<figure>
<p><a href="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213500.jpg"><img src="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213500.jpg" alt="Squeak Smalltalk on PostmarketOS"></a>
Squeak Smalltalk
<a href="http://files.squeak.org/6.0alpha/Squeak6.0alpha-19812-64bit/">6.0-alpha</a>
on PostmarketOS</p>
</figure>

<p>Smalltalk could make an ideal basis for a mobile personal computing
platform.</p>

<p>I’ve <a href="https://eighty-twenty.org/tag/smalltalk">enjoyed</a> using,
developing with, and contributing to the
<a href="https://squeak.org/">Squeak Smalltalk</a> implementation since the mid
’00s.</p>

<p>So I compiled the
<a href="https://github.com/OpenSmalltalk/opensmalltalk-vm">Cog Smalltalk VM</a>
on the phone itself, making use of the 64-bit ARM support code that
landed extremely recently.</p>

<p>And lo and behold, it runs! Shown to the right is a bleeding-edge,
fully up-to-date Squeak 6.0-alpha image running on the phone itself.
(<a href="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213500.jpg">Click here or on the image to embiggen.</a>)</p>

<p>From here, I can experiment with new ideas using the full power of a
modern Smalltalk environment.</p>

<h3 id="what-next">What next?</h3>

<p>My previous Openmoko experiments foundered, in part, on the GUI aspect
of the system; GTK+ via Erlang was fine for quick prototyping but
wasn’t really up to the task for a day-to-day usable machine.</p>

<p>I recall getting Squeak running on my GTA01, in order to see if it
could provide a viable UI. However, I remember being stymied by the
mismatch between the expectations of the Smalltalk environment and the
realities of the phone.</p>

<p>Squeak wants a mouse and keyboard. It assumes a monitor-sized display,
in everything from widget and font sizes to window management. To work
well on a phone, it needs a touchscreen-based, high-DPI UI in addition
to its existing toolset.</p>

<p>Smalltalk, in both its language aspect and its system design aspect,
also <a href="https://eighty-twenty.org/2011/05/08/weaknesses-of-smalltalk-strengths-of-erlang">suffers from some weaknesses in areas where Erlang shines</a>.</p>

<p>However, in the years since the GTA01:</p>

<ul>
  <li>
    <p>the hardware is much better,</p>
  </li>
  <li>
    <p>the Squeak VM and image are better,</p>
  </li>
  <li>
    <p>I’ve learned a heck of a lot about
<a href="https://syndicate-lang.org/tonyg-dissertation/html/">some good ways to design interactive systems</a>,
and</p>
  </li>
  <li>
    <p>I’ve recently
<a href="https://tonyg.github.io/squeak-actors/">built some tools that help bring Erlang- and Syndicate-style architectural patterns for concurrency to Smalltalk</a>.</p>
  </li>
</ul>

<p>So I think using Erlang/Syndicate-style
<a href="https://tonyg.github.io/squeak-actors/">Actors</a> to structure a
Smalltalk-based phone userland, perhaps with <code>cgroups</code>-based
sub-virtual-machines and images, could work well.</p>

<p>My initial experiments have concentrated on</p>

<ul>
  <li>
    <p>fixing the tiny fonts (the DPI-change support code in the image
needs work, and the support in the VM seems to be absent (?)),</p>
  </li>
  <li>
    <p>reading from the touchscreen (probably
<a href="http://lists.squeakfoundation.org/pipermail/squeak-dev/2016-June/190051.html">like this</a>),</p>
  </li>
  <li>
    <p>thinking about how to structure Actor supervision hierarchies and
<a href="https://syndicate-lang.org/tonyg-dissertation/html/#sec:Syndicate's-approach-to-concurrency">Dataspaces</a>
for a mobile phone (probably borrowing some design elements from my
earlier
<a href="https://github.com/tonyg/erlang-openmoko">Openmoko Erlang-based userland</a>),
and</p>
  </li>
  <li>
    <p>thinking about how to layer a touchscreen (panel-based?) GUI atop
Squeak’s <a href="http://wiki.squeak.org/squeak/morphic">Morphic</a> UI.</p>
  </li>
</ul>

<p>I’ll write more on this blog as things develop.</p>

<hr>

<p><strong>Update:</strong> <a href="https://eighty-twenty.org/2020/08/27/squeak-postmarketos-update">Some progress on the font front!</a></p>

  </div></div>]]>
            </description>
            <link>https://eighty-twenty.org/2020/08/25/postmarketos-smalltalk</link>
            <guid isPermaLink="false">hacker-news-small-sites-24276883</guid>
            <pubDate>Tue, 25 Aug 2020 22:17:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Rapier Physics Engine]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24276785">thread link</a>) | @alex_hirner
<br/>
August 25, 2020 | https://www.dimforge.com/blog/2020/08/25/announcing-the-rapier-physics-engine/ | <a href="https://web.archive.org/web/*/https://www.dimforge.com/blog/2020/08/25/announcing-the-rapier-physics-engine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>In our announcement last week, we briefly mentioned this new physics engine we have been working on during the past 5 months.
Today we are officially releasing it for the first time: the project <a href="https://rapier.rs/" target="_blank" rel="noopener noreferrer"><strong>Rapier</strong></a>; a set of two 100%
rust libraries <strong>rapier2d</strong> and <strong>rapier3d</strong> for 2D and 3D physics simulations for games, animation, and robotics.</p><p><img src="https://www.dimforge.com/img/rapier_logo_color_textpath_dark.svg" alt="rapier logo"></p><p>This post will be quite long, so here are all the different sections:</p><ul><li><a href="#presenting-rapier">Presenting Rapier</a></li><li><a href="#reaching-out-to-other-communities-bevy-and-javascript">Reaching out to other communities: Bevy and JavaScript</a></li><li><a href="#feature-comparison-with-nphysics">Feature comparison with nphysics</a></li><li><a href="#benchmarks">Benchmarks</a><ul><li><a href="#3d-benchmark-rapier-vs-physx-vs-nphysics">3D Benchmark: Rapier vs. PhysX vs. nphysics</a></li><li><a href="#3d-benchmark-conclusion">3D Benchmark: Conclusion</a></li><li><a href="#2d-benchmark-rapier-vs-box2d-vs-nphysics">2D Benchmark: Rapier vs. Box2D vs. nphysics</a></li><li><a href="#2d-benchmark-conclusion">2D Benchmark: Conclusion</a></li><li><a href="#running-the-benchmarks-yourself">Running the benchmarks yourself</a></li></ul></li><li><a href="#conclusion">Conclusion</a></li></ul><h3>Presenting Rapier</h3><p><strong>Rapier</strong> is the successor of <a href="https://nphysics.org/" target="_blank" rel="noopener noreferrer">nphysics</a> and focuses on performance first.
Just like <strong>nphysics</strong> it is split into two crates: <strong>rapier2d</strong> and <strong>rapier3d</strong> for 2D and 3D physics respectively. It
is designed to be fast and multithreaded right from the beginning. It is also designed to require less incremental compilation
times because the data structures it defines are not generic.</p><p>In release mode, <strong>Rapier</strong> runs 5 to 8 times faster than <strong>nphysics</strong> , making it close to the performance of (the CPU version of) NVidia PhysX
and slightly faster than Box2D as you will see in the <a href="#benchmarks">benchmark sections</a>. <strong>Rapier</strong> is only at its beginning, so many features
are still missing. However some performance optimizations like parallelism, and SIMD have been integrated right from the start.</p><p>There already are a few key features that makes Rapier stand out. Since they may affect compilation times and/or performance,
they are disabled by default and need to be enabled explicitly through cargo features:</p><ol><li><strong>Serialization</strong>: if the <code>serde-serialize</code> feature of <strong>Rapier</strong> is enabled, every physics component will be serializable using <code>serde</code>.
This means that you can take a deep snapshot of the physics state and restore it later. This snapshot can even be saved on
disk or sent through network.</li><li><strong>Cross-platform determinism</strong>: if the <code>enhanced-determinism</code> feature of <strong>Rapier</strong> is enabled, it will behave in
a <em>bit-level cross-platform deterministic</em> way in all platforms that comply with the IEEE 754-2008 floating point standard.
This means that if you run the same simulation with the same initial states on two different machines (or browsers)
you will get the exact same results. Here "bit-level" determinism means that if you serialize the physics state after the
same number of timesteps on two different machines, you will obtain the exact same byte array for both: you may compute a checksum
of both snapshots and they will be identical. All this doesn't apply to platforms with pointer size smaller than 32-bit, and on
platforms that don't comply to IEEE&nbsp;754-2008 strictly.</li></ol><p>See <a href="#feature-comparison-with-nphysics">that section</a> for a comparison between Rapier and nphysics features.</p><h3>Reaching out to other communities: Bevy and JavaScript</h3><p><img src="https://www.dimforge.com/img/bevy_wasm_js.svg" alt="Bevy WASM JS"></p><p>Writing a physics engine is hard. There are not a lot of choices out there and most of them are written in C++. With
<strong>nphysics</strong> we wanted to provide an open-source 100% rust physics solution for the Rust community.
With <strong>Rapier</strong> we want to go one step further by contributing to as many communities in need of a physics engine as we can. This is why we are
starting, right at the beginning of the <strong>Rapier</strong> story, by providing:</p><ul><li>Official <strong>JavaScript bindings</strong> for the WASM version of <strong>Rapier</strong>. These binding are generated using <code>wasm_bindgen</code> and
are published to NPM as the packages <a href="https://www.npmjs.com/package/@dimforge/rapier3d" target="_blank" rel="noopener noreferrer">@dimforge/rapier3d</a> and
<a href="https://www.npmjs.com/package/@dimforge/rapier2d" target="_blank" rel="noopener noreferrer">@dimforge/rapier2d</a>. While multiple physics solutions already exist
for JavaScript they are either slow (because they are manually written in JS like <strong>cannon.js</strong> or <strong>oimo.js</strong>), or not
officially maintained by their original developers (because they are ported from C++ using Emscripten, like <strong>box2d.wasm</strong>,
<strong>ammo.wasm</strong>, or <strong>physx.wasm</strong>). By providing official wasm builds and JS bindings, we are making sure to provide the
best support, documentation, and continuous updates to the JS community.</li><li>Official <strong>plugins for the <a href="https://bevyengine.org/" target="_blank" rel="noopener noreferrer">Bevy</a></strong> game engine. They are available as the
<a href="https://crates.io/crates/bevy_rapier2d" target="_blank" rel="noopener noreferrer">bevy_rapier2d</a> and <a href="https://crates.io/crates/bevy_rapier3d" target="_blank" rel="noopener noreferrer">bevy_rapier3d</a>
crates. The <strong>Bevy</strong> game engine has recently been released as an efficient, fast-to-compile, and easy to use, data-oriented
game engine. It is still at its early state and is lacking any physics feature. We believe physics support is a very high-value
feature to have in a game engine. By providing official plugins we want to make sure the <strong>Bevy</strong> community can benefit from the
<strong>Rapier</strong> physics engines quickly and easily.</li></ul><p>There are so many more communities we would like to contribute to but don't have manpower to support all of them just now.
Other integrations and languages will come in the future.</p><p>We also plan to create official plugins for the <strong>Amethyst</strong> game engine but have not started yet. We are waiting
for the migration of <strong>Amethyst</strong> to the <a href="https://crates.io/crates/legion" target="_blank" rel="noopener noreferrer">legion</a> ECS solution before starting to work
on this.</p><div><p><h5><span><svg xmlns="http://www.w3.org/2000/svg" width="14" height="16" viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</h5></p><p>Examples using the 2D JS bindings are available on GitHub:
<a href="https://github.com/dimforge/rapier.js/tree/master/testbed2d/src/demos" target="_blank" rel="noopener noreferrer">2D</a> and
<a href="https://github.com/dimforge/rapier.js/tree/master/testbed3d/src/demos" target="_blank" rel="noopener noreferrer">3D</a>. You can see these demos running
<a href="https://rapier.rs/demos2d/index.html" target="_blank" rel="noopener noreferrer">there for 2D</a> and <a href="https://rapier.rs/demos3d/index.html" target="_blank" rel="noopener noreferrer">there for 3D</a>.
In these demos, the physics simulation runs inside of a web worker and the rendering is performed by
<a href="https://www.pixijs.com/" target="_blank" rel="noopener noreferrer">PixiJS</a> and <a href="https://threejs.org/" target="_blank" rel="noopener noreferrer">Three.js</a>.</p></div><h3>Feature comparison with nphysics</h3><p><strong>Rapier</strong> does not have as many features as <strong>nphysics</strong> yet, but it also has a few features <strong>nphysics</strong> does not have.
Here are comparative tables of both physics engines: </p><center><table><thead><tr><th>Dynamics features</th><th>Rapier</th><th>nphysics</th></tr></thead><tbody><tr><td>Rigid-body physics</td><td>✅</td><td>✅</td></tr><tr><td>Kinematic bodies</td><td>✅</td><td>✅</td></tr><tr><td>Rigid-body islands and sleeping</td><td>✅</td><td>✅</td></tr><tr><td>Joint constraints</td><td>✅</td><td>✅</td></tr><tr><td>Joint constraint limits and motors</td><td>❌</td><td>❌</td></tr><tr><td>Reduced-coordinate joints</td><td>❌</td><td>✅</td></tr><tr><td>Reduced-coordinates joint limits and motors</td><td>❌</td><td>✅</td></tr><tr><td>Conveyor belts</td><td>❌</td><td>✅</td></tr><tr><td>Deformable bodies</td><td>❌</td><td>✅</td></tr><tr><td>Fluids (integration with <a href="https://salva.rs/" target="_blank" rel="noopener noreferrer">Salva</a>)</td><td>❌</td><td>✅</td></tr></tbody></table></center><center><table><thead><tr><th>Geometry features</th><th>Rapier</th><th>nphysics</th></tr></thead><tbody><tr><td>Colliders</td><td>✅</td><td>✅</td></tr><tr><td>Sensors</td><td>✅</td><td>✅</td></tr><tr><td>Contact/proximity events</td><td>✅</td><td>✅</td></tr><tr><td>Contact graph</td><td>✅</td><td>✅</td></tr><tr><td>Continuous Collision Detection</td><td>❌</td><td>✅</td></tr><tr><td>Ray-casting</td><td>❌</td><td>✅</td></tr><tr><td>Convex-casting</td><td>❌</td><td>✅</td></tr></tbody></table></center><center><table><thead><tr><th>Performance and portability features</th><th>Rapier</th><th>nphysics</th></tr></thead><tbody><tr><td>Floating-point cross-platform determinism</td><td>✅</td><td>❌</td></tr><tr><td>Parallelization</td><td>✅</td><td>❌</td></tr><tr><td>SIMD</td><td>✅</td><td>❌</td></tr><tr><td>Serialization</td><td>✅</td><td>❌</td></tr><tr><td><strong>JavaScript</strong> bindings</td><td>✅</td><td>❌</td></tr><tr><td>Integration to <strong>Bevy</strong></td><td>✅</td><td>❌</td></tr><tr><td>Integration to <strong>Amethyst</strong></td><td>❌</td><td>❌</td></tr><tr><td>Fixed-point cross-platform determinism</td><td>❌</td><td>✅</td></tr><tr><td>64-bits physics</td><td>❌</td><td>✅</td></tr></tbody></table></center><p>Today <strong>nphysics</strong> is more mature than <strong>Rapier</strong>. Our first goal during the next few months is to bring <strong>Rapier</strong> at the
same level as <strong>nphysics</strong> featurewise, while keeping the significant performance improvements and better accuracy.</p><h3>Benchmarks</h3><p>Alright, we claimed that <strong>Rapier</strong> is nearly as fast as the CPU version of PhysX, 5 to 10 times faster than nphysics, and
slightly faster than Box2D. It is now time to prove these claims using benchmarks.</p><div><p><h5><span><svg xmlns="http://www.w3.org/2000/svg" width="14" height="16" viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</h5></p><p>Keep in mind that <strong>Rapier</strong> is still at a early development stage. It does not have as many features as the ofther
physics engines involved in this benchmark. However, our objective is to ensure that the future addition of new features
to <strong>Rapier</strong> don't reduce the level of perfomance you see here.</p></div><p>In the subsequent benchmarks we ran a set of stress tests using four different physics engines:</p><ol><li><strong>Rapier</strong> using our <a href="https://crates.io/crates/rapier3d" target="_blank" rel="noopener noreferrer">rapier3d</a> crate for 3D and <a href="https://crates.io/crates/rapier2d" target="_blank" rel="noopener noreferrer">rapier2d</a> for 2D.</li><li><strong>PhysX 4</strong> using the <a href="https://crates.io/crates/physx" target="_blank" rel="noopener noreferrer">physx</a> crate.</li><li><strong>Box2d</strong> using the <a href="https://crates.io/crates/wrapped2d" target="_blank" rel="noopener noreferrer">wrapped2d</a> crate.</li><li><strong>nphysics</strong> using our <a href="https://crates.io/crates/nphysics3d" target="_blank" rel="noopener noreferrer">nphysics3d</a> crate for 3D and <a href="https://crates.io/crates/nphysics2d" target="_blank" rel="noopener noreferrer">nphysics2d</a> for 2D</li></ol><p>Independently of the chosen physics engine, all scenes are always initialized in the
exact same way (same bodies, same colliders at the same initial positions) and with the following
parameters:</p><ul><li><strong>Rust compiler and flags</strong>: <code>rustc 1.46.0-nightly</code>, <code>--release</code>, <code>--features simd-nightly</code>, <code>codegen-units = 1</code>.</li><li><strong>Timestep length</strong>: 0.016 (i.e. 16 milliseconds).</li><li><strong>Number of velocity iterations</strong>: 4 for Rapier, nphysics, and Box2D. 1 for PhysX.</li><li><strong>Number of position iterations</strong>: 1 from Rapier, nphysics, and Box2D. 4 for PhysX.</li><li><strong>Targets</strong>: native CPU (WebAssembly versions and PhysX on GPU have not been benchmarked.)</li><li><strong>Solvers</strong>: variations of PGS. (The PhysX 4.0 TGS solver has not been benchmarked. We used the default <code>ePGS</code> solver.)</li><li><strong>Number of threads</strong>: 1.</li></ul><div><p><h5><span><svg xmlns="http://www.w3.org/2000/svg" width="14" height="16" viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</h5></p><p>In this benchmark we don't use multithreading. A benchmark with multithreading enabled, involving only multithread physics
engine will be the subject of another blog post.</p></div><p>Each 3D benchmark is run on two different machines because we observed performance differences between
PhysX and Rapier depending on the processor:</p><ol><li>A desktop computer, running Ubuntu, equipped with an AMD Ryzen 9 3900X CPU, 3.8GHz.</li><li>A MacBook Pro (plugged to a power outlet), running Mac OS, equipped with an Intel Core i7 7920HQ, 3.1GHz.</li></ol><p>The 2D benchmarks are run only on the AMD Ryzen 9 3900X CPU (the relative performance remain the same with
the Inter Core i7 CPU).</p><h3>3D Benchmark: Rapier vs. PhysX vs. nphysics</h3><p>A few notes are in order regarding PhysX in this benchmark. First, we don't use the same number of iterations for Rapier and PhysX.
For Rapier and nphysics we use 4 velocity iterations and 1 position iteration. It is the other way round for PhysX: 1 velocity
iteration and 4 position iterations. This is the most sensible configuration because:</p><ul><li>PhysX developers <a href="http://www.codercorner.com/blog/?p=2072" target="_blank" rel="noopener noreferrer">advise to increase</a> the number of position iterations for
better stability, and leave to 1 the number of velocity iterations.</li><li>PhysX itself (independently from this benchmark) uses 1 velocity iteration and 4 position iterations by default.
It yields more stable simulations than using 4 velocity and 1 position without performance difference.</li><li>Rapier and nphysics use a solver different from PhysX's. With our solver, it is recommended to increase the number of
velocity iterations instead of position iterations, and leave the number of position iterations to 1.</li></ul><p>The PhysX benchmarks will include two performance curves:</p><ol><li>One performance curve using their default <code>ePATH</code> friction model. This is a simplified friction model, faster to
compute, but less realistic. Rapier and nphysics don't implement a similar model yet.</li><li>One performance curve using their <code>eTWO_DIRECTIONAL</code> friction model. This is similar to the friction model used by Rapier
and nphysics.</li></ol><h4>8.000 stacked balls</h4><p>In this benchmark there are 8000 balls falling on a ground also composed of balls. In the end, they form 400
independent small stacks of balls.
<img src="https://www.dimforge.com/img/bench_balls.png" alt="bench balls">
<img src="https://www.dimforge.com/img/bench_ryzen_balls.svg" alt="bench balls">
<img src="https://www.dimforge.com/img/bench_intel_balls.svg" alt="bench balls"></p><h4>3.000 falling boxes</h4><p>In this benchmark, there are about 3000 small cubes falling on a large cube floor in a completely …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.dimforge.com/blog/2020/08/25/announcing-the-rapier-physics-engine/">https://www.dimforge.com/blog/2020/08/25/announcing-the-rapier-physics-engine/</a></em></p>]]>
            </description>
            <link>https://www.dimforge.com/blog/2020/08/25/announcing-the-rapier-physics-engine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24276785</guid>
            <pubDate>Tue, 25 Aug 2020 22:08:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interview with Bifat / the Electronic Knights]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24276569">thread link</a>) | @doener
<br/>
August 25, 2020 | https://www.amigalife.org/index.php?topic=189.0 | <a href="https://web.archive.org/web/*/https://www.amigalife.org/index.php?topic=189.0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
								<div id="msg_335"><p><strong>Hello Bifat. Could you please introduce yourself to our readers?<br></strong><br>Hi, my name is Timm, I live in Berlin, I started as a member of TEK in 1991 on the Amiga. I did graphics for a few weeks, then I switched my main profession to coding. I left TEK in about 2004 with my then girlfriend Blue to do Playstation 2 demos as Neoscientists. In 2016 I returned to TEK to do demos on the Amiga again. In 2018 I joined K2 as my second group.</p><p><strong>When did you get interested in computers and what was your first computer?<br></strong><br>I got interested in computers because my uncle was a construction engineer, and he had a PET in his office. He used a sort of finite elements method to calculate the hulls of nuclear power plants with it. I was promised to be given the PET when it would be taken out of service. Then the C64 came out and seemed more appropriate. It was some kind of a family effort to finance the C64 very early.</p><p><strong>What Amiga(s) did you have in the past and if you remember, what were the(ir) configuration(s)?<br></strong><br>My first Amiga was an Amiga 500, Kick 1.2, soon with a 1.8mb memory expansion, then I replaced the ROM with Kick 1.3, so I could add an ALF controller and a second-hand 30mb harddisk. In 1990 I got an Amiga 3000, which was extremely expensive. It was an early model shipped with a SuperKickstart disk and very buggy Kick 2.01. Initially it had 6mb RAM, a 210mb SCSI harddisk. This became my main computer for more than 10 years. Over the years Blue and I had about five A3000s altogether, most of them expanded with 68060s, gfx and network cards.</p><p><strong>Do you still have any Amiga(s) today? If yes, which ones and what configuration(s) <br></strong><br>I have an A500, Rev. 5, Kick 1.2, 0,5mb fake fast, 1084s monitor, no other extensions or modifications. This is my machine for final testing of my stuff for "OCS" compliance. I have another A500 with an ACA500+ and an XSurf500 network module. My main computer for coding is an A600 with 2mb of chipmem and a PCMCIA network adapter. Also I have two A3000s, of which one is in regular use. Also I have an A1200, but only for testing my OCS stuff for AGA compatibility. All Amigas except one are in my network, and I use real disk drives and disks on all Amigas.</p><p><strong>Can you tell us how you got involved with the demoscene?<br></strong><br>I lived in a small town in Hesse, Germany. In this town there was an uncanny concentration of early computer scene people. Most of them were two or three years older than me. They founded TEK on the C64. I didn't know them at first. In my own grade there was a very active Amiga guy running a BBS since 1987/88 or so. He supplied me with manuals and tools and so I learned C and assembler and did "serious" programming on the Amiga first. In around 1990 I got to know the other scene people in this town, and being among the more proficient, I got nice support from the others and was well integrated when TEK took off on the Amiga. Also noteworthy is that from the same town our C16/Plus4 section originated, with people who were slightly younger than me.</p><p><strong>Can you tell us a bit about the story behind your group TEK?<br></strong><br>It was founded on the C64 in 1987 by White Knight, Banana, and Mac and possibly a few others, who were all from this town. From White Knight came a part of its name. TEK was more on the creative side of things, known for great music, funny ideas and weird humor. TEK also did cracks and was very active in swapping, and on the C64, the group went into hibernation due to problems with the police, but reappeared shortly thereafter on the Amiga, when I and a few others joined.&nbsp; We brought some new, different attitudes into the group, but Banana's and Mac's punk-like, brazen spirit and humor were still alive and continued to shape the group. With Blue I shared some interesting times, as I introduced her to assembler and demo coding on the Amiga, and when she got it, she asked me to join her making demos on the PS2.</p><p><strong>Do you remember which tools you used back when you started out, and what are you using these days for development?<br></strong><br>Early: Aztec C, Seka, DPaint, AsmOne, Noisetracker, Protracker. Middle ages: DevPac, SAS/C, AsmOne, PPaint, TVPaint, Protracker. Now: Linux, vasm, Lua, PPaint, Protracker, Inkscape, Grafx2. I'm using a toolchain that I mostly wrote myself, plus shell and editor. I use vasm (with a few modifications) for cross-coding, and run the stuff on a real Amiga on fixed addresses using a TCP server. I also wrote a cross cruncher, which later got released as 'Cranker', and I use my own Lua-based macro<br>language 'DemoPHP'. In DemoPHP I can for example calculate tables and do on-the-fly image processing. My workflow is often that I prototype an effect in Lua, which I then slap into an assembler source.</p><p><strong>Do you have some tips for anyone that might want to start doing Amiga productions in 2020?<br></strong><br>Yes. I recommend getting a real Amiga and connect it to the network. Then you can work on the real machine using an assembler like AsmOne, or you can use vasm on a PC and start your work directly from a network share, e.g. using smbfs. Use for example an A500/ACA500+, A600, or an A1200. You can use an emulator as an additional tool, but do not code against it primarily. Don't let yourself get distracted by too much framework stuff, IDE integration and PC side peculiarities, that's<br>beside the point I think.</p><p><strong>What would you consider the best production you worked on and why?<br></strong><br>Elevation, 2016 slideshow. Here everything just worked perfectly. Artistically and technically it fell into place like never before, thanks to Blue (pictures and texts), Blueberry and TTY (help on compression). It was finished literally on the last day.</p><p><strong>Can you tell us what you consider the best Amiga demos back in the golden years? as well as now<br></strong><br>There are too many good, underrated, even mostly forgotten works, not only the usual suspects. To give you an idea: Vector Exterminator, Sound Vision, Absolute Inebriation, Boundless Void... I don't want to name recent productions, because they are too fresh to put labels on them, and it might hurt some people if their productions are not mentioned also. There is not the one and only way of making demos, part of the fun is the multitude of formats and approaches. And by the way, I also appreciate Atari ST/STe demos a lot.</p><p><strong>What do you think of the state of the demo scene today?<br></strong><br>It was in a good shape until the Covid-19 craze, to which most governments reacted in the wrong way. It remains to be seen if we can get back on our feet and what the repercussions are. The parties make little sense without demos, and the demos make little sense without parties. In the long term we are losing people to "getting a life", which is actually an euphemism for something closer to death. But there are also people discovering (or remembering) that making demos and showing them off at international parties might be one of the finest hobbies they'll ever find.</p><p><strong>What do you feel you got out of the whole experience of being active in the Amiga demoscene? for example, did it lead you to code professionally in any way?<br></strong><br>From the demoscene emerged a certain mindset in me as much as I was attracted to it due to this mindset. Optimization and the desire to try impossible things are deeply engrained into my thinking. I hate wasting resources. I like to spend huge amounts of time and work for all sorts of crazy research, but practicability always wins in the end. This was all very helpful in life. I have been working with computers professionally from a young age, and I never really did something I didn't like.</p><p><strong>Is there anyone you would like to send some greetings to? Or perhaps you have some other last words?<br></strong><br>Greetings to all. Thank you for keeping the demoscene alive. This especially goes to the organizers of parties. Your work is appreciated, too.</p><p><strong>That is the end of this interview, thanks for taking the time to do it Bifat, I am sure our readers will appreciate it <img src="https://amigalife.org/Smileys/default/smiley.gif" alt=":)" title="Smiley">.</strong></p></div>
							</div></div>]]>
            </description>
            <link>https://www.amigalife.org/index.php?topic=189.0</link>
            <guid isPermaLink="false">hacker-news-small-sites-24276569</guid>
            <pubDate>Tue, 25 Aug 2020 21:48:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Minimal React: getting started with the front end library]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24276175">thread link</a>) | @joeyespo
<br/>
August 25, 2020 | https://2ality.com/2020/08/minimal-react.html | <a href="https://web.archive.org/web/*/https://2ality.com/2020/08/minimal-react.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This blog post explains how to get started with React while using as few libraries as possible.</p>
<!--more-->
<hr>
<p><strong>Table of contents:</strong></p>
<nav><ul><li><a href="#required-knowledge">Required knowledge&nbsp;&nbsp;</a></li><li><a href="#about-this-blog-post">About this blog post&nbsp;&nbsp;</a></li><li><a href="#the-repository">The repository&nbsp;&nbsp;</a></li><li><a href="#what-is-react%3F">What is React?&nbsp;&nbsp;</a><ul><li><a href="#the-traditional-model-view-controller-(mvc)-approach">The traditional model-view-controller (MVC) approach&nbsp;&nbsp;</a></li><li><a href="#react">React&nbsp;&nbsp;</a></li></ul></li><li><a href="#first-example%3A-counting-clicks">First example: counting clicks&nbsp;&nbsp;</a><ul><li><a href="#adding-the-user-interface-to-the-html-page">Adding the user interface to the HTML page&nbsp;&nbsp;</a></li><li><a href="#creating-user-interface-elements">Creating user interface elements&nbsp;&nbsp;</a><ul></ul></li><li><a href="#the-component-countingclicks()">The component CountingClicks()&nbsp;&nbsp;</a><ul></ul></li></ul></li><li><a href="#second-example%3A-expandable-sections">Second example: expandable sections&nbsp;&nbsp;</a><ul><li><a href="#user-interface-component-sections()">User interface component Sections()&nbsp;&nbsp;</a></li><li><a href="#user-interface-component-section()">User interface component Section()&nbsp;&nbsp;</a><ul></ul></li><li><a href="#exercises">Exercises&nbsp;&nbsp;</a></li></ul></li><li><a href="#third-example%3A-quiz">Third example: quiz&nbsp;&nbsp;</a><ul><li><a href="#the-model">The model&nbsp;&nbsp;</a></li><li><a href="#immer">Immer&nbsp;&nbsp;</a></li><li><a href="#the-root-controller-pattern">The root controller pattern&nbsp;&nbsp;</a></li><li><a href="#the-user-interface-components">The user interface components&nbsp;&nbsp;</a><ul></ul></li><li><a href="#exercises-2">Exercises&nbsp;&nbsp;</a></li></ul></li><li><a href="#how-does-snowpack-work%3F">How does Snowpack work?&nbsp;&nbsp;</a><ul><li><a href="#building">Building&nbsp;&nbsp;</a></li></ul></li><li><a href="#conclusion">Conclusion&nbsp;&nbsp;</a><ul><li><a href="#state-management-via-the-root-controller-pattern">State management via the root controller pattern&nbsp;&nbsp;</a></li><li><a href="#next-steps">Next steps&nbsp;&nbsp;</a></li><li><a href="#learning-more-about-the-react-ecosystem">Learning more about the React ecosystem&nbsp;&nbsp;</a></li></ul></li></ul></nav><hr>
<h2 id="required-knowledge">Required knowledge&nbsp;&nbsp;</h2>
<p>Things you should know before reading this blog post:</p>
<ul>
<li>JavaScript: You should have already written code in that language.</li>
<li>Browser DOM (document object model): It helps if you are loosely familiar with how the DOM represents HTML and how it handles events.</li>
<li>npm: It also helps if you have a basic understanding of the npm package manager for Node.js.</li>
</ul>
<h2 id="about-this-blog-post">About this blog post&nbsp;&nbsp;</h2>
<p>Many tutorials provide comprehensive introductions to the React ecosystem. I wanted to try something different:</p>
<blockquote>
<p>What is the smallest set of libraries that allows you to be productive in React?</p>
</blockquote>
<p>This is an exhaustive list of the npm packages that the code in this blog post depends on:</p>
<ul>
<li><a href="https://www.snowpack.dev/">Build tool <em>Snowpack</em></a>:
<ul>
<li><code>snowpack</code></li>
<li><code>@snowpack/plugin-react-refresh</code></li>
</ul>
</li>
<li><a href="https://reactjs.org/">User interface library <em>React</em></a>:
<ul>
<li><code>react</code></li>
<li><code>react-dom</code></li>
</ul>
</li>
<li><a href="https://github.com/developit/htm">React helper library <em>HTM</em></a> (to specify user interfaces via an HTML-like syntax):
<ul>
<li><code>htm</code></li>
</ul>
</li>
<li><a href="https://immerjs.github.io/immer/docs/introduction">Library <em>Immer</em></a> for non-destructively updating data:
<ul>
<li><code>immer</code></li>
</ul>
</li>
</ul>
<h2 id="the-repository">The repository&nbsp;&nbsp;</h2>
<p>The repository <a href="https://github.com/rauschma/minimal-react"><code>minimal-react</code></a> contains the examples that we are exploring in this blog post:</p>
<ul>
<li>You can try out the examples <a href="https://rauschma.github.io/minimal-react/build/">online</a>.</li>
<li>You can install it locally to play with the complete setup. Everything is installed inside a single directory, so it’s easy to remove later on.</li>
<li>However, installing the repository is not required for following this blog post. All relevant data is quoted inside the post.</li>
</ul>
<p>The repository has the following structure:</p>
<ul>
<li><code>minimal-react/</code>
<ul>
<li><code>html/</code>: HTML files</li>
<li><code>js/</code>: JavaScript code</li>
<li><code>README.md</code>: Instructions for installing and running the project</li>
<li><code>package.json</code>: Configuring the npm package manager</li>
<li><code>snowpack.config.json</code>: Configuring the Snowpack build tool</li>
</ul>
</li>
</ul>
<p><code>package.json</code> specifies the npm packages that the JavaScript code depends on:</p>
<pre><code>"devDependencies": {
  "@snowpack/plugin-react-refresh": "^2.1.0",
  "snowpack": "^2.9.0"
},
"dependencies": {
  "htm": "^3.0.4",
  "immer": "^7.0.7",
  "react": "^16.13.1",
  "react-dom": "^16.13.1"
}
</code></pre>
<p><code>package.json</code> also defines two scripts:</p>
<pre><code>"scripts": {
  "start": "snowpack dev",
  "build": "snowpack build"
},
</code></pre>
<p>These are executed via:</p>
<ul>
<li>Starting the development web server: <code>npm run start</code>
<ul>
<li>Abbreviated: <code>npm start</code></li>
</ul>
</li>
<li>Creating a standalone application (that runs without the development server): <code>npm run build</code></li>
</ul>
<h2 id="what-is-react%3F">What is React?&nbsp;&nbsp;</h2>
<p>React is a library for creating user interfaces in web browsers. Before we take a look at how it works, let us remind ourselves how user interfaces are created if they are based on a traditional model-view-controller approach.</p>
<h3 id="the-traditional-model-view-controller-(mvc)-approach">The traditional model-view-controller (MVC) approach&nbsp;&nbsp;</h3>
<p>Traditional MVC-based user interfaces work as follows:</p>
<ul>
<li>A tree of user interface components is created once.</li>
<li>Each user interface component manages its own state and updates it incrementally, in response to user interactions.</li>
<li>So-called “glue code”&nbsp;propagates state changes across UI components.</li>
</ul>
<p>This approach has downsides:</p>
<ul>
<li>The user interface logic is often scattered across the code.</li>
<li>Cross-component changes are difficult to implement.</li>
<li>It’s easy to introduce inconsistencies because there can be many different combinations of states.</li>
</ul>
<h3 id="react">React&nbsp;&nbsp;</h3>
<p>React works differently:</p>
<ul>
<li>The user interface is encoded as a data structure that is similar to the <em>document object model (DOM)</em> used by browsers to represent HTML. That data structure is called <em>virtual DOM</em>.</li>
<li>There is a single (nested) model for the complete user interface.</li>
<li>A user interface component is simply a function that maps a model to a user interface.
<ul>
<li>The root component has as input the whole model and passes on parts of that model to subcomponents (which are also functions).</li>
</ul>
</li>
<li>When the user interacts with the UI, the model is changed accordingly and the complete user interface is recreated (by invoking the root component again).
<ul>
<li>To make this viable, performance-wise, React compares the virtual DOM returned by the root component with the current browser DOM. It only changes the latter where the former differs.</li>
</ul>
</li>
</ul>
<p>Benefits of this approach:</p>
<ul>
<li>It’s easier to understand the user interface logic.</li>
<li>Cross-component dependencies are easier to implement.</li>
<li>The data flow is simpler: always from the top of the user interface component tree to its bottom.</li>
</ul>
<h2 id="first-example%3A-counting-clicks">First example: counting clicks&nbsp;&nbsp;</h2>
<p>The first example is in the file <code>minimal-react/html/counting-clicks.html</code>.</p>
<h3 id="adding-the-user-interface-to-the-html-page">Adding the user interface to the HTML page&nbsp;&nbsp;</h3>
<p>This is the body of the HTML page:</p>
<pre><code><span>&lt;<span>h1</span>&gt;</span>Counting clicks<span>&lt;/<span>h1</span>&gt;</span>
<span>&lt;<span>div</span> <span>id</span>=<span>"root"</span>&gt;</span><span>&lt;/<span>div</span>&gt;</span>
<span>&lt;<span>script</span> <span>type</span>=<span>"module"</span> <span>src</span>=<span>"../js/counting-clicks.js"</span>&gt;</span><span>&lt;/<span>script</span>&gt;</span>
</code></pre>
<p>This is how <code>minimal-react/js/counting-clicks.js</code> adds its user interface to the web page:</p>
<pre><code><span>import</span> ReactDOM <span>from</span> <span>'react-dom'</span>;
<span>import</span> {html} <span>from</span> <span>'htm/react'</span>;
<span>import</span> {useState} <span>from</span> <span>'react'</span>;



ReactDOM.render(
  html<span>`&lt;<span>${CountingClicks}</span> rootModel=<span>${rootModel}</span> /&gt;`</span>, 
  <span>document</span>.getElementById(<span>'root'</span>)); 
</code></pre>
<ul>
<li>Line A is how we create user interface elements (via the virtual DOM). Read on for more information.</li>
<li>Line B is the HTML element in which React creates the user interface.</li>
</ul>
<h3 id="creating-user-interface-elements">Creating user interface elements&nbsp;&nbsp;</h3>
<p>Consider the following syntax from the previous example:</p>
<pre><code>html<span>`&lt;<span>${CountingClicks}</span> rootModel=<span>${rootModel}</span> /&gt;`</span>
</code></pre>
<p>There are two layers to this syntax.</p>
<h4 id="syntactic-layer-1%3A-tagged-templates">Syntactic layer 1: tagged templates&nbsp;&nbsp;</h4>
<p><code>html`···`</code> is a <a href="https://exploringjs.com/impatient-js/ch_template-literals.html#tagged-templates"><em>tagged template</em></a>. Tagged templates are a JavaScript language feature that lets us embed foreign syntax in JavaScript code. Each tagged template is actually a function call – for example:</p>
<pre><code><span>const</span> numberOfFruits = <span>4</span>;
<span>const</span> nameOfFruits = <span>'strawberries'</span>;
<span>const</span> result = someFunc<span>`I have <span>${numberOfFruits}</span> <span>${nameOfFruits}</span>!`</span>;
</code></pre>
<p>The the last line is equivalent to:</p>
<pre><code><span>const</span> result = someFunc([<span>'I have '</span>, <span>' '</span>, <span>'!'</span>], numberOfFruits, nameOfFruits);
</code></pre>
<p>Tag functions such as <code>someFunc()</code> can return arbitrary values and are usually guided by their input. In this case, the input is:</p>
<ul>
<li>The <em>template strings</em> <code>['I have ', ' ', '!']</code> are static (the same each time this particular function call is made)</li>
<li>The <em>substitutions</em> <code>numberOfFruits</code> and <code>nameOfFruits</code> are dynamic (possibly different each time this particular function call is made)</li>
</ul>
<p>Substitutions are inserted “into” the template via the syntax <code>${···}</code>.</p>
<p>The <em>tag function</em> <code>html</code> supports React’s syntax for creating virtual DOM elements. It parses its input to produce its output.</p>
<h4 id="syntactic-layer-2%3A-jsx%2C-react%E2%80%99s-syntax-for-creating-virtual-dom-elements">Syntactic layer 2: JSX, React’s syntax for creating virtual DOM elements&nbsp;&nbsp;</h4>
<p><em>JSX</em> is a non-standard JavaScript language feature introduced by React. It lets us use HTML-ish expressions to create virtual DOM data. JSX must be compiled to standard JavaScript and is supported by several compilers – for example:</p>
<ul>
<li><a href="https://babeljs.io/">Babel</a>:
<ul>
<li>Input: modern and/or future JavaScript</li>
<li>Output: current or older JavaScript</li>
</ul>
</li>
<li><a href="https://www.typescriptlang.org/">TypeScript</a>:
<ul>
<li>Input: JavaScript plus static type information (roughly, a superset of JavaScript)</li>
<li>Output: current or older JavaScript</li>
</ul>
</li>
</ul>
<p>In this tutorial, we use a tagged template instead of JSX, which has the benefit that we can use plain JavaScript (no compilation is necessary). There are only minor differences between <code>html</code> syntax and JSX, which is why I’ll occasionally use the name JSX for the former.</p>
<p>There are two kinds of elements.</p>
<h5 id="react-components">React components&nbsp;&nbsp;</h5>
<p>First, the name of an element can be a function whose name starts with an uppercase letter:</p>
<pre><code>html<span>`&lt;<span>${UiComponent}</span> arg1="abc" arg2=<span>${<span>123</span>}</span> /&gt;`</span>
</code></pre>
<p>This expression is equivalent to:</p>
<pre><code>React.createElement(UiComponent, { <span>arg1</span>: <span>"abc"</span>, <span>arg2</span>: <span>123</span> })
</code></pre>
<p>In this case, <code>React.createElement()</code> makes the following function call:</p>
<pre><code>UiComponent({ <span>arg1</span>: <span>"abc"</span>, <span>arg2</span>: <span>123</span> })
</code></pre>
<h5 id="virtual-dom-elements">Virtual DOM elements&nbsp;&nbsp;</h5>
<p>Second, the name of an element can also be a string that starts with a lowercase letter:</p>
<pre><code>html<span>`&lt;div arg1="abc" arg2=<span>${<span>123</span>}</span> /&gt;`</span>
</code></pre>
<p>This expression is equivalent to:</p>
<pre><code>React.createElement(<span>"div"</span>, { <span>arg1</span>: <span>"abc"</span>, <span>arg2</span>: <span>123</span> })
</code></pre>
<p>In this case, <code>React.createElement()</code> directly creates virtual DOM data.</p>
<h4 id="jsx-in-action">JSX in action&nbsp;&nbsp;</h4>
<p>Let’s go back to the initial code:</p>
<pre><code>html<span>`&lt;<span>${CountingClicks}</span> rootModel=<span>${rootModel}</span> /&gt;`</span>
</code></pre>
<p>What is happening here?</p>
<p>We are invoking the component <code>CountingClicks</code> (a function) and pass it a single parameter, whose label is <code>rootModel</code>. This is what the root model looks like:</p>
<pre><code><span>const</span> rootModel = {
  <span>numberOfClicks</span>: <span>0</span>,
};
</code></pre>
<h3 id="the-component-countingclicks()">The component <code>CountingClicks()</code>&nbsp;&nbsp;</h3>
<p>The component is implemented as follows:</p>
<pre><code><span><span>function</span> <span>CountingClicks</span>(<span>{rootModel: initialRootModel}</span>) </span>{
  <span>const</span> [rootModel, setRootModel] = useState(initialRootModel); 
  <span>return</span> html<span>`
    &lt;div&gt;
      &lt;a href="" onClick=<span>${handleIncrement}</span>&gt;
        Number of clicks: <span>${rootModel.numberOfClicks}</span>&lt;/a&gt;
      &lt;p /&gt;
      &lt;button onClick=<span>${handleReset}</span>&gt;Reset&lt;/button&gt;
    &lt;/div&gt;
  `</span>;

  <span><span>function</span> <span>handleIncrement</span>(<span>event</span>) </span>{
    
  }
  <span><span>function</span> <span>handleReset</span>(<span>event</span>) </span>{
    
  }
}
</code></pre>
<p>The component returns a single virtual DOM element, a <code>&lt;div&gt;</code>. We use the <code>${···}</code> syntax to insert values into the returned data:</p>
<ul>
<li>The click event handler <code>handleIncrement</code></li>
<li>The number <code>rootModel.numberOfClicks</code></li>
<li>The click event handler <code>handleReset</code></li>
</ul>
<h4 id="handling-state-via-the-usestate-hook">Handling state via the <code>useState</code> hook&nbsp;&nbsp;</h4>
<p>The function call <code>useState()</code> in line A adds <em>reactivity</em> to our code:</p>
<ul>
<li><code>rootModel</code> is the current model data (the M in MVC).</li>
<li><code>initialRootModel</code> is the initial value of <code>rootModel</code>.</li>
<li><code>setRootModel</code> can be used to change <code>rootModel</code>. Whenever we do that, React automatically reruns the <code>CountingClicks</code> component so that the user interface always reflects what’s in the model.</li>
</ul>
<p>Never mind <em>how exactly</em> React does this! There is a ton of magic going on behind the scenes. Therefore, it is better to think of <code>useState()</code> as a language mechanism rather than as a function …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://2ality.com/2020/08/minimal-react.html">https://2ality.com/2020/08/minimal-react.html</a></em></p>]]>
            </description>
            <link>https://2ality.com/2020/08/minimal-react.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24276175</guid>
            <pubDate>Tue, 25 Aug 2020 21:12:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tipe raises $2.1M seed round to build a customizable CMS for developers]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 41 (<a href="https://news.ycombinator.com/item?id=24275948">thread link</a>) | @tmvnty
<br/>
August 25, 2020 | https://tipe.io/blog/tipe-raises-seed | <a href="https://web.archive.org/web/*/https://tipe.io/blog/tipe-raises-seed">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Today we're excited to announce that tipe has raised $2.1m in seed funding led by CRV and joined by investors YC, M Ventures, and Precursor Ventures. This investment will help tipe deliver an excellent experience for developers and teams who need a better workflow for managing content. Since graduating from YC's Winter 18 batch, we've been building prototypes, talking with users, and learning from the community. We're finally ready to show everyone what we've learned.  </p><p>Teams are shifting away from legacy site builders to more sophisticated builds with frameworks like Next.js and Gatsby. Cloud computing, crawlers, and JavaScript have all approved and come together to enable this shift. Jamstack offers so many benefits for low effort but also introduces more decision making. Teams must now decide on a content workflow, and developers are on the hook to figure it out.</p><p>We want to make this decision easy for developers. </p><h2>Make it your own, together</h2><p>They always say, "...never build a CMS". We know every team has different needs and use cases when it comes to content workflows. Customization and extendability are at the core of tipe's design.  That's why tipe is open-source and has a simple plugin features that make it easy for you to create your own CMS.</p><p>We invest in the open-source community and all the efforts to create and maintain the fantastic projects leading the Jamstack wave. We encourage developers to use plugins and extensions for tipe created by the community. One of our goals is to make sure we're not another app devs have to maintain, so we'll be working with developers to make sure working with tipe stays lean and fast. </p><p>We can't do this alone, so today we're launching the <a href="https://join.slack.com/t/tipe-hq/shared_invite/zt-gfesfzxf-9KHj1Q3GPhUbUOa6PjNpTA">tipe community slack</a>ðŸŽ‰. You can interact with the tipe team more closely, see what the community is cooking up, or even get help for anything that comes up. </p><h2>Roadmap to the best experience</h2><p>Developer and user experience are our main focuses here at tipe. As we grow, we want to move towards a minimal and straightforward product to use but powerful when combined with plugins and extensions. To achieve this goal, we plan on maintaining transparency about the direction of tipe and what's coming next. We'll also be leaning on our users and the community to help us build something that they would love. </p><p>To start, we have support for Jamstack frameworks like Next.js and Gatsby, a CLI to get started without ever visiting our web app, and SDKs to query content. As the community grows and improves tooling, we'll support all that comes from it. Open-source is are core, well before tipe, and will remain that way as we grow. </p><h2>Perfect timing</h2><p>The web is transitioning into another era with all the moving pieces seeing significant enhancements. Now is the time to build a fast experience for your users. You can't do that if your team is slow, because of content changes or any reason.</p><p>We look forward to helping teams stay fast as they deliver amazing journeys for their users. Also, <a href="https://tipe.io/jobs">we're hiring</a>! If anything you read here resonates with you, we'd love to hear from you. </p></div></div></div>]]>
            </description>
            <link>https://tipe.io/blog/tipe-raises-seed</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275948</guid>
            <pubDate>Tue, 25 Aug 2020 20:51:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to not fear your death: An Epicurean perspective]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24275882">thread link</a>) | @diodorus
<br/>
August 25, 2020 | https://psyche.co/guides/how-to-use-philosophy-to-overcome-the-fear-of-your-own-death | <a href="https://web.archive.org/web/*/https://psyche.co/guides/how-to-use-philosophy-to-overcome-the-fear-of-your-own-death">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><h2 data-guide-section-number="1"><span>Need to know</span></h2><div><p>Your demise is inevitable. I hope that doesnâ€™t come as too much of a shock. I agree that the brevity of human existence is bothersome. Thankfully, for most of us, this frightful fact usually hovers somewhere beyond the margins of our consciousness: weâ€™re â€˜awareâ€™ of our death without constantly fearing it.</p>
<p>Inevitably, though, there are moments when the reality of our eventual death strikes us in a new, chillier light. A close call demonstrates the tenuousness of life, or the death of a loved one reminds us that no one is exempt from humanityâ€™s ultimate destination. Even talking about death, as we are now, can be enough to bring on a ruminative contemplation of the end, and with it a shudder of fear about oneâ€™s own extinguishment.</p>
<p>In these moments, when your pending dissipation presents itself afresh, the fact of death is <em>experienced</em> in a new way. Rather than merely being â€˜knownâ€™ like one more quotidian statement about the world â€“ â€˜The sky is blue. I will dieâ€™ â€“ the sense of oneâ€™s ending is felt more deeply and more immediately. In these moods, the terror of death seeps into your awareness of yourself as a person; its awesome inevitability and finality makes you feel small and powerless. This is the fear of death at an existential level, brought on by the almost unthinkable notion that there is and only ever will be one of you â€“ and sooner or later it will flicker out of existence, leaving little more than memories in other soon-to-be-gone beings. The fear of death as Iâ€™m discussing it here is not about the practical worry of who will pay off your credit card debt after youâ€™re gone: itâ€™s about the unsettling fact that the person who earned that debt in the first place is but a fleeting speck of an event in the infinite history of the Universe.</p>
<p>The fear of death is also heightened by thinking about how harmful mortality is to us â€“ how there is no greater blow in life than for life to cease. As the philosopher Thomas Nagel observed, death is the great deprivation. There is always more life to be lived, and it is painful to have that taken away. The best way to get at this fear, perhaps, is to contemplate the almost unbearable thought of your future absence: one day, at family dinners, a place will no longer be set for you. The day after you die, the newspaper will still be published just as it was the day before. And the morning after your funeral, friends will make their morning coffee. You will be gone for good, though, and that certainly is a terrifying impediment.</p>
<p>So the fear of death is awful to behold â€“ and therefore, naturally, something to overcome. Indeed, the striving to overcome the fear of death, I would suggest, has stimulated a great deal of thinking over the course of humanityâ€™s time on Earth: one could go so far as to say that working out how to thwart, or perhaps accommodate, death sits at the root of a vast number of cultural achievements. The fear of finitude is a powerful propellant.</p>
<p>So how <em>can</em> the fear of death be overcome? One popular strategy is to plan for a sequel to life, which, itâ€™s usually expected, will take place in another, happier realm. Resurrection, whether as a human or otherwise, has won a great many adherents. And there have been several religions, as well as philosophers, that have promulgated a view of time as cyclical: weâ€™ve done this before, and weâ€™ll do this again. Death as a mere interlude.</p>
<p>These tactics and ideas have something to recommend them, certainly. But for now, letâ€™s set aside all possibility of life after death so that we are left with the often horrifying thought: you exist, but one day you wonâ€™t. Are there any good philosophical reasons not to fear that gulf â€“ between being and not-being? In this Guide, I will suggest several philosophically inspired reasons not to be fearful of your own death â€“ and so, in that sense, I hope that there is something helpful here to lighten the weight of the deeply unsettling existential state in which we are all lucky enough to find ourselves.</p></div></div></section><section><div><h2 data-guide-section-number="2"><span>What to do</span></h2><div><p>The life of the city-dwelling Ancient Greek philosopher Epicurus straddled the 3rd and 4th centuries BCE. His philosophy nowadays is popularly packaged as a kind of light hedonism: sensualist, joyful, a hint of luxury, a naughty second glass of wine. Though Epicurus himself was probably not quite the blinkered and unimaginative pleasure-seeker that these clichÃ©s suggest, they do give a flavour of his outlook.</p>
<p>For him, the purpose of human life is to achieve happiness. Epicurus construed this as an absence of pain rather than a positive programme of indulging oneself by, say, keeping up a rigorous schedule of orgies or downing flasks of opium on Tuesday mornings. He recognised that whatever temporary excitement such pursuits yield in the moment will probably be well counterbalanced by a severe price to pay later on. So instead, Epicurus recommended (somewhat disappointingly) that it is <em>moderation</em> that will lead to a release from pain and suffering, which in turn will bring a respectable measure of happiness and therefore a good life. Our limitations, our meagre certainties, are at the centre of Epicurusâ€™ system of thought, and it is in this context of mitigating pain and accruing a gentle happiness that he believed the fear of death needs to be understood. Epicurus and his followers held that the fear of death is harmful to the enjoyment of our lives, and so showing why this fear isnâ€™t well-founded contributes to the overall hedonic project of living well.</p>
<p>According to this tradition, the first thing to do to overcome the fear of death is to try to articulate to yourself what it would be like to <em>be</em> dead. Imagine <em>yourself</em>, but rather than alive â€“ dead. (Remember, weâ€™ve cast aside the afterlife.) As youâ€™ll swiftly appreciate, there is an intractable contradiction right at the centre of this first actionable item. You cannot imagine what it would be like to be dead, because death is an absence of existence. There is, literally, nothing to imagine â€“ because nothingness itself cannot be imagined. There is no perspective, no view from nothingness, nothing to which it can be approximated. So that is the first recommendation: realise that being dead isnâ€™t an experience. Death itself isnâ€™t really a <em>thing</em> at all. In Epicurusâ€™ words: â€˜Death is nothing to us.â€™</p>
<p>To drive the point home, letâ€™s turn to the Roman poet Lucretius. He was a saltier and more ironic Epicurean of a later generation, the 1st century BCE, whose unexampled poem <em>On the Nature of Things</em> fell afoul of early Christians because of its crypto-atheism. In the poem, Lucretius proposes an idea, later termed the â€˜Symmetry Argumentâ€™, that hints at the second thing you should do to overcome the fear of death: try to recall what it was like before you were born. Not how the world was, which is the task of historical imagination, but what it was like to <em>be</em> you â€“ before you were created. Youâ€™ll discover that prenatal existence isnâ€™t something that can be thought about, much less experienced. The symmetrical part of the argument, of course, is that you have the very same difficulty in imagining what it is like to be dead. Indeed, according to Lucretius, you-pre-existence is the same thing as death or post-existence: both involve the absence of you. No doubt you donâ€™t fear your prenatal existence and logically speaking, given their equivalence, it follows that you should fear death the exact same amount, as in not at all. (As the novelist Vladimir Nabokov put it in his memoirs: â€˜common sense tells us that our existence is but a brief crack of light between two eternities of darkness.â€™)</p>
<p>This brings us to the third thing to do to calm your existential angst: examine how much â€˜nothingâ€™ â€“ nonexistence â€“ can reasonably be feared. That is, are there any good reasons for your pending death to trigger the emotion of fear? It is reasonable to be fearful of things to the extent that those things can cause you harm. It was reasonable to be jittery about nukes during the Cold War era; it is reasonable to be scared that humanity is turning the globe into a sauna; and it is reasonable for your heart to launch as from a trebuchet into your throat when your partner says to you the words â€˜We need to talk.â€™ These are all identifiable threats that foretell awful experiences. None of them would help us in our Epicurean goal of being happy, and so are reasonably feared.</p>
<p>But death itself â€“ not the process of dying, which is something different â€“ doesnâ€™t seem to be the sort of thing that one can reasonably be fearful of because it isnâ€™t anything. Itâ€™s not uncomfortable or hurtful to <em>be</em> dead. Itâ€™s not as if youâ€™re being deprived of life or of more contented years because, again, you simply arenâ€™t <em>there</em> to be deprived in the first place. For you, there is nowhere to locate the harm of being dead since being dead isnâ€™t a state of being. Itâ€™s not something that strictly speaking happens to you and so it canâ€™t be harmful. (No one would say St Francis of Assisi is <em>more</em> dead than the punk rocker â€˜GGâ€™ Allin because St Francis died longer ago.) Death is the absence of an event; itâ€™s not a happening or a thing at all because there isnâ€™t such a thing as you any longer. Even something that you dreamed or imagined â€“ say, a stranger standing silently by your bed as you wake â€“ has a kind of existence necessary for it to be the reasonable object of a fear, even if it turns out to have been the shadow of a tree. Death itself doesnâ€™t have this quality. And Lucretius would add: it is just as unreasonable to fear nonexistence after life as it is to fear nonexistence before birth.</p>
<p>This is the heart of Epicurusâ€™ and Lucretiusâ€™ argument for why there is no good reason to fear death. Note that their argument doesnâ€™t speak to the fear that others will die, which is a perfectly reasonable anxiety and one that we should …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/guides/how-to-use-philosophy-to-overcome-the-fear-of-your-own-death">https://psyche.co/guides/how-to-use-philosophy-to-overcome-the-fear-of-your-own-death</a></em></p>]]>
            </description>
            <link>https://psyche.co/guides/how-to-use-philosophy-to-overcome-the-fear-of-your-own-death</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275882</guid>
            <pubDate>Tue, 25 Aug 2020 20:45:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DevOps, DataOps, and MLOps: the three waves of operationalization]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24275856">thread link</a>) | @mvartak
<br/>
August 25, 2020 | https://blog.verta.ai/blog/the-third-wave-of-operationalization-is-here-mlops | <a href="https://web.archive.org/web/*/https://blog.verta.ai/blog/the-third-wave-of-operationalization-is-here-mlops">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>

<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>Using machine learning models in products is hard. Most companies fail at extracting value from them because they can't operationalize models properly.</p>
<!--more-->
<p>We have gotten good at creating models and iterating on them, but <a href="https://venturebeat.com/2019/07/19/why-do-87-of-data-science-projects-never-make-it-into-production/"><span>most companies still don't use them well</span></a>. A model with acceptable performance that you can use is better than a great model that you can't. Then why are companies having so many issues leveraging them?</p>
<p>In this blog post, we show that some challenges are analogous to those before DevOps. We’ll also show that others introduce a new level in the development and operation process that requires a new stack.</p>
<p>The lessons here come from building ML products and platforms at companies like Twitter, NVIDIA, Cloudera, Google, and others. These companies have invested heavily in building their in-house ML platforms or external products for a variety of scenarios.</p>

<h2><span>Moving development closer to operations</span></h2>
<p>Two decades ago, software development was painful. Developers and operators were silos, and making any changes was an adventure. DevOps helped us fix that with a simple shift in mindset: developers should own their software end-to-end, and operators should support them. Operators could focus on building robust IT infrastructure instead of handling each application individually. Meanwhile, developers could speed their development practices by using the tools as their product demanded. This change was the first wave of operationalization, and it changed how we do software.</p>
<p><img src="https://lh5.googleusercontent.com/AzBl9kIU1PCLQLTZQ91tKPpn7bAmjghns_vNHPdloZ-V3XytDuyTemoZn96xA_QEgwuxrVG5vxqSBFixSx2hEtOhiawWdwQ_Ix7TYS_sQ1A5pxbrFhGtT4cWw7rewEymlJqtQ1ya" width="453" height="283"></p>
<p><span>Around the same time, data started to become more relevant via analytics. The goal was to understand the data companies had available. Seeing the success of DevOps, analytics professionals partnered with their operators to create DataOps. In this case, analysts could focus on their business use case while operators made their use reliable.</span></p>
<p><span>Today, machine learning faces a similar challenge. The goal of ML is to help products make decisions on the spot. For example, which messages to show from a search query. These applications focus on actively improving the business instead of just providing insights. However, these more complex applications also have requirements we had never seen, and the operations world is just starting to adjust.</span></p>
<p><span>We now face a similar challenge for model developers that we have encountered before in software development:</span></p>
<ul>
<li><span>Data scientists don't own their work end-to-end. Instead, they send their models to a software developer and data engineer to build the machinery on a case by case basis.</span></li>
<li><span>Data scientists are frequently blocked, waiting for other developers to help them.</span></li>
<li><span>Data scientists are blind to the processes required to satisfy operations until it's too late. In which case, the work is dropped or re-done.</span></li>
</ul>
<h2><span>Why MLOps is so hard</span></h2>
<p><span>Using ML models in products is a quantum leap in their value, and every such significant change comes with paradigm shifts. Not only MLOps is hard on itself, but most companies are not prepared to practice it today if done naively. The challenges of adopting MLOps boils down to:</span></p>
<ul>
<li><span>You have to support multiple pre-existing tools in two isolated ecosystems;</span></li>
<li><span>Models have more dimensions in their requirements, and operate on a broader range of each trade-off;</span></li>
<li><span>You need to provide a self-service ecosystem for data scientists that currently don't have the operations skills that developers do;</span></li>
<li><span>Companies' processes on using ML must start where they're at today and adapt as their use advances;</span></li>
<li><span>ML adds an entirely new layer to the operations stack.</span></li>
</ul>

<h4><span>MLOps challenge 1: pre-existing ecosystems</span></h4>
<p>Software development and model development have pretty mature ecosystems today, with constant and fast improvements. However, these ecosystems are mostly isolated. Consider a core piece of infrastructure: the workflow system. Software engineers will most likely use Jenkins, GitLab, CircleCI, or any similar tools. However, data scientists use Airflow, Kubeflow, and other ML-targeted workflow systems. These two ecosystems might eventually combine, but this can take years and a lot of effort. Instead, we need to meet them where they are today.</p>

<p><img src="https://lh4.googleusercontent.com/GV0KR8tRUGnuk80NmXXCdUuZPwkoupXwKLisbeq2e8-wpmyqjKY0CMMmx6QwafOC61QboUsIC58ZegUYS4hSrfM8VO1Gbv7fgULTyuFPcH14hM_uQGgp1kFchIqQFEfJsAapbInQ" width="277" height="305"></p>
<p>From the data scientist's perspective, they need the infrastructure to be reliable. It should work in the way that they want almost always and provide all the functionality they want to use but not develop. The researcher isn't concerned with which tools achieve this goal, as long as it works with their current solutions.</p>
<p>On the other hand, IT provides a vibrant ecosystem of productivity tools, but they require applications to behave in a particular way. The challenge operators face with data science today is that adapting all those practices to the ML ecosystem is difficult and time-consuming. So they need the ML applications to look like applications they already support.</p>
<p>This golden standard is hard to achieve. Therefore most companies end up with multi-year migration projects that change how everyone does their job simultaneously. As you can imagine, these projects fail most of the time. Instead, we need to figure out how to get these two personas to collaborate first and get value from each other.</p>

<h4><span>MLOps challenge 2: dimensions of model requirements</span></h4>
<p>In modern software development, the system's requirements are usually pretty narrow, so tools can be more focused. Models not only have more dimensions, but the placement of a solution is also fuzzier.</p>
<p><img src="https://lh6.googleusercontent.com/6emah1WRzYxr97IHXpSJzKyeweuXtc3weSwUWtwBrXYJpVhg3keKrtaH_OszAh_Y6UYcaTXYX_OuqPw8DpncM_VmISOvpy58jzleK1VWUoMWV0nezh2doT64UeF0B-gvBwS_UhWX" width="487" height="426"></p>
<p>These are just a few examples of standard dimensions considered and it’s by no means an exhaustive list. Note how software usually lies on clear points in the spectrum. For instance, you know if the application provides an HTTP endpoint or runs in the user's device. Unsurprisingly, that is generally not the case for models. During the lifecycle of the model, from conception to use in a product, the same model might be at different places in the requirements balance. Using the same example, we might not use the end device for computing our test metrics due to speed concerns, but use the model as a library instead.</p>
<p>Most companies start to deploy models by building a solution for a particular case and ignoring others. Then they patch it a little bit to adapt to another model or another use case of the same model. And again, until they end up with a system that is hard to use, change, and maintain.</p>
<p>In which case, new users might consider it's easier to build their own from scratch for their use case. That's how many companies, including big tech ones, end up with multiple internal ML platforms if they're not careful. Keeping in mind the diversity of requirements, even within a single project, is an essential but challenging effort.</p>

<h4><span>MLOps challenge 3: self-service operations for data scientists</span></h4>
<p>One of the core tenets of DevOps is that developers should own their applications end-to-end. To do this properly, operators needed to provide mechanisms for their users to self-service. It allows IT to scale to multiple customers and removes delays waiting on someone else to provide some tooling.</p>

<p><img src="https://lh6.googleusercontent.com/hcT3ffqnaPw9OltYcczXKEgqjt2IHm1xB0O6vuPt2THWRmkHK62dKJ3dwdlm2UajB3mdtN4RskM3CbCJ_L9nh0cU-1pA56x9PtBziPQitU28STuw5NQMpJXaBXOxZFlQmfHLEr1i" width="499" height="326"></p>
<p>The image above covers a few of the functionalities most companies will have in their self-service platform. IT provides tools and processes for core functionalities, focusing on providing a solid foundation. Meanwhile, developers define customizations on top of the platform or perform integration for their particular application. Companies have been reducing the distance between developers and operators for many years now, which allowed lower-level constructs to be used. However, that is not enough for researchers.</p>
<p><img src="https://lh6.googleusercontent.com/4zjcm39V61mB1y4PWkJvzrrkHAVzBG6R9KKwChTHJUe81tr87ppMc2aq1DrppBgbnUXdkbJWVQUvQP0PdMlk5xpMZommxEkhKsSxmWoaZLoQ_lrv4yE2a3dFGnv79oguFTUL4yqD" width="499" height="326"></p>

<p>As we have argued before, data scientists' current skill set is very distinct from bringing up and operating one of their models in production. Hence the platform provided for researchers needs to be at a higher level than for software developers. For example, developers know how to define their systems' behavior to ensure it meets a particular SLA. But data scientists want to specify what those SLAs are and rely on a platform to handle the complexities to achieve that.</p>
<p>Thankfully the industry started to make higher-level constructs available for software engineers too. As anybody would suspect, operating low-level definitions is a considerable overhead. However, the further away you get from the specifics, the more domain knowledge you need to embed in the platform. Unfortunately, not every operations team has this knowledge at hand to support ML applications.</p>

<h4><span>MLOps challenge 4: adapt to existing processes and grow with the company</span></h4>
<p>Every big software company has a set of processes in place for software development. These processes took years and many iterations to develop correctly, potentially including expensive mistakes. When thinking about using models in production, teams frequently face the challenge of building these processes from scratch.</p>

<p><img src="https://lh5.googleusercontent.com/755p1w0mxyZwNwQFrwm_C2OLPIfMS-OAoOrRN5DjfAx2Z_70kHhNRvDRQk4L-Ygu3bnZRBkweEyRrtr8AlGKKQVQFFES7-yXnceVLGkI8VkBLNVh5yhrn5eyNDjmNTcrUvw_Yky9" width="452" height="285"></p>

<p>However, at the start of the ML journey, most operations constraints will look similar to doing software engineering. Operationalizing ML has higher success at places that first adapt their current processes the best they can. Once they have that initial version, the team iterates on the process as they identify improvements related to the new application domain or new product requirements.</p>
<p>This evolution of processes means that platforms and infrastructure must be able to adapt along with their teams. As new regulations and customer requests evolve, so will the requirements and limitations on model development and execution. Switching to a new system every time that happens is expensive. But relying on external enforcement is prone to misalignment failures. Hence production ML needs to meet users where they are today to bring immediate value while supporting the evolution of their ML methodologies.</p>

<h4><span>MLOps challenge 5: new layer at the operations stack</span></h4>
<p>This challenge is potentially the most undervalued one for MLOps: adding models creates an entirely new layer to the operations stack. In a simplified way, each level of the operation stack covers the unit of computation, how …</p></span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.verta.ai/blog/the-third-wave-of-operationalization-is-here-mlops">https://blog.verta.ai/blog/the-third-wave-of-operationalization-is-here-mlops</a></em></p>]]>
            </description>
            <link>https://blog.verta.ai/blog/the-third-wave-of-operationalization-is-here-mlops</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275856</guid>
            <pubDate>Tue, 25 Aug 2020 20:43:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eight Lessons I Learned from Hiring a Writing Coach]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24275828">thread link</a>) | @aml183
<br/>
August 25, 2020 | https://www.arilewis.com/aris-posts/nb79cps2558ad5k88qusj2g761nph0 | <a href="https://web.archive.org/web/*/https://www.arilewis.com/aris-posts/nb79cps2558ad5k88qusj2g761nph0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-ff90fafa3d7cc2ce1565"><div><p>The best athletes in the world have personal trainers: LeBron James, Serena Williams, Megan Rapinoe. I knew that to be the best, I needed to hire a writing coach to take me to the next level.</p><p>As a species, we have a monopoly on collective knowledge. So engaging with a mentor or a coach is one of the best ways to become smarter. A good friend referred me to his writing coach, who lives outside the Cleveland region. Now I value a good referral, but I also value relationships — and we've got plenty of expertise in this region. In Cleveland, relationships remain key — over the course of the pandemic, and long after.</p><p>I wanted to become an even better writer simply to see where it would take me. I enlisted the help of Randal Doane at&nbsp;<a href="https://cadence-editorial-neo.com/about/" target="_blank">Cadence Editorial Services</a>. (He works with clients in medtech and biotech, and he has a side hustle contributing to&nbsp;<a href="https://harpers.org/author/randaldoane/" target="_blank">Harper's</a>.) Randal's based on the west side, and his knowledge of the region and some of its key players allowed us to talk at a high level about things well beyond split infinitives and paragraph breaks. He is also knowledgeable about a range of topics, which is apparently what happens when you have a Ph.D.</p><p><strong>How did it work?</strong></p><p>To begin, our process entailed:</p><ul data-rte-list="default"><li><p>my delivery via Google Docs of essays to Randal on Monday and Wednesday by 11 a.m.</p></li><li><p>a Zoom chat at 3 p.m. those days, which included line-by-line discussions of my draft, with a focus on pop, voice and formatting</p></li><li><p>work on my social media voice, and in particular Twitter</p></li></ul><p>Before connecting with Randal, I published nine essays a month: eight for my newsletter and one for Crain's Cleveland Business. In that period, I learned quickly that quantity doesn't equal quality.</p><p><strong>Key tips</strong></p><p>We covered, of course, the obvious things. Make verbs active. Use the historical present. Put subheads to work, because some readers will simply scan your article. "Be honest about your own attention limits," Randal also advised. "If it takes you 20 minutes to get into a writing head space, don't schedule a 30 minute writing session. You're just building frustration into your process." Randal also taught me how to split quotes and put the speaker's name in the middle.</p><p>I'd be lying if I told you I'm on a schedule, but it's definitely getting better. Typically, I'd write from 10 p.m. to 1 a.m. (Yes, I'm a night owl. It works for me. Per Randal's suggestion, I wrote this essay on a Monday morning. A huge accomplishment for me!)</p><p>Next, on Randal's recommendation, I downloaded&nbsp;<a href="http://www.hemingwayapp.com/" target="_blank">the Hemingway app</a>. This app helps you make your writing more succinct. If you want to be a better writer, download it.</p><p>Writing isn't only about words. It's about appearance, too. So what's the best way to engage readers in the attention economy? I started crafting multiple headlines and subheads and using bold words strategically. I also aim to ensure that every sentence delivers value. With my essays on branding and digital platforms, I aim to deliver reader-friendly, thought-provoking content every time.</p><p>Once I finished my first draft, I'd read it aloud. What a difference that makes. "Your ear will pick up things your eye scans past," Randal noted. Awkward phrasing, subject-verb disagreement, and run-on sentences: You name it, I wrote it, and now my ear knows better. In my defense: My mom served as my proofreader for ages, so I was pretty lazy about proofreading.</p><p>Finally, I'd send it to Randal. His edit focused on the Cs of writing: clarity, concision and cadence. We'd connect by phone and Google Docs and, on an unmarked copy of the essay, he would introduce his suggestions one by one. Every time Randal dropped a knowledge bomb, I scooped it up, defused it, and either applied it right then or filed it away for future engagement.</p><p>So what did the finished product look like?</p><p><strong>The results</strong></p><p>Right away, I saw how my writing improved, and my readers took notice, too. "These pieces are getting better and better," one reader wrote. "I find myself wanting more though. Ever thought about bringing them up to 750-1000 words instead of what seems like 450-650?" I think a big part of it was sentence length. With Randal's help, I trimmed median sentence length by 27% and still increased the variety of sentence lengths by 12%.</p><p>Wow! Not only was I enjoying the writing more, my readers wanted me to write longer pieces. My list of subscribers kept growing, too. In the month and a half I worked with Randal, my newsletter list increased by 49%. My open rate is solid, too, and 170 new people signed up to read my writing twice a week.</p><p>But the biggest accomplishment was from my mom. The self-described "perfectionist" was always supportive of my work, but definitely critical. As a proofreader in her past life, she was obsessed with finding the mistakes. By the end of my coaching boot camp with Randal, she complimented me on how much my writing had improved.</p><p><strong>More than just words on the page</strong></p><p>Our work entailed more than writing. It included work on my personal brand. Randal kept asking: Who is Ari Lewis? Why does he write? Who is his audience? What do they need from him?</p><p>Today, I'm building my niche in the attention economy. Every week I'm proud to share close to 800 words across my platform. It's fun to go back and review previous essays to see the difference in the thinking and the writing.</p><p>Another key thing I learned is the importance of brevity. I know I have plenty of room for improvement. Still, I'm putting in the hours and enjoying the process. Hiring a coach made a huge difference.</p></div></div></div>]]>
            </description>
            <link>https://www.arilewis.com/aris-posts/nb79cps2558ad5k88qusj2g761nph0</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275828</guid>
            <pubDate>Tue, 25 Aug 2020 20:39:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[If Humans Spoke in Vectors]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24275741">thread link</a>) | @KhoomeiK
<br/>
August 25, 2020 | https://rohan.bearblog.dev/humans-spoke-vectors/ | <a href="https://web.archive.org/web/*/https://rohan.bearblog.dev/humans-spoke-vectors/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div><p>Would we be as successful as we are now? I'd say no.</p>
<h3 id="what-are-semantic-vectors">What are Semantic Vectors</h3>
<p>But first, what does it even mean to communicate with vectors? Communication can be defined as the transfer of an idea from one person to another, and a semantic vector essentially tries to capture an idea in a numerical representation. Vectors have grown vastly in popularity in Natural Language Processing in the past decade, and now virtually all research in the field revolves around a basic assumption that vectors can effectively convey ideas.</p>
<p>The first commonly used semantic vector model, generally known as word embedding (as in embedding a word in a vector space), was <a href="https://en.wikipedia.org/wiki/Word2vec">word2vec</a> in 2013. Word2vec learns vector representations of words by encouraging words that occur in similar contexts to have similar vector representations. So, for example, if we have a corpus with examples like "the dog chased the cat", "the canine chased the cat", and "the rat feared the cat", word2vec would learn to represent "dog" and "canine" with similar embeddings. The generated vectors are generally hundreds of dimensions, but the embeddings for "dog", "canine", and "rat" in our example might look something like [0.3, 0.1, 0.8], [0.3, 0.2, 0.8], and [0.4, 0.6, 0.7], respectively. Notice the similarity of "dog" and "canine" due to occurrence in similar contexts in our corpus.</p>
<p>These were known as "distributional embeddings", because they were found to distribute semantic categories across vector dimensions. A commonly cited example points out how if you subtract the word embedding for "man" from "king", and then add "woman", you get "queen". So these high-dimensional vectors that learn word representations just from context are able to pretty accurately understand the relationships between words. Sure, they might not know what a king looks like, what he does, and his historic relevance, but they do know that he's similar to a man in some ways and similar to a queen in other ways.</p>
<h3 id="word-relations-and-differance">Word Relations and Différance</h3>
<p>These relations are what many of us will resort to when asked about the structure of language. A dictionary, after all, just refers us to other words when asked for any definition. The implicit conclusion here that without grounding in the real world, all words are purely relational, bears striking resemblance to <a href="https://en.wikipedia.org/wiki/Differance">Derrida's Différance</a>. The core of Différance, which became fundamental to Deconstruction and the Postmodernism that now dominates humanities, is the idea that words gain meaning only through their difference with (and deference to) others. Only in the real world, with speech, outside of the realm of paper, would Derrida acknowledge that an uttered symbol can present real meaning.</p>
<p>But virtually all Machine Learning research in Natural Language Understanding focuses on written text, so can any real meaning be derived? Again, I'd say no. All the colossal Deep Learning architectures that seem to dominate NLP these days don't actually understand language—they've just learned correlations between words in manners ultimately quite similar to the original word2vec. This is quite obvious with <a href="https://arxiv.org/abs/2005.14165">OpenAI's GPT-3</a>, which is able to produce text that sounds very realistically written by a human, but doesn't form any coherent meaning. The model has essentially memorized all the relationships between words from a huge corpus of internet text, but it can't know what those words mean without some kind of grounding in the physical world.</p>
<p>Some meanings can be largely summed up in these simple vector relationships, but others are quite a bit more complex. The relationship between "predator" and "prey", for example, is abstract enough that I'd pretty confidently say their meanings can be captured in some kind of vector representation. But the relationship between "knife" and "onion"? You as a reader probably know how those words are related, but I can't even begin to capture the nature of their relationship in language. Yes, we can "cut an onion with a knife" (and <a href="https://transformer.huggingface.co/doc/gpt2-large">GPT-2</a>) is actually capable of predicting "knife" here), but how does this action actually work? What is the purpose it serves? What do the words really mean?</p>
<h3 id="grounding-meaning">Grounding Meaning</h3>
<p>But we might be confusing two things here. Though these language models learn the meanings of words through their relationships and co-occurence with one another, we can think about definitions on their own as well. A classic example from Indian philosophy is that of the pot. What does it mean to be a pot? As humans, we're great at generating <a href="https://en.wikipedia.org/wiki/Theory_of_forms">Platonic Forms</a> from our real world experiences. Once we've seen a few pots, our brains are able to construct a pretty accurate generalized Form for pots, and when we see one again, we're easily able to recognize that it's another instance of this Form. This representation our brain learns is so much more information dense than what can be gleaned from language. It's imbued with an innate understanding of visual and physical attributes.</p>
<p><a href="https://arxiv.org/abs/1810.04805">Google's BERT</a> might read an article about pots and then tell us that pots are often made of clay, can be used as cooking vessels, and have been found in China from 20,000 BC. But ask BERT whether a pot with holes would be able to hold water and it'd have no idea. This could certainly be construed as a language issue instead of a grounding issue. Maybe we could find some more textual data that relates pots to holes and holes to water so that BERT can learn better semantic representations for them. The real solution to me though, would be to ground the language model in the physical world, perhaps with some kind of Reinforcement Learning strategy. If a picture is worth a thousand words and a video is worth a million, the ability to interact with a physical environment must carry a tremendous amount of semantic information.</p>
<h3 id="composing-and-comprehending-meaning">Composing and Comprehending Meaning</h3>
<p>While grounding is vital for learning accurate word representations, something even more elementary to me is the <a href="https://en.wikipedia.org/wiki/Principle_of_compositionality">compositionality of language</a>. Compositionality is the idea that the meaning of a sentence is a unique, synergistic result of combining the constituent words within it. It's closely related to Noam Chomsky's <a href="https://en.wikipedia.org/wiki/Recursion#In_language">Recursion</a>, which he asserts is the fundamental element underlying all human language. Recursion is the ability for us to infinitely nest expressions in language, much like this very sentence, where I can just continue chaining on clauses, again and again, until I desire to stop, at which point I may place a period in writing, or a pause in speech, and then continue on to present yet another idea.</p>
<p>And upon the conclusion of that sentence, there is a moment of understanding, where the meaning that I intend to express bursts forth in its entire form in your mind. Bhartrhari, an Indian linguistic philosopher of the 5th century, termed this "bursting forth" as "<a href="https://en.wikipedia.org/wiki/Sphota">sphoṭa</a>". The symbols, whether as letters on paper or sounds in speech, agglomerate together to create a unified meaning that is entirely comprehended in a single moment. Later on, the Mimamsakas built on this idea to emphasize that a sphoṭa is not indivisible as originally conceptualized, but rather is the result of the hierarchical composition of sounds, words, and clauses through grammatical structures.</p>
<p>The ability to compose words to generate coherent moments of understanding is vital to language in my opinion, and I'm skeptical of the ability of word vector embeddings to do this effectively. There has certainly been progress on this front in ML with <a href="https://arxiv.org/abs/1706.03762">Transformer architectures</a>. Previously, RNNs dominated the NLP landscape. These neural nets linearly process language one word at a time, feeding the collective representation of the sentence so far forward until an entire representation is outputted at the end.</p>
<p>The problem here, of course, is the severe loss of information due to the lack of syntax trees. While you may not actively think about parsing syntax trees of sentences, it's an essential prior for proper understanding of any language. Some languages like Japanese put their verbs at the end of the sentence ("cat mouse chased") whereas others like English put our verbs between the subject and object ("cat chased mouse"). It might seem trivial, but syntax has wide-reaching consequences for language understanding. If you were reading a text in an Object-Verb-Subject language ("mouse chased cat") without knowledge of the syntax and the consequent relations constructed in the sentence, you'd be very confused.</p>
<p>An interesting side-note here is that speakers of left-branching languages (which put the verb at the end of a clause) have been <a href="https://www.nature.com/articles/s41598-018-37654-9">shown</a> to have better short-term memories than right-branching speakers. This is theorized to be because speakers must maintain the multiple elements in their memory for longer before their related together by the verb. In a right-branching language, the sphoṭa builds from a subject, to the subject's relationship, to the subject's relationship to the object. But with a left-branching language, one first perceives the sphoṭa of the subject, remembers it while perceiving the sphoṭa of the object, then composes those sphoṭas in the final verbal relation.</p>
<p>The true nature of a sentence is more like a graph/network or a tree, and the fact that we communicate it linearly is more of an evolutionary hack we've developed to speak out of our single mouth. So when attentional models and Transformers came along, they blew RNNs out of the water because they were implicitly capable of understanding tree structures. The attention mechanism of a Transformer is much what it sounds like, it learns to pay attention to the right things at the right time. When given a sentence "the cat chased the mouse", for the first "the" it might attend to "cat", and for "chased" it might attend to "cat" and "mouse" in unique ways (which are the verb's subject and object). Attention learns how to correctly identify the syntax relationships for sentences, thereby arriving at better semantic representations.</p>
<h3 id="logic-or-statistics">Logic or Statistics</h3>
<p>Transformers, …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rohan.bearblog.dev/humans-spoke-vectors/">https://rohan.bearblog.dev/humans-spoke-vectors/</a></em></p>]]>
            </description>
            <link>https://rohan.bearblog.dev/humans-spoke-vectors/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275741</guid>
            <pubDate>Tue, 25 Aug 2020 20:29:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unity Lerp]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24275730">thread link</a>) | @generalistp
<br/>
August 25, 2020 | https://generalistprogrammer.com/unity/unity-2d-lerp-tutorial-in-depth/ | <a href="https://web.archive.org/web/*/https://generalistprogrammer.com/unity/unity-2d-lerp-tutorial-in-depth/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
	
<p>Welcome to this Unity 2D Lerp Tutorial. The Unity 2D Lerp function is often used to move objects along a path or to change values along a path. </p>



<p>However in essence LERP is code word for Linear Interpolation, but what is linear interpolation?</p>



<p>Well interpolation is a mathematical concept which is used to fit points within other points.</p>



<p>Essentially how this works is it takes a set of points and estimates other points for a given x or y value on a graph. </p>



<h2>Visually explaining Lerp</h2>



<p>Here is essentially what this would look like.</p>



<figure><img loading="lazy" width="570" height="400" src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2020/04/image-41.png" alt="Unity 2D Lerp Tutorial - Linear interpolation graph" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20570%20400'%3E%3C/svg%3E" data-lazy-src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2020/04/image-41.png"></figure>



<p>To explain this in brief. The green dots are all the co ordinates that are known.</p>



<p>The red one is a estimation of what the point will look like at that given x or y. So how Lerp works in unity is it will use the first point you give it and the 2nd point you give. </p>



<p>It and create estimations for the time value you pass in. By doing so you can get linear values back between the point 1 and point 2. </p>



<p>With these values you can modify scales, object positions etc, anything that has a linear motion or change. </p>



<p>Here is what the Lerp function definition looks like.</p>



<p>public static&nbsp;<strong>Lerp</strong>(Vector2&nbsp;<strong>a</strong>,&nbsp;Vector2&nbsp;<strong>b</strong>, float&nbsp;<strong>t</strong>);</p>



<p>So in terms of our graph Vector2 a could be the first green dot at the bottom of our graph and Vector2 b could be our last one at the top. </p>



<p>The float t, will move us along on the x axis and give us estimates of the line drawn between Vector a and Vector b. </p>



<p>In so doing if we step the time in our Lerp function we would be able to animate, move or modify unity game object.</p>



<p>I hope this makes sense. Can be quite tricky without a mathematical background. </p>



<p>You might begin to understand it more in depth with the following demonstrations.</p>



<h2>Demonstrating unity lerp between two positions</h2>



<p>Let’s start off with a new unity project. Open up unity hub and create a project called unity 2d lerp tutorial.</p>



<figure><img loading="lazy" width="815" height="386" src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2020/04/image-42.png" alt="Demonstrating unity lerp translate" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20815%20386'%3E%3C/svg%3E" data-lazy-src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2020/04/image-42.png"></figure>



<p>So generally when we say translate in the same sentence as lerp we talking about different things really. </p>



<p>Lerp will give us the next co ordinate in our series, where translate will add values to our vector. </p>



<p>It technically would be possible to simulate a lerp with translate. By using a linear function to determine the gradient of our linear graph. </p>



<p>However let us stick to the lerp way of doing a “translate”. This will be using the time function. Let’s start by adding a basic square to our scene.</p>



<p>So in the assets tab add a square 2d sprite like this.</p>



<figure><img loading="lazy" width="748" height="500" src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2020/04/image-43.png" alt="unity lerp between two positions tutorial" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20748%20500'%3E%3C/svg%3E" data-lazy-src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2020/04/image-43.png"></figure>



<p>Drag it into your hierarchy.</p>



<figure><img loading="lazy" width="306" height="114" src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2020/04/image-44.png" alt="" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20306%20114'%3E%3C/svg%3E" data-lazy-src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2020/04/image-44.png"></figure>



<p>Let’s now create the first basic c# script to handle a “translate”. Go ahead and right click in the assets tab and create a new c# script and call it translate lerp.</p>



<figure><img loading="lazy" width="853" height="446" src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2020/04/image-45.png" alt="" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20853%20446'%3E%3C/svg%3E" data-lazy-src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2020/04/image-45.png"></figure>



<figure><img loading="lazy" width="146" height="153" src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2020/04/image-46.png" alt="unity lerp translate tutorial" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20146%20153'%3E%3C/svg%3E" data-lazy-src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2020/04/image-46.png"></figure>



<p>Open that up in visual studio code. Here is what our code is going to look like.</p>



<pre><code lang="csharp">using System.Collections;
using System.Collections.Generic;
using UnityEngine;

public class TranslateLerp : MonoBehaviour
{
    // Start is called before the first frame update
    float accum = 0.0f;
    Vector2 p1, p2;
    void Start()
    {
         p1 = new Vector2(0, 0);
         p2 = new Vector2(20, 20);
        
    }

    // Update is called once per frame
    void Update()
    {
        accum += 1.1f * Time.deltaTime;
        this.transform.position = Vector2.Lerp(p1,p2, accum);
    }
}
</code></pre>



<p>Save that off and attach that to our square by dragging it into the insepector.</p>



<figure><img loading="lazy" width="365" height="447" src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2020/04/image-47.png" alt="unity lerp smooth tutorial" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20365%20447'%3E%3C/svg%3E" data-lazy-src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2020/04/image-47.png"></figure>



<p>Run that and you should get a square moving on the screen. So very simple how this works. </p>



<p>First we have our two vectors point 1 and point 2. We then lerp between the two passing the lerp function our deltaTime * 1.1f. The 1.1f which is our speed at which we want to move our object. </p>



<p>We assign this to a accum variable which is our lerp float over time. </p>



<h2>Modifying this code to lerp scale</h2>



<p>All we now need to do to get unity lerp to scale is change the code to have this instead.</p>



<pre><code lang="csharp">this.transform.localScale = Vector2.Lerp(p1,p2, accum);</code></pre>



<figure><img loading="lazy" width="402" height="255" src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2020/04/image-48.png" alt="unity lerp scale tutorial" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20402%20255'%3E%3C/svg%3E" data-lazy-src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2020/04/image-48.png"></figure>



<h2>Unity lerp smooth step</h2>



<p>Want to smooth out the motion try this.</p>



<pre><code lang="csharp">using System.Collections;
using System.Collections.Generic;
using UnityEngine;

public class TranslateLerp : MonoBehaviour
{
    // Start is called before the first frame update
    float accum = 0.0f;
    Vector2 p1, p2;
    void Start()
    {
         p1 = new Vector2(0, 0);
         p2 = new Vector2(20, 20);
        
    }

    // Update is called once per frame
    void Update()
    {
        accum += 1.1f * Time.deltaTime;
        this.transform.position = Vector2.Lerp(p1,p2, Mathf.SmoothStep(0,1,accum));
    }
}
</code></pre>



<p>Here we use Mathf.SmoothStep to control the estimation.</p>



<p>That’s it for this tutorial. Going to end it here and in the next section I will be answering some frequently asked questions. </p>


        <section>
            <div>
				<h2>How do I do a smooth lerp in unity?</h2>                <p>
						To do a smooth lerp you can use a smoothing function like Mathf.SmoothStep.                    </p>
            </div>
        </section>
	        <section>
            <div>
				<h2>How do I do lerp on scale in unity?</h2>                <p>
						To lerp on scale in unity you can simply provide 2 vectors and lerp over the localScale like this.<br>accum += 1.1f * Time.deltaTime;<br>this.transform.localScale = Vector2.Lerp(p1,p2, accum);                    </p>
            </div>
        </section>
	        <section>
            <div>
				<h2>How do I do a translate lerp in unity?</h2>                <p>
						You can lerp between two points like this.<br>accum += 1.1f * Time.deltaTime;<br>this.transform.position= Vector2.Lerp(p1,p2, accum);                    </p>
            </div>
        </section>
	



<h2>Some final words</h2>



<p>I hope this tutorial was useful and helped you understand lerp in a new way. If you want to support me and my content please check out my skillshare course here: </p>



<p><a href="https://skl.sh/2YhzEfe" rel="nofollow">https://skl.sh/2YhzEfe</a></p>



<p>If you prefer watching video over reading tutorials, why not subscribe to my YouTube channel over here:&nbsp;<a href="https://www.youtube.com/channel/UC1i4hf14VYxV14h6MsPX0Yw?sub_confirmation=1">https://www.youtube.com/channel/UC1i4hf14VYxV14h6MsPX0Yw?sub_confirmation=1</a></p>



<p>Here are also some other tutorials you might be interested in:</p>



</div></div>]]>
            </description>
            <link>https://generalistprogrammer.com/unity/unity-2d-lerp-tutorial-in-depth/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275730</guid>
            <pubDate>Tue, 25 Aug 2020 20:28:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Performance Impact of Parallel Disk Access]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24275722">thread link</a>) | @pkolaczk
<br/>
August 25, 2020 | https://pkolaczk.github.io/disk-parallelism/ | <a href="https://web.archive.org/web/*/https://pkolaczk.github.io/disk-parallelism/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <header>
  
  <time datetime="2020-08-24T00:00:00+00:00">August 24, 2020</time>
</header>

  <p>One of the well-known ways of speeding up a data processing task is partitioning the data into smaller
chunks and processing the chunks in parallel. Let’s assume we can partition the task easily, or the input data is already 
partitioned into separate files which all reside on a single storage device. Let’s also assume the algorithm we run on those
data is simple enough so that the computation time is not a bottleneck. How much performance can we gain by reading the files in parallel? 
Can we lose any?</p>

<!--more-->



<p>While working on <a href="https://github.com/pkolaczk/fclones">fclones</a> duplicate file finder,
I’ve put a lot of effort into making it as fast as possible by leveraging capabilities of modern hardware.
That’s why I designed my program in a way that all data processing stages can be easily parallelized. 
The newest version at the moment of writing this post (0.7.0) allows to set thread pools for random I/O 
and sequential I/O separately, and can adapt the settings to different types of storage devices.</p>

<p>In this blog post I’m presenting the results of a few experiments I’ve made separately on SSD and HDD.
All the experiments were perfomed on either a Dell Precision 5520 laptop with a 4-core Xeon and a 512 NVMe SSD, from 2016, 
running Ubuntu Linux 20.04, or an older Dell M4600 with a 7200 RPM Toshiba HDD running Mint Linux 19.03.</p>


<p>The most time-consuming part of the job is actually reading
the data from disk into memory in order to compute hashes. The number of files is typically large (thousands or even millions) 
and the problem of computing their hashes is embarrassingly parallel. 
The first thing my duplicate finder does is scanning directory tree and fetching file metadata like file lenghts and inode identifiers. 
This process issues a lot of random I/O requests. As expected, the performance gains from multithreading were huge, 
which is illustrated in Fig.&nbsp;1.</p>

<div>
    
    
    <p><span> Fig.1: Time to fetch metadata of ~1.5 million file entries on an SSD</span>
</p></div>

<p>In the next stage, the files matching by size are compared by hashes of their initial 4 kB block. This involves a lot of random I/O as well – 
for each file, <code>fclones</code> opens it, reads the first 4 kB of data, computes the hash and closes the file, then moves to the next file. 
SSDs are great at random I/O, and high parallelism level leads to big wins here as well (Fig.&nbsp;2). It was surprising to me
that even 64 threads, which are far more than the number of CPU cores (4 physical, 8 virtual), still improved the performance.
I guess that with requests of such a small size to such a fast storage, you need to submit really many of them to keep 
the SSD busy.</p>

<div>
    
    
    <p><span> Fig.2: Time to hash initial blocks of ~1.2 million files on an SSD</span>
</p></div>

<p>Let’s look at <code>iostat</code>. With only 1 thread, <code>iostat</code> reports CPU to be mostly idle, but
the SSD utilization is at 100%.</p>

<pre>avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           2,39    0,00    5,03    5,03    0,00   87,55

Device            r/s     rMB/s   rrqm/s  %rrqm r_await rareq-sz   aqu-sz  %util
nvme0n1       5458,00     21,32     0,00   0,00    0,11     4,00     0,00 100,00
</pre>

<p>Does it mean the SSD is already at its 100% performance? No, because 
<code>%util</code> is calculated as the ratio of <em>wall clock time</em> the device is serving requests. 
This doesn’t account for effects of submitting multiple requests at the same time.
It looks like my SSD is very happy to receive more load. With 64 threads,
<code>%util</code> is still at 100%, but the served read request rate went up by over 40 times:</p>

<pre>avg-cpu:  %user   %nice %system %iowait  %steal   %idle
          28,46    0,00   66,92    4,62    0,00    0,00

Device            r/s     rMB/s   rrqm/s  %rrqm r_await rareq-sz   aqu-sz  %util
nvme0n1     223974,00    874,90     0,00   0,00    0,17     4,00     0,00 100,00
</pre>

<p>BTW: why the average queue size <code>aqu-sz</code> remains 0,00 even under 64 threads remain a mystery to me. 
Feel free to drop any clues in the comments.</p>

<p>How do I known the CPU is not the main bottleneck here then? The CPU load numbers given by <code>iostat</code> are pretty high, aren’t they?
I measured how much time it takes to do the task when all the data were cached, by running it again, without prior dropping caches. 
When all cached, the metadata scanning took 1.5&nbsp;s and the partial hashing took 1.7&nbsp;s. This is still
significantly faster than when physical reads were involved, so nope, 
I/O is still the major bottleneck, even with 64 threads.</p>



<p>And what about the sequential I/O reads? Does parallelizing the sequential I/O improve speed as well?
It looks like it does, although not by as much as for random I/O (Fig.&nbsp;3).
The last stage of <code>fclones</code> algorithm is hashing full files – in this experiment the files were mostly JPG and RAW images, 
about 10 MB large on average. Gains seem to hit a plateau a bit earlier – after 8 threads. In this case the operating 
system has an opportunity to prefetch data, so
it can keep the SSD busy even when my application is not asking for data for a while.</p>

<div>
    
    
    <p><span> Fig. 3: Time to hash 21.6 GB of data read from an SSD in function of number of threads</span>
</p></div>


<p>Contrary to an SSD, a spinning drive has a large seek-latency and it can serve I/O requests
at much lower rate. Hence, we can definitely expect random I/O to be much slower on an HDD than on an SSD. 
But can we expect any performance gains from reading in parallel? 
My initial thought was there shouldn’t be any visible gains, because a single HDD can only serve 
a single read request at a given time, then it has to reposition the heads to “jump” to another file, and 
this looks very “sequentially” in principle. Having a large number of requests piled up in the queue 
shouldn’t change anything: the HDD would handle them in a sequence anyways. 
An HDD is also slow enough that even a single fast thread should keep it fully busy with at 
least one request ready to serve at any time.</p>

<p>I was wrong. It turns out that for small, random I/O requests there are noticeable gains from parallelism 
even on an HDD (Fig. 4). But this happens for a different reason than on SSD. 
The seek latency depends heavily on the <em>order</em> of the I/O requests. If the process submits more
I/O requests from multiple threads, the operating system can <em>reorder</em> them by physical data location, thus minimizing
the distance the HDD heads have to travel.</p>

<div>
    
    
    <p><span> Fig.4: Time to hash initial blocks of 46,165 files on a 7200 RPM HDD</span>
</p></div>


<p>Unfortunately, when reading larger chunks of data sequentially, using multi-threding actually hurts the throughput (Fig.&nbsp;5).
This is because the operating system interleaves the I/O requests coming from different threads and the HDD would have
to reposition the heads frequently jumping from one file to another. How much throughput is lost depends heavily on the operating
system and its configuration, but generally I’d expect this to be a factor 2x-10x.</p>

<div>
    
    
    <p><span> Fig.5: Time to hash 1.7 GB of data on a 7200 RPM HDD</span>
</p></div>

<p>One way of solving this problem in an application is to not allow many threads to contend for the same HDD device at the OS level, and 
instead make the application take some control over the I/O request scheduling by itself.
You can use a dedicated single thread to handle all I/O to a single spinning drive (this is what <code>fclones</code> does since version 0.7.0),
or guard I/O operations by a critical section (mutex) associated with each HDD and locked at a granularity coarse enough that
seek time doesn’t matter. I don’t recommend making the whole application single-threaded, because that would disallow
issuing parallel requests to multiple devices and it wouldn’t allow the gains outlined above.</p>

<p>Additionally, many operating systems allow to tell the kernel that the application will be reading the file data sequentially. 
For example in Linux, after opening the file, just call <a href="https://man7.org/linux/man-pages/man2/posix_fadvise.2.html"><code>posix_fadvise</code></a> with <code>POSIX_FADV_SEQUENTIAL</code>:</p>

<div><div><pre><code><span>use</span> <span>std</span><span>::</span><span>fs</span><span>::</span><span>*</span><span>;</span>
<span>use</span> <span>nix</span><span>::</span><span>fcntl</span><span>::</span><span>*</span><span>;</span>
<span>let</span> <span>file</span> <span>=</span> <span>File</span><span>::</span><span>open</span><span>(</span><span>"foo.txt"</span><span>)</span><span>?</span><span>;</span>
<span>let</span> <span>errno</span> <span>=</span> <span>posix_fadvise</span><span>(</span><span>file</span><span>.as_raw_fd</span><span>(),</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>PosixFadviseAdvice</span><span>::</span><span>POSIX_FADV_SEQUENTIAL</span><span>)</span><span>?</span><span>;</span>
</code></pre></div></div>

<p>Internally this option increases the size of the read-ahead buffer, so the system can fetch data in larger chunks, 
potentially reducing the number of seeks. The effects of this flag are clearly visible and it improves performance of parallel access, 
but it is not strong enough to reduce the seek overhead to zero. Interestingly, I haven’t observed any effects 
of this flag on single-threaded throughput in my test, but YMMV.</p>


<ul>
  <li>Random I/O and reading metadata benefits from parallelism on both types of drives: SSD and HDD</li>
  <li>SSDs generally benefit from parallelism much more than HDDs</li>
  <li>Parallel access to HDD when reading large chunks of data sequentially can deteriorate performance</li>
  <li>Calling <code>posix_fadvise</code> to inform the system about sequential access pattern improves read throughput slightly
when sharing the device between multiple threads on Linux</li>
</ul>


  
    <hr>
    
        
      
      
       
    
    
  
</article></div>]]>
            </description>
            <link>https://pkolaczk.github.io/disk-parallelism/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275722</guid>
            <pubDate>Tue, 25 Aug 2020 20:27:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Server-Side Tagging in Google Tag Manager]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24275661">thread link</a>) | @jlbnjmn
<br/>
August 25, 2020 | Https://www.simoahava.com/analytics/server-side-tagging-google-tag-manager | <a href="https://web.archive.org/web/*/Https://www.simoahava.com/analytics/server-side-tagging-google-tag-manager">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p>Ever since <strong>Server-side tagging</strong> was <a href="https://twitter.com/SimoAhava/status/1222459714614841346?s=20">publicly announced</a> at <a href="https://superweek.hu/">SUPERWEEK 2020</a>, Google and the trusted tester community have been hard at work, building something that just might change the landscape of digital analytics for good.</p>
<p><a href="https://tagmanager.google.com/">Google Tag Manager</a> has now released Server-side tagging into <strong>public beta</strong>. In this lengthy article, we’ll take a look at what Server-side tagging is, how it should (and should not) be used, and what its implications are on the broader digital analytics community.</p>
<p><a href="https://www.simoahava.com/images/2020/07/server-side-tagging-google-tag-manager.jpg" title="Server-side tagging">
<img data-src="https://www.simoahava.com/images/2020/07/server-side-tagging-google-tag-manager.jpg#ZgotmplZ" alt="Server-side tagging" src="https://www.simoahava.com/images/2020/07/server-side-tagging-google-tag-manager.jpg#ZgotmplZ">
</a>
</p>
<p>In short, <strong>Server-side tagging</strong> means running a <strong>Google Tag Manager container</strong> in a server-side environment (at the time of writing, the only available environment is the <a href="https://cloud.google.com/">Google Cloud Platform</a>, though I’m certain more options will become available in good time).</p>
<p>Many of the <a href="#key-benefits">benefits</a> and <a href="#key-concerns">concerns</a> are tackled in their respective chapters. Even so, I want to emphasize that Server-side tagging has the potential to overturn the current dynamic of data collection and governance for an organization. You <a href="#full-control-and-ownership-of-the-data-collected-by-the-container"><strong>own</strong> and have <strong>full control</strong></a> over the server-side environment. You have access to <strong>tools</strong> and <strong>methods</strong> to thoroughly <a href="#clean-up-and-validate-payloads">vet and validate the traffic</a> between network sources and your advertising and analytics endpoints.</p>
<p>You can run a fully functional digital analytics and marketing setup without loading <em>any</em> third-party code in the user’s browser or device. With appropriate monitoring in place, you can say <a href="#more-control-over-http-traffic">goodbye to PII and credential leaks</a>, cross-site tracking traps, and bloated third-party JavaScript <a href="#reduced-client-load">encumbering the client</a>.</p>
<p>Server-side tagging utilizes many of the concepts familiar to Google Tag Manager users:</p>
<ul>
<li>
<p>There are <strong>tags</strong> which fire on <strong>triggers</strong> and pull in data from <strong>variables</strong>.</p>
</li>
<li>
<p>New container <strong>versions</strong> can be <strong>previewed</strong> and <strong>published</strong>.</p>
</li>
<li>
<p>Users can create their own <a href="https://www.simoahava.com/analytics/custom-templates-guide-for-google-tag-manager/"><strong>custom templates</strong></a>.</p>
</li>
</ul>
<p>However, there are new, fundamentally different features that introduce something of a <strong>paradigm shift</strong> to the type of dynamic tagging that Google Tag Manager promotes.</p>
<ul>
<li>
<p>The container itself is a new <a href="#server-container"><strong>Server</strong></a> type; different from the web, app, and AMP containers that precede it.</p>
</li>
<li>
<p>Instead of trigger events, processes are initialized by <strong>incoming HTTP requests</strong>.</p>
</li>
<li>
<p>These requests are digested by a new type of GTM entity: <strong>a <a href="#clients-and-tags">Client</a></strong>.</p>
</li>
<li>
<p>The Client parses the requests, generates an <strong>event data object</strong>, and feeds this into a <strong>virtual container</strong>, where tags can use this event object to map and send data to their endpoints.</p>
</li>
</ul>
<p><a href="https://www.simoahava.com/images/2020/08/preview-example.jpg" title="Example from preview mode">
<img data-src="https://www.simoahava.com/images/2020/08/preview-example.jpg#ZgotmplZ" alt="Example from preview mode" src="https://www.simoahava.com/images/2020/08/preview-example.jpg#ZgotmplZ">
</a>
</p>
<p>This article <strong>will not be</strong> an exhaustive guide. I will walk you through the main concepts of Server-side tagging and there should be little you’ll be left wanting, but to complement this article, I do recommend you consult Google’s <a href="https://developers.google.com/tag-manager/serverside">own, official documentation</a>.</p>

<h2 id="how-to-follow-this-guide">How to follow this guide</h2>
<p>While I hope everyone would devour every last word of this article, I’m aware that not all sections are relevant to all readers.</p>
<p>If you’re looking for an overview of Server-side tagging, perhaps for getting buy-in within your organization, I recommend reading these chapters:</p>
<ul>
<li><a href="#what-is-server-side-tagging">What is Server-side tagging</a></li>
<li><a href="#reduced-client-load">Key benefits - Reduced client load</a></li>
<li><a href="#content-security-policy">Key benefits - Content Security Policy</a></li>
<li><a href="#full-control-and-ownership-of-the-data-collected-by-the-container">Key benefits - Full control and ownership of the data collected by the container</a></li>
<li><a href="#key-concerns">Key concerns - All chapters</a></li>
<li><a href="#cost-1">Technical outline - Cost</a></li>
<li><a href="#custom-domain">Technical outline - Custom domain</a></li>
<li><a href="#summary">Summary</a></li>
</ul>
<p>If you’re a developer or working in IT, I’d recommend focusing on these chapters:</p>
<ul>
<li><a href="#what-is-server-side-tagging">What is Server-side tagging</a></li>
<li><a href="#reduced-client-load">Key benefits - Reduced client load</a></li>
<li><a href="#keep-keys-and-secrets-safe">Key benefits - Keep keys and secrets safe</a></li>
<li><a href="#more-control-over-what-endpoints-collect">Key benefits - More control over what endpoints collect</a></li>
<li><a href="#content-security-policy">Key benefits - Content Security Policy</a></li>
<li><a href="#key-concerns">Key concerns - All chapters</a></li>
<li><a href="#server-container">Technical outline - Server container</a></li>
<li><a href="#custom-domain">Technical outline - Custom domain</a></li>
<li><a href="#clients-and-tags">Technical outline - Clients and tags</a></li>
<li><a href="#custom-templates">Technical outline - Custom templates</a></li>
<li><a href="#resources">Technical outline - Resources</a></li>
<li><a href="#summary">Summary</a></li>
</ul>
<p>Everything else is still important, but I’ll forgive you if you gloss over them initially, only to return to them hungrily once you’re hooked into all the awesomeness that Server-side tagging brings in its wake.</p>
<p>I recommend you watch the following two videos regardless.</p>
<p>The first one is a general introduction to <strong>Server-side tagging</strong>, focusing on deployment and getting started with your first Client and tag.</p>
<p>The second is a deep-dive into building your own Client template. It’s a bit more specialized and can thus be skipped if you’re not interested in customizing the container.</p>
<h3 id="video-introduction-to-server-side-tagging">Video: Introduction to Server-side tagging</h3>
<p>
<iframe src="https://www.youtube.com/embed/6OGbOh216mU?enablejsapi=1" allowfullscreen="" title="YouTube Video"></iframe>
</p>
<p>If the video doesn’t work, you can watch it <a href="https://youtu.be/6OGbOh216mU">here</a>.</p>
<h3 id="video-create-a-client-template-in-a-server-container">Video: Create a Client template in a Server container</h3>
<blockquote>
<p><strong>NOTE!</strong> The video below has one important omission. When creating the <strong>Client</strong> template, make sure to update the “Sends HTTP Requests” permission to include “Allow Google Domains”. Otherwise the proxying of analytics.js doesn’t work.</p>
</blockquote>
<p>
<iframe src="https://www.youtube.com/embed/_c4JEfSkP6U?enablejsapi=1" allowfullscreen="" title="YouTube Video"></iframe>
</p>
<p>If the video doesn’t work, you can watch it <a href="https://youtu.be/_c4JEfSkP6U">here</a>.</p>
<h2 id="what-is-server-side-tagging">What is Server-side tagging?</h2>
<p><a href="https://www.simoahava.com/images/2020/07/server-side-tagging-outline.jpg" title="Server-side tagging outline">
<img data-src="https://www.simoahava.com/images/2020/07/server-side-tagging-outline.jpg#ZgotmplZ" alt="Server-side tagging outline" src="https://www.simoahava.com/images/2020/07/server-side-tagging-outline.jpg#ZgotmplZ">
</a>
</p>
<p>With Server-side tagging, Google Tag Manager has introduced a new <strong>Server</strong> container type, which resides in a <a href="https://cloud.google.com/">Google Cloud</a> environment.</p>
<p>In a nutshell, the purpose of this setup is to create an endpoint in a server environment that <strong>you own</strong>. It will act as a sort of a <strong>proxy</strong> between the hits sent from browsers and devices and the actual endpoints to which the hits are collected. See the <a href="#key-benefits">next chapter</a> for more details on what this type of proxy can do.</p>
<p>The container itself operates as an HTTP API endpoint, to which any browser, device, or other sources that support the HTTP protocol can send requests.</p>
<p>Ideally, this endpoint would be mapped with a <strong>custom subdomain</strong> in the same domain hierarchy as the website sending the requests. That way the requests are considered to happen in <a href="https://www.cookiestatus.com/introduction/tracking-protection/#first-party-and-third-party-context">first-party context</a>, which has a significant impact on how cookies can be read and written, for example.</p>
<p>Within the Server container, workers known as <strong>Clients</strong> are configured to listen for these incoming HTTP requests, which they then parse into a <strong>unified event format</strong>. The Clients then run a <em>virtual container</em> with the <a href="#event-model">event data object</a>, where tags, triggers, and variables react to the event push similar to how they would with “regular” Google Tag Manager.</p>
<p>Tags take the information in these event data objects and compile them into HTTP requests to their respective endpoints. Finally, the Client sends an HTTP response back to the source of the initial request.</p>
<p><a href="https://www.simoahava.com/images/2020/07/ua-response.jpg" title="Example of a Universal Analytics client responding with a success status and setting the _ga cookie in the response.">
<img data-src="https://www.simoahava.com/images/2020/07/ua-response.jpg#ZgotmplZ" alt="Example of a Universal Analytics client responding with a success status and setting the _ga cookie in the response." src="https://www.simoahava.com/images/2020/07/ua-response.jpg#ZgotmplZ">
</a>
<span>Example of a Universal Analytics client responding with a success status and setting the _ga cookie in the response.</span>
</p>
<p>All of the above happens within the confines of the Server-side tagging environment. The only way the browser or app sending the data can be made aware of what’s going on is if the <strong>Client</strong> adds information into the HTTP response, which is fully configurable.</p>
<h2 id="key-benefits">Key benefits</h2>
<p>Here are some of the key benefits of using Server-side tagging.</p>
<h3 id="reduced-client-load">Reduced client load</h3>
<p>By running the logic of building and dispatching hits to the vendor endpoint in your server-side environment, you have a golden opportunity to reduce the amount of (especially third-party) JavaScript run in the user’s browser.</p>
<p>Because you can configure the Server container to map <em>any</em> incoming HTTP request into the format required by the vendor, you can theoretically reduce your entire third-party pixel and JavaScript load to a single event stream directed into your Server container.</p>
<p><a href="https://www.simoahava.com/images/2020/07/all-javascript.jpg" title="Imagine if you could reduce the amount of JavaScript loaded and executed in the browser...">
<img data-src="https://www.simoahava.com/images/2020/07/all-javascript.jpg#ZgotmplZ" alt="Imagine if you could reduce the amount of JavaScript loaded and executed in the browser..." src="https://www.simoahava.com/images/2020/07/all-javascript.jpg#ZgotmplZ">
</a>
<span>Imagine if you could reduce the amount of JavaScript loaded and executed in the browser...</span>
</p>
<p>This stream can then be intercepted by a Client which proceeds to map the stream into the <a href="#event-model">event model</a> expected by the vendor tags, also running in the Server container.</p>
<p>This is the <strong>ultimate benefit</strong> of a Server-side tagging setup. Even if you don’t want to reduce everything to a single stream, you can build your own <a href="https://www.simoahava.com/analytics/custom-templates-guide-for-google-tag-manager/">custom template</a> in the web container, which builds the HTTP request to the Server container without having to load any third-party JavaScript at all (apart from the GTM library itself).</p>

<h3 id="keep-keys-and-secrets-safe">Keep keys and secrets safe</h3>
<p>By transporting data processing logic away from the device, where it would be visible for anyone with debugging skills, you will also be able to run secured and credential-based transactions without having to worry about exposing sensitive information to the device.</p>
<p>For example, a plague on Google Analytics has been <a href="https://help.analyticsedge.com/article/definitive-guide-to-removing-google-analytics-spam/">Measurement Protocol spam</a>, where malicious parties crawl potential tracking IDs and then proceed to spam them with automated HTTP requests that masquerade as “regular” hits from the site. Alternatively, these hackers send spam hits to <strong>random tracking IDs</strong>, knowing that if they send enough hits, some of them will end up in real Universal Analytics accounts.</p>
<p>This type of spam is notoriously difficult to identify and prevent because it’s built to resemble actual hits that are sent from the website itself.</p>
<p>Now that you have the server endpoint handy, you can add a new <strong>Custom Dimension</strong> within the Server container, which is then sent to Google Analytics. In Google Analytics, you can then create a filter for this Custom Dimension, allowing only traffic that matches it.</p>
<div><pre><code data-lang="javascript">event[<span>'x-ga-mp1-cd11'</span>] = <span>'my_secret_key'</span>;
</code></pre></div>
<p><a href="https://www.simoahava.com/images/2020/07/custom-dimension-set.jpg" title="Secret key custom dimension">
<img data-src="https://www.simoahava.com/images/2020/07/custom-dimension-set.jpg#ZgotmplZ" alt="Secret key custom dimension" src="https://www.simoahava.com/images/2020/07/custom-dimension-set.jpg#ZgotmplZ">
</a>
</p>
<p>By adding this “secret key” in the Server container, there’s no way that a random Measurement Protocol spammer can know it’s there. Similarly, it won’t help if the spammer crawls your site, looking at the requests sent to Google Analytics, because there are no such requests! There are only requests to your own server-side endpoint, and it would be odd if Measurement Protocol spammers would utilize those to fuel their spam algorithms.</p>
<p>Naturally, this isn’t limited to just what you can do with Universal Analytics. Any third-party servers that identify your access with an <strong>API key</strong> or <strong>credential token</strong> can now be proxied through your Server container so that these keys are not exposed in the device!</p>
<h3 id="more-control-over-what-endpoints-collect">More control over what endpoints collect</h3>
<p>Because your proxy now resides between the user’s device and the endpoint, you are in full control over what is shipped to the vendor.</p>
<p>Unless the Client <a href="https://developers.google.com/tag-manager/serverside/api#getremoteaddress">specifically overrides</a> things like the IP address and User-Agent in the outgoing HTTP request from the Server container (this is what the built-in Universal …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="Https://www.simoahava.com/analytics/server-side-tagging-google-tag-manager">Https://www.simoahava.com/analytics/server-side-tagging-google-tag-manager</a></em></p>]]>
            </description>
            <link>Https://www.simoahava.com/analytics/server-side-tagging-google-tag-manager</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275661</guid>
            <pubDate>Tue, 25 Aug 2020 20:21:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unity top down movement: 2d player script]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24275642">thread link</a>) | @generalistp
<br/>
August 25, 2020 | https://generalistprogrammer.com/game-design-development/unity-2d-movement-top-down-tutorial/ | <a href="https://web.archive.org/web/*/https://generalistprogrammer.com/game-design-development/unity-2d-movement-top-down-tutorial/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
	
<p>Doing 2D top down movement in Unity for your player can easily be achieved with some basic Unity functions and a small script. </p>



<p>First we just going to setup our project. If you don’t want to follow along on this page you can watch the video version below:</p>



<iframe loading="lazy" width="560" height="315" src="about:blank" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" data-rocket-lazyload="fitvidscompatible" data-lazy-src="https://www.youtube.com/embed/IP30ys3CN2g"></iframe>



<h3>Setting up our top down game scene</h3>



<p>On the left hand side in the Unity hierarchy right click and create a empty game object. In the inspector add a sprite renderer component.</p>



<p>Copy the following inspector settings, the most import settings is the position and the order in layer must be -100 so the background renders at the back of all your assets in your game scene.</p>



<figure><img loading="lazy" width="388" height="429" src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image.png" alt="unity 2d move up and down" srcset="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image.png 388w, https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-271x300.png 271w" sizes="(max-width: 388px) 100vw, 388px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20388%20429'%3E%3C/svg%3E" data-lazy-srcset="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image.png 388w, https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-271x300.png 271w" data-lazy-src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image.png"></figure>



<p>Add in your background image into the sprite slot and you are ready to go. You now have a nice background in my case I have something that looks like this.</p>



<figure><img loading="lazy" width="733" height="725" src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-1.jpg" alt="Background image in our scene in the top down" srcset="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-1.jpg 733w, https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-1-300x297.jpg 300w, https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-1-640x633.jpg 640w" sizes="(max-width: 733px) 100vw, 733px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20733%20725'%3E%3C/svg%3E" data-lazy-srcset="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-1.jpg 733w, https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-1-300x297.jpg 300w, https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-1-640x633.jpg 640w" data-lazy-src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-1.jpg"></figure>



<h3>Adding our player to our scene: unity top down movement</h3>



<p>Right click in the hierarchy again and create a new game object, rename it and call it Player. </p>



<p>In the inspector add a Rigidbody 2D.  Copy the details below:</p>



<figure><img loading="lazy" width="390" height="454" src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-2.png" alt="Player movement settings inspector" srcset="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-2.png 390w, https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-2-258x300.png 258w" sizes="(max-width: 390px) 100vw, 390px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20390%20454'%3E%3C/svg%3E" data-lazy-srcset="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-2.png 390w, https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-2-258x300.png 258w" data-lazy-src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-2.png"></figure>



<p>You should now have your player in the scene and should look something like this now.</p>



<figure><img loading="lazy" width="608" height="648" src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-3.jpg" alt="Unity 2D movement top down without our player added" srcset="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-3.jpg 608w, https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-3-281x300.jpg 281w" sizes="(max-width: 608px) 100vw, 608px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20608%20648'%3E%3C/svg%3E" data-lazy-srcset="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-3.jpg 608w, https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-3-281x300.jpg 281w" data-lazy-src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-3.jpg"><figcaption>Unity 2D movement top down</figcaption></figure>



<h3>Write our code for our Unity 2D top down player movement controller</h3>



<p>First off click on your player game object. Add a new component in the inspector called Player Movement. </p>



<p>Like below this is going to be our 2d character controller :</p>



<figure><img loading="lazy" width="275" height="257" src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-4.png" alt="movement code 2d unity" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20275%20257'%3E%3C/svg%3E" data-lazy-src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-4.png"></figure>



<p>Now open up your new c# script in visual studio. </p>



<p>We need to now define a few things, we first of all want to control our player movement speed so we will need a player movement variable. </p>



<p>Next we need a target position variable which will be the position we want our player to move towards. </p>



<p>We now need to use some of the built in Unity functions like the Vector2.MoveTowards method. Also we will use time.deltaTime to make sure our movement is frame rate independent. </p>



<p>We will also use ScreenToWorldPoint to convert our mouse position on screen to a point in our world. </p>



<p>We will use the Input class to get the position of our mouse clicks.</p>



<p>Lets get into the code.</p>



<pre><code lang="csharp">using System.Collections;
using System.Collections.Generic;
using UnityEngine;

public class PlayerMovement : MonoBehaviour
{
    // Start is called before the first frame update
   
    public float speed;
    private Vector2 targetPosition;
    void Start()
    {
        
        targetPosition = new Vector2(0.0f, 0.0f);
    }

    // Update is called once per frame
    void Update()
    {
        if (Input.GetMouseButtonDown(0))
        {
            targetPosition = Input.mousePosition;
            targetPosition = Camera.main.ScreenToWorldPoint(new Vector3(targetPosition.x, targetPosition.y, 0.0f));
        }
        this.transform.position = Vector2.MoveTowards(this.transform.position, targetPosition, speed * Time.deltaTime);
           
       
    }
}
</code></pre>



<p>Just a quick explanation on how this code works. In the start method we just set a start position to 0.0f and 0.0f just to start with a default position. </p>



<p>Our player initially will also be at 0,0 in our scene so when our game starts our player won’t jump or move. </p>



<p>Next in the update method we need to get our mouse input. So we call Input.GetMouseButtonDown(0) the zero is for the left click on our mouse.  We then set our targetPosition to our mousePosition. </p>



<p>We then take those co ordinates to worldPoints the ScreenToWolrdPoint method needs a Vector3 in our case we just pass the x and y position because we are only moving in 2D space. </p>



<p>Then finally we set the transform position of our player by calling Vector2.MoveTowards with the player current position and target position. </p>



<p>We plugin our speed and multiply it by Time.deltaTime to make our movement frame rate independent.</p>



<h3>Setting our player movement speed</h3>



<p>Once you have saved the script. Close visual studio and now we just need to give our player a movement speed.</p>



<figure><img loading="lazy" width="397" height="158" src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-5.png" alt="unity top down movement rotation" srcset="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-5.png 397w, https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-5-300x119.png 300w" sizes="(max-width: 397px) 100vw, 397px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20397%20158'%3E%3C/svg%3E" data-lazy-srcset="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-5.png 397w, https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-5-300x119.png 300w" data-lazy-src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-5.png"></figure>



<p>I just chose a speed of 10 which is a decent smooth speed for our player to move. </p>



<p>Well done if you have done everything correctly you should now have your first Unity 2D top down player movement working. </p>



<p>What’s great about this very basic movement script is that it can be used for so many types of games. </p>



<p>Adventure games, rpg style games, if you wanted to stick to complete rpg style you would just have to make sure your Vector in your MoveTowards is locked to one axis at a time because your player can only move up or down and left or right not diagonally.</p>



<h3>Weird issues you might have</h3>



<p>You might have run into some issues. Where your player might be falling off the screen when you hit play. </p>



<p>In order to make your unity 2d top down&nbsp;gravity work properly you need to set your gravity scale to 0 in your Rigidbody 2D component. Like so:</p>



<figure><img loading="lazy" width="376" height="141" src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-6.png" alt="unity 2d top down gravity" srcset="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-6.png 376w, https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-6-300x113.png 300w" sizes="(max-width: 376px) 100vw, 376px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20376%20141'%3E%3C/svg%3E" data-lazy-srcset="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-6.png 376w, https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-6-300x113.png 300w" data-lazy-src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-6.png"><figcaption> unity 2d top down&nbsp;gravity </figcaption></figure>



<p>If this tutorial and want to learn more about making 2d games with unity check out our <a href="http://generalistprogrammer.com/category/game-design-development/">game development</a> section.</p>



<p>So I hope you liked this short tutorial on unity movement and how you can move a player easily in unity using a c# script. There are a lot of ways in which you can create player movement and more.</p>



<p>Some of which is using animation transitions. You could also use a physics based approach propelling your player on screen as well. It’s really up to your creativity. However hopefully this will get you off to a good start.</p>





</div></div>]]>
            </description>
            <link>https://generalistprogrammer.com/game-design-development/unity-2d-movement-top-down-tutorial/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275642</guid>
            <pubDate>Tue, 25 Aug 2020 20:19:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thinking Scientifically to Get Rid of Acne: The SkinTheory Method]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24275521">thread link</a>) | @jealousgelatin
<br/>
August 25, 2020 | https://blog.skintheory.app/skintheorys-birth/ | <a href="https://web.archive.org/web/*/https://blog.skintheory.app/skintheorys-birth/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>Click <a href="#acne-method">here</a> to skip to my acne solution section if you’d like. Read on if you’d like the whole story!</p>



<p>Hey there, I’m Conor. I’m a software engineer, I like to make indie music, and I’m an alumnus of suffering from some pretty bad acne.</p>



<p>Living with acne has been a humbling test of confidence. Talking about it this openly on the internet is something I don’t find easy, even though I no longer really have any acne. I’d like to share my success story in hopes of inspiring you guys to solve your acne with a new mindset.</p>



<h2>Here’s what I used to look like</h2>







<p>So, here I am on April 25, 2017. I’m 21 years old and a junior in University of Pittsburgh. My face hurts me, both mentally and physically. I had intense cystic acne that was deep enough to continue causing new pimples. Some days, I would leave class early because I felt gross and my face hurt.</p>



<h2>Bad Acne Can Be Hard To Get Rid Of</h2>



<div><figure><img loading="lazy" width="580" height="447" src="https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=580%2C447&amp;ssl=1" alt="" srcset="https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=1024%2C789&amp;ssl=1 1024w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=300%2C231&amp;ssl=1 300w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=768%2C592&amp;ssl=1 768w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=1536%2C1184&amp;ssl=1 1536w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=1200%2C925&amp;ssl=1 1200w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?w=1650&amp;ssl=1 1650w" sizes="(max-width: 580px) 100vw, 580px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=1024%2C789&amp;ssl=1 1024w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=300%2C231&amp;ssl=1 300w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=768%2C592&amp;ssl=1 768w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=1536%2C1184&amp;ssl=1 1536w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=1200%2C925&amp;ssl=1 1200w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?w=1650&amp;ssl=1 1650w" data-lazy-src="https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=580%2C447&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Tons and Tons of different acne medications</figcaption></figure></div>



<p>I was looking for anything that would solve my acne. I was constantly trying new regimens and routines: regimens I’d found online, advice from my dermatologist, regimens that I’d concocted out of thin air, etc. There are an enormous amount of resources/communities online where I ‘d sourced these ideas from acne.org, <a href="https://www.reddit.com/r/skincareaddiction">reddit.com/r/skincareaddiction</a>, bloggers/youtube. While these communities were great for inspiration, they also created an information overload.</p>



<p>Each community would have their own regimens to try, some of which would contradict one another, some regimens were straight up paid celebrity/blogger propaganda, some regimens were just placebos. Forums could be filled with people saying, “This product is a miracle cure!”, while others said the product had flared up their acne. It was tough to find scientific, unbiased reviews of regimens to try on my own skin.</p>



<p>To compound this, trying a new routine on skin is a frustratingly slow process. Unfortunately, overnight cures don’t yet exist for acne. Changes in skin from a new regimen can take days or weeks to be seen and sometimes the skin will get worse before it gets better. There are also external forces working on your skin, like stress in school or work, sweating from working out, and climate (like warmer weather). <strong>I needed to experiment with my own skin and environment to accurately understand what was causing my acne.</strong></p>



<h2>Solving My Acne Scientifically</h2>



<div><figure><img loading="lazy" src="https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/540px-CNX_Psych_02_01_Method.jpg?resize=405%2C348&amp;ssl=1" alt="" width="405" height="348" srcset="https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/540px-CNX_Psych_02_01_Method.jpg?w=540&amp;ssl=1 540w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/540px-CNX_Psych_02_01_Method.jpg?resize=300%2C258&amp;ssl=1 300w" sizes="(max-width: 405px) 100vw, 405px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/540px-CNX_Psych_02_01_Method.jpg?w=540&amp;ssl=1 540w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/540px-CNX_Psych_02_01_Method.jpg?resize=300%2C258&amp;ssl=1 300w" data-lazy-src="https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/540px-CNX_Psych_02_01_Method.jpg?resize=405%2C348&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>The handy dandy scientific method</figcaption></figure></div>



<p>It’s an understatement to say that tackling my acne seemed like a daunting challenge. It felt hopeless some days. I would try different regimens, my acne would flare, and I’d have no clue as to why. So I’d switch to a different regimen after a few days and still have no luck. Eventually I would return, cyclically to the same non-working regimens and never get anywhere.</p>



<p>I was still in college at this time, studying mainly Computer Science. I really dug my CS degree. Everyone has seen all the wild stuff that comes out of CS like machine learning and what not, but I think CS gave me something something else: a process for solving complex problems.</p>



<p>In the abstract, students of Computer Science are taught logical ways of problem solving. We are taught multiple sets of <a href="https://medium.com/@codingfreak/top-algorithms-data-structures-concepts-every-computer-science-student-should-know-e0549c67b4ac">rules</a> which we will use for transforming raw data inputs into our ideal and repeatable data outputs. What started as completely impossible problems (i.e <a href="https://www.geeksforgeeks.org/reverse-a-linked-list/">reversed linked list problems</a>) became trivial with these processes of algorithmic thinking. <a href="#note-1">[1]</a></p>



<h3 id="acne-method">My Acne Management Method</h3>



<p><em>Side Note: See the below section: <a href="#making-method-easier">Making The Method Easier</a> for a better experience.</em></p>



<p>With these newfound algorithmic ways of thinking, it was time logically get rid of my acne. Using the scientific method as a guideline, I decided to narrow down what factors affected my skin and try different product regimens to find my cure. The process looked like so:</p>



<ol><li><strong>Create a Hypothesis</strong>: I would choose a regimen to follow for some amount of time. Maybe I’d try a regimen I’d found on acne.org.<ul><li>e.g “Benzoyl Peroxide on left side of face, 1x a day; Moisturize 1x a day for 2 weeks.”</li></ul></li><li><strong>Run the Experiment</strong>: Every day or two I would:<ol><li>Take pictures of the affected areas with my new regimen.</li><li>Write a log in a private Google Doc the status of my skin and how the experiment was going. This log includes how my skin looks and feels, and any externalities that could affect the experiment. These logs would allow me to pinpoint how I felt about my skin over time.<ul><li>e.g “I have 10 pimples today and a good bit of redness. Mostly on the right side of my face. They do feel a bit less inflamed today. I also forgot to shower after working out yesterday, and woke up feeling sweaty. OOF 😕”</li></ul></li></ol></li><li><strong>Analyze the Results</strong>: After a solid time period (and 2 weeks may not always be enough!), I would compare my photos and logs from today to before I began this regimen’s experiment. If I showed some improvement, I would keep up the regimen. If I was getting worse, I would tweak the regimen or completely change to a new one with a day or 2 of buffer in between.</li></ol>



<p>I began to take a secret joy in doing this method. Firstly, I felt like I was actively working towards clearing my acne every night. I would come up with new ideas through the week and save them for later to try. Secondly, I felt like I wasn’t completely lost with my acne anymore. I used to get overwhelmed trying to keep all of my past treatments and externalities (food, sleep schedules, stress, etc.) together in my head. I would recurrently try regimens that I’d already attempted and forgot about to see if they’d work this time. Now, I had a mental map, process, and actual log of what worked and what didn’t.</p>



<h4>Issues</h4>



<p>The above method worked, but it is definitely rudimentary and so I’d found a few annoyances.</p>



<ul><li><a href="https://docs.google.com/">Google Docs</a> and <a href="https://blog.skintheory.app/skintheorys-birth/Flickr.com">Flickr</a> (where I stored my photos) were completely unlinked. They are 2 different apps. I would have to date entries in the Google Doc and find them in another tab on Flickr to find the photos.</li><li>I had to use Flickr to store my photos because I now had nightly acne selfies showing up in my phone’s gallery. If I were then trying to show a friend another picture, all these acne photos would pop up. 😐 Also, Flickr, now has a 1k picture upload limit. 😐</li></ul>



<h2 id="making-method-easier">Making The Method Easier: The SkinTheory App</h2>







<p>As someone who was able to beat their acne by thinking this way, I wanted to share this scientific process with kindred spirits who I knew were suffering as well. Unfortunately, my home-brewed process felt kinda janky.</p>



<p>In my free time I decided to learn React-Native to make an app (with some help of course) to streamline this process. It took loads of work between coding, making art assets, making a website, etc. but I think the acne solving method above is now much more straight forward. Especially for people who don’t consider themselves “technical”. Anyone with problem skin can now find a solution using this <a href="https://www.skintheory.app/">SkinTheory Method</a> without the <a href="https://www.urbandictionary.com/define.php?term=pita">PITA</a> overhead of managing a huge Google Doc and Flickr Library. Also, photos are sneakily hidden away in the app in order to not peskily show up in the phone gallery when you’re showing friends your cute dog pics.</p>



<h2>Skin Success</h2>



<p>So, if you like to see the results of my “Before &amp; After pics” here’s a pic with some of the fam below. I’ve moved to Ireland since I graduated so we’re out on my cousin’s farm.</p>



<div><figure><img loading="lazy" src="https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1.jpg?resize=512%2C384&amp;ssl=1" alt="" width="512" height="384" srcset="https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=2048%2C1536&amp;ssl=1 2048w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=1200%2C900&amp;ssl=1 1200w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=1980%2C1485&amp;ssl=1 1980w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?w=1740&amp;ssl=1 1740w" sizes="(max-width: 512px) 100vw, 512px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=2048%2C1536&amp;ssl=1 2048w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=1200%2C900&amp;ssl=1 1200w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=1980%2C1485&amp;ssl=1 1980w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?w=1740&amp;ssl=1 1740w" data-lazy-src="https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1.jpg?resize=512%2C384&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>I’m completely clear now and most of the scarring has healed. It’s a liberating feeling to be past acne but it did take time to find the correct regimen.</p>



<p>To wrap up what worked for me, I have crazy sensitive skin. The normal benzoyl peroxides and salicylic acids for solving acne would irritate my skin and cause more acne. I learned that I had to be moisturizing daily (thanks <a href="http://acne.org/">Acne.org</a>!), using gentle <a href="https://www.acne.org/comedogenic-list.html">non-comedogenic</a> moisturizers and soaps, and managing my stress. College caused huge stress and also affected my sleeping/eating habits which seemed to be causing more acne for me.</p>



<p>In the end, the SkinTheory Method helped me act as a scientist, testing and isolating factors affecting my own skin. It gave me the peace of mind that I was doing something at each step to control my acne. It paid off. <strong>Best of luck with your</strong> <strong>own experiments. 🔬</strong></p>



<h2 id="notes">Extra Notes</h2>



<p>[1]: Whether you have Computer Science know-how or not: I highly recommend this book on thinking about algorithms in day-to-day life (non-affiliate link): <a href="https://www.goodreads.com/book/show/25666050-algorithms-to-live-by">Algorithms to Live By: The Computer Science of Human Decisions by Brian Christian</a></p>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://blog.skintheory.app/skintheorys-birth/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275521</guid>
            <pubDate>Tue, 25 Aug 2020 20:07:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cloudflare Warp Beta for macOS and Windows]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24275292">thread link</a>) | @0xbkt
<br/>
August 25, 2020 | https://1.1.1.1/beta/ | <a href="https://web.archive.org/web/*/https://1.1.1.1/beta/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-depth-perspective-root=""><div><div><div data-depth="3"><div><h2 data-js-balance-text="">Thank you for helping us make a safer and faster internet for the desktop</h2><div data-js-balance-text=""><p>Select the appropriate link to download the desktop app for your system. This is a Beta release, so remember to provide feedback and learn about known issues using the link below.</p><p><a href="https://support.cloudflarewarp.com/hc/en-us/articles/360051891794-Beta-Known-issues" target="_blank">Learn more about known issues</a></p></div></div></div></div><div><div><p>macOS Catalina</p><div><p>Minimum system <br> requirements</p><p>10.15 or higher <br> 64 bit only</p></div><p><a href="https://support.cloudflarewarp.com/hc/en-us/articles/360051891814-Beta-Install-Instructions">macOS installation Instructions</a></p><p>Windows 10</p><div><p>Minimum system <br> requirements</p><p>1909 or higher <br> 64 bit only</p></div><p>Windows Installation instructions</p></div></div><div data-depth-perspective-scroll-anchor="" data-depth="3"><div><div><div><div><div><div><p>Minimum system <br> requirements</p></div><div> <p>10.15 or higher <br> 64 bit only</p></div><div><p>1909 or higher <br> 64 bit only</p></div></div></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://1.1.1.1/beta/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275292</guid>
            <pubDate>Tue, 25 Aug 2020 19:49:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Behind the Scenes – An Inside Look at the $3.5T Chronic Disease Industry]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24275187">thread link</a>) | @Chetane
<br/>
August 25, 2020 | https://flowdash.com/blog/behind-the-scenes-an-inside-look-at-the-3-5-trillion-chronic-disease-industry/ | <a href="https://web.archive.org/web/*/https://flowdash.com/blog/behind-the-scenes-an-inside-look-at-the-3-5-trillion-chronic-disease-industry/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><em>“Behind the Scenes” is a series focused on highlighting the unsung heroes – Operations teams. </em><em>Their work is often critical to the operations of the company, yet few if any customers know they exist. Our goal is to bring these teams to light and surface the amazing work they do day-to-day to keep the products we love humming along smoothly.</em></p>



<p>We spoke with Shohini, Product Manager at Oscar Health – a health insurance company headquartered in New York City whose mission is to “do our part to dismantle and rebuild the country’s broken health care system and improve health outcomes for everyone”.<span id="easy-footnote-1-57"></span><span><a href="#easy-footnote-bottom-1-57" title="&amp;#8220;About Oscar Health&amp;#8221;, accessed August 18, 2020, https://www.hioscar.com/about."><sup>1</sup></a></span> Shohini’s team, Digital Member Experience, builds products to empower users to easily find the care that they need<strong>.</strong></p>



<p>We discussed her thoughts on a current project at Oscar Health, how she thought through her career path, and her advice for new grads on how to choose a role or company.</p>



<p><strong>Project Highlight – Chronic Disease, the $3.5 Trillion Industry</strong></p>



<p>Shohini walks me through Oscar Health’s upcoming Virtual Care Program, a program that provides patients with no-cost telemedicine visits with an Oscar Health primary care provider and provides free downstream services such as labs, medical equipment, and prescriptions. Her focus is on managing care routing, mainly driving adoption and tailoring the user experience.&nbsp;</p>



<p>Oscar’s unique positioning as an insurer, and now care delivery provider, allows them to disrupt the current service model – namely when a patient’s provider and insurer are two parties pitted against each other, with no coordination. Ideal especially during COVID, the program’s goal is to incentivize patients to exercise preventative care, allowing them to save on potential financial, emotional, and physical constraints that come from unmanaged diseases.&nbsp;</p>



<p>The long term goal of many virtual care programs is to help patients manage and bring down the cost of chronic diseases. Chronic disease is defined broadly as “conditions that last 1 year or more and require ongoing medical attention or limit activities of daily living or both.”<span id="easy-footnote-2-57"></span><span><a href="#easy-footnote-bottom-2-57" title="CDC, &amp;#8220;About Chronic Diseases&amp;#8221;, accessed August 18, 2020, <a href=&quot;https://www.cdc.gov/chronicdisease/about/index.htm#:~:text=Chronic%20diseases%20are%20defined%20broadly,disability%20in%20the%20United%20States.&quot;>https://www.cdc.gov/chronicdisease/about/index.htm#:~:text=Chronic%20diseases%20are%20defined%20broadly,disability%20in%20the%20United%20State.</a>"><sup>2</sup></a></span> As the country’s leading cause of death and disability, chronic disease has affected 6 out of 10 Americans, lead to the deaths of 1.7 million Americans annually, and accounts for a whopping $3.5 trillion in healthcare costs every year.<span id="easy-footnote-3-57"></span><span><a href="#easy-footnote-bottom-3-57" title="CDC, &amp;#8220;About Chronic Diseases&amp;#8221;, accessed August 18, 2020, <a href=&quot;https://www.cdc.gov/chronicdisease/about/index.htm#:~:text=Chronic%20diseases%20are%20defined%20broadly,disability%20in%20the%20United%20States.&quot; data-type=&quot;URL&quot; data-id=&quot;https://www.cdc.gov/chronicdisease/about/index.htm#:~:text=Chronic%20diseases%20are%20defined%20broadly,disability%20in%20the%20United%20States.&quot;><a href=&quot;https://www.cdc.gov/chronicdisease/about/index.htm#:~:text=Chronic%20diseases%20are%20defined%20broadly,disability%20in%20the%20United%20States.&quot;>https://www.cdc.gov/chronicdisease/about/index.htm#:~:text=Chronic%20diseases%20are%20defined%20broadly,disability%20in%20the%20United%20States.</a></a>"><sup>3</sup></a></span>&nbsp; To make matters worse, the prevalence rate of chronic disease is increasing. With the advancement of medicine leading to longer lifespans, as well as existing risk factors such as poor nutrition, smoking, and excessive alcohol use, the effects of heart disease, cancer, and stroke (top chronic diseases) has led to a greater impact on the wider American population and has thus attracted a greater focus from the healthcare industry.&nbsp;</p>



<p>Many within the industry are aiming to solve the problem of chronic diseases – some remedies being chronic disease focused primary care, Medicare payment models, and even tech investments focused on Medicaid populations. Medicare is a federal insurance program that provides health coverage for Americans 65 years or older or younger and disabled. Given the older population, Medicare sees a higher concentration of chronic diseases across its participants. In contrast, Medicaid is a state and federal assistance program that serves a low-income population, another hub for potential high rates of chronic disease due to structural disadvantages.</p>



<p>The main pain point here, Shohini highlights, is the ruthless cycle of poverty, where healthcare is more often mixed in with other economic, educational, and social gaps. For example, a low-income American would have access to low quality housing and food, leading to greater likelihood of contracting diseases. This circumstance would ultimately lead to greater time spent having to go to doctor’s appointments, more money lost given the increased number of visits, and low productivity due to the physical, emotional, and financial stressors. Care is needed, but financial incentives make it difficult to distribute to those most in need. Oscar Health, through its focus on easy-to-use and no-cost preventative care, hopes to test a different economic model for healthcare that actually incentivizes preventative care in the general population. In focusing more specifically on tackling chronic diseases and addressing social determinants of health, Oscar’s new program will hopefully lead to a brighter, healthier future for the American population.</p>



<p><strong>Shohini’s Background – Why Oscar Health?&nbsp;</strong></p>



<p>Shohini’s career is threaded with the principle of “working to build and expand upon basic services for people”. Coming from UC Berkeley with an initial focus on International Relations and Policy, she pivoted into tech by interning for Oscar Health as a Product Management intern focused on insurance infrastructure. She then transitioned to an operational role at Savvy, an early-stage healthcare startup based in the Bay Area. Both experiences brought their respective learnings and perspectives.</p>



<p>Upon experiencing both an early-stage startup and larger-scale company, Shohini details the different pros and cons she experienced from both. The startup allowed for flexibility, quick decision-making and re-prioritization but at the cost of less structured experimentation. On the flip-side, the larger-scale company had access to a broader range of healthcare experts and ample data. As a side effect, however, more stakeholders led to greater time spent gathering project feedback and buy-in.</p>



<p>Ultimately Shohini landed back at Oscar Health, charged with broader experiences and fresh learnings, ready to help tackle the company’s mission of making virtual care and healthcare concepts more accessible. She rejoined excited to learn more broadly about healthcare and to continue her personal mission of “expanding basic services”. Not only is she able to be part of a company that aligns with her personal mission, but her function allows her to play a pivotal role in actively building products to improve the care experience for the user.</p>



<p><strong>Advice for New Grads – Materialize the Change You Want to Make&nbsp;</strong></p>



<p>Shohini speaks to her internship experience at Oscar Health and her approach to understanding whether or not the company was the right fit. Driving projects given to her were of course learning experiences, but going beyond the assigned work allowed her to fully maximize her time there. She grabbed coffees with people and teams outside of her scope in order to explore her interests. She dug into understanding which projects (outside of her day-to-day) were prioritized as a company. She socialized with colleagues after work, observing to see if the company would be a good culture fit. All were factors that played important roles in having Shohini choose the right company, the right team, and the right product.</p>



<p>Zooming out, she provides three actionable principles she used to help her decision-making process for choosing a company/role:</p>



<p>1) Have a clear idea of the outcome you want to create.&nbsp;</p>



<p>2) Understand what the gaps are of the company and whether that’s exciting to you.&nbsp;</p>



<p>3) Pick a mission or product that you’re building over a specific role. It’s easy to be drawn towards specific companies for the sake of the title or prestige, but at the end of the day, choose based on your passion and interests. And <em>that</em> is what will provide long-term impact.</p>



<p>In summary, Shohini’s Virtual Care project, journey of navigating different companies and functions, and thinking through culture and company fit, all highlight the importance of mission and impact – execution for the the sake of execution can take you only so far, but execution with a purpose leads to greater momentum, longevity, and well-being.</p>



<p>Interested in learning about Oscar Health’s COVID resources? Click here: <a href="https://www.hioscar.com/covid19">https://www.hioscar.com/covid19</a></p>



<p>To learn more about Oscar Health, you can find more information here: <a href="https://www.hioscar.com/about">https://www.hioscar.com/about</a></p>



<p>To learn more about Savvy, you can find more information here: <a href="https://www.gosavvy.com/">https://www.gosavvy.com/</a></p>



<p><strong><a href="https://flowdash.com/">Flowdash’s</a> mission is to bring happiness back to the workplace by changing the way people create software. We’re making it easier to build applications without code so that individuals within every organization are empowered to create the tools they need — the tools they deserve.</strong></p>
<ol><li><span id="easy-footnote-bottom-1-57"></span>“About Oscar Health”, accessed August 18, 2020, https://www.hioscar.com/about.<a href="#easy-footnote-1-57"></a></li><li><span id="easy-footnote-bottom-2-57"></span>CDC, “About Chronic Diseases”, accessed August 18, 2020, <a href="https://www.cdc.gov/chronicdisease/about/index.htm#:~:text=Chronic%20diseases%20are%20defined%20broadly,disability%20in%20the%20United%20States.">https://www.cdc.gov/chronicdisease/about/index.htm#:~:text=Chronic%20diseases%20are%20defined%20broadly,disability%20in%20the%20United%20State.</a><a href="#easy-footnote-2-57"></a></li><li><span id="easy-footnote-bottom-3-57"></span>CDC, “About Chronic Diseases”, accessed August 18, 2020, <a href="https://www.cdc.gov/chronicdisease/about/index.htm#:~:text=Chronic%20diseases%20are%20defined%20broadly,disability%20in%20the%20United%20States." data-type="URL" data-id="https://www.cdc.gov/chronicdisease/about/index.htm#:~:text=Chronic%20diseases%20are%20defined%20broadly,disability%20in%20the%20United%20States."></a><a href="https://www.cdc.gov/chronicdisease/about/index.htm#:~:text=Chronic%20diseases%20are%20defined%20broadly,disability%20in%20the%20United%20States.">https://www.cdc.gov/chronicdisease/about/index.htm#:~:text=Chronic%20diseases%20are%20defined%20broadly,disability%20in%20the%20United%20States.</a><a href="#easy-footnote-3-57"></a></li></ol></div></div>]]>
            </description>
            <link>https://flowdash.com/blog/behind-the-scenes-an-inside-look-at-the-3-5-trillion-chronic-disease-industry/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275187</guid>
            <pubDate>Tue, 25 Aug 2020 19:40:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[React with Next.js vs. Ruby on Rails]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24275175">thread link</a>) | @kirillzubovsky
<br/>
August 25, 2020 | https://suddenschools.org/blog/react-nextjs-vs-ruby-on-rails | <a href="https://web.archive.org/web/*/https://suddenschools.org/blog/react-nextjs-vs-ruby-on-rails">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>As a long-time Ruby on Rails developer I was really hesitant to try something new. Learning is time consuming, it requires exploring and making mistakes. Why bother, if you already know a language that works pretty great, and gets the job done?</p>
<p>While Ruby is a lovely language, and Rails is a fantastic framework which enabled countless startups to launch and become famous, Rails also has limitations which can be easily overcome with React, and the time and cost savings are worth the initial learning curve.</p>
<p>React enables a smooth transition from a monolith app, where everything is programmed from one code base, to a component based app, where logic, data, and presentation are handled by multiple applications. It was developed out of necessity to run an efficient engineering operations with thousands of developers, but it scales equally well for a company of one.</p>
<p>With React you can easily split your application into parts where front and back are developed, maintained and deployed by different teams, at different times. This improves flexibility across the board. Different teams can work on a single app, but improve it in steps, without affecting each other.</p>
<p>React simply listens to new data and updates your application when the data is updated. It's magic!</p>
<p>Facebook, the React parent, did lots of pretty forward-thinking development, and Rails team has been playing catch up. Rails is still a great way to build logic bits for your application, to be the brain and the datacenter of your app, but as far as display of information is concerned, React is a few steps ahead.</p>
<p>Before <a href="https://nextjs.org/">Next.js</a>, I was afraid of React. If something broke in Rails, I knew where to fix it, or at least how to look for the right information which would enable me to fix it. I was familiar with a bunch of useful gems, and the MVC model was well engrained in my head. Rails was familiar, and comfortable. The paradigm change from Rails to webpack/node/react ..etc, it seemed more work than I was willing to put in. </p>
<p>Next changed everything. They took everything that was good about React, sprinkled some useful simplifications, made it idiot-proof (thank you!), and put it all on efficient pipeline that deploys blazingly fast (seconds vs. minutes). Now that I have taken the time to understand it a little, I can launch a brand new website using Next in a matter of minutes, deploy it to Vercel in seconds, and show it to customers in that moment. Then, if I want to make a change, re-deployment only takes a few seconds. Quite literally, it took only 35 seconds to deploy this blog post.</p>
<p>If I were to pick my top 3 favorites about Next, it would be this. (1) It turns your entire website into a series of static pages that render really fast, for really cheap. Right now, hobby hosting on Vercel costs $0, and that's a pretty great price! (2) Next.js does not require a database to start, which removes the unnecessary complexity for both local dev and deploy. On top of that, when needed, the "database" can be literally anything, from Postgres to a Google Sheet, which again makes it simple and cheap. (3) It's made React Routing manageable, so when users click on a link, it works just like it would in a normal static html, with the underlying complexity hidden away. This might be a small thing by dev standards, but it's a huge plus when it comes for a particular purpose of lauching usable websites.</p>
<p>Learning gives you options, whether you are learning a new foreign language, or learning to use a fork, learning enables a new experience that leads to new, usually better outcomes. It is no different for programming, and I highly recommend Next.js as step in the right direction.</p>
<p>Take a look on their website, look at the showcase for social proof, and of course if you want a bit more information without having to dig it up yourself, sign up for one of the <a href="https://suddenschools.org/">Sudden Schools</a> courses, and have it explained in short delightful videos.</p>
<p>Hope to see you soon!</p>
</div></div></div>]]>
            </description>
            <link>https://suddenschools.org/blog/react-nextjs-vs-ruby-on-rails</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275175</guid>
            <pubDate>Tue, 25 Aug 2020 19:39:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pmem.io: Static code analysis of the PMDK]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24275157">thread link</a>) | @EvgeniyZh
<br/>
August 25, 2020 | https://pmem.io//2020/08/20/pmdk-pvs-studio.html | <a href="https://web.archive.org/web/*/https://pmem.io//2020/08/20/pmdk-pvs-studio.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrap">
	
	
	<br>
	<h3>Static code analysis of the PMDK</h3>
	<ul>
	</ul>
	<div id="postinfo"><p>Posted August 20, 2020&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	
	<span size="-1"><a href="https://pmem.io/2020/05/27/llpl-intro1.html" title="Introduction to LLPL">«&nbsp;Previous&nbsp;post</a></span>&nbsp;&nbsp;&nbsp;&nbsp;
	
	
	</p></div>
	
	

<p>In the PMDK team, we focus on the quality of our codebase. One of the
standard practices in the software development is a static code analysis, which
improves the overall project quality and fixes bugs in the early stage of
development. Since there is no silver bullet for avoiding bugs, we already use
two different static analysis tools and many runtime checkers e.g. <a href="https://www.youtube.com/watch?v=R2m-wH7W-5U">valgrind</a>.
Improving static analysis effectiveness is a separate academic problem. What is
worth mentioning is the fact that different tools take a various approach. With
combined advantages of Open Source projects such as transparency and
reliability, as well as a new static analysis tool, we get a new bag of tricks
and a fresh look to an old problem :).</p>



<p><a href="https://viva64.com/en/pvs-studio/">PVS-Studio</a> is a static-analysis tool for detecting bugs and
security weaknesses in the source code of programs. What distinguishes
PVS-Studio is their comprehensive support for open-source projects.
After a quick e-mail exchange, the PVS-Studio team agreed to perform an analysis
of the PMDK project. The analysis is available in this <a href="https://viva64.com/en/b/0756/">post</a>.</p>



<p>PVS-Studio managed to find a couple of issues, which were not previously
detected; we analyzed detected bugs and addressed changes in the following
<a href="https://github.com/pmem/pmdk/pull/4942">Pull Request</a>. From my experience, I highly recommend cooperating with
the PVS-Studio team - excellent support and quick response time allows us to
improve the PMDK project. See <a href="https://viva64.com/en/pvs-studio/">PVS-Studio</a> yourself :)</p>


	

	
	
	
	
	


	
</div></div>]]>
            </description>
            <link>https://pmem.io//2020/08/20/pmdk-pvs-studio.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275157</guid>
            <pubDate>Tue, 25 Aug 2020 19:38:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python libraries to make your code readable, reliable and maintainable]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24275037">thread link</a>) | @makaimc
<br/>
August 25, 2020 | https://isaak.dev/2020/08/python-libraries-to-make-your-code-readable-and-maintainable | <a href="https://web.archive.org/web/*/https://isaak.dev/2020/08/python-libraries-to-make-your-code-readable-and-maintainable">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Experienced programmers understand perfectly well that in development they spend most of the time reading code 
and therefore they treat the process of writing code with the deepest trepidation (and sometimes with fanaticism). 
To write quality and maintainable code, you need to take the time to write tests and integrate QA tools. There is a 
whole technique aimed at test-driven development (<a href="https://en.wikipedia.org/wiki/Test-driven_development">TDD</a>) and I will not devote this article to the topic of testing as 
such. Tests are absolutely necessary and there is nothing to discuss. In this article, we are going to talk about tools 
that help you write quality Python code.</p>

<p>Table of content:</p>

<ul>
  <li><a href="#testing-frameworks">Testing Frameworks</a></li>
  <li><a href="#test-runners">Test Runners</a></li>
  <li><a href="#e2e-testing-gui--frontend">E2E Testing</a></li>
  <li><a href="#fake-data">Fake Data</a></li>
  <li><a href="#mocking">Mocking</a></li>
  <li><a href="#code-coverage">Code coverage</a></li>
  <li><a href="#object-factories">Object Factories</a></li>
  <li><a href="#code-style">Code Style</a></li>
  <li><a href="#typing">Typing</a></li>
</ul>


      <h2 id="testing-frameworks">
        
        <a href="#testing-frameworks">Testing Frameworks</a>
        
      </h2>

<p><a href="https://github.com/pytest-dev/pytest/"><strong>pytest</strong></a> is a framework that makes it easy to write small tests, yet scales to support complex functional testing for applications and libraries.</p>

<p>Features</p>

<ul>
  <li>Detailed info on failing assert statements (no need to remember self.assert* names);</li>
  <li>Auto-discovery of test modules and functions;</li>
  <li>Modular fixtures for managing small or parametrized long-lived test resources;</li>
  <li>Can run <code>unittest</code> (including trial) and nose test suites out of the box;</li>
  <li>Python 3.5+ and PyPy 3;</li>
  <li>Rich plugin architecture, with over 315+ external plugins and thriving community;</li>
</ul>



<p><a href="https://github.com/HypothesisWorks/hypothesis"><strong>Hypothesis</strong></a>  is a family of testing libraries that let you write 
tests parametrized by a source of examples. A Hypothesis implementation then generates simple and comprehensible 
examples that make your tests fail. This simplifies writing your tests and makes them more powerful at the same time, 
by letting software automate the boring bits and do them to a higher standard than a human would, freeing you to focus 
on the higher-level test logic.</p>



<p><a href="https://github.com/robotframework/robotframework"><strong>Robot Framework</strong></a> is a generic open-source automation framework 
for acceptance testing, acceptance test-driven development (ATDD), and robotic process automation (RPA). 
It has simple plain text syntax and it can be extended easily with libraries implemented using Python or Java.</p>



<p><a href="https://docs.python.org/3/library/unittest.html"><strong>unittest</strong></a> is a unit testing framework from Python’s stdlib, 
which was originally inspired by JUnit and has a similar flavor as major unit testing frameworks in other languages. 
It supports test automation, sharing of setup and shutdown code for tests, aggregation of tests into collections, 
and independence of the tests from the reporting framework.</p>




    
      <h2 id="test-runners">
        
        <a href="#test-runners">Test Runners</a>
        
      </h2>

<p><a href="https://github.com/tox-dev/tox"><strong>tox</strong></a> is a command-line driven CI frontend and development task automation tool.</p>

<p>tox creates virtual environments for all configured so-called <code>testenvs</code>, it then installs the project and other necessary dependencies and runs the configured set of commands:</p>

<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598270513268/Q1-E6b6nw.png" alt="image.png"></p>




    
      <h2 id="e2e-testing-gui--frontend">
        
        <a href="#e2e-testing-gui--frontend">E2E Testing (GUI / Frontend)</a>
        
      </h2>

<p><a href="https://github.com/SeleniumHQ/selenium/"><strong>Selenium</strong></a> is an umbrella project encapsulating a variety of tools and 
libraries enabling web browser automation. Selenium specifically provides an infrastructure for the W3C WebDriver 
specification — a platform and language-neutral coding interface compatible with all major web browsers.</p>



<p><a href="https://github.com/locustio/locust"><strong>Locust</strong></a> is an easy to use, scriptable, and scalable performance testing tool.
 You define the behavior of your users in regular Python code, instead of using a clunky UI or domain-specific 
 language. This makes Locust infinitely expandable and very developer-friendly.</p>



<p><a href="https://github.com/DevExpress/testcafe"><strong>TestCafe</strong></a> is a Node.js tool to automate end-to-end web testing. Write 
tests in JS or TypeScript, run them, and view results.</p>

<ul>
  <li><strong>Works on all popular environments</strong>: TestCafe runs on Windows, MacOS, and Linux. It supports desktop, mobile, remote and cloud <a href="https://devexpress.github.io/testcafe/documentation/using-testcafe/common-concepts/browsers/browser-support.html">browsers</a> (UI or headless).</li>
  <li><strong>1 minute to set up</strong>: You <a href="https://devexpress.github.io/testcafe/faq/#i-have-heard-that-testcafe-does-not-use-selenium-how-does-it-operate">do not need WebDriver</a> or any other testing software. Install TestCafe with one command, and you are ready to test: <code>npm install -g testcafe</code></li>
  <li><strong>Free and open source</strong>: TestCafe is free to use under the <a href="https://github.com/DevExpress/testcafe/blob/master/LICENSE">MIT license</a>. <a href="#plugins">Plugins</a> provide custom reports, integration with other tools, launching tests from IDE, etc. You can use the plugins made by the GitHub community or make your own.</li>
</ul>

<p>Usage example:</p>

<p><img src="https://raw.githubusercontent.com/DevExpress/testcafe/master/media/install-and-run-test.gif" alt="Install TestCafe and Run a Test"></p>



<p><a href="https://github.com/asweigart/pyautogui"><strong>PyAutoGUI</strong></a> is a cross-platform GUI automation Python module for human beings. 
Used to programmatically control the mouse &amp; keyboard.</p>




    
      <h2 id="fake-data">
        
        <a href="#fake-data">Fake Data</a>
        
      </h2>

<p><a href="https://github.com/lk-geimfari/mimesis"><strong>Mimesis</strong></a> is a high-performance fake data generator for Python, which
provides data for a variety of purposes in a variety of languages. The
fake data could be used to populate a testing database, create fake API
endpoints, create JSON and XML files of arbitrary structure, anonymize
data taken from production and etc.</p>

<p>The key features are:</p>

<ul>
  <li><strong>Performance</strong>: The <a href="https://mimesis.name/foreword.html#performance">fastest</a> data generator available for Python.</li>
  <li><strong>Extensibility</strong>: You can create your own data providers and use them with Mimesis.</li>
  <li><strong>Generic data provider</strong>: The <a href="https://mimesis.name/getting_started.html#generic-provider">simplified</a> access to all the providers from a single object.</li>
  <li><strong>Multilingual</strong>: Supports data for <a href="https://mimesis.name/getting_started.html#locales">a lot of languages</a>.</li>
  <li><strong>Data variety</strong>: Supports <a href="https://mimesis.name/api.html">a lot of data providers</a> for a variety of purposes.</li>
  <li><strong>Schema-based generators</strong>: Provides an easy mechanism to generate data by the schema of any complexity.</li>
  <li><strong>Country-specific data providers</strong>: Provides data specific only for <a href="https://mimesis.name/api.html#builtin-data-providers">some countries</a>.</li>
</ul>




    
      <h2 id="mocking">
        
        <a href="#mocking">Mocking</a>
        
      </h2>

<p><a href="https://docs.python.org/3/library/unittest.mock.html"><strong>unittest.mock</strong></a> is a library from Python’s stdlib for mocking. 
It allows you to replace parts of your system under test with mock objects and make assertions about how they have been used.</p>

<p><code>unittest.mock</code> provides a core <code>Mock</code> class removing the need to create a host of stubs throughout your test suite. 
After performing an action, you can make assertions about which methods / attributes were used and arguments they
were called with. You can also specify return values and set needed attributes in the normal way.</p>



<p><a href="https://github.com/spulec/freezegun"><strong>FreezeGun</strong></a> is a library that allows your Python tests to travel through time
 by mocking the datetime module.</p>

<p>Once the decorator or context manager have been invoked, all calls to <code>datetime.datetime.now()</code>, 
<code>datetime.datetime.utcnow()</code>, <code>datetime.date.today()</code>, <code>time.time()</code>, <code>time.localtime()</code>, <code>time.gmtime()</code>, and <code>time.strftime()</code>
will return the time that has been frozen.</p>



<p><a href="https://github.com/patrys/httmock"><strong>HTTPretty</strong></a> is an HTTP client mocking tool for Python - inspired by Fakeweb for Ruby.</p>

<p>Common use cases:</p>

<ul>
  <li>Test-driven development of API integrations</li>
  <li>Fake responses of external APIs</li>
  <li>Record and playback HTTP requests</li>
</ul>



<p><a href="https://github.com/getsentry/responses"><strong>responses</strong></a> is a utility library for mocking out the requests Python library.</p>

<p>Example of usage:</p>

<div><div><pre><code><span>import</span> <span>responses</span>
<span>import</span> <span>requests</span>

<span>@</span><span>responses</span><span>.</span><span>activate</span>
<span>def</span> <span>test_simple</span><span>():</span>
    <span>responses</span><span>.</span><span>add</span><span>(</span><span>responses</span><span>.</span><span>GET</span><span>,</span> <span>'http://twitter.com/api/1/foobar'</span><span>,</span>
                  <span>json</span><span>=</span><span>{</span><span>'error'</span><span>:</span> <span>'not found'</span><span>},</span> <span>status</span><span>=</span><span>404</span><span>)</span>

    <span>resp</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>'http://twitter.com/api/1/foobar'</span><span>)</span>

    <span>assert</span> <span>resp</span><span>.</span><span>json</span><span>()</span> <span>==</span> <span>{</span><span>"error"</span><span>:</span> <span>"not found"</span><span>}</span>

    <span>assert</span> <span>len</span><span>(</span><span>responses</span><span>.</span><span>calls</span><span>)</span> <span>==</span> <span>1</span>
    <span>assert</span> <span>responses</span><span>.</span><span>calls</span><span>[</span><span>0</span><span>].</span><span>request</span><span>.</span><span>url</span> <span>==</span> <span>'http://twitter.com/api/1/foobar'</span>
    <span>assert</span> <span>responses</span><span>.</span><span>calls</span><span>[</span><span>0</span><span>].</span><span>response</span><span>.</span><span>text</span> <span>==</span> <span>'{"error": "not found"}'</span>
</code></pre></div></div>




    
      <h2 id="code-coverage">
        
        <a href="#code-coverage">Code coverage</a>
        
      </h2>

<p><a href="https://github.com/nedbat/coveragepy"><strong>Coverage.py</strong></a> measures code coverage, typically during test execution. It uses 
the code analysis tools and tracing hooks provided in the Python standard library to determine which lines are 
executable, and which have been executed.</p>




    
      <h2 id="object-factories">
        
        <a href="#object-factories">Object Factories</a>
        
      </h2>

<p><a href="https://github.com/FactoryBoy/factory_boy"><strong>factory_boy</strong></a> is a fixtures replacement based on thoughtbot’s factory_bot.</p>

<p>As a fixtures replacement tool, it aims to replace static, hard to maintain fixtures with easy-to-use 
factories for complex objects.</p>




    
      <h2 id="code-style">
        
        <a href="#code-style">Code Style</a>
        
      </h2>

<p><a href="https://github.com/wemake-services/wemake-python-styleguide"><strong>wemake-python-styleguide</strong></a> is is strictest and most 
opinionated python linter ever.</p>

<p>Goals of WPS:</p>

<ol>
  <li>Enforce <code>Python 3.6+</code> usage</li>
  <li>Significantly reduce complexity of your code and make it more maintainable</li>
  <li>Enforce “There should be one– and preferably only one –obvious way to do it” rule</li>
  <li>Create consistent coding and naming style</li>
</ol>



<p><a href="https://github.com/PyCQA/pycodestyle"><strong>pycodestyle</strong></a> is a tool to check your Python code against some of the style 
conventions in PEP8.</p>

<p>Features:</p>

<ul>
  <li>Plugin architecture: Adding new checks is easy.</li>
  <li>Parseable output: Jump to error location in your editor.</li>
  <li>Small: Just one Python file, requires only <code>stdlib</code>. You can use just the <code>pycodestyle.py</code> file for this purpose.</li>
  <li>Comes with a comprehensive test suite.</li>
</ul>



<p><a href="https://github.com/psf/black"><strong>Black</strong></a> is the uncompromising Python code formatter. By using it, you agree to cede
control over minutiae of hand-formatting. In return, <em>Black</em> gives you speed,
determinism, and freedom from <code>pycodestyle</code> nagging about formatting. You will save time
and mental energy for more important matters.</p>



<p><a href="https://github.com/google/yapf"><strong>yapf</strong></a> is a formatter for Python files.</p>

<p>YAPF takes a different approach. It’s based off of <code>clang-format</code>, developed by Daniel Jasper. In essence, 
the algorithm takes the code and reformats it to the best formatting that conforms to the style guide, even if the 
original code didn’t violate the style guide. The idea is also similar to the ‘gofmt’ tool for the Go programming 
language: end all holy wars about formatting - if the whole codebase of a project is simply piped through YAPF 
whenever modifications are made, the style remains consistent throughout the project and there’s no point 
arguing about style in every code review.</p>




    
      <h2 id="typing">
        
        <a href="#typing">Typing</a>
        
      </h2>

<p><a href="https://github.com/python/mypy"><strong>mypy</strong></a> is an optional static type checker for Python. You can add type 
hints (PEP 484) to your Python programs, and use <code>mypy</code> to type check them statically. Find bugs in your 
programs without even running them!</p>

<p>Here is a small example to whet your appetite (Python 3):</p>

<div><div><pre><code><span>from</span> <span>typing</span> <span>import</span> <span>Iterator</span>

<span>def</span> <span>fib</span><span>(</span><span>n</span><span>:</span> <span>int</span><span>)</span> <span>-&gt;</span> <span>Iterator</span><span>[</span><span>int</span><span>]:</span>
    <span>a</span><span>,</span> <span>b</span> <span>=</span> <span>0</span><span>,</span> <span>1</span>
    <span>while</span> <span>a</span> <span>&lt;</span> <span>n</span><span>:</span>
        <span>yield</span> <span>a</span>
        <span>a</span><span>,</span> <span>b</span> <span>=</span> <span>b</span><span>,</span> <span>a</span> <span>+</span> <span>b</span>
</code></pre></div></div>



<p><a href="https://github.com/facebook/pyre-check"><strong>Pyre</strong></a> is a performant type checker for Python compliant with PEP 484. 
Pyre can analyze codebases with millions of lines of code incrementally – providing instantaneous feedback to 
developers as they write code.</p>

<p>Pyre ships with Pysa, a security-focused static analysis tool we’ve built on top of Pyre that reasons about data flows 
in Python …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://isaak.dev/2020/08/python-libraries-to-make-your-code-readable-and-maintainable">https://isaak.dev/2020/08/python-libraries-to-make-your-code-readable-and-maintainable</a></em></p>]]>
            </description>
            <link>https://isaak.dev/2020/08/python-libraries-to-make-your-code-readable-and-maintainable</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275037</guid>
            <pubDate>Tue, 25 Aug 2020 19:25:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Do We Debug?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24274930">thread link</a>) | @iamflimflam1
<br/>
August 25, 2020 | https://blog.cmgresearch.com/2020/08/25/how-do-we-debug.html | <a href="https://web.archive.org/web/*/https://blog.cmgresearch.com/2020/08/25/how-do-we-debug.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <h2 id="a-programming-classic">A programming classic</h2>

<p>There’s a classic programmer joke - the stages of debugging:</p>

<ol>
  <li>That can’t happen</li>
  <li>That doesn’t happen on my machine</li>
  <li>That shouldn’t happen</li>
  <li>Why does that happen</li>
  <li>Oh, I see…</li>
  <li>How did that ever work?</li>
</ol>

<p>It’s funny because it’s true.</p>

<p>But why do we laugh at this? It’s a pretty terrible state of affairs.</p>

<p>There’s a lot to unpack in this joke.</p>

<h3 id="that-cant-happen">“That can’t happen”</h3>

<p>First off why is our reaction immediately to deny the very existence of the bug? It’s unlikely that someone will have gone to the effort of cooking up an elaborate lie to waste our time looking for a non-existent bug.</p>

<p>Bugs are a violation of expectation, someone expected the system to behave in a certain way and it didn’t.</p>

<p>From a developers point of view, our expectations have also been violated. We told the computer to do one thing, and it has decided to something completely different.</p>

<p>This leads to the classic - “there must be a bug in the compiler” or “must be user error” and the equally popular blame the tools: “it’s because we’re using XYZ language or framework - everyone knows it’s buggy/broken”.</p>

<p>Developers take a lot of pride in their work - we’re generally compensated well because we are considered to be experts in our field - suddenly we’re exposed as being just as fallible as the next person.</p>

<p>Obviously the “That can’t happen” is a foolish response. A computer just does what it is told to do. It is not an evil mischievous imp that is deliberately trying to sabotage our work.</p>

<p>We need to change our immediate response to one of acceptance - there’s a bug, no point in pretending it doesn’t exist.</p>

<h3 id="that-doesnt-happen-on-my-machine">“That doesn’t happen on my machine”</h3>

<p>What kind of a developer just chucks code over the wall without testing it? Of <em>course</em> it works on my machine!</p>

<p>Well, what can we say about this one? We could just lump this in with the denial of the bug existence, but it’s worth breaking it out into its own discussion.</p>

<p>In complex systems this is a remote possibility, code that works in isolation may not work when deployed. Interactions between different parts of a system can cause the behaviour to change in unexpected ways.</p>

<p>However, in a well-architected system this should be rare, and if it’s really happening then it’s a sign that something is wrong.</p>

<p>There’s no point saying “it works on my machine” until you’ve actually gone and tried to reproduce the bug on your machine.</p>

<p>Once you can prove categorically that it works on your machine then you can add that to the evidence pile for debugging the problem.</p>

<h3 id="that-shouldnt-happen">“That shouldn’t happen”</h3>

<p>“Umm, yes, that’s why I’ve reported it as a bug” would be the facetious reply.</p>

<p>But this is another facet of the “I told the computer to do this, but instead it’s doing that”. It’s a violation of expectations on the developer’s side of things.</p>

<p>This is usually the phase of acceptance. We’ve now reached the point where we agree that something is wrong, we’ve seen the bug with our own eyes, it’s something wrong with what we’ve done, there’s no more excuses to hide behind.</p>

<h3 id="why-does-that-happen">“Why does that happen?”</h3>

<p>This is where things start to get interesting. This is the fun part bug bashing.</p>

<p>Why is this bug happening? What’s our hypothesis for what we are seeing and how do we test it?</p>

<h3 id="oh-i-see">“Oh, I see”</h3>

<p>The lightbulb moment of insight, through investigation you’ve developed a hypothesis of why the bug is happening and you have an idea on how to fix it.</p>

<p>The problem now becomes impossible not to see. It’s obvious. How did this code ever ship? Which moves up nicely onto the next stage.</p>

<h3 id="how-did-that-ever-work">“How did that ever work?”</h3>

<p>Hindsight is a wonderful thing.</p>

<p>Now that you know how to create the bug, and you know how the code is wrong, you’re wondering which idiot wrote it (spoiler alert - git blame will point the finger at you).</p>

<p>The code could never have worked properly. You’ll start to wonder how many other bits of the codebase are complete nonsense.</p>

<h2 id="adjusting-our-approach">Adjusting our approach</h2>

<p>Let’s turn the programming classic on its head and rewrite the stages of debugging:</p>

<ol>
  <li>This is happening</li>
  <li>Research</li>
  <li>Create a hypothesis</li>
  <li>Test hypothesis</li>
  <li>Fix the problem</li>
  <li>How do we stop this happening again?</li>
</ol>

<h3 id="this-is-happening">“This is happening”</h3>

<p>No point denying it - there’s a bug, I’m glad you found it.</p>

<h3 id="research">Research</h3>

<p>We need to gather information on the bug:</p>

<ul>
  <li>how do we reproduce it?</li>
  <li>what test data do we need?</li>
  <li>how much of the system do we need to run recreate it?</li>
  <li>what’s the minimum I need to recreate to debug it?</li>
  <li>which part of the codebase is it happening in?</li>
  <li>which bit of code is the likely problem?</li>
  <li>do we have any relevant logs from when the problem occurred?</li>
</ul>

<p>The more information we can gather the better.</p>

<h3 id="create-a-hypothesis">Create a hypothesis</h3>

<p>Our research should have pointed us at the potential problem, we should have developed enough knowledge to form a working hypothesis on what the bug is caused by. We should hopefully be looking at the bit of code that is wrong and have an idea on how to fix it.</p>

<h3 id="test-hypothesis">Test hypothesis</h3>

<p>How are you going to test your fix works?</p>

<p>Before jumping in and changing code can you definitely recreate the bug? Does it happen consistently in your test environment?</p>

<p>Can you write a unit test to recreate the bug?</p>

<p>When you apply your fix does the test now pass? When you run through the steps to recreate does it now consistently work?</p>

<h3 id="fix-the-problem">Fix the problem</h3>

<p>If we’re lucky the previous step proves that our thinking was correct, we’ve changed the code and everything works.</p>

<p>Clean up any debugging code go through code reviews and deploy - everyone is happy!</p>

<p>Don’t forget to check that you’ve not broken anything else…</p>

<p>The bug is fixed when the person who raised the bug in the first place is happy.</p>

<h3 id="how-do-we-stop-this-happening-again">How do we stop this happening again?</h3>

<p>This is the real value in finding and fixing bugs. The bug should never have happened in the first place.</p>

<ul>
  <li>Are we missing unit tests for this part of the codebase?</li>
  <li>Have we missed a whole class of unit tests across the codebase that make this kind of bug more likely?</li>
  <li>Are we missing integration tests?</li>
  <li>Do we have automated tests to catch these bugs?</li>
  <li>Is there something wrong in our process that allowed this bug to slip through the net?</li>
</ul>

<h2 id="types-of-bugs">Types of Bugs</h2>

<p>What kind of bugs do we encounter? And how do we fix them?</p>

<h3 id="easy-bugs">Easy(?) Bugs</h3>

<p>There’s a set of bugs that can be classed as “easy(?)”. There’s a question mark next to the easy as a bug being obvious or repeatable does not necessarily mean the finding the underlying cause and fixing it is necessarily easy.</p>

<ul>
  <li>UI Bugs</li>
  <li>Bugs of Omission or Misinterpretation</li>
  <li>Repeatable bugs</li>
</ul>

<h3 id="ui-bugs">UI Bugs</h3>

<p>It functions but it doesn’t look right.</p>

<p>UI bugs tend to revolve around the styling and positioning of elements.</p>

<p>Well organised companies will have wireframes and high definition mockups that you should be working from. They should have style guides and component libraries that tell you how things should look and behave.</p>

<p>Sometimes, we are working in the dark, there may not have been time or resources to design wireframes and mockups, you may be working from some scribbles on a napkin - make sure you fit with the rest of the application. Don’t break people’s expectations!</p>

<p>Another source of these bugs are different device formats - maybe it’s fine on your large desktop monitor, but on small laptops or mobile devices the UI you’ve created just doesn’t work.</p>

<p>There’s also a class of bugs around accessibility issues - these often get overlooked and unless attention is paid to this area it’s easy to forget about it only to have it flagged by a diligent QA person.</p>

<p>Solving these bugs should be straightforward:</p>

<ul>
  <li>What is it supposed to look like?</li>
  <li>Make it look right</li>
  <li>Test on the correct target devices and sizes</li>
</ul>

<p>There may be some fundamental process issues to be addressed here - someone knows what it should look like as they have raised the bug.</p>

<p>Why didn’t you know what it was supposed to look like when you built it?</p>

<h3 id="bugs-of-omission-or-misinterpretation">Bugs of Omission or Misinterpretation</h3>

<p>You thought you’d built the right thing.</p>

<p>You didn’t…</p>

<p>In theory, this should be an easy one to fix - find out what was supposed to be built, build it…</p>

<p>There are some questions to be asked around what went wrong in this situation - was the task not specified in enough detail, is there a communication gap between the product managers and the dev team that leads to the wrong thing being built?</p>

<p>Or did you just fundamentally misunderstand what was being asked of you?</p>

<p>Sometimes it’s simply a case of trying to hit a moving target. By the time you’ve finished building something everyone’s understanding of what should be built has changed. Expectations have changed and someone forgot to tell you…</p>

<p>Something is broken in your process - it’s important to work out what it is if this class of bug keeps occurring.</p>

<h3 id="repeatable-bugs">Repeatable bugs</h3>

<p>Every time I do these steps, this thing happens, it’s not what I expect to happen, it should do this instead.</p>

<p>This is a nice class of bugs - repeatable with a clear set of steps to recreate the problem.</p>

<p>Should be an easy fix:</p>

<ul>
  <li>Look at the application logs whilst recreating the bug</li>
  <li>Inspect any relevant crash logs and stack traces</li>
  <li>Run through the steps with a debugger attached and have it break on exceptions</li>
  <li>Simply walk through the code and sanity check it - does it make sense?</li>
</ul>

<p>However, for new developers or people unfamiliar with the codebase these can also be extremely frustrating bugs.</p>

<p>I can happily recreate the bug, it breaks on my machine, I have no idea where to even start looking in the codebase for where to fix it.</p>

<p>Senior developer strolls over, takes one look at the bug and immediately brings up the line of code that is the problem.</p>

<p>Someone who knows the codebase intimately will probably know where most data in the system is coming from and will appear to have some magical power for identifying where a bug it.</p>

<p>This is why bug fixing a few simple bugs can be such a good onboarding process.</p>

<p>What can we do if we don’t know the codebase?</p>

<p>We’ll need to start employing our powers of detection and deduction.</p>

<p>Look at the architecture of the system, how does data flow from one place to another. What are good …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.cmgresearch.com/2020/08/25/how-do-we-debug.html">https://blog.cmgresearch.com/2020/08/25/how-do-we-debug.html</a></em></p>]]>
            </description>
            <link>https://blog.cmgresearch.com/2020/08/25/how-do-we-debug.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24274930</guid>
            <pubDate>Tue, 25 Aug 2020 19:16:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Firefox’s criteria for installable web apps]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24274732">thread link</a>) | @SimeVidas
<br/>
August 25, 2020 | https://webplatform.news/issues/2020-08-25 | <a href="https://web.archive.org/web/*/https://webplatform.news/issues/2020-08-25">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://webplatform.news/issues/2020-08-25</link>
            <guid isPermaLink="false">hacker-news-small-sites-24274732</guid>
            <pubDate>Tue, 25 Aug 2020 18:58:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open source platform for making synthetic data, sharing it]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24274535">thread link</a>) | @watson1008
<br/>
August 25, 2020 | https://gretel.ai/blog/readme-v2 | <a href="https://web.archive.org/web/*/https://gretel.ai/blog/readme-v2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main"><div><div><h2>We founded Gretel based on our beliefs that data shouldn’t be scary.</h2><figure><img src="https://uploads-ssl.webflow.com/5ec4696a9b6d337d51632638/5f45361b7ebe7f6e8e7ed9cd_Readmev2.png" alt="" sizes="(max-width: 767px) 100vw, 586.95654296875px" srcset="https://uploads-ssl.webflow.com/5ec4696a9b6d337d51632638/5f45361b7ebe7f6e8e7ed9cd_Readmev2-p-1080.png 1080w, https://uploads-ssl.webflow.com/5ec4696a9b6d337d51632638/5f45361b7ebe7f6e8e7ed9cd_Readmev2.png 1440w"></figure><div><p><strong>It’s way too hard- sometimes seemingly impossible- to safely share and collaborate with sensitive data.</strong> We have a solution to this problem that we and every developer faces each day. We founded Gretel based on our beliefs that data shouldn’t be scary, and for you to compete in today’s world, you need to be able to use and learn from your data. </p><p>Companies like Amazon, Google, and Apple have the resources to give the developers the best of both worlds- data privacy and streamlined access to data. We’re here to make that possible for any developer.</p><p>In February we published our first <a href="https://gretel.ai/blog/gretel-readme">README</a> and started laying out our goal of enabling developers to safely share and collaborate with sensitive data, and our vision of democratizing building with data so everyone can use it. We asked for your feedback and ideas, and promised to share research, open source code, and provide examples. </p><p>In the 6 months since then, we have had conversations with nearly 100 developers and companies to understand the barriers to working with sensitive data and how we can apply privacy-enhancing technology to break down those barriers. Here is what we learned:</p><ul role="list"><li><strong>It can take developers months to get access to sensitive data to test an idea</strong>. Often this requires PM and legal approvals, snap-shots of production databases, and manual anonymization of sensitive fields. </li><li><strong>Privacy is an engineering problem, not a policy problem</strong>. Policies are open to interpretation, lack enforceability at different stages of a workflow, and eventually get abused. </li><li><strong>Fairness and ethics in AI is incredibly important. Datasets used to power AI in our lives are often limited and imbalanced, leading to bias against users and groups. &nbsp;</strong>‍</li></ul><p>In the past year, we have built a set of open-source SDKs that enable developers to label and share access to data, composable APIs to enable transformations to streaming data, and an &nbsp;open-source AI-based synthetic data library that can generate artificial datasets from sensitive data with <a href="https://gretel.ai/blog/using-generative-differentially-private-models-to-build-privacy-enhancing-synthetic-datasets-from-real-data">provable privacy guarantees</a>, and automatically boost minority classes in datasets to <a href="https://gretel.ai/blog/reducing-ai-bias-with-synthetic-data">reduce AI bias</a>.</p><p>Today, we are thrilled to release <a href="https://console.gretel.cloud/login">Gretel’s public beta to any developer</a>. It’s free, and you can get started in minutes with one of our guides for <a href="https://gretel.ai/gretel-cloud-faqs/how-do-i-get-started">labeling and sharing a dataset in 2 minutes</a>, or even generating <a href="https://www.youtube.com/watch?v=gS7kpR-LJTs&amp;t=144s">your first synthetic dataset</a> with differential privacy guarantees.</p><p>We are building Gretel for developers like you, so don’t be shy. Please follow us here, <a href="https://twitter.com/gretel_ai">Twitter</a>, and <a href="https://github.com/gretelai/gretel-synthetics">Github</a>. Want to see for yourself? <a href="https://console.gretel.cloud/login">Get started now!</a> We’re <a href="https://gretel.ai/cdn-cgi/l/email-protection#ea8283aa8d988f9e8f86c48b83"><span data-cfemail="cda5a48daabfa8b9a8a1e3aca4">[email&nbsp;protected]</span></a>.<br></p></div><a href="https://gretel.ai/blog"><p>View all posts</p></a></div></div></div></div>]]>
            </description>
            <link>https://gretel.ai/blog/readme-v2</link>
            <guid isPermaLink="false">hacker-news-small-sites-24274535</guid>
            <pubDate>Tue, 25 Aug 2020 18:40:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modern algebra in 16 tables and 200 symbols]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24274474">thread link</a>) | @R3G1R
<br/>
August 25, 2020 | https://mathvault.ca/hub/higher-math/math-symbols/algebra-symbols/ | <a href="https://web.archive.org/web/*/https://mathvault.ca/hub/higher-math/math-symbols/algebra-symbols/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div id="theme-content-section"><div><section data-css="tve-u-16ec5d248bb"><p><span>A</span>lgebra is a subfield of mathematics pertaining to the manipulation of symbols and their governing rules. The following is a compilation of <strong>symbols</strong> from the different branches of algebra, which include basic algebra, number theory, linear algebra and abstract algebra.</p><p>For readability purpose, these symbols are categorized by their function and topic into <strong>charts</strong> and <strong>tables</strong>. Other comprehensive lists of symbols — as categorized by subject&nbsp;and type — can be also found in the relevant pages below (or in the navigational panel).</p><div><div><div><figure><img loading="lazy" width="400" height="518" src="https://mathvault.ca/wp-content/uploads/Math-Symbols-eBook-Cover.png" alt="Cover of Math Vault's Comprehensive List of Mathematical Symbols eBook" title="Math Symbols eBook Cover"></figure><div><p>Prefer the PDF version instead?</p><p>Get the master summary of mathematical symbols in <strong>eBook form</strong> — along with each symbol’s usage and LaTeX code.</p></div></div></div></div><h2><span id="Constants"></span>Constants<span></span></h2><p>In algebra, <strong>constants</strong> are symbols used to denote key mathematical elements and sets. The following tables document the most common of these — along with each symbol’s name, usage and example.</p><p>(For common constants in general, see <a href="https://mathvault.ca/hub/higher-math/math-symbols/common-math-symbols/#Mathematical_Constants" target="_blank" rel="noopener noreferrer">common math constants</a>.)</p><h3><span id="Key_Mathematical_Elements"></span>Key Mathematical Elements<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$i$</td><td><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Imaginary_unit" target="_blank"><strong>Imaginary unit</strong></a></td><td>$i^2 + 1 = 0$</td></tr><tr><td>$\mathbf{0}$, $\vec{0}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Zero_element#Additive_identities" target="_blank" aria-label="Zero vector (opens in a new tab)" rel="noreferrer noopener">Zero vector</a></strong></td><td>$\mathbf{0} \ne 0$</td></tr><tr><td>$O$</td><td><strong><a href="https://en.wikipedia.org/wiki/Zero_matrix" target="_blank" aria-label="Zero matrix (opens in a new tab)" rel="noreferrer noopener">Zero matrix</a></strong></td><td>$O_{2 \times 3} = \\ \begin{pmatrix} 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 \end{pmatrix}$</td></tr><tr><td>$I$</td><td><strong><a aria-label="$n$-dimensional identity matrix (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Identity_matrix" target="_blank">Identity matrix</a></strong></td><td>$I_2 = \begin{pmatrix} 1 &amp; 0 \\ 0 &amp; 1 \end{pmatrix}$</td></tr><tr><td>$e$</td><td><a href="https://en.wikipedia.org/wiki/Identity_element" target="_blank" aria-label="Identity element of a group (opens in a new tab)" rel="noreferrer noopener"><strong>Identity element of a group</strong></a></td><td>For all $g \in G$, $g \circ e = e \circ g = g$.</td></tr></tbody></table></figure><h3><span id="Key_Mathematical_Sets"></span>Key Mathematical Sets<span></span></h3><p>In algebra, certain sets of numbers (or other more elaborated objects) tend to occur more frequently than others. These sets are often denoted by some variants of <strong>alphabetical letters</strong>&nbsp;— many of which are of the <a href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Latin-based_Alphabets" target="_blank" rel="noopener noreferrer">blackboard bold</a> typeface.</p><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$\mathbb{P}$</td><td>Set of <strong>prime numbers</strong></td><td>$127 \in \mathbb{P}$</td></tr><tr><td>$\mathbb{N}_0$</td><td>Set of <strong>natural numbers</strong> <br>(starting with $0$)</td><td>$0 \in \mathbb{N}_0$</td></tr><tr><td>$\mathbb{N}_1$</td><td>Set of <strong>natural numbers</strong><br>(starting with $1$)</td><td>$0 \notin \mathbb{N}_1$</td></tr><tr><td>$\mathbb{Z}$</td><td>Set of <strong>integers</strong></td><td>For all $x, y \in \mathbb{N}$, $x-y \in \mathbb{Z}$.</td></tr><tr><td>$\mathbb{Z}_+$</td><td>Set of <strong>positive integers</strong></td><td>$\mathbb{Z}_+ = \mathbb{N}_1$</td></tr><tr><td>$\mathbb{Q}$</td><td>Set of <strong>rational numbers</strong></td><td>$3.\overline{73} \in \mathbb{Q}$</td></tr><tr><td>$\mathbb{Q}_p$</td><td>Set of <strong><a href="https://en.wikipedia.org/wiki/P-adic_number#Introduction" target="_blank" aria-label="p-adic numbers (opens in a new tab)" rel="noreferrer noopener">p-adic numbers</a></strong></td><td>In $\mathbb{Q}_{10}$, $-1 = …999$ (as $1 +  …999  = 0$).</td></tr><tr><td>$\mathbb{A}$</td><td>Set of <strong><a aria-label="algebraic numbers (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Algebraic_number" target="_blank">algebraic numbers</a></strong></td><td>$\sqrt{5} + 3 \in \mathbb{A}$</td></tr><tr><td>$\mathbb{R}$</td><td>Set of <strong><a href="https://en.wikipedia.org/wiki/Real_number" target="_blank" aria-label="real numbers (opens in a new tab)" rel="noreferrer noopener">real numbers</a></strong></td><td>$i \notin \mathbb{R}$</td></tr><tr><td>$\mathbb{R}_+$</td><td>Set of <strong><a href="https://en.wikipedia.org/wiki/Positive_real_numbers" target="_blank" aria-label="positive real numbers (opens in a new tab)" rel="noreferrer noopener">positive real numbers</a></strong></td><td>For all $x, y \in \mathbb{R}_+$, $xy \in \mathbb{R}_+$.</td></tr><tr><td>$\mathbb{R}_-$</td><td>Set of <strong><a href="https://en.wikipedia.org/wiki/Real_number#Vocabulary_and_notation" target="_blank" aria-label="negative real numbers (opens in a new tab)" rel="noreferrer noopener">negative real numbers</a></strong></td><td>If $a, b \in \mathbb{R}_-$, then $a+b \in \mathbb{R}_-$.</td></tr><tr><td>$\mathbb{R}-\mathbb{Q}$</td><td>Set of <strong><a href="https://en.wikipedia.org/wiki/Irrational_number" target="_blank" aria-label="irrational numbers (opens in a new tab)" rel="noreferrer noopener">irrational numbers</a></strong></td><td>$\log 2 \in \mathbb{R}-\mathbb{Q}$</td></tr><tr><td>$\mathbb{I}$</td><td>Set of <strong><a href="https://en.wikipedia.org/wiki/Imaginary_number" target="_blank" aria-label="imaginary numbers (opens in a new tab)" rel="noreferrer noopener">imaginary numbers</a></strong></td><td>$5i \in \mathbb{I}, 2+3i \notin \mathbb{I}$</td></tr><tr><td>$\mathbb{C}$</td><td>Set of <strong><a href="https://en.wikipedia.org/wiki/Complex_number" target="_blank" aria-label="complex numbers (opens in a new tab)" rel="noreferrer noopener">complex numbers</a></strong></td><td>There exists a number $x \in \mathbb{C}$ such that $x^2 + 2x + 3 = 0$.</td></tr><tr><td>$\mathbb{H}$</td><td>Set of <strong><a href="https://en.wikipedia.org/wiki/Quaternion" target="_blank" aria-label="quaternions (opens in a new tab)" rel="noreferrer noopener">quaternions</a></strong></td><td>$5+6i-2j+3k \in \mathbb{H}$</td></tr><tr><td>$\mathbb{O}$</td><td>Set of <strong><a href="https://en.wikipedia.org/wiki/Octonion" target="_blank" aria-label="octonions (opens in a new tab)" rel="noreferrer noopener">octonions</a></strong></td><td>$e_0 + \cdots + e_7 \in \mathbb{O}$</td></tr><tr><td>$\mathbb{R}^n$</td><td>N-dimensional <strong><a href="https://en.wikipedia.org/wiki/Euclidean_space" target="_blank" aria-label="Euclidean space (opens in a new tab)" rel="noreferrer noopener">Euclidean space</a></strong></td><td>$\mathbf{i}, \mathbf{j}, \mathbf{k} \in \mathbb{R}^3$</td></tr><tr><td>$B_r(p)$</td><td><strong><a aria-label="Ball (opens in a new tab)" href="https://en.wikipedia.org/wiki/Ball_(mathematics)#In_general_metric_spaces" target="_blank" rel="noreferrer noopener">Open ball</a></strong> of radius $r$ around point $p$</td><td>$(0.5, 0.8, 0.4) \notin$<br>$B_1(0)$</td></tr><tr><td>$\mathbb{Z}_n$</td><td>Set of <strong><a href="https://en.wikipedia.org/wiki/Modular_arithmetic#Integers_modulo_n" target="_blank" aria-label="integers modulo $n$ (opens in a new tab)" rel="noreferrer noopener">integers modulo $n$</a></strong></td><td>$[24] = [11] \in \mathbb{Z}_{13}$</td></tr><tr><td>$R^{m \times n}$</td><td>Set of <strong><a aria-label="$m \times n$ matrices (opens in a new tab)" href="https://en.wikipedia.org/wiki/Matrix_(mathematics)#Notation" target="_blank" rel="noreferrer noopener">$m \times n$ matrices</a></strong> with entries from ring $R$</td><td>$\begin{pmatrix} 2 &amp; 3 \\ 1 &amp; 4 \end{pmatrix} \in \mathbb{R}^{2 \times 2}$</td></tr><tr><td>$GL_n(R)$</td><td>Group of <strong><a href="https://en.wikipedia.org/wiki/General_linear_group" target="_blank" aria-label="$n \times n$ invertible matrices (opens in a new tab)" rel="noreferrer noopener">$n \times n$ invertible matrices</a></strong> with entries from ring $R$</td><td>$\begin{pmatrix} 1 &amp; 0 \\ 2 &amp; 0 \end{pmatrix} \notin GL_2(\mathbb{R})$</td></tr><tr><td>$S_n$</td><td><strong><a href="https://en.wikipedia.org/wiki/Symmetric_group" target="_blank" aria-label="Symmetric group (opens in a new tab)" rel="noreferrer noopener">Symmetric group</a></strong> on a set of $n$ elements</td><td>$|S_n| = n!$</td></tr><tr><td>$R^{\times}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Unit_(ring_theory)#Group_of_units" target="_blank" aria-label="Group of units (opens in a new tab)" rel="noreferrer noopener">Group of units</a></strong> of ring $R$</td><td>$x \in \mathbb{Z}^{\times}$ if $x \in \mathbb{Z}$ and $\exists y \in \mathbb{Z}$ such that $xy = yx = 1$.</td></tr><tr><td>$R[x]$</td><td><strong><a href="https://en.wikipedia.org/wiki/Polynomial_ring" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">Polynomial ring</a></strong> with coefficients from ring $R$</td><td>$-3x^3 + x^2 + 2x +1$<br>$\in \mathbb{Z}[x]$</td></tr></tbody></table></figure><h2><span id="Variables"></span>Variables<span></span></h2><p>Since algebra is concerned with the manipulation of mathematical symbols, it often draws upon a wide range of <strong>variables</strong> as placeholders for varying objects and quantities. The following table documents the most common of these — along with their respective usage and example.</p><figure><table><thead><tr><th>Symbol Name</th><th>Used For</th><th>Example</th></tr></thead><tbody><tr><td>$m, n, p, q$</td><td><strong>Natural numbers</strong> and <strong>integers</strong></td><td>$m+n-2p = q$</td></tr><tr><td>$a, b, c$</td><td><strong>Coefficients</strong> of functions and equations</td><td>A linear equation has the general form $ax+by+c = 0$.</td></tr><tr><td>$x, y, z$</td><td><strong>Unknowns</strong> in functions and equations</td><td>If $14x + 2y = 4$, then $y = 2-7x$.</td></tr><tr><td>$\Delta$</td><td><strong><a href="https://en.wikipedia.org/wiki/Discriminant" target="_blank" aria-label="Discriminant (opens in a new tab)" rel="noreferrer noopener">Discriminant</a></strong></td><td>For <a aria-label="quadratic polynomials (opens in a new tab)" rel="noreferrer noopener" href="https://mathvault.ca/quadratic-factorisation/#The_General_Method_Theory" target="_blank">quadratic polynomials</a>, $\Delta = b^2 – 4ac$.</td></tr><tr><td>$i, j, k$</td><td><strong>Index variables</strong></td><td>$\displaystyle \prod_{(i,j)=(1,1)}^{(3,5)} \frac{i + j}{2}$</td></tr><tr><td>$z$</td><td><strong><a href="https://en.wikipedia.org/wiki/Complex_number" target="_blank" aria-label="Complex numbers (opens in a new tab)" rel="noreferrer noopener">Complex numbers</a></strong></td><td>$ |z_1 z_2| = |z_1| |z_2|$</td></tr><tr><td>$f(x)$, $g(x, y)$, $h(z)$</td><td><strong>Functions</strong></td><td>$g(f(x), 3) = h(x)$</td></tr><tr><td>$\mathbf{u}, \mathbf{v}, \mathbf{w}$<br>(or $\vec{u}, \vec{v}, \vec{w}$)</td><td><strong><a href="https://en.wikipedia.org/wiki/Euclidean_vector" target="_blank" aria-label="Vectors (opens in a new tab)" rel="noreferrer noopener">Vectors</a></strong></td><td>$2\mathbf{u} + 3\mathbf{v} = 5\mathbf{w}$</td></tr><tr><td>$U, V, W$</td><td><strong><a href="https://en.wikipedia.org/wiki/Vector_space" target="_blank" aria-label="Vector spaces (opens in a new tab)" rel="noreferrer noopener">Vector spaces</a></strong></td><td>$U$ is a subspace of vector space $V$.</td></tr><tr><td>$A, B, C$</td><td><strong><a href="https://en.wikipedia.org/wiki/Matrix_(mathematics)" target="_blank" aria-label="Matrices (opens in a new tab)" rel="noreferrer noopener">Matrices</a></strong></td><td>$AB \ne BA$</td></tr><tr><td>$\lambda$</td><td><strong><a href="https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors#Formal_definition" target="_blank" aria-label="Eigenvalues (opens in a new tab)" rel="noreferrer noopener">Eigenvalues</a></strong></td><td>Since $A\mathbf{v_0}=3\mathbf{v_0}$, $3$ is an eigenvalue of $A$.</td></tr><tr><td>$G, H$</td><td><strong><a href="https://en.wikipedia.org/wiki/Group_(mathematics)#Definition" target="_blank" aria-label="Groups (opens in a new tab)" rel="noreferrer noopener">Groups</a></strong></td><td>There exists an element $e \in G$ such that for all $x \in G$, $x \circ e = x$.</td></tr><tr><td>$\mathbb{F}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Field_(mathematics)" target="_blank" aria-label="Fields (opens in a new tab)" rel="noreferrer noopener">Fields</a></strong></td><td>A polynomial ring $\mathbb{F}[x]$ consists of polynomials with coefficients from field $\mathbb{F}$.</td></tr><tr><td>$X, Y$</td><td><strong><a href="https://en.wikipedia.org/wiki/Indeterminate_(variable)" target="_blank" aria-label="Indeterminates (opens in a new tab)" rel="noreferrer noopener">Indeterminates</a></strong></td><td>$3X^2Y + 5Y \in \\ \mathbb{Z}[X, Y]$</td></tr></tbody></table></figure><h2><span id="Delimiters"></span>Delimiters<span></span></h2><p>In mathematics, delimiters are symbols used to denote the separation between independent mathematical entities. The following table features some of the most common delimiters in algebra. For common delimiters in general, see <a href="https://mathvault.ca/hub/higher-math/math-symbols/common-math-symbols/#Delimiters" target="_blank" rel="noopener noreferrer">common delimiters</a>.</p><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$()$, $[]$, $\begin{pmatrix} x \\ y \\ z \end{pmatrix}$, $\begin{bmatrix} x &amp; y \\ w &amp; z\end{bmatrix}$</td><td><strong>Vectors/matrices indicators</strong></td><td>$\begin{pmatrix} 1 \\ 2 \\ 3 \end{pmatrix} +  \begin{pmatrix} 4 \\ 5 \\ 6 \end{pmatrix} = \\ \begin{pmatrix} 5 \\ 7 \\ 9 \end{pmatrix} $</td></tr><tr><td>$\{ \}$</td><td><strong>Set builder</strong></td><td>$\{ -1, 3.\overline{5}, \pi \} \in \mathbb{R}$</td></tr><tr><td>$\bigg\{$</td><td><strong><a href="https://en.wikipedia.org/wiki/Piecewise" target="_blank" aria-label="Piecewise-function (opens in a new tab)" rel="noreferrer noopener">Piecewise-function</a> indicator</strong></td><td>$|x| = \begin{cases} x &amp; x \ge 0 \\ -x &amp; x&lt;0 \end{cases}$</td></tr><tr><td>$:$, $\mid$</td><td><strong>“Such that” marker</strong></td><td>$\mathbb{Q} =$<br>$\displaystyle \left\{ \frac{x}{y} \,\middle|\, x \in \mathbb{Z}, y \in \mathbb{N} \right\}$</td></tr></tbody></table></figure><h2>Function-related Symbols<span></span></h2><p>As a foundational component of algebra, <strong>function</strong> plays a key role in establishing the rules pertaining to the manipulation of symbols. The following table documents some of the most common function-related operators and notational symbols — along with their meaning and example.</p><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$f : A \to B$,<br>$A \overset{f}{\to} B$</td><td><strong>Function mapping rule</strong><br>($f$ maps set $A$ to set $B$)</td><td>The function $f:\mathbb{N} \to \mathbb{R}$ with $f(x)=x^2$ is strictly increasing.</td></tr><tr><td>$f: x \mapsto y$,<br>$x \overset{f}{\mapsto} y$</td><td><strong>Function mapping rule</strong><br>($f$ maps element $x$ to element $y$)</td><td>The function $g: x \to x^3$ takes a number to its cube.</td></tr><tr><td>$\mathrm{dom}(f)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Domain_of_a_function" target="_blank" aria-label="Domain (opens in a new tab)" rel="noreferrer noopener">Domain</a></strong> of $f$</td><td>$\mathrm{dom} (g) = \mathbb{R}_+$</td></tr><tr><td>$\mathrm{ran}(f)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Range_of_a_function" target="_blank" aria-label="Range (opens in a new tab)" rel="noreferrer noopener">Range</a></strong> of $f$</td><td>If $\mathrm{ran} (f) = \mathbb{Z}$, then $f$ is an integer-valued function.</td></tr><tr><td>$f(x)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Image_(mathematics)#Image_of_an_element" target="_blank" aria-label="Image of element (opens in a new tab)" rel="noreferrer noopener">Image of element</a></strong> $x$ under function $f$</td><td>$f(g(3)) = f(5) = 7$</td></tr><tr><td>$f(X)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Image_(mathematics)#Image_of_a_subset" target="_blank" aria-label="Image of set (opens in a new tab)" rel="noreferrer noopener">Image of set</a> </strong>$X$ under function $f$</td><td>If $f(x) = \tan(x)$, then $f\left[ \left(-\frac{\pi}{2}, \frac{\pi}{2}\right) \right] = \mathbb{R}$</td></tr><tr><td>$f^{-1}(y)$</td><td><strong><a aria-label="Inverse function (opens in a new tab)" rel="noreferrer noopener" href="https://mathvault.ca/derivative-inverse-functions/#A_Primer_on_Inverse_Functions" target="_blank">Inverse function</a></strong> of $f$, <strong><a href="https://en.wikipedia.org/wiki/Image_(mathematics)#Inverse_image" target="_blank" aria-label="pre-image (opens in a new tab)" rel="noreferrer noopener">pre-image</a></strong> of element $y$ under function $f$</td><td>If $f$ is an <a href="https://mathvault.ca/math-glossary/#onetoone" target="_blank" aria-label="one-to-one (opens in a new tab)" rel="noreferrer noopener">one-to-one</a> function with $f(3)=5$, then $f^{-1}(5)=3$.</td></tr><tr><td>$f^{-1}(Y)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Image_(mathematics)#Inverse_image" target="_blank" aria-label="Pre-image (opens in a new tab)" rel="noreferrer noopener">Pre-image</a></strong> of set $Y$ under function $f$</td><td>If $g: \mathbb{R} \to \mathbb{R}$ with $g(x)=x^2$, then $g^{-1}([0, 1]) = [-1, 1]$.</td></tr><tr><td>$f \circ g$</td><td><strong><a href="https://mathvault.ca/chain-rule-derivative/#Chain_Rule_A_Review" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">Composite function</a></strong> $f$ of $g$</td><td>If $f(x)=5x$ and $g(x)=x^3$, then $(f \circ g) (x) = 5x^3$.</td></tr><tr><td>$f |_A$</td><td><strong><a aria-label="Restriction (opens in a new tab)" href="https://en.wikipedia.org/wiki/Restriction_(mathematics)" target="_blank" rel="noreferrer noopener">Restriction</a></strong> of function $f$ to set $A$</td><td>$\mathrm{dom}(f |_A) =$<br>$A \cap \mathrm{dom}(f)$</td></tr><tr><td>$R \circ S$</td><td><strong><a aria-label="Composite relation (opens in a new tab)" href="https://en.wikipedia.org/wiki/Composition_of_relations" target="_blank" rel="noreferrer noopener">Composite relation</a></strong> $R$ of $S$</td><td>If $(1, 3) \in R$ and $(3, 6) \in S$, then $(1, 6) \in R \circ S$.</td></tr><tr><td>$R^{-1}$</td><td><strong><a aria-label="Inverse relation (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Converse_relation" target="_blank">Converse relation</a></strong> of $R$</td><td>$(x, y) \in R^{-1} \iff$<br>$(y, x) \in R$</td></tr><tr><td>$R^{+}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Transitive_closure" target="_blank" aria-label="Transitive closure (opens in a new tab)" rel="noreferrer noopener">Transitive closure</a></strong> of relation $R$</td><td>For all transitive relations $T$ containing $R$, $R^{+} \subseteq T$.</td></tr></tbody></table></figure><h2><span id="Operators"></span>Operators<span></span></h2><p>In algebra, <strong>operators</strong> can be thought of as a special type of function mapping one or multiple mathematical entities to another, and are often given special names or notations due to their repeated occurrences.</p><p>In particular, these operators are often related to <strong>numbers</strong>, <strong>key functions</strong>, <strong>linear algebra</strong> and <strong>abstract algebra</strong> — the vast majority of which are found in the tables below. For common operators in general, see <a href="https://mathvault.ca/hub/higher-math/math-symbols/common-math-symbols/#Operators" target="_blank" rel="noopener noreferrer">common operators</a>.</p><h3>Number-related Operators<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$\gcd (x,y)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Greatest_common_divisor" target="_blank" aria-label="Greatest common divisor (opens in a new tab)" rel="noreferrer noopener">Greatest common divisor</a></strong> of $x$ and $y$</td><td>$\gcd (20, 15) = 5$</td></tr><tr><td>$\mathrm{lcm} (x, y)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Least_common_multiple" target="_blank" aria-label="Least common multiple (opens in a new tab)" rel="noreferrer noopener">Least common multiple</a></strong> of $x$ and $y$</td><td>$\mathrm{lcm} (x, y) = \dfrac{xy}{\gcd (x, y)}$</td></tr><tr><td>$x \bmod y$</td><td><strong><a aria-label=" (opens in a new tab)" rel="noreferrer noopener" href="https://mathvault.ca/long-division/#Euclidean_Division_Terminology" target="_blank">Remainder</a></strong> of $x$ when divided by $y$</td><td>$23 \bmod 4 = 3$</td></tr><tr><td>$|x|$</td><td><strong>Absolute value</strong> of $x$</td><td>$|-5| = |5| = 5$</td></tr><tr><td>$\lfloor x \rfloor$</td><td><strong><a href="https://en.wikipedia.org/wiki/Floor_and_ceiling_functions" target="_blank" aria-label="Floor (opens in a new tab)" rel="noreferrer noopener">Floor</a></strong> of $x$</td><td>$\lfloor 5.999 \rfloor = 5$</td></tr><tr><td>$\lceil x \rceil$</td><td><strong><a href="https://en.wikipedia.org/wiki/Floor_and_ceiling_functions" target="_blank" aria-label="Ceiling (opens in a new tab)" rel="noreferrer noopener">Ceiling</a></strong> of $x$</td><td>For all $x \in \mathbb{R}$,  $\lceil x \rceil-1 &lt; x \le \lceil x \rceil$.</td></tr><tr><td>$\lfloor x \rceil$, $\mathrm{round}(x)$</td><td><strong><a href="https://mathworld.wolfram.com/NearestIntegerFunction.html" target="_blank" aria-label="Nearest integer (opens in a new tab)" rel="noreferrer noopener">Nearest integer</a></strong> of $x$</td><td>$\mathrm{round}(3.5) =4$</td></tr><tr><td>$\max (A)$</td><td><strong>Maximum </strong>of set $A$</td><td>$\max \left( \{3, 11, 5 \}\right) = 11$</td></tr><tr><td>$\min (A)$</td><td><strong>Minimum</strong> of set $A$</td><td>For all $x \in A$, $\min (A) \le x$.</td></tr><tr><td>$\displaystyle \sum_{i=1}^{n} a_i$, $ \displaystyle \sum_{(i, j) = (1, 1)}^{(m, n)} a_{ij}$, $\displaystyle \sum_{i \in I} a_i$</td><td><strong><a href="https://en.wikipedia.org/wiki/Summation#Notation" target="_blank" aria-label="Sum (opens in a new tab)" rel="noreferrer noopener">Sum</a></strong> of $a_i$/$a_{ij}$</td><td>$\displaystyle \sum_{(i, j) = (1, 1)}^{(5, 5)} \frac{i+j}{2} \ge 15$</td></tr><tr><td>$\displaystyle \prod_{i=1}^n a_i$, $ \displaystyle \prod_{(i, j) = (1, 1)}^{(m, n)} a_{ij}$,  $\displaystyle \prod_{i \in I} a_i$</td><td><strong><a href="https://en.wikipedia.org/wiki/Multiplication#Capital_pi_notation" target="_blank" aria-label="Product (opens in a new tab)" rel="noreferrer noopener">Product</a></strong> of $a_i$/$a_{ij}$</td><td>$\displaystyle \prod_{i \in \{ 3, 5, 7\} } (i^2-1) =$<br>$8 \cdot 24 \cdot 48$</td></tr></tbody></table></figure><h3><span id="Key_Functions"></span>Key Functions<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$k_n x^n + \cdots + k_0 x^0$</td><td><strong><a href="https://mathvault.ca/polynomial-infinity/#Polynomials_A_Review" target="_blank" aria-label="Polynomial (opens in a new tab)" rel="noreferrer noopener">Polynomial</a></strong> of degree $n$ with coefficients $k_0, \ldots, k_n$</td><td>$2x^3 (x+1) = $<br>$2x^4 + 2x^3$</td></tr><tr><td>$e^x, \exp x$</td><td><strong><a href="https://en.wikipedia.org/wiki/Exponential_function" target="_blank" aria-label="Natural exponential function (opens in a new tab)" rel="noreferrer noopener">Natural exponential function</a></strong></td><td>For all $x \ge 3$, $e^x \ge 20$.</td></tr><tr><td>$b^x$</td><td><strong><a href="https://en.wikipedia.org/wiki/Exponential_function" target="_blank" aria-label="Exponential function (opens in a new tab)" rel="noreferrer noopener">Exponential function</a></strong> with base $b$</td><td>$2^{x+y} = 2^x \cdot 2^y$</td></tr><tr><td>$\ln x$</td><td><strong><a href="https://mathvault.ca/logarithm-theory/#Natural_Logarithm_Base_e" target="_blank" aria-label="Natural logarithmic function (opens in a new tab)" rel="noreferrer noopener">Natural logarithmic function</a></strong></td><td>$\ln 10 = \ln 2 + \ln 5$</td></tr><tr><td>$\log x$</td><td><strong><a aria-label="Common logarithmic function (opens in a new tab)" href="https://mathvault.ca/logarithm-theory/#Common_Logarithm_Base_10" target="_blank" rel="noreferrer noopener">Common logarithmic function</a></strong></td><td>$\log 1000000 = 6$</td></tr><tr><td>$\log_b x$</td><td><strong><a href="https://en.wikipedia.org/wiki/Logarithm" target="_blank" aria-label="Logarithmic function (opens in a new tab)" rel="noreferrer noopener">Logarithmic function</a></strong> of base $b$</td><td>$\log_{11} 23 = \dfrac{\ln 23}{\ln 11}$</td></tr><tr><td>$\sin x$, $\cos x$, $\tan x$, $\sec x$, $\csc x$, $\cot x$</td><td>6 <strong><a href="https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/#Trigonometric_Functions" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">trigonometric functions</a></strong> (sine, cosine, tangent, secant, cosecant, cotangent)</td><td>$\csc x = \dfrac{1}{\sin x}$</td></tr><tr><td>$\arcsin(x)$, $\sin^{-1}(x)$, $\arccos(x)$, $\cos^{-1}(x)$, $\arctan(x)$, $\tan^{-1}(x)$</td><td><strong><a aria-label="Inverse trigonometric functions (opens in a new tab)" href="https://en.wikipedia.org/wiki/Inverse_trigonometric_functions" target="_blank" rel="noreferrer noopener">Inverse trigonometric functions</a></strong> (inverse sine, inverse cosine, …</td></tr></tbody></table></figure></section></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mathvault.ca/hub/higher-math/math-symbols/algebra-symbols/">https://mathvault.ca/hub/higher-math/math-symbols/algebra-symbols/</a></em></p>]]>
            </description>
            <link>https://mathvault.ca/hub/higher-math/math-symbols/algebra-symbols/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24274474</guid>
            <pubDate>Tue, 25 Aug 2020 18:33:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stealing local files using Safari Web Share API]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24274405">thread link</a>) | @ra7
<br/>
August 25, 2020 | https://blog.redteam.pl/2020/08/stealing-local-files-using-safari-web.html?m=1 | <a href="https://web.archive.org/web/*/https://blog.redteam.pl/2020/08/stealing-local-files-using-safari-web.html?m=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://blog.redteam.pl/2020/08/stealing-local-files-using-safari-web.html?m=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24274405</guid>
            <pubDate>Tue, 25 Aug 2020 18:27:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Supreme Court of Canada Upholds Genetic Non-Discrimination Act]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24274306">thread link</a>) | @mpatobin
<br/>
August 25, 2020 | https://www.fightingblindness.ca/news/11-years-in-the-making-supreme-court-of-canada-passes-genetic-non-discrimination-act-gnda | <a href="https://web.archive.org/web/*/https://www.fightingblindness.ca/news/11-years-in-the-making-supreme-court-of-canada-passes-genetic-non-discrimination-act-gnda">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="readspeak">
			<div>
				<div>
					<div itemscope="" itemprop="mainContentOfPage" itemtype="http://schema.org/Article">
						<h5>Aug 12, 2020</h5>
						
						
																				
<p>In the past decades, genetic testing has played a growing
role in the diagnosis of inherited eye diseases such as retinitis pigmentosa, Usher
syndrome and Leber Congenital Amaurosis. Not only can a genetic test
information provide accuracy about how the eye disease will progress, but it also
takes on a greater significance as new gene-specific treatments, such as gene
therapy and gene editing are starting to be developed. &nbsp;Without a genetic test result, individuals might
not be eligible to participate in clinical trials or to receive these new treatments.
</p>



<p>To protect the privacy of Canadians’ genetic test
information, in 2009, Huntington Society of Canada, Fighting Blindness Canada
(FBC), Parkinson Canada, and other leading Canadian health charities came
together to be part of the Canadian Coalition for Genetic Fairness (CCGF), all
meeting at Parliament Hill to discuss genetic discrimination, providing a voice
for their patient communities. For 11 years, CCGF would work endlessly to
advocate for the protection of genetic test information privacy, sharing real
life stories from across Canada. </p>



<p>In May 2017, the Genetic
Non-Discrimination Act (GNDA) received Royal Assent and became law. However, the
Quebec government appealed this decision and did not agree that the GNDA was a valid act of Parliament’s
criminal law power, putting the GNDA at risk and forcing the CCGF to
refer it to the Supreme Court of Canada for their opinion.</p>



<p>What did unprotected genetic test information mean for Canadians? Simply put, if you had a genetic test done, the information was not private and could be used against you. This means it was possible for companies, such as insurance companies, to demand to see your genetic test information, which could be used to deny you coverage. Or an employer might use the genetic test information to make assumptions about your health and ability. </p>



<p>While the European Union (28 countries) were signatories to the Oviedo Convention that was first presented in 1997 (agreeing to not use genetic test information), Canada was falling behind. &nbsp;As science evolved and genetic testing became more routine, researchers and medical experts came forth to express their concern and the need to protect the privacy of genetic test information. </p>



<p>Canadian researchers like Dr. Yvonne Bombard (a genomics health services researcher and Scientist at the Li Ka Shing Knowledge Institute of St. Michael’s Hospital, Toronto) voiced concerns that if the Canadian government did not protect genetic test information, people would be afraid to participate in clinical trials, putting research and future medical advancements in jeopardy. In a written testimony to the Standing Senate Committee Dr. Bombard stated, </p>



<blockquote><p>“Genetic discrimination – the differential treatment of an individual based on genetic information – represents an important social risk associated with genetic testing. The extent and impact of genetic discrimination has been the subject of much public concern and policy attention.”<a href="#_edn1">[i]</a> <a href="https://sencanada.ca/content/sen/committee/421/RIDR/Briefs/Bombard-UnivTorontoWrittenTestimony_e.pdf">(access full testimonial and results from her study)</a></p></blockquote>



<p>After many years of dedication and hard work, on July 3rd,
2020 the Supreme Court of Canada upheld the GNDA. Passing of the act was no
easy task. CCGF experienced several barriers, including push back from
insurance companies, government turnover, and the belief from some that genetic
discrimination was not real. </p>



<p>Bev Heim-Myers, CCGF Chair explains, </p>



<blockquote><p>“Getting to where we are today was not easy but it was a huge milestone for all Canadians and worth the fight.” Sharing further, “…years ago, many thought we were doing the impossible. Genetic discrimination –what was that? Conversations were business centred not patient centered. Together, we flipped the conversation.”</p></blockquote>



<p>Champion volunteers came together from organizations like FBC to share their stories and get the attention of Parliament. </p>



<blockquote><p>“People’s lives were being ruined based on perception,” Bev explains. “Seniors were being denied entrance into long-term care, children denied adoption –genetic discrimination was ruining lives and it was time that governments listened.”</p></blockquote>



<p>For Bev and other CCGF representatives like Sharon Colle, former President and CEO of FBC, the fight to pass the GNDA was not about if, but when. The act’s undivided purpose was (and remains) to protect the health and privacy of all Canadians. And, as champion voices grew louder over the course of the 11 years it took to get the act in place, it was clear that the well-being of Canadians came first.</p>



<p>FBC is honoured to be part of this historic endeavor that will protect generations to come. With the support of our dedicated vision loss community, we brought a voice to the thousands of individuals living with inherited eye diseases and the millions of Canadians living with genetic conditions. </p>



<hr>



<p><a href="#_ednref1">[i]</a> <a href="https://sencanada.ca/content/sen/committee/421/RIDR/Briefs/Bombard-UnivTorontoWrittenTestimony_e.pdf">https://sencanada.ca/content/sen/committee/421/RIDR/Briefs/Bombard-UnivTorontoWrittenTestimony_e.pdf</a></p>
											</div>
					

				</div>
			</div>
		</div></div>]]>
            </description>
            <link>https://www.fightingblindness.ca/news/11-years-in-the-making-supreme-court-of-canada-passes-genetic-non-discrimination-act-gnda</link>
            <guid isPermaLink="false">hacker-news-small-sites-24274306</guid>
            <pubDate>Tue, 25 Aug 2020 18:19:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Worldly Wisdom]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24274238">thread link</a>) | @yarapavan
<br/>
August 25, 2020 | https://ltcwrk.com/worldly-wisdom/ | <a href="https://web.archive.org/web/*/https://ltcwrk.com/worldly-wisdom/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>Worldly Wisdom can be thought of as meta-learning or meta-ideas â€“ essentially instruction manuals for life. These concepts are universally valuable and applicable, being time-tested and proven robust. We begin with these ideas because, if properly applied, they can form the â€œkernelâ€� to your â€œoperating systemâ€� â€“ governing how you think and learn, paving the way for deeper understanding later on.</p>
<p>...</p>		<p>
                 <h4>To Continue Reading...</h4>
                <!-- <ul>
                 <li class='wc_active'><a href="https://ltcwrk.com/join-us/?redirecturl=d29ybGRseS13aXNkb20=">Join Us</a>
                 
                 </li>
                  <li class='wc_active'><a href="https://ltcwrk.com/?memberful_endpoint=auth">Sign In</a> </li>
                 </ul>  -->
		</p>
		<div><form method="POST" action="" id="wcwaitlistform"><p><label for="wcnewsalert1">Newsletter</label></p><div><div></div><div></div></div></form></div>	</div></div>]]>
            </description>
            <link>https://ltcwrk.com/worldly-wisdom/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24274238</guid>
            <pubDate>Tue, 25 Aug 2020 18:12:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Manifesto on the Teaching of Mathematics]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24274186">thread link</a>) | @noch
<br/>
August 25, 2020 | http://intellectualmathematics.com/manifesto/ | <a href="https://web.archive.org/web/*/http://intellectualmathematics.com/manifesto/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<div id="primary">
		<main id="main" role="main">

		
<article id="post-31" class="page">
	

	
	<div>
		<p>My general teaching philosophy can be summarised in three principles or axioms regarding learning. They concern the source, the process, and the goal of learning respectively.</p>
<p>My first axiom is this: In a perfect world students pursue learning not because it is prescribed to them but rather out of a genuine desire to figure things out. We must therefore teach as if our students were of this kind. Only by aspiring to this ideal can we bring it closer to being realised.</p>
<p>It follows that we must not introduce any topic for which we cannot first convince the students that they should want to pursue it. This is a standard very rarely met in mathematics. Everyone likes to tell themselves that they are giving motivations for what they teach, but very little of what passes for motivation stands up to critical scrutiny as a motivation in the sense of the learning ideal outlined above. In all such cases, therefore, the student has no reason to pursue the topic in question other than obedience to the dictatorial authority of the teacher. In my view we cannot fault a student who hates mathematics in such circumstances; if anything, I would sooner fault a student who did not.</p>
<p>My second axiom concerns the process of learning. It says: We learn when we are challenged, when we push ourselves. If you’re not stuck you’re not learning. If it’s not a struggle you’re not doing it right.</p>
<p>It follows that we must always look for new points of view and pursue open-ended questions. The role of the teacher is not to make life easy for the student by giving crystal clear lectures and predictable tests. Instead the role of the teacher is to guide and encourage the student’s own process of learning by setting suitable challenges and by stimulating thought and reflection.</p>
<p>The final axiom of my teaching philosophy is that the goal of teaching is independent thought. We want students to be able to think and reason and apply what they know in new situations. We do not want to create robots or parrots or one-trick ponies.</p>
<p>It follows that when we learn something we must always inquire why it is so, and that we must answer this question according to our own judgement, not by mimicking some external standards of rigour and proof. It also follows that we must always seek out the broader meaning of what we are studying through its applications and interconnections with other ideas.</p>
<p>* &nbsp; &nbsp; * &nbsp; &nbsp; *</p>
<p>I have coined the phrase “Intellectual Mathematics” for the teaching philosophy I have in mind, because its fundamental principle is to treat students with the greatest possible intellectual respect.</p>
<p>This is the opposite of traditional mathematics teaching, which treats students like circus animals who need to be taught to jump through hoops by means of mindless drill training.</p>
<p>In the traditional approach the essence of the teacher’s role is authority. The teacher holds the carrot and the stick and that’s why you have to do as he says.</p>
<p>In the Intellectual Mathematics approach the essence of the teacher’s role is inspiration, and the goal of teaching is to stimulate thought and reflection. The teacher disavows the notion that he has the right to boss people around. Instead he considers it his responsibility to nourish in the students a desire to pursue their studies out of their own intrinsic motivation and interest.</p>
<p>It follows that in Intellectual Mathematics a topic is introduced only when the student can be convinced of the value of doing so. This is the opposite of the traditional approach where topics are routinely introduced at a stage where they serve no credible purpose whatsoever, simply because some curriculum designer decided that the students “need to have seen it” a year or two down the line.</p>
<p>Traditional curriculum designers butcher mathematics the way colonialists used to divide conquered continents: with crude and clinical cuts that are profoundly insensitive to any and all organic connections between the constituent parts. Such an approach makes sense for those who take their own authority for granted.</p>
<p>Intellectual Mathematics does not use such totalitarian techniques. Borders are not drawn where they do not belong and organic connections are respected. Mathematics is not severed from physics, nor differential equations from calculus, and so on, regardless of the administrative efficiencies of such compartmentalisation. You do not read every other line of a Shakespeare play in one class, and then the remaining lines in another class the following year. But in mathematics we routinely do precisely this. Such an approach is incompatible with intellectual respect for the students.</p>
<p>In traditional mathematics, things are taught because they are replicable and testable. The teacher is so dependent on the drillmaster paradigm that only topics that fit it can be taught. If a topic doesn’t allow for fifty-eight near-identical drill problems at the end of the section, then that topic is unteachable in traditional mathematics. It will not be taught no matter how important or crucial for understanding the true purpose of the entire subject. Conversely, topics that do lend themselves to endless drill problems will often be taught for this reason alone, despite being utterly pointless and contrived.</p>
<p>In Intellectual Mathematics, presenting topics in an inherently interesting and meaningful way is the first and foremost consideration. The purpose of the problems at the end of the section is not to force students through a repetitive obstacle course, but to convince the students of the value and importance of what they are studying.</p>
<p>The traditional approach fosters robotic, unthinking students. It selects for obedience and punishes independent and critical thought. Intellectual Mathematics does the opposite.</p>
<p>I say with Rousseau: “Let the child do nothing because he is told; nothing is good for him but what he recognises as good. When you are always urging him beyond his present understanding, you think you are exercising a foresight which you really lack. To provide him with useless tools which he may never require, you deprive him of man’s most useful tool — common-sense. You would have him docile as a child; he will be a credulous dupe when he grows up. You are always saying, ‘What I ask is for your good, though you cannot understand it. ...’ All these fine speeches with which you hope to make him good, are preparing the way, so that … every kind of fool may catch him in his snare or draw him into his folly.”</p>
<p>* &nbsp; &nbsp; * &nbsp; &nbsp; *</p>
<p>Intellectual Mathematics should not be confused with what passes for “reform” teaching. Everything we have said about the traditional approach applies equally well to “reform” approaches, because what is called “reform” pertains almost exclusively to surface form, not substance.</p>
<p>The basic fault of the modern “reform” movement is that it does not have the courage and confidence and ability to challenge the mathematical establishment on matters of substance. It assumes that the traditional approach is mathematically infallible, though pedagogically flawed. It therefore busies itself with concocting pedagogical schemes to make the same old medicine go down more easily. Group work! Use of technology! Inquiry learning! Flipping the classroom!</p>
<p>Modern “reform” efforts start at the wrong end. They put the cart before the horse, lipstick on the pig. The enterprise is doomed because it is predicated on the false assumption that the underlying curriculum is beyond rebuke. It doesn’t matter what pedagogical tricks you use if the substance you are trying to teach is poorly conceived in the first place. It is impossible to teach bad material well. That is why any reform worthy of its name needs to actually reform mathematical substance.</p>
<p>The Intellectual Mathematics approach starts with content and substance. It is not primarily about how to teach, but what to teach. It does not start with the question: “How can we make students understand concept X?” Rather it starts with the question: “Should we even teach concept X in the first place? If so, why?” This should be the guiding question of true reform.</p>
<p>* &nbsp; &nbsp; * &nbsp; &nbsp; *</p>
<p>Intellectual Mathematics is written for the intellectual fulfilment of the reader. This means that it seeks the most satisfying explanations, the most vivid illustrations, and the most compelling motivations. It also means that it engages our intuition whenever possible.</p>
<p>Traditional mathematics is written for robots and nitpickers. It is obsessed with being technically correct at the expense of all else. Again and again the ugliest proofs and the most contrived order of presentation are favoured in the traditional approach on the sole grounds that they are the easiest to write down in a manner that cannot be faulted with respect to logical correctness.</p>
<p>In Intellectual Mathematics, when facing a new concept, our primary goal is to understand how and why it works. The standard by which this is judged is our own sense of satisfaction and understanding. Emotion, passion, and the joy of insight are therefore essential components of Intellectual Mathematics.</p>
<p>In traditional mathematics, when facing a new concept, the goal is to reach the requisite results without making any technical errors. Crossing the t’s and dotting the i’s are the alpha and omega of traditional mathematics. Traditional mathematics is anti-human. It fetishises robotic manipulation of symbols and involves no emotions except a crippling fear of genuine and free human thought.</p>
<p>In traditional mathematics, the character and bulk of any given proof usually has next to nothing to do with why that particular theorem is true and everything to do with incidental technicalities. Students soon get the hint that mathematics is not about actually thinking and trying to figure stuff out; rather it is clearly a formal game completely divorced from common sense.</p>
<p>Indeed, formal proofs are sometimes accompanied by an informal heuristic argument, only to be followed …</p></div></article></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://intellectualmathematics.com/manifesto/">http://intellectualmathematics.com/manifesto/</a></em></p>]]>
            </description>
            <link>http://intellectualmathematics.com/manifesto/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24274186</guid>
            <pubDate>Tue, 25 Aug 2020 18:08:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SQL Templates for Common Product, Sales, Marketing, and Analytics Questions]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24274045">thread link</a>) | @rahilsondhi
<br/>
August 25, 2020 | https://popsql.com/sql-templates | <a href="https://web.archive.org/web/*/https://popsql.com/sql-templates">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>From startups to enterprises, SQL is more powerful when used across teams. Here are foundational templates we've battle-tested at PopSQL. Try them in our <a href="https://popsql.com/sql-templates/analytics/exploring-sample-dataset">sample DB</a>.</p><header><h2>Product</h2></header><div><a href="https://popsql.com/sql-templates/product/monitoring-a-feature-launch-with-sql"><div><h2><img src="https://popsql.com/static/docs/icons/inspect.svg" alt="icon"><div><p>Monitoring a Feature Launch with SQL</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/product/how-has-customer-used-your-product"><div><h2><img src="https://popsql.com/static/docs/icons/inspect.svg" alt="icon"><div><p>Auditing a Customer's Usage of Your Product</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/product/product-most-used-features"><div><h2><img src="https://popsql.com/static/docs/icons/inspect.svg" alt="icon"><div><p>Ranking the Most Used Features in Your Product</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/product/finding-your-most-engaged-users"><div><h2><img src="https://popsql.com/static/docs/icons/inspect.svg" alt="icon"><div><p>Finding Your Product's Most Engaged Users</p><p>-&gt;</p></div></h2></div></a></div><hr><header><h2>Engineering</h2></header><div><a href="https://popsql.com/sql-templates/engineering/filtering-users-by-version-number-with-sql-regex"><div><h2><img src="https://popsql.com/static/docs/icons/schema.svg" alt="icon"><div><p>Filtering Users by Version Number with Regex in SQL</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/engineering/filtering-users-by-platform-in-sql"><div><h2><img src="https://popsql.com/static/docs/icons/schema.svg" alt="icon"><div><p>Filtering Users by Platform in SQL</p><p>-&gt;</p></div></h2></div></a></div><hr><header><h2>Support</h2></header><div><a href="https://popsql.com/sql-templates/support/analyzing-nps-responses-in-sql"><div><h2><img src="https://popsql.com/static/docs/icons/troubleshooting.svg" alt="icon"><div><p>Analyzing NPS Responses in SQL</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/support/finding-customers-at-risk-of-churning"><div><h2><img src="https://popsql.com/static/docs/icons/troubleshooting.svg" alt="icon"><div><p>Finding Customers at Risk of Churning</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/support/detecting-spikes-in-issues-from-support-tickets"><div><h2><img src="https://popsql.com/static/docs/icons/troubleshooting.svg" alt="icon"><div><p>Detecting Spikes in Issues from Support Tickets</p><p>-&gt;</p></div></h2></div></a></div><hr><header><h2>Sales</h2></header><div><a href="https://popsql.com/sql-templates/sales/tagging-sign-up-emails-as-work-vs-personal"><div><h2><img src="https://popsql.com/static/docs/icons/grow.svg" alt="icon"><div><p>Tagging Sign Up Emails as Work vs Personal</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/sales/creating-lead-scores-in-sql"><div><h2><img src="https://popsql.com/static/docs/icons/grow.svg" alt="icon"><div><p>Creating Lead Scores in SQL</p><p>-&gt;</p></div></h2></div></a></div><hr><header><h2>Marketing</h2></header><div><a href="https://popsql.com/sql-templates/marketing/calculating-daily-active-users-in-sql"><div><h2><img src="https://popsql.com/static/docs/icons/announce.svg" alt="icon"><div><p>Calculating Daily Active Users (and digging deeper)</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/marketing/running-a-funnel-analysis"><div><h2><img src="https://popsql.com/static/docs/icons/announce.svg" alt="icon"><div><p>Running a Funnel Analysis in SQL</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/marketing/marketing-attribution-in-sql"><div><h2><img src="https://popsql.com/static/docs/icons/announce.svg" alt="icon"><div><p>Marketing Attribution in SQL</p><p>-&gt;</p></div></h2></div></a></div><hr><header><h2>Analytics</h2></header><div><a href="https://popsql.com/sql-templates/analytics/how-to-create-histograms-in-sql"><div><h2><img src="https://popsql.com/static/docs/icons/analyze.svg" alt="icon"><div><p>Creating Histograms in SQL</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/analytics/detecting-skewness-in-sql"><div><h2><img src="https://popsql.com/static/docs/icons/analyze.svg" alt="icon"><div><p>Detecting Skewness in a Dataset in SQL</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/analytics/linear-regression-in-sql"><div><h2><img src="https://popsql.com/static/docs/icons/analyze.svg" alt="icon"><div><p>Calculating Linear Regression in SQL</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/analytics/exploring-sample-dataset"><div><h2><img src="https://popsql.com/static/docs/icons/analyze.svg" alt="icon"><div><p>Exploring our Sample Dataset</p><p>-&gt;</p></div></h2></div></a></div><hr><p>Want to write or request a new SQL template? <a href="https://airtable.com/shr37S7ciAObk7yk1">Let's talk!</a></p></section></div>]]>
            </description>
            <link>https://popsql.com/sql-templates</link>
            <guid isPermaLink="false">hacker-news-small-sites-24274045</guid>
            <pubDate>Tue, 25 Aug 2020 17:57:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning JavaScript? Series – Debugging like a pro using Console.log()]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24273815">thread link</a>) | @omotola28
<br/>
August 25, 2020 | https://blog.oshogunle.com/learning-javascript-series-debugging-like-a-pro-using-consolelog-ckea828h000k2wks102o6dqqj | <a href="https://web.archive.org/web/*/https://blog.oshogunle.com/learning-javascript-series-debugging-like-a-pro-using-consolelog-ckea828h000k2wks102o6dqqj">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1598376418025/o2KPEw6yF.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><p>One of the ways JavaScript developers debug their code is by using <strong>console.log</strong> to figure out what the output of a particular variable  or condition is. But, what if there is a better way of using this function to give us a better developer experience?</p>
<p>The popular methods to use console.log may look something like this.</p>
<pre><code><span>const</span> blogger1 = {name : <span>"mycodinghabits"</span>, occupation : <span>"software developer"</span>, interest : <span>"dancing"</span>}
<span>const</span> blogger2 = {name : <span>"victoria lo"</span>, occupation : <span>"web developer"</span>, interest : <span>"collecting quotes"</span>}
<span>const</span> blogger3 = {name : <span>"bolaji ayodeji"</span>, occupation : <span>"JAMStack developer"</span>, interest : <span>"sharing knowledge"</span>}

<span>console</span>.log(blogger1)
<span>console</span>.log(blogger2)
<span>console</span>.log(blogger3)
</code></pre><p>And the output on the web browser is</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598375354524/mBgXtzN5w.png?auto=format&amp;q=60" alt="Untitled.png"></p>
<p>From that log we arent sure who is <strong>blogger1, 2 or 3.</strong> This is where we can start to do more with <strong>console.log.</strong> To make this more readable which in turn increases developer happiness,  we can do this instead</p>
<pre><code><span>console</span>.log({blogger1, blogger2, blogger3})
</code></pre><p>which gives us a better output with our variable names. </p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598375469237/qeKNMcZOi.png?auto=format&amp;q=60" alt="Untitled 1.png"></p>
<p>Or even better, if our object has the same properties we can use.</p>
<h2 id="consoletable">Console.table</h2>
<pre><code>
<span>console</span>.table([blogger1, blogger2, blogger3])


<span>console</span>.table({blogger1, blogger2, blogger3})
</code></pre><p>This gives us
<img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598375525122/ExahwpS8p.png?auto=format&amp;q=60" alt="Untitled 2.png"></p>
<p>The first example is useful when you have </p>
<ul>
<li>an array of objects</li>
</ul>
<p>and the second when you have </p>
<ul>
<li>objects embedded in another object.</li>
</ul>
<p>Thats cool, but whats even cooler is if I wanted to log performance of a piece of code  which iterates over an array of my objects, I can do this using <strong>console.time</strong>.</p>
<h2 id="consoletime">Console.time</h2>
<p>In this example, I am trying to compare the performance of using maps instead of for loops. Check out all I had to say about this in this <a target="_blank" href="https://blog.oshogunle.com/learning-javascript-topic-higher-order-functions-ckdvlkqxs0151jas1fl8tdx13">article</a></p>
<pre><code><span>const</span> blogger1 = {name : <span>"mycodinghabits"</span>, occupation : <span>"software developer"</span>, interest : <span>"dancing"</span>}
<span>const</span> blogger2 = {name : <span>"victoria lo"</span>, occupation : <span>"web developer"</span>, interest : <span>"collecting quotes"</span>}
<span>const</span> blogger3 = {name : <span>"bolaji ayodeji"</span>, occupation : <span>"JAMStack developer"</span>, interest : <span>"sharing knowledge"</span>}

<span>let</span> array0fObjects = [blogger1, blogger2, blogger3];




<span>console</span>.time(<span>"timer for loops"</span>)

<span>for</span>(i = <span>0</span>; i &lt; array0fObjects.length; i++) {
    <span>console</span>.log(<span>`%c Hi <span>${array0fObjects[i].name}</span>`</span>, <span>"color: green; font-weight: bold; background-color: black"</span>)
}

<span>console</span>.timeEnd(<span>"timer for loops"</span>)


<span>console</span>.time(<span>"timer for maps"</span>)

array0fObjects.map(<span><span>v</span> =&gt;</span> <span>console</span>.log(<span>`%c <span>${v.name}</span> likes <span>${v.interest}</span>`</span>, <span>"color: yellow; font-weight: bold; background-color: black"</span>))

<span>console</span>.timeEnd(<span>"timer for maps"</span>)
</code></pre><p>The output</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598375674441/G47tjtcZM.png?auto=format&amp;q=60" alt="Untitled 3.png"></p>
<blockquote>
<p>Bonus - Here you can see that my console logs are prettier, this is because the string formatting I applied using the %c allows me to add styling like you would do in css. Try it!</p>
</blockquote>
<h2 id="consoletrace">Console.trace</h2>
<p>Have you ever had a bug in your code and wanted to figure out where in your code execution your function was being called? Great! We can use <strong>console.trace</strong> to do this. </p>
<pre><code><span>const</span> loopBloggers = <span><span>()</span> =&gt;</span> {
    <span>for</span>(i = <span>0</span>; i &lt; array0fObjects.length; i++) {
        <span>console</span>.log(<span>`%c Hi <span>${array0fObjects[i].name}</span>`</span>, <span>"color: green; font-weight: bold; background-color: black"</span>)
    }

    
    mapBloggers();
}

<span>const</span> mapBloggers = <span><span>()</span> =&gt;</span> {

    <span>console</span>.trace(<span>"I was called here"</span>)

    array0fObjects.map(<span><span>v</span> =&gt;</span> <span>console</span>.log(<span>`%c <span>${v.name}</span> likes <span>${v.interest}</span>`</span>, <span>"color: yellow; font-weight: bold; background-color: black"</span>))
}

loopBloggers();
</code></pre><p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598375742138/k_lLbDYVZ.png?auto=format&amp;q=60" alt="Untitled 4.png"></p>
<p>Keeping in mind that the call stack follows a <a target="_blank" href="https://www.freecodecamp.org/news/understanding-the-javascript-call-stack-861e41ae61d4/">Last In, First Out Principle</a>, and in this case loopBloggers was pushed into the stack first followed by mapBloggers.</p>
<h2 id="consoleassert">Console.assert</h2>
<p>If you want a fancy way of logging errors from your conditinal statements in Javascript, you can use <strong>console.assert</strong> to do this.</p>
<pre><code><span>let</span> isPostHelpful = <span>true</span>;

 <span>if</span>(isPostHelpful == <span>true</span>){
    <span>console</span>.log(<span>"%c Please share or react to it 👏🏾"</span>, 
                <span>"color: black; font-weight: bold; background-color:yellow"</span>)
 }
 <span>else</span>{
     <span>console</span>.assert(<span>false</span>, <span>"Comment below what you would like to see in this series"</span>)
 }
</code></pre><h3 id="isposthelpful-true">isPostHelpful == true</h3>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598375798625/8ozkMrlg-.png?auto=format&amp;q=60" alt="Untitled 5.png"></p>
<h3 id="isposthelpful-false">isPostHelpful == false</h3>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598375817086/u50JOLRbv.png?auto=format&amp;q=60" alt="Untitled 6.png"></p>
<p>If you want to take your debugging skills to an even higher level, you can use the browser debug tools as demonstrated <a target="_blank" href="https://www.youtube.com/watch?v=H0XScE08hy8">here</a>. </p>
<blockquote>
<p>BONUS - If doing that doesn't help maybe the LOGIC is wrong, consider rubber ducking. This is a technique that is used to work through your code line by line by telling a rubber duck what you think your code should be doing. That way you might find flaws in your logic or your code. </p>
</blockquote>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598376275398/K1cuVemte.gif?auto=format,compress&amp;gif-q=60" alt="Animated GIF-downsized_large.gif"></p>
<p>Thank you for reading! Hope you learn something new! Like, share, react to the post so others can see it.</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.oshogunle.com/learning-javascript-series-debugging-like-a-pro-using-consolelog-ckea828h000k2wks102o6dqqj</link>
            <guid isPermaLink="false">hacker-news-small-sites-24273815</guid>
            <pubDate>Tue, 25 Aug 2020 17:35:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding self-supervised/contrastive learning w Bootstrap Your Own Latent]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24273792">thread link</a>) | @christinakim
<br/>
August 25, 2020 | https://untitled-ai.github.io/understanding-self-supervised-contrastive-learning.html | <a href="https://web.archive.org/web/*/https://untitled-ai.github.io/understanding-self-supervised-contrastive-learning.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    

<p>Unlike prior work like SimCLR and MoCo, the recent paper <a href="http://arxiv.org/abs/2006.07733">Bootstrap Your Own Latent</a> (BYOL) from <a href="https://deepmind.com/">DeepMind</a> demonstrates a state of the art method for self-supervised learning of image representations without an explicitly contrastive loss function. This simplifies training by removing the need for negative examples in the loss function. We highlight two surprising findings from our work on reproducing BYOL:</p>

<p><strong>(1) BYOL generally performs no better than random when batch normalization is removed, and</strong></p>

<p><strong>(2) the presence of batch normalization implicitly causes a form of contrastive learning</strong>.</p>

<p>These findings highlight the importance of contrast between positive and negative examples when learning representations and help us gain a more fundamental understanding of how and why self-supervised learning works.</p>

<p>The code used for this post can be found at <a href="https://github.com/untitled-ai/self_supervised">https://github.com/untitled-ai/self_supervised</a>.</p>

<!--more-->



<p>Machine learning is typically done in a <em>supervised</em> fashion: we use a dataset consisting of the inputs and “right answers” (outputs) to find the best function that maps from the input data onto the right answers. By contrast, in <em>self-supervised</em> <sup id="fnref:ssup" role="doc-noteref"><a href="#fn:ssup">1</a></sup>  learning, no right answers are provided in the data set. Instead, we learn a function that maps the input data onto itself (ex: using the right half of an image to predict the left half of an image).</p>

<p>This approach has proven successful in everything from language to images and audio. In fact, most recent language models, from <a href="http://jalammar.github.io/illustrated-word2vec/">word2vec</a> to <a href="http://jalammar.github.io/illustrated-bert/">BERT</a> and <a href="https://arxiv.org/abs/2005.14165">GPT-3</a>, are examples of self-supervised approaches. More recently, this approach has had some incredible results for audio and images as well, and <a href="https://cacm.acm.org/news/244720-yann-lecun-yoshua-bengio-self-supervised-learning-is-key-to-human-level-intelligence/fulltext">some believe</a> that it may be an important component of human-like intelligence. This post focuses on self-supervised learning for image representations. For more background on self-supervised learning, see the resources below <sup id="fnref:resources" role="doc-noteref"><a href="#fn:resources">2</a></sup>.</p>



<h3 id="contrastive-learning">Contrastive learning</h3>

<p>Until <a href="https://arxiv.org/abs/2006.07733">BYOL</a> was published a few months ago, the best performing algorithms were <a href="http://arxiv.org/abs/1911.05722">MoCo</a> and <a href="http://arxiv.org/abs/2002.05709">SimCLR</a>. MoCo and SimCLR are both examples of <em>contrastive learning</em>.</p>

<p>Contrastive learning is the process of training a classifier to distinguish between “similar” and “dissimilar” input data. For MoCo and SimCLR specifically, the classifier’s positive examples are modified versions of the same image, while negative examples are other images in the same data set. For example, suppose there is a picture of a dog. In that case, the positive examples could be different crops of that image (see below figure), while the negative examples could be crops from entirely different images.</p>

<figure>
  <img src="https://untitled-ai.github.io/assets/img/understanding_self_supervised/dog_aug.png" alt="Dog augmentations">
  <figcaption>Augmented versions of the original picture of a dog (a). Any two of these could be used as a positive example pair. Image from the <a href="https://ai.googleblog.com/2020/04/advancing-self-supervised-and-semi.html">SimCLR post</a>.</figcaption>
</figure>

<h3 id="byol-self-supervised-learning-without-contrastive-learning-not-exactly">BYOL: self-supervised learning without contrastive learning? Not exactly.</h3>

<p>While MoCo and SimCLR use contrastive learning between positive and negative examples in their loss functions, BYOL uses only positive examples in the loss function. At first glance, BYOL appears to be doing self-supervised learning without contrasting between different images at all. However, it appears that the primary reason BYOL works is that it is doing a form of contrastive learning — just via an indirect mechanism.</p>

<p>To more deeply understand this indirect contrastive learning in BYOL, we should first review how each of these algorithms works. See <a href="https://untitled-ai.github.io/appendix-for-understanding-self-supervised-contrastive-learning.html#appendix-a">Appendix A</a> for a table that shows the notation used in each of the papers. In this post, we use the notation from BYOL for consistency.</p>

<h3 id="simclr">SimCLR</h3>

<p>SimCLR is a particularly elegant self-supervised algorithm that managed to simplify previous approaches to their essential core and improve upon their performance. Two transformations <em>v</em> and <em>v’</em> of the same image <em>x</em> are fed through the same network to produce two projections <em>z</em> and <em>z’</em>. The contrastive loss aims to maximize the similarity of the two projections from the same input $x$ while minimizing the similarity to projections of other images within the same mini-batch. Continuing our dog example, projections of different crops of the same dog image would hopefully be more similar than crops from other random images in the same batch.</p>

<p>The multilayer perceptron (MLP) used for projection in SimCLR uses batch normalization after each linear layer.</p>

<figure>
  <img src="https://untitled-ai.github.io/assets/img/understanding_self_supervised/simclr_arch.png" alt="SimCLR architecture">
  <figcaption>SimCLR architecture.</figcaption>
</figure>

<h3 id="moco">MoCo</h3>

<p>Relative to SimCLR, MoCo v2 manages to both decrease the batch size (from 4096 to 256) and improve the performance. Unlike SimCLR, where the top and bottom row in the diagram represent the same network (parameterized by $\theta$), MoCo splits the single network into an <em>online network</em> (top row) parameterized by $\theta$ and a <em>momentum network</em> (bottom row) parameterized by $\xi$. The online network is updated by stochastic gradient descent, while the momentum network is updated based on an exponential moving average of the online network weights. The momentum network allows MoCo to efficiently use a memory bank of past projections as negative examples for the contrastive loss. This memory bank is what enables the much smaller batch sizes. In our dog image illustration, the positive examples would be crops of the same image of a dog. The negative examples are completely different images that were used in past mini-batches, projections of which are stored in the memory bank.</p>

<p>The MLP used for projection in <a href="http://arxiv.org/abs/2003.04297">MoCo v2</a> does not use batch normalization</p>

<figure>
  <img src="https://untitled-ai.github.io/assets/img/understanding_self_supervised/moco_v2_arch.png" alt="MoCo v2 architecture">
  <figcaption>MoCo v2 architecture. Top row is online encoder, bottom row is momentum encoder.</figcaption>
</figure>

<h3 id="byol">BYOL</h3>

<p>BYOL builds on the momentum network concept of MoCo, adding an MLP $q_\theta$ to predict z’ from z. Rather than using a contrastive loss, BYOL uses the L2 error between the normalized prediction p and target z’. Using our dog image example, BYOL tries to convert both crops of the dog image into the same representation vector (make p and z’ equal.) Because this loss function does not require negative examples, there is no use for a memory bank in BYOL.</p>

<p>Both MLPs in BYOL use batch normalization after the first linear layer only.</p>

<figure>
  <img src="https://untitled-ai.github.io/assets/img/understanding_self_supervised/byol_arch.png" alt="BYOL architecture">
  <figcaption>BYOL architecture.</figcaption>
</figure>

<p>By the above description, it appears that BYOL can learn without explicitly contrasting between multiple different images. <strong>Surprisingly, however, we found that BYOL is not only doing contrastive learning, but that contrastive learning is essential to its success</strong>.</p>



<p>We originally implemented BYOL in PyTorch using code we had written for MoCo. When we began training our network, we found that <strong>our network performed no better than random</strong>. Comparing our code to <a href="https://github.com/sthalles/PyTorch-BYOL">another available implementation</a> (thanks sthalles!), we discovered we were missing batch normalization in the MLP. We were quite surprised that batch normalization was critical to training BYOL, while MoCo v2 did not require it at all.</p>

<p>For our initial testing, we trained a ResNet-18 with BYOL on the STL-10 unsupervised dataset using SGD with momentum and a batch size of 256 <sup id="fnref:opt" role="doc-noteref"><a href="#fn:opt">3</a></sup>. See <a href="https://untitled-ai.github.io/appendix-for-understanding-self-supervised-contrastive-learning.html#appendix-b">Appendix B</a> for details on data augmentation. Below are the first ten epochs of training for the same BYOL algorithm with and without batch normalization in the MLPs</p>

<figure>
  <img src="https://untitled-ai.github.io/assets/img/understanding_self_supervised/surprising_stl10_10e.png" alt="MoCo v2 architecture">
  <figcaption>Linear evaluation accuracy on a validation set during early training of a ResNet-18 on STL10. When BYOL was trained without batch normalization in the MLP, the performance remained no better than a random baseline.</figcaption>
</figure>

<h3 id="why-did-this-happen">Why did this happen?</h3>

<p>To investigate the cause of this dramatic change in performance, we performed some additional experiments.</p>

<figure>
  <img src="https://untitled-ai.github.io/assets/img/understanding_self_supervised/contrastive_loss_arch.png" alt="Contrastive loss architecture">
  <figcaption>Configuration used for experiments with contrastive loss, enabling better comparison to BYOL results.</figcaption>
</figure>

<p>Because the prediction MLP q changes the network depth compared to MoCo, we wondered if batch normalization might be needed to regularize this network. That is, while MoCo <em>does not</em> require batch normalization, it could be that MoCo <em>does</em> require batch normalization when paired with an additional prediction MLP. To test this, we started training the network shown above with a contrastive loss function. We found that the network was able to perform significantly better than random within ten epochs. This result made us suspect that something about <strong>not using a contrastive loss function</strong> causes the dependence of training on batch normalization.</p>

<p>We then wondered whether another type of normalization would have the same effect. We applied Layer Normalization to the MLPs instead of batch normalization and trained the network with BYOL <sup id="fnref:layernorm" role="doc-noteref"><a href="#fn:layernorm">4</a></sup>. As in the experiments where MLPs had no normalization, the performance was no better than random. This result told us that <strong>the activations of other inputs in the same mini-batch</strong> are essential in helping BYOL find useful representations.</p>

<p>Next, we wanted to know whether batch normalization is required in the projection MLP $g$, the prediction MLP $q$, or both. Our experiments showed that batch normalization is most useful in the projection MLP, but the network can learn useful representations with batch normalization in either MLP. A <strong>single batch normalization layer</strong> in one of the MLPs is sufficient for the network to learn.</p>

<h3 id="performance-for-each-variation">Performance for each variation</h3>

<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Projection MLP Norm</th>
      <th>Prediction MLP Norm</th>
      <th>Loss Function</th>
      <th>Contrastive</th>
      <th>Performance</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Contrastive Loss</td>
      <td>None</td>
      <td>None</td>
      <td>Cross Entropy</td>
      <td>Explicit</td>
      <td>44.1</td>
    </tr>
    <tr>
      <td>BYOL</td>
      <td>Batch Norm</td>
      <td>Batch Norm</td>
      <td>L2</td>
      <td>Implicit</td>
      <td>57.7</td>
    </tr>
    <tr>
      <td>Projection BN Only</td>
      <td>Batch Norm</td>
      <td>None</td>
      <td>L2</td>
      <td>Implicit</td>
      <td>55.3</td>
    </tr>
    <tr>
      <td>Prediction BN Only</td>
      <td>None</td>
      <td>Batch Norm</td>
      <td>L2</td>
      <td>Implicit</td>
      <td>48</td>
    </tr>
    <tr>
      <td>No Normalization</td>
      <td>None</td>
      <td>None</td>
      <td>L2</td>
      <td>None</td>
      <td>28.3</td>
    </tr>
    <tr>
      <td>Layer Norm</td>
      <td>Layer Norm</td>
      <td>Layer Norm</td>
      <td>L2</td>
      <td>None</td>
      <td>29.4</td>
    </tr>
    <tr>
      <td>Random</td>
      <td>—</td>
      <td>—</td>
      <td>—</td>
      <td>None</td>
      <td>28.8</td>
    </tr>
  </tbody>
</table>

<p>To summarize the findings so far: in the absence of a contrastive loss function, the success of BYOL training hinges on something about a single batch normalization layer related to the activations from other inputs in the mini-batch.</p>

<h3 id="why-batch-normalization-is-critical-in-byol-mode-collapse">Why batch normalization is critical in BYOL: mode collapse</h3>

<p>One purpose of negative examples in a contrastive loss function is to prevent mode collapse<sup id="fnref:collapse" role="doc-noteref"><a href="#fn:collapse">5</a></sup>. An example of mode collapse would be a network that always outputs [1, 0, 0, 0, …] as its projection vector <em>z</em>. If all projection vectors <em>z</em> are the same, then the network only needs to learn the identity function for $q$ in order to …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://untitled-ai.github.io/understanding-self-supervised-contrastive-learning.html">https://untitled-ai.github.io/understanding-self-supervised-contrastive-learning.html</a></em></p>]]>
            </description>
            <link>https://untitled-ai.github.io/understanding-self-supervised-contrastive-learning.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24273792</guid>
            <pubDate>Tue, 25 Aug 2020 17:33:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Experimenting with QUIC and WebTransport in Go]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24273371">thread link</a>) | @FZambia
<br/>
August 25, 2020 | https://centrifugal.github.io/centrifugo/blog/quic_web_transport/ | <a href="https://web.archive.org/web/*/https://centrifugal.github.io/centrifugo/blog/quic_web_transport/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-md-component="main">
        <div>
          
            
              
            
            
              
            
          
          <div>
            <article>
              

                
                  <a href="https://github.com/centrifugal/centrifugo/edit/master/docs/content/blog/quic_web_transport.md" title="Edit this page">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"></path></svg>
                  </a>
                
                
                  
                
                
                
<p><img alt="post-cover" src="https://i.imgur.com/sH9zfhe.jpg"></p>
<h2 id="overview">Overview<a href="#overview" title="Permanent link">¶</a></h2>
<p>WebTransport is a new browser API offering low-latency, bidirectional, client-server messaging. If you have not heard about it before I suggest to first read a post called <a href="https://web.dev/quictransport/">Experimenting with QuicTransport</a> published recently on web.dev – it gives a nice overview to WebTransport and shows client-side code examples. Here we will concentrate on implementing server side.</p>
<p>Some key points about WebTransport spec:</p>
<ul>
<li>WebTransport standard will provide a possibility to use streaming client-server communication using modern transports such as <a href="https://en.wikipedia.org/wiki/QUIC">QUIC</a> and <a href="https://en.wikipedia.org/wiki/HTTP/3">HTTP/3</a></li>
<li>It can be a good alternative to <a href="https://en.wikipedia.org/wiki/WebSocket">WebSocket</a> messaging, standard provides some capabilities that are not possible with current WebSocket spec: possibility to get rid of head-of-line blocking problems using individual streams for different data, the possibility to reuse a single connection to a server in different browser tabs</li>
<li>WebTransport also defines an unreliable stream API using UDP datagrams (which is possible since QUIC is UDP-based) – which is what browsers did not have before without a rather complex <a href="https://en.wikipedia.org/wiki/WebRTC">WebRTC</a> setup involving ICE, STUN, etc. This is sweet for in-browser real-time games.</li>
</ul>
<p>To help you figure out things here are links to current WebTransport specs:</p>
<ul>
<li><a href="https://tools.ietf.org/html/draft-vvv-webtransport-overview-01">WebTransport overview</a> – this spec gives an overview of WebTransport and provides requirements to transport layer</li>
<li><a href="https://tools.ietf.org/html/draft-vvv-webtransport-quic">WebTransport over QUIC</a> – this spec describes QUIC-based transport for WebTransport</li>
<li><a href="https://tools.ietf.org/html/draft-vvv-webtransport-http3">WebTransport over HTTP/3</a> – this spec describes HTTP/3-based transport for WebTransport (actually HTTP/3 is a protocol defined on top of QUIC)</li>
</ul>
<p>At moment Chrome only implements <a href="https://web.dev/quictransport/#register-for-ot">trial possibility</a> to try out WebTransport standard and only implements WebTransport over QUIC. Developers can initialize transport with code like this:</p>
<div><pre><span></span><code><span>const</span> <span>transport</span> <span>=</span> <span>new</span> <span>QuicTransport</span><span>(</span><span>'quic-transport://localhost:4433/path'</span><span>);</span>
</code></pre></div>

<p>In case of HTTP/3 transport one will use URL like <code>'https://localhost:4433/path'</code> in transport constructor. All WebTransport underlying transports should support instantiation over URL – that's one of the spec requirements. </p>
<p>I decided that this is a cool possibility to finally play with QUIC protocol and its Go implementation <a href="https://github.com/lucas-clemente/quic-go">github.com/lucas-clemente/quic-go</a>.</p>
<div>
<p>Danger</p>
<p>Please keep in mind that all things described in this post are work in progress. WebTransport drafts, Quic-Go library, even QUIC protocol itself are subjects to change. You should not use it in production yet.</p>
</div>
<p><a href="https://web.dev/quictransport/">Experimenting with QuicTransport</a> post contains links to a <a href="https://googlechrome.github.io/samples/quictransport/client.html">client example</a> and companion <a href="https://github.com/GoogleChrome/samples/blob/gh-pages/quictransport/quic_transport_server.py">Python server implementation</a>.</p>
<p><img alt="client example" src="https://i.imgur.com/Hty00aG.png"></p>
<p>We will use a linked client example to connect to a server that runs on localhost and uses <a href="https://github.com/lucas-clemente/quic-go">github.com/lucas-clemente/quic-go</a> library. To make our example work we need to open client example in Chrome, and actually, at this moment we need to install Chrome Canary. The reason behind this is that the  <code>quic-go</code> library supports QUIC draft-29 while Chrome &lt; 85 implements QuicTransport over draft-27. If you read this post at a time when Chrome stable 85 already released then most probably you don't need to install Canary release and just use your stable Chrome.</p>
<p>We also need to generate self-signed certificates since WebTransport only works with a TLS layer, and we should make Chrome trust our certificates. Let's prepare our client environment before writing a server and first install Chrome Canary.</p>
<h2 id="install-chrome-canary">Install Chrome Canary<a href="#install-chrome-canary" title="Permanent link">¶</a></h2>
<p>Go to <a href="https://www.google.com/intl/en/chrome/canary/">https://www.google.com/intl/en/chrome/canary/</a>, download and install Chrome Canary. We will use it to open <a href="https://googlechrome.github.io/samples/quictransport/client.html">client example</a>.</p>
<div>
<p>Note</p>
<p>If you have Chrome &gt;= 85 then most probably you can skip this step.</p>
</div>
<h2 id="generate-self-signed-tls-certificates">Generate self-signed TLS certificates<a href="#generate-self-signed-tls-certificates" title="Permanent link">¶</a></h2>
<p>Since WebTransport based on modern network transports like QUIC and HTTP/3 security is a keystone. For our experiment we will create a self-signed TLS certificate using <code>openssl</code>. </p>
<p>Make sure you have <code>openssl</code> installed:</p>
<div><pre><span></span><code>$ which openssl
/usr/bin/openssl
</code></pre></div>

<p>Then run:</p>
<div><pre><span></span><code>openssl genrsa -des3 -passout pass:x -out server.pass.key <span>2048</span>
openssl rsa -passin pass:x -in server.pass.key -out server.key
rm server.pass.key
openssl req -new -key server.key -out server.csr
</code></pre></div>

<p>Set <code>localhost</code> for Common Name when asked.</p>
<p>The self-signed TLS certificate generated from the <code>server.key</code> private key and <code>server.csr</code> files:</p>
<div><pre><span></span><code>openssl x509 -req -sha256 -days <span>365</span> -in server.csr -signkey server.key -out server.crt
</code></pre></div>

<p>After these manipulations you should have <code>server.crt</code> and <code>server.key</code> files in your working directory.</p>
<p>To help you with process here is my console output during these steps (click to open):</p>
<details><summary>My console output generating self-signed certificates</summary><div><pre><span></span><code>$ openssl genrsa -des3 -passout pass:x -out server.pass.key <span>2048</span>
Generating RSA private key, <span>2048</span> bit long modulus
...........................................................................................+++
.....................+++
e is <span>65537</span> <span>(</span>0x10001<span>)</span>

$ ls
server.pass.key

$ openssl rsa -passin pass:x -in server.pass.key -out server.key
writing RSA key

$ ls
server.key      server.pass.key

$ rm server.pass.key

$ openssl req -new -key server.key -out server.csr
You are about to be asked to enter information that will be incorporated
into your certificate request.
What you are about to enter is what is called a Distinguished Name or a DN.
There are quite a few fields but you can leave some blank
For some fields there will be a default value,
If you enter <span>'.'</span>, the field will be left blank.
-----
Country Name <span>(</span><span>2</span> letter code<span>)</span> <span>[]</span>:RU
State or Province Name <span>(</span>full name<span>)</span> <span>[]</span>:
Locality Name <span>(</span>eg, city<span>)</span> <span>[]</span>:
Organization Name <span>(</span>eg, company<span>)</span> <span>[]</span>:
Organizational Unit Name <span>(</span>eg, section<span>)</span> <span>[]</span>:
Common Name <span>(</span>eg, fully qualified host name<span>)</span> <span>[]</span>:localhost
Email Address <span>[]</span>:

Please enter the following <span>'extra'</span> attributes
to be sent with your certificate request
A challenge password <span>[]</span>:

$ openssl x509 -req -sha256 -days <span>365</span> -in server.csr -signkey server.key -out server.crt
Signature ok
<span>subject</span><span>=</span>/C<span>=</span>RU/CN<span>=</span>localhost
Getting Private key

$ ls
server.crt server.csr server.key
</code></pre></div>

</details>
<h2 id="run-client-example">Run client example<a href="#run-client-example" title="Permanent link">¶</a></h2>
<p>Now the last step. What we need to do is run Chrome Canary with some flags that will allow it to trust our self-signed certificates. I suppose there is an alternative way making Chrome trust your certificates, but I have not tried it.</p>
<p>First let's find out a fingerprint of our cert:</p>
<div><pre><span></span><code>openssl x509 -in server.crt -pubkey -noout <span>|</span> openssl pkey -pubin -outform der <span>|</span> openssl dgst -sha256 -binary <span>|</span> openssl enc -base64
</code></pre></div>

<p>In my case base64 fingerprint was <code>pe2P0fQwecKFMc6kz3+Y5MuVwVwEtGXyST5vJeaOO/M=</code>, yours will be different.</p>
<p>Then run Chrome Canary with some additional flags that will make it trust out certs (close other Chrome Canary instances before running it):</p>
<div><pre><span></span><code>$ /Applications/Google<span>\ </span>Chrome<span>\ </span>Canary.app/Contents/MacOS/Google<span>\ </span>Chrome<span>\ </span>Canary <span>\</span>
    --origin-to-force-quic-on<span>=</span>localhost:4433 <span>\</span>
    --ignore-certificate-errors-spki-list<span>=</span>pe2P0fQwecKFMc6kz3+Y5MuVwVwEtGXyST5vJeaOO/M<span>=</span>
</code></pre></div>

<p>This example is for MacOS, for your system see <a href="https://www.chromium.org/developers/how-tos/run-chromium-with-flags">docs on how to run Chrome/Chromium with custom flags</a>.</p>
<p>Now you can open <a href="https://googlechrome.github.io/samples/quictransport/client.html">https://googlechrome.github.io/samples/quictransport/client.html</a> URL in started browser and click <code>Connect</code> button. What? Connection not established? OK, this is fine since we need to run our server :)</p>
<h2 id="writing-a-quic-server">Writing a QUIC server<a href="#writing-a-quic-server" title="Permanent link">¶</a></h2>
<p>Maybe in future we will have libraries that are specified to work with WebTransport over QUIC or HTTP/3, but for now we should implement server manually. As said above we will use <a href="https://github.com/lucas-clemente/quic-go">github.com/lucas-clemente/quic-go</a> library to do this.</p>
<h3 id="server-skeleton">Server skeleton<a href="#server-skeleton" title="Permanent link">¶</a></h3>
<p>First, let's define a simple skeleton for our server:</p>
<div><pre><span></span><code><span>package</span> <span>main</span>

<span>import</span> <span>(</span>
    <span>"errors"</span>
    <span>"log"</span>

    <span>"github.com/lucas-clemente/quic-go"</span>
<span>)</span>

<span>// Config for WebTransportServerQuic.</span>
<span>type</span> <span>Config</span> <span>struct</span> <span>{</span>
    <span>// ListenAddr sets an address to bind server to.</span>
    <span>ListenAddr</span> <span>string</span>
    <span>// TLSCertPath defines a path to .crt cert file.</span>
    <span>TLSCertPath</span> <span>string</span>
    <span>// TLSKeyPath defines a path to .key cert file</span>
    <span>TLSKeyPath</span> <span>string</span>
    <span>// AllowedOrigins represents list of allowed origins to connect from.</span>
    <span>AllowedOrigins</span> <span>[]</span><span>string</span>
<span>}</span>

<span>// WebTransportServerQuic can handle WebTransport QUIC connections according</span>
<span>// to https://tools.ietf.org/html/draft-vvv-webtransport-quic-02.</span>
<span>type</span> <span>WebTransportServerQuic</span> <span>struct</span> <span>{</span>
    <span>config</span> <span>Config</span>
<span>}</span>

<span>// NewWebTransportServerQuic creates new WebTransportServerQuic.</span>
<span>func</span> <span>NewWebTransportServerQuic</span><span>(</span><span>config</span> <span>Config</span><span>)</span> <span>*</span><span>WebTransportServerQuic</span> <span>{</span>
    <span>return</span> <span>&amp;</span><span>WebTransportServerQuic</span><span>{</span>
        <span>config</span><span>:</span> <span>config</span><span>,</span>
    <span>}</span>
<span>}</span>

<span>// Run server.</span>
<span>func</span> <span>(</span><span>s</span> <span>*</span><span>WebTransportServerQuic</span><span>)</span> <span>Run</span><span>()</span> <span>error</span> <span>{</span>
    <span>return</span> <span>errors</span><span>.</span><span>New</span><span>(</span><span>"not implemented"</span><span>)</span>
<span>}</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
    <span>server</span> <span>:=</span> <span>NewWebTransportServerQuic</span><span>(</span><span>Config</span><span>{</span>
        <span>ListenAddr</span><span>:</span>     <span>"0.0.0.0:4433"</span><span>,</span>
        <span>TLSCertPath</span><span>:</span>    <span>"server.crt"</span><span>,</span>
        <span>TLSKeyPath</span><span>:</span>     <span>"server.key"</span><span>,</span>
        <span>AllowedOrigins</span><span>:</span> <span>[]</span><span>string</span><span>{</span><span>"localhost"</span><span>,</span> <span>"googlechrome.github.io"</span><span>},</span>
    <span>})</span>
    <span>if</span> <span>err</span> <span>:=</span> <span>server</span><span>.</span><span>Run</span><span>();</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
        <span>log</span><span>.</span><span>Fatal</span><span>(</span><span>err</span><span>)</span>
    <span>}</span>
<span>}</span>
</code></pre></div>

<h3 id="accept-quic-connections">Accept QUIC connections<a href="#accept-quic-connections" title="Permanent link">¶</a></h3>
<p>Let's concentrate on implementing <code>Run</code> method. We need to accept QUIC client connections. This can be done by creating <code>quic.Listener</code> instance and using its <code>.Accept</code> method to accept incoming client sessions.</p>
<div><pre><span></span><code><span>// Run server.</span>
<span>func</span> <span>(</span><span>s</span> <span>*</span><span>WebTransportServerQuic</span><span>)</span> <span>Run</span><span>()</span> <span>error</span> <span>{</span>
    <span>listener</span><span>,</span> <span>err</span> <span>:=</span> <span>quic</span><span>.</span><span>ListenAddr</span><span>(</span><span>s</span><span>.</span><span>config</span><span>.</span><span>ListenAddr</span><span>,</span> <span>s</span><span>.</span><span>generateTLSConfig</span><span>(),</span> <span>nil</span><span>)</span>
    <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
        <span>return</span> <span>err</span>
    <span>}</span>
    <span>for</span> <span>{</span>
        <span>sess</span><span>,</span> <span>err</span> <span>:=</span> <span>listener</span><span>.</span><span>Accept</span><span>(</span><span>context</span><span>.</span><span>Background</span><span>())</span>
        <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
            <span>return</span> <span>err</span>
        <span>}</span>
        <span>log</span><span>.</span><span>Printf</span><span>(</span><span>"session accepted: %s"</span><span>,</span> <span>sess</span><span>.</span><span>RemoteAddr</span><span>().</span><span>String</span><span>())</span>
        <span>go</span> <span>func</span><span>()</span> <span>{</span>
            <span>defer</span> <span>func</span><span>()</span> <span>{</span>
                <span>_</span> <span>=</span> <span>sess</span><span>.</span><span>CloseWithError</span><span>(</span><span>0</span><span>,</span> <span>"bye"</span><span>)</span>
                <span>log</span><span>.</span><span>Println</span><span>(</span><span>"close session"</span><span>)</span>
            <span>}()</span>
            <span>s</span><span>.</span><span>handleSession</span><span>(</span><span>sess</span><span>)</span>
        <span>}()</span>
    <span>}</span>
<span>}</span>

<span>func</span> <span>(</span><span>s</span> <span>*</span><span>WebTransportServerQuic</span><span>)</span> <span>handleSession</span><span>(</span><span>sess</span> <span>quic</span><span>.</span><span>S…</span></code></pre></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://centrifugal.github.io/centrifugo/blog/quic_web_transport/">https://centrifugal.github.io/centrifugo/blog/quic_web_transport/</a></em></p>]]>
            </description>
            <link>https://centrifugal.github.io/centrifugo/blog/quic_web_transport/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24273371</guid>
            <pubDate>Tue, 25 Aug 2020 16:55:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everything you need to know about the recent stock splits (Tesla/ Apple)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24273249">thread link</a>) | @theaveragejoe
<br/>
August 25, 2020 | https://readthejoe.com/articles/the-beauty-of-doing-nothing/ | <a href="https://web.archive.org/web/*/https://readthejoe.com/articles/the-beauty-of-doing-nothing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div id="primary"><main id="main" role="main"><div><p>Equities</p><div> <p><img width="597" height="327" src="https://readthejoe.com/wp-content/uploads/2020/08/Breaking-Bad.gif" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p></div><div><p><span>What does a stock split do? It doesn’t do anything… That’s the beauty of it.</span></p><p><span>Tesla ($TSLA)&nbsp;<a href="https://www.cnn.com/2020/08/12/investing/stock-split-apple-tesla/index.html">announced</a>&nbsp;a 5 for 1 split of its stock to be completed on Aug. 31. The move by Tesla follows Apple’s ($AAPL) 4 for 1 stock split announced on Jul. 30.</span></p><p><span><strong>Financial hand waving</strong></span></p><p><span>On Aug. 31, every Tesla stock that you own will turn into 5. What’s the catch? Each stock will be worth a fifth of what it was worth before. Stock splits were massively popular back in the 90s with an average of 64 companies splitting their stock each year. That number dropped to 9 over the past decade.</span></p><p><span>Companies often split their stock to make it more affordable for everyday investors. The invention of fractional shares, the ability to purchase a fraction of a stock, made stock splits redundant. Stock splits cost companies&nbsp;<a href="https://www.marketwatch.com/story/companies-are-weighing-stock-splits-after-tesla-and-apples-announcements-expert-says-11597404072?mod=home-page">~$800,000</a>&nbsp;which makes them even less attractive.</span></p><p><span><strong>Don’t celebrate… or do?</strong></span></p><p><span>Stock splits are mere cosmetics that should not impact stock prices. Turning your five-dollar bill into five one-dollar bills should not make you any wealthier… Unless your bill is manufactured by Elon Musk. Tesla’s stock price increased 17% in the 2 days following the announcement.</span></p><p><span><strong>The lack of science behind stock splits</strong></span></p><p><span>A research study by David Ikenberry, a Professor of Finance at the University of Colorado, revealed stocks that split their shares&nbsp;<a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=7929">outperform</a>&nbsp;the average market return by 7.9% in the year after a stock split.</span></p><p><span>There’s no definitive explanation on why prices go up after stock splits but here are&nbsp;<a href="https://www.marketwatch.com/story/apples-stock-may-beat-the-market-through-2016-2014-06-09">two theories</a>:</span></p><ul><li><span><strong>Theory 1:</strong>&nbsp;Splits are a signal that management expects their stock prices to continue rising.</span></li><li><span><strong>Theory 2</strong>: Investors have a bias in buying stocks with lower prices thinking they have more room to increase.</span></li></ul><p><span><strong>Take no action:</strong>&nbsp;Investors should not solely use stock splits as a reason to buy. They do not fundamentally change anything in a company.</span></p></div></div></main><!-- #main --></div><!-- #primary --></div><!-- .wrap --></div><div><div><div><h3>Investing trends and news sent to your inbox twice a week</h3><p>The 5-minute newsletter that brings you new investment ideas and trends in a bite-sized format</p></div></div></div></div>]]>
            </description>
            <link>https://readthejoe.com/articles/the-beauty-of-doing-nothing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24273249</guid>
            <pubDate>Tue, 25 Aug 2020 16:45:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[LiquidHaskell Is a GHC Plugin]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24273161">thread link</a>) | @Tehnix
<br/>
August 25, 2020 | https://ucsd-progsys.github.io/liquidhaskell-blog/2020/08/20/lh-as-a-ghc-plugin.lhs/ | <a href="https://web.archive.org/web/*/https://ucsd-progsys.github.io/liquidhaskell-blog/2020/08/20/lh-as-a-ghc-plugin.lhs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
            <!-- Post Header -->


<!-- Post Content -->
<article>
    <div>
        <div>
            <div>

            <br>

            

            
			            
<p>I enjoy working with LH. However, I’d be the very first to confess that it has been incredibly tedious to get to work on <em>existing</em> code bases, for various reasons.</p>
<ol type="1">
<li><p>LH ran <em>one file at a time</em>; it was a hassle to <strong>systematically analyze</strong> all the modules in a single package.</p></li>
<li><p>LH had <em>no notion of packages</em>; it was impossible to <strong>import specifications</strong> across packages.</p></li>
<li><p>LH had <em>no integration</em> with the standard compilation cycle; it was difficult to get robust, <strong>development-time feedback</strong> using <code>ghci</code> based tools.</p></li>
</ol>
<p>I’m delighted to announce the release of <a href="http://ucsd-progsys.github.io/liquidhaskell/">LH version 0.8.10.2</a>.</p>
<p>Thanks to the ingenuity and tireless efforts of our friends <a href="http://www.alfredodinapoli.com/">Alfredo Di Napoli</a> and <a href="https://www.andres-loeh.de/">Andres Loh</a> at <a href="http://www.well-typed.com/">Well-Typed</a> this new version solves all three of the above problems in a single stroke, making it vastly simpler (dare I say, quite straightforward!) to run LH on your Haskell code.</p>
<!-- more -->
<p>Alfredo and Andres’ key insight was that all the above problems could be solved if LH could be re-engineered as a <a href="https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/extending_ghc.html#compiler-plugins">GHC Compiler Plugin</a> using hooks that GHC exposes to integrate external checkers during compilation. I strongly encourage you to check out Alfredo’s talk at the <a href="https://icfp20.sigplan.org/details/hiw-2020-papers/1/Liquid-Haskell-as-a-GHC-Plugin">Haskell Implementor’s Workshop</a> if you want to learn more about the rather non-trivial mechanics of how this plugin was engineered. However, in this post, lets look at <em>how</em> and <em>why</em> to use the plugin, in particular, how the plugin lets us</p>
<ol type="1">
<li><p>Use GHC’s dependency resolution to analyze entire packages with minimal recompilation;</p></li>
<li><p>Ship refined type specifications for old or new packages, and have them be verified at client code;</p></li>
<li><p>Use tools like <code>ghci</code> based IDE tooling (e.g.&nbsp;<code>ghcid</code> or <code>ghcide</code> to get interactive feedback),</p></li>
</ol>
<p>all of which ultimately, I hope, make Liquid Haskell easier to use.</p>
<h2 id="analyzing-packages">1. Analyzing Packages</h2>
<p>First, lets see a small “demo” of how to <em>use</em> the plugin to compile a small <a href="https://github.com/ucsd-progsys/lh-plugin-demo"><code>lh-plugin-demo</code></a> package with two modules</p>

<p>which defines a function <code>incr</code> that consumes and returns positive integers, and</p>

<p>which imports <code>Demo.Lib</code> and uses <code>incr</code>.</p>
<h3 id="updating-.cabal-to-compile-with-the-lh-plugin">Updating <code>.cabal</code> to compile with the LH plugin</h3>
<p>To “check” this code with LH we need only tell GHC to use it as a plugin, in two steps.</p>
<ol type="1">
<li>First, adding a dependency to LH in the <code>.cabal</code> file (or <code>package.yaml</code>)</li>
</ol>
<pre><code>  build-depends:
      liquid-base,
      liquidhaskell &gt;= 0.8.10</code></pre>
<ol start="2" type="1">
<li>Second, tell GHC to use the plugin</li>
</ol>
<pre><code>  ghc-options: -fplugin=LiquidHaskell</code></pre>
<p>That’s it. Now, everytime you (re-)build the code, GHC will <em>automatically</em> run LH on the changed modules! If you use <code>stack</code> you may have to specify a few more dependencies, as the various packages are not (yet) on stackage, as shown in the <a href="https://github.com/ucsd-progsys/lh-plugin-demo/blob/main/stack.yaml">demo <code>stack.yaml</code></a>. No extra dependencies are needede if you use <code>cabal-v2</code>. In both cases, you can use the respective files <a href="https://github.com/ucsd-progsys/lh-plugin-demo/blob/main/stack.yaml.github"><code>stack.yaml</code></a> and <a href="https://github.com/ucsd-progsys/lh-plugin-demo/blob/main/cabal.project.github"><code>cabal.project</code></a> point to specific git snapshots if you want to use the most recent versions. If you clone the repo and run, e.g.&nbsp;<code>cabal v2-build</code> or <code>stack build</code> you’ll get the following result, after the relevant dependencies are downloaded and built of course…</p>
<pre><code>rjhala@khao-soi ~/r/lh-demo (main)&gt; stack build
lh-plugin-demo&gt; configure (lib)
Configuring lh-plugin-demo-0.1.0.0...
lh-plugin-demo&gt; build (lib)
Preprocessing library for lh-plugin-demo-0.1.0.0..
Building library for lh-plugin-demo-0.1.0.0..
[1 of 2] Compiling Demo.Lib

**** LIQUID: UNSAFE ************************************************************

/Users/rjhala/research/lh-demo/src/Demo/Lib.hs:7:1: error:
    Liquid Type Mismatch
    .
    The inferred type
      VV : {v : GHC.Types.Int | v == x - 1}
    .
    is not a subtype of the required type
      VV : {VV : GHC.Types.Int | 0 &lt; VV}
    .
    in the context
      x : {v : GHC.Types.Int | 0 &lt; v}
  |
7 | incr x = x - 1
  | ^^^^^^^^^^^^^^</code></pre>
<p>oops, of course that <code>(-)</code> should be a <code>(+)</code> if we want the output to also be <em>positive</em> so lets edit the code to</p>

<p>and now we get</p>
<pre><code>rjhala@khao-soi ~/r/lh-plugin-demo (main)&gt; stack build
lh-plugin-demo&gt; configure (lib)
Configuring lh-plugin-demo-0.1.0.0...

lh-plugin-demo&gt; build (lib)
Preprocessing library for lh-plugin-demo-0.1.0.0..
Building library for lh-plugin-demo-0.1.0.0..
[1 of 2] Compiling Demo.Lib

**** LIQUID: SAFE (2 constraints checked) *****************************
[2 of 2] Compiling Demo.Client

**** LIQUID: UNSAFE ***************************************************

/Users/rjhala/lh-plugin-demo/src/Demo/Client.hs:6:15: error:
    Liquid Type Mismatch
    .
    The inferred type
      VV : {v : GHC.Types.Int | v == n}
    .
    is not a subtype of the required type
      VV : {VV : GHC.Types.Int | 0 &lt; VV}
    .
    in the context
      n : GHC.Types.Int
  |
6 | bump n = incr n
  |               ^</code></pre>
<p>That is, during the build, LH complains that <code>incr</code> is being called with a value <code>n</code> that is not strictly positive as required by <code>incr</code>. To fix the code, we can edit it in various ways, e.g.&nbsp;to only call <code>incr</code> if <code>n &gt; 0</code></p>

<p>and now the code builds successfully</p>
<pre><code>rjhala@khao-soi ~/r/lh-plugin-demo (main)&gt; stack build
lh-plugin-demo&gt; configure (lib)
Configuring lh-plugin-demo-0.1.0.0...
lh-plugin-demo&gt; build (lib)
Preprocessing library for lh-plugin-demo-0.1.0.0..
Building library for lh-plugin-demo-0.1.0.0..
[2 of 2] Compiling Demo.Client

**** LIQUID: SAFE (2 constraints checked) ****************************
lh-plugin-demo&gt; copy/register
Installing library in ... 
Registering library for lh-plugin-demo-0.1.0.0..</code></pre>
<h3 id="benefits">Benefits</h3>
<p>There are a couple of benefits to note immediately</p>
<ul>
<li><p>A plain <code>stack build</code> or <code>cabal v2-build</code> takes care of all the installing <em>and</em> checking!</p></li>
<li><p>No need to separately <em>install</em> LH; its part of the regular build.</p></li>
<li><p>GHC’s recompilation machinery ensures that only the relevant modules are checked, e.g.&nbsp;the second time round, LH did not need to analyze <code>Lib.hs</code> only <code>Client.hs</code></p></li>
</ul>
<h2 id="shipping-specifications-with-packages">2. Shipping Specifications with Packages</h2>
<p>While the above is nice, in principle it could have been done with some clever <code>makefile</code> trickery (perhaps?). What I’m much more excited about is that now, for the first time, you can <em>ship refinement type specifications within plain Haskell packages</em>.</p>
<p>For example, consider a different <a href="https://github.com/ucsd-progsys/lh-plugin-demo-client">lh-plugin-demo-client</a> package that uses <code>incr</code> from <code>lh-plugin-demo</code>:</p>

<p>Again, the <code>lh-plugin-demo-client.cabal</code> file need only specify the various dependencies:</p>
<pre><code>  build-depends:
      liquid-base,
      liquidhaskell,
      lh-plugin-demo</code></pre>
<p>and that GHC should use the plugin</p>
<pre><code>  ghc-options: -fplugin=LiquidHaskell</code></pre>
<p>and lo! a plain <code>stack build</code> or <code>cabal v2-build</code> takes care of all the rest.</p>
<pre><code>rjhala@khao-soi ~/r/lh-plugin-demo-client (main)&gt; stack build
lh-plugin-demo-client&gt; configure (lib)
Configuring lh-plugin-demo-client-0.1.0.0...

lh-plugin-demo-client&gt; build (lib)
Preprocessing library for lh-plugin-demo-client-0.1.0.0..
Building library for lh-plugin-demo-client-0.1.0.0..
[1 of 1] Compiling Demo.ExternalClient

**** LIQUID: UNSAFE ****************************************************

/Users/rjhala/lh-plugin-demo-client/src/Demo/ExternalClient.hs:8:22: error:
    Liquid Type Mismatch
    .
    The inferred type
      VV : {v : GHC.Types.Int | v == 0 - n}
    .
    is not a subtype of the required type
      VV : {VV : GHC.Types.Int | VV &gt; 0}
    .
    in the context
      n : GHC.Types.Int
  |
8 |   | otherwise = incr (0 - n)
  |                      ^^^^^^^</code></pre>
<p>(Whoops another off by one error, lets fix it!)</p>

<p>and now all is well</p>
<pre><code>rjhala@khao-soi ~/r/lh-plugin-demo-client (main)&gt; stack build --fast
lh-plugin-demo-client&gt; configure (lib)
Configuring lh-plugin-demo-client-0.1.0.0...
lh-plugin-demo-client&gt; build (lib)
Preprocessing library for lh-plugin-demo-client-0.1.0.0..
Building library for lh-plugin-demo-client-0.1.0.0..
[1 of 1] Compiling Demo.ExternalClient

**** LIQUID: SAFE (3 constraints checked) *****************************

lh-plugin-demo-client&gt; copy/register
Installing library in ... 
Registering library for lh-plugin-demo-client-0.1.0.0..</code></pre>
<h3 id="prelude-specifications">Prelude Specifications</h3>
<p>Did you notice the strange <code>liquid-base</code> dependency in the cabal files?</p>
<p>Previously, LH came installed with a “built-in” set of specifications for various <code>prelude</code> modules. This was <em>hacked</em> inside LH in a rather unfortunate manner, which made these specifications very difficult to extend.</p>
<p>Moving forward, all the refinement specifications e.g.&nbsp;for <code>GHC.List</code> or <code>Data.Vector</code> or <code>Data.Set</code> or <code>Data.Bytestring</code> simply live in packages that <em>mirror</em> the original versions, e.g.&nbsp;<code>liquid-base</code>, <code>liquid-vector</code>, <code>liquid-containers</code>, <code>liquid-bytestring</code>. Each <code>liquid-X</code> package directly <em>re-exports</em> all the contents of the corresponding <code>X</code> package, but with any additional refinement type specifications.</p>
<p>Thus, all the refined types for various prelude operations like <code>(+)</code> or <code>(-)</code> or <code>head</code> and so on, now ship with <code>liquid-base</code> and we add that dependency <strong>instead of</strong> base. Similarly, if you want to verify that <em>your</em> code has no <code>vector</code>-index overflow errors, you simply build with <code>liquid-vector</code> <strong>instead of</strong> <code>vector</code>! Of course, in an ideal, and hopefully not too distant future, we’d directly include the refinement types inside <code>vector</code>, <code>containers</code> or <code>bytestring</code> respectively.</p>
<h3 id="benefits-1">Benefits</h3>
<p>So to recap, the plugin offers several nice benefits with respect to <em>shipping specifications</em></p>
<ul>
<li><p>Refined signatures are bundled together with packages,</p></li>
<li><p>Importing packages with refined signatures automatically ensures those signatures are checked on client code,</p></li>
<li><p>You can (optionally) use refined versions of <code>prelude</code> signatures, and hence, even write refined versions of your favorite <em>custom preludes</em>.</p></li>
</ul>

<p>I saved <em>my</em> favorite part for the end.</p>
<p>What I have enjoyed the most about the plugin is that now (almost) all the GHC-based tools that I use in my regular Haskell development workflow, automatically incorporate LH too! For example, reloading a module in <code>ghci</code> automatically re-runs LH on that file.</p>
<h3 id="ghcid"><code>ghcid</code></h3>
<p>This means, that the mega robust, editor-independent <code>ghcid</code> now automatically produces LH type errors when you save a file. Here’s <code>ghcid</code> running in a terminal.</p>
<figure>
<img src="https://ucsd-progsys.github.io/liquidhaskell-blog/static/img/plugin-ghcid.gif" alt="ghcid"><figcaption>ghcid</figcaption>
</figure>
<h3 id="vscode"><code>vscode</code></h3>
<p>Editor plugins now produce little red squiggles for LH errors too. Here’s <code>code</code> with the <code>Simple GHC (Haskell) Integration</code> plugin</p>
<p><img src="https://ucsd-progsys.github.io/liquidhaskell-blog/static/img/plugin-vscode.gif"></p>
<h3 id="emacs"><code>emacs</code></h3>
<p>H…</p></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ucsd-progsys.github.io/liquidhaskell-blog/2020/08/20/lh-as-a-ghc-plugin.lhs/">https://ucsd-progsys.github.io/liquidhaskell-blog/2020/08/20/lh-as-a-ghc-plugin.lhs/</a></em></p>]]>
            </description>
            <link>https://ucsd-progsys.github.io/liquidhaskell-blog/2020/08/20/lh-as-a-ghc-plugin.lhs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24273161</guid>
            <pubDate>Tue, 25 Aug 2020 16:37:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unity Mars – Advanced AR Workflows with Andrew Maneri]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24273057">thread link</a>) | @barbelldan
<br/>
August 25, 2020 | https://circuitstream.com/workshop/advanced-ar-unity-mars/ | <a href="https://web.archive.org/web/*/https://circuitstream.com/workshop/advanced-ar-unity-mars/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <!-- main tag closed in footer.php-->    <main role="main">
                    <div><!-- bs section -->
<section aria-label="Workshop Detail Content" role="region">
    <div>
                <div>
            <div>
	
<div>
    <div>
                <div>
            


<div>
        <div>
        <p>
		        		        03 September 2020		        <span>– 7pm ET</span>            </p>
    </div>
</div>
<div>
    <div>
                    <div title="TextBox Title">
                <p>We've already experienced the fundamentals&nbsp; of Unity MARS. This time we are kicking it up a notch by discovering a true power of MARS workflows.</p><p>Unity Technologies is sending one of their own engineers to show you the way. Andrew Maneri, perceptual engineer at Unity is going to demonstrate advanced workflows inside MARS editor: from creating simulation environments to utilizing landmarks and forces, to scripting new actions and reasoning APIs</p><p>By the end of the workshop, you'll be armed to tackle Unity MARS like a pro.</p><p><strong>Resources:</strong></p><ul><li><em>Presentation slides</em></li></ul><p>Hosted by</p>            </div>
            </div> 
</div>


<div aria-label="author">
    <div>
        
    <div>
                        <figure>
                            <img src="https://cs-wordpress-static-assets.s3.amazonaws.com/uploads/2020/08/andrew_maneri-unity.jpeg" alt="" title="">
                            <figcaption></figcaption>
                            </figure>
                       </div><div><p aria-label="author name">
    <h3 role="heading">Andrew Maneri</h3>
</p>
<p>Perceptual Engineer at Unity Technologies</p>
    </div>
    </div>
</div>
<div>
    <div>
                    <div title="What you will learn">
                <h2>During the workshop, we'll share:</h2><ul><li>Introduction to advanced MARS workflows</li><li>MARS best practices for designers and developers</li><li>How to create simulation environments</li><li>How to utilize landmarks and forces</li><li>How to script new actions</li><li>How to access and use MARS data with Reasoning APIs</li></ul><h2>At the end of the workshop, you'll have:</h2><ul><li>Knowledge of MARS workflows</li><li>A deeper understanding of how simulation works</li><li>Knowledge how to script and utilize MARS data</li><li>Answers to your questions about MARS development</li></ul><h2>Workshop prerequisites</h2><ul><li>Downloaded Unity 2019.3 or newer (optional)</li><li>Installed MARS (free for 45 days) (optional)</li><li>AR headset is not needed</li></ul><h2>About Your Instructor:</h2><p>Andrew Maneri has been working with Unity Labs since 2015 to pioneer the future of XR interaction. He has been a technical Lead on Unity Project MARS.</p>            </div>
            </div> 
</div>
        </div>
            </div>
</div>


</div>
        </div>
            </div>
</section>


<!-- bs section -->
<section aria-label="Our Partners" role="region">
    
</section>


</div>
            </main>
</div></div>]]>
            </description>
            <link>https://circuitstream.com/workshop/advanced-ar-unity-mars/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24273057</guid>
            <pubDate>Tue, 25 Aug 2020 16:28:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to achieve career growth: opportunities, skills and sponsors]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24273025">thread link</a>) | @yenkel
<br/>
August 25, 2020 | https://yenkel.dev/posts/how-to-achieve-career-growth-opportunities-skills-sponsors | <a href="https://web.archive.org/web/*/https://yenkel.dev/posts/how-to-achieve-career-growth-opportunities-skills-sponsors">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>I recently started mentoring someone that works at another company. Their goal is to become a “tech lead”: at their company, this is a person that others look for technical advice, and that can influence teams’ technical decisions. Because this person does not work where I do, I was forced to think generically about the matter of growth, rather than jumping to specific advice I would be able to provide a coworker.</p><p>In general, you might want to grow in your software engineering career, but:</p><ul><li>what does growth mean? </li><li>how can you achieve it?</li><li>who decides if you are ready to grow?</li><li>where do you start?</li></ul><p>Years ago I read a phrase in <a href="https://www.forbes.com/sites/daviatemin/2016/04/04/what-theyre-saying-about-you-when-youre-not-in-the-room-and-what-you-can-do-to-influence-it/#4cb99ee771ac" target="_blank" rel="nofollow noopener noreferrer">this article</a> that made many things click for me:</p><blockquote><p>The biggest decisions about your career are often made when you’re not in the room</p></blockquote><p>For example, when I was working at a consulting company I did not decide which projects I was involved in. It depended on the contracts we closed, customers’ budget and other’s allocations.</p><p>Whenever I’m thinking about career growth I keep that in mind.  It helped me put together a mental model for professional growth. This blog post shares my growth model and how you can use it to carve your career growth path.</p><p>Let’s introduce some terms first:</p><ul><li>Growth: access to more challenging and/or new opportunities. Growth is multidimensional.</li><li>Opportunity: a possibility for improving and/or displaying your skills. They might be accompanied by financial rewards, recognition, etc.</li><li>Skills: what you can do, including knowledge required to do it</li></ul><p>From those three definitions a couple of questions arise:</p><ol><li>Who are you displaying your skills to?</li><li>Who gets you access to opportunities?</li></ol><p>To answer those questions and complete the model we need to define <strong>Sponsors</strong>:</p><ul><li>Sponsors: People that are aware of available opportunities and can grant them to you. </li></ul><p>Applying <a href="https://lethain.com/systems-thinking/" target="_blank" rel="nofollow noopener noreferrer">systems thinking</a> to the model we come up with this diagram:
<img src="https://yenkel.dev/media/2020-08-25/growth.png"></p><ol><li>Your opportunities increase as new opportunities are granted to you. This rate depends on your sponsors.</li><li>Your skills improve depending on how fast you learn from your opportunities.</li><li>You get more sponsors the more people have a positive perception of your skills. These displays depend on your skills, e.g.: when you are given the opportunity to present you are displaying your presentation skills. If you are good at presenting, sponsors will perceive that.</li></ol><h2 id="takeaways"><a href="#takeaways" aria-label="takeaways permalink"></a>Takeaways</h2><p>Our <em>growth</em> definition means you want to maximize <em>your opportunities</em>. The most important takeaway is:</p><p><strong>Skill alone doesn’t matter. If no one but yourself knows about your skills, you won’t get any opportunities.</strong></p><p>What you want is to:</p><ol><li>Maximize <strong>Available Opportunities</strong></li><li>Maximize <strong>Sponsors</strong></li></ol><h2 id="your-energy"><a href="#your-energy" aria-label="your energy permalink"></a>Your energy</h2><p>To keep the model simple and the post short I am not including “Your energy” as a stock. Modeling energy is complex:
When you take new opportunities your energy decreases. When you run out of energy you <a href="https://medium.com/hackernoon/why-theres-so-much-burnout-in-software-and-what-to-do-about-it-4ef0297ca7cc" target="_blank" rel="nofollow noopener noreferrer">burnout</a>.
When you do things you enjoy doing or rest (take fewer opportunities) your energy replenishes.
Your energy levels affect your skill learning/improvement rate.
And there are many ways in which your energy levels change that are not part of the system model I propose but impact the system nevertheless…</p><p>You can easily see how this would make the model more complex. However, just because it is harder to model it doesn’t mean you shouldn’t consider energy as part of your approach to growth.</p><p>Opportunities come in different flavors, not all of them are “being tasked to do something”. All of these are opportunities:</p><ul><li>Changing teams to work on a different problem set</li><li>Being picked to technically lead an initiative larger than you have ever lead before</li><li>Speaking at a conference</li><li>Attending a workshop</li><li>Frequently being mentored by a more senior person</li></ul><p><img src="https://yenkel.dev/media/2020-08-25/opportunity.jpg"></p><p>If there are few <strong>Available Opportunities</strong>, it doesn’t matter how good you are, it is very unlikely you will be granted new ones. <strong>Available Opportunities</strong> are also contextual: they depend on your seniority, team, company’s financial situation, etc. You are also not interested in ANY opportunity. There are specific things that you’ll be interested in doing and/or learning.</p><p>With those things in mind, these are some tips for maximizing <strong>Available Opportunities</strong>.</p><ol><li><strong>Pick opportunities based on your growth goals</strong>: If you want to grow as a distributed systems engineer, opportunities related to building mobile applications are likely to help you less than opportunities related to building databases. I recommend avoiding short term goals related to “titles” and instead prioritized improving your skills over time.</li></ol><p>Goals don’t necessarily need to be getting a better title/promoted. A goal in your career can just be “maximizing learning”, which means you need to “maximize learning opportunities” and your “improve rate”.</p><p><a href="https://lethain.com/forty-year-career/" target="_blank" rel="nofollow noopener noreferrer">This article</a> by Will Larson does a great job of explaining how to plan for a long term career.
<a href="https://medium.com/@bellmar/why-is-this-idiot-running-my-engineering-org-c6e815790cdb" target="_blank" rel="nofollow noopener noreferrer">This article</a> by Marianne Belloti talks about some drawbacks of making career decisions based on just looking for higher titles and admiration</p><ol><li><p><strong>Determine how to best get those opportunities</strong>, ideally minimizing <em>“investment”</em> required to get them: </p><p>If you can get the opportunities you are interested in by staying in your current team, that’s great. If that’s not the case: are there other teams in the engineering organization doing what you want? Are there teams in other departments in the organization doing it? If not, then it might be time to change companies.</p><p>The same applies to conference speaking. If there are two similar conferences on the same date, and one of them requires you to fly 14 hours and the other one only 2 hours, you probably want to pick the latter.</p><p>Large companies that have a strict process for granting opportunities based on just “years at the company” are reducing the amount of <strong>Available Opportunities</strong>, regardless of your skills. This is why high growth startups are sometimes so popular for people that want to grow, there are plenty of opportunities.</p></li><li><p><strong>Create your opportunities</strong>: Proactively propose opportunities to sponsors, adding them to the <strong>Available Opportunities</strong> stock. </p><p>Want to get better at automated testing? Do some research to explain how more testing would help the team/company, explain that to the right sponsor (more on that later), and pitch to work on a project related to that next quarter. Simultaneously, reach out to someone in your organization that you believe is great at automated testing and ask them to mentor you.</p></li></ol><h2 id="reorganizations"><a href="#reorganizations" aria-label="reorganizations permalink"></a>Reorganizations</h2><p>Reorganizations might change the <strong>Available Opportunities</strong> a lot, especially at Senior Engineer (or higher) roles. Depending on the reorganization type and size you might get a heads up and be asked for feedback on options regarding where you will land. During those conversations consider the future <strong>Available Opportunities</strong> to decide what to do.</p><p>Having determined the kind of opportunity you want, the next thing is to get the sponsors for those opportunities to think of your skills as a good fit for them. This involves:</p><ol><li>Finding the right sponsor</li><li>Make your skills visible to them</li></ol><p>When you begin your career as a developer, your team’s Manager or Tech Lead is likely your main sponsor. They are aware of opportunities for tasks/work inside the team and they are the ones assigning work.</p><p>As you grow the situation changes, but you <a href="https://staffeng.com/guides/staying-aligned-with-authority" target="_blank" rel="nofollow noopener noreferrer">always need sponsors</a>. Senior Engineer role (or higher) related opportunities might be discussed at a cross-team level, maybe in a forum involving multiple Managers and/or Directors. Principal level engineers might also have a say in nudging decisions about critical initiatives. People’s titles stop being a good indicator of “sponsorship ability”. <strong>In essence, you need to understand the <a href="https://en.wikipedia.org/wiki/Informal_organization" target="_blank" rel="nofollow noopener noreferrer">informal organization</a> and how it relates to the opportunities you are interested in.</strong></p><p>If you are lost, ask someone you trust and is influential for help. This person doesn’t necessarily need to be a coworker. They should be able to provide guidance. </p><p><img src="https://yenkel.dev/media/2020-08-25/sponsors.jpg"></p><h2 id="visibility"><a href="#visibility" aria-label="visibility permalink"></a>Visibility</h2><p>After identifying the right sponsor(s) you need to make your skills (and interest) visible to them (“skill displays”). Remember: this is not about “lying” or “faking it”. This is about generating awareness. </p><p>You can do this in different ways:</p><ol><li><strong>1:1s</strong>: if you can get a 1:1 with the sponsor to chat about opportunities, do it. In general, when you reach out to people asking them to help you grow and learn, their reactions will be helpful and positive. In these situations, it helps to <a href="#self-awareness">be self-aware</a>.</li><li><strong>Generate content</strong>: internal or external content (conference talks, blog posts) allows you to share your skills. If you want more opportunities to work with Kafka maybe doing a Kafka brown bag and inviting the infrastructure tech leads can help.</li><li><strong>Share accomplishments</strong>: The parallel to: “If a tree falls in a forest and no one is around to hear it, does it make a sound?” is “If you reduce AWS expenses by 25% but no one knows about it, did it happen?“. Make sure the right sponsors know what you have achieved. Whenever you do this, make sure you give credit where credit is due.</li></ol><p>The more senior your sponsor the more things they have on their mind. It is hard for them to pay attention and keep in mind the skills and goals of multiple people. </p><p>Make sure you provide visibility in an easy to consume format. There are some specific approaches that you can use to provide visibility about your work:
<a href="https://jvns.ca/blog/brag-documents/" target="_blank" rel="nofollow noopener noreferrer">Brag documents</a> by Julia Evans
<a href="https://lethain.com/career-narratives/" target="_blank" rel="nofollow noopener noreferrer">Career narratives</a> by Will Larson</p><p>Periodically remind sponsors of your skills and goals. Following up with your sponsors and repeating yourself once in a while is fine.</p><p>Some potential sponsors might be biased. If they are negatively biased towards you, you will need a much higher “skill display rate” than a person they aren’t biased against would need to get them to be YOUR sponsor. There might even be cases when they will never become sponsors, no matter how high your “skill display rate”.</p><p>Lara Hogan has a <a href="https://larahogan.me/blog/what-sponsorship-looks-like/" target="_blank" rel="nofollow noopener noreferrer">great blog post</a> on this topic.</p><p>Consider sponsor bias whenever you are looking to decide if a person is “the right sponsor” for you.</p><h3 id="outside-your-company"><a href="#outside-your-company" aria-label="outside your company permalink"></a>Outside your company</h3><p>Sharing your skills in public sites (LinkedIn, Twitter, conference talks, blogs, etc.) creates …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://yenkel.dev/posts/how-to-achieve-career-growth-opportunities-skills-sponsors">https://yenkel.dev/posts/how-to-achieve-career-growth-opportunities-skills-sponsors</a></em></p>]]>
            </description>
            <link>https://yenkel.dev/posts/how-to-achieve-career-growth-opportunities-skills-sponsors</link>
            <guid isPermaLink="false">hacker-news-small-sites-24273025</guid>
            <pubDate>Tue, 25 Aug 2020 16:25:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimal Peanut Butter and Banana Sandwiches]]>
            </title>
            <description>
<![CDATA[
Score 285 | Comments 99 (<a href="https://news.ycombinator.com/item?id=24272814">thread link</a>) | @ethanahte
<br/>
August 25, 2020 | https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/ | <a href="https://web.archive.org/web/*/https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      <section>
          <section>
              

              
              
              
              
              


              <article>
                  <div>
<video autoplay="" muted="" loop="loop">
    <source src="https://www.ethanrosenthal.com/videos/optimal-peanut-butter-and-banana/banana_small.mp4" type="video/mp4">
</video>

<p>I was personally useless for most of the Spring of 2020. There was a period of time, though, after the peak in coronavirus cases here in NYC and before the onslaught of police violence here in NYC that I managed to scrounge up the motivation to do something other than drink and maniacally refresh my Twitter feed. I set out to work on something completely meaningless. It was almost therapeutic to work on a project with no value of any kind (<em>insert PhD joke here</em>).</p>
<p>A side effect of having spent 10 years with limited income in college and grad school, 6 of those here in expensive ass NYC, is that I eat of lot of cheap sandwiches, even though I now have a nice Tech™ job. While my sandwich consumption was quite formidable pre-covid, sheltering in place cemented this staple in my diet. I am particularly fond of peanut butter and banana sandwiches, having been introduced to them as a child by my maternal grandfather who ate them regularly.</p>
<p>I start a peanut butter and banana sandwich by spreading peanut butter on two slices of bread. I then slice circular slices of the banana, starting at the end of the banana, and place each slice on one of the pieces of bread until I have a single layer of banana slices. Every time I do this, the former condensed matter physicist in me starts to twitch his eye. You see, I have this urge, this desire, this <em>need</em> to maximize the <a href="https://en.wikipedia.org/wiki/Atomic_packing_factor">packing fraction</a> of the banana slices. That is, I want to maximize the coverage of the banana slices on the bread. Just as bowl-form food is perfect because you get every ingredient in every bite, each bite of my sandwich should yield the same golden ratio of bread, peanut butter, and banana.</p>
<p>If you were a machine learning model (or my wife), then you would tell me to just cut long rectangular strips along the long axis of the banana, but I’m not a sociopath. If life were simple, then the banana slices would be perfect circles of equal diameter, and we could coast along looking up optimal configurations on <a href="http://packomania.com/">packomania</a>. But alas, life is not simple. We’re in the middle of a global pandemic, and banana slices are elliptical with varying size.</p>
<p>So, how do we make optimal peanut butter and banana sandwiches? It’s really quite simple. You take a picture of your banana and bread, pass the image through a deep learning model to locate said items, do some nonlinear curve fitting to the banana, transform to polar coordinates and “slice” the banana along the fitted curve, turn those slices into elliptical polygons, and feed the polygons and bread “box” into a 2D nesting algorithm.</p>
<p>You may have noticed that I supposedly started this project in the Spring, and it’s now August. Like most idiot engineers, I had no idea how complicated this stupid project was going to be, but time’s meaningless in quarantine, so here we are. And here you are! Because I made a pip installable python package <a href="https://github.com/EthanRosenthal/nannernest">nannernest</a> if you want to optimize your own sandwiches, and I’m going to spend the rest of this post describing how this whole godforsaken thing works.</p>
</div>
<div>
<h2 id="sandwich-segmentation">Sandwich Segmentation</h2>
<p>I know that deep learning has been properly commoditized when the easiest part of this project was identifying every pixel that belongs to a banana or slice of bread in an image. Seriously, this step was super easy. I used a pretrained Mask-RCNN torchvision <a href="https://pytorch.org/docs/stable/torchvision/models.html#torchvision.models.detection.maskrcnn_resnet50_fpn">model</a> with a Resnet backbone. The model was pretrained on the COCO <a href="https://cocodataset.org/">dataset</a>, and thankfully the dataset has “banana” as segmentation category, along with “sandwich” and “cake” which were close enough categories for suitable detection of most slices of bread.</p>
<p>Passing an image through the model outputs a bunch of detected objects, where each detected object has an associated <code>label</code>, <code>score</code>, <code>bounding box</code>, and <code>mask</code>, where the mask identifies the pixels that correspond to the object with a weight at each pixel corresponding to the model’s confidence in that pixel’s label.</p>
<p>Because there could be multiple bananas and slices of bread in the image, I pick out the banana and slice of bread with the highest score. Below, you can see the model is clearly able to identify the banana and bread, with the mask overlaid in a semi-transparent, radioactive green.</p>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>%</span><span>config</span> <span>InlineBackend</span><span>.</span><span>figure_format</span> <span>=</span> <span></span><span>'</span><span>retina</span><span>'</span>

<span>from</span> <span>pathlib</span> <span>import</span> <span>Path</span>
<span>import</span> <span>matplotlib.pyplot</span> <span>as</span> <span>plt</span>
<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>import</span> <span>nannernest</span>

<span>_RC_PARAMS</span> <span>=</span> <span>{</span>
    <span></span><span>"</span><span>figure.figsize</span><span>"</span><span>:</span> <span>(</span><span>8</span><span>,</span> <span>4</span><span>)</span><span>,</span>
    <span></span><span>"</span><span>axes.labelsize</span><span>"</span><span>:</span> <span>16</span><span>,</span>
    <span></span><span>"</span><span>axes.titlesize</span><span>"</span><span>:</span> <span>18</span><span>,</span>
    <span></span><span>"</span><span>axes.spines.right</span><span>"</span><span>:</span> <span>False</span><span>,</span>
    <span></span><span>"</span><span>axes.spines.top</span><span>"</span><span>:</span> <span>False</span><span>,</span>
    <span></span><span>"</span><span>font.size</span><span>"</span><span>:</span> <span>14</span><span>,</span>
    <span></span><span>"</span><span>lines.linewidth</span><span>"</span><span>:</span> <span>2</span><span>,</span>
    <span></span><span>"</span><span>lines.markersize</span><span>"</span><span>:</span> <span>6</span><span>,</span>
    <span></span><span>"</span><span>legend.fontsize</span><span>"</span><span>:</span> <span>14</span><span>,</span>
<span>}</span>
<span>for</span> <span>k</span><span>,</span> <span>v</span> <span>in</span> <span>_RC_PARAMS</span><span>.</span><span>items</span><span>(</span><span>)</span><span>:</span>
    <span>plt</span><span>.</span><span>rcParams</span><span>[</span><span>k</span><span>]</span> <span>=</span> <span>v</span>

<span>DPI</span> <span>=</span> <span>160</span>
</code></pre></div></div>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>image</span><span>,</span> <span>banana</span><span>,</span> <span>bread</span> <span>=</span> <span>nannernest</span><span>.</span><span>segmentation</span><span>.</span><span>run</span><span>(</span><span>Path</span><span>(</span><span></span><span>"</span><span>pre_sandwich.jpg</span><span>"</span><span>)</span><span>)</span>
</code></pre></div></div>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>nannernest</span><span>.</span><span>viz</span><span>.</span><span>plot</span><span>(</span><span>image</span><span>,</span> <span>banana</span><span>=</span><span>banana</span><span>,</span> <span>bread</span><span>=</span><span>bread</span><span>,</span> <span>show</span><span>=</span><span>True</span><span>,</span> <span>dpi</span><span>=</span><span>DPI</span><span>)</span>
</code></pre></div></div>



<figure>
    
        <img src="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/index_4_0.png"> </figure>

</div>
<div>
<h2 id="what-shape-does-a-banana-makehttpswwwyoutubecomwatchv3o1ad4lzygk"><a href="https://www.youtube.com/watch?v=3O1ad4lZYGk">What shape does a banana make?</a></h2>
<p>Now that we have identified the banana in the image, we need to virtually “slice” it. This is where we are first introduced to the universal pain of computer vision:</p>
<p><em>By eye, I can see exactly what I want to do; by code, it’s so damn difficult.</em></p>
<p>I could ask you to draw lines on the banana identifying where you would slice it, and you could easily draw well-spaced, somewhat parallel slices. It’s not so easy to do this with code. However, I would also argue that this is the fun part of the problem. There are many ways to solve this, and it feels creative, as opposed to using a pre-trained deep learning model. On the other hand, “creatively” solving these problems likely leads to more brittle solutions compared to deep learning models trained on millions of examples. There’s a tradeoff here.</p>
<p>I tried a bunch of analytical solutions based on ellipses, but nothing seemed to work quite right. I ended up landing on a somewhat simpler solution that may not be robust to straight bananas, but who cares – this is a silly project anyway. Using the wonderful <a href="https://scikit-image.org/">scikit-image</a> library, I first calculate the <a href="https://scikit-image.org/docs/dev/auto_examples/edges/plot_skeleton.html">skeleton</a> of the banana segmentation mask. This reduces the mask to a one pixel wide representation which effectively creates a curve that runs along the long axis of the banana.</p>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>slices</span><span>,</span> <span>banana_circle</span><span>,</span> <span>banana_centroid</span><span>,</span> <span>banana_skeleton</span> <span>=</span> <span>nannernest</span><span>.</span><span>slicing</span><span>.</span><span>run</span><span>(</span>
    <span>banana</span><span>.</span><span>mask</span>
<span>)</span>
</code></pre></div></div>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>nannernest</span><span>.</span><span>viz</span><span>.</span><span>plot</span><span>(</span><span>image</span><span>,</span> <span>banana_skeleton</span><span>=</span><span>banana_skeleton</span><span>,</span> <span>show</span><span>=</span><span>True</span><span>,</span> <span>dpi</span><span>=</span><span>DPI</span><span>)</span>
</code></pre></div></div>



<figure>
    
        <img src="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/index_7_0.png"> </figure>

</div>
<p>I then fit a circle to the banana skeleton using a nice scipy-based least squares optimization I found <a href="https://scipy-cookbook.readthedocs.io/items/Least_Squares_Circle.html#Using-scipy.optimize.leastsq">here</a>. I actually originally tried to fit this with PyTorch and totally failed, likely due to the fact that this is actually a nonlinear optimization problem.</p>
<div>
<div>
<div><pre><code data-lang="python"><span>nannernest</span><span>.</span><span>viz</span><span>.</span><span>plot</span><span>(</span>
    <span>image</span><span>,</span>
    <span>banana_skeleton</span><span>=</span><span>banana_skeleton</span><span>,</span>
    <span>banana_circle</span><span>=</span><span>banana_circle</span><span>,</span>
    <span>show</span><span>=</span><span>True</span><span>,</span>
    <span>dpi</span><span>=</span><span>DPI</span><span>,</span>
<span>)</span>
</code></pre></div></div>



<figure>
    
        <img src="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/index_9_0.png"> </figure>

</div>
<div>
<h2 id="rad-coordinate-transformations">Rad Coordinate Transformations</h2>
<p>With the circle fit to the banana, the goal is to now draw radial lines out from the center of the circle to the banana and have each radial line correspond to the slice of a knife. Again, while it’s easy to visualize this, it’s much harder in practice. For example, we need to start slicing at one end of the banana, but how do we find an end of the banana? Also, there are two ends, and we have to differentiate between them. Contrary to the behavior of <a href="https://www.thekitchn.com/why-you-should-peel-your-banana-like-a-monkey-206322">monkeys</a>, I start slicing my bananas at the stem end, and that’s what we’re going to do here.</p>
<p>Crucially, because we now have this circle and want to cut radial slices, we must transform from cartesian to polar coordinates and orient ourselves both radially and angularly with respect to the banana. As a start for orienting ourselves angularly, we calculate the <em>centroid</em> of the banana mask, which corresponds to the center of mass of the banana mask if the banana mask were a 2D object. The centroid is shown below as a red dot.</p>
<p>We now draw a radial line originating from the banana circle and passing through the centroid, shown as the dashed white line below. We will consider that line to mark our <em>reference</em> angle which orients us to the center of the banana.</p>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>ax</span> <span>=</span> <span>nannernest</span><span>.</span><span>viz</span><span>.</span><span>plot</span><span>(</span>
    <span>image</span><span>,</span>
    <span>banana_skeleton</span><span>=</span><span>banana_skeleton</span><span>,</span>
    <span>banana_circle</span><span>=</span><span>banana_circle</span><span>,</span>
    <span>banana_centroid</span><span>=</span><span>banana_centroid</span><span>,</span>
    <span>show</span><span>=</span><span>False</span><span>,</span>
    <span>dpi</span><span>=</span><span>DPI</span><span>,</span>
<span>)</span>

<span>dy</span> <span>=</span> <span>banana_centroid</span><span>[</span><span>0</span><span>]</span> <span>-</span> <span>banana_circle</span><span>.</span><span>yc</span>
<span>dx</span> <span>=</span> <span>banana_centroid</span><span>[</span><span>1</span><span>]</span> <span>-</span> <span>banana_circle</span><span>.</span><span>xc</span>
<span>reference_angle</span> <span>=</span> <span>np</span><span>.</span><span>arctan2</span><span>(</span><span>dy</span><span>,</span> <span>dx</span><span>)</span>
<span>radius</span> <span>=</span> <span>np</span><span>.</span><span>sqrt</span><span>(</span><span>dx</span> <span>*</span><span>*</span> <span>2</span> <span>+</span> <span>dy</span> <span>*</span><span>*</span> <span>2</span><span>)</span>

<span>radial_end_point</span> <span>=</span> <span>(</span>
    <span>banana_circle</span><span>.</span><span>xc</span> <span>+</span> <span>2</span> <span>*</span> <span>radius</span> <span>*</span> <span>np</span><span>.</span><span>cos</span><span>(</span><span>reference_angle</span><span>)</span><span>,</span>
    <span>banana_circle</span><span>.</span><span>yc</span> <span>+</span> <span>2</span> <span>*</span> <span>radius</span> <span>*</span> <span>np</span><span>.</span><span>sin</span><span>(</span><span>reference_angle</span><span>)</span><span>,</span>
<span>)</span>

<span>ax</span><span>.</span><span>plot</span><span>(</span>
    <span>(</span><span>banana_circle</span><span>.</span><span>xc</span><span>,</span> <span>radial_end_point</span><span>[</span><span>0</span><span>]</span><span>)</span><span>,</span>
    <span>(</span><span>banana_circle</span><span>.</span><span>yc</span><span>,</span> <span>radial_end_point</span><span>[</span><span>1</span><span>]</span><span>)</span><span>,</span>
    <span>color</span><span>=</span><span></span><span>"</span><span>white</span><span>"</span><span>,</span>
    <span>linestyle</span><span>=</span><span></span><span>"</span><span>--</span><span>"</span><span>,</span>
    <span>linewidth</span><span>=</span><span>1</span><span>,</span>
<span>)</span>
<span>None</span>
</code></pre></div></div>



<figure>
    
        <img src="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/index_11_0.png"> </figure>

</div>
<p>Using <code>scikit-image</code>, we calculate the segmentation <code>mask</code> intensity along this radial line using the <code>profile_line</code> function. Because our line is passing at an angle along discrete <code>mask</code> pixels (aka matrix entries), we take an average of neighboring points along the radial line cut using the <code>linewidth</code> arguments. As you can see, the banana mask pops out a little over 100 points from the banana circle center.</p>
<div>
<div>
<div><pre><code data-lang="python"><span>from</span> <span>skimage</span> <span>import</span> <span>measure</span>

<span>profile_line</span> <span>=</span> <span>measure</span><span>.</span><span>profile_line</span><span>(</span>
    <span>banana</span><span>.</span><span>mask</span><span>.</span><span>T</span><span>,</span> <span>banana_circle</span><span>.</span><span>center</span><span>,</span> <span>radial_end_point</span><span>,</span> <span>linewidth</span><span>=</span><span>2</span><span>,</span> <span>mode</span><span>=</span><span></span><span>"</span><span>constant</span><span>"</span>
<span>)</span>
</code></pre></div></div>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>fig</span><span>,</span> <span>ax</span> <span>=</span> <span>plt</span><span>.</span><span>subplots</span><span>(</span><span>)</span>
<span>ax</span><span>.</span><span>plot</span><span>(</span><span>profile_line</span><span>)</span>
<span>ax</span><span>.</span><span>set_xlabel</span><span>(</span><span></span><span>"</span><span>Distance from banana circle center</span><span>"</span><span>)</span>
<span>ax</span><span>.</span><span>set_title</span><span>(</span><span></span><span>"</span><span>Mask Intensity</span><span>"</span><span>)</span>
<span>None</span>
</code></pre></div></div>



<figure>
    
        <img src="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/index_14_0.png"> </figure>

</div>
<p>This profile line is what allows us to orient ourselves radially. You can clearly see where the banana starts and ends, in the radial direction. As always, just seeing it is not good enough. We need code to define the start and end of the banana in this direction. The <code>mask</code> tends to be monotonically increasing and then monotonically decreasing along the start and end, respectively. Using this information, there are a couple ways …</p></article></section></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/">https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/</a></em></p>]]>
            </description>
            <link>https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272814</guid>
            <pubDate>Tue, 25 Aug 2020 16:10:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[But does it help you ship?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24272630">thread link</a>) | @misternugget
<br/>
August 25, 2020 | https://thorstenball.com/blog/2020/08/25/but-does-it-help-you-ship/ | <a href="https://web.archive.org/web/*/https://thorstenball.com/blog/2020/08/25/but-does-it-help-you-ship/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p>25 Aug 2020</p>

  <p>Whenever I’m not sure whether I’m spending my time on the right thing I ask
myself: <em>does it help me ship?</em></p>

<p>If what I consider working on is not the thing we want to ship itself, but lies
in the vast grey area of software projects where I could write code all day long
without the user ever noticing, this question helps me decide whether to drop it
or invest some time in it.</p>

<p>Let me illustrate.</p>

<p>One imaginary Friday afternoon I notice that we have a few <code>// TODO</code> comments in our
codebase. Hmm, I could create a bot that looks for those comments whenever a new
commit is pushed. It could use <code>git blame</code> to see who the author is and create a
ticket assigned to them, saying that they should fix their TODO in line X in
file Y, please. And, cherry on top, when a pull request that touches a TODO is
opened, the bot would mark the corresponding ticket as work-in-progress. And
when the pull request is merged, the bot closes the ticket. And when a pull
request merely changes the <code>TODO:</code> into a <code>TODO(poorsoul):</code> then it assigns the
ticket to <code>poorsoul</code>.</p>

<p>Sounds pretty good, right? Turn those TODOs into tickets and never lose a TODO
again.</p>

<p>The problem is: it’s not free. It looks like it is, because the code is quickly
written and it runs as a GitHub action we don’t have to pay for, but it’s not.</p>

<p>It’s <em>another</em> process, <em>another</em> tool, <em>another</em> automated piece in our
machinery. Another thing that needs to be fixed when it ultimately breaks
down, another bit of automation that works 99% of the time, but starts making
funny noises when you slip into the 1% and, say, moved a TODO down five lines by
accident and don’t want the bot to close and re-open tickets, kicking off
another wave of notifications.</p>

<p><em>That’s</em> the actual cost of adding that bot.</p>

<p>The question is do we want to pay it? Does it help me ship? Does it help me ship
<em>more</em>? Or does it help me ship <em>faster</em>, or with less friction, more safely?</p>

<p>If our imaginary codebase has more TODOs than test cases, for example, and these
TODOs are holding us back from shipping because we can’t make a change without
having to ask colleagues what this TODO we just discovered means, then it might
be a good idea to add the bot. Even if we don’t intend to fix all of the TODOs,
but only to finally get an overview and a peek at hidden part of the iceberg. It
helps us ship.</p>

<p>If the code contains more than one <code>TODO: make sure this works</code> and we can’t
ship because changing the code is playing a game of Russian roulette, where
every change could kick off an avalanche of bugs, then yes, this bot would
probably help us ship.</p>

<p>But what if we’re <em>not</em> held back by TODOs? What if we have a total of 18 of them,
and 12 of those have been in the codebase longer than you and I have been at the
company, and, generally speaking, our codebase is in an okay state — is the cost
worth it?</p>

<p>If what’s holding you back from shipping is, say, getting more customer input,
or a brittle release process, or flaky monitoring, or missing tests, then all
the bot does is to add noise. It doesn’t help you ship.</p>

</div></div>]]>
            </description>
            <link>https://thorstenball.com/blog/2020/08/25/but-does-it-help-you-ship/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272630</guid>
            <pubDate>Tue, 25 Aug 2020 15:56:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unpopular Opinion – Data Scientists Should Be More End-to-End]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24272617">thread link</a>) | @importantbrian
<br/>
August 25, 2020 | https://eugeneyan.com/writing/end-to-end-data-science/?mkt_tok=eyJpIjoiWmpBNVlURTRNRE00WXpjMiIsInQiOiJockxCUXB1YmRPOGxvNm40UDhwdEk2dlI0UHhRY0NzTmdDV3ZnbFl4d3p6WGNZRU56Qmh1S2VNXC9zbmR2RUJrTjk4bW1DeVNUVHdBQW50aHdEOXhLd3VPVDRnbmRWOWdiSFFQVTVmaFZwZ3o3N0tLMk9Xdk9sYXBPc0I3Y1FhREoifQ%3D%3D | <a href="https://web.archive.org/web/*/https://eugeneyan.com/writing/end-to-end-data-science/?mkt_tok=eyJpIjoiWmpBNVlURTRNRE00WXpjMiIsInQiOiJockxCUXB1YmRPOGxvNm40UDhwdEk2dlI0UHhRY0NzTmdDV3ZnbFl4d3p6WGNZRU56Qmh1S2VNXC9zbmR2RUJrTjk4bW1DeVNUVHdBQW50aHdEOXhLd3VPVDRnbmRWOWdiSFFQVTVmaFZwZ3o3N0tLMk9Xdk9sYXBPc0I3Y1FhREoifQ%3D%3D">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Recently, I came across a <a href="https://www.reddit.com/r/datascience/comments/i48b5q/for_those_that_work_for_a_team_that_has_both_data/" target="_blank">Reddit thread</a> on the different roles in data science and machine learning: data scientist, decision scientist, product data scientist, data engineer, machine learning engineer, machine learning tooling engineer, AI architect, etc.</p>

<p>I found this <em>worrying</em>. It’s difficult to be effective when the data science process (problem framing, data engineering, ML, deployment/maintenance) is split across different people. It leads to coordination overhead, diffusion of responsibility, and lack of a big picture view.</p>

<p>IMHO, <strong>I believe data scientists can be more effective by being end-to-end</strong>. Here, I’ll discuss the <a href="#from-start-identify-the-problem-to-finish-solve-it">benefits</a> and <a href="#but-we-need-specialist-experts-too">counter-arguments</a>, <a href="#the-best-way-to-pick-it-up-is-via-learning-by-doing">how to</a> become end-to-end, and the experiences of <a href="#end-to-end-in-stitch-fix-and-netflix">Stitch Fix and Netflix</a>.</p>

<h2 id="from-start-identify-the-problem-to-finish-solve-it">From start (identify the problem) to finish (solve it)</h2>

<p>You may have come across similar <em>labels</em> and definitions, such as:</p>
<ul>
  <li><a href="https://towardsdatascience.com/why-you-shouldnt-be-a-data-science-generalist-f69ea37cdd2c" target="_blank">Generalist</a>: Focused on roles (<a href="https://en.wikipedia.org/wiki/Product_manager" target="_blank">PM</a>, <a href="https://en.wikipedia.org/wiki/Business_analyst" target="_blank">BA</a>, <a href="https://www.oreilly.com/content/data-engineering-a-quick-and-simple-definition/" target="_blank">DE</a>, <a href="https://en.wikipedia.org/wiki/Category:Data_scientists" target="_blank">DS</a>, <a href="https://www.quora.com/What-exactly-does-a-machine-learning-engineer-do" target="_blank">MLE</a>); some negative connotation</li>
  <li><a href="https://skillcrush.com/blog/front-end-back-end-full-stack/" target="_blank">Full-stack</a>: Focused on tech (Spark, Torch, Docker); popularized by full-stack devs</li>
  <li><a href="https://www.infoworld.com/article/3429185/stop-searching-for-that-data-science-unicorn.html" target="_blank">Unicorn</a>: Focused on mythology; believed not to exist</li>
</ul>

<p>I find these definitions to be more prescriptive than I prefer. Instead, I have a simple (and pragmatic) definition: An end-to-end data scientist can <strong>identify and solve problems with data, to deliver value</strong>. To achieve the goal, they’ll wear as many (or as little) hats as required. They’ll also learn and apply whatever tech, methodology, and process that works. Throughout the process, they ask questions such as:</p>
<ul>
  <li>What is the problem? Why is it important?</li>
  <li>Can we solve it? How should we solve it?</li>
  <li>What is the estimated value? What was the actual value?</li>
</ul>

<details><summary>Data Science Processes</summary>
<div>
<p>Another way of defining end-to-end data science is via processes. These processes are usually complex and I’ve left them out of the main discussion. Nonetheless, here are a few in case you’re curious:</p>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Cross-industry_standard_process_for_data_mining" target="_blank">CRISP-DM</a>: Cross-Industry Standard Process for Data Mining (1997).</li>
  <li><a href="https://en.wikipedia.org/wiki/Data_mining#Process" target="_blank">KDD</a>: Knowledge Discovery in Databases.</li>
  <li><a href="https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/overview" target="_blank">TDSP</a>: Team Data Science Process, proposed by Microsoft in 2018.</li>
  <li><a href="https://github.com/dslp/dslp" target="_blank">DSLP</a>: Data Science Lifecycle Process.</li>
</ul>

<p>Don’t worry if these processes seem heavy and overwhelming. You don’t have to adopt them wholesale—start bit by bit, keep what works and adapt the rest.</p>
</div>

</details>

<h2 id="more-context-faster-iteration-greater-satisfaction">More context, faster iteration, greater satisfaction</h2>

<p>For most data science roles, being more end-to-end improves your ability to make meaningful impact. (Nonetheless, there are <a href="https://nvidia.wd5.myworkdayjobs.com/en-US/NVIDIAExternalCareerSite/job/US-CA-Santa-Clara/Senior-Deep-Learning-Data-Scientist--RAPIDS---AI_JR1929838" target="_blank">roles</a> that focus on machine learning.)</p>

<p><strong>Working end-to-end provides increased context.</strong> While specialized roles can increase efficiency, it reduces context (for the data scientist) and leads to suboptimal solutions.</p>

<blockquote>
  <p>The trick to forgetting the big picture is to look at everything close-up. – Chuck Palahniuk</p>
</blockquote>

<p>It’s hard to design a holistic solution without full context of the upstream problem. Let’s say conversion has decreased and a PM raises a request to improve our search algorithm. However, what’s causing the decrease in the first place? There could be various causes:</p>
<ul>
  <li>Product: Is fraudulent/poor quality product reducing customer trust?</li>
  <li>Data pipelines: Has data quality been compromised or are there delays/outages?</li>
  <li>Model refresh: Is the model not refreshing regularly/correctly?</li>
</ul>

<p>More often than not, the problem—and solution—lies <em>outside</em> of machine learning. A solution to <em>improve the algorithm</em> would miss the root cause.</p>

<p>Similarly, it’s risky to develop a solution without awareness of downstream engineering and product constraints. There’s no point:</p>
<ul>
  <li>Building a near-real time recommender if infra and engineer cannot support it</li>
  <li>Building an infinite scroll recommender if it doesn’t fit in our product and app</li>
</ul>

<p>By working end-to-end, data scientists will have the full context to identify the right problems and develop usable solutions. It can also lead to innovative ideas that specialists, with their narrow context, might miss. Overall, it increases the ability to deliver value.</p>

<p><strong>Communication and coordination overhead is reduced.</strong> With multiple roles comes additional overhead. Let’s look at an example of a data engineer (DE) cleaning the data and creating features, a data scientist (DS) analysing the data and training the model, and a machine learning engineer (MLE) deploying and maintaining it.</p>

<blockquote>
  <p>What one programmer can do in one month, two programmers can do in two months. – Frederick P. Brooks</p>
</blockquote>

<p>The DE and DS need to <em>communicate</em> on what data is (and is not) available, how it should be cleaned (e.g., outliers, normalisation), and which features should be created. Similarly, the DS and MLE have to discuss how to deploy, monitor, and maintain the model, as well as how often it should be refreshed. When issues occur, we’ll need three people in the room (likely with a PM) to triage the root cause and next steps to fix it.</p>

<p>It also leads to additional coordination, where schedules need to be aligned as work is executed and passed along in a sequential approach. If the DS wants to experiment with additional data and features, we’ll need to wait for the DE to ingest the data and create the features. If a new model is ready for A/B testing, we’ll need to wait for the MLE to (convert it to production code) and deploy it.</p>

<p>While the actual development work may take days, the communication back-and-forth and coordination can take weeks, if not longer. With end-to-end data scientists, we can minimize this overhead as well as prevent technical details from being lost in translation.</p>

<p>(But, can an end-to-end DS really do all that? I think so. While the DS might not be as proficient in some tasks as a DE or MLE, they will be able to perform most tasks effectively. If they need help with scaling or hardening, they can always get help from specialist DEs and MLEs.)</p>

<details><summary>The Cost of Communication and Coordination</summary>
<div>
<p>Richard Hackman, a Harvard psychologist, showed that the number of relationships in a team is <code><span>N</span><span>(</span><span>N</span><span>-</span><span>1</span><span>)</span> <span>/</span> <span>2</span></code>, where <code><span>N</span></code> is the number of people. This leads to exponential growth in links, where:</p>

<ul>
  <li>A start-up team of 7 has 21 links to maintain</li>
  <li>A group of 21 (i.e., three start-up teams) has 210 links</li>
  <li>A group of 63 has almost 2,000 links.</li>
</ul>

<p>In our simple example, we only had three roles (i.e., six links). But as a PM, BA, and additional members are included, this leads to greater than linear growth in communication and coordination costs. Thus, while each additional member increases total team productivity, the increased overhead means productivity grows at a decreasing rate. (Amazon’s <a href="https://buffer.com/resources/small-teams-why-startups-often-win-against-google-and-facebook-the-science-behind-why-smaller-teams-get-more-done/" target="_blank">two-pizza teams</a> are a possible solution to this.)</p>
</div>
</details>

<p><strong>Iteration and learning rate is increased.</strong> With greater context and lesser overhead, we can now iterate, fail (read: learn), and deliver value faster.</p>

<p>This is especially important for developing data and algorithmic products. Unlike software engineering (a far more mature craft), we can’t do all the learning and design before we start building—our blueprints, architectures, and design patterns are not as developed. Thus, rapid iteration is essential for the design-build-learn cycle.</p>

<p><strong>There’s greater ownership and accountability.</strong> Having the data science process split across multiple people can lead to diffusion of responsibility, and worse, social loafing.</p>

<p>A common anti-pattern observed is “<a href="https://wiki.c2.com/?ThrownOverTheWall" target="_blank">throw over the wall</a>”. For example, the DE creates features and throws a database table to the DS, the DS trains a model and throws <code>R</code> code over to the MLE, and the MLE translates it to <code>Java</code> to production.</p>

<p>If things get lost-in-translation or if results are unexpected, who is responsible? With a strong culture of ownership, everyone steps up to contribute in their respective roles. But without it, work can degenerate into ass-covering and finger-pointing while the issue persists and customers and the business suffers.</p>

<p>Having the end-to-end data scientist take ownership and responsibility for the entire process can mitigate this. They should be empowered to take action from start to finish, from the customer problem and input (i.e., raw data) to the output (i.e., deployed model) and measurable outcomes.</p>

<details><summary>Diffusion of Responsibilty &amp; Social Loafing</summary>
<div>

<p><a href="https://en.wikipedia.org/wiki/Diffusion_of_responsibility" target="_blank">Diffusion of responsibility</a>: We are less likely to take responsibility and act when there are others present. Individuals feel less responsibility and urgency to help if we know that there are others also watching the situation. </p>

<p>One form of this is the <a href="https://en.wikipedia.org/wiki/Diffusion_of_responsibility#Bystander_effect" target="_blank">Bystander effect</a>, where <a href="https://en.wikipedia.org/wiki/Murder_of_Kitty_Genovese" target="_blank">Kitty Genovese</a> was stabbed outside the apartment building across the street from where she lived. While there were 38 witnesses who saw or heard the attack, none called the police or helped her.</p>

<p><a href="https://en.wikipedia.org/wiki/Social_loafing" target="_blank">Social loafing</a>: We exert less effort when we work in a group vs. working alone. In the 1890s, Ringelmann made people pull on ropes both separately and in groups. He measured how hard they pulled and found that members of a group tended to exert less effort in pulling a rope than did individuals alone.</p>

</div>
</details>

<p><strong>For (some) data scientists, it can lead to increased motivation and job satisfaction</strong>, which is <a href="https://www.clearpointstrategy.com/how-employees-are-motivated-autonomy-mastery-purpose/" target="_blank">closely tied</a> to autonomy, mastery, and purpose.</p>
<ul>
  <li><strong>Autonomy:</strong> By being able to solve problems independently. Instead of waiting and depending on others, end-to-end data scientists are able to identify and define the problem, build their own data pipelines, and deploy and validate a solution.</li>
  <li><strong>Mastery:</strong> In the problem, solution, outcome from end-to-end. They can also pick up the domain and tech as required.</li>
  <li><strong>Purpose</strong>: By being deeply involved in the entire process, they have a more direct connection with the work and outcomes, leading to an increased sense of <em>purpose</em>.</li>
</ul>

<h2 id="but-we-need-specialist-experts-too">But, we need specialist experts too</h2>

<p>Being end-to-end is not for everyone (and every team) though, for reasons such as:</p>

<p><strong>Wanting to specialize</strong> in machine learning, or perhaps a specific niche in machine learning such as neural text generation (read: <a href="https://mc.ai/the-subtle-art-of-priming-gpt-3/" target="_blank">GPT-3 primer</a>). While being end-to-end is valuable, we also need such world-class experts in research and industry who push the envelope. Much of what we have in ML came from academia and pure research efforts.</p>

<blockquote>
  <p>No one achieves greatness by …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://eugeneyan.com/writing/end-to-end-data-science/?mkt_tok=eyJpIjoiWmpBNVlURTRNRE00WXpjMiIsInQiOiJockxCUXB1YmRPOGxvNm40UDhwdEk2dlI0UHhRY0NzTmdDV3ZnbFl4d3p6WGNZRU56Qmh1S2VNXC9zbmR2RUJrTjk4bW1DeVNUVHdBQW50aHdEOXhLd3VPVDRnbmRWOWdiSFFQVTVmaFZwZ3o3N0tLMk9Xdk9sYXBPc0I3Y1FhREoifQ%3D%3D">https://eugeneyan.com/writing/end-to-end-data-science/?mkt_tok=eyJpIjoiWmpBNVlURTRNRE00WXpjMiIsInQiOiJockxCUXB1YmRPOGxvNm40UDhwdEk2dlI0UHhRY0NzTmdDV3ZnbFl4d3p6WGNZRU56Qmh1S2VNXC9zbmR2RUJrTjk4bW1DeVNUVHdBQW50aHdEOXhLd3VPVDRnbmRWOWdiSFFQVTVmaFZwZ3o3N0tLMk9Xdk9sYXBPc0I3Y1FhREoifQ%3D%3D</a></em></p>]]>
            </description>
            <link>https://eugeneyan.com/writing/end-to-end-data-science/?mkt_tok=eyJpIjoiWmpBNVlURTRNRE00WXpjMiIsInQiOiJockxCUXB1YmRPOGxvNm40UDhwdEk2dlI0UHhRY0NzTmdDV3ZnbFl4d3p6WGNZRU56Qmh1S2VNXC9zbmR2RUJrTjk4bW1DeVNUVHdBQW50aHdEOXhLd3VPVDRnbmRWOWdiSFFQVTVmaFZwZ3o3N0tLMk9Xdk9sYXBPc0I3Y1FhREoifQ%3D%3D</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272617</guid>
            <pubDate>Tue, 25 Aug 2020 15:54:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Train Your Remote Employee]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24272611">thread link</a>) | @dsalzman
<br/>
August 25, 2020 | https://www.dannysalzman.com/2020/08/25/how-to-train-remote-employee | <a href="https://web.archive.org/web/*/https://www.dannysalzman.com/2020/08/25/how-to-train-remote-employee">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="a8786e28-940e-481a-88b6-5224ae91fc6e" class="page"><div><figure id="9908aef5-23a6-4991-a859-9bcc2b75d3af"><p><iframe src="https://player.vimeo.com/video/422640276" width="640" height="360" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe></p></figure><p id="1cd3001f-a94e-407c-8984-290fc480de35">Using&nbsp;<a href="https://www.thesprucepets.com/ways-to-reward-a-dog-1118276">p</a>ositive reinforcement to train your employee means you reward the behaviors you like and ignore the behaviors you do not like. You can use praise, life rewards (such as&nbsp;awards, a bonus, or&nbsp;recognition to reward your employees.</p><p id="263d2fcb-e82e-4f9e-86b7-4a5cb576fb54">The Kudoos is a another effective method to for remote managers to positively reinforce good work for their employees. It’s automatic, safe, and easy!</p><p id="a0bd861b-11b8-4d8e-88c7-290094860d2c">The Kudoos is an internet connected smart device that dispenses your employees favorite treat when they complete actions or goals specified by their manager. This could be completing a Jira task or crushing a presentation. Kudoos has integrations into Jira, Slack, and Zoom!</p><p id="866ee7a3-2c49-41e3-bd6a-b239c3d1ecf6">Use the Kudoos slash command to quickly reward a teammate for a great idea. It’s immediate feedback! They will love it.</p><h2 id="221c5e03-cf83-47c9-922d-746b02e4bf05">Slack Integration 😃</h2><p id="8be6ca5f-721c-4874-bc8b-9934711bc42c">Kudoos also has a custom slack integration to quickly give your team member some Kudoos.</p><h3 id="c7ce9347-9ede-4105-8395-63202283de27">Did they just squash a massive bug?</h3><p id="70d722ee-e23c-4b70-9b78-833e946dc493">Give some Kudoos.</p><h3 id="1900ba19-4c18-4e3a-8111-d74e3976f5e3">Did your employee stay up late crushing some new code?</h3><p id="8edfac47-88d0-4cd5-a836-3f54d2fe63bf">Give some Kudoos.</p><h3 id="f04de163-b370-4780-8abe-35e6adc4b821">Did your badass team grind out another killer sprint to make your deadline?</h3><p id="0580b504-aac6-467b-a3b0-f0689d7f0634">Give some Kudoos.</p><pre id="22d94418-54d8-44cd-aa1f-207964f3981a"><code>/feed [employee #] [amount] </code></pre><p id="b6332038-f25c-4710-afc3-f156f163cd37">Kudoos integrates seamlessly with JIRA to dispense treats when stories or tasks are completed. You can even make the Kudoos dispense based on the story points!</p><h2 id="a87296c6-1f5e-4073-9fd0-179222161b82">Apple Shortcuts Widget</h2><p id="81c3cd31-cfde-45d4-b5c5-27cbba294303">Create a custom iOS home screen button for every employee for instant feedback. You can even use Siri to invoke as well!</p><figure id="defb0ba5-cec1-4fc3-8d1c-66a95cc7f184"><p><iframe src="https://player.vimeo.com/video/422643406" width="640" height="1138" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe></p></figure><h2 id="7d18639b-8f6c-48e9-9aa7-16c2a15f7794">What People are Saying</h2><blockquote id="9ce69a02-1a78-4faa-ae67-600aa07607d5">I feel more connected with my team and manager</blockquote><h2 id="761768b5-8368-4d52-852c-96d96efd7213">Where do I get a Kudoos?</h2><p id="9990ac6e-1032-4ab0-b3ab-b579075bbc49">There is currently a long waitlist. Please send your order request to givemekudoos (at) fastmail.com</p></div></article></div>]]>
            </description>
            <link>https://www.dannysalzman.com/2020/08/25/how-to-train-remote-employee</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272611</guid>
            <pubDate>Tue, 25 Aug 2020 15:54:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I entered the matrix through the red and blue fakesciencenews and became purple]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24272567">thread link</a>) | @gloriosoc
<br/>
August 25, 2020 | https://realscience.community/2020/08/25/how-i-entered-the-matrix-through-the-red-and-blue-fakesciencenews-and-came-out-purple/ | <a href="https://web.archive.org/web/*/https://realscience.community/2020/08/25/how-i-entered-the-matrix-through-the-red-and-blue-fakesciencenews-and-came-out-purple/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<div id="speakaboutWrapper"><p id="block-afdaa339-e8b3-4447-a026-bf90c8730369">I have been a life long Democrat with almost 100% alignment with liberal party views. I may even fall a little bit left of left. Nationalized healthcare and free college tuition are both things I believe in. I was raised on NPR in the car with my mom and we had a print subscription to Newsweek magazine that I looked forward to reading at the kitchen table. It’s safe to say that my lifetime exposure to conservative media has been little to none. I had a medschool classmate that would sometimes drive me to school and listen to conservative talk shows on the way, just so he could get fired up and yell, but that hardly provided me with much insight. Mostly, I just thought, why are you doing this to yourself?</p>



<p id="block-e7955bc2-d365-41c9-ba94-0ec9636a2da6">But, there has always been a little suspicious voice in my head that has said- how can you totally believe one side of things? There must be some validity to the other side. There is something not quite adding up about this.</p>



<p id="block-bdbd8e30-2533-495a-af2b-eb5a385cf734">Then when Donald Trump got elected, I stopped listening to the news all together. This was a strange interlude for me given my lifelong passion for policy and advocacy. I was President of my Graduate School’s student government and Community Building Chair of the MIT Postdoc Association. In 2015, I co-founded a <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">science</a> advocacy non-profit organization, Academics for the Future of <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">Science</a> (AFS), which was a partner of the national and Boston March for <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">Science</a> and hosted a 200 person <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">science</a> advocacy meeting and workshop at MIT (some pics below).</p>



<figure id="block-f76359d7-20ab-4228-963e-7bd4eb407353"><img src="https://realscience.community/wp-content/uploads/2020/08/grab-em-by-the-data-1024x566.png" alt="This image has an empty alt attribute; its file name is grab-em-by-the-data-1024x566.png"><figcaption>March for <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">Science</a> D.C.</figcaption></figure><figure id="block-d1e3f730-bd13-4bc4-8a61-4498e207860c"><img src="https://realscience.community/wp-content/uploads/2020/08/Planning-meeting-March-for-Science-1024x570.png" alt="This image has an empty alt attribute; its file name is Planning-meeting-March-for-Science-1024x570.png"><figcaption>National March for <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">Science</a> organizer’s planning meeting with all of the <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">science</a> societies.</figcaption></figure><figure id="block-1302d7dd-7bd7-4227-af52-a7a584b149cf"><img src="https://realscience.community/wp-content/uploads/2020/08/Cambridge-Science-Festival-1024x566.png" alt="This image has an empty alt attribute; its file name is Cambridge-Science-Festival-1024x566.png"><figcaption>AFS at the Cambridge <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">Science</a> Festival Robot Zoo.</figcaption></figure><figure id="block-73f4d549-100a-4bbb-aff4-12ca262580d1"><img src="https://realscience.community/wp-content/uploads/2020/08/advocating-for-science-symp-holt-walk-1024x540.png" alt="This image has an empty alt attribute; its file name is advocating-for-science-symp-holt-walk-1024x540.png"><figcaption>Walking with our keynote Speaker, former Congressmen, and then CEO of the American Association for the Advancement of <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">Science</a> (AAAS), Rush Holt, during AFS’s “Advocating for <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">Science</a> Workshop and Symposium” in 2016.</figcaption></figure><figure id="block-11a4b735-aef4-420a-9351-fa0c6cf138b3"><img src="https://realscience.community/wp-content/uploads/2020/08/setting-up-for-symp-talk-1024x541.png" alt="This image has an empty alt attribute; its file name is setting-up-for-symp-talk-1024x541.png"><figcaption>Setting up to speak at AFS’s “Advocating for <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">Science</a> Workshop and Symposium” at MIT.</figcaption></figure><figure id="block-c2cdfc07-df18-46fd-a3f4-0cc9bbe4a046"><img src="https://realscience.community/wp-content/uploads/2020/08/workshop-participants-1024x384.png" alt="This image has an empty alt attribute; its file name is workshop-participants-1024x384.png"><figcaption>AFS and workshop participants.</figcaption></figure><figure id="block-fdf25323-618d-4890-b77b-f90ca86d5dee"><img src="https://realscience.community/wp-content/uploads/2020/08/classroom-1024x540.png" alt="This image has an empty alt attribute; its file name is classroom-1024x540.png"><figcaption>AFS’s Advocating for <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">Science</a> workshops at MIT.</figcaption></figure><p id="block-949aa724-7e35-4fca-89a6-915a4459cf2f">The election of Donald Trump shocked and traumatized me for so many reasons, pussy grabbing and a disregard for <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">science</a> were not least among them. Frankly, I just shut down when it came to politics. The news was too negative and depressing. I got off social media as well, burying my head in work, doing the mental equivalent of “la-la-la” with fingers in my ears for three years.</p>



<p id="block-6b03038c-9c83-457c-9309-918c951f7cbc">That was until the <a href="https://realscience.community/wiki/covid-19-pandemic/" target="_blank" title="From Wikipedia, the free encyclopedia. COVID‑19 pandemicConfirmed cases per 100,000 population as of 8 August 2020&nbsp;&nbsp;>3,000&nbsp;&nbsp;1,000–3,000&nbsp;&nbsp;300–1,000&nbsp;&nbsp;100–300&nbsp;&nbsp;30–100&nbsp;&nbsp;0–30&nbsp;&nbsp;None or no dataCases per countryDeaths per capitaClockwise, starting from top:A nurse caring for a COVID‑19 patient in an&nbsp;intensive care&nbsp;unit aboard a U.S. hospital shipDisinfection vehicles in TaiwanDonated medical supplies being received in the PhilippinesBurial in IranThe&nbsp;Italian government's outbreak task…">COVID-19 pandemic</a> hit and a strange thing happened. I re-engaged with politics with a whole new pair of eyes. It was pretty hard for me to ignore the pandemic, especially because I was so stringently locked down in my Cambridge apartment, working remotely, having very few people that I could see. I was desperate to make sense of things, desperate for some control over my life, desperate to make sure the people that I love are ok, and desperate for a hug. The pandemic also just happened to be aligned with many things that I have expertise in- medicine, data <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">science</a>, and virology. I am both a medical doctor (not practicing) and I have a PhD. I currently am a Computational Biologist at MIT. My undergraduate and postbac years were spent in virology labs. So I felt compelled to be back on Facebook, talking to friends about the Pandemic, trying to help people navigate it. But at the same time, I was still attempting to mostly ignore the lay press. I was reading almost exclusively <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">science</a> journals and analyzing data myself. And the odd thing is, I was coming to very different conclusions than many of my friends, most of whom are liberal and many of whom have PhDs or MDs or both. For the first time in my life, people were arguing with me and in some cases, <em>mad at me</em>, for what I was saying on Facebook, and it took me by surprise.</p>



<p id="block-87ecc4f7-17e6-4afe-8253-97bf0b9081c3">Here is an example of this, on March 20th, I posted this “New York is growing exponentially faster than Italy- 8x rise in 5 days- 16k cases- this is holy fucking shit level. Please shelter in place NY even if your government has been catastrophically slow at asking you to do so.” with some analysis that I had done from online databases- (screen shot below). Surprisingly, people on my Facebook page were pushing back with all sorts of untrue things- NY just has done more testing, UV light and hotter months will kill it, it’s not because of not shutting down- NY is just more crowded.</p>



<p id="block-02e564b2-41c3-4cdc-b13f-31658348dc2c">I was baffled. Where were they getting this from? None of this was true from my analysis.</p>



<figure id="block-dce67ef5-7bb3-48c1-a2f3-eb2574e48ead"><img src="https://realscience.community/wp-content/uploads/2020/08/March-20-black-boxes-1-576x1024.png" alt="This image has an empty alt attribute; its file name is March-20-black-boxes-1-576x1024.png"></figure><p id="block-74897d32-3107-48f6-9cdf-f85a125b8cbf">Turns out the answer is that they were getting their info from (and believing) NY Governor, Andrew Cuomo, through the mainstream liberal media. Below is a YouTube video of Cuomo’s press conference with Trump on March 18, 2020. At minute 20:31, he says the following: “As I’ve said every day, the more you test, the more positives you will find.” and “New York is the state that has the most number of cases. Again, you would have to correlate that to how many tests the other states are doing, because the more tests they’re doing, the more cases they will find.” and “Again, perspective, perspective, because we’re fighting the virus, we’re fighting fear. The fear is winning. And the fear is disconnected from the facts. Fear is an emotion. Emotion can often be disconnected from facts, and that’s what happening here.”</p>



<figure id="block-db6f72ec-3731-4558-822b-ea9dbb94c1a2"><img src="https://realscience.community/wp-content/uploads/2020/08/image-1-1024x591.png" alt="This image has an empty alt attribute; its file name is image-1-1024x591.png"></figure><p id="block-534c5863-748e-4e26-8f20-d0e60c0aa999">And this was quoted and propagated by the news-<a href="https://www.cnn.com/2020/03/21/politics/new-york-andrew-cuomo-coronavirus-spread/index.html">like CNN’s March 21st article</a> and <a href="https://www.nbcnews.com/news/us-news/coronavirus-cases-new-york-state-now-top-10-000-n1165626">NBC’s March 21st article</a> – “The more tests you take, the more positives you find,” he said, adding that New York is now conducting more tests per capita than China or South Korea.”</p>



<p id="block-e894bbf7-ef23-45c8-8cff-03fce469fe28"><strong>Why is this false information? or blue #fakesciencenews</strong></p>



<p id="block-e894bbf7-ef23-45c8-8cff-03fce469fe28">Because only symptomatic people were being tested. Health insurance wasn’t paying for people without symptoms to be tested (and still isn’t in most places). They were <strong>testing more BECAUSE more people were sick, NOT finding more cases because they were testing more.</strong> Also the percent positives and hospitalization rates were going up, proving that testing was not the reason for the increased number of cases.</p>



<p id="block-cc3eb2a1-ec9c-4417-a779-cf2c4bcbd7e0">I have to say, I have heard President Trump say these exact same things. The two of them, Trump and Cuomo, have pretty similar rhetoric.</p>



<p id="block-59df9799-baae-4608-ab83-e57e076ee46a">Cuomo also at that time, said that if you told him to shelter-in-place, he personally wouldn’t listen, he’d just go have fun instead. This is documented in this <a href="https://www.nbcnews.com/news/us-news/ny-gov-cuomo-says-no-new-york-city-s-shelter-n1162911">March 18th NBC article</a>:</p>







<p id="block-143b308e-8bd8-48c8-b918-dc73798bfe37">March 18, 2020, 12:58 PM EDT&nbsp;/&nbsp;Updated&nbsp;March 18, 2020, 3:46 PM EDT By&nbsp;Tom Winter and Corky Siemaszko</p>



<p id="block-bcab33e2-05e1-4ff0-a6bf-2ca6632c6612">New York Gov. Andrew Cuomo had some choice words Wednesday for New York City mayor Bill de Blasio’s proposal to effectively shut the city down to stop the spread of the coronavirus: Not a chance…</p>



<p id="block-6a86db55-108c-4762-ba17-c55f943cc351">Cuomo echoed that point later at a press conference saying, “it just can’t be New York City.”</p>



<p id="block-8e0ff99d-5fe9-4d0e-828b-cc1673a388d5">“I’m from Queens and if you tell me to shelter-in-place I’ll just go stay with my sister in Westchester (County) and have a good time,” he said.”</p>



<p id="block-180b71a6-053f-4db0-bbfb-c4d81fa4c838">So in summary, I got yelled at by my educated liberal friends for singling out NYC to shut down because the liberal media was quoting the dangerous and reckless rhetoric and decisions by Andrew Cuomo.</p>



<p id="block-ef1b178b-8509-4080-beb3-01a78ed937c9"><strong>Obviously, we know what happened in NYC after that– 30,000 people died because Cuomo didn’t shut down in time.</strong></p>



<p id="block-84af9b9a-cc0f-4136-94df-b79be61bfc5b">That was one example of many of the blue #fakesciencenews stories- aimed at saving Cuomo’s butt (or whatever the political agenda was) that was believed by liberals because it was from a liberal news source.</p>



<p id="block-83aabbcc-fff3-44bd-9c96-4011de750e97"><strong>What about the red #fakesciencenews?</strong></p>



<p id="block-03b83506-17cf-413d-bfae-447b54ab4e13">Beginning to understand the perspective of the right and how it was driven by fake <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">science</a> news was a real eye opener for me. The best example of this was a little later on in the pandemic during the first weeks of re-opening. I <strong>was VERY worried about the onslaught of rising cases that was about to happen and high-risk people not taking it seriously</strong>, including some of my own friends and family. There was a false narrative circulating that somehow the virus was just going to magically disappear, even though places still had lots of cases.</p>



<p id="block-deb3c9e4-4920-417b-b259-4651006f4031">This was being pushed by Trump, Pence, and the conservative media. They were downplaying the virus’s seriousness.</p>



<figure id="block-3d54e755-8904-47ff-b36c-df43995695af"><img src="https://realscience.community/wp-content/uploads/2020/08/covid-hoax.jpeg" alt="This image has an empty alt attribute; its file name is covid-hoax.jpeg"></figure><p id="block-f9b9c31a-4ff5-4824-b25a-12b49f9c5d4e">Trump and Pence were also vocally against masks at that time, including by example (see pic below). This was incredibly harmful and a lot of people died unnecessarily because of it.</p>



<figure id="block-48c238e1-81a3-4860-a333-3ff888c9354b"><img src="https://realscience.community/wp-content/uploads/2020/08/pence-no-mask-1024x512.jpeg" alt="This image has an empty alt attribute; its file name is pence-no-mask-1024x512.jpeg"></figure><p id="block-2b65c71e-ff78-49b0-8549-b210c168ef38">On June 12th, I posted this to AFS’s Facebook page in order to try and get public health messaging out to save lives:</p>



<figure id="block-fd0b05eb-e6cb-4c6f-9bd9-472229659f58"><img src="https://realscience.community/wp-content/uploads/2020/08/image-9-1024x986.png" alt="This image has an empty alt attribute; its file name is image-9-1024x986.png"></figure><p id="block-56720ed1-f5bf-4e0b-b2c0-e1a31abd3337">And the response from the right was illuminating. Below are some screen shots:</p>



<figure id="block-e4f73b51-fcdf-4162-b04c-284a785f6d22"><img src="https://realscience.community/wp-content/uploads/2020/08/image-4.png" alt="This image has an empty alt attribute; its file name is image-4.png"></figure><p id="block-194e16f8-52e1-46bc-a574-c13e1a46b8c0">What did I make of this? People were mad at Cuomo and rightfully so. I am outraged at his actions personally. People think the virus is a hoax. People are worried about the economy. People are pointing out the hypocrisy of the liberal media saying that protests don’t spread COVID but reopening does. Here are some more responses:</p>



<figure id="block-d6bf0481-f7e7-4c33-8563-f646a0127b0c"><img src="https://realscience.community/wp-content/uploads/2020/08/image-5.png" alt="This image has an empty alt attribute; its file name is image-5.png"></figure><p id="block-24310a82-4b4d-4c2f-b958-cf09cf49a8a0">That top one is just amazing (and racist of course, <strong>no excuses</strong> for that). More calling out of hypocrisy of protests vs. reopening.</p>



<figure id="block-4dfff567-169c-4b79-b1ef-40a8a8634f96"><img src="https://realscience.community/wp-content/uploads/2020/08/image-6.png" alt="This image has an empty alt attribute; its file name is image-6.png"></figure><p id="block-c2234e34-3785-43d2-a1d2-2284c3224d83">The above posts were my first introduction to the Bill Gates microchipping conspiracy theory and to Agenda 21. The top post does also have some valid points about confusion about death rates, unreliable tests, media induced hysteria, and bogus treatments that are killing people. And so I actually found myself agreeing with some of the things being said. And more importantly, I was starting to get why people would feel this way.</p>



<p id="block-3862550a-2b2e-4b15-b23c-7fe5afc0d3ed">People were also very confused and eager to talk about the math behind the death rates etc. When people realized that I wasn’t just some liberal propaganda bot, the convos were really very constructive on the whole. Below is one of the many back and forths I had about the math.</p>



<figure id="block-5a7eb5fe-42c5-4a26-ac5f-f561cdf37471"><img src="https://realscience.community/wp-content/uploads/2020/08/image-7.png" alt="This image has an empty alt attribute; its file name is image-7.png"></figure><p id="block-f87a41f9-28f9-4f55-91ac-9eaea11511e7">And people were scared. Especially older and higher risk people.</p>



<figure id="block-3a4815cc-25cb-4fa8-9f31-1e2fb7bfa2bb"><img src="https://realscience.community/wp-content/uploads/2020/08/image-8.png" alt="This image has an empty alt attribute; its file name is image-8.png"></figure><p>It became clear to me that any public health messaging needed to start with empathy and understanding. This pandemic is super scary for so many people.</p>



<p id="block-f86a2091-4c56-44c2-baa1-17f4971b7ed2">Perhaps …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://realscience.community/2020/08/25/how-i-entered-the-matrix-through-the-red-and-blue-fakesciencenews-and-came-out-purple/">https://realscience.community/2020/08/25/how-i-entered-the-matrix-through-the-red-and-blue-fakesciencenews-and-came-out-purple/</a></em></p>]]>
            </description>
            <link>https://realscience.community/2020/08/25/how-i-entered-the-matrix-through-the-red-and-blue-fakesciencenews-and-came-out-purple/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272567</guid>
            <pubDate>Tue, 25 Aug 2020 15:49:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[VGA Signal (Software Generated, PIC24EP512GP202 Microcontroller)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24272519">thread link</a>) | @peter_d_sherman
<br/>
August 25, 2020 | http://www.voja.rs/PROJECTS/GAME_HTM/3.%20VGA.htm | <a href="https://web.archive.org/web/*/http://www.voja.rs/PROJECTS/GAME_HTM/3.%20VGA.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <td>
              <p>
			  <img height="515" src="http://www.voja.rs/PROJECTS/GAME_HTM/timings.gif" width="700">Video 
			  processors are not typically embedded in microcontrollers, so 
			  using the external video display unit is considered in gaming 
			  consoles. As this is the minimalistic project, VGA video signal is 
			  generated by software, based on interrupt driven kernel.</p>
			  <p>
			  &nbsp;The
              routine which generates VGA signal is the part of&nbsp;
			  <strong>T2</strong> (<b>Timer 2</b> module) interrupt service 
			  routine. This routine also services vertical sync pulse, markers 
			  for monitor auto adjustment and the bottom line text routine. At 
			  this version, no other interrupts are active, but the user can add 
			  his own interrupt sources, as long as they have the lower
              priority level.</p>
			  
			  <p>
			  <strong>Timing details</strong></p>
              <p>VGA
              timings for resolution <b> 800x600</b> in <b> 56Hz</b> refresh 
			  rate are represented on the drawing. Here are detailed
              timings data:</p>
              <p><u>Horizontal
              timing:</u></p>
              <p>Pixel clock: 36 MHz 
			  (13.89 ns)<br>
              Horizontal frequency/period: 35.16 KHz (28.44 us)<br>
              Visible area: 800 pixels (22.22 us)<br>
              Front porch: 24 pixels (0.67 us)<br>
              Sync pulse: 72 pixels (2 us)<br>
              Back porch: 128 pixels (3.56 us)</p>
              <p><u>Vertical
              timing:</u></p>
              <p>Vertical
              frequency/period: 56 Hz (17.86 ms)<br>
              Visible area: 600 lines (17.067 ms)<br>
              Front porch: 1 line (28.44 us)<br>
              Sync pulse: 2 lines (56.89 us)<br>
              Back porch: 22 lines (625.78 us)<br>
              Whole frame: 625 lines (17.78 ms)</p>
              <p>Dot clock for
              <b> 800x600</b> resolution <b> @ 56 Hz</b> vertical frequency is
              exactly <b> 36 MHz</b>, and the maximum execution speed for
			  <strong>PIC24E</strong> family is <strong>70 MIPS</strong>. So the 
			  MCU has to be slightly overclocked to <strong>72 MHz</strong> to 
			  get the desired instruction/pixel clock rate. This overclocking is 
			  only 2.8%, which is 
			  negligible and will not noticeable affect operational safety or thermal 
			  dissipation.</p>
			  <p>As it was noted, 
			  each pixel takes the place of 2x2 pixels area, so the actual dot clock is not 36 but 18 MHz. 
			  That gives enough time to the processor to execute four instructions 
			  in one pixel timing. In addition, every scan line is displayed 
			  twice, so there is even more time for buffer setup during 
			  horizontal sync and porches.</p>
			  
			<p>
			<strong>RAM organization</strong></p>
			<p>Video memory is 
			located in internal 
			48 KB RAM, where it occupies 45600 bytes. All video signal timings match VGA standard in <b> 800x600</b> mode, 
			but, due to RAM limitations, the actuual displayed resolution is only 
			<strong>380x240</strong>, and it is displayed on <strong>760x480</strong> 
			pixels original screen area.</p>
			<p>
			To use the whole <strong>800x600</strong> display area in 
			8-bit pixel mode, we need 800x600=<strong>480,000</strong> bytes of memory, but 
			in the best case, all that PIC microcontrollers offer at this 
			time is only 48K (<strong>49,152</strong> bytes), which is too far from what we need. There are some 16-bit PICs with 
			<strong>96K</strong> RAM, but they are too 
			slow for video signal generation, and some <strong>52K</strong> PICS, 
			but they are in SMD 64-pin packages with 0.5 mm pitch, which is 
			quite unconvenient for&nbsp; DIY projects. Although it is possible 
			to add external RAM, it is of no practical use, as the access to the 
			external RAM would be too slow. So we have to do it with 
			<strong>48K</strong> RAM MCUs somehow.</p>
			<p>
			To do that, we have to make some copromises:</p>
			<p>
			1. The colour of each pixel is defined by four bits only, so it works in 
			16-colour mode. In fact, only 15 colours are used, as one of them 
			(binary represened as 0000) does not mean "black" but "transparent", 
			which shalll be used in sprite handling. More about that later.</p>
			  <p>
			2. Each pixel from the video memory is displayed on 4-pixel (2x2) 
			area of the VGA screen.</p>
			<p>
			3. Actual displayed resolution is 380x240, which occupies 760x480 
			pixels on the screen. The 20 pixel wide margin on the top, left and 
			right side of the monitor are not used and are left black. At the 
			bottom there is one line (39 characters) of text. It needs no frame 
			buffer, as the routine interprets text directly from the text buffer in RAM.</p>
			<p>
			This organization gives 380x240=91,200 graphical pixels, but as 
			each pixel is covered by 4 bits, the video memory needs only 
			91,200/2=45,600 bytes of memory. Bottom line text needs no video 
			buffer and it occupies only 78 
			bytes (39 for text and 39 for colour attributes). So there are 
			49,152-45,678=3,474 free bytes, which is quite enough for housekeeping 
			(internal buffers and general purpose registers).</p>
			  
			  <p>
			  <strong>Sprites</strong></p>
			  <p>
			  With the processing power of 72 MIPS, it would be easy to generate the video signal 
			  by software, if 
			  the only requirement is to show the contents of video memory. As 
			  there is no video processing unit here and the MCU has to handle 
			  one pixel at a time, such concept would be useful for static 
			  images or very small movable blocks of pixels, but not for the 
			  game, which requires real time processing of large memory blocks. 
			  To make things worse, more than 1/3 of the time CPU is busy 
			  generating video signal, which leaves only 1/3 for housekeeping 
			  and active memory handling.</p>
			  <p>
			  The solution to this problem is to use <strong><em>sprites</em></strong>, 
			  which are 2D images located outside the video RAM, and somehow 
			  superimposed in the main scene. Video units in some of the first 
			  personal computers could handle sprites in hardware, but in this 
			  project it is realized in software. The sprites are in internal 
			  program memory of the MCU and they are combined with video RAM 
			  contents to generate the full video signal. That means that there 
			  is no way to manipulate the sprite contents, it can only be 
			  displayed at the desired location of the screen. As the most of characters in 
			  this game are animated, there is a large number of pixels, and 
			  each of them represents one frame of that pixel in the 
			  animation.&nbsp;Here is the example of Jack's jump. Note 
			  that X and Y absolute position on the screen is permanently 
			  adjusted during 
			  the jump, as well as the order of slides in the jump sequence 
			  (which is listed in the script table in the firmware), so it gives 
			  much more freedom in creating the <em>Mise en scène</em> for the 
			  game - this jump is, in reality, much higher and lasts longer than 
			  it may look while just watching those slides. So there is no need 
			  to draw the equal slides again, as each of them can be called repeatedly 
			  in the script table. In this example, the last five slides are 
			  repeated only because of the hair splash, otherwise slides 11, 12, 
			  13, 14 and 15 could be ommited and listed as 9, 8, 
			  6, 4 and 3 in the script. The same slides are used for jump up and 
			  for jump down to the lower floor, but with different script 
			  tables.</p>
			  <p>
					  <img height="90" src="http://www.voja.rs/PROJECTS/GAME_HTM/jump.gif" width="582"></p>
			  <p>
			  All that software has to do while servicing the video scenario, is 
			  to preset the special sprite registers, determining X and Y 
			  positions (relative to the left and upper border of the active 
			  portion of the screen), 
			  width and height of one slide image, and address of the current 
			  slide in program memory. Video firmware, located in the interrupt 
			  routine, will superimpose that sprite in the content of the 
			  background video memory during RGB signal generation.</p>
			  <p>
			&nbsp;One more thing to note is that the orange colour in sprites 
			  means "transparent" (there is no orange colour in the 
			  game pallete, only in the pallete of the PC drawing program during 
			  sprite design process). 
			  Each orange pixel on the sprite will be displayed from the video memory, which will 
			  typically hold the background image. Yet, there is one drawback of 
			  this princip. If two or more sprites are overlapping, then 
			  transparent (orange) pixels on the 
			  first of them (which holds the highest priority, that means which 
			  is located higher on the special sprite table in RAM) will partly covered 
			  the lower sprite, displaying the background instead of lower 
			  sprite's active pixels. The first (simulated) screenshot 
			  shows that example.</p>
			  <p>
			  <img height="105" src="http://www.voja.rs/PROJECTS/GAME_HTM/overlapping2.gif" width="831"></p>
			  <p>
			&nbsp;There is the way to solve this problem, but only for the 
			  limited number of sprites. Some sprites can be treated as 
			  "special", and they do not have that drawback (see the second screenshot). 
			  The only problem with those sprites is that they require 18 times 
			  more time for the video routine to execute, so programmer has to 
			  take care not to use this option if it is not necessarry, as it 
			  could result in losing scan lines on the screen.</p>
			  <p>
			  <img height="105" src="http://www.voja.rs/PROJECTS/GAME_HTM/overlapping1.gif" width="441"></p>
			  <p>
			&nbsp;How to tell to the video routine which sprite is special, and 
			  which is not? The sprite list (located in RAM and named SPRITELIST) holds 
			  pointers for active sprites. The video routine can place (or erase) any 
			  sprite at that list at any time, and at any table position which 
			  is not currently occupied. This table can hold the 
			  maximum of 20 sprites at the same time. Only four sprites (number 
			  17, 18, 19 and 20) are 
			  treated as "special" ones - they are executed much slower, but they 
			  do not generate the described problem in overlapping conflict, or 
			  at least it is minimized so that it is not noticeable. In 
			  this game, only one sprite (Jack itself) has that privilege, as 
			  the game scenario is such that all other sprites will never be 
			  overlapped.</p>
			  
			  <p>
			  <strong>Theory of operation</strong></p>
			  <p>
			  The most significant part of the video routine uses SPRITEBUFFER, 
			  which is 190 bytes long (equal to one scan line in video memory), 
			  and in which the video routine prepares the sprite contents for 
			  the …</p></td></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.voja.rs/PROJECTS/GAME_HTM/3.%20VGA.htm">http://www.voja.rs/PROJECTS/GAME_HTM/3.%20VGA.htm</a></em></p>]]>
            </description>
            <link>http://www.voja.rs/PROJECTS/GAME_HTM/3.%20VGA.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272519</guid>
            <pubDate>Tue, 25 Aug 2020 15:45:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Slack Hacks: 14 Ideas for Dev and DevOps Workflows in Slack via AWS, Twilio]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24272333">thread link</a>) | @jacksonpollock
<br/>
August 25, 2020 | https://cto.ai/blog/slack-hacks-14-ideas-for-developer-devops-workflows-slack-aws-twilio-lyft/ | <a href="https://web.archive.org/web/*/https://cto.ai/blog/slack-hacks-14-ideas-for-developer-devops-workflows-slack-aws-twilio-lyft/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<!-- .cover -->
			<div>
				<p>Increasingly companies are bringing their entire workflows and data streams into Slack via apps, integrations, and APIs. Slack is currently reporting over <a href="https://kommandotech.com/statistics/slack-statistics/#:~:text=135%2C983%20companies%20are%20currently%20using,million%20people%20daily%20in%202019.">135,000 active companies</a> and that’s just the beginning amid a global rise of remote-first work.</p><p>Why this move to Slack? For millions of users, Slack is THE place for communication and collaboration. Slack is not just an email killer because it’s a novel form of communication. We already had SMS and WhatsApp. What Slack brings to the table is deeper-seated in company transparency and velocity.</p><p>Slack is seamlessly synchronous and asynchronous. It allows you to reduce context switching by creating a space for both short-form communication and long-form with a sprinkle of emoji-led authentic conversations and interactions. It also is beautifully designed.</p><p>Most importantly though, Slack brings in streams of information out of the countless siloed data sources in your consoles and Chrome browser tabs. It surfaces real-time and important metrics, queries, customer support tickets, PagerDuty downtime pings, and so much more. It’s become your dashboard for your company, team, and everything in between.</p><p>The average company loses <a href="https://slack.com/resources/why-use-slack/software-development-teams-and-slack">more than 20%</a> of its productive power to organizational drag. Put Slack in the picture though and development teams using Slack deliver 5% more output overall, with 23% faster time to market, 27% less time needed to test and iterate, and faster identification and resolution of engineering-related bugs, <a href="https://slack.com/resources/why-use-slack/software-development-teams-and-slack#">according to IDC research</a>.</p><p>Here at CTO.ai, we use a plethora of Slackbots and SlackOps to run our company. From our <a href="https://cto.ai/platform">Slack-first DevOps workflow automation platform</a> to Geekbot for company standups to the <a href="https://ops-community.slack.com/apps/A2RPP3NFR-jira-cloud">Jira chatbot</a> for our product roadmap to Greetbot to welcome new members of <a href="https://w.cto.ai/community">our Slack developer community</a>, we are believers that Slack is the key to fluid, meshed flow states that increase productivity and observability.</p><p>To say the least, we are big fans of Slack, but don’t take our word for it. Below are some Slack hacks, tips and tricks for developers and engineering teams of all ilks to get the most out of Slack. In no particular order, here are what DevOps and engineering workflows technical leaders are using in Slack:</p><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-1-send-delayed-messages">#1 Send Delayed Messages</h2><h3 id="lizzie-sigal-developer-evangelist-twilio"><em><a href="https://www.linkedin.com/in/elsiegle/">Lizzie Sigal</a>, Developer Evangelist, Twilio</em></h3><p>“The <a href="https://ops-community.slack.com/apps/ANPGHD2F8-gator">Gator Slack app</a> lets you send delayed messages at 9am in the recipient's time zone so as to not notify them if they've logged off for the day. Convenient, more thoughtful, simple.”</p><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-2-team-celebrations">#2 Team Celebrations</h2><h3 id="fletcher-richman-co-founder-ceo-halp-senior-product-manager-atlassian"><em><a href="https://twitter.com/fletchrichman?lang=en">Fletcher Richman</a>, Co-Founder/CEO Halp; Senior Product Manager, Atlassian</em></h3><p>“Every time a new customer signs up for Halp via Stripe, we post a gif to #halp-wins.” </p><p><em>Atlassian, <a href="https://techcrunch.com/2020/05/12/atlassian-acquires-halp-to-bring-slack-integration-to-the-forefront/">which acquired Halp</a>, also has <a href="https://statuspage.io/">Statuspage</a>, a chatbot with a full Slack integration that allows updating and maintaining your status page directly inside your ops chatroom.</em></p><!--kg-card-begin: html--><!--kg-card-end: html--><h3 id="daniel-hochman-platform-engineer-lyft"><em><a href="https://www.linkedin.com/in/danielhochman/">Daniel Hochman</a>, Platform Engineer, Lyft</em></h3><p>“<a href="https://eng.lyft.com/announcing-clutch-the-open-source-platform-for-infrastructure-tooling-143d00de9713">Clutch</a> ships with authentication and authorization components. OpenID Connect (OIDC) authentication flows for single-sign on, resource-level role-based access control (RBAC) via static mapping, and automatic auditing of all actions with the ability to run additional sinks for output, e.g., a Slackbot.”</p><!--kg-card-begin: html--><br><!--kg-card-end: html--><!--kg-card-begin: image--><figure><img src="https://lh4.googleusercontent.com/s0GcOYpOtfDNhE-jH7RyDcXo-uZQubyEZAyrdtTWYKpKibznvl4QezGLiTrhbNa4U_2XR2k_MHE8gKcyo2G2XM01ErSixY5k6kxU8Q2nj9NDp6T00ifdJo04qla74pph5DOfoS8"></figure><!--kg-card-end: image--><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-4-reminders">#4 Reminders</h2><h3 id="don-burks-technical-lead-sphere"><em><a href="https://donburks.com/">Don Burks</a>, Technical Lead, Sphere</em></h3><p>“/remind is one of the biggest ones. Instead of having to break flow from my keyboard and write something down, I can get Slack to remind me.”</p><p>(I personally enjoy CMD K for quick searching and /collapse for minimizing all those extra pop-ups from Slack integrations.)</p><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-5-wins-failure-alerts-retros-standups">#5 Wins, Failure Alerts, Retros, Standups</h2><h3 id="brice-pollock-senior-ios-engineer-betterup"><em><a href="http://www.bricepollock.com/">Brice Pollock</a>, Senior iOS Engineer, BetterUp</em></h3><ul><li>Looking for a way to give sales organizations more visibility to product teams? Use the <a href="https://slack.com/help/articles/227838227-Salesforce-for-Slack">Salesforce integration</a> for closed opportunities in #general.</li><li>Looking for a way to get more insight into build failures? Use a CircleCI integration in a Slack channel that reports build failures.</li><li>Looking for a way to get more insight into runtime failures? Use a <a href="https://support.google.com/firebase/answer/9005934">Firebase integration</a> in a Slack channel that reports changes in thresholds for fatals and non-fatals.</li><li>Looking for a way to help with Team Retros? Pin a poll to a Slack channel and use a slash reminder command (/remind) to get the team to enter responses prior to retro.</li><li>Looking for a way to automate standup? Integrate Jira and Confluence so a new standup doc is generated every day with a random ice breaker question in a randomized standup order.</li><li>Looking for a way to highlight SWAT or blocking issues? Create a macro that like reminders will print all blockers right before standup and anyone on the team can add a blocker or discussion topic.</li></ul><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-6-website-metrics">#6 Website Metrics</h2><h3 id="frances-coronel-executive-director-techqueria"><em>Frances Coronel, Executive Director, <a href="https://techqueria.org/">Techqueria</a></em></h3><p>“Website metrics are a way we measure impact and we use Arc to bring Google Analytics to us automatically each week and with a cumulative monthly update instead of having to manually go into there. It's so easy to update our partnerships deck and impact report with the latest numbers.”</p><!--kg-card-begin: image--><figure><img src="https://lh4.googleusercontent.com/fZKgM1bwrrtm8o2ui1T4kaeC35c9wNGB0VkNYkGybp0uykh1npMX-OUkZRo7r-bMriqc6htXbzs18wqFdxqj-rhnOLo_DMCpt_yESqGehTop-bSqN5zYgpfC6NIJ-swfC5LyxSk"></figure><!--kg-card-end: image--><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-7-product-support">#7 Product Support</h2><h3 id="vlad-shlosberg-ceo-foqal-io"><em>Vlad Shlosberg, CEO, <a href="https://www.foqal.io/">Foqal.io</a></em></h3><p>“Immediate access to your customers and conversion to become a customer. With this Slack bot, it made our support process a lot more manageable.”</p><!--kg-card-begin: html--><br>
<!--kg-card-end: html--><!--kg-card-begin: image--><figure><img src="https://lh3.googleusercontent.com/XnpvjRt1iYXctHd7CaW37kjYjb4D4QIa7odG70yyBqOBaxbdrHdV6aF4eqI_hzxyaebD7WtFnYOWSxge1iGCho-BK6pbCFP3RySDCYR_ynHGfSvXqJdKtBwL83cJV-ePNbuEV1A"></figure><!--kg-card-end: image--><!--kg-card-begin: html--><br>
<!--kg-card-end: html--><!--kg-card-begin: image--><figure><img src="https://lh6.googleusercontent.com/y8ah1JRLFkMxexXrK9uMy9q8UaRsxjRU4zPW7IEhwUZI_T-XxL3x1i8toFgkzAK9DOhV3EIK2JtnpsHjYnNQ4aI1ED-jH4pP-DaBn2HulFwcAmzUH58HxKSJDemdnuCDjfe1deU"></figure><!--kg-card-end: image--><!--kg-card-begin: html--><br>
<!--kg-card-end: html--><p><a href="https://medium.com/swlh/creating-a-sentiment-bot-in-slack-with-node-js-and-symantos-text-analytics-api-560e854a090d">Symanto</a> built a chatbot with Node.js in Slack using their text analytics API and sentiment models.</p><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-9-status-aggregation-status-gator">#9 Status Aggregation — Status Gator</h2><p><a href="https://statusgator.com/">Status Gator</a> aggregates almost 700 status pages into Slack and you can query the status of any page on demand.</p><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-10-devops-monitoring-aws-chatbot">#10 DevOps Monitoring — AWS Chatbot</h2><p><a href="https://docs.aws.amazon.com/chatbot/latest/adminguide/what-is.html?sc_channel=sm&amp;sc_campaign=Docs&amp;sc_publisher=TWITTER&amp;sc_country=Global&amp;sc_geo=GLOBAL&amp;sc_outcome=awareness&amp;trk=Docs_TWITTER&amp;sc_content=Docs&amp;linkId=87843477">AWS Chatbot</a> enables DevOps and software development teams to use Slack chat rooms to monitor and respond to operational events in their AWS Cloud.</p><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-11-pipeline-notifications-spinnaker">#11 Pipeline Notifications — Spinnaker</h2><p>Configure the <a href="https://blog.opsmx.com/configure-slack-notifications-for-spinnaker-pipelines/">Spinnaker</a> software to receive pipeline notifications through Slack.</p><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-12-azure-boards-pipelines-repos-microsoft">#12 Azure Boards, Pipelines, Repos — Microsoft</h2><p>Post messages to Slack in response to events in your Azure DevOps organization, such as completed builds, code changes, pull requests, releases, work items changes, and more. <a href="https://docs.microsoft.com/en-us/azure/devops/service-hooks/services/slack?view=azure-devops">Details here</a>.</p><p>There are also <a href="https://zapier.com/apps/azure-devops/integrations/slack">Zapier “zaps” for Azure</a> (and many other <a href="https://zapier.com/apps/categories/developer-tools">dev tools</a>).</p><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-13-infrastructure-notifications-terraform">#13 Infrastructure Notifications — Terraform</h2><p><a href="https://www.terraform.io/docs/cloud/workspaces/notifications.html">Terraform Cloud</a> can use Slack webhooks to notify external systems about the progress of runs.</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>Don’t forget the preprogrammed apps made just for Slack. Use the <a href="https://ops-community.slack.com/apps/category/At0EFRCDNY-developer-tools">Slack app marketplace</a> to connect your development tools to Slack and raise visibility into builds, errors, or anything else that needs your attention.</p><p>Some Slack apps to call out for DevOps: <a href="https://ops-community.slack.com/apps/A0F7VRE7N-circleci">CircleCI</a>, <a href="https://ops-community.slack.com/apps/A0F81FP4N-travis-ci">Travis CI</a>, <a href="https://gitlab.com/profile/slack/edit">Gitlab</a>, <a href="https://slack.github.com/">Github</a>, <a href="https://cto-ai.slack.com/apps/A0F7VRFKN-jenkins-ci">Jenkins</a>, and <a href="https://www.atlassian.com/software/opsgenie">Atlassian Opsgenie</a>.</p><p><em>Learn more about using Slack for dev teams with their <a href="https://slack.com/resources/why-use-slack/software-development-teams-and-slack">handy handbook</a>.</em></p><p><em>Of course, you also have <a href="https://slack.com/intl/en-ca/features/workflow-automation">Workflow Builder</a> and the <a href="https://slack.dev/">Slack API</a> at your disposal.</em></p><!--kg-card-begin: html--><br><!--kg-card-end: html--><!--kg-card-begin: image--><figure><img src="https://lh5.googleusercontent.com/FTsHIO7yuWQV8WeYinn4_LGFkKSZy8o4lDe-SFgc7PljWTlxAlCqvoc1-Ce4YTwXhl5fDIMhtEqgbnLw4_bH1VGfIPPCCGcsWNWiv3HQT6QefotRGBZY30FwJwPEb4wd0rhdDfk"></figure><!--kg-card-end: image--><!--kg-card-begin: html--><!--kg-card-end: html--><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><p>Now the power of Slack is within you. Take to the channels and reinvent your developer and DevOps workflows with the tools above or in a <a href="https://cto.ai/blog/slack-control-plane-for-devops-workflows/">single control plane within Slack</a>.</p><p>And if you’d like to make your life easier and want to take the CTO.ai Slack-first DevOps workflow platform for a free spin, just <a href="https://w.cto.ai/contact-us">let us know</a>.</p>
			</div><!-- .post-content -->
			<!-- .post-footer -->
		</article></div>]]>
            </description>
            <link>https://cto.ai/blog/slack-hacks-14-ideas-for-developer-devops-workflows-slack-aws-twilio-lyft/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272333</guid>
            <pubDate>Tue, 25 Aug 2020 15:28:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Global Mass Surveillance – The Fourteen Eyes]]>
            </title>
            <description>
<![CDATA[
Score 316 | Comments 133 (<a href="https://news.ycombinator.com/item?id=24272244">thread link</a>) | @latexr
<br/>
August 25, 2020 | https://www.privacytools.io/providers/#ukusa | <a href="https://web.archive.org/web/*/https://www.privacytools.io/providers/#ukusa">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <nav id="breadcrumb" aria-label="breadcrumb">
  
  <ol itemscope="" itemtype="https://schema.org/BreadcrumbList">
    <li>
      <a href="https://www.privacytools.io/"> <span>Home</span></a>
    </li>
    
    
    <li aria-current="page" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
      
      <span itemprop="name">Providers 
      </span>
      <meta itemprop="position" content="1">
    </li>
    
    
  </ol>
</nav>


<div>
  
  <p>There's a ton of people providing services online. Discover which ones you should avoid and our recommendations for a variety of services.</p>
</div>



<p>Click on whatever service you need to view our recommendations.</p>





<img src="https://www.privacytools.io/assets/img/svg/layout/ukusa.svg" width="260" height="115" alt="UKUSA Agreement">

<p>The UKUSA Agreement is an agreement between the United Kingdom, United States, Australia, Canada, and New Zealand to cooperatively collect, analyze, and share intelligence. Members of this group, known as the <a href="https://www.giswatch.org/en/communications-surveillance/unmasking-five-eyes-global-surveillance-practices">Five Eyes</a>, focus on gathering and analyzing intelligence from different parts of the world. While Five Eyes countries have agreed to <a href="https://www.pbs.org/newshour/world/an-exclusive-club-the-five-countries-that-dont-spy-on-each-other">not spy on each other</a> as adversaries, leaks by Snowden have revealed that some Five Eyes members monitor each other's citizens and <a href="https://www.theguardian.com/uk/2013/jun/21/gchq-cables-secret-world-communications-nsa">share intelligence</a> to <a href="https://www.theguardian.com/politics/2013/jun/10/nsa-offers-intelligence-british-counterparts-blunkett">avoid breaking domestic laws</a> that prohibit them from spying on their own citizens. The Five Eyes alliance also cooperates with groups of third-party countries to share intelligence (forming the Nine Eyes and Fourteen Eyes); however, Five Eyes and third-party countries can and do spy on each other.</p>

<div>
  <div>
    <div>
        
        
        <div>
            
  <ol>
    <li>Australia </li>
    <li>Canada </li>
    <li>New Zealand </li>
    <li>United Kingdom </li>
    <li>United States of America </li>
  </ol>
  
        </div>
    </div>
</div>


  <div>
    <div>
        
        
        <div>
            
  <ol>
    <li>Denmark </li>
    <li>France </li>
    <li>Netherlands </li>
    <li>Norway </li>
  </ol>
  
        </div>
    </div>
</div>


  <div>
    <div>
        
        
        <div>
            
  <ol>
    <li>Belgium </li>
    <li>Germany </li>
    <li>Italy </li>
    <li>Spain </li>
    <li>Sweden </li>
  </ol>
  
        </div>
    </div>
</div>

</div>




<h3>Who is required to hand over the encryption keys to authorities?</h3>

<p>Mandatory <a href="https://en.wikipedia.org/wiki/Key_disclosure_law">key disclosure laws</a> require individuals to turn over encryption keys to law enforcement conducting a criminal investigation. How these laws are implemented (who may be legally compelled to assist) vary from nation to nation, but a warrant is generally required. Defenses against key disclosure laws include steganography and encrypting data in a way that provides plausible deniability.</p>  <p><a href="https://en.wikipedia.org/wiki/Steganography">Steganography</a> involves hiding sensitive information (which may be encrypted) inside of ordinary data (for example, encrypting an image file and then hiding it in an audio file). With plausible deniability, data is encrypted in a way that prevents an adversary from being able to prove that the information they are after exists (for example, one password may decrypt benign data and another password, used on the same file, could decrypt sensitive data).</p>



<p> * (people who know how to access a system may be ordered to share their knowledge, <strong>however, this doesn't apply to the suspect itself or family members.</strong>)</p>

<h3>Related Information</h3>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Key_disclosure_law">Wikipedia page on key disclosure law</a></li>
  <li><a href="https://law.stackexchange.com/questions/1523/can-a-us-citizen-be-required-to-provide-the-authentication-key-for-encrypted-dat">law.stackexchange.com question about key disclosure law in US</a></li>
  <li><a href="https://peertube.mastodon.host/videos/watch/e09915eb-5962-4830-a02f-8da5c2b59e71">DEFCON 20: Crypto and the Cops: the Law of Key Disclosure and Forced Decryption</a></li>
</ul>

<h3 id="usa">Why is it not recommended to choose a US-based service?</h3>

<img src="https://www.privacytools.io/assets/img/svg/layout/great_seal_of_the_united_states_obverse.svg" width="200" height="200" alt="USA">

<p>Services based in the United States are not recommended because of the country's surveillance programs and use of <a href="https://www.eff.org/issues/national-security-letters/faq">National Security Letters</a> (NSLs) with accompanying gag orders, which forbid the recipient from talking about the request. This combination allows the government to <a href="https://www.schneier.com/blog/archives/2013/08/more_on_the_nsa.html">secretly force</a> companies to grant complete access to customer data and transform the service into a tool of mass surveillance.</p>

<p>An example of this is <a href="https://en.wikipedia.org/wiki/Lavabit#Suspension_and_gag_order">Lavabit</a> – a secure email service created by Ladar Levison. The FBI <a href="https://www.vice.com/en_us/article/nzz888/lavabit-founder-ladar-levison-discusses-his-federal-battle-for-privacy">requested</a> Snowden's records after finding out that he used the service. Since Lavabit did not keep logs and email content was stored encrypted, the FBI served a subpoena (with a gag order) for the service's SSL keys. Having the SSL keys would allow them to access
communications (both metadata and unencrypted content) in real time for all of Lavabit's customers, not just Snowden's.</p>

<p>Ultimately, Levison turned over the SSL keys and <a href="https://www.theguardian.com/commentisfree/2014/may/20/why-did-lavabit-shut-down-snowden-email">shut down</a> the service at the same time. The US government then <a href="https://www.cnbc.com/id/100962389">threatened Levison with arrest</a>, saying that shutting down the service was a violation of the court order.</p>

<h3>Related Information</h3>

<ul>
  <li><a href="https://www.bestvpn.com/the-ultimate-privacy-guide/#avoidus">Avoid all US and UK based services</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Surespot#History">Proof that warrant canaries work based on the surespot example.</a></li>
  <li><a href="https://en.wikipedia.org/wiki/UKUSA_Agreement">The United Kingdom – United States of America Agreement (UKUSA)</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Lavabit#Suspension_and_gag_order">Lavabit: Suspension and gag order</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Key_disclosure_law">Key disclosure law</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Portal:Mass_surveillance">Wikipedia Portal: Mass_surveillance</a></li>
</ul>




<img src="https://www.privacytools.io/assets/img/svg/layout/warrant_canary_example.svg" width="450px" alt="Warrant Canary Example">

<p>A warrant canary is a posted document stating that an organization has not received any secret subpoenas during a specific period of time. If this document fails to be updated during the specified time then the user is to assume that the service has received such a subpoena and should stop using the service.</p>

<h4>Warrant Canary Examples:</h4>

<ol>
  <li><a href="https://proxy.sh/canary">https://proxy.sh/canary</a></li>
  <li><a href="https://www.ivpn.net/resources/canary.txt">https://www.ivpn.net/resources/canary.txt</a></li>
  <li><a href="https://www.bolehvpn.net/canary.txt">https://www.bolehvpn.net/canary.txt</a></li>
  <li><a href="https://www.ipredator.se/static/downloads/canary.txt">https://www.ipredator.se/static/downloads/canary.txt</a></li>
</ol>

<h4>Related Warrant Canary Information</h4>

<ul>
  <li><a href="https://www.eff.org/deeplinks/2014/04/warrant-canary-faq">Warrant Canary Frequently Asked Questions</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Warrant_canary#Companies_and_organizations_with_warrant_canaries">Companies and organizations with warrant canaries</a></li>
  <li><a href="https://www.schneier.com/blog/archives/2015/03/australia_outla.html">Warrant canary criticism by Bruce Schneier and an example of a law against warrant canaries.</a></li>
</ul>



  </div></div>]]>
            </description>
            <link>https://www.privacytools.io/providers/#ukusa</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272244</guid>
            <pubDate>Tue, 25 Aug 2020 15:20:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Psychologists confront impossible finding, triggering a revolution in the field]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24272198">thread link</a>) | @colinprince
<br/>
August 25, 2020 | https://www.cbc.ca/radio/ideas/psychologists-confront-impossible-finding-triggering-a-revolution-in-the-field-1.5344467 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/radio/ideas/psychologists-confront-impossible-finding-triggering-a-revolution-in-the-field-1.5344467">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>In 2011, American psychologist Daryl Bem proved the impossible. He showed that precognition — the ability to sense the future — is real. His study was explosive, and shook the very foundations of psychology. Contributor Alexander B. Kim in Vancouver explores the ‘replication crisis’ and what it means for the field and beyond.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5344852.1572640305!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/data-analysis.jpg"></p></div><figcaption>Psychology’s ‘replication crisis’ inspired major changes in how researchers conduct their work across the social sciences and beyond.<!-- --> <!-- -->(SolStock/iStock)</figcaption></figure><p><span></span><span>Listen<!-- --> to the full episode</span><span>53:59</span></p><p><span><p><em>*Originally published on November 1, 2019.</em></p>  <p>In 2011, an American psychologist named Daryl Bem proved the impossible. He showed that precognition&nbsp;—&nbsp;the ability to sense the future — is real. His study was explosive, and shook the very foundations of psychology.&nbsp;</p>  <p>"This would probably be the most important research paper I would say ever published in any field, if it were true," said Jeff Galak, psychologist at Carnegie Mellon University.&nbsp;</p>  <p>"If this paper were true, our understanding of the entire world, the universe, physics, [and] psychology, for sure, would be completely different," Galak said.</p>  <p>"We would no longer see time as this linear thing that we move through, but instead something that can go forwards and backwards. And we could reach into the future and pull information from that — if it were true. And 'if 'is a big part of that statement."&nbsp;&nbsp;</p>  <h2>Replication crisis</h2>  <p>Daryl Bem is a professor emeritus of psychology at Cornell University. His paper, <em>Feeling the Future: Experimental Evidence for Anomalous Retroactive Influences on Cognition and Affect,</em>&nbsp;was published in the Journal of Personality and Social Psychology&nbsp;—&nbsp;a top-tier journal for the field.</p>  <p>"The [paper's] conclusion was ridiculous," said Chris Chambers, a professor of cognitive neuroscience at Cardiff University in Wales. He's the author of the book<em> The Seven Deadly Sins of Psychology.&nbsp;</em></p>  <p>"And this is really interesting because if a paper like this that's doing everything normally and properly can end up producing a ridiculous conclusion, then how many other papers that use those exact same methods that didn't reach ridiculous conclusions are similarly flawed?"</p>    <blockquote><span><span><svg version="1.1" focusable="false" x="0px" y="0px" width="30px" height="25px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g><g><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g display="none"><g display="inline"> <path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg>You have a right to scrutinize and verify and correct.​​​​<svg focusable="false" x="0px" y="0px" width="23px" height="22px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g display="none"><g display="inline"><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g><g><path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg></span><cite>- Simine Vazire, psychologist&nbsp;</cite></span></blockquote>    <p>After <em>Feeling the Future</em>&nbsp;was published, a group called the Open Science Collaboration organized a massive replication study. And 270 scientists from 17 countries signed up. They picked 100 studies published in the year 2008 as their test sample — all from reputable, peer-reviewed psychology journals.&nbsp;</p>  <p>The plan was to repeat all 100 experiments exactly as described, and then see what happens. The findings came out in 2015. The results were stunning: only 36 percent of replications were successful.</p>  <h2>The ripple effect</h2>  <p>University of Toronto psychologist Michael Inzlicht was shocked to find that research papers in his own area of research no longer held water. They could not be replicated under the filter of more rigorous methodology.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5344903.1572637528!/fileImage/httpImage/image.jpeg_gen/derivatives/original_300/michael-inzlicht.jpeg 300w,https://i.cbc.ca/1.5344903.1572637528!/fileImage/httpImage/image.jpeg_gen/derivatives/original_460/michael-inzlicht.jpeg 460w,https://i.cbc.ca/1.5344903.1572637528!/fileImage/httpImage/image.jpeg_gen/derivatives/original_620/michael-inzlicht.jpeg 620w,https://i.cbc.ca/1.5344903.1572637528!/fileImage/httpImage/image.jpeg_gen/derivatives/original_780/michael-inzlicht.jpeg 780w,https://i.cbc.ca/1.5344903.1572637528!/fileImage/httpImage/image.jpeg_gen/derivatives/original_1180/michael-inzlicht.jpeg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5344903.1572637528!/fileImage/httpImage/image.jpeg_gen/derivatives/original_780/michael-inzlicht.jpeg"></p></div><figcaption>Michael Inzlicht is the principal investigator at the Toronto Laboratory for Social Neuroscience.<!-- --> <!-- -->(Submitted by Michael Inzlicht )</figcaption></figure></span></p>  <p>"I had grown up a scientist believing in the scientific method and the tools that we used, and all of a sudden, this one replication just made me question everything," said Inzlicht.&nbsp;</p>  <p>"What was real, what could I trust? The things I was studying... were they real? Could I trust them?"</p>  <p>Inzlicht is one of the psychologists leading the way to set new research standards. He attributes the lapse in his field to the tremendous pressure researchers face to produce new, high-impact research.</p>  <p>"Basic science is not always about chasing the new," said Inzlicht.&nbsp;</p>  <p>"It's not always about chasing something groundbreaking. It's about building a house. And if the foundations of the house are rotten, if from the beginning a discipline was built on shoddy foundations, the entire enterprise can fall."</p>  <h2>Building a new foundation</h2>  <p>Since 2011, standards for psychology research have indeed changed.&nbsp;</p>  <p>What's known as 'pre-registration' is becoming more common: researchers writing up how they're going to conduct a study, what their hypotheses are, and how they intend to analyze the data before doing their experiment. This protocol prevents researchers from massaging the data and reporting a positive result until they actually find one.</p>  <p>More than 200 scientific journals, both inside and outside psychology, now publish "registered reports," reporting their decision whether to accept or reject studies that are submitted before the experiments have actually been performed. So the decision is based on the proposed methodology and not how exciting the results are.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5344999.1572636662!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/alexander-b-kim.JPG 300w,https://i.cbc.ca/1.5344999.1572636662!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/alexander-b-kim.JPG 460w,https://i.cbc.ca/1.5344999.1572636662!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/alexander-b-kim.JPG 620w,https://i.cbc.ca/1.5344999.1572636662!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/alexander-b-kim.JPG 780w,https://i.cbc.ca/1.5344999.1572636662!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/alexander-b-kim.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5344999.1572636662!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/alexander-b-kim.JPG"></p></div><figcaption>Alexander Kim is a journalist and radio producer based in Vancouver.<!-- --> <!-- -->(Submitted by Alexander B. Kim)</figcaption></figure></span></p>  <p>Researchers also formed formed organizations like the Centre for Open Science and the <a href="https://improvingpsych.org/" target="_blank">Society for the Improvement of Psychological Science</a>.</p>  <p>"If you're signing up to be a scientist, you're signing up to say 'check my work'," said Simine Vazire,&nbsp;psychologist at the University of California at Davis and one of the co-founders of the Society for the Improvement of Psychological Science.&nbsp;</p>  <p>"Don't just take my word for it. Don't just trust me," said Vazire.&nbsp; "You have a right to scrutinize and verify and correct."<br> &nbsp;</p>  <p><strong>Guests in this episode:</strong></p>  <ul>   <li><strong><a href="http://www.jeffgalak.com/" target="_blank">Jeff Galak</a></strong>&nbsp;is a&nbsp;professor of marketing at Carnegie Mellon University.&nbsp;</li>   <li><strong><a href="https://psychology.cornell.edu/daryl-bem" target="_blank">Daryl Bem</a>&nbsp;</strong>is professor emeritus of psychology at Cornell University.&nbsp;</li>   <li><strong><a href="https://www.cardiff.ac.uk/people/view/133632-chambers-chris" target="_blank">Chris Chambers</a>&nbsp;</strong>is a professor of psychology specializing in cognitive neuroscience at Cardiff University in Wales. He's also the author of the book,<em> The Seven Deadly Sins of Psychology</em>.</li>   <li><strong><a href="http://http//michaelinzlicht.com/#lab-view" target="_blank">Michael Inzlicht</a></strong>&nbsp;is a professor of psychology at the University of Toronto. He's also a principal investigator at the Toronto Laboratory for Social Neuroscience.</li>   <li><strong><a href="http://https//www.simine.com/" target="_blank">Simine Vazire</a></strong>&nbsp;is an&nbsp;associate professor of psychology at U.C. Davis where she studies personality. She is one of the co-founders of the <a href="https://improvingpsych.org/&amp;nbsp;" target="_blank">Society for the Improvement of Psychological Science</a>.</li>   <li><strong><a href="https://www.cardiff.ac.uk/people/view/38108-collins-harry" target="_blank">Harry Collins</a></strong>&nbsp;is a&nbsp;distinguished research professor of social science at Cardiff University, specializing in scientific knowledge. He's the author of <a href="http://sites.cardiff.ac.uk/harrycollins/main-books/" target="_blank">several books</a> including <em>Forms of Life: The method and meaning of sociology.</em></li>   <li><strong><a href="http://https//atullett.people.ua.edu/" target="_blank">Alexa Tullet </a></strong>is an&nbsp;assistant professor of social psychology at the University of Alabama and co-founder of the Society for the Improvement of Psychological Science.</li>   <li><strong><a href="https://psychology.ucdavis.edu/people/aml" target="_blank">Alison Ledgerwood </a></strong>is a professor of psychology at U.C. Davis.<p>  <em>Special thanks to Dr. Ed Kroc, for help with statistics; Dr. Candis Callison, for help with philosophy of science; Tom Lowe, for recording Professor Collins in Wales; Emma Partridge, for booking Professor Bem; and Cited Media Productions, for supporting the making of this programme.</em></p></li>  </ul>  <hr>  <p><br> <em>** This episode was written and produced by<a href="https://alexanderbkim.wordpress.com/" target="_blank"> Alexander B. Kim</a> of <a href="https://citedpodcast.com/&amp;nbsp;" target="_blank">Cited Podast</a>,&nbsp;with support from Ideas Senior Producer&nbsp;Nicola&nbsp;Luksic.</em></p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/radio/ideas/psychologists-confront-impossible-finding-triggering-a-revolution-in-the-field-1.5344467</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272198</guid>
            <pubDate>Tue, 25 Aug 2020 15:15:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rip.com: Here's What Happens to Your Domains When You Die]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24272178">thread link</a>) | @KaiserSanchez
<br/>
August 25, 2020 | https://www.kubera.com/blog/what-happens-to-your-domains-when-you-die | <a href="https://web.archive.org/web/*/https://www.kubera.com/blog/what-happens-to-your-domains-when-you-die">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Even experienced domainers may not know the name Igal Lichtman. The legendary domain investor was better known by his business name, Mrs Jello.<br></p><p>Over a career spanning decades, Lichtman acquired a vast portfolio of investment domains, many worth tens of thousands of dollars. But it was what happened after Lichtman passed away in 2013 that should serve as a cautionary tale to <em>all</em> domainers.</p><h2>What Happens to Your Domains When You Die?<br></h2><p>What happens to your domains <a href="https://www.kubera.com/blog/what-important-financial-information-should-my-family-know">when you die</a> depends on how you prepare for the inevitable.</p><p>In Lichtman’s case, there wasn’t nearly enough preparation, if any. When Lichtman died from cancer complications in February of 2013, his family was left with the difficult task of trying to organize and gain access to his vast portfolio of investment domains.<br></p><p>But as his family learned, Lichtman hadn’t created a clear path for his beneficiaries to take ownership of his domains. As they expired, they were <a href="https://www.thedomains.com/2013/02/22/after-75k-in-lost-domains-igal-in-death-teaches-us-we-need-an-after-life-plan/" target="_blank">auctioned off by their registrars</a>.&nbsp;<br></p><p>The same month that Lichtman died, Vodka.net sold for $20,000. Penis.net was auctioned for $5,015. And in one of the biggest sales from Lichtman’s portfolio, Vegans.com sold for $48,000.<br></p><p>This is all money that could have gone to Lichtman’s beneficiaries. They could have kept those domains as investments, or sold them for an immediate payout for Lichtman’s family. Instead, those big payouts went to the domain registrars and auction companies that facilitated the sales.<br></p><h2>What Happened To Igal Lichtman Could Happen To Anyone<br></h2><p>Igal Lichtman made a career out of investing in domains, so his death (and the subsequent loss of his entire portfolio) made waves in the domainer world.<br></p><p>But this isn’t something that only happens to professional domain investors.<br></p><p>Jane Both, a lifelong entrepreneur from Milford, Pennsylvania, was just 50 years old when she <a href="https://www.recordonline.com/article/20170331/obituaries/303319989" target="_blank">died suddenly</a> while walking her dogs in her neighborhood in late March of 2017. Both was involved in all kinds of business ventures, including Streamline Management of Port Jervis, a home inspection service. But she was also savvy when it came to domain investing. In 2013, long before many people were considering the potential of blockchain domains, Both was buying as many as she could find.<br></p><p>Her portfolio eventually consisted of more than 100 domains containing the “blockchain” keyword — including appealing domains like BlockchainManagement.com, BlockchainAssets.com, BlockchainFinance.com, BlockchainPro.com, and BlockchainTools.com.<br></p><p>But you can probably guess where this story is going. Like Lichtman, Both didn’t plan for what would happen to her domains after her death. And so, in 2018, they <a href="https://www.thedomains.com/2018/01/18/100-expiring-blockchain-domain-auctions-next-5-days/" target="_blank">began to expire and head to auction.</a><br></p><figure id="w-node-eb256527c8e9-ac468d02"><p><img src="https://uploads-ssl.webflow.com/5ded36b5e942e74b13468d23/5f32b6a8e3394406d2d74bf9_01-Image%402x.png" alt="what happens to your domains when you die"></p></figure><p>Of the more than 100 blockchain domains Both owned, many sold for thousands of dollars, and many more for hundreds. In all, her beneficiaries missed out on tens of thousands of dollars that resulted from the sale of all of Both’s domains — money that should have gone to her loved ones, but instead went to registrars and auction companies.<br></p><h2>It’s Time to Treat Domains Like Any Other Wealth Asset<br></h2><p>These stories make one thing clear: Whether you purchase domains for the express purpose of investing in them, or just own the domains for your business or personal websites, domains can be valuable and sentimental, and they should be treated like any other digital wealth asset. In the digital age, anyone who owns a domain needs a plan in place for someone to take ownership of and manage it after their death.<br></p><p>Most domain registrars have a process in place for when an account owner dies. For example, GoDaddy, one of the world’s largest domain registrars, <a href="https://www.godaddy.com/help/how-to-gain-access-to-domainsaccounts-after-owners-death-8356" target="_blank">outlines steps</a> for what to do and how to gain access to domains or accounts after their owner’s death.<br></p><p>But even when a registrar has a process in place, it can be complicated for beneficiaries who aren’t well versed in domains and digital assets. And then there’s the question of whether your beneficiaries will even <em>know</em> what domains you own, whether they have value, and how to seek access to them.<br></p><p>You can’t leave this process to chance, or just assume that your beneficiaries will know to follow your registrar’s steps to take control of your domains. You have to be proactive to protect your domain investments.<br></p><h2>How to Protect Your Domain Investments: Step By Step<br></h2><p>Ready to make sure your domains are protected in case of the worst? Here’s what you need to do.<br></p><h3>Create a Digital Inventory<br></h3><p>We rarely think about how many online accounts we create all the time. From social media, to streaming sites and Spotify, ecommerce sites, food delivery, and, of course, our domains — there are <em>tons</em> of sites that have our personal information and, oftentimes, payment information stored. Making sure your beneficiaries have access to all these accounts will greatly simplify the process of organizing and closing them after your death.<br></p><p>That’s why, for domains, but also <em>all</em> other digital assets and accounts, <a href="https://www.kubera.com/blog/using-excel-or-google-sheets-for-tracking-net-worth">everyone should have a digital inventory</a>. This should include every account you own, passwords, associated phone numbers and email addresses, and, for any accounts that require payments or renewals, the dates and costs for renewal.<br></p><p>Your digital inventory should be available <a href="https://www.kubera.com/blog/which-important-financial-documents-should-you-safekeep">both online and offline</a> (like in a safe deposit box that a trusted beneficiary can access) and should be updated regularly.<br></p><h3>Write a Digital Will<br></h3><p>If you’re a sole trader or proprietor, your business assets, including domains and other digital assets, are legally indistinguishable from you, and would be distributed <a href="https://www.kubera.com/blog/wills-trusts-and-estate-planning-not-enough-to-protect-wealth">according to your will</a>.<br></p><p>However, it’s becoming a more common practice for people who hold a variety of digital wealth assets to write a digital will, specifying exactly how they want things like their domains passed on after their death. It’s also becoming a more common practice to name a digital executor for that will — someone who has the knowledge and experience to ensure that digital assets are transferred safely and correctly.<br></p><h3>Use a Portfolio Manager That’s Made for the Digital Age<br></h3><p>It’s long been standard practice to use a portfolio manager for tracking net worth and organizing investments in one place — a good practice that makes them easier to distribute after you’re gone.<br></p><p>But as we move forward in the digital age, wealth and investments are becoming more complex, and most traditional portfolio managers aren’t up to the task of <a href="https://www.kubera.com/blog/portfolio-manager-to-track-fiat-currency-crypto-portfolios">tracking digital wealth like crypto wallets, multi-currency accounts, and domains</a>. That’s why you need a portfolio manager that’s made for the digital age. That’s why <a href="https://www.kubera.com/">you need Kubera</a>.<br></p><p>Not only does Kubera allow you to track <em>all</em> your wealth assets — from the traditional, like stocks, bonds, bank accounts, cash, and real estate, to the modern, like collectibles, crypto exchanges and wallets, domains, and other digital assets. Kubera is also made to ensure safe and secure transfer of <em>all</em> your wealth to a beneficiary in the event something happens to you. You can even set a beneficiary to receive access to your portfolio automatically if your account becomes inactive for a set period of time.<br></p><p>Kubera is the only way to manage and protect your wealth in the digital age. Ready to see for yourself? <a href="https://app.kubera.com/signup">Try all our features free for 100 days</a>.<br></p></div></div>]]>
            </description>
            <link>https://www.kubera.com/blog/what-happens-to-your-domains-when-you-die</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272178</guid>
            <pubDate>Tue, 25 Aug 2020 15:14:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[(N)vim for Clojure development]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24272116">thread link</a>) | @tomekw
<br/>
August 25, 2020 | https://tomekw.com/nvim-for-clojure-development/ | <a href="https://web.archive.org/web/*/https://tomekw.com/nvim-for-clojure-development/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>Everything you need to write Clojure using (N)vim.</p>

<p>I used different editors and IDEs over the years: Netbeans, Vim, Emacs, and IntelliJ.
And on all of them, I always enabled Vim keybindings.</p>

<p>Few months ago, after more than 10 years writing Ruby, I started my first commercial
role as a Clojure Software Engineer at <a href="https://commsor.com/">Commsor</a>! I’m lazy,
so I picked <a href="https://cursive-ide.com/">Cursive IDE</a> (which is great BTW!), with IdeaVim
plugin enabled. Everything worked out of the box, but after while I, obviously, started to envy
my colleagues their custom workflows and setups…</p>

<p>Now that I’m sure I am Vim person to the bone - why not to give it a go? I decided to configure
a pretty minimal, as close to the Vim philosophy, setup as possible. Here it is!</p>

<h3 id="choosing-vim-distribution">Choosing Vim distribution</h3>

<p>I’m on MacOS, so I could either use <a href="https://macvim-dev.github.io/macvim">MacVim</a> distribution,
console <a href="https://neovim.io/">nvim</a>, or some GUI client for it. I decided to try out
<a href="https://github.com/qvacua/vimr">VimR</a> and I’m not disappointed:</p>



<h3 id="essential-plugins">Essential plugins</h3>

<p>I decided to manage my plugin dependencies with <a href="https://github.com/junegunn/vim-plug">vim-plug</a>.
It keeps the configuration file small and readable, and just gets the job done:</p>

<div><div><pre><code><span>" ~/.config/nvim/init.vim</span>

<span>call</span> plug#begin<span>()</span>

<span>" Plugins to install</span>
Plug <span>'first/plugin-vim'</span>
Plug <span>'second/plugin-vim'</span>

<span>call</span> plug#end<span>()</span>

<span>" Rest to the configuation file</span>
<span>" ...</span>
</code></pre></div></div>

<p>To install them we can reloaded the current file (<code>~/.config/nvim/init.vim</code>) with <code>:so %</code>
and run <code>:PlugInstall</code>.</p>

<p>I started by including:</p>

<div><div><pre><code>Plug <span>'tpope/vim-sensible'</span>
Plug <span>'vim-airline/vim-airline'</span>
</code></pre></div></div>

<p>which provide universal set of defaults and a lean status line.</p>

<p>For file and project management I picked <a href="https://github.com/ctrlpvim/ctrlp.vim">ctrlp.vim</a>:</p>

<div><div><pre><code>Plug <span>'ctrlpvim/ctrlp.vim'</span>
</code></pre></div></div>

<p>The only custom configuration I added was setting up additional project root marker and a different
user command to list files based on Git index:</p>

<div><div><pre><code><span>let</span> <span>g:ctrlp_root_markers</span> <span>=</span> <span>[</span><span>'deps.edn'</span><span>]</span>
<span>let</span> <span>g:ctrlp_user_command</span> <span>=</span> <span>[</span><span>'.git'</span><span>,</span> <span>'cd %s &amp;&amp; git ls-files -co --exclude-standard'</span><span>]</span>
</code></pre></div></div>

<p>Also, I chose Apprentice as my color scheme:</p>

<div><div><pre><code>Plug <span>'romainl/Apprentice'</span>

<span>colorscheme</span> apprentice
</code></pre></div></div>

<p>Mandatory screenshot:</p>

<p><img src="https://tomekw.com/assets/images/apprentice.png" alt="Apprentice"></p>

<p>The must-have plugin for everyone is:</p>

<div><div><pre><code>Plug <span>'axelf4/vim-strip-trailing-whitespace'</span>
</code></pre></div></div>

<p>which removes trailing whitespace on modified lines before saving.</p>

<p>Last but not least there is support for searching across the files in the project.
<a href="https://github.com/mileszs/ack.vim">ack.vim</a> supported
by <a href="https://github.com/BurntSushi/ripgrep">ripgrep</a> works perfectly!
Importantly, it takes <code>.gitignore</code> settings into account.</p>



<p>and</p>



<p>Custom configuration sets the ripgrep as a backend, closes the search results popup after choosing
the result, and stops the plugin from jumping to the first result automatically.</p>

<div><div><pre><code><span>let</span> <span>g:ackprg</span> <span>=</span> <span>'rg --vimgrep'</span>
<span>let</span> <span>g:ack_autoclose</span> <span>=</span> <span>1</span>
cnoreabbrev Ack Ack<span>!</span>
</code></pre></div></div>

<p>All of that alone would be a potent general-purpose Vim setup.</p>

<h3 id="clojure-support">Clojure support</h3>

<p>To efficiently write Clojure code I needed syntax highlighting, structural editing
support, REPL management, and context-aware autocomplete.</p>

<p>These three plugins:</p>

<div><div><pre><code>Plug <span>'guns/vim-clojure-highlight'</span>
Plug <span>'guns/vim-clojure-static'</span>
Plug <span>'luochen1990/rainbow'</span>
</code></pre></div></div>

<p>give me syntax highlighting, indentation, and rainbow parentheses to better distinguish forms
visually.</p>

<p>Next two plugins:</p>

<div><div><pre><code>Plug <span>'guns/vim-sexp'</span>
Plug <span>'tpope/vim-sexp-mappings-for-regular-people'</span>
</code></pre></div></div>

<p>provide structural editing support with vim-like mappings.</p>

<p>These five:</p>

<div><div><pre><code>Plug <span>'clojure-vim/vim-jack-in'</span>
Plug <span>'radenling/vim-dispatch-neovim'</span>
Plug <span>'SevereOverfl0w/vim-replant'</span><span>,</span> <span>{</span> <span>'do'</span><span>:</span> <span>':UpdateRemotePlugins'</span> <span>}</span>
Plug <span>'tpope/vim-dispatch'</span>
Plug <span>'tpope/vim-fireplace'</span>

</code></pre></div></div>

<p>allow me to start and / or connect to existing nREPL session, with <code>deps.edn</code> support
by just invoking:</p>



<p><code>vim-replant</code> adds handy keybindings for working with Clojure REPLs. Just invoke
<code>&lt;LocalLeader&gt;rf</code> to refresh namespaces by automatically calling your common <code>(stop)</code>/<code>(start)</code>
functions! Magic!</p>

<p>And you know what? All of this doesn’t need a single line of custom configuration.
I love the sane defaults and conventions!</p>

<p>Context-aware autocomplete needs more work, but it’s worth the effort.</p>

<div><div><pre><code>Plug <span>'clojure-vim/async-clj-omni'</span>
Plug <span>'prabirshrestha/asyncomplete.vim'</span>
</code></pre></div></div>

<p>These two plugins provide autocomplete which understands your code by using the existing REPL
connection! <code>asyncomplete</code> doesn’t come with any sources enabled and it needs to be registered:</p>

<div><div><pre><code><span>au</span> <span>User</span> asyncomplete_setup <span>call</span> asyncomplete#register_source<span>({</span>
<span>    \</span> <span>'name'</span><span>:</span> <span>'async_clj_omni'</span><span>,</span>
<span>    \</span> <span>'whitelist'</span><span>:</span> <span>[</span><span>'clojure'</span><span>],</span>
<span>    \</span> <span>'completor'</span><span>:</span> <span>function</span><span>(</span><span>'async_clj_omni#sources#complete'</span><span>),</span>
<span>    \</span> <span>})</span>
</code></pre></div></div>

<p>And that’s all! It’s ready to help you keep all the parentheses balanced :)</p>

<p>The complete configuration file, with few additional plugins, can be found on my
<a href="https://github.com/tomekw/dontfiles/blob/master/.config/nvim/init.vim">tomekw/dontfiles</a> repo.
I’m sure the current setup will grow in the future, but you can track the progress by following
me on <a href="https://twitter.com/_tomekw">Twitter</a>!</p>

    </div></div>]]>
            </description>
            <link>https://tomekw.com/nvim-for-clojure-development/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272116</guid>
            <pubDate>Tue, 25 Aug 2020 15:08:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hide a problem from your client and now you've got 2 problems]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24272092">thread link</a>) | @mcrittenden
<br/>
August 25, 2020 | https://critter.blog/2020/08/25/hide-a-problem-from-your-client-and-now-youve-got-2-problems/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/08/25/hide-a-problem-from-your-client-and-now-youve-got-2-problems/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-798">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>Once upon a time, I was working on a project that was going pretty well until it wasn’t. Our full time DevOps person suddenly quit and we were struggling to find a replacement, so builds were getting flakier by the day. Plus, the frontend work had slowed to a trickle because one dev had to start splitting time with another project, and the other dev was still ramping up. </p>



<p>That’s what we saw, and it sucked but it was understandable. These things happen.</p>



<p>But what did the client see? <strong>Slow progress</strong>. That’s all they got, because we didn’t tell them about any of our staffing issues. Clients gonna client, so their natural reaction was to panic that work wasn’t getting done and start making wild guesses about why, most of which involved some form of them getting screwed or the team not understanding how important this all is. </p>



<p>We had turned 1 problem (staffing issues) into 2 problems (staffing issues and a thrashing client). Abracadabra!</p>



<hr>



<p>Why do we do this to ourselves and our clients? Why do we try to hide our problems? Because it’s embarrassing that we’re struggling with staffing? Because we don’t want to admit that we don’t know technology X as deeply as we thought? Because we want to be professional, and professionals don’t have problems? Because we don’t want to upset them?</p>



<p>If we want to be professional, then we need to be transparent and say the embarrassing thing. If we want to avoid upsetting them, then we should tell them what’s going on instead of making them guess. <em>Their guesses are usually more upsetting than the truth</em>. </p>



<p>The book <em>Joy Inc</em>. by Richard Sheridan talks a lot about aligning the world’s outside perception of your company with your inside reality: “The message felt quite freeing, because it meant you didn’t have to lie to anybody about anything.” </p>



<p>That’s what we’re doing when we hide things from the client. We’re lying. How professional is that? How does that help anyone?</p>



<p>Stop that. Be radically candid with your clients. Bring them in. Don’t just show them the sausage making, but make the sausage with them instead of for them. That way, when the sausage machine goes haywire, the client can skip the thrashing and focus on the fixing.</p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/08/25/hide-a-problem-from-your-client-and-now-youve-got-2-problems/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272092</guid>
            <pubDate>Tue, 25 Aug 2020 15:07:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Things Every Landing Page Should Have]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24272071">thread link</a>) | @johannesippen
<br/>
August 25, 2020 | https://toolbox.humandeluxe.com/landing-page-essentials/ | <a href="https://web.archive.org/web/*/https://toolbox.humandeluxe.com/landing-page-essentials/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  



  <p><img src="https://d33wubrfki0l68.cloudfront.net/e7b2e5a7c740261a93e10f899991c533f986e7f6/3e96c/uploads/landing-page-hacks.jpg" alt=""></p>

<p>The difference between a landing page and company website is simple: while the latter is an all-purpose website that people will access from your social media profile or general Google search, the landing serves a more specific purpose. It will usually be the endpoint of an ad campaign, may it be a social media banner campaign, a search ad campaign or even offline, through a special URL or QR code printed on a poster or magazine ad.</p>

<p>A landing page can be covering your whole product or be centered on one specific feature, problem or audience segment. In highly competitive spaces, a landing page can be used to compare your product against a popular competitor, trying to steal away their search traffic.</p>

<p>What all landing pages have in common is their purpose: They will try to convert a visitor into a paying customer – something that we call conversion design. To be successful with that, there is no cookie cutter formula: Every landing page is different, just as every product is different. If someone tries to tell you otherwise, they are probably trying to sell you their templated landing page builder.</p>

<p>However, there a few things that every successful landing page needs to have – regardless of content and design. At Human Deluxe, we have been creating a lot of landing pages – and these are the things that we learned on the way:</p>

<h2 id="1-simple-catchy-entry">1. Simple, Catchy Entry</h2>

<p>To eliminate one big myth first: There is no “fold” on a landing page. Trying to get all the seemingly important elements “above the fold” will make your header section messy and overcrowded. Instead, find a good, simple and catchy way to start your landing page: Start with a short and catchy title that draws attention and invests users emotionally in your product. If you use a visual, try making it simple and readable: A simplified screenshot of your app in a device frame works well, a playful illustration that sets the tone or even a simple moody stock photo that conveys an emotion. Same goes here: Do not overload users, but also make clear: There is more!</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/a39223ff2a1afa279eabc7d9ea82849a67ecd13f/20325/uploads/landing-page-avocode.jpeg" alt=""></p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/68a77217bcaf68643a6b1072aae8c6d7ccbb66db/b3613/uploads/landing-page-stripe.jpeg" alt=""></p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/cd4ed1751f7bd9975be54c7a2479a73cc05487fd/33786/uploads/landing-page-epicurrence.jpg" alt=""></p>

<h2 id="2-one-very-clear-call-to-action">2. One Very Clear Call to Action</h2>

<p>Speaking of conversion, think about what you want your visitors to do, and make it very clear for them. We call this: Call to Action. A call to action is not only a nice big button, but the whole context. Avoid generic texts like “Learn more …” or “Contact us”. Instead, try to manage expectations with your call to action, like:</p>

<ul>
  <li>Start your FREE 30 day trial</li>
  <li>Book a call with Katja</li>
</ul>

<p>For successful call to actions, the context is important: Make sure that your nice big button has enough white space around it to properly stand out. Provide information about what is going happen next or what is not going to happen. A simple hint like: “No credit card required” might be an amazing conversion driver, taking the fear of being ripped off of users.</p>

<h2 id="3-concrete-product-showcase">3. Concrete Product Showcase</h2>

<p>When your landing page is for a concrete product (and it usually is), make sure you show and explain it. Especially in B2B, landing pages often make the mistake of trying to stay too vague around what the user will get, excusing it with “it’s too complicated”, “it’s super individual” or “We will overhaul the whole thing”.</p>

<p>Explain features and requirements, show photos, screenshots or even videos. Take some time to do so – users love to see your actual product before they use it.</p>

<p>In best case, you will have a customised version of your product for the landing page that idealises and simplifies your product, showing demo data, focussed interfaces or even highlights the important sections.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/7157128a6aaadd96d7c2acb6a43e91fd52580060/9a292/uploads/landing-page-product.jpeg" alt=""></p>

<h2 id="4-structured-information">4. Structured Information</h2>

<p>Think of all the questions that a visitor could have and try to answer them, in a simple and structured way. A good way to do this is a kind of FAQ section: Short questions, clear &amp; short answers. Don’t be afraid of being redundant: What you want to have here is an inclusive and accessible experience, where people get the information, even if they missed it in the first 3 placements.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/30e8345aa637bc3fbd72c97c1a73c91f9cfbd240/8e154/uploads/landing-page-faq.jpeg" alt=""></p>

<p>Structuring information in a simple and expected way helps users to consume it very quickly – don’t try to be too innovative here, this will rather scare people.</p>

<h2 id="5-show-your-face">5. Show your Face</h2>

<p>Lastly, show the team: Who is making the product? It may seem irrelevant to the product, but we Human beings tend to trust other more than we trust products or concepts. So in order to build an engaging, converting landing page – make sure that you are a part of it.</p>

<p>I hope these help you create or improve your own landing page. What other best practices do you have? Let me know on Twitter or Instagram: <a href="https://twitter.com/johannesippen">@johannesippen</a></p>

</div></div>]]>
            </description>
            <link>https://toolbox.humandeluxe.com/landing-page-essentials/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272071</guid>
            <pubDate>Tue, 25 Aug 2020 15:05:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to split your time – tips from a Lead at Google]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24271926">thread link</a>) | @windy-topology
<br/>
August 25, 2020 | https://www.lifetechpsych.com/tips-from-googler/ | <a href="https://web.archive.org/web/*/https://www.lifetechpsych.com/tips-from-googler/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-reactid="8"><p>The beginning of the week is the worst.</p>
<p>And to be honest, it doesn’t feel any different from last week.</p>
<p>And the week before — <em>slow, boring, simply-looking-forward-to-Friday</em>.</p>
<h2>Dragging through a slow start</h2>
<p>For many, Monday is the least productive day and it comes with a lot of guilt that sets the tone for the rest of the week. </p>
<p>I see all over the internet, especially on LinkedIn, how you should start your week with so much enthusiasm. </p>
<blockquote>
<p><em>Yeah! New week! New me! New possibilities!”</em> </p>
</blockquote>
<p>Ummm maybe they’re unto something - good for them. But in reality, most Mondays feel like:</p>
<blockquote>
<p><em>New week! Ugh! It’s sooooo long until the weekend!</em></p>
</blockquote>
<p>Then it’s Tuesday. Same story.</p>
<p>I don’t know about you but this is usually the summary of many weekends for me:</p>
<ul>
<li>It was too short.</li>
<li>I had this feeling last week.</li>
<li>I had the same this week.</li>
<li>At this rate, I’ll have this feeling next week.</li>
</ul>
<h2>A potential solution</h2>
<p>I’ve been thinking a lot about this. </p>
<p>And recently found a breakdown by <a href="https://twitter.com/jeremiahdillon">Jeremiah Dillon</a>, previously Head of Product Marketing at Google for 9 years, to be super helpful.</p>
<p>At Google, Dillon <a href="https://www.fastcompany.com/3054571/the-better-time-management-strategy-this-googler-taught-his-coworkers">sent an email</a> that encouraged employees to set aside more time for <em>Maker Time — our creativity and thinking time —</em> instead of having endless busy times, back to back.</p>
<p>Here’s a <a href="https://www.youtube.com/watch?v=noc-DKZoNGU">2-minute video</a> on this concept.
<a href="https://www.youtube.com/watch?v=noc-DKZoNGU">
  </a><a href="https://www.lifetechpsych.com/static/youtube-2377829a910c408f124d14e92b1a4337-1062e.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="Youtube video" title="" src="https://www.lifetechpsych.com/static/youtube-2377829a910c408f124d14e92b1a4337-fb8a0.png" srcset="https://www.lifetechpsych.com/static/youtube-2377829a910c408f124d14e92b1a4337-1a291.png 148w,
https://www.lifetechpsych.com/static/youtube-2377829a910c408f124d14e92b1a4337-2bc4a.png 295w,
https://www.lifetechpsych.com/static/youtube-2377829a910c408f124d14e92b1a4337-fb8a0.png 590w,
https://www.lifetechpsych.com/static/youtube-2377829a910c408f124d14e92b1a4337-526de.png 885w,
https://www.lifetechpsych.com/static/youtube-2377829a910c408f124d14e92b1a4337-fa2eb.png 1180w,
https://www.lifetechpsych.com/static/youtube-2377829a910c408f124d14e92b1a4337-1062e.png 1360w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </p>
<p>In summary: first set aside more time for creativity by reducing the amount of busy times you have. Then align your days throughout the week with your energy level.</p>
<p><strong>Instead of fighting a lost battle with slow week starts, use Mondays to proactively plan your maker time and to align your energy level with tasks for the rest of the week.</strong></p>
<p>Make sense? </p>
<p>Now, don’t just make plans for planning sake. You want your plan to drive down busy time while also increasing maker time. </p>
<p>
  <a href="https://www.lifetechpsych.com/static/chart-0821bc8879ca96bfba3ef7c06990d881-66b54.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="Busy Time vs Maker Time" title="" src="https://www.lifetechpsych.com/static/chart-0821bc8879ca96bfba3ef7c06990d881-fb8a0.png" srcset="https://www.lifetechpsych.com/static/chart-0821bc8879ca96bfba3ef7c06990d881-1a291.png 148w,
https://www.lifetechpsych.com/static/chart-0821bc8879ca96bfba3ef7c06990d881-2bc4a.png 295w,
https://www.lifetechpsych.com/static/chart-0821bc8879ca96bfba3ef7c06990d881-fb8a0.png 590w,
https://www.lifetechpsych.com/static/chart-0821bc8879ca96bfba3ef7c06990d881-526de.png 885w,
https://www.lifetechpsych.com/static/chart-0821bc8879ca96bfba3ef7c06990d881-fa2eb.png 1180w,
https://www.lifetechpsych.com/static/chart-0821bc8879ca96bfba3ef7c06990d881-66b54.png 1282w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    
&nbsp; &nbsp; &nbsp; <em>The higher your busy time, the lower your maker time; but you can plan ahead more maker time by reducing your busy time.</em></p>
<h2>What the chart means</h2>
<p>The chart moves from 100% busy time to 100% maker time.</p>
<p>But 100% maker time is an idealistic state. We most likely will never get there. And that’s fine. I like to think of it as a form of stretch goal.</p>
<p>If you picture the top left corner of the graph, most of us reside there: <em>busy, exhausting, working on back-to-back tasks</em>.</p>
<p>A more realistic place to shoot for is somewhere, a little past the center where you’re still busy but you’ve set aside even more maker time. </p>
<p>Then on the far right is where you keep pushing yourself to, as you go more towards the right, it becomes much tougher to achieve 100%.</p>
<h2>Let’s look at a specific example</h2>
<p>Here’s a breakdown of an example week by Dillon:</p>
<p><strong>Monday</strong></p>
<p>Energy ramps out of the weekend — schedule low-demand tasks like setting goals, organizing, and planning.</p>
<p><strong>Tuesday, Wednesday</strong></p>
<p>Peak of energy — tackle the most difficult problems, write, brainstorm, schedule your Make Time.</p>
<p><strong>Thursday</strong></p>
<p>Energy begins to ebb — schedule meetings, especially when consensus is needed.</p>
<p><strong>Friday</strong></p>
<p>Lowest energy level — do open-ended work, long-term planning, and relationship building.”</p>
<h2>But I don’t manage anyone</h2>
<p>That’s ok. </p>
<p>You actually don’t have to be a manager to follow the high level principle. You don’t even have to work for a company.</p>
<p>You can adapt it for:</p>
<ul>
<li>
<p><strong>Workouts</strong>: Days where you want to do a full work out. Plan ahead something simple for days when you notice your energy is typically low</p>
</li>
<li>
<p><strong>Writing</strong>: You have a book to write but feel lazy in the evenings. You can use that period to plan titles for the book, outline for chapters, etc. But then dedicate your high energy in the mornings to writing at least one pages.</p>
</li>
<li>
<p><strong>Meditation/House Chores/Job application/etc</strong>: Plan ahead for low-energy moments.</p>
</li>
</ul>
<h2>Your next action</h2>
<p>Maybe for you, Mondays are not slow.</p>
<p>It could be Tuesday or Thursday.</p>
<p>The most important takeaway is that you should chunk your activities by different days of the week or different hours of the day and align them with your energy level.</p>
<p>That way, you’ll feel more balance and control in how your week goes.</p>
<p><strong>Remember, simple little actions everyday are what add up to the big transformation we all desire.</strong></p>
<p>The goal of this post is to push you to proactively remove barriers that will prevent you from starting a task in the future. By planning ahead simple tasks for when you feel lazy, you increase your chance of showing up everyday.</p>
<h2>Thanks for Reading</h2>
<p>Have any questions or comments, <a href="https://ctt.ac/I1f33">let me know on Twitter</a>. Until the next post – see ya</p></div></div>]]>
            </description>
            <link>https://www.lifetechpsych.com/tips-from-googler/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271926</guid>
            <pubDate>Tue, 25 Aug 2020 14:53:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vim-Like Layer for Xorg and Wayland]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24271904">thread link</a>) | @todsacerdoti
<br/>
August 25, 2020 | https://cedaei.com/posts/vim-like-layer-for-xorg-wayland/ | <a href="https://web.archive.org/web/*/https://cedaei.com/posts/vim-like-layer-for-xorg-wayland/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
        
<h2 id="insert-mode">Insert Mode<a href="#insert-mode" arialabel="Anchor">⌗</a> </h2>
<p><img src="https://cedaei.com/images/insert_mode.jpg" alt="Insert Mode: A keyboard layout similar to normal QWERTYlayout"></p>
<h2 id="normal-mode">Normal Mode<a href="#normal-mode" arialabel="Anchor">⌗</a> </h2>
<p><img src="https://cedaei.com/images/normal_mode.jpg" alt="Normal Mode: A keyboard layout with the alphabet keys replaced with shortcutkey"></p>
<p>Inspired by vim, I wanted to create a layer on top of my keyboard which worked
like a shortcut layer. So, to start off, I found out about XKB<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>. XKB is the
Xorg Keyboard Extension which tells Xorg on how to react to input from
keyboard.  After reading through some source code, I found out that Xorg has
support for function keys F1 - F35<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>. The general idea here was:</p>
<ul>
<li>Create an insert mode layout for text input.</li>
<li>Replace keys with relevant keys in normal mode (e.g. replace j with Down) and
for keys that require executing a command, replace then with a function key
above F12 (e.g. replace q with F13).</li>
<li>Bind all the function keys above F12 to the respective functions.</li>
</ul>
<p>To start off, I began a fresh Xorg session with nothing modifying the keys
(removed <code>xmodmap</code> from startup) and first dumped the current layout into a
file.</p>
<div><pre><code data-lang="bash">xkbcomp $DISPLAY ~/.xkb/insert.xkb
</code></pre></div><p>This was my starting point. I made changes to this file which were common to
both Insert and Normal mode. e.g. replaced <code>Caps Lock</code> with <code>Ctrl</code> and made
<code>Shift+Caps Lock</code> <code>Caps Lock</code>. Also, I unbound <code>Alt_R</code> as a modifier so that I
could use that as a switch between Normal and Insert Mode.</p>
<p>Here is a diff between the original layout and Insert mode.</p>
<pre><code>1323c1321
&lt;     key &lt;CAPS&gt; {         [       Caps_Lock ] };
---
&gt;     key &lt;CAPS&gt; {         [       Control_L,       Caps_Lock ] };
1551c1549
&lt;     modifier_map Lock { &lt;CAPS&gt; };
---
&gt;     modifier_map Control { &lt;CAPS&gt; };
1555d1552
&lt;     modifier_map Mod1 { &lt;RALT&gt; };
</code></pre><p>Next, I copied <code>~/.xkb/insert.xkb</code> to <code>~/.xkb/normal.xkb</code>. I replaced keys as
per the plan.</p>
<p>Here is a diff between Insert mode and Normal mode.</p>
<div><pre><code data-lang="diff">1200c1200
&lt;         symbols[Group1]= [               q,               Q ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F13]
1204c1204
&lt;         symbols[Group1]= [               w,               W ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F14]
1208c1208
&lt;         symbols[Group1]= [               e,               E ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F15]
1212c1212
&lt;         symbols[Group1]= [               r,               R ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F16]
1216c1216
&lt;         symbols[Group1]= [               t,               T ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F17]
1220c1220
&lt;         symbols[Group1]= [               y,               Y ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F18]
1224c1224
&lt;         symbols[Group1]= [               u,               U ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F19]
1228c1228
&lt;         symbols[Group1]= [               i,               I ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Alt_R]
1232c1232
&lt;         symbols[Group1]= [               o,               O ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F20]
1236c1236
&lt;         symbols[Group1]= [               p,               P ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F21]
1244c1244
&lt;         symbols[Group1]= [               a,               A ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F22]
1248c1248
&lt;         symbols[Group1]= [               s,               S ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Delete]
1252c1252
&lt;         symbols[Group1]= [               d,               D ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [BackSpace]
1256c1256
&lt;         symbols[Group1]= [               f,               F ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Home]
1260c1260
&lt;         symbols[Group1]= [               g,               G ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [End]
1264c1264
&lt;         symbols[Group1]= [               h,               H ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Left]
1268c1268
&lt;         symbols[Group1]= [               j,               J ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Down]
1272c1272
&lt;         symbols[Group1]= [               k,               K ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Up]
1276c1276
&lt;         symbols[Group1]= [               l,               L ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Right]
1285c1285
&lt;         symbols[Group1]= [               z,               Z ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F23]
1289c1289
&lt;         symbols[Group1]= [               x,               X ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F24]
1293c1293
&lt;         symbols[Group1]= [               c,               C ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F25]
1297c1297
&lt;         symbols[Group1]= [               v,               V ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F26]
1301c1301
&lt;         symbols[Group1]= [               b,               B ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F27]
1305c1305
&lt;         symbols[Group1]= [               n,               N ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Next]
1309c1309
&lt;         symbols[Group1]= [               m,               M ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Prior]
</code></pre></div><p>At this point, <code>normal.xkb</code> file defines the following layout.</p>
<p><img src="https://cedaei.com/images/normal_mode_unbound.jpg" alt="Normal Mode: A keyboard "></p>
<p>Now, we need a script that switches between layouts. To load an layout in Xorg, we use</p>
<div><pre><code data-lang="bash">xkbcomp ~/.xkb/normal.xkb <span>"</span>$DISPLAY<span>"</span>
</code></pre></div><p>Sway supports this via the input command in the following form.</p>
<div><pre><code data-lang="bash">swaymsg input <span>'*'</span> xkb_file ~/.xkb/normal.xkb
</code></pre></div><p>The following script cycles through the layouts when it is called. It also
allows to add more layouts later (just add them to layouts array and it will
cycle in the order of the array).</p>
<div><pre><code data-lang="bash"><span>#!/usr/bin/env bash
</span><span></span><span># Usage: xkb_swapper.sh [layout_name]</span>

<span>function</span> set_layout<span>()</span> <span>{</span>
	echo <span>"Setting layout to </span>$1<span>"</span>
	<span>if</span> <span>[[</span> -v WAYLAND_DISPLAY <span>]]</span>; <span>then</span>
		swaymsg input <span>'*'</span> xkb_file ~/.xkb/<span>"</span>$1<span>"</span>.xkb
	<span>else</span>
		xkbcomp ~/.xkb/<span>"</span>$1<span>"</span>.xkb <span>"</span>$DISPLAY<span>"</span>
	<span>fi</span>
	echo <span>"</span>$1<span>"</span> &gt; ~/.cache/xkb-curr-<span>"</span>$DISPLAY<span>"</span>
<span>}</span>
layouts<span>=(</span>insert normal<span>)</span>
current_layout<span>=</span><span>$(</span>cat ~/.cache/xkb-curr-<span>"</span>$DISPLAY<span>"</span> <span>||</span> echo <span>""</span><span>)</span>

<span>if</span> <span>[[</span> $1 !<span>=</span> <span>""</span> <span>]]</span>; <span>then</span>
	set_layout <span>"</span>$1<span>"</span>
	exit
<span>fi</span>
<span>if</span> <span>[[</span> $current_layout <span>==</span> <span>""</span> <span>]]</span>; <span>then</span>
	echo <span>"No current layout found!"</span>
	set_layout <span>"</span><span>${</span>layouts[0]<span>}</span><span>"</span>
<span>fi</span>

i<span>=</span><span>0</span>
<span>while</span> <span>[[</span> $i -lt <span>${#</span>layouts[@]<span>}</span> <span>]]</span>; <span>do</span>
	<span>if</span> <span>[[</span> $current_layout <span>==</span> <span>"</span><span>${</span>layouts[$i]<span>}</span><span>"</span> <span>]]</span>; <span>then</span>
		new_idx<span>=</span><span>"</span><span>$((</span>i+1<span>))</span><span>"</span>
		<span>if</span> <span>[[</span> $new_idx -eq <span>${#</span>layouts[@]<span>}</span> <span>]]</span>; <span>then</span>
			set_layout <span>"</span><span>${</span>layouts[0]<span>}</span><span>"</span>
		<span>else</span>
			set_layout <span>"</span><span>${</span>layouts[$new_idx]<span>}</span><span>"</span>
		<span>fi</span>
		exit
	<span>fi</span>
	<span>((</span>i++<span>))</span>
<span>done</span>

echo <span>"Current Layout doesn't exist!"</span>
set_layout <span>"</span><span>${</span>layouts[0]<span>}</span><span>"</span>
</code></pre></div><p>The above script works with all Xorg based DE/WMs as well as Sway (wayland
compositor). I saved it as <code>xkb_swapper.sh</code> in my <code>PATH</code>. Calling the script
without any argument cycles through the layouts. If arguments are passed, the
first argument is taken as layout name and layout is changed to that.</p>
<p>The last step is binding the function keys and <code>Alt_R</code> to commands to execute.
Here are some of the parts of my i3 config that bind the function keys.</p>
<pre><code>bindsym Alt_R exec xkb_swapper.sh
bindsym 0xffca kill
bindsym 0xffcf exec volchange -5
bindsym 0xffd0 exec volchange +5
bindsym 0xffd1 exec brightness -200
bindsym 0xffd2 exec brightness +200
bindsym 0xffcb exec mpc prev
bindsym 0xffcc exec mpc toggle
bindsym 0xffcd exec mpc next
</code></pre><p><code>i3</code> doesn’t seem to accept <code>F13</code> - <code>F35</code> as keynames however it accepts the
keycodes<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.  Here is a small list for easy access.</p>
<pre><code>0xffbe   F1
0xffbf   F2
0xffc0   F3
0xffc1   F4
0xffc2   F5
0xffc3   F6
0xffc4   F7
0xffc5   F8
0xffc6   F9
0xffc7   F10
0xffc8   F11
0xffc9   F12
0xffca   F13
0xffcb   F14
0xffcc   F15
0xffcd   F16
0xffce   F17
0xffcf   F18
0xffd0   F19
0xffd1   F20
0xffd2   F21
0xffd3   F22
0xffd4   F23
0xffd5   F24
0xffd6   F25
0xffd7   F26
0xffd8   F27
0xffd9   F28
0xffda   F29
0xffdb   F30
0xffdc   F31
0xffdd   F32
0xffde   F33
0xffdf   F34
0xffe0   F35
</code></pre>
<p>The script stores the mode in <code>~/.cache/xkb-curr-$DISPLAY</code>. <code>cat</code> that and
wrap in your bar’s config. Here is my config for
<a href="https://github.com/greshake/i3status-rust">i3status-rust</a>.</p>
<div><pre><code data-lang="toml">[[<span>block</span>]]
<span>block</span> = <span>"custom"</span>
<span>command</span> = <span>"echo -en '\\uf11c '; cat ~/.cache/xkb-curr-$DISPLAY"</span>
<span>interval</span> = <span>0.5</span>
</code></pre></div><section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>As always, the <a href="https://wiki.archlinux.org/index.php/X_keyboard_extension">Arch Wiki page on XKB</a> is a nice place to start. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>You can find all the defined keys in <code>/usr/include/X11/keysymdef.h</code>. <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

      </div></div></div>]]>
            </description>
            <link>https://cedaei.com/posts/vim-like-layer-for-xorg-wayland/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271904</guid>
            <pubDate>Tue, 25 Aug 2020 14:51:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Start an Online Bakery (Or transfer an existing one online)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24271789">thread link</a>) | @porthas
<br/>
August 25, 2020 | https://www.mightyforms.com/blog/how-to-start-an-online-bakery-or-transfer-an-existing-one-online | <a href="https://web.archive.org/web/*/https://www.mightyforms.com/blog/how-to-start-an-online-bakery-or-transfer-an-existing-one-online">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>If there is one thing that is certain in these uncertain times is that the current pandemic has forever changed how businesses operate.</p><p>It also changed how we shop. Right now, having an online bakery can be the answer to your questions on how to use your kitchen gifts to profit.</p><p>Starting a new business requires courage. But, if you got here, it shows that you are brave enough to put the idea into practice. So, roll up your sleeves and let’s get started. It’s time to work on your new online bakery.</p><figure><p><img src="https://uploads-ssl.webflow.com/5ef0df6b9272f7410180a013/5f287bb0207e2c729c3793fb_University%20Application%20Process%20Infographic%20(1).jpg" alt="How to start an Online Bakery infographic _MightyForms"></p></figure><p>‍</p><p>These tips can work for a new business or if you are transferring your current bakery to an online store.</p><h2><strong>1. Write A Business Plan Specific for Your Online Bakery</strong></h2><p>Going online is easy. Getting results online, that’s a different story. But you can’t start anything without a proper plan first.&nbsp;</p><p>Having a detailed action plan will guide you every step of the way. It also helps you determine and learn to prioritize several important tasks that are part of having a business.&nbsp;</p><p>It doesn’t hurt to create a <a href="https://www.sba.gov/business-guide/plan-your-business/write-your-business-plan">lean business plan</a> at first since it allows you to be more flexible once you start your online bakery.</p><p>After careful review of the resources found in the U.S. Small Business Administration (SBA) website, we summed up how to write a business plan for an online bakery:</p><h3><strong>Value Proposition</strong></h3><p>Any business plan needs a value proposition. In a few words, you should be able to describe what goods you are going to offer. In a bakery case, it will be bread, cakes, donuts, sweets, and other kinds of cottage food. Then you define the range of products you are offering.&nbsp;</p><p>As a bakery, you can offer a large range of products. But, it’s interesting to narrow down and specialize your bakery on a few key bakes.</p><h3><strong>Market Need</strong></h3><p>Always be aware of what the market’s needs are, especially since they can often change. You can open an online bakery but get no results unless you investigate what the market is going for.&nbsp;</p><p>Explore your region to make sure you are not just offering more of the same. Observe if there is any demand for some specific product. Decide what you can offer and how you can do it. You can start your production offering what your region needs more. Sometimes that can be birthday cakes, but it can also be simple daily bread.</p><figure><p><img src="https://uploads-ssl.webflow.com/5ef0df6b9272f7410180a013/5f287f3d6a4df90473d1ad1b_hands-731265_1920.jpg" alt="hands baking"></p></figure><h3><strong>Solution Proposition</strong></h3><p>Now that you investigated what the market’s needs are, it’s time to give a solution. You already know what your region is demanding. Now, give the solution by offering a demanding product. And, of course, something more. You can, as an example, offer personalized cupcakes, vegan options, gluten-free, and so on.</p><h3><strong>Sales System</strong></h3><p>How are you going to sell your products? How are you going to deliver the sold goods? These are questions you must think when building the business plan. After all, you are selling delicate products, and on an internet base. You must have the plan very well-built, predicting any possible trouble you may have. You must decide how is going to be the payment method and if you are going to use an <a href="https://www.mightyforms.com/blog/how-to-create-an-order-form">order form.</a> Are you using Instagram for your sales? A website? Or both? Study your target market and see which way is better for selling.</p><h3><strong>Costs and Expenses</strong></h3><p>In your business plan, you must add any prediction of what you are going to spend during the process. These predictions must include:</p><ul role="list"><li>Kitchen renovation;</li><li>Equipment;</li><li>Supplies;</li><li>Ingredients;</li><li>License fees;</li><li>Insurance.</li></ul><h2><strong>2. Start Focusing On Marketing&nbsp;</strong></h2><p>You want your business to be successful. For this, you must be known, recognized, and seen. Your marketing strategy must focus on target customers. When you have an ideal client and focus any effort on delight them your chance of success is greater. But, what kind of strategy can you use for your online bakery? Here are three examples of how you can do your marketing strategy.<br></p><h3><strong>Create a Website</strong></h3><p>A website is the easiest way to divulge your bakery. Besides, this can be how you sell your products, as well. You are going to display your products on several landing pages. Write some content to go with the product description. You can also add order forms, intake forms, and contact forms to assist your prospect make an order or get in touch with you. Make your business easy to be found online.</p><h3><strong>Use Social Media&nbsp;</strong></h3><p>In a pandemic world where everyone is communicating remotely, it is easy to understand the importance that social media has gained. The past months changed the world and put a new perspective on how business must work. And an online bakery is exactly what people need right now. Use all the tools you have to sell your products.&nbsp;</p><figure><p><img src="https://uploads-ssl.webflow.com/5ef0df6b9272f7410180a013/5f287f7a068aa869efa6c5b6_social-media-1795578_1920.jpg" alt="Social media icons - MightyForms"></p></figure><p>Use social media that focuses more on the visual, like<strong> Pinterest and Instagram,</strong> to show your beautiful merchandise and sell it as well. Instagram is the main social media for food products. Use it without fear. Don’t forget any other social media that exists so you can profit and thrive. Don’t be shine. Use social media in favor of your online bakery.&nbsp;</p><h3><strong>Encourage Word of mouth</strong></h3><p>Word of mouth is still one of the most useful mechanisms of marketing. People that know your work and enjoy it can refer to friends and family. And you can also do it yourself by talking about your online bakery for everyone in your community. Besides asking for friends and family for assistance.&nbsp;Share campaigns and giveaways are two examples on how you can start word of mouth marketing.</p><p>‍<br></p><blockquote><strong>Fast fact: Messenger Apps As Your New Tool For Getting Close To The Customer: </strong>The modern world brings several tools and technologies to help the entrepreneur’s life. Online messengers, such as WhatsApp, Telegram, and Facebook Messenger, are tools that allow you to contact your prospects easily. And make your business open to new customers. For some places, it can help your business create a better set of contact with customers, which means more trust in your business. You can use online messengers to promote your bakery for everyone you have on your contact list and ask for them to do the same. Be aware of which of the messengers works better in your region.</blockquote><h2><strong>3. Define Your Online Bakery Specialty</strong></h2><p>The world is going into specialized markets. So should your online bakery. Your specialty can be personalized frosting, or maybe your products are all vegan or gluten-free. Or you can create your own recipes. Or you can offer products inspired by recipes from other countries. No matter how you do it, as long as you do it.&nbsp;</p><figure><p><img src="https://uploads-ssl.webflow.com/5ef0df6b9272f7410180a013/5f287d75063b890c9bae4dab_stephanie-leblanc-NZH0p2_2kMo-unsplash.jpg" alt="Specialized bakery"></p></figure><h3><strong>Why have a specialty?</strong></h3><p>When you have a specialty,&nbsp; it makes it easier to stand out from your competitors. Focusing on a few types of products, you can get more specific feedback to improve your product, define your business, and become a reference for that specialty.</p><p>Starting as an original niche is going to highlight your business against your backdrop of competitors. That can be the winning card for your bakery. It doesn’t mean that you can’t have various products, it only means that you have one type that is your masterpiece.</p><h2><strong>4. Prepare The Offline Background&nbsp;</strong></h2><p>When you’re starting any business you need to know in advance the cost of every tool and resource you need to get the gears running. In the case of an online bakery, you need not only an online marketing strategy, but you also need to consider the offline background of workspace, tools, and supplies.&nbsp;</p><p><strong>Investigate all the costs of starting your home bakery and the ongoing expenses</strong>. You must have projections of any costs you will have during the production and distribution. And calculate into your business pricing.</p><figure><p><img src="https://uploads-ssl.webflow.com/5ef0df6b9272f7410180a013/5f287fb0b52c819bc38ec2cf_taylor-grote-LqkFX2Km1a0-unsplash.jpg" alt="Cupcakes in oven "></p></figure><p>‍</p><p>Other aspects to consider are:</p><ul role="list"><li><strong>Space. </strong>Any production requires a certain space. Be sure you have the proper place to start your production. It must be clean, sanitized, large enough so you can prepare your tasty treats. Watch over your local regulation as well. See if you can use your home kitchen, or if you need a separate space to start baking.</li><li><strong>Equipment. </strong>If you are going to bake cakes you must have the proper equipment, that is different for cookies, cupcakes, bread, etc. For each kind of specialty, you must be prepared with the proper kind of equipment. Be sure you have the right oven, fridge, and kitchen utensils.</li><li><strong>Employees. </strong>Think about it: <em>Does your business need anyone else to help?</em> Maybe you need someone to make the deliveries or to assist you in baking. No matter the reason, you must be prepared to hire someone if it is the case. Study your business and try to see if or when you are going to start hiring. Again, pay close attention to your state and county laws.</li><li><strong>Supply. </strong>You can’t prepare food without the right ingredients. Put in your account all the supplies you may need to use when cooking. Don’t ever let any of your main ingredients lack in your kitchen. You must have in hand everything you need before starting baking. Organize your space and pantry.</li></ul><h2><strong>5. Register your business</strong></h2><p>At last, but not least, comes the registration of your new business, or the transferred one. It must be registered according to any legal aspect that exists for home bakery and cottage food, both at state and local levels.&nbsp;</p><p><strong>State laws </strong>must be observed. As an example, we have Indiana, where you can’t produce cottage food in your residence and Ohio, where to be considered cottage food it must be made in a residence kitchen. Therefore, look with close attention to understand your own state and local legalization. You can always consult the <a href="https://www.chlpi.org/flpc-releases-cottage-food-laws-united-states-report/">Harvard Law School: Food Law and Policy Clinic (FLPC) report</a>. In this report, they clarify what each state determines for cottage food and home bakery.</p><p>Besides looking for any regulation, you must guarantee that you have licenses, certifications, and health requirements. All to be sure that your business can function properly and legally. For State information about <a href="https://www.mightyforms.com/blog/small-business-forms">how to open a small business</a>, you can consult <a href="https://www.sba.gov/blogs/">the U.S. Small Business Administration.</a></p><h3><strong>Changes in the kitchen or baking space</strong></h3><p>Depending on the state laws for home bakery and cottage food you may need to change aspects from your residence. Some changes are necessary and can guarantee the safety of not only your business but also your family.</p><p>We are talking about installing sprinkler systems and …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mightyforms.com/blog/how-to-start-an-online-bakery-or-transfer-an-existing-one-online">https://www.mightyforms.com/blog/how-to-start-an-online-bakery-or-transfer-an-existing-one-online</a></em></p>]]>
            </description>
            <link>https://www.mightyforms.com/blog/how-to-start-an-online-bakery-or-transfer-an-existing-one-online</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271789</guid>
            <pubDate>Tue, 25 Aug 2020 14:40:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Transparency and Good Intent]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24271786">thread link</a>) | @danso
<br/>
August 25, 2020 | https://boz.com/articles/transparency | <a href="https://web.archive.org/web/*/https://boz.com/articles/transparency">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><p>It is wise to assume <a href="https://en.wikipedia.org/wiki/Hanlon%27s_razor">good
intent</a> of your colleagues. It
is also wise to assume your colleagues may not all do the same for you. Being
transparent can help remove any doubt that you are acting in good faith.</p>
<p>Transparency can be scary. It sometimes means weighing in sooner than you
might otherwise be comfortable, with less information, and with unpolished
thoughts. It often means taking a position and having to revise it later. But
occasionally being wrong in front of others and owning up to it is precisely
what allows us to be trusted as
<a href="https://boz.com/articles/authenticity">authentic</a>.</p>
<p>Transparency is not a mythical state of being. It is a set of simple
practices:</p>
<ul>
<li>Be responsive. At Facebook, in particular, being unresponsive is seen as
very disrespectful. That doesn’t mean people get to hijack your schedule with
any email they send. It means they will get a timely response that sets their
expectations for when they can expect a full response. As a transparency bonus
you may even find it helpful to share what work you are prioritizing instead.</li>
<li>Be open. If you have concerns but wait until a conversation is almost closed
to raise them it can surprise people and invite them to wonder if you have
ulterior motives for derailing the progress of the group. Instead be open
about what you are thinking even if it isn’t fully thought through yet. Just
make sure you preface it with the fact that you are still thinking things
through and may change. That allows others to understand and participate not
only around the concern but also your mental processes.</li>
<li>Be proactive. When you arrive at a position that impacts others they should
ideally hear about it from you. I always tell people if I have feedback for
them they will hear it from me first. Those who have worked with me for a
while can likely vouch that I am as good as my word. That allows people to
feel confident that if they haven’t heard from me then there is nothing new
they need to know. No news really is good news.</li>
<li>Be consistent. Few things create conspiracies faster than a message that is
adapted for different audiences. When people invariably exchange notes and
discover they were told different things their minds immediately jump to
malice.</li>
<li>Communicate at scale. Writing or speaking to larger groups is greater
transparency not only because it extends to more people but because those
people now all have <a href="https://boz.com/articles/mutual-knowledge">mutual
knowledge</a> of your mindset.</li>
</ul>
<p>When it comes to maintaining trust many people work hard to avoid mistakes.
But mistakes do far less damage to trust than secrecy does.</p></section></div></div>]]>
            </description>
            <link>https://boz.com/articles/transparency</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271786</guid>
            <pubDate>Tue, 25 Aug 2020 14:40:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why would you want more than machine language?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24271652">thread link</a>) | @mxek
<br/>
August 25, 2020 | https://blog.deta.sh/posts/assembly/ | <a href="https://web.archive.org/web/*/https://blog.deta.sh/posts/assembly/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <header>
    
    <time datetime="2020-03-05T00:00:00Z">March 05, 2020</time>
  </header>
  

<p><strong><em>(a short history of the birth of assembly)</em></strong></p>

<p>The use of assembly language and an assembler was an idea that evolved at the dawn of early digital <em>stored program computers</em>, in the decade following the Second World War. <a href="https://en.wikipedia.org/wiki/Richard_Hamming">Richard Hamming</a> reports an estimate that the use of assembly language represented a 2x improvement on programmer productivity <a href="#hamming">[p. 31]</a>.</p>

<p>Nonetheless, it took awhile to catch on amongst experienced programmers, many of whom continued to program in the earlier <em>machine code</em>.  Hamming reports of these programmers dismissing assembly as ‘sissy stuff’ and there are legends of towering figures in computing being quite dismissive of it. This piece is a short historical survey of the early development behind initial assembly languages and samples some of these early reactions to it.</p>

<h2 id="programming-before-assembly">Programming Before Assembly</h2>

<p>At the dawn of assembly, the model of computing which was taking shape was that of the <em>stored program computer</em>. The ideas for the <em>stored program computer</em> sprang out of the <a href="https://en.wikipedia.org/wiki/ENIAC">ENIAC Project</a> and its shortcomings.  One of the early shortcomings of the ENIAC was that it required significant hardware modifications each time a new program was run <a href="#campbell">[p.75]</a>.  <a href="https://en.wikipedia.org/wiki/John_von_Neumann">John von Neumann</a> did consulting work on this project and outlined the ideas for improvement from this collaboration with the ENIAC team in the <a href="http://web.eah-jena.de/~kleine/history/machines/VonNeumann-1stDraftReportEDVAC.pdf">initial report on the EDVAC</a>, though there are questions about who should get credit for the ideas <a href="#hamming">[p. 24]</a><a href="#campbell">[p. 77]</a>.</p>

<p>One of the most important of these ideas was to organize the computer such that the program being executed is itself also stored in the computer’s memory–this way, the computer itself did not need to be tediously reconfigured for each new program <a href="#campbell">[p. 75-76]</a>.</p>

<h2 id="what-is-assembly">What is Assembly?</h2>

<p>Stored program computers understand and can execute <em>machine code</em>, code expressed in numerical form (many of the earliest computers in pure binary). Below is a very short snippet of a more modern version of such machine code:</p>

<p><code>6689C3</code></p>

<p>From a human’s perspective, it’s not very intuitive, and if you are not incredibly immersed in a specific set of machine code, it is  <em>meaningless</em>.</p>

<p>In contrast, the below code is something a human with knowledge of English can get some type of idea about, even with little background.</p>

<p><code>mov bx, ax</code></p>

<p>The second snippet is assembly code, which is read by an <em>assembler</em> and translated into the first snippet for execution by a computer.</p>

<p>In <em>Assemblers and Loaders</em>, an assembler is described as <a href="#saloman">[p. 1]</a>:</p>

<blockquote>
<p>… a translator that translates source instructions (in symbolic language) into target instructions (in machine language), on a one to one basis.</p>
</blockquote>

<p>For early <em>stored program computers</em>, humans had to <em>first do this translation</em> themselves <em>before</em> they could execute the programs. The idea behind assembly was to <em>use the machine itself</em> to translate between a more programmer friendly notation and the code the machine could understand, because computers are great at manipulating symbols at a high speed and precision <a href="#campbell">[p. 168]</a>. <a href="https://en.wikipedia.org/wiki/Richard_Hamming">Richard Hamming</a> reports an estimate that the use of assembly language represented a 2x improvement on programmer productivity <a href="#hamming">[p. 31]</a>.</p>

<h2 id="the-development-of-assembly-on-early-stored-program-computers">The Development of Assembly on Early Stored Program Computers</h2>

<p>Inspired by von Neumann and the ideas in the EDVAC report, two British research camps started working on stored program computers at the end of the 1940s, leading to some of the earliest assemblers.</p>

<p><a href="https://en.wikipedia.org/wiki/Andrew_Donald_Booth">Andrew Booth</a> led the ARC project out of Birbeck College, with <a href="https://en.wikipedia.org/wiki/Kathleen_Booth">Kathleen Booth</a> (born as Britten) as an assistant — Kathleen is credited with creating an assembler for the ‘ARC2’. Meanwhile, <a href="https://en.wikipedia.org/wiki/Maurice_Wilkes">Maurice Wilkes</a> led the EDSAC project out of Cambridge with David Wheeler as an assistant — Wheeler is credited with creating the EDSAC’s assembler <a href="#campbell">[p. 81]</a>.</p>

<p>The tedium of translating human symbolic understandings of programs into machine-readable programs led to the early assemblers.</p>

<h3 id="the-arc-project-kathleen-booth">The ARC Project &amp; Kathleen Booth</h3>

<p>Kathleen was working with Andrew on the ARC, a specialized computer for calculating Fourier synteses 12-24x faster than a research student could do using traditional methods <a href="https://www.ams.org/journals/mcom/1954-08-046/S0025-5718-54-99336-9/S0025-5718-54-99336-9.pdf">[p. 102]</a>. After visiting von Neumann in Princeton, they constructed the ARC2, which was a <a href="https://www.i-programmer.info/history/people/1253-andrew-booth.html">‘stored program computer’</a>.</p>

<p>She and her husband released a few publications about this machine in 1947, one of which is <a href="http://www.mt-archive.info/Booth-1947.pdf"><em>General Considerations in the Design of an All Purpose Electronic Digital Computer</em></a>. The second, <em>Coding For A.R.C</em>, is believed to contain her <a href="https://hackaday.com/2018/08/21/kathleen-booth-assembling-early-computers-while-inventing-assembly/">assembly language for the ARC2</a>. There is little documented about this second report and, as far as we know, there is no digital copy of <em>Coding For A.R.C.</em>. Birbeck College only goes as far as to say she <a href="https://www.dcs.bbk.ac.uk/about/history/">‘developed a very early assembly language’</a>.</p>

<h3 id="edsac-david-wheeler">EDSAC &amp; David Wheeler</h3>

<p>The story of David Wheeler and the EDSAC is more widely documented.</p>

<p>As it goes, Maurice Wilkes led the EDSAC project (after visiting the United States and learning about the EDVAC) to launch a stored program computer at Cambridge University. The EDSAC became operational in May 1949 <a href="#campbell">[85]</a>. During this project Wilkes noticed that ‘assembling’ <em>is something computers are well equipped to do;</em> he put David Wheeler on this job for a doctorate project <a href="#campbell">[168-169]</a>.</p>

<p>The result of this project was the <em>Initial Orders</em> program, completed in May 1949, which would translate more human friendly punched codes into binary, and was loaded into memory as a <a href="https://www.cl.cam.ac.uk/~mr10/Edsac/edsacposter.pdf">‘bootstrap program’</a>.</p>

<p>Wikipedia cites the earlier source crediting Kathleen Booth as the inventor of assembly. Her <em>Coding for A.R.C.</em> piece was released in 1947, while Wheeler’s Initial orders came online later in 1949. He is credited by the IEEE Computer Society as having created the first <a href="https://www.computer.org/profiles/david-wheeler">‘assembly language’</a>. As far as we are aware, there is no digital copy of <em>Coding for A.R.C.</em>, and it is something we would love to see come online.</p>

<h3 id="ibms-early-commercial-assemblers">IBMs Early Commercial Assemblers</h3>

<p>In the early 1950s, IBM’s first commercial computers also had assemblers running. These assemblers took another step forwards from the early academics who developed assemblers. The earlier assemblers used more human friendly symbols for ‘operations’, but computer addresses were still fixed in a program’s code. This had the downside that programmers who encountered and corrected bugs needed to re-assign a chain of subsequent addresses by hand or use an alternate method and end up with ‘spaghetti code’ <a href="#hamming">[p. 25]</a>.</p>

<p>With IBM’s assemblers, <em>symbolic</em> addresses were introduced, where the assembler did the work of address assignment for the programmer <a href="https://blog.deta.sh/posts/assembly/(https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4640454)">[p. 116]</a>. Both IBM’s first commercial scientific (<a href="https://en.wikipedia.org/wiki/IBM_701">the 701</a>) and business (<a href="https://en.wikipedia.org/wiki/IBM_650">the 650</a>) computers had assembly languages with symbolic addresses. For the 701, Nathaniel Rochester developed the <a href="https://ia600101.us.archive.org/25/items/symbolic-programming/Image111817152723.facing_text.pdf">*Symbolic Assembly Program (SAP) in 1953</a>. For the 650, Stan Poley <a href="http://www.columbia.edu/cu/computinghistory/650.html">developed SOAP in 1955</a>, which improved the performance of programs by the intelligent assignment of addresses <a href="#saloman">[p. 16]</a>.</p>

<h2 id="early-responses-to-assembly">Early Responses to Assembly</h2>

<p>Though most of the following perspectives are largely anecdotal, they suggest there is evidence that using <em>assembly language</em>, or anything higher than machine code, took time to catch on among practicing programmers and faced tremendous skepticism, even from earlier figures of our story, like Von Neumann (credit to <a href="http://worrydream.com/dbx/">this presentation</a> for the sources).</p>

<p><a href="http://ei.cs.vt.edu/~history/VonNeumann.html">John Lee</a> reports anecdotes from von Neumann himself questioning the use of anything higher than machine code :</p>

<blockquote>
<p>In the 1950’s von Neumann … was confronted with the FORTRAN concept; John Backus remembered von Neumann being unimpressed and that he asked “why would you want more than machine language?” …</p>

<p>… Donald Gillies, one of von Neumann’s students at Princeton, and later a faculty member at the University of Illinois, recalled in the mid-1970’s that the graduates students were being “used” to hand assemble programs into binary for their early machine (probably the IAS machine). He took time out to build an assembler, but when von Neumann found out about he was very angry, saying (paraphrased), “It is a waste of a valuable scientific computing instrument to use it to do clerical work.”</p>
</blockquote>

<p>Richard Hamming, writing about programming on the IBM 701 (the same machine Rochester developed the assembler for) <a href="#hamming">[p. 25]</a>:</p>

<blockquote>
<p>I once spent a full year, with the help of a lady programmer from Bell Telephone Libraries, on one big problem coding in absolute binary for the IBM 701, which used all the 32K registers then available. After that experience I vowed never again would I ask anyone to do such labor. Having heard about a symbolic system from Poughkeepsie, IBM, I ask[ed] her to send for it and to use it on the next problem…As I expected, she reported it was much easier…</p>

<p>So we told everyone about the new method, meaning about 100 people …</p>

<p>… To my knowledge only one person —yes, only one—of all 100 showed any interest!</p>
</blockquote>

<p>He also writes (most probably about <a href="#ibms-early-commercial-assemblers">Rochester’s system for the 701</a>) <a href="#hamming">[p. 26]</a>:</p>

<blockquote>
<p>Finally a more complete, and more useful, Symbolic Assembly Program (SAP) was devised after more years than you are apt to believe … most programmers continued their heroic absolute binary programming. At the time SAP first appeared I would guess about 1% of the older programmers were interested in it—using SAP was “sissy stuff” and a real programmer would not stoop to wasting machine capacity to do the assembly.</p>
</blockquote>

<p>As Rochester developed SAP out of Poughkeepsie for IBM, it raises the question if Hamming’s two anecdotes were referring to one and the same event, and the earlier ‘symbolic system’ was also Rochester’s assembler.</p>

<p>Nonetheless, Hamming estimates an initial interest level of about 1% amongst experienced programmers, despite his report of an estimated 2x productivity improvement.</p>

<h2 id="conclusion">Conclusion</h2>

<p>The anecdotal evidence suggests assembly language was far from an overnight success, despite the advantages it offered. Nonetheless zooming forwards, it’s clear that the idea behind assembly took hold. At a more abstract level, the idea of ‘<em>buffering the user from the machine itself</em>’, most likely using the computers themselves to do so, has …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.deta.sh/posts/assembly/">https://blog.deta.sh/posts/assembly/</a></em></p>]]>
            </description>
            <link>https://blog.deta.sh/posts/assembly/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271652</guid>
            <pubDate>Tue, 25 Aug 2020 14:26:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Best Social Media Posting and Scheduling APIs of 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24271513">thread link</a>) | @gbourne
<br/>
August 25, 2020 | https://www.ayrshare.com/best-social-media-posting-and-scheduling-apis-of-2020/ | <a href="https://web.archive.org/web/*/https://www.ayrshare.com/best-social-media-posting-and-scheduling-apis-of-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-node="5f340663d99e7">
	<div>
		
<p>When you manage your social media presence there are two distinct types of posts: manual and automated. </p>



<p>Manual posting and scheduling is when you type up a post and choose a time for it to be published, usually via a <a href="https://www.techradar.com/best/best-social-media-management-tools">scheduling tool</a> (there are some great ones out there). </p>



<p>Automated posting and scheduling is when system generated data automatically posts to your social media networks via your back-end system using an API. </p>



<p>For example, a game company might auto-post when a gamer enters the top-ten leaderboard. Or a news company’ back-end system sees a new breaking headline and automatically schedules the post without manual intervention. If your system has unique dynamic data you should consider publishing to your networks.</p>







<p>Ideally, all scheduling tools would provide an API to programmatically schedule post, but unfortunately most don’t or have <a href="https://buffer.com/developers/api">removed</a> their API access.</p>



<p>When building <a href="https://www.ayrshare.com/">Ayrshare</a> as an API-first social media posting and scheduling tool, we did a lot of research on the APIs available in the market. We would like to share what we have found. </p>



<p>Each tool is broken down by the site name, tagline, API documentation, and pricing. Pricing will vary depending upon the features selected.</p>







<h2>Top Social Media Network APIs</h2>



<h3>1. <a href="https://www.ayrshare.com/"><span><strong>Ayrshare</strong></span></a></h3>



<p><strong>Tagline:</strong> Powerful APIs that enable you to send social media posts effortlessly.</p>



<p><strong>API Documentation</strong>: <a href="https://docs.ayrshare.com/rest-api/overview">link</a></p>



<p><strong>Pricing</strong>: <a href="https://www.ayrshare.com/#pricing">$4.99</a> a month for full access</p>







<h3>2. <a href="https://hootsuite.com/"><span><strong>HootSuite</strong></span></a></h3>



<p><strong>Tagline:</strong> Easily manage all your social media and get results with Hootsuite.</p>



<p><strong>API Documentation</strong>: <a href="https://platform.hootsuite.com/docs/api/index.html#section/Introduction">link</a></p>



<p><strong>Pricing</strong>: <a href="https://hootsuite.com/plans">$29 to $599</a> a month</p>







<h3>3. <a href="https://hootsuite.com/"><span><strong>Buffer</strong></span></a></h3>



<p><strong>Tagline:</strong> Tell your brand’s story and grow your audience with a publishing, analytics, and engagement platform you can trust.</p>



<p><strong>API Documentation</strong>: <a href="https://buffer.com/developers/api">link</a> – no new developer accounts after 2019</p>



<p><strong>Pricing</strong>: <a href="https://buffer.com/pricing/publish">$15 to $99</a> a month</p>







<h3>4. <strong><a href="https://www.socialoomph.com/"><span>SocialOomph</span></a></strong></h3>



<p><strong>Tagline:</strong> Boost your productivity with advanced post scheduling tools.</p>



<p><strong>API Documentation</strong>: <a href="https://www.socialoomph.com/developers/api/">link</a></p>



<p><strong>Pricing</strong>: <a href="https://www.socialoomph.com/pricing/">$20 to $83</a> a month</p>







<h3>5. <strong><strong><a href="https://amplifr.com/"><span>Amplifr</span></a></strong></strong></h3>



<p><strong>Tagline:</strong> In&nbsp;all social networks from one window, metrics from posts to&nbsp;projects, collaboration and automation of&nbsp;routine.</p>



<p><strong>API Documentation</strong>: <a href="https://amplifr.docs.apiary.io/#">link</a></p>



<p><strong>Pricing</strong>: <a href="https://amplifr.com/en/prices/">$30 to $500 a month</a></p>







<p>If you have thoughts on these tools or know of others we didn’t mention, drop us a <a href="https://www.ayrshare.com/cdn-cgi/l/email-protection#b2c1c7c2c2ddc0c6f2d3cbc0c1dad3c0d79cd1dddf">line</a> to let us know.</p>




	</div>
</div></div>]]>
            </description>
            <link>https://www.ayrshare.com/best-social-media-posting-and-scheduling-apis-of-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271513</guid>
            <pubDate>Tue, 25 Aug 2020 14:12:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Delta Fellowship]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24271478">thread link</a>) | @maxkohnke
<br/>
August 25, 2020 | https://human.capital/deltafellowship | <a href="https://web.archive.org/web/*/https://human.capital/deltafellowship">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
      <!-- ======= About Section ======= -->
      <section id="about">
        <div>
          <div>
            <div>
              <h3>
                $50k to start building something meaningful
              </h3>
              <p>
                  We’ll give you the funds and resources you need to explore
                  your ideas and learn how to be a better founder. This isn’t
                  just about the money—it’s about helping you understand and
                  navigate the venture world.
                </p>
            </div>
            <div>
              <div>
                <ul>
                  <li>
                    A <span>$50k</span> grant
                  </li>
                  <li>
                    Hands-on support from our
                    <span>cofounders</span>
                  </li>
                  <li>
                    Introductions to
                    <span>leaders at our portfolio companies</span>, who can teach you about data infrastructure, hiring your
                    first 5 employees, and other topics you’re interested in
                  </li>
                  <li>
                    Access to a
                    <span>network of college students</span>
                    who are as ambitious and eager to build as you are
                  </li>
                  <li>
                    Exposure to the
                    <span>venture capital</span>
                    world—you’ll see firsthand how Human Capital’s people-first
                    investment approach allows us to evaluate and work with
                    founders across stages
                  </li>
                  <li>
                    <span>Mentorship</span> from
                    other founders, many of whom started their companies in
                    college and went on to raise funding from top tier venture
                    funds
                  </li>
                </ul>
              </div>
            </div>
          </div>
          <hr>
          <div>
            <div>
              <h3>
                Learn from other successful young entrepreneurs
              </h3>
              <p>
                  Being a student founder comes with unique challenges. We’ll
                  pair you with mentors who were in your shoes not long ago—and
                  have since turned their startups into high growth companies.
                </p>
            </div>
          </div>
          <div>
            <div>
              <div>
                <p><img src="https://human.capital/assets/img/contents/members/brex_white.png">
                </p>
                <h6>Henrique Dubugras</h6>
                <p><i><h6>Cofounder</h6></i></p><h6>Stanford (dropped out ‘17)</h6>
              </div>
            </div>
            <div>
              <div>
                <p><img src="https://human.capital/assets/img/contents/members/agora_white.png">
                </p>
                <h6>Maria Rioumine</h6>
                <p><i><h6>Cofounder</h6></i></p><h6>Oxford (graduated ‘14)</h6>
              </div>
            </div>
            <div>
              <div>
                <p><img src="https://human.capital/assets/img/contents/members/bolt_white.png">
                </p>
                <h6>Ryan Breslow</h6>
                <p><i><h6>Cofounder</h6></i></p><h6>Stanford (dropped out ‘14)</h6>
              </div>
            </div>
            <div>
              <div>
                <p><img src="https://human.capital/assets/img/contents/members/vise_white.png">
                </p>
                <h6>Runik Mehotra</h6>
                <p><i><h6>Cofounder</h6></i></p><h6>Penn (dropped out ‘19)</h6>
              </div>
            </div>
          </div>
          <div>
            <div>
              <div>
                <p><img src="https://human.capital/assets/img/contents/members/scale.png">
                </p>
                <h6>Alex Wang</h6>
                <p><i><h6>Founder</h6></i></p><h6>MIT (dropped out ‘16)</h6>
              </div>
            </div>
            <div>
              <div>
                <p><img src="https://human.capital/assets/img/contents/members/vise_white.png">
                </p>
                <h6>Samir Vasavada</h6>
                <p><i><h6>Cofounder</h6></i></p><h6>Pre-college dropout</h6>
              </div>
            </div>
            <div>
              <div>
                <p><img src="https://human.capital/assets/img/contents/members/monthly.png">
                </p>
                <h6>Valentin Perez</h6>
                <p><i><h6>Cofounder</h6></i></p><h6>Brown (graduated ‘18)</h6>
              </div>
            </div>
            <div>
              <div>
                <p><img src="https://human.capital/assets/img/contents/members/switch.png">
                </p>
                <h6>Liana Kadisha Cohn</h6>
                <p><i><h6>Cofounder</h6></i></p><h6>Stanford (graduated ‘16)</h6>
              </div>
            </div>
          </div>
        </div>
      </section>
      <!-- End About Section -->

      <section>
        <div>
          <div>
            <div>
              <h3>
                We’re looking for exceptional people
              </h3>
              <p>
                  We want to get to know you. If you have a problem you’re
                  obsessed with solving, that’s great—but it’s not required, and
                  it’s not what we’re evaluating.
                </p>
            </div>
            <div>
              <div>
                <div>
                  <p>You’re ambitious.</p>
                  <p>
                    You have lofty goals for your future. You’re not content
                    with the conventional. You want to do something different.
                  </p>
                </div>
                <div>
                  <p>You’re innovative.</p>
                  <p>
                    You’re constantly solving the problems you see—building
                    productivity hacks, creatively patching up the hole of your
                    dorm room, leading a new initiative to drive change in your
                    school.
                  </p>
                </div>
                <div>
                  <p>You’re relentless.</p>
                  <p>
                    Starting a company isn’t always easy and fun. It’s a rocky
                    journey of ups and downs. You have to manage uncertainty and
                    push through discomfort.
                  </p>
                </div>
              </div>
            </div>
          </div>
        </div>
      </section>

      <section id="timeline">
        <div>
          <div>
            <div>
              <p>
                Interviews conducted on a rolling basis
              </p>
              
            </div>
          </div>
          <div>
            <div>
              
              <p>
                Interviews conducted on a rolling basis
              </p>
            </div>
          </div>
          <hr>
          <div>
            <p>
              <h3>
                Built for student founders, by student founders
              </h3>
            </p>
            <div>
              <p>
                Our founders, Baris and Armaan, met on the first day of
                international student orientation at Stanford. That year, Baris
                started a web development automation business, while Armaan
                began investing in companies started by his entrepreneurial
                peers.
              </p>
              
              <p>
                Both realized they loved helping students with a cerebral desire
                to have a meaningful, material impact. Sometimes that meant
                guiding them to jobs at high growth startups. Sometimes it meant
                helping them build their own startups (and investing in them).
                Sometimes it was a combination of both.
              </p>
              
              <p>
                The desire to help students make a meaningful impact led to the
                founding of Human Capital. Over the last 5 years, we’ve built
                relationships with more than 5,000 engineers and entrepreneurs
                and spent countless hours helping young founders dissect
                industries, test early betas, and acquire their first customers.
              </p>
              
              <p>
                We’ve invested in six companies that are now worth over $1B
                each, and have over $200M in AUM. And we’re eager to partner
                with more great young founders.
              </p>
            </div>

            <!-- <div class="col-lg-3 content">
              <div class="photo-box"> 
              </div>
              <p class="photo-caption">
                Henrique Dubugras, founder of Brex, at one of the first
                networking events Baris hosted in 2017—back when Human Capital
                was known as Nav Talent, and before Henrique had dropped out to
                focus on Brex full time. Not long after, we placed two of the
                first ten engineers at the company. Brex is now worth $2.6B
              </p>
            </div> -->
          </div>
          <div id="counts">
            <div>
              <div>
                <p><span>$200M+</span>
                </p>
                <p>Assets under management</p>
              </div>
            </div>
            <div>
              <div>
                <p><span>6</span>
                </p>
                <p>
                    Companies with $1B+ valuation in our investment portfolio
                  </p>
              </div>
            </div>
            <div>
              <div>
                <p><span>5,000+</span>
                </p>
                <p>Engineers and founders in our community</p>
              </div>
            </div>
            <div>
              <div>
                <p><span>12</span>
                </p>
                <p>
                    Companies with $1B+ valuation where we’ve placed members as
                    early engineers
                  </p>
              </div>
            </div>
          </div>
        </div>
      </section>

      <!-- ======= Apply now Section ======= -->
      <section id="apply-now">
        
      </section>
      <!-- ======= Apply now Section end======= -->
      <!-- ======= Frequently Asked Questions Section ======= -->
      <section id="faq">
        <div>
          <h3>
            FAQ
          </h3>

          <div>
            <div>
              <h4>Who can apply?</h4>
              <p>
                Incoming, current, and recent undergraduate and graduate
                students.
              </p>
            </div>
            <div>
              <h4>
                Do I need to take a semester off from school?
              </h4>
              <p>
                No, but we recommend it. We expect you to dedicate a significant
                amount of time to the program, but it’s up to you.
              </p>
            </div>
            <div>
              <h4>
                Do I have to drop out of college after the program?
              </h4>
              <p>
                No. You should do what you think is best—whether that means
                going back to college, pursuing your startup idea, or something
                else entirely.
              </p>
            </div>
            <div>
              <h4>
                Are you looking for solo founders or co-founder pairs?
              </h4>
              <p>
                Either. You can apply as a solo founder, but we’ve found most
                successful ventures are built by teams—so if you know someone
                exceptional you’d like to build with, mention them in the
                application and encourage them to apply.
              </p>
            </div>
            <div>
              <h4>When does the program run?</h4>
              <p>
                August through December.
              </p>
            </div>
            <div>
              <h4>
                Can I apply and participate as an international student?
              </h4>
              <p>
                Yes. We hope you’ll apply, no matter what country you live in.
                If you’re selected, you can work from wherever you want. If you
                have a visa, we’ll work with you to find the best way to have
                you participate. (There are tax implications for international
                students that you’ll need to handle since each country has its
                own specific tax policies and regulations, but we’ll work
                through any issues with you together.)
              </p>
            </div>
            <div>
              <h4>
                Do I need to be in San Francisco for the fellowship?
              </h4>
              <p>
                No. Given the …</p></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://human.capital/deltafellowship">https://human.capital/deltafellowship</a></em></p>]]>
            </description>
            <link>https://human.capital/deltafellowship</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271478</guid>
            <pubDate>Tue, 25 Aug 2020 14:08:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Avo Eliminates Biases in Hiring]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24271434">thread link</a>) | @kelseyfecho
<br/>
August 25, 2020 | https://www.avo.app/blog/how-we-hire-at-avo | <a href="https://web.archive.org/web/*/https://www.avo.app/blog/how-we-hire-at-avo">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Every application is reviewed blind to ensure fairness.</p><p>Avo is committed to hiring talent of diverse backgrounds because not only does <a href="https://www.weforum.org/agenda/2019/04/business-case-for-diversity-in-the-workplace/">the data now demonstrate the business validity</a> of having an inclusive workplace, but because it’s the right thing to do.&nbsp;</p><h3>With Systematic Structures Against Bias</h3><p>It is one of my deep passions to combat the unconscious bias that most of us have (I recommend taking the <a href="https://implicit.harvard.edu/implicit/takeatest.html">Harvard managed test for unconscious bias</a>). Unfortunately, as Iris Bohnet discusses in In <a href="https://www.goodreads.com/book/show/27311743-what-works#:~:text=Gender%20equality%20is%20a%20moral%20and%20a%20business%20imperative.&amp;text=Presenting%20research%2Dbased%20solutions%2C%20Iris,and%20the%20lives%20of%20millions.">What Works: Gender Equality by Design</a>, it’s difficult to rewire our brains. She even refers to research showing how we subject ourselves to our pendulum swinging backwards whenever we try to educate ourselves (much like we think we deserve a break from being unbiased after the hard work of learning how not to be biased). Instead, the most efficient tool to combat bias is to structure hiring and compensation processes so we remove any opportunity to act on bias.&nbsp;</p><p>When we looked into how we could make this a reality for hiring at Avo, we found <a href="https://www.beapplied.com/">Applied</a>. It’s a&nbsp; platform designed following best practices to prevent the opportunity for unconscious bias. Instead of focusing on the person’s background, the Applied process asks the candidate to reflect on situations related to the role, and enables a structured, unbiased review of the person’s potential and ability.</p><h3>How We Use Applied At Avo</h3><p>These questions outline situations that may come up – directly or indirectly related to the role. Some of the situations are complicated, and this is a great opportunity to shed a light on how aligned Avo and the candidate are in how to handle them. The answers are then anonymized and randomized for a blind review.. It means that each answer is reviewed individually, without us knowing anything about the candidate, or their other answers.&nbsp;&nbsp;</p><p>When hiring for <em>Growth Marketing</em> we asked what recent campaign for a technical product stood out to them. When hiring for <em>Product Designer</em> we ask how to respond to a customer feature request or inconsiderate feedback from someone in a leadership position. When hiring for <em>Infrastructure Developer</em> we ask how they’d address a design issue in the core data model.&nbsp;&nbsp;</p><p>It’s our job as founders to find highly skilled individuals for each and every role. It’s hard to adequately account for one’s own biases, even when acknowledged and worked against. And as a data scientist, I believe in a systematic solution. That’s why Avo chose Applied’s blind process as a way to ensure fairness throughout the process, which is really important to me, personally.&nbsp;</p><p>Working against bias is more than addressing the obvious gender and race discrimination we face in the tech industry. It’s also a matter of making sure our culture is accessible to anyone who does good work, and good work will be celebrated no matter who does it. There are also those who feel like they might not fit a stereo-type of the industry, or those who live far away from tech-centric cities. And even still, some feel like they may have never been given the opportunity to demonstrate their skills.&nbsp;</p><p>We find that with this process, we’re able to really get a sense of the person’s fit for the role; removing any bias we might have had, consciously or subconsciously, on the person’s age, gender, sexuality, race, nationality, location, or background.&nbsp;</p><p><strong>What ultimately matters is we’re able to hire the right people, fast, and that the people we want to work with are willing to go through this process with us.&nbsp;</strong></p><h3>What do the applicants think?&nbsp;</h3><p>The feedback we’ve received so far has been outstanding. 9 out of 10 would recommend this process – and that includes a lot of people we could not hire. To exemplify, here are a few anonymous quotes from people who have gone through this process:</p><p>"I wish more companies assessed their candidates this way. I hope this eliminates bias."<br></p><p>“Just applied, I LOVED that application process"</p><p>"That fact y'all are actually testing their knowledge is amazing and not just judging a book by the cover, or <em>well</em> – <em>person</em> by a piece of paper (resume!). I like the alternative approach of blind question-answer review and screening for hiring bias!"<br></p><p>"I totally enjoyed this application process compared to other application formats. I'm reflecting and thinking based on the given scenarios. I have learned a lot and I love it."</p><p>We find this dive into our candidates’ problem-solving skills, which ultimately is what we’re hiring them for, has been a huge success. Aligning on ability seems fairer than judging someone based on what they look like or the logos on their CVs. And we found that the people we’ve met in our hiring process love that we let their work stand for itself; regardless of their background, where they’re from, or what they’ve done in the past.&nbsp;</p><div><p>My personal goal for 2020 was to maintain a gender balance in Avo through our 2020 hiring. Now we’ve succeeded in making sure more than 50% of our team is female identifying. This is a rare feat, which I’m proud of. I also understand that this means it’s time to set more aggressive goals. It is imperative to my co-founder, Solvi, and myself, to continue to build inclusive culture at Avo. </p><p>– Stefania Olafsdottir<br>Avo CEO and co-founder</p></div><p><strong>What are you waiting for, we are hiring for two roles!&nbsp;</strong></p><p><a href="https://www.avo.app/jobs"><strong>Now is the time to apply. We want you to join us &gt;&gt;&nbsp;</strong></a></p></div></div>]]>
            </description>
            <link>https://www.avo.app/blog/how-we-hire-at-avo</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271434</guid>
            <pubDate>Tue, 25 Aug 2020 14:02:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You Need a Nemesis]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24271340">thread link</a>) | @thinking_slow_
<br/>
August 25, 2020 | https://www.animalz.co/blog/you-need-a-nemesis/ | <a href="https://web.archive.org/web/*/https://www.animalz.co/blog/you-need-a-nemesis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2280" role="article" itemscope="" itemtype="http://schema.org/BlogPosting">

	

	<div>

		<div>
			<section>
														<p><img src="https://2l4ff1gokdmn317w442ckjyu-wpengine.netdna-ssl.com/wp-content/uploads/intervention/cache/attentie-attentie-ig7vN6OkGNE-unsplash-scaled-e1598344745396-2048x1234-2212294583.jpg">
					</p>
								<!-- wp:paragraph -->
<div><p>It isn’t always enough to cast your company as the hero—sometimes, you also need a villain. </p><p>DHH’s recent spat with Apple turned a pedestrian product launch into an epic battle between a corporate juggernaut and the plucky underdogs of Basecamp. A <a href="https://twitter.com/dhh/status/1275070000814948353?s=20">hundred thousand product sign-ups</a> followed.</p><p>Much of Box’s earliest press coverage can be traced back to a <a href="https://techcrunch.com/2015/01/22/box-has-always-been-about-reshaping-enterprise-software/?guccounter=1&amp;guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;guce_referrer_sig=AQAAAFl7N1icsmzGQEIAh-x7jAIvo5TOrq1tC3fuAZy3v6HFQf0EJcKKYAC1gGUZ_FQ5rE4faMDZBouACHEgy4i-eIi8ZQkqZOrbDWNAMa1kckujCUYiOEQ9nHFU2q4Q9KxaFRQ4oQEAggxM_KG3Wll7xxAx_dB2tUUFhfKO-Spsa_Hf">towering billboard</a> on California’s Route 101, proudly proclaiming: <em>“Box.net is like Sharepoint, but without the servers, setups costs, manuals, downtime, firewall restrictions . . .”</em></p><p>To this day, I can’t think of HubSpot without imagining a shadowy “<a href="https://blog.hubspot.com/blog/tabid/6307/bid/2989/inbound-marketing-vs-outbound-marketing.aspx">outbound marketer</a>” physically cramming spam mail through my letter box.</p><p>These brands are case studies in what Paul Graham called “<a href="https://twitter.com/paulg/status/1273233413261209600?s=20">beef marketing</a>”: find the adversary you have a strategic, beneficial beef with, and cast them as the villain in your story.</p></div>
<!-- /wp:paragraph -->

<!-- wp:more -->
			</section>
		</div>

	</div>

	<div>

		<div>
			<section>
				
<!-- /wp:more -->

<!-- wp:heading -->
<h2>Villains Make Heroes Look Better</h2>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<div><p>HubSpot, Basecamp, and Box understand a core tenet of storytelling: villains exist to make heroes look better.</p><p>Without a force to fear, fight, and eventually overcome, your story isn’t worth telling. Remove Sauron from <em>The Lord of the Rings </em>and you have a flaccid tale of Frodo’s privilege and family squabbles. Without the nemesis of “outbound marketing,” the redemption offered by inbound marketing is meaningless.</p><p>There’s a lot going for the hero vs. nemesis dynamic:</p></div>
<!-- /wp:paragraph -->

<!-- wp:list -->
<ul><li><strong>Build empathy.</strong> A day in the life of your target customer is fraught with frustration, like—in the case of HubSpot’s target audience—an inbox of junk mail, obnoxious telesales callers and internet-ruining pop-up ads. Vilification allows you to call out the struggle, empathize with the reader, and nudge your product into view:<em> “You’re sick of this. So are we. Here’s the product we built to fix it.”</em></li><li><strong>Differentiate. </strong>Most marketing is pretty saccharine. Measured criticism and, heaven forbid, acknowledging the existence of your competitors, can cut through the mix like nothing else. Picking a fight—albeit in a measured, strategic way—is just downright interesting.</li><li><strong>Change your industry.</strong> DHH’s critique of Apple gained traction because of its valid concern: monopoly power. Many of the story’s loudest amplifiers were other company founders who had fallen afoul of seemingly arbitrary judgments from Apple. Criticizing Apple led to Hey’s approval and, according to DHH, it “<a href="https://twitter.com/dhh/status/1276158293375934470?s=20">paves an illuminated path</a>” for other apps to follow.</li></ul>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p>HubSpot, Basecamp, and Box illustrate three different approaches to “beef marketing,” and three different ways you can cast a villain in your own story. They are (in order of ascending spiciness):</p>
<!-- /wp:paragraph -->

<!-- wp:image {"id":2285,"sizeSlug":"large"} -->
<figure><img src="https://2l4ff1gokdmn317w442ckjyu-wpengine.netdna-ssl.com/wp-content/uploads/2020/08/You-Need-a-Nemesis-2.png" alt=""></figure>
<!-- /wp:image -->

<!-- wp:heading -->
<h2>You vs. the Legacy Solution</h2>
<!-- /wp:heading -->

<!-- wp:heading {"level":4} -->
<h4>Spice Level: 🌶️</h4>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<div><p>HubSpot’s vocal opposition to “outbound marketing” is an example of squaring off with a legacy solution—an older, dated, and relatively inefficient way of achieving the same goals as your product.</p><p>Spreadsheets are the classic legacy solution.<a href="https://twitter.com/thinking_slow/status/1255874409086287879?s=20"> As this viral tweet posits</a>, the chances are high that someone, somewhere, is using the humble spreadsheet to achieve pretty much the same thing your product does. In the same way, outbound marketing is just an amalgamation of lots of legacy marketing tactics—like cold calling and direct mail.</p></div>
<!-- /wp:paragraph -->

<!-- wp:html -->
<blockquote><p lang="en" dir="ltr">*spreadsheets* are the main competitor for 90% of software startups</p>— Ryan Law (@thinking_slow) <a href="https://twitter.com/thinking_slow/status/1255874409086287879?ref_src=twsrc%5Etfw">April 30, 2020</a></blockquote> 
<!-- /wp:html -->

<!-- wp:paragraph -->
<div><p>Legacy solutions are soft targets for vilification because they’re often processes or products so old as to be virtually faceless. You can criticize spreadsheets freely: they’re slow, prone to human error, and difficult to scale, and Excel’s board members won’t take offense at the critique. Similarly, outbound marketing is a total straw man: it isn’t a person, or a company, or really even a single process, so there’s nobody to resist the critique.</p><p>As a result, any company can cast a legacy solution as the villain of their story. Many do:</p></div>
<!-- /wp:paragraph -->

<!-- wp:list -->
<ul><li>Coda’s entire go-to-market messaging is built around its opposition to spreadsheets, epitomized by the tagline <em>“</em><a href="https://coda.io/welcome" target="_blank" rel="noreferrer noopener"><em>Enough of this sheet</em></a>.<em>”</em></li><li>Vyond’s animation software <a href="https://www.vyond.com/resources/the-6-best-business-presentation-software-alternatives-to-powerpoint/" target="_blank" rel="noreferrer noopener">takes aim at PowerPoint</a>, another last-generation product in the same vein as Excel.</li><li>Greenlight Guru pits itself against old-fashioned processes and “<a href="https://www.greenlight.guru/blog/legacy-quality-management-systems" target="_blank" rel="noreferrer noopener"><em>the lure of legacy quality management systems</em></a>,<em>”</em> highlighting the pitfalls of using paper or <em>“digital paper”</em> solutions like Google Docs.</li></ul>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p>These legacy solutions are easy enough to find. They’re the products and processes your product is bought to replace, discussed in every sales call and likely still used by laggardly hold-outs. If in doubt—trash-talk the spreadsheet.</p>
<!-- /wp:paragraph -->

<!-- wp:heading -->
<h2><strong>You vs. the Big Guy/Gal</strong></h2>
<!-- /wp:heading -->

<!-- wp:heading {"level":4} -->
<h4>Spice Level: 🌶️🌶️</h4>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<div><p>Basecamp vs. Apple is an example of taking up arms against your industry’s biggest players. It works because most of us <a href="https://hbr.org/2010/11/capitalizing-on-the-underdog-effect">enjoy rooting for the underdog</a>. We like to see small, plucky startups overcoming the odds and beating faceless corporate behemoths.</p><p>In the Apple example, DHH used the ubiquity of a globally recognized brand to raise awareness for a less famous product. His bombastic <a rel="noreferrer noopener" href="https://twitter.com/dhh/status/1272968382329942017?s=20" target="_blank">tweetstorms</a> and <a rel="noreferrer noopener" href="https://m.signalvnoise.com/on-apples-monopoly-power-to-destroy-hey/" target="_blank">blog posts</a> garnered coverage from media outlets like Wired, TechCrunch, and Engadget. By piggybacking on the vaunted Apple brand, Basecamp turned a pedestrian problem—app store regulation—into a huge PR coup.</p></div>
<!-- /wp:paragraph -->

<!-- wp:html -->
<blockquote><p lang="en" dir="ltr">Like any good mafioso, they paid us a visit by phone. Stating that, firstly, that smashing our windows (by denying us the ability to fix bugs) was not a mistake. Then, without even as much of a curtesy euphemism, said they'd burn down our store (remove our app!), lest we paid up.</p>— DHH (@dhh) <a href="https://twitter.com/dhh/status/1272969688507539457?ref_src=twsrc%5Etfw">June 16, 2020</a></blockquote> 
<!-- /wp:html -->

<!-- wp:paragraph -->
<div><p>Like legacy solutions, huge companies are relatively easy targets. A company of Apple’s size is used to criticism and weathers it on a regular basis (as <a href="https://twitter.com/Austen/status/1273236329178869761?s=20">Austen Allred</a> points out, <em>“Apple has plenty of experience with ‘I don’t care what you think’ as a stance”</em>). The blow is softened further by the decision to attack a nebulous, unsexy part of the bigger Apple business—App Store regulation instead of, say, the iPhone.</p><p><a rel="noreferrer noopener" href="https://wistia.com/" target="_blank">Wistia</a> is another company that’s adopted a strategic beef with an industry giant: YouTube. The giant video platform is referred to as a<em> “<a rel="noreferrer noopener" href="https://wistia.com/learn/marketing/where-to-share-your-brands-video-content-besides-youtube" target="_blank">legacy social network</a>,”</em> with warnings made to avoid a<em> “world where Google keeps your traffic, owns your subscribers, and controls their viewing experience.”</em> There’s even a guide that walks the reader through the steps required to <a rel="noreferrer noopener" href="https://wistia.com/learn/marketing/how-to-delete-your-youtube-channel" target="_blank">delete their YouTube channel</a>.</p></div>
<!-- /wp:paragraph -->

<!-- wp:heading -->
<h2><strong>You vs. your Competitors</strong></h2>
<!-- /wp:heading -->

<!-- wp:heading {"level":4} -->
<h4>Spice Level: 🌶️🌶️🌶️</h4>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<div><p>Box took beef marketing to its logical conclusion by leveling criticism at the company’s direct competitors. Instead of tip-toeing, Box went<a href="https://techcrunch.com/2015/01/22/box-has-always-been-about-reshaping-enterprise-software/"> straight for the jugular</a>.</p><p>Many companies are reluctant to acknowledge the existence of their competitors, but loyal customers are not the product of information asymmetry. Most customers already know about your competitors.</p></div>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Against that backdrop, Box understands that an honest critique of the competition is a powerful differentiator. It’s a chance to make the comparison on your terms. It raises awareness for your product among the very customer base you’re trying to court. It’s useful for the customer, and it oozes confidence.<br></p>
<!-- /wp:paragraph -->

<!-- wp:image {"id":2283,"sizeSlug":"large"} -->
<figure><img src="https://2l4ff1gokdmn317w442ckjyu-wpengine.netdna-ssl.com/wp-content/uploads/2020/08/image-10.png" alt="box-billboard.jpg"></figure>
<!-- /wp:image -->

<!-- wp:paragraph -->
<div><p><a href="https://techcrunch.com/2015/01/22/box-has-always-been-about-reshaping-enterprise-software/">Source</a></p><p>Box was able to make these feature comparisons because they took pains to offer a truly competitive product. You can likely do the same: most founders aim to build products that are better and different than anything that’s come before. There’s no need to be coy when you’ve built a best-in-class product—calling out the limitations of competitors is fair game.</p></div>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<div><p>Even without feature parity, direct comparisons can work in your favor: if you’re not strictly <em>better, </em>highlight how you’re <em>different.</em></p><p><a rel="noreferrer noopener" href="https://www.podia.com/" target="_blank">Podia</a> is an example for competitor critique done well. They harness a strategy we call “competitor alternative” content: using the natural search volume for keywords like “<a rel="noreferrer noopener" href="https://www.podia.com/clickfunnels-alternative" target="_blank">clickfunnels alternative</a>” or “<a rel="noreferrer noopener" href="https://www.podia.com/teachable-alternative" target="_blank">teachable alternative</a>” to create search-friendly comparison pages. Each page includes testimonials from post-switch users, a direct feature comparison, and a clear product call-to-action.</p></div>
<!-- /wp:paragraph -->

<!-- wp:heading -->
<h2>Crying Wolf</h2>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<div><p>The power of a beef marketing strategy stems largely from its rarity; few companies call out their rivals, so we take notice when one does. We don’t follow brands that cry wolf, because the strategy loses efficacy with each subsequent crusade (case in point: I’m starting to develop cynicism around Basecamp’s ongoing feud with </p><a href="https://www.animalz.co/blog/thought-leadership-content/"><s>offices</s> <s>meetings</s> <s>email</s> big tech</a><p>).</p><p>If you want to incorporate the power of beef into your marketing, use it sparingly and deliberately.</p></div>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<div><p>Each of the companies covered here—HubSpot, Box, Basecamp, Coda, Wistia, and Podia—spend far more time and energy on the “hero” part of their marketing (building incredible products, adding value through content) than they do the “nemesis” portion. They use villains as a point of contrast—a way of bringing their great work into sharp relief.</p><p><em>H/T to Benyamin Elias for introducing me to the term beef marketing <a rel="noreferrer noopener" href="https://masters.substack.com/p/oatly-picking-a-fight-marketing" target="_blank">in his newsletter</a>.</em></p></div>
<!-- /wp:paragraph -->				<div>
	
	<p><img src="https://2l4ff1gokdmn317w442ckjyu-wpengine.netdna-ssl.com/wp-content/uploads/2019/06/ryanlaw-125x125.png" width="125" height="125" alt="Ryan Law"></p><h5><a href="https://www.animalz.co/blog/author/ryan-law/">
		Ryan Law	</a></h5>

			<a href="https://twitter.com/thinking_slow" target="_blank">
			<svg><use xlink:href="#icon-twitter"></use></svg> Follow @thinking_slow		</a>
	
	<p>Ryan is the Director of Marketing at Animalz, an agency that provides high-end content marketing solutions to SaaS and tech companies.</p>
</div>			</section>
		</div>

		
	</div>

	

</article></div>]]>
            </description>
            <link>https://www.animalz.co/blog/you-need-a-nemesis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271340</guid>
            <pubDate>Tue, 25 Aug 2020 13:52:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tarsnap Podcast episode with FreeBSD ex security officer Colin]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24271291">thread link</a>) | @devrustr
<br/>
August 25, 2020 | https://blog.firosolutions.com/2020/08/tarsnap-podcast/ | <a href="https://web.archive.org/web/*/https://blog.firosolutions.com/2020/08/tarsnap-podcast/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  





<p><img alt="tarsnap security headlines podcast with Colin Percival" src="https://blog.firosolutions.com/tarsnap.png"></p><p>Tarsnap is a backup service running with the slogan “Online backups for the truly paranoid”.<br>
The service has well earned its slogan as a secure backup option.<br>
Created in 2006 by at the time FreeBSD’s security officer Dr. Colin Percival, who<br>
was responsible for FreeBSD’s security advisory.<br>
Colin is not only a successful entrepreneur but also a dedicated FreeBSD user.<br>
After dealing with the pain of running Tarsnap for himself for a while he decided<br>
to follow Paul Graham’s<br>
wisdom of “There are certain things that naturally needs to be companies” and<br>
the Tarsnap company is born
While modern startup companies spend there budget on marketing campaigns, pouring<br>
in Money into Google Adwords and similar service,
Colin focused on building a great product that resulted in its user base adoption.  He
even experimented with google adwords spending around 200 usd, but it didnt<br>
result in any new users. Proving that when
you provide a good value to the market, the market rewards you.</p>

<p>Colin has been getting his hands dirty with FreeBSD in the late 1990’ies<br>
when the firewall in his family house<br>
running openbsd crashed due to disk failure. After changing the disk he<br>
did not manage to<br>
figure out how to install OpenBSD so he went with FreeBSD.   While<br>
studying for his doctrine, he got concern<br>
about security, that led him to use freebsd where he later jumped<br>
on as FreeBSD security officer.<br>
Being the FreeBSD’s security officer gave him knowledge of<br>
security holes before anyone else did and<br>
he needed a secure backup solution for storing his files.<br>
After some head scratching, he decided to<br>
go the startup route and create his own backup solution. After<br>
getting several user requests about having<br>
password-protected key storage, Collin created Tarsnap’s<br>
secure cryptographical solution for<br>
protecting keys called “Scrypt”, which later got picked up by several opensource<br>
projects such as the cryptocurrency project Litecoin.</p>

<p>Colin is a very intelligent and trustworthy person, to<br>
improve security when connecting<br>
and staying connected between machines he creates spiped.<br>
Adding a layer of safety on top of just using regular<br>
ssh, to mitigate attacks and weaknesses caused by OpenSSL.</p>

<p>Because scrypt has a heavy resource need, making it hard for<br>
attackers to crack, it became a more secure alternative then the<br>
standard hash functions we use in modern systems such as sha1 and md5.</p>

<p>The project started to growth and it was soon adopted by various larger companies<br>
such as stripe.</p>

<p>If you are interested in finding and submitting bugs in Tarsnaps<br>
own code base, Colin has put up a Bug bounty<br>
rewarding the people that find all kinds of bugs in the code base, a fun<br>
fact is that a majority of the security bugs<br>
that gets submitted is not found by security researchers looking<br>
for holes but by average developers looking at<br>
the functions in the code.</p>

<p>Today Tarsnap runs on a large set of different systems by a diverse<br>
crowd, providing secure storage of<br>
data thanks to its stable code base and amazon s3.</p>

<p>Colin also donates Tarsnap’s December profit to the opensource<br>
community sponsoring the FreeBSD foundation, the EuroBSD<br>
conference, the bsdcan conference, bsdnow podcast and several other projects.</p>

<p>We are super happy to have Colin as a guest on Security Headlines!
Relax and give it a listen at:</p>







<p><a href="https://anchor.fm/firo-solutions/episodes/A-tarsnap-Special-with-Colin-Percival-eikv06">https://anchor.fm/firo-solutions/episodes/A-tarsnap-Special-with-Colin-Percival-eikv06</a></p>

<h3 id="external-links">External links:</h3>

<p><a href="https://github.com/Tarsnap/spiped">https://github.com/Tarsnap/spiped</a><br>
<a href="https://en.wikipedia.org/wiki/Tarsnap">https://en.wikipedia.org/wiki/Tarsnap</a><br>
<a href="https://en.wikipedia.org/wiki/Scrypt">https://en.wikipedia.org/wiki/Scrypt</a><br>
<a href="https://www.tarsnap.com/spiped.html">https://www.Tarsnap.com/spiped.html</a><br>
<a href="https://www.tarsnap.com/kivaloo.html">https://www.Tarsnap.com/kivaloo.html</a><br>
<a href="https://github.com/Tarsnap/spiped">https://github.com/Tarsnap/spiped</a><br>
<a href="https://www.tarsnap.com/open-source.html">https://www.Tarsnap.com/open-source.html</a><br>
<a href="https://github.com/mendsley/bsdiff">https://github.com/mendsley/bsdiff</a><br>
<a href="https://en.wikipedia.org/wiki/Paul_Graham_(programmer">https://en.wikipedia.org/wiki/Paul_Graham_(programmer</a>)</p>

</div></div>]]>
            </description>
            <link>https://blog.firosolutions.com/2020/08/tarsnap-podcast/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271291</guid>
            <pubDate>Tue, 25 Aug 2020 13:48:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bcrypt Broken Down Step by Step]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24271227">thread link</a>) | @lanecwagner
<br/>
August 25, 2020 | https://qvault.io/2020/08/24/bcrypt-step-by-step/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/08/24/bcrypt-step-by-step/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>Bcrypt is a <a href="https://qvault.io/2019/12/30/very-basic-intro-to-key-derivation-functions-argon2-scrypt-etc/">key derivation function</a>, which can be thought of as a slow <a href="https://qvault.io/2020/01/01/very-basic-intro-to-hash-functions-sha-256-md-5-etc/">hash function</a>. Its purpose is to <em>slowly</em> convert a piece of input data to a fixed-size, deterministic, and unpredictable output. A common use-case is to convert a password into an n-bit cryptographic key, which can then be used for safe authentication. </p>



<p>Here at <a href="https://classroom.qvault.io/">Qvault,</a> we use Bcrypt in our security systems. Bcrypt is a very popular password hashing function, so much so that it’s the hash function we currently teach the implementation of in our <a href="https://classroom.qvault.io/">Practical Cryptography</a> course.</p>



<h2>What Bcrypt Looks Like</h2>



<p>Using Bcrypt on the password <em>myPassword123</em> would produce something like the following:</p>



<pre><strong><em>myPassword123</em> </strong>-&gt;
$2y$12$vUw4OU4EAl4w4vC6/lA33OtDSYGhiIdekdT9iOoSs9/ckwrffaEui</pre>



<p>That output can be used to compare against future hashes against to see if the original data matches.</p>



<h2>Why not compare passwords directly?</h2>



<p>In web development,<em> </em>it is insecure to store user’s passwords in plain text. If an attacker were to gain access to the server’s database they could find raw email/password combinations and use them to attack the same users on other sites. </p>



<p>At the <em>very least</em> we must hash user’s passwords, but hash functions like <a href="https://qvault.io/2020/07/08/how-sha-2-works-step-by-step-sha-256/">SHA-2</a> and MD5 are too fast to be secure. Using a KDF like Bcrypt provides security benefits over fast hashes because it is computationally expensive and slow. If an attacker gains access to a database of password hashes made with fast algorithms it is easy for them to “reverse” the hashes by guessing different inputs and seeing if the outputs match.</p>



<p>For example, let’s say the attacker finds the following entry in a database:</p>



<pre>user@gmail.com 5906ac361a137e2d286465cd6588ebb5ac3f5ae955001100bc41577c3d751764</pre>



<p>They can try hashing common passwords like:</p>



<pre>password1 -&gt;
0b14d501a594442a01c6859541bcb3e8164d183d32937b851835442f69d5c94e
password2 -&gt;
6cf615d5bcaac778352a8f1f3360d23f02f34ec182e259897fd6ce485d7870d4
password3 -&gt; 5906ac361a137e2d286465cd6588ebb5ac3f5ae955001100bc41577c3d751764</pre>



<p><br>The password, <code>password3</code>, produced a matching hash! Now the attacker knows that <code>user@gmail.com</code> is likely to use the password <code>password3</code> on other sites and can go hack other accounts. This is only possible because the attacker is able to quickly compute many hashes per second and guess millions of potential passwords.</p>



<p>A slow KDF like Bcrypt solves this problem.</p>



<h2>Bcrypt Output Format</h2>



<pre>$2a$10$N9qo8uLOickgx2ZMRZoMyeIjZAgcfl7p92ldGxad68LJZdL17lhWy
\___/\__/\_____________________________/\___________________________________/
Alg   Cost                  Salt                                            Hash</pre>



<ul><li><code>2a</code>: The hash algorithm identifier (Bcrypt)</li><li><code>10</code>: Cost factor (2<sup><code>10</code></sup>&nbsp;= 1,024 rounds of key expansion)</li><li><code>N9qo8uLOickgx2ZMRZoMye</code>: 16-byte (128-bit) salt, base64 encoded to 22 characters</li><li><code>IjZAgcfl7p92ldGxad68LJZdL17lhWy</code>: 24-byte (192-bit) hash, base64 encoded to 31 characters</li></ul>



<p>Direct from <a aria-label="Wikipedia (opens in a new tab)" rel="noreferrer noopener nofollow" href="https://en.wikipedia.org/wiki/Bcrypt#Description" target="_blank">Wikipedia</a></p>



<h2>Bcrypt Explained Step by Step</h2>



<p>Bcrypt can be visualized with the following Go-like pseudo code:</p>



<pre><code lang="go">func bcrypt(cost int, salt [16]byte, password [72]byte) (hash string) {
	// Initialize Blowfish state with expensive key setup algorithm
	// This is the slow part of the algorithm
	pEighteenSubkeys, sFourSubBoxes := expensiveBlowfishSetup(cost, salt, password)

	// Repeatedly encrypt the text "OrpheanBeholderScryDoubt" 64 times
	// 24 bytes = three 64-bit blocks
	ctext := "OrpheanBeholderScryDoubt"
	for i := 0; i &lt; 64; i++ {
		// Encrypt using standard Blowfish in ECB mode
		ctext = encryptECB(pEighteenSubkeys, sFourSubBoxes, ctext)
	}

	// return the version, cost, salt, and ctext in the proper format
	return "$2a${cost}${salt}{ctext}"
}</code></pre>



<p>As you can see, Bcrypt depends heavily on the <a href="https://en.wikipedia.org/wiki/Blowfish_(cipher)" rel="noopener">Blowfish</a> cipher. Put simply, Bcrypt is an expensive key expansion coupled with Blowfish encryption.</p>



<p>The <code>expensiveBlowfishSetup</code> function can be understood by following pseudo code:</p>



<pre><code lang="go">// pEighteenSubkeys: array of 18 subkeys
// sFourSubBoxes: Four substitution boxes
// Each S-Box is a 256-length array of uint32
func expensiveBlowfishSetup(cost int, salt [16]byte, password [72]byte) (pEighteenSubkeys [18]uint32, sFourSubBoxes [4][256]uint32) {
	// Initialize arrays
	pEighteenSubkeys := [18]uint32
	sFourSubBoxes := [4][256]uint32

	// Fill pEighteenSubkeys and sFourSubBoxes with the hex digits of pi 
	// This initial state works as in the original Blowfish algorithm
	// it populates the P-array and S-box entries with the fractional part of pi in hexadecimal
	pEighteenSubkeys = fillWithPi(pEighteenSubkeys)
	sFourSubBoxes = fillWithPi(sFourSubBoxes)

	// Permutate P and S based on the password and salt
	pEighteenSubkeys, sFourSubBoxes = expandKey(pEighteenSubkeys, sFourSubBoxes, salt, password)

	// This is the "Expensive" part of the "Expensive Key Setup"
	// Otherwise the key setup would be identical to Blowfish
	// Expand the key an exponentially increasing number of times
	// depending on the cost factor
	for i := 0; i &lt; math.Pow(2, cost); i++ {
		pEighteenSubkeys, sFourSubBoxes = expandKey(pEighteenSubkeys, sFourSubBoxes, 0, password)
		pEighteenSubkeys, sFourSubBoxes = expandKey(pEighteenSubkeys, sFourSubBoxes, 0, salt)
	}

	return pEighteenSubkeys, sFourSubBoxes
}</code></pre>



<p><code>The expandKey function</code> is executed an exponentially increasing number of times depending on the value of the <code>cost</code> parameter. The <code>expandKey</code> function is explained by the following pseudo-code:</p>



<pre><code lang="go">func expandKey(pEighteenSubkeys [18]uint32, sFourSubBoxes [4][256]uint32, salt [16]byte, password [72]byte) (
	pEighteenSubkeys [18]uint32, sFourSubBoxes [4][256]uint32
	) {

	// Mix password into the pEighteenSubkeys array
	// by XORing password with subkeys
	for i := 0; i &lt; 18; i++{
		// treat the password as cyclic, XOR 32 bit chunks of password with subkeys
		pEighteenSubkeys[i] ^= password[i % 18]
	}
 
   // Treat the 128-bit salt as two 64-bit halves 
   saltHalf[0] = salt[0:63]
   saltHalf[1] = salt[64:127]

   // Initialize an 8-byte (64-bit) buffer with all zeros.
   block := [8]byte

   // Mix internal state into P-boxes   
   for i := 0; i &lt; 9; i++ {
	  // XOR 64-bit block with a 64-bit salt half
	  // Each iteration alternating between saltHalf[0], and saltHalf[1]
      block ^= saltHalf[(i-1) mod 2]

	  // Encrypt block using current key schedule with blowfish block encryption
	  block = Encrypt(pEighteenSubkeys, sFourSubBoxes, block)
	  
	  // Split block and use as new subkeys
      pEighteenSubkeys[2*i] = block[0:31]
	  pEighteenSubkeys[2*i + 1] = block[32:63]
   }

   // Mix encrypted state into the internal S-boxes of state
   for i := 0; i &lt; 4; i ++ {
      for j := 0; j &lt; 127; j++ {
		// Encrypt block using blowfish block encryption
		// where salt[i] is 64 bit chunks
        block = Encrypt(pEighteenSubkeys, sFourSubBoxes, block ^ salt[i])
        sFourSubBoxes[2*i] = block[0:31]
		sFourSubBoxes[2*i + 1] = block[32:63]
	  }
	}
    return pEighteenSubkeys, sFourSubBoxes
}</code></pre>



<p>It helps me to visualize the details of the pseudo-code by using a more “real” programming syntax like Go. If that doesn’t help you then take a look at the code on the <a aria-label="Wikipedia (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Bcrypt#Algorithm" target="_blank">Wikipedia</a> page here.</p>



<div><div>
<h2>Thanks For Reading!</h2>



<p>Follow us on Twitter <a href="https://twitter.com/q_vault" rel="noopener">@q_vault</a> if you have any questions or comments</p>



<p>Take game-like coding courses on <a href="https://classroom.qvault.io/#/">Qvault Classroom</a></p>



<p><a href="https://mailchi.mp/5c7f5c281bbe/qvault-newsletter-subscribe" rel="noopener">Subscribe</a> to our Newsletter for more educational articles</p>
</div></div>

		</div></div>]]>
            </description>
            <link>https://qvault.io/2020/08/24/bcrypt-step-by-step/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271227</guid>
            <pubDate>Tue, 25 Aug 2020 13:42:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nbuwe/Forth – A Simple Forth]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24271178">thread link</a>) | @todsacerdoti
<br/>
August 25, 2020 | https://hg.sr.ht/~nbuwe/forth/ | <a href="https://web.archive.org/web/*/https://hg.sr.ht/~nbuwe/forth/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://hg.sr.ht/~nbuwe/forth/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271178</guid>
            <pubDate>Tue, 25 Aug 2020 13:39:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I set my own salary, it blows peoples minds]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24271143">thread link</a>) | @LatteLazy
<br/>
August 25, 2020 | https://granttree.co.uk/i-set-my-own-salary-it-blows-peoples-minds/ | <a href="https://web.archive.org/web/*/https://granttree.co.uk/i-set-my-own-salary-it-blows-peoples-minds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>Happy Bossâ€™s Day! Or is it Merry Bossâ€™s day? Come to think about it, what even is Bossâ€™s day? It sounds like a holiday invented by a search engine or a particularly cloying batch of Hallmark interns.</span></p><p><span>It shouldnâ€™t bother me, I suppose. I’m my own boss, like everyone else at GrantTree. Itâ€™s my day too. So let’s just pretend todayâ€™s a nice excuse for me to buy myself a new mug. We’ll ignore the fact that asking people to thank their boss for being nice is…well…absurd.<br> </span></p><p><span>In truth, there are no â€˜bossesâ€™ at GrantTree. We embrace a unique organisational philosophy called Open Culture, where there are no managers, no subordinates, no hierarchy of personnel. Each employee has autonomous control, or â€˜domainâ€™, over their specific responsibilities. The companyâ€™s functions are assigned to employees (we call them partners) who are interested and qualified to manage them. </span></p><p><span>For example, Iâ€™m in charge of writing GrantTreeâ€™s blog posts. While I can ask my colleagues for their input, Iâ€™m under no obligation to change what I write. There are ways for my colleagues to intervene if I publish something that could damage the company. But otherwise I have free rein. Iâ€™m trusted to do a good job. </span></p><p><span>This isnâ€™t to say thereâ€™s no hierarchy at GrantTree. There is a hierarchy of work. Writing blog posts is part of the work of Marketing, which is part of the work of our Tax Credits business. In this model, work is subordinate to other kinds of work. Blog posts ultimately serve our Tax Credits business, for instance. While still relatively flat, this organisation creates structure.</span></p><p><span>The lack of a â€˜personnel hierarchyâ€™ means each person can make important decisions within their sphere of influence and accountability. We call this system self-management. Self-management has some interesting consequences, aside from the fact I have to write my own Bossâ€™s Day card. For one thing, I canâ€™t get promoted. Not in the traditional sense. Thereâ€™s no â€˜ladderâ€™ to climb. I can choose to take on more responsibility by signing up for more duties, but thereâ€™s no top-down system of appraisal and reward. No one will sit me down in a yearâ€™s time and give me a raise. </span></p><p><span>So what do I do if I deserve a raise? Simple. I give myself one. </span></p><p><span>At GrantTree, we set our own pay. </span></p><p><b>Yes, I really do set my own pay</b></p><p><span>Having partners set their own pay is the ultimate expression of the self-management philosophy. Companies often use self-management as a millennial-baiting euphemism for a handful of fairly superficial freedoms like working remotely or wearing shorts in the office. </span></p><p><span>True self-management goes far beyond relaxing company etiquette. It requires taking control from the upper echelons of management and sewing it into the primary responsibilities of every single employee. Thereâ€™s no better (or more challenging) example of this than empowering staff to adjust their own pay. </span></p><p><span>When I talk to my friends and family about GrantTreeâ€™s radical practices, they give me a suspicious look. But when it comes to the idea of setting my own salary, they look almost aghast. Then they’ll usually ask me â€˜why donâ€™t you just quadruple your salary and be done with it?â€™</span></p><p><span>The simple answer is I, like most people, wouldnâ€™t do that. GrantTree expects partners to act responsibly. Our hiring process thoroughly tests a candidateâ€™s development and maturity. If someone were short-sighted enough to raise their pay to exorbitant levels, they probably wouldn’t be hired in the first place.</span></p><p><span>But moving past this silly example, what would happen if I felt I deserved a reasonable raise? </span></p><p><b>How I change my pay </b></p><p><span>In most jobs, salaries are set by negotiation – a tug of war between company and employee. Salaries are reflections of more than an employeeâ€™s development or market value. They incorporate the strength of both sidesâ€™ bargaining positions and their ability to argue their case. GrantTree removes negotiation from the procedure and places the decision entirely on the shoulders of the partner, via a process called Pay Self-Assessment (PSA for short). Hereâ€™s how it works.</span></p><p><span>There are four stages: We collect data relevant to our salary and performance, we write a proposal for a new salary based on this data, we receive feedback on our proposal and we make a final decision about our pay. </span></p><p><span>1) Data Collection </span></p><p><span>This is where I collect data that will inform my decision about what my salary should be, including information about my performance, my career progression, the market value of my role (i.e. what I could be earning given my skills and experience), and an analysis of the impact my raise will have on the companyâ€™s budgets. Then I look at what this data says. If, for example, the evidence shows I have grown professionally and that the market value for my skills has increased, I can work out a numerical value for my wage increase. Of course, the data could also could lead me to conclude that I should be paid less. PSA isnâ€™t just about raises. Pay decreases are also possible.</span></p><p><span>2) PSA Proposal</span></p><p><span>I then compile this information into a PSA Proposal; a form in which I state my current pay, my proposed new salary, and an explanation for how the data and evidence I have collected supports my proposal for a pay raise. For example, I would point to how the data I have collected indicates professional growth and my market value has increased.</span></p><p><span>3) PSA Feedback</span></p><p><span>A number of my colleagues – those who supplied evidence in the data collection stage – will then review my PSA Proposal to provide feedback and ask questions about the data Iâ€™ve provided. For example, they could suggest that Iâ€™ve misinterpreted the budgetary impact of my proposed wage increase, and that I should lower it. This feedback isnâ€™t binding. Itâ€™s there to advise me on the best course of action, for both me and the company. Â&nbsp;</span></p><p><span>4) PSA Decision</span></p><p><span>Finally, I publish my Pay Decision. This confirms my new salary and also allows me the opportunity to answer questions or concerns my colleagues posed in their feedback to my PSA Proposal. My new salary will take effect the next pay cycle. And voila. Thatâ€™s it. I have my pay raise.</span></p><p><span>The PSA process might seem strange. It did to me, at first. I used to work for a large PR firm where the process for granting raises and promotions was both inscrutable and strictly controlled. But now I can see the benefits of this approach. While a lot of companies underpay employees that have been with them a long time, the PSA process allows us to set our wage at a level that reflects our value to the company.</span></p><p><span>However you prefer to be managed, I hope you feel valued and fairly paid. If you do have a nice manager, maybe get them a card for Bossâ€™s day. Or not. Itâ€™s a silly idea, anyway. </span></p></div></div>]]>
            </description>
            <link>https://granttree.co.uk/i-set-my-own-salary-it-blows-peoples-minds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271143</guid>
            <pubDate>Tue, 25 Aug 2020 13:35:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Robots I Love]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24271121">thread link</a>) | @whatrocks
<br/>
August 25, 2020 | https://www.charlieharrington.com/robots-i-love | <a href="https://web.archive.org/web/*/https://www.charlieharrington.com/robots-i-love">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3>Beware of scissors</h3>
<p>The other day I lopped off a sizeable chunk of my thumbprint while making a robot. The cut? It was one of those bright-red, swiftly-flowing ones, where you're pretty sure you're seeing bone or muscle or some other gross-thing-that-should-probably-stay-inside-your-body. The robot? It was made of cardboard and beer cans:</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/9d940d0f21aec7abb6525a0c3097ef1c/5c744/cardboard.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="cardboard robot" title="cardboard robot" src="https://www.charlieharrington.com/static/9d940d0f21aec7abb6525a0c3097ef1c/a6d36/cardboard.png" srcset="https://www.charlieharrington.com/static/9d940d0f21aec7abb6525a0c3097ef1c/222b7/cardboard.png 163w,
https://www.charlieharrington.com/static/9d940d0f21aec7abb6525a0c3097ef1c/ff46a/cardboard.png 325w,
https://www.charlieharrington.com/static/9d940d0f21aec7abb6525a0c3097ef1c/a6d36/cardboard.png 650w,
https://www.charlieharrington.com/static/9d940d0f21aec7abb6525a0c3097ef1c/e548f/cardboard.png 975w,
https://www.charlieharrington.com/static/9d940d0f21aec7abb6525a0c3097ef1c/5c744/cardboard.png 1206w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p>
<p>This little guy is one of many cardboard robots that I've made over the years. During summers, my sister and I would go to Vineland, New Jersey to stay with my aunt and cousins for a glorious week of catching frogs, playing Sega Genesis, eating spoonfuls of iced tea mix, and arts 'n' crafts.</p>
<p>For some reason, we'd always center on a unique theme each year for our arts 'n' crafts. One summer, it was <a href="https://www.charlieharrington.com/create-wonderful-things-be-good-have-fun">Klutz Press friendship bracelets</a>. Another was god's eyes - we made hundreds. Our proudest summer craft of them all? A "working" cardboard R2-D2. If not for a late '90s winter basement flood, Cardboard Artoo would still be with us today.</p>
<p>I decided to try my hand at making another cardboard robot because I've been thinking a lot about them. Mostly because I'm writing a children's novel about robots, but also cause it's summer and that's the sort of thing you do during summer.</p>
<p>There are all kinds of robots, cardboard and not. But there's a certain sort of robot that makes my gears turn. The rest of this post will review my favorite robots (and the kid who loves them).</p>
<h2>Robots I Love</h2>
<h3>R.O.B. (Robotic Operating Buddy)</h3>
<p>It's a robot... for your original Nintendo. I'm embarassed to admit it, but I've never seen a R.O.B. in real-life, despite scouring every local garage sale in New Jersey for years.</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/e2bd304c9728a8ea5a8c8a3e6c78b650/0a47e/rob.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="rob1" title="rob1" src="https://www.charlieharrington.com/static/e2bd304c9728a8ea5a8c8a3e6c78b650/0a47e/rob.png" srcset="https://www.charlieharrington.com/static/e2bd304c9728a8ea5a8c8a3e6c78b650/222b7/rob.png 163w,
https://www.charlieharrington.com/static/e2bd304c9728a8ea5a8c8a3e6c78b650/ff46a/rob.png 325w,
https://www.charlieharrington.com/static/e2bd304c9728a8ea5a8c8a3e6c78b650/0a47e/rob.png 600w" sizes="(max-width: 600px) 100vw, 600px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://en.wikipedia.org/wiki/R.O.B.">Wikipedia</a></p>
</blockquote>
<p>These Nintendo ads are just perfection. I'm still more excited for the promise of this system than any game console out today.</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/249e6e5d55d9532ba82345dee293de3a/9c538/rob-1.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="rob2" title="rob2" src="https://www.charlieharrington.com/static/249e6e5d55d9532ba82345dee293de3a/6aca1/rob-1.jpg" srcset="https://www.charlieharrington.com/static/249e6e5d55d9532ba82345dee293de3a/d2f63/rob-1.jpg 163w,
https://www.charlieharrington.com/static/249e6e5d55d9532ba82345dee293de3a/c989d/rob-1.jpg 325w,
https://www.charlieharrington.com/static/249e6e5d55d9532ba82345dee293de3a/6aca1/rob-1.jpg 650w,
https://www.charlieharrington.com/static/249e6e5d55d9532ba82345dee293de3a/7c09c/rob-1.jpg 975w,
https://www.charlieharrington.com/static/249e6e5d55d9532ba82345dee293de3a/01ab0/rob-1.jpg 1300w,
https://www.charlieharrington.com/static/249e6e5d55d9532ba82345dee293de3a/9c538/rob-1.jpg 2550w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p>
<p><span>
      <a href="https://www.charlieharrington.com/static/1f2df2dc5f2c9d2e7931bd92c78eef19/a0850/rob-2.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="rob3" title="rob3" src="https://www.charlieharrington.com/static/1f2df2dc5f2c9d2e7931bd92c78eef19/6aca1/rob-2.jpg" srcset="https://www.charlieharrington.com/static/1f2df2dc5f2c9d2e7931bd92c78eef19/d2f63/rob-2.jpg 163w,
https://www.charlieharrington.com/static/1f2df2dc5f2c9d2e7931bd92c78eef19/c989d/rob-2.jpg 325w,
https://www.charlieharrington.com/static/1f2df2dc5f2c9d2e7931bd92c78eef19/6aca1/rob-2.jpg 650w,
https://www.charlieharrington.com/static/1f2df2dc5f2c9d2e7931bd92c78eef19/7c09c/rob-2.jpg 975w,
https://www.charlieharrington.com/static/1f2df2dc5f2c9d2e7931bd92c78eef19/01ab0/rob-2.jpg 1300w,
https://www.charlieharrington.com/static/1f2df2dc5f2c9d2e7931bd92c78eef19/a0850/rob-2.jpg 4096w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p>
<p><span>
      <a href="https://www.charlieharrington.com/static/919afde0ddef82184e8b12c4f32a0574/9c538/rob-3.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="rob4" title="rob4" src="https://www.charlieharrington.com/static/919afde0ddef82184e8b12c4f32a0574/6aca1/rob-3.jpg" srcset="https://www.charlieharrington.com/static/919afde0ddef82184e8b12c4f32a0574/d2f63/rob-3.jpg 163w,
https://www.charlieharrington.com/static/919afde0ddef82184e8b12c4f32a0574/c989d/rob-3.jpg 325w,
https://www.charlieharrington.com/static/919afde0ddef82184e8b12c4f32a0574/6aca1/rob-3.jpg 650w,
https://www.charlieharrington.com/static/919afde0ddef82184e8b12c4f32a0574/7c09c/rob-3.jpg 975w,
https://www.charlieharrington.com/static/919afde0ddef82184e8b12c4f32a0574/01ab0/rob-3.jpg 1300w,
https://www.charlieharrington.com/static/919afde0ddef82184e8b12c4f32a0574/9c538/rob-3.jpg 2550w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://twitter.com/heyphilsummers/status/1199532600911683585">Twitter</a></p>
</blockquote>
<p>R.O.B. only ever worked with two Nintendo games. From what I've read, neither is very fun. But I'm sure there are some great ROM-hacks out there with more robotic operating buddy interactions.</p>
<h3>Johnny 5</h3>
<p>Duh.</p>
<p>Johnny 5 looks a lot like R.O.B., except with more nuclear-weapons. He loves reading, loves input, loves New York City. A loyal friend, and perhaps a bit too gullible for his own good.</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/def1bd3463f03cf94b8a53217bafb621/7723c/johnny5.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="johnny-5" title="johnny-5" src="https://www.charlieharrington.com/static/def1bd3463f03cf94b8a53217bafb621/7723c/johnny5.jpg" srcset="https://www.charlieharrington.com/static/def1bd3463f03cf94b8a53217bafb621/d2f63/johnny5.jpg 163w,
https://www.charlieharrington.com/static/def1bd3463f03cf94b8a53217bafb621/c989d/johnny5.jpg 325w,
https://www.charlieharrington.com/static/def1bd3463f03cf94b8a53217bafb621/7723c/johnny5.jpg 564w" sizes="(max-width: 564px) 100vw, 564px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://synthiam.com/Community/Questions/Original-Movie-Rc-Johnny-5-For-Sale-6415">Synthiam</a></p>
</blockquote>
<p>Major spoiler-alert for Short Circuit 2, but this action sequence gets me every time:</p>
<iframe width="720" height="415" src="https://www.youtube.com/embed/POxMp61Ksbk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<h3>Wall-E</h3>
<p>What do you get when you cross R.O.B., Johnny 5, and a Tonka truck? This lil' garbage-collecting cutie!</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/a0029b6a0a4cd8dce5007aece8b5c0e9/eea4a/walle.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="wall-e" title="wall-e" src="https://www.charlieharrington.com/static/a0029b6a0a4cd8dce5007aece8b5c0e9/6aca1/walle.jpg" srcset="https://www.charlieharrington.com/static/a0029b6a0a4cd8dce5007aece8b5c0e9/d2f63/walle.jpg 163w,
https://www.charlieharrington.com/static/a0029b6a0a4cd8dce5007aece8b5c0e9/c989d/walle.jpg 325w,
https://www.charlieharrington.com/static/a0029b6a0a4cd8dce5007aece8b5c0e9/6aca1/walle.jpg 650w,
https://www.charlieharrington.com/static/a0029b6a0a4cd8dce5007aece8b5c0e9/7c09c/walle.jpg 975w,
https://www.charlieharrington.com/static/a0029b6a0a4cd8dce5007aece8b5c0e9/eea4a/walle.jpg 1280w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://gsouto-digitalteacher.blogspot.com/2012/04/wall-e-as-green-resource-for-earth-day.html">Blogspot</a></p>
</blockquote>
<p>It's probably becoming quite clear that I'm drawn to a rectangular face on a telescopic neck with tread-like wheels. That's just my type.</p>
<p>I also just discovered this video of someone's real-life Wall-E, and it's frightenly real-looking. Maybe this means I'll get to meet a Wall-E one day, hopefully not on a post-apocalyptic wasteland Earth.</p>
<iframe width="720" height="415" src="https://www.youtube.com/embed/7oVSaUWeKt0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<h3>The flying robots from *Batteries Not Included</h3>
<p>I don't remember much about this movie, other than that my sister and I watched the recorded-from-TV VHS tape all the time, and there were these super cute baby flying robots who lived with a bunch of old people in an apartment building in New York City.</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/b82a9f26dcde56c27d022b62cf3e394d/7de01/batteries.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="batteries robots" title="batteries robots" src="https://www.charlieharrington.com/static/b82a9f26dcde56c27d022b62cf3e394d/a6d36/batteries.png" srcset="https://www.charlieharrington.com/static/b82a9f26dcde56c27d022b62cf3e394d/222b7/batteries.png 163w,
https://www.charlieharrington.com/static/b82a9f26dcde56c27d022b62cf3e394d/ff46a/batteries.png 325w,
https://www.charlieharrington.com/static/b82a9f26dcde56c27d022b62cf3e394d/a6d36/batteries.png 650w,
https://www.charlieharrington.com/static/b82a9f26dcde56c27d022b62cf3e394d/7de01/batteries.png 794w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://play.google.com/store/movies/details?id=lfDVLChs2jI&amp;gl=US&amp;utm_source=na_Med&amp;utm_medium=hasem&amp;utm_campaign=MoviesPLA&amp;pcampaignid=MKT-DR-na-us-all-Med-pla-mo-Evergreen-Dec1115-1-movieslibrary&amp;gclid=CjwKCAjwyo36BRAXEiwA24CwGWL_psFBrrF21EnfNQPDkkWrr37zjejRvlynYt1oSgr2cXgp5DmPyhoCppwQAvD_BwE&amp;gclsrc=aw.ds">Google Play Store</a></p>
</blockquote>
<p>I think these robots might actually be aliens, but I'm not sure, so let's keep 'em around.</p>
<h3>2-XL</h3>
<p>I'm all about using robots for learning (see my post on <a href="https://www.charlieharrington.com/mindstorms">Mindstorms, Seymour Papert, and his cute LOGO Turtle robots for teaching kids how to program computers</a>), and 2-XL was my first introduction to robot-powered-learning.</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/e427b0ab3f3772309062f6c535faf3a6/eea4a/2-xl.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="2xl" title="2xl" src="https://www.charlieharrington.com/static/e427b0ab3f3772309062f6c535faf3a6/6aca1/2-xl.jpg" srcset="https://www.charlieharrington.com/static/e427b0ab3f3772309062f6c535faf3a6/d2f63/2-xl.jpg 163w,
https://www.charlieharrington.com/static/e427b0ab3f3772309062f6c535faf3a6/c989d/2-xl.jpg 325w,
https://www.charlieharrington.com/static/e427b0ab3f3772309062f6c535faf3a6/6aca1/2-xl.jpg 650w,
https://www.charlieharrington.com/static/e427b0ab3f3772309062f6c535faf3a6/7c09c/2-xl.jpg 975w,
https://www.charlieharrington.com/static/e427b0ab3f3772309062f6c535faf3a6/eea4a/2-xl.jpg 1280w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://en.wikipedia.org/wiki/2-XL">Wikipedia</a></p>
</blockquote>
<p>We got our 2-XL at a garage sale (garage sales were things of wonder to me as a child). Yes, we had the original 2-XL, the eight-track one. In fact, 2-XL was my first and only interaction with an eight-track system. In the early `90s, Tiger Electronics must have bought 2-XL, and they came out with a cassette-version. </p>
<p><span>
      <a href="https://www.charlieharrington.com/static/b4f82ab27f934ed502846b4686fb90e3/41099/2-xl-cassette.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="2xl cassette version" title="2xl cassette version" src="https://www.charlieharrington.com/static/b4f82ab27f934ed502846b4686fb90e3/41099/2-xl-cassette.jpg" srcset="https://www.charlieharrington.com/static/b4f82ab27f934ed502846b4686fb90e3/d2f63/2-xl-cassette.jpg 163w,
https://www.charlieharrington.com/static/b4f82ab27f934ed502846b4686fb90e3/c989d/2-xl-cassette.jpg 325w,
https://www.charlieharrington.com/static/b4f82ab27f934ed502846b4686fb90e3/41099/2-xl-cassette.jpg 500w" sizes="(max-width: 500px) 100vw, 500px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://en.wikipedia.org/wiki/2-XL">Wikipedia</a></p>
</blockquote>
<p>But I'll always prefer our smart-alecky 8-track 2-XL, and my fond memories of jamming catridges into his belly, wishing that he was a Nintendo Entertainment System instead.</p>
<h3>Mega Man X</h3>
<p>When I was a kid, I was pretty sure that one day I was going to become Mega Man X. Buried alive in a weird time capsule, awokened years later to avenge my creator, upgrading my body with strange new powers.</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/39d29464655aae0ce2f0e13229322f16/41099/mmx.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="Mega Man X" title="Mega Man X" src="https://www.charlieharrington.com/static/39d29464655aae0ce2f0e13229322f16/41099/mmx.jpg" srcset="https://www.charlieharrington.com/static/39d29464655aae0ce2f0e13229322f16/d2f63/mmx.jpg 163w,
https://www.charlieharrington.com/static/39d29464655aae0ce2f0e13229322f16/c989d/mmx.jpg 325w,
https://www.charlieharrington.com/static/39d29464655aae0ce2f0e13229322f16/41099/mmx.jpg 500w" sizes="(max-width: 500px) 100vw, 500px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://www.amazon.co.uk/Mega-Man-Megaman-X/dp/B00004TMBD">Amazon</a></p>
</blockquote>
<p>I'm still waiting for that to happen, but the the mean time, I recently started playing Mega Max X2, and it's hard! I'm four bosses in, haven't found a single upgrade, and only snagged one heart container so far. Wish me luck.</p>
<h3>DUM-E and U</h3>
<p>Robot arms with quirky personalities, built by someone named Tony Stark.</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/653244aa1db702282adae95d91fb4138/41099/starm.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="Stark" title="Stark" src="https://www.charlieharrington.com/static/653244aa1db702282adae95d91fb4138/41099/starm.jpg" srcset="https://www.charlieharrington.com/static/653244aa1db702282adae95d91fb4138/d2f63/starm.jpg 163w,
https://www.charlieharrington.com/static/653244aa1db702282adae95d91fb4138/c989d/starm.jpg 325w,
https://www.charlieharrington.com/static/653244aa1db702282adae95d91fb4138/41099/starm.jpg 500w" sizes="(max-width: 500px) 100vw, 500px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://ironman.fandom.com/wiki/Dum-E_and_U">Fandom</a></p>
</blockquote>
<p>PSA - check out <a href="https://www.amazon.com/gp/product/1250192757/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=whatrocks09-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=1250192757&amp;linkId=041dcc62a5770e833dc59991bf57e5ee">Sourdough by Robin Sloan</a> for a great little novel on robot arms, bread-making, and San Francisco.</p>
<h3>Metal Head</h3>
<p>Two of my favorite things in one terrifying package - turtles and robots:</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/77ae95136bf95ec6a8828bce2a0b9f3f/b8284/metalhead.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="Metal Head" title="Metal Head" src="https://www.charlieharrington.com/static/77ae95136bf95ec6a8828bce2a0b9f3f/6aca1/metalhead.jpg" srcset="https://www.charlieharrington.com/static/77ae95136bf95ec6a8828bce2a0b9f3f/d2f63/metalhead.jpg 163w,
https://www.charlieharrington.com/static/77ae95136bf95ec6a8828bce2a0b9f3f/c989d/metalhead.jpg 325w,
https://www.charlieharrington.com/static/77ae95136bf95ec6a8828bce2a0b9f3f/6aca1/metalhead.jpg 650w,
https://www.charlieharrington.com/static/77ae95136bf95ec6a8828bce2a0b9f3f/7c09c/metalhead.jpg 975w,
https://www.charlieharrington.com/static/77ae95136bf95ec6a8828bce2a0b9f3f/b8284/metalhead.jpg 985w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://turtlepedia.fandom.com/wiki/Metalhead_(IDW)">Fandom</a></p>
</blockquote>
<p>Not to be confused with the always-evil Mechaturtles from the impossible original Nintendo TMNT game:</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/dfd0388a52796c6aa0b6271fa404d8f9/16745/Mechaturtle1.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Mechaturtles" title="Mechaturtles" src="https://www.charlieharrington.com/static/dfd0388a52796c6aa0b6271fa404d8f9/16745/Mechaturtle1.png" srcset="https://www.charlieharrington.com/static/dfd0388a52796c6aa0b6271fa404d8f9/16745/Mechaturtle1.png 78w" sizes="(max-width: 78px) 100vw, 78px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://turtlepedia.fandom.com/wiki/Mechaturtle">Fandom</a></p>
</blockquote>
<h3>Sonic Sam</h3>
<p>I had one of these (it's still in my parent's attic). This guy rolled around our kitchen, flashing its eyes and emitting weird smoke from its mouth.</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/de0408c04849f7c44e84532c3e696f1a/c08c5/robottoy.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="Sonic Sam" title="Sonic Sam" src="https://www.charlieharrington.com/static/de0408c04849f7c44e84532c3e696f1a/c08c5/robottoy.jpg" srcset="https://www.charlieharrington.com/static/de0408c04849f7c44e84532c3e696f1a/d2f63/robottoy.jpg 163w,
https://www.charlieharrington.com/static/de0408c04849f7c44e84532c3e696f1a/c989d/robottoy.jpg 325w,
https://www.charlieharrington.com/static/de0408c04849f7c44e84532c3e696f1a/c08c5/robottoy.jpg 640w" sizes="(max-width: 640px) 100vw, 640px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://www.spotern.com/en/spot/tv/stranger-things/188454/the-robot-magic-mike-ii-from-dustin-henderson-gaten-matarazzo-in-stranger-things-season-3">Spotern</a></p>
</blockquote>
<p>And it's now memorialized in one of my favorite TV shows.</p>
<h3>Robo from Chrono Trigger</h3>
<p>The best JRPG of all time? I think so. I loved Chrono and his gang. I used to draw them all the time. Frog and Robo were my favs.</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/6c22080c421e67c0bac7aee47f76f0de/772e8/robo.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Robo" title="Robo" src="https://www.charlieharrington.com/static/6c22080c421e67c0bac7aee47f76f0de/772e8/robo.png" srcset="https://www.charlieharrington.com/static/6c22080c421e67c0bac7aee47f76f0de/222b7/robo.png 163w,
https://www.charlieharrington.com/static/6c22080c421e67c0bac7aee47f76f0de/772e8/robo.png 200w" sizes="(max-width: 200px) 100vw, 200px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://chrono.fandom.com/wiki/Robo">Fandom</a></p>
</blockquote>
<h3>The Iron Giant</h3>
<p>Sometimes giant robots are gentle and curious. They just want to love and learn. The Iron Giant is one of those robots.</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/2a5c15093914ba94c385d4a49fd0f063/23db2/irongiant.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="Iron Giant" title="Iron Giant" src="https://www.charlieharrington.com/static/2a5c15093914ba94c385d4a49fd0f063/23db2/irongiant.jpg" srcset="https://www.charlieharrington.com/static/2a5c15093914ba94c385d4a49fd0f063/d2f63/irongiant.jpg 163w,
https://www.charlieharrington.com/static/2a5c15093914ba94c385d4a49fd0f063/23db2/irongiant.jpg 269w" sizes="(max-width: 269px) 100vw, 269px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://upload.wikimedia.org/wikipedia/en/d/d3/The_Iron_Giant_poster.JPG">Wikipedia</a></p>
</blockquote>
<p>Kids and robots just go together, like kids and E.T.</p>
<h3>Cozmo</h3>
<p>A programmable robot!</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/0aa53da4daf21c62993620a41767c0a2/1cfc2/cozmo.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Cozmo" title="Cozmo" src="https://www.charlieharrington.com/static/0aa53da4daf21c62993620a41767c0a2/a6d36/cozmo.png" srcset="https://www.charlieharrington.com/static/0aa53da4daf21c62993620a41767c0a2/222b7/cozmo.png 163w,
https://www.charlieharrington.com/static/0aa53da4daf21c62993620a41767c0a2/ff46a/cozmo.png 325w,
https://www.charlieharrington.com/static/0aa53da4daf21c62993620a41767c0a2/a6d36/cozmo.png 650w,
https://www.charlieharrington.com/static/0aa53da4daf21c62993620a41767c0a2/1cfc2/cozmo.png 900w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://www.digitaldreamlabs.com/pages/cozmo">Digital Dream Labs</a></p>
</blockquote>
<p>Cozmo's fatal flaw is how nearly impossible it is to connect your phone to the robot's local wifi service, which is how you are forced to control and interact with Cozmo. The connection process is random, non-deterministic, and saps up most of the time you've allocated to play with Cozmo. Also, Cozmo's parent company recently went out of business, which is a huge bummer for the robot-toy industry.</p>
<p>That said, I've had a lot fun with Cozmo, including <a href="https://www.charlieharrington.com/teaching-my-robot-with-tensorflow">teaching him how to find my toothpaste with a TensorFlow computer vision model</a>.</p>
<h3>Droids</h3>
<p>Okay, the main event. Droids.</p>
<p>The Star Wars folks who put together the droids for A New Hope are complete geniuses. They're dirty, they're resilient, they're loyal, they're funny, they're everywhere. I could go through a whole list of them, cause I really do love them all (GNKs, Artoo, Threepio, IG-88, BB-8, those little mouse-like black boxes in the Death Star), but in a rare dose of restraint, here's my favorite Star Wars droid!</p>
<h4>WED-15-1016</h4>
<p>It's R.O.B. with a longer neck, a blue face, and way more creepy claw arms. You may remember this robot critter from its role in repairing the Millenium Falcon at Hoth Base in Empire Strikes Back. Or at least attempting to repair.</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/da34ef15c6d3d7825f5cff64051e89b3/cb69c/wed-techie.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="wed-technie" title="wed-technie" src="https://www.charlieharrington.com/static/da34ef15c6d3d7825f5cff64051e89b3/cb69c/wed-techie.jpg" srcset="https://www.charlieharrington.com/static/da34ef15c6d3d7825f5cff64051e89b3/d2f63/wed-techie.jpg 163w,
https://www.charlieharrington.com/static/da34ef15c6d3d7825f5cff64051e89b3/cb69c/wed-techie.jpg 320w" sizes="(max-width: 320px) 100vw, 320px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://starwarsataglance.wordpress.com/2014/06/30/wed-1016-teche/">Star Wars At a Glance</a></p>
</blockquote>
<p>I treasuring my WED-15-1016 card from the Star Wars collectible card game, and I'd play it every single one of our daily games in latchkey, no matter what. (Side note: listen to this <a href="http://www.zachtronics.com/podcast/">great Zachtronics podcast</a> episode with one of the designers of the Star Wars and Star Trek collectible card games)</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/42d3d89633a83af49f7eb084c0aa25cc/a414c/wed-card.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="wed-card" title="wed-card" src="https://www.charlieharrington.com/static/42d3d89633a83af49f7eb084c0aa25cc/a414c/wed-card.png" srcset="https://www.charlieharrington.com/static/42d3d89633a83af49f7eb084c0aa25cc/222b7/wed-card.png 163w,
https://www.charlieharrington.com/static/42d3d89633a83af49f7eb084c0aa25cc/a414c/wed-card.png 206w" sizes="(max-width: 206px) 100vw, 206px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="http://www.cardgamedb.com/index.php/starwars/star-wars-card-spoilers/_/the-hoth-cycle/assault-on-echo-base/wed-15-1016-assault-on-echo-base-55-2">Card Game DB</a></p>
</blockquote>
<p>Here is one of WED-15-1016's cousins, a fully tricked-out WED Treadwell with all sorts of terrifying arms and claws:</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/6afe934f96e3f13bbf2ce81b82c3f2c6/0d333/WED-treadwell.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="wed-tread" title="wed-tread" src="https://www.charlieharrington.com/static/6afe934f96e3f13bbf2ce81b82c3f2c6/6aca1/WED-treadwell.jpg" srcset="https://www.charlieharrington.com/static/6afe934f96e3f13bbf2ce81b82c3f2c6/d2f63/WED-treadwell.jpg 163w,
https://www.charlieharrington.com/static/6afe934f96e3f13bbf2ce81b82c3f2c6/c989d/WED-treadwell.jpg 325w,
https://www.charlieharrington.com/static/6afe934f96e3f13bbf2ce81b82c3f2c6/6aca1/WED-treadwell.jpg 650w,
https://www.charlieharrington.com/static/6afe934f96e3f13bbf2ce81b82c3f2c6/7c09c/WED-treadwell.jpg 975w,
https://www.charlieharrington.com/static/6afe934f96e3f13bbf2ce81b82c3f2c6/0d333/WED-treadwell.jpg 1175w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://starwars.fandom.com/wiki/WED_Treadwell_repair_droid/Legends">Fandom</a></p>
</blockquote>
<p>I even found this questionably-real deleted scene from A New Hope showing an impatient Luke Skywalker interacting with a Treadwell on Tattoine:</p>
<iframe width="720" height="415" src="https://www.youtube.com/embed/nDPZfPe5F-w" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<h2>More robots</h2>
<p>So, who did I miss in my list? Data? He's an android, so not exactly a robot. But possibly Mega Man X is an android, so maybe I'm already mixing things up.</p>
<p>Speaking of lists, I also found this gigantic <a href="https://en.wikipedia.org/wiki/List_of_fictional_robots_and_androids">list of fictional robots and androids</a> on Wikipedia.</p>
<p>I'm not-so-secretly hoping that, one day, the robots in my book will be added to this Wikipedia list. Yes, I could edit the Wikipedia page myself, but c'mon, that's not the goal here.</p>
<h2>From cardboard to ciruit boards</h2>
<p>Also, it's high time to upgrade my hobby. I've begun looking into basic robotics kits, and I'll hopefully be constructing some new robotic best friends very soon. Maybe not Maker-Faire worthy, but ya gotta start somewhere.</p></div></div>]]>
            </description>
            <link>https://www.charlieharrington.com/robots-i-love</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271121</guid>
            <pubDate>Tue, 25 Aug 2020 13:32:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gitpod is now Open Source]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24271090">thread link</a>) | @henningcash
<br/>
August 25, 2020 | https://www.gitpod.io/blog/opensource/ | <a href="https://web.archive.org/web/*/https://www.gitpod.io/blog/opensource/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>As of today Gitpod is open source under the AGPL license at <a href="https://github.com/gitpod-io/gitpod" target="_blank" rel="nofollow noopener noreferrer">github.com/gitpod-io/gitpod</a>. This allows the community to participate in the development of Gitpod, provides more transparency and makes it even easier for developers to use and integrate Gitpod in their workflows.</p>
<p>For those of you who know us, this probably does not come as a big surprise. Working in open source is in our DNA and everything we’ve created over the past 10 years, including <a href="https://github.com/eclipse-theia/theia" target="_blank" rel="nofollow noopener noreferrer">Theia</a>, <a href="https://github.com/eclipse/xtext" target="_blank" rel="nofollow noopener noreferrer">Xtext</a>, <a href="https://github.com/eclipse/openvsx" target="_blank" rel="nofollow noopener noreferrer">Open VSX</a> and many other projects have been open source. In fact, Gitpod was our only closed-source project and it is a relief to change that going forward.</p>

<p>Contributing to Gitpod should be easy and accessible for everyone. All contributions are welcome, including pull requests, issues, documentation as well as updates and tweaks, blog posts, tutoials, and more. Please head over to <a href="https://github.com/gitpod-io/gitpod" target="_blank" rel="nofollow noopener noreferrer">Github</a> to find out about the various ways you can contribute and join our <a href="https://community.gitpod.io/" target="_blank" rel="nofollow noopener noreferrer">Gitpod Community</a>.</p>
<p>Over the past year, Gitpod has simplified contributions to many open source projects (see <a href="https://contribute.dev/" target="_blank" rel="nofollow noopener noreferrer">contribute.dev</a> for examples). Today, everyone in our team is excited to share our own streamlined development pipeline including Kubernetes preview deployments, an aggressively cached build system, our own slim and fast CI system and of course Gitpod, which continuously beams us into ready-to-code (and debug) dev environments. <a href="https://github.com/csweichel" target="_blank" rel="nofollow noopener noreferrer">Chris</a> gave a great talk about this setup earlier this year 👇</p>
<div> <p> <iframe title="" src="https://www.youtube.com/embed/dFMpXUsJcGM?rel=0" allowfullscreen=""></iframe> </p> </div>
<p>Naturally, we develop Gitpod in Gitpod. This allows the  whole team  to spin up fully initialized, remote dev environments on any branch at any time. </p>
<p>In line with the <a href="http://cloudscaling.com/blog/cloud-computing/the-history-of-pets-vs-cattle/?utm_source=thenewstack&amp;utm_medium=website&amp;utm_campaign=platform" target="_blank" rel="nofollow noopener noreferrer">pets vs. cattle</a> analogy of the cloud-native world, we treat dev environments as automated (yet customizable) resources you can spin up when you need them and close down (and forget about) when you are done with your task. Once you experience the peace of mind of automated, ephemeral dev environments you never want to go back.</p>
<p>Sven will run a webinar next week on Thursday, where we will showcase how we use Gitpod internally at Gitpod and how much it improves our workflow. Hope to see you there! </p>



<p>The <a href="https://www.gitpod.io/pricing/#" target="_blank" rel="nofollow noopener noreferrer">SaaS offering of gitpod.io</a> remains the easiest way to streamline your development workflows with continuously prebuilt dev environments. </p>
<p>In case you want to host Gitpod on your own infrastructure or private cloud, starting today, Gitpod Self-Hosted is free for unlimited users. Organizations using Gitpod Self-Hosted can purchase an enterprise license in order to get additional features like:</p>
<ul>
<li><a href="https://www.gitpod.io/features/#snapshot" target="_blank" rel="nofollow noopener noreferrer">Snapshots</a> (share a reproducible workspace with your team)</li>
<li><a href="https://www.gitpod.io/features/#share" target="_blank" rel="nofollow noopener noreferrer">Live Share</a> (invite others into your running workspace)</li>
<li><a href="https://www.gitpod.io/features/#prebuilt" target="_blank" rel="nofollow noopener noreferrer">Unlimited Prebuilds</a> (making ephemeral dev environments possible)</li>
<li>Admin Dashboard</li>
</ul>
<p>Offering a paid plan for enterprises makes it possible for us to keep working towards building a new category in developer tooling, which completes modern DevOps pipelines. In the future we will add additional functionality to both the open source code as well our paid offering.</p>
</div></div></div>]]>
            </description>
            <link>https://www.gitpod.io/blog/opensource/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271090</guid>
            <pubDate>Tue, 25 Aug 2020 13:28:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Blinkist's landing page is almost perfect]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24270762">thread link</a>) | @themarcthomas
<br/>
August 25, 2020 | https://www.iammarcthomas.com/videos/blinkist-landing-page | <a href="https://web.archive.org/web/*/https://www.iammarcthomas.com/videos/blinkist-landing-page">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Blinkist know exactly who their customer is – it's CEOs, founders, VCs and other general tech people who are pretty busy and are either looking for a way to increase their knowledge quickly or to read books faster. </p><p>They know how to perfect that customer profile – they make reference to people like Yuval Noah Harari (Sapiens) and other writers like Seth Godin throughout. </p><p>Their free trial explainer is the best I’ve ever seen – this is one of the best illustrations of how much value I'll get from a trial that I've seen yet. </p><p>Their teaser content is expansive – This is so important for product businesses. </p><p>But what’s up with their CTAs? – Seems like a missed opportunity!</p></div></div></div>]]>
            </description>
            <link>https://www.iammarcthomas.com/videos/blinkist-landing-page</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270762</guid>
            <pubDate>Tue, 25 Aug 2020 12:49:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Mathematical Structure of Particle Collisions Comes into View]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24270579">thread link</a>) | @rbanffy
<br/>
August 25, 2020 | http://abstractions.nautil.us/article/606/the-mathematical-structure-of-particle-collisions-comes-into-view | <a href="https://web.archive.org/web/*/http://abstractions.nautil.us/article/606/the-mathematical-structure-of-particle-collisions-comes-into-view">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p><span><br></span><span>W</span>hen particle physicists try to model experiments, they confront an impossible calculation—an infinitely long equation that lies beyond the reach of modern mathematics.&nbsp;<br></p>

<p>Fortunately, they can generate largely accurate predictions without seeing this arcane math all the way through. By cutting the calculation short, scientists at CERNâ€™s Large Hadron Collider in Europe make forecasts that match events they actually observe when they send subatomic particles barreling toward each other around a nearly 17-mile track.</p>
<p>Unfortunately, the era of agreement between forecast and observation may be ending. As measurements grow more precise, the approximation schemes theorists use to make predictions may not be able to keep up.</p>
<p>â€œWeâ€™re getting close to exhausting what can be done,â€� said&nbsp;<a href="https://theory.cern/roster/duhr-claude" target="_blank">Claude Duhr</a>, a particle physicist at CERN.&nbsp;</p>
<p>But&nbsp;<a href="https://link.springer.com/article/10.1007/JHEP02(2019)139" target="_blank">three</a>&nbsp;<a href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.123.201602" target="_blank">papers</a>&nbsp;from a group of physicists led by&nbsp;<a href="https://amplitudesatpadova.wixsite.com/amplitudes-at-padova" target="_blank">Pierpaolo Mastrolia</a>&nbsp;of the University of Padua in Italy and&nbsp;<a href="https://www.ias.edu/scholars/sebastian-mizera" target="_blank">Sebastian Mizera</a>&nbsp;of the Institute for Advanced Study in Princeton, New Jersey, have revealed an underlying mathematical structure in the equations. The structure provides a new way of collapsing interminable terms into just dozens of essential components. Their method may help bring about new levels of predictive accuracy, which theorists desperately need if they are to move beyond the leading but incomplete model of particle physics.</p>
<p>â€œThey have delivered lots of proof-of-concept results which show that this is a very promising technique,â€� Duhr said.</p>
<p>There could be a bigger payoff than improved predictions.&nbsp;</p>
<p>The new method skirts the traditional mathematical slog by directly computing â€œintersection numbers,â€� which some hope could eventually lead to a more elegant description of the subatomic world.&nbsp;</p>
<p>â€œThis is something thatâ€™s not just mathematics,â€� said&nbsp;<a href="https://www.physics.mcgill.ca/~schuot/" target="_blank">Simon Caron-Huot</a>&nbsp;of McGill University, a quantum theorist who is studying the implications of Mastrolia and Mizeraâ€™s work.&nbsp;â€œItâ€™s something thatâ€™s deeply baked into quantum field theory.â€�&nbsp;</p>
<p><strong>An Infinite Loop</strong></p>
<p>When physicists model particle collisions they use a tool called a Feynman diagram, a simple schematic invented by Richard Feynman in the 1940s.</p>
<p>To get a feel for these diagrams, consider a simple particle event: Two quarks streak in, exchange a single gluon as they â€œcollide,â€� then bounce away on their separate trajectories.</p>
<p>In a Feynman diagram the quarksâ€™ paths are represented by â€œlegs,â€� which join to form â€œverticesâ€� when particles interact. Feynman developed rules for turning this cartoon into an equation which calculates the probability that the event actually takes place: You write a specific function for each leg and vertex—generally a fraction involving the particleâ€™s mass and momentum—and multiply everything together. For straightforward scenarios like this one, the calculation might fit on a cocktail napkin.&nbsp;</p>
<figure><img src="https://s3.amazonaws.com/nautilus-vertical/abstractions_5242dbae24adf53fee012a27d96504f9.jpg" alt="nautilus gluon"><figcaption><br><span>Samuel Velasco/Quanta Magazine</span></figcaption></figure>
<p>But the golden rule of quantum theory is to consider all possibilities, and exchanging a simple gluon represents just one among a vast landscape of scenarios that could unfold when two quarks collide. The exchanged gluon might momentarily split into a â€œvirtualâ€� quark pair, for instance, before reconstituting itself in a flash. Two quarks enter and two quarks leave, but a lot can happen in the middle. A full accounting, implying a perfect prediction, would demand an infinite number of diagrams. No one expects perfection, but the key to improving a calculationâ€™s precision is getting further along in the infinite line of events.<strong>&nbsp;</strong><br></p>
<p>And thatâ€™s where physicists are getting stuck.&nbsp;</p>
<p>Zooming in to that hidden center involves virtual particles—quantum fluctuations that subtly influence each interactionâ€™s outcome. The fleeting existence of the quark pair above, like many virtual events, is represented by a Feynman diagram with a closed â€œloop.â€� Loops confound physicists—theyâ€™re black boxes that introduce additional layers of infinite scenarios. To tally the possibilities implied by a loop, theorists must turn to a summing operation known as an integral. These integrals take on monstrous proportions in multi-loop Feynman diagrams, which come into play as researchers march down the line and fold in more complicated virtual interactions.&nbsp;</p>
<p>Physicists have algorithms to compute the probabilities of no-loop and one-loop scenarios, but many two-loop collisions bring computers to their knees. This imposes a ceiling on predictive precision—and on how well physicists can understand what quantum theory says.&nbsp;</p>
<center>
<iframe width="560" height="315" src="https://www.youtube.com/embed/qe7atm1x6Mg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""><span id="selection-marker-1" class="redactor-selection-marker"></span></iframe>
</center>
<p>But there is one small mercy: Physicists donâ€™t need to calculate every last integral in a complicated Feynman diagram because the vast majority can be lumped together.<br></p>
<p>Thousands of integrals can be reduced to just dozens of â€œmaster integrals,â€� which are weighted and added together. But exactly which integrals can be subsumed under which master integrals is itself a hard computational question. Researchers use computers to essentially guess at millions of relationships and laboriously extract the combinations of integrals that matter.</p>
<p>But with intersection numbers, physicists may have found a way of elegantly plucking out the essential information from a sprawling calculation of Feynman integrals.</p>
<p><strong>A Geometric Fingerprint&nbsp;</strong></p>
<p>Mastrolia and Mizeraâ€™s work is rooted in a branch of pure math called algebraic topology, which classifies shapes and spaces. Mathematicians pursue this classification with â€œcohomologyâ€� theories, which allow them to extract algebraic fingerprints from complicated geometric spaces.</p>
<p>â€œItâ€™s kind of a summary, an algebraic gadget that incorporates the essence of the space you want to study,â€� said&nbsp;<a href="https://imag.umontpellier.fr/~dupont/" target="_blank">ClÃ©ment Dupont</a>, a mathematician at the University of Montpellier in France.</p>
<p>Feynman diagrams can be translated into geometric spaces that are amenable to analysis by cohomology. Each point within these spaces might represent one of a multitude of scenarios that could play out when two particles collide.</p>
<p>You might hope, naively, that by taking the cohomology of this space—finding its algebraic structure—you could calculate the weights for the master integrals that support it. But the type of geometric space that characterizes most Feynman diagrams is warped in a way that resists many cohomology calculations.</p>
<p>In 2017, Mizera was struggling to analyze how objects in string theory collide when he stumbled upon tools pioneered by Israel Gelfand and Kazuhiko Aomoto in the 1970s and 1980s as they worked with a type of cohomology called â€œtwisted cohomology.â€� Later that year Mizera met Mastrolia, who realized that these techniques could work for Feynman diagrams too. In 2019,&nbsp;they published three papers that used this cohomology theory to streamline calculations involving simple particle collisions.</p>
<p>Their method takes a family of related physical scenarios, represents it as a geometric space, and calculates the twisted cohomology of that space. â€œThis twisted cohomology has everything to say about the integrals we are interested in,â€� Mizera said.</p>
<p>In particular, the twisted cohomology tells them how many master integrals to expect and what their weights should be. The weights emerge as values they call â€œintersection numbers.â€� In the end, thousands of integrals shrink to a weighted sum of dozens of master integrals.</p>
<p>The cohomology theories that produce these intersection numbers may do more than just ease a computational burden—they could also point to the physical significance of the most important quantities in the calculation.</p>
<p>For example, when a virtual gluon splits into two virtual quarks, the quarksâ€™ possible lifetimes can vary. In the associated geometric space, each point can stand for a different quark lifetime. When researchers compute the weights, they see that scenarios with the longest-lasting virtual particles—that is, cases in which the particles become essentially real—shape the outcome the most.</p>
<p>â€œThatâ€™s the amazing thing about this method,â€� said Caron-Huot. â€œIt reconstructs everything starting from just these rare, special events.â€�</p>
<p>In August 2020,&nbsp;Mizera, Mastrolia and colleagues published&nbsp;<a href="https://arxiv.org/abs/2008.04823" target="_blank">another preprint</a>&nbsp;showing that the technique has matured enough to handle real-world two-loop diagrams. A forthcoming paper by Caron-Huot will push the method further, perhaps bringing three-loop diagrams to heel.</p>
<p>If successful, the technique could help usher in the next generation of theoretical predictions. And, a few researchers suspect, it may even foreshadow a new perspective on reality.</p>

<ul><li> is a journalist covering developments in the physical sciences both on and off the planet. His work has appeared in <span>Scientific American, The Christian Science Monitor</span> and <span>LiveScience</span>, among other publications. Previously, he taught physics and English in Mozambique and Japan, and he has a bachelorâ€™s in physics from Brown University.</li></ul>
<p>Lead image:&nbsp;<a href="https://www.istockphoto.com/video/animation-of-particles-collision-in-hadron-collider-astrophysics-concept-gm1151477191-312085198" target="_blank" rel="noreferrer nofollow" data-is-link="https://www.istockphoto.com/video/animation-of-particles-collision-in-hadron-collider-astrophysics-concept-gm1151477191-312085198">vchal</a></p>
<p>Video: The brilliant physicist Richard Feynman devised a system of line drawings that simplified calculations of particle interactions and helped rescue the field of quantum electrodynamics.&nbsp;Directed by&nbsp;<a href="http://www.bonscifilms.com/" target="_blank">Emily Driscoll</a>&nbsp;and animated by&nbsp;<a href="http://metteilene.com/" target="_blank">Mette Ilene Holmriis&nbsp;</a>for Quanta Magazine.<br></p>





                    <p>Reprinted with permission from <a href="https://www.quantamagazine.org/">Quanta Magazine</a>'s <a href="https://www.quantamagazine.org/category/abstractions/">Abstractions blog</a>.</p>
            </article></div>]]>
            </description>
            <link>http://abstractions.nautil.us/article/606/the-mathematical-structure-of-particle-collisions-comes-into-view</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270579</guid>
            <pubDate>Tue, 25 Aug 2020 12:23:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Low adoption of features and the sad realization]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24270576">thread link</a>) | @damandloi
<br/>
August 25, 2020 | https://agyam.com/low-adoption-and-sad-realization/ | <a href="https://web.archive.org/web/*/https://agyam.com/low-adoption-and-sad-realization/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><main id="main" role="main"> <article id="post-778"><div><div><p>Early in my career, I used to get so excited from hearing client’s complaints that I would instantly start to conceptualize solutions and put them in the backlog, ready to be discussed and pushed in the roadmap. Only later, I started realizing that none of the solutions were getting used as much as I had thought. It would break my heart – How can something I believed in so strongly would not get used by customers?</p><figure><img loading="lazy" width="700" height="467" src="https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash.jpg?resize=700%2C467&amp;ssl=1" alt="New feature, no usage" srcset="https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=1024%2C683&amp;ssl=1 1024w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=300%2C200&amp;ssl=1 300w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=768%2C512&amp;ssl=1 768w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=1536%2C1024&amp;ssl=1 1536w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=2048%2C1365&amp;ssl=1 2048w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=434%2C289&amp;ssl=1 434w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=868%2C579&amp;ssl=1 868w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=1736%2C1157&amp;ssl=1 1736w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?w=1400&amp;ssl=1 1400w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?w=2100&amp;ssl=1 2100w" sizes="(max-width: 700px) 100vw, 700px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=1024%2C683&amp;ssl=1 1024w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=300%2C200&amp;ssl=1 300w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=768%2C512&amp;ssl=1 768w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=1536%2C1024&amp;ssl=1 1536w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=2048%2C1365&amp;ssl=1 2048w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=434%2C289&amp;ssl=1 434w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=868%2C579&amp;ssl=1 868w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=1736%2C1157&amp;ssl=1 1736w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?w=1400&amp;ssl=1 1400w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?w=2100&amp;ssl=1 2100w" data-lazy-src="https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash.jpg?resize=700%2C467&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure><p>I would also try for all sorts of marketing tactics to make it noticeable to users, only to find temporary blip in the adoption. And, when the adoption rate reverts to the mean or does not show significant improvement, I would be worried about its impact on my performance evaluation and promotion.</p><p>After going to multiple phases of this sad realization of low adoption rates, here is how I now think about it:</p><p><strong>Building for adoption</strong></p><ul><li>Customers tell the right problem, but never the right solution.</li><li>Understanding the problem without the context won’t help in adoption. We should not build what the customers have asked or wanted to tell, but what helps them do their job.</li><li>If building what customers did not even know they needed, make sure they have a great experience with the aha moment.</li></ul><p><strong>Increasing adoption</strong></p><ul><li>Guestimate an adoption rate, and keep working towards it after the initial release. No feature/product is perfect in the first release.</li><li>Make a conscious decision of working towards increasing adoption or building a new feature. Sometimes a feature can increase the adoption of a product, and sometimes that feature won’t even get used for the low adoption of the product. Know the minimum feature set required for adoption.</li><li>Recognize that problem lies somewhere else if adoption isn’t increasing after multiple efforts.</li></ul><p><strong>Not all features are equal</strong></p><ul><li>Adoption seems to have an inverse relationship with the type of clients your product has.</li></ul><figure><img loading="lazy" width="700" height="487" src="https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=700%2C487&amp;ssl=1" alt="" srcset="https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=1024%2C713&amp;ssl=1 1024w, https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=300%2C209&amp;ssl=1 300w, https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=768%2C535&amp;ssl=1 768w, https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=434%2C302&amp;ssl=1 434w, https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=868%2C604&amp;ssl=1 868w, https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?w=1257&amp;ssl=1 1257w" sizes="(max-width: 700px) 100vw, 700px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=1024%2C713&amp;ssl=1 1024w, https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=300%2C209&amp;ssl=1 300w, https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=768%2C535&amp;ssl=1 768w, https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=434%2C302&amp;ssl=1 434w, https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=868%2C604&amp;ssl=1 868w, https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?w=1257&amp;ssl=1 1257w" data-lazy-src="https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=700%2C487&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Small clients can easily adopt whereas enterprises take their own time.</figcaption></figure><ul><li>It is ok to have some features build for limited enterprise clients having a disproportionate ratio of product revenue. However, only if the team agrees on the tradeoffs of increased complexity and tech debt.</li><li>Feature adoption also seems to have an inverse relationship with the depth of the product. Features for advanced users can be good differentiators and add to the marketing arsenal, but they remain least used.</li></ul><p><strong>Adoption is breaking inertia</strong></p><ul><li>Customers become habitual to their flows and often ignore new features. We need to break their inertia by making them realize the value and reducing the effort required.</li><li>Consider adoption as an onboarding strategy:<ul><li>`Attract them with multi-channel launch announcements</li><li>Interest them with contextual nudges and making it easy to find</li><li>Increase desire with use cases and testimonials</li><li>Reduce anxiety with upfront help</li><li>Make it easy to perform an action or use the feature</li></ul></li></ul><figure><blockquote><p>Adoption is breaking inertia. It happens when users realize the value outweighs the efforts invested.</p></blockquote></figure><ul><li>For features that increase the overall product value, keep educating customers until new habits are formed. For advanced and specific features, hide them slowly to make way for new features.</li></ul><p>As years go by, I started realizing another truth – Adoption is necessary but not a sufficient condition for the product’s success.</p><hr><pre>Image by <a href="https://unsplash.com/@jonasjacobsson?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Jonas Jacobsson</a>.

* These pointers are applicable equally for feature and product adoption.</pre></div> </div> <nav> « <a href="https://agyam.com/good-product-manager-bad-product-manager/" rel="prev">Good Product Manager and Bad Product Manager by Ben Horowitz</a> </nav></article></main></div></div>]]>
            </description>
            <link>https://agyam.com/low-adoption-and-sad-realization/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270576</guid>
            <pubDate>Tue, 25 Aug 2020 12:22:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't marry your design after the first date]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24270554">thread link</a>) | @todsacerdoti
<br/>
August 25, 2020 | https://tomgamon.com/posts/2020-08-25-dont-marry-your-design/ | <a href="https://web.archive.org/web/*/https://tomgamon.com/posts/2020-08-25-dont-marry-your-design/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Prudent dating advice would be to get to know someone first, before making an everlasting commitment to them. The same advice holds when designing software systems. Don’t marry yourself to your design decisions before at least getting to learn more about them first. Once you have learned their quirks and seen how they act under pressure, you can make a much more informed decision about whether you want to commit. When I am designing new software from scratch I often think about this quote from Uncle Bob.</p><div><blockquote><p>Good architecture allows major architectural decisions to be deferred. The job of an architect is not to make decisions, but to defer those decisions for as long as possible, To allow the program to be built in the absence of decisions so that decisions can be made later with the most possible information</p></blockquote></div><p>At the point you start a new project, you have the least amount of possible knowledge about that project. As The Project Paradox states, this is the worst possible time to be committing to major decisions.</p><blockquote><p lang="en" dir="ltr">The project paradox: making the biggest decisions when knowledge is at it's absolute lowest. <a href="https://t.co/b7zBa4Aq7m">pic.twitter.com/b7zBa4Aq7m</a></p>— Tobias Fors (@tofo) <a href="https://twitter.com/tofo/status/512666251055742977?ref_src=twsrc%5Etfw">September 18, 2014</a></blockquote><p>The more time you spend in the problem space, the more information you can gather and the better decision you can make when the time comes. For example, you can probably start working on your domain logic without knowing how the data is going to be served to the client, or what particular flavour of database you are going to use. Once you have chosen a database, by carefully encapsulating the access logic, if it turns out that this database isn’t the one, it is much easier to part ways amicably.</p><p>Structure your code in such a way that you don’t have to commit to major decisions up front, and perhaps you too can live happily ever after.</p></section></div>]]>
            </description>
            <link>https://tomgamon.com/posts/2020-08-25-dont-marry-your-design/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270554</guid>
            <pubDate>Tue, 25 Aug 2020 12:19:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Practical tips for better microcopy]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24270552">thread link</a>) | @jrdnbwmn
<br/>
August 25, 2020 | https://learnuxd.io/posts/7-practical-tips-for-better-microcopy/ | <a href="https://web.archive.org/web/*/https://learnuxd.io/posts/7-practical-tips-for-better-microcopy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">
        
        <p>Good microcopy is one of the fastest ways to improve an interface. Try doing an audit on your UI with these tips to see how it stands up.</p>

<h2 id="1-use-personal-pronouns">1) Use personal pronouns</h2>

<p>Address the reader instead of just talking out loud. Use the word <em>you</em>. People pay more attention when you talk directly to them.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post1.png">
</figure>

<h2 id="2-start-with-a-verb">2) Start with a verb</h2>

<p>Names for interactive elements should begin with an action verb. The same goes for important copy. Starting with a verb is more direct and engaging.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post2.png">
</figure>

<h2 id="3-prevent-concerns">3) Prevent concerns</h2>

<p>Point out concerning actions before your user can worry about your motives. Be transparent<span>—</span>make sure they understand what they’re doing and why.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post3.png">
</figure>

<h2 id="4-use-natural-language">4) Use natural language</h2>

<p>Write conversationally, like you’re one-on-one. Be professional but get rid of jargon. Use familiar, simple words with a friendly, relaxed tone.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post4.png">
</figure>

<h2 id="5-default-to-active-voice">5) Default to active voice</h2>

<p>Most of the time, active voice is the way to go. It’s easier to understand than passive voice, feels more personal, and is often shorter and stronger.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post5.png">
</figure>

<h2 id="6-show-useful-error-messages">6) Show useful error messages</h2>

<p>Avoid negative, threatening, or overly technical words. Be friendly, show empathy, take the time to explain what’s going on, and be helpful.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post6.png">
</figure>

<h2 id="7-write-iteratively">7) Write iteratively</h2>

<p>We write code iteratively, so why everything else? Things probably won’t be perfect the first time around. Test, refine, ship again. It adds up.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post7.png">
</figure>

<p>Thanks for reading. If you enjoyed the article, sharing on Twitter is really appreciated:</p>

<div>
    <div>
        <blockquote><div lang="en" dir="ltr"><p>Good microcopy is one of the fastest ways to improve an interface. </p><p>Try doing an audit on your UI with these tips to see how it stands up. 👇 <a href="https://t.co/DqRSmVTIvt">pic.twitter.com/DqRSmVTIvt</a></p></div>— Learn UXD (@learn_uxd) <a href="https://twitter.com/learn_uxd/status/1298228761771552773?ref_src=twsrc%5Etfw">August 25, 2020</a></blockquote> 
    </div>
</div>


    </article></div>]]>
            </description>
            <link>https://learnuxd.io/posts/7-practical-tips-for-better-microcopy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270552</guid>
            <pubDate>Tue, 25 Aug 2020 12:19:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stealing local files using Safari Web Share API]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24270538">thread link</a>) | @doener
<br/>
August 25, 2020 | https://blog.redteam.pl/2020/08/stealing-local-files-using-safari-web.html | <a href="https://web.archive.org/web/*/https://blog.redteam.pl/2020/08/stealing-local-files-using-safari-web.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://blog.redteam.pl/2020/08/stealing-local-files-using-safari-web.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270538</guid>
            <pubDate>Tue, 25 Aug 2020 12:16:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Free fantasy books well worth reading]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24270517">thread link</a>) | @pavelegorkin
<br/>
August 25, 2020 | https://bookpub.club/post/10-free-fantasy-books-well-worth-reading-1598356560236x990698759299006500 | <a href="https://web.archive.org/web/*/https://bookpub.club/post/10-free-fantasy-books-well-worth-reading-1598356560236x990698759299006500">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://bookpub.club/post/10-free-fantasy-books-well-worth-reading-1598356560236x990698759299006500</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270517</guid>
            <pubDate>Tue, 25 Aug 2020 12:11:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dataiku Raises $100M In Series D Funding]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24270513">thread link</a>) | @yadavrohit
<br/>
August 25, 2020 | https://www.analyticsdrift.com/dataiku-raises-100m-in-series-d-funding/ | <a href="https://web.archive.org/web/*/https://www.analyticsdrift.com/dataiku-raises-100m-in-series-d-funding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                    <!-- .entry-header -->

                
                        <div>
                                    <p><img width="1024" height="536" src="https://i2.wp.com/www.analyticsdrift.com/wp-content/uploads/2020/08/dataiku-series-d.png?fit=1024%2C536&amp;ssl=1&amp;is-pending-load=1" alt="dataiku series d" loading="lazy" data-lazy-srcset="https://i2.wp.com/www.analyticsdrift.com/wp-content/uploads/2020/08/dataiku-series-d.png?w=1200&amp;ssl=1 1200w, https://i2.wp.com/www.analyticsdrift.com/wp-content/uploads/2020/08/dataiku-series-d.png?resize=300%2C157&amp;ssl=1 300w, https://i2.wp.com/www.analyticsdrift.com/wp-content/uploads/2020/08/dataiku-series-d.png?resize=1024%2C536&amp;ssl=1 1024w, https://i2.wp.com/www.analyticsdrift.com/wp-content/uploads/2020/08/dataiku-series-d.png?resize=768%2C402&amp;ssl=1 768w" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-src="https://i2.wp.com/www.analyticsdrift.com/wp-content/uploads/2020/08/dataiku-series-d.png?fit=1024%2C536&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">                </p>
            
                                            </div>

            

        <!-- end slider-section -->
                                    

    <div>
        <div>
            
<p>Dataiku <a href="https://blog.dataiku.com/dataiku-series-d-fueling-the-future-of-enterprise-ai" target="_blank" rel="noreferrer noopener">announced</a> that it raised $100 million Series D funding for enhancing the platform to empower different data-driven firms to leverage data effectively. Lead by Stripes with Tiger Global Management and joined by existing investors Battery Ventures, CapitalG, Dawn Capital, FirstMark Capital, and ICONIQ. In December 2019, Dataiku was valued at $1.4 billion when Alphabet’s investment firm CapitalG poured money into the company.</p>



<p>In an attempt to democratize Enterprise AI, Dataiku is committed to explore new opportunities and include functionalities in its end-to-end data science platform. There is a sudden change in people behaviour, which has forced organizations to transform the delivery of services and products.</p>



<p><strong>Also Read:</strong> <a href="https://www.analyticsdrift.com/amazon-makes-its-machine-learning-course-free-for-all/" target="_blank" rel="noreferrer noopener">Amazon Makes Its Machine Learning Course Free For All</a></p>



<p>Dataiku wants to capitalize on the opportunity by allowing companies to bring resilience in the difficult times caused by COVID-19 with its robust platform. The firm already enables users to collaborate for data science projects, code to click, model development, model prediction, and model deployment.</p>



<p>Founded in 2013, today, the company has more than 450 employees, 300 customers, and partners around the globe. Due to its feature-rich Dataiku platform, the company has quickly gained traction in the data science domain.</p>



<figure><blockquote><p>I suspect in ten years we won’t be using spreadsheets</p><cite>Florian Douetteau, CEO of Dataiku</cite></blockquote></figure>



<p>Currently, Dataiku’s significant competitors are Alteryx, Databricks, and more, which have made reasonable grounds in the self-service analytics domain. All these platforms, including Dataiku, are working towards democratizing data by allowing users to get insight into information without programming skills.</p>



<p>According to Dataiku, with this Series D funding, the company will continue to simplify its platform for organizations to have hundreds, thousands, or hundreds of thousands of machine learning models in production.</p>
                <div>
                    
                                        
        <div>

                <p><a href="https://www.analyticsdrift.com/author/analyticsdriftgmail-com/"><img alt="" src="https://secure.gravatar.com/avatar/b4013be20eaee509a78cd792d7474854?s=150&amp;r=g" srcset="https://secure.gravatar.com/avatar/b4013be20eaee509a78cd792d7474854?s=300&amp;r=g 2x" height="150" width="150" loading="lazy" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a>
                </p>
                
        </div>

                                            </div>
                                            
                        
	<nav role="navigation" aria-label="Continue Reading">
		<h2>Continue Reading</h2>
		
	</nav>                    </div><!-- .entry-content -->
    </div>
                        </div></div>]]>
            </description>
            <link>https://www.analyticsdrift.com/dataiku-raises-100m-in-series-d-funding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270513</guid>
            <pubDate>Tue, 25 Aug 2020 12:11:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flutter vs. React Native, writing an app with each one: Part 1]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24270496">thread link</a>) | @pixo
<br/>
August 25, 2020 | https://pixo.sh/flutter-vs-react-native-an-app-with-each-one-part-1/ | <a href="https://web.archive.org/web/*/https://pixo.sh/flutter-vs-react-native-an-app-with-each-one-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure><img loading="lazy" width="1024" height="675" src="https://pixo.sh/wp-content/uploads/flutter-vs-react-native-1024x675.jpg" alt="Flutter vs React Native" srcset="https://pixo.sh/wp-content/uploads/flutter-vs-react-native-1024x675.jpg 1024w, https://pixo.sh/wp-content/uploads/flutter-vs-react-native-300x198.jpg 300w, https://pixo.sh/wp-content/uploads/flutter-vs-react-native-768x506.jpg 768w, https://pixo.sh/wp-content/uploads/flutter-vs-react-native.jpg 1489w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
<p>Flutter vs React Native, two widely used cross platform tools, but what should I use?. In this “experiment”, Im going to try to develop the same app, in both frameworks, the goal is to spot differences between them.</p>
<p>No framework is better than the other, they work in different ways, and they fit different developer requirements</p>
<h2>Main differences</h2>
<p>For me the main difference between them, is that React Native run using a Javascript bridge, while Flutter is compiled to native code. This is strictly reflected in the performance of each one.</p>
<figure><table><tbody><tr><td></td><td>Flutter</td><td>React Native</td></tr><tr><td>Language</td><td>Dart</td><td>Javascript</td></tr><tr><td>Compiles native code</td><td>Yes</td><td>No</td></tr><tr><td>Maintained by</td><td>Google</td><td>Facebook</td></tr></tbody></table></figure>
<h2>What im going to build and test</h2>
<p>I will write an app in both frameworks, will be a simple app using the <a aria-label="Rick and Morty API (opens in a new tab)" href="https://rickandmortyapi.com/" target="_blank" rel="noreferrer noopener">Rick and Morty API</a>.</p>
<p>I’m going to test:</p>
<p>Part 1</p>
<ul><li>How fast is to install each framework create and run an app</li><li>Reloading time, both frameworks have hot reloading, a fast one is needed for a seamlessly development workflow</li><li>Development experience, which one offers a better development experience</li></ul>
<p>Part 2</p>
<ul><li>Writing the app in React Native</li><li>Writing the app in Flutter</li></ul>
<p>Part 3</p>
<ul><li>Testability, how easy is to test each app</li><li>Stress test and benchmarking </li></ul>
<h2>Installing Flutter and React Native</h2>
<p>Before I start, i have already installed in my computer Android Studio and Xcode, since they are not related directly to any framework, I won’t include their installation process.</p>
<h3>Flutter process</h3>
<ol><li>Install the <a aria-label="Flutter SDK (opens in a new tab)" href="https://flutter.dev/docs/get-started/install" target="_blank" rel="noreferrer noopener">Flutter SDK</a> (2min)</li><li>Add the Flutter SDK PATH (20s)</li><li>Create the app with flutter create (1min)</li></ol>
<p>The whole process to install Flutter took me 3 minutes, not including the downloading time, also Flutter provides a tool called flutter doctor, which for first installs is really useful it scans our system to check if we have all the needed tools for flutter development (Xcode, Android Studio, Dart plugins, VScode extensions…)</p>
<h3>React Native process</h3>
<p>You can use Expo, but I will use React Native CLI</p>
<ol><li>Install Node.js (3min)</li><li>Install watchman (2min</li><li>Create our app with typescript support (2min)</li></ol>
<p>Total time, 7 mins, and i needed to fix my nvm versions, also first build took about 3 minutes to start.</p>
<p>The Flutter installation process was smoother and faster than the React Native one, probably because RN needs to deal with Node.js under the hood…</p>
<h2>Development experience</h2>
<h3>Hot reloading</h3>
<p>Hot reloading is a must feature for me in web and app development, both, React Native and Flutter have the same feature.</p>
<p>I tested both with the default app which each framework creates</p>
<p>Flutter took 47ms to hot reload the app</p>
<p>React Native took 630ms, because it needs to compile javascript and inject it again with Metro.</p>
<p>Also a note on this, Flutter hot reloading only worked for me if I run my app from VScode, if i run the flutter app from an external terminal, the <strong>automatic hot reloading</strong> doesn’t work, I need to type r to hot reload the app, while in React Native you only need to save the file. I guess this is the only tradeoff. </p>
<h3>Extensions</h3>
<p>I installed Flutter extension for VScode, which is very recommended from the dev team. It adds an extension icon in your sidebar, and you can view your project structure from that tab.</p>
<p>For React Native I added React Native Tools, you can run React Native commands directly from your VScode command palette, but if you run your app from a terminal i don’t find it very useful</p>
<h3>Debugging</h3>
<p>Both frameworks come with their own debugging tools, however, for me Flutter ones are more useful.</p>
<p>One thing I don’t like about React Native debugger is that you can’t see directly your network requests, you need to do some tweaks in order to do that, you can see more info about that <a aria-label="here (opens in a new tab)" href="http://One thing I don't like about React Native debugger is that you can't see directly your network requests, you need to do some tweaks in order to do that, you can see more info about that here" target="_blank" rel="noreferrer noopener">here</a></p>
<p>Here you can see each one debugger GUI</p>
<p>React Native:</p>
<figure><img loading="lazy" width="1024" height="611" src="https://pixo.sh/wp-content/uploads/react-native-debugger-1024x611.png" alt="Flutter vs React Native: React Native debugger" srcset="https://pixo.sh/wp-content/uploads/react-native-debugger-1024x611.png 1024w, https://pixo.sh/wp-content/uploads/react-native-debugger-300x179.png 300w, https://pixo.sh/wp-content/uploads/react-native-debugger-768x458.png 768w, https://pixo.sh/wp-content/uploads/react-native-debugger.png 1452w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>React Native Debugger in Chrome devtools</figcaption></figure>
<p>Flutter:</p>
<figure><img loading="lazy" width="1024" height="610" src="https://pixo.sh/wp-content/uploads/dart-devtools-1024x610.png" alt="Flutter vs React Native: Dart DevTools" srcset="https://pixo.sh/wp-content/uploads/dart-devtools-1024x610.png 1024w, https://pixo.sh/wp-content/uploads/dart-devtools-300x179.png 300w, https://pixo.sh/wp-content/uploads/dart-devtools-768x458.png 768w, https://pixo.sh/wp-content/uploads/dart-devtools.png 1448w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Dart DevTools, running in Chrome</figcaption></figure>
<h2>Conclusion on Part 1</h2>
<p>In terms of development experience, Flutter is the winner for me, the whole process from 0 to app running in my emulator didn’t took more than 10 minutes.</p>
<p>With React Native, compilation took a lot of time (I’m running each one in a 16″ 2019 Macbook Pro), also i had some Node.js issues.</p>
</div></div>]]>
            </description>
            <link>https://pixo.sh/flutter-vs-react-native-an-app-with-each-one-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270496</guid>
            <pubDate>Tue, 25 Aug 2020 12:07:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How We’re Able to Host 1M Sites per MongoDB Cluster]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24270294">thread link</a>) | @MoradSTR
<br/>
August 25, 2020 | https://www.wix.engineering/post/how-we-re-able-to-host-1-million-sites-per-mongodb-cluster | <a href="https://web.archive.org/web/*/https://www.wix.engineering/post/how-we-re-able-to-host-1-million-sites-per-mongodb-cluster">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.16.2"><div dir="ltr"><div><div id="viewer-2s5km"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.wix.engineering/post/how-we-re-able-to-host-1-million-sites-per-mongodb-cluster" data-pin-media="https://static.wixstatic.com/media/66bc35_6432ceb8864c4d3fa46cdd82b1d92263~mv2.jpg/v1/fit/w_3000,h_2000,al_c,q_80/file.png" src="https://static.wixstatic.com/media/66bc35_6432ceb8864c4d3fa46cdd82b1d92263~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-cg3mc">Photo by <a href="https://unsplash.com/@shiroscope?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank" rel="noopener">Shiro hatori</a> on <a href="https://unsplash.com/@shiroscope?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank" rel="noopener">Unsplash</a></p><p id="viewer-7j6po"><span>When you need to store millions of databases with multiple collections efficiently, what do you do? This is exactly the question we asked ourselves a year and a half after having launched </span><a href="https://www.wix.com/corvid" target="_blank" rel="noopener"><span><u>Corvid</u></span></a><span> (then called Wix Code). Corvid is a serverless code platform for site builders, which lets developers add frontend and backend code to their Wix sites.</span></p><p id="viewer-4ipl4"><span>Part of Corvid is a product called </span><a href="https://support.wix.com/en/article/about-wix-data" target="_blank" rel="noopener"><span><u>Wix Data</u></span></a><span>. It allows anyone with a Wix website to own a document database. You can use it in multiple ways - via our visual tools to bind content in your collections to forms, tables, and other components on your site, or just access it via API from code running within your site. Think of it as “Database as a Service”, not unlike Google’s Firestore.</span></p><p id="viewer-4rkm2"><span>Behind the scenes, user data is stored in MongoDB. Which works really well, but as we are soon to find out - everything has its limits. </span></p><p id="viewer-ko3m"><span>Back at the time of Wix Code, every user collection was stored in a dedicated MongoDB collection in one of our server clusters. Each site had (and still has) mapping information, which would tell the cluster and the database where the site data is located. Collections themselves were named according to the following pattern:</span></p><p id="viewer-c6cjv">	<span>{site}@{dev/public}@{collection name}. </span></p><p id="viewer-46pqu"><span>Each user effectively had (and still has, in fact) two databases - DEV, used for development, and PUBLIC - used in the live site. Using this pattern allowed us to query all user collections simply by issuing a listCollections with a </span><a href="https://docs.mongodb.com/manual/reference/command/listCollections/" target="_blank" rel="noopener"><span><u>simple regex pattern</u></span></a><span>.</span></p><div id="viewer-4k4b6"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.wix.engineering/post/how-we-re-able-to-host-1-million-sites-per-mongodb-cluster" data-pin-media="https://static.wixstatic.com/media/66bc35_d2b3693bdfc646d69b6681dbbde77cf6~mv2.png/v1/fit/w_1546,h_710,al_c,q_80/file.png" src="https://static.wixstatic.com/media/66bc35_d2b3693bdfc646d69b6681dbbde77cf6~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-1nap2"><span>But then our product met success and we started growing. The first problems began at around 100k collections.</span></p><p id="viewer-11eou"><span>Even for some low-level operations we would basically list all the physical collections, which involved us querying all of the user collections via a regex query. Naturally, as the number of collections in a single database grew, listing them all started to become slower and slower. At the time all data was stored in a single cluster, all collections were split into a total of 10 databases. The fix here was quite easy - we need to split all the collections into more databases. And that is what we did.</span></p><p id="viewer-6grke"><span>But at the same time another problem had been manifesting - our backups instance started having problems. It was getting really really slow at creating backups and one time even crashed. See, in MongoDB every collection gets its own file handle. And so as the system tried to make backups, it would open a number of handlers which was equal to the number of collections we had.</span></p><p id="viewer-dhikr"><span>This meant we had to:</span></p><ol><li id="viewer-e9piu"><p><span>Increase process file handle limit, just to stop the OS from killing an instance because the limit would be exhausted;</span></p></li><li id="viewer-1t5s9"><p><span>Tune the file handle garbage collection, as Mongo was still having troubles and slowing down as soon as the number of open file handles grew into 10s of k.</span></p></li></ol><p id="viewer-e1b5k"><span>Soon after the backups issue was resolved, we saw this problem manifest in other places - like spinning up a new replica, which didn’t always succeed on the first or even on the second try. Needless to say, neither the engineering team nor the DBAs enjoyed that rush of cortisol induced by just trying to add more capacity to the system.</span></p><p id="viewer-dgeb6"><span>The obvious easy solution was to scale out with more instances, which is exactly what we did at the time. But we were lucky. Our product was growing in popularity and that meant we had to keep adding new instances every time we reached 100k new collections. And a typical website had way more than one.</span></p><p id="viewer-bo4to"><span>A year and a half after the launch, we had lots of MongoDB instances that were sitting mostly idle. Some sites are really big and receive lots of visitors, many others follow a different pattern. A new artist portfolio typically has a collection with around 30 works, which is also similar to a number of items a boat rental company has in its boat inventory collection. Given this and probably more importantly - the enthusiasm of our DBAs having to keep up with our success and having to spin up more MongoDB clusters (did I mention that Wix Data is global and each cluster has quite a few instances all over the world?) - we had to do something.</span></p><p id="viewer-e0h9j"><span>We gathered in the DBA room in one of our Tel Aviv offices and rather quickly a simple and elegant solution sprang into existence. We came home, did the design, ran some testing and the results were more than encouraging.</span></p><p id="viewer-72lq"><span><strong>Introducing “Multi-tenant Storage”</strong></span></p><p id="viewer-b83pf"><span>In the next few months we implemented what we called “multi-tenant storage”. </span></p><div id="viewer-34rej"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.wix.engineering/post/how-we-re-able-to-host-1-million-sites-per-mongodb-cluster" data-pin-media="https://static.wixstatic.com/media/66bc35_117e6df56c2448a9a5b174f37876d7f7~mv2.png/v1/fit/w_1550,h_700,al_c,q_80/file.png" src="https://static.wixstatic.com/media/66bc35_117e6df56c2448a9a5b174f37876d7f7~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-b3ra"><span>While MongoDB wasn’t great at storing a million of collections (MongoDB actually made some progress in </span><a href="https://www.mongodb.com/presentations/scaling-mongodb-to-a-million-collections" target="_blank" rel="noopener"><span><u>this area</u></span></a><span> since then), it’s great at storing a few with millions of documents. And that was the basis for our solution. Storing data from multiple sites in a single collection. Thus document primary key has become:</span></p><p id="viewer-1sebm"><span><em>{</em></span>
  <span><em>site &lt;- site identification,</em></span></p><p id="viewer-4bde5">  <span><em>database &lt;- sandbox or live, </em></span></p><p id="viewer-61ftj">  <span><em>collectionName &lt;- the name of the user collection,</em></span></p><p id="viewer-1c944">  <span><em>_id &lt;- the id of the item</em></span></p><p id="viewer-6krnu"> <span><em>}</em></span></p><p id="viewer-bqn2i"><span>That meant our queries by <em>_id</em> were still fast, we could store multiple tenants in a single collection without overloading MongoDB and could also easily add indexes for everyone on the common part of the schema. For example, we added an index on our default sort key (item creation date). On top of that we implemented a tenant allocation system which allocates new tenants in the least used collections. </span></p><p id="viewer-2g8b6"><span>By keeping collections fairly small (&lt;50GB) we are also able to avoid increased read and write latency. </span></p><p id="viewer-5r0b3"><span>We also kept the ability to relocate tenants to dedicated storage to accommodate larger sites that could benefit from such isolation. For example, we can apply custom indexes or even move a tenant to a dedicated cluster.</span></p><p id="viewer-4t4bn"><span>This will sound quite obvious - but it’s important to know your tools, their strengths and weaknesses. By adjusting our storage to make use of the strengths of MongoDB we are now able to host 1 million sites and many more collections per MongoDB cluster running a few replicas around the globe (on quite a few </span><span>r4.</span><span>2xlarge</span><span> AWS instances). </span></p><div id="viewer-2mq8v"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.wix.engineering/post/how-we-re-able-to-host-1-million-sites-per-mongodb-cluster" data-pin-media="https://static.wixstatic.com/media/66bc35_7fc07cb46f3e4b8c9f361b4b9c617756~mv2.jpg/v1/fit/w_1650,h_1611,al_c,q_80/file.png" src="https://static.wixstatic.com/media/66bc35_7fc07cb46f3e4b8c9f361b4b9c617756~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-edat7">This post was written by <strong>Giedrius Graževičius</strong></p><p id="viewer-17itc"><strong>For more engineering updates and insights:</strong> </p><ul><li id="viewer-e21l"><p>Follow us on: <a href="https://twitter.com/WixEng" target="_blank" rel="noopener"><u>Twitter</u></a> | <a href="https://www.facebook.com/WixEngineering/" target="_blank" rel="noopener"><u>Facebook</u></a> | <a href="https://www.linkedin.com/showcase/wix-engineering/" target="_blank" rel="noopener"><u>LinkedIn</u></a></p></li><li id="viewer-bmvq6"><p>Visit us on <a href="https://github.com/wix" target="_blank" rel="noopener"><u>GitHub</u></a> </p></li><li id="viewer-enpb"><p><a href="https://www.wix.engineering/subscribe" target="_blank" rel="noopener"><u>Subscribe to our monthly newsletter</u></a> </p></li><li id="viewer-alvjs"><p>Subscribe to our <a href="https://www.youtube.com/WixTechTalks" target="_blank" rel="noopener"><u>YouTube channel</u></a> </p></li><li id="viewer-7fn1f"><p><a href="https://medium.com/wix-engineering" target="_blank" rel="noopener"><u>Follow our Medium publication</u></a> </p></li><li id="viewer-eokcs"><p>Listen to our podcast on <a href="https://podcasts.apple.com/il/podcast/wix-engineering-podcast/id1503976848" target="_blank" rel="noopener"><u>Apple</u></a>, <a href="https://open.spotify.com/show/5CmjtjpdcKkHDnr0601uYS?si=PcOf7Rx_RUmGojFj5n7CEA" target="_blank" rel="noopener"><u>Spotify</u></a> or <a href="https://podcasts.google.com/?feed=aHR0cHM6Ly9yYW5sZXZpLmNvbS9mZWVkL3dpeF9wb2Qv&amp;ved=0CAAQ4aUDahcKEwjY3bLcy7_oAhUAAAAAHQAAAAAQAQ" target="_blank" rel="noopener"><u>Google</u></a></p></li></ul></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.wix.engineering/post/how-we-re-able-to-host-1-million-sites-per-mongodb-cluster</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270294</guid>
            <pubDate>Tue, 25 Aug 2020 11:38:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What do we mean by rewrite and refactor?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24270257">thread link</a>) | @shzfrk
<br/>
August 25, 2020 | http://www.bennorthrop.com/rewrite-or-refactor-book/chapter-1-what-we-mean-by-rewrite-and-refactor.php | <a href="https://web.archive.org/web/*/http://www.bennorthrop.com/rewrite-or-refactor-book/chapter-1-what-we-mean-by-rewrite-and-refactor.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
	<header>
		<!--
		<div class="header-title">
			<h1><a href="http://www.bennorthrop.com">Ben Northrop</a></h1><br class="mobile-only" />
			<span class="header-tagline">Decisions and software development</span>
		</div>
		<hr id="header-divider"/>
		-->
		<nav>
			
		</nav>
	</header>

		<br>
	<section id="content-title">
		<h2>
			What do we Mean by "Rewrite" and "Refactor"? 
    </h2>
    		
				
			
			<p>August 24th 2020 </p>
				<hr id="content-title-divider">
	</section>
	<br>
	

	<section id="content">	
	

	

					
<p>
We're ready to start our journey.  We have an application that's riddled with technical debt, woefully out of date, or just generally underserving its users, and so we need to understand what our best option is going forward - does it make more sense to continue to plod along and incrementally refactor?  Or do we blow it all up and rewrite from scratch?  This is the basic dilemma we'll be exploring in <a href="http://www.bennorthrop.com/rewrite-or-refactor-book/index.php">this book</a>.  So let's get going...
</p>

<p>
But not so fast!  Before we go any further we need to address the elephant in the room, which is this: for any legacy application in need of improvement, <b>what to do next is not a simple this-or-that decision</b>.  We may frame our options generally as <i>rewrite</i> or <i>refactor</i>, but these terms, as we'll see, are really just stand-ins for a whole spectrum of choices that lie before us.  
</p>

<img src="http://www.bennorthrop.com/rewrite-or-refactor-book/Rewrite-Refactor-Spectrum.png">

<p>
By refactoring, within the context of modernizing a legacy application, we typically mean that we're going to keep the application mostly as it is, but make some minor, internal improvements to solve specific problems (like maintainability, extensibility, etc.).  By rewriting, on the other hand, we imply that we intend to "start again from scratch", or in other words to make major changes.  
</p>

<p>
But this only begs the next question!  What exactly do we mean by <i>minor</i> and <i>major</i>?  If we plan to upgrade our frontend framework from AngularJS to React but keep the backend services as they are, is that a refactor or rewrite?  Or what about if we want to break a monolith into three different microservices, but the business logic is just copied-and-pasted into new version-control repos - is that a rewrite, refactor, or something else?  And do we even care?  Does labeling our effort really matter?
</p>

<p>
Yes, it does.  Although our job is to build working software and not philosophize about semantics, the words we use <i>do</i> make a difference.  When we suggest the path of rewriting or to refactoring, business and technology stakeholders should understand exactly what we mean and what type of effort will be entailed.  In other words, some <b>precision in our terms will help us better set expectations</b>.  Further, as we burn through some of this conceptual fog and find clearer definitions, it will also give us a more nuanced view of this decision, and move us beyond the narrow <i>rewrite or refactor</i> framing.  
</p>
<p>
So like any big journey, let's spend a little time packing before we jump in the car and go.  We don't want to show up at the beach and realize we forgot our swim suit.  
</p>


<h3>Functional Improvement</h3>
<p>
A good place to start is to define what rewrites and refactors are <i>not</i>, which are strategies to improve the functionality of an application.  This type of work, whether it's fixing defects, delivering new features, or cleaning up the user interface, we can call enhancement.  It's about improving on what the application <i>does</i> for its users, and as we'll see later, it's the normal state of development.  
</p>
<img src="http://www.bennorthrop.com/rewrite-or-refactor-book/Rewrite-Refactor-Functional.png">
<p>
In some cases, the scope of the functional enhancements can be quite large though.  The business may determine that the app serves the right user base, for example, but the features all need to be overhauled.  It may be tempting to call this case a rewrite as well, however we're going to make a distinction here.  Because this type of effort entails building <i>all</i> new functionality, it is basically indistinguishable from greenfield development.  When new functional requirements need to be defined, a separate system is developed from scratch, and no carry over of logic or code is possible, we will consider this to be development of a greenfield app and not a rewrite.  
</p>



<h3>What we mean by Refactoring</h3>
<p>
Adding functionality to an application is not what this book is about. Our situation is that the application generally does <i>what</i> it is expected to do, but is lacking in the <i>how</i> - in other words, the non-functional or <a href="http://www.qasigma.com/2008/12/software-quality-attributes.html">quality attributes</a> of the system.  For example, users might be happy with the set of features, but the application might be excessively difficult to maintain, or it may crash frequently, or may perform poorly under peak load.  It's when these non-functional attributes are lacking that we consider a rewrite or refactor.  
</p>
<p>With respect to refactoring, we often use this term to refer to different scopes of work. In his book <a href="https://martinfowler.com/books/refactoring.html"><i>Refactoring</i></a>, <a href="https://martinfowler.com/">Martin Fowler</a> defines it this way:
</p>

<p>
Refactoring is a disciplined technique for restructuring an existing body of code, altering its internal structure without changing its external behavior.
</p>

<p>
In this purist sense, refactoring is primarily about making the code more maintainable.   This might be decomposing long or complex functions, fixing inconsistent naming, adding unit tests, or restructuring class hierarchies, data structures, or schemas.  Note that nothing that is <i>visible</i> to the user changes, but the internal code structure is modified to make it easier to work with for developers, thus improving our productivity (and happiness!).   
</p>

<p>
In the context of our rewrite or refactor decision, however, this definition is too restrictive.  When we talk about refactoring in this context, we're not typically making a distinction between internal and external, but rather about <b>functional and non-functional</b>.  For example, we may say that we are choosing to refactor the existing code base to improve the reliability or performance of the application.  These quality attributes are technically not <i>internal</i> properties of the system (they are very visible to the users in that they directly impact them), they are just <i>non-functional</i>.  This might be a pedantic distinction, but in the spirit of precision, I think it's important to call out.   In this book we'll be using a broader definition of refactoring:
</p>

<p>
Refactoring is an approach by which an existing body of code is incrementally restructured in order  to improve the quality attributes of the system.
</p>

<p>
Lastly, it's important to note that refactoring is about iterative change.  It's making minor tweaks to the application, delivering them, and then rinse and repeat.  Layered in with functional enhancements, refactoring can keep our users happy and our codes base healthy, minimizing technical debt and feature gaps.  When neglected, however, we may need to consider the more heavy-weight alternative.
</p>

<h3>What we mean by Rewriting</h3>
<p>
Like refactoring, rewriting has the same basic goal - to improve the non-functional nature of the application.  The difference is in how much is changed.  Simply put, if refactoring is duct tape, rewriting is a sledge hammer or a back hoe.  It's not about making incremental improvements to what is there, it's about blowing it up and building anew.  With respect to the other types of development efforts we've discussed, we can visualize a rewrite this way:
</p>

<img src="http://www.bennorthrop.com/rewrite-or-refactor-book/Rewrite-Refactor-Quadrant.png">


<p>
We can say then that a rewrite is an effort that <b>involves major changes to the system in order to make fundamental improvements to its quality attribute</b>s.  But there is gray area.  Rewrite efforts often spill over into the other quadrants.  For example, an application may be so crippled by technical debt that it's virtually impossible to add new features.  We may choose then to rewrite  and build a new foundation to improve maintainability and extensibility (quality attributes), but during the course of that rewrite we may also sneak in a few new features to satisfy the business.  It's fundamentally a rewrite, but there is some enhancement going on as well.  
</p>
<p>
Likewise, there is some fuzziness at the boundary of rewrite and refactor.  There are lift-and-shift scenarios where the system is moved to a new platform making it essentially a different application, but the code implementation within it is mostly the same - i.e. not refactored.  This feels like a rewrite, but is it?  How much do we have to change to consider it a rewrite?
</p>

<p>Again, let's see if we can add some precision.  For the purpose of this book, let's use the following definition:
</p>

<p>
Rewriting is re-building the same functionality that exists in a legacy application but using a different language/framework, maintaining within a new code repository (not just a branch), and deploying as an entirely new artifact (possibly to a different platform - e.g. servers, hardware, serverless, client, etc.).
</p>

<p>
In other words, we're drawing some clear lines.  If, for example, we're rewriting an important function, class, or even module, but our work is made in a branch off of the mainline of our codebase, it's not a rewrite.  Likewise, if we re-implement a segment of the application, but the system itself is still deployed as the same artifact (binary, WAR, etc.), this also is not a rewrite.  Rewrites within our context are BIG.  They are about major changes that necessitate an entirely new application to be built and deployed.  Yes, there may be incremental steps along the road to get there, as we'll see later, but it is a fundamentally different effort than refactoring.  
</p>

<p>
To help clarify things in your individual case, it can be helpful to diagram this out.  For the different possible paths for modernizing or improving your application, what exactly is being changed?  Here's an example:
</p><div>

<p><img src="http://www.bennorthrop.com/rewrite-or-refactor-book/Rewrite-Refactor-Distinction.png"></p></div><p>
In practice, the nature of the changes may not line up neatly with the definitions of rewrite or refactor, and that's ok.  The diagram above, for example, might represent a case where we're proposing to re-implement a service using a more modern set of technologies, but while keeping the exposed API and underlying persistence structure the same.  This represents a blend of minor and major changes, so it still may not be clear precisely what to label it.  What's important, however, is that we've arrived at deeper level of detail which will help us better reason about and justify the decision.  
</p>

<p>
Now we're almost done with our preparations, but before we get on with our …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.bennorthrop.com/rewrite-or-refactor-book/chapter-1-what-we-mean-by-rewrite-and-refactor.php">http://www.bennorthrop.com/rewrite-or-refactor-book/chapter-1-what-we-mean-by-rewrite-and-refactor.php</a></em></p>]]>
            </description>
            <link>http://www.bennorthrop.com/rewrite-or-refactor-book/chapter-1-what-we-mean-by-rewrite-and-refactor.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270257</guid>
            <pubDate>Tue, 25 Aug 2020 11:34:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Secure Modular Runtimes]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24270195">thread link</a>) | @ispivey
<br/>
August 25, 2020 | https://guybedford.com/secure-modular-runtimes.html | <a href="https://web.archive.org/web/*/https://guybedford.com/secure-modular-runtimes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>I recently posted the following Tweet with regards to the current state of the third-party security problem in the JavaScript ecosystem:

</p><blockquote><div lang="en" dir="ltr"><p>Having worked on and followed modules standards from TC39 and WhatWG to Node.js, it's so so clear that security was, is, and always will be an afterthought.</p><p>Where are the secure-by-default open platform developments? Crypto is the only community I see doing it.</p></div>— Guy Bedford (@guybedford) <a href="https://twitter.com/guybedford/status/1296935308445900801?ref_src=twsrc%5Etfw">August 21, 2020</a></blockquote> 

<p>I wanted to fill in some of the background to this from my own work on Node.js modules and security concepts, following the Agoric SES and compartment models, and from a growing feeling of the inadequacy of the Node.js, Deno and browser runtimes for supporting the third-party security needs of the ecosystem.

</p><p><em>TLDR; I think we need to think about new more secure runtimes for JS, and it should be a collaborative effort, with the components being modules, adding isolated scopes to import maps, and a careful security model plus compatibility with the existing ecosystem. <a href="#secure-modular-runtime-proposal">Skip ahead to the proposal here.</a></em>

</p><p><em>Update: Since posting this, I see that <a rel="noopener" target="_blank" href="https://github.com/Agoric/SES-shim/tree/master/packages/endo">Endo</a> and <a rel="noopener" target="_blank" href="https://github.com/LavaMoat/LavaMoat">LavaMoat</a> provide techniques very close to these directions, although neither has quite yet taken the leap that I argue is necessary that such a security system should be integrated into the primary runtime itself.</em></p>

<h2><a href="#third-party-security-problem">#</a>The Third-Party Security Problem</h2>

<p>The underlying issue is the <code>npm install</code> one. As the registry and our dependence on it continues to expand, the security gap here continues to grow in terms of the amount of untrusted code we are running on a daily basis.

</p><p>Maintainers giving up their time freely now find themselves obliged to respond to regular security issues or risk having unpatchable advisories released for their packages, which may or may not even be genuine escalations of privilege.
  We engage in security theatre to create the illusion of safety, and yet all the while everything remains highly unsecure.

</p><p>Rather than simply accepting the status quo, many companies are actively working on mitigating these security properties. The problem is that they end up creating side ecosystems or patches to the existing ecosystem, security measures that are never fundamentally designed into the ecosystem itself. Third-party security remains a huge if not impossible effort, that only dedicated teams can afford to tackle, as we see for example with these intiatives by <a rel="noopener" target="_blank" href="https://www.figma.com/blog/how-we-built-the-figma-plugin-system/">Figma</a> or <a rel="noopener" target="_blank" href="https://developer.salesforce.com/blogs/developer-relations/2017/02/lockerservice-lightning-container-third-party-libraries-lightning-components.html">Salesforce</a>.

</p><p>The <a rel="noopener" target="_blank" href="https://github.com/tc39/proposal-realms">Realms proposal</a> may give us the tools for constructing a secure runtime, but the JavaScript ecosystem conventions themselves work against supporting security restrictions.

</p><p>The general view from Chrome/v8, is that this type of third-party per-package security within the same process isn't possible:

</p><blockquote><p lang="en" dir="ltr">how is this possible post spectre</p>— Sathya Gunasekaran (@_gsathya) <a href="https://twitter.com/_gsathya/status/1297121933004353536?ref_src=twsrc%5Etfw">August 22, 2020</a></blockquote> 

<p>Now I admit I have fully bought in to the elegance of the the OCAP, SES and compartment models, the ideas shared by those at Agoric (who are long-time members of TC39). I gave a session on these concepts at the Node.js Collaboration summit.

</p><p>For all the tremendous benefits of the concept of modular security, there are certainly important questions, but I believe we should actively tackle this work and these questions, and not abandon the same-process modular security models unless they can be fully disproved.

<a name="compartment-model"></a>
</p><h2><a href="#compartment-model">#</a>The Compartment Model</h2>

<p>The gist of the compartment model builds on top of SES (<a rel="noopener" target="_blank" href="https://github.com/Agoric/ses-shim">Secure ECMAScript</a>), as proposed by Agoric, something like the following:

</p><ol>
  <li>All capabilities are imported through the module system (<code>import fetch from 'fetch'</code> kind of thing) - <em>the module resolver acts as the capability system, enforcing permissions</em>.</li>
  <li>The consequence of (1) is that <em>all global capabilities should be disabled / carefully controlled.</em></li>
  <li>JavaScript needs a whole bunch of patching to prevent prototype mutations and unintentional side channels such as <code>return { toString() {} }</code> object hooks. You have to manage package interfaces very carefully and freeze the entire global object from prototype mutation.</li>
</ol>

<p>See the talk by Mark Miller on <a rel="noopener" target="_blank" href="https://www.youtube.com/watch?v=9WdbTucMaRo">Extremely Modular Distributed JavaScript</a>, or my presentation from the Node.js Collaboration Summit,
<a rel="noopener" target="_blank" href="https://docs.google.com/presentation/d/1VUpxoxitZCINJI7jXec4i87YiYZsXr8pCSHdHY5pW30/edit?usp=sharing">Security, Modules and Node.js</a>, for a more in-depth coverage of the full model.

</p><p>The result of this model is, in theory, the ability to restrict destructive code. The date time library you npm install cannot install a trojan horse on your computer, which seems a pretty useful property to have.

</p><p>Towards (3) we already <a rel="noopener" href="https://nodejs.org/dist/latest-v14.x/docs/api/cli.html#cli_frozen_intrinsics">shipped the `--frozen-intrinsics` flag in Node.js</a>. (1) and (2) clearly require breaking changes to what we have in any existing runtimes today.</p>

<h2><a href="#criticisms">#</a>Criticisms</h2>

<p>The criticisms of this model include the Spectre class of vulnerabilities, the difficulty in providing secure cross-package interfaces, and that these ideas might sound good in theory but are impractical in real JS environments.

<a name="spectre"></a>
</p><h3><a href="#spectre">#</a>Spectre</h3>

<p>The Spectre class of attacks means that code running on the same process can use CPU reverse engineering and timing information to read secret information
used by other separate code in the same process. Think - passwords, secure tokens, etc.

</p><p>The first thing to note is that Spectre is the ability to steal secrets and not the ability to install a trojan horse on your computer. Even if we can't fully mitigate Spectre (and we can certainly try), we are still limiting destructive capabilities such as giving full disk and network access
  to random people on the internet, which is a huge win. What we are comparing this model against, is having no separate security for third-party libraries at all, which is the case in Node.js, Deno and browsers today. <em>In the case of an attack, it is better to just lose a credit card, than to lose a credit card AND have your house burnt down.</em>

</p><p>The second thing to note here is that if you have a true capability system and can carefully control network access, then the capability to exfiltrate (basically to use <code>fetch</code>), can itself be treated as a critical permission. Secrets might be discovered but not as easily shared.

</p><p>The counterargument to controlling the capability to exfiltrate is that there are always side channels to be found - the blinking of a light through whatever complex window to share the information of the secret token. It's a complex boundary to mitigate.

</p><p>Finally, in terms of genuine Spectre mitigations, Cloudflare have this same problem for their same-process deployment of Cloudflare Workers, which they recently discussed here - <a rel="noopener" target="_blank" href="https://blog.cloudflare.com/mitigating-spectre-and-other-security-threats-the-cloudflare-workers-security-model/">Mitigating Spectre and Other Security Threats: The Cloudflare Workers Security Model</a>.

</p><p>Their mitigations are summarized at the end, and roughly involve:

</p><ul>
<li>Restricting Date.now() and multi-threading via new Worker (which allows custom timer creation) to attempt to disable the time measurements necessary to initiate the attack.
</li><li>Proactively detecting the attack behaviour based on monitoring and initiating full isolation.
</li><li>Exploring memory shuffling techniques so that secret information does not remain static.
</li></ul>

<p>As Cloudflare mention, this is an active mitigation space that can continue to be developed. In theory, these similar mitigations could apply to new runtime development as well.

</p><p>The important thing to note is that these mitigation techniques do not apply to the Web platform at all as they are simply not possible (at least not without <a rel="noopener" target="_blank" href="https://github.com/tc39/proposal-realms">Realms</a>). The Google / v8 position completely makes sense, given this angle,
  but the focus I want to make is on <strong>new JavaScript runtimes</strong>, like successors to Node.js such as Deno and others, <em>which should really be exploring these security properties today</em>.

<a name="insecure-module-interfaces"></a>
</p><h3><a href="#insecure-module-interfaces">#</a>Insecure Module Interfaces</h3>

<p>The next major problem comes down to the complex interface boundary between third-party packages. For example, consider the following code:

</p><pre><code>
import { renderer } from 'renderer';
import { renderGraph } from 'graph';
import { renderTitle } from 'title';

renderer.render([renderGraph, renderTitle]);
</code></pre>

<p>In theory, <code>renderGraph</code> doesn't need any other capabilities other than the ability to call into the renderer so it can be treated as low-trust code.

</p><p>But now consider a malicious implementation of <code>renderGraph</code>:

</p><pre><code>
export function renderGraph () {
  this[1].setTitle('Changed the title');
}
</code></pre>

<p><code>renderGraph</code> knows the renderer will call it via <code>renderArray[i]()</code>, which in JavaScript will set the <code>this</code> binding to the array itself, thus giving access to the title component from the graph component.

</p><p>Yes, it's a contrived example, but it demonstrates how easily you can get capability spillage in JavaScript, and that's before we even get to information spillage eg via <code>toString()</code>.

</p><p>Locking down these sorts of inadvertant side channels means making all package interfaces out of <code>SafeFunction</code> and <code>SafeObject</code> objects that don't have these sorts of awful flaws, and it's not an easy problem to solve - this is where the bulk of the effort needs to be made.

</p><p>The other side of this to consider is that Web Assembly module interfaces don't have these same sorts of capability and information spillage that we have in JavaScript, which certainly gives hope for future ecosystems dealing with these problems.

<a name="impractical-constraints"></a>
</p><h3><a href="#impractical-constraints">#</a>Impractical Constraints</h3>

<p>The third argument is that the security requirements are simply too much of a constraint on JavaScript and its ecosystems. That there exists no path from the ecosystems today to this kind of secure ecosystem. As a result, secure runtimes will always be a fringe effort
  adopted by the few who can invest in the time and effort to support them.

</p><p>This, I believe, is the most crucial problem to solve. The ability to run third-party libraries with less risk should be fully democratized.

<a name="secure-modular-runtime-proposal"></a>
</p><h2><a href="#secure-modular-runtime-proposal">#</a>Secure Modular Runtime Proposal</h2>

<p>I'd like to propose a hypothetical runtime for JavaScript, as a strawman, and to invite scrutiny as to whether this solves the following problems:

</p><ol>
<li>That this runtime can fully restrict high-level capability access from packages for third-party code running in the same process than we have in Node.js, Deno and browsers today.
</li><li>That this runtime can support …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://guybedford.com/secure-modular-runtimes.html">https://guybedford.com/secure-modular-runtimes.html</a></em></p>]]>
            </description>
            <link>https://guybedford.com/secure-modular-runtimes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270195</guid>
            <pubDate>Tue, 25 Aug 2020 11:25:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Finnish logistics giant uses predictive database for intelligent automation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24270164">thread link</a>) | @arauhala
<br/>
August 25, 2020 | https://aito.ai/blog/posti-boosts-their-rpa-with-aito/ | <a href="https://web.archive.org/web/*/https://aito.ai/blog/posti-boosts-their-rpa-with-aito/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Posti boosts purchase invoice automation with Aito</h2><p>The RPA team of Posti has moved to the next level by adding machine learning into their toolbox. Using Aito has allowed Posti to utilize machine learning independently and the first Aito implementation is now live in production, tirelessly churning through thousands of purchase invoices and saving their finance team countless of hours worth of mechanical work.</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/posti_quote.png" alt="Aito has provided Posti a fast and easy tool to implement machine learning to business processes, adding new opportunities to our Intelligent Automation toolkit."></p></div></div><h2>Automation in the Finnish logistics giant</h2><p>As the largest postal service operator in Finland, Posti delivers hundreds of thousands of parcels and envelopes daily around the country. This naturally involves much more behind the scenes than just the logistics though, and automation has been at the core of Posti for years.</p><p>To streamline its operations, Posti’s RPA Center of Excellence has been automating countless business processes within the company. With Aito now in their toolbox, the RPA team can conquer even complex processes without having to go through the data science pipeline. No custom code or scripts are needed either since interaction with Aito happens directly through standard UiPath activities.</p><h2>Handling purchase invoices</h2><p>By using Aito and in collaboration with Sisua Digital, Posti has automated their purchase invoice handling processing. Processing the 3000 new invoices every month requires several cognitive decisions, making automation impossible with traditional RPA methods. Before storing the final version in their invoice management system, each digital invoice needs to be:</p><ol><li>Assigned to the right reviewer</li><li>Allocated to the right cost center</li><li>Tagged for the right category</li><li>Corrected in case of missing information</li></ol><p>Visualizing the problem with some mock data, this is how a new invoice looks like entering the system. A correct value needs to be selected for the empty fields.</p><table><thead><tr><th>Vendor_Code</th><th>Inv_Amt</th><th>VAT_Code</th><th>Item_Description</th><th>Product_Category</th><th>Reviewer</th><th>CC_Code</th><th></th><th></th><th></th></tr></thead><tbody><tr><td>VENDOR-1676</td><td>83.24</td><td></td><td>Artworking/Typesetting ...</td><td></td><td></td><td></td><td></td><td></td><td></td></tr></tbody></table><p>Posti has automated this process by creating a software robot with UiPath and having it interact with Aito. The robot reads the information in each new invoice and asks Aito to predict the right values.</p><table><thead><tr><th>Vendor_Code</th><th>Inv_Amt</th><th>VAT_Code</th><th>Item_Description</th><th>Product_Category</th><th>Reviewer</th><th>CC_Code</th><th></th><th></th><th></th></tr></thead><tbody><tr><td>VENDOR-1676</td><td>83.24</td><td>VAT-24</td><td>Artworking/Typesetting ...</td><td>CLASS-1593</td><td>R-085</td><td>CC-164</td><td></td><td></td><td></td></tr></tbody></table><h2>Launching the robot</h2><p>To test the performance of the new automation, it was first operated in parallel with the manual process for one month and all the predictions of Aito were recorded for evaluation. During the simulation, Aito’s predictions fulfilled the accuracy requirement of 95% set by the project steering group, giving it the green light for production. The first version of the robot includes a few of types of purchase invoices in one legal company. Later during this the fall, more companies and invoice types will be added.</p><p>During its first couple of months in production, more than 7,000 purchase invoices have been processed automatically. The new automation has reduced the workload on the Accounts Payable team at Posti while boosting the speed of invoice review. But even more importantly, the RPA team of Posti now has the ability to replicate the technology for countless other business processes. After the initial learning curve, they found Aito very straightforward to use with standard UiPath functionality.</p><a href="https://aito.ai/blog">Back to blog list</a></div></div>]]>
            </description>
            <link>https://aito.ai/blog/posti-boosts-their-rpa-with-aito/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270164</guid>
            <pubDate>Tue, 25 Aug 2020 11:20:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenNebula announces new experimental support for PostgreSQL]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24270048">thread link</a>) | @amarti
<br/>
August 25, 2020 | http://docs.opennebula.io/5.12/deployment/opennebula_installation/postgresql_setup.html | <a href="https://web.archive.org/web/*/http://docs.opennebula.io/5.12/deployment/opennebula_installation/postgresql_setup.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
            
  <div id="postgresql-setup">

<div>
<p>Important</p>
<p>This feature is a <strong>Technology Preview</strong>. It’s not recommended for production environments!</p>
</div>
<p>The PostgreSQL back-end is an alternative to SQLite and MySQL/MariaDB back-ends. All back-ends cannot coexist, and you will have to decide which one is going to be used while planning your OpenNebula installation. It’s not possible to automatically migrate the existing OpenNebula database from SQLite or MySQL/MariaDB to PostgreSQL.</p>
<p>Features:</p>
<ul>
<li>Required <strong>PostgreSQL 9.5 or newer</strong> (WARNING: base RHEL/CentOS 7 contains unsupported PostgreSQL 9.2!)</li>
<li>No migrator for existing deployments from SQLite or MySQL/MariaDB</li>
<li>No full-text search support</li>
</ul>
<div>
<p>Note</p>
<p>If you are planning to install OpenNebula with PostgreSQL back-end, please follow this guide <strong>prior</strong> to starting OpenNebula for the first time to avoid problems with oneadmin and serveradmin credentials.</p>
</div>
<div id="installation">
<h2>Installation<a href="#installation" title="Permalink to this headline">¶</a></h2>
<p>First of all, you need a working PostgreSQL server <strong>version 9.5 or newer</strong>. You can either deploy one for the OpenNebula installation or reuse any existing PostgreSQL already deployed and accessible by the Frontend. We assume you have PostgreSQL server installed and running.</p>
<div id="configuring-postgresql">
<h3>Configuring PostgreSQL<a href="#configuring-postgresql" title="Permalink to this headline">¶</a></h3>
<p>Create new database user <code><span>oneadmin</span></code> and provide own password for database user:</p>
<div><div><pre><span></span>$ sudo -i -u postgres -- createuser -E -P oneadmin
Enter password for new role: **********
Enter it again: **********
</pre></div>
</div>
<p>Create database <code><span>opennebula</span></code> with owner <code><span>oneadmin</span></code>:</p>
<div><div><pre><span></span>$ sudo -i -u postgres -- createdb -O oneadmin opennebula
</pre></div>
</div>
<div>
<p>Note</p>
<p>The database doesn’t need to be created if the database user has privileges to create databases. In that case, OpenNebula creates the database on the first connect. To keep the lowest needed privileges, it’s recommended to follow the steps above and prepare everything beforehand.</p>
</div>
<p>Visit the <a href="https://www.postgresql.org/docs/12/user-manag.html">PostgreSQL documentation</a> to learn how to manage accounts.</p>
<p>Validate a working connection, e.g.:</p>
<div><div><pre><span></span>$ psql -h localhost -U oneadmin opennebula
Password for user oneadmin:
psql (10.12 (Ubuntu 10.12-0ubuntu0.18.04.1))
SSL connection (protocol: TLSv1.2, cipher: ECDHE-RSA-AES256-GCM-SHA384, bits: 256, compression: off)
Type "help" for help.

opennebula=&gt;
</pre></div>
</div>
<p>If connection above fails, you might need to configure client authentication mechanisms in your PostgreSQL server. Review authentication configuration file <code><span>pg_hba.conf</span></code> in your installation (e.g., located in <code><span>/var/lib/pgsql/data/pg_hba.conf</span></code>, <code><span>/etc/postgresql/$VERSION/main/pg_hba.conf</span></code> where <code><span>$VERSION</span></code> is your major PostgreSQL version). Ensure the file contains:</p>
<div><div><pre><span></span><span># host  DATABASE        USER            ADDRESS                 METHOD  [OPTIONS]</span>
<span>host</span>    <span>opennebula</span>      <span>oneadmin</span>        <span>127.0</span><span>.</span><span>0.1</span><span>/</span><span>32</span>            <span>md5</span>
<span>host</span>    <span>opennebula</span>      <span>oneadmin</span>        <span>::</span><span>1</span><span>/</span><span>128</span>                 <span>md5</span>
</pre></div>
</div>
<p>Reload the PostgreSQL server after the change:</p>
<div><div><pre><span></span>$ sudo systemctl reload postgresql
</pre></div>
</div>
<p>Validate a working connection again.</p>
<p>Visit the <a href="https://www.postgresql.org/docs/12/auth-pg-hba-conf.html">PostgreSQL documentation</a> to learn how to manage client authentication configuration.</p>
</div>
<div id="configuring-opennebula">
<h3>Configuring OpenNebula<a href="#configuring-opennebula" title="Permalink to this headline">¶</a></h3>
<p>Before you run OpenNebula for the first time, you need to set database connection details in <a href="http://docs.opennebula.io/5.12/deployment/references/oned_conf.html#oned-conf"><span>oned.conf</span></a>.</p>
<div><div><pre><span></span><span># Sample configuration for PostgreSQL</span>
<span>DB</span> <span>=</span> <span>[</span> <span>backend</span> <span>=</span> <span>"postgresql"</span><span>,</span>
       <span>server</span>  <span>=</span> <span>"localhost"</span><span>,</span>
       <span>port</span>    <span>=</span> <span>0</span><span>,</span>
       <span>user</span>    <span>=</span> <span>"oneadmin"</span><span>,</span>
       <span>passwd</span>  <span>=</span> <span>"**********"</span><span>,</span>
       <span>db_name</span> <span>=</span> <span>"opennebula"</span> <span>]</span>
</pre></div>
</div>
<p>Fields:</p>
<ul>
<li><strong>server</strong>: of the machine running the PostgreSQL server.</li>
<li><strong>port</strong>: port for the connection to the server. If set to 0, the default port is used.</li>
<li><strong>user</strong>: PostgreSQL user-name.</li>
<li><strong>passwd</strong>: PostgreSQL password.</li>
<li><strong>db_name</strong>: Name of the PostgreSQL database OpenNebula will use.</li>
</ul>
</div>
</div>
<div id="using-opennebula-with-postgresql">
<h2>Using OpenNebula with PostgreSQL<a href="#using-opennebula-with-postgresql" title="Permalink to this headline">¶</a></h2>
<p>After this installation and configuration process you can use OpenNebula as usual.</p>
</div>
</div>


           </div>
          </div></div>]]>
            </description>
            <link>http://docs.opennebula.io/5.12/deployment/opennebula_installation/postgresql_setup.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270048</guid>
            <pubDate>Tue, 25 Aug 2020 11:02:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Move Uno Platform Pages to a Multi-Targeting Library]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24269958">thread link</a>) | @cfdevelop
<br/>
August 25, 2020 | https://christianfindlay.com/2020/08/25/uno-multitargeting/ | <a href="https://web.archive.org/web/*/https://christianfindlay.com/2020/08/25/uno-multitargeting/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main">

<section id="content">

	<article id="post-1692">

		<div>
			
<p>You can move Uno Platform pages and other code into a multi-targeted library that you can reference from the Uno Platform head projects. This is much more convenient than using Visual Studio Shared libraries. Shared libraries don’t seem to have full support in Visual Studio, and some features like quick refactors often don’t work. This article briefly explains what I did to get this working. I completely removed the shared library in my sample. You can clone my&nbsp;<a rel="noreferrer noopener" target="_blank" href="https://github.com/MelbourneDeveloper/Samples/tree/master/UnoCrossPlatformTemplate">working sample</a>&nbsp;here.&nbsp;</p>



<p>Check out my Udemy course <a href="https://www.udemy.com/course/introduction-to-uno-platform/?referralCode=C9FE308096EADFB5B661" data-type="URL" data-id="https://www.udemy.com/course/introduction-to-uno-platform/?referralCode=C9FE308096EADFB5B661">Introduction To Uno Platform</a>.</p>



<p>This video gives you a quick overview of creating a multi-targeting library and moving a page into it.&nbsp;</p>



<figure><p><span><iframe width="760" height="428" src="https://www.youtube.com/embed/MYEwMvQd9SM?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span>
</p></figure>



<p><a href="https://nicksnettravels.builttoroam.com/uno-crossplatform-template/" data-type="URL" data-id="https://nicksnettravels.builttoroam.com/uno-crossplatform-template/">This article</a> gives you a much more comprehensive step by step guide to converting an existing solution to used a multi-targeting library. Also, this process seems support hot-reload.</p>



<p>The trick is that this template project uses SDK type MSBuild.Sdk.Extras . These types of projects build for all the different platforms mentioned. Here is some of the config in the csproj file. The noteworthy part is the TargetFrameworks. We can’t merely build for .NET Standard. We need libraries for all the platforms we want to target.</p>



<pre data-enlighter-language="xml" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">&lt;PropertyGroup&gt;
&lt;TargetFrameworks&gt;uap10.0.16299;netstandard2.0;xamarinios10;xamarinmac20;MonoAndroid90;monoandroid10.0&lt;/TargetFrameworks&gt;
  &lt;!-- Ensures the .xr.xml files are generated in a proper layout folder --&gt;
  &lt;GenerateLibraryLayout&gt;true&lt;/GenerateLibraryLayout&gt;
  &lt;LangVersion&gt;8.0&lt;/LangVersion&gt;
  &lt;Nullable&gt;enable&lt;/Nullable&gt;
  &lt;TreatWarningsAsErrors&gt;true&lt;/TreatWarningsAsErrors&gt;    
&lt;/PropertyGroup&gt;</pre>



<p>I took the time to add some basic features to the project so that you can get started with Uno Platform development quickly. Also, it gives you Cat Facts! The only extra dependency I have added is to&nbsp;<a rel="noreferrer noopener" target="_blank" href="https://github.com/MelbourneDeveloper/RestClient.Net">RestClient.Net</a>, which the app uses to make Web API calls. These are the features of the project at the time of publishing this article. I will try to update and fix this sample moving into the future.</p>



<ul><li>Current version of Uno Platform (3.0.12)</li><li>C# version 8</li><li>FxCop with my flavor of code rules. This prevents common coding mistakes. Check out the documentation at the&nbsp;<a target="_blank" href="https://github.com/dotnet/roslyn-analyzers" rel="noreferrer noopener">Roslyn Github repo</a>.</li><li>RestClient .Net for APIs</li><li>ViewModel with binding</li><li>ICommands</li><li>Converters</li><li><strong><em>No shared project</em></strong></li><li>Nullable turned on. This a feature of C# 8 to reduce the need for null checking</li></ul>



<p>In Progress</p>



<ul><li>Hot reload doesn’t seem to work. Shout out if you know why!</li><li>There is a build problem on Mac because it cannot build for UWP. Let me know if you know how to ignore this on Mac for Visual Studio</li></ul>



<p>Watch a video of the app:</p>



<figure><p><span><iframe width="760" height="428" src="https://www.youtube.com/embed/oOMvHV1U82w?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span>
</p></figure>



<h2>Wrap-up</h2>



<p>Grab the sample and get started building an app. If you found this information useful, check out my Udemy course&nbsp;<a target="_blank" href="https://www.udemy.com/course/introduction-to-uno-platform/?referralCode=C9FE308096EADFB5B661" rel="noreferrer noopener">Introduction To Uno Platform</a>.</p>
					</div>

		

		

	<!-- .comments -->




		

		
		

		
		
	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
	</article>

</section>

	


</div></div>]]>
            </description>
            <link>https://christianfindlay.com/2020/08/25/uno-multitargeting/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269958</guid>
            <pubDate>Tue, 25 Aug 2020 10:48:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Provider-shims: stopgap solution for using community Terraform providers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24269946">thread link</a>) | @draganm
<br/>
August 25, 2020 | https://numtide.com/articles/generate-terraform-provider-shim/ | <a href="https://web.archive.org/web/*/https://numtide.com/articles/generate-terraform-provider-shim/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div id="content">
      
<p>Two weeks ago, Hashicorp has announced <a href="https://www.hashicorp.com/blog/announcing-hashicorp-terraform-0-13/">the release of Terraform 0.13.0</a>.
This release automates the installation of third-party providers, which was a major pain point when using such providers until now.
Unfortunately, this solution puts the burden of providing a service implementing <a href="https://www.terraform.io/docs/internals/provider-registry-protocol.html">registry protocol</a> onto the third-party plugin providers.
With time, we expect that most of the community-provided plugins will be available through such registries, but at the moment, most of them are not.</p>
<p>As a stopgap solution, we have implemented a so-called <a href="https://github.com/numtide/generate-terraform-provider-shim">Provider Shim generator</a>.</p>
<h2 id="provider-shims">Provider Shims</h2>
<p>TL;DR: Provider Shim is a <code>bash</code> script that gets placed in the repository, and that downloads, caches and executes the real Terraform provider when accessed.
Due to it's size it's very suitable to be checked along side the Terraform code in source code repositories.</p>
<h2 id="background">Background</h2>
<p>Before we can explain what Provider Shim does, it is crucial to understand what a Terraform provider is and how Terraform interacts with the providers.</p>
<h3 id="what-is-a-terraform-provider">What is a Terraform provider?</h3>
<p>Basic building blocks of Terraform are Resources and Data sources.
Resource is something that is managed (created, updated, destroyed) by Terraform, for example an EC2 instance, or a Storage Bucket in Google Cloud.
On the other hand, Data source is something that is not managed by Terraform per se (for example: GCP VM that has been manually created), but can be queried by Terraform to get information about it (such as public IP address of the said VM).</p>
<p>Terraform itself does not know how to interact with the resources, it only manages information about the resources, and all the operations (create, read, update, destroy) are delegated to so called providers.</p>
<p>Providers are executable files that are started and terminated by Terraform when needed.
Once started, Terraform communicates with a provider through a Unix socket using a <a href="https://github.com/hashicorp/terraform-plugin-sdk/blob/master/internal/tfplugin5/tfplugin5.proto">GRPC protocol</a>.
Providers on their own do not store any state, but are provided by Terraform with the state whenever an operation (such as <code>ReadResource</code>, <code>PlanResourceChange</code>, ..) needs to be performed.</p>
<h3 id="how-does-terraform-gets-its-providers">How does Terraform gets its providers?</h3>
<p>When <code>terraform init</code> is performed, Terraform downloads all the required modules and parses their HCLs (<code>.tf</code> files).
Among other things, HCLs contain <a href="https://www.terraform.io/docs/configuration/provider-requirements.html">provider requirements</a>, describing which versions of providers (and since Terraform 0.13.x locations of the registries) are required.</p>
<p>For each such requirement, Terraform will perform the following steps:</p>
<ul>
<li>Try finding the plugin on the local machine, in the following directories
<ul>
<li>Current directory: <code>.</code> (used mainly for plugin development)</li>
<li>Same directory where <code>terraform</code> binary is located</li>
<li><code>terraform.d/plugins</code></li>
<li><code>.terraform.d/plugins</code></li>
<li><code>~/.terraform.d/plugins</code></li>
</ul>
</li>
<li>If the plugin binary is not available in any of those locations, try downloading the plugin from the registry, storing it in <code>.terraform.d/plugins</code></li>
</ul>
<p>Once <code>terraform init</code> was successful, <code>terraform plan/apply/destroy</code> will be searching for needed plugins in the same directories as the <code>terraform init</code> would search.</p>
<h2 id="what-happens-if-a-provider-is-not-available-through-a-registry">What happens if a provider is not available through a registry?</h2>
<p>Performing <code>terraform init</code> is a really convenient way to install all providers needed by your Terraform project, provided that your provider is available using the provider registry protocol.
If that is not the case, things are getting uggly.</p>
<p>When your Terraform project depends on a community provider that can't be downloaded with <code>terraform init</code>, one has to somehow obtain binary of the provider and put it in the correct path for Terraform to find it.</p>
<p>This is very tedious and error prone manual process that has to be repeated for every provider and every location where Terraform is executed.</p>
<p>To make this easier, one can use one of the relative paths to the root Terraform module (such as <code>terraform.d/plugins</code> or <code>.terraform.d/plugins</code>) and check them in together with the terraform code into source control version.</p>
<p>This leads to repeatable builds with the manual task being done only once, but it also means that the source control contains all the binaries of the providers (each of them being megabytes in size) - working with such source repositories can be very daunting.</p>
<h3 id="provider-shim-saves-the-day">Provider Shim saves the day</h3>
<p>Instead of checking in the binary of a provider, we propose checking in a so called Provider Shim.</p>
<p>Shim is a small Bash script that will check if there is a copy of the provider binary on the local disk, if not, it will download the binary from GitHub and after the binary is available it will start the binary.</p>
<p>Such a shim would be small in size (less than 2 kilobytes) is a Bash script, making it easy to review and debug.</p>
<p>An example of such a Shim looks like this:</p>
<pre><code><span>#!/usr/bin/env bash
#
# Generated by generate-terraform-provider-shim: https://github.com/numtide/generate-terraform-provider-shim
#

</span><span>set </span><span>-e -o</span><span> pipefail

plugin_url</span><span>=</span><span>"https://github.com/numtide/terraform-provider-linuxbox/releases/download/v0.2.2/terraform-provider-linuxbox_v0.2.2_linux_amd64.tar.gz"
</span><span>plugin_unpack_dir</span><span>=</span><span>"${XDG_CACHE_HOME</span><span>:-</span><span>$HOME/.cache}/terraform-providers/linuxbox_v0.2.2"
</span><span>plugin_binary_name</span><span>=</span><span>"terraform-provider-linuxbox_v0.2.2"
</span><span>plugin_binary_path</span><span>=</span><span>"${plugin_unpack_dir}/${plugin_binary_name}"
</span><span>plugin_binary_sha1</span><span>=</span><span>"7232dbb6760d34e844ce731226b9eec67c5bb276"

</span><span>if </span><span>[[ </span><span>! </span><span>-d </span><span>"${plugin_unpack_dir}" </span><span>]]</span><span>; then
    </span><span>mkdir</span><span> -p </span><span>"${plugin_unpack_dir}"
</span><span>fi

if </span><span>[[ </span><span>-f </span><span>"${plugin_binary_path}" </span><span>]]</span><span>; then
    </span><span>current_sha</span><span>=</span><span>$(git hash-object "${plugin_binary_path}")
    </span><span>if </span><span>[[ </span><span>$current_sha </span><span>!= </span><span>"${plugin_binary_sha1}" </span><span>]]</span><span>; then
        </span><span>rm </span><span>"${plugin_binary_path}"
    </span><span>fi
fi

if </span><span>[[ </span><span>! </span><span>-f </span><span>"${plugin_binary_path}" </span><span>]]</span><span>; then
    </span><span>curl</span><span> -sL </span><span>"${plugin_url}" </span><span>| </span><span>tar xzvfC - </span><span>"${plugin_unpack_dir}"
    </span><span>chmod 755 </span><span>"${plugin_binary_path}"
</span><span>fi

</span><span>current_sha</span><span>=</span><span>$(git hash-object "${plugin_binary_path}")
</span><span>if </span><span>[[ </span><span>$current_sha </span><span>!= </span><span>"${plugin_binary_sha1}" </span><span>]]</span><span>; then
    </span><span>echo </span><span>"plugin binary sha does not match ${current_sha} != ${plugin_binary_sha1}" </span><span>&gt;&amp;</span><span>2
    </span><span>exit</span><span> 1
</span><span>fi

</span><span>exec </span><span>"${plugin_binary_path}" </span><span>$@
</span></code></pre><h3 id="what-does-the-provider-shim-do">What does the Provider Shim do?</h3>
<p>Provider Shim performs the following operations:</p>
<ul>
<li>Check if the binary of the provider is available in <code>~/.cache/terraform-providers</code>.</li>
<li>If there is no binary available, use <code>curl</code> to fetch an archive of the binary from the release in GitHub.</li>
<li>When fetched, extract the binary from the archive.</li>
<li>Check the integrity of the binary against a known SHA1 of the binary.
This step will detect if someone has replaced the binary of the provider in the GitHub release or on the local disk.</li>
<li>If the SHA1 matches, <code>exec</code> the provider giving it the same ARGs that shim has received, which will replace the <code>bash</code> process with the process of the provider binary.</li>
</ul>
<h3 id="what-happens-when-terraform-finds-the-provider-shim-at-the-right-place">What happens when Terraform finds the Provider Shim at the right place?</h3>
<p>Once terraform executes the Provider Shim instead of the provider, Provider Shim will (if needed) download the binary of the provider and start the provider.</p>
<p>All of this is transparent for Terraform, as if the provider binary was directly executed.</p>
<p>The only noticeable difference is the wait time for the fetching of the provider over the network using <code>curl</code>.
This happens only once, after that provider binary is cached on the local disk and won't be downloaded again.</p>
<h2 id="generating-provider-shims">Generating Provider Shims</h2>
<p>Generating such Provider Shims manually is a repetitive task that can be easily automated.
For this purpose, we have implemented a <a href="https://github.com/numtide/generate-terraform-provider-shim">command line utility</a> to generate such shims.</p>
<p>In order to generate shims for your terraform project, execute <code>generate-terraform-provider-shim &lt;provider path&gt;</code> in the directory of your root Terraform module.
Required <code>&lt;provider path&gt;</code> argument is the <code>&lt;owner&gt;/&lt;project&gt;</code> GitHub path of the project of the provider.</p>
<p>By default, <code>generate-terraform-provider-shim</code> will find latest release of the provider and generate a shim for it in <code>terraform.d/</code> directory for each arch supported by the provider.</p>
<p>If a specific version is required, an argument <code>--version=&lt;semver matcher&gt;</code> can be provided.</p>
<p>Generated Provider Shim can (and should be checked in together with the Terraform code)</p>
<p>Since version 0.2.0, the shim generator will generate shims in proper paths for both Terraform <code>0.12.x</code> and <code>0.13.x</code>, making it a great tool for a smooth transition to Terraform <code>0.13.x</code>.</p>
<h2 id="limitations">Limitations</h2>
<p>Like every hack, Provider Shims come with a set of limitations.
We are aware of the following constraints for using Provider Shims:</p>
<h3 id="dependencies">Dependencies</h3>
<p>Due to it's nature, Provider Shims have number of dependencies that have to be installed on the system in order for it to work.
Fortunately, most of those dependencies are available on many Unix-like systems.</p>
<p>Here is the list of dependencies:</p>
<ul>
<li><code>bash</code>: Provider Shims are <code>bash</code> scripts relying on <code>bash</code> internal commands.</li>
<li><code>curl</code>: used for fetching archives of the community provider.</li>
<li><code>unzip</code> or <code>gzip</code>/<code>tar</code>: depending on the archive type used in the provider release, either unzip or <code>tar</code>/<code>gzip</code> are required.</li>
<li><code>git</code>: we took an unorthodox approach to use <code>git</code> internal command to calculate SHA1 of the provider binary. Rational behind this: most of the time Terraform projects are stored in <code>git</code> repositories, hence <code>git</code> will be available.</li>
</ul>
<h3 id="only-providers-with-binaries-attached-to-the-github-releases-are-supported">Only providers with binaries attached to the GitHub releases are supported</h3>
<p>We are relying on the developers of the provider to create releases with attached compiled binaries of the providers for different architectures.
If that is not the case, a Provider Shim cannot be generated.</p>
<h3 id="only-tar-gz-and-zip-archives-are-supported">Only .tar.gz and .zip archives are supported</h3>
<p>There is no standard way of packaging providers.
Most of the time they are packaged in a Zip or Gzipped Tar archive - those are formats we are supporting.</p>
<h3 id="windows-is-not-supported">Windows is not supported</h3>
<p>We do not have access to a Windows machine and have never run terraform in a Windows environment, hence the generated shims will definitely not work under Windows.</p>
<h3 id="can-t-be-executed-in-terraform-cloud">Can't be executed in Terraform Cloud</h3>
<p>Since VMs used in Terraform cloud are lacking numerous <a href="https://numtide.com/articles/generate-terraform-provider-shim/#Dependencies">dependencies</a> (most notably: <code>curl</code>), Provider Shims cannot be used in <code>Remote</code> execution mode of Terraform Cloud.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Provider Shims can be very useful in Terraform <code>0.12.x</code> world and also can be useful for the …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://numtide.com/articles/generate-terraform-provider-shim/">https://numtide.com/articles/generate-terraform-provider-shim/</a></em></p>]]>
            </description>
            <link>https://numtide.com/articles/generate-terraform-provider-shim/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269946</guid>
            <pubDate>Tue, 25 Aug 2020 10:46:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Code-first GraphQL server by Prisma]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24269944">thread link</a>) | @oczek
<br/>
August 25, 2020 | https://blog.graphqleditor.com/graphql-nexus-codefirst-graphql-server/ | <a href="https://web.archive.org/web/*/https://blog.graphqleditor.com/graphql-nexus-codefirst-graphql-server/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>GraphQL schema is a set of rules describing the functionality available to the client, including specification of operations (queries and mutations) that can be executed to execute against your data graph. When building a GraphQL service, there is a choice that needs to be made whether you want to follow the code-first or schema-first path: </p>
<ul>
<li>Schema-first - which prioritizes process of designing the schema which puts schema as your source of truth and forces your code to follow the definitions stored in your schema,</li>
<li>Code-first (resolver-first) - is an approach where the GraphQL schema is implemented programmatically.</li>
</ul>
<p>In either case, we will end up with a fully functional GraphQL service, but this choice will influence your project in terms of the amount of work you will need to put to introduce some features (but it’s a topic that deserves to be covered in a separate post).</p>
<h2>Code-first framework for GraphQL Server development</h2>
<p>The rapid growth of GraphQL’s popularity generated the natural need for different tools, both schema-first and code-first oriented, facilitating GraphQL working experience. One of the tools representing the code-first approach is <a href="https://nexus.js.org/">GraphQL Nexus framerwork</a>.</p>
<p>GraphQL Nexus is a GraphQL framework for building your GraphQL Server, where the schema is defined and implemented programmatically. GraphQL Nexus relies on a Node.js and TypeScript thanks to which it can provide features such as:</p>
<ul>
<li><strong>Type-Safety</strong> -  type-definitions are being generated as you proceed with the development process &amp; inferred in your code, providing you with auto-completion and error catching,</li>
<li><strong>Compatibility with GraphQL Ecosystem</strong> - GraphQL Nexus relies heavily on graphql-js and works well with its existing types when constructing the schema which makes the auto-generated schema compatible with most popular tools like Apollo Server etc.,</li>
<li><strong>Data-Agnostic</strong> - GraphQL Nexus is a declarative syntax layered on the top of the graphql-js library which basically means that you can achieve with it all that you can do with graphql-js or apollo-tools.</li>
</ul>
<p>Having figured out all the types you need for your schema all you need to do is simply use <code>makeSchema</code> function to create the schema instance that would be used as the foundation for your GraphQL server.</p>
<div data-language="tsx"><pre><code><span>const</span> schema <span>=</span> <span>makeSchema</span><span>(</span><span>{</span>
  
  types<span>:</span> <span>[</span>User<span>,</span> Query<span>,</span> Mutation<span>]</span><span>,</span>

  
  outputs<span>:</span> <span>{</span>
    typegen<span>:</span> __dirname <span>+</span> <span>'/generated/typings.ts'</span><span>,</span>
    schema<span>:</span> __dirname <span>+</span> <span>'/generated/schema.graphql'</span><span>,</span>
  <span>}</span><span>,</span>

  
  nonNullDefaults<span>:</span> <span>{</span>
    input<span>:</span> <span>true</span><span>,</span>
    output<span>:</span> <span>true</span><span>,</span>
  <span>}</span><span>,</span>
<span>}</span><span>)</span>

</code></pre></div>
<h2>Getting started</h2>
<p>As previously mentioned GraphQL Nexus relies heavily on <code>graphql-js</code> and it’s also required for the installation:</p>
<div data-language="text"><pre><code>npm install nexus
npm install graphql # required as a peer dependency</code></pre></div>
<p>The best way to begin with GraphQL Nexus is of course the <a href="https://nexus.js.org/docs/getting-started">official documentation</a>. After familiarizing with it the next step could be playing around with their <a href="https://github.com/prisma/nexus/tree/develop/examples">official examples</a> and the <a href="https://nexus.js.org/playground">online Playground</a>. Have fun!</p></div><p>The GraphQL Editor is a supportive tool for both advanced GraphQL users as well as those taking their first steps with GraphQL APIs. Our all-in-one development environment for GraphQL will help you build, manage &amp; deploy your GraphQL API much faster thanks to dozens of built-in micro features. Its graphical interface will also fix communication within your product team. Visualization is the key!</p></div>]]>
            </description>
            <link>https://blog.graphqleditor.com/graphql-nexus-codefirst-graphql-server/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269944</guid>
            <pubDate>Tue, 25 Aug 2020 10:46:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Seamless head tracking for games using the TrueDepth camera (iOS)]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24269925">thread link</a>) | @epaga
<br/>
August 25, 2020 | http://www.inflightassistant.com/smoothtrack/index.html | <a href="https://web.archive.org/web/*/http://www.inflightassistant.com/smoothtrack/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <h2>
          <p><a href="https://apps.apple.com/de/app/smoothtrack/id1528839485?l=en"><img src="http://www.inflightassistant.com/img/appstore.svg" height="45/"></a></p>
            
            <p><b><a href="https://testflight.apple.com/join/ytc1tAdA">Click here to join a free public beta</a> which runs on ANY iOS 13 device, not only ones with TrueDepth!</b></p>
            
          <p>SmoothTrack is the best input source for the free OpenTrack software which enables you to use head tracking in your Mac or PC games.</p>
<br>
<div>
  <div>
    <div>
      <p>
        <h6>
          "Just flew a few patterns with this - it genuinely works better for me than TrackIR ever did, at a fraction of the cost." - /u/yawnyprawny
        </h6>
      </p>
    </div>
  </div>
</div>

          <p>SmoothTrack provides you with 6 degrees-of-freedom head tracking for beautiful head tracking for your games.</p>
          

            <p>No headset or extra equipment of any kind is required! Simply set up your device so that it can see your face. Using the on-screen controls, you can shift your perspective in-game.</p>
            

              <p>It's an amazing experience to seamlessly move your head and have your game perspective play along.</p>
              <br>
              <div>
                <div>
                  <div>
                    <p>
                      <h6>
                        "This worked perfectly and way better than expected! Totally enhanced my experience with MFS 2020!" - /u/lexpert1
                      </h6>
                    </p>
                  </div>
                </div>
              </div>
              
              
                <p>Any game that supports the FreeTrack or TrackIR protocol will work with this, including Flight Simulator, Elite: Dangerous, FSX, IL2: Sturmovik, and many, many others!</p>
                

                  <p>INSTRUCTIONS (included in the app):</p>
                  <br>

                    <ol><li>On your computer, install and run the free program "OpenTrack".</li>
                      <li>In OpenTrack, as Input source, choose "UDP over network". As Output, choose "freetrack 2.0 Enhanced".</li>
                        <li>Make sure the UDP port OpenTrack is using is open both on your firewall and router.</li>
                          <li>Find the IP address of your PC</li>
                            <li>Now, in SmoothTrack, set up your IP address and port in the settings</li>
                              <li>Tap Play and you should see the OpenTrack octopus move around, which means any game that supports TrackIR will now be supporting your head tracking!</li>
</ol>
<p>Email support is provided if there are any issues.</p>

    
  
</h2></div></div></div>]]>
            </description>
            <link>http://www.inflightassistant.com/smoothtrack/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269925</guid>
            <pubDate>Tue, 25 Aug 2020 10:43:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Incident updates, interruptions and the 30 minute window]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24269804">thread link</a>) | @vinnyglennon
<br/>
August 25, 2020 | https://www.unixdaemon.net/sysadmin/incident-updates-and-interruptions/ | <a href="https://web.archive.org/web/*/https://www.unixdaemon.net/sysadmin/incident-updates-and-interruptions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>For most companies Incident Commander or Incident Manager is not a
specific job, it’s a role you may take on when something has gone, often
horribly, wrong and you need to quickly unite an adhoc group into a team
to resolve it. The incident commander should be the point of contact,
and source of truth, about your incident and to do that successfully
they’ll need to be updated and kept informed about what’s happening.
Depending on how experienced they are in the role this can be a very
light touch experience or it can feel like being constantly nagged to
put the washing away while someone burns money nearby.</p>
<p>I’ve been involved in a fair few incidents over the years and one of the
best approaches I’ve seen to handling updates and interruptions was from
someone who had an amazing internal clock; or a watch we never noticed.
When handling an incident he’d essentially give himself a 30 minute,
reset-able, window of time. Once he’d been given the initial
introduction to the incident he’d step back, handle the communication
and anything else the incident responders has asked for and wait for
about 30 minutes.</p>
<p>If no one gave him any new information or status updates he’d consider
it an invitation to interrupt and ask what was going on. Once he’d been
updated he’d move back and let the team run with the problem. If someone
gave him an update before the 30ish minutes were up he’d reset his
timer, leave you alone and try to get whatever you’d asked for. I don’t
know if it was just a well chosen period based on experience or the
limit of his patience but 30 minutes was often enough to stop people
rabbit holing while the fires were raging.</p>
<p>Once I’d left the team he often managed incidents for and became one of
his internal customers I began to notice that everyone in his area
developed the subconscious habit of delivering their status updates
every 25 minutes or so, even when he wasn’t the incident manager for
a specific incident. I never discovered if this was all a deliberate
attempt to set the culture he wanted or he was just being himself but as
someone handling an incident I always appreciated the time and
predictability of his involement. Thanks to LinkedIn and Twitter I could
probably track him down and ask but I’ve always liked the idea it was
just him being himself.</p>
</div></div>]]>
            </description>
            <link>https://www.unixdaemon.net/sysadmin/incident-updates-and-interruptions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269804</guid>
            <pubDate>Tue, 25 Aug 2020 10:18:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing good software comments (Part I/2019)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24269760">thread link</a>) | @juanorozcov
<br/>
August 25, 2020 | https://www.brainstobytes.com/writing-good-software-comments-i/ | <a href="https://web.archive.org/web/*/https://www.brainstobytes.com/writing-good-software-comments-i/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<!--kg-card-begin: markdown--><p>Comments are, to put it mildly, a controversial topic.</p>
<p>There are two very strong opinions in software development, both extremely popular and widespread. The first one states that comments are evil, and you should not use them under any circumstance. The main argument is that instead of using comments, you should try to make the code as readable as possible. If the code is written in an expressive way using best practices, comments are not needed.</p>
<p>The second group thinks that comments are a necessity. The code can't hold all the information needed to properly maintain a solution, and comments are an effective way of communication for fellow developers. If all we needed was the code, we could grab the binaries and work from them.</p>
<p>I think both groups have something valuable to teach. It's true that comments can be dangerous, some of the reasons why you might be wary of them are:</p>
<ul>
<li>Comments easily become outdated, and it's unreasonable to expect everyone to update every comment when code changes. It would be an ideal thing, but it rarely happens in reality.</li>
<li>Code is the sole source of truth that is guaranteed to be true at any given point through the lifecycle of software.</li>
<li>A bad comment is worse than no comments at all, as it misleads you into wrong assumptions.</li>
<li>When overused, comments clutter our code and make it harder to find the things we are looking for.</li>
</ul>
<p>Comments are essentially there because we weren't able to perfectly express our ideas in code. Every single time you write a comment, think if it's possible to refactor your code in a way that makes it obvious to the reader. With effort and experience, you can remove most of the unnecessary comments from your projects.</p>
<p>Despite their downsides, comments can be used to effectively communicate with fellow developers. The trick is not to repeat your code, but to clarify its intent and provide valuable extra information that you can't represent in code. If you can keep your comments at a higher level of abstraction, you will have a powerful tool for making your code more maintainable.</p>
<p>Let's take a look at 5 scenarios where using comments can help improve the readability of our code:</p>
<h4 id="explainingtheintentandansweringwhy">Explaining the intent and answering why</h4>
<p>Explaining why things are done in a specific way in the code is one of the most accepted uses for comments.</p>
<p>The reason is simple: code itself only tells you <strong>what</strong> is there, not <strong>why</strong> it is there. The motivations behind seemingly arbitrary choices in design and development are usually found in the documentation, but if you need to keep this information in the source code, comments are the best way of doing it.</p>
<p>Feel free to add comments if you feel that something looks too arbitrary, or to let other developers know why you are doing things the way you are doing them. Don't write a huge essay supporting the choice, a quick one-liner is enough to convey information. Other developers will appreciate this valuable information.</p>
<h4 id="clarifyingdetails">Clarifying details</h4>
<p>Sometimes you need to write small clarifications for input arguments or data returned from a function, in this case, a comment might make things easier to understand.</p>
<p>It's also useful for summarizing a series of complicated operations: writing a small comment that explains the intent of the following lines is useful to understand how they work together.</p>
<p>Another common usage is specifying the units of a variable: is this meant to be a distance in meters or feet?</p>
<p>This might be the weakest use case of the list because comments of this type are rendered useless by giving variables and functions good names. If you want some guidelines for naming variables, you can read the <a href="https://www.brainstobytes.com/writing-good-variable-names/">previous article on the topic</a>.</p>
<h4 id="warningtheuserofamethodaboutsideeffects">Warning the user of a method about side effects</h4>
<p>There are methods with 'dangerous' side effects. Some of them will perform actions that are hard or impossible to revert or will remove records from an important record.</p>
<p>You could have in place some special naming conventions to make this clear. The Ruby community, for example, has a convention for appending a '!' character at the end of methods that perform this type of action. If there is a need for a more detailed explanation, feel free to add a comment explaining the possible dangers of calling a specific method.</p>
<pre><code># Warning!: This method will stop the pipeline and all unprocessed data will be lost, 
# ensure the queue is empty before calling it, otherwise, you might lose data. 
def perform_teardown():
#    Implementation of this method
   return
</code></pre>

<p>You can add little reminders for things you need to improve or refactor later. There are lots of changes that don't merit a new ticket in the issue tracking system, and those little reminders can be useful for not forgetting about these little improvements.</p>
<p>Most modern text editors and IDEs have tools for finding those TODOs, and I have the feature enabled in every single one I use (actually, it's one of the first things I do when setting up a new system). Use them with confidence, TODO comments are ok.</p>
<pre><code># TODO: Find out if there's an efficient alternative for linear algebra and make this method a wrapper around it
def transpose_matrix(matrix)
# code for transposing a matrix
end

</code></pre>
<h4 id="publicapidocumentation">Public API documentation</h4>
<p>Documenting the public interface of your classes is a very important part of software development. You want other users (and well, you too) to know how to use your classes and code. There are many tools that let you convert comments into documentation (PDF, HTML, and other formats), as long as you write your comments with a specific format. The tool will scan your code and extract all the required information for the documents.</p>
<p>Some popular examples are Javadoc for Java and YARD for Ruby, the comments on top of methods look like this:</p>
<p>Javadoc:</p>
<pre><code>/**
 * &lt;p&gt;Translates text from English to alienspeak
 * &lt;/p&gt;
 * @param textInEnglish the text in English I want to translate
 * @return the text after being translated into alienspeak
 */
public String translateToAlienspeak(String textInEnglish) {
    // contents of the function
}
</code></pre>
<p>YARD:</p>
<pre><code># Translates a text from English to alienspeak
#
# @param text_in_english [String] the text in English I want to translate
# @return [String] the text after being translated into alienspeak
def translate_to_alienspeak(text_in_english)
  # content of the function
end
</code></pre>

<p>These are just a couple of cases where comments are helpful, but there are many other scenarios where using a comment is the right thing.</p>
<p>The trick for writing good comments is asking yourself why you are writing them in the first place. Is it to fix a deficiency in the clarity of your code? if that's the case, stop and refactor your code to make it more readable. As we said before, most comments can be omitted in favor of a better-written piece of code.</p>
<p>On the other hand, if you are providing information that your colleagues will find helpful, and there is no way to embed that info in the code, then go for a comment. Good comments can be extremely helpful. Just make sure they are <em>good</em> comments, not lazy patches for code that can still improve.</p>
<p>In the next article, we will see scenarios where comments are definitely a bad choice.</p>
<h2 id="whattodonext">What to do next:</h2>
<ul>
<li>Share this article with friends and colleagues. Thank you for helping me reach people who might find this information useful.</li>
<li>You can find more information about creating good function arguments in chapter 4 of Clean Code, and in chapter 32 of Code Complete. This and other very helpful books can be found in the <a href="https://www.brainstobytes.com/recommended-books/">recommended reading list</a>.</li>
<li>Send me an email with questions, comments or suggestions (it's in the <a href="https://www.brainstobytes.com/about">About Me page</a>). Come on, don't be shy!</li>
</ul>
<!--kg-card-end: markdown-->
					</div></div>]]>
            </description>
            <link>https://www.brainstobytes.com/writing-good-software-comments-i/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269760</guid>
            <pubDate>Tue, 25 Aug 2020 10:11:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I'm shutting down my side-hustle with zero revenue despite traction]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24269743">thread link</a>) | @codecors
<br/>
August 25, 2020 | https://meetchopra.com/blog/looking-back-at-prosper | <a href="https://web.archive.org/web/*/https://meetchopra.com/blog/looking-back-at-prosper">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><article><p>10 months ago, I launched Prosper which started as an NPS software, but ended up becoming a marketing tool. I’m writing this to reflect on why I won't be working on Prosper anymore. What went wrong? What went good? And lastly, what I’m working on next. </p><h2>The Launch</h2><p>The idea behind Prosper was simple, video popups for capturing email address. I added video inside popups to make marketing more real by showing the real person behind the website. It was a completely an unexplored idea. I developed Prosper on weekends and after office hours as I had a full time job.</p><p>It took me a month or two to develop, and on Oct 15th, I launched Prosper on Product Hunt and Hacker News. At the time of launch, I kept the product free, so people could try it out without any friction. The launch went pretty good, and Prosper became #5 trending product of the day. </p><p>For launching on Product Hunt, you might have heard of tactics like, post on Tuesday, 00:00 pacific time. All these matters!. But, one thing that helped me was - the idea. It was the new which helped me a lot in catching eyeballs. People were automatically <a href="https://twitter.com/manikarthik/status/1184018595824619520">sharing and talking</a> about the product. </p><p>And, getting comments&nbsp;from <a href="https://twitter.com/rrhoover">Ryan Hoover</a> (founder of Product Hunt) and <a href="https://twitter.com/jijosunny">Jijo Sunny</a> (founder of Buymeacoffee) added more fuel to my motivation. Whatever users I have got, I can attribute it to Product Hunt only. </p><p data-url=""><img src="https://images.prismic.io/meetchopra/92586717-049b-4af5-ace9-0dc3a399af99_PH_Comments.png?auto=compress,format&amp;rect=0,0,879,208&amp;w=1200&amp;h=284"></p><p>At the same time, launching on Hacker News didn’t bring anything. People there didn’t like the product at all. Hacker News is a really unpredictable platform.&nbsp;</p><h2>Where things started falling</h2><p>After the launch, I started monitoring how the popups were performing. And, here’s where it all started going down.</p><p>According to SumoMe, the average performing popups resulted in 3.1% conversion rate. As I was introducing a new type of solution, it should be at least double the existing conversion rate, which should be around 6%.</p><p data-url=""><img src="https://images.prismic.io/meetchopra/c938d4d5-5c20-4ee5-a066-03dc895a55fe_conversion.png?auto=compress,format&amp;rect=0,0,586,367&amp;w=1200&amp;h=752"></p><p>For my product, 444 users signed up out of which only 5% (23) of the people gave it a try by installing on their website. Out of this thin slice of bread, the conversion rate was nothing. The conversion rate didn't even match for an average performing popups.</p><p data-url=""><img src="https://images.prismic.io/meetchopra/b7280505-7a10-410f-b48d-3bd09298cc4a_prosper_graph.png?auto=compress,format&amp;rect=0,0,1355,788&amp;w=1200&amp;h=698"></p><p>The product needed more experiments at a fast speed like building more types of popups, talking to customers, etc.</p><p>After getting such a good reaction to the idea, and the product not performing well. I was stuck. I didn’t know what to do. It was a pretty confusing state to be in. The product needed more work on a fundamental level. With more experiments at a fast speed, and talking to customers, I’m sure the product would have been in a better place.</p><p>But it struck me hard. I started losing motivation. I was not able to convince myself that my popup works better than the existing one. It was some kind of decision paralysis, where I didn’t know what to pick up next. As I was working solo, it became difficult for me to iterate fast on the product, respond to customers, and work on marketing it all by myself.</p><p>So, as an IndieHacker it turned out to be a pretty bad idea to start with an experimental idea. It was tough and the odds of success are always low if the whole idea is an experiment. It's better to build and serve a proven market that is big enough, as an IndieHacker. Starting with a new idea, that hasn’t been explored much, needs a lot of consistent work which becomes difficult for a single person. So, Prosper turned out to be a bad idea for me.</p><p>What Justin Jackson said in <a href="https://justinjackson.ca/good-idea-or-bad-idea">good idea or bad idea</a> fit’s here perfectly: </p><blockquote><div><p>Bad ideas are&nbsp;hungry: they consume whatever energy, money, or time you throw at them, without giving you anything back.
</p><p>
Good business ideas sweep you up with their momentum.</p></div><a href="#"><svg xmlns="http://www.w3.org/2000/svg" role="img" viewBox="0 0 24 24" data-src="/img/icons/social/twitter.svg" xmlns:xlink="http://www.w3.org/1999/xlink"><title>Twitter icon</title><path d="M23.954 4.569c-.885.389-1.83.654-2.825.775 1.014-.611 1.794-1.574 2.163-2.723-.951.555-2.005.959-3.127 1.184-.896-.959-2.173-1.559-3.591-1.559-2.717 0-4.92 2.203-4.92 4.917 0 .39.045.765.127 1.124C7.691 8.094 4.066 6.13 1.64 3.161c-.427.722-.666 1.561-.666 2.475 0 1.71.87 3.213 2.188 4.096-.807-.026-1.566-.248-2.228-.616v.061c0 2.385 1.693 4.374 3.946 4.827-.413.111-.849.171-1.296.171-.314 0-.615-.03-.916-.086.631 1.953 2.445 3.377 4.604 3.417-1.68 1.319-3.809 2.105-6.102 2.105-.39 0-.779-.023-1.17-.067 2.189 1.394 4.768 2.209 7.557 2.209 9.054 0 13.999-7.496 13.999-13.986 0-.209 0-.42-.015-.63.961-.689 1.8-1.56 2.46-2.548l-.047-.02z"></path></svg><span>Tweet</span></a></blockquote><h2>Quick Learnings</h2><p>While working on Prosper, I learned a few small things. Here’s some of them:</p><ul><li>One thing that struck out was the importance of keeping in touch with your customers, especially in the early days. Be it on twitter, running an email series, or whatever. That’s where you can learn more about them and decide the direction of the product. Talking to customers on support is the best source where you can know them better. </li><li>Keeping your support channels limited. For Prosper, I added my email address, support email address, live chat, and&nbsp;even a phone number. Creating multiple channels to contact was a terrible move. I was not able to reply properly to any customer. I lost the chance to connect with the customers there. For my next products, I have shifted to live chat only. Much better. There's less friction on reaching over chat. </li></ul><p><em>One tip, don’t install drift. Installing drift was a pretty bad decision. You can’t even reply to a chat from email. And, the whole platform&nbsp;seems to be lost. I have started using <a href="https://crisp.chat/">crisp</a> for all my products. Much better. Tons of reliable features with great support.</em></p><ul><li>User onboarding, is very critical. Displaying the value early often and delivering the wow moment will make them come back to your software. Otherwise, people forget about your software after trying it out. If you look at Prosper’s metrics, 76% (341 people) did nothing after signing up. Clearly, I failed at&nbsp;showing the value upfront clearly in as few steps as possible. </li></ul><p data-url=""><img src="https://images.prismic.io/meetchopra/f46fcea2-e502-4f7a-97f0-7a418425bf2c_analytics_prosper.png?auto=compress,format&amp;rect=0,0,1366,820&amp;w=1200&amp;h=720"></p><h2>What’s next?</h2><p>I have 2 things on my plate.</p><p><a href="https://usespotlight.co/">Spotlight</a> and a new product I will be working on -&nbsp;<a href="https://waveapp.io/">Wave</a>.</p><p>I’m building a popup builder. It’s one place for all types of popups. This time I’m not looking for an experimental idea. Since I have some experience in this type of product and with&nbsp;all the previous learnings,&nbsp;I hope it will perform better.&nbsp;I plan to focus more on marketing and building it in public. You can follow me on <a href="https://twitter.com/@meet__chopra">twitter</a>&nbsp;as I share my progress.  </p><p>Also, I’m offering a lifetime deal until&nbsp;I launch the product. Go, check it out - <a target="_blank" rel="noopener" href="https://waveapp.io/">waveapp.io</a></p><p data-url="https://waveapp.io/"><img src="https://images.prismic.io/meetchopra/aa3ad0ce-c328-471d-9ab9-83b9b70bef33_social.png?auto=compress,format&amp;rect=0,0,1200,630&amp;w=1200&amp;h=630"></p><p><em>Thanks to <a target="_blank" rel="noopener" href="https://www.linkedin.com/in/divyasharma411/">Divya Sharma</a> for reviewing the article and making it readable :)</em></p></article></div></div></div></section></div>]]>
            </description>
            <link>https://meetchopra.com/blog/looking-back-at-prosper</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269743</guid>
            <pubDate>Tue, 25 Aug 2020 10:08:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Q from QAnon proves his identity using DES and a 2 character salt from password]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24269647">thread link</a>) | @DyslexicAtheist
<br/>
August 25, 2020 | https://poal.co/s/Whatever/96505 | <a href="https://web.archive.org/web/*/https://poal.co/s/Whatever/96505">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-f9b525e3-30b3-4d38-89c4-1733cfc7da6e">
                  <p>Q verifies his identity via a cryptographic signature, or "tripcodes."  These tripcode hashes (e.g. CbboFOtcZs ) are based on the DES/crypt(3) encryption algorithm.  DES (Digital Encryption Standard) was standardized in 1977 and has been largely deprecated due to widely-known weaknesses.  A good primer on these weaknesses from way back in 1997 can be found here: <a href="http://personal.stevens.edu/~khockenb/crypt3.html">http://personal.stevens.edu/~khockenb/crypt3.html</a> .   Tripcodes are created via the algorithm described here: <a href="http://www.thefullwiki.org/Tripcode">http://www.thefullwiki.org/Tripcode</a>.  I suspect that if such an operation were carried out, the coordinator would at least sign messages using an algorithm from the NSA Suite B, such as the Advanced Encryption Standard (AES) -- or even a PGP signature -- so that an opponent couldn't hijack his identity as easily as has been done here.  He may upgrade his standards after reading this, but frankly, it is a far too late to matter.</p>

<p>Using an open source password cracker (hashcat), publicly available information, and a little guess work about Q's favored key space, a user can successfully recover all of the passwords that correspond to Q tripcodes. These are posted below in chronological order of use:</p>

<p>Tripcode:  ITPb.qbhqo  -&gt;  Password:  Matlock
Tripcode:  UW.yye1fxo  -&gt;  Password:  M@tlock!
Tripcode:  xowAT4Z3VQ  -&gt;  Password:  Freed@m-
Tripcode:  2jsTvXXmXs  -&gt;  Password:  F!ghtF!g
Tripcode:  4pRcUA0lBE  -&gt;  Password:  NowC@mes
Tripcode:  CbboFOtcZs  -&gt;  Password:  StoRMkiL
Tripcode:  A6yxsPKia.  -&gt;  Password:  WeAReQ@Q</p>

<p>Note that Q seems to be unaware that the algorithm only takes the first 8 characters of the password and ignores the rest.  In the past, Q has claimed to have baked meaning and foreknowledge of future events into these passwords, in particular, the 4pRcUA0lBE:NowC@mes tripcode-password pair.  If I understand correctly, Q claims that the full password was "NowC@mesTHEP@in---23," with 23 signifying the date of an important event, but anything beginning with "NowC@mes" would yield the same tripcode signature.  This weakness severely undercuts any claimed predictive power and indicates a possible intent to mislead.  For example, all of the following passwords should yield the same tripcode, 4pRcUA0lBE:</p>

<p>NowC@mesTheKing      -- Q is Snoop Dogg
NowC@mesTheSun       -- Q is Ringo Starr
NowC@mesTheAnswer-42 -- Q is Douglas Adams</p>

<p>These can all be tested at at minichan's tripcode test page. <a href="https://minichan.org/triptest?name=A%23NowC%40mesTheAnswer-42">https://minichan.org/triptest?name=A%23NowC%40mesTheAnswer-42</a> .</p>

<p>To directly test all of these examples with a DES cypher, go to <a href="https://www.functions-online.com/crypt.html">https://www.functions-online.com/crypt.html</a> , paste the password in, and use the second and third characters of the password as the salt.  The tripcode will be the final ten characters of the resulting DES hash.  </p>

          </div></div>]]>
            </description>
            <link>https://poal.co/s/Whatever/96505</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269647</guid>
            <pubDate>Tue, 25 Aug 2020 09:53:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Umash: A fast and universal enough hash]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24269645">thread link</a>) | @gbrown_
<br/>
August 25, 2020 | https://engineering.backtrace.io/2020-08-24-umash-fast-enough-almost-universal-fingerprinting/ | <a href="https://web.archive.org/web/*/https://engineering.backtrace.io/2020-08-24-umash-fast-enough-almost-universal-fingerprinting/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><div><p>We accidentally a whole hash function… but we had a good reason!
Our
<a href="https://github.com/backtrace-labs/umash">MIT-licensed UMASH hash function</a>
is a decently fast non-cryptographic hash function that guarantees
a worst-case bound on the probability of collision
<a href="https://en.wikipedia.org/wiki/Universal_hashing#Mathematical_guarantees">between any two inputs generated independently of the UMASH parameters</a>.</p><p>On the
<a href="https://en.wikichip.org/wiki/intel/xeon_platinum/8175m">2.5 GHz Intel 8175M</a>
servers that power <a href="https://backtrace.io/">Backtrace</a>’s hosted
offering, UMASH computes a 64-bit hash for short cached inputs of up
to 64 bytes in 9-22 ns, and for longer ones at up to 22 GB/s, while
guaranteeing that two distinct inputs of at most \(s\) bytes collide
with probability less than \(\lceil s / 2048 \rceil \cdot 2^{-56}\).
If that’s not good enough, we can also reuse most of the parameters to
compute two independent UMASH values. The resulting 128-bit
<a href="https://en.wikipedia.org/wiki/Fingerprint_(computing)">fingerprint function</a>
offers a short-input latency of 9-26 ns, a peak throughput of 11.2
GB/s, and a collision probability of \(\lceil s / 2048 \rceil^2 \cdot
2^{-112}\) (better than \(2^{-70}\) for input size up to 7.5 GB).
These collision bounds hold for all inputs constructed without any
feedback about the randomly chosen UMASH parameters.</p><p>The latency on short cached inputs (9-22 ns for 64 bits, 9-26 ns for
128) is somewhat worse than the state of the art for non-cryptographic
hashes—
<a href="https://github.com/wangyi-fudan/wyhash">wyhash</a> achieves
8-15 ns and <a href="http://fastcompression.blogspot.com/2019/03/presenting-xxh3.html">xxh3</a>
8-12 ns—but still in the same ballpark. It also
compares well with latency-optimised hash functions like
<a href="https://en.wikipedia.org/wiki/Fowler%E2%80%93Noll%E2%80%93Vo_hash_function#FNV-1a_hash">FNV-1a</a>
(5-86 ns) and
<a href="https://en.wikipedia.org/wiki/MurmurHash#MurmurHash2">MurmurHash64A</a>
(7-23 ns).</p><p>Similarly, UMASH’s peak throughput (22 GB/s) does not match
the current best hash throughput (37 GB/s with
<a href="https://github.com/Cyan4973/xxHash">xxh3</a>
and <a href="https://github.com/gamozolabs/falkhash">falkhash</a>, apparently
10% higher with <a href="https://github.com/cmuratori/meow_hash">Meow hash</a>),
but does comes within a factor of two; it’s actually higher than that of
some performance-optimised hashes, like
<a href="https://github.com/wangyi-fudan/wyhash">wyhash</a> (16 GB/s) and
<a href="https://github.com/google/farmhash">farmhash32</a>
(19 GB/s). In fact, even the 128-bit fingerprint (11.2 GB/s) is
comparable to respectable options like
<a href="https://github.com/aappleby/smhasher/blob/master/src/MurmurHash2.cpp#L89">MurmurHash64A</a>
(5.8 GB/s) and
<a href="https://burtleburtle.net/bob/hash/spooky.html">SpookyHash</a> (11.6 GB/s).</p><p>What sets UMASH apart from these other non-cryptographic hash
functions is its proof of a collision probability bound. In the
absence of an adversary that adaptively constructs pathological inputs
as it infers more information about the randomly chosen parameters, we
know that two distinct inputs of \(s\) or fewer bytes will have the
same 64-bit hash with probability at most \(\lceil s / 2048 \rceil
\cdot 2^{-56},\) where the expectation is taken over the random
“key” parameters.</p><p>Only one non-cryptographic hash function in
<a href="https://github.com/rurban/smhasher">Reini Urban’s fork of SMHasher</a>
provides this sort of bound: <a href="https://github.com/lemire/clhash">CLHash</a>
<a href="https://arxiv.org/abs/1503.03465">guarantees a collision probability \(\approx 2^{-63}\)</a>
in the same
<a href="https://en.wikipedia.org/wiki/Universal_hashing#Mathematical_guarantees">universal hashing</a>
model as UMASH. While CLHash’s peak throughput (22 GB/s) is
equal to UMASH’s, its latency on short inputs is worse (23-25 ns
instead of 9-22ns). We will also see that its stronger collision
bound remains too weak for many practical applications. In order to
compute a <a href="https://en.wikipedia.org/wiki/Fingerprint_(computing)">fingerprint</a>
with CLHash, one would have to combine multiple hashes, exactly like
we did for the 128-bit UMASH fingerprint.</p><p>Actual cryptographic hash functions provide stronger bounds in a much
more pessimistic model; however they’re also markedly slower than
non-cryptographic hashes. <a href="https://github.com/BLAKE3-team/BLAKE3">BLAKE3</a>
needs at least 66 ns to hash short inputs, and achieves a peak throughput
of 5.5 GB/s. Even the <a href="https://github.com/rust-lang/rust/issues/29754">reduced-round SipHash-1-3</a>
hashes short inputs in 18-40 ns and longer ones at a peak throughput
of 2.8 GB/s. That’s the price of their pessimistically adversarial
security model. Depending on the application, it can make sense to
consider a more restricted adversary that must prepare its dirty deed
before the hash function’s parameters are generated at random, and
still ask for provable bounds on the probability of collisions.
That’s the niche we’re targeting with UMASH.</p><p>Clearly, the industry is comfortable with no bound at all.
However, even in the absence of
<a href="https://www.131002.net/siphash/#at">seed-independent collisions</a>,
timing side-channels in a data structure implementation could
theoretically leak information about colliding inputs, and iterating
over a hash table’s entries to print its contents can divulge even more
bits. A sufficiently motivated adversary could use something like
that to learn more about the key and deploy an algorithmic denial of
service attack. For example, the linear structure of UMASH (and of
other polynomial hashes like CLHash) makes it easy to combine known
collisions to create exponentially more colliding inputs. There is no
universal answer; UMASH is simply another point in the solution space.</p><p>If reasonable performance coupled with an actual bound on collision
probability <em>for data that does not adaptively break the hash</em> sounds
useful to you,
<a href="https://github.com/backtrace-labs/umash">take a look at UMASH on GitHub</a>!</p><p>The <a href="#but-why">next section</a> will explain why we found it useful to
design another hash function. The rest of the post
<a href="#umash-high-level">sketches how UMASH works</a> and
<a href="#implementation-tricks">how it balances short-input latency and strength</a>,
before <a href="#usage">describing a few interesting usage patterns.</a></p><p><small>The latency and throughput results above were all measured on
the same unloaded 2.5 GHz Xeon 8175M. While we did not disable
frequency scaling (#cloud), the clock rate seemed stable at 3.1
GHz during our run.</small></p><h2 id="a-idbut-whyahow-did-we-even-get-here"><a id="but-why"></a>How did we even get here?</h2><p>Engineering is the discipline of satisficisation: crisply defined
problems with perfect solutions rarely exist in reality, so we must
resign ourselves to satisfying approximate constraint sets “well
enough.” However, there are times when all options are not only
imperfect, but downright sucky. That’s when one has to put on a
different hat, and question the problem itself: are our constraints
irremediably at odds, or are we looking at an under-explored
solution space?</p><p>In the former case, we simply have to want something else. In the
latter, it might make sense to spend time to really understand the
current set of options and hand-roll a specialised approach.</p><p>That’s the choice we faced when we started caching intermediate
results in
<a href="https://help.backtrace.io/en/articles/2428859-web-console-overview">Backtrace’s database</a>
and found a dearth of acceptable hash functions. Our in-memory
columnar database is a core component of the backend, and, like most
analytics databases, it tends to process streams of similar queries.
However, a naïve query cache would be ineffective: our more heavily
loaded servers handle a constant write load of more than 100 events
per second with dozens of indexed attributes (populated column values)
each. Moreover, queries invariably select a large number of data
points with a time windowing predicate that excludes old data… and
the endpoints of these time windows advance with each wall-clock
second. The queries evolve over time, and must usually consider newly
ingested data points.</p><p><a href="https://www.gsd.inesc-id.pt/~rodrigo/slider_middleware14.pdf">Bhatotia et al’s Slider</a>
show how we can specialise the idea of
<a href="http://adapton.org/">self-adjusting or incremental computation</a>
for repeated MapReduce-style queries over a sliding window.
The key idea is to split the data set at stable boundaries (e.g., on
date change boundaries rather than 24 hours from the beginning of the
current time window) in order to expose memoisation opportunities, and
to do so recursively to repair around point mutations to older data.</p><p>Caching fully aggregated partial results works well for static
queries, like scheduled reports… but the first step towards creating
a great report is interactive data exploration, and that’s an activity
we strive to support well, even when drilling down tens of millions of
rich data points. That’s why we want to also cache intermediate
results, in order to improve response times when tweaking a saved
report, or when crafting ad hoc queries to better understand how and
when an application fails.</p><p>We must go back to a
<a href="http://www.umut-acar.org/self-adjusting-computation">more general incremental computation strategy</a>:
rather than only splitting up inputs, we want to stably partition the
data dependency graph of each query, in order to identify shared
subcomponents whose results can be reused. This finer grained
strategy surfaces opportunities to “resynchronise” computations, to
recognize when different expressions end up generating a subset of
identical results, enabling reuse in later steps. For example, when
someone updates a query by adding a selection predicate that only
rejects a small fraction of the data, we can expect to reuse some of
the post-selection work executed for earlier incarnations of the
query, if we remember to key on the selected data points rather than
the predicates.</p><p>The complication here is that these intermediate results tend to be
large. Useful analytical queries start small (a reasonable query
coupled with cache/transaction invalidation metadata to stand in for
the full data set), grow larger as we select data points, arrange them
in groups, and materialise their attributes, and shrink again at the
end, as we summarise data and throw out less interesting groups.</p><p>When caching the latter shrinking steps, where resynchronised reuse
opportunities abound and can save a lot of CPU time, we often
find that storing a fully materialised representation of the cache key
would take up more space than the cached result.</p><p>A classic approach in this situation is to fingerprint cache keys with
a cryptographic hash function like
<a href="https://en.wikipedia.org/wiki/BLAKE_(hash_function)">BLAKE</a>
or <a href="https://en.wikipedia.org/wiki/SHA-3">SHA-3</a>, and store a
compact (128 or 256 bits) fingerprint instead of the cache key: the
probability of a collision is then so low that we might as well assume
any false positive will have been caused by a bug in the code or a
hardware failure. For example,
<a href="https://users.ece.cmu.edu/~omutlu/pub/memory-errors-at-facebook_dsn15.pdf#page=3">a study of memory errors at Facebook</a>
found that uncorrectable memory errors affect 0.03% of servers each
month. Assuming a generous clock rate of 5 GHz, this means each
clock cycle may be afflicted by such a memory error with probability
\(\approx 2.2\cdot 10^{-20} &gt; 2^{-66}.\) If we can guarantee that
distinct inputs collide with probability significantly less than
\(2^{-66}\), e.g., \(&lt; 2^{-70},\) any collision is far
more likely to have been caused by a bug in our code or by
hardware failure than by the fingerprinting algorithm itself.</p><p>Using cryptographic hashes is certainly safe enough, but requires a lot of
CPU time, and, more importantly, worsens latency on smaller keys (for
which caching may not be that …</p></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://engineering.backtrace.io/2020-08-24-umash-fast-enough-almost-universal-fingerprinting/">https://engineering.backtrace.io/2020-08-24-umash-fast-enough-almost-universal-fingerprinting/</a></em></p>]]>
            </description>
            <link>https://engineering.backtrace.io/2020-08-24-umash-fast-enough-almost-universal-fingerprinting/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269645</guid>
            <pubDate>Tue, 25 Aug 2020 09:51:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DIY Artificial Intelligence: How I build a Potato Chips recognizer with no code]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24269631">thread link</a>) | @danroseai
<br/>
August 25, 2020 | https://danrose.ai/blog/potato-chips-recognizer-with-google-automl | <a href="https://web.archive.org/web/*/https://danrose.ai/blog/potato-chips-recognizer-with-google-automl">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page" role="main">
        
          <article data-page-sections="5ee8645a9b717b3e78ba3365" id="sections">
  
    <section data-section-id="5ee8645a9b717b3e78ba3367" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
  &quot;imageOverlayOpacity&quot; : 0.15,
  &quot;video&quot; : {
    &quot;playbackSpeed&quot; : 0.5,
    &quot;filter&quot; : 1,
    &quot;filterStrength&quot; : 0,
    &quot;zoom&quot; : 0
  },
  &quot;backgroundWidth&quot; : &quot;background-width--full-bleed&quot;,
  &quot;sectionHeight&quot; : &quot;section-height--medium&quot;,
  &quot;horizontalAlignment&quot; : &quot;horizontal-alignment--center&quot;,
  &quot;verticalAlignment&quot; : &quot;vertical-alignment--middle&quot;,
  &quot;contentWidth&quot; : &quot;content-width--wide&quot;,
  &quot;sectionTheme&quot; : &quot;white&quot;,
  &quot;sectionAnimation&quot; : &quot;none&quot;,
  &quot;backgroundMode&quot; : &quot;image&quot;
}" data-animation="none">
  
  <div>
    <div>
      
      
      <div data-content-field="main-content" data-item-id="">
  <article id="article-">
  
    <div>
      

      <div>
        <div><div data-layout-label="Post Body" data-type="item" id="item-5f26bde87e854c47e05b169f"><div><div><div data-block-type="2" id="block-60dc3150fccc97540532"><div><p>I have two passions. Potato chips and artificial intelligence. So why not combine those to show how easy it is to build your own AI models?&nbsp;</p><p>I could do that by crafting an AI, that can accurately predict different brands of potato chips. So that’s what I’m going to do here. I’ll show you how you can make your own AI models for your business or for fun. <strong>All this without coding.</strong><br></p><p>I built this AI on <a href="https://cloud.google.com/automl"><span>Google AutoML</span></a>. By doing that I only had to collect data and upload it to Google that in turn trained the model and deployed it ready to use. If you want a deeper discussion on AutoML you can read <a href="https://www.danrose.ai/blog/automl-is-it-useful"><span>my post here</span></a>.</p><p>You might wonder how expensive or difficult it was. Actually the total cost was around <strong>40 EUR and about three hours of work</strong>.</p><p>The result was pretty amazing. Even though I almost ate the training data before getting started I managed to make a model that accurately recognized the different kinds of chips.</p><h2>Why is this even relevant to you?</h2><p>This project might sound silly but you shouldn’t underestimate the business potential in this easy access to custom AI. If you have a business with a lot of spare parts that employees have to identify on the go, identify mistakes on an assembly line or other visual problems with high frequency then you can save a lot of money with very little effort.</p><p>Besides the visual problems as the one I’m tackling here you can also make your own Language models or forecast based on data in a database.</p><h2>How I did it</h2><p>Now for the fun stuff. I’ll go through the problem I’m trying to solve, how I got training data, how I trained the model and how I evaluated it.</p><h3>The problem</h3></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1596374505645_4904"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596374667861-9JEUPNDONCTZCBRUJEMM/ke17ZwdGBToddI8pDm48kDHPSfPanjkWqhH6pl6g5ph7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0mwONMR1ELp49Lyc52iWr5dNb1QJw9casjKdtTg1_-y4jz4ptJBmI9gQmbjSQnNGng/IMG_20200801_174153.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596374667861-9JEUPNDONCTZCBRUJEMM/ke17ZwdGBToddI8pDm48kDHPSfPanjkWqhH6pl6g5ph7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0mwONMR1ELp49Lyc52iWr5dNb1QJw9casjKdtTg1_-y4jz4ptJBmI9gQmbjSQnNGng/IMG_20200801_174153.jpg" data-image-dimensions="2500x1875" data-image-focal-point="0.5,0.5" alt="IMG_20200801_174153.jpg" data-load="false" data-image-id="5f26be779cf1312821f9e99f" data-type="image" src="https://danrose.ai/blog/IMG_20200801_174153.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596374505645_5194"><div><p>So the problem is simple. I chose four different kinds of potato chips that I wanted the AI to be able to differentiate. To make the problem a little harder I chose two of them to be very similar.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1596374505645_7980"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596374757817-YW7GUER193GKXXOWSRGN/ke17ZwdGBToddI8pDm48kP--Gy_hAcl7mgvb9_zoAut7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UYW6-c2-nOiTzS0bbX-AuynKRuGejHNxHGae8e4Kgea0JvwGh1qtNWvMhYKnvaKhbA/scene00172.png" data-image="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596374757817-YW7GUER193GKXXOWSRGN/ke17ZwdGBToddI8pDm48kP--Gy_hAcl7mgvb9_zoAut7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UYW6-c2-nOiTzS0bbX-AuynKRuGejHNxHGae8e4Kgea0JvwGh1qtNWvMhYKnvaKhbA/scene00172.png" data-image-dimensions="1920x1088" data-image-focal-point="0.5,0.5" alt="scene00172.png" data-load="false" data-image-id="5f26bee278e49e62c8ca1487" data-type="image" src="https://danrose.ai/blog/scene00172.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1596374505645_10463"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596374802772-AYLU13AJVRTKR3DPV1XI/ke17ZwdGBToddI8pDm48kP--Gy_hAcl7mgvb9_zoAut7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UYW6-c2-nOiTzS0bbX-AuynKRuGejHNxHGae8e4Kgea0JvwGh1qtNWvMhYKnvaKhbA/scene00052.png" data-image="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596374802772-AYLU13AJVRTKR3DPV1XI/ke17ZwdGBToddI8pDm48kP--Gy_hAcl7mgvb9_zoAut7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UYW6-c2-nOiTzS0bbX-AuynKRuGejHNxHGae8e4Kgea0JvwGh1qtNWvMhYKnvaKhbA/scene00052.png" data-image-dimensions="1920x1088" data-image-focal-point="0.5,0.5" alt="scene00052.png" data-load="false" data-image-id="5f26bf0f6ae770371cfc9b7c" data-type="image" src="https://danrose.ai/blog/scene00052.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596374505645_8269"><div><p>The images below are respectively “snack chips original” and “snack chips sour cream and onion”. As you can see they look very similar.</p><h2>Getting training data</h2><p>As I’m writing this I’m devouring the remaining training data. I’m a little sick of potato chips now but not ashamed at all. It’s a sacrifice I had to make in the name of AI.<br></p><p>Google recommends around 100 different examples for each label. I was lazy so I went a little below that with 289 images in total with 4 different labels.<br></p><p>Taking 289 would take a while so I did some cheating that you should do if you want to do a similar case. Instead of taking pictures I took video with my smartphone and extracted the images from the video.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1596374505645_15061"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375090548-YPFPV6RDZUMXG4ZHVZ1B/ke17ZwdGBToddI8pDm48kHUzxcQwd2DgHE3KO6VtZClZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PI1qPlfs3HYKbanWcQQqBRZmpTq4czOe8Acgsq9n8pASg/ezgif-7-f5708715b22c.gif" data-image="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375090548-YPFPV6RDZUMXG4ZHVZ1B/ke17ZwdGBToddI8pDm48kHUzxcQwd2DgHE3KO6VtZClZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PI1qPlfs3HYKbanWcQQqBRZmpTq4czOe8Acgsq9n8pASg/ezgif-7-f5708715b22c.gif" data-image-dimensions="800x450" data-image-focal-point="0.5,0.5" alt="ezgif-7-f5708715b22c.gif" data-load="false" data-image-id="5f26bfe6c74d304b66fc0728" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596374505645_15350"><div><p>I used VLC player to extract the frames. VLC has a setting in video filters to extract frames from videos but I guess there is a lot of software out there that can do this for free.</p><p>After getting the images for training data ready I simply logged in to Google Cloud and enabled the AutoML Vision API.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1596374505645_28240"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375153037-X34723CXDQBLC13PQ6XX/ke17ZwdGBToddI8pDm48kOYgNfBE3pTmL5XfhHR4-g97gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1URZssu81Ld-7FrwoxLhHEJd5Cl50eQY0vS3s-ErHaXsWm4bjm9DAHF2kOsIZRJKXnA/Screen+Shot+2020-08-02+at+14.48.04.png" data-image="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375153037-X34723CXDQBLC13PQ6XX/ke17ZwdGBToddI8pDm48kOYgNfBE3pTmL5XfhHR4-g97gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1URZssu81Ld-7FrwoxLhHEJd5Cl50eQY0vS3s-ErHaXsWm4bjm9DAHF2kOsIZRJKXnA/Screen+Shot+2020-08-02+at+14.48.04.png" data-image-dimensions="2496x1448" data-image-focal-point="0.5,0.5" alt="Screen Shot 2020-08-02 at 14.48.04.png" data-load="false" data-image-id="5f26c0700ba3997952d493c5" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375153037-X34723CXDQBLC13PQ6XX/ke17ZwdGBToddI8pDm48kOYgNfBE3pTmL5XfhHR4-g97gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1URZssu81Ld-7FrwoxLhHEJd5Cl50eQY0vS3s-ErHaXsWm4bjm9DAHF2kOsIZRJKXnA/Screen+Shot+2020-08-02+at+14.48.04.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596374505645_28529"><p><br>After that I created a new dataset. In this case I chose single-label classification since it’s the simplest solution for the use case. If you need to identify several different object or even get a bounding box for the position of the object then that is a possibility too.</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1596374505645_31298"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375207786-V040HAI5WIA3H2CU9ZNC/ke17ZwdGBToddI8pDm48kGLi6xYBB2UyCEqI0Pc_jBN7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0raKnEK4LNhjn5BoF_7_GYE-gdvfyxhoPeDE6WiT2jOUQPRcov3m5hi8LiAGJBXlTg/Screen+Shot+2020-08-02+at+14.49.45.png" data-image="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375207786-V040HAI5WIA3H2CU9ZNC/ke17ZwdGBToddI8pDm48kGLi6xYBB2UyCEqI0Pc_jBN7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0raKnEK4LNhjn5BoF_7_GYE-gdvfyxhoPeDE6WiT2jOUQPRcov3m5hi8LiAGJBXlTg/Screen+Shot+2020-08-02+at+14.49.45.png" data-image-dimensions="2500x1450" data-image-focal-point="0.5,0.5" alt="Screen Shot 2020-08-02 at 14.49.45.png" data-load="false" data-image-id="5f26c0a3a9e7856699c0de8c" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375207786-V040HAI5WIA3H2CU9ZNC/ke17ZwdGBToddI8pDm48kGLi6xYBB2UyCEqI0Pc_jBN7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0raKnEK4LNhjn5BoF_7_GYE-gdvfyxhoPeDE6WiT2jOUQPRcov3m5hi8LiAGJBXlTg/Screen+Shot+2020-08-02+at+14.49.45.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596374505645_31587"><p>With the dataset created I know just bulk uploaded potato chips with the UI and put on labels.<br></p></div><div data-block-type="5" id="block-yui_3_17_2_1_1596374505645_34177"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375264281-RW4D3BT3Z27ELG4NPL0U/ke17ZwdGBToddI8pDm48kBCaMk_a5jnPkzckNsOsCmN7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0vc___Vi-l6i_tO81lSXAWFK-5YqTXot-_p5YIxO6Alsb_bOgbgE6mRwf-vgKTQPMg/Screen+Shot+2020-08-02+at+14.49.57.png" data-image="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375264281-RW4D3BT3Z27ELG4NPL0U/ke17ZwdGBToddI8pDm48kBCaMk_a5jnPkzckNsOsCmN7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0vc___Vi-l6i_tO81lSXAWFK-5YqTXot-_p5YIxO6Alsb_bOgbgE6mRwf-vgKTQPMg/Screen+Shot+2020-08-02+at+14.49.57.png" data-image-dimensions="2500x1397" data-image-focal-point="0.5,0.5" alt="Screen Shot 2020-08-02 at 14.49.57.png" data-load="false" data-image-id="5f26c0d6028ea31cb0c01ad3" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375264281-RW4D3BT3Z27ELG4NPL0U/ke17ZwdGBToddI8pDm48kBCaMk_a5jnPkzckNsOsCmN7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0vc___Vi-l6i_tO81lSXAWFK-5YqTXot-_p5YIxO6Alsb_bOgbgE6mRwf-vgKTQPMg/Screen+Shot+2020-08-02+at+14.49.57.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596374505645_34466"><div><p>Easy right? The entire dataset is now ready.</p><h2>Training</h2><p>After getting data I trained the model. I simply clicked “Train new model” and got presented with a few different options. First I chose Cloud hosted. This is for getting the model hosted at Google. ”Edge”, the alternative, is if you want to deploy on devices such as Raspberry Pi.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1596374505645_36444"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375320663-O49CUT6JMCGT2HYQR000/ke17ZwdGBToddI8pDm48kCHV4JP_uPLZT7_OEP-kOap7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0rgHhgU1kmzSCGpabQyjAEJfc6ifPVsNDj16at0jXsT90RiD7LBvSy379FoW-lGkkg/Screen+Shot+2020-08-02+at+14.59.07.png" data-image="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375320663-O49CUT6JMCGT2HYQR000/ke17ZwdGBToddI8pDm48kCHV4JP_uPLZT7_OEP-kOap7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0rgHhgU1kmzSCGpabQyjAEJfc6ifPVsNDj16at0jXsT90RiD7LBvSy379FoW-lGkkg/Screen+Shot+2020-08-02+at+14.59.07.png" data-image-dimensions="2500x1506" data-image-focal-point="0.5,0.5" alt="Screen Shot 2020-08-02 at 14.59.07.png" data-load="false" data-image-id="5f26c116b436d408b92f5330" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375320663-O49CUT6JMCGT2HYQR000/ke17ZwdGBToddI8pDm48kCHV4JP_uPLZT7_OEP-kOap7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0rgHhgU1kmzSCGpabQyjAEJfc6ifPVsNDj16at0jXsT90RiD7LBvSy379FoW-lGkkg/Screen+Shot+2020-08-02+at+14.59.07.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596374505645_38869"><div><p>Next I chose the recommended node hour budget. One node hour is about 3 USD. I also clicked “deploy model” so it’s ready to use.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1596374505645_38580"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375348005-U9MOQ2533XJ5XGKQDTH7/ke17ZwdGBToddI8pDm48kKDD9K8EWjxZpuR9yHkNE4V7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0s2CZOjZ4kkgxkahrfeDuWXrqiwJ1R_kUl8avHlfFlZsQFve0KgIJ3Op-WvcgG54Mg/Screen+Shot+2020-08-02+at+15.01.40.png" data-image="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375348005-U9MOQ2533XJ5XGKQDTH7/ke17ZwdGBToddI8pDm48kKDD9K8EWjxZpuR9yHkNE4V7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0s2CZOjZ4kkgxkahrfeDuWXrqiwJ1R_kUl8avHlfFlZsQFve0KgIJ3Op-WvcgG54Mg/Screen+Shot+2020-08-02+at+15.01.40.png" data-image-dimensions="2500x1616" data-image-focal-point="0.5,0.5" alt="Screen Shot 2020-08-02 at 15.01.40.png" data-load="false" data-image-id="5f26c13035718e4a35afc2c3" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375348005-U9MOQ2533XJ5XGKQDTH7/ke17ZwdGBToddI8pDm48kKDD9K8EWjxZpuR9yHkNE4V7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0s2CZOjZ4kkgxkahrfeDuWXrqiwJ1R_kUl8avHlfFlZsQFve0KgIJ3Op-WvcgG54Mg/Screen+Shot+2020-08-02+at+15.01.40.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596374505645_45675"><div><p>When clicking start training the model’s training. In my experience this is 2-3 hours. Google will send you an email when it’s done, so you don’t have to sit there waiting.</p><h2>The costs</h2><p>I wrote in the introduction that this project had a cost of 40 EUR and three hours of work. To give you a better picture then here’s the costs in a bit more detail.</p><p>Potato chips: 10 EUR.&nbsp;</p><p>Training the model: 30 EUR.</p><p>There will also be some costs associated with hosting data, calling the Gcloud API when using the model and hosting the model. I haven’t put these costs in since they vary a lot based on the use case. That being said it’s usually not a significant cost.</p><p>As a little bonus I actually didn’t spend any real money on this project. When you sign up for Google Cloud they give you a 300 USD voucher to spend on&nbsp;</p><h2>Results</h2><p>Alright. Now for the results. The model actually did pretty well. I expected it to have a lot of trouble with the similar looking kind of chips but it usually guessed the right one with more that 80% confidence. Pretty nice for a few hours of work.</p><p>I tested the confidence directly in the cloud UI as a sanity check.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1596374505645_51339"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375483274-61YNLFP5H638851IJMJH/ke17ZwdGBToddI8pDm48kJkYH13nBiaG57XymelfPbF7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Uc9UkuhcffCPttvW4WBGNe9RETMIZH93Wv--W4mLu0m2G6v6ULRah83RgHXAWD5lbQ/Screen+Shot+2020-08-02+at+13.13.12.png" data-image="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375483274-61YNLFP5H638851IJMJH/ke17ZwdGBToddI8pDm48kJkYH13nBiaG57XymelfPbF7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Uc9UkuhcffCPttvW4WBGNe9RETMIZH93Wv--W4mLu0m2G6v6ULRah83RgHXAWD5lbQ/Screen+Shot+2020-08-02+at+13.13.12.png" data-image-dimensions="2268x1880" data-image-focal-point="0.5,0.5" alt="Screen Shot 2020-08-02 at 13.13.12.png" data-load="false" data-image-id="5f26c1ac0dc876268b21f879" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375483274-61YNLFP5H638851IJMJH/ke17ZwdGBToddI8pDm48kJkYH13nBiaG57XymelfPbF7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Uc9UkuhcffCPttvW4WBGNe9RETMIZH93Wv--W4mLu0m2G6v6ULRah83RgHXAWD5lbQ/Screen+Shot+2020-08-02+at+13.13.12.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596374505645_51628"><p>When the model is ready you also get some analytics about the model.<br></p></div><div data-block-type="5" id="block-yui_3_17_2_1_1596374505645_53690"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375534840-SP4HHBADJ9XGQQZUVNSU/ke17ZwdGBToddI8pDm48kBCppz4f318kQhgOkLoMjtx7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UUHjNPxecGPLsNPOs7j5ghY0WJ3f6AT1P4UchDw8jTgvJvwGh1qtNWvMhYKnvaKhbA/Screen+Shot+2020-08-02+at+13.11.57.png" data-image="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375534840-SP4HHBADJ9XGQQZUVNSU/ke17ZwdGBToddI8pDm48kBCppz4f318kQhgOkLoMjtx7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UUHjNPxecGPLsNPOs7j5ghY0WJ3f6AT1P4UchDw8jTgvJvwGh1qtNWvMhYKnvaKhbA/Screen+Shot+2020-08-02+at+13.11.57.png" data-image-dimensions="2200x1758" data-image-focal-point="0.5,0.5" alt="Screen Shot 2020-08-02 at 13.11.57.png" data-load="false" data-image-id="5f26c1ed78e49e62c8ca635f" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375534840-SP4HHBADJ9XGQQZUVNSU/ke17ZwdGBToddI8pDm48kBCppz4f318kQhgOkLoMjtx7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UUHjNPxecGPLsNPOs7j5ghY0WJ3f6AT1P4UchDw8jTgvJvwGh1qtNWvMhYKnvaKhbA/Screen+Shot+2020-08-02+at+13.11.57.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596374505645_53979"><div><p>Confusion matrix, recall and precision are really interesting metrics to look into when analyzing your model. If you want to utilize AI in your business you should definitely spend some time on this. I wrote a post about this subject <a href="https://www.danrose.ai/blog/vi4gsbdxe78pk3rdhwac8ixbtoin0j"><span>here</span></a>.</p><h2>Connecting to other services</h2><p>Since Google deploy and have an API ready you can from here implement the service into existing web services, mobile apps or other systems. This is really simple and this integration should take long for a developer.</p><h2>Final notes</h2><p>I did this to show how accessible AI really is and hopefully more business will invest in this technology now that the barriers are so low.</p><p>That being said I am a big advocate for the idea that the technical problem in fields like AI is usually the easiest part. Everything around the AI such as the people and processes is usually where the problems start showing. So before you jump right into building AI, spend some time on how it will affect the employees using it and what processes you might want to change. That is usually a very rewardful exercise no matter the technology.</p><p>Have fun building and let me know if you have any fun project ideas I should try out.</p></div></div></div></div></div></div>

        

        
        
          
        
      </div>

      
    </div>
  
</article>

</div>
    </div>
  </div>
</section>

  
</article>

          
          
            

          
          
        
      </div></div>]]>
            </description>
            <link>https://danrose.ai/blog/potato-chips-recognizer-with-google-automl</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269631</guid>
            <pubDate>Tue, 25 Aug 2020 09:49:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clients’ want-tos: ways to accomplish advanced tasks]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24269587">thread link</a>) | @Headqq
<br/>
August 25, 2020 | https://www.purrweb.com/blog/about-client-requests-wristband/ | <a href="https://web.archive.org/web/*/https://www.purrweb.com/blog/about-client-requests-wristband/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        

                          <p><em><span>Using the example of the <a href="https://www.purrweb.com/portfolio/wristband/">WRISTBAND event app</a>, I will tell you how to boost up the hard skills of developers and smoothly test new features right while developing a real project.</span></em></p>
<p>Developers, trying to make <del>life</del> the project process easy and improve their skills, bury themselves in useful tools: frameworks, libraries, manuals. In fact, the situation is as follows: unsolved tasks seem to never end, and the extension of the expertise becomes a daily routine. It’s unlikely that we can change it. And seeking to do it is hardly pragmatic</p>
<p>Let’s see what can be optimized!</p>
<h2>How not to drown in the information chaos</h2>
<p>Client feature request – can it be challenging? Of course! To deal with such, some employers prefer to take team training upon themselves: they buy up various courses and tickets to conferences and hackathons. Is it effective? Probably yes. Are there any other options? Our experience shows — yes.</p>
<p>To level up team skills (to handle tough feature request, you should be a pro), we chose a very rational approach: it’s up to a person what and where to learn, which means that the developers are responsible for their own skills. This saves a lot of time since developers learn skills that are required immediately and test them on real projects.</p>
<p>If the client feature request is about working with a technology we aren’t familiar with, we follow the pre-developed plot. I’ll explain it by using the example of a small passing application for the event industry that we’ve created.</p>
<p><img src="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image6.gif" alt="" width="600" height="365"></p>
<h2>The client feature request is to create something we’ve never done before</h2>
<p>To get more details about this feature request, let us tell you a story. We received a trial task to develop a mobile application from startupers who lived in New Orlean and sold IT-solutions for event organizers. Ok. We’ve got a task. The task was to build a service for security guards which will reduce queues at the entrance and make it real for guests to pass through by using wristbands with RFID-tags.</p>

<p>Creating an interface for this mini-app — only three screens — dead easy for us. But its performance was to be provided by technologies we weren’t sure of. In particular, this applied to RFID tags. At the time, we didn’t work with them, and online research didn’t give a clear answer to our question if there are libraries that can read them.</p>
<p>Additional conditions set by the clients during the briefing made the overall situation even worse. Go ahead and find out what happened.</p>
<p><a href="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image1.png"><img src="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image1.png" alt="" width="1400" height="900" srcset="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image1.png 1400w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image1-300x193.png 300w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image1-768x494.png 768w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image1-1024x658.png 1024w" sizes="(max-width: 1400px) 100vw, 1400px"></a></p>
<h2>The first stage: complexity estimation</h2>
<p>One of the main project challenges — deadlines (tough feature request isn’t the only thing we should worry about). We had less than a month. Besides it, another factor impeding the situation was that the service was to be used from a rare smartphone model that could not be obtained.</p>
<p>One more thing: the application needed steady offline mode. At events (especially held in the open air), there are often problems with the internet connection but a bad signal should not slow down the work of the guards. The app was to be designed so it could work without connection but sync with the server as soon as the internet shows up. What if someone bought a ticket at the last moment or after the event starts?</p>
<p>Handling this feature request didn’t seem challenging, but everything had to be done flawlessly. As it’s supposed that letting through would take no more than 2 seconds, lags and slowdowns were not allowed.</p>
<p><a href="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image8.png"><img src="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image8.png" alt="" width="1400" height="900" srcset="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image8.png 1400w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image8-300x193.png 300w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image8-768x494.png 768w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image8-1024x658.png 1024w" sizes="(max-width: 1400px) 100vw, 1400px"></a></p>
<h2>The second stage: implementation and testing</h2>
<p>As we had less than a month, our strategy was like this: 2 days to test the most problematic features and if find a solution — keep working. The clients were pleased with it and we dug deep in the development stage.</p>
<p>First, we plumbed the depths of RFID tags. We chose several libraries that could help us manage this task. We then discovered that RFID tag — is a predecessor of NFC technology, hence theoretically any smartphone with an NFC module could ‘understand’ the information in the bracelet.</p>
<p>As a result, we created the technical prototype and tested the needed set of features (using our own smartphones and credit cards). The original hypothesis was confirmed, and the library didn’t fail. Since we didn’t have the opportunity to test this functionality on the right model, we sent a technical prototype to the clients. Everything worked as expected, and we promptly switched to other tasks that were not somehow difficult.</p>

<p>So what did we get? A very minimalistic design with traditional ‘traffic light’ colors: red — if the guest doesn’t have access to a zone, and yellow — if the check-in stage was passed earlier. Additionally, app work was accompanied by relevant audio signals which helped to reduce the time of passage of a person through the control point.</p>
<p><a href="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image5.png"><img src="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image5.png" alt="" width="1400" height="900" srcset="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image5.png 1400w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image5-300x193.png 300w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image5-768x494.png 768w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image5-1024x658.png 1024w" sizes="(max-width: 1400px) 100vw, 1400px"></a></p>
<h2>The third stage: consolidation of knowledge</h2>
<p>What can help you in mastering a new feature (and handling client feature request — particularly, the toughest ones) is telling your teammates about it. Unlike attending conferences, this practice is a mandatory and regular ritual that happens several times a month in our team. No preludes or formalities — a short speech of 30 minutes is enough.</p>
<p>As part of an in-company meetup, we discuss not only features but also the process of solving problems. Sometimes we end with a detailed guide — this works in cases when the team regularly uses a particular technology (for example, FaceID).</p>
<p><a href="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image2.png"><img src="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image2.png" alt="" width="1400" height="900" srcset="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image2.png 1400w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image2-300x193.png 300w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image2-768x494.png 768w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image2-1024x658.png 1024w" sizes="(max-width: 1400px) 100vw, 1400px"></a></p>
<p>Initially, it seemed that programmers would be skeptical about such performances and the prospect of broadcasting ‘about something’ in public would strain them. In fact, it turned out differently: the opportunity to share experience was taken with sympathy. People were glad to get the chance to be an expert. Plus, such events added value to the work and greatly improved the team spirit.</p>
<h2>Conclusion</h2>
<p>The app and the wristband have successfully worked at several events, and the project is now actively developing. What about us: we have been working on the contactless payment feature and we’re almost in the home stretch, which means that the bracelet will contain not only information about access to specific zones but also turn into an e-wallet that can be used for transactions at the event.</p>
<p><a href="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image3.png"><img src="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image3.png" alt="" width="1400" height="900" srcset="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image3.png 1400w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image3-300x193.png 300w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image3-768x494.png 768w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image3-1024x658.png 1024w" sizes="(max-width: 1400px) 100vw, 1400px"></a></p>
<p>For example, you will be able to pay via it for a dish on the food court or in the shop zone. Thus, the app has become the basis for an infrastructure service that allows to collect detailed statistics about the event and purchases made during it. And we have got a promising client who likes to experiment with technology and is ready to entrust us with the most complex pieces.</p>
              </div></div>]]>
            </description>
            <link>https://www.purrweb.com/blog/about-client-requests-wristband/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269587</guid>
            <pubDate>Tue, 25 Aug 2020 09:42:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[E-Yuan (China's coin) is fake, who would have guessed]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24269449">thread link</a>) | @phorcys
<br/>
August 25, 2020 | https://git.rip/phorcys/e-yuan-is-scam | <a href="https://web.archive.org/web/*/https://git.rip/phorcys/e-yuan-is-scam">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div dir="auto">

<p>Info: SSH access won't work right now</p>

</div></div>]]>
            </description>
            <link>https://git.rip/phorcys/e-yuan-is-scam</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269449</guid>
            <pubDate>Tue, 25 Aug 2020 09:11:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My AI Timelines Have Sped Up]]>
            </title>
            <description>
<![CDATA[
Score 77 | Comments 72 (<a href="https://news.ycombinator.com/item?id=24269316">thread link</a>) | @T-A
<br/>
August 25, 2020 | https://www.alexirpan.com/2020/08/18/ai-timelines.html | <a href="https://web.archive.org/web/*/https://www.alexirpan.com/2020/08/18/ai-timelines.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>For this post, I’m going to take artificial general intelligence (AGI) to mean
an AI system that matches or exceeds humans at almost all (95%+)
economically valuable work. I prefer this definition because it focuses on what
causes the most societal change, rather than how we get there.</p>

<p>In 2015, I made the following forecasts about when AGI could happen.</p>

<ul>
  <li>10% chance by 2045</li>
  <li>50% chance by 2050</li>
  <li>90% chance by 2070</li>
</ul>

<p>Now that it’s 2020, I’m updating my forecast to:</p>

<ul>
  <li>10% chance by 2035</li>
  <li>50% chance by 2045</li>
  <li>90% chance by 2070</li>
</ul>

<p>I’m keeping the 90% line the same, but shifting everything else to
be faster. Now, if you’re looking for an argument of why I picked these particular
years, and why I shifted by 10 years instead of 5 or 15, you’re going to be
disappointed. Both are driven by a gut feeling.
What’s important is why parts of my thinking have changed - you can choose
your own timeline adjustment based on that.</p>

<p>Let’s start with the easy part first.</p>

<h2 id="i-should-have-been-more-uncertain">I Should Have Been More Uncertain</h2>

<p>It would be incredibly weird if I was never surprised by machine learning (ML)
research.
Historically, it’s very hard to predict the trajectory a research field will
take, and if I were never surprised, I’d take that as a personal failing to
not consider large enough ideas.</p>

<p>At the same time, when I think back on the past 5 years, I believe I was
surprised more often than average. It wasn’t all in a positive direction.
Unsupervised learning got better way faster than I expected. Deep reinforcement
learning got better
a little faster than I expected. Transfer learning has been slower than
expected. Combined, I’ve decided I should widen the distribution of outcomes,
so now I’m allocating 35 years to the 10%-90% interval instead of 25 years.</p>

<p>I also noticed that my 2015 prediction placed 10% to 50% in a 5 year range,
and 50% to 90% in a 20 year range. AGI is a long-tailed event, and there’s
a real possibility it’s never viable, but a 5-20 split is absurdly skewed.
I’m adjusting accordingly.</p>

<p>Now we’re at the hard part. Why did I choose to shift the 10% and 50% lines
closer to present day?</p>



<p>Three years ago, I was talking to someone who mentioned
that <a href="https://intelligence.org/2017/10/13/fire-alarm/">there was no fire alarm for AGI</a>.
I told them I knew Eliezer Yudkowsky had written another post about AGI, and
I’d seen it shared among Facebook friends, but I hadn’t gotten around to reading it.
They summarized it as, “It will never be obvious when AGI is going to occur.
Even a few years before it happens, it will be possible to argue AGI is far
away. By the time it’s common knowledge that AI safety is the most
important problem in the world, it’ll be too late.”</p>

<p>And my reaction was, “Okay, that matches what I’ve gotten from my Facebook
timeline. I already know the story of
Fermi predicting <a href="https://books.google.com/books?id=aSgFMMNQ6G4C&amp;pg=PA813&amp;lpg=PA813&amp;dq=weart+fermi&amp;source=bl&amp;ots=Jy1pBOUL10&amp;sig=c9wK_yLHbXZS_GFIv0K3bgpmE58&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwjNofKsisnWAhXGlFQKHbOSB1QQ6AEIKTAA#v=onepage&amp;q=%22ten%20per%20cent%22&amp;f=false">a nuclear chain reaction was very likely
to be impossible</a>, only a few years before he worked on the
Manhattan Project. More recently, we had
<a href="https://www.wired.com/2014/05/the-world-of-computer-go/">Rémi Coulom state that superhuman Go was about 10 years away</a>,
one year before <a href="https://arxiv.org/abs/1412.6564">the first signs it could happen</a>,
and two years before <a href="https://en.wikipedia.org/wiki/AlphaGo_versus_Lee_Sedol">AlphaGo</a> made it official.
I <em>also</em> already know the <a href="https://en.wikipedia.org/wiki/Common_knowledge_(logic)">common knowledge</a>
arguments for AI safety.”
I decided it wasn’t worth my time to read it.</p>

<p>(If you haven’t heard the common knowledge arguments, here’s the quick
version: it’s possible for the majority to believe AI safety is
worthwhile, even if no one says so publicly, because each individual could be
afraid everyone else will call them crazy if they argue for drastic action. This can happen
even if literally everyone agrees, because they don’t know that everyone agrees.)</p>

<p>I read the post several years later out of boredom, and
I now need to retroactively complain to all my Facebook friends who only
shared the historical events and common knowledge arguments. Although
that post summary is <em>correct</em>, the ideas I found useful were all
<em>outside that summary</em>. I trusted you, filter bubble! How could you let me
down like this?</p>

<p>Part of the fire alarm post proposes hypotheses for why people claim AGI is
impossible. One of the hypotheses is that researchers pay too much attention
to the difficulty of getting something working with their current tools,
extrapolate that difficulty to the future, and conclude we could never create
AGI because the available tools aren’t good enough.
This is a bad argument, because your extrapolation needs to account for
research tools also improving over time.</p>

<p>What “tool” means is a bit fuzzy. One clear example is our coding libraries.
People used to write neural nets in Caffe, MATLAB, and Theano. Now it’s mostly
TensorFlow and PyTorch. A less obvious example is
feature engineering for computer vision. When was the
last time anyone talked about <a href="https://en.wikipedia.org/wiki/Scale-invariant_feature_transform">SIFT features</a> for computer vision? Ages ago,
they’re obsolete. But feature engineering didn’t disappear, it just turned into
<a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural net</a> architecture tuning instead.
For a computer vision researcher, SIFT features were the old tool,
convolutional neural nets are the new tool, and computer vision is the application
that’s been supercharged by the better tool.</p>

<p>Whereas for me, I’m not a computer vision person. I think ML for control is a much
more interesting problem. However, you have to do computer vision to do control
in image-based environments, and if you want to handle the real world, image-based
inputs are the way to go. So for me, computer vision is the tool, robotics
is the application, and the improvements in computer vision have driven many
promising robot learning results.</p>

<p><img src="https://www.alexirpan.com/public/ai-timelines/filters.png" alt="AlexNet conv filters"></p>

<p>(Filters automatically learned by <a href="https://en.wikipedia.org/wiki/AlexNet">AlexNet</a>, which has
itself been obsoleted by the better tool, <a href="https://en.wikipedia.org/wiki/Residual_neural_network">ResNets</a>.)</p>

<p>I’m a big advocate for research tools. I think on average, people underestimate
their impact. So after reading the hypothesis that people don’t forecast
tool improvement properly, I thought for a bit, and decided I hadn’t properly
accounted for it either. That deserved shaving off a few years.</p>

<p>In the more empirical sides of ML, the obvious components of progress are your
ideas and computational budget, but there are less obvious ones too, like
your coding and debugging skills, and your ability to utilize your compute.
It doesn’t matter how many processors you have per machine, if your code doesn’t
use all the processors available.
There are a surprising number of ML applications where the main value-add
comes from better data management and data summarizing,
because those tools free up decision making time for everything else.</p>

<p>In general, everyone’s research tools are deficient in some way.
Research is
about doing something new, which naturally leads to discovering new problems,
and it’s highly unlikely someone’s already made the perfect tool for a problem
that didn’t exist three months ago. So, your current
research tools will <em>always</em> feel janky, and you shouldn’t be using that to
argue anything about timelines.</p>

<p>The research stack has lots of parts, improvements continually happen across that
entire stack, and most of
these improvements have multiplicative benefits. Multiplicative factors
can be very powerful.
One simple example is that to get 10x better results, you can either make one
thing 10x better with a paradigm shift, or you can make ten different
things
<a href="https://www.google.com/search?&amp;q=1.26^10">1.26x better</a>, and they’ll combine
to a 10x total improvement.
The latter is just as transformative, but can be much easier,
especially if you get 10 experts with different skill sets
to work together on a common goal. This is how corporations become a thing.</p>

<p><img src="https://www.alexirpan.com/public/ai-timelines/tiny-gains-graph.jpg" alt="Tiny gains graph"></p>

<p>(From <a href="https://jamesclear.com/marginal-gains">JamesClear.com</a>)</p>

<h2 id="semi-supervised-and-unsupervised-learning-are-getting-better">Semi-Supervised and Unsupervised Learning are Getting Better</h2>

<p>Historically, unsupervised learning has been in this weird position where it is
obviously the right way to do learning, and also a complete waste of time if
you want something to work ASAP.</p>

<p>On the one hand, humans don’t have labels for most things they learn,
so ML systems shouldn’t need labels either. On the other hand, the
deep learning boom of 2015 was mostly powered by supervised learning on
large, labeled datasets.
Richard Socher made a notable tweet at the time:</p>

<div>
<blockquote><p lang="en" dir="ltr">Rather than spending a month figuring out an unsupervised machine learning problem, just label some data for a week and train a classifier.</p>— Richard Socher (@RichardSocher) <a href="https://twitter.com/RichardSocher/status/840333380130553856?ref_src=twsrc%5Etfw">March 10, 2017</a></blockquote> 
</div>

<p>I wouldn’t say unsupervised learning has always been useless. In 2010, it was
common wisdom that deep networks should go through an unsupervised pre-training
step before starting supervised learning. See <a href="https://jmlr.csail.mit.edu/papers/volume11/erhan10a/erhan10a.pdf">(Erhan et al, JMLR 2010)</a>.
In 2015, self-supervised word vectors like <a href="https://nlp.stanford.edu/projects/glove/">GloVe</a>
and <a href="https://en.wikipedia.org/wiki/Word2vec">word2vec</a> were automatically
learning interesting relationships between words.
As someone who started ML around 2015,
these unsupervised successes felt like exceptions to the rule. Most other
applications relied on labels. Pretrained ImageNet features
were the closest thing to general behavior, and those features were learned
from scratch through only supervised learning.</p>

<p>I’ve long agreed that unsupervised learning is the future, and the right way
to do things, as soon as we figure out how to do so.
But man, we have spent a long time trying to do so.
That’s made me
pretty impressed with the semi-supervised and unsupervised learning papers from
the past few months.
Momentum Contrast from <a href="https://arxiv.org/abs/1911.05722">(He et al, CVPR 2020)</a>
was quite nice, SimCLR from <a href="https://arxiv.org/abs/2002.05709">(Chen et al, ICML 2020)</a> improved
on that, and Bootstrap Your Own Latent <a href="https://arxiv.org/abs/2006.07733">(Grill, Strub, Altché, Tallec, Richemond et al, 2020)</a>
has improved on that. And then there’s <a href="https://arxiv.org/abs/2005.14165">GPT-3</a>,
but I’ll get to that later.</p>

<p>When I was thinking through what made ML hard, the trend lines were pointing to larger
models and larger labeled datasets. They’re still pointing that way now.
I concluded that future ML progress would be bottlenecked by labeling requirements.
Defining a 10x bigger model is easy. <em>Training</em> a 10x bigger model is harder, but
it doesn’t need 10x as many people to work on it. Getting 10x as many labels
does. Yes, data labeling tools are getting better, <a href="https://en.wikipedia.org/wiki/Amazon_Mechanical_Turk">Amazon Mechanical Turk</a> is very popular, and there are even
startups whose missions are to provide fast data labeling …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.alexirpan.com/2020/08/18/ai-timelines.html">https://www.alexirpan.com/2020/08/18/ai-timelines.html</a></em></p>]]>
            </description>
            <link>https://www.alexirpan.com/2020/08/18/ai-timelines.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269316</guid>
            <pubDate>Tue, 25 Aug 2020 08:41:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eclipse Dirigible 5.1.0]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24269256">thread link</a>) | @delchevn
<br/>
August 25, 2020 | https://www.dirigible.io/release/2020/08/24/news_new_release_5_1.html | <a href="https://web.archive.org/web/*/https://www.dirigible.io/release/2020/08/24/news_new_release_5_1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<header>
				
				
				<sub>August 24, 2020</sub>
				
			</header>
			<p>New version <a href="https://download.eclipse.org/dirigible/drops/R-5.1-202008241951/index.html">5.1</a> has been released.</p>

<p>Release is of <em>Type A</em></p>

<h4 id="features">Features</h4>

<ul>
  <li>Support for required properties</li>
  <li>Security Roles management the Entity/Property UIs</li>
  <li>Support for more widget types</li>
  <li>Support for pattern based validation</li>
  <li>Support for widget length</li>
  <li>Support for pattern hint</li>
  <li>Support for Color widget type</li>
  <li>Projection Entity type introduced</li>
  <li>Application template separation</li>
  <li>SAP Cloud Foundry - Runtime Only Image</li>
  <li>Enhanced build of application WAR from the pre-defined packages</li>
  <li>SAP Cloud Foundry Ephemeral - Runtime Only</li>
  <li>Form Builder - Experimental</li>
</ul>

<h4 id="fixes">Fixes</h4>

<ul>
  <li>List the available icon names in a dropdown</li>
  <li>SAP Cloud Foundry - Missing Default Database Configuration</li>
  <li>SAP CMS - MS files content type override</li>
  <li>Minor fixes</li>
</ul>

<h4 id="statistics">Statistics</h4>

<ul>
  <li>54K+ Users</li>
  <li>77K+ Sessions</li>
  <li>184 Countries</li>
  <li>394 Repositories in DirigibleLabs</li>
</ul>

<h4 id="operational">Operational</h4>

<ul>
  <li>Available packages for download - <a href="https://download.eclipse.org/dirigible/drops/R-5.1-202008241951/index.html">https://download.eclipse.org/dirigible/drops/R-5.1-202008241951/index.html</a></li>
  <li>Docker images at Docker Hub under DirigibleLabs organization:	<a href="https://hub.docker.com/u/dirigiblelabs/">https://hub.docker.com/u/dirigiblelabs/</a></li>
  <li>Maven Central artifacts by org.eclipse.dirigible namespace: <a href="https://search.maven.org/search?q=org.eclipse.dirigible">https://search.maven.org/search?q=org.eclipse.dirigible</a></li>
  <li>The full list of bug-fixes and enhancements can be found here: <a href="https://github.com/eclipse/dirigible/milestone/35?closed=1">https://github.com/eclipse/dirigible/milestone/35?closed=1</a></li>
  <li>The source code is available at GitHub repository here: <a href="https://github.com/eclipse/dirigible/tree/5.1.0">https://github.com/eclipse/dirigible/tree/5.1.0</a></li>
  <li>The instant trial is updated accordingly with the released version here: <a href="http://trial.dirigible.io/">http://trial.dirigible.io</a></li>
</ul>

<h4 id="enjoy">Enjoy!</h4>

		</article></div>]]>
            </description>
            <link>https://www.dirigible.io/release/2020/08/24/news_new_release_5_1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269256</guid>
            <pubDate>Tue, 25 Aug 2020 08:31:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My reflections on Smittestopp (Norwegian Covid-app)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24269039">thread link</a>) | @eivarv
<br/>
August 25, 2020 | https://www.eivindarvesen.com/blog/2020/06/27/my-reflections-on-smittestopp | <a href="https://web.archive.org/web/*/https://www.eivindarvesen.com/blog/2020/06/27/my-reflections-on-smittestopp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <p>We – the government appointed expert group – published our final public report last month (informally summarized by me in English <a href="https://www.eivindarvesen.com/blog/2020/05/20/smittestopp-summarized">here</a>) on the Norwegian COVID-19 app "Smittestopp", ascertaining whether security and privacy is responsibly taken care of.</p>
<p>In a group effort such as this one, there is often compromise –&nbsp;in order to be able to end up with a result everyone involved can justify to themselves, and stand by.</p>
<p><strong>We all agree on the conclusion in our report.</strong></p>
<p>There are, however – in <em>my</em> opinion – certain issues that are not addressed in the final report (and that might be out of scope for the report), that I think are imporant to consider. I will state some of these here, in addition to expanding on issues that appear in the report.</p>
<p><em>What I write here is my own professional opinion on security- and privacy aspects of the Norwegian COVID-19 contact tracing app, "Smittestopp". I do not (and can not) speak on behalf of any other persons, including any other members of the government appointed expert group. Nothing described herein is covered by NDA or legislation – everything is completely based on public information and what is described in our public report.</em></p>
<h2>Introduction and Context</h2>
<p>Comparatively, Norway was fairly early in rolling out an app, and the app itself is arguably one of the most invasive ones on the market – at least in a European context, where there are few (if any) other countries with the same configuration of privacy-impacting factors.</p>
<p>Smittestopp&nbsp;is a closed-source solution; requires registration and de facto identification of users; collects sensor data from multiple sources (both BLE and GPS); and uploads data from all users, all of the time, to a centralized storage – unless users pause collection, but even then "heartbeats" that contain information about BLE and GPS-activations in the app are sent in the background. </p>
<p>The degree to which (if any) there is data minimization in such a solution has been questioned by experts in public debate from the get-go.</p>
<p>Some of the design choices has been defended by involved parties in the media, as a prerequisite for attempting to both contact tracing <em>and</em> generating data for monitoring of public movement and other research and analysis purposes (including datasets for long term use).
One might then question the choice of attempting to solve both problems with one application, and what the privacy implications of this might be.</p>
<p>Any privacy engineer (and indeed many others with a modicum of technical or practical understanding) will quickly see that these design choices have practical consequences – and, in my assessment, huge privacy implications.</p>
<h2>Location data</h2>
<p><img src="https://www.eivindarvesen.com/content/blog/2020/06/27/location.jpg" alt="Man on a smartphone" title="Man on a smartphone"></p>
<p>What one is interested in when performing contact tracing is "who met whom". The identity of either party, or the location of contact is not relevant to prove contact.
You thus don't necessarily need to know <em>who</em> the involved parties are, or <em>where</em> the contact took place.</p>
<p>The argument made for the use of location data in the case of Smittestopp is to attempt to compensate for lack in data quality as a consequence of Bluetooth API limitations at the time: Bluetooth wouldn't work reliably in the backround on iOS, whereas Android might kill apps that continuously used Bluetooth or location services in the background.</p>
<p>On the other hand, GPS has a typical accuracy of 3 - 10 meters under ideal conditions (meaning outdoor usage).</p>
<p>A proper and transparent evaluation of the possibilities available here might then include:</p>
<ul>
<li>How big of a problem does the current API limitations pose in practice (i.e. "could we get by at all?")</li>
<li>If workarounds are needed, how do we evaluate alternatives (for instance, non-exhaustively):
<ul>
<li>Attempting to "live with" the current limitations</li>
<li>The Singaporean approach (in practice implementing a faux sleep-mode, necessitating keeping the app in foreground, but dimming screen when device is positioned "upside-down")</li>
<li>Collecting location data, which is Personally Identifiable Information (PII)</li>
</ul></li>
<li>How do the privacy implications of the respective alternatives size up against each other and the issue at hand?</li>
</ul>
<p>Though it has been claimed that this data is "anonymous" in several contexts, this is incorrect. By virtue of being personally identifiable information, location data cannot be anonymous by definition.
Location data can in itself reveal a person's identity. There is no such thing as "anonymous location data" on an individual basis. In aggregated datasets, one can have certain quantifiable guarantees about degree of privacy (e.g. via <a href="https://en.wikipedia.org/wiki/K-anonymity" target="_blank" rel="noopener noreferrer">k-anonymity</a>, <a href="https://en.wikipedia.org/wiki/Differential_privacy" target="_blank" rel="noopener noreferrer">differential privacy</a>), but this gets complicated very quickly for a variety of reasons, such as temporal correlations or re-identification by combining data sources.</p>
<p>In practice, location data is only a <em>clear</em> functional requirement (of sorts, not necessarily to this degree of accuracy) in the case of monitoring public movement or other research – the second purpose of the app.</p>
<h2>Centralized storage</h2>
<p>When we talk about centralized storage in the context of contact tracing apps, we usually mean systems that are based on collection that is uploaded to a central server, which holds all data. This is in contrast with decentralized systems, where every user's data is stored on their device – until it is needed. One should also note that most popular decentralized solutions are not <em>distributed</em>, i.e. they still use a central server as a communications channel of some sort (as opposed to purely peer-to-peer communications).</p>
<p>The argument made in favor of data centralization in the case of Smittestopp is that augmentation of user data with data from other users is needed in analysis. It is also a prerequisite for the purpose of looking at movement patterns (to evaluate government actions), or do further unspecified research on aggregated data – which is also a purpose of the same app.</p>
<p>A centralized datastore is in principle a defining factor when dealing with private data. Its very existence makes misuse, function creep, leakage and so on possible in a way that a decentralized solution just plainly doesn't –&nbsp;as you can't lose or abuse data you don't have.</p>
<p>Alternative sources to aggregated data may already exist, such as the data telco's already provide in aggregate form, and which has already been used for the same purposes in Norway. The upside in using this is reusing existing data (not collecting, storing, protecting the same data) and existing control mechanisms that protects security and privacy. The downside is that this data might not be as precise as location data collected directly from devices, as resolution would depend on a host of factors, including cell site density.</p>
<p>The privacy cost of uploading every user's locations and movements, as well as who they have met, and timestamps for all these events is undoubtably <em>much</em> larger than uploading what data is needed <em>when</em> needed, e.g. prompting users to upload their movements (or even just BLE-defined contacts) once a person they have been in contact with is positively diagnosed with COVID-19.</p>
<h2>Two purposes</h2>
<p>The current app is all-or-nothing, in that users can chose to have their data used for all the app's purposes, or to not use the app.</p>
<p>It is obviously not ideal to <em>not</em> let users explicitly opt in for either purpose. Nor is it in accordance with regular GDPR-demands (though we must remember that this is a major crisis), nor even best practice. A potential consequence of implementing one app that collects <em>a lot</em> of data (as a consequence of enabling two purposes), as well as not giving users a choice is that user uptake may be hampered.</p>
<h2>Data integrity and user traceability</h2>
<p>The use and communications of static device identifiers makes it possible to track or impersonate others, trace users in limited/partial leaks, and so on. Just about <em>every</em> other proposed solution (both protocol specifications, and existing apps) use "rolling" identifiers in one form or another. </p>
<p>Data was temporarily stored in an unencrypted database on user devices in previous versions of the app, which made it possible to inject or modify data before uploading it to the server.</p>
<p>The application connects to a cloud solution using an everlasting connection string, using no other session handling.</p>
<p>All of this means that data integrity cannot be guaranteed, at least in the parts of the dataset collected before fixes for some of these issue was released.</p>
<h2>Identifying users and analytics data</h2>
<p><img src="https://www.eivindarvesen.com/content/blog/2020/06/27/silhouette.jpg" alt="Silhouette of man" title="Silhouette of man"></p>
<p>In order to use the application, users have to register their phone number (de facto identifying themselves). Functionally, there is no need to identify any involved party. Even in contact tracing, users could be notified by the application when a contact has been diagnosed with COVID-19 by health authorities.
One could argue that registration is a mechanism that protects against bogus uploads to some extent – but this, in addition to protection of privacy, is in a sense built-in to decentralized approaches that demands human intervention before any upload takes place (e.g. distributing upload-codes, in the case of DP-3T) – many of which also lets users choose specificly what timespans to share.</p>
<p>Smittestopp was also found to be uploading analytics data (including potentially fingerprintable information) on just about any interaction the users do with the application –&nbsp;without telling users this (it was not stated in the privacy policy) or letting them choose whether they want to upload this data.</p>
<h2>Legal implications</h2>
<p><strong>Note:</strong> <em>I am not a lawyer. Read my reflections with this in mind.</em></p>
<p>The regulation that is the formal basis for processing of the data mentions that health- and location data collected for this purpose can not be shared with law enforcement, etc.
Bluetooth-data, however, is not mentioned. I interpret this as sharing of Bluetooth-data being permitted. This would mean that parties the data is shared with could be able to, for instance, build social graphs of the data subjects.
Though the regulation puts in place certain limitations …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.eivindarvesen.com/blog/2020/06/27/my-reflections-on-smittestopp">https://www.eivindarvesen.com/blog/2020/06/27/my-reflections-on-smittestopp</a></em></p>]]>
            </description>
            <link>https://www.eivindarvesen.com/blog/2020/06/27/my-reflections-on-smittestopp</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269039</guid>
            <pubDate>Tue, 25 Aug 2020 07:51:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DIY Single-Chip 2D Retro Game Console]]>
            </title>
            <description>
<![CDATA[
Score 124 | Comments 25 (<a href="https://news.ycombinator.com/item?id=24268585">thread link</a>) | @0xmarcin
<br/>
August 24, 2020 | http://www.voja.rs/PROJECTS/GAME_HTM/1_intro.htm | <a href="https://web.archive.org/web/*/http://www.voja.rs/PROJECTS/GAME_HTM/1_intro.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <td rowspan="4">
      <div>
			<iframe width="420" height="315" src="//www.youtube.com/embed/VbTwWFwbsE4" frameborder="0" allowfullscreen=""></iframe>
			<p>
			<img height="420" src="http://www.voja.rs/PROJECTS/GAME_HTM/console.jpg" width="600"></p>
			<p>This 
			DIY project offers the
            simple stand-alone VGA game console which is based on <b> PIC24EP512GP202</b>  microcontroller.
            As the video signal and the corresponding sync signals are generated by software, 
			the console contains a
            minimum of hardware. There is also an audio signal output with five binary tone channels, mixed by 
			a 
			passive resistor network. Two of those channels are used for sound effects,  
			similar to ones used in video games of that time (early eighties) and 
			three for background music. This output is capable of driving line 
			output for PC speakers or headphones.</p>
			<p>
			It should be noted that there is no video processing unit, PGA or 
			any special purpose chips, and that PIC microcontrollers are not 
			designed for video signal generation. Everything is achieved by a 
			series of different design tricks and some compromises.</p>
			<p>
			This is an open hardware and open software project. Video 
			and audio generators, which are the vital parts of the firmware, are 
			the parts of the operating system, which will soon be documented, and can be used 
			for any other game or application. As the timings are critical, those parts 
			are written in assembly language, but all the other parts of the 
			program (scenario for some other games or any other application) may 
			also be written in some other programming language, preferably 
			Microchip's C. In this case all parts are written in Assembler, but 
			only as a result of author's preference.</p>
			<p>
			At the moment, only the game Jumping Jack is written for the 
			platform, well known to those who played with the Spectrum personal 
			computer back in the day. However, once a new game is created, it is 
			easy to download it from the computer, via 
			the serial port. The console has a USB connector, but it is used 
			only for 5V power supply. Unfortunately, microcontrollers which are 
			packed in DIP packages (with thru-hole soldering, convenient for DIY 
			projects and workshops) do not have USB interface but only serial ports, so 
			you have to use RS 232 to download the new game instead of Jumping 
			Jack, which is deafult in this project.</p>
			<p>
			If you want to build this console, you need the PCB and components 
			which are listed <span><strong>
			<a href="http://www.voja.rs/PROJECTS/GAME_HTM/2.%20Hardware.htm#BOM">here</a></strong></span>. 
			To program the microcontroller, you should need a PIC programmer (e.g. 
			<strong>PICKIT3</strong>, avaliable <span><strong>
			<a href="http://www.microchipdirect.com/ProductSearch.aspx?Keywords=PG164130">here</a></strong></span>) and
			<strong>MPLAB X IDE</strong> software, available <span><strong>
			<a href="http://www.microchip.com/pagehandler/en-us/family/mplabx/">here</a></strong></span>. 
			But if you want to know how PIC generates video and audio signals by 
			software in real time, or even if you feel ambitious enough to 
			create your own game for this platform, please visit the
			<span>
			<strong><a href="http://www.voja.rs/PROJECTS/GAME_HTM/2.%20Hardware.htm">next page</a></strong></span></p>
          </div>
    </td>
  </div></div>]]>
            </description>
            <link>http://www.voja.rs/PROJECTS/GAME_HTM/1_intro.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24268585</guid>
            <pubDate>Tue, 25 Aug 2020 06:23:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Renaissance of the Shell?]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 59 (<a href="https://news.ycombinator.com/item?id=24268533">thread link</a>) | @dwmkerr
<br/>
August 24, 2020 | https://effective-shell.com/docs/part-1-transitioning-to-the-shell/6-the-renaissance-of-the-shell/ | <a href="https://web.archive.org/web/*/https://effective-shell.com/docs/part-1-transitioning-to-the-shell/6-the-renaissance-of-the-shell/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>This is the first of the “interludes” which end each section of the book. They don't teach any specific skills but instead give a little flavour and background about the world of the shell, Linux and modern computing.</p><p>In this first interlude we'll look at just why the shell is experiencing something of a renaissance in the modern age of IT.</p><p>To be honest, it is hard to know whether there is an increase in popularity of the use of the shell and command-line tooling in general. There are data sources which indicate there is more widespread usage amongst the technical community - Stack Overflow tag popularity is one. LinkedIn data on desired skillsets is another. However, disassociating whether there is a general increase in the need for diverse technical skillsets and whether there is a <em>specific</em> increase in the popularity of keyboard and script operated systems is a challenge.</p><p>For the purposes of this chapter, we'll instead examine changes in the technology landscape over the last few decades and consider what those changes might mean for the shell, the command-line and similar tools.</p><p>We'll look at three specific developments in technology:</p><ul><li>Diversity of programming languages</li><li>Convergence of operating platforms</li><li>DevOps</li></ul><p>Each of these developments has a potentially profound impact on how we work with computers, and might hint at the long term need for shell skills.</p><p>So let's look at some of the key changes in the technology landscape over recent years and consider how they might affect the popularity and importance of the shell.</p><h2 id="the-diversity-of-programming-languages">The Diversity of Programming Languages</h2><p>There have been many programming languages and platforms over the years. But in recent years it is possible that the diversity has increased at a greater rate than ever before.</p><p>With the advent of the internet and the increase in the size of the online technical community, programming has in a sense become more democratised (which we will discuss a little more in the ‘citizen coder’ section). When in the past it was necessary to find physical books or teachers and tutors to learn a programming language, students can now find a wealth of resources online.</p><p>It is perhaps this democratisation which has led to a startlingly diverse world of programming languages. For many years, there were a small number of ‘general purpose’ languages, and a larger number of highly specialised languages (and associated platforms).</p><p>“C”, and later, “C++” were the go-to languages for systems programming (sometimes backed up by assembly language). This was the language which kernels and compilers were written in.</p><p>“Java” become the ‘general purpose’ language of choice for applications which had to run on many systems. “Basic” and later “C#” were the standards for Windows platform development. PHP was a staple for web development.</p><p>Alongside these giants were the workhorses for specific use cases. Erlang was (and is) a language which is highly popular in the telecommunications industry, where high availability and reliability were paramount. COBOL was the language for the financial industry, where mission critical systems ran on mainframes (and many still do).</p><p>Of course there were many other languages, but many of these other languages were highly specific, in a sense C, Java, PHP and later C# dominated the landscape.</p><p>Transition to the time of writing. In the Stack Overflow 2020 Technology Survey[^1], the top ten languages most wanted by employers are:</p><ul><li>Python</li><li>JavaScript</li><li>Go</li><li>TypeScript</li><li>Rust</li><li>Kotlin</li><li>Java</li><li>C++</li><li>SQL</li><li>C#</li></ul><p>Some of our old friends are there, but there are many new languages, languages which are evolving quickly. Later on in the list we will see Swift, Dart, Ruby, Haskell, Scala. There are many programming languages which are extremely popular today.</p><p>Why does this matter for the shell? The answer is that for <em>many</em> new languages, developer tooling is not as mature (some might say bloated) as it is for the ‘Workhorse’ languages. Java developers are likely very familiar with the Eclipse IDE, Microsoft shops will be familiar with Visual Studio. These are products which have been evolving for years (or decades) to support developers with rich integrated development environments.</p><p>For server-side JavaScript, Golang, Rust, Python and other languages, the development environment really is the shell. Modern editors like Visual Studio Code, Atom and so on provide a vast amount of support and tooling, encompassing the features of a full fledged IDE if the user wants. But for modern programming languages, users often have <em>had</em> to rely on the shell to compile, transpile, manage packages, bundle and so on. The average developer today is perhaps much more likely to have to use the shell - to manage Python virtual environments one day, to run Node.js another, to install packages for Golang another.</p><p>In time tooling will likely catch up and provide a ‘friendly’ interface on top of these operations, but many engineers have realised (or always known) that direct access to simple command line tools can be <em>extremely efficient</em> when working, and that overly featured IDEs can get in the way and hide complexity.</p><p>The modern programming is often polyglot - having to be at least familiar in a number of languages. The shell provides a common environment and interface for tooling, which is accessible by all, without installing many complex components, for both development and runtime environments.</p><h2 id="convergence-of-operating-platforms">Convergence of Operating Platforms</h2><p>Whilst the variety in programming languages and developer tooling may have increased, in many ways the <em>operating platforms</em> engineers use have become more homogeneous.</p><p>In the early days of computing, each operating environment was highly diverse. There were many systems which were used for production and many of them were highly proprietary. Even popular application servers were often closed source and highly specialised.</p><p>The modern execution environment however is often fairly uniform. A Linux-like system, with few customisations, which the developer or operator can tweak to suit their needs.</p><p>More and more enterprise users have moved away from proprietary Unix platforms to Linux platforms (whether commercial or non-commercial). The earliest cloud environments were using open-source Linux distributions as the available operating systems.</p><p>Even Windows has increasing support for Linux-like operation, in the form of the Windows Subsystem for Linux.</p><p>Perhaps the greatest movement in this area has been the rapid adoption of Docker as a common container technology. Containers, or container-like systems have been around for a long time, but Docker brought containers to the masses. With Docker, engineers expect operating environments to be even more uniform and Linux-like.</p><p>This has made knowledge of the shell extremely valuable. For any containerised workloads, Linux and shell skills are crucial. Kubernetes (as an execution environment) has standardised things even more.</p><p>Whilst there are still many workloads which run on proprietary systems, modern solutions are often built to run in containers on Linux. The shell has historically been the most common way to manage Linux systems, and the standardisation of operating environments around Linux, or Linux-like systems has made shell skills even more critical.</p><h2 id="devops">DevOps</h2><p>Love it or hate it, DevOps has exploded in popularity. DevOps engineers, site-reliability engineers, these kinds of roles may have been unheard of in companies not that long ago and are now becoming ubiquitous.</p><p>In attempting to unify the goals of development and operation of software, DevOps represents an organisational and cultural change. Rather than having one group focus on feature development and another group focus on reliable software operations, a single group is responsible for both. The theory is that this encourages software engineers to also consider security, reliability, maintainability etc, and operators to also consider speed of delivery.</p><p>Regardless of whether teams are genuinely combined, or specialised roles are added to teams, or even if teams are still separated, the lines between development and operations blur somewhat. Software developers are expected to build and plan with knowledge of the execution environment, operators are expected to work with developers to build features which support reliability.</p><p>The intersection of these two roles often is in the realm of automation. Automated deployments after testing, automated failover in case of errors, automated alerting when potential issues are discovered, automated provisioning of environments, automated scaling of systems when load increases.</p><p>The world of automation is intimately linked to the world of the shell and in particular shell scripting. Many tasks which require automation can be easily achieved using shell scripts. Many aspects of modern environments (such as cloud environments) support provisioning and management of services via scripting. In fact, services which <em>cannot</em> be managed via shell scripts or simple interfaces are increasingly becoming obsolete. If it cannot be scripted, it cannot be automated, and the increasingly complex systems we build <em>require</em> automation.</p><p>In practice, this means software engineers are far more likely to have to build shell scripts (or at least understand how to interface with systems via the shell) than they perhaps might have been. Similarly, operators are far more likely to have to <em>program</em> automated routines to manage high availability and so on. Again, the shell and shell scripts are a common way to manage this (even if they are simply entrypoints to more complex systems, such as scripts which execute programs).</p><p>The rise in popularity of DevOps as a set of practices and beliefs has perhaps made the shell more popular, and more important, than any other recent developments in software engineering.</p><p>And for these reasons and many more, learning how to use the shell effectively has never been more relevant or practical.</p></article></div>]]>
            </description>
            <link>https://effective-shell.com/docs/part-1-transitioning-to-the-shell/6-the-renaissance-of-the-shell/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24268533</guid>
            <pubDate>Tue, 25 Aug 2020 06:13:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cyph and PGP – An Alternative to Keybase]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24268298">thread link</a>) | @LaSombra
<br/>
August 24, 2020 | https://www.cyph.com/blog/cyph-pgp | <a href="https://web.archive.org/web/*/https://www.cyph.com/blog/cyph-pgp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main><article><div><div><p><img src="https://www.cyph.com/wp-content/uploads/2020/06/AdobeStock_296619919.png?ef8fdd9eb11b8a5b7c39e3671fa0de8da9750a94d0c5b7339c6f8a91bd5dd134b356d2c31d8f0742a87b385c263376447a98a62bed24dfa27e7dfaa20e370124" alt="Cyph + PGP"></p></div></div></article><section><div><p><span>One of our major competitors, Keybase, was </span><a href="https://news.ycombinator.com/item?id=23102430"><span>acquired by Zoom</span></a><span> last month.</span></p><p><span>Many Keybase users are now </span><a href="https://news.ycombinator.com/item?id=23103386"><span>looking for alternatives</span></a><span> as a result, primarily due to a lack of trust in the new ownership to maintain high privacy standards, as well as speculation that the service is now doomed to ultimately be shut down. However, no single solution has so far stood out from the crowd; instead, users are faced with the prospect of setting up a hodgepodge of independent solutions.</span></p><p><span>Keybase is great, but a full alternative is clearly needed. That’s why we’ve spent the past month building new features to make Cyph more of a direct replacement.</span></p><p><img src="https://www.cyph.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-10-at-4.38.11-PM-1024x640.png?9e56b59e17dd8d0c24ced228ed7ea88c2bcabfe24b86ae53a95ba06df0fb6d2b2fa818ab92622828b0eba4e32774328f7715ea8cc2eb380f2f14521decd6842b" alt="" width="560" height="350"></p><p><span>Cyph’s features and general architecture are similar in many ways to Keybase, plus/minus a few features:</span></p><ul><li><span>On the plus side, our features include voice/video calling (with group support), Bitcoin, and social networking (like Twitter, but all posts are signed + optionally encrypted for a subset of your contacts).</span></li><li><span>On the minus side, Keybase offers some awesome niche features (like encrypted git repos) that we currently do not.</span></li><li><span>And now, with our latest release, we’ve built out a set of PGP key management and utility features to make Cyph more immediately useful for users coming from Keybase.</span></li></ul><p><img src="https://www.cyph.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-10-at-4.39.49-PM-1024x640.png?f0bd1ee3132c87cc78b8cedeb60710eeb23fd5a7f872ad008ea828201a5fddb2fc486aab5a5ddcc0f006233616219034b2a9fb46fd4f93ec95de99dc175143cc" alt="" width="560" height="350"></p><p><span>Additionally, the architecture of Cyph yields some </span><i><span>significant</span></i><span> broader advantages:</span></p><ul><li><span>Full web support</span><ul><li><span>Whereas Keybase splits up its features between the web UI, the CLI, GPG, and the native apps, thanks to </span><a href="https://www.cyph.com/websign"><span>WebSign</span></a><span> Cyph is able to provide a consistent experience across all platforms. The full functionality is available regardless of whether you use </span><a href="https://cyph.app/"><span>https://cyph.app</span></a><span> or the desktop and mobile apps, with no need to worry about degraded security on the web.</span></li></ul></li><li><a href="https://www.cyph.com/agse"><span>Automatic strong public key authentication</span></a><span> for all users</span><ul><li><span>No need to verify keys or usernames out of band, meet up in person to compare fingerprints or “Safety Numbers”, etc.</span></li></ul></li><li><a href="https://www.cyph.com/blog/quantum-resistance"><span>Quantum-resistant cryptography</span></a><ul><li><span>Post-quantum encryption, key exchange, and signing algorithms are used throughout the application (in combination with classical crypto such as elliptic curves). Whereas others are still planning long-term migrations to post-quantum crypto, Cyph was built with it in mind from the start, meaning that your private data is theoretically protected from future QC attacks </span><i><span>today</span></i><span>.</span></li></ul></li></ul><p>We encourage you to submit a response to <a href="https://docs.google.com/forms/d/e/1FAIpQLSdMOdjPKf1O3jb2vBURF5N-UGsr08XLO6GJazlUOy1r_sCnKQ/viewform">our poll</a><span> to vote on the missing features you’d like us to add. And if you’re a Keybase user, just include your username and email address to skip the line and get a free invite to the Cyph beta!</span></p></div></section><section></section></main></div></div></div>]]>
            </description>
            <link>https://www.cyph.com/blog/cyph-pgp</link>
            <guid isPermaLink="false">hacker-news-small-sites-24268298</guid>
            <pubDate>Tue, 25 Aug 2020 05:15:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Animal behavior during a solar eclipse]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 36 (<a href="https://news.ycombinator.com/item?id=24268252">thread link</a>) | @everbody
<br/>
August 24, 2020 | https://readwildness.com/23/poli-eclipse | <a href="https://web.archive.org/web/*/https://readwildness.com/23/poli-eclipse">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				
				<p><span>The farm dimmed mid-afternoon</span>, dipping into dusk-light. Beside the parked tractors, we passed around a block of green glass from a welder’s helmet and took turns looking through it up at the sky. I chewed a single pebble of a snap pea in my mouth. That was the size of the sun through the glass, I thought, no bigger than a pea, a sliver missing as if chewed by a caterpillar or potato beetle.</p>
				
				<p>In a total solar eclipse, photosynthesis slows down. Plants, which turn to face the sun throughout the day, may change direction, feeling for the light. Without the sun, they become unmoored. Lost in the dark. In the 2017 eclipse, changes in light intensity were attributed to bees going temporarily still. Observers in the path of totality—the stretch of land where the sun goes fully dark—reported fireflies emerging, crickets chirping. Night behavior bleeding into day.</p>
				
				<p>I stared through the glass. Sun the size of a blueberry. Size of a chrysanthemum bud.</p>
				
				<p>We wouldn’t get to see the total eclipse—that dramatic upheaval of the afternoon’s forward march, an ebb when there should be flow. The path of totality was south of us, stretching from Oregon to South Carolina. Still, the light waned at our small farm. Contrast became muted, the sky and hayfields feeling duller, softer. The zinnia patch still sparked with its shocks of red, orange, pink, yellow, but the flowers seemed unsure of themselves. The shadows from the trees did strange things, cast crescent-shaped spells on the ground, reminding me of the light funneled through a dime-store kaleidoscope. Someone arrived with a pair of glasses—the kind made from plastic and cardboard that they’d been selling at gas stations for months, running out in the final few days. We passed them around, but <span>I preferred the welding glass, the way it turned the sliver of sun goblin-green.</span></p>
				
				<p>Sun the size of a kernel of the summer’s first sweet corn; the size of a worm, coiled inside an ear from the later crop, chewing on its silky tassel.</p>
				
				<p>During a total solar eclipse, dairy cows have been known to return to their barn as the sun and sky darken. Orb-weaving spiders have been observed taking down their webs during totality, then rebuilding them <span>when the sun reappears. Some species of birds will sing out their night calls,</span> then go to their roosts, falling silent; when the sun reappears, they start their morning rituals. In this sense, the eclipse is a microcosm of night, the dark sped up, the hour hand spinning around a clock at a horse’s trot.</p>
				
				<p>Sun the size of a pepper seed. Size of a flea beetle. A ladybug resting on a windowsill. A thistle bur stuck to a coat.</p>
				
				<p>There is no evidence that an eclipse affects the behavior of horses, but nevertheless, there will be some owners who usher them into the safety of the barn before the sky goes dark. This is a form of love which happens to involve a kind of captivity.</p>
				
				<p>Sun the size of a nostril, size of a belly button, a baby’s tooth, a fingertip. Size of the chunk of flesh I’d sliced off the top of my thumb one day when I was careless with a head of cauliflower. It bled so much and so steadily that I ran to the back of the farm stand where someone sat me down on a bench to bandage the cut. I remember they held my hand so carefully, tilting it one direction then the other, saying twice, maybe three times, <i>You need to be more careful</i>.</p>
				
				<p>Once we’d passed around the glass, we scattered to our different jobs. I drove back to the snap pea patch, where I continued filling a bucket with round, ripe pods. I heard a tractor starting, the exhaust clearing its throat, then watched from where I was crouched as someone connected a hay rake to the back and pulled back onto the road, headed for one of the higher fields, leaving a cloud of dust and acres of silence behind. I realized then that the birds, which were usually a constant chorus, had gone quiet—the small snapping of my hands plucking peas from their vines, the only noise that reached me. I stood, stretching, and looked at the sky, the familiar fields—their flat, muted light. I stood there looking at the farm that for years I had grown to know and care for, and I thought of scale—of how the land surrounding me had come to feel like it was my own body, a breathing, pulsing creature that could weep or swell; and, at the same time, how the land felt unthinkably large—a roaring sun—the weight of it and of the people who worked it reaching deep into the smallest cracks and crevasses of my life like the tendrilled arms of solar flares bursting.</p>
				
				<p>I thought of all of this as I rolled another snap pea over my tongue, biting down, tasting the small eruption of green. Then I bent down, knees to dirt, to finish my work.</p>
				
				<hr>
				
				<p>Read more from <a href="https://readwildness.com/23">Issue No. 23</a> or share  on <a href="http://www.facebook.com/share.php?u=http://readwildness.com/23/poli-eclipse">Facebook</a> and <a href="https://twitter.com/share?url=http://readwildness.com/23/poli-eclipse&amp;via=platypuspress&amp;related=twitterapi%2Ctwitter&amp;hashtags=wildnessjournal&amp;text=Check%20this%20out">Twitter</a>.</p>
				
			</section></div>]]>
            </description>
            <link>https://readwildness.com/23/poli-eclipse</link>
            <guid isPermaLink="false">hacker-news-small-sites-24268252</guid>
            <pubDate>Tue, 25 Aug 2020 05:02:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacking the Tesla Model 3 – Security Overview]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24268185">thread link</a>) | @cwaffles
<br/>
August 24, 2020 | https://fn.lc/post/tesla-model-3/ | <a href="https://web.archive.org/web/*/https://fn.lc/post/tesla-model-3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="content" itemprop="articleBody">
    <p><em>See the follow up at <a href="https://fn.lc/post/tesla-model-3-services/">Hacking my Tesla Model 3 - Internal API</a>.</em></p>
<p>I recently got a Tesla Model 3 and since I’m a huge nerd I’ve been spending a
lot of time poking at the systems and trying to reverse engineer/figure out how
to root my car.</p>
<p>I work on Machine Learning infrastructure so I’d love to be able to take a deep
look at how autopilot/FSD works under the hood and what it can actually do
beyond what limited information the UI shows. I know some people have managed to
get a copy of this.</p>






<a href="https://fn.lc/images/tesla-model-3/model-3-owned.jpg">
<amp-img src="../../images/tesla-model-3/model-3-owned.jpg" height="2048" width="3526" layout="responsive">
</amp-img>
</a>


<div>
  <p>Displaying messages on the screen using the internal API. Version 2020.12.11.1</p>

</div>


<h2 id="existing-research">Existing Research</h2>
<p>A lot of the existing knowledge about the internal systems are specific to the
older Model S cars since their security is pretty non-existent. The Model 3 (and
presumably the newer Model S/X/Y) has numerous layers of security measures. The
high level architecture is fairly similar but has been hardened a lot.</p>
<h3 id="model-3">Model 3</h3>
<ul>
<li><a href="https://github.com/lewurm/blog/issues">lewurm’s blog posts about his Model 3</a></li>
</ul>
<h3 id="model-sx">Model S/X</h3>
<ul>
<li><a href="https://twitter.com/greentheonly">green’s analysis from his older Model S</a></li>
<li><a href="https://github.com/Lunars/tesla">Lunar’s Model S MCU1 info dumps/wiki</a></li>
<li><a href="https://www.pentestpartners.com/security-blog/reverse-engineering-the-tesla-firmware-update-process/">Reverse Engineering the Tesla Firmware Update Process</a></li>
<li><a href="https://github.com/jnuyens/freedomev">freedomEV for Model S MCU1</a></li>
</ul>
<h4 id="tencent-keen-security-lab">Tencent Keen Security Lab</h4>
<ul>
<li><a href="https://www.blackhat.com/docs/us-17/thursday/us-17-Nie-Free-Fall-Hacking-Tesla-From-Wireless-To-CAN-Bus-wp.pdf">Free-Fall: Hacking Tesla From Wireless To CAN BUS</a></li>
<li><a href="https://i.blackhat.com/us-18/Thu-August-9/us-18-Liu-Over-The-Air-How-We-Remotely-Compromised-The-Gateway-Bcm-And-Autopilot-Ecus-Of-Tesla-Cars-wp.pdf">Over-The-Air: How We Remotely Compromised The Gateway, BCM, and Autopilot ECUs Of Tesla Cars</a></li>
</ul>
<h2 id="tesla-security-researcher-program">Tesla Security Researcher Program</h2>
<p>Before I touched my car at all, I registered as part of the Tesla bug bounty
program and my car is a research-registered vehicle. If you’re interested in
poking at your car at all, I’d highly recommend registering as Tesla will try to
fix it if you brick your car.</p>
<blockquote>
<p>If, through your good-faith security research, you (a pre-approved, good-faith
security researcher) cause a software issue that requires your
research-registered vehicle to be updated or “reflashed,” as an act of
goodwill, Tesla shall make reasonable efforts to update or “reflash” Tesla
software on the research-registered vehicle by over-the-air update, offering
assistance at a service center to restore the vehicle’s software using our
standard service tools, or other actions we deem appropriate.</p>
</blockquote>
<p><a href="https://www.tesla.com/about/security">https://www.tesla.com/about/security</a></p>
<h2 id="internal-layout-of-the-car">Internal Layout of the Car</h2>
<p>All of the higher level components are connected via an internal Ethernet
switch. These include:</p>
<ul>
<li>cid/ice - this is the computer that controls the display and all of the media
systems such as sound.
<ul>
<li>192.168.90.100</li>
</ul>
</li>
<li>autopilot primary and secondary computers.
<ul>
<li>192.168.90.103 - ap/ape</li>
<li>192.168.90.105 - ap-b/ape-b</li>
</ul>
</li>
<li>Gateway - this is primarily UDP server that controls the switch, vehicle
config and proxies requests between the ethernet side (cid/autopilot) and the
<ul>
<li>192.168.90.102
CAN BUS to the motor controllers and sensors.</li>
</ul>
</li>
<li>Modem - this is the LTE modem
<ul>
<li>192.168.90.60</li>
</ul>
</li>
<li>Tuner - this is for the AM/FM radio. Not present on the newer Model 3 cars
including mine. Not having an AM/FM radio does seem like a safety issue so I
was surprised to see it was removed.
<ul>
<li>192.168.90.60</li>
</ul>
</li>
</ul>
<h2 id="seceth---secure-ethernet-tcam">seceth - Secure Ethernet TCAM</h2>
<p>The internal car network appears to be using a Marvel 88EA6321 as a switch. This
is an automative gigabit switch.</p>
<p>Most of the connections are using 100BASE-T1 which is a 2 wire PHY for ethernet.
The autopilot computers, modem, tuner, gateway, CID all use 100Base-T1. There’s
two standard ethernet ports. One is located on the CID motherboard and has a
standard ethernet jack. The other is located in the driver side footwell and has
a <a href="https://teslaownersonline.com/threads/ethernet-port-in-driver-footwell.15045/">custom connector</a>.</p>
<h3 id="dsa">DSA</h3>
<p>The switch appears to be using something called <a href="https://www.kernel.org/doc/Documentation/networking/dsa/dsa.txt">Distributed Switch
Architecture</a>
and TCAM.</p>
<p>DSA allows the switch to be controlled by a separate processor. In the
Model 3, I believe the Gateway controls it. I haven’t seen any references to the
Linux dsa subsystem in the CID.</p>
<h3 id="tcam">TCAM</h3>
<p>TCAM is a special type of memory that can do very fast lookups/filters in a
sincel cycle. This allows for the Gateway to specify packet filters for the
switch to apply. By default the ethernet port in the driver side footwell is
disabled by these rules. The diagnostic jack on the CID motherboard can only
access port 8080 (Odin) and 22 (SSH) on the CID.</p>
<p>There is a way to disable the secure ethernet but this seems to be only
accessible via Odin by Tesla engineering and possibly service.</p>
<p>There’s apparently a daily changed code that unlocks the diagnostic
port/service mode. Service likely has to get this from Tesla via Toolbox.</p>
<h2 id="hermes---talking-to-the-mothership">Hermes - Talking to the Mothership</h2>
<p>The older Model S cars use a persistent OpenVPN connection to communicate with the
“mothership” as Tesla refers to it. All communication with Tesla go through this
VPN connection so there’s no way to sniff any of the updates.</p>
<p>Instead of using OpenVPN, the Model 3 runs a proxy service called Hermes. Hermes
is a relatively simple service that can proxy unauthenticated requests on the
CID to the mothership. Presumably maintaining persistent OpenVPN connections on
500,000+ cars wasn’t scalable so they switched to a lower overhead solution.</p>
<p>Hermes also allows Tesla to make requests to the car itself and fetch logs from
it. Presumably this is how Tesla can enable features such as Full Self-Driving
over the air without a full software update as well as do remote service.</p>
<h3 id="certificates">Certificates</h3>
<p>Every car is issued unique client certificates for Hermes/OpenVPN and they’re
periodically rotated. This makes it quite hard to do things like grabbing
firmware images or inspect Tesla’s backend since you first have to get root
access to a car.</p>
<p>These certificates live under <code>/var/lib/car_creds/car.{crt,key}</code>.</p>
<pre><code># Phone Home connects to devices over Hermes based on the
# Hermes certificate CN.
...
#     subject=
#     CN=BANGELOM300000001
#     OU=Tesla Motors
#     O=Tesla
#     L=Palo Alto
#     ST=California
#     C=US
</code></pre><p>Each car is issued a specific common name that’s only accessible internally to
make it harder for attackers to try and fake a cert. This is relevant for SSH as
we’ll see later.</p>
<h3 id="binaries">Binaries</h3>
<p>There’s a bunch of different hermes binaries. They all seem to be written in
<em>Go</em> :). It’s nice to see my favorite programming language running in my car.</p>
<pre><code>$ ls opt/hermes/
hermes_client*     hermes_fileupload*  hermes_historylogs*  hermes_teleforce*
hermes_eventlogs*  hermes_grablogs*    hermes_proxy*

$ file /opt/hermes/hermes_client
opt/hermes/hermes_client: sticky ELF 64-bit LSB executable, x86-64, version 1 (SYSV), statically linked, Go BuildID=JRZRLflVY89A6p67rwkt/nb9KmeWMLadrBGvRVujH/aJPtciQz8Xldpa7VcVy_/XzIY9KY7sZI0KdwLYOK5, stripped
</code></pre><p>It’s pretty easy to see what OSS libraries they’re using in the binary by using
<code>strings hermes_client | rg vendor/</code>. Maybe I’ll make a follow up post analyzing
Hermes itself.</p>
<h2 id="odin---service-interface">Odin - Service Interface</h2>
<p>Odin is a python 3 service running on every car. It’s used for various
maintenance actions on the car such as calibrating the radar and the cameras. If
you connect to the internal car network you can access it at
http://192.168.90.100:8080.</p>
<p>There’s a screenshot of this interface at <a href="https://github.com/lewurm/blog/issues/4">https://github.com/lewurm/blog/issues/4</a></p>
<p>If you try to run any of the actions on Odin it just throws an error.</p>
<h3 id="odin-authentication">Odin Authentication</h3>
<pre><code>{error: "Token 2.0 not found."}
</code></pre><p>I dug into the source code.</p>
<p><em>Tesla uses signed certificates for everything.</em></p>
<p>From a security perspective this is amazing. :) From a “I want to get root on my
car” perspective it’s awful. :(</p>
<p>Each token contains a security level. These levels grant access to different
Odin commands. This allows different tiers of service the minimum permissions
they need to do their job.</p>
<p>These are broken into <code>principals</code> and <code>remote_execution_permissions</code>.
Presumably <code>principals</code> requires physical access via the diagnostic ethernet
port.</p>
<p>The <code>principals</code> levels listed in the Odin tasks are:</p>
<ul>
<li>tbx-internal</li>
<li>tbx-external</li>
<li>tbx-technical-specialist</li>
<li>tbx-engineering</li>
<li>tbx-service</li>
</ul>
<p>These seem to be mostly internal car tests likely used during manufacturing.
The only time the non internal/external principals show up is for
<code>PROC_ICE_X_LOGS-UPLOADER</code> and <code>ICE_DEASSOCIATE_PRODUCT_ID</code>. The second is
engineering only and appears to wipe the vehicle VIN and car config.</p>
<p>The <code>remote_execution_permission</code> levels listed in the Odin tasks are:</p>
<ul>
<li>tbx-service</li>
<li>tbx-service-infotainment</li>
<li>tbx-technical-specialist</li>
<li>tbx-service-engineering</li>
<li>tbx-engineering</li>
<li>tbx-mothership</li>
</ul>
<p>Things like <code>TEST-BASH_ICE_X_SEARCH-UI-ALERTS</code> can be accessed by <code>tbx-service</code>,
<code>tbx-service-engineering</code> and <code>tbx-mothership</code>.</p>
<p>Things like <code>PROC_ICE_X_SET-VEHICLE-CONFIG</code> can only be accessed by
<code>tbx-mothership</code>.</p>
<p>The token’s are signed by an intermediate certificate. This intermediate
certificate public key is included as part of the token and signed by Tesla’s
root CA. From my understanding this follows standard security practices of web
CAs to prevent the root certificate from being compromised.</p>
<h3 id="odin-networks">Odin Networks</h3>
<p>Odin is implemented in a pretty interesting way. There’s a list of <code>tasks</code> and
<code>networks</code>. The tasks are high level actions that can be executed by someone
with specific permissions.</p>
<p>The <code>lib</code> files are “networks” that appear to be a domain specific language/UI
program just for creating service tasks.</p>
<p>The networks are very close to JSON but stored in <code>.py</code> files.</p>
<p>Here’s an excerpt of one:</p>
<div><pre><code data-lang="py"><span>network</span> <span>=</span> <span>{</span>
<span>...</span>
    <span>"get_success"</span><span>:</span> <span>{</span>
	<span>"default"</span><span>:</span> <span>{</span><span>"datatype"</span><span>:</span> <span>"Bool"</span><span>,</span> <span>"value"</span><span>:</span> <span>False</span><span>},</span>
	<span>"position"</span><span>:</span> <span>{</span><span>"y"</span><span>:</span> <span>265.22259521484375</span><span>,</span> <span>"x"</span><span>:</span> <span>108.96072387695312</span><span>},</span>
	<span>"variable"</span><span>:</span> <span>{</span><span>"value"</span><span>:</span> <span>"success"</span><span>},</span>
	<span>"value"</span><span>:</span> <span>{</span><span>"datatype"</span><span>:</span> <span>"Bool"</span><span>},</span>
	<span>"type"</span><span>:</span> <span>"networks.Get"</span><span>,</span>
    <span>},</span>
    <span>"IfThen"</span><span>:</span> <span>{</span>
	<span>"position"</span><span>:</span> <span>{</span><span>"y"</span><span>:</span> <span>340.1793670654297</span><span>,</span> <span>"x"</span><span>:</span> <span>297.02069091796875</span><span>},</span>
	<span>"expr"</span><span>:</span> <span>{</span><span>"datatype"</span><span>:</span> <span>"Bool"</span><span>,</span> <span>"connection"</span><span>:</span> <span>"get_success.value"</span><span>},</span>
	<span>"if_true"</span><span>:</span> <span>{</span><span>"connection"</span><span>:</span> <span>"exit.exit"</span><span>},</span>
	<span>"type"</span><span>:</span> <span>"control.IfThen"</span><span>,</span>
	<span>"if_false"</span><span>:</span> <span>{</span><span>"connection"</span><span>:</span> <span>"capturemetric.capture"</span><span>},</span>
    <span>},</span>
<span>...</span>
<span>}</span>
</code></pre></div><p>Each network is structured as a series of nodes with types describing what they
do. The nodes can consume inputs from other nodes via “connection"s. The actual
logic of each node type is implemented in standard python.</p>
<p>The <code>position</code> field seems to indicate that these networks are created via a UI
tool.</p>
<h3 id="toolbox">Toolbox</h3>
<p>Tesla’s service tool is called Toolbox. There seems to be two versions.</p>
<ol>
<li>A program you can download …</li></ol></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fn.lc/post/tesla-model-3/">https://fn.lc/post/tesla-model-3/</a></em></p>]]>
            </description>
            <link>https://fn.lc/post/tesla-model-3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24268185</guid>
            <pubDate>Tue, 25 Aug 2020 04:46:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Economic Cost of Oil Spills]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24268051">thread link</a>) | @amrrs
<br/>
August 24, 2020 | https://finshots.in/archive/the-economic-cost-of-oil-spills/ | <a href="https://web.archive.org/web/*/https://finshots.in/archive/the-economic-cost-of-oil-spills/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">

    <div>

        <article>

            

            <figure>
                <img srcset="https://d3jlwjv6gmyigl.cloudfront.net/images/2020/08/oilsp-min.jpg 300w,
                            https://d3jlwjv6gmyigl.cloudfront.net/images/2020/08/oilsp-min.jpg 600w,
                            https://d3jlwjv6gmyigl.cloudfront.net/images/2020/08/oilsp-min.jpg 1000w,
                            https://d3jlwjv6gmyigl.cloudfront.net/images/2020/08/oilsp-min.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://d3jlwjv6gmyigl.cloudfront.net/images/2020/08/oilsp-min.jpg" alt="The Economic Cost of Oil Spills">
            </figure>

            <section>
                <div>
                    <p><em>A few days ago, a cargo vessel MV Wakashio ran aground off Pointe d’Esny, on the south-east coast of Mauritius and started spilling oil.</em></p><p><em>Needless to say, we need to talk about it.</em></p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><!--kg-card-begin: html--><!--kg-card-end: html--><h3 id="the-story">The Story</h3><p>Imagine thousands of gallons of oil pouring into a water body somewhere along the coast of a small island nation. Your first order of business is to contain and clean up the spill — in that order specifically.</p><p>Because when oil does spill, it forms a thick film that floats on top of the water body slowly spreading out and thinning as time progresses. More time means more coverage area. More coverage means a more elaborate cleanup effort. So in theory, if a cleanup crew can reach a spill quickly, they could contain it more efficiently and reduce costs across the board.</p><p>With the MV Wakashio oil spill, things didn’t exactly go as planned. The ship <a href="https://gcaptain.com/wakashio-breached-oil-leaks-from-grounded-bulk-carrier-in-mauritius-police-investigation-launched/#:~:text=The%20Indian%20Ocean%20island%20nation,Brazil%20via%20Singapore%20on%20ballast.">struck</a> a reef on July 25th and its body began to crack after days of pounding waves. At the time, the Mauritius government could have averted the crisis altogether by emptying the ship of its fuel. But that did not happen. Instead, the ship kept taking the beating and finally started leaking fuel on August 6th. Now the ship’s owners contest that oil prevention measures were in place by then. But clearly, it wasn’t helping a lot.</p><!--kg-card-begin: image--><figure><img src="https://d3jlwjv6gmyigl.cloudfront.net/images/2020/08/5f2bf41a78a54_wakashio_ecosud-1443924.jpg"><figcaption><a href="https://la1ere.francetvinfo.fr/reunion/naufrage-du-wakashio-il-y-breche-fuite-huile-859552.html">Source: France Info</a></figcaption></figure><!--kg-card-end: image--><p>The Mauritius government could have taken some initiative here. But they waited for a whole day before finally taking stock of the situation and <a href="https://www.bbc.com/news/world-africa-53702877#:~:text=The%20island%20nation%20of%20Mauritius,and%20its%20crew%20was%20evacuated.&amp;text=The%20French%20island%20of%20Reunion%20lies%20near%20Mauritius%20in%20the%20Indian%20Ocean.">declaring emergency</a> late on Aug 7th. Thankfully the people of Mauritius stepped up. As an article in the New York Times <a href="https://www.nytimes.com/2020/08/14/world/africa/mauritius-oil-spill.html">notes</a> —</p><blockquote><em>“Immediately after the accident, individuals, civil society organizations and environmental groups mobilized to save the mangrove forest and coral reefs that give Mauritian waters their rich biodiversity.<p>Thousands of volunteers pulled all-nighters gathering plastic bottles and skimming oil into barrels, while salons donated hair and <a href="https://www.instagram.com/p/CDt2gpzg133/?igshid=1uidpqls8erlm" rel="noopener noreferrer noopener">children collected straw</a> from fields to help soak up the oil. Mauritians abroad began <a href="https://www.instagram.com/savemauritiusreef/" rel="noopener noreferrer noopener">social media campaigns</a> to raise awareness, and hundreds of thousands of dollars <a href="https://www.crowdfund.mu/mauritius-oil-spill-cleaning-2020-mv-wakashio-306.html" rel="noopener noreferrer noopener">were collected</a> on fund-raising platforms.”</p></em></blockquote><p>However, despite the collective effort, the size of the oil slick had already <a href="https://twitter.com/UrsaSpace/status/1293587048344047621?s=20" rel="noopener">expanded 10x</a> within just one week and the cleanup effort could now take months costing the shipping company and the Mauritius government millions of dollars.</p><p>How many millions? That’s difficult to calculate.</p><p>The Exxon Valdez case— a spill of approximately 10.8 million gallons in Alaska in 1989 cost <a href="https://media.rff.org/archive/files/sharepoint/WorkImages/Download/RFF-BCK-Cohen-DHCosts_update.pdf">$2.1 Billion</a> (in cleanup efforts). The MV Wakashio, on the other hand, was only carrying ~127,000 gallons of oil. The reason for the disparity — Exxon Valdez was a cargo ship ferrying oil. Wakashio was an empty ship travelling to pick cargo. The leak was from the fuel tank and the oil it was carrying to propel the vessel. Also, the cleanup team emptied the ship of its fuel before everything could spill out. So it’s safe to say the cleanup effort won’t cost billions.</p><p>But the impact will probably be severe either way.</p><p>Beyond the cleanup costs, we also have to contend with the ecological devastation that almost inevitably follows. Four years after the Exxon Valdez spill, a population of forage fish called herring <a href="https://www.history.com/topics/1980s/exxon-valdez-oil-spill">disappeared</a> entirely from the location where the vessel broke. Scientists still aren’t sure why this happened. They can’t even ascertain fully if the oil spill was to blame. But the impact of this disappearance was catastrophic. It spelt the death of an 8-million-dollar-a-year fishery industry. Although most fishermen never explicitly sought herrings, these small forage fishes are preyed on by larger fish for food. Once the population of herrings collapsed, it left a gaping hole in the middle of the marine food chain. 25 years later, herrings are yet to return and the fishery industry has all but vanished.</p><p>With the Wakashio oil spill, we have the same concerns. Blue Bay — The place where the ship ran aground was <a href="https://www.bloombergquint.com/opinion/why-mauritius-oil-spill-is-a-very-big-problem-for-the-oil-industry">declared</a> a marine park back in 1997. It’s perhaps one of the last remaining areas which still harbours undamaged coral reefs and an abundance of underwater life. The oil spill might have spelt the death of the ecological balance in the area. What will it cost the local population? We don’t know yet. But it’s a tragedy that we still have to contend with oil spills this day and age.</p><p>Share this Finshots on <a href="https://api.whatsapp.com/send?text=What%20happens%20when%20there%27s%20an%20oil%20spill?%20https://bit.ly/3llY8AL">WhatsApp</a>, <a href="https://twitter.com/intent/tweet?url=https://bit.ly/3jdaCsa&amp;via=finshots&amp;text=What%20happens%20when%20there%27s%20an%20oil%20spill?">Twitter</a>, or <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://finshots.in/archive/the-economic-cost-of-oil-spills">LinkedIn</a>.</p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><!--kg-card-begin: html--><!--kg-card-end: html--><h3 id="an-inside-scoop">An Inside Scoop</h3><p>A few days back we wrote about the legal battle brewing between Apple and Epic Games. Since then, news websites have managed to access the email correspondence between the two companies before Epic Games decided to file the lawsuit. And considering it’s not always you get to read internal emails from top companies, we urge you to read the full correspondence <a href="https://www.theverge.com/2020/8/21/21396313/apple-fortnite-lawsuit-emails-app-store-ban-epic">here</a>. It’s quite revealing to be honest.</p><p>P.S. The actual correspondence is located in the exhibit at the bottom of the article.</p><p><em>Until next time...</em></p>
                </div>
            </section>


            

            
            


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://finshots.in/archive/the-economic-cost-of-oil-spills/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24268051</guid>
            <pubDate>Tue, 25 Aug 2020 04:02:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[rc.d belongs in libexec, not etc]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 65 (<a href="https://news.ycombinator.com/item?id=24267933">thread link</a>) | @Khaine
<br/>
August 24, 2020 | https://jmmv.dev/2020/08/rcd-libexec-etc.html | <a href="https://web.archive.org/web/*/https://jmmv.dev/2020/08/rcd-libexec-etc.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
              
              <article>

<p>Let’s open with the controversy: the scripts that live under <code>/etc/rc.d/</code> in FreeBSD, NetBSD, and OpenBSD are in the wrong place. They all should live in <code>/libexec/rc.d/</code> because they are code, <em>not</em> configuration.</p>

<p>This misplacement is something that has bugged me for ages but I never had the energy to open this can of worms back when I was very involved in NetBSD. I suspect it would have been a draining discussion and a very difficult thing to change.</p>

<p>But… what am I talking about anyway?</p>

<p>If you have administered a BSD system, you have certainly encountered the <code>/etc/rc.d/</code> directory; and if you have administered pre-systemd Linux systems, you have dealt with <code>/etc/init.d/</code>. These directories contain startup scripts to configure the system at boot time and are immutable. Their code is parameterized to allow changing their behavior via configuration files, not via code edits. And that’s the base of my critique.</p>

<p>But before getting into why the current state is problematic and how things should look like, let’s first dig into how we got here. And, for that, we need to go back in history.</p>



<p>4.4BSD’s (1993) boot process was rather simple: the kernel started <code>init</code> which in turn ran the <code>/etc/rc</code> script before starting <code>getty</code> on each console. The <code>/etc/rc</code> monolith was in charge of configuring the machine’s file systems and processes, and delegated to two other scripts: <code>/etc/netstart</code> for network configuration and <code>/etc/rc.local</code> for locally-added services. Current BSD systems are more advanced in this area as we shall see later, but the core boot process remains the same: <code>/etc/rc</code> is the primary entry point and bootstraps a collection of shell scripts.</p>

<p>In the early days, package management and file provenance tracking, like we are used to having in popular Linux distributions, was not a thing. You were expected to tune the systems’ behavior by <em>editing</em> files which might or might not have been designed to support edits. If you had to edit <code>/etc/rc</code>, which was a script shipped by the system, that was alright.</p>

<p><code>/etc/rc.local</code>, on the other hard, was <em>not</em> shipped by the system, and it was up to you to create it if you wanted to add custom startup commands without modifying <code>/etc/rc</code>. And this is where things get interesting. <code>/etc/rc.local</code> didn’t need to be supported: if you were expected and able to edit <code>/etc/rc</code> anyway, why would you deal with a separate file? The reason is, most likely, to simplify system upgrades: during an upgrade, you want to benefit from any upstream changes made to <code>/etc/rc</code> (some of which might actually be <em>necessary</em> for proper system operation). Applying updates to a manually-modified file is tricky, so putting as many of your manual overrides into <code>/etc/rc.local</code> helped minimize this problem.</p>



<p>System V 4 (SVR4, 1988) also came with its own, and very different, boot process. The key difference was that System V had the concept of runlevels. As a result, configuring the boot process was a more convoluted endeavour because it was possible to select different services per runlevel.</p>

<p>To accomplish per-runlevel tuning, the system used <a href="https://jmmv.dev/2020/08/config-files-vs-directories.html">configuration directories rather than files</a>: there was a separate <code>/etc/rcX.d/</code> directory for each runlevel (where <code>X</code> was the number of the runlevel), and these directories contained one file per action to take at startup time. To avoid duplicates, these files were just symlinks to common files under <code>/etc/init.d/</code>—and the symlinks, not their targets, were named so that their lexicographical order determined startup execution order.</p>

<p>Once again, we can already observe issues here: the symlinks under <code>/etc/rcX.d/</code> <em>are</em> configuration because their presence indicates what to start and their names determine their startup order. But the files under <code>/etc/init.d/</code> are <em>not</em>: they are shell scripts shipped with the system and should not be manually modified.</p>



<p>NetBSD <a href="http://www.mewburn.net/luke/papers/rc.d.pdf">modernized the boot process</a> in its 1.5 release (2000), and it did so in two ways: first, it introduced <code>/etc/rc.d/</code> as a directory to contain separate scripts per action and service; and, second, it introduced <a href="https://netbsd.gw.com/cgi-bin/man-cgi?rcorder+8+NetBSD-9.0-STABLE">the <code>rcorder(8)</code> tool</a> to determine the order in which these services run. <code>rcorder(8)</code> uses dependency information encoded in the scripts as comments—not lexicographical ordering as System V did. FreeBSD <a href="https://www.freebsd.org/cgi/man.cgi?query=rc&amp;apropos=0&amp;sektion=8&amp;manpath=FreeBSD+12.1-RELEASE&amp;arch=default&amp;format=html">inherited this design</a> in its 5.0 release (2003) and OpenBSD reimplemented something similar in its 4.9 release (2011).</p>

<p>With these two pieces in place, the <code>/etc/rc</code> script in NetBSD and FreeBSD changed to execute all files from <code>/etc/rc.d/</code> based on the output of <code>rcorder(8)</code>. Among these scripts is <a href="https://github.com/NetBSD/src/blob/8f8c6d6b2a8778b653d9630f3f18e057b477a012/etc/rc.d/local"><code>/etc/rc.d/local</code></a>, whose purpose is to run <code>/etc/rc.local</code> if it exists. And that’s all, really. The <code>/etc/rc</code> script thus became <a href="https://github.com/NetBSD/src/blob/8f8c6d6b2a8778b653d9630f3f18e057b477a012/etc/rc">trivial</a>.</p>

<p>The key thing to notice here is that the scripts shipped in <code>/etc/rc.d/</code> are <em>highly configurable</em> via the user-controlled <a href="https://github.com/NetBSD/src/blob/8f8c6d6b2a8778b653d9630f3f18e057b477a012/etc/rc.conf"><code>/etc/rc.conf</code></a> file. This essentially makes the scripts read-only, as it shifts local customizations to the configuration file. <em>System administrators are not supposed to edit the scripts.</em> Instead, they are supposed to: modify <code>/etc/rc.conf</code> to customize what gets run and how; add new scripts under <code>/etc/rc.d/</code> if they so choose; and edit <code>/etc/rc.local</code> to easily run arbitrary commands.</p>



<p>My main gripe is that the files under <code>/etc/rc.d/</code> are immutable scripts. They do not belong in <code>/etc/</code> and their presence there makes system upgrades harder for no good reason.</p>

<p>You see: in NetBSD and FreeBSD, system upgrades happen by unpacking new distribution sets in the root directory and then running a script to incorporate configuration updates. This script is interactive and helps highlight how new system-provided updates to configuration files conflict with previous manual edits. (This process might seem rudimentary to you, but it’s actually pretty robust and easy to understand—and you can use tooling like <a href="https://github.com/jmmv/sysupgrade/">sysupgrade</a> to make it trivial.)</p>

<p>So why is that a problem? Because you will <em>always</em> face merges like this:</p>
<div><pre><code data-lang="diff"><span>--- /etc/rc.d/npf               2019-08-09 19:09:42.800758233 -0400
</span><span></span><span>+++ /tmp/temproot/etc/rc.d/npf  2019-11-16 10:39:27.000000000 -0500
</span><span></span><span>@@ -1,6 +1,6 @@
</span><span></span> #!/bin/sh
 #
<span>-# $NetBSD: npf,v 1.3 2012/11/01 06:06:14 mrg Exp $
</span><span></span><span>+# $NetBSD: npf,v 1.4 2019/04/19 18:36:25 leot Exp $
</span><span></span> #
 # Public Domain.
 #
<span>@@ -36,7 +36,11 @@
</span><span></span>        echo "Enabling NPF."
        npf_cfg_check
        /sbin/npfctl reload
<span>-       /sbin/npfctl start
</span><span></span><span>+
</span><span>+       # The npf_boot script has enabled npf already.
</span><span>+       if [ "$autoboot" != "yes" ]; then
</span><span>+               /sbin/npfctl start
</span><span>+       fi
</span><span></span> }
 
 npf_stop()

File: /etc/rc.d/npf (modified)

Please select one of the following operations:

  d  Don't install the new file (keep your old file)
  i  Install the new file (overwrites your local modifications!)
  m  Merge the currently installed and new files
  s  Show the differences between the currently installed and new files
  su  Show differences in unified format ("diff -u")
  sc  Show differences in context format ("diff -c")
  ss  Show differences side by side ("sdiff -w187")
  scommand Show differences using the specified diff-like command
  v  Show the new file

What do you want to do? [Leave it for later]
</code></pre></div>
<p>And, really, who cares? Why are you being distracted to review a <em>code</em> change when what you are trying to do is assess <em>configuration</em> conflicts? How many times have you actually objected to these merges?</p>

<p>You might say: well, I want to know <em>exactly</em> how the boot process of my machine changes during an upgrade. Sure, that’s a fine goal, but then this procedure is flawed and completely insufficient to achieve such goal. In the example above, whatever <code>/etc/rc.d/npf</code> does can also be done from within the <code>/sbin/npfctl</code> binary it invokes… and you were never asked to review changes to the latter during an upgrade, were you? And <em>of course</em> you could review the binary’s code as part of your own system build, but if you did that, then you could have reviewed the startup script as well, right?</p>



<p>Startup scripts provided by the system need to live in a location that can contain executables—but we don’t want those executables to show up in the <code>PATH</code>. These requirements discard <code>bin</code> and <code>sbin</code>, and points us towards <code>libexec</code> on BSD systems and somewhere under <code>lib</code> on Linux.</p>

<p>Therefore, the read-only startup scripts should move from <code>/etc/rc.d/</code> to <code>/libexec/rc.d/</code> (which, by the way, also applies to <code>/etc/rc</code>, <code>/etc/rc.subr</code>, and <code>/etc/rc.shutdown</code>). And that’s it. <del><code>/etc/rc</code></del> <code>/libexec/rc</code> should continue to use <code>rcorder(8)</code> to check what’s needed to run, but it should read files from <code>/libexec/rc.d/</code>. You might even want to support a separate location for user-created services, which might still be <code>/etc/rc.d/</code> or, better yet, a more fitting location like <code>/usr/pkg/libexec/rc.d/</code> (though that quickly runs into problems if you have multiple file systems).</p>

<p>With this design, system upgrades would be much saner because the configuration merge process would focus, purely, on actual configuration changes and not on irrelevant code changes. All updates to <code>/libexec/rc.d/</code> would be applied by unpacking the new distribution sets (<code>base.txz</code> in this case) without disturbing you about how exactly they changed.</p>

<p>Does this relate to Linux distributions at all? I briefly mentioned <code>/etc/init.d/</code> at the beginning, and the problem there is similar. But it’s also an obsolete problem given that Linux distributions have moved onto systemd by now. That said, systemd still has to manage individual services and, like it or not, has gotten this right. If we look at the <a href="https://www.freedesktop.org/software/systemd/man/systemd.unit.html"><code>systemd.unit(5)</code></a> manual page, which describes where units are loaded from, the system first looks into various <code>/etc/</code> and <code>/run/</code> directories, but then also looks at <code>/usr/lib/systemd/system/</code> (a read-only location correctly controlled by the package manager)—and the vast majority of the scripts live inside the latter.</p>



<p>I currently don’t run BSD systems any more so my incentives to make this happen are low… but if this all makes sense and is something you’d like to pursue, by all means please do! I’m happy to help …</p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jmmv.dev/2020/08/rcd-libexec-etc.html">https://jmmv.dev/2020/08/rcd-libexec-etc.html</a></em></p>]]>
            </description>
            <link>https://jmmv.dev/2020/08/rcd-libexec-etc.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24267933</guid>
            <pubDate>Tue, 25 Aug 2020 03:35:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stealing Local Files Using Safari Web Share API – Redteam.pl Techblog]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24267676">thread link</a>) | @jayliew
<br/>
August 24, 2020 | https://blog.redteam.pl/2020/08/stealing-local-files-using-safari-web.html | <a href="https://web.archive.org/web/*/https://blog.redteam.pl/2020/08/stealing-local-files-using-safari-web.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://blog.redteam.pl/2020/08/stealing-local-files-using-safari-web.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24267676</guid>
            <pubDate>Tue, 25 Aug 2020 02:37:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Deliver Meaningful Software]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24267325">thread link</a>) | @astrocreep2k
<br/>
August 24, 2020 | https://7samurai.dev/2020/08/24/how-to-deliver-meaningful-software/ | <a href="https://web.archive.org/web/*/https://7samurai.dev/2020/08/24/how-to-deliver-meaningful-software/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
										
	<div>
	
		<div>
												        
									
				<div id="post-20">

										
					<div>
					
						<!-- .post-header -->
						
											
						<p><img width="1140" height="863" src="https://7samurai.dev/wp-content/uploads/2020/08/image-11-1140x863.jpg" alt="Meaningful Features" loading="lazy" srcset="https://7samurai.dev/wp-content/uploads/2020/08/image-11-1140x863.jpg 1140w, https://7samurai.dev/wp-content/uploads/2020/08/image-11-300x227.jpg 300w, https://7samurai.dev/wp-content/uploads/2020/08/image-11-1024x775.jpg 1024w, https://7samurai.dev/wp-content/uploads/2020/08/image-11-768x582.jpg 768w, https://7samurai.dev/wp-content/uploads/2020/08/image-11-1536x1163.jpg 1536w, https://7samurai.dev/wp-content/uploads/2020/08/image-11-2048x1551.jpg 2048w, https://7samurai.dev/wp-content/uploads/2020/08/image-11-552x418.jpg 552w" sizes="(max-width: 1140px) 100vw, 1140px">									
						</p><!-- .featured-media -->
					
																			                                    	    
						<div>

							
<p><strong>Surprise! Delivering valuable software is difficult.</strong> (Ok.. maybe not that surprising.)</p>



<div><p>Maybe it started out well – but over time it grew stale. Or it was wrong from the very beginning. Despite the common belief that software is an asset – it’s just as easily a liability.&nbsp;</p><p>Let’s start with how do you define “Meaningful” software? Developers know when something they are working on doesn’t matter. Sometimes the indicator is a lack of interest in investing further or it’s heavy investment in something that gets little usage. Either way meaningful software must be a win-win for both creator and consumer.</p></div>



<p><strong>“Meaningful software delivers value to a substantial segment of the target user group and </strong><strong>directly</strong><strong> supports the goals and objectives of those delivering the software. “</strong></p>



<p>I’ll argue that any software feature or platform that fulfills this criteria will produce positive results. I’ll also suggest that it can be challenging to achieve and maintain this balance.</p>



<blockquote><p>Example 1: <em>“Hey – we should build our own shopping cart system”</em></p></blockquote>



<p>If you are competing against Amazon in the high volume retail market and need proprietary AI recommendation systems – then it’s a worthy investment. If you are selling flowers at the corner market, probably not. It sounds simple on the surface but the question you always need to ask is: will it give me a competitive advantage and help me directly achieve my goals?</p>



<blockquote><p>Example 2: <em>“Hey, power user X says they would love this feature”</em></p></blockquote>



<p>Power users and early adopters are extremely valuable. But it’s important that you obtain and test feedback against a larger market. Investing in a feature that is utilized by a few users doesn’t contribute to growth. Will it deliver value to a large portion of my target users?</p>



<h2>Why is this important?</h2>



<p><strong>Software that isn’t meaningful isn’t sustainable</strong>.<br>If it doesn’t meet the objectives of its creators, they should be building something else.&nbsp; If it doesn’t deliver value to a substantial number of target users then they don’t really need it or should be using something else.&nbsp; When one or both of these conditions have not been met it creates an imbalance that generally results in a slow painful death for the platform.</p>



<p><strong>Software that isn’t meaningful creates unnecessary costs for its creator.</strong> This takes many forms – time, opportunity, and financial cost. The long term impact of holding meaningless software with active users is dangerous because its toxic byproducts are usually hidden in the depths of technical teams.&nbsp; If your are interested in learning more about the costs associated with building features, <a href="https://productcoalition.com/the-real-cost-of-adding-a-new-feature-9d527448df41">this is a great article</a> that highlights the risks.<br>&nbsp;</p>



<p><strong>Software that isn’t meaningful disrupts focus on key objectives.</strong> It creates confusion, takes over meetings, hurts morale, and ultimately can derail strategic direction. The real danger of meaningless software is it appears to be “low hanging fruit” and usually brings a level of comfort that attracts all sorts of “feature requests” and “ideas”.&nbsp; If the creators lose sight of its intended purpose then the strategic objective quickly shifts from whatever it was originally to the ambiguous effort of making the software “better”. <br>&nbsp;</p>







<div><p><strong>Mastering the ability to distinguish meaningful from meaningless requires discipline.</strong> You have to be honest with yourself and objective about what it is you are producing.&nbsp; You cannot fall in love with your creation. You have to be willing to refactor design, listen to concerns, take time to organize, reject tradition, kill exciting (but distracting) ideas, and ignore the urge to “make things” right without purpose.&nbsp; It requires focus and it requires constant re-evaluation. It’s uncomfortable – but once you know you are building something that matters – it all clicks.</p><p><strong>Shaping software into something meaningful requires thinking holistically.</strong>&nbsp;  Understanding the goals of stakeholders, needs of target users, cost of building, validation techniques, and methods of promotion are just as important as the mechanics of how the software functions. Alignment and positioning of effort is key to the  “meaningful” attribute of the art.</p></div>



<p><strong>Producing meaningful software requires a fundamental understanding of how software is created, tested, and distributed.</strong> It’s also not enough to make plans and collaborate with stakeholders – it’s very important to understand capabilities, risks, and mechanics of how software is made and maintained. You don’t have to be a developer to deliver meaningful software, but you do need to know how to communicate with one. Mastering this is how the “delivery” happens.</p>







<div><p><strong>The end product speaks for itself.</strong> If you can’t deliver it or what is shipped doesn’t provide direct value then start over or re-work. Much like an artist would paint over the canvas or toss it away – there is no value (only risk) in maintaining meaningless software.&nbsp; Attachment to sunk cost, “technology” hording, and pet projects are guaranteed ways to fail or prolong the achievement of goals.</p><p><strong>If you want to improve your ability to contribute to and drive the delivery of meaningful software</strong> I’d encourage you to follow along on this journey – <a href="https://7samurai.dev/weekly-newsletter/">sign up for my weekly newsletter</a>.</p></div>
<!-- Simple Share Buttons Adder (7.7.1) simplesharebuttons.com -->							
							
										        
						</div><!-- .post-content -->
						
												
					</div><!-- .post-inner -->
					            					
					<!-- .post-meta.bottom -->
					
					<!-- .post-nav -->
												                        
			   	    
				
				
	<!-- .widget-area -->

						
			</div><!-- .post -->
		
		</div><!-- .content -->
		
		
		
	</div><!-- .wrapper-inner -->

</div></div>]]>
            </description>
            <link>https://7samurai.dev/2020/08/24/how-to-deliver-meaningful-software/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24267325</guid>
            <pubDate>Tue, 25 Aug 2020 01:22:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One-third of people with Covid-19 lie about their symptoms, study shows]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24267303">thread link</a>) | @9nGQluzmnq3M
<br/>
August 24, 2020 | https://www.cbc.ca/news/canada/hamilton/covid-19-1.5695230 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/hamilton/covid-19-1.5695230">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.cbc.ca/news/canada/hamilton/covid-19-1.5695230</link>
            <guid isPermaLink="false">hacker-news-small-sites-24267303</guid>
            <pubDate>Tue, 25 Aug 2020 01:18:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Safe eval() Alternative in JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24267198">thread link</a>) | @stin23
<br/>
August 24, 2020 | https://austinrepp.com/javascript-safe-eval/ | <a href="https://web.archive.org/web/*/https://austinrepp.com/javascript-safe-eval/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
            

            <div id="container">


<div>
    <article itemscope="" itemtype="http://schema.org/BlogPosting">
        

        <div itemprop="articleBody">
    

    <p>A problem I encountered while creating <a href="https://discordbotstudio.org/">Discord Bot Studio</a>, was allowing users to enter variables which could be evaluated at runtime. Discord Bot Studio is a visual programming tool, so I felt it was important to offer a familiar variable syntax. Ideally, I wanted a user to be able to type a variable using the following notation, and have it be replaced with that variable’s value at runtime:</p>
<p>An example would be if I have an object as follows:</p>
<div><pre><code data-lang="javascript"><span>variableObject</span> {
    <span>variableName</span><span>:</span> {
        <span>fieldName</span><span>:</span> <span>"Austin"</span>
    }
}
</code></pre></div><p>The user should be able to retrieve that value “Austin” with the following syntax:</p>
<div><pre><code data-lang="javascript"><span>$</span>{<span>variableObject</span>.<span>variableName</span>.<span>fieldName</span>}
</code></pre></div><p>Rmember, this is a visual programming tool, so there could be any number of variables in an input string, or there could be none at all. The input is being evaluated at runtime, as it can be dynamic.</p>
<p>The seemingly obvious solution is to use Javascript’s <code>eval()</code> function, to evaluate the variables at runtime. Since DBS creates bots which will eventually be taking untrusted user input, this is not safe to do. Rather than trying to clean any incoming input, I settled on another solution which still allows variables with the dot (.) syntax to be evaluated.</p>
<h2 id="the-solution">The solution</h2>
<p>First I match variables in the input string using regex by looking for the ${} notation I mentioned above.</p>
<p>I trim the excess ${} from the match, and pass the resultant string to the following function, along with the object containing any variables that may be referenced by the user.</p>
<div><pre><code data-lang="javascript"><span>// desc = variableObject.variableName.fieldName
</span><span></span><span>/* obj = userVariables {
</span><span>    variableObject {
</span><span>        variableName: {
</span><span>            fieldName: "Austin"
</span><span>        }
</span><span>    }
</span><span>}
</span><span>*/</span>
<span>function</span> <span>getDescendantProp</span>(<span>obj</span>, <span>desc</span>) {
    <span>var</span> <span>arr</span> <span>=</span> <span>desc</span>.<span>split</span>(<span>"."</span>);

    <span>while</span> (<span>arr</span>.<span>length</span>) {
        <span>obj</span> <span>=</span> <span>obj</span>[<span>arr</span>.<span>shift</span>()];
    }
    <span>return</span> <span>obj</span>;
}
</code></pre></div><p>Here obj is the object containing any variables the user input should have access to. Desc is the trimmed match string. Continuing the example from above, desc would equal <code>variableObject.variableName.fieldName</code>. The string is split into an array on the periods.  <code>variableObject.variableName.fieldName</code> would be split into 
<code>[variableObject, variableName, fieldName]</code>. These array values are then shifted out in order, and used as keys to access the variable-containing object. This function will return just the string “Austin” using the example object from above.</p>
<p>By doing this, I can limit the variables that are available to the user, and also give them access to those variables using normal Javascript syntax. This can be extended if you would like to support <code>variableObject[variableName]</code> as well. This is not a true alternative to <code>eval()</code> for all scenarios, but it works well for indexing into objects at runtime.</p>

</div>

        

        
    </article>
</div>

            </div>
        </div></div>]]>
            </description>
            <link>https://austinrepp.com/javascript-safe-eval/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24267198</guid>
            <pubDate>Tue, 25 Aug 2020 00:59:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Video Face Recognition Software]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24267147">thread link</a>) | @rbitsoft
<br/>
August 24, 2020 | http://roundbit.tech/vfr | <a href="https://web.archive.org/web/*/http://roundbit.tech/vfr">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<div id="infinite-post-wrap">
						
<article id="post-90">
	<div>
		
		<div>
			<!-- .entry-header -->

			<div>
				<p>Our beta version of the Video Face Recognition software is now available Features: Learn to recognize faces from photos Select image files to train the AI Only one face photo</p>
<p><a href="https://roundbit.tech/w/video-face-recognition/">Continue reading<span>Video Face Recognition 0.6</span></a></p>
			</div><!-- .entry-summary -->
		</div><!-- .entry-container -->
	</div><!-- .hentry-inner -->
</article><!-- #post-90 -->					</div><!-- .archive-post-wrap -->
				</div></div>]]>
            </description>
            <link>http://roundbit.tech/vfr</link>
            <guid isPermaLink="false">hacker-news-small-sites-24267147</guid>
            <pubDate>Tue, 25 Aug 2020 00:50:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Avoiding Imposter Syndrome Driven Development]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24267126">thread link</a>) | @helenanders26
<br/>
August 24, 2020 | https://helenanderson.co.nz/imposter-syndrome-stress/ | <a href="https://web.archive.org/web/*/https://helenanderson.co.nz/imposter-syndrome-stress/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
						
<p>If you’re taking your first steps into development you may have a nagging feeling like you don’t belong. Or that you’re failing because you don’t know ‘enough’ in your chosen field. You’re not alone. </p>



<p>Here’s how to recognise what you’re feeling, that it’s normal, and some strategies to feel better.</p>



<hr>



<h3>You don’t need to know everything, about everything</h3>



<p>You may be overthinking small mistakes. Feeling lost in meetings because there are terms and tools you’ve not heard before. Maybe you feel guilty for having to reluctantly ask for help after spending time googling, knowing that it must be something simple. And to make it worse, feeling like you’re falling farther and farther behind as the tech world moves on.</p>



<p>There is so much to learn about how things work in tech now, and things are constantly changing. Instead of comparing yourself to the seniors on your team use it as motivation to learn more from those around you.</p>



<hr>



<h3>Not every request is an emergency</h3>



<p>Even if you don’t have deadlines to meet, facing your team’s ticket queue or backlog of projects can seem overwhelming. You may not be managing the workflow but watching them piling up is stressful. You know you can’t whizz through and get everything ticked off in a day because you don’t have all the answers. </p>



<p>Even though the ticket is assigned to you, it’s not completely up to you to complete it. Your team are there to help you with a code review at the very least, but in most teams, it’s a collaborative effort and not all tasks are an emergency.</p>



<hr>



<h3>Leave work at work</h3>



<p>You may not realise it but it’s easy to let anxious feelings about work follow you home.  On your walk to work, walking home, even sitting on the couch after dinner. You may even fall into bed thinking about work, even if nothing bad has happened. Take time to disconnect from your work-life each day and do something else that refreshes your mind and makes you happy. Leaving work at work and focussing on all the other great things you have going on will keep things in perspective.</p>



<hr>



<h3>Remember the good stuff</h3>



<p>All too often we put pressure on ourselves to learn the next new thing on our wishlist of tools and technologies. But how often do you celebrate what you’ve learned so far?</p>



<p>Start a list of all the new things you’ve learned and&nbsp;the <a href="https://helenanderson.co.nz/big-data-a-to-z/" target="_blank" rel="noreferrer noopener">technologies</a>&nbsp;you’re using. When you put that on paper it reminds you that you are capable of learning new tools and how far you’ve come. </p>



<hr>



<h3>You’re doing great</h3>



<p>At some stage, everyone feels a little like an imposter. But you don’t need to be overwhelmed by it.  When you feel overwhelmed know you can talk to your manager and your team. They’ve been right where you are too, and may still feel like an imposter sometimes themselves. </p>



<p>The important thing is to give yourself a break, you’re doing great.</p>



<hr>



<p>Photo by&nbsp;<strong><a href="https://www.pexels.com/@skitterphoto?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels">Skitterphoto</a></strong>&nbsp;from&nbsp;<strong><a href="https://www.pexels.com/photo/pink-tulip-flowers-under-white-clouds-blue-skies-at-daytime-1019475/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels">Pexels</a></strong></p>
					
					</div></div>]]>
            </description>
            <link>https://helenanderson.co.nz/imposter-syndrome-stress/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24267126</guid>
            <pubDate>Tue, 25 Aug 2020 00:45:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to serve premium/private content on your site?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24266871">thread link</a>) | @rajanpanchal
<br/>
August 24, 2020 | https://blog.rajanpanchal.net/how-to-serve-premiumprivate-content-on-your-site-cke6jrnsg00duxms1e7o52kr5 | <a href="https://web.archive.org/web/*/https://blog.rajanpanchal.net/how-to-serve-premiumprivate-content-on-your-site-cke6jrnsg00duxms1e7o52kr5">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1598549115771/RWPaNJmMu.jpeg?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><p>A lot of online companies (for example: Netflix, Udemy etc ) distribute contents over internet that is accessible only to the members of the site or who have subscribed or paid a premium. Today in this post we see how you can achieve this for your website using Amazon Web Services. We will see how you can securely serve private content to your users from AWS S3 bucket using S3 Presigned URLs</p>
<h3 id="what-are-presigned-urls">What are Presigned URLs?</h3>
<p>A <strong>Presigned URL</strong> is a <strong>URL</strong> that provides limited permission and time to make a request. Anyone who receives the presigned URL can then access the object. For example, if you have a file in your bucket and both the bucket and the object are private, you can share the file with others by generating a presigned URL. </p>
<h4 id="some-important-points-on-presigned-urls">Some important points on Presigned URLs</h4>
<ul>
<li>The creator of Presigned URL should have access to object for URL to work, otherwise URL wont work.</li>
<li>You can create a presigned URL that's are not usable or doesn’t work. </li>
<li>It doesn’t cost anything to create Presigned URLs.</li>
<li>You can set expiration time on the URLs </li>
<li>If you created a presigned URL using a temporary token, then the URL expires when the token expires, even if the URL was created with a later expiration time</li>
<li>You can revoke the URL by removing the permissions to access the object from the user created the URL.</li>
</ul>
<h3 id="how-to-create-presigned-url">How to create Presigned URL?</h3>
<p>When you create a presigned URL for your object, you must provide your security credentials, specify a bucket name, an object key, specify method and expiration time.</p>
<p>In Python, using Boto3, you can use <em>generate_presigned_url</em> method to generate the URL</p>
<pre><code>response = s3_client.generate_presigned_url(<span>'get_object'</span>,
            Params={<span>'Bucket'</span>: bucket_name,
            <span>'Key'</span>: object_name},
            ExpiresIn=expiration)
</code></pre><p>The <em>response</em> object will contain the URL which will look similar to this</p>
<pre><code><span>https</span>://somebucketname-rep.s3.amazonaws.com/someFileName.txt?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=ASIAQS3IOUWUZF7YSXGA<span>%2</span>F20200821<span>%2</span>Fus-east-2<span>%2</span>Fs3<span>%2</span>Faws4_request&amp;X-Amz-Date=20200821T051228Z&amp;X-Amz-Expires=3600&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Security-Token=FwoGZXIvYXdzEH8aDCfJDxO0y6xQxYmdGCK2AXe71W<span>%2</span>FgZEg<span>%2</span>FSnSWC<span>%2</span>Fw<span>%2</span>FaJHeZ20M7OI7AqMEum5c98Chl6pSNPwE5Awsc3ySwokDF6L8a9wP0ceXWAmxT3WXLSoFeNHDbbEHfUKWnvGL8yFzAxdmf<span>%2</span>Fmi<span>%2</span>B5Tnl62td8Nad<span>%2</span>F0Ct1Sx11Mip1h2qdYxw80OX5bCTq7cAHHjpmupvaDt<span>%2</span>BZ3qVyIA9WZmeS63dCPOlieE9IiBZf<span>%2</span>FjxF4Mcs5w4ZIHtZL<span>%2</span>F3LvqMXAy3XfzCgnlYVZeCNczKLuv<span>%2</span>FfkFMi0mStwkzyO<span>%2</span>BfMIxWJ82GJmyNi7LZuY5r0Hx0mE<span>%2</span>BxLnre8jp9<span>%2</span>FACoV<span>%2</span>FM92GnsR0<span>%3</span>D&amp;X-Amz-Signature=17046b630ad4dede85af1cd57204bba8adc462a1825a35d93e81b656c683ad75
</code></pre><p>You can use this URL in the browser and access the object! Simple.. isn't it?</p>
<h3 id="lets-see-it-in-action">Lets see it in Action</h3>
<p>We are going to implement this on top of previous two posts, <a target="_blank" href="https://blog.rajanpanchal.net/aws-kms-use-case-with-serverless-application-model-sam-an-end-to-end-solution-ckdfenqag00lsqqs1csp05vhj">in the first post</a>, we implemented custom identity broker(signup/login), using AWS KMS to encrypt decryt password. In <a target="_blank" href="https://blog.rajanpanchal.net/how-to-give-access-to-aws-resources-without-creating-100s-of-iam-users-ckds91qj100pf97s1gc3v8vwb">second post</a>, we used AWS STS to AssumeRole to read bucket files names and now we will extend that to use presigned url. Download code for second post from <a href="http://github.com/rajanpanchal/aws-kms-sts" target="_blank">github.com/rajanpanchal/aws-kms-sts</a> and modify it.
Here is how overall process looks like
<img src="https://s3.amazonaws.com/blog-images-rajanpanchal.net/presignedUrl/presignedurl_diagram.jpg" alt="free cloud storage on s3, presigned URL diagram"></p>
<p>Open file <a href="http://showfiles.py/" target="_blank">showFiles.py</a> from the Lamdba folder and lets add function to generate presigned URL. Call this function from <em>getFilesList</em> function.</p>
<pre><code><span><span>def</span> <span>getSignedUrl</span><span>(key,s3_client)</span>:</span>
    KeyUrl = {}

    response = s3_client.generate_presigned_url(<span>'get_object'</span>,
                        Params={<span>'Bucket'</span>: os.environ[<span>'filesBucket'</span>],
                        <span>'Key'</span>: key},
                        ExpiresIn=<span>3600</span>)
    KeyUrl[key] = response
    <span>return</span> KeyUrl



<span><span>def</span> <span>getFilesList</span><span>()</span>:</span>
    sts_client = boto3.client(<span>'sts'</span>)

    
    
    assumed_role_object=sts_client.assume_role(
        RoleArn=os.environ[<span>'s3role'</span>],
        RoleSessionName=<span>"AssumeRoleSession1"</span>
    )

    
    
    credentials=assumed_role_object[<span>'Credentials'</span>]

    
    
    s3_resource=boto3.resource(
        <span>'s3'</span>,
        aws_access_key_id=credentials[<span>'AccessKeyId'</span>],
        aws_secret_access_key=credentials[<span>'SecretAccessKey'</span>],
        aws_session_token=credentials[<span>'SessionToken'</span>],
    )
    s3_client = boto3.client(<span>'s3'</span>,aws_access_key_id=credentials[<span>'AccessKeyId'</span>],
aws_secret_access_key=credentials[<span>'SecretAccessKey'</span>],
aws_session_token=credentials[<span>'SessionToken'</span>])
    bucket = s3_resource.Bucket(os.environ[<span>'filesBucket'</span>])
    files=[]
    <span>for</span> obj <span>in</span> bucket.objects.all():
        files.append(getSignedUrl(obj.key,s3_client))
    <span>return</span> files
</code></pre>
<p>We are using the temporary credentials obtained from <em>AssumeRole</em> to generate Presigned URL in <em>getSignedUrl</em> function. The <em>getFilesList</em> functions returns list of file names and presigned URL.</p>
<p>Now, modify showFiles.html, to iterate over response and create links for files</p>
<pre><code><span>&lt;<span>html</span>&gt;</span>
<span>&lt;<span>head</span>&gt;</span>
<span>&lt;<span>link</span> <span>rel</span>=<span>"stylesheet"</span> <span>href</span>=<span>"https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css"</span> <span>integrity</span>=<span>"sha512-8bHTC73gkZ7rZ7vpqUQThUDhqcNFyYi2xgDgPDHc+GXVGHXq+xPjynxIopALmOPqzo9JZj0k6OqqewdGO3EsrQ=="</span> <span>crossorigin</span>=<span>"anonymous"</span> /&gt;</span>
<span>&lt;<span>script</span>
  <span>src</span>=<span>"https://code.jquery.com/jquery-3.1.1.min.js"</span>
  <span>integrity</span>=<span>"sha256-hVVnYaiADRTO2PzUGmuLJr8BLUSjGIZsDYGmIJLv2b8="</span>
  <span>crossorigin</span>=<span>"anonymous"</span>&gt;</span><span></span><span>&lt;/<span>script</span>&gt;</span>

<span>&lt;<span>script</span> <span>src</span>=<span>"https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"</span>&gt;</span><span></span><span>&lt;/<span>script</span>&gt;</span>
<span>&lt;/<span>head</span>&gt;</span>
<span>&lt;<span>body</span>&gt;</span>

<span>&lt;<span>div</span> <span>class</span>=<span>"ui raised very text container"</span>&gt;</span>
<span>&lt;<span>h1</span> <span>class</span>=<span>"ui header"</span>&gt;</span>File Access System<span>&lt;/<span>h1</span>&gt;</span>
<span>&lt;<span>i</span> <span>class</span>=<span>"folder open icon"</span>&gt;</span><span>&lt;/<span>i</span>&gt;</span><span>&lt;/<span>i</span>&gt;</span><span>&lt;<span>div</span> <span>class</span>=<span>"ui label"</span>&gt;</span>Files<span>&lt;/<span>div</span>&gt;</span>
<span>&lt;<span>div</span> <span>id</span>=<span>"files"</span> &gt;</span>Loading..<span>&lt;/<span>div</span>&gt;</span>
<span>&lt;/<span>div</span>&gt;</span>
<span>&lt;/<span>body</span>&gt;</span>
<span>&lt;<span>script</span>&gt;</span><span>

fetch(<span>"    https://g4m3zpzp95.execute-api.us-east-2.amazonaws.com/Prod/showFiles/"</span>, {
  credentials: <span>'include'</span>
})
  .then(response =&gt; response.text())
  .then((body) =&gt; {
    <span>var</span> files=<span>""</span>;

    <span>var</span> obj = <span>JSON</span>.parse(body)
    <span>for</span> (i = <span>0</span>; i &lt; obj.length; i++) {
            <span>var</span> o = obj[i]

            <span>for</span>(x <span>in</span> o){
                files =  files+ <span>"&lt;i class='file alternate outline icon'&gt;&lt;a href='"</span>+o[x]+<span>"' target='_blank'&gt;&amp;nbsp;&amp;nbsp;"</span>+x+<span>"&lt;/a&gt;"</span>
            }
    }
    <span>document</span>.getElementById(<span>"files"</span>).innerHTML= files
  })
  .catch(<span><span>function</span>(<span>error</span>) </span>{
    <span>console</span>.log(error); 
  });

</span><span>&lt;/<span>script</span>&gt;</span>
<span>&lt;/<span>html</span>&gt;</span>
</code></pre>
<p>Do SAM build and Deploy.
<img src="https://s3.amazonaws.com/blog-images-rajanpanchal.net/presignedUrl/presignedUrlStack.PNG" alt="Free cloud storage Presigned URL"></p>
<p>Modify login.html, signup.html and showFiles.html to update the api urls from cloudformation outputs.
Upload these files to the bucket <em>stsexamplebucket</em> or the bucket you created. Keep these files Public</p>
<p>You can find the code here:<br><a href="https://github.com/rajanpanchal/aws-kms-sts-presigned-url" target="_blank">github.com/rajanpanchal/aws-kms-sts-presign..</a></p>
<h3 id="testing">Testing</h3>
<p><img src="https://s3.amazonaws.com/blog-images-rajanpanchal.net/presignedUrl/testingVideo.gif" alt="private content serve using Presigned URL"></p>
<p>Let me know if you have any questions or comments!</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.rajanpanchal.net/how-to-serve-premiumprivate-content-on-your-site-cke6jrnsg00duxms1e7o52kr5</link>
            <guid isPermaLink="false">hacker-news-small-sites-24266871</guid>
            <pubDate>Tue, 25 Aug 2020 00:02:07 GMT</pubDate>
        </item>
    </channel>
</rss>
