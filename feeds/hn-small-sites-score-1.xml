<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 17 Jul 2020 08:18:04 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 17 Jul 2020 08:18:04 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Privacytools.io – Toxic Endorsements]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23845319">thread link</a>) | @realpanzer
<br/>
July 15, 2020 | https://dev.lemmy.ml/post/31434 | <a href="https://web.archive.org/web/*/https://dev.lemmy.ml/post/31434">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://dev.lemmy.ml/post/31434</link>
            <guid isPermaLink="false">hacker-news-small-sites-23845319</guid>
            <pubDate>Wed, 15 Jul 2020 14:02:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SML Dev Setup]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23845306">thread link</a>) | @vyuh
<br/>
July 15, 2020 | https://blog.jez.io/sml-dev-setup/ | <a href="https://web.archive.org/web/*/https://blog.jez.io/sml-dev-setup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main">
  <article>
    <p>When it comes right down to it, SML is a pretty great language. It’s clear that
extensive thought has gone into its design and implementation. I quite enjoy
programming in SML, due in no small part to my collection of workflow hacks that
make editing and developing with SML responsive and interactive.</p>

<!-- more -->


<p>We’re going to be walking through a couple easy steps to make developing SML
feel more fluid. I have a slight preference for Vim (Neovim) on macOS, but many
of these steps are platform agnostic.</p>

<p><strong>Note</strong>: I updated this post to more accurately reflect my SML dev setup in
December 2019.</p>

<h2>Installing SML Locally</h2>

<p>While developing SML in a remote environment like the shared Andrew Unix
machines makes it easy to dive right in, I prefer doing development on my
laptop—it doesn’t get slow when there are many people logged in, there’s no
nightly reboots, and it doesn’t matter whether I have a strong WiFi connection.</p>

<p>On macOS and Ubuntu, the two most popular implementations of SML are already
packaged. Take the time to install a version of SML right now:</p>

<ul>
<li><p>At CMU we use <a href="http://smlnj.org/">SML/NJ</a>, which is convenient because it has a REPL that
for playing around with SML interactively.</p></li>
<li><p>To play around with releasing programs written in SML to other people, install
<a href="http://www.mlton.org/">MLton</a>. It has better support for compiling SML programs to standalone
executables which can be shared from one machine to another. (I have a
separate post on <a href="https://blog.jez.io/sml-travis-ci/">using SML to release software publically</a>
with more details).</p></li>
</ul>


<figure><figcaption><span>Install SML from your package manager</span></figcaption><div><div><pre><code><span><span># macOS -- one or both of:</span>
</span><span>brew install smlnj
</span><span>brew install mlton
</span><span>
</span><span><span># Ubuntu -- one or both of:</span>
</span><span>sudo apt-get install smlnj
</span><span>sudo apt-get install mlton</span></code></pre></div></div></figure>


<p>Feel free to install both; they’ll play nicely with each other, and each offers
advantages over the other.</p>

<p>Note for macOS users: if you’ve never used <a href="https://brew.sh/">Homebrew</a> before, you’ll need
to <a href="https://brew.sh/">install it first</a>.</p>

<p>Note for Ubuntu users: the versions of these two that ship in the default
package distribution are frequently out of date. If that matters to you,
consider following the the <a href="http://smlnj.org/">SML/NJ</a> and <a href="http://www.mlton.org/">MLton</a> installation
instructions directly.</p>

<h2>Getting Comfortable with SML/NJ</h2>

<p>The rest of these steps should apply regardless of whether you’re working on SML
locally or remotely.</p>

<p>One thing that I’ve seen far too many times from course documentation is that
they tell students to run their code like this:</p>

<ol>
<li>Run <code>sml</code></li>
<li>Type <code>use "foo.sml";</code> or <code>CM.make "sources.cm";</code> at the REPL</li>
</ol>


<p>Don’t get me wrong; this works, but there’s a better way. Being responsible
CLI-citizens, we should always be looking for ways to tab-complete. We can
easily get tab-completion on the filename by changing our workflow:</p>

<ol>
<li>Run <code>sml foo.sml</code> or <code>sml -m sources.cm</code></li>
</ol>


<p>Look at that! We’ve,</p>

<ul>
<li>dropped a step (having to launch the REPL first), and</li>
<li>introduced tab completion (because the shell has filename completion)</li>
</ul>


<p>It’s the little things, but they add up.</p>

<h2>Enhancing the REPL</h2>

<p>Speaking of the little things, when using the SML REPL, you don’t have access to
all the usual command line niceties like command history and access to arrow
keys for editing, let alone Vi-like keybindings. To get started, you’ll have to
change how you launch the SML/NJ REPL. In particular, we’re going to preface our
commands with <code>rlwrap</code>:</p>

<figure><div><div><pre><code><span><span># instead of this...</span>
</span><span><span>$ </span>sml
</span><span>
</span><span><span># use this:</span>
</span><span><span>$ </span>rlwrap sml</span></code></pre></div></div></figure>


<p><code>rlwrap</code> stands for “readline wrap.” Readline is a library that adds all the
features mentioned above to any REPL program:</p>

<ul>
<li>Command history tracking (up arrow keys)</li>
<li>Line editing with arrow keys</li>
<li>Configuration through the <code>~/.inputrc</code> file

<ul>
<li>We can use this to get fancy features like Vi keybindings</li>
</ul>
</li>
</ul>


<p>For more information, see <a href="https://github.com/jez/dotfiles/blob/ed8e531eebe43a8aef05fc4cb768157d03408cea/inputrc#L12-L14">these lines</a> of my inputrc, a small part of
my <a href="https://github.com/jez/dotfiles">dotfiles repo</a> on GitHub.</p>

<h2>Setting Up Vim</h2>

<p>Programming is so much more enjoyable when you’re not fighting your editor. For
me, this means striving to get the most out of Vim. In this section, I’ll
outline all the cool tips and tricks I have for developing SML in Vim.</p>

<p>But first, if you’ve never taken a look into how to configure Vim, I suggest you
start out by walking through this quick workshop called <a href="https://github.com/jez/vim-as-an-ide">Vim as an
IDE</a>. It’ll teach you where to start when configuring Vim and get
you set up with a bunch of standard plugins that improve on the standard Vim
experience tenfold.</p>

<p>No actually, take a second and <a href="https://github.com/jez/vim-as-an-ide">walk through it</a>. We’ll still be
here when you’re done, and you’ll appreciate Vim more when you’re done.</p>

<h3>ALE</h3>

<p><a href="https://github.com/dense-analysis/ale">ALE</a> is a Vim plugin that provides what it calls “asynchronous linting.”
That’s a fancy way of saying that it can show little red x’s on all the lines
that have errors. It works for many languages out of the box, including Standard
ML.</p>

<p>It’s super simple to set up. The <a href="https://github.com/dense-analysis/ale">ALE homepage</a> should have all the
instructions.</p>

<p>With ALE set up, try writing this into a file called <code>test.sml</code>:</p>

<figure><figcaption><span>test.sml</span></figcaption><div><div><pre><code><span><span>val</span> <span>foo</span> <span>:</span> <span>string</span> <span>=</span> <span>42</span></span></code></pre></div></div></figure>


<p>While typing, any errors should appear as markers to the left of the line
numbers. Super handy!</p>

<p>If nothing shows up, check <code>:ALEInfo</code> which dumps a bunch of information
about whether ALE was set up correctly. In particular, SML support requires
having <a href="http://smlnj.org/">SML/NJ</a> installed (i.e., installing it on your laptop or working
on a server where it’s already installed).</p>

<h3>Extra ALE Setup</h3>

<p>While the default settings for ALE work well enough, there’s plenty of reasons
to tweak them. For example, here are <a href="https://github.com/jez/dotfiles/blob/b942b6336ee968c9d94a9ea363c1cbcdb44b9846/vim/plug-settings.vim#L227-L239">all my ALE settings</a>.</p>

<p>The key changes I make:</p>

<ul>
<li>I ask ALE to show a list of all errors if there were any.</li>
<li>I ask ALE to only run when the file was saved (not when it was opened or
edited).</li>
</ul>


<p>(You’ll also see a bunch of settings for other languages, but you won’t find any
SML-specific config… it’s not needed!)</p>

<p>Also, a tip for those who’ve never used Vim’s location list: you can close the
list of errors with <code>:lclose</code>.</p>

<h3>Using ALE with CM files</h3>

<p>Sometimes a single SML file is self-contained enough to type check on it’s own.
But most of the time, we’re working with multi-file SML projects. With SML/NJ,
multi-file SML projects are managed using CM files (<code>*.cm</code> files) which declare
groups of SML files that must be compiled together to make sense.</p>

<p>ALE’s support for SML handles both of these scenarios. When opening an SML file,
ALE will search up the folder hierarchy for any <code>*.cm</code> file, stopping when it
finds the first one. When there are multiple in a single folder, it takes the
alphabetically first option.</p>

<p>Usually this works fine but sometimes ALE picks the wrong one. There are
instructions for how to manually fix this by setting some variables in the ALE
help:</p>

<figure><div><div><pre><code><span>:help ale-sml-options</span></code></pre></div></div></figure>


<h3><code>vim-better-sml</code></h3>

<p>After all that, I still wasn’t satisfied with developing SML in Vim, so I wrote
a plugin to make it even better: <a href="https://github.com/jez/vim-better-sml">vim-better-sml</a>. Here’s a
quick rundown of its features:</p>

<ul>
<li>It supports for embedding a REPL directly inside Vim.</li>
<li>It supports asking for the type of a variable under the cursor.</li>
<li>It supports jump to definition, even into the Standard Basis Library.</li>
<li><code>*.sig</code> files are properly detected as SML signature files.</li>
<li>Many small annoyances with syntax highlighting and indentation are fixed.</li>
</ul>


<p>For more information, including how to install it, check out the homepage:
<a href="https://github.com/jez/vim-better-sml">vim-better-sml</a>. For the most part, the plugin itself will
guide you through the installation, declaring any dependencies that might be
missing.</p>

<p>I recorded a screencast of all those features above in action, which you might
want to check out:</p>

<p><a href="https://youtu.be/Z5FsPZ5cm8Y"><img src="https://blog.jez.io/images/vim-better-sml-demo-thumbnail.png" alt="thumbnail"></a></p>

<h2>General Vim Settings</h2>

<p>As a quick addendum, one common complaint people have when editing SML is that
it forces the line to wrap if it extends past 80 characters. Some people don’t
like that, and others don’t like that it doesn’t do it frequently enough
(namely, it only wraps the line if your <strong>cursor</strong> extends past 80 characters,
not the end of the line).</p>

<p>If you don’t want Vim to do any of this wrapping, run this:</p>

<figure><figcaption><span>Disable hard line wrapping</span></figcaption><div><div><pre><code><span><span>setlocal</span> textwidth<span>=</span><span>0</span></span></code></pre></div></div></figure>


<p>If you’d like this change to persist between Vim sessions, add it to
<code>~/.vim/after/ftplugin/sml.vim</code>. These folders and file likely don’t exist
yet; you’ll have to create them. The <code>after</code> folder in Vim is used to override
settings loaded from plugins.</p>

<p>Alternatively, if you’d like a little better idea when Vim’s going to hard wrap
your line, you can add one of these lines to your vimrc:</p>

<figure><figcaption><span>Show a color column</span></figcaption><div><div><pre><code><span><span>" Always draw the line at 80 characters</span>
</span><span><span>set</span> colorcolumn<span>=</span><span>80</span>
</span><span>
</span><span><span>" Draw the line at whatever the current value of textwidth is</span>
</span><span><span>set</span> colorcolumn<span>+=</span><span>0</span></span></code></pre></div></div></figure>


<p>That way, it’s easier to see when a line is getting long.</p>

<h2>TL;DR</h2>

<p>We covered a lot, so here’s a quick recap:</p>

<ul>
<li>Install SML locally. It’s super easy to do on macOS and Linux (use your
package manager), and means you don’t have to have a Wi-Fi connection to
develop SML.</li>
<li>Invest time into learning Vim. Here’s a reference: <a href="https://github.com/jez/vim-as-an-ide">Vim as an
IDE</a>.</li>
<li>Install <a href="https://github.com/dense-analysis/ale">ALE</a>. It tells you what lines your errors are on.</li>
<li>Install <a href="https://github.com/jez/vim-better-sml">vim-better-sml</a>. It includes a whole host of added
power features.</li>
</ul>


<p>And as always, you can see even more Vim settings in my <a href="https://github.com/jez/dotfiles">dotfiles
repo</a> on GitHub.</p>

    
  </article></div></div>]]>
            </description>
            <link>https://blog.jez.io/sml-dev-setup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23845306</guid>
            <pubDate>Wed, 15 Jul 2020 14:00:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Roll your own Ngrok with Nginx, Letsencrypt, and SSH reverse tunnelling]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23845294">thread link</a>) | @flipchart
<br/>
July 15, 2020 | https://jerrington.me/posts/2019-01-29-self-hosted-ngrok.html | <a href="https://web.archive.org/web/*/https://jerrington.me/posts/2019-01-29-self-hosted-ngrok.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
            

            <p>
    Posted on January 29, 2019
    
</p>

<p>Ngrok is a fantastic tool for creating a secure tunnel from the public web to a machine behind NAT or a firewall. Sadly, it costs money and it’s proprietary. If you’re a developer, odds are that you’re already renting a server in the public cloud, so why not roll your own ngrok?</p>
<p>It turns out that you can do it using free, off-the-shelf tools, with no sophisticated scripting required! In this article, I’ll show you how.</p>
<h2 id="step-1.-configuring-nginx">Step 1. Configuring Nginx</h2>
<p>Use a server block like this, so that incoming HTTP connections to <code>tunnel.yourdomain</code> are reverse proxied into the application listening on port <code>3333</code>.</p>
<pre><code>server {
    server_name tunnel.yourdomain;

    access_log /var/log/nginx/$host;

    location / {
	    proxy_pass http://localhost:3333/;
	    proxy_set_header X-Real-IP $remote_addr;
	    proxy_set_header Host $host;
	    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto https;
	    proxy_redirect off;
    }

    error_page 502 /50x.html;
    location = /50x.html {
	    root /usr/share/nginx/html;
    }
}</code></pre>
<p>With this configuration in place, suppose I visited <code>tunnel.yourdomain</code>. Nginx will receive the connection, and see that it should reverse proxy it. It will effectively pass the connection on to whatever application is listening on port <code>3333</code>. Currently, there is nothing listening on this port, so we will get a <code>502 Bad Gateway</code> or <code>404 Not Found</code> error from Nginx.</p>
<p>Let’s fix that.</p>
<h2 id="step-2.-using-an-ssh-reverse-tunnel">Step 2. Using an SSH reverse tunnel</h2>
<p>SSH reverse tunnelling port <code>N</code> to port <code>K</code> means making sshd listen on port <code>N</code> and effectively transfer incoming connections over the SSH connection to the SSH client. The SSH client will then transfer the connection to the application listening on port <code>K</code> on the client machine.</p>
<p>Here’s the command to run on your client machine: <code>ssh -R N:localhost:K yourdomain</code></p>
<p>An interactive session on your server should begin; while it is open, the reverse tunnel from port <code>N</code> to port <code>K</code> is active, and sshd will allow connections originating only from <code>localhost</code>, i.e.&nbsp;your server.</p>
<p>Choosing <code>N</code> = <code>3333</code> will make it so Nginx reverse proxies incoming connections on <code>tunnel.yourdomain</code> into sshd, over the SSH connection, and into the application running on your local machine on port <code>K</code>.</p>
<p>To test this out, on your local machine, in one shell run <code>python -m http.server 8888</code> and in another shell run <code>ssh -R 3333:localhost:8888 yourdomain</code>. Visit <code>tunnel.yourdomain</code>. You should see a directory listing for whatever directory you were in when you ran the Python command!</p>
<p>However, there’s a glaring problem with this setup.</p>
<h2 id="step-3.-securing-the-connection-in-the-browser">Step 3. Securing the connection in the browser</h2>
<p>The connection the browser is making to Nginx is at the moment not secure: it was a plain HTTP connection. You can fix this by obtaining a free TLS certificate with Letsencrypt, and using it to secure the connection the browser is making.</p>
<p>There are already excellent tutorials available on setting up Letsencrypt, so I won’t repeat that here. I recommend consulting the ArchWiki article <a href="https://wiki.archlinux.org/index.php/Certbot">here</a>. Letsencrypt is a self-hosters dream-come-true since it is truly a set-it-and-forget-it type of thing. With the appropriate setup, (namely a simple systemd timer,) the certificate you get will renew itself when it its expiry is approaching.</p>
<p>Once you have a certificate, it suffices to adjust the Nginx server block above so it looks like this.</p>
<pre><code>server {
    server_name tunnel.yourdomain;

    access_log /var/log/nginx/$host;
    
    # These three lines are new.
    listen 443 ssl;
    ssl_certificate /path/to/tls/cert/fullchain.pem;
    ssl_certificate_key /path/to/tls/cert/privkey.pem;

    location / {
	    proxy_pass http://localhost:3333/;
	    proxy_set_header X-Real-IP $remote_addr;
	    proxy_set_header Host $host;
	    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto https;
	    proxy_redirect off;
    }

    error_page 502 /50x.html;
    location = /50x.html {
	    root /usr/share/nginx/html;
    }
}</code></pre>
<p>Only <em>three lines</em> need to be added!</p>
<h3 id="conclusion">Conclusion</h3>
<p>With very little setup, we saw how to configure Nginx to act as a reverse proxy, and how to use an SSH reverse tunnel. By combining these off-the-shelf tools, we essentially replicated the core functionality of the fantastic tool Ngrok. Using this double-reverse-proxy technique, web applications running on a machine behind NAT or a firewall can be accessed easily and securely from a public domain or IP address.</p>
<p>If you have any comments or concerns, <a href="https://github.com/tsani/jerrington.me/issues">open an issue</a> on Github.</p>

        </div></div>]]>
            </description>
            <link>https://jerrington.me/posts/2019-01-29-self-hosted-ngrok.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23845294</guid>
            <pubDate>Wed, 15 Jul 2020 13:59:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Efficient Navigation in Vim]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23845213">thread link</a>) | @lvht
<br/>
July 15, 2020 | https://blog.bespinian.io/posts/efficient-navigation-in-vim/ | <a href="https://web.archive.org/web/*/https://blog.bespinian.io/posts/efficient-navigation-in-vim/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>When editing a file, it’s quite crucial that you can navigate your cursor around rather quickly. <a href="https://www.vim.org/">Vim</a> and <a href="https://neovim.io/">NeoVim</a> allow for many different ways of doing so which, depending on the situation, can be more or less efficient and useful. This article examines the different ways of moving the cursor and compares them. Here, the term “efficiency” refers to navigating the cursor with as little time and effort (i.e. the number of keystrokes) as possible.</p>
<h2 id="using-the-mouse">Using the Mouse</h2>
<p><strong>TL;DR: Not recommended</strong></p>
<p>Using the mouse pointer to navigate Vim may seem like an obvious choice for users coming from a GUI editor like <a href="https://code.visualstudio.com/">Visual Studio Code</a> or similar. However, in Vim, the goal is to keep your fingers on the “home row” of the keyboard (the row where the <code>F</code> and the <code>J</code> keys reside) and not having to move them greatly towards the touchpad or even the mouse. This should reduce the strain on your hands and wrists and make editing more efficient. Therefore, navigating with the mouse should be highly discouraged in most situations and is even disabled by default.</p>
<p>It can be helpful to enable it for users transitioning from one of the aforementioned editors who would like to have a smooth transition by allowing themselves to use the mouse initially and switching it back off again later in their learning journey. To turn on mouse navigation, add the following to your configuration file (either <code>~/.vimrc</code> or <code>~/.config/nvim/init.vim</code>):</p>
<div><pre><code data-lang="vim"><span>" Temporarily enable mouse support</span><span>
</span><span></span><span>set</span> <span>mouse</span>=<span>a</span><span>
</span></code></pre></div><p>This will allow you to point and click to move the cursor and to scroll through the current buffer.</p>
<h2 id="using-the-arrow-keys">Using the Arrow Keys</h2>
<p><strong>TL;DR: Not recommended</strong></p>
<p>Again, for users used to other text editors or even word processing software like <a href="https://www.libreoffice.org/discover/writer/">LibreOffice Writer</a>, it may be tempting to use what they know. In these programs, you mostly use the arrow keys for keyboard-based navigation. This is not recommended because… you guessed it: They require the user to move their fingers away from the home row.</p>
<p>The alternative is, as described in the next section, to use the <code>h</code>, <code>j</code>, <code>k</code> and <code>l</code> keys on the keyboard which are conveniently placed at the center and where you most likely have your fingers most of the time.</p>
<h2 id="using-hjkl">Using h,j,k,l</h2>
<p><strong>TL;DR: Use for small navigations. Use in combination with relative line numbers.</strong></p>
<p><code>h</code>, <code>j</code>, <code>k</code> and <code>l</code> are the basic movement keys in Vim. They should be used instead of the usual arrow keys on the keyboard to, as discussed above, keep your fingers on the home row as much as possible. It takes a little practice but will pay off in the long run.</p>
<p>One hugely important thing to do with these keys is to not press them multiple times in sequence or even hold them down to move several columns or rows. As with many commands in Vim, they can be prefixed with numbers to move multiple times. For example, <code>12j</code> can be used rather than pressing the <code>j</code> key twelve times which is, obviously, much more efficient (3 vs. 12 keystrokes). However, it is recommendable to only use these keys for small movements and mostly to move lines up or down because there are more efficient ways of moving longer vertical distances or horizontal distances in general.</p>
<p>It can be very useful to enable relative line numbers to see at a glance what number to prefix <code>j</code> or <code>k</code> with to move to a certain line. They can be enabled by adding the following two lines to your configuration file:</p>
<div><pre><code data-lang="vim"><span>" Enable relative line numbers</span><span>
</span><span></span><span>set</span> <span>relativenumber</span><span>
</span><span></span><span>set</span> <span>number</span><span>
</span></code></pre></div><p>This will always show the absolute number of the line the cursor is currently on and relative numbers for all others.</p>
<h2 id="navigation-within-a-line">Navigation Within a Line</h2>
<p><strong>TL;DR: Mostly use <code>f</code>. Also consider <code>w</code>,<code>b</code>,<code>e</code>,<code>^</code> and <code>$</code>.</strong></p>
<p>So far, we’ve mostly looked at navigating from one line to another. The next step is to navigate within a line. In many cases, the straight forward thing to do is to use <code>w</code> or <code>W</code> to move to the next word, <code>b</code> or <code>B</code> to move to the previous word or even <code>e</code> or <code>E</code> to move directly to the end of the next word. For all of them, the lowercase variant considers a “word” to be what we intuitively see as one using delimiters like <code>-</code>, <code>/</code> or <code>.</code> to separate one word from another. The uppercase variant considers anything a word that is delimited by whitespace. Obviously, any of these commands can be prefixed with a number to jump multiple words in one go (e.g. <code>7w</code>). Other useful commands are <code>^</code> which moves to the first non-whitespace character of the line and <code>$</code> to move to the last character of a line. Considering the following line</p>
<p>with the cursor currently on the <code>g</code> character, pressing the following commands is the most efficient way to get to a specific target character:</p>
<table>
<thead>
<tr>
<th>Target Character</th>
<th>Command</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>j</code></td>
<td><code>2w</code></td>
</tr>
<tr>
<td><code>m</code></td>
<td><code>W</code></td>
</tr>
<tr>
<td><code>d</code></td>
<td><code>B</code></td>
</tr>
<tr>
<td><code>i</code></td>
<td><code>e</code></td>
</tr>
<tr>
<td><code>l</code></td>
<td><code>E</code></td>
</tr>
<tr>
<td><code>a</code></td>
<td><code>^</code> or <code>0</code></td>
</tr>
<tr>
<td><code>o</code></td>
<td><code>$</code></td>
</tr>
</tbody>
</table>
<p>When moving multiple words back and forth or to a specific place within a word, <code>t</code> and <code>f</code> are incredibly helpful. Especially <code>f</code> moves to the next occurrence of a specific character which lets you make big jumps within a line. The difference is that <code>f</code> moves to a character and <code>t</code> moves to right before a character. So <code>t</code> is mostly useful for deleting everything to a character. These commands’ uppercase variants <code>F</code> and <code>T</code> do the same thing but backwards. All of these commands can be “repeated” with the <code>;</code> command which jumps to the next occurrence of the targeted character while <code>,</code> jumps to the previous one.</p>
<h2 id="search">Search</h2>
<p><strong>TL;DR: Great for moving larger distances vertically and horizontally</strong></p>
<p>By far one of the most efficient ways of moving longer distances horizontally and vertically in a buffer is to use the search. The <code>/</code> key lets you search for a term and conveniently jump to its location. Pressing the <code>n</code> and <code>N</code> keys jumps to the next and previous occurrence of the search term respectively. The <code>?</code> key searches backwards from the current cursor position (which inverts <code>n</code> and <code>N</code>). Even though, the main purpose of the search command is obviously to search, it is an incredibly powerful tool to navigate quickly and efficiently.</p>
<p>The user experience of the search command can be vastly improved by adding the following settings to your configuration file:</p>
<div><pre><code data-lang="vim"><span>" Incrementally search while typing</span><span>
</span><span></span><span>set</span> <span>incsearch</span><span>
</span><span></span><span>" Use smart case for searching</span><span>
</span><span></span><span>set</span> <span>ignorecase</span><span>
</span><span></span><span>set</span> <span>smartcase</span><span>
</span><span></span><span>" Highlight searches</span><span>
</span><span></span><span>set</span> <span>hlsearch</span><span>
</span><span></span><span>" Use &lt;C-L&gt; to clear the highlighting of :set hlsearch.</span><span>
</span><span></span><span>if</span> <span>maparg</span>(<span>'&lt;C-L&gt;'</span>, <span>'n'</span>) ==# <span>''</span><span>
</span><span></span>  <span>nnoremap</span> &lt;<span>silent</span>&gt; &lt;<span>C</span>-<span>L</span>&gt; :<span>nohlsearch</span>&lt;<span>C</span>-<span>R</span>&gt;=<span>has</span>(<span>'diff'</span>)?<span>'&lt;Bar&gt;diffupdate'</span>:<span>''</span>&lt;<span>CR</span>&gt;&lt;<span>CR</span>&gt;&lt;<span>C</span>-<span>L</span>&gt;<span>
</span><span></span><span>endif</span><span>
</span></code></pre></div><p><code>incsearch</code> will make sure that the search pattern is applied incrementally while typing instead of only after pressing the enter key. The combination of <code>ignorecase</code> and <code>smartcase</code> ignores the case of the search term when not using any uppercase letters and doesn’t ignore it when using at least one uppercase letter which is quite convenient and surprisingly intuitive. <code>hlsearch</code> highlights any matches for the search term allowing to easily jump between them using <code>n</code> and <code>N</code>. The last statement lets you clear the highlighted search results by pressing <code>ctrl+l</code> to unclutter your view once done searching and jumping.</p>
<p>All in all, search is one of the powerful tools for intuitive and efficient navigation. It covers the common use case of knowing the word or part of a word to navigate to but not having your eyes directly pointed there yet. Furthermore, it’s simply the fastest way of jumping somewhere in many cases and beats other methods of navigation quite often in that regard.</p>
<h2 id="clunky-movements">Clunky Movements</h2>
<p><strong>TL;DR: Use for very specific use cases only. Consider <code>gg</code> and <code>G</code> for getting to know a file.</strong></p>
<p>In this section we’ll discuss what can be referred to as “clunky movements”. They let the user navigate larger distances in the buffer while sacrificing precision. These commands are less useful for exactly that reason. Vim can be a very efficient text editor by letting the user think about what they want to change, jumping precisely there with very few keystrokes, entering insert mode, performing a change with scalpel-like precision and finally exiting insert mode as soon as it’s done. The movement commands in this section however, get the cursor around the document as a whole while it’s hard for the user to predict at a glance, which line and column exactly they will land on.</p>
<p>A good example are the <code>H</code>, <code>M</code> and <code>L</code> keys which take the cursor to the top, the middle or the bottom of the current view port respectively. While this is a very big movement with just one keystroke, it’s highly likely that they won’t exactly get the cursor to the line needed but rather will have to be accompanied by pressing <code>j</code> or <code>k</code> multiple times which will result in much more thinking and many more keystrokes than what can be achieved with other methods. Similar are the <code>{</code> and <code>}</code> keys which take the cursor to the next paragraph (a block of text delimited by blank lines).</p>
<p>A useful exception to that are the <code>gg</code> and <code>G</code> commands which take the cursor to the first or the last line of a buffer respectively. It’s easy and effortless to predict where these movements will take you. Especially the <code>G</code> command can be quite useful because it allows to append to a file with just two keystrokes (<code>G</code> followed by <code>o</code>).</p>
<h2 id="plugins">Plugins</h2>
<p><strong>TL;DR: Install only the necessary plugins. Check out fzf!</strong></p>
<p>So far, we’ve only talked about features that are built into Vim or that can be configured on a vanilla installation. However, there are many useful plugins which can make navigating Vim even more efficient. It is important to carefully pick them though as any plugin can make Vim slower and/or less stable.</p>
<h3 id="fzf">fzf</h3>
<p>One of the most useful plugins is <a href="https://github.com/junegunn/fzf.vim">fzf</a> which is a great one to have in general. It offers many helpful commands like <code>:BLines</code> for searching the current buffer with intelligent fuzzy matching or <code>:Rg</code> for even searching the whole project for specific patterns which, in contrast to the other methods we’ve looked at so far, lets the user navigate between files. fzf is a tool that can be used for jumping between files and buffers but also between different locations within them. I highly recommend to check it out and add the following lines to your configuration file:</p>
<div><pre><code data-lang="vim"><span>" Jump to specific file</span><span>
</span><span></span><span>nnoremap</span> &lt;<span>C</span>-<span>P</span>&gt; :<span>Files</span>&lt;<span>cr</span>&gt;<span>
</span><span></span><span>" Search whole project</span><span>
</span><span></span><span>nnoremap</span> \ :<span>Rg</span>&lt;<span>space</span>&gt;<span>
</span></code></pre></div><p>The first line lets you open …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.bespinian.io/posts/efficient-navigation-in-vim/">https://blog.bespinian.io/posts/efficient-navigation-in-vim/</a></em></p>]]>
            </description>
            <link>https://blog.bespinian.io/posts/efficient-navigation-in-vim/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23845213</guid>
            <pubDate>Wed, 15 Jul 2020 13:52:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Keybase - stay away from it, seriously.]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23845180">thread link</a>) | @realpanzer
<br/>
July 15, 2020 | https://dev.lemmy.ml/post/31190 | <a href="https://web.archive.org/web/*/https://dev.lemmy.ml/post/31190">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://dev.lemmy.ml/post/31190</link>
            <guid isPermaLink="false">hacker-news-small-sites-23845180</guid>
            <pubDate>Wed, 15 Jul 2020 13:50:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[$0-$1M ARR in 12 Months Bootsrapped]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23844894">thread link</a>) | @sabbakeynejad
<br/>
July 15, 2020 | https://www.veed.io/blog/0-1m-arr-12-months/ | <a href="https://web.archive.org/web/*/https://www.veed.io/blog/0-1m-arr-12-months/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/Screenshot-2020-06-24-at-14.40.11.png 300w,
                            https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/Screenshot-2020-06-24-at-14.40.11.png 600w,
                            https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/Screenshot-2020-06-24-at-14.40.11.png 1000w,
                            https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/Screenshot-2020-06-24-at-14.40.11.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/Screenshot-2020-06-24-at-14.40.11.png" alt="0-1M ARR in 12 Months Bootsrapped">
            </figure>

            <section>
                <div>
                    <p>VEED.IO has grown fast.</p><p>12 months ago we turned on our paywall and made our first ever SaaS $1.</p><p>For any entrepreneur, this is a moment that they will never forget. Tim and I could not control our excitement.</p><figure><img src="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/IMG_0318.jpeg"><figcaption>Our first ever $1 - 12 months ago</figcaption></figure><p>You achieved the impossible, there is light at the end of the tunnel and everything you have been dreaming about and working towards might come true!</p><p>Exactly 12 months after this first payment, we have managed to cross the seemingly impossible task of hitting $83,333 MRR / $1M ARR.</p><p>And the best part is we did it 100% self-funded, with no external funding.</p><figure><img src="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/IMG-20200703-WA0015-1.jpg"><figcaption>1M ARR - Tim &amp; Sabba - VEED.IO</figcaption></figure><p>In this post, I would like to share relevant financial data that might give other founders insights into how to build their own bootstrapped SaaS to $1M ARR.</p><p>I would also like to share some insights into our attitudes and believes that have got us to where we are. Such as our bullish attitude towards growth, how we build the product and how we think about the future of VEED.</p><h3 id="the-numbers">The Numbers</h3><p>First off, we are aware that we did this very fast and we also go lucky (I talk about this more below) From the outside, VEED might look like an overnight success, however it was 10 years in the making!</p><p>Before we look at the numbers, I would like to provide some context. When we started charging, we already had about 30,000 MAU. However, pretty much none of those users would speak to us and we were unsure that if we added the paywall any of the users would upgrade.</p><figure><img src="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/Accounts-Copy-149.png"><figcaption>1M ARR in 12 Months</figcaption></figure><p>Growth starts slow, but having a product that is scalable and can we assessed globally from day one really means the sky is the limit. 6 months in, our projection for 1M ARR was December, then August and due to increasing demand influenced by the pandemic, we hit 1M ARR in June. </p><figure><img src="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/Accounts-Copy-150.png"><figcaption>ARR Milestones</figcaption></figure><p>As you can see, the first $100K ARR took 171 days to reach and the following $100K took just 48 days. The reason why the 2nd was much quicker than the first is because we were learning from users and building the required product features. We were also learning more about our acquisition channels and were able to double down on them. </p><p>Although 171 days is not a very long period of time, turning up to the office and putting in 12 hours every day can be really draining. The stress of getting to profitability was really real. For bootstrapped startup, be aware that it can really take some time.</p><p>Like with anything with compounding growth your first 100K takes ages, but the next comes a lot quicker. It took 12 months for us to hit 1M ARR, however we are projected to hit 2M in just 4 months!</p><figure><img src="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/Accounts-Copy-151.png"><figcaption>1M ARR Traffic Growth</figcaption></figure><p>Bootstrapping is hard work, but as you grow it gets a lot easier. The speed in which you grow makes a HUGE difference to the bootstrapping experience. You need to get the flywheel moving super fast to keep everyone motivated and to get you to ramen profitability.</p><p>6 months after our first-ever paid users, we reached $10K MRR. Although a relatively small sum, it was enough to support the founding team.</p><p>This is important as it means you can donate 100% of your time building and growing your product.</p><p>However, if it took 18 months to reach this goal, the market would have moved on, our attitudes towards the product would have changed and maybe we would have been disillusioned. Otherwise known as the "Long, Slow, SaaS Ramp of Death"</p><p>From our experience, there are three keys to successfully bootstrapping.</p><h3 id="your-ideas-at-the-core-"><br>Your ideas at the core.</h3><p>A common mistake I often see is founders building way too much!</p><p>Building any app is hard work. If you set out to build a fully-fledged product you might never finish and more importantly, you are not getting valuable feedback from your users to help shape your product.</p><p>Setting the bar too high will also delay your launch and also make responding to feedback much harder due to a bloated codebase and feature set.</p><p>After years of building VEED, we don't even think we are at version 1.0.</p><p>We believe the best thing to do is to build your MVP and get it out into the world as soon as possible. The first version of VEED had only 4 features, Trim, Crop, Draw and Text. There was no login, no accounts, just a simple web app. Looking back, I think we made way too much, we should have launched with just a really good crop tool.</p><p>After we saw that users were responding well to your app, we started building new features that they had requested. This kickstarted our build measure learn process. So you need to find the minimum set of features that represents your idea.</p><h3 id="validate-your-ideas-fast-">Validate your ideas fast.</h3><p>When I first entered the startup world, I was under the impression that you needed a new and original idea. For many years I tried that approach with little to no success.</p><p>In my opinion, the best way to validate an idea is to look to see if this is a product people are already willing to pay for.</p><p>For example, I would feel comfortable that people are willing to pay for an email marketing tool. Why? Because Mailchimp has proven this for us!</p><p>This questions now is, how are you different or what subset of users do you believe they are undeserving?</p><p>For us at VEED, we knew people where the will to pay for video editing software (I know because I had an Adobe subscription myself). What we did differently is we just put it online and targeted, short-form content creators.</p><p>Why? Because we believe they were being underserved by legacy video editing platform. One of my fave tutors from art school once told me "An original idea is not something completely new, it just 10% different"</p><p>If it feels like you are pushing a boulder uphill and struggling to get traction, it might be time to move to the next idea. Seriously, the faster you can get to this realisation, the better. Don't let a "sunk cost" fallacy keep you working on the same idea.<br></p><h3 id="work-out-how-to-charge-for-your-product-early-on-">Work out how to charge for your product early on.</h3><p>Your funds will not last forever. We ran out of money before and had to go back to contract jobs. This ultimately set us back 6 months. To give your startup the best opportunity for success (I believe this both applies to Boostrapped &amp; VC backed startups, with some exceptions*) it has to generate revenue, a clear sign that you are creating value.</p><p>And charging for your product early on does a few things.</p><ol><li>Proves that users are willing to pay for it.</li><li>Provides you with better feedback (users care more if they are paying)</li><li>Lowers your burn rate and gets your closer to profitability.</li></ol><p>If you can't avoid writing a lot of code before you get your basic product live, you can follow the real estate showroom strategy!</p><p>When a property developer is building a new block of flats, the first thing they do is build a showroom and start selling! Then once someone is interested and buys, you can ask them what colour they want the walls and ask them what taps they would like in the bathroom.</p><p>Overall we have been laser-focused over the last 12 months. We have not gone to any conferences, pitched investors, built pointless pitch decks, entertained any partnerships. We have just been 100% focused on building VEED, learning from our users and growing the company.</p><h3 id="product">Product </h3><p>Our product development strategies are user-centric. Every user who signs up for VEED can book an on-boarding call with us. This process is time-consuming but provided incredible insight into who our users are, what they don't understand and what they need from VEED.</p><figure><img src="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/IMG_20200714_174440.jpg"><figcaption>User calls every day of the week</figcaption></figure><p>We have built new features fast and scrapped useless features even quicker. Overall we have put a lot of time into UX, but I must admit consistency with the design is sometimes lacking. But that is the cost we are willing to pay to move fast.</p><p>New paid users are also prompted to let us know why they chose VEED. We have collected over 500 of these responses and use them to inform our copy and also our focus.</p><h3 id="marketing">Marketing</h3><div><p>For the first 8 months, Tim has spent all of his time building the product and I (Sabba) have spent all of my time working on marketing. Admittedly, we were shameless and scrappy and had varying levels of success.</p><p>When starting VEED we knew nothing about marketing, so we made it our full-time job to learn and execute on our findings.</p></div><figure><img src="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/IMG_20200714_174857.jpg"><figcaption>58 users a day was HUGE!!!</figcaption></figure><p>For first time founders, growth and marketing are often overlooked. The majority of the time, this is because it can appear confusing and complex. Another big reason why technical founder shies away from marketing is that they feel a lot more comfortable coding a new feature because that is what they know.</p><p>You need to understand what acquisition channels are the most relevant for your startup and go deep on understanding them. The book "Traction" by Gabriel Weinberg, founder of DuckDuckGo is a great starting point.</p><p>If you would like to lean more about the exact tactics we used to grow VEED, please check an older post on how we <a href="https://www.veed.io/blog/startup-growth-no-budget/">grew to 50,000 MAU</a></p><p>As entrepreneurs, we like to believe there as a playbook and a recipe to build a successful business.</p><p>The truth is there kinda is, but one of the largest factors of a successful business is luck. A topic topic that many founders like to admit.</p><p>Yes, we worked hard, we made educated decisions, learnt as much as we could and applied our knowledge the best as we could. But looking back on how we got here, I just can't kick the feeling that we got lucky.</p><p>This is my imposter syndrome kicking in again</p><p>The good news is that luck is not 100% out of control and there are things we can do to make ourselves luckier. Two important things happened during our journey that we were smart enough to capitalise on and make ourselves more lucky.</p><blockquote>Example 1<br><strong>We got lucky: </strong>Finding our first two engineers, Mate and Veljko. Without these two we would not be here today. Period.<p><strong>We made our luck: </strong>Posting the job posts everywhere, interviewing as many candidates as possible, not settling for ok. We wouldn't stop until we found the right people, the 100% yes's.</p></blockquote><blockquote>Example 2<br><strong>We got lucky: </strong>Tim …</blockquote></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.veed.io/blog/0-1m-arr-12-months/">https://www.veed.io/blog/0-1m-arr-12-months/</a></em></p>]]>
            </description>
            <link>https://www.veed.io/blog/0-1m-arr-12-months/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23844894</guid>
            <pubDate>Wed, 15 Jul 2020 13:27:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Paper Mario: The Origami King is a laugh-out-loud funny RPG on the Switch]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23844806">thread link</a>) | @suleaty
<br/>
July 15, 2020 | https://newsworthy.to/article/2020/07/15/paper-mario-origami-king-is-a-laugh-out-loud-funny-rpg-on-switch | <a href="https://web.archive.org/web/*/https://newsworthy.to/article/2020/07/15/paper-mario-origami-king-is-a-laugh-out-loud-funny-rpg-on-switch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article><p><time datetime="2020-07-15T13:00:00">July 15, 2020</time> by <a href="https://www.theverge.com/21324614/paper-mario-the-origami-king-review-nintendo-switch">The Verge</a> | <a href="https://newsworthy.to/category/entertainment">Entertainment</a></p><p>A great comedy that also happens to be a great game</p><p>Super Mario’s roleplaying adventures have always been playful twists on the genre. RPGs can be uptight, all melodrama and end-of-the-world theatrics. But games like <em>Super Mario RPG</em> and the <em>Mario &amp; Luigi</em> series took what made RPGs great — the strategic battles, lengthy adventures, and vast stories — and infused them with humor and charm. <em>Paper Mario: The Origami King</em> continues this tradition but updates it in lots of clever ways. It’s the rare game where being funny is its biggest strength.</p><p>As with most Mario adventures, <em>The Origami King</em> involves trouble with Princess Peach, but not in the typical damsel in distress way. At the outset, Mario and his brother arrive at Toad Town for an origami festival, only to discover the city is mostly deserted. Inside the castle, they find a disturbing — and origami-fied — version of the princess. “Why haven’t you joined me in folding glory?” she asks. As it turns out, the princess, and much of the Mushroom Kingdom, are under the control of an evil origami wizard bent on reshaping the world in his image.</p><p>It’s an admittedly silly premise, but it works; the villains and their intentions feel appropriately evil, and it’s a great excuse to venture across the world. As part of his scheme, the origami king uses five gigantic pieces of ribbon to rip Peach’s castle out of the ground and transport it to a remote mountaintop. The goal is simple: destroy the ribbons to get into the castle. Your destination is almost always in view; when you’re out in the world, you can see the ribbons stretching across the landscape until you finally manage to remove them.</p><p><em>The Origami King</em> plays out sort of like an open-world RPG. You play as a flat rendition of Mario venturing across the world — to ancient deserts, underwater dungeons, and abandoned theme parks — all while solving often arcane brain teasers to open up new areas, eliminate the origami menace, and dispose of the ribbons. There are RPG-like mechanics like equippable weapons and additional party members, including an amnesiac Bob-omb and a Toad archaeologist. Battles are clever turn-based affairs that are essentially puzzles: you have to spin enemies around on a wheel to line them up so you can get the right attack in before a timer runs out. In most RPGs, I mash the attack button through random battles, but here, I had to actually pay attention.</p><p>Many of the elements streamline what can often be a tedious and fiddly genre. The battles, outside of bosses, are snappy and fun, and you only have to worry about a few items and skills to succeed. If you get stuck, a helpful origami friend named Olivia is available at any time to give you helpful hints, sort of like a less annoying version of Navi from <em>Ocarina of Time</em>. <em>The Origami King</em> strikes a nice balance between being approachable but still having depth. It’s also wonderfully tactile. While Mario can jump, he also has a hammer to smash everything and anything around him, which he does to open up secret areas, solve puzzles, and rescue flattened toads hidden almost anywhere you look.</p><p>The game looks and plays wonderfully, but really, the star is its sense of humor. It’s downright silly. There are copious puns and visual jokes and all kinds of things that don’t make sense but are delightful regardless. For instance, since you’re made of paper, you can travel around the world via fax machine; the game calls this “fax travel.” At one point, after wandering through a forest of talking trees, I came across firewood chanting “light me!” and “we must burn!”</p><p>Everything is goofy: the most difficult bosses are sentient office supplies, and there are multiple surprise musical numbers and performances, including a multipart stage play that ends in a Shy Guy ballet. Much like <a href="https://www.theverge.com/2019/10/31/20942003/luigis-mansion-3-review-nintendo-switch-gooigi-comedy">the most recent <em>Luigi’s Mansion</em></a>, a lot of the silliness comes from slapstick comedy, as you take your hammer and smash things to see what happens. It could be an unusual toad unfolding after previously being disguised as an origami frog or butterfly, or a secret cafe full of grumbling Bowser minions. At the very least, you’ll see colorful confetti rain down from the tree you just bonked. The story even has rare moments of poignant drama to round out the experience; <em>Paper Mario</em> is not a game where I expected to be shocked by a character’s death, but the team at Nintendo pulled it off masterfully.</p><p>The fact that <em>The Origami King</em> is a great game almost feels like a bonus. It could’ve simply been a vehicle for Nintendo’s goofs, and I would’ve enjoyed it, such is the rarity of truly funny comedy games. But it also happens to be a fantastic example of how to freshen up the classic RPG formula with a few new ideas and clever simplification. In virtually every regard, the latest <em>Paper Mario</em> is anything but flat.</p><p><small>Paper Mario: The Origami King </small><small><em>launches on July 17th on the Nintendo Switch.</em></small></p></article></div></div></div>]]>
            </description>
            <link>https://newsworthy.to/article/2020/07/15/paper-mario-origami-king-is-a-laugh-out-loud-funny-rpg-on-switch</link>
            <guid isPermaLink="false">hacker-news-small-sites-23844806</guid>
            <pubDate>Wed, 15 Jul 2020 13:21:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Runnaroo claims to be a privacy-respecting search engine – but they got issues]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23844748">thread link</a>) | @realpanzer
<br/>
July 15, 2020 | https://dev.lemmy.ml/post/37504 | <a href="https://web.archive.org/web/*/https://dev.lemmy.ml/post/37504">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://dev.lemmy.ml/post/37504</link>
            <guid isPermaLink="false">hacker-news-small-sites-23844748</guid>
            <pubDate>Wed, 15 Jul 2020 13:18:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Developers can't fix bad management]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23844701">thread link</a>) | @replyifuagree
<br/>
July 15, 2020 | https://iism.org/article/developers-can-t-fix-bad-management-57 | <a href="https://web.archive.org/web/*/https://iism.org/article/developers-can-t-fix-bad-management-57">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://iism.org/article/developers-can-t-fix-bad-management-57</link>
            <guid isPermaLink="false">hacker-news-small-sites-23844701</guid>
            <pubDate>Wed, 15 Jul 2020 13:14:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Book: Writing Maintainable Unit Tests]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23844534">thread link</a>) | @JanVanRyswyck
<br/>
July 15, 2020 | https://principal-it.eu/2020/07/writing-maintainable-unit-tests/ | <a href="https://web.archive.org/web/*/https://principal-it.eu/2020/07/writing-maintainable-unit-tests/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<div>
					<h2>
						Announcing Book: Writing Maintainable Unit Tests
					</h2>
					<p><span>
						July 15, 2020
					</span>
				</p></div>

				
<p>I’m very happy to announce that the first draft of my book <a href="https://leanpub.com/writing-maintainable-unit-tests" target="_blank" rel="noopener noreferrer nofollow">Writing Maintainable Unit Tests</a> has been published on LeanPub. 
It’s the written counterpart of my <a href="https://www.udemy.com/course/writing-maintainable-unit-tests" target="_blank" rel="noopener noreferrer nofollow">video course</a>, with some significant revisions as well as additional content and 
examples.</p>

<p>The book currently contains the first three chapters. I’m still working on the final two chapters which I expect to be 
finished somewhere in autumn.</p>

<p>
    <a href="https://leanpub.com/writing-maintainable-unit-tests" target="_blank" rel="noopener noreferrer nofollow">
        <img src="https://principal-it.eu/assets/img/writing-maintainable-unit-tests-book.jpg" alt="Book cover of 'Writing Maintainable Unit Tests'" width="300">
    </a>
</p>

<p>The book, as well as the video course, is my attempt to teach software developers how to 
<a href="https://principal-it.eu/2020/03/why-write-maintainable-unit-tests/">write maintainable and readable unit tests</a>.
Have a look at the <a href="https://leanpub.com/writing-maintainable-unit-tests" target="_blank" rel="noopener noreferrer nofollow">table of contents</a> and let me know what you think. All feedback is very much 
appreciated.</p>


				<p>
						<em>
							If you're interested in an in-person or online course that teaches you and your team
							how to <u>write maintainable unit tests</u> and <u>get the most out of TDD practices</u>,
							make sure to have a look at our
							<a href="https://principal-it.eu/training.html">trainings and workshops</a>
							or contact us at <span>info@principal-it.be</span>.
						</em>
					</p>

				

				<div>
					<div>
						<div>
							<p><img src="https://principal-it.eu/assets/img/profile-picture-thumbnail.jpg" alt="Profile picture of Jan Van Ryswyck"></p>
						</div>
					</div>
				</div>

				
			</div></div>]]>
            </description>
            <link>https://principal-it.eu/2020/07/writing-maintainable-unit-tests/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23844534</guid>
            <pubDate>Wed, 15 Jul 2020 13:00:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Facebook faces another privacy issues]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23844183">thread link</a>) | @UtopiaFans
<br/>
July 15, 2020 | https://saidit.net/s/SocialMedia/comments/5fc9/another_privacy_issue_of_facebook_is_there_any/ | <a href="https://web.archive.org/web/*/https://saidit.net/s/SocialMedia/comments/5fc9/another_privacy_issue_of_facebook_is_there_any/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><hr>



<p>Centralized corporate technocracy monopolies mine users data while providing controlled divisive propaganda narratives without context to social engineer speech, thought, subservience, and manufacture consent for endless war and illusory unjust systems, all the while addicting, isolating, and weakening us.  </p>



<hr>

<p>See also:  </p>

<p><a href="https://saidit.net/s/AlternativeMedia">/s/AlternativeMedia</a> aka Independent Media = Anything other than "mainstream" legacy media or centralized social media propaganda tools of the corporatocracy.  </p>

<p><a href="https://saidit.net/s/censorship">/s/censorship</a>  </p>

<p><a href="https://saidit.net/s/CorporateMedia">/s/CorporateMedia</a> = Legacy "mainstream" media of only 6 companies produce propaganda to deceive, divide, manipulate, and socially engineer all of humanity to be easily governed, exploited, and exterminated by psychotic Machiavellian elite for full spectrum dominance under their techno-corporatocracy.  </p>

<p><a href="https://saidit.net/s/MediaAnalysis">/s/MediaAnalysis</a>  </p>

<p><a href="https://saidit.net/s/propaganda">/s/propaganda</a>  </p>

<p><a href="https://saidit.net/s/ZOG">/s/ZOG</a> (Zionist Occupied Government)  </p>



<hr>

<p>Social media:  </p>

<p><a href="https://saidit.net/s/AntiFacebook">/s/AntiFacebook</a><br>
<a href="https://saidit.net/s/CorporateMedia">/s/CorporateMedia</a><br>
<a href="https://saidit.net/s/DecentralizeAllThings">/s/DecentralizeAllThings</a><br>
<a href="https://saidit.net/s/Facebook">/s/Facebook</a><br>
<a href="https://saidit.net/s/InfoGalactic">/s/InfoGalactic</a><br>
<a href="https://saidit.net/s/MeanwhileOnReddit">/s/MeanwhileOnReddit</a><br>
<a href="https://saidit.net/s/MeanwhileOnVoat">/s/MeanwhileOnVoat</a><br>
<a href="https://saidit.net/s/MediaAnalysis">/s/MediaAnalysis</a><br>
<a href="https://saidit.net/s/newSubreddit">/s/newSubreddit</a><br>
<a href="https://saidit.net/s/Reddit">/s/Reddit</a><br>
<a href="https://saidit.net/s/SaidIt">/s/SaidIt</a><br>
<a href="https://saidit.net/s/SaidItBots">/s/SaidItBots</a><br>
<a href="https://saidit.net/s/ShitRedditorsSay">/s/ShitRedditorsSay</a><br>
<a href="https://saidit.net/s/Twitter">/s/Twitter</a><br>
<a href="https://saidit.net/s/youtube">/s/youtube</a>  </p>


</div>
</div></div>]]>
            </description>
            <link>https://saidit.net/s/SocialMedia/comments/5fc9/another_privacy_issue_of_facebook_is_there_any/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23844183</guid>
            <pubDate>Wed, 15 Jul 2020 12:27:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Simple Workflow Service (SWF)]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 11 (<a href="https://news.ycombinator.com/item?id=23844177">thread link</a>) | @adrianancona
<br/>
July 15, 2020 | https://ncona.com/2020/07/introduction-to-aws-simple-workflow-service/ | <a href="https://web.archive.org/web/*/https://ncona.com/2020/07/introduction-to-aws-simple-workflow-service/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>In this post I’m going to explore Simple Workflow Service (SWF) available in AWS.</p>

<p>To understand what SWF is good for, we need to first understand what a workflow is. <a href="https://en.wikipedia.org/wiki/Workflow">Wikipedia defines it</a> as follows:</p>

<blockquote>
  <p>A workflow consists of an orchestrated and repeatable pattern of activity, enabled by the systematic organization of resources into processes that transform materials, provide services, or process information. It can be depicted as a sequence of operations, the work of a person or group, the work of an organization of staff, or one or more simple or complex mechanisms.</p>
</blockquote>

<p>In computer systems we care about the part about processing information. Some things that could be modeled as workflows:</p>

<ul>
  <li><strong>Deployment pipeline</strong>: We could receive some code as input and then build it in a worker machine. We can run tests in parallel in different machines. If all tests pass we can deploy the binaries to another set of machines.</li>
  <li><strong>Coordinate shipments</strong>: A user buys a product on an online store and the order is placed on a system. A human monitors this system and takes care of finding the products in a warehouse and shipping them to the correct address. When the shipment is made, the information is entered in a system. The workflow notices this information an e-mails the user the shipping details.</li>
  <li><strong>Asynchronous image processing</strong>: A system uploads files to a system for processing (let’s say, create thumbnails). A workflow uses multiple workers to execute the task. If any of the machines fails while processing a set of files, they same work can be taken over by another worker.</li>
</ul>

<!--more-->

<p>Those are some high level examples. In this post I’m going to go over one example in more detail.</p>

<h2 id="components">Components</h2>

<p>Before we start building a workflow, let’s learn a little about the components of an SWF:</p>

<ul>
  <li><strong>Workflow</strong>: A set of activities, and some logic that defines how these work together to achieve some objective</li>
  <li><strong>Domain</strong>: A workflow lives in a domain. A Domain can contain multiple workflows. Workflows in different domains can’t interact</li>
  <li><strong>Execution</strong>: An instance of the workflow with its associated state</li>
  <li><strong>Event</strong>: Represents a change on the state of an execution</li>
  <li><strong>Starter</strong>: A program, or person that starts and execution</li>
  <li><strong>Activity</strong>: A type of task that needs to be performed, such as: resizing images, running tests, etc</li>
  <li><strong>Task</strong>: An invocation of an activity</li>
  <li><strong>Worker</strong>: Program that performs tasks</li>
  <li><strong>Decider</strong>: Program that defines the logic for the workflow</li>
</ul>

<h2 id="machine-repair-workflow">Machine repair workflow</h2>

<p>To help us get familiar with SWF, we are going to create a workflow to model the process for fixing a broken machine in a fleet. It will look something like this:</p>

<p><a href="https://ncona.com/images/posts/fixing-broken-machine-workflow.png"><img src="https://ncona.com/images/posts/fixing-broken-machine-workflow.png" alt="Fixing broken machine workflow"></a></p>

<p>This workflow can be used in a datacenter that runs a lot of machines. We can have the workflow probe machines to see if they are working well. If it notices something wrong, it sets the machine state as <code>maintenance</code> in a database. If it doesn’t find anything wrong, it finishes the execution.</p>

<p>Once a machine is drained we’ll do two things. We’ll have a person take a look at the machine and fix it and we’ll take the oportunity to reimage the machine so we have clean machine when it comes back.</p>

<p>Once the repair and the reimage are done, we can set the state back to <code>available</code> and finish the execution.</p>

<h2 id="getting-ready">Getting ready</h2>

<p>For our activities and the decider, we are going to need the AWS SDK. In this section I’m going to show how to get it ready.</p>

<p>We’ll use Ruby for our examples, since it’s easy to run and it’s very well supported. The latest version of the Ruby SDK at the time of this writing is version 3. We’ll create a <code>Gemfile</code> with dependencies:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre><span>source</span> <span>'https://rubygems.org'</span>

<span>gem</span> <span>'aws-sdk-swf'</span><span>,</span> <span>'~&gt; 1'</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>We can then install them using:</p>



<p>The AWS SDK will need to communicate with AWS, so we’ll need some credentials, these credentials can be set in environment variables like this:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre><span>export </span><span>AWS_ACCESS_KEY_ID</span><span>=</span>&lt;your key <span>id</span><span>&gt;</span>
<span>export </span><span>AWS_SECRET_ACCESS_KEY</span><span>=</span>&lt;your secret&gt;
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="activities">Activities</h2>

<p>Each of the boxes in the diagram above is an <code>activity</code>. Activities can be pretty self contained, so we’ll start building those.</p>

<p>An activity works by polling the workflow for pending tasks. If it finds that there is a task it can perform, it does so, and returns a result back. Polling then continues until there is more work to do.</p>

<p>Our activities will share some code with the decider, so let’s create a base class that will be shared between them (<code>workflow_base.rb</code>):</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
</pre></td><td><pre><span>require</span> <span>'aws-sdk-swf'</span>

<span>class</span> <span>WorkflowBase</span>
  <span>DOMAIN_NAME</span> <span>=</span> <span>'datacenter-domain'</span>
  <span>REGION</span> <span>=</span> <span>'ap-southeast-2'</span>
  <span>TASK_LIST_NAME</span> <span>=</span> <span>'repairs-workflow-task-list'</span>
  <span>VERSION</span> <span>=</span> <span>'14'</span>

  <span>def</span> <span>initialize</span>
    <span>@swf</span> <span>=</span> <span>Aws</span><span>::</span><span>SWF</span><span>::</span><span>Client</span><span>.</span><span>new</span><span>(</span><span>region: </span><span>REGION</span><span>)</span>
    <span>register_domain</span><span>(</span><span>REGION</span><span>,</span> <span>DOMAIN_NAME</span><span>)</span>
  <span>end</span>

  <span># Register a domain for our workflow (if it doesn't already exist)</span>
  <span>def</span> <span>register_domain</span><span>(</span><span>region</span><span>,</span> <span>domain_name</span><span>)</span>
    <span>swf</span> <span>=</span> <span>Aws</span><span>::</span><span>SWF</span><span>::</span><span>Client</span><span>.</span><span>new</span><span>(</span><span>region: </span><span>region</span><span>)</span>
    <span>begin</span>
      <span>swf</span><span>.</span><span>register_domain</span><span>({</span>
        <span>name: </span><span>domain_name</span><span>,</span>
        <span>workflow_execution_retention_period_in_days: </span><span>'3'</span>
      <span>})</span>
      <span>puts</span> <span>"Domain </span><span>#{</span><span>domain_name</span><span>}</span><span> registered"</span>
    <span>rescue</span> <span>Aws</span><span>::</span><span>SWF</span><span>::</span><span>Errors</span><span>::</span><span>DomainAlreadyExistsFault</span>
      <span>puts</span> <span>"Domain </span><span>#{</span><span>domain_name</span><span>}</span><span> already exists"</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This class defines some constants that are shared between the decider and activities. It also initializes the SWF client and register the domain if it doesn’t yet exist.</p>

<p>Because of the way SWF works, it is best if the code for all our activities is handled by a single program. This program will poll for any new tasks in the domain. Every time it sees a task it will execute it and send the result back to SWF. Because each task is blocking, we could spin many copies of this program to allow tasks to be executed in parallel if we wanted to.</p>

<p>The activities handler (<code>activities.rb</code>):</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
</pre></td><td><pre><span>require</span> <span>'aws-sdk-swf'</span>
<span>require_relative</span> <span>'workflow_base.rb'</span>

<span>class</span> <span>Activities</span> <span>&lt;</span> <span>WorkflowBase</span>
  <span>ACTIVITIES</span> <span>=</span> <span>[</span>
    <span>'probe_machines'</span><span>,</span>
    <span>'drain_machine'</span><span>,</span>
    <span>'fix_machine'</span><span>,</span>
    <span>'reimage_machine'</span><span>,</span>
    <span>'enable_machine'</span>
  <span>]</span>

  <span>def</span> <span>initialize</span>
    <span>super</span><span>()</span>
    <span>register_activities</span>
    <span>poll</span>
  <span>end</span>

  <span># Register the activities with the domain</span>
  <span>def</span> <span>register_activities</span><span>()</span>
    <span>ACTIVITIES</span><span>.</span><span>each</span> <span>do</span> <span>|</span><span>activity</span><span>|</span>
      <span>begin</span>
        <span>@swf</span><span>.</span><span>register_activity_type</span><span>({</span>
          <span>domain: </span><span>DOMAIN_NAME</span><span>,</span>
          <span>name: </span><span>activity</span><span>,</span>
          <span>version: </span><span>VERSION</span><span>,</span>
          <span># Maximum time it can take to process an activity</span>
          <span>default_task_start_to_close_timeout: </span><span>'60'</span>
        <span>})</span>
        <span>puts</span> <span>"Activity </span><span>#{</span><span>activity</span><span>}</span><span> registered"</span>
      <span>rescue</span> <span>Aws</span><span>::</span><span>SWF</span><span>::</span><span>Errors</span><span>::</span><span>TypeAlreadyExistsFault</span>
        <span>puts</span> <span>"Activity </span><span>#{</span><span>activity</span><span>}</span><span> already exists"</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>

  <span># Poll the domain for tasks for this activity</span>
  <span>def</span> <span>poll</span>
    <span>while</span> <span>true</span>
      <span>options</span> <span>=</span> <span>{</span>
        <span>domain: </span><span>DOMAIN_NAME</span><span>,</span>
        <span>task_list: </span><span>{</span>
          <span>name: </span><span>TASK_LIST_NAME</span>
        <span>}</span>
      <span>}</span>
      <span>task</span> <span>=</span> <span>@swf</span><span>.</span><span>poll_for_activity_task</span><span>(</span><span>options</span><span>)</span>

      <span>if</span> <span>task</span><span>.</span><span>task_token</span> <span>==</span> <span>nil</span>
        <span>puts</span> <span>'Polling expired for activities expired. Trying again'</span>
        <span>next</span>
      <span>end</span>

      <span>if</span> <span>!</span><span>ACTIVITIES</span><span>.</span><span>include?</span><span>(</span><span>task</span><span>.</span><span>activity_id</span><span>)</span>
        <span>raise</span> <span>"Activity </span><span>#{</span><span>task</span><span>.</span><span>activity_id</span><span>}</span><span> unknown"</span>
      <span>end</span>

      <span># If execute is successfull, it will return the result, otherwise ti will</span>
      <span># throw</span>
      <span>puts</span> <span>"Executing </span><span>#{</span><span>task</span><span>.</span><span>activity_id</span><span>}</span><span>"</span>
      <span>begin</span>
        <span># Call the method for the activity</span>
        <span>result</span> <span>=</span> <span>send</span><span>(</span><span>task</span><span>.</span><span>activity_id</span><span>,</span> <span>task</span><span>,</span> <span>task</span><span>.</span><span>input</span><span>)</span>

        <span>puts</span> <span>"Completing </span><span>#{</span><span>task</span><span>.</span><span>activity_id</span><span>}</span><span>"</span>
        <span>@swf</span><span>.</span><span>respond_activity_task_completed</span><span>({</span>
          <span>task_token: </span><span>task</span><span>.</span><span>task_token</span><span>,</span>
          <span># SWF doesn't provide a way to know which activity this result</span>
          <span># belongs to, so we'll prepend the result with it</span>
          <span>result: </span><span>"</span><span>#{</span><span>task</span><span>.</span><span>activity_id</span><span>}</span><span>:</span><span>#{</span><span>result</span><span>}</span><span>"</span>
        <span>})</span>
      <span>rescue</span> <span>=&gt;</span> <span>e</span>
        <span>puts</span> <span>e</span>
        <span>puts</span> <span>"Failing </span><span>#{</span><span>task</span><span>.</span><span>activity_id</span><span>}</span><span>"</span>
        <span>@swf</span><span>.</span><span>respond_activity_task_failed</span><span>({</span>
          <span>task_token: </span><span>task</span><span>.</span><span>task_token</span><span>,</span>
          <span>reason: </span><span>@failure</span>
        <span>})</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>

  <span>def</span> <span>probe_machines</span><span>(</span><span>task</span><span>,</span> <span>input</span><span>)</span>
    <span># Because this is just an example and I don't actually have machines to test,</span>
    <span># I'm going to use some mock data</span>
    <span>machines</span> <span>=</span> <span>[</span>
      <span>'machine-A459Z'</span><span>,</span>
      <span>'machine-M3992'</span><span>,</span>
      <span>'machine-A873R'</span>
    <span>]</span>

    <span>machines</span><span>.</span><span>each</span> <span>do</span> <span>|</span> <span>machine</span> <span>|</span>
      <span># A machine is bad, set it to maintenance</span>
      <span>if</span> <span>check_machine</span><span>(</span><span>machine</span><span>)</span> <span>==</span> <span>'FAIL'</span>
        <span># In a real scenario we would update the database with the new state</span>
        <span>puts</span> <span>"Set machine </span><span>#{</span><span>machine</span><span>}</span><span> to maintenance"</span>
        <span>return</span> <span>machine</span>
      <span>end</span>
    <span>end</span>

    <span>puts</span> <span>'No bad machines found'</span>
    <span>return</span> <span>''</span>
  <span>end</span>

  <span># Randomly decide if it's drained. In a real scenario we would communicate with</span>
  <span># the machine, or check a database</span>
  <span>def</span> <span>drain_machine</span><span>(</span><span>task</span><span>,</span> <span>input</span><span>)</span>
    <span>puts</span> <span>"Draining machine </span><span>#{</span><span>input</span><span>}</span><span>"</span>
    <span>random_number</span> <span>=</span> <span>rand</span><span>(</span><span>5</span><span>)</span>
    <span>if</span> <span>random_number</span> <span>==</span> <span>4</span>
      <span>puts</span> <span>'Machine is drained'</span>
      <span>return</span>
    <span>end</span>

    <span>raise</span> <span>"</span><span>#{</span><span>input</span><span>}</span><span> is not drained"</span>
  <span>end</span>

  <span># In real life we would check if a human has marked the task as fixed. In this</span>
  <span># case, we'll just sleep and use a random number</span>
  <span>def</span> <span>fix_machine</span><span>(</span><span>task</span><span>,</span> <span>input</span><span>)</span>
    <span>puts</span> <span>"Check if machine </span><span>#{</span><span>input</span><span>}</span><span> is fixed"</span>
    <span>sleep</span><span>(</span><span>1</span><span>)</span>
    <span>random_number</span> <span>=</span> <span>rand</span><span>(</span><span>2</span><span>)</span>
    <span>if</span> <span>random_number</span> <span>==</span> <span>1</span>
      <span>puts</span> <span>"Machine </span><span>#{</span><span>input</span><span>}</span><span> has been fixed"</span>
      <span>return</span>
    <span>end</span>

    <span>raise</span> <span>"</span><span>#{</span><span>input</span><span>}</span><span> is not fixed yet"</span>
  <span>end</span>

  <span># In real life we would use something like chef to re-image the machine here</span>
  <span># we'll just sleep and use a random number</span>
  <span>def</span> <span>reimage_machine</span><span>(</span><span>task</span><span>,</span> <span>input</span><span>)</span>
    <span>puts</span> <span>"Reimaging </span><span>#{</span><span>input</span><span>}</span><span>"</span>
    <span>sleep</span><span>(</span><span>1</span><span>)</span>
    <span>random_number</span> <span>=</span> <span>rand</span><span>(</span><span>2</span><span>)</span>
    <span>if</span> <span>random_number</span> <span>==</span> <span>1</span>
 …</pre></td></tr></tbody></table></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ncona.com/2020/07/introduction-to-aws-simple-workflow-service/">https://ncona.com/2020/07/introduction-to-aws-simple-workflow-service/</a></em></p>]]>
            </description>
            <link>https://ncona.com/2020/07/introduction-to-aws-simple-workflow-service/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23844177</guid>
            <pubDate>Wed, 15 Jul 2020 12:26:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mining and Exploring Reddit Data Using Python, Easy]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23843902">thread link</a>) | @klarahorton
<br/>
July 15, 2020 | https://beta.deepnote.com/article/mining-and-exploring-reddit-data-using-python | <a href="https://web.archive.org/web/*/https://beta.deepnote.com/article/mining-and-exploring-reddit-data-using-python">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><div><p>

Reddit <span>is</span> a social network which <span>is</span> mainly organized <span>in</span> communities<span>,</span> also called <span>*</span>subreddit<span>*</span><span>.</span> Each subreddit can be topic<span>-</span>oriented<span>,</span> e<span>.</span>g<span>.</span><span>,</span> <span>[</span><span>/</span>r<span>/</span>gaming<span>]</span><span>(</span>http<span>:</span><span>//</span>reddit<span>.</span>com<span>/</span>r<span>/</span>gaming<span>)</span><span>,</span> <span>or</span> more general<span>,</span> e<span>.</span>g<span>.</span><span>,</span> <span>[</span><span>/</span>r<span>/</span>iama<span>]</span><span>(</span>https<span>:</span><span>//</span>www<span>.</span>reddit<span>.</span>com<span>/</span>r<span>/</span>IAmA<span>/</span><span>)</span><span>,</span> <span>and</span> <span>is</span> populated of submissions posted by users<span>.</span> Each submission can be commented by other users <span>and</span> can be upvoted <span>or</span> downvote<span>,</span> marginally similar to a like <span>or</span> dislike<span>.</span> <span>[</span>At the time of writing<span>]</span><span>(</span>https<span>:</span><span>//</span>www<span>.</span>redditinc<span>.</span>com<span>/</span><span>)</span><span>,</span> Reddit <span>is</span> the <span>5</span><span>-</span>th most visited website <span>in</span> the US <span>and</span> has 430M<span>+</span> average monthly active users<span>.</span>

To explore <span>and</span> mine Reddit<span>,</span> we need a way to access <span>all</span> of its exposed data<span>,</span> such <span>as</span> submissions<span>,</span> comments <span>and</span> users' information<span>.</span> The more brutal <span>and</span> straightforward way obviously <span>is</span> that of scrape the website itself<span>.</span> In particular<span>,</span> scraping Reddit would require a scraper<span>,</span> that <span>is</span> a software which should request one <span>or</span> more webpages<span>,</span> parse them <span>and</span> extract the information of interest<span>.</span> However<span>,</span> this <span>is</span> marginally doable <span>and</span> there are cases <span>in</span> which scraping a website would violate the Term of Service <span>(</span>ToS<span>)</span> of the website itself<span>.</span> Thus<span>,</span> we surely need another way to do it<span>.</span>

Luckily <span>for</span> us<span>,</span> there <span>is</span> a service called <span>[</span>pushshift<span>.</span>io<span>]</span><span>(</span>http<span>:</span><span>//</span>pushshift<span>.</span>io<span>)</span> that provides Reddit data by allowing users to access it via two different forms<span>,</span> that are the direct download of datasets containing Reddit data <span>and</span> the usage of an Application Programming Interface <span>(</span>API<span>)</span><span>.</span> In our case<span>,</span> we resort on the latter by using <span>**</span>psaw<span>**</span><span>,</span> an API wrapper <span>for</span> pushshift<span>.</span>io<span>.</span> To install it<span>,</span> just <span>open</span> up your favourite shell <span>and</span> <span>type</span>

```bash
pip install psaw
```

Having psaw installed<span>,</span> we are now able to query pushshift<span>.</span>io’s API by using the library itself<span>.</span>

To use the library<span>,</span> we need an instance of `PushshiftAPI`<span>.</span> It will be the <span>*</span>entry point<span>*</span> <span>for</span> <span>any</span> request<span>.</span> We can find `PushshiftAPI` within psaw<span>,</span> thus we can <span>import</span> it <span>and</span> define an instance<span>:</span></p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://beta.deepnote.com/article/mining-and-exploring-reddit-data-using-python</link>
            <guid isPermaLink="false">hacker-news-small-sites-23843902</guid>
            <pubDate>Wed, 15 Jul 2020 11:53:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Steve Jobs Interview – Moving to Ireland (1980)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23843862">thread link</a>) | @Irishsteve
<br/>
July 15, 2020 | https://www.rte.ie/archives/2014/0124/499863-30-years-since-the-1st-apple-mac-went-on-sale/ | <a href="https://web.archive.org/web/*/https://www.rte.ie/archives/2014/0124/499863-30-years-since-the-1st-apple-mac-went-on-sale/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Apple founder Steve Jobs talks to reporter Pat Kenny at the company's Cork plant in 1980.</p>
<p>On 24 January 1984 the first Apple Macintosh computer went on sale.&nbsp;The Apple prided itself on its user-friendly interface, came in a nine inch black and white monitor, accommodated one 3.5 inch floppy disc, and ran the Mac OS 1.0.</p>
<p>Apple has long been synonymous with Ireland and set up a manufacturing plant in Hollyhill Industrial Estate overlooking Cork city. On 25 November 1980 the programme 'Public Account' broadcast a report by Pat Kenny from the Apple plant in Cork, when Pat met up with self-made millionaire and Apple founder Steve Jobs.</p>
<p><img alt="Steve Jobs (1980)" src="https://img.rasset.ie/00086923-622.jpg"><br>
<small>Steve Jobs chats to Pat Kenny at the newly opened Apple plant in Cork (1980)</small></p>
<p>Pat Kenny speaks to Steve Jobs about the origins of Apple and how they came to set up their manufacturing plant in Cork. Steve comments</p>
<blockquote>
<p>We started off building a computer because we couldn't afford to buy one.</p>
</blockquote>
<p>Then all their friends wanted one which gave them the initial market indication that there was a demand for computers. Steve differentiates Apple computers as more "sophisticated" than other computers. Steve predicts that computers will be used extensively in the home, in education and in business. When questioned about the usability of the Apple, Steve comments that the computer weighs about 12lbs, so</p>
<blockquote>
<p>if you don't like what it's doing, you can throw it out the window.</p>
</blockquote>
<p>When the Apple plant opened it was somewhat unconventional in its treatment of its workers. Apple operated a "no clock-in" policy opting instead to trust their employees.</p>
<p>This episode of the programme 'Public Account' was broadcast on 26 November, 1980.</p>

</div></div>]]>
            </description>
            <link>https://www.rte.ie/archives/2014/0124/499863-30-years-since-the-1st-apple-mac-went-on-sale/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23843862</guid>
            <pubDate>Wed, 15 Jul 2020 11:48:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Speeding up similarity search in recommender systems using FAISS]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23843752">thread link</a>) | @drishya
<br/>
July 15, 2020 | https://caboom.ai/blog/speeding-up-similarity-search-in-recommender-systems-using-faiss-basics-part-i | <a href="https://web.archive.org/web/*/https://caboom.ai/blog/speeding-up-similarity-search-in-recommender-systems-using-faiss-basics-part-i">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Measuring the similarity between vectors or arrays is a calculation that we encounter often while developing recommendation systems or other machine learning models. This often involves performing similarity searches on entire datasets that can be computationally expensive. For systems that require such calculations to happen online in real-time, this can be a major issue and is something we often have to deal with at Caboom.</p><p><br>Luckily, we are not the only ones faced with this problem and there are open-source libraries like <a href="https://github.com/facebookresearch/faiss">FAISS</a> that have been developed to solve this exact problem by the Facebook AI Research team.</p><p>‍</p><p>FAISS or <strong>F</strong>acebook <strong>AI</strong> <strong>S</strong>imilarity <strong>S</strong>earch is a library written in the C++ language with GPU support. It also has Python bindings so that it can be used with Numpy, Pandas, and other Python-based libraries. Its algorithmic enhancements that vastly narrow down the search space for a vector's k-nearest neighbors allow it to have much faster similarity search between vectors as compared to existing libraries like Scikit Learn. This technique is called Approximate Nearest Neighbours (ANN) search, and sacrifices some precision to obtain the vast speedups.&nbsp;</p><p>Compared to other ANN libraries FAISS implements various vector compression, partitioning, and indexing techniques, especially by making use of the parallelism enabled by GPUs to make similarity search lookups more efficient. We will mostly be focusing on its indexing features and how that leads to fast similarity search in recommender systems. There are several other methods and optimizations in FAISS which can’t be covered by this blog alone. For a detailed overview of how its internal mechanism works, different&nbsp; and the previous work it builds upon please refer <a href="https://github.com/facebookresearch/faiss/wiki">here</a>.</p><p>To show the speed gains obtained from using FAISS, we did a comparison of bulk cosine similarity calculation between the FlatL2 and IVFFlat indexes in FAISS and the brute-force similarity search used by one of the most popular Python machine learning frameworks Scikit-learn.&nbsp;</p><p>A dataset of 20k movies was used for this comparison, with the similarity search performed on vectors obtained from the various genres of the movie.The task was to select the top 10 most similar movies for each of the 20k movies from a candidate pool ranging from 0 to 1000 movies. </p><p>‍</p><figure id="w-node-0ec5b7e06d99-2fefdd35"><p><img src="https://uploads-ssl.webflow.com/5ef484d478bae23cf2704aef/5f0c174333f77039795e2d8a_Screen%20Shot%202020-07-13%20at%2013.56.15.png" alt="Speed comparison between two FAISS indexes"></p></figure><figure id="w-node-cf497c7d8071-2fefdd35"><p><img src="https://uploads-ssl.webflow.com/5ef484d478bae23cf2704aef/5f0c17886b4272e3e7bd2790_Screen%20Shot%202020-07-13%20at%2013.56.35.png" alt=""></p></figure><p>As seen from the plots above, the time taken to perform the similarity search increases linearly for Scikit-learn to a few seconds, while that for the Flat index based search is an order of magnitude faster.&nbsp;</p><h2>Basic Indexes</h2><p>As stated above the main strength of FAISS is the speed with which it can perform similarity searches on billions of vectors at the cost of some precision. This is possible because of the implementation of indexes in FAISS that the whole package is optimized for. These indexes store a set of vectors and provide search functions in these sets with various vector comparison algorithms. One good way of understanding them is to think of them like the indexes used in databases to make queries faster.&nbsp;</p><p>We will now go through an example implementation of creating a FAISS index.&nbsp;</p><h3>Flat Index</h3><p>The simplest implementation of the index in FAISS is the <strong>IndexFlatL2 index</strong>. It is an exact search index that encodes the vectors into fixed-size codes. As the name suggests it is an index that compares the L2 (euclidean) distance between vectors and returns the top-k similar vectors. During the search, all the indexed vectors are decoded sequentially, and compared to the vector whose nearest neighbors we are being calculated. This vector is also called the <strong>query vector</strong>.&nbsp;</p><p>This is different from how similarity search is done in libraries like Scikit-learn, as we have to choose the kind of similarity we are measuring and select the index accordingly. FAISS also optimizes how the index vectors are stored in memory or disk by using a tree data structure that hugely improves the search time.</p><p>The following code shows the process of defining the index vector size, initiating the IndexFlatL2 index, adding vectors to the index and saving the index into disk.</p><p>‍</p><figure><p><img src="https://uploads-ssl.webflow.com/5ef484d478bae23cf2704aef/5f0d8a67e212a15625c1ca46_Image1.png" alt=""></p></figure><p>‍</p><p>We can reuse the saved index later for searching a vector's nearest neighbors. The following code snippet shows how to load the index and perform nearest neighbor search on it.</p><p>‍</p><figure><p><img src="https://uploads-ssl.webflow.com/5ef484d478bae23cf2704aef/5f0d8a7a898b077ff2c73e44_image%202.png" alt=""></p></figure><p>‍</p><p>Output:<br>‍</p><figure><p><img src="https://uploads-ssl.webflow.com/5ef484d478bae23cf2704aef/5f0d8a87898b072b2ac73e45_image%203.png" alt=""></p></figure><p>‍</p><p>‍</p><p>The output shows the resulting indexes and distances for the first five vectors of an index. In the second “distances” matrix we can see that the vectors have their nearest neighbors at the beginning of the array row, with a distance of 0 with itself and increasing in value as we move towards the end.&nbsp;</p><p>Another thing to remember is that in this case the index of the arrays is set automatically by FAISS in increasing order like the "auto_increment" column in SQL databases. It is advisable to use either a mapper with FAISS to real indexes or use a FAISS provided index setting which will come up further along.</p><h3>Cosine Similarity Measurement</h3><p>Although calculating Euclidean distance for vector similarity search is quite common, in many cases <strong>cosine similarity</strong> is preferred. In FAISS we don't have a cosine similarity method but we do have indexes that calculate the inner or dot product between vectors. For example, the <strong>IndexFlatIP</strong> <strong>index</strong>. We can then take advantage of the fact that cosine similarity is simply the dot product between normalized vectors.&nbsp;</p><p>The code snippet below shows how this can be implemented. Partition-based Index</p><figure><p><img src="https://uploads-ssl.webflow.com/5ef484d478bae23cf2704aef/5f0d8aa4dd31940e941cddbd_image%204.png" alt=""></p></figure><p>Another class of indexes in FAISS are partition-based indexes that speed up searches by partitioning the index into clusters and limiting the search to only a few clusters. This method however is not exact as there is no guarantee that the nearest neighbors will be in the clusters searched in.&nbsp;&nbsp;</p><p><br>An example of an index that uses partitioning techniques to make the search space a lot less and far more efficient is <strong>IndexIVFFlat index</strong>.</p><p>‍</p><figure><p><img src="https://uploads-ssl.webflow.com/5ef484d478bae23cf2704aef/5f0d8aaf04e10128d6d54b3c_image%205.png" alt=""></p></figure><p>‍</p><p>The search operation can be carried out in the same way as earlier indexes. However, in the IVFFlat index we define the “nprobe” hyperparameter to limit the search to only the defined number of clusters nearest to the query vector. This is also an example of how different indexes can be compounded to form a single index.</p><h3>Principal Component Analysis (PCA)</h3><p>We’ve looked at the use cases for some of the basic algorithms in FAISS. This section looks at a method called PCA. It is an algorithm that is popular in unsupervised machine learning that is used to reduce the vector dimensions using <strong>Principal Components</strong> of the vector space.</p><p>In FAISS, PCA is generally followed by indexes like IndexFlatL2 or IndexIVFFlat and they are linked with the help of the <strong>IndexPreTransform</strong> function.&nbsp;One requirement of this method is that the dimension of a vector needs to be a multiple of 4.</p><p>‍</p><figure><p><img src="https://uploads-ssl.webflow.com/5ef484d478bae23cf2704aef/5f0d8ab9ec95620e8410fb11_image%206.png" alt=""></p></figure><h3>Dimension Remapping</h3><p>PCA allows us to reduce the dimensions but what if we want to increase the dimensionality of the vectors? We may encounter this scenario if we want to use an IndexIVFFlat index for instance. In this case, the dimensionality should ideally be a multiple of 4. FAISS allows us to do this through the <strong>RemapDimensionTransform </strong>method.As an example, let us suppose we have a vector of size 150 that we need to use with an IndexIVFFlat index. The way we transform this to a size that is a multiple of 4 (152) is given below.</p><figure><p><img src="https://uploads-ssl.webflow.com/5ef484d478bae23cf2704aef/5f0d8ac81fd412abe2e2dab8_image%207.png" alt=""></p></figure><p>‍</p><div><p>What next?This brings us to the end of Part 1 of this discussion on using the FAISS library from Facebook. Here we looked at the speedup it provides when compared to the similar methods used in Scikit-learn, and how FAISS optimizes this through various indexes. In Part 2 we will go beyond the basic indexing methods and look at more advanced versions. We will also look at the GPU support in FAISS, and how to make the calculations even faster by leveraging them.</p><p>‍</p></div></div></div>]]>
            </description>
            <link>https://caboom.ai/blog/speeding-up-similarity-search-in-recommender-systems-using-faiss-basics-part-i</link>
            <guid isPermaLink="false">hacker-news-small-sites-23843752</guid>
            <pubDate>Wed, 15 Jul 2020 11:32:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hungary's Leading Outlet Became the Target of Political Control]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23843605">thread link</a>) | @pabo
<br/>
July 15, 2020 | https://insighthungary.444.hu/2020/07/14/index-and-independence-how-hungarys-leading-outlet-became-the-target-of-political-control | <a href="https://web.archive.org/web/*/https://insighthungary.444.hu/2020/07/14/index-and-independence-how-hungarys-leading-outlet-became-the-target-of-political-control">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-main">
<article>
<ul><li>Stay updated on the latest news from Hungary by signing up for the free InsightHungary newsletter:</li></ul><p>Vice President of the European Commission for Values and Transparency Věra Jourová sent a <a href="https://index.hu/kultur/media/2020/07/07/aggodik_az_index_fuggetlensegeert_az_europai_bizottsag_alelnoke/">letter</a> on July 7 to Index.hu, Hungary’s largest online news portal, expressing her solidarity with its staff which she said “has been working under very difficult conditions”.<br></p><p>Jourová wrote that while media revenues have been heavily hit by the coronavirus pandemic, “economic pressure should not turn into political pressure...I have been following the situation of Index with concern. What you are doing, the values you are fighting for, media freedom and pluralism, are essential for democracy.”</p><p>The letter came amid what Index considered a fight for its existence. In late June, an urgent <a href="https://index.hu/english/2020/06/21/independence_of_index_in_danger_hungary_press_freedom_media/">public statement</a> signed by around 100 editors and journalists raised the alarm that the site's independence had come under attack, and that the outlet was in "grave danger".&nbsp;</p><p>To many observers of Hungary's media environment, the news came as little surprise. It was widely considered only a matter of time before the outlet faced attacks on its editorial independence, an expectation engendered by years of other Hungarian websites, newspapers, television networks and radio stations being shuttered or suddenly transformed under political and financial pressure.</p><p>This year, media watchdog Reporters Without Borders, which has described the level of media control in Hungary as "unprecedented" in the European Union, <a href="https://rsf.org/en/hungary">ranked </a>the country 89th in the world for media freedom, down 33 places from when the organization began its rankings in 2013. Additionally, the U.S.-based non governmental organization <a href="https://freedomhouse.org/country/hungary/freedom-world/2020">Freedom House</a> gave Hungary a score of two out of four for media freedom and plurality this year.</p><p>Despite this media environment and a perpetual struggle to preserve its independence, Index has, somewhat paradoxically, managed to remain the <a href="https://reutersinstitute.politics.ox.ac.uk/sites/default/files/2020-06/DNR_2020_FINAL.pdf">most-read and one of the most trusted news sources in Hungary</a>&nbsp;for the past 20 years. It has maintained its critical reporting even as government-tied businesspeople were embedded in its ownership structure, and has walked a tightrope between its journalistic principles and a deep uncertainty over when, and how, they might be curtailed.</p><p>This constant vulnerability, and the ways Index’s newsroom has successfully struggled to retain its independence while so many other Hungarian outlets could not, are illustrative of the broader mechanisms that have undermined media plurality and freedom in Hungary for the past decade.</p><h2>“Index Is In Danger”</h2><p>Two years ago, staff at the outlet established an <a href="https://szabadindex.eu/">online independence barometer</a>, a means of directly addressing readers on the status of Index's editorial independence. The barometer was set up after a government-tied figure purchased a stake in the company that controls Index’s revenue stream, and was emblematic of the perceived inevitability of an attack on the site. At the time, a <a href="https://index.hu/english/2018/09/18/index_independence_press_freedom/">letter to readers</a> said that staff felt they were “stuck on the frontline of a world war. Sometimes it’s the Red Army, sometimes it’s the Wehrmacht that marches over us.”<br></p><p>For the two years since its inception, the barometer read “Independent”. But on June 21, for the first time, staff moved the dial to "In Danger".</p><figure><a rel="nofollow" href="https://4cdn.hu/kraken/image/upload/s--axVjxGbd--/7T9PtAkyhooMBj7ps.jpeg"></a><figcaption><svg xmlns="http://www.w3.org/2000/svg" version="1.1" preserveAspectRatio="xMidYMid">
<use xlink:href="/assets/blog/static/icon-defs.svg#icon-photocamera"></use>
</svg><span>Index's "independence barometer"</span><span>Fotó: index.hu</span></figcaption></figure><p>The change came after a series of board meetings of Index’s parent foundation, where a recommendation was made by an outside advisor to break up the site and outsource its content creation to external, newly-formed companies.<br></p><p>The proposal, ostensibly a response to economic pressure caused by the coronavirus pandemic, alarmed several members of the board of directors, including editor-in-chief Szabolcs Dull and CEO András Pusztay. In a <a href="https://index.hu/english/2020/06/21/independence_of_index_in_danger_hungary_press_freedom_media/">statement</a>, Dull wrote that Index was “under such external pressure that could spell out the end of our editorial staff as we know it. We are concerned that with the proposed organisational overhaul, we will lose those values that made Index.hu the biggest and most-read news site in Hungary.”<br></p><p>When news of the proposal leaked in the media, Dull was suspended from the board of directors. A few days later, Pusztay resigned as CEO, saying he could not in good conscience carry out the orders which had been placed on him. Since then, the newly-appointed CEO <a href="https://index.hu/kultur/media/2020/06/30/lemondott_az_index_vezerigazgatoja_zodi_zsolt/">resigned</a> after less than a week on the job, and another <a href="https://index.hu/english/2020/07/07/index_indamedia_hungary_press_freedom_editor_in_chief_advisor/">external advisor</a> has <a href="https://444.hu/2020/07/07/az-indamedia-tanacsadoja-az-index-foszerkesztojenek-levaltasat-surgeti">recommended Dull’s removal</a> as editor-in-chief.</p><p>These disruptive events and proposals by government-tied advisors alarmed Dull, Pusztay and many staff members on their own merits, but the circumstances’ similarities to earlier takeovers of critical media outlets likely added fuel to their suspicions. The events at Index, and some of the actors involved, fit a pattern going back years that illustrates a cohesive strategy for building a media environment that can be managed from the highest levels of political power.</p><h2>The Usual Suspects</h2><p>In March, an influential figure in pro-government media enterprises purchased a 50 percent stake in Indamedia, the company which controls all of Index's revenue streams and has exclusive rights to manage its advertising. The arrival of Miklós Vaszily in Index’s innermost circumference caused new concerns that government-tied figures were closing in on the outlet, evoking alarming memories of an earlier event involving Vaszily that sent shockwaves through the Hungarian media market.</p><p>In 2014, Vaszily oversaw the <a href="https://444.hu/2014/06/05/deutsche-telekom-hungarian-government-collude-to-silence-independent-media">dramatic takeover</a> of Hungary’s then-largest online news outlet Origo, where he served as CEO. Origo’s reporting on cases of corruption within the government, especially concerning two high-level ministers from the governing Fidesz party, reportedly angered party officials and led to political pressure being placed on the outlet’s parent company.&nbsp;</p><p>Vaszily is widely thought to have acted on the government’s behalf to facilitate changes at Origo that resulted in the <a href="https://444.hu/2014/06/02/varatlanul-kirugtak-az-origo-foszerkesztojet/">dismissal of the site’s editor-in-chief</a> and the <a href="https://444.hu/2014/06/04/petho-andras-a-lazar-utazasairol-szolo-cikk-szerzoje-felmond-az-origonal/">resignation</a> of more than 30 journalists over what they considered a pro-government shift in editorial direction. Once a producer of quality investigative journalism and reportage, Origo is now considered by many to be a government mouthpiece.</p><figure><a rel="nofollow" href="https://4cdn.hu/kraken/image/upload/s--RGLOgiES--/6rMVTtlrB1zC1F5pJs.jpeg"></a><figcaption><svg xmlns="http://www.w3.org/2000/svg" version="1.1" preserveAspectRatio="xMidYMid">
<use xlink:href="/assets/blog/static/icon-defs.svg#icon-photocamera"></use>
</svg><span>Miklós Vaszily (center), the joint owner of Indamedia.</span><span>Fotó: Koszticsák Szilárd</span></figcaption></figure><p>Following the takeover of Origo, Vaszily quickly rose through the ranks of government-tied media. He was appointed CEO of Hungary's public broadcasting organization MTVA (itself deeply loyal to the Fidesz-led government), and later became the CEO of Echo TV and the chairman of TV2, both owned by Lőrinc Mészáros, an oligarch and personal childhood friend of Prime Minister Viktor Orbán. According to <a href="https://tldr.444.hu/2020/07/02/csendben-fojtana-meg-az-indexet-a-kormany-de-a-szerkesztoseg-nem-hagyja-magat">reporting by 444’s Pál Dániel Rényi</a>, Vaszily is known to have connections with the highest levels of government, and meets personally with Mr. Orbán to discuss important issues.<br></p><p>His important role in the government-tied media landscape and involvement in the Origo affair made Vaszily’s entrance in the ownership structure of Index seem to portend a future for the outlet which could echo Origo’s fate.&nbsp;</p><p>Origo’s 180-degree turn serves as a template for how government loyalists have repurposed critical media in the service of political interests. Often, rather than hostile legislation or direct intervention being used to transform an outlet, changes in ownership and financial pressure have been applied to indirectly shift outlets’ editorial direction, insulating the government from direct involvement. Financial "reforms" are thus used to justify takeovers under the banner of simple commercial efficiency.&nbsp;</p><p>These same arguments are now being used to account for changes at Index: Vaszily has <a href="https://tldr.444.hu/2020/07/02/csendben-fojtana-meg-az-indexet-a-kormany-de-a-szerkesztoseg-nem-hagyja-magat">denied</a> he intends to muzzle the outlet, but insists economic problems must be addressed – despite the site’s position as the leader on the Hungarian media market.&nbsp;</p><p>Undermining media independence using financial “reforms” is a model that has been frequently used since 2010, although more aggressive methods including outright closure have also been employed. In 2016, Hungary's most-read daily newspaper Népszabadság was <a href="https://www.nytimes.com/2016/10/12/world/europe/hungary-newspaper-nepszabadsag.html">suddenly shut down</a> following the acquisition of the paper’s publisher by an Austrian businessman with ties to Fidesz. Staff arrived one morning to find they had been locked out of the building, and could access neither their company email accounts nor the paper’s website. The closure, which staff described as a “coup”, made international headlines and resulted in a wave of <a href="https://www.theguardian.com/world/2016/oct/09/protests-in-hungary-at-closure-of-main-leftwing-opposition-newspaper">street protests</a> for media freedom, but the paper’s publisher insisted the decision was purely economic, and that the paper had been struggling financially.</p><figure><a rel="nofollow" href="https://4cdn.hu/kraken/image/upload/s--MT582P6T--/6vATDH0v0K1lghSTs.jpeg"></a><figcaption><svg xmlns="http://www.w3.org/2000/svg" version="1.1" preserveAspectRatio="xMidYMid">
<use xlink:href="/assets/blog/static/icon-defs.svg#icon-photocamera"></use>
</svg><span>A protester holds a copy of Népszabadság at a protest against the paper's closure.</span><span>Fotó: Zoltan Tuba.www.tubazoltan.com</span></figcaption></figure><p>Another means for seizing control of the media has been the generous use of <a href="https://www.tandfonline.com/doi/full/10.1080/21599165.2019.1662398?fbclid=IwAR0dDqMkZUlLipK1vS_QqWTEN1qm99Iupb4qde-vj1IW4BVx8kW9vv1LLDE&amp;">government advertising</a> in friendly publications and the withholding of ads in critical ones, heavily distorting the media market and putting financial pressure on independent outlets. Nearly 90 percent of ad revenues in the Fidesz-tied newspaper Magyar Idők came from <a href="https://www.tandfonline.com/doi/full/10.1080/21599165.2019.1662398#F0002">ads paid for by the government</a> in 2017, compared with 3 percent in the conservative Magyar Nemzet (which was government-critical at the time but has since been recaptured). According to editor-in-chief Dull, Index receives practically none of its ad revenue from the government.<br></p><p>Such methods for media control, which have now become commonplace, first began with Fidesz’s entrance to power in 2010, and represented a dramatic interruption of some 20 years of relative balance and development in Hungary’s media market following the collapse of socialism in 1990.</p><h2>Paradise Lost</h2><p>At the time of Index’s founding in the late 1990s, Hungary was entering a period of hopeful optimism following a decade of uncertainty and economic decay that came after what Hungarians call “the system change”, the country’s democratic transition after 1989. The internet was just taking off in the country, and for many, Index was symbolic …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://insighthungary.444.hu/2020/07/14/index-and-independence-how-hungarys-leading-outlet-became-the-target-of-political-control">https://insighthungary.444.hu/2020/07/14/index-and-independence-how-hungarys-leading-outlet-became-the-target-of-political-control</a></em></p>]]>
            </description>
            <link>https://insighthungary.444.hu/2020/07/14/index-and-independence-how-hungarys-leading-outlet-became-the-target-of-political-control</link>
            <guid isPermaLink="false">hacker-news-small-sites-23843605</guid>
            <pubDate>Wed, 15 Jul 2020 11:08:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Online Screen Recorder]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23843467">thread link</a>) | @sabbakeynejad
<br/>
July 15, 2020 | https://www.veed.io/screen-recorder | <a href="https://web.archive.org/web/*/https://www.veed.io/screen-recorder">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.veed.io/screen-recorder</link>
            <guid isPermaLink="false">hacker-news-small-sites-23843467</guid>
            <pubDate>Wed, 15 Jul 2020 10:49:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rewriting Fortran Software in Rust]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23843434">thread link</a>) | @fanf2
<br/>
July 15, 2020 | https://mckeogh.tech/post/shallow-water/ | <a href="https://web.archive.org/web/*/https://mckeogh.tech/post/shallow-water/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section></section><section><section id="articleHero"><div><header><div><div><p>
July 14, 2020
• 9 min read</p></div></div></header><p><img src="https://mckeogh.tech/images/shallow-water.png"></p></div></section><article id="articleContent"><h3 id="githubcomrse-standrewscsshallow-waterhttpsgithubcomrse-standrewscsshallow-water"><a href="https://github.com/rse-standrewscs/shallow-water">github.com/rse-standrewscs/shallow-water</a></h3><p>TL;DR: Rewriting isn’t <em>always</em> bad, <a href="https://en.wikipedia.org/wiki/Amdahl%27s_law">Amdahl’s Law</a> is important and memory bandwidth is a potential bottleneck when doing many simple double precision math operations</p><h2 id="introduction">Introduction</h2><p>As part of an Undergraduate Research Assistant Scheme in my first year of university I was tasked with parallelising a piece of shallow water simulation software written in FORTRAN by Dr David Dritschel of the Vortex Dynamics Research Group, under supervision of Dr. Alexander Konovalov, at the University of St Andrews. There were secondary goals such as improving the testing infrastructure, setting up CI/CD, estimating progress and allowing the computation to be paused and resumed.</p><p>Forewarning: I have essentially zero domain knowledge in this project (and fluid dynamics simulation isn’t exactly the kind of topic you can catch up to research level on over a weekend) so I approached this project from a purely software engineering perspective. As for my Rust experience, I’ve been using it for personal projects since ~2016 and I worked as a Rust software engineer at a startup in Berlin for a year after leaving high school.</p><h2 id="dont-rewrite">Don’t Rewrite</h2><p><a href="https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/">Don’t.</a></p><p><a href="https://understandlegacycode.com/blog/avoid-rewriting-a-legacy-system-from-scratch-by-strangling-it/">Rewrite.</a></p><p><a href="https://medium.com/better-programming/how-i-failed-to-deal-with-legacy-code-8e123cff5bce">Legacy.</a></p><p><a href="https://daedtech.com/the-myth-of-the-software-rewrite/">Code.</a></p><p>Not too hard a concept to grasp, is it? Not much ambiguity and a clear line of reasoning to follow as to why legacy software should not be rewritten. Well I read the articles written by people far more experienced and knowledgable than myself and thought:</p><p><img src="https://mckeogh.tech/post/shallow-water/0e1.png" alt="https://knowyourmeme.com/memes/that-sign-cant-stop-me-because-i-cant-read"></p><h2 id="why-my-situation-is-different">Why <em>My</em> Situation is Different</h2><p>All jokes aside, there are situations where a re-implementation is a reasonable option and I did have several factors to back me up.</p><p>FORTRAN is undoubtably <em>very</em> fast and highly suited to HPC problems with decades-optimised compilers and debugging tooling but it does lack certain features, namely memory safety, thread safety, data race guarantees and ergonomic GPU/CLI/TUI libraries.</p><p>Having written parallel software in both C and Rust, the memory safety guarantees and easy parallelisation with Rayon offered by Rust contrasts quite sharply with my poor experience using OpenMP. Replacing <code>.iter()</code> with <code>.par_iter()</code> and having the compiler automatically throw errors for any code that isn’t thread safe is amazing compared with adding OpenMP directive sentinels (designed to be hidden from a non OpenMP-compliant FORTRAN compiler) and manually determining thread and memory safety. Here seems a good a place as any to mention that <a href="https://msrc-blog.microsoft.com/2019/07/16/a-proactive-approach-to-more-secure-code/">“~70% of the vulnerabilities Microsoft assigns a CVE each year continue to be memory safety issues”</a>.</p><p>It was believed initially that GPUs could be used to accelerate the computation, ~another place where Rust’s (while not mature) ecosystem also shines above those offered for FORTRAN~ EDIT: completely untrue, FORTRAN’s GPU acceleratin libraries are very mature and production ready. Additionally when it came to the additional requirements building a <code>ncurses</code> interface in FORTRAN isn’t exactly ergonomic compared with the libraries available in Rust. I spent some time reading through the original implementation and attempted some basic parallelisation with little success due to small errors being hard to diagnose across long executions without snapshot testing across multiple modules.</p><p>Not only was there several “pull” factors, but there was also the absence of the typical reasons you shouldn’t rewrite: I was working as a one-person team, the software was finalised and so never needed to be modified again, it was relatively small so could be rewritten in a matter of months (part time) and is not a live business component so uptime and upkeep of the original implementation are irrelevant.</p><p>Given all of this I decided it would be faster to rewrite in Rust, then be able parallelise it and add features quickly than it would be to plough through with the FORTRAN, and with a go-ahead from my supervisor I got to work.</p><h2 id="translating-fortran-to-rust">Translating FORTRAN to Rust</h2><p><em>Relatively</em> straightforward translation of existing codebases in compiled languages to Rust is a noted benefit due to the combination of software like <a href="https://c2rust.com/">C2Rust</a> to perform automatic translation of C source into Rust, <a href="https://github.com/rust-lang/rust-bindgen">bindgen</a> for automatically generating FFI bindings and of Cargo’s ability to compile code in other languages as part of a Rust project. While there are plenty examples of large projects successfully migrating to Rust this way, the issue I faced was that it would have required a two-step process, first translating from FORTRAN to C and then from C to Rust. I assumed the likelihood that the resulting code would be remotely parsable was very low and I couldn’t even get either of the most popular FORTRAN to C conversion tools to work.</p><p>Since the original implementation was only 6,000 lines total I decided to go with a manual translation. This involved starting at the base of the module tree with the Fast Fourier Transform routines and working upwards. I kept my process simple by inserting small pieces of FORTRAN to dump state at the beginning and end of routines which was then used for snapshot tests for the Rust implementation. This resulted in a thorough, robust testing suite which was invaluble during the optimization period. I really only made one bad design decision (please don’t read through the git history to confirm this 😅) during the translation phase which was thinking that nested <code>Vec</code>s would be easier than using <code>ndarray</code> from the start. This was a Bad Decision™️ and wasted so much time, not only in the abysmal execution speeds slowing down <code>cargo test</code>, but also in that it significantly increased development time. I would replace a statement such as</p><p>with</p><div><pre><code data-lang="rust"><span>// Awful, awful Rust
</span><span></span><span>for</span> i <span>in</span> <span>0</span>..x {
	<span>for</span> j <span>in</span> <span>0</span>..y {
		a[i][j] <span>=</span> a[i][j] <span>*</span> b[i][j]
	}
}
</code></pre></div><p>when the final <code>ndarray</code> version would look like</p><div><pre><code data-lang="rust"><span>// Ergonomic Rust
</span><span></span>a <span>*=</span> <span>&amp;</span>b;
</code></pre></div><p>Clearly the intermediary step could have been skipped and a more direct translation was possible. I wrote a regex to replace FORTRAN array indexing syntax (<code>array(x,y,z)</code>) to nested <code>Vec</code>s in Rust (<code>array[x][y][z]</code>), when <code>ndarray</code> syntax (<code>array[[x,y,z]]</code>) would have been a far simpler conversion. If this decision wasn’t bad enough, I also wasted time writing several functions to convert between a byte slice and the nested <code>Vec</code>s with the FORTRAN memory layout when <code>ndarray</code> has a built-in preset for FORTRAN shape and strides.</p><p>One issue that arose during testing was that due to the accumulation of small errors in floating point math, results would be slightly different between operating systems and hardware configurations which made the fantastic snapshot testing tool <code>insta</code> unsuitable. Instead <code>ndarray</code>’s <code>serde</code> and <code>approx</code> feature flags are used to read serialised arrays from disk to compare approximately during tests which has been working well.</p><h2 id="optimizing">Optimizing</h2><h3 id="parallelisation">Parallelisation</h3><p>Fundamentally the problem is not one that may be described as “embarrassingly parallel”, which was the assumption made going into the project (early discussions involved expectations of a 100x improvement on the university cluster). Ideally we would be want many large chunks of independent computation operating on a small amount of data, making it easy to distribute work across threads, GPUs and potentially different machines, but unfortunately I learned this problem is quite far from that ideal.</p><p>The outermost loop advances through time and is therefore strictly sequential, and in the primary function of the program (<code>src/nhswps/advance.rs:advance</code>) a large portion is iterated over twice, also strictly sequential. Some other lower-level functions perform operations on individual layers and so can be parallelised completely, but these are not generally very complex functions and so finish quickly before returning to sequential execution. <a href="https://en.wikipedia.org/wiki/Amdahl%27s_law">Amdahl’s Law</a> comes into affect here, describing how even if everything that can be parallelised is, there are fundamental limits to the scaling we can ever achieve.</p><h3 id="memory-bandwidth-issues">Memory Bandwidth Issues</h3><p>Throughout the program there are several kinds of operations being performed on the 2- and 3-dimensional arrays. Transformations between physical and spectral is common, involving calling the Fourier transform functions and swapping axes. Other than those, many operations are simple additions, subtractions and multiplications between arrays, sometimes including constants. The result of this is that these simple operations are being performed on some very large amounts of data which I believe is resulting in a memory bandwidth bottleneck. This hypothesis explains why SIMD did not improve performance and performance is not significantly improved by parallelisation. It only takes several cycles to perform a floating point ADD or MUL instruction, so even at tens of gigabytes per second of memory bandwidth it will be insufficient to keep the CPU “fed”. Performing the operations with AVX-2 instructions does not improve performance because even though the same operation may now be performed on several floats simultaneously the limit is still how quickly they may be read from memory. It is slightly more complicated in the multithreaded context because there is an improvement in performance; perhaps due to multiple threads being able to increase the amount of data read from memory. The program is also very cache-unfriendly, reading large amounts of data in only to perform a simple, fast operation before reading in new data. At several gigabytes in size even individual layers aren’t even close to being able to reside in on-die cache. I am unsure of how I might collect proof of my hypothesis but I believe it explains a great deal of the behaviours I’ve witnessed throughout this project.</p><h3 id="gpu-unsuitability">GPU Unsuitability</h3><p>There was also some hope at the beginning of the project that GPUs could be used but there are two main reasons they are unsuitable.</p><p>Firstly, ~GPUs with large amounts of VRAM (128GB+) simply aren’t available~ EDIT: I was wrong, <em>commercial</em> gaming and workstation GPUs don’t get that large, but there are plenty of datacentre options, like the <a href="https://cloud.google.com/blog/products/compute/announcing-google-cloud-a2-vm-family-based-on-nvidia-a100-gpu">A100</a>. There is the <a href="https://www.amd.com/en/products/professional-graphics/radeon-pro-ssg">Radeon Pro SSG</a> which is a really interesting product but the memory bandwidth of …</p></article></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mckeogh.tech/post/shallow-water/">https://mckeogh.tech/post/shallow-water/</a></em></p>]]>
            </description>
            <link>https://mckeogh.tech/post/shallow-water/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23843434</guid>
            <pubDate>Wed, 15 Jul 2020 10:43:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pavel Durov wants a law to make Apple allow iPhone users install other app store]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 6 (<a href="https://news.ycombinator.com/item?id=23843296">thread link</a>) | @vvpvijay
<br/>
July 15, 2020 | https://androidrookies.com/telegram-developer-wants-a-law-to-make-apple-allow-iphone-users-to-install-apps-from-other-app-stores/ | <a href="https://web.archive.org/web/*/https://androidrookies.com/telegram-developer-wants-a-law-to-make-apple-allow-iphone-users-to-install-apps-from-other-app-stores/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-8890"><div><div><div><p>VK social networking website and Telegram messenger App founder and developer, Pavel Durov wants Apple to let iPhone users install different App stores other than Apple App Store. Not only that, but he also wants legislation to make this happen.</p><p>Speaking at the panel discussion with Russian Prime Minister Mikhail Mishustin and representatives of the IT industry in Innopolis, Telegram Manager and Vice President, Ilya Perekopsky said that Apple and Google are holding back the development of startups by charging a tax of 30 percent commission from app developers. Immediately after Perekopsky’s speech,&nbsp;Durov published an article in which he called for legislation mandating Apple to be legally obliged to allow users to install an alternative App Store on the iPhone. Durov says that Tim Cook, Apple CEO should be obligated to this at the legislative level.</p><p>Durov is taking the bull by its horn. Apple has been successful because of its closed technology. It not only does not allow any other App store to be installed on iPhones but it also takes action against any iPhone jailbreaks that happen. We all know that the <a href="https://androidrookies.com/unc0ver-jailbreak-tool-for-iphone-released-works-on-all-ios-versions-including-ios-13-5/">uc0ver team released a jailbreak</a> exploiting the previously unknown vulnerability in iOS just hours after Apple released iOS 13.5. The <a href="https://androidrookies.com/kernel-vulnerability-unc0ver-jailbreak-patched-as-apple-releases-ios-13-5-1/">iPhone jailbreak was shut down in iOS 13.5.1</a> within days by Apple. Many private iPhone App stores exist like Cydia, Xabsi, etc but they work only on jailbroken iPhones.</p><p>Much of Apple’s profit is from selling content on its App stores. In fact, Apple’s App Store platform grossed around $50 billion for App store in 2019, according to an analysis by CNBC. Apple takes 30 percent commission from App developers to make their apps available on Apple Store. Last year it paid $35 billion to developers from the App store revenue and kept $15 billion for itself.</p><p>Durov has reasons for being mad at Apple for not allowing other App stores. Durov says that Russian startups fail to make money by paying 30% to Apple. “Preventing two supranational corporations from collecting taxes from all of humanity is not an easy task. Corporations employ thousands of lobbyists, lawyers, and PR agents, and their budgets are unlimited. At the same time, app developers are scattered and scared, as the fate of their projects depends entirely on the favor of Apple and Google,” wrote Pavel Durov.</p><p>Durov also has a personal bias for wanting Apple to open up its iOS for alternative App stores. In 2016, Apple banned the Telegram team from launching its own game platform. This hurt Durov and Telegram’s ambitions, “We had to remove the telegram games catalog that we had already created and almost the entire platform interface, otherwise Apple threatened to remove Telegram from the AppStore.”</p><p>Recently, <a href="https://androidrookies.com/apple-threatens-to-remove-hey-com-email-app-unless-it-pays-outrageous-cuts-to-them/">email client, Hey.com</a> had a similar experience with Apple regarding publishing their App on the Apple App store.</p></div></div></div></article></div>]]>
            </description>
            <link>https://androidrookies.com/telegram-developer-wants-a-law-to-make-apple-allow-iphone-users-to-install-apps-from-other-app-stores/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23843296</guid>
            <pubDate>Wed, 15 Jul 2020 10:21:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The hardship of SaaS in the video games industry]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23843282">thread link</a>) | @philippz
<br/>
July 15, 2020 | https://philippzentner.com/hardship-saas-video-games-industry | <a href="https://web.archive.org/web/*/https://philippzentner.com/hardship-saas-video-games-industry">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-block="true" data-editor="gn18" data-offset-key="m69q-0-0"><p><span data-offset-key="m69q-0-0">At </span><a href="https://www.stomt.com/"><span data-offset-key="m69q-1-0">STOMT</span></a><span data-offset-key="m69q-2-0"> we've been focusing on the video games industry. And let me tell you, it's been a ride. When we started out, we tried to approach the industry from the bottom-up. </span><span><span data-offset-key="m69q-3-0">We got feedback and love from independent developers first and then started to approach bigger companies</span></span><span data-offset-key="m69q-4-0">. It became difficult right here.</span></p></div><div data-block="true" data-editor="gn18" data-offset-key="1b2ek-0-0"><p><span data-offset-key="1b2ek-0-0">Roughly 50% of that <a href="https://newzoo.com/insights/trend-reports/newzoo-global-games-market-report-2020-light-version/" rel="nofollow">~$160 billion revenue market (2020, Newzoo)</a> </span><span><span data-offset-key="1b2ek-1-0">is made by</span></span> <span><span data-offset-key="1b2ek-3-0">just</span></span><span data-offset-key="1b2ek-4-0"> 10-15 companies. The rest </span><span><span data-offset-key="1b2ek-5-0">is distributed</span></span><span data-offset-key="1b2ek-6-0"> across many small studios and publishers across the world. But what does that </span><span><span data-offset-key="1b2ek-7-0">really</span></span><span data-offset-key="1b2ek-8-0"> mean? </span><span><span data-offset-key="1b2ek-9-0">The gaming industry works like this: game developers have a vision, which then gets financed and marketed by publishers</span></span><span data-offset-key="1b2ek-10-0">. </span><span><span data-offset-key="1b2ek-11-0">When we talk about the biggest 10-15 companies, we're actually talking about publishers, which in return work with dozens of globally distributed teams of game development studios to create the next hit</span></span><span data-offset-key="1b2ek-12-0">. </span><span><span data-offset-key="1b2ek-13-0">When you aim to sell a service to the gaming industry, make sure to target either 100% publishers or a 100% game developers, which is hard as the line is blurry</span></span><span data-offset-key="1b2ek-14-0">. Depending on their deal, certain responsibilities are shifting. For STOMT it was especially difficult: Who cares about feedback? Customer service (publisher)? The producer (developer)? The developer? Marketing (publisher)? Finding someone who cares about it is easy, finding someone who wants to make it part of their budget not.&nbsp;</span></p></div><div data-block="true" data-editor="gn18" data-offset-key="a3hni-0-0"><p><span><span data-offset-key="a3hni-0-0">For publishers it's the classic venture capital rule of thumb, that one success out of ten investments have to outweigh the rest</span></span><span data-offset-key="a3hni-1-0">. And it's a risky business. Most games fail. </span><span><span data-offset-key="a3hni-2-0">Platforms and app stores </span></span><span><span data-offset-key="a3hni-3-0">are saturated</span></span><span><span data-offset-key="a3hni-4-0"> and games, as part of the entertainment industry, are competing for consumer's attention</span></span><span data-offset-key="a3hni-5-0">. By the end of each year we see massive amounts of layoffs, shutdowns and M&amp;As. It </span><span><span data-offset-key="a3hni-6-0">easily</span></span><span data-offset-key="a3hni-7-0"> cuts your deal flow by 30%.</span></p></div><div data-block="true" data-editor="gn18" data-offset-key="eed00-0-0"><p><span data-offset-key="eed00-0-0">And that is expensive. </span><span><span data-offset-key="eed00-1-0">Due to the very globally distributed publisher-developer relationship, you spend a lot of money on going to conferences and meeting people face to face, building up relationships</span></span><span data-offset-key="eed00-2-0">. In 2018 I did sale and business development in 14 countries. In fact, if you'd want to attend all gaming industry events, you could be on the road almost every day. </span><span><span data-offset-key="eed00-3-0">In between</span></span><span><span data-offset-key="eed00-4-0"> you try to figure out who your buyer persona / decision-maker is and if that person is part of the developer or part of the publisher side</span></span><span data-offset-key="eed00-5-0">. </span><span><span data-offset-key="eed00-6-0">You better build</span></span><span><span data-offset-key="eed00-8-0">&nbsp;something that </span></span><span><span data-offset-key="eed00-9-0">is needed</span></span><span><span data-offset-key="eed00-10-0"> all the time</span></span><span data-offset-key="eed00-11-0">.</span></p></div><div data-block="true" data-editor="gn18" data-offset-key="f3998-0-0"><p><span data-offset-key="f3998-0-0">Timing also plays a huge role. The development of a game takes 2-4 years. </span><span><span data-offset-key="f3998-1-0">If you're too early, you're not relevant, if you're too late, you won't end up on the roadmap, assuming you're a middleware provider</span></span><span data-offset-key="f3998-2-0">. The sales process is lengthy. So you better have huge pipeline and try to be present in people's head all the time.</span></p></div><div data-block="true" data-editor="gn18" data-offset-key="v7i9-0-0"><p><span><span data-offset-key="v7i9-0-0">As an industry of passion, you're also confronted with certain paradigms, that won't fit your McKinsey brain</span></span><span data-offset-key="v7i9-1-0">. </span><span><span data-offset-key="v7i9-2-0">There's often a lack of ownership, process or transparency and that makes it hard to keep up with your deal-flow</span></span><span data-offset-key="v7i9-3-0">. We also see it in the high fluctuation within teams. Fluctuation seems to be much higher than elsewhere. </span><span><span data-offset-key="v7i9-4-0">This is still the creative industry and people are not only passioned about what they are doing but also much more emotional when it comes to decisions</span></span><span data-offset-key="v7i9-5-0">. So don't even try to sell to indies (referring to small &lt;10 people teams). They often have very limited budgets and are not very business minded. With the availability of <a href="https://www.game.de/wp-content/uploads/2017/02/2019_Guide-to-the-German-Games-Industry_web.pdf" rel="nofollow">more and more grants for the creative gaming industry,</a> this is changing as considerations about the underlying business model have to be made much earlier</span><span data-offset-key="v7i9-7-0">.&nbsp;</span></p></div><div data-block="true" data-editor="gn18" data-offset-key="ech92-0-0"><p><span data-offset-key="ech92-0-0">Another cost-block is the development and maintenance of relevant integrations. </span><span><span data-offset-key="ech92-1-0">The ecosystem of the gaming industry is currently based on certain game engines like Unity, Unreal, GameMaker, Cocos2D and the proprietary ones, often written in C++, of the big ones</span></span><span data-offset-key="ech92-2-0">. On top we have unique to the gaming industry relevant platforms like Twitch and Discord. Most platforms are still young and have frequent releases containing breaking changes. Have fun trying to find a passioned game developer that likes to work on middleware. It's expensive. </span><span><span data-offset-key="ech92-3-0">We're happy to have a capable CTO (shoutout to <a href="https://www.linkedin.com/in/maxklenk/">Max Klenk</a>), who is flexible enough to solve any problem in any language on any system</span></span><span data-offset-key="ech92-4-0">. I mean, look at </span><a href="https://www.stomt.com/integrations"><span data-offset-key="ech92-5-0">that</span></a><span data-offset-key="ech92-6-0">.&nbsp;</span></p></div></div></div>]]>
            </description>
            <link>https://philippzentner.com/hardship-saas-video-games-industry</link>
            <guid isPermaLink="false">hacker-news-small-sites-23843282</guid>
            <pubDate>Wed, 15 Jul 2020 10:19:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Education 2.0 – A brand new education system]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23843235">thread link</a>) | @aryankashyap
<br/>
July 15, 2020 | https://aryankashyap.com/education-2-dot-0 | <a href="https://web.archive.org/web/*/https://aryankashyap.com/education-2-dot-0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post_body_1570553">
    
      <div><p>What this essay does is that it introduces a brand new education system. This education system is way more effective than the current education system we have in place. And unlike the current education system, which has been the same for a long time. This one is constantly getting better with time and data, thanks to AI.<br></p><p>The best thing about it is that it's totally free of cost. So anyone in the world with access to a basic smartphone+Internet can access Education 2.0. Meaning, now everyone has the same educational opportunities as a Harvard/Stanford student.<br></p><p>You see, education is the most fundamental thing to human progress. And once you deploy something like Education 2.0 on a global scale, it will have huge positive implications on economic growth, life quality, and human progress. And to emphasise what I just said, the collective intelligence of humanity is the best predictor of future progress.Â&nbsp;<a href="https://ourworldindata.org/global-education#education-outcomes-predict-economic-growth" target="_blank">Here</a>Â&nbsp;is some empirical data to prove this statement. Nevertheless, you don't need empirical evidence; look around, education is what drives societal growth.<br></p><p>Looking at the current education system we have in place. It would be unfair to say that it hasn't done an excellent job in aiding human progress. Resolving the COVID-19 Pandemic, the Apollo Program, the iPhone, Tesla, SpaceX, the Internet, All of Science etc. are a prime example.<br></p><p>But it certainly hasn't been able to keep up with the growing human population, and the challenges raised by it. Looking at all the pressing issues, we face today like global poverty, climate change, and war. The incapability of civilisation to solve these problems stems from the fact that it's not educated enough as a whole. There is conclusive evidence to prove this â€”Â&nbsp;<a href="https://ourworldindata.org/global-education#social-returns-to-education" target="_blank">Education correlates with prosocial behaviour</a>. Prosocial behaviour is behaviour, which affects society as a whole.<br></p><p>So the best way to ensure that we progress into a brighter future is by rewiring the current education system. So it can keep up with the ever-growing population and the challenges we face, which will then eventually increase the collective wisdom and prosocial behaviour of humans at a much faster rate.<br></p><p>There are 3 main issues with the current education system, which dramatically lowers its potential.<br></p><ol>
<li>Its inability to reach a large population of the world.</li>
<li>The unequal distribution of resources.</li>
<li>The low efficacy of the current learning environments (i.e. lectures/books).</li>
</ol><p>And Education 2.0 fixes all of these issues.<br></p><p><strong><u>No access to education</u></strong></p><p>The biggest problem with the current education system is that it's unable to reach an unfairly enormous number of the global population. People say that education is a human right, but looking at the current situation â€” that doesn't seem so.</p><p>According to Humanium.org,Â&nbsp;<strong>72 million</strong>Â&nbsp;children of primary education age are not in school, andÂ&nbsp;<strong>759 million</strong>Â&nbsp;adults are illiterate.<strong>Â&nbsp;</strong>And we haven't even considered the inconsistency in educational outcomes yet.<br></p><p>Now I would like to explain the enormous implications this has on the economy. But first, I would like toÂ&nbsp;<a href="https://ourworldindata.org/grapher/correlation-between-mean-years-of-schooling-and-gdp-per-capita" target="_blank">establish a conclusive link between Education and GDP per capita</a>.<br></p><p>Now doing the math:<br></p><ul><li>
<strong>$18,381</strong>Â&nbsp;is the global average GDP per capita (a measure of economic output per person), and we haveÂ&nbsp;<strong>831 million peopleÂ&nbsp;</strong>with no access to education at all.</li></ul><ul><li>
<strong>831 million people * $18,381 ~ $15 Trillion</strong>Â&nbsp;worth of economic output wasted. And it has a growth rate of ~<strong>Â&nbsp;1.8% per year</strong>Â&nbsp;(Taking into account the growth rates of global GDP &amp; global population).</li></ul><ul><li>To put this number in perspective, this is more than the GDP of<strong>Â&nbsp;China</strong>,Â&nbsp;<strong>India,</strong>Â&nbsp;andÂ&nbsp;<strong>the UK</strong>Â&nbsp;separately, andÂ&nbsp;<strong>$5 TrillionÂ&nbsp;</strong>less than the USA.</li></ul><p>There is no doubt that the current model of the education system is responsible for this issue. An education system is basically a collection of what we call "learning environment.". And a learning environment is an environment where learning takes place (i.e. classroom).</p><p>You see, the major problem with the current system is the high relative cost of setting up that learning environment (i.e. a classroom with qualified teachers, furniture, and students, etc.). So when you scale the education system, the setup + maintenance costs increase with it. And some countries just don't have the resources to scale. This can be due to many factors like large population, not enough teachers, etc. All of these issues then boil down to one primary issue â€” lack of economic resources, aka no money.</p><p>Scaling requires huge costs, which then dramatically lowers the potential for impact. Due to which, a significant amount of people in the world don't have access to basic education.</p><p>To beat this issue, what we need to do is switch to a new model of the education system. One which can scale cheaply and effectively. The best way to do this is by moving to a more digitalised education system.</p><p>One way to go about doing this is by leveraging Software, AI, and low-cost smartphones. Software and AI can be leveraged to create digital learning environments, which are more effective than the current learning environments we have, and its efficacy improves with time &amp; data. These AI-taught lessons will be way better than attending a Stanford/Harvard lecture.<br>
</p><p>Once this works, the next thing to do is to ensure it supports low-cost smartphones, which will then allow for distribution at an enormous scale, while keeping the costs minimal. This will go a really long way in closing the educational gap. The best thing is that now anyone in the world will be able to have the same educational opportunities as an Ivy-League student.</p><p>In the long-term, you will see substantial positive implications on collective prosocial behaviour, economy, and quality of life. And redundancy in the current education system.<br>
</p><p><strong><u>Unequal distribution of educational resources</u></strong><br>
</p><p>First, we looked at inequality in terms of access to education. Now, we're going to look at inequality inside the people with access to education (in terms of the quality of educational resources). Turns out that this has huge negative implications on the overall learning outcome of the education system.</p><p>It is implausible to sustain the quality of educational resources (e.g. teachers, books, etc.) as you scale (make it available for a larger population) the education system. Due to which, a major side-effect of scaling is that it induces a widely unequal distribution of educational resources, which varies by economic demographic. Which then leads to variation in educational outcomes.</p><p>This is why the number of high-school graduates who attend prestigious colleges tends to be higher in private high-schools, relative to a public high-schools. The quality &amp; quantity of educational resources (quality of teachers, study material, support, etc.) available to students at the private school is more elevated. Which then leads to higher success.Â&nbsp;<br></p><p>Inequality in educational resources leads to a variation in educational outcomes, which then lowers the average output of the education system.</p><p>Now, coming around to solve this issue. We need to create a system where the quality of educational resources is the best on earth. And it's available to everyone, no matter their economic situation. And finally, as it scales, its overall effectiveness doesn't reduce.Â&nbsp;<br></p><p><strong><u>Low efficacy of current learning environments</u></strong></p><p>The final issue I would like to talk about is regarding the teaching methods used currently. Teaching methods are ways in which teachers teach the student. Â&nbsp;<br></p><p>The problem is that the current teaching methods, which are used around the world, are scientifically flawed. This then makes the process of learning inefficient and ineffective. And on a large scale, it reduces the learning output (the product of learning) of the education system.<br></p><p>You might think that sitting in a classroom, while a teacher speaks out everything, and you note it down is an excellent way to learn. But in fact, this method is flawed. The reason it's flawed because it bears no consideration whatsoever to how our brain operates during learning. Due to which, the conversion rate from auditory + visual perception to long-term memory is low. This dramatically lowers the learning potential of the student.<br></p><p>The modern K-12 education system was established back in the 19th century to prepare the population to participate in the Industrial Revolution. At the time, not a lot of thought was given to the science of how we learn; they just wanted a cheap way to deliver information to a large number of students. And surprisingly, this factory model of the education system hasn't changed since then.<br></p><p>What we need to do now is to build a digital learning environment, which makes learning way more effective &amp; efficient. Leading to a dramatic increase in learning output of the education system. And leverage AI, to make it so that it improves its efficacy with time &amp; data.<br></p><p>The way to do this is by understanding thoroughly, how the human brain operates while learning. And then using those scientific principles to design the learning environment.Â&nbsp;<br></p><p>Here is a fantastic essay by Andy Matuschak, which explains what I just said above better. You can read itÂ&nbsp;<a href="https://andymatuschak.org/books/" target="_blank">here</a>.</p><p>The starting point for this digital learning environment should be something, which is way more effective than any learning environment present today. Deploying this on a global scale will yield dramatically higher overall learning output than today. Making the current education systems redundant.Â&nbsp;</p><p>This would be the first step in accelerating the advent of Education 2.0. A world where high-quality education is free of cost to anyone and the quality of education is increasing over time. In the long term, this will mitigate all forms of inequality, and help humanity get onto a path of something bigger and brighter, thanks to its more immense collective wisdom.</p><p><b><u>Education 2.0Â&nbsp;</u></b></p><p><b><u></u></b>We have now talked about the major issues our education system faces and potential solutions to them. I would now like to introduce a brand new education system â€” Education 2.0.<b><u><br></u></b></p><p>Introducing …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aryankashyap.com/education-2-dot-0">https://aryankashyap.com/education-2-dot-0</a></em></p>]]>
            </description>
            <link>https://aryankashyap.com/education-2-dot-0</link>
            <guid isPermaLink="false">hacker-news-small-sites-23843235</guid>
            <pubDate>Wed, 15 Jul 2020 10:11:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple and Ireland have won their appeal against the EU €13B tax ruling]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23843150">thread link</a>) | @benoitg
<br/>
July 15, 2020 | https://www.thejournal.ie/apple-tax-fine-gael-fianna-fail-government-eu-5149993-Jul2020/ | <a href="https://web.archive.org/web/*/https://www.thejournal.ie/apple-tax-fine-gael-fianna-fail-government-eu-5149993-Jul2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="articleContent">

                    <p title="Wednesday 15 Jul 2020, 3:25 PM"><span></span>Updated Wed 3:25 PM</p>                <p>A TOP EU court has ruled in favour of Ireland and Apple in their appeal against the European Commission’s finding that the country breached state aid rules in its dealings with the multinational.</p>
<p>The European Commission previously ordered the US company to hand back €13 billion in unpaid tax and over €1 billion in interest payments to the Irish government.</p>
<p>Both Ireland and Apple appealed that ruling and the General Court of the European Union has now found in their favour.</p>
<p>It is widely expected that this ruling will be appealed to the European Court of Justice, with parties having a little over two months to file an appeal.</p>
<p>In its judgement, the General Court of the European Union said:
</p>
<blockquote>
<p>By today’s judgement, the General Court annuls the contested decision because the Commission did not succeed in showing to the requisite legal standard that there was an advantage for the purposes of Article 107(1) TFEU.According to the General Court, the Commission was wrong to declare that Apple Sales International (ASI) and Apple Operations Europe (AOE) had been granted a selective economic advantage and, by extension, State aid.The General Court endorses the Commission’s assessments relating to normal taxation under the Irish tax law applicable in the present instance, in particular having regard to the tools developed within the OECD, such as the arm’s length principle, in order to check whether the level of chargeable profits endorsed by the Irish tax authorities corresponds to that which would have been obtained under market conditions.However, the General Court considers that the Commission incorrectly concluded, in its primary line of reasoning, that the Irish tax authorities had granted ASI and AOE an advantage.
</p>
</blockquote>
<p>Apple Operations International (AOI) and Apple Sales International (ASO) were two Apple subsidiaries that were based in Ireland.&nbsp;</p>
<p>The General Court of Justice went on to say: “The Commission did not prove, in its alternative line of reasoning, that the contested tax rulings were the result of discretion exercised by the Irish tax authorities and that, accordingly, ASI and AOE had been granted a selective advantage.”</p>

<p><strong>Reaction</strong></p>
<p>Both Apple and the Irish government have welcomed the judgement.</p>
<p>“This case was not about how much tax we pay, but where we are required to pay it,” an Apple spokesman said in a statement.</p>
<p>“We’re proud to be the largest taxpayer in the world as we know the important role tax payments play in society,” Apple added.</p>
<p>The government has welcomed the judgement, stating in a statement that Ireland has “always been clear that, based on Irish law, the correct amount of Irish tax was charged and that Ireland provided no State aid to Apple”.&nbsp;</p>
<p>“Ireland appealed to the Commission decision on that basis and the judgement today from teh court vindicates this stance.”</p>
<p>The Department of Finance said the decision showed there had been “no special treatment” for the tech giant.</p>
<p>“We welcome the judgment by the General Court of the European Union annulling the Decision of the European Commission of August 2016, which alleged Ireland provided State aid to Apple,” the department said in a statement.</p>
<blockquote>
<p>Ireland has always been clear that there was no special treatment provided to the two Apple companies – ASI and AOE. The correct amount of Irish tax was charged taxation in line with normal Irish taxation rules. Ireland appealed the Commission decision on the basis that Ireland granted no state aid and the decision today from the Court supports that view.</p>
</blockquote>
<p>Finance Minister Paschal Donohoe said the judgement “proves Ireland was correct to pursue this case in the European courts”.&nbsp;</p>


<p>The court was asked to determine whether two tax rulings delivered by Revenue in 1991 and 2007 allowed Apple to funnel profits through Irish-anchored structures without paying tax in any jurisdiction.</p>
<p>It is the first legal ruling in a case that formally kicked off in 2014 when the Commission opened an investigation into the matter, which concluded in 2016. The decision could have major implications for the European Commission’s plans to harmonise tax regimes across member states.&nbsp;</p>
<p>The Commission had found that the two rulings had breached EU state aid rules designed to prevent individual companies from receiving favourable treatment from member state governments. As then-commissioner for competition Margrethe Vestager put it at the time, “Ireland had granted illegal tax benefits to Apple”.</p>
<p>After concluding that Apple had been paying corporation tax at an effective rate of just 0.005%, the Commission ordered the US company to hand back €13 billion in unpaid tax and over €1 billion in interest payments to the Irish government.&nbsp;</p>
<p>Apple denied that it had ever sought special deals with any government and accused the Commission of selectively quoting “tiny figures”.&nbsp;</p>
<p><a href="https://ec.europa.eu/commission/presscorner/detail/en/statement_20_1356">In a statement this morning</a> Vestager, who is now Executive Vice-President of the Commision, said that the body will “carefully study the judgment and reflect on possible next steps”.</p>
<p>“The Commission stands fully behind the objective that all companies should pay their fair share of tax,” she said.&nbsp;</p>
<blockquote>
<p>If member states give certain multinational companies tax advantages not available to their rivals, this harms fair competition in the EU. It also deprives the public purse and citizens of funds for much needed investments the need for which is even more acute during times of crisis.</p>
</blockquote>
<p><strong>Political reaction</strong></p>
<p>Following Apple’s appeal of the 2016 Commission finding, the Fine Gael minority government at the time, supported by Fianna Fáil, decided to join the appeal – prompting significant political and public opposition.</p>
<section id="contribution-prompt-article">
    <div>
        <p><span>#Open journalism</span>

        <span>No news is bad news</span>
        <span>Support The Journal</span></p><p>
            Your <b>contributions</b> will help us continue
            to deliver the stories that are important to you
        </p>
    </div>

    <a href="https://www.thejournal.ie/contribute">
        Support us now
    </a>
</section>

<p>Responding to the ruling this morning, former minister Charlie Flanagan said: “Important EU court ruling vindicates actions of Enda Kenny, Michael Noonan and government despite incessant hostility at home and abroad.”</p>
<p>Sinn Féin’s finance spokesperson Pearse Doherty TD said that “morally this is a terrible day” because Apple was allowed to avoid paying a “fair amount of tax”</p>
<p>“Apple had three stateless companies here, ‘we shouldn’t pay tax here, or anywhere in the world’. So, while the Department of Finance may be thinking that this is a good day for themselves, morally this is a terrible day,” Doherty told RTÉ’s Today with Sarah McInerney.</p>
<p>“The richest company in the world was able to generate over €100 billion of profits and not pay tax anywhere in the world on those profits despite the fact that the companies are incorporated here in Ireland. “&nbsp;</p>
<p><em>With reporting from Ian Curran and Dominic McGrath</em></p>

            </div></div>]]>
            </description>
            <link>https://www.thejournal.ie/apple-tax-fine-gael-fianna-fail-government-eu-5149993-Jul2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23843150</guid>
            <pubDate>Wed, 15 Jul 2020 09:58:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One Trillion Connections – Nebula Graph Database at WeChat]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23843038">thread link</a>) | @jamie-vesoft
<br/>
July 15, 2020 | https://nebula-graph.io/posts/nebula-graph-for-large-social-network/ | <a href="https://web.archive.org/web/*/https://nebula-graph.io/posts/nebula-graph-for-large-social-network/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><p><img src="https://nebula-graph.io/images/writer.png" width="16px" height="16px">
<span>Li Benli</span></p><p><img src="https://nebula-graph.io/images/calendar.png" width="16px" height="16px">
<span>2020-07-02</span></p></div><p><img src="https://user-images.githubusercontent.com/57335825/87518187-cdb4d200-c634-11ea-9dc4-264001420b55.png" alt="Nebula Graph for Large Social Network: Practices at WeChat"></p><p>WeChat is one of the social network apps in the world that deals with large scale heterogeneous graphs. The dataset to be processed has:</p><ul><li>One trillion edges/connections</li><li>A total dataset of 150TB</li><li>An hourly update of 100 billion connections,</li></ul><p>And it is a huge challenge. The team at WeChat encountered problems when using <a href="https://github.com/vesoft-inc/nebula">Nebula Graph</a>, an open source distributed graph database.</p><p>However, through deep customization capabilities in the database, the team has realized some useful on-demand features. They include big data storage, data import for large data sets with a fast performance, version control, rollback at the second level, and access to the database at millisecond level.</p><h2 id="the-challenges-facing-large-internet-companies">The Challenges Facing Large Internet Companies</h2><p>Most well-known graph databases are not capable of dealing with truly big data. For example, the community version of <a href="https://neo4j.com/">Neo4j</a> provides single-host service and is widely adopted in the knowledge graph area. However, when it comes to a very large data set this solution misses the mark. And large data sets are increasingly common in today’s business world.</p><p>Plus, there are issues like data consistency and disaster recovery to consider if you choose a multi-copy implementation. <a href="https://janusgraph.org/">Janus Graph</a> has solved the big data storage problem by using external metadata management, kv storage and indexes. Yet the performance has been widely criticized. As a result, most graph database solutions that the WeChat team evaluated are many times better than Janus Graph in terms of performance.</p><p>Some Internet companies build their own databases. These self-developed solutions are catering to their own business requirements, rather than for general graph scenarios. So, they support only a limited proportion of query syntaxes.</p><h3 id="geabase-from-ant-financial">GeaBase from Ant Financial</h3><p><a href="https://tech.antfin.com/products/GEABASE">GeaBase</a> is another option, mainly used in the finance industry. It features a self-developed query language, pushdown computation and millisecond latency. The main scenarios for its usage include risk management in financial organizations. To this end, it supports a transaction network with trillions of edges/relationships, storing real-time transaction data, real-time fraud detection.</p><p>It is also useful for recommendation engines. This includes applications like stocks and securities recommendations. Its Ant Forest features the capability to store trillions of nodes, strong data consistency, and low latency querying. It also has a GNN feature for Dynamic Graph CNN, for online inference based on dynamic graphs.</p><h3 id="igraph-from-alibaba">iGraph from Alibaba</h3><p>There is also iGraph, a graph indexing and query system. It stores user behavior information and serves as one of the four backbone middle platforms in Alibaba. iGraph has adopted Gremlin as its graph query language for real-time queries of e-commerce relationships.</p><h3 id="bytegraph-from-bytedance-aka-tiktok">ByteGraph from ByteDance (a.k.a TikTok)</h3><p>By adding a cache layer to the kv layer, ByteGraph splits the relationships into B+ trees for efficient access to edges and data sampling. The structure is like the TAO of Facebook.</p><h2 id="architecture-of-the-wechat-big-data-solution">Architecture of the WeChat Big Data Solution</h2><p>The WeChat team has come up with the following architecture to solve the big data storage and processing problem.</p><p><img src="https://user-images.githubusercontent.com/57335825/86352447-a87a9980-bc1a-11ea-83c6-47a481675e9e.png" alt="Architecture of the WeChat Big Data Solution"></p><h2 id="why-nebula-graph">Why Nebula Graph?</h2><p>As seen in the architecture above, a graph database is the main component of the solution. WeChat ended up selecting Nebula Graph as the starting point of its journey in exploring graph databases.</p><p>WeChat found Nebula Graph had the most potential for handling huge dataset storage needs based on the capability of dataset partitioning and an independent relationship storage. It also had pushdown computation and MPP optimization based on the strong consistency storage engine. Finally, the team had extensive experience in the graph database field and a proven model for abstraction for big data.</p><h2 id="problems-in-practice-nebula-graph">Problems in Practice Nebula Graph</h2><h3 id="insufficient-memory">Insufficient Memory</h3><p>The WeChat team encountered memory issues. At its essence, it was a problem of performance versus resources. Memory occupation is an un-neglectable issue in an application dealing with large scale datasets.
There are a couple of components in RocksDB that contribute to memory usage. There are Block cache, Indexes and bloom filters. There are also Memtables and Blocks pinned by iterators.
So, the WeChat team moved to optimize memory utilization. It began with block cache optimization. To do this, it adopted a global LRU cache to control the cache occupation of all RocksDB instances in a machine.</p><p>Then the team did a bloom filter optimization. An edge is designed as a key-value pair and stored in RocksDB. If all keys are stored in a bloom filter and each key occupies 10bit, then the memory required by the entire filter will exceed the machine memory by a large margin.</p><p>The team observed that most of the time the requests are to acquire a list of edges for a specific node. Therefore, the team adopted a prefix bloom filter. Another optimization was made to create indexes for properties on vertices, which enables acceleration for most requests. Finally, the memory occupation of a single-host filter is at the gigabyte level without sacrificing the speed of most requests.</p><h3 id="version-control">Version Control</h3><p>There are several business requirements in practice for version control. It offers graph data fast rollback, periodic full data import, and automatic access to the latest versioning data. The team has classified data sources into two categories.</p><p>Recurring data, for example, generates a list of similar users by day and the data takes effect after being successfully imported. Then there is History data and real-time data. For example, there is refresh history data by day and the team combines the history data with real-time data as full data to be imported.</p><p>Following is the data storage model in RockDB.</p><p>Vertex Storage Model:</p><p><img src="https://user-images.githubusercontent.com/57335825/86352518-c516d180-bc1a-11ea-9ea3-25a774e6478c.png" alt="Vertex Storage Model in RocksDB"></p><p>Edge Storage Model:</p><p><img src="https://user-images.githubusercontent.com/57335825/86352600-e2e43680-bc1a-11ea-819c-6161cdf719b3.png" alt="Edge Storage Model in RocksDB"></p><p>Timestamp is used as the versioning method for real-time data. The version of imported data is specified manually. In practice, the team has three options for version control. First, reverse_versions, where the list of versions is to be kept for rollback. Second is active_version, where the version is accessed by users’ requests. And finally, max_version, where data is reversed after a certain version. The reversed data is the combination of the history data and the real-time data.</p><p>Using the three options, the team can manage offline data and online data efficiently. The data that is no longer used is cleared from the disk during the next compaction.
In this way, the application can update the data version without in the background. And the data rollback can be completed within seconds.</p><p>Below are some examples:</p><ul><li>Keep three versions of data and activate one of them</li></ul><p><code>alter edge friend reserve_versions = 1 2 3 active_version = 1</code></p><ul><li>Data sources are history data and real-time write data</li></ul><p><code>alter edge friend max_version = 1592147484</code></p><h2 id="fast-full-data-import">Fast Full Data Import</h2><p>Conducting data imports at a large scale is a common practice. The import requests, without any optimization, would not only affect requests in production, but take longer than a day to complete. So, it became an urgent requirement to improve import speed. SST Ingest is a commonly adopted method to achieve fast import. The WeChat team adopted something similar.</p><p>The team generated SST files offline via scheduling Spark tasks. Storage nodes pull the data required and ingest the data to the graph database. And, then there is access to the latest versioning data via the version control request. The import process takes several hours to complete, which is fast. And it does not affect requests to the graph database because the computation is mainly offline.</p><p>The shared-nothing architecture is a widely discussed method for ensuring horizontal scalability. It requires programming skills to implement the architecture in practice. The meta cache is encapsulated with <code>shared_ptr</code> and is frequently accessed, making it a warm bed for atomic operation clashing. To realize shared-nothing, the WeChat team copied each meta cache as a local thread. This <a href="https://github.com/vesoft-inc/nebula/pull/2165">pull request</a> provides details.</p><p>It has been a long journey to achieve graph database utilization. And it is one that continues with success in large part by overcoming obstacles.</p><h2 id="you-might-also-like">You Might Also Like</h2><ul><li><a href="https://nebula-graph.io/posts/detect-corona-virus-spreading-with-graph-database/">Detect Corona Virus Spreading With Graph Database Based on a Real Case</a></li><li><a href="https://nebula-graph.io/posts/review-on-graph-databases/">A Review of Graph Databases</a></li></ul><blockquote><span>Like what we do ? Star us on GitHub.</span>
<a href="https://github.com/vesoft-inc/nebula" onclick="gtag('event','Link Click',{event_category:'Engagement',event_label:'Star via blogbody'});">https://github.com/vesoft-inc/nebula</a></blockquote></section></div>]]>
            </description>
            <link>https://nebula-graph.io/posts/nebula-graph-for-large-social-network/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23843038</guid>
            <pubDate>Wed, 15 Jul 2020 09:41:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google is investing Rs 33,737 crore for a 7.7% stake in India's Jio Platforms]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23843004">thread link</a>) | @hacknoid
<br/>
July 15, 2020 | https://mythreadreader.com/ETtech/1283321850412412928 | <a href="https://web.archive.org/web/*/https://mythreadreader.com/ETtech/1283321850412412928">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                  
                  <div>
                    <a href="https://twitter.com/ETtech/status/1283327519253344257"><p>A new JioTV+ platform would aggregate content from over 12 video streaming services such as Netflix, Amazon Prime, Disney+ Hotstar, Voot, SonyLiv, Zee5, JioCinema, JioSaavn and YouTube among others #RILAGM</p></a>
                    
                    
                    

                    
                  </div>    
                </div></div>]]>
            </description>
            <link>https://mythreadreader.com/ETtech/1283321850412412928</link>
            <guid isPermaLink="false">hacker-news-small-sites-23843004</guid>
            <pubDate>Wed, 15 Jul 2020 09:36:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New Zealand: Next steps in Covid response]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23842977">thread link</a>) | @sohkamyung
<br/>
July 15, 2020 | https://www.beehive.govt.nz/speech/next-steps-covid-response | <a href="https://web.archive.org/web/*/https://www.beehive.govt.nz/speech/next-steps-covid-response">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Kia ora tatou</p>
<p><span><span><span><span>Today I am setting out our plan in the event we have a new case of community transmission of COVID-19 in New Zealand. </span></span></span></span></p>
<p><span><span><span><span>I will take a bit of time to do that, and then I’ll be happy to take questions at the end. </span></span></span></span></p>
<p><span><span><span><span>Since we moved to level one, we have continued work to ensure we have an ongoing level of preparedness for resurgence in New Zealand. </span></span></span></span></p>
<p><span><span><span><span>The framework I will be speaking to today has been through a Cabinet process, and is more important than ever. </span></span></span></span></p>
<p><span><span><span><span>It is designed to give the public, and our business community as much certainty as we can around what to expect if new cases inside our borders are found. And that is something we all must prepare for. </span></span></span></span></p>
<p><span><span><span><span>We have been 75 days without community transmission here in New Zealand, but COVID is now exploding outside our borders and every country we have sought to replicate or have drawn from in the fight against COVID has now experienced further community outbreaks.</span></span></span></span></p>
<p><span><span><span><span>We only need to look to Victoria, New South Wales, Hong Kong, Singapore and Korea to see examples of other places that like us had the virus under control at a point in time only to see it emerge again. </span></span></span></span></p>
<p><span><span><span><span>This does not mean anyone has failed- it means perfection in the response to a virus, and a pandemic, is just not possible. That is certainly the case as we see this pandemic continue to grow.&nbsp;&nbsp; </span></span></span></span></p>
<p><span><span><span><span>The World Health Organisation this week reported the global infection rate is nearing 13 million cases, with over 215,000 cases reported globally on Tuesday. </span></span></span></span></p>
<p><span><span><span><span>To put that into perspective when we closed our borders on the 19th of March there were 240,000 cases in the world in total. It’s fifty times worse than that now. </span></span></span></span></p>
<p><span><span><span><span>We see this growth in cases around the world reflected in the steady stream of New Zealanders returning from overseas, some of whom are bringing the virus back with them, which we continue to contain at our borders. </span></span></span></span></p>
<p><span><span><span><span>In the main the pattern of returnees carrying the virus reflects the state of COVID in the world, with our cases coming from places like India, the US and the UK. </span></span></span></span></p>
<p><span><span><span><span>New modelling by Rodney Jones indicates there will be over 100,000 new cases a day in the US by the end of the month, nearly 70,000 cases a day in India and nearly 10,000 cases a day across Europe by early August. </span></span></span></span></p>
<p><span><span><span><span>We will continue to welcome home New Zealanders from these places as citizens, as they have a right to come home to their legal place of residence. But with that right comes risk, and the need to continue ongoing stringent measures to keep them, and everyone around them, safe. </span></span></span></span></p>
<p><span><span><span><span>Victoria in particular is a cautionary tale for New Zealand that we must learn from. </span></span></span></span></p>
<p><span><span><span><span>It appears their current outbreak is linked to a managed isolation facility similar to the ones we run here and that the entire outbreak was seeded by just two cases. </span></span></span></span></p>
<p><span><span><span><span>That goes to show how quickly the virus can spread and it can move from being under control to out of control, and that even the best plans still carry risk in a pandemic. </span></span></span></span></p>
<p><span><span><span><span>It’s important to remember that our border facilities have served us well so far. </span></span></span></span></p>
<p><span><span><span><span>Our testing regime is picking up cases amongst new arrivals who are in quarantine and nearly 30,000 people have been through a facility without a case of COVID transferring to the community. But there is limited room for error.</span></span></span></span></p>
<p><span><span><span><span>Just as many of our frontline health workers like nurses who were in contact with COVID patients got the virus from those patients during level 4 lockdown, our frontline border and airline staff and staff in our managed isolation facilities are in daily contact with returnees carrying the virus. Even our most experienced and trained support workers have picked up COVID.</span></span></span></span></p>
<p><span><span><span><span>Experts tell us that even with the best precautions possible, the chances of the virus passing from a surface, or contact with someone who is a carrier are high. </span></span></span></span></p>
<p><span><span><span><span>We must prepare now for that eventuality and have a plan at the ready in the event that it does. </span></span></span></span></p>
<p><span><span><span><span>The first thing we need to do is continue to ensure our border and our managed isolation facilities stay as tight as they can be. </span></span></span></span></p>
<p><span><span><span><span>We have ensured our frontline workers at the border are safe by wearing appropriate PPE, getting regularly tested and that our systems for managing returnees are robust and limit the risk of spread. As I say the system has done the job it was set up to do to date. </span></span></span></span></p>
<p><span><span><span><span>The work done by Minister Woods and Air Commodore Webb in recent weeks have made significant additional improvements in this space, and we will continue to improve the system. Australia is currently conducting an audit of its quarantine system and I’ve asked Prime Minister Morrison to share any insights so we can continually learn and improve on what we do here. </span></span></span></span></p>
<p><span><span><span><span>But again, no system is 100% fool proof and around the world we are seeing even the most rigorous measures being tested by the virus. </span></span></span></span></p>
<p><span><span><span><span>And so today I am setting out the next stage in our COVID plan in the event we have new cases in the community. </span></span></span></span></p>
<p><span><span><span><span>The first thing to note is that the Government’s strategy for responding to the COVID-19 pandemic remains elimination. That has not and will not change. </span></span></span></span></p>
<p><span><span><span><span>Allowing our hospitals to be overrun, further deaths and the economy to close down again for an indefinite period of time is not a strategy.</span></span></span></span></p>
<p><span><span><span><span>We have seen overseas the toll that that takes on lives and economies.</span></span></span></span></p>
<p><span><span><span><span>We have said from the start that the best approach for the economy is a strong health response, and the evidence has supported that approach throughout.</span></span></span></span></p>
<p><span><span><span><span>We can already see that with New Zealand’s economy more open than nearly anywhere in the world because of the steps we took to break the chain of transmission under lockdown. </span></span></span></span></p>
<p><span><span><span><span>Our plan moving forward seeks to protect that position and minimise any economic impact of future cases. </span></span></span></span></p>
<p><span><span><span><span>So in the event of new community cases we would move immediately to implement our “Stamp it Out” approach again.&nbsp; </span></span></span></span></p>
<p><span><span><span><span>There are two key things to remember.</span></span></span></span></p>
<p><span><span><span><span>Firstly, the simple approach of limiting the ability for the virus to move from human to human to break the chain of transmission remains the foundation of our response no matter what. </span></span></span></span></p>
<p><span><span><span><span>That’s why our key public health measures remain important for protecting ourselves and each other from the spread of disease. They are: </span></span></span></span></p>
<p><span><span><span><span>-&nbsp; wash your hands regularly and thoroughly </span></span></span></span></p>
<p><span><span><span><span>- cough or sneeze into your elbow </span></span></span></span></p>
<p><span><span><span><span>- don’t go to work, socialise, or be out in public if you are sick </span></span></span></span></p>
<p><span><span><span><span>- Keep a digital diary of your whereabouts by downloading and using the COVID Tracer app. </span></span></span></span></p>
<p><span><span><span><span>These principles are key to the second ongoing tool in our response. </span></span></span></span></p>
<p><span><span><span><span>Rapid contact tracing, testing, and use of isolation and quarantine for those exposed to COVID. That is why the Covid tracer app, and whatever other means of recording where you have been remains vital. Every time you step into the world I want you to ask this question “if I come into contact with COVID today, how will I know, and how will others know”. </span></span></span></span></p>
<p><span><span><span><span>If you are in or near a situation of community transmission this will be an exceptionally important tool for contact tracing, and for finding you. </span></span></span></span></p>
<p><span><span><span><span>In this area we are constantly looking at how we can use new technology to strengthen our response, the same goes for testing. </span></span></span></span></p>
<p><span><span><span><span>But these are the principles we are all familiar with. Now I want to touch on what would be different.</span></span></span></span></p>
<p><span><span><span><span>The alert level system and framework remains in place. But in the event of cases, rather than apply the framework nationally, we would look to apply our Alert Level system at a localised or regional level in the first instance.&nbsp; </span></span></span></span></p>
<p><span><span><span><span>Our priority will be to control any cases with the least intrusive measures, and over the smallest area we can.&nbsp; </span></span></span></span></p>
<p><span><span><span><span>In practical terms that means doing absolutely everything possible to avoid the entire country returning to Alert Levels 3 or 4 as a measure of last resort.&nbsp; </span></span></span></span></p>
<p><span><span><span><span>“Our ‘Stamp it Out’ approach is scenario specific meaning that our actions will depend on the severity of the situation. </span></span></span></span></p>
<p><span><span><span><span>And of course when we see the first COVID-19 case beyond the border, you can expect us to move very quickly and very firmly to contain it while we gather information on the situation we are facing. </span></span></span></span></p>
<p><span><span><span><span>However there are three broad starting scenarios we can plan around. </span></span></span></span></p>
<p><span><span><span><span>1. A case or a number of cases in a community. </span></span></span></span></p>
<p><span><span><span><span>2. A larger number of cases or cluster in a region</span></span></span></span></p>
<p><span><span><span><span>3. Multiple clusters that have spread nationally</span></span></span></span></p>
<p><span><span><span><span>Let me run through what each scenario might look like. </span></span></span></span></p>
<p><span><span><span><span>First a contained case or cases within a community.</span></span></span></span></p>
<p><span><span><span><span>We would be looking at applying strong restrictions but only applied locally in a neighbourhood, town or city to contain the virus and stopping it spread. </span></span></span></span></p>
<p><span><span><span><span>We would likely remain at Alert Level 1 nationally. </span></span></span></span></p>
<p><span><span><span><span>The local measures to contain the case would involve rapid contact tracing and isolation of cases and their contacts, scaled up and targeted testing of people connected to the case, such as workmates, those they live with or those in their neighbourhood. </span></span></span></span></p>
<p><span><span><span><span>The point with this scenario is we would look at act hard and fast, but local in an attempt to ring fence the virus.&nbsp; </span></span></span></span></p>
<p><span><span><span><span>The second scenario is a large cluster within a region. </span></span></span></span></p>
<p><span><span><span><span>Here, a significant increase in testing would be the priority. We would look to undertake much wider community testing, on top of testing any contacts or potential contact of those with the virus. This could look like it did in Victoria where health staff went door to door to test people in affected areas. </span></span></span></span></p>
<p><span><span><span><span>We would also take steps to stop the spread to other parts of the country so a regional shift in Alert Level would likely be applied that restricted travel. This would mean travel in or out of the city, town or region could be stopped, people in that place asked to work from home, and local restrictions on gatherings implemented. </span></span></span></span></p>
<p><span><span><span><span>The aim here is to contain the spread away from other areas to avoid the whole country having to put in place restrictions so we can remain at Alert Level 1 nationally, depending on the evidence of risk of spread outside the region. </span></span></span></span></p>
<p><span><span><span><span>The final scenario is if multiple clusters, spread nationally. </span></span></span></span></p>
<p><span><span><span><span>In this scenario we would …</span></span></span></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.beehive.govt.nz/speech/next-steps-covid-response">https://www.beehive.govt.nz/speech/next-steps-covid-response</a></em></p>]]>
            </description>
            <link>https://www.beehive.govt.nz/speech/next-steps-covid-response</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842977</guid>
            <pubDate>Wed, 15 Jul 2020 09:31:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux 4K Demo Development]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23842875">thread link</a>) | @onidaito
<br/>
July 15, 2020 | https://benjamin.computer/posts/2020-07-15-nova.html | <a href="https://web.archive.org/web/*/https://benjamin.computer/posts/2020-07-15-nova.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

	<a href="https://benjamin.computer/"><img src="https://benjamin.computer/images/bcpu_04_flat.png" alt="benjamin.computer"></a>
  
	<ul>
	<li><a href="https://benjamin.computer/about.html">ABOUT</a></li>
	<li><a href="https://benjamin.computer/atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide Atom feed">RSS</a></li>
	<li><a href="https://mastodon.social/web/accounts/220949">MASTODON</a></li>
	<li><a href="https://www.github.com/onidaito">GITHUB</a></li>
	<li><a href="mailto:me@benjamin.computer">EMAIL</a></li>
	</ul>
 

<hr>

<p><h2>My First Demoscene production</h2></p> 
<em>15-07-2020</em> 
<p>This year, I made my first ever demo! I've been threatening to do so for ages now, but since the lockdown hit, I've really had no excuse not to. For these of you unfamiliar with the demoscene, it's a small, yet internationally recognised[^0] subculture revolving around computer art. Some of the best programmers and artists produce works for all sorts of computers and electronic equipment, pushing the machines and themselves to the very limit! There are demoscene parties taking place all over Europe (and some further afield). I entered <a href="http://novaparty.org/">NOVA</a> this year - the UK's main demoscene party, and had great fun doing so.</p>
<h3>Demos and the Demoscene</h3>
<p>The demoscene has been around for a while now. It started out when crackers learned to break the copy protection on games. To show off their prowess, these expert programmer-pirates would leave messages at the beginning of the game. These messages often had music, scrollers, custom art. You can draw quite a few parallels to graffiti work, and I mean <em>really good</em> graffitti work! Some of these <em>'cracktros'</em> are incredible! The crackros became the main event, and the demoscene was born.</p>
<p>Back in these days, before the internet, demos were distributed via disk or bulletin boards. You could swap disks with folks you knew, dial into a modem and download, get disks in the mail, or go to a demoparty. Demo parties are still going today, stronger than ever one could argue. The largest Demoscene party is <a href="https://2019.revision-party.net/">Revision</a>, held in Saarbrucken, Germany. I've been a couple of times - you'll see some of the finest computer art in the world at this event! </p>
<p>Parties tend to be built around competitions. There are several categories and you can enter as many as you like. The competitions range from oldschool demos, such as these written for the <a href="https://en.wikipedia.org/wiki/Amiga">Amiga</a> or the <a href="https://en.wikipedia.org/wiki/ZX_Spectrum">ZX Spectrum</a>, to 64K PC Demos - where the size limit is 64K. There are competitions for music, ranging from new school to tracked, and also competitions for Pixel Art and digital photography. Something for everyone.</p>
<p>Quite often, folks will get together to form a demoscene group. Musicians, teaming up with programmers and illustrators to create entries none of them could do on their own. Some of these groups have been going for decades, albeit with different members.</p>
<p>In the past, computers were a bit more restrictive than they are now. 3D rendering on the Amiga is quite the task whereas it's quite trivial on a modern PC. To keep up the challenge, a set of size-coding competitions were devised. The idea is fairly simple - see how much you can do with 64K, 8K or 4K. Some competitions even go as far down as 256 Bytes[^3]! For reference, an average email is around 400 Kilobytes.</p>
<iframe width="881" height="496" src="https://www.youtube.com/embed/JZ6ZzJeWgpY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>Some of these competition entries are absolutely fabulous. One of my favourites is <a href="http://www.pouet.net/prod.php?which=67113">Fermi Paradox</a>; a 64k entry by the demogroup <a href="https://mercury.sexy/">Mercury</a>. I'm still amazed that not only can so much be packed into such a small space, but that so much can be <em>said</em> in a short space of time. The programming skill is only matched by the art.</p>
<h3>Linux 4K</h3>
<p>One of the things I've noticed is there are very few Linux demos. This sounds odd to me as Linux is quite the open platform, at least compared to Windows. However, Windows has been the mainstay of the PC demoscene for much of the scene's history. I think this is because the graphics drivers tend to be better, Windows setups are much more homogeneous (you can generally rely on certain libraries being around), and more of a history of the kinds of hacking techniques often used in demo production. As more demos were released for Windows, more demotools became available. Tools such as <a href="http://crinkler.net/">crinkler</a>, which compresses your demos down to a tiny size, to the <a href="https://github.com/laurentlb/Shader_Minifier">shader minifier</a>. Linux hasn't got there yet with it's tooling, until recently.</p>
<p>Thanks to the efforts of <a href="https://bitbucket.org/blackle_mori/scalemark/src/master/">Blackle</a> and <a href="https://gitlab.com/PoroCYon/linux-4k-intro-template">poroCyon</a>, we now have a starting template for Linux 4K entries. I took a look at how the template was built up. There seems to be the following processes:</p>
<ul>
<li>Compress the shaders into a header file with shader minifier</li>
<li>Build the object files with some embedded assembly (which I don't understand!)</li>
<li>Strip out any of the bits of the ELF Header we don't need. </li>
<li>Link everything together with the <a href="https://github.com/Shizmob/smol">Shoddy minsize-oriented linker (SMOL)</a></li>
<li>Compress everything with the <a href="https://in4k.github.io/wiki/lsc-wiki-vondehi.html">vondehi</a> program.</li>
</ul>
<p>Vondhehi is quite funky! The decompressor itself is loaded into your program and decompresses the rest of the program once the program is run. </p>
<p>There are no doubt other subtle things going on. If you want to know more, <a href="https://www.youtube.com/watch?v=a03HXo8a_Io">there is a talk from Revision you can watch</a> that explains the process in more detail. The code-base itself seems a little complicated but some of that is down to the tools being made for windows; there is a dependency on <a href="https://www.mono-project.com/">Mono</a> (among other things) for example. Nevertheless, it's quite possible to get down to an executable of 4K or smaller.</p>
<figure><img src="https://shutr.benjamin.computer/inpost/numenera1.jpg" alt="Generating protein images."><figcaption>Screenshot from within the mysterious Menger Sponge!</figcaption></figure>

<p>This demo runs on every Linux setup I've tested it on. The de-facto standard for demoparties seems to be Ubuntu (at the time of writing, Ubuntu 18 for Revision). All size coding demos rely on some libraries being pre-installed. Unlike Windows, there is no guarantee you'll have the library you want installed under Linux, so this template comes with three options for the OpenGL context: SDL2 and GTK3. I went with SDL2 in the end, as it resulted in a slightly smaller filesize.</p>
<h3>Music</h3>
<p>Definitely my weakest area this one. I had no idea where to begin. Thankfully the template is setup to use a tracker or synthesizer. I honestly don't know how this bit works but after looking around briefly, I found a program called <a href="https://www.renoise.com/">Renoise</a>. Apparently, there are set of instruments made by demosceners that can be loaded into renoise, whereupon you can make your soundtrack. These instruments tend to compress rather well it is claimed. <a href="https://github.com/askeksa/Oidos">Oidos</a>, <a href="http://4klang.untergrund.net/">4KLang</a> and <a href="http://www.pouet.net/prod.php?which=61592">Clinkster</a> are recommended in the template. I decided to go with Clinkster for no real reason at all. </p>
<p>Renoise is a Windows program unfortunately, but it seems to run well enough under <a href="https://www.winehq.org/">Wine</a>. I could create a tracked piece of music fairly quickly (I use music in the loosest possible sense of the word!). With the file placed in the right directory, the template makefile rolls it in quite easily.</p>
<p>If you want to know more about demoscene music and listen to the work of someone who really knows what they are doing, check out <a href="https://soundcloud.com/h0ffman">h0ffman</a>. He has <a href="https://hoffman.home.blog/2019/04/27/eon/">a good write-up on his site</a> about the kinds of hoops a demoscener composer needs to jump through.</p>
<h3>Raymarching Menger Sponges</h3>
<p>With everything in place, I set to. I'd wanted to learn a bit more about fractals and how they are rendered. I started with the <a href="https://en.wikipedia.org/wiki/Menger_sponge">Menger sponge</a> -  a classic fractal. I like the look of it! Something weirdly alien yet constructed. I thought I'd use this as the main feature around which this intro would be based.</p>
<p>Normally, fractals are described using <a href="https://en.wikipedia.org/wiki/Recursion">recursion</a>. It's an elegant way of of generating an image as fractals are self similar. However, in a fragment shader, this isn't possible.</p>
<p>It's worth mentioning what a <a href="https://www.khronos.org/opengl/wiki/Fragment_Shader">fragment shader</a> is. In early 3D graphics, the pipeline that took your triangles and spat out pixels on your screen was fixed; you couldn't really tweak it. Nowadays, you can alter the functionality of many different sections of the pipeline using small programs called <em>shaders</em>. The fragment shader is the last shader in the line before the pixels appear. It's sometimes called a pixel shader too, though you aren't manipulating pixels at this point (well, you are close enough I guess). </p>
<p>The fragment shader is where all the graphics magic happens. You are given a fragment and you output a colour for that fragment. The in-between step is where the fun is. We can use a technique known as raymarching. </p>
<p>Raymarching (or Volume Ray Casting) is used all over the place in a lot of demos; it's a powerful technique. Similar to raytracing, you shoot a ray from your camera through the screen at the fragment position. You then need to find out what this ray hits. To do that, you use a <a href="https://prideout.net/blog/distance_fields/">distance field</a>.</p>
<p>Distance fields are a parametric way of defining a scene. The simplest example is a sphere. A sphere can be defined as a 3D point and a radius - 4 numbers. From these four numbers you can figure out the distance from where your ray is, to the sphere, even figuring out where on the sphere your ray will intersect. The next step is to <em>march the ray</em> that distance and then check again how far away you are. </p>
<p>You can build up an entire scene this way, with multiple objects, creating realistic lighting, special effects and more! It's a really powerful technique made famous by the website <a href="https://www.shadertoy.com/">Shadertoy</a> and it's creator, <a href="https://iquilezles.org/">Iniqgo Quilez</a>. His site details a number of <a href="https://iquilezles.org/www/articles/distfunctions/distfunctions.htm">mathematical formulas for distance fields</a> though I can't claim to understand most of them. However, we can do all this in a single pixel shader.</p>
<p>Back to our Menger sponge then. If we can do it recursively, we'll have to go iteratively. One way we can create the sponge is to start with a field for a large cube and effectively carve out the holes using smaller cuboids and a subtraction function. Turns out all of these are easy to do in a fragment shader if you have the right functions. An excellent set of such functions can be found on <a href="https://mercury.sexy/">Mercury's homepage</a>.</p>
<h3>Numenera</h3>
<p>Back to our demo. I had the idea of using a Menger Sponge but no idea on the actual <em>art</em>. Where to begin? What was a trying to say? I must admit, this bit really took me by surprise how hard it was! I suppose that's a bit of a cliche right - the engineer trying to do an art? Still, undeterred, I'd been reading a little about the roleplay game <a href="https://en.wikipedia.org/wiki/Numenera">Numenera</a>. I liked the idea of long lost advanced technology. I pictured a desert, with an ancient and worn down artefact, suddenly coming alive as we observe it. I had an idea, so off I went!</p>
<p>The desert part is quite easy - it's just a plane with a noise offset on the distance field. I used Iq's lighting model for the shadows and the ambient occlusion. With …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://benjamin.computer/posts/2020-07-15-nova.html">https://benjamin.computer/posts/2020-07-15-nova.html</a></em></p>]]>
            </description>
            <link>https://benjamin.computer/posts/2020-07-15-nova.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842875</guid>
            <pubDate>Wed, 15 Jul 2020 09:13:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microsoft have no intentions of paying for submitted vulnerabilities]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23842758">thread link</a>) | @pabs3
<br/>
July 15, 2020 | https://twitter.net/jonasLyk/status/1282945750746509313 | <a href="https://web.archive.org/web/*/https://twitter.net/jonasLyk/status/1282945750746509313">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://twitter.net/jonasLyk/status/1282945750746509313</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842758</guid>
            <pubDate>Wed, 15 Jul 2020 08:51:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Late-life restoration of mitochondria reverses cardiac dysfunction in old mice]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23842748">thread link</a>) | @JPLeRouzic
<br/>
July 15, 2020 | https://padiracinnovation.org/News/2020/07/late-life-restoration-of-mitochondrial-function | <a href="https://web.archive.org/web/*/https://padiracinnovation.org/News/2020/07/late-life-restoration-of-mitochondrial-function">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    						
					                    <p>
                        <span itemprop="datePublished">15 July 2020</span> - Posted in 
                        <span itemprop="articleSection"><a href="https://padiracinnovation.org/News/category/english">English</a></span> by 
                        
                    </p>
                </div><div itemprop="articleBody">                                   
                    <p><a href="https://elifesciences.org/articles/55513">The article discussed here</a> is not related to neurodegeneration diseases, it discusses about heart failure, however it might have implications for ALS.
While most ALS targeting therapies might aim at reducing TDP-43 aggregates (and similar protein aggregates in other neurodegenerative diseases), humans are indeed more than bags of identical cells, they are first living because they are composed of a multitude of physiological systems that interact to maintain homeostasis.
So even if a therapy was invented that would efficiently remove TDP-43 aggregates, ALS patients would still be unable to recover health as motor neurons do not rejuvenate nor are replaced with newer cells. As this heart failure treatment improves heart muscle cells, it should also to some degree improve motor neuron cells.
This article is also interesting as it mentions some drugs that are discusses ALS online internet forums, such as glutathione, N-Acetyl Cysteine (NAC) and Glycine.</p>

<p>This article explains precisely how some muscle cells seem to rejuvenate when a specific peptide is administrated. Very roughly: With this peptide, metabolism is rejuvenated at cellular level, so cells can use more energy, something which is clearly lacking in ALS cells which are characterized by hypermetabolism.  Humans produce and consume about 65 kg of ATP every day. Because ATP cannot be stored, it is critical that the rate of ATP synthesis matches the rate of ATP consumption. The primary role of mitochondria is the generation of adenosine triphosphate (ATP) from adenosine diphosphate (ADP) using macromolecular complexes that form the electron transport chain.</p>

<p><img src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7000886/bin/gr3.jpg" alt="enter image description here"></p>

<p>Mitochondrial dysfunction is one of the hallmarks of aging. While mitochondria generate the
bulk of cellular ATP, they are also the major source of reactive oxygen species (ROS) in most
cells. ROS are sub-products inherent to ATP metabolism.</p>

<p>Aging is the strongest risk factor for cardiovascular diseases. It is also accompanied by a
decline in cardiac function, especially diastolic dysfunction and hypertrophy of the left ventricle
and left atrium. The heart is rich in mitochondria and has a high metabolic demand; therefore,
it is highly susceptible to oxidative damage and the effects of mitochondrial dysfunction.
Increasing evidence suggests that mitochondrial oxidative stress and mitochondrial dysfunction
play critical roles in cardiovascular diseases and cardiac aging.</p>

<p>The mitochondrial-targeted tetrapeptide SS-31 (elamipretide), is a pharmacologic intervention that selectively concentrates in mitochondria, suppressing mitochondrial ROS and increasing skeletal muscle ATP production. Elamipretide (also named SS-31, MTP-131, Bendavia) is sold by Stealth BioTherapeutics, Newton, Massachusetts. It is a water-soluble, aromatic-cationic mitochondria-targeting tetrapeptide that readily penetrates and transiently localizes to the inner mitochondrial membrane and associates with cardiolipin to restore mitochondrial bioenergetics</p>

<p>it has not been established whether delivering such interventions in later life can rescue pre-existing mitochondrial and cardiac dysfunction. In this study, the authors demonstrate that mitochondrial-targeted interventions can improve mitochondrial function and reverse pre-existing cardiac dysfunction in old mice.</p>

<p>To determine the effects of SS-31 treatment on cardiac function in old mice, the scientists treated 24-month-old mice with the SS-31 peptide or saline control and examined cardiac function by echocardiography after 4 and 8 weeks of treatment.</p>

<p>SS-31 treatment was effective in aged hearts with pre-existing mitochondrial dysfunction but had little effects in young hearts with normal functioning mitochondria.</p>

<p>The authors acknowledge that the persistence of SS-31 induced functional benefit varied between individual mice. Other studies have reported negative effects of targeting mitochondrial ROS. In another study, suppression of mitochondrial ROS in mice resulted in impaired macrophage bactericidal activity.</p>

<p>However not everything is rosy, elamipretide is known since quite some time and had been tested in several different diseases. Recently it did not meet expectations stemming from promising early trial results in patients with primary mitochondrial myopathy (PMM), data from a Phase 3 (NCT03323749) trial show.</p>
                </div></div>]]>
            </description>
            <link>https://padiracinnovation.org/News/2020/07/late-life-restoration-of-mitochondrial-function</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842748</guid>
            <pubDate>Wed, 15 Jul 2020 08:50:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Return on Investment for Machine Learning]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23842652">thread link</a>) | @arauhala
<br/>
July 15, 2020 | https://aito.ai/blog/return-on-investment-for-machine-learning/ | <a href="https://web.archive.org/web/*/https://aito.ai/blog/return-on-investment-for-machine-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote><p>This post appeared first on <a href="https://towardsdatascience.com/return-on-investment-for-machine-learning-1a0c431509e">Towards Data Science</a> on July 8th, 2020.</p></blockquote><p>Machine learning deals with probabilities, which means there’s always a chance for mistakes. This inherent uncertainty causes many decision makers feel uncomfortable with implementing machine learning and traps them in an endless chase for the magical 100% accuracy. The fear of mistakes nearly always pops up when I’m working with companies taking their first steps towards intelligent automation, and I get asked “What if the algorithm makes a wrong prediction?”</p><p>If this issue is not addressed, the company will very likely spend a hefty amount of resources and years of development time on machine learning without ever getting returns for their investment. In this article, I’ll show you the simple equation I use to relieve these concerns and get decision makers more comfortable with the uncertainty.</p><h3>When is machine learning worth it</h3><p>Just like with any investment, the feasibility of machine learning comes down to whether it generates more value than it costs. It’s a normal Return on Investment (ROI) calculation which, in the context of machine learning, weighs the generated value against the cost of mistakes and accuracy. So instead of asking “How do we get 100% accuracy?”, the right question is “How do we maximize ROI?”</p><p>Determining the expected returns is quite straightforward. I usually begin opening up the business case for machine learning implementation by comparing its benefits against the potential costs in mathematical terms. This can be formalized in an equation which basically says “What’s left of the generated value after the cost of mistakes is accounted for?” Solving this simple equation allows us to estimate the profits for different scenarios.</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/roi_simple.png" alt="returns = value - (1 - accuracy) * cost of a mistake"></p></div></div><p>Let’s look at the variables:</p><ul><li><strong>returns</strong>: Generated net value or profit per prediction  </li><li><strong>value</strong>: The new value generated by every prediction (e.g. assigning a document to the right category now takes 0.01 seconds instead of 5 minutes, so the value is 5 minutes saved)  </li><li><strong>accuracy</strong>: The accuracy of predictions made by the algorithm  </li><li><strong>cost of a mistake</strong>: The additional costs incurred by a wrong prediction (e.g. it takes 20 minutes for someone to correct the mistake in the system)  </li></ul><p>By flipping the equation around and setting returns to zero, we get the minimum accuracy required to generate net value. This is called <strong>break-even accuracy</strong>:</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/roi_simple_flip.png" alt="accuracy = 1 - (value / cost of a mistake)"></p></div></div><p>The equation gets more intuitive when plotted in a graph:</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/roi_simple_graph.png" alt="Break-even point visualized"></p></div></div><p>So let’s say each prediction saves you 5 minutes of work but it takes 20 minutes of extra work to fix a wrong prediction. We can now calculate the break-even accuracy to be 1–5/20 = <strong>75%</strong>. Any improvement after this point brings concrete profits.</p><p>The above equation assumes us to blindly accept any prediction the algorithm makes and fix the errors afterwards. Sounds risky? We can do much better by extending the equation with confidence scores to lower the risks.</p><h3>Optimizing ROI</h3><p>A machine learning algorithm (done right) does not only spew out predictions, it also tells us how confident it is in every prediction. The majority of mistakes happen when the algorithm is unsure of its answer, allowing us to focus automation on the highest certainty predictions while manually reviewing the lowest few. Even though manual review does cost a bit of labor, it’s normally much cheaper than fixing a mistake later on.</p><p>Let’s choose a threshold which picks out 10% of the least confident predictions for manual review. The rest 90% will be handled automatically. This ratio is called confidence split. The accuracy in the high confidence bracket will now be considerably better since many of the mistakes are caught in the small unconfident bracket. This leads us to the extended equation. It says “What’s left of the generated value after the costs of mistakes and manual review are accounted for?”</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/roi_extended.png" alt="returns = (value - (1 - confident accuracy) * cost of a mistake) * confidence split - (1 - confidence split) * cost of manual review"></p></div></div><p>Let’s look at the variables:</p><ul><li><strong>returns</strong>: Generated net value or profit per prediction  </li><li><strong>value</strong>: The new value generated by every prediction  </li><li><strong>confident accuracy</strong>: The accuracy of predictions in the high confidence bracket  </li><li><strong>cost of a mistake</strong>: The additional costs incurred by a wrong prediction  </li><li><strong>confidence split</strong>: The ratio of high confidence predictions (90% in our case)  </li><li><strong>cost of manual review</strong>: The costs of manually reviewing the prediction  </li></ul><p>We can again flip the equation to calculate the break-even accuracy by setting returns to zero, like so:</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/roi_extended_flip.png" alt="confident accuracy = ((1 - confidence split) * cost of manual review) / (confidence split * cost of a mistake) - value / cost of a mistake + 1"></p></div></div><p>We’ll solve it using the following variables:</p><ul><li>value = 5 minutes saved  </li><li>cost of a mistake = 20 minutes  </li><li>cost of manual review = 5 minutes  </li><li>confidence split = 0.9  </li></ul><p>Now the new break-even accuracy is 78%. Wait a minute, that’s higher than with the simpler equation, did it just get worse? Not quite! Remember that many of the mistakes are caught in the low confidence bracket, which significantly boosts the accuracy in the high confidence bracket. Even though the minimum accuracy requirement for break-even got higher, it is now much easier to achieve.</p><p>The ability to calculate the profitability of a machine learning algorithm in operation allows you to find the optimal accuracy. And no, it’s not 100%. As I discussed in my previous article, the development cost of any system increases exponentially while providing diminishing returns. With the above equations, you can estimate a realistic ROI and calculate the point where accuracy improvements incur more development costs than increase in returns in a time-frame of your choice. That’s the ROI-optimized accuracy.</p><h3>Practical example</h3><p>Let’s take a real world scenario and run through the whole thing. Imagine your Accounts Payable team handles 5000 invoices every month, and you’ve been presented the idea of automating a part of the process. More specifically, the proposed automation would categorize incoming invoices to match complex internal vendor codes, which is currently done manually. You need to figure out whether a machine learning approach is worth the effort to solve this task.</p><p>In terms of data, below is what you’ll be working with. You have a history of previously processed invoices and the correct “Vendor_Code” value for each. The task is to predict the right “Vendor_Code” for any new invoice. You can find the original dataset <a href="https://www.kaggle.com/nikhil1011/predict-product-category-from-given-invoice/data#Train.csv">here</a>.</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/roi_data.png" alt="Sneak peet at the data"></p></div><p><span>Sneak peet at the data</span></p></div><p>To start off, use any machine learning library or tool you prefer and run a basic accuracy test for the data. I’m using aito.ai which gives me an accuracy of 78% after training with 4000 rows and testing with 1500 rows. If we use the same values and costs as before, we can calculate the monthly returns with the first equation:</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/roi_calc_simple.png" alt="returns = 5 minutes - (1 - 0.78) * 20 minutes = 0.59 minutes"></p></div></div><p>Using the simple approach which ignores the confidence scores, every prediction made by the algorithm with 78% accuracy saves you on average 0.59 minutes of work, or 35 seconds. That means almost <strong>50 hours of work saved every month</strong> from processing 5000 invoices. Not bad.</p><p>Now let’s look at the equation which considers confidence scores. I compiled the results and confidence scores for each prediction into a neat table like below which allows us to divide them into high and low confidence brackets. In this case, any prediction with confidence lower than 0.21 will be reviewed manually. This threshold gives us the 90/10 confidence split.</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/roi_conf_table.png" alt="Prediction results, including confidence scores"></p></div><p><span>Prediction results</span></p></div><p>The accuracy in our high confidence bracket is an impressive 84%, and a measly 22% in the low confidence bracket. This makes the impact of utilizing confidence scores crystal clear. Now we can calculate the new returns when confidence and manual review costs are a part of the equation:</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/roi_calc_extended.png" alt="returns = (5 minutes - (1 - 0.84) * 20 minutes) * 0.9 - (1- 0.9) * 5 minutes = 1.15 minutes"></p></div></div><p>The extended approach nearly doubles the returns! Every prediction saves, on average, 1.15 minutes. Processing your 5000 monthly invoices now involves <strong>95 hours less work</strong> even when the cost of mistakes and manually reviewing 10% of the predictions are accounted for. That’s pretty great!</p><p>Now you know the level of profitability you can currently achieve. And even better, you now have a tool to determine the feasibility of further machine learning development. For example, with the equation, you may calculate the returns for a hypothetical 90% accuracy and find the returns to be <strong>183 hours saved monthly</strong>. Compare it to the estimated development costs of reaching the 90% accuracy and you’ll have factual data for deciding if further development is worth the investment.</p><h3>Summing it up</h3><p>As you’ve seen, machine learning should be approached just like any other investment. The inevitable mistakes are just a cost of doing business and they’re normal variables in our calculations. Armed with these equations, you know exactly when to start reaping the benefits of machine learning without playing a guessing game, and you can put the algorithms into production way earlier. Be freed from the endless grind towards 100% accuracy and start generating value already.</p><p><strong>Done is better than perfect.</strong></p><a href="https://aito.ai/blog">Back to blog list</a></div></div>]]>
            </description>
            <link>https://aito.ai/blog/return-on-investment-for-machine-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842652</guid>
            <pubDate>Wed, 15 Jul 2020 08:33:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Re: Garden of Forking Memes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23842509">thread link</a>) | @severine
<br/>
July 15, 2020 | http://subpixel.space/entries/re-garden-of-forking-memes/ | <a href="https://web.archive.org/web/*/http://subpixel.space/entries/re-garden-of-forking-memes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Aaron, I’ve been reflecting on your <a href="https://aaronzlewis.com/blog/2020/07/07/the-garden-of-forking-memes/">Garden of Forking Memes</a> essay. I’m so glad you’ve written such a comprehensive piece on this topic of subculture and history, and I’m honored you asked me to provide feedback on it. It gave me a lot of thoughts that I wanted to flesh out, so I’m responding here. I’m most interested to talk with you about something we’ve discussed a bit before, something which is left implicit in your essay: the disappearance and now reappearance of the future as an idea, and the question of from where the <em>actual</em> future will come.</p>

<blockquote darkmode="" data-title="The%20Garden%20of%20Forking%20Memes%3A%20How%20Digital%20Media%20Distorts%20Our%20Sense%20of%20Time" data-author="Aaron Z. Lewis" cite="https://aaronzlewis.com/blog/2020/07/07/the-garden-of-forking-memes">
The conversations of internet subcultures often feel substantive and expansive compared to the shallow discourse of presidential debates, op-ed pages, and cable TV shows. Mainstream news cycles rarely last more than a few hours, and their narratives are constantly shifting. They don’t tend to give a big-picture sense of where we came from or where we’re going. Internet subcultures, by contrast, are building grand narratives and <a href="https://www.ecosophia.net/the-kek-wars-part-one-aristocracy-and-its-discontents/" target="_blank" rel="noopener">meme worlds</a> that help people feel their way through the chaos that’s currently unfolding. These stories cut deep,&nbsp;down to the most foundational questions of race and religion and destiny. We shouldn’t be too surprised that complex conspiracy theories, intergenerational trauma, and age-old <a href="https://www.scribd.com/document/431359952/Peter-Thiel-The-Straussian-Moment" target="_blank" rel="noopener">religious</a> fervor are coming to the fore — in a contest of narrative memes, deep history is a serious competitive advantage.

</blockquote>


<p>This part of your essay recalled me to our last in-person conversation. In January, you and I were sitting in A/D/O, talking about all manner of things, when you pointed out that every trace of the future seems to have been vanished from popular media. Perhaps this observation was inspired by this sterile piece of public art, whose ceaseless revolutions into new, forgettable arrangements of panels we watched as we conversed.</p>

<p><img src="http://subpixel.space/uploads/ado-panels.jpg" alt="image of rotating panels"></p>

<p>Your observation certainly held true for prestige television: the most popular shows of the last decade have been either gritty realist tragedies (e.g. The Wire, Breaking Bad, even the family politics of Game of Thrones) and unimaginative alternative-now dystopias (e.g. Black Mirror, Handmaid’s Tale, Man in the High Castle). The same could be said for movies, with the addition of campy fantasy, and here I’m sure I showed you this classic David Rudnick tweet. And of course, it’s been said by many that contemporary critical theory seems to have abandoned a progressive agenda beyond enumerating endless variations of capitalism&nbsp;—&nbsp;the carceral, communicative, surveillance…. Even fiction appears to have lost its edge, with last year’s most lauded sci-fi-adjacent novels, Oval and Infinite Detail, failing to render a meaningful vision of the future in any way.</p>

<blockquote><p lang="en" dir="ltr">A training program to acclimatize the citizen under late capitalism to learn and love humanity's new role as spectator and occasional collateral damage in a society consisting of godlike megacorporations and their chaotic interactions? That would be The Marvel Cinematic Universe</p>— ཊལབསརངཧ (@David_Rudnick) <a href="https://twitter.com/David_Rudnick/status/1122271106805719040?ref_src=twsrc%5Etfw">April 27, 2019</a></blockquote>


<p>On the other hand, when optimistic ideas for the future <em>do</em> get proposed (such as carless cities or 100% renewable energy) they are often deemed either unrealistic, delusional, or fiction by mainstream media. I recall coming to the hilarious and grim conclusion that the only type of pop media where a vision of the future is taken seriously is the “request for startup” variety of venture capitalist blog posts. Unfortunately this half-joke was borne out later this year with Marc Andreessen’s TIME TO BUILD essay managing to inspire and invigorate thousands, despite containing no plan for what specifically we should be building towards.</p>

<p>Returning to your essay, it seems that history actually <em>has</em> ended in some meaningful way within mainstream consciousness. While the entire media environment today operates under stream logic — involving&nbsp;the continuous production of new pseudo-events —&nbsp;what is different about legacy 20th-century media institutions is that their discursive progression is wholly ignorant of the past. The evolving discourse of new internet native subcultures, on the other hand, <em>continues to produce history by incorporating new historical facts into themselves.</em> I hope readers take your line “deep history is a serious competitive advantage” literally. Internet-native groups seek out historical events not only because they are politically aware, but because they are in competition with other ideological streams. To combine with Louise Druhle’s analogy, they are under selective pressure to increase their gravitational pull, and in doing so are producing significantly more compelling narratives than mainstream media.</p>

<p>One thing I’m unclear on is why history disappeared from mainstream consciousness in the way it did. Mark Fisher would say that neoliberal subjectivity corrodes one’s imaginary capabilities&nbsp;—&nbsp;the “slow cancellation of the future.” Philip Mirowski would be more explicit, arguing that neoliberal doctrine has had such patently devastating consquences for the working person that it has needed to obscure the origin of its crises and actively shape public discourse to protect itself. I’d also speculate about the separation of public and private spheres we currently tend to make, and the separation of home life, public life, and civic life, both of which also go back to the 70s, but I know little about those things. I guess a good generalization inclusive of all of the above would be that culture is in many ways downstream of capital.</p>

<p>On the other hand, mainstream media may have become ignorant of history as a psychological defense. The development of <a href="https://twitter.com/tobyshorin/status/1273296665416515585">multihistories</a> and memetic competition is just another way of saying the culture war. While we’ve all gotten used to living in a persistent conflict zone, it’s not exactly fun. Under these conditions, the mainstream world of lukewarm takes and forever-breaking news cycles, this Disneyfied universe of crossover events, characterized by the ambient listlessness of memory lapse, provides a sort of dull respite for the mind strained by ideological battle. Do you think this purgatory can last? What is its relationship with centrism? Personally, I’d guess any relief mainstream consciousness provides is illusory. The mainstream is under attack from all sides, with groups of all types attempting to seize its ideological ground. The best defense against ideology remains ideology.</p>

<p>Then there are nomadic anthropologists like you and I. So far, we haven’t declared a side. Up until now I’ve preferred to play the merchant, traveling from tribe to tribe, here selling a rare gem, there performing a clever trick learned far away, collecting oddities and fragments of wisdom as I make my living on the spice route.</p>

<hr>

<blockquote><p lang="en" dir="ltr">The futures we envision never appear, receding into memory like dreams... The real future merges fluidly into the present, forcing revisions, mergers, and forks of historical streams of consciousness....</p>— Toby (@tobyshorin) <a href="https://twitter.com/tobyshorin/status/1273297245853663235?ref_src=twsrc%5Etfw">June 17, 2020</a></blockquote>


<hr>

<p>You ask:</p>

<blockquote darkmode="" data-title="The%20Garden%20of%20Forking%20Memes%3A%20How%20Digital%20Media%20Distorts%20Our%20Sense%20of%20Time" data-author="Aaron Z. Lewis" cite="https://aaronzlewis.com/blog/2020/07/07/the-garden-of-forking-memes"> How does the immediate accessibility of so many alt histories undermine our ability to create shared futures?

</blockquote>


<p>But if all we’ve said before is true, doesn’t it follow that the actual future of humanity will develop not out of mainstream consciousness but out of one or more of these subcultures with a view of big history. In his New Models interview, Venkat mentioned something along these lines: that while inventing the future once took the ambition and charisma of an Elon Musk or an Edison, it’s now realistic to be able to invent the future for a few thousand citizens of one’s small-scale subjective reality.</p>

<p>That’s one reason why at some point, I think it’s more virtuous to choose the future we want to live in than to arbitrage from culture to another. Personally, I’ve never been able to avoid writing moralizing conclusions to my own essays, and these days I’m inclined to push myself further in that direction. I think that’s my biggest difference from Venkat, and the source of my biggest disagreement with him. What’s the point of developing Correct Opinions if you don’t use them to actualize the future you believe in? That’s one reason I’ve been addressing my writing slightly more toward a business audience. We <em>are</em> living in a liminal time, a time with high tolerance (outside the mainstream) for new ideas and experiments with new ways of living. We have higher leverage than we think.</p>

<p>One area I’m investing time into thinking about is new ownership models and ways of dealing with capital. I don’t understand monetary policy and I’m not particularly knowledgeable about economics, but it’s clear to me that we need new ways of understanding and allocating value the networked 21st century. I believe many of the co-ownership experiments happening in cryptocurrency communities can be made less esoteric and ported to areas outside. Capital ownership is a counterbalance to wage stagnation. Economists say that wealth has universal	 power laws, but designable economic models can surely make the curve more equitable. That’s a future worth working towards, IMO.</p>

<p>To what groups and ideas have you been hitching your camel? What history do you believe everyone should acknowledge? And what future? Your essay left me with questions about the role of the individual. Identity has never been ahistorical, and history has never been apolitical, but now more than ever, our identity is a decision of historical politics. With a self awareness unmatched by any historical subject, we see who we walk alongside, and can choose our caravan. We may not all be history-makers, we are all at least history selectors.</p>

</div></div>]]>
            </description>
            <link>http://subpixel.space/entries/re-garden-of-forking-memes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842509</guid>
            <pubDate>Wed, 15 Jul 2020 08:07:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tech vs. Media: We Need a New Model of Truth]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23842362">thread link</a>) | @mehdiyac
<br/>
July 15, 2020 | https://www.mehdiyacoubi.com/post/iterative-model-of-truth | <a href="https://web.archive.org/web/*/https://www.mehdiyacoubi.com/post/iterative-model-of-truth">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.12.2"><div dir="ltr"><div><p id="viewer-foo"><em>New times call for new ways of finding the truth</em></p><div id="viewer-1i4li"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.mehdiyacoubi.com/post/iterative-model-of-truth" data-pin-media="https://static.wixstatic.com/media/caefc6_b809e6bb440e4a3881f817c2c94d0ca2~mv2.jpg/v1/fit/w_1600,h_1538,al_c,q_80/file.png" src="https://static.wixstatic.com/media/caefc6_b809e6bb440e4a3881f817c2c94d0ca2~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div><p><span>Veritas, goddess of truth in Roman mythology</span></p></div></div></div><p id="viewer-e9mbk"><span>We’re in January 2020. A new virus just appeared in China. What is going to happen in the following months will reveal everything that is wrong with one of the pillars of our societies: Truth.</span></p><div id="viewer-3sk6m"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.mehdiyacoubi.com/post/iterative-model-of-truth" data-pin-media="https://static.wixstatic.com/media/caefc6_ec5b098f28b04fecb0bccd5a2c761745~mv2.jpeg/v1/fit/w_5000,h_1332,al_c,q_80/file.png" src="https://static.wixstatic.com/media/caefc6_ec5b098f28b04fecb0bccd5a2c761745~mv2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div><p><span>Coronavirus headlines in January</span></p></div></div></div><p id="viewer-8gj82">The COVID-19 crisis showed our society isn’t equipped with the right systems to find the truth. Our current model is broken and we need to reinvent it!</p><p id="viewer-asqnc">In his <a href="https://en.wikipedia.org/wiki/Metaphysics_(Aristotle)" target="_blank" rel="noopener">Metaphysics</a>, Aristotle wrote:</p><blockquote id="viewer-3njpj"><p>“To say of what is that it is not, or of what is not that it is, is false, while to say of what is that it is, and of what is not that it is not, is true”.</p></blockquote><p id="viewer-1hd5d">Truth played many different roles throughout history. It served as a source of political authority, religious doctrine, cultural common ground, and scientific thinking.</p><p id="viewer-aro6r">With the development of science and scientific thinking, Truth became intrinsically related to scientific and factual knowledge.</p><p id="viewer-a987q">The German philosopher Enrich Fromm said:</p><blockquote id="viewer-bb6ml"><p>“The history of thought is the history of an ever-increasing approximation to the truth. Scientific knowledge is not absolute but optimal; it contains the optimum of truth attainable in a given historical period.”</p></blockquote><p id="viewer-c6tf1">Truth is what makes us understand things and progress. It helps us make the right decisions, act without prejudice or bias, and achieve optimal outcomes. Without Truth, we live in darkness, and society can’t thrive in the long term.</p><p id="viewer-avtn3">For example, in January, knowing the truth would have meant understanding the gravity of the virus in China which would have pushed us to act fast and potentially prevent it from spreading globally. That is not what happened, was it?</p><p id="viewer-eumsn"><a href="https://membership.theguardian.com/event/are-we-living-in-a-posttruth-era-34826634401" target="_blank" rel="noopener">Many argue</a> that we live in a “post-truth” era. It feels as if the concept of truth had lost its importance. But which truths are we talking about? There are personal truths, community truths, cultural truths, scientific truths… Some of these do not have anything to do one with another, scientific truths are very different from cultural truths. Here I will focus on scientific and factual truths.</p><p id="viewer-ad34j">If you take a look at the institutions people rely upon as a source of truth, you’ll discover that, at best, the information they provide is distorted, biased, or simply unreliable. At worst, you’ll immediately think “that’s a lie”.</p><h2 id="viewer-7bhim">Legacy Media</h2><p id="viewer-95upa">Media companies market themselves as “the source of infallible truth.” They aren’t seeking truth as a primary goal. How could we expect the truth from an entity that isn’t incentivized to produce it?</p><div id="viewer-fgr36"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.mehdiyacoubi.com/post/iterative-model-of-truth" data-pin-media="https://static.wixstatic.com/media/caefc6_740801898c4b4244b36b13f4e956e522~mv2.jpg/v1/fit/w_1000,h_562,al_c,q_80/file.png" src="https://static.wixstatic.com/media/caefc6_740801898c4b4244b36b13f4e956e522~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-butea">The other problem with media comes from the new subscription business model they implemented. With an increasing polarization, media outlets must stay in their political leaning. If they don’t, they face a massive loss of subscriptions. An example of this happened recently with the NYT. By publishing “<a href="https://www.nytimes.com/2020/06/03/opinion/tom-cotton-protests-military.html" target="_blank" rel="noopener">Send in the Troops</a>,” the company faced one of its biggest subscription losses ever.</p><p id="viewer-50a3q">The following picture shows the evolution of word usage frequency at the New York Times. As <a href="https://twitter.com/paulg/status/1136962504343662592" target="_blank" rel="noopener">mentioned</a> by Paul Graham, it seems that in our current world, if you want people to subscribe, you must pick a side. Truth doesn’t have side, however. It makes it impossible to rely on media corporations to find it.</p><div id="viewer-87avr"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.mehdiyacoubi.com/post/iterative-model-of-truth" data-pin-media="https://static.wixstatic.com/media/caefc6_f2246ffcdc69493baf77ec5bf5f1b9b0~mv2.jpeg/v1/fit/w_1855,h_2048,al_c,q_80/file.png" src="https://static.wixstatic.com/media/caefc6_f2246ffcdc69493baf77ec5bf5f1b9b0~mv2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><h2 id="viewer-eg9dc">Social Media</h2><p id="viewer-daoe">Social networks users <a href="https://www.emarketer.com/content/us-adults-are-spending-more-time-on-social-media-during-the-pandemic#:~:text=Social%20network%20users%20will%20spend,minutes%20from%20our%20previous%20forecast" target="_blank" rel="noopener">spend</a> an average of 1h 22minutes on social media per day. This number is increasing very fast, and it shows no signs of slowing down. Most of the content we consume we get on social media. This makes social media a critical protagonist in our search for truth.</p><p id="viewer-d3dka">The problem with this is that social media value engagement, and this doesn’t align generally with the truth. The number of retweets and likes has nothing to do with what’s true.</p><p id="viewer-669lp">Social media has increased our tendency to rely on tribal truth. It has become the realm of tribal truth. Identity is an essential part of who we are and when we base our identity on a set of ideologies that prevent people from accepting facts, there’s a clear problem. We learn and accept facts from people we like and trust. It’s obvious that this can’t be a way to find the truth.</p><p id="viewer-9pbaa">What if social media curated information and made the real facts more visible?</p><p id="viewer-9srt6">In that case, we’re back to the “Media” point above. If social media had become the new “guardian of truth,” we did not solve the problem. If Youtube bans what isn’t explicitly compliant with WHO’s recommendations, and if Twitter can edit the Times, it means there is one version of the truth. History already showed this isn’t a good idea.</p><p id="viewer-8quv5">Social media shouldn’t become the new “guardian of truth”.</p><h2 id="viewer-ajc89">Government Institutions</h2><p id="viewer-ee82t">The third entity where we usually get information from is institutions, from governments to global organizations. These entities have a lot of power but as they are political and strategic entities, they aren’t always incentivized to tell us the truth.</p><p id="viewer-7nopo">For example, a significant turning point may have happened during the current COVID-19 pandemic where science transformed from a tool of discovering the truth into a political tool of institutions.</p><p id="viewer-bq8u0">If science is used by big institutions to push their ideas or to justify their actions, we are lost.

</p><div id="viewer-915ga"><a href="https://twitter.com/joshmich/status/1235201253296263169?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1235201253296263169%7Ctwgr%5E&amp;ref_url=https%3A%2F%2Fcdn.embedly.com%2Fwidgets%2Fmedia.html%3Ftype%3Dtext2Fhtmlkey%3Da19fcc184b9711e1b4764040d3dc5c07schema%3Dtwitterurl%3Dhttps3A%2F%2Ftwitter.com%2Fjoshmich%2Fstatus%2F1235201253296263169image%3D" target="_blank" rel="noopener"><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.mehdiyacoubi.com/post/iterative-model-of-truth" data-pin-media="https://static.wixstatic.com/media/caefc6_ce4dda2309e84c33aeb0102a5c63b67f~mv2.png/v1/fit/w_1170,h_504,al_c,q_80/file.png" src="https://static.wixstatic.com/media/caefc6_ce4dda2309e84c33aeb0102a5c63b67f~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></a></div><h2 id="viewer-20f8p">A Lost sense of Truth</h2><p id="viewer-7t4ga">With all these shortcomings, it’s getting really hard to find the truth these days. Social media is weaponized, and while people spend more and more time online, they are being influenced by ideas turned into ideologies that may factually be wrong.</p><p id="viewer-bv41a"><a href="https://www.hilltimes.com/author/matt-mcmanus" target="_blank" rel="noopener">Matt McManus</a>, coined the term “<a href="https://www.hilltimes.com/2018/08/27/trump-age-bullshit-roots-knowledge-crisis/155316" target="_blank" rel="noopener">age of bullshit</a>” to express the knowledge crisis we are going through. It’s a dangerous time we live in, and in order to solve many of the challenges we face, we need, first, to focus on the meta-problems.</p><h2 id="viewer-83re0">A solution: the iterative model of truth</h2><h3 id="viewer-b8q47">The COVID19 Tracking Project</h3><p id="viewer-hnvv">As said, the press coverage of COVID-19 was disastrous early on. It led to most people and governments not taking the pandemic seriously. A counterexample of this is the <a href="https://covidtracking.com/" target="_blank" rel="noopener">COVID19 Tracking Project</a>.</p><p id="viewer-a7kdk">This tracking project was not presented as “the Truth” in the way the New York Times does. It shows the most accurate data, with revision history.</p><p id="viewer-544ku">Truth is a process; it’s not something set in stone; it changes. The problem with media corporations is that they present the truth as something fixed — the truth is what they publish. When they mistake, it’s difficult for them to admit that they have mistaken, because they would risk losing their positions as the guardians of the truth.</p><p id="viewer-dl914">It’s not a problem to be incorrect; the problem is not to admit it and build your whole legitimacy on being the truth.</p><h2 id="viewer-a80de">The GitHub Model of Truth</h2><p id="viewer-1vh0c">When’s the last time you heard a politician admitting he or she was wrong? I can’t think of an example. Conversely, if an app crashes, its developers will have no choice but to admit they made a mistake.</p><p id="viewer-fk3m8">It’s the GitHub model of truth. You know there will be mistakes, and you’re okay with it. As soon as you discover a problem, you correct it, and everyone can submit corrections.</p><p id="viewer-4ida7">Truth should follow the Github model. As soon as something is factually wrong, it should be easy to correct it and make the mistake visible to everyone.</p><p id="viewer-4l7ld">But how could we make it a reality outside of the tech world?</p><p id="viewer-e8tjf">For something to work, it must be created in a way that incentives are correctly aligned. Here, we want a collaborative system that gives us the best version of the truth.</p><h2 id="viewer-5otrr">How to Align the Incentives</h2><p id="viewer-a8302">The first idea that comes in mind to align the incentives is to make it financially attractive to be correct. What if “being right” meant earning money? An idea to fix this problem is to modify social media engagement metrics with social features based on a prediction market. Imagine if instead of liking or retweeting a tweet about an economically impactful statement, you could “bet” financially on it.</p><p id="viewer-46ogj">This approach would change the nature of the attention you give to the truth. You wouldn’t want to back the false claims, right? So before “betting” on a tweet, you would do your due diligence of fact-checking it and make sure it’s correct.</p><p id="viewer-c3726">No one should have the ability to say what’s right or wrong. It’s a collective process of multiple people fact-checking the statements and sourcing the information that can lead to the best version of the truth. The era of decentralized media must start if we want the truth.</p><p id="viewer-4djfj">In academia (I know a lot of things are wrong with academia), when a paper is published, it gets reviewed. We should do the same, but, unlike academia, we should do it in a decentralized way.</p><p id="viewer-b9dgk">For example, The <strong>Reproducibility Project: Psychology</strong> was a <a href="https://en.wikipedia.org/wiki/Crowdsourced_psychological_science" target="_blank" rel="noopener">crowdsourced</a> collaboration of 270 contributing authors to repeat 100 published experimental and correlational psychological studies. This idea of reproducing a finding must be transferred outside of the research world. What if independent reporters were doing the same with major stories?</p><p id="viewer-d2436">How would they get paid? The rise of independent journalism is happening now; Substack is an excellent example of it. An increasing amount of people are ready to subscribe to independent journalists to receive their work. It could be a solution to the problem. The <a href="https://taibbi.substack.com/" target="_blank" rel="noopener">newsletter</a> of Matt Taibbi is a great example of this, and another example is the excellent reporting of <a href="https://twitter.com/DellAnnaLuca" target="_blank" rel="noopener">Luca Dellanna</a> during the COVID-19 pandemic. To get the best information on the coronavirus, you had to follow the right people on Twitter, not the prominent publications.</p><p id="viewer-foc37">Decentralized and independent sources of information is also a way to promote <a href="https://marginalrevolution.com/marginalrevolution/2003/11/metarational_an.html" target="_blank" rel="noopener">meta-rationality</a>, a concept <a href="https://twitter.com/tylercowen" target="_blank" rel="noopener">Tyler Cowen</a> brings up a lot. It’s the concept of being aware of your cognitive limitations and know how to trust in topics where you don’t have the expertise to understand.</p><h2 id="viewer-4l0pi">New Social Media</h2><p id="viewer-5g9m7">Is it possible to have this approach to the truth using the existing social media? It seems hard. The social media were built with different motivations at the core. What we need is social media made entirely for the purpose of revealing the truth. As the French investor Xavier Faure <a href="https://twitter.com/XFaure/status/1092444972635303936" target="_blank" rel="noopener">said</a>:</p><blockquote id="viewer-ah70t"><p>“We need a trust social network. Where we don’t signal what we like, but what we vouch for.”</p></blockquote><p id="viewer-aiqju">It …</p></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mehdiyacoubi.com/post/iterative-model-of-truth">https://www.mehdiyacoubi.com/post/iterative-model-of-truth</a></em></p>]]>
            </description>
            <link>https://www.mehdiyacoubi.com/post/iterative-model-of-truth</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842362</guid>
            <pubDate>Wed, 15 Jul 2020 07:41:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Make Your Own ColecoVision at Home – Part 2]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23842351">thread link</a>) | @kyleee
<br/>
July 15, 2020 | https://www.leadedsolder.com/2020/07/10/colecovision-diy-part-2.html | <a href="https://web.archive.org/web/*/https://www.leadedsolder.com/2020/07/10/colecovision-diy-part-2.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>The boards for the homemade ColecoVision clone project have arrived. It’s been a long haul of finger-burning fun to get the console assembled, but will it ever be able to play a cartridge?</p>

<h2 id="parting-with-cash">Parting, with Cash</h2>
<p>Almost immediately after the Gerbers were sent off to JLCPCB, I ordered the entire BOM from Digi-Key. A huge bag of crap arrived within a few days.</p>

<p>It’s easy to lose scale on how big things really are when you’re constantly fighting for those fractions of a millimeter to route traces. At human-scale, I was a little shocked by how small a lot of the components were. All the SOT-23 stuff is smaller than a pinky fingernail and has teeny-tiny pins that don’t stick out very far. There’s no better way than this to get better at surface-mount soldering!</p>

<p>There were a couple problems with the order, but that’s to be expected. This was definitely the biggest parts-count board I’ve ever done, and I learned a lot. Things like, don’t leave making the BOM until the very last minute, because it takes an entire morning and four cups of coffee. And that you should always do the BOM <em>before</em> you order the board, in case your footprints aren’t right.</p>

<p>One big problem was that I wasn’t able to find a bi-polar 68µF capacitor in 0805. You’d think that would be easy, but it appears the laws of physics forbid it. I changed the footprint (<em>after</em> ordering the board, of course) to a larger 1206 and then ordered some through-hole ceramic caps that I could bodge onto the pad. Said 68µF capacitor is for the clock circuit, so I think its value was quite important:</p>

<p><img src="https://www.leadedsolder.com/assets/colecovision-68uf-cap.png" alt="The 68µF capacitor in question, nestled between a 2n3904 transistor and some flip-flops."></p>

<p>You might be asking yourself why I need such a big capacitor for a clock circuit. Aren’t clock circuits usually using <em>pico</em>-Farads? Well…….</p>

<p>A few hours after I ordered the parts, I got an email from Digi-Key saying that there was an inventory discrepancy and that they actually only had one 2kΩ 0805 surface-mount resistor in stock, not two. This was a pretty funny idea to me, that their inventory robots would constantly be shuttling past a sad bin that only contains one minuscule resistor in an extremely common capacitance.</p>

<p>What was even funnier is that the part was now <em>discontinued</em> - as if a bunch of people working at the resistor factory got told by their boss that he doesn’t think anyone’s going to really want 2kΩ resistors anymore. “No, what customers want now is <em>capacitors</em>,” he’ll chuckle at his business acumen, while the resistor department’s hated rival, Bob Dielectric, rubs his hands in glee. I ordered literally one hundred 2kΩ 0805s from a different manufacturer for a buck instead.</p>

<p>What’s not as funny is that the cartridge slot I had paid six bucks for came without pins. When I saw it on Digi-Key, it had been listed without an image, but I figured there was no way it wouldn’t come without pins. After cursing myself, I ordered up another bunch of 0.1” 30-pin edge connector slots, except this time with pins. The new Sullins-branded ones came in a fetching shade of blue and - just to rub it in - cost a little less. However, they still weren’t what I was looking for…</p>

<p>Another small opposition to the project came in the form of some local scumbag, who stole one of the DigiKey orders off my porch, tore it open, presumably found nothing that they could fence or snort, and then threw the opened box into my backyard. Everything was still there, but clearly the forces of “I’d really like some drugs” are aligned against the Leako Initiative.</p>

<p>And, yes, the clock circuit did ask for 68 <em>pF</em>. I made a mistake reading it off the schematic, which changed between notations of capacitors depending on which sheet you were looking at. I figured this out a while later, which I’m not very proud of.</p>

<h2 id="sound-off">Sound Off</h2>
<p>Another mistake I made was not reversing the data bus on the 76489 sound chip. Like the TMS9918, this TI sound chip is also ‘backwards’ from the Z80’s data pin convention: pin D<sub>0</sub> on the Z80 goes to D<sub>7</sub> on the 76489 and so on.</p>

<p>I resolved to bodge wire this onto a piece of protoboard, and just live with the shame for now. Unfortunately, the sound chips took several months to arrive (coronavirus again,) so I ended up just going ahead with the v0.2 board, where I made this change. Despite the counterfeits and recaps, it is great to ride the “80s grey-market sound chip” market until something like this happens to screw it up.</p>

<p>When one of the orders of SN78649s arrived, I built a breadboard tester for it powered by an Arduino. I had heard that the reliability of these chips was very low, so I expected not very many of them would work. The first chip I tested worked great - except that my code was terrible and didn’t produce a reliable result due to bad timing.</p>

<center><iframe width="560" height="315" src="https://www.youtube.com/embed/ZMITqYnvz-A" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></center>

<p>After a few hours of bodging and reading <a href="https://www.smspower.org/Development/SN76489">documentation on SMSPower</a>, I managed to figure out how to test the chip. Here it is cycling through channels 0, 1, 2 and the two kinds of noise supported by the chip. At least we’ve got <em>one</em> known-good salvage part!</p>

<h2 id="controller-prep">Controller Prep</h2>
<p>The controller I ordered as part of a lot from Quebec in the previous entry arrived almost immediately, and I set about tearing it down and cleaning it. It was really gross! The plastics got washed in my kitchen sink, the coiled cord scrubbed <a href="https://www.leadedsolder.com/2019/10/29/pc8801mh-keyboard-clean.html">with the flossing method</a>, and the (delaminating) matrix keypad got a once-over with some disinfecting wipes.</p>

<p>It had one missing coarse-thread Phillips screw, which I replaced with another from my junk drawer. I still haven’t figured out how to get a new shiny ‘grip disc’ for the top of the joystick - maybe I’ll make something with hockey tape.</p>

<p>Cleaning and servicing controllers doesn’t need a whole lot of focus or technical skill, which makes it the perfect task to say you’ve actually done <em>something</em> on a project today.</p>

<p>The wires that go from the DE9 cable onto the PCB are just crimped onto the pads on the PCB. A bunch of these crimps were super loose and probably not making good contact, which might be the reason why this controller was getting sold with the other junky parts. I tried to tighten them up, but one tragically snapped as soon as I applied any force:</p>

<p><img src="https://www.leadedsolder.com/assets/colecovision-controller-dead-crimp.jpg" alt="A good and a bad crimp. The red one (bottom) has lost one of its little crimpy 'wings'."></p>

<p>I decided I would cut off all the crimps and solder the wires directly to the board. This worked okay, except that the insulation on the wires was definitely not solder-heat proof and melted. Since the pads had never been used for solder in 37 years, I decided it would also be prudent to put a little liquid flux on them in order to prep them for the solder.</p>

<p><img src="https://www.leadedsolder.com/assets/colecovision-controller-crimps-cut.jpg" alt="The cut crimps in a pile."></p>

<p>The joints weren’t pretty since I had to work fast. That’s my excuse. Also, I had to desolder the entire thing and do it again after I realized the wires have to slip through the back plastic case and so should be soldered only <em>after</em> threading them through…</p>

<p><img src="https://www.leadedsolder.com/assets/colecovision-controller-soldered-wires.jpg" alt="The wires soldered to the ColecoVision controller PCB. The PCB calls out the colour of each wire."></p>

<p>Finally, after some fighting, I was able to reassemble the controller. It wasn’t a great fit, even with the new screw, because the lower plastics that clip together had broken from age and abuse. Also, I didn’t do a great job of actually cleaning the top plastic for fear of rusting the spring, so I went back and did another quick scrubbing with a q-tip and isopropyl alcohol.</p>

<p><img src="https://www.leadedsolder.com/assets/colecovision-controller-reassembled.jpg" alt="The re-assembled controller."></p>

<p>That was a lot of work for an ugly controller that doesn’t feel that great in the end… I hoped it would at least work. I can always buy or build a nicer one later.</p>

<h2 id="get-onboard">Get Onboard</h2>
<p>Eventually, the boards shipped from the fab. One of them had been ‘scratched’ during the assembly process, so I was fully refunded on it. It’s still nice enough to use for a practice board in the future.</p>

<p>And as soon as they shipped, I noticed something a little weird. Remember last episode, where I told you about how to wire up a clock divider? Well, the new clock divider I added to go from 14MHz down to 7MHz was done correctly, but not the “original” clock divider from the schematic that I blindly copied.</p>

<p>Here are the two dividers in different schematics:</p>

<p><img src="https://www.leadedsolder.com/assets/colecovision-bad-clock-divider.png" alt="The schematic that was sent off to fab. The not-Q output is not connected to anything."></p>

<p><img src="https://www.leadedsolder.com/assets/colecovision-good-clock-divider.png" alt="The schematic that I discovered after fabrication. The not-Q output is connected to the D-input."></p>

<p><a href="https://atariage.com/forums/topic/285656-new-colecovision-schematics/">The latter schematics, by an Atari Age user known as ChildOfCv</a>, were meticulously double-checked. Had I known there were errors in the original schematic, I probably would have gone from the start with ChildOfCv’s. I have a huge debt to the original schematics, of course, as that is an immense amount of work. One or two errors here isn’t surprising in a task like that. It was only here that I discovered my 68pF clock circuit error, in case you’re keeping track.</p>

<p>Clearly, it was time to rework my clock circuit and spin a v0.2 with all the other problems I’d noticed. This made the board a little uglier in some spots, as I tried to reintroduce chips into the same general location they had once occupied but ran new traces. My timing circuit got split up when I put it on the board originally (since I left it for almost last), so changing it isn’t necessarily a matter of removing one chunk of the board and laying a new one down. I’ll try to get better at keeping physical space for “zones of responsibility” on future projects. Still, though, the re-routing took less than an hour and I was able to send the v0.2 board off:</p>

<p><img src="https://www.leadedsolder.com/assets/colecovision-v0.2.png" alt="The ColecoVision v0.2 board as viewed by the JLCPCB gerber viewer."></p>

<p>Why yes, I <em>did</em> put Q3, a through-hole transistor, right in the way of the plastic shell of the cartridge when it is inserted into the slot. Good thing they have bendy legs…</p>

<h2 id="v01-arrives">v0.1 Arrives</h2>
<p>Even though I knew that my first-born clone board had some flaws, it was hard not to smile when I unpacked the boards. They’re so <em>tiny</em>, but they (will) do so much!</p>

<p><img src="https://www.leadedsolder.com/assets/leako-v0.1.jpg" alt="The (red) v0.1 boards, front and back."></p>

<p>That RAM chip next to the Z80 being so far north really bugs me now, although I hardly noticed it before. If it works…</p>

<p><img src="https://www.leadedsolder.com/assets/leako-v0.1-posed.jpg" alt="The v0.1 board on some improvised standoffs"></p>

<p>I used some of <a href="https://en.wikipedia.org/wiki/Spacers_and_standoffs">those little jackscrew standoff retainers that hold on VGA cables</a> to stand the board up off the table. This is important not just for looks, avoiding shorts, and cooling, but because there are chips on both sides. They weren’t a perfect fit for an M3 hole, but when screwed tightly together they don’t wobble. At last, the junk-bin investment is paying off.</p>

<p>Even though I had already ordered the v0.2 boards, I started doing some of the test-fitting that I should have done on paper. That’s right, I’m once again …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.leadedsolder.com/2020/07/10/colecovision-diy-part-2.html">https://www.leadedsolder.com/2020/07/10/colecovision-diy-part-2.html</a></em></p>]]>
            </description>
            <link>https://www.leadedsolder.com/2020/07/10/colecovision-diy-part-2.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842351</guid>
            <pubDate>Wed, 15 Jul 2020 07:39:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Not Recommending Purism]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23842347">thread link</a>) | @varbhat
<br/>
July 15, 2020 | https://anarc.at/blog/2020-07-13-not-recommending-purism/ | <a href="https://web.archive.org/web/*/https://anarc.at/blog/2020-07-13-not-recommending-purism/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">


          

            <p>This is just a quick note to mention that I have updated my <a href="https://anarc.at/hardware/laptop/purism-librem13v4">hardware
documentation on the Librem 13v4 laptop</a>. It has unfortunately
turned into a rather lengthy (and ranty) piece about Purism. Let's
just say that waiting weeks for your replacement laptop (yes, it died
again) does wonders for creativity. To quote the full review:</p>

<blockquote><p>TL;DR: I recommend people avoid the Purism brand and products. I
find they have questionable politics, operate in a "libre-washing"
fashion, and produce unreliable hardware. Will not buy again.</p></blockquote>

<p>People who have read the article might want to jump directly to the
new sections:</p>

<ul>
<li><a href="https://anarc.at/hardware/laptop/purism-librem13v4/#libre-washing">Libre washing</a></li>
<li><a href="https://anarc.at/hardware/laptop/purism-librem13v4/#bullshit-anti-interdiction">Bullshit anti-interdiction</a></li>
<li><a href="https://anarc.at/hardware/laptop/purism-librem13v4/#bullshit-crowdfunding">Bullshit crowdfunding</a></li>
<li><a href="https://anarc.at/hardware/laptop/purism-librem13v4/#hardware-reliability">Hardware reliability</a> (or lack thereof)</li>
</ul>


<p>I have also added the minor section of the <a href="https://anarc.at/hardware/laptop/purism-librem13v4/#no-mic-jack">missing mic jack</a>.</p>

<p>I realize that some folks (particularly at Debian) might still work at
Purism, and that this article might be demoralizing for their work. If
that is the case, I am sorry this article triggered you in any way and
I hope this can act as a disclaimer. But I feel it is my duty to
document the issues I am going through, as a user, and to call
bullshit when I see it (let's face it, the anti-interdiction stuff and
the Purism 5 crowd-funding campaign were total bullshit).</p>

<p>I also understand that the pandemic makes life hard for everyone, and
probably makes a bad situation at Purism worse. But those problems
existed before the pandemic happened. They were issues I had
identified in 2019 and that I simply never got around to document.</p>

<p>I wish that people wishing to support the free software movement would
spend their energy towards organisations that actually do honest work
in that direction, like <a href="https://system76.com/">System76</a> and <a href="https://www.pine64.org/">Pine64</a>. And if you're
going to go crazy with an experimental free hardware design, why not
go retro with the <a href="https://www.crowdsupply.com/mnt/reform">MNT Reform</a>.</p>

<p>In the meantime, if you're looking for a phone, I recommend you give
the <a href="https://www.fairphone.com/">Fairphone</a> a fair chance. It really is a "fair" (as in, not
the best, but okay) phone that you can moderately liberate, and it
actually frigging works. See also my <a href="https://anarc.at/hardware/phone/fairphone2">hardware review of the FP2</a>.</p>

<p>Update: this kind of blew up, for my standards: 10k visitors in ~24h
while I usually get about 1k visitors after a week on any regular blog
post. There were more discussions on the subject here:</p>

<ul>
<li><a href="https://lobste.rs/s/ecyjq2/not_recommending_purism">Lobsters</a></li>
<li><a href="http://www.reddit.com/r/linux/comments/hr8hvi/not_recommending_purism">Reddit /r/linux</a>, <a href="https://www.reddit.com/r/linuxhardware/comments/hqs48i/debian_developer_not_recommending_purism/">/r/linuxhardware</a>, <a href="https://www.reddit.com/r/Purism/comments/hqs0vz/debian_developer_not_recommending_purism/">r/purism</a></li>
<li><a href="https://news.ycombinator.com/item?id=23842347">Hacker news</a></li>
</ul>


<p>Trigger warning: some of those threads include personal insults and
explicitly venture into the <a href="https://anarc.at/blog/2019-05-13-free-speech/">free speech
discussion</a>, with predictable (sad)
consequences...</p>


            

            
              
  
  <nav>
    
  </nav>
  


            

            
            
            
            

            

            <nav>
                
            
            
            </nav>
            

            
    </div></div>]]>
            </description>
            <link>https://anarc.at/blog/2020-07-13-not-recommending-purism/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842347</guid>
            <pubDate>Wed, 15 Jul 2020 07:38:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I built a new app for practicing keyboard shortcuts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23842339">thread link</a>) | @jacobedawson
<br/>
July 15, 2020 | https://tkainrad.dev/posts/why-i-built-a-new-app-for-practicing-keyboard-shortcuts/ | <a href="https://web.archive.org/web/*/https://tkainrad.dev/posts/why-i-built-a-new-app-for-practicing-keyboard-shortcuts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="contentdiv">

<p>I have always wanted to build a software product as a side project. Something that I could gradually improve and work on for years without deadlines and technology restrictions. Something that was <em>my</em> side-project.
Fortunately, I was never short of ideas. In my post on <a href="https://tkainrad.dev/posts/managing-my-personal-knowledge-base/#shortcut-database">managing my personal knowledge base</a>, I have mentioned that I keep a Notion database of project ideas. It has plenty of entries.</p>
<p>In the same post, I also described my shortcut database use case. It was a spreadsheet to keep track of all the keyboard shortcuts I was using. Something about this motivated me much more than all the Slack bots and browser extensions lurking around in my ideas list. So, I started to work and expand on the concept in the form of a new web application. Initially, I thought It would take me until the end of 2020 to have anything that I could share with the world. Then, the Corona-lockdown came, and suddenly most of my other free time activities were no longer possible.</p>
<p>Long story short, <a href="http://keycombiner.com/">keycombiner.com</a> is now available for everyone to use.
This post covers how it compares to existing tools, what it tries to do, how it does it, and the road ahead.</p>
<p>KeyCombiner is completely free to use, with no strings attached. For a demo of the <em>Practice</em> mode or browsing <a href="https://keycombiner.com/collecting/collections/public/">public shortcut collections</a>, you don’t even need to create an account.</p>

<p>There are a lot of typing practice tools available. However, KeyCombiner is quite different from all of them.</p>
<p>The vast majority of existing tools focus on text typing. These applications will show you automatically generated pieces of text that you are supposed to type as fast and as correct as possible.
Usually, you will get a report at the end about your speed and accuracy. I do like this a lot and often test my typing speed. It is a fun thing to do once in a while, and if you realize that your typing speed is low, you might want to work on it.
Of course, these tools have nothing to do with keyboard shortcuts. They will not help with learning them and also do not include them in their typing practice.</p>
<p>When looking at practicing keyboard shortcuts, there are far fewer alternatives to choose from. But still, there are a couple of existing apps.
To my knowledge, all of them work with pre-defined lessons, which is very unintuitive for me. I don’t want to learn <em>all</em> keyboard shortcuts of a particular app. Also, they are focused solely on learning keyboard shortcuts, not with your typing skills per se. Therefore, they do not record typing speed, accuracy, or any other such metrics. For me, this alone removes most of the motivation for using such a tool. I don’t want to only learn shortcuts, I also want to become faster and more accurate at using them.</p>
<p>KeyCombiner aims to bridge this gap between typing training software and shortcut learning apps. Besides, it goes to great lengths to make it easy to learn and practice not just any shortcuts but precisely the ones you want to use.
If you like to look at Venn diagrams that probably shouldn’t be Venn diagrams, I have just the thing for you:</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/typing-trainers-venn.svg">
</figure>

<p>Developing KeyCombiner, I had and still have the following goals:</p>
<p><strong>Enable efficient creation of keyboard shortcut collections</strong></p>
<p>The first goal is, of course, to cover the original use case described in my <a href="https://tkainrad.dev/posts/managing-my-personal-knowledge-base/#shortcut-database">knowledge management post</a>.
Having an overview of all the keyboard shortcuts you are using and intend to learn is already useful in itself. However, it is clear that most people don’t want to spend a lot of time with this task, so it has to be possible in a couple of minutes to build meaningful collections.</p>
<p><strong>Facilitate learning of keyboard shortcuts</strong></p>
<p>Generally, I want to provide as much value on top of a user’s shortcut collections as possible. Learning new keyboard shortcuts is probably the most powerful thing that can be done. It is therefore the second fundamental goal of KeyCombiner.</p>
<p><strong>Allow to practice also text snippets</strong></p>
<p>As developers, we have many short text snippets that we need to remember. Think of <em>git</em> commands or language syntax. These feel similar to keyboard shortcuts, and I would like to be able to practice them together.</p>
<p><strong>Help to improve typing speed and accuracy</strong></p>
<p>Going beyond mere memorization of keyboard shortcuts is an important aspect and one thing that sets KeyCombiner apart from other software. The goal is not just to learn keyboard shortcuts, but to be able to type them fast and accurately, too.</p>

<p>This section covers KeyCombiner’s three main areas. However, those are very much connected, as illustrated in the following figure:</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/tirangle-of-col-stat-train.svg">
</figure>
<h2 id="create-shortcut-collections">Create shortcut collections</h2>
<p>A core idea of KeyCombiner is to learn and practice <em>exactly</em> the shortcuts you need or want to use. The only way to achieve this is if you choose them yourself.</p>
<p>I thought a lot about how to make this collection building process as efficient as possible. From the start, it was apparent that it would need to be possible to import keyboard shortcuts and text snippets from a public database of popular application shortcuts. This mechanic can be used to build the bulk of your collections quickly. They can then be completed by manually adding entries.</p>
<p>I like to compare my approach to how you build playlists in music software. Instead of browsing your favorite artists’ albums, KeyCombiner allows you to browse categories of your favorite applications. Instead of adding songs to your playlists, you can add keyboard shortcuts and text snippets to your collections:</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/collecting.gif" alt="KeyCombiner&amp;rsquo;s combination tables support all popular multi-selection patterns, i.e. drag selecting, Shift-selection and maintaining selection via Ctrl"> <figcaption>
<p>KeyCombiner’s combination tables support all popular multi-selection patterns, i.e. drag selecting, <kbd>Shift</kbd>-selection and maintaining selection via <kbd>Ctrl</kbd></p>
</figcaption>
</figure>
<p>KeyCombiner’s <a href="https://keycombiner.com/collecting/collections/public/">public collections</a> already contain thousands of keyboard shortcuts. Each collection can be filtered and searched quickly.</p>
<p>Creating collections of keyboard shortcuts is already a use case in itself. It can help to answer a variety of questions:</p>
<ul>
<li>How many shortcuts am I using?</li>
<li>Are my key bindings logical and consistent or am I using completely different combinations for similar things?</li>
<li>For which applications am I using my shortcuts?</li>
<li>I am setting up a new machine and want to set up my key bindings. What were those exactly?</li>
</ul>
<p>When combining personal shortcut collections with the other two main areas of KeyCombiner, we can answer even more interesting questions:</p>
<ul>
<li>How well do I actually know the shortcuts in my collections?</li>
<li>How fast can I type them?</li>
<li>How often do I make an error while typing a specific shortcut?</li>
</ul>
<p>As shown in the <a href="#how-it-works">illustration above</a>, collections are annotated with information gathered from KeyCombiner’s statistics. Most importantly, the confidence value shows how good you are with a combination in your collections:</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/confidence.png" alt="Some keyboard shortcuts that I have practice often and am therefore very confident with."> <figcaption>
<p>Some keyboard shortcuts that I have practice often and am therefore very confident with.</p>
</figcaption>
</figure>
<h2 id="learn-shortcuts-flashcard-style">Learn shortcuts flashcard-style</h2>
<p>Before going deeper into confidence values and other statistical measures, we need to take a step back and look at how data is gathered. It is done while you practice your shortcut collections.</p>
<p>In principle, KeyCombiner’s interactive training is similar to other applications. You are shown what a shortcut does and, ideally, you know the keys and type it in correctly:</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/learning.gif" alt="KeyCombiner&amp;rsquo;s interactive trainer has a visual keyboard and options for displaying the keys to type."> <figcaption>
<p>KeyCombiner’s interactive trainer has a visual keyboard and options for displaying the keys to type.</p>
</figcaption>
</figure>
<p>What makes KeyCombiner unique in this regard is that you are practicing your very own collections, hence exactly the shortcuts you want to learn! Furthermore, KeyCombiner gathers detailed statistics that help to analyze your performance. You might know how many words you can type by minute (WPM), but do you also know how many keyboard shortcuts you can execute during this time?</p>
<p>There are many more things to be said about the <em>Practice</em> mode. It does all kinds of things to make learning as efficient as possible. For example, it uses ideas from spaced repetition and shows keyboard shortcuts with low confidence value more often than others. Then, there is the option to display the actual keys of a combination after a delay that gives you some time to think. This is a tricky thing to do, because key combinations typed with hints should not influence the confidence value. But that’s a topic for another blog post.</p>
<p>What I like to do personally is to gradually expand my collections. For example, I set a goal of learning 10 new shortcuts a given week. Then, at the beginning of the week, I browse the public collections for 10 new shortcuts and add them to one of my collections.
Throughout the week, I do a 60-seconds practice session from time to time. Because the new shortcuts have a low confidence value at the beginning, KeyCombiner will show them often during practice, and after just a couple of practice runs, I usually know them well.</p>
<h2 id="statistics-to-improve-accuracy--speed">Statistics to improve accuracy &amp; speed</h2>
<p>One of the defined goals is to help users improve their typing skills beyond just remembering shortcuts. It is of similar importance to be able to type them fast and accurately. To help identify weaknesses and bad habits, KeyCombiner gathers detailed statistics during practice.</p>
<p>The below figure shows an example bar chart for one of my early practice runs.</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/test-run-stats.png" alt="Interactive charts show which combinations need some further practice."> <figcaption>
<p>Interactive charts show which combinations need some further practice.</p>
</figcaption>
</figure>
<p>It is immediately obvious that I had problems typing <kbd>Shift</kbd>+<kbd>a</kbd>, <kbd>Ctrl</kbd>+<kbd>Alt</kbd>+<kbd>m</kbd> and <kbd>Ctrl</kbd>+<kbd>Shift</kbd> + <kbd>c</kbd>. Using such statistics, I actually found that I was occasionaly making mistakes with some of the most essential shortcuts: <kbd>Ctrl</kbd>+<kbd>x</kbd>/<kbd>c</kbd>/<kbd>v</kbd>. This was because I used my pointer finger for each of them. After realizing that this was a problem, I started to use the middle finger for <kbd>Ctrl</kbd>+<kbd>x</kbd> and am no longer making mistakes.</p>
<p>When taking the average time into account, there are many more observations to make. If you find out which combinations are the fastest to type for you, you can use this knowledge and set such convenient combinations wherever possible.</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/analytics.gif" alt="KeyCombiner presents statistics per practice run and per key combination."> <figcaption>
<p>KeyCombiner presents statistics per practice run and per key combination.</p>
</figcaption>
</figure>

<p>The most pressing issue right now is user onboarding. Unfortunately, many people sign up and then never create any meaningful …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tkainrad.dev/posts/why-i-built-a-new-app-for-practicing-keyboard-shortcuts/">https://tkainrad.dev/posts/why-i-built-a-new-app-for-practicing-keyboard-shortcuts/</a></em></p>]]>
            </description>
            <link>https://tkainrad.dev/posts/why-i-built-a-new-app-for-practicing-keyboard-shortcuts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842339</guid>
            <pubDate>Wed, 15 Jul 2020 07:37:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introducing 2nd Generation IPU Systems for AI at Scale]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23842281">thread link</a>) | @ingve
<br/>
July 15, 2020 | https://www.graphcore.ai/posts/introducing-second-generation-ipu-systems-for-ai-at-scale | <a href="https://web.archive.org/web/*/https://www.graphcore.ai/posts/introducing-second-generation-ipu-systems-for-ai-at-scale">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
				
				
				

				<div>
					
					<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p><span data-contrast="auto" xml:lang="EN-GB" lang="EN-GB"><span>I am delighted to introduce our second-generation IPU platform with greater processing power, more memory and built-in scalability for handling extremely large Machine Intelligence workloads.</span></span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<!--more-->
<p><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"><span data-contrast="auto" xml:lang="EN-GB" lang="EN-GB"><span>The IPU-Machine M2000 is a plug-and-play Machine Intelligence compute blade that has been designed for easy deployment and supports systems that can grow to massive scale. The slim 1U blade delivers one<span>&nbsp;</span></span><span>PetaFlop</span><span><span>&nbsp;</span>of Machine Intelligence compute and includes integrated networking technology, optimized for AI scale-out, inside the box.</span></span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></span></p>
<div>
<p><iframe xml="lang" src="//www.youtube.com/embed/_zvU0uwIafQ" width="560" height="315" allowfullscreen="" data-service="youtube"></iframe></p>
</div>

<p><span data-contrast="auto">Each IPU-Machine M2000 is powered by four of our brand new 7nm Colossus™ Mk2 GC200 IPU processors, and is fully supported by our Poplar® software stack.&nbsp;</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">Users of our Mk1 IPU products can be assured that their existing models and systems will run seamlessly on these new Mk2 IPU systems but will deliver an incredible 8X step up in performance when compared to our already&nbsp;class-leading&nbsp;first-generation&nbsp;Graphcore&nbsp;IPU products.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><img src="https://www.graphcore.ai/hs-fs/hubfs/Colossus%20MK2%20Performance%20Comparison.png?width=601&amp;name=Colossus%20MK2%20Performance%20Comparison.png" alt="Colossus MK2 Performance Comparison" width="601" srcset="https://www.graphcore.ai/hs-fs/hubfs/Colossus%20MK2%20Performance%20Comparison.png?width=301&amp;name=Colossus%20MK2%20Performance%20Comparison.png 301w, https://www.graphcore.ai/hs-fs/hubfs/Colossus%20MK2%20Performance%20Comparison.png?width=601&amp;name=Colossus%20MK2%20Performance%20Comparison.png 601w, https://www.graphcore.ai/hs-fs/hubfs/Colossus%20MK2%20Performance%20Comparison.png?width=902&amp;name=Colossus%20MK2%20Performance%20Comparison.png 902w, https://www.graphcore.ai/hs-fs/hubfs/Colossus%20MK2%20Performance%20Comparison.png?width=1202&amp;name=Colossus%20MK2%20Performance%20Comparison.png 1202w, https://www.graphcore.ai/hs-fs/hubfs/Colossus%20MK2%20Performance%20Comparison.png?width=1503&amp;name=Colossus%20MK2%20Performance%20Comparison.png 1503w, https://www.graphcore.ai/hs-fs/hubfs/Colossus%20MK2%20Performance%20Comparison.png?width=1803&amp;name=Colossus%20MK2%20Performance%20Comparison.png 1803w" sizes="(max-width: 601px) 100vw, 601px"></p>
<p><span data-contrast="auto">The design of our IPU-Machine M2000 allows customers to build datacenter-scale systems of up to 64,000 IPUs, in IPU-POD™ configuration, that deliver 16 ExaFlops of Machine Intelligence compute. Our new IPU-Machine M2000 is capable of handling even the toughest Machine Intelligence training or large-scale deployment workloads.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">You can get started with a single IPU-Machine M2000 box, directly connected to one of your existing CPU-servers, or&nbsp;add up to a total of eight IPU-Machine M2000s connected to this one server. For larger systems, you can use our rack-scale IPU-POD</span><sub><span data-contrast="auto">64</span></sub><span data-contrast="auto">, comprising 16 IPU-Machine M2000s built into a standard 19-inch rack and scale these racks out to deliver&nbsp;datacenter-scale Machine Intelligence compute.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><img src="https://www.graphcore.ai/hs-fs/hubfs/IPU%20Machine%20for%20machine%20intelligence%20compute.jpg?width=601&amp;name=IPU%20Machine%20for%20machine%20intelligence%20compute.jpg" alt="IPU Machine for machine intelligence compute" width="601" srcset="https://www.graphcore.ai/hs-fs/hubfs/IPU%20Machine%20for%20machine%20intelligence%20compute.jpg?width=301&amp;name=IPU%20Machine%20for%20machine%20intelligence%20compute.jpg 301w, https://www.graphcore.ai/hs-fs/hubfs/IPU%20Machine%20for%20machine%20intelligence%20compute.jpg?width=601&amp;name=IPU%20Machine%20for%20machine%20intelligence%20compute.jpg 601w, https://www.graphcore.ai/hs-fs/hubfs/IPU%20Machine%20for%20machine%20intelligence%20compute.jpg?width=902&amp;name=IPU%20Machine%20for%20machine%20intelligence%20compute.jpg 902w, https://www.graphcore.ai/hs-fs/hubfs/IPU%20Machine%20for%20machine%20intelligence%20compute.jpg?width=1202&amp;name=IPU%20Machine%20for%20machine%20intelligence%20compute.jpg 1202w, https://www.graphcore.ai/hs-fs/hubfs/IPU%20Machine%20for%20machine%20intelligence%20compute.jpg?width=1503&amp;name=IPU%20Machine%20for%20machine%20intelligence%20compute.jpg 1503w, https://www.graphcore.ai/hs-fs/hubfs/IPU%20Machine%20for%20machine%20intelligence%20compute.jpg?width=1803&amp;name=IPU%20Machine%20for%20machine%20intelligence%20compute.jpg 1803w" sizes="(max-width: 601px) 100vw, 601px"></p>
<p><span data-contrast="auto">Connecting IPU-Machine M2000s and IPU-PODs at scale is made possible by our new IPU-Fabric™ technology, which has been designed from the ground-up for Machine Intelligence communication and delivers a dedicated low latency fabric that connects IPUs across the entire&nbsp;datacenter.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">Our Virtual-IPU software integrates with workload management and orchestration software to easily serve many different users for training and&nbsp;inference, and&nbsp;allows the available resources to be adapted and reconfigured from job to job.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">Whether you are using a single IPU or thousands for your Machine Intelligence workload,&nbsp;Graphcore’s&nbsp;Poplar SDK makes this simple. You can use your preferred AI framework, such as TensorFlow or&nbsp;PyTorch, and from this high-level description, Poplar will build the complete compute graph, capturing the computation, the data and the communication. It then compiles this compute graph and builds the runtime programs that manage the compute, the memory management and the networking communication, to take full advantage of the available IPU hardware.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">If you’re looking to add Machine Intelligence compute into your&nbsp;datacenter, there’s nothing more powerful, flexible or easier to use than a&nbsp;Graphcore&nbsp;IPU-Machine M2000.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><strong>Innovation and advantage</strong></p>
<p><span data-contrast="auto">Graphcore&nbsp;customers span automotive, consumer internet, finance, healthcare, research and more.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">The number of corporations, organisations and research institutions using Graphcore systems is growing rapidly and includes Microsoft, Oxford Nanopore, EspresoMedia, the University of Oxford, Citadel and Qwant.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">Graphcore’s technology is also being evaluated by J.P. Morgan to see if its solutions can accelerate the bank’s advances in AI, specifically in Natural Language Processing and speech recognition.</span></p>
<p><span data-contrast="auto">With the launch of the IPU-Machine M2000 and IPU POD</span><span data-contrast="auto">64</span><span data-contrast="auto">, the competitive advantage that we are able offer is extended even further.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">Graphcore’s&nbsp;latest product line is made possible by a range of ambitious technological innovations across compute, data, and communication, that deliver the industry-leading performance customers expect.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><strong>Compute</strong></p>
<p><span data-contrast="auto" xml:lang="EN-GB" lang="EN-GB"><span>At the heart of every IPU-Machine M2000 is our new<span>&nbsp;</span></span><span>Graphcore</span><span><span>&nbsp;</span>Colossus™ Mk2 GC200 IPU. Developed using TSMC’s latest 7nm process technology, each chip contains more than 59.4 billion transistors on a single 823sqmm die, making it the most complex processor ever made.</span></span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><img src="https://www.graphcore.ai/hs-fs/hubfs/GC200%20image.jpg?width=600&amp;name=GC200%20image.jpg" alt="GC200 image" width="600" srcset="https://www.graphcore.ai/hs-fs/hubfs/GC200%20image.jpg?width=300&amp;name=GC200%20image.jpg 300w, https://www.graphcore.ai/hs-fs/hubfs/GC200%20image.jpg?width=600&amp;name=GC200%20image.jpg 600w, https://www.graphcore.ai/hs-fs/hubfs/GC200%20image.jpg?width=900&amp;name=GC200%20image.jpg 900w, https://www.graphcore.ai/hs-fs/hubfs/GC200%20image.jpg?width=1200&amp;name=GC200%20image.jpg 1200w, https://www.graphcore.ai/hs-fs/hubfs/GC200%20image.jpg?width=1500&amp;name=GC200%20image.jpg 1500w, https://www.graphcore.ai/hs-fs/hubfs/GC200%20image.jpg?width=1800&amp;name=GC200%20image.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></p>
<p><span data-contrast="auto">GC200 integrates 1,472 separate IPU-Cores, and&nbsp;is capable of executing&nbsp;8,832 separate parallel computing threads. Each IPU processor core gets a performance boost from a set of novel floating-point technologies developed by&nbsp;Graphcore, called&nbsp;</span><strong><span data-contrast="auto">AI-Float.&nbsp;</span></strong><span data-contrast="auto">By tuning arithmetic implementations for energy and performance in Machine Intelligence computation, we&nbsp;are able to&nbsp;serve up one&nbsp;PetaFlop&nbsp;of AI compute in each IPU-Machine M2000 1U blade.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">With class leading support for FP32 IEEE floating point arithmetic we also support FP16.32 (16bit multiply with 32bit accumulate) and FP16.16 (16bit multiply accumulate). However, our Colossus IPUs are unique in having support for Stochastic Rounding on the arithmetic that is supported in hardware and runs at the full speed of the processor. This allows the Colossus Mk2 IPU to keep all arithmetic in 16bit formats, reducing memory requirements, saving on read and write energy and reducing energy in the arithmetic logic, while delivering full accuracy Machine Intelligence results. Each of the 1,472 processor cores and each of the 8,832 parallel program threads can generate a separate random number seed with shaped noise, allowing a unique compute capability to support, for example, Probabilistic or Evolution Strategy models. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">The AI-Float arithmetic block also provides native support for sparse arithmetic floating-point operations. We provide library support for different sparse operations including block sparsity and dynamic sparsity. This means that the IPU delivers much more efficient compute on sparse data, not just in inference, but also during training, helping innovators to create new types of complex models that deliver state of the art performance with much fewer parameters, faster training times and using much less energy.&nbsp;</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><strong>Data</strong></p>
<p><span data-contrast="auto">Our IPUs working together with Poplar, also have a radical new approach to memory organisation. Firstly, each IPU has a huge amount of In-Processor Memory™ with our new Mk2 GC200 having an unprecedented 900MB ultra-high-speed SRAM inside the processor. This is spread across the IPU, with In-Processor Memory sitting right next to each processor core in an IPU-Tile™ for the lowest energy access per bit. 900 MB is a 3x step up in density when compared to our Mk1 IPU and is enough to hold massive models, prior state, or many layers of even the world’s largest models inside the chip running at the full speed of the processor. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">Our Poplar software also allows IPUs to access Streaming Memory™&nbsp; through&nbsp;our unique&nbsp;</span><strong><span data-contrast="auto">Exchange-Memory™</span></strong><span data-contrast="auto"> communication. This allows large models with 100’s Billions of parameters to be supported. Each IPU-Machine M2000 can support Exchange-Memory™ with up to 450GB in density and with an unprecedented bandwidth of 180TBytes/sec. As a result, the IPU Exchange-Memory delivers over a 10x advantage in density together with over a 100x advantage in memory bandwidth when compared to the very latest 7nm GPU products. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">Overall, the combination of the unique way that the IPU accesses memory, the class-leading In-Processor Memory design and Exchange Memory features, together with native support for sparsity, enable developers to execute machine learning models at very high speed, no matter how large or how complex. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><strong>Communication</strong></p>
<p><span data-contrast="auto" xml:lang="EN-GB" lang="EN-GB"><span>Unlike other solutions, you don’t need to add expensive InfiniBand networking cards to connect the IPU-Machines; each IPU-M2000 has dedicated AI networking built in. We call this<span>&nbsp;</span></span></span><strong><span data-contrast="auto" xml:lang="EN-GB" lang="EN-GB"><span>IPU-Fabric</span></span></strong><span data-contrast="auto" xml:lang="EN-GB" lang="EN-GB"><span><strong>™</strong>.</span></span></p>
<p><img src="https://www.graphcore.ai/hs-fs/hubfs/Fabric%20map.jpg?width=601&amp;name=Fabric%20map.jpg" alt="Fabric map" width="601" srcset="https://www.graphcore.ai/hs-fs/hubfs/Fabric%20map.jpg?width=301&amp;name=Fabric%20map.jpg 301w, https://www.graphcore.ai/hs-fs/hubfs/Fabric%20map.jpg?width=601&amp;name=Fabric%20map.jpg 601w, https://www.graphcore.ai/hs-fs/hubfs/Fabric%20map.jpg?width=902&amp;name=Fabric%20map.jpg 902w, https://www.graphcore.ai/hs-fs/hubfs/Fabric%20map.jpg?width=1202&amp;name=Fabric%20map.jpg 1202w, https://www.graphcore.ai/hs-fs/hubfs/Fabric%20map.jpg?width=1503&amp;name=Fabric%20map.jpg 1503w, https://www.graphcore.ai/hs-fs/hubfs/Fabric%20map.jpg?width=1803&amp;name=Fabric%20map.jpg 1803w" sizes="(max-width: 601px) 100vw, 601px"></p>
<p><span data-contrast="auto">We created a new Graphcore GC4000 IPU-Gateway chip that delivers incredibly low latency and high bandwidth, for each IPU-Machine M2000 delivering 2.8 Tbps bandwidth. As you connect more IPU-Machine M2000 systems together, the overall bandwidth grows to many Petabits/sec.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">And while IPU-Fabric has been built from the ground-up to maximise performance in IPU-based systems, it is also designed for maximum compatibility with existing datacenter infrastructure.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">IPU-Fabric uses standard copper or optical OSFP connectors, linking IPUs up and down the rack. In larger configurations, communication between IPU-PODs uses tunneling-over-Ethernet technology to maintain throughput, while allowing the use of standard QSFP interconnect and 100Gb Ethernet switches – underscoring Graphcore’s commitment to straightforward deployment in mixed-use datacenters.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">Across the entire system, IPU-Fabric uses a 3D ring topology, chosen both for maximum efficiency and because it maps well to the three dimensions of parallelism found in Machine Intelligence compute.</span></p>
<p><img src="https://play.vidyard.com/N2ErtY89YFKYapUroqdQqZ.jpg" width="1920" height="1080" alt="3D ring topology animation" data-uuid="N2ErtY89YFKYapUroqdQqZ" data-v="4" data-width="1920" data-height="1080" data-viral_sharing="0" data-embed_button="0" data-hide_playlist="1" data-color="FFFFFF" data-playlist_color="FFFFFF" data-play_button_color="2A2A2A" data-gdpr_enabled="0" data-type="inline" data-new_player_ui="1" data-autoplay="0" data-loop="0" data-muted="0" data-hidden_controls="0">

</p>


<p><span data-contrast="auto">IPU-Fabric is fully supported by our Poplar SDK. As you extend your datacenter setup through the addition of extra IPU-PODs our Virtual-IPU software is used to tell Poplar how many machines are present for each workload and all subsequent adjustments to compile and other processes are taken care of by Poplar.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">The incredible IPU-Fabric technology keeps communication latency close to constant while scaling from 10s of IPUs to 10s of thousands of IPUs.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><img src="https://www.graphcore.ai/hs-fs/hubfs/IPU%20Servers%20and%20Machine%20Images.jpg?width=601&amp;name=IPU%20Servers%20and%20Machine%20Images.jpg" alt="IPU Servers and Machine Images" width="601" srcset="https://www.graphcore.ai/hs-fs/hubfs/IPU%20Servers%20and%20Machine%20Images.jpg?width=301&amp;name=IPU%20Servers%20and%20Machine%20Images.jpg 301w, https://www.graphcore.ai/hs-fs/hubfs/IPU%20Servers%20and%20Machine%20Images.jpg?width=601&amp;name=IPU%20Servers%20and%20Machine%20Images.jpg 601w, https://www.graphcore.ai/hs-fs/hubfs/IPU%20Servers%20and%20Machine%20Images.jpg?width=902&amp;name=IPU%20Servers%20and%20Machine%20Images.jpg 902w, https://www.graphcore.ai/hs-fs/hubfs/IPU%20Servers%20and%20Machine%20Images.jpg?width=1202&amp;name=IPU%20Servers%20and%20Machine%20Images.jpg 1202w, https://www.graphcore.ai/hs-fs/hubfs/IPU%20Servers%20and%20Machine%20Images.jpg?width=1503&amp;name=IPU%20Servers%20and%20Machine%20Images.jpg 1503w, https://www.graphcore.ai/hs-fs/hubfs/IPU%20Servers%20and%20Machine%20Images.jpg?width=1803&amp;name=IPU%20Servers%20and%20Machine%20Images.jpg 1803w" sizes="(max-width: 601px) 100vw, 601px"></p>
<p><span data-contrast="auto" xml:lang="EN-GB" lang="EN-GB"><span>The IPU-Machine M2000 also enables a flexible disaggregated model, where users are not confined to a fixed ratio of CPU to Machine Intelligence compute at a server level. Rather,<span>&nbsp;</span></span><span>Graphcore</span><span><span>&nbsp;</span>customers can choose their preferred mix of CPUs and IPUs, connected via Ethernet switches. You can easily change this ratio from one workload to the next. For example, NLP has relatively low CPU host processing requirements whereas image classification may require a higher ratio of servers to support more pre-processing of the data. The IPU-Machine M2000 allows these ratios to be changed and will support new applications as they emerge.&nbsp;</span></span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><strong>Virtual-IPU™ and workload management</strong></p>
<p><span data-contrast="auto">Graphcore’s&nbsp;</span><strong><span data-contrast="auto">Virtual-IPU™&nbsp;</span></strong><span data-contrast="auto">Technology allows users to dynamically provision which IPUs they want to associate with specific hosts, and to assign workloads even down to individual IPU level.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">Virtual-IPU also supports multi-tenancy …</span></p></span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.graphcore.ai/posts/introducing-second-generation-ipu-systems-for-ai-at-scale">https://www.graphcore.ai/posts/introducing-second-generation-ipu-systems-for-ai-at-scale</a></em></p>]]>
            </description>
            <link>https://www.graphcore.ai/posts/introducing-second-generation-ipu-systems-for-ai-at-scale</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842281</guid>
            <pubDate>Wed, 15 Jul 2020 07:26:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[This Website Is Killing the Planet]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 11 (<a href="https://news.ycombinator.com/item?id=23842225">thread link</a>) | @brokebroadbeat
<br/>
July 15, 2020 | https://visitmy.website/2020/07/13/this-website-is-killing-the-planet/ | <a href="https://web.archive.org/web/*/https://visitmy.website/2020/07/13/this-website-is-killing-the-planet/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>For a while I’ve been intending to make my website more sustainable, but I succumbed, as I often do, to the human trait of sloth. But this morning after reading <a href="https://alistapart.com/article/webwaste/">Gerry McGovern’s post on webwaste</a>, I thought I’d procrastinated long enough.</p>

<p>So I ran a web page performance test and got some <a href="https://www.webpagetest.org/result/200713_XX_e2daed33a24cd8a099d930fc373b1083/">grim results</a>: my website takes over a minute to load on a Moto G4 on using 3G data networks. It’s just as bad <a href="https://www.webpagetest.org/result/200713_6E_4e249b485a45882604420068caa21ae0/">using a desktop PC in Nottingham on 1.5Mbps DSL</a>. My website is bloated with large images and a bunch of JavaScript, which means it’s eating up lots of energy transmitting those bits and bytes.</p>

<p>But how much energy? I used the <a href="https://www.websitecarbon.com/">Website Carbon Calculator</a> to find out. Turns out that</p>

<ul>
  <li>6.90g of CO2 is produced every time someone visits the homepage</li>
  <li>it emits the amount of carbon that 4 trees absorb in a year, and</li>
  <li>it uses enough electricity to drive an electric car 1,116km</li>
</ul>

<p>Eugh. That’s disgusting. For each year my website has been online, I should have planted 4 trees just for the homepage alone. But, instead, my laziness has filled the atmosphere with more and more carbon.</p>

<p>I have to do something, this has gone on long enough, so I’m committing to some actions.</p>

<ol>
  <li>I’ll move my site to a web hosting provider using renewable energy, one that’s listed on the <a href="https://www.thegreenwebfoundation.org/directory/">Green Web Foundation’s directory</a>. <strong>DONE</strong></li>
  <li>I’ll compress and optimise the images on my site using <a href="https://imageoptim.com/mac">ImageOptim</a>. <strong>DONE</strong></li>
  <li>I’ll get rid of <a href="https://github.com/samesies/barber-jekyll">my energy-guzzling site theme</a> until I can introduce one that’s lightweight and accessible. <strong>DONE</strong></li>
  <li>Going forward, my website will enshrine the principles of the <a href="https://www.sustainablewebmanifesto.com/">Sustainable Web Manifesto</a>. <strong>SIGNED</strong></li>
  <li><strong>NEW</strong>: I’ll pay for some trees to be planted that’ll reduce the impact of my website’s carbon footprint going forward.</li>
</ol>

<p>To show my committment to being a good web citizen, I’ll add the <a href="https://www.websitecarbon.com/badge/">Website Carbon Badge</a> to all pages (<strong>DONE</strong>) and the <a href="https://www.thegreenwebfoundation.org/green-web-check/">Green Web Foundation’s renewable hosting badge</a> (<strong>DONE</strong>). Once I’ve improved things, I’ll add a <a href="https://carbontxt.org/">carbon.txt</a> (<strong>DONE</strong>).</p>

<p>One day I’ll actually get around to building a solar-powered battery bank and run my site off my home connection, but until then I’m taking small steps to remove, minimise and clean-up my presence on the web.</p>

<p>What’s the carbon footprint of your website? What steps will you take to reduce it?</p>

<h2 id="further-reading">Further reading</h2>

<ul>
  <li><a href="https://alistapart.com/article/webwaste/">Webwaste</a></li>
  <li><a href="https://pxlnv.com/blog/bullshit-web/">The bullshit web</a></li>
  <li><a href="https://www.wholegraindigital.com/blog/sustainable-web-design/">3 steps to creating zero carbon websites</a></li>
  <li><a href="https://solar.lowtechmagazine.com/2018/09/how-to-build-a-lowtech-website.html">How to build a low-tech website</a></li>
  <li><a href="https://www.thegreenwebfoundation.org/news/notes-for-greening-internet-governance-at-eurodig/">Greening Internet governance: environmental sustainability and digital transformation</a></li>
</ul>

  </div>
</article>



      </div>
    </div></div>]]>
            </description>
            <link>https://visitmy.website/2020/07/13/this-website-is-killing-the-planet/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842225</guid>
            <pubDate>Wed, 15 Jul 2020 07:15:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You Shouldn’t Use LinkedIn Automation Tools Using Your Own Account]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23842205">thread link</a>) | @ferlita
<br/>
July 15, 2020 | https://nubela.co/blog/why-you-shouldnt-use-linkedin-automation-tools-using-your-own-account/ | <a href="https://web.archive.org/web/*/https://nubela.co/blog/why-you-shouldnt-use-linkedin-automation-tools-using-your-own-account/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://nubela.co/blog/why-you-shouldnt-use-linkedin-automation-tools-using-your-own-account/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842205</guid>
            <pubDate>Wed, 15 Jul 2020 07:12:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Snorkel AI: Putting Data First in ML Development]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23842195">thread link</a>) | @dsr12
<br/>
July 15, 2020 | https://www.snorkel.ai/07-14-2020-snorkel-ai-launch | <a href="https://web.archive.org/web/*/https://www.snorkel.ai/07-14-2020-snorkel-ai-launch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                  <p>
                      Today I’m excited to announce Snorkel AI’s launch out of stealth!
                      Snorkel AI, which spun out of the Stanford AI Lab in 2019, was founded on two simple premises: first, that the labeled <b>training data</b>  machine learning models learn from is increasingly what determines the success or failure of AI applications.
                      And second, that we can do much better than labeling this data entirely by hand.
                  </p>
                  <p>
                      At the Stanford AI lab, the Snorkel AI founding team spent over four years developing new <b>programmatic</b> approaches to labeling, augmenting, structuring, and managing this training data.
                      We were fortunate to develop and deploy early versions of our technology with some of the world’s leading organizations like <a href="https://ai.googleblog.com/2019/03/harnessing-organizational-knowledge-for.html">Google</a>, <a href="https://dl.acm.org/doi/abs/10.1145/3329486.3329492">Intel</a>, <a href="https://arxiv.org/abs/1909.05372">Apple</a>, <a href="https://www.sciencedirect.com/science/article/pii/S2666389920300192">Stanford Medicine</a>, resulting in <a href="https://www.snorkel.ai/technology#reference">over thirty-six peer-reviewed publications</a> on our findings; innovations in weak supervision modeling, data augmentation, multi-task learning, and more; inclusion in university computer science curriculums; and deployments in popular products and systems that you’ve likely interacted with in the last few hours.
                  </p>
                  <p>
                      Through all this academic tinkering and industry spelunking, we realized two things: first, that this concept of labeling and building training data programmatically, rather than by hand, had transformational potential to make machine learning more iterative, auditable, faster to deploy, and ultimately, more practical.
                      And second, that these ideas changed not just how you label training data, but so much of the entire lifecycle and pipeline of ML: how knowledge and feedback is injected; how models are constructed, trained, versioned, and monitored; how entire pipelines are developed iteratively; and how the full set of stakeholders in any ML deployment, from subject matter experts to ML engineers, are incorporated into the process.
                  </p>
                  <p>
                      In other words, we saw that this shift to programmatic training data required a top-to-bottom rewrite of the entire ML development and deployment process.
                      With the support of some amazing investors (Greylock, GV, In-Q-Tel, and others) and incredible early customers, we’ve spent the last year doing just this: building and deploying <a href="https://www.snorkel.ai/platform">Snorkel Flow</a>, an end-to-end platform to support this new vision of the ML process.
                  </p>
                  <h2>The Training Data Bottleneck</h2>
                  <p>
                      Snorkel Flow was motivated first and foremost by a growing realization that training data had become the key bottleneck in much of ML pipeline and AI application development.
                  </p>
                  <p><img data-src="https://d33wubrfki0l68.cloudfront.net/f63e7bd828cf6019ca0add38ca51ca4050dfeea5/288e4/images/training_data_bottleneck.png" alt="" src="https://d33wubrfki0l68.cloudfront.net/f63e7bd828cf6019ca0add38ca51ca4050dfeea5/288e4/images/training_data_bottleneck.png"></p><p>
                      <b>Today’s ML successes often rest on a hidden cost: massive, hand-labeled training datasets.</b>
                      In the last decade, we’ve seen a tectonic shift in AI and ML towards powerful but data-hungry representation learning models.
                      These models—often deep learning architectures—are not only more powerful at obviating traditionally manual development tasks like feature engineering and bespoke model design, but also have never been more accessible in the open source.
                      However, there’s no such thing as a free lunch: these models are highly complex, with tens to hundreds of millions of parameters, and they require massive labeled training datasets to learn from.
                      And, other than in special scenarios where labels are naturally derivative of existing processes, these training datasets need to be labeled by hand.
                  </p>
                  <p>
                      <b>The hand-labeled training data interface to ML has enabled tremendous progress, but is also ridiculously broken.</b>
                      Consider a simple example: a legal analyst at a bank wants to train a contract classification model, and wants to inject a simple heuristic into the ML model: that if “employment” is in the title, the contract should be labeled as an “Employment contract.”
                      Simple, right?
                      Not so.
                      Theoretically, to communicate this specific feature to a machine learning model via only labeling individual data points could require thousands of examples (roughly, inversely proportional to the sparsity of the feature space).
                      From this perspective, it’s like playing 20 questions rather than just communicating the answer directly—fine if you have a massive question-answer bank, but otherwise wholly impractical.
                  </p>
                  <p>
                      <b>Manually labeling training data is prohibitively expensive–especially when expertise and privacy are required.</b>
                      Building training datasets often requires <a href="http://nytimes.com/2018/11/25/business/china-artificial-intelligence-labeling.html">armies of human labelers</a> at massive cost and time expense.
                      For example, ImageNet—one of the foundational projects behind ML’s current explosive progress—took <a href="https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world/">over two years</a> to create.
                      However, labeling cats, dogs, stop signs, and pedestrians is one thing; labeling data like medical images, legal and financial contracts, government documents, user data, and network data requires <b>stringent privacy protections</b> and <b>subject matter expert labelers</b>.
                      This means for sectors like financial services, government, telecommunications, insurance, healthcare, and more, creating training data (and by extension, using ML) is either a hugely expensive on-premise activity—or more often, one that is just not feasible to tackle, let alone practical.
                  </p>
                  <p>
                      <b>Iterative development is not possible with hand-labeled data.</b>
                      From an engineering and data science perspective, manually labeled training data fundamentally breaks the ability to quickly iterate, which is absolutely essential in real world settings where input data, output goals, and annotation schema change all the time.
                      From a business perspective, training data is an expensive asset that can’t be reused across projects, can often depreciate to worthless overnight due to changing conditions or business goals, and that presents growing risks—everything from <a href="https://web.archive.org/web/20200703104247/https://cloud.google.com/ai-platform/data-labeling/docs">COVID-related delays</a> to <a href="https://www.theverge.com/2018/1/12/16882408/google-racist-gorillas-photo-recognition-algorithm-ai">issues of bias</a>.
                  </p>
                  <h2>A New Input Paradigm for ML: Programming with Data</h2>
                  <p>
                      With Snorkel Flow, rather than needing to hand-label any training data, users develop <b>programmatic operators</b> that label, augment, and build training data to drive the ML development process.
                  </p>
                  <p><img data-src="https://d33wubrfki0l68.cloudfront.net/ae088a1fc7f3c6326c2e7285bc2d3c7e88907290/ad302/images/platform-label-v3.png" alt="" src="https://d33wubrfki0l68.cloudfront.net/ae088a1fc7f3c6326c2e7285bc2d3c7e88907290/ad302/images/platform-label-v3.png"></p><p>
                      <b>Programmatically labeling and building training data.</b>
                      With Snorkel Flow, the idea is to instead communicate this domain knowledge directly via a programmatic operator like a <a href="https://papers.nips.cc/paper/6523-data-programming-creating-large-training-sets-quickly">labeling function</a>.
                      For example, our legal analyst could write a labeling function that labels documents as “Employment contracts” if the word “employment” is in the title, and otherwise abstains; or, a range of more complex and powerful labeling functions relying on internal knowlegebases, models, legacy heuristics, and more.
                      This approach of effectively programming ML with data is simple, direct, interpretable, modifiable, and agnostic to the model used (which is especially important given the ongoing Cambrian explosion of powerful new open source model architectures).
                  </p>
                  <p>
                      <b>The directness of rules with the flexibility of ML.</b>
                      Rule-based systems have long been used in industry for certain tasks—as an input, individual rules have the desirable property of being direct and interpretable.
                      However, rules can also be brittle, and lack the robustness, flexibility, and sheer power of ML approaches.
                      With Snorkel Flow, you get the best of both worlds: rules (and other interpretable resources) as inputs, and powerful ML models that generalize beyond these rules as the output.
                  </p>
                  <p><img data-src="https://d33wubrfki0l68.cloudfront.net/8b9653f8e7b7803550e9afd55284d43beb190fbe/e2b34/images/platform-manage-v3.png" alt="" src="https://d33wubrfki0l68.cloudfront.net/8b9653f8e7b7803550e9afd55284d43beb190fbe/e2b34/images/platform-manage-v3.png"></p><p>
                      <b>A more powerful yet weaker supervision.</b>
                      At the same time that this programmatic supervision is advantageous in several transformational ways, it is also messier and raises fundamental new technical challenges.
                      The labeling functions and other programmatic operators that users write will have varying unknown accuracies and expertise areas, will overlap and disagree with each other, and may be correlated in tangled and unknown ways.
                      We focused on the algorithmic and systems solutions to these issues over <a href="https://www.snorkel.ai/technology">four-plus years of research</a>, showing both empirically and theoretically that with the right techniques, these deep technical challenges can be overcome.
                      The result: training data that is as good as or better than hand-labeled data, and immensely more practical to create and maintain.
                  </p>
                  <p>
                      <b>Beyond labeling: data augmentation, slicing, monitoring, and more.</b>
                      In high-performance production ML, training data is about a lot more than labeling.
                      For example, data augmentation is a cornerstone technique wherein transformed copies of data (e.g. rotated or blurred images) are used to expand the sizes of training datasets, and make resulting models more robust.
                      Slicing or structuring training datasets into more or less important and difficult subsets is also a critical part of managing production ML. 
                      Finally, monitoring and adapting not just models but …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.snorkel.ai/07-14-2020-snorkel-ai-launch">https://www.snorkel.ai/07-14-2020-snorkel-ai-launch</a></em></p>]]>
            </description>
            <link>https://www.snorkel.ai/07-14-2020-snorkel-ai-launch</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842195</guid>
            <pubDate>Wed, 15 Jul 2020 07:10:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Riot is now Element]]>
            </title>
            <description>
<![CDATA[
Score 413 | Comments 254 (<a href="https://news.ycombinator.com/item?id=23842179">thread link</a>) | @J_tt
<br/>
July 15, 2020 | https://element.io/blog/welcome-to-element/ | <a href="https://web.archive.org/web/*/https://element.io/blog/welcome-to-element/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Hi everyone,</p><p>We are incredibly excited to announce that <strong>Riot is now Element</strong>! </p><p>In fact we have simplified all our naming: Element is also the name for New Vector (the company behind Riot) while Modular, our flagship Matrix hosting service, has become Element Matrix Services.</p><p>For those discovering us for the first time: Element is the flagship secure collaboration app for the decentralised <a href="https://matrix.org/">Matrix</a> communication network. &nbsp;Element lets you own your own end-to-end encrypted chat server, while still connecting to everyone else in the wider Matrix network.</p><figure><img src="https://element.io/blog/content/images/2020/07/element-logo.png"></figure><p><br>What’s more, <strong>RiotX is now out of beta</strong> - our next generation Matrix client for Android has flown the nest and spread its wings as Element - replacing the old Riot Android app at last!</p><p>This name change has been a long time in the making. As we explained when we announced the rebrand <a href="https://blog.riot.im/the-world-is-changing/">a few weeks ago</a>, we’ve had major issues with a certain gigantic games company which has blocked us from being able to trademark Riot or even Riot.im - a huge issue when it comes to defending users against abusive forks of the app. Secondly, people incorrectly assume Riot refers to violence, rather than the more constructive forms of chaos we had in mind. Lastly, it made sense in the early days of Matrix to have different brands to illustrate the different roles of Riot, Modular and New Vector in the ecosystem… but nowadays there are loads of Matrix clients, Matrix hosting providers and companies building on Matrix - and so all New Vector’s different names were just causing confusion. &nbsp;</p><h3 id="so-why-element">So, why Element?</h3><p>We want a name that reflects the emphasis on simplicity and clarity that we aimed for when designing RiotX; a name that highlights our single-minded mission to make Element the most elegant and usable mainstream comms app imaginable. &nbsp;Riot had a pretty chequered history, spending much of its life in beta, with intermittent attention to design until we hit 1.0 last year - but nowadays we have a dedicated full-time design team working on Element, who not only design the graphics but the overall behaviour of new features in the app. &nbsp;This is not an easy task, given it turns out the hardest bits of end-to-end encryption are almost entirely UX challenges. &nbsp;What’s more, presenting a global decentralised communication network as simply as a centralised communication island is surprisingly tricky. &nbsp;However: we have been making massive progress, to the extent that we are barely recognisable as the Riot of the past. Element reflects a clean start to focus monomaniacally on mainstream usability in future.</p><p>We also want a name that better evokes the idea of data ownership and self-sovereignty. &nbsp;An element is the smallest indivisible thing in a system - yet one which can stand alone. &nbsp;You can customise it, control it and make it your own - you can literally be in your Element!</p><p>Moreover, we want a name that will be future-proof for peer-to-peer Matrix. &nbsp;As Matrix.org announced last month, <a href="https://matrix.org/blog/2020/06/02/introducing-p-2-p-matrix">P2P Matrix is in heavy development</a> - and we can see a world where Element will literally be an element of Matrix, running your own homeserver within the app, so you can communicate if you don’t have a server… or even Internet. In fact, we published the first experimental build of <a href="https://matrix.org/blog/2020/07/10/this-week-in-matrix-2020-07-10#riot-ios-p2p-demo">P2P Riot for iOS</a> on Testflight a few days ago - so we can clearly see a future where we will be in our P2P element!</p><p>Finally, we think it’s a cool name :D &nbsp;It fits in nicely with the term Matrix while not being as nerdy as Vector. &nbsp;We’re obviously aware that Element is (once again) both a dictionary word and a mathematical term - but in practice, looking at search results for Element right now, the top hits are for dictionary sites(!) and the field is wide open. &nbsp;Conversely, in a virgin browser on VPN, Riot is the 4th hit on Google for Riot; second only to a certain games company. &nbsp;In other words, we’ve shown that we can successfully adopt dictionary words - and if you do find yourself lost searching in a maze of mathematics, just throw in the word ‘chat’ to get back on track. &nbsp;(For all the linear algebraists who are spitting with rage at this point: we promise we’ll make it up to you by finally sorting out <a href="https://github.com/matrix-org/matrix-react-sdk/pull/3251">latex support</a> in Element!)</p><p>This change is inevitably going to be disruptive, and we’re painfully aware that we’ve spent four years building up Riot’s reputation and persuading everyone to move their friends, families and teams onto it. &nbsp;To reiterate what we said when we announced the change, we know that many people reading this will have put their necks on the line to get folks to adopt Riot, and we really appreciate how frustrating it may be to have to explain the change to your users. &nbsp;However, this is unquestionably the right time to shed our skin and make the change, and we hope folks will grow to love Element much more than they ever did Riot. &nbsp;To aid the transition, we’ve named the installable apps “Element (Riot.im)” for a while to help people get reoriented (e.g. when searching by name for Riot).</p><p>Last but not least: Element isn’t just a new name - it comes with a massive suite of improvements across Android, iOS and Web.</p><p>We’ll write about these in full over the coming days, but the big headlines are that RiotX (our ground-up rewrite of Riot Android) has exited beta, and replaces Riot Android as Element - complete with VoIP calls and Widget support! Riot Android users will magically autoupgrade into Element; the old RiotX app will be retired in due course. FDroid is likely releasing Element as an entirely new app. &nbsp;Meanwhile On iOS we now have full support for iOS 13, complete with entirely new push notification support (thanks to Apple’s nightmarish <a href="https://appleinsider.com/articles/19/09/05/secure-messaging-apps-working-to-comply-with-apples-ios-13-privacy-changes">deprecation of PushKit</a>).</p><figure><img src="https://element.io/blog/content/images/2020/07/RiotX-1.png"><figcaption>The App Formerly Known As RiotX!</figcaption></figure><p>On Element Web, we’ve given the UI a massive refresh, with a beautiful new font (<a href="https://rsms.me/inter/">Inter</a>) giving much improved legibility, and we’ve <strong>completely</strong> rewritten the Room List control - adding in room previews(!!), alphabetic ordering, resizable lists, improved notification UI and more. We’ve also landed the first phase of further improving the end-to-end encryption setup process - letting users generate a recovery key rather than forcing them to select a recovery passphrase when setting up E2EE for the first time (the next phase is to delay setting up E2EE until the user actually starts talking in encrypted rooms).</p><figure><img src="https://element.io/blog/content/images/2020/07/Screenshot-2020-07-15-at-00.54.45.png"></figure><p>So there you have it. Welcome to a whole new beginning for Riot: welcome to your new Element, one where mainstream Matrix users will enjoy themselves too - and which will pave the way for wider adoption of open, secure, decentralised communication via Matrix throughout the world.</p><p>- Matthew, Amandine, and the whole Element team.</p><p>P.S. Check out our <a href="https://element.io/">all-new website</a> and in particular the <a href="https://element.io/previously-riot">migration page</a> for much more information about our brave new world!<br></p></div></div>]]>
            </description>
            <link>https://element.io/blog/welcome-to-element/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842179</guid>
            <pubDate>Wed, 15 Jul 2020 07:07:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Welcome to Element [Riot chat rebranded as Element]]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23842154">thread link</a>) | @ptman
<br/>
July 15, 2020 | https://element.io/blog/welcome-to-element/ | <a href="https://web.archive.org/web/*/https://element.io/blog/welcome-to-element/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Hi everyone,</p><p>We are incredibly excited to announce that <strong>Riot is now Element</strong>! </p><p>In fact we have simplified all our naming: Element is also the name for New Vector (the company behind Riot) while Modular, our flagship Matrix hosting service, has become Element Matrix Services.</p><p>For those discovering us for the first time: Element is the flagship secure collaboration app for the decentralised <a href="https://matrix.org/">Matrix</a> communication network. &nbsp;Element lets you own your own end-to-end encrypted chat server, while still connecting to everyone else in the wider Matrix network.</p><figure><img src="https://element.io/blog/content/images/2020/07/element-logo.png"></figure><p><br>What’s more, <strong>RiotX is now out of beta</strong> - our next generation Matrix client for Android has flown the nest and spread its wings as Element - replacing the old Riot Android app at last!</p><p>This name change has been a long time in the making. As we explained when we announced the rebrand <a href="https://blog.riot.im/the-world-is-changing/">a few weeks ago</a>, we’ve had major issues with a certain gigantic games company which has blocked us from being able to trademark Riot or even Riot.im - a huge issue when it comes to defending users against abusive forks of the app. Secondly, people incorrectly assume Riot refers to violence, rather than the more constructive forms of chaos we had in mind. Lastly, it made sense in the early days of Matrix to have different brands to illustrate the different roles of Riot, Modular and New Vector in the ecosystem… but nowadays there are loads of Matrix clients, Matrix hosting providers and companies building on Matrix - and so all New Vector’s different names were just causing confusion. &nbsp;</p><h3 id="so-why-element">So, why Element?</h3><p>We want a name that reflects the emphasis on simplicity and clarity that we aimed for when designing RiotX; a name that highlights our single-minded mission to make Element the most elegant and usable mainstream comms app imaginable. &nbsp;Riot had a pretty chequered history, spending much of its life in beta, with intermittent attention to design until we hit 1.0 last year - but nowadays we have a dedicated full-time design team working on Element, who not only design the graphics but the overall behaviour of new features in the app. &nbsp;This is not an easy task, given it turns out the hardest bits of end-to-end encryption are almost entirely UX challenges. &nbsp;What’s more, presenting a global decentralised communication network as simply as a centralised communication island is surprisingly tricky. &nbsp;However: we have been making massive progress, to the extent that we are barely recognisable as the Riot of the past. Element reflects a clean start to focus monomaniacally on mainstream usability in future.</p><p>We also want a name that better evokes the idea of data ownership and self-sovereignty. &nbsp;An element is the smallest indivisible thing in a system - yet one which can stand alone. &nbsp;You can customise it, control it and make it your own - you can literally be in your Element!</p><p>Moreover, we want a name that will be future-proof for peer-to-peer Matrix. &nbsp;As Matrix.org announced last month, <a href="https://matrix.org/blog/2020/06/02/introducing-p-2-p-matrix">P2P Matrix is in heavy development</a> - and we can see a world where Element will literally be an element of Matrix, running your own homeserver within the app, so you can communicate if you don’t have a server… or even Internet. In fact, we published the first experimental build of <a href="https://matrix.org/blog/2020/07/10/this-week-in-matrix-2020-07-10#riot-ios-p2p-demo">P2P Riot for iOS</a> on Testflight a few days ago - so we can clearly see a future where we will be in our P2P element!</p><p>Finally, we think it’s a cool name :D &nbsp;It fits in nicely with the term Matrix while not being as nerdy as Vector. &nbsp;We’re obviously aware that Element is (once again) both a dictionary word and a mathematical term - but in practice, looking at search results for Element right now, the top hits are for dictionary sites(!) and the field is wide open. &nbsp;Conversely, in a virgin browser on VPN, Riot is the 4th hit on Google for Riot; second only to a certain games company. &nbsp;In other words, we’ve shown that we can successfully adopt dictionary words - and if you do find yourself lost searching in a maze of mathematics, just throw in the word ‘chat’ to get back on track. &nbsp;(For all the linear algebraists who are spitting with rage at this point: we promise we’ll make it up to you by finally sorting out <a href="https://github.com/matrix-org/matrix-react-sdk/pull/3251">latex support</a> in Element!)</p><p>This change is inevitably going to be disruptive, and we’re painfully aware that we’ve spent four years building up Riot’s reputation and persuading everyone to move their friends, families and teams onto it. &nbsp;To reiterate what we said when we announced the change, we know that many people reading this will have put their necks on the line to get folks to adopt Riot, and we really appreciate how frustrating it may be to have to explain the change to your users. &nbsp;However, this is unquestionably the right time to shed our skin and make the change, and we hope folks will grow to love Element much more than they ever did Riot. &nbsp;To aid the transition, we’ve named the installable apps “Element (Riot.im)” for a while to help people get reoriented (e.g. when searching by name for Riot).</p><p>Last but not least: Element isn’t just a new name - it comes with a massive suite of improvements across Android, iOS and Web.</p><p>We’ll write about these in full over the coming days, but the big headlines are that RiotX (our ground-up rewrite of Riot Android) has exited beta, and replaces Riot Android as Element - complete with VoIP calls and Widget support! Riot Android users will magically autoupgrade into Element; the old RiotX app will be retired in due course. FDroid is likely releasing Element as an entirely new app. &nbsp;Meanwhile On iOS we now have full support for iOS 13, complete with entirely new push notification support (thanks to Apple’s nightmarish <a href="https://appleinsider.com/articles/19/09/05/secure-messaging-apps-working-to-comply-with-apples-ios-13-privacy-changes">deprecation of PushKit</a>).</p><figure><img src="https://element.io/blog/content/images/2020/07/RiotX-1.png"><figcaption>The App Formerly Known As RiotX!</figcaption></figure><p>On Element Web, we’ve given the UI a massive refresh, with a beautiful new font (<a href="https://rsms.me/inter/">Inter</a>) giving much improved legibility, and we’ve <strong>completely</strong> rewritten the Room List control - adding in room previews(!!), alphabetic ordering, resizable lists, improved notification UI and more. We’ve also landed the first phase of further improving the end-to-end encryption setup process - letting users generate a recovery key rather than forcing them to select a recovery passphrase when setting up E2EE for the first time (the next phase is to delay setting up E2EE until the user actually starts talking in encrypted rooms).</p><figure><img src="https://element.io/blog/content/images/2020/07/Screenshot-2020-07-15-at-00.54.45.png"></figure><p>So there you have it. Welcome to a whole new beginning for Riot: welcome to your new Element, one where mainstream Matrix users will enjoy themselves too - and which will pave the way for wider adoption of open, secure, decentralised communication via Matrix throughout the world.</p><p>- Matthew, Amandine, and the whole Element team.</p><p>P.S. Check out our <a href="https://element.io/">all-new website</a> and in particular the <a href="https://element.io/previously-riot">migration page</a> for much more information about our brave new world!<br></p></div></div>]]>
            </description>
            <link>https://element.io/blog/welcome-to-element/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842154</guid>
            <pubDate>Wed, 15 Jul 2020 07:01:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Create a sleek UI in Flutter – Wolt app case study]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23842062">thread link</a>) | @czajuuu
<br/>
July 14, 2020 | https://www.nomtek.com/blog/sleek-ui-in-flutter-wolt | <a href="https://web.archive.org/web/*/https://www.nomtek.com/blog/sleek-ui-in-flutter-wolt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>Flutter is Google’s UI toolkit for building beautiful, natively compiled applications for mobile, web, and desktop from a single codebase</em>. We are going to check its promises by recreating part of an existing application as accurately as possible. I chose the Wolt app because the Wolt team has been doing an amazing job, creating sleek UI &amp; UX with many subtle details.</p><figure id="w-node-ef7dc46c635c-c5de3bde"><p><iframe allowfullscreen="true" frameborder="0" scrolling="no" src="https://www.youtube.com/embed/UI9vN8Y583o"></iframe></p></figure><p>‍<br></p><p>My goal for this series is to present a thought process that leads to the desired result rather than provide a copy-paste solution. We will work in a build-refactor cycle, examining potential problems and framework limitations. You may find the whole code for this series on our github: <a href="https://github.com/nomtek/flutter-meets-wolt">https://github.com/nomtek/flutter-meets-wolt</a>.<br>Let’s dive in!<br></p><h2>App bar buttons &amp; menu</h2><p>Let’s warm up with something that seems to be simple - app bar buttons. There are two of them - one is used to navigate back, and the other is showing a menu with two items. My first idea was to use <em>IconButton</em> composed with <em>Container</em> that has circle-shaped decoration:</p><div>
<pre>class AppBarButton extends StatelessWidget {
  final IconData icon;
  final VoidCallback onPressed;
     
     const AppBarButton({Key key, this.icon, this.onPressed}) : super(key: key);

  @override
  Widget build(BuildContext context) {
    return Container(
      decoration: BoxDecoration(shape: BoxShape.circle, color: Colors.grey[300]),
      child: IconButton(
        icon: Icon(icon),
        onPressed: onPressed,
      ),
    );
  }
}
     </pre>
</div><p>When we put those widgets in an AppBar:</p><div>
<pre>SliverAppBar(
  leading: AppBarButton(
    icon: Icons.keyboard_backspace,
    onPressed: () =&gt; Navigator.pop(context),
  ),
  actions: [
    AppBarButton(
      icon: Icons.more_horiz,
      onPressed: () { /* TODO */ },
    ),
  ],
  </pre>
  </div><p>The result is already quite similar to what we have in the original application:<br></p><figure><p><img src="https://global-uploads.webflow.com/5c95072393140f36ecc22e60/5eeca98badfe870ce2c0e65a_Hnet.com-image.gif" alt=""></p></figure><p>Our first implementation has no padding and buttons are too big. When we press the button it shows a grey highlight followed by an animated, darker splash instead of opacity change. Let’s try to implement those missing features.</p><h2>Size and layout</h2><p>On the iPhone 8, original buttons have a size of 40x40 points, 16 points margin to the screen edge and 8 points bottom offset. Given that app bar has a height of 44 points on this iPhone it would mean that those buttons have to overlay status bar (the one with signal strength, clock and battery status) and indeed they are:<br></p><figure id="w-node-53719c61cb64-c5de3bde"><p><img src="https://global-uploads.webflow.com/5c95072393140f36ecc22e60/5eeca9d84b65ff38701fee0a_overlay.png" alt="flutter_overlay"></p></figure><p>We can apply those constraints by wrapping our button widgets in <em>Padding</em> and <em>Align</em>.</p><div>
<pre>    return Padding(
      padding: EdgeInsets.fromLTRB(
        position == AppBarPosition.leading ? 16 : 0, 0,
        position == AppBarPosition.trailing ? 16 : 0, 8),
      child: Align(
        alignment: Alignment.topCenter,
        child: Container(
          width: 40,
          height: 40,
(...)

  </pre>
  </div><figure id="w-node-11a065b0312c-c5de3bde"><p><img src="https://global-uploads.webflow.com/5c95072393140f36ecc22e60/5eecaa077f68da65b8562c7c_56px_app_bar.png" alt="flutter_app_bar"></p></figure><p>One difference is that the bottom offset is bigger in our implementation and we don’t even overflow status bar. The reason is that the height of our app bar is calculated based on the <em>const double kToolbarHeight = 56.0; </em>constant from the Flutter framework. There is no explicit way to set app bar height, eg. by constructor parameter, and the class responsible for the app bar layout, which uses this constant, is private (<em>_SliverAppBarDelegate</em>). This prevents us from using inheritance to override the code responsible for height computation. This delegate is, again, not exposed by the app bar (<em>SliverAppBar</em>), so even if we end up creating our own version, we won’t be able to use it unless we also extend <em>SliverAppBar</em> and override<em> build</em> method from its state. Since Flutter is open source this could be done in a few minutes, by copy-paste original implementation and tweaking those details, but it’s far from feasible solution as we would have to maintain our version and keep it in sync with improvements made by the Flutter team to the original classes.<br></p><p>It’s worth to take a note, that<em> kToolbarHeight</em> is also used to constraint the width of the leading widget (back button in our case), forcing it to be a square. This is how our app bar looks like with margins increased to 25 points. Notice shrunken leading button, while trailing is spaced from the screen edge as expected. This limitation has no effect in our case, as designed margin and button size is exactly matching available space.<br></p><figure id="w-node-0b501ed6363f-c5de3bde"><p><img src="https://global-uploads.webflow.com/5c95072393140f36ecc22e60/5eecaa3d49a49185d4d77cdd_25px_margin.png" alt="flutter_margin"></p></figure><h2>Highlight behaviour<br></h2><p>In the Wolt app when the button is highlighted it changes the opacity of the icon. There is no highlight colour change or splash animation. We can re-create such behaviour by wrapping button in the <em>Opacity</em> widget. To track highlight status we have to introduce an internal state, represented by the <em>_isHighlighted</em> boolean property. That means we have to refactor our widget from stateless to stateful:</p><div>
<pre>enum AppBarPosition {
  leading,
  trailing,
}

class AppBarButton extends StatefulWidget {
  final IconData icon;
  final VoidCallback onPressed;
  final AppBarPosition position;

  const AppBarButton({Key key, this.icon, this.onPressed, this.position}) : super(key: key);

  @override
  _AppBarButtonState createState() =&gt; _AppBarButtonState();
}

class _AppBarButtonState extends State<appbarbutton> {

  bool _isHighlighted = false;

  @override
  Widget build(BuildContext context) {
    return Padding(
      padding: EdgeInsets.fromLTRB(widget.position == AppBarPosition.leading ? 16 : 0, 0,
          widget.position == AppBarPosition.trailing ? 16 : 0, 8),
      child: Align(
        alignment: Alignment.topCenter,
        child: Container(
          width: 40,
          height: 40,
          decoration: BoxDecoration(shape: BoxShape.circle, color: Colors.grey[300]),
          child: Opacity(
            opacity: _isHighlighted ? 0.3 : 1.0,
            child: IconButton(
              icon: Icon(
                widget.icon,
                color: Colors.black,
              ),
              onPressed: widget.onPressed,
            ),
          ),
        ),
      ),
    );
  }
}
  </appbarbutton></pre>
  </div><p>Unfortunately, <em>IconButton</em> we are using is not exposing <em>onHighlightChanged</em> callback - only <em>onPressed</em>, which is not enough for our needs. We have to refactor our code to use more generic button class, like<em> RawMaterialButton</em> where we have more control over callbacks and visual settings.</p><div>
<pre>  child: RawMaterialButton(
    highlightColor: Colors.transparent,
    splashColor: Colors.transparent,
    onHighlightChanged: (isHighlighted) =&gt; setState(() {
      _isHighlighted = isHighlighted;
    }),
    child: Icon(
      widget.icon,
      color: Colors.black,
    ),
    onPressed: widget.onPressed,
  ),
</pre>
</div><h2>Showing the menu<br></h2><p>When the user presses menu button two things happen - the menu is shown and the button icon changes from three dots to close cross. We are going to track the current state in the boolean property <em>_isMenuShown </em>in the State of the screen-route. Updated menu button:</p><div>
<pre>    AppBarButton(
      icon: _isMenuShown ? Icons.close : Icons.more_horiz,
      position: AppBarPosition.trailing,
      onPressed: () {
        Navigator.push(context, AppBarMenu())
            .then((_) =&gt; setState(() =&gt; _isMenuShown = false));
        setState(() =&gt; _isMenuShown = true);
      },
    ),
</pre>
</div><p>We will build <em>AppBarMenu</em> class that extends <em>PopupRoute</em>, as it gives us more control over UI of the menu than <em>PopupMenuButton</em> from the Flutter framework. On button press, Navigator widget is tasked to push our Route to the stack. Push method returns a future which completes after this route is dismissed - that’s why we set <em>_isMenuShown</em> to false in the <em>then </em>callback.</p><h2>Menu look &amp; feel<br></h2><p>Our final task is to build a menu that will be displayed. It’s pretty straightforward - a list with two items, the less obvious parts maybe how to place it on the screen, and how to achieve the shape of a rectangle with rounded corners and triangle indicator on top. We are going to use <em>ClipPath</em> widget with a custom clipper to build the desired shape. An alternative solution would be to compose <em>ClipRRect</em> (RRect stands for rounded rectangle) with an <em>Image</em> widget for the top triangle. Yet another idea is to have a whole background as a nine-patch image, and there are for sure a few more feasible options to achieve the desired UI. Due to Flutter’s widget-oriented architecture, there are often multiple ways how can we compose existing primitives into more complex structures - like this fancy-shaped menu. You can preview updated buttons and the menu on the gif below:<br></p><figure id="w-node-2d5de7a9800c-c5de3bde"><p><img src="https://global-uploads.webflow.com/5c95072393140f36ecc22e60/5eecaa9a37ac27758ef39129_Hnet.com-image%20(1).gif" alt="flutter_buttons_menu"></p></figure><h2>Conclusion<br></h2><p>Flutter allowed us to recreate, very closely, UI and UX of Wolt’s piece of the interface. We were able to achieve the compelling look &amp; feel quickly by composing native widgets, and even if there are certain limitations, due to open-source nature of the Flutter framework, achieving pixel-perfect quality is possible when needed.<br></p></div></div>]]>
            </description>
            <link>https://www.nomtek.com/blog/sleek-ui-in-flutter-wolt</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842062</guid>
            <pubDate>Wed, 15 Jul 2020 06:43:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lost in vs Code Windows?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23841817">thread link</a>) | @archyking
<br/>
July 14, 2020 | https://marquee.activecove.com/blog/2 | <a href="https://web.archive.org/web/*/https://marquee.activecove.com/blog/2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2>Stop losing track of your thoughts switching between workspaces</h2><p><img src="https://marquee.activecove.com/blog/2/multivscode.png"></p><p>Marquee strives to make working inside VS Code more productive 🦾. Thanks to VS Code's leightweight nature, devs love to open multiple windows for projects, repo, and workspaces. Running multiple VS Code 🗃 instances at the same time. Here are some tools available in Marquee's latest release to help you stay on top of your workspaces.</p><blockquote><p><a href="https://marquee.activecove.com/">Install Marquee</a>, if you haven't already 🤔</p></blockquote><h3>💣 Add todo from editor's context meneu</h3><p>Creating a todo while you're deep inside your editor is now as easy as two clicks away. Just select the text inside your editor, right click, and select "Add todo to Marquee". Done.</p><p><img src="https://marquee.activecove.com/blog/2/context.gif" alt="Marquee Blog"></p><h3>🤖 Auto-suggest to add todos</h3><p>Even more conveniently Marquee will auto-suggest to add a line as todo whenever it's prefixed with uppercase TODO. Notice the blue underline, hover over it, click "Quick Fix", "Add todo". Leave losing track of your thoughts while coding behind you.</p><p><img src="https://marquee.activecove.com/blog/2/quickfix.gif" alt="Marquee Blog"></p><h3>🤓 Workspace specifc todos</h3><p>Marquee will keep a record of all your VS Codes no matter whether you open a new window for workspaces or folders. Whenver you add a new todo Marquee will associate it with your currently active workspace and allow you to toggle the list of displayed todos between all of them (global) or workspace-specifc, scoped down to the active workspace/folder you're currently running.</p><p><img src="https://marquee.activecove.com/blog/2/toggle.gif" alt="Marquee Blog"></p><h2>📮 Didn't do it for you?</h2><p>Let us know what you think. We've located a "Give Feedback" button in the Marquee UX to easily share feedback 📨 with us, good or bad. Please be candid 🤩. If you like Marquee, let your 🧑‍🤝‍🧑 friends know. We mightly appreciate it!</p></div></div></div>]]>
            </description>
            <link>https://marquee.activecove.com/blog/2</link>
            <guid isPermaLink="false">hacker-news-small-sites-23841817</guid>
            <pubDate>Wed, 15 Jul 2020 05:55:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OnionFruit Connect – use any browser to connect to the Tor network]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23841606">thread link</a>) | @realpanzer
<br/>
July 14, 2020 | https://dragonfruit.network/onionfruit/ | <a href="https://web.archive.org/web/*/https://dragonfruit.network/onionfruit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        


<div>
    <nav>
    <div>
        <p><a href="https://dragonfruit.network/">
            <img src="https://dragonfruit.network/logos/dragonfruit.png" height="25" width="25">
        </a></p>
    </div>
</nav>
    

    <div>
            
            <h3>Free Tor Gateway</h3>
            <p><i>
                    keyboard_arrow_down
                </i>
            </p>
    </div>
</div>

<div>
    <div>
        <div>
            <h2>Connect to Tor in seconds</h2>
            <p>Free and Unlimited Access to the Tor Network</p>
            <p><a href="https://github.com/dragonfruitnetwork/onionfruit/releases/latest/download/install.exe" target="_blank">
                <img src="https://dragonfruit.network/vendor/assets/github.png">
            </a>
        </p></div>
    </div>
</div>



<div>
    <div>
        <div>
            <p><img src="https://dragonfruit.network/img/onionfruit/onionfruit-countries.png">
            </p>
            <div>
                <p>Locations</p>
                <h2>Where to next? Anywhere Specific?</h2>
                <div>
                    <p>OnionFruit Uses a range of open-source databases to find high-speed servers to route your encrypted traffic through. You can choose from over <strong>7,000</strong> servers in <strong>95+</strong> countries to have your data directed through before you connect, or let Tor decide for you with the random option.</p>
                    <p><a href="https://dragonfruit.network/onionfruit/nodes">View Metrics</a>
                </p></div>
            </div>
        </div>
    </div>
</div>



<div>
    <div>
        <div>
            <p><img src="https://dragonfruit.network/img/onionfruit/onionfruit-connected.png">
            </p>
            <div>
                <p>Support</p>
                <h2>Most apps are compatible</h2>
                <p>OnionFruit™ creates a proxy for any app to connect to. Apps that are set to use the system settings are highly likely to be compatible</p>
            </div>
        </div>
    </div>
</div>

<div>
    <div>
        <p>Disclaimer</p>
        <h2>Nice to know...</h2>
        <p>DragonFruit Network does not endorse any activity undertaken using this app. We also provide no warranty and guarantee that you are completely anonymous. We also accept no responsibility for any user activity. DragonFruit Network does not own/maintain any of the servers connected to the Tor network - we canâ€™t guarantee the servers will always be online. OnionFruitâ„¢ Connect is produced independently from TorÂ® and carries no guarantee from The Tor Project about quality, suitability or anything else.</p>
    </div>
</div>








    </div>
</div></div>]]>
            </description>
            <link>https://dragonfruit.network/onionfruit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23841606</guid>
            <pubDate>Wed, 15 Jul 2020 05:15:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Bank of Korea to move the country’s financial system to blockchain]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23841581">thread link</a>) | @JesseJon
<br/>
July 14, 2020 | https://newsbitcoin247.com/the-bank-of-korea-to-move-the-countrys-financial-system-to-blockchain-by-acquiring-bank-sign/ | <a href="https://web.archive.org/web/*/https://newsbitcoin247.com/the-bank-of-korea-to-move-the-countrys-financial-system-to-blockchain-by-acquiring-bank-sign/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="the-post">

		
<!-- .entry-header-outer /-->


		<!-- .post-footer-on-top /-->

		<div><div><figure><img width="780" height="405" src="https://newsbitcoin247.com/wp-content/uploads/2020/07/bank-of-korea-780x405.jpg" alt=""></figure></div></div>
		<div>

			
			<p>According to <a href="https://thenews.asia/bank-of-korea-acquires-bank-sign/" target="_blank" rel="nofollow noopener noreferrer">The News Asia</a>, the Bank of Korea (BOK) is using blockchain technology in its banking sector also in order to commercialize the infrastructure. It has acquired Bank Sign for this purpose. It will help in transferring the financial services to a more organized structural framework. It will also help in making everything one step away with digital services. People will trust more the authentication and transparency of the system and will be able to invest in blockchain technology.</p>
<p>Bank Sign is a blockchain-based co-verification system that allows authenticated data to transfer among banks and financial institutions.</p>
<h2>Bank sign as&nbsp; a replacement for digital ID</h2>
<p>South Korea’s central bank plans to offer Bank Sign as a replacement for “Digital ID” (DID ). The COVID-19 pandemic situation is forcing South Korea’s banking stakeholders to consider other alternatives rather than currency exchanges such as digital alternatives for live operations.</p>
<p>Since the corona pandemic, organizations and banks have been trying to make everything online and operational through the digital space. Many people also believe that this pandemic can have positive outcomes for the emerging industries as they will render everything online.</p>
<p>Favoring the benefits of adopting Bank Sign, a BOK official told The News Asia:</p>
<blockquote><p>I expect that through cooperation, we will be able to realize cost reduction, service improvements, and discovery of new businesses</p></blockquote>
<p>The BOK adopting a blockchain digital ID system will not only strengthen the infrastructure but also will help in the development of advanced technology.</p>
<h2>Collaborating with Sendsquare to utilize blockchain in medical storage</h2>
<p>According to BTC Manager, the government is now planning to induce blockchain technology in medicine too by work in partnership with Send square.</p>


			
		</div><!-- .entry-content /-->

		
		<!-- .post-footer-on-top /-->

		
	</article><div>

		
		<div>

								<p><a href="https://newsbitcoin247.com/author/danna-james/">
							<img src="https://newsbitcoin247.com/wp-content/uploads/2020/02/danna-e1582923655574.jpg" width="171" height="180" alt="Danna James">						</a>
					</p><!-- .author-avatar /-->
					
			<div>
				

				<p>
					Danna is a journalist and technical writer with six years of experience researching and creating crypto articles, reviews, and how-to guides for different online media outlets, and academic journals.				</p><!-- .author-bio /-->

							</div><!-- .author-info /-->
			
		</div><!-- .about-author /-->
		<!-- .prev-next-post-nav /-->
	

				<!-- #related-posts /-->

				<!-- .comments-area -->


	</div></div>]]>
            </description>
            <link>https://newsbitcoin247.com/the-bank-of-korea-to-move-the-countrys-financial-system-to-blockchain-by-acquiring-bank-sign/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23841581</guid>
            <pubDate>Wed, 15 Jul 2020 05:11:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Wiring of the Nervous System]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23841506">thread link</a>) | @yoloswagins
<br/>
July 14, 2020 | https://zswitten.github.io/2020/06/03/neuroscience-neural-networks-7.html | <a href="https://web.archive.org/web/*/https://zswitten.github.io/2020/06/03/neuroscience-neural-networks-7.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><a href="https://zswitten.github.io/2019/08/04/neuroscience-neural-networks-0.html">Part 0: Introduction</a><br>
<a href="https://zswitten.github.io/2019/08/04/neuroscience-neural-networks-1-3.html">Part 1-3: Properties of Neurons</a><br>
<a href="https://zswitten.github.io/2019/09/08/neuroscience-neural-networks-4.html">Part 4: Vision</a><br>
<a href="https://zswitten.github.io/2019/10/07/neuroscience-neural-networks-5.html">Part 5: Wiring of the Visual System</a><br>
<a href="https://zswitten.github.io/2019/11/13/neuroscience-neural-networks-6.html">Part 6: Smell, Taste, Hearing, and Touch</a><br>
<a href="https://zswitten.github.io/2020/06/03/neuroscience-neural-networks-7.html">Part 7: Wiring of the Nervous System</a></p>

<p>We have billions of neurons. And 10^14 connections between those neurons. But our instruction manual for putting it together is a mere 20,000 genes. How does a neuron know what other neurons it’s supposed to connect to?</p>

<p>First, let’s talk about how the basic shape of the brain gets made. A sperm fertilizes an egg. The fertilized egg cell-divides a few thousand times. Then you have a hollow ball. The cells in the ball self-sort into three layers (outside/skin, middle, inside), and the ball of cells flattens out into a plate. Then the plate curves around to form a tube.</p>

<p>Next, on the tube, forward/backward and up/down axes get defined. The way this works is, there are proteins called “morphogens” [short for mighty morphing power generators] that are produced at specific places on the tube. The morphogens spread out from their sources, creating a gradient: the closer a cell is to a morphogen factory, the more morphogen a cell gets. The morphogens control how active various genes are in a cell, and that determines its “cell fate”, i.e. what type of cell it becomes.</p>

<p>Keep in mind this is all happening before the cells have started extending their axons and dendrites to communicate with each other. They have to get their own act together first. In particular, they are deciding whether they will be excitatory, inhibitory, or modulatory, and what neurotransmitter they’re going to use.</p>

<p>But even though they aren’t directly communicating with each other, their fates are intertwined. For instance, each Drosophila (fruit fly) (my biology-knowledgable friends keep yelling at me for calling it “Drosophilia”) sensory organ is supposed to have one socket cell, one hair cell, one sheath cell, and one sensory neuron. If the organ doesn’t have all those things, it doesn’t work, so it’s important for nearby cells to coordinate their cell fate decisions.</p>

<p>This is handled by a protein called Numb. Socket, hair, sheath, and sensory cells all start from the same precursor. When that precursor divides, one child gets most of the Numb. Numb makes another protein called Notch stop working, and one of the things Notch does is 1. upregulate itself and 2. downregulate a different protein called Delta, so the four siblings end up with different amounts of Notch and Delta which makes one of them become socket, one hair, etc. <a href="https://www.youtube.com/watch?v=kXYiU_JCYtU">More like me, less like you!</a></p>

<p>Cells don’t stay in the same place their whole lives. They migrate. In particular, in the cortex, you can tell a cell’s age by how far it is from the center. Cells that are born later migrate to the outer layers of the cortex. Kind of like tree rings.</p>

<p>Now that all the pieces are in place, it’s time for the cells to link up. Remember, cells have one long poky part, the axon, that carries information out, and a bushy bunch of dendrites that take information in. Cells know they’re only meant to have one axon; if you cut off a cell’s axon while it’s growing, one and only one developing dendrite will become the new axon.</p>

<p>Because the axons can grow very long, it’s their job to grow their way to the appropriate dendrites. As we saw in the <a href="https://zswitten.github.io/2019/10/07/neuroscience-neural-networks-5.html">chapter</a> about wiring of the visual system, axons are attracted to or repulsed by various proteins that appear in different amounts in different places, and that determines where they go.</p>

<p>Sometimes, axons have to travel quite a long way to get to their final destination. These long journeys get broken up into multiple steps. For example, there’s a really strong attractant protein at the spine that draws axons to it. But the axon’s true purpose lies elsewhere. So once it reaches the spine, there’s another protein hanging out nearby that makes it so the axon isn’t attracted to the first protein anymore. And meanwhile, there’s a third protein in the area that actively repels the axon away. Grass is always greener!</p>

<p>Axons and dendrites from the same cell repel each other, to induce them to spread out and cover the whole of an area – “dendritic tiling”. But they’re chill with being around axons and dendrites from other cells.</p>

<p>OK, so an axon found the right general area. Now it has to mate with a dendrite to form a synapse. Axons produce a protein called agrin that triggers a bunch of receptors for action potentials to come cluster around it, while also breaking up any random other clusters that happened to be nearby. To make things easier, the axons are attracted to places where there were already preexisting clusters of receptors.</p>

<p>Some of these synapses are lifelong partnerships between two cells, but the divorce rate is real. In mouse muscles, the divorce rate is 90%; each muscle fiber in a mouse newborn gets input from ten neurons, but as the mouse gets older, one of those synapses dominates, taking all the territory from the other synapses which then shrink to nothing. The pattern of which synapses win is unpredictable and differs between individuals and even between the two sides of an individual’s body. This indicates that it’s being driven by activity-dependent competition AKA Nurture not Nature. Synapses can also die out if the axons get pruned, or if the entire cell dies. Long axons are especially likely to get pruned. Also, axons that aren’t firing a lot get pruned.</p>

<p>The second part of the chapter/of this blog post is a case study of the formation of the olfactory map of a mouse. We’ve seen two types of neural map. The first is continuous, in the mathy sense of a continuous function where two points that are close together in the input space will be mapped to close-together points in the output space. Vision is like this: two nextdoor neighbor pixels of your visual screen will map to two nextdoor neighbor neurons. Touch is also mostly continuous. Two nerve cells in your left foot map to two nearby cells in your brain. But it’s not always totally continuous: an example is that signals from mouse whiskers go to their own special place that’s not especially near input from the rest of the face.</p>

<p>Smell is the other kind of map: discrete. Rather than being organized spatially, the smell map is organized by odorant. You could imagine three strategies for making a neural map. Number one: the input neurons are in charge. They know their own identities, and so they know what target neurons in the next layer they should connect to. The target neurons are dumb and define their identity by which input neurons choose them. Number two: the input neurons are dumb and connect randomly to target neurons. It’s the target neurons that are in control and tell the input neurons what to be. Number three: the input neurons and target neurons are both smart. In vision, it’s number three. Both the neurons in the eye and the retinal ganglia cells they connect to are smart. Smart in this sense: different cells in each layer have different amounts of attractor/repeller proteins, and if you turn off the genes that make those proteins, the whole thing stops working. You could call it a healthy equal relationship where both sides contribute.</p>

<p>Smell is the same way, but with another fun twist: the axons sort themselves out along the way. Axons that are coming from cells that sense two different odorants repel each other, while axons that are coming from cells that sense the same odorant attract each other. Like if your tangled-up headphones could magically unscramble themselves on the way to your ears.</p>

<p>Summing it all up, how do we get from 20,000 genes to 10^14 connections?</p>

<ul>
  <li>Some genes make multiple different proteins</li>
  <li>The amount of a protein that’s present makes a difference, not just whether it’s present vs. absent</li>
  <li>Proteins do different stuff in different contexts</li>
  <li>Combinations of proteins do stuff that neither can do alone</li>
  <li>Wiring decisions can have multiple steps, both spatially (multi-step journeys) and temporally (pruning)</li>
  <li>Activity/learned experience can help make connection decisions</li>
  <li>Some of the details don’t matter, like as long as an odorant axon is going to the right glomerulus, it doesn’t really matter which exact cell in the glomerulus it connects to.</li>
</ul>

<p>And finally, what you’ve all been waiting for: half-baked speculation about how we could use this info to make machine learning work better!</p>

<p>Neural networks come into existence with all their connections fully specified. Some of the weights die/go to zero during training, which is like axon pruning. I wonder what it would be like to build up the connectome gradually over time, and to add an element of indeterminism where cells occasionally connect to the “wrong place”. AutoML is arguably like the former, while skip connections are arguably like the latter.</p>

<p>I’m intrigued by the idea of having some concept of a protein, that operates in some “area” (i.e. subset) of different layers, and attracts connections from some neurons in the layers before and after it, while repelling others. Or a whole family of proteins that regulate each other. I wonder whether the practical difficulties of assembling a brain can act as a kind of regularizer. Like, the <a href="https://en.wikipedia.org/wiki/Vapnik%E2%80%93Chervonenkis_dimension#VC_dimension_of_a_neural_network">VC dimension</a> of a brain with 86 billion neurons that can connect to each other in any arbitrary way is huge. The VC dimension of brains that are physically and biologically possible to assemble is a lot smaller.</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://zswitten.github.io/2020/06/03/neuroscience-neural-networks-7.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23841506</guid>
            <pubDate>Wed, 15 Jul 2020 04:58:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Impact of GitHub Suggested Changes on Recommendations Between Developers [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23841479">thread link</a>) | @azhenley
<br/>
July 14, 2020 | http://www.chrisparnin.me/pdf/suggs_FSE_20.pdf | <a href="https://web.archive.org/web/*/http://www.chrisparnin.me/pdf/suggs_FSE_20.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.chrisparnin.me/pdf/suggs_FSE_20.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23841479</guid>
            <pubDate>Wed, 15 Jul 2020 04:54:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debunking the “users always click yes” myth]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23841435">thread link</a>) | @magic5227
<br/>
July 14, 2020 | https://emilymstark.com/2020/07/14/debunking-the-users-always-click-yes-myth.html | <a href="https://web.archive.org/web/*/https://emilymstark.com/2020/07/14/debunking-the-users-always-click-yes-myth.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>There’s a common myth among software engineers, and security engineers in
particular, that people will always click “yes” on any warning or prompt,
blindly accepting any risk about which the UI warns. This is not generally true,
and the misconception can lead to suboptimal design decisions and even <a href="https://noncombatant.org/2016/01/28/against-security-nihilism/">security
nihilism</a>.</p>

<h2 id="warnings-can-be-designed-for-adherence">Warnings can be designed for adherence</h2>

<p>Warning adherence is the percentage of users who do what a warning wants them to
do. For example, we say that users adhere to an SSL certificate warning if they
leave the offending site upon encountering the warning.</p>

<p>Design decisions can influence adherence significantly – for example,
redesigning the Chrome SSL warning
<a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/43265.pdf">increased</a>
adherence from 37% to 62%. (Today, SSL warning adherence is even higher, at
around 80% on Windows. One possible
<a href="https://research.google/pubs/pub46359/">explanation</a> is that we got rid of many
false positive SSL errors, thereby leaving more real errors that users don’t
want to bypass, but I don’t know for sure.) Example of visual or interaction
adherence cues include highlighting the “safe” button or hiding the “unsafe”
button behind a dropdown.</p>

<figure>
  <img src="https://emilymstark.com/assets/cert_error.png" alt="Chrome 86 SSL certificate warning">
  <figcaption><i>Chrome 86 SSL
certificate warning. The safe option (“Back to safety”) is visually highlighted.
The unsafe option is only shown when the “Advanced” button is clicked.</i></figcaption>
</figure>

<p>Some warnings may not need to be as extremely opinionated as the SSL certificate
warning to achieve good adherence. For example, Chrome has a warning for
lookalike domains that use unusual characters to create convincing spoofing
domains. This warning, shown below, is designed to be less opinionated and makes
it easier for people to find the unsafe option, yet people choose the unsafe
option &lt;15% of the time.</p>

<figure>
  <img src="https://emilymstark.com/assets/lookalike_warning.png" alt="Chrome 86 lookalike domain warning">
  <figcaption><i>Chrome 86
SSL lookalike domain warning. This warning is designed to be less scary than the
SSL certificate warning, and it is easier for users to find and exercise the
unsafe option. The warning still produces good adherence.</i></figcaption>
</figure>

<p>It can also be useful to measure user behaviors other than adherence. People may
choose the unsafe option on a warning, but then act more cautiously as they
proceed (for example, by not entering passwords on the unsafe site). Depending
on the risk in question, this may or may not be a safe behavior. My team has
some recent data on this phenomenon that I hope we’ll be able to share publicly
soon.</p>

<p>There are some caveats to this approach of designing warnings for adherence:</p>
<ul>
  <li>In the
<a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/43265.pdf">study</a>
I linked above, the redesigned warning did not improve comprehension. People
made safer decisions with the redesigned warning, but they didn’t understand
the warning better than before. Convincing people to make safe choices may be
easier than helping them understand the risks, especially in light of
follow-up <a href="https://research.google/pubs/pub46632/">research</a> suggesting that
there is no single easily-surmountable challenge that gets in the way of
comprehensibility.</li>
  <li>Designing for adherence can be seen as a spectrum. On one end of the spectrum
might be an <a href="https://stackoverflow.com/questions/35274659/does-using-badidea-or-thisisunsafe-to-bypass-a-chrome-certificate-hsts-error/35275060">obfuscated
password</a>
for bypassing the warning. This end of the spectrum could be seen as
paternalistic, or as favoring expert users and denying non-expert users the
same functionality. On the other end might be placing the safe and unsafe
options on equal footing with no visual or interaction distinctions. This end
of the spectrum lets people make their own uninfluenced choices, but puts them
at risk if they do not comprehend the warning well. I think that choosing a
point on this spectrum is probably a subjective, qualitative product decision,
but it’s important to know that the spectrum exists.</li>
</ul>

<h2 id="prompts-that-arent-warnings">Prompts that aren’t warnings</h2>

<p>One might concede that warnings can achieve good adherence, but still speculate
that users will always say “yes” to a prompt – a neutral question that doesn’t
have any particular desired outcome.</p>

<p>I’m less familiar with the research in this area, and there may in fact be less
research overall. But, one public data source we have is the <a href="https://developers.google.com/web/tools/chrome-user-experience-report">Chrome User
Experience
Report</a>,
which recently added <a href="https://developers.google.com/web/updates/2020/02/notification-permission-data-in-crux">permission acceptance
data</a>
for the web notification permission prompt. This data suggests that users
neither blindly accept nor deny notification permission prompts. To pick a few
examples that come to mind, users accept ~3% of notification prompts on
www.tomshardware.com, ~22% on www.facebook.com, and ~82% on news.google.com (as
of early 2020). These numbers are not apples-to-apples comparisons; many
factors, including the audience and context of the website, will influence the
acceptance rate. However, I do think these numbers suggest that users do not
have a constant uniform reaction to permission prompts.</p>

<h2 id="so-what-does-this-mean">So what does this mean?</h2>

<p>Developers shouldn’t assume that users will always blindly say “yes” to any
security or privacy warning or prompt. We can design warnings to achieve good
adherence, and even neutral prompts elicit neither a single uniform response nor
a random response. Still, I think of it as good practice to avoid overloading
people with security and privacy decisions, especially when the risks may not be
comprehensible. I also think it can become unmaintainable to expose every
security decision in the UI; software designers need to prioritize which choices
to expose, and users should choose the software that gives the right level of
control for them.</p>

  </div></div>]]>
            </description>
            <link>https://emilymstark.com/2020/07/14/debunking-the-users-always-click-yes-myth.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23841435</guid>
            <pubDate>Wed, 15 Jul 2020 04:46:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hip-Hop Helped Cash App Grow Faster]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23841365">thread link</a>) | @mehdiyac
<br/>
July 14, 2020 | https://trapital.co/2020/03/18/how-hip-hop-helped-cash-app-grow-faster/ | <a href="https://web.archive.org/web/*/https://trapital.co/2020/03/18/how-hip-hop-helped-cash-app-grow-faster/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main id="genesis-content"><article itemscope="" itemtype="https://schema.org/CreativeWork"><div itemprop="text"><h3>Square’s mobile payment service teamed up with rappers to grow fast, use their influence, and acquire the right customers.</h3>
<p><img src="https://i0.wp.com/i.ytimg.com/vi/mjLuy5U9PNU/maxresdefault.jpg?w=700&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.ytimg.com/vi/mjLuy5U9PNU/maxresdefault.jpg?w=700&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<h6>Cardi B is the <a href="https://twitter.com/CashApp/following">only person that Cash App follows on Twitter</a>! (via YouTube)</h6>
<p>Last week’s “Cash App Friday” came at the perfect time. The COVID-19 pandemic has been costly, scary, and uncertain, especially for those living paycheck-to-paycheck. On Cash App Fridays, the mobile payment app users can log on Twitter and reply to <a href="https://twitter.com/CashApp">@CashApp</a> with their $cashtag for a chance to win prizes that range from $100 to $500. Later that weekend, Cash App matched some of the giveaways from Shea Serrano –The Ringer staff writer and <a href="https://trapital.co/2019/11/04/shea-serrano-on-the-economics-of-book-publishing-movies-and-other-things-and-how-dj-screw-inspired-his-promotional-tactics/">Trapital Podcast guest</a>— who had already made it habit to give money to those in need.</p>
<p>These philanthropic measures are gracious, but it’s essential to Cash App’s growth model. In 2019, the company spent an estimated <a href="https://money.com/what-is-cash-app-friday/">$60,000 on Cash App Fridays</a>. In return, it earned much more in heightened brand awareness and earned media. This strategy translated well to hip-hop, where rappers use the app to give money to fans. Cash App has now been name-dropped by over 200 hip-hop artists.</p>
<p>Cash App achieved the modern brand’s dream: to become part of the culture. No appropriation. No cringe-worthy attempts to sound like a 23-year-old hypebeast. All genuine. It’s easier said than done, and it’s a model others can learn from.</p>
<hr>
<h4><strong>Make it easy for the customer</strong></h4>
<p>When Cash App launched in 2013, it was much more buttoned-up. Users needed phone numbers or email addresses to transfer money. A year and a half later, the service eased up, followed Venmo’s lead with usernames, and introduced the <a href="https://squareup.com/us/en/press/introducing-cashtags">$cashtag</a>. These handles made the app more social and reduced friction to transfer money.</p>
<p>Square continued this trend when it offered debit cards. From <a href="https://www.fool.com/investing/2018/02/28/squares-cash-app-killed-it-in-2017.aspx">Motley Fool</a>:</p>
<blockquote><p>Square introduced a virtual debit card at the end of 2016, which allowed users to spend their Cash App balance online or through a mobile wallet. So, if you were ordering a pizza online, for example, your friends could send you money on Cash App, then you could pay for the pie with the debit card number.</p>
<p>Square followed it up in April with a physical debit card and allowed users to add a personalized signature or drawing to the front of the card. The card has proved extremely popular, with users spending over $90 million using their Cash Cards during the month of December. That’s a run rate of over $1 billion.</p></blockquote>
<p>It dropped a full year before Venmo’s debit card, which also helped!</p>
<p>Cash App took its efforts to another level in November 2017 when it introduced the ability to trade Bitcoin. This was one month before Bitcoin’s peak valuation (and peak public interest). The timing was perfect. It would be like buying Nicki Minaj stock the month before “Monster” came out.</p>
<p>Square CFO Amrita Ahuja said that Cash App’s Bitcoin and Investing customers <a href="https://www.forbes.com/sites/darrynpollock/2020/02/29/bitcoin-paying-off-for-squares-cash-app-raking-in-178-million/#4ea73a5e28e7">generate up to two-to-three times more revenue</a> than the rest. Since Bitcoin accounts for about <a href="https://www.coindesk.com/bitcoin-drove-half-of-squares-cash-app-revenue-in-the-4th-quarter">half of Cash App’s revenue</a> and Cash App has 24 million monthly active users, that means less than 7 million (28%) use those features.</p>
<p>Most companies would use this as a reason to solely focus on acquiring more Bitcoin investors. They would run ads in fintech newsletters, sponsor emerging tech meetups, find Libertarian groups on Reddit, and so on.</p>
<p>But Cash App expanded its reach. Cash App giveaway recipients aren’t exactly the demo for Bitcoin investing. But they might be someday and may spread the word to someone who <em>is</em> in that cryptocurrency demo. That’s what Cash App is banking on (literally). This is the long game.</p>
<p><img data-attachment-id="3531" data-permalink="https://trapital.co/2020/03/18/how-hip-hop-helped-cash-app-grow-faster/screen-shot-2020-03-18-at-10-50-49-am/" data-orig-file="https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?fit=2240%2C1458&amp;ssl=1" data-orig-size="2240,1458" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2020-03-18 at 10.50.49 AM" data-image-description="" data-medium-file="https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?fit=300%2C195&amp;ssl=1" data-large-file="https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?fit=700%2C456&amp;ssl=1" src="https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?resize=700%2C456&amp;ssl=1" alt="" width="700" height="456" srcset="https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?w=2240&amp;ssl=1 2240w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?resize=300%2C195&amp;ssl=1 300w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?resize=1024%2C667&amp;ssl=1 1024w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?resize=768%2C500&amp;ssl=1 768w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?resize=1536%2C1000&amp;ssl=1 1536w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?resize=2048%2C1333&amp;ssl=1 2048w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?w=1400&amp;ssl=1 1400w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?w=2100&amp;ssl=1 2100w" sizes="(max-width: 700px) 100vw, 700px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?w=2240&amp;ssl=1 2240w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?resize=300%2C195&amp;ssl=1 300w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?resize=1024%2C667&amp;ssl=1 1024w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?resize=768%2C500&amp;ssl=1 768w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?resize=1536%2C1000&amp;ssl=1 1536w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?resize=2048%2C1333&amp;ssl=1 2048w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?w=1400&amp;ssl=1 1400w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?w=2100&amp;ssl=1 2100w" data-lazy-src="https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?resize=700%2C456&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<h6>This is a Spotify screenshot of songs named “Cash App.” That list keeps going… it’s clearly an SEO play.</h6>
<h4><strong>Influencer marketing done right</strong></h4>
<p>Square is still not entirely sure how Cash App first became popular with hip-hop. Here’s Square CEO Jack Dorsey at a 2019 investor conference via <a href="https://www.wsj.com/articles/dont-venmo-iggy-azalea-cash-app-rules-rap-11565191206">Wall Street Journal</a>:</p>
<blockquote><p>“This is also something we weren’t expecting, but I think Cash App has touched in the culture. We’ve just benefited from people loving it and wanting to sing about it, and putting it in their music videos, and it’s amazing how much that spreads.”</p></blockquote>
<p>But once Square noticed the trend, it locked in. In 2018 it teamed up with <a href="https://www.businessinsider.com/travis-scott-is-giving-away-100000-to-fans-through-the-cash-app-2018-8">Travis Scott </a>and <a href="https://www.complex.com/music/2018/08/why-are-rappers-giving-away-money-cash-app-lil-b">Lil’ B</a>. In December, it got together with <a href="https://cash.app/legal/us/en-us/snoop-special-stars">Snoop Dogg</a>. Each of them used the app to give away money. The company acquired customers through the rappers’ social media followings at an extremely low cost. Free money is an easy sell, and it doesn’t take that many customers to justify the cost.</p>
<p>Here’s a great breakdown from <a href="https://ark-invest.com/research/squares-cash-app-twitter">Ark Invest</a> on the low-cost customer acquisition:</p>
<blockquote><p>While banks can pay from $350 to $1500 to acquire users, Cash App acquired a new customer through Burger King in five minutes without any direct mail or bank branch visit.</p>
<p>Square has run similar [$100,000] campaigns with rappers like Travis Scott and Lil B and other influencers, triggering a network effect for the Cash App… If only 129 of the 120,000 who commented on [Travis Scott’s] tweet were new to Cash App, then Square’s cost of customer acquisition would have been less than the $925 per user that banks pay on average, according to our research, and 6,000 comments, only 5% of the total, would have dropped it to $20. Moreover, as the converted users appear to spread the word on social media, the Cash App can acquire additional users from just one.</p></blockquote>
<p>That’s well worth $100,000 for both La Flame and Cash App. It’s even more worthwhile considering the influence that hip-hop fans have on their peers. According to <a href="https://www.revolt.tv/2020/1/1/21043728/generation-hip-hop-2020">REVOLT’s Gen Hip Hop study</a>, hip-hop fans are 2x more likely to be culturally influential. It’s the right audience to acquire.</p>
<p>Cash App’s user base is <a href="https://twitter.com/hknightsf/status/1239976638844039168?s=20">strongest in the South and the Midwest</a> of the US, which aligns with the regions where many hip-hop fans are at. It’s the opposite of most founders who focus first on their “early adopter” personal networks in the coastal metro hubs in New York and San Francisco. This strategy made more sense years ago when broadband internet access was noticeably stronger in tech hubs and universities, but that’s no longer the case. It’s 2020. Smartphones are now ubiquitous. It’s time to think beyond Mark Zuckerberg’s Ivy League expansion plan that worked for Facebook in 2004.</p>
<p>Venmo’s growth strategy was more aligned with the traditional tech growth model. The founders are UPenn alums who hit up Princeton Hackathons and other similar events. It had its own “Million Dollar Money Tree” cash giveaway and $5 referral sign-up bonuses to attract customers. But those offers were also centered around Ivy League users and their friends who live on the coasts.</p>
<p>Cash App’s <a href="https://s21.q4cdn.com/114365585/files/doc_financials/2019/q4/2019-Q4-Shareholder-Letter-Square.pdf">monthly active users have grown</a> from 7 million in 2017, 15 million in 2018, to 24 million in 2019. It still trails Venmo in users, but Cash App is <a href="https://www.fool.com/investing/2019/08/27/the-gap-between-cash-app-and-venmo-is-getting-bigg.aspx">growing faster</a>.</p>
<p>I drew this chart to highlight the difference:</p>
<p><img data-attachment-id="3529" data-permalink="https://trapital.co/2020/03/18/how-hip-hop-helped-cash-app-grow-faster/screen-shot-2020-03-18-at-9-33-56-am/" data-orig-file="https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?fit=2104%2C1576&amp;ssl=1" data-orig-size="2104,1576" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2020-03-18 at 9.33.56 AM" data-image-description="" data-medium-file="https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?fit=300%2C225&amp;ssl=1" data-large-file="https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?fit=700%2C524&amp;ssl=1" src="https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?resize=700%2C524&amp;ssl=1" alt="" width="700" height="524" srcset="https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?w=2104&amp;ssl=1 2104w, https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?resize=300%2C225&amp;ssl=1 300w, https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?resize=1024%2C767&amp;ssl=1 1024w, https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?resize=768%2C575&amp;ssl=1 768w, https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?resize=1536%2C1151&amp;ssl=1 1536w, https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?resize=2048%2C1534&amp;ssl=1 2048w, https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?w=1400&amp;ssl=1 1400w" sizes="(max-width: 700px) 100vw, 700px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?w=2104&amp;ssl=1 2104w, https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?resize=300%2C225&amp;ssl=1 300w, https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?resize=1024%2C767&amp;ssl=1 1024w, https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?resize=768%2C575&amp;ssl=1 768w, https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?resize=1536%2C1151&amp;ssl=1 1536w, https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?resize=2048%2C1534&amp;ssl=1 2048w, https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?w=1400&amp;ssl=1 1400w" data-lazy-src="https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?resize=700%2C524&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<h4><strong>An effective flywheel</strong></h4>
<p>Cash App’s strategy is a true flywheel that drives more peer-to-peer transactions. The hip-hop influencers and their fans grew the user base and brand awareness further, which gained the attention of those who seek higher-end services like Bitcoin and Investing.</p>
<p>The flywheel looks like this:</p>
<p><img data-attachment-id="3530" data-permalink="https://trapital.co/2020/03/18/how-hip-hop-helped-cash-app-grow-faster/screen-shot-2020-03-18-at-9-34-31-am/" data-orig-file="https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?fit=2026%2C1172&amp;ssl=1" data-orig-size="2026,1172" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2020-03-18 at 9.34.31 AM" data-image-description="" data-medium-file="https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?fit=300%2C174&amp;ssl=1" data-large-file="https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?fit=700%2C405&amp;ssl=1" src="https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?resize=700%2C405&amp;ssl=1" alt="" width="700" height="405" srcset="https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?w=2026&amp;ssl=1 2026w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?resize=300%2C174&amp;ssl=1 300w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?resize=1024%2C592&amp;ssl=1 1024w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?resize=768%2C444&amp;ssl=1 768w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?resize=1536%2C889&amp;ssl=1 1536w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?w=1400&amp;ssl=1 1400w" sizes="(max-width: 700px) 100vw, 700px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?w=2026&amp;ssl=1 2026w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?resize=300%2C174&amp;ssl=1 300w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?resize=1024%2C592&amp;ssl=1 1024w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?resize=768%2C444&amp;ssl=1 768w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?resize=1536%2C889&amp;ssl=1 1536w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?w=1400&amp;ssl=1 1400w" data-lazy-src="https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?resize=700%2C405&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>It’s similar to Jay Z’s flywheel with his <em>4:44</em> release. Here’s <a href="https://trapital.co/2019/11/21/jay-zs-cell-phone-partnership-strategy-explained/">what I wrote last year</a>:</p>
<blockquote><p>Jay Z made a sale that valued the company at more than 10x his purchase price just two years earlier. That’s impressive especially with all the turmoil and controversy that surrounded Tidal during that stretch.</p>
<p>But the real kicker is that $75 million was budgeted for exclusive content for Sprint. Five months after the deal was publicized, Jay Z dropped 4:44 as a Sprint-Tidal exclusive. This connected the streaming service with Sprint, which now had a vested interest in Tidal’s success (not too different from Live Nation’s interest in Roc Nation). And by partnering with a cellular carrier instead of a manufacturer like Nokia or Samsung, Jay increased his flexibility and integration capabilities.</p></blockquote>
<p>Jay Z distributed his album through Sprint because it has an active customer base and a means to deliver his product. Sprint was now a co-owner of Tidal, Jay’s streaming service. The cellular carrier had a vested interest in both the delivery and implementation. And Sprint customers got the album for free. Everybody won.</p>

<hr>
<p>In this next decade, Cash App’s customer acquisition tactics will be replicated by many. Products that are built to serve the mass consumer will waste time if they religiously follow Silicon Valley’s age-old mantra to “start in San Francisco and New York” and expand from there. That traditional plan still makes sense for a product like Superhuman, the $30 / month email service that’s specifically targeted at that who will pay for that. It’s less ideal for an app that relies on network effects and massive scale.</p>
<p>Mass-market products need branding. In consumer tech, hip-hop has been the backbone. TikTok had Lil’ Nas X. Snapchat had DJ Khaled. YouTube had Soulja Boy. The list goes on. Hip-hop culture influence continues to grow, and more companies will find their own way to engage fans.</p>

</div></article></main></div></div></div>]]>
            </description>
            <link>https://trapital.co/2020/03/18/how-hip-hop-helped-cash-app-grow-faster/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23841365</guid>
            <pubDate>Wed, 15 Jul 2020 04:37:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Insomniac's journey to regular sleep]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23841175">thread link</a>) | @rahulshiv7
<br/>
July 14, 2020 | https://www.sleepedy.com/articles/insomniac-journey-to-better-sleep/ | <a href="https://web.archive.org/web/*/https://www.sleepedy.com/articles/insomniac-journey-to-better-sleep/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>I'd done everything right, yet it was 2 am and I still couldn't sleep. I had meditated for 30 minutes before I went to bed. I even took a couple of melatonin pills right after to be sure. Yet, here I was wide awake dreading how exhausted I would be the next day at work.</p><p>My problem wasn't unique. In America, one in every 10 adults will experience chronic insomnia<sup><a href="#references">1</a></sup>. It takes just one poor night of sleep to devolve into long term sleeping problems. This is because the majority of sleeping problems stem from anxiety and worry<sup><a href="#references">2</a></sup>. <b>The more you worry about not getting enough sleep, the worse your sleep gets</b>.</p><p>For me, my sleeping issues began right out of college. I had started a job as a software engineer and I was starting to feel the pressure. I had a couple of big deadlines coming up and I found myself tossing and turning unable to sleep one night. My mind kept racing, thinking about all the work I had until I finally fell asleep.</p><p>I thought that was it — an abnormal night, but then it happened again. This time, my outlook changed. I started worrying about how not getting enough sleep would affect my day. I looked up basic sleep hygiene tips online and decided to go to bed extra early to make sure I made up for lost sleep. This ended up backfiring and it took a few hours before I could finally sleep.</p><p>At this point, my sleeping struggles started becoming more regular. I downloaded a couple of meditation apps in the hopes that meditating and listening to soothing sounds would help me sleep better. I even resorted to over the counter sleeping aids on nights when it took me too long to fall asleep. <b>The results were mixed — I'd fall asleep faster but over time I'd revert back to having poor sleep</b>.</p><p>I finally caved and decided to try prescription medication. I had read a lot about them and was very reluctant because of their long term side effects. On a visit to my doctor, I asked her if she could prescribe me something to help me sleep. She said she said she could, but it wasn't going to be medication. Instead, she put in a referral to a CBT-I (Cognitive Behavioral Therapy for Insomnia) therapist.</p><p>CBT-I is an evidence-based (proven in clinical trials) technique used to treat sleep problems<sup><a href="#references">3</a></sup>. <b>Two driving forces induce sleep — sleep drive &amp; mental arousal</b>. Your sleep drive is how sleepy/tired you feel when going to bed. Your mental arousal is the racing thoughts and alertness you feel when you go to bed. When your sleep drive is high and your arousal levels are low; it is easier to fall asleep. CBT-I prescribes a sleep schedule that ensures you have a high sleep drive. It also teaches you techniques to worry less and reduce your arousal.</p><p><b>CBT-I is extremely effective in treating sleeping problems</b>. Clinical trials have shown that 80% of people that follow a good CBT-I program will have normal sleep by the end<sup><a href="#references">4</a></sup>. The results are also permanent, unlike sleeping aids which are effective only as long as you are taking them<sup><a href="#references">5</a></sup>.</p><p>There were three main rules that I had to follow -</p><ol><li><p>I could only sleep within the sleep window my therapist prescribed. This ensured that I only went to bed when my sleep drive was high.</p></li><li><p>Every time I couldn't sleep, I had to make sure I didn't stay in bed for over 20 minutes. This way, I would subconsciously re-train my mind to not associate my bed with wakefulness<sup><a href="#references">6</a></sup>.</p></li><li><p>No day time naps and no caffeine after 2pm.</p></li></ol><div><p>I was sleeping around 5 hours at the time, so we set a 6 hour window within which I could sleep (1am - 7am in my case). I kept a log of how long it took me to sleep, how long I was awake in the middle of the night and how long I slept. This data was recorded to the closest 15th minute and is self reported. At the end of each week, my therapist would alter my sleep schedule based on the previous week's data.<b> Note:</b> Time awake is the time it took me to fall asleep + my night time awakenings
</p></div><p>
At the end of week 1, I was sleeping about the same as I was before. My time awake at night though had fallen by an hour. I was falling asleep faster and I was having less interrupted sleep. We decided to stick to the same sleep schedule for week 2.
</p><p>
At the end of this week, my sleep had increased and I was consistently awake for less than an hour. We decided to expand my window by 15 minutes for week 3.
</p><p>
We followed the same rules and either expanded or kept the same sleeping window for the next few weeks.
</p><p><b>At the end of the 10 week program, I was sleeping over 7 hours a night</b>. More importantly, I wasn't spending my days worrying about my sleep.
</p><p><b>CBT-I isn't an easy solution</b>. The sleep schedules are hard to follow and the results aren't instantaneous. It takes time and effort but the reward of permanently improved sleep is well worth it. Let me know if you do decide to try it and if it helps you improve your sleep. Here's to hoping you get better sleep soon.</p><p>If you'd like to know more about CBTI and other behavioral therapy techniques to improve sleep, check out our <a href="https://www.sleepedy.com/" target="_blank" rel="nofollow noopener noreferrer">website</a>!</p><h2 id="references">References</h2><ol><li><p><a href="http://sleepeducation.org/news/2014/03/10/insomnia-awareness-day-facts-and-stats" target="_blank" rel="nofollow noopener noreferrer">Insomnia Awareness Day by the American Association of Sleep Medicine</a></p></li><li><p><a href="https://adaa.org/understanding-anxiety/related-illnesses/sleep-disorders" target="_blank" rel="nofollow noopener noreferrer">Sleep Disorders by the Anxiety and Depression Association of America</a></p></li><li><p><a href="https://www.sleepedy.com/cbt-for-insomnia" target="_blank" rel="nofollow noopener noreferrer">CBT for Insomnia: A comprehensive guide</a></p></li><li><p>Trauer, James M. et al. “<a href="https://www.ncbi.nlm.nih.gov/pubmed/26054060" target="_blank" rel="nofollow noopener noreferrer">Cognitive Behavioral Therapy for Chronic Insomnia: A Systematic Review and Meta-analysis.</a> Ann Intern Med. August 2015 163(3) : 191-204</p></li><li><p><a href="https://www.phillymag.com/be-well-philly/2016/04/29/otc-sleep-aids-sleeping-supplements/" target="_blank" rel="nofollow noopener noreferrer">Phily Mag interview with doctors on efficacy of sleep supplements</a></p></li><li><p><a href="https://stanfordhealthcare.org/medical-treatments/c/cognitive-behavioral-therapy-insomnia/procedures/stimulus-control.html" target="_blank" rel="nofollow noopener noreferrer">Stimulus Control: Stanford Healthcare</a></p></li></ol></div></div></div>]]>
            </description>
            <link>https://www.sleepedy.com/articles/insomniac-journey-to-better-sleep/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23841175</guid>
            <pubDate>Wed, 15 Jul 2020 03:59:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How we grew Sentry's monthly active users by rethinking invitations]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23841049">thread link</a>) | @bentlegen
<br/>
July 14, 2020 | https://blog.sentry.io/2020/02/12/how-we-grew-sentrys-monthly-active-users-by-rethinking-invitations | <a href="https://web.archive.org/web/*/https://blog.sentry.io/2020/02/12/how-we-grew-sentrys-monthly-active-users-by-rethinking-invitations">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><time datetime="2020-02-12T00:00">February 12, 2020</time><div><p>At its core, Sentry is a tool that alerts you to defects in your production software. But it does more than blast stack traces into your inbox: Sentry provides powerful workflows to help your team determine root cause, <a href="https://blog.sentry.io/2019/02/07/sentry-workflow-triage">triage issues</a> to your team, and keep tabs on ongoing concerns with comments and notifications.</p>
<p>These collaborative features can help you resolve problems with your software quickly. But the keyword here is <strong>collaborative</strong>; without your full team having access to Sentry, you may find yourself quickly becoming overwhelmed with an endless backlog of issues and no one to help.</p>
<p>At the end of 2019, the Growth team made it our mission to make it easier for our users to invite their teammates to join them on Sentry. To achieve this, we tackled three distinct areas:</p>
<ol>
<li>Surfacing the ability to invite users contextually</li>
<li>Expanding Sentry’s permission model to allow <em>more types of users</em> to send invitations </li>
<li>Allowing external users to request access themselves</li>
</ol>
<p>Our theory: improving the user experience of inviting users, <em>as well as</em> democratizing the process to include all team members would lead to a significant increase in team-wide adoption. <em>(Narrator: it did.)</em></p>
<h2 id="the-status-quo"><a href="#the-status-quo" aria-label="the status quo permalink"><svg width="24" height="24" viewBox="0 0 24 24" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M10.8786797,6.05025253 L15,1.92893219 C16.7967298,0.132202428 19.6206785,-0.0112433245 21.5814287,1.49859493 C21.7515515,1.62959474 21.9151761,1.77304049 22.0710678,1.92893219 C24.0236893,3.88155365 24.0236893,7.04737854 22.0710678,9 L17.9497475,13.1213203 C17.5592232,13.5118446 16.9260582,13.5118446 16.5355339,13.1213203 C16.1450096,12.7307961 16.1450096,12.0976311 16.5355339,11.7071068 L20.6568542,7.58578644 C21.8284271,6.41421356 21.8284271,4.51471863 20.6568542,3.34314575 C19.4852814,2.17157288 17.5857864,2.17157288 16.4142136,3.34314575 L12.2928932,7.46446609 C11.9023689,7.85499039 11.2692039,7.85499039 10.8786797,7.46446609 C10.4881554,7.0739418 10.4881554,6.44077682 10.8786797,6.05025253 Z M13.1213203,17.9497475 L9,22.0710678 C7.04737854,24.0236893 3.88155365,24.0236893 1.92893219,22.0710678 C-0.0236892706,20.1184464 -0.0236892706,16.9526215 1.92893219,15 L6.05025253,10.8786797 C6.44077682,10.4881554 7.0739418,10.4881554 7.46446609,10.8786797 C7.85499039,11.2692039 7.85499039,11.9023689 7.46446609,12.2928932 L3.34314575,16.4142136 C2.17157288,17.5857864 2.17157288,19.4852814 3.34314575,20.6568542 C4.51471863,21.8284271 6.41421356,21.8284271 7.58578644,20.6568542 L11.7071068,16.5355339 C12.0976311,16.1450096 12.7307961,16.1450096 13.1213203,16.5355339 C13.5118446,16.9260582 13.5118446,17.5592232 13.1213203,17.9497475 Z M4.75735931,17.8284271 L17.8284271,4.75735931 C18.2189514,4.36683502 18.8521164,4.36683502 19.2426407,4.75735931 C19.633165,5.1478836 19.633165,5.78104858 19.2426407,6.17157288 L6.17157288,19.2426407 C5.78104858,19.633165 5.1478836,19.633165 4.75735931,19.2426407 C4.36683502,18.8521164 4.36683502,18.2189514 4.75735931,17.8284271 Z" fill="currentColor">
  </path>
</svg>
</a>The status quo</h2>
<p>Before we get deep into what we changed and how it impacted the bottom line, let’s quickly revisit how user invitations worked: the <em>Add Member to Organization</em> page you see below.</p>
<p><a href="https://images.ctfassets.net/em6l9zw4tzag/6BLSaoIQWaMkETq7E0Th9b/b61433d66e986f44e19d25c01f5186d1/1-invitations.png" target="_blank" rel="noopener">
          <span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/6BLSaoIQWaMkETq7E0Th9b/b61433d66e986f44e19d25c01f5186d1/1-invitations.png?fm=webp&amp;w=233 233w,
https://images.ctfassets.net/em6l9zw4tzag/6BLSaoIQWaMkETq7E0Th9b/b61433d66e986f44e19d25c01f5186d1/1-invitations.png?fm=webp&amp;w=465 465w,
https://images.ctfassets.net/em6l9zw4tzag/6BLSaoIQWaMkETq7E0Th9b/b61433d66e986f44e19d25c01f5186d1/1-invitations.png?fm=webp&amp;w=930 930w" sizes="(max-width: 800px) 100vw, 800px" type="image/webp">
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/6BLSaoIQWaMkETq7E0Th9b/b61433d66e986f44e19d25c01f5186d1/1-invitations.png?w=233 233w,
https://images.ctfassets.net/em6l9zw4tzag/6BLSaoIQWaMkETq7E0Th9b/b61433d66e986f44e19d25c01f5186d1/1-invitations.png?w=465 465w,
https://images.ctfassets.net/em6l9zw4tzag/6BLSaoIQWaMkETq7E0Th9b/b61433d66e986f44e19d25c01f5186d1/1-invitations.png?w=930 930w" sizes="(max-width: 800px) 100vw, 800px">
          <img alt="1-invitations" title="" src="https://images.ctfassets.net/em6l9zw4tzag/6BLSaoIQWaMkETq7E0Th9b/b61433d66e986f44e19d25c01f5186d1/1-invitations.png" loading="lazy">
        </picture>
        </span>
      </span>
        </a></p>
<p>This full-page experience, tucked away deep in Sentry’s account settings, had a number of issues:</p>
<ol>
<li>Since this is a full page, reaching it meant you would be taken out of context of whatever you were doing previously</li>
<li>Its location deep in our navigation hierarchy meant discoverability was poor</li>
<li>It’s <em>unclear</em> you can actually invite multiple people at once (you can!)</li>
<li>When inviting multiple users, you could only assign the group to the same role and collection of teams</li>
</ol>
<p>Interestingly, to improve discoverability, we had previously introduced a number of “quick links” to reach this page more easily. But these links were scattered around the application, and didn’t appear contextually when users signaled intent to invite members.</p>
</div><figure><p><img src="https://images.ctfassets.net/em6l9zw4tzag/4xiHp1Gl0HaZ0l8USGDPLr/79402583357d98cf55ad2dfda6ffe537/2-invitations.png" alt="" title="2-invitations"></p></figure><div>
<p>These user experience and discovery challenges felt like obvious starting places. But instead of just settling for a new “improved” form, we decided to rethink the entire experience from the ground up.</p>
<h2 id="the-new-member-invitation-modal"><a href="#the-new-member-invitation-modal" aria-label="the new member invitation modal permalink"><svg width="24" height="24" viewBox="0 0 24 24" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M10.8786797,6.05025253 L15,1.92893219 C16.7967298,0.132202428 19.6206785,-0.0112433245 21.5814287,1.49859493 C21.7515515,1.62959474 21.9151761,1.77304049 22.0710678,1.92893219 C24.0236893,3.88155365 24.0236893,7.04737854 22.0710678,9 L17.9497475,13.1213203 C17.5592232,13.5118446 16.9260582,13.5118446 16.5355339,13.1213203 C16.1450096,12.7307961 16.1450096,12.0976311 16.5355339,11.7071068 L20.6568542,7.58578644 C21.8284271,6.41421356 21.8284271,4.51471863 20.6568542,3.34314575 C19.4852814,2.17157288 17.5857864,2.17157288 16.4142136,3.34314575 L12.2928932,7.46446609 C11.9023689,7.85499039 11.2692039,7.85499039 10.8786797,7.46446609 C10.4881554,7.0739418 10.4881554,6.44077682 10.8786797,6.05025253 Z M13.1213203,17.9497475 L9,22.0710678 C7.04737854,24.0236893 3.88155365,24.0236893 1.92893219,22.0710678 C-0.0236892706,20.1184464 -0.0236892706,16.9526215 1.92893219,15 L6.05025253,10.8786797 C6.44077682,10.4881554 7.0739418,10.4881554 7.46446609,10.8786797 C7.85499039,11.2692039 7.85499039,11.9023689 7.46446609,12.2928932 L3.34314575,16.4142136 C2.17157288,17.5857864 2.17157288,19.4852814 3.34314575,20.6568542 C4.51471863,21.8284271 6.41421356,21.8284271 7.58578644,20.6568542 L11.7071068,16.5355339 C12.0976311,16.1450096 12.7307961,16.1450096 13.1213203,16.5355339 C13.5118446,16.9260582 13.5118446,17.5592232 13.1213203,17.9497475 Z M4.75735931,17.8284271 L17.8284271,4.75735931 C18.2189514,4.36683502 18.8521164,4.36683502 19.2426407,4.75735931 C19.633165,5.1478836 19.633165,5.78104858 19.2426407,6.17157288 L6.17157288,19.2426407 C5.78104858,19.633165 5.1478836,19.633165 4.75735931,19.2426407 C4.36683502,18.8521164 4.36683502,18.2189514 4.75735931,17.8284271 Z" fill="currentColor">
  </path>
</svg>
</a>The new member invitation modal</h2>
<p>It’s probably not a surprise that our first instinct was to convert this page into a modal –&nbsp;one that manages to squeeze all of the capabilities shown earlier into a smaller, more concise experience. It actually does one better: the modal is clearer in indicating that you can invite multiple users, and allows you to set unique permissions for each invitee.</p>
<p><a href="https://images.ctfassets.net/em6l9zw4tzag/xP7CehFwrtHYSvw9T3v7r/f67674006a888517f98422f47a3883a8/invitation-modal-tutorial.gif" target="_blank" rel="noopener">
          <span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/xP7CehFwrtHYSvw9T3v7r/f67674006a888517f98422f47a3883a8/invitation-modal-tutorial.gif?fm=webp&amp;w=190 190w,
https://images.ctfassets.net/em6l9zw4tzag/xP7CehFwrtHYSvw9T3v7r/f67674006a888517f98422f47a3883a8/invitation-modal-tutorial.gif?fm=webp&amp;w=381 381w,
https://images.ctfassets.net/em6l9zw4tzag/xP7CehFwrtHYSvw9T3v7r/f67674006a888517f98422f47a3883a8/invitation-modal-tutorial.gif?fm=webp&amp;w=761 761w" sizes="(max-width: 761px) 100vw, 761px" type="image/webp">
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/xP7CehFwrtHYSvw9T3v7r/f67674006a888517f98422f47a3883a8/invitation-modal-tutorial.gif?w=190 190w,
https://images.ctfassets.net/em6l9zw4tzag/xP7CehFwrtHYSvw9T3v7r/f67674006a888517f98422f47a3883a8/invitation-modal-tutorial.gif?w=381 381w,
https://images.ctfassets.net/em6l9zw4tzag/xP7CehFwrtHYSvw9T3v7r/f67674006a888517f98422f47a3883a8/invitation-modal-tutorial.gif?w=761 761w" sizes="(max-width: 761px) 100vw, 761px">
          <img alt="3-invitations" title="" src="https://images.ctfassets.net/em6l9zw4tzag/xP7CehFwrtHYSvw9T3v7r/f67674006a888517f98422f47a3883a8/invitation-modal-tutorial.gif" loading="lazy">
        </picture>
        </span>
      </span>
        </a></p>
<p>While modals are sometimes overused in web applications, we believed this approach would solve our key discoverability and navigation concerns: it can be shown contextually without leaving the current page, and completing the form returns you to what you were doing.</p>
<p>To that point, we additionally introduced buttons to launch this <em>Invite New Members</em> modal contextually throughout Sentry:</p>
<ul>
<li>Viewing an issue and notice a <a href="https://docs.sentry.io/workflow/releases/?platform=node#after-associating-commits">suspect commit</a> made by a coworker? If they’re not already part of your Sentry organization, you can now invite them then and there.</li>
<li>Trying to assign an issue to a team member, but don’t see their name in the assignee list? You now have the option to invite them right in the dropdown.</li>
<li>Creating a new team? Now you can invite new members directly to that team as you go.</li>
</ul>
</div><figure><p><img src="https://images.ctfassets.net/em6l9zw4tzag/60GpNeFNg4toier5a02zh4/ba868de307b0dcc6764805901b0b6e93/4-invitations.png" alt="" title="4-invitations"></p><figcaption><p>Example contextual link that launches the Invite New Members modal</p></figcaption></figure><div>
<h2 id="democratizing-invitations"><a href="#democratizing-invitations" aria-label="democratizing invitations permalink"><svg width="24" height="24" viewBox="0 0 24 24" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M10.8786797,6.05025253 L15,1.92893219 C16.7967298,0.132202428 19.6206785,-0.0112433245 21.5814287,1.49859493 C21.7515515,1.62959474 21.9151761,1.77304049 22.0710678,1.92893219 C24.0236893,3.88155365 24.0236893,7.04737854 22.0710678,9 L17.9497475,13.1213203 C17.5592232,13.5118446 16.9260582,13.5118446 16.5355339,13.1213203 C16.1450096,12.7307961 16.1450096,12.0976311 16.5355339,11.7071068 L20.6568542,7.58578644 C21.8284271,6.41421356 21.8284271,4.51471863 20.6568542,3.34314575 C19.4852814,2.17157288 17.5857864,2.17157288 16.4142136,3.34314575 L12.2928932,7.46446609 C11.9023689,7.85499039 11.2692039,7.85499039 10.8786797,7.46446609 C10.4881554,7.0739418 10.4881554,6.44077682 10.8786797,6.05025253 Z M13.1213203,17.9497475 L9,22.0710678 C7.04737854,24.0236893 3.88155365,24.0236893 1.92893219,22.0710678 C-0.0236892706,20.1184464 -0.0236892706,16.9526215 1.92893219,15 L6.05025253,10.8786797 C6.44077682,10.4881554 7.0739418,10.4881554 7.46446609,10.8786797 C7.85499039,11.2692039 7.85499039,11.9023689 7.46446609,12.2928932 L3.34314575,16.4142136 C2.17157288,17.5857864 2.17157288,19.4852814 3.34314575,20.6568542 C4.51471863,21.8284271 6.41421356,21.8284271 7.58578644,20.6568542 L11.7071068,16.5355339 C12.0976311,16.1450096 12.7307961,16.1450096 13.1213203,16.5355339 C13.5118446,16.9260582 13.5118446,17.5592232 13.1213203,17.9497475 Z M4.75735931,17.8284271 L17.8284271,4.75735931 C18.2189514,4.36683502 18.8521164,4.36683502 19.2426407,4.75735931 C19.633165,5.1478836 19.633165,5.78104858 19.2426407,6.17157288 L6.17157288,19.2426407 C5.78104858,19.633165 5.1478836,19.633165 4.75735931,19.2426407 C4.36683502,18.8521164 4.36683502,18.2189514 4.75735931,17.8284271 Z" fill="currentColor">
  </path>
</svg>
</a>Democratizing invitations</h2>
<p>As we began rolling out our new <em>Invite New Members</em> experience across the application, we came to a sobering realization: only roughly <strong><em>half</em></strong> of Sentry users could actually use our new modal. That’s because historically, only those with Owner or Manager-level permissions could invite other team members. Combined, users with these permissions accounted for less than 50% of active users.</p>
<p><a href="https://images.ctfassets.net/em6l9zw4tzag/5fURXm9mS5xbmyG3kgUakB/ed4cfdbcf818ed596cce78e937f246a3/5-invitations.png" target="_blank" rel="noopener">
          <span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/5fURXm9mS5xbmyG3kgUakB/ed4cfdbcf818ed596cce78e937f246a3/5-invitations.png?fm=webp&amp;w=123 123w,
https://images.ctfassets.net/em6l9zw4tzag/5fURXm9mS5xbmyG3kgUakB/ed4cfdbcf818ed596cce78e937f246a3/5-invitations.png?fm=webp&amp;w=245 245w,
https://images.ctfassets.net/em6l9zw4tzag/5fURXm9mS5xbmyG3kgUakB/ed4cfdbcf818ed596cce78e937f246a3/5-invitations.png?fm=webp&amp;w=490 490w" sizes="(max-width: 490px) 100vw, 490px" type="image/webp">
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/5fURXm9mS5xbmyG3kgUakB/ed4cfdbcf818ed596cce78e937f246a3/5-invitations.png?w=123 123w,
https://images.ctfassets.net/em6l9zw4tzag/5fURXm9mS5xbmyG3kgUakB/ed4cfdbcf818ed596cce78e937f246a3/5-invitations.png?w=245 245w,
https://images.ctfassets.net/em6l9zw4tzag/5fURXm9mS5xbmyG3kgUakB/ed4cfdbcf818ed596cce78e937f246a3/5-invitations.png?w=490 490w" sizes="(max-width: 490px) 100vw, 490px">
          <img alt="5-invitations" title="" src="https://images.ctfassets.net/em6l9zw4tzag/5fURXm9mS5xbmyG3kgUakB/ed4cfdbcf818ed596cce78e937f246a3/5-invitations.png" loading="lazy">
        </picture>
        </span>
      </span>
        </a></p>
<p>Restricting the ability to add new users to account administrators is pretty common practice for software tools, and Sentry is no exception. When an employee onboards on a new team, it’s common to see an exchange like this:</p>
<blockquote>
<p>Alice: Oh awesome, we use Sentry. Can you add me to the organization?
Bob: Ah, I can’t invite you. Maybe ask Jen?</p>
</blockquote>
<p>In a perfect world, one of your administrators is tracked down, and they manually add the new teammate to the account. But sometimes that person is unknown, or is on a vacation, or maybe it takes them days or weeks or even months.</p>
<p>We began asking ourselves: what if we could unlock team members to fast-track this whole process and invite members themselves? This led to our next major change: updating our permission model to allow for <strong>members to request to invite other members.</strong></p>
<p><a href="https://images.ctfassets.net/em6l9zw4tzag/3OdTQxgXsLOT7x1LhbdkcW/a1da3024530fea1163d3d66de8b214bf/6-invitations.png" target="_blank" rel="noopener">
          <span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/3OdTQxgXsLOT7x1LhbdkcW/a1da3024530fea1163d3d66de8b214bf/6-invitations.png?fm=webp&amp;w=185 185w,
https://images.ctfassets.net/em6l9zw4tzag/3OdTQxgXsLOT7x1LhbdkcW/a1da3024530fea1163d3d66de8b214bf/6-invitations.png?fm=webp&amp;w=369 369w,
https://images.ctfassets.net/em6l9zw4tzag/3OdTQxgXsLOT7x1LhbdkcW/a1da3024530fea1163d3d66de8b214bf/6-invitations.png?fm=webp&amp;w=738 738w" sizes="(max-width: 738px) 100vw, 738px" type="image/webp">
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/3OdTQxgXsLOT7x1LhbdkcW/a1da3024530fea1163d3d66de8b214bf/6-invitations.png?w=185 185w,
https://images.ctfassets.net/em6l9zw4tzag/3OdTQxgXsLOT7x1LhbdkcW/a1da3024530fea1163d3d66de8b214bf/6-invitations.png?w=369 369w,
https://images.ctfassets.net/em6l9zw4tzag/3OdTQxgXsLOT7x1LhbdkcW/a1da3024530fea1163d3d66de8b214bf/6-invitations.png?w=738 738w" sizes="(max-width: 738px) 100vw, 738px">
          <img alt="6-invitations" title="" src="https://images.ctfassets.net/em6l9zw4tzag/3OdTQxgXsLOT7x1LhbdkcW/a1da3024530fea1163d3d66de8b214bf/6-invitations.png" loading="lazy">
        </picture>
        </span>
      </span>
        </a>  </p>
<p>Now, when non-administrators open up the Invite New Members modal, it changes contextually to become a “request to invite” rather than a direct invitation. Hitting “send” kicks off an email to all organization administrators, who are prompted to approve any outstanding requests.</p>
</div><figure><p><img src="https://images.ctfassets.net/em6l9zw4tzag/4oi9gYhVX185djAJWppP3Q/ff565fcd34cf00c3a60a32c5ec0cde7b/7-invitations.png" alt="" title="7-invitations"></p><figcaption><p>Organization owners and managers can see pending invitation requests.</p></figcaption></figure><div>
<p>At this point, we had built what we thought was a fantastic new user experience and we just <em>doubled</em> the number of users who could take advantage of it. But this exercise of opening up user invitations got us thinking: what if there was an even <em>further</em> source of untapped users we weren’t reaching?</p>
<h2 id="removing-the-middleman-entirely"><a href="#removing-the-middleman-entirely" aria-label="removing the middleman entirely permalink"><svg width="24" height="24" viewBox="0 0 24 24" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M10.8786797,6.05025253 L15,1.92893219 C16.7967298,0.132202428 19.6206785,-0.0112433245 21.5814287,1.49859493 C21.7515515,1.62959474 21.9151761,1.77304049 22.0710678,1.92893219 C24.0236893,3.88155365 24.0236893,7.04737854 22.0710678,9 L17.9497475,13.1213203 C17.5592232,13.5118446 16.9260582,13.5118446 16.5355339,13.1213203 C16.1450096,12.7307961 16.1450096,12.0976311 16.5355339,11.7071068 L20.6568542,7.58578644 C21.8284271,6.41421356 21.8284271,4.51471863 20.6568542,3.34314575 C19.4852814,2.17157288 17.5857864,2.17157288 16.4142136,3.34314575 L12.2928932,7.46446609 C11.9023689,7.85499039 11.2692039,7.85499039 10.8786797,7.46446609 C10.4881554,7.0739418 10.4881554,6.44077682 10.8786797,6.05025253 Z M13.1213203,17.9497475 L9,22.0710678 C7.04737854,24.0236893 3.88155365,24.0236893 1.92893219,22.0710678 C-0.0236892706,20.1184464 -0.0236892706,16.9526215 1.92893219,15 L6.05025253,10.8786797 C6.44077682,10.4881554 7.0739418,10.4881554 7.46446609,10.8786797 C7.85499039,11.2692039 7.85499039,11.9023689 7.46446609,12.2928932 L3.34314575,16.4142136 C2.17157288,17.5857864 2.17157288,19.4852814 3.34314575,20.6568542 C4.51471863,21.8284271 6.41421356,21.8284271 7.58578644,20.6568542 L11.7071068,16.5355339 C12.0976311,16.1450096 12.7307961,16.1450096 13.1213203,16.5355339 C13.5118446,16.9260582 13.5118446,17.5592232 13.1213203,17.9497475 Z M4.75735931,17.8284271 L17.8284271,4.75735931 C18.2189514,4.36683502 18.8521164,4.36683502 19.2426407,4.75735931 C19.633165,5.1478836 19.633165,5.78104858 19.2426407,6.17157288 L6.17157288,19.2426407 C5.78104858,19.633165 5.1478836,19.633165 4.75735931,19.2426407 C4.36683502,18.8521164 4.36683502,18.2189514 4.75735931,17.8284271 Z" fill="currentColor">
  </path>
</svg>
</a>Removing the middleman entirely</h2>
<p>In the last section, we highlighted a scenario where one teammate asks another teammate for access to Sentry. And because of our recent changes, users can request to invite their teammates themselves instead of having to track down and ask their account administrator.</p>
<p>But this scenario still has a gatekeeping element: the new teammate has to ask <em>another</em> teammate for access. What if the new teammate spots an alert from Sentry in Slack stemming from their recent changes, and no one’s around to grant them access? Unfortunately, they’d land on an authentication wall that would prevent them from going any further.</p>
<p><a href="https://images.ctfassets.net/em6l9zw4tzag/51YEH5Ipq6HWcU052ogj6i/0967cecf4f1dd88efcbab507de6a8a69/8-invitations.png" target="_blank" rel="noopener">
          <span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/51YEH5Ipq6HWcU052ogj6i/0967cecf4f1dd88efcbab507de6a8a69/8-invitations.png?fm=webp&amp;w=112 112w,
https://images.ctfassets.net/em6l9zw4tzag/51YEH5Ipq6HWcU052ogj6i/0967cecf4f1dd88efcbab507de6a8a69/8-invitations.png?fm=webp&amp;w=225 225w,
https://images.ctfassets.net/em6l9zw4tzag/51YEH5Ipq6HWcU052ogj6i/0967cecf4f1dd88efcbab507de6a8a69/8-invitations.png?fm=webp&amp;w=449 449w" sizes="(max-width: 449px) 100vw, 449px" type="image/webp">
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/51YEH5Ipq6HWcU052ogj6i/0967cecf4f1dd88efcbab507de6a8a69/8-invitations.png?w=112 112w,
https://images.ctfassets.net/em6l9zw4tzag/51YEH5Ipq6HWcU052ogj6i/0967cecf4f1dd88efcbab507de6a8a69/8-invitations.png?w=225 225w,
https://images.ctfassets.net/em6l9zw4tzag/51YEH5Ipq6HWcU052ogj6i/0967cecf4f1dd88efcbab507de6a8a69/8-invitations.png?w=449 449w" sizes="(max-width: 449px) 100vw, 449px">
          <img alt="8-invitations" title="" src="https://images.ctfassets.net/em6l9zw4tzag/51YEH5Ipq6HWcU052ogj6i/0967cecf4f1dd88efcbab507de6a8a69/8-invitations.png" loading="lazy">
        </picture>
        </span>
      </span>
        </a></p>
<p>This begged the question: was there an untapped source of potential users we weren’t reaching by restricting invitations <em>only</em> to active Sentry users? What if new users didn’t have to ask anyone at all?</p>
<p>So, to keep this party going, we dug in and additionally made it possible for <strong>external users to request to join an organization</strong>.</p>
</div><figure><p><img src="https://images.ctfassets.net/em6l9zw4tzag/6mRCkcVZkkAlZ0ELzWUGHr/3123b1113330661bc7ee5023aa5ef54c/9-invitations.png" alt="" title="9-invitations"></p><figcaption><p>The “Request to Join” button has been added to the organization login page, allowing</p></figcaption></figure><div>
<p>Now when a user lands on an Organization’s login page, they have the option to “Request to join”, which asks for the user’s name and email address. Once they hit send, the organization owners are sent an email that prompts them to approve the join request. Just in case, there’s also a call-to-action to disable the feature entirely for their organization.</p>
<p><a href="https://images.ctfassets.net/em6l9zw4tzag/NwB91DxtuVJ7p8o5sPMmV/53d84e72fda2e78b4ccb31522ff4a02c/10-invitations.png" target="_blank" rel="noopener">
          <span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/NwB91DxtuVJ7p8o5sPMmV/53d84e72fda2e78b4ccb31522ff4a02c/10-invitations.png?fm=webp&amp;w=165 165w,
https://images.ctfassets.net/em6l9zw4tzag/NwB91DxtuVJ7p8o5sPMmV/53d84e72fda2e78b4ccb31522ff4a02c/10-invitations.png?fm=webp&amp;w=330 330w,
https://images.ctfassets.net/em6l9zw4tzag/NwB91DxtuVJ7p8o5sPMmV/53d84e72fda2e78b4ccb31522ff4a02c/10-invitations.png?fm=webp&amp;w=660 660w" sizes="(max-width: 660px) 100vw, 660px" type="image/webp">
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/NwB91DxtuVJ7p8o5sPMmV/53d84e72fda2e78b4ccb31522ff4a02c/10-invitations.png?w=165 165w,
https://images.ctfassets.net/em6l9zw4tzag/NwB91DxtuVJ7p8o5sPMmV/53d84e72fda2e78b4ccb31522ff4a02c/10-invitations.png?w=330 330w,
https://images.ctfassets.net/em6l9zw4tzag/NwB91DxtuVJ7p8o5sPMmV/53d84e72fda2e78b4ccb31522ff4a02c/10-invitations.png?w=660 660w" sizes="(max-width: 660px) 100vw, 660px">
          <img alt="10-invitations" title="" src="https://images.ctfassets.net/em6l9zw4tzag/NwB91DxtuVJ7p8o5sPMmV/53d84e72fda2e78b4ccb31522ff4a02c/10-invitations.png" loading="lazy">
        </picture>
        </span>
      </span>
        </a></p>
<p>Having developed a new contextual invitation modal and a pair of invite-friendly permission changes, we were <em>feeling</em> confident that these changes were going to have a strong impact on user behavior. It was time now to put our money where our code was, and verify that all this hard work actually moved the needle.</p>
<h2 id="ab-testing-the-impact"><a href="#ab-testing-the-impact" aria-label="ab testing the impact permalink"><svg width="24" height="24" viewBox="0 0 24 24" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M10.8786797,6.05025253 L15,1.92893219 C16.7967298,0.132202428 19.6206785,-0.0112433245 21.5814287,1.49859493 C21.7515515,1.62959474 21.9151761,1.77304049 22.0710678,1.92893219 C24.0236893,3.88155365 24.0236893,7.04737854 22.0710678,9 L17.9497475,13.1213203 C17.5592232,13.5118446 16.9260582,13.5118446 16.5355339,13.1213203 C16.1450096,12.7307961 16.1450096,12.0976311 16.5355339,11.7071068 L20.6568542,7.58578644 C21.8284271,6.41421356 21.8284271,4.51471863 20.6568542,3.34314575 C19.4852814,2.17157288 17.5857864,2.17157288 16.4142136,3.34314575 L12.2928932,7.46446609 C11.9023689,7.85499039 11.2692039,7.85499039 10.8786797,7.46446609 C10.4881554,7.0739418 10.4881554,6.44077682 10.8786797,6.05025253 Z M13.1213203,17.9497475 L9,22.0710678 C7.04737854,24.0236893 3.88155365,24.0236893 1.92893219,22.0710678 C-0.0236892706,20.1184464 -0.0236892706,16.9526215 1.92893219,15 L6.05025253,10.8786797 C6.44077682,10.4881554 7.0739418,10.4881554 7.46446609,10.8786797 C7.85499039,11.2692039 7.85499039,11.9023689 7.46446609,12.2928932 L3.34314575,16.4142136 C2.17157288,17.5857864 2.17157288,19.4852814 3.34314575,20.6568542 C4.51471863,21.8284271 6.41421356,21.8284271 7.58578644,20.6568542 L11.7071068,16.5355339 C12.0976311,16.1450096 12.7307961,16.1450096 13.1213203,16.5355339 C13.5118446,16.9260582 13.5118446,17.5592232 13.1213203,17.9497475 Z M4.75735931,17.8284271 L17.8284271,4.75735931 C18.2189514,4.36683502 18.8521164,4.36683502 19.2426407,4.75735931 C19.633165,5.1478836 19.633165,5.78104858 19.2426407,6.17157288 L6.17157288,19.2426407 C5.78104858,19.633165 5.1478836,19.633165 4.75735931,19.2426407 C4.36683502,18.8521164 4.36683502,18.2189514 4.75735931,17.8284271 Z" fill="currentColor">
  </path>
</svg>
</a>A/B testing the impact</h2>
<p>Our standard procedure for validating the efficacy of product changes is through A/B testing (also known as split testing). This means instrumenting our application code to serve different experiences to segments of users over the same time period, and comparing the results. This step takes extra effort, but it’s worth it –&nbsp;the alternative is to settle for a before-and-after snapshot of data, which is too easily impacted by external factors like seasonality or marketing pushes.</p>
<p>ℹ️ <em>To learn more about how we perform A/B testing at Sentry, please see <a href="https://blog.sentry.io/2019/05/09/easy-ab-testing-with-planout">this earlier blog post</a>.</em></p>
<p>It’s easy to get carried away with A/B testing, and having so many permutations that you don’t have enough data to be statistically significant. So, to simplify things, we decided that all treatments would get the new modal experience, and our “treatment” groups would focus on the new permission changes.</p>
<p>This left us with 4 distinct treatments that we rolled out to 4 equally-sized customer segments:</p>
<ol>
<li><strong>Baseline</strong> (new modal only)</li>
<li><strong>Request to Invite</strong> (user invites another user)</li>
<li><strong>Request to Join</strong> (external user requests to join)</li>
<li><strong><em>Both</em></strong> Request to Invite and Request to Join are enabled together</li>
</ol>
<p>Our main criteria for determining success: which of these treatments would result in <strong>an increase in <em>accepted</em> invitations</strong> (and thus new users)?</p>
</div><figure><p><img src="https://images.ctfassets.net/em6l9zw4tzag/rlobEVJ4FCzWbU1tmPqqb/8ed779f9a63aa3382e5590cfa8e4bec1/11-invitations_2_.png" alt="" title="11-invitations"></p><figcaption><p>% of accepted invitations relative to baseline</p></figcaption></figure><div>
<p>After 30 days, the results became clear (not to mention, statistically significant):</p>
<ul>
<li><strong>11%</strong> more users accepted invitations in the <em>Request to Invite</em> treatment vs. the baseline</li>
<li><strong>9%</strong> more users accepted invitations in the <em>Request to Join</em> treatment vs. the baseline</li>
<li><strong>21%</strong> more users accepted invitations who had both <em>Request to Invite</em> and <em>Request to Invite</em> treatments enabled</li>
</ul>
<p>It’s probably not a surprise that allowing a wider set of users to invite team members resulted in more users inviting team members. It’s also probably not a surprise that enabling both feature sets at the same time was even better (given that they complement each other)!</p>
<h2 id="turning-users-into-active-users"><a href="#turning-users-into-active-users" aria-label="turning users into active users permalink"><svg width="24" height="24" viewBox="0 0 24 24" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M10.8786797,6.05025253 L15,1.92893219 C16.7967298,0.132202428 19.6206785,-0.0112433245 21.5814287,1.49859493 C21.7515515,1.62959474 21.9151761,1.77304049 22.0710678,1.92893219 C24.0236893,3.88155365 24.0236893,7.04737854 22.0710678,9 L17.9497475,13.1213203 C17.5592232,13.5118446 16.9260582,13.5118446 16.5355339,13.1213203 C16.1450096,12.7307961 16.1450096,12.0976311 16.5355339,11.7071068 L20.6568542,7.58578644 C21.8284271,6.41421356 21.8284271,4.51471863 20.6568542,3.34314575 C19.4852814,2.17157288 17.5857864,2.17157288 16.4142136,3.34314575 L12.2928932,7.46446609 C11.9023689,7.85499039 11.2692039,7.85499039 10.8786797,7.46446609 C10.4881554,7.0739418 10.4881554,6.44077682 10.8786797,6.05025253 Z M13.1213203,17.9497475 L9,22.0710678 C7.04737854,24.0236893 3.88155365,24.0236893 1.92893219,22.0710678 C-0.0236892706,20.1184464 -0.0236892706,16.9526215 1.92893219,15 L6.05025253,10.8786797 C6.44077682,10.4881554 7.0739418,10.4881554 7.46446609,10.8786797 C7.85499039,11.2692039 7.85499039,11.9023689 7.46446609,12.2928932 L3.34314575,16.4142136 C2.17157288,17.5857864 2.17157288,19.4852814 3.34314575,20.6568542 C4.51471863,21.8284271 6.41421356,21.8284271 7.58578644,20.6568542 L11.7071068,16.5355339 C12.0976311,16.1450096 12.7307961,16.1450096 13.1213203,16.5355339 C13.5118446,16.9260582 13.5118446,17.5592232 13.1213203,17.9497475 Z M4.75735931,17.8284271 L17.8284271,4.75735931 C18.2189514,4.36683502 18.8521164,4.36683502 19.2426407,4.75735931 C19.633165,5.1478836 19.633165,5.78104858 19.2426407,6.17157288 L6.17157288,19.2426407 C5.78104858,19.633165 5.1478836,19.633165 4.75735931,19.2426407 C4.36683502,18.8521164 4.36683502,18.2189514 4.75735931,17.8284271 Z" fill="currentColor">
  </path>
</svg>
</a>Turning users into active users</h2>
<p>Having more users join your platform is great, but what’s the point if those users never actually <em>use</em> the product? To be truly confident …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.sentry.io/2020/02/12/how-we-grew-sentrys-monthly-active-users-by-rethinking-invitations">https://blog.sentry.io/2020/02/12/how-we-grew-sentrys-monthly-active-users-by-rethinking-invitations</a></em></p>]]>
            </description>
            <link>https://blog.sentry.io/2020/02/12/how-we-grew-sentrys-monthly-active-users-by-rethinking-invitations</link>
            <guid isPermaLink="false">hacker-news-small-sites-23841049</guid>
            <pubDate>Wed, 15 Jul 2020 03:42:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quick Landing Page Optimization Tips (With Examples)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23840363">thread link</a>) | @nscalice
<br/>
July 14, 2020 | https://growthmarketer.co/landing-page-optimization-tips/ | <a href="https://web.archive.org/web/*/https://growthmarketer.co/landing-page-optimization-tips/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wtr-content" data-bg="#ffffff" data-fg="#165cfc" data-width="5" data-mute="" data-fgopacity="0.5" data-mutedopacity="0.5" data-placement="top" data-placement-offset="0" data-content-offset="0" data-placement-touch="top" data-placement-offset-touch="0" data-transparent="" data-touch="1" data-non-touch="1" data-comments="0" data-commentsbg="#ffcece" data-location="page" data-mutedfg="#165cfc" data-rtl="">
<p>Need to&nbsp;<strong>optimize your website or landing page</strong>&nbsp;in a hurry?</p>
<p>While there’s no one-size-fits-all approach to conversion optimization, there are some recurring recommendations that come up again and again when I’m consulting with clients.</p>
<p>And in this article, I break down seven such landing page optimization tips for you, one-by-one.</p>
<p>Each tip is based off my <a href="https://growthmarketer.co/framework/">7 Question Landing Page Framework</a>, and backed by years of data and testing.</p>
<p><em>Let’s go!</em></p>
<h2>Focus on clarity</h2>
<p>Simplify the above-the-fold section of your landing page to focus on&nbsp;<strong>one main thought</strong>&nbsp;(headline), a subheadline that goes into more detail, and one&nbsp;clear&nbsp;call-to-action.</p>
<p>Here’s what an&nbsp;<em>unclear</em>&nbsp;headline looks like:</p>
<figure><img src="https://growthmarketer.co/wp-content/uploads/2020/07/unclear-headline.png" alt="" srcset="https://growthmarketer.co/wp-content/uploads/2020/07/unclear-headline.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/unclear-headline-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/unclear-headline-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/unclear-headline-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/unclear-headline-1536x864.png 1536w" sizes="(max-width: 1920px) 100vw, 1920px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-srcset="https://growthmarketer.co/wp-content/uploads/2020/07/unclear-headline.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/unclear-headline-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/unclear-headline-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/unclear-headline-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/unclear-headline-1536x864.png 1536w" data-lazy-src="https://growthmarketer.co/wp-content/uploads/2020/07/unclear-headline.png"></figure>
<p>If you just read the headline, would you have any idea what this company does?</p>
<p>Now, on the flip side, what do you think of this headline:</p>
<figure><img src="https://growthmarketer.co/wp-content/uploads/2020/07/clear-headline.png" alt="" srcset="https://growthmarketer.co/wp-content/uploads/2020/07/clear-headline.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/clear-headline-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/clear-headline-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/clear-headline-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/clear-headline-1536x864.png 1536w" sizes="(max-width: 1920px) 100vw, 1920px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-srcset="https://growthmarketer.co/wp-content/uploads/2020/07/clear-headline.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/clear-headline-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/clear-headline-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/clear-headline-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/clear-headline-1536x864.png 1536w" data-lazy-src="https://growthmarketer.co/wp-content/uploads/2020/07/clear-headline.png"></figure>
<p>It’s pretty clear right away that this tool helps you sell stuff online.</p>
<h2>Increase the relevance</h2>
<p>Focus less on the features and more on&nbsp;<strong>benefits and outcomes</strong>&nbsp;that show the visitor how your offer will solve their problem.</p>
<p>This landing page below does a good job of focusing on the benefits for their sales tool, by mentioning stuff like “prioritize which decision makers to pursue with relevant insights:”</p>
<figure><img src="https://growthmarketer.co/wp-content/uploads/2020/07/copy.png" alt="" srcset="https://growthmarketer.co/wp-content/uploads/2020/07/copy.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/copy-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/copy-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/copy-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/copy-1536x864.png 1536w" sizes="(max-width: 1920px) 100vw, 1920px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-srcset="https://growthmarketer.co/wp-content/uploads/2020/07/copy.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/copy-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/copy-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/copy-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/copy-1536x864.png 1536w" data-lazy-src="https://growthmarketer.co/wp-content/uploads/2020/07/copy.png"></figure>
<h2>Create strong affinity</h2>
<p><strong>Design</strong>&nbsp;your page in a way that is easy-to-use, easy-to-navigate, looks great on mobile, has legible typography, consistent&nbsp;colors, and authentic images.</p>
<p>Creating a sense of affinity is not easy, but when you nail it, you know right away.</p>
<p>Here are two pages side-by-side:</p>
<figure><img src="https://growthmarketer.co/wp-content/uploads/2020/07/affinity.png" alt="" srcset="https://growthmarketer.co/wp-content/uploads/2020/07/affinity.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/affinity-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/affinity-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/affinity-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/affinity-1536x864.png 1536w" sizes="(max-width: 1920px) 100vw, 1920px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-srcset="https://growthmarketer.co/wp-content/uploads/2020/07/affinity.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/affinity-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/affinity-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/affinity-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/affinity-1536x864.png 1536w" data-lazy-src="https://growthmarketer.co/wp-content/uploads/2020/07/affinity.png"></figure>
<p>Don’t you simply like one way better than the other, even if you can’t explain exactly why?</p>
<h2>Showcase your influence</h2>
<p>Add&nbsp;<strong>social proof</strong>&nbsp;to your page with&nbsp;testimonials, case studies, numbers of customers/clients, etc.</p>
<p>One company that goes above and beyond with their social proof is Basecamp. Look at all of those testimonials:</p>
<figure><img src="https://growthmarketer.co/wp-content/uploads/2020/07/social-proof.png" alt="" srcset="https://growthmarketer.co/wp-content/uploads/2020/07/social-proof.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/social-proof-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/social-proof-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/social-proof-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/social-proof-1536x864.png 1536w" sizes="(max-width: 1920px) 100vw, 1920px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-srcset="https://growthmarketer.co/wp-content/uploads/2020/07/social-proof.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/social-proof-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/social-proof-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/social-proof-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/social-proof-1536x864.png 1536w" data-lazy-src="https://growthmarketer.co/wp-content/uploads/2020/07/social-proof.png"></figure>
<h2>Build up trust</h2>
<p>Increase the perception of&nbsp;<strong>trust</strong>&nbsp;by adding trust indicators, badges, certifications, affiliations, and other quantifiable stats such as the number of years in business.</p>
<p>InVision does a great job of showcasing some well-known trust signals below the hero section:</p>
<figure><img src="https://growthmarketer.co/wp-content/uploads/2020/07/trust-signals.png" alt="" srcset="https://growthmarketer.co/wp-content/uploads/2020/07/trust-signals.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/trust-signals-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/trust-signals-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/trust-signals-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/trust-signals-1536x864.png 1536w" sizes="(max-width: 1920px) 100vw, 1920px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-srcset="https://growthmarketer.co/wp-content/uploads/2020/07/trust-signals.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/trust-signals-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/trust-signals-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/trust-signals-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/trust-signals-1536x864.png 1536w" data-lazy-src="https://growthmarketer.co/wp-content/uploads/2020/07/trust-signals.png"></figure>
<h2>Mention an advantage</h2>
<p>Make sure to mention your&nbsp;<strong>unique advantage</strong>&nbsp;that highlights something special about your offer/product/service to address how your solution is different from other options.</p>
<p>My&nbsp;<em>favorite</em>&nbsp;example of a unique advantage is Dyson and their “cyclone technology:”</p>
<figure><img src="https://growthmarketer.co/wp-content/uploads/2020/07/unique-advantage.png" alt="" srcset="https://growthmarketer.co/wp-content/uploads/2020/07/unique-advantage.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/unique-advantage-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/unique-advantage-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/unique-advantage-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/unique-advantage-1536x864.png 1536w" sizes="(max-width: 1920px) 100vw, 1920px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-srcset="https://growthmarketer.co/wp-content/uploads/2020/07/unique-advantage.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/unique-advantage-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/unique-advantage-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/unique-advantage-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/unique-advantage-1536x864.png 1536w" data-lazy-src="https://growthmarketer.co/wp-content/uploads/2020/07/unique-advantage.png"></figure>
<h2>Make it easy to take action</h2>
<p>Repeat your&nbsp;<strong>call-to-action</strong>&nbsp;several times throughout the page using a contrasting color/style to make it stand out, especially mentioning it at the top and bottom sections.</p>
<p>Here’s an above-the-fold portion of a site that has literally&nbsp;<em>no</em>&nbsp;visible&nbsp;call-to-action&nbsp;in their hero section:</p>

<figure><img src="https://growthmarketer.co/wp-content/uploads/2020/07/bad-cta.png" alt="" srcset="https://growthmarketer.co/wp-content/uploads/2020/07/bad-cta.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/bad-cta-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/bad-cta-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/bad-cta-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/bad-cta-1536x864.png 1536w" sizes="(max-width: 1920px) 100vw, 1920px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-srcset="https://growthmarketer.co/wp-content/uploads/2020/07/bad-cta.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/bad-cta-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/bad-cta-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/bad-cta-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/bad-cta-1536x864.png 1536w" data-lazy-src="https://growthmarketer.co/wp-content/uploads/2020/07/bad-cta.png"></figure>
<p>On the other hand, this financial services company makes it super easy to understand exactly what they want you to do next:</p>
<figure><img src="https://growthmarketer.co/wp-content/uploads/2020/07/good-cta.png" alt="" srcset="https://growthmarketer.co/wp-content/uploads/2020/07/good-cta.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/good-cta-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/good-cta-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/good-cta-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/good-cta-1536x864.png 1536w" sizes="(max-width: 1920px) 100vw, 1920px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-srcset="https://growthmarketer.co/wp-content/uploads/2020/07/good-cta.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/good-cta-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/good-cta-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/good-cta-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/good-cta-1536x864.png 1536w" data-lazy-src="https://growthmarketer.co/wp-content/uploads/2020/07/good-cta.png"></figure>
<h2>The “7 Question” Landing Page Framework</h2>
<p>If you’ve been reading my blog for a while, or listening to my podcasts, you might realize a recurring theme here.</p>
<p>Each landing page optimization tip I shared above is directly related to one of the questions in my <a href="https://growthmarketer.co/framework/"><strong>7 Question Landing Page Framework</strong></a>.</p>
<p>Get instant access to the free guide <a href="https://growthmarketer.co/framework/">here</a>.</p>
<figure><a href="https://growthmarketer.co/framework/"><img src="https://growthmarketer.co/wp-content/uploads/2020/07/free-framework-cta.png" alt="" srcset="https://growthmarketer.co/wp-content/uploads/2020/07/free-framework-cta.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/free-framework-cta-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/free-framework-cta-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/free-framework-cta-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/free-framework-cta-1536x864.png 1536w" sizes="(max-width: 1920px) 100vw, 1920px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-srcset="https://growthmarketer.co/wp-content/uploads/2020/07/free-framework-cta.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/free-framework-cta-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/free-framework-cta-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/free-framework-cta-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/free-framework-cta-1536x864.png 1536w" data-lazy-src="https://growthmarketer.co/wp-content/uploads/2020/07/free-framework-cta.png"></a></figure>
<p>So, there you have it! With the landing page optimization tips I shared above <strong><em>and</em> my <a href="https://growthmarketer.co/framework/">7 Question Landing Page Framework</a></strong>, you’re well on your way to&nbsp;<strong>higher-converting landing pages</strong>.</p>
<p><em>PS: Sharing is caring. ❤️ If you found this article helpful, give it a quick share on Twitter. Here’s a ready-to-go tweet for you!</em> 👇</p>

</div></div>]]>
            </description>
            <link>https://growthmarketer.co/landing-page-optimization-tips/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23840363</guid>
            <pubDate>Wed, 15 Jul 2020 01:57:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Heisenberg's Uncertainty Principle]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23840342">thread link</a>) | @keyboardman
<br/>
July 14, 2020 | https://leimao.github.io/blog/Heisenberg-Uncertainty-Principle/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Heisenberg-Uncertainty-Principle/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>In quantum mechanics, one of the key discoveries is that it is not always possible that we could measure two physical observables precisely, which is the Heisenberg’s general uncertainty principle.</p>



<p>We might have learned a special case of the Heisenberg’s general uncertainty principle from high school or college physics courses that the more precisely the position of some particle is determined, the less precisely its momentum can be predicted from initial conditions, and vice versa. In this case, the two physical observables are position and momentum.</p>



<p>Formally, the Heisenberg’s general uncertainty principle states that the product of the variances of two arbitrary hermitian operators on a given state is always greater than or equal to one-fourth the square of the expected value of their commutator. In formulas:</p>



<p>where $\mathbb{V}_{\psi}(\Omega_1)$ and $\mathbb{V}_{\psi}(\Omega_2)$ are using the notations from my previous <a href="https://leimao.github.io/blog/Quantum-Mean-Variance/">post</a>, $[\Omega_1, \Omega_2]$ is called the commutator of $\Omega_1$ and $\Omega_2$, and $[\Omega_1, \Omega_2] = \Omega_1 \Omega_2 - \Omega_2 \Omega_1$.</p>



<p>In this blog post, I would like to show a mathematical proof to Heisenberg’s general uncertainty principle.</p>

<h3 id="prerequisites">Prerequisites</h3>

<p>We would use the following four theorems and properties to prove Heisenberg’s general uncertainty principle.</p>

<h4 id="cauchyschwarz-inequality">Cauchy–Schwarz Inequality</h4>

<p>The Cauchy–Schwarz inequality states that for all vectors $u$ and $v$ of an inner product space it is true that</p>



<p>The proof could be found on <a href="https://en.wikipedia.org/wiki/Cauchy%E2%80%93Schwarz_inequality">Wikipedia</a>.</p>

<h4 id="imaginary-part-of-vector-inner-product">Imaginary Part of Vector Inner Product</h4>

<p>The imaginary part of the inner product of all vectors $u$ and $v$, $\text{Im}\big(\langle u, v \rangle\big)$, could be computed as</p>



<p>Assuming $u = a_1 + b_1 i$ and $v = a_2 + b_2 i$, where $a_1$, $a_2$, $b_1$, and $b_2$ are real (column) vectors.</p>





<p>It is trivial to see that</p>



<p>This concludes the proof.</p>

<h4 id="triangle-inequality">Triangle Inequality</h4>

<p>Let $z$ be any complex number, we have</p>



<p>This should be very straightforward to the people who are familiar with triangles and know the polar coordinate expression of complex numbers. We will skip the formal proof here.</p>

<h4 id="hermitian-property">Hermitian Property</h4>

<p>If A is a hermitian $n$-by-$n$ matrix, then for all $u, v^{\prime} \in \mathbb{C}$. we have</p>



<p>Using the property of hermitian matrix $A^{\dagger} = A$, we simply have</p>



<p>This concludes the proof.</p>

<h3 id="proof-to-heisenbergs-general-uncertainty-principle">Proof to Heisenberg’s General Uncertainty Principle</h3>

<p>Because $\Delta_{\psi}(\Omega) = \Omega - \langle \Omega \rangle_{\psi} I$ and $\Omega$ is a hermitian operator, therefore $\Delta_{\psi}(\Omega)$ is also a hermitian operator. Based on <a href="https://leimao.github.io/blog/Quantum-Mean-Variance/">the definition of variance</a>, using the hermitian property, we further have</p>



<p>We apply the Cauchy–Schwarz inequality to the left side of the Heisenberg’s general uncertainty principle,</p>



<p>We further apply the Triangle inequality,</p>



<p>We use the imaginary part of vector inner product,</p>



<p>We use the hermitian property again,</p>



<p>This concludes the proof.</p>

<h3 id="caveats">Caveats</h3>

<p>In Heisenberg’s general uncertainty principle, the commutator $[\Omega_1, \Omega_2] = 0$ suggests $\Omega_1 \Omega_2 = \Omega_2 \Omega_1$ and $\Omega_1 \Omega_2 | \psi \rangle = \Omega_2 \Omega_1 | \psi \rangle$. This means that the system states after the two sequential measures $\Omega_1 \Omega_2$ and $\Omega_1 \Omega_2$ are the same if $[\Omega_1, \Omega_2] = 0$. Otherwise, if $[\Omega_1, \Omega_2] \neq 0$ the system states after the two sequential measures $\Omega_1 \Omega_2$ and $\Omega_1 \Omega_2$ are not the same. If the commutator $[\Omega_1, \Omega_2] = 0$, Heisenberg’s general uncertainty principle suggests that the two physical observables that $\Omega_1$ and $\Omega_2$ are measuring would have not limit in precision.</p>



<p>In other expressions of Heisenberg’s general uncertainty principle, sometimes we would see the word “simultaneity”. How to understand the simultaneity in Heisenberg’s general uncertainty principle? Given measurement would change the system state, and it is almost impossible to achieve the absolute simultaneity in the time domain, what does the simultaneity mean in this case? Here simultaneity means that the order of measurement $\Omega_1$ and $\Omega_2$ do not change the final observation, as we tried hard to make them simultaneous and it is impossible to control the exact order of these two measurements. In short, simultaneity just means $[\Omega_1, \Omega_2] = 0$.</p>



<p>How to measure the variance of physical observable for a system state, as is shown at the left side of the inequality of Heisenberg’s general uncertainty principle? Measurement changes system state in quantum mechanics. We would need to create lots of clones of the system state. Once a system state is measured, it should be discarded and not be used for the measurement for the physical observable anymore. Measurement on the same system state means measurement on system state clones and not the exact system state.</p>

<h3 id="conclusions">Conclusions</h3>

<p>It is quite amazing that the Heisenberg’s general uncertainty principle could be derived in a such simple way. Unfortunately, the my college physics course instructor never showed a proof to this important principle.</p>

<h3 id="references">References</h3>

<ul>
  <li><a href="https://leimao.github.io/blog/Inner-Product/">Inner Product and Inner Product Space</a></li>
  <li><a href="https://leimao.github.io/blog/Quantum-Mean-Variance/">Expected Value and Variance from the Perspective of Quantum Theory</a></li>
</ul>

      <hr>
      
    </div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/Heisenberg-Uncertainty-Principle/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23840342</guid>
            <pubDate>Wed, 15 Jul 2020 01:52:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[$45k ARR in 10 months: Optimizations as a company of one]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23840321">thread link</a>) | @jnfr
<br/>
July 14, 2020 | https://lunchbag.ca/company-of-one | <a href="https://web.archive.org/web/*/https://lunchbag.ca/company-of-one">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
		<p><span>
				Written on <time datetime="2020-05-18 16:00:00 +0000 UTC">May 18, 2020</time>
			</span>
		</p>
		

<p>Hello! 👋 My name is Jen and I’m the founder, engineer, designer and customer support at <a href="https://lunchmoney.app/">Lunch Money</a>, a personal finance and budgeting web app.</p>

<p>In short, I am a company of one. I answer the customer support emails and I code and deploy new features. I also manage the <a href="https://developers.lunchmoney.app/" target="_blank">API docs</a> and <a href="https://support.lunchmoney.app/" target="_blank">knowledge base</a>, poke around the logs when there are issues, write the <a href="https://lunchmoney.app/sample_newsletter" target="_blank">bi-monthly newsletters</a> and I designed the logo!</p>

<p>As the company scales, so too must all aspects of my work which I break down into 4 parts: customer support, engineering, product and marketing.</p>

<p><strong>Finding opportunities for process optimization is honestly one of the more fun parts of running a business</strong>. I greatly attribute these to how I’ve been able to stay both solo &amp; sane up until now, currently with 600+ users and $45,000 ARR. In this post, I’m excited to share some of my most successful strategies along with anecdotes from my experience working on Lunch Money.</p>



<p>In the last 14 days, here’s what I got done across all departments:</p>

<ul>
<li><strong>Product:</strong> Launched an internal beta testers program and two sets of new features to test</li>
<li><strong>Engineering:</strong> Wrapped up a 2-week long refactor of some core components on the client-side</li>
<li><strong>Engineering:</strong> Launched a major feature: advanced transaction filters</li>
<li><strong>Engineering:</strong> Closed 13 tickets related to feature improvements and bug fixes</li>
<li><strong>Marketing:</strong> Sent out a newsletter outlining the latest new features</li>
<li><strong>Marketing:</strong> This blog post</li>
<li><strong>Marketing:</strong> Added new pages to the marketing site (<a href="https://lunchmoney.app/features/rules">Rules</a> and <a href="https://lunchmoney.app/features/collaboration">Collaboration</a>) and updated the icons in <a href="https://lunchmoney.app/features">Features</a></li>
<li><strong>Support:</strong> Received 239 inbound support tickets and sent out 358 emails</li>
</ul>

<p>What makes all this work bearable for me is the fact that there is so much variety (which, of course, is the spice of life!). I love being able to switch between tasks to keep the job interesting and my mind refreshed while still being productive overall.</p>

<p><em>Case in point: I just finished a major refactor and pushed out 2 major features to beta, so writing this blog post right now feels like a vacation for my brain.</em></p>

<p>To state the obvious, I enjoy being hyper-efficient (without burning myself out, of course). Even though I am a single person, I can still automate, optimize and parallelize processes.</p>



<h2 id="implement-safeguards">Implement safeguards</h2>

<p><i>Ah, the blissful beginnings of Lunch Money when I’d push code directly to production several times a day.</i></p>

<p>At 500+ users now, those days are long gone and I’ve since needed to adopt the more boring but responsible approach of implementing safeguards to prevent shipping faulty code.</p>

<p>For one, <b>I’ve been thoroughly reviewing my own code before every change</b>. Every major feature, improvement and bug fix lives in a feature branch that I still, by habit from the corporate days, prepend with <code>jen/</code>. After verifying everything works great locally, I make sure to take a break first, whether that’s working on a completely unrelated task, going for a meal or going to bed. The point of this is to ensure that I’m code reviewing with a clear head.</p>

<p>While adhering to these standards of code reviewing myself may add extra time to my overall process, it potentially saves hours of bug-fixing, answering related support tickets and self-loathing (I’m half-kidding here) down the line if I accidentally ship bad code.</p>

<center><blockquote><p lang="en" dir="ltr">New phase of Lunch Money– no more pushing major features straight to production 🤯😂 <a href="https://t.co/RYsz7BnU3L">https://t.co/RYsz7BnU3L</a></p>— Jen (@lunchbag) <a href="https://twitter.com/lunchbag/status/1256987437600927744?ref_src=twsrc%5Etfw">May 3, 2020</a></blockquote> </center>

<p><b>I also recently implemented an internal beta-testing program open to Lunch Money subscribers.</b> With more users accessing my app on a regular basis, the stakes are higher to ship a version that’s as bug-free as possible.</p>

<p>As an engineering team of one, it’s nearly impossible to always get it right the first time, despite having tests (what if I missed an edge case?) or testing locally extensively (how I think my users will use a feature is not always so).</p>

<p>The beta-testing program has provided some additional benefits. It’s nice to have a cohort of users with whom I can have a more candid conversation about Lunch Money and it’s also a great way to show users that their feedback is valued!</p>

<h2 id="automate-later-than-you-need-to">Automate later than you need to</h2>

<p>While automating tasks can save a lot of time in the long-term, it doesn’t always make sense to automate right off the bat.</p>

<p><img src="https://imgs.xkcd.com/comics/is_it_worth_the_time.png"><span>Obligatory XKCD comic (<a href="https://xkcd.com/1205/" target="_blank">link</a>)</span></p>

<p>Automating too late is not a bad thing. I’ll have done the manual work enough times to understand how to eventually automate the task and what edge cases to look out for. I equate it to doing a job yourself before hiring someone– it’s always better to grok the requirements first to some degree so you can understand how to best utilize who you’ve brought on (and appreciate them more!).</p>

<p>I manually triggered the emails for bi-monthly account summaries for months because I wasn’t confident the sending cadence was reasonable. After observing open rates and collecting user feedback, these are now automated to go out on the 5th &amp; 25th of every month.</p>

<p>Something that I’m glad I didn’t spend the time to automate at all was the referral program. If an existing user refers a new user and the new user subscribes to a plan, then both users will receive credit for 1 month.</p>

<p>In the end, the referral program only brought on 11 extra users. It was not a pain at all to manually process rewards for those who did. If I had spent time conjuring up all the edge cases and automating this process, it would not have been worth the time investment.</p>

<h2 id="keep-low-hanging-fruits-in-the-back-pocket">Keep low-hanging fruits in the back pocket</h2>

<p>In my task management system, I use a tag (🍏) to denote which tasks are low-hanging fruits. For the uninitiated, low-hanging fruits are quick tasks that are easy to knock out, such as one-liners or 5-minute fixes.</p>

<p><img src="https://media.giphy.com/media/YP1Jb0JNc7kqFDbdjm/giphy.gif"></p>

<p>I find that keeping these around and tackling them on days when you feel generally unmotivated can really help raise spirits. Still being able to get something completed and shipped is a great way to get out of a slump.</p>



<h2 id="timing-marketing-pushes">Timing marketing pushes</h2>

<p>At Lunch Money, a big part of the business is using the services of Plaid for bank syncing. Plaid charges on a monthly basis which means that if a user signs up on April 30, connects a bank account immediately and doesn’t end up subscribing at the end of their 14-day trial, they will charge me for this user in both April &amp; May’s invoices.</p>

<p>This realization coupled with my intense aversion to paying more than I need to has shaped a lot of practices at Lunch Money.</p>

<p>For one, the data retention policy used to be 30 days which means if your trial ends and you didn’t put in your billing information, your data will be deleted in 30 days. This certainly guarantees that I’ll be overpaying for churned users and is the reason why the data retention policy has since been revised to 5 days.</p>

<p>In total, a user who does not end up subscribing can spend up to 26 days in the Lunch Money system. This comprises of a 14-day trial, the potential for a 1 week trial extension and a 5 day grace period. Assuming enough users connect their bank accounts, the best way to minimize my costs for churned users is to ensure their lifetimes are within one calendar month.</p>

<p><img src="https://lunchbag.ca/uploads/calendar-1.png"></p>

<p>As a result, I always schedule marketing pushes such as blog posts and product launches in the first few days of the month. When I came to this realization, my next Plaid bill went down for the first time.</p>

<h2 id="merging-marketing-and-engineering-for-a-combo-win">Merging marketing and engineering for a combo win</h2>

<p>Taking this a step further, the perk of having a spike in new users is that their trial periods more-or-less overlap. Usually when a new user signs up, they will poke around the product and maybe send in a bug report, a feature request or another piece of feedback. If I reply and address their feedback by putting in a fix or shipping their requested feature within days, more often than not, they end up converting into a happy customer.</p>

<p>I’ve therefore identified the following cycle to maximize potential conversions from spikes in user signups:</p>

<p><img src="https://lunchbag.ca/uploads/gantt-2.png"></p>

<p>After a marketing push, let’s say a product launch, I will see an immediate increase in signups lasting about 3 days and then slowly trailing off.</p>

<p>Over the next few days, I’ll start hearing from these new users via support tickets. I prioritize responding to them and I get to work. Showing these users that I’m committed to improving Lunch Money based on their feedback is a great and honest sales tactic.</p>

<p>About 3 days before the initial wave of user trials ends, I wrap up my engineering sprint and send out a newsletter detailing the latest features and improvements. This re-enforces to new users that the product is under continuous development.</p>

<p>Finally, I have a drip campaign that automatically notifies users a few days before their trial expires and on the actual date of expiry. This period of time is when I typically see most users convert 🤞.</p>



<p>I used to think that if I were to hire someone, it would first be a customer support agent but I’ve since been moving away from that idea. Users are constantly surprised (in a good way!) when they realize the founder is responding to their bug reports or feature requests directly.</p>

<p><strong>Consistently providing great customer support is a long-term investment for Lunch Money</strong> as it is undoubtedly a great way to turn customers into champions. As I receive and respond to support tickets, I’m also able to identify and overhaul the common sources of trouble for users.</p>

<p>I’ve always believed that customer support would be the most important and the hardest part of the business to scale, especially if I have the goal of staying a company of one.</p>

<p>Corroborating data from <a href="https://emailmeter.com/">EmailMeter</a> and my database, it seems my changes are making a difference. Despite a growing user base, inbound support emails remain fairly steady!</p>

<p><img src="https://lunchbag.ca/uploads/screen-shot-2020-05-21-at-4-20-15-pm.png"><span>Handling support on my own should be sustainable at least for the foreseeable future!</span></p>

<h2 id="how-do-support-tickets-work-at-lunch-money">How do support tickets work at Lunch Money?</h2>

<p>A feedback button is located at the bottom right corner of every page. Clicking on it opens up a text area wherein users can submit feature requests, questions, bug …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lunchbag.ca/company-of-one">https://lunchbag.ca/company-of-one</a></em></p>]]>
            </description>
            <link>https://lunchbag.ca/company-of-one</link>
            <guid isPermaLink="false">hacker-news-small-sites-23840321</guid>
            <pubDate>Wed, 15 Jul 2020 01:48:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Intro to Logical Arguments for Programmers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23840254">thread link</a>) | @jasonswett
<br/>
July 14, 2020 | https://www.codewithjason.com/logical-arguments-programmers/ | <a href="https://web.archive.org/web/*/https://www.codewithjason.com/logical-arguments-programmers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<h2>What it means to be wrong and why it’s bad</h2>
<h3>Logical incorrectness</h3>
<p>It’s generally better to be right than to be wrong. Since there’s more than one way to be wrong, I want to be specific about the type of wrongness I want to address in this post before I move on.</p>
<p>The type of wrongness I’m interested in in this post is logical incorrectness, like two plus two equals five.</p>
<h3>The danger of being wrong</h3>
<p>Being right or wrong isn’t just an academic concern. In programming, being wrong often has concrete negative economic (and other) impacts. Developers who are often wrong will be much less efficient and burn up much more payroll cost and opportunity cost than developers who are wrong less often.</p>
<p>Being wrong is also not something that happens every great once in a while. Most humans are wrong about a whole bunch of stuff, a lot of the time, because that’s just human nature. Even really smart people are wrong about things a very nonzero amount of the time.</p>
<p>So I want to share some things we developers can do in order to be wrong less. But first let me share a concrete example of the kind of mistakenness I’m talking about.</p>
<h2>An example of being wrong</h2>
<h3>Bug: an appointment goes missing</h3>
<p>Let’s say I’m building some scheduling software. One of my users, Rachel, reports to me that yesterday she rescheduled someone’s appointment from July 1st at 10am to July 3rd at 10am. Today, Rachel looked at both the schedule for July 1st and July 3rd and the appointment isn’t present on either day. Apparently there’s a bug that removes appointments from the schedule when you try to reschedule them.</p>
<p>So I start to look at the code and see if I can find any evidence that this buggy behavior is present. Unfortunately, the code is very complicated, and my investigation takes a long time. My investigation lasts an entire day. By the end of the day I’ve made almost no progress toward fixing the bug.</p>
<h3>The bug was not the bug</h3>
<p>Unbeknownst to me, the thing I thought was the bug was not actually the bug. In fact, there was no bug. Between the time Rachel rescheduled the appointment and the time Rachel found the appointment missing, another user, Janice. deleted the appointment. There was in fact no bug at all. I was wrong. I wasted a whole day as a consequence of being wrong.</p>
<h2>How to be less wrong</h2>
<p>We developers can be wrong less of the time by studying <b>epistemology</b>. Epistemology is a branch of philosophy which deals with the acquisition of knowledge. Epistemology tells us how we can know, with certainty, what’s true and what isn’t.</p>
<p>More narrowly, we can study <b>logic</b>. Logic is a branch of philosophy that deals with a formal system of reasoning. One of the central ideas of logic is that of an <b>argument</b>. Arguments are the ideas we’ll be focusing on in this post.</p>
<h2>The definition of a logical argument</h2>
<p>An argument is a group of statements including one or more <b>premises</b> and one and only one <b>conclusion</b>. (I shamelessly stole this definition word-for-word from <a href="http://www.uky.edu/~rosdatte/phi120/lesson1a.htm">this web page</a>.)</p>
<p>Now let’s talk about what a premise is and what a conclusion is. As an aid I’ll share an example of a logical argument, henceforth just referred to as an “argument”.</p>
<h3>Argument example</h3>
<blockquote><p>
All fish live in water.<br>
All sharks are fish.<br>
Therefore, all sharks live in water.
</p></blockquote>
<p>This argument contains two premises. “All fish live in water” is a premise. “All sharks are fish” is also a premise.</p>
<p>This argument’s conclusion is of course “Therefore, all sharks live in water”. If it’s true that all fish live in water and it’s true that all sharks are fish, then it’s of course true that all sharks live in water.</p>
<h2>Validity and soundness</h2>
<p>Not all arguments are good ones. An argument can be <b>valid</b> or <b>invalid</b> and <b>sound</b> or <b>unsound</b>.</p>
<h3>Validity</h3>
<p>An argument is <b>valid</b> if the truth of the argument’s conclusion is logically connected to the argument’s premises. Our above fish/shark argument is a valid argument because, if the argument’s premises are true, its conclusion must necessarily be true. We could make the argument invalid by changing some things.</p>
<blockquote><p>
All fish live in water.<br>
All sharks are fish.<br>
Therefore, all sharks have fins.
</p></blockquote>
<p>This argument isn’t valid because its conclusion doesn’t logically flow from its premises. It happens to be true that all sharks have fins, but that fact isn’t true as a natural consequence of this argument’s premises, so the argument isn’t valid.</p>
<p>Note that validity doesn’t have anything to do with truth. An argument can be valid even if its premises aren’t true.</p>
<blockquote><p>
All turtles are invisible.<br>
Everyone has a turtle in their brain.<br>
Therefore, everyone has an invisible turtle in their brain.
</p></blockquote>
<p>The premises of the above argument aren’t true (at least as far as I know) but the argument is nonetheless valid.</p>
<h3>Soundness</h3>
<p>An argument is <b>sound</b> if the argument is valid and its premises are true. Our first argument (“all fish live in water, all sharks are fish, therefore all sharks live in water”) is sound because the argument is valid and its premises are true. <b>Sound arguments always have true conclusions.</b></p>
<p>Here’s another sound argument.</p>
<blockquote><p>
Every 20th century American president has been male.<br>
Richard Nixon was a 20th century American president.<br>
Richard Nixon was male.
</p></blockquote>
<p>Now comes the fun part, where we apply logical arguments to programming. </p>
<h2>Arguments in programming</h2>
<p>Read the following argument, keeping in mind the definitions of validity and soundness. See if you can tell if the argument is valid or invalid, sound or unsound. (If you don’t want a spoiler, don’t scroll past the argument until you’ve read the full argument.)</p>
<blockquote><p>
The site is unusually slow today.<br>
We performed a large deployment this morning.<br>
The deployment is the cause of the slowness.
</p></blockquote>
<p>This argument is <b>unsound</b>. Even if the premises are true, we can’t know based on the premises that the deployment was the cause of the slowness. How do we know it’s not a coincidence? For all we know, our site got featured on Hacker News and a big traffic spike is the cause of the slowness. Our argument is unsound because its conclusion isn’t necessarily true based on its premises. So, the reason that the argument is unsound is because even though its premises are true, its logic is invalid.</p>
<p>Here’s another example. Instead of just two premises, this argument has three.</p>
<blockquote><p>
Sometimes slowness is caused by code changes.<br>
Sometimes slowness is caused by traffic spikes.<br>
The site is unusually slow today.<br>
The cause of the slowness is either a code change or a traffic spike.
</p></blockquote>
<p>This argument is also unsound. There are more possible reasons for a site to be slow than just a code change or a traffic spike. For example, maybe our DevOps person killed half the servers in the middle of the night last night without our knowing it. So despite true premises, this argument, like the preceding one, is <b>invalid</b>.</p>
<p>Here’s another example.</p>
<blockquote><p>
The code in the most recent deployment introduced a bug.<br>
The only thing that went out in the most recent deployment was Josh’s code.<br>
Josh’s code caused the bug.
</p></blockquote>
<p>As long as this argument’s premises are true, this argument is <b>sound</b>. If we know for sure that the most recent deployment introduced a bug, and we know for sure that the only thing that went out in the most recent deployment was Josh’s code, then it does logically follow that Josh’s code caused the bug.</p>
<p>Here’s a final example. This one is a little more detailed than the previous ones.</p>
<blockquote><p>
At 10:32am, a duplicate $20 charge appeared in the system for patient #5225.<br>
Also at 10:32am, Jason carelessly performed a manual actual action on patient #5225, an action that was related to that patient’s $20 charge.<br>
Jason caused the duplicate charge.
</p></blockquote>
<p>This is another <b>unsound</b> argument. Even though it sounds likely that my action caused the duplicate charge, it’s not logically valid to make that inference based on the premises. The invalidity is perhaps not obvious, but can be made more apparent by asking the question: “Are there any possible circumstances under which Jason’s manual action would NOT have created the duplicate charge?” For example, it’s possible that the card could have accidentally been run twice, and the timing was a coincidence.</p>
<p>I have empirical proof of the invalidity of the above argument because this is a real-life example and, in fact, my action was not the cause of the duplicate charge. Part of what helped me determine this is the following sound argument.</p>
<blockquote><p>
It’s impossible to create a charge without having a patient’s credit card information.<br>
It would have been physically impossible for me to involve the patient’s credit card information when I performed my manual action because we don’t store credit card information in the system.<br>
My action couldn’t have created the duplicate charge.
</p></blockquote>
<p>The preceding sound argument (and remember, sound arguments always have true conclusions) led me to investigate more deeply. What I ultimately discovered was that the patient’s card did in fact get run twice and the timing was just a coincidence. Why wasn’t it obvious from the outset that the patient’s card was run twice? Because we use Authorize.net as a payment gateway, and apparently sometimes the Authorize.net API returns a failure response even when the charge was successfully incurred, so from the perspective of our application there was only one charge that got successfully created, even though in reality there were two.</p>
<h2>Good luck with your arguments</h2>
<p>Next time you’re confronted with a programming mystery, I invite you to frame your mystery in terms of arguments. Write down your premises, and make sure to write down only premises that are true, otherwise your argument will be unsound. Then try to come up with a conclusion and make sure that your conclusion necessarily follows from your premises so that your argument is valid. If your argument is valid and sound, your conclusion will necessarily be true.</p>
<p>If you’d like to have an argument with me on Twitter, you can find me <a href="https://twitter.com/JasonSwett">here</a>.</p>
					</div></div>]]>
            </description>
            <link>https://www.codewithjason.com/logical-arguments-programmers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23840254</guid>
            <pubDate>Wed, 15 Jul 2020 01:37:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SHA-256 in Excruciating Detail]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23839895">thread link</a>) | @lanecwagner
<br/>
July 14, 2020 | https://qvault.io/2020/07/08/how-sha-2-works-step-by-step-sha-256/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/07/08/how-sha-2-works-step-by-step-sha-256/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>SHA-2 (Secure Hash Algorithm 2), of which SHA-256 is a part, is one of the most popular <a href="https://qvault.io/2020/01/01/very-basic-intro-to-hash-functions-sha-256-md-5-etc/">hashing algorithms</a> out there. In this article, we are going to break down each step of the algorithm as simple as we can and work through a real-life example by hand.</p>



<p>SHA-2 is known for its security (it hasn’t <a aria-label="undefined (opens in a new tab)" href="https://shattered.io/" target="_blank" rel="noreferrer noopener">broken down like SHA-1</a>), and its speed. In cases where <a href="https://qvault.io/2019/12/30/very-basic-intro-to-key-derivation-functions-argon2-scrypt-etc/">keys are not being generated</a>, such as mining Bitcoin, a fast hash algorithm like SHA-2 often reigns supreme.</p>



<h2><span id="What_Is_a_Hash_Function">What Is a Hash Function?</span>
</h2>



<p>If you want to read more about hash functions in general, do so <a href="https://qvault.io/2020/01/01/very-basic-intro-to-hash-functions-sha-256-md-5-etc/">here</a>. That said, in order to move forward let’s recap three of the main purposes of a hash function:</p>



<ul>
<li>To scramble data deterministically</li>
<li>To accept input of any length and output a fixed-length result</li>
<li>To irreversibly manipulate data. The input can’t be derived from the output</li>
</ul>
<h2><span id="SHA-2_vs_SHA-256">SHA-2 vs SHA-256</span>
</h2>



<p>SHA-2 is an <em>algorithm</em>, a generalized idea of how to hash data. SHA-256 sets additional constants that define the SHA-2 algorithm’s behavior. One such constant is the output size. “256” and “512” refer to their respective output digest sizes in bits.</p>



<p>Let’s step through an example of SHA-256.</p>



<h2><span id="SHA-256_hello_world_Step_1_-_Pre-Processing">SHA-256 “hello world”; Step 1 – Pre-Processing</span>
</h2>



<ul><li>Convert “hello world” to binary:</li></ul>
<pre><code>01101000 01100101 01101100 01101100 01101111 00100000 01110111 01101111
01110010 01101100 01100100</code></pre>



<ul><li>Append a single 1:</li></ul>
<pre><code>01101000 01100101 01101100 01101100 01101111 00100000 01110111 01101111
01110010 01101100 01100100 1</code></pre>



<ul><li>Pad with 0’s until data is a multiple of 512, less 64 bits (448 bits in our case):</li></ul>
<pre><code>01101000 01100101 01101100 01101100 01101111 00100000 01110111 01101111
01110010 01101100 01100100 10000000 00000000 00000000 00000000 00000000
00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
</code></pre>



<ul><li>Append 64 bits to the end, where the 64 bits are a <a href="https://en.wikipedia.org/wiki/Endianness">big-endian</a> integer representing the length of the original input in binary. In our case, 88, or in binary, “1011000”.</li></ul>
<pre><code>01101000 01100101 01101100 01101100 01101111 00100000 01110111 01101111
01110010 01101100 01100100 10000000 00000000 00000000 00000000 00000000
00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
00000000 00000000 00000000 00000000 00000000 00000000 00000000 01011000</code></pre>



<p>Now we have our input, which will always be evenly divisible by 512.</p>



<h2><span id="Step_2_-_Initialize_Hash_Values_h">Step 2 – Initialize Hash Values (h)</span>
</h2>



<p>Now we create 8 hash values. These are hard-coded constants that represent the first 32 bits of the fractional parts of the square roots of the first 8 primes: 2, 3, 5, 7, 11, 13, 17, 19</p>



<pre><code>h0 := 0x6a09e667
h1 := 0xbb67ae85
h2 := 0x3c6ef372
h3 := 0xa54ff53a
h4 := 0x510e527f
h5 := 0x9b05688c
h6 := 0x1f83d9ab
h7 := 0x5be0cd19</code></pre>



<h2><span id="Step_3_-_Initialize_Round_Constants_k">Step 3 – Initialize Round Constants (k)</span>
</h2>



<p>Similar to step 2, we are creating some constants (<em>Learn more about constants and when to use them <a href="https://qvault.io/2019/10/14/constants-in-go-vs-javascript-and-when-to-use-them/" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">here</a></em>). This time, there are 64 of them. Each value (0-63)  is the first 32 bits of the fractional parts of the cube roots of the first 64 primes (2 – 311).</p>



<pre><code>0x428a2f98 0x71374491 0xb5c0fbcf 0xe9b5dba5 0x3956c25b 0x59f111f1 0x923f82a4 0xab1c5ed5
0xd807aa98 0x12835b01 0x243185be 0x550c7dc3 0x72be5d74 0x80deb1fe 0x9bdc06a7 0xc19bf174
0xe49b69c1 0xefbe4786 0x0fc19dc6 0x240ca1cc 0x2de92c6f 0x4a7484aa 0x5cb0a9dc 0x76f988da
0x983e5152 0xa831c66d 0xb00327c8 0xbf597fc7 0xc6e00bf3 0xd5a79147 0x06ca6351 0x14292967
0x27b70a85 0x2e1b2138 0x4d2c6dfc 0x53380d13 0x650a7354 0x766a0abb 0x81c2c92e 0x92722c85
0xa2bfe8a1 0xa81a664b 0xc24b8b70 0xc76c51a3 0xd192e819 0xd6990624 0xf40e3585 0x106aa070
0x19a4c116 0x1e376c08 0x2748774c 0x34b0bcb5 0x391c0cb3 0x4ed8aa4a 0x5b9cca4f 0x682e6ff3
0x748f82ee 0x78a5636f 0x84c87814 0x8cc70208 0x90befffa 0xa4506ceb 0xbef9a3f7 0xc67178f2</code></pre>



<h2><span id="Step_4_-_Chunk_Loop">Step 4 – Chunk Loop</span>
</h2>



<p>The following steps will happen for each 512-bit “chunk” of data from our input. In our case, because <em>“hello world”</em> is so short, we only have one chunk. At each iteration of the loop, we will be mutating the hash values h0-h7, which will be the final output.</p>



<h2><span id="Step_5_-_Create_Message_Schedule_w">Step 5 – Create Message Schedule (w)</span>
</h2>



<ul><li>Copy the input data from step 1 into a new array where each entry is a 32-bit word:</li></ul>
<pre><code>01101000011001010110110001101100 01101111001000000111011101101111
01110010011011000110010010000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000001011000</code></pre>



<ul><li>Add 48 more words initialized to zero, such that we have an array <strong>w[0…63]</strong>
</li></ul>
<pre><code>01101000011001010110110001101100 01101111001000000111011101101111
01110010011011000110010010000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000001011000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
...
...
00000000000000000000000000000000 00000000000000000000000000000000</code></pre>



<ul>
<li>Modify the zero-ed indexes at the end of the array using the following algorithm:</li>
<li>For <strong>i</strong> from w[16…63]:<ul>
<li>s0 = (w[i-15] rightrotate 7) xor (w[i-15] rightrotate 18) xor (w[i-15] rightshift 3)</li>
<li>s1 = (w[i- 2] rightrotate 17) xor (w[i- 2] rightrotate 19) xor (w[i- 2] rightshift 10)</li>
<li>w[i] = w[i-16] + s0 + w[i-7] + s1</li>
</ul>
</li>
</ul>
<p>Let’s do w[16] so we can see how it works:</p>



<pre><code>w[1] rightrotate 7:
  01101111001000000111011101101111 -&gt; 11011110110111100100000011101110
w[1] rightrotate 18:
  01101111001000000111011101101111 -&gt; 00011101110110111101101111001000
w[1] rightshift 3:
  01101111001000000111011101101111 -&gt; 00001101111001000000111011101101

s0 = 11011110110111100100000011101110 XOR 00011101110110111101101111001000 XOR 00001101111001000000111011101101

s0 = 11001110111000011001010111001011

w[14] rightrotate 17:
  00000000000000000000000000000000 -&gt; 00000000000000000000000000000000
w[14] rightrotate19:
  00000000000000000000000000000000 -&gt; 00000000000000000000000000000000
w[14] rightshift 10:
  00000000000000000000000000000000 -&gt; 00000000000000000000000000000000

s1 = 00000000000000000000000000000000 XOR 00000000000000000000000000000000 XOR 00000000000000000000000000000000

s1 = 00000000000000000000000000000000

w[16] = w[0] + s0 + w[9] + s1

w[16] = 01101000011001010110110001101100 + 11001110111000011001010111001011 + 00000000000000000000000000000000 + 00000000000000000000000000000000

// addition is calculated modulo 2^32

w[16] = 00110111010001110000001000110111


</code></pre>



<p>This leaves us with 64 words in our message schedule (w):</p>



<pre><code>01101000011001010110110001101100 01101111001000000111011101101111
01110010011011000110010010000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000001011000
00110111010001110000001000110111 10000110110100001100000000110001
11010011101111010001000100001011 01111000001111110100011110000010
00101010100100000111110011101101 01001011001011110111110011001001
00110001111000011001010001011101 10001001001101100100100101100100
01111111011110100000011011011010 11000001011110011010100100111010
10111011111010001111011001010101 00001100000110101110001111100110
10110000111111100000110101111101 01011111011011100101010110010011
00000000100010011001101101010010 00000111111100011100101010010100
00111011010111111110010111010110 01101000011001010110001011100110
11001000010011100000101010011110 00000110101011111001101100100101
10010010111011110110010011010111 01100011111110010101111001011010
11100011000101100110011111010111 10000100001110111101111000010110
11101110111011001010100001011011 10100000010011111111001000100001
11111001000110001010110110111000 00010100101010001001001000011001
00010000100001000101001100011101 01100000100100111110000011001101
10000011000000110101111111101001 11010101101011100111100100111000
00111001001111110000010110101101 11111011010010110001101111101111
11101011011101011111111100101001 01101010001101101001010100110100
00100010111111001001110011011000 10101001011101000000110100101011
01100000110011110011100010000101 11000100101011001001100000111010
00010001010000101111110110101101 10110000101100000001110111011001
10011000111100001100001101101111 01110010000101111011100000011110 10100010110101000110011110011010 00000001000011111001100101111011
11111100000101110100111100001010 11000010110000101110101100010110</code></pre>



<h2><span id="Step_6_-_Compression">Step 6 – Compression</span>
</h2>



<ul>
<li>Initialize variables <strong>a, b, c, d, e, f, g, h</strong> and set them equal to the current hash values respectively. <strong>h0, h1, h2, h3, h4, h5, h6, h7</strong>
</li>
<li>Run the compression loop. The compression …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://qvault.io/2020/07/08/how-sha-2-works-step-by-step-sha-256/">https://qvault.io/2020/07/08/how-sha-2-works-step-by-step-sha-256/</a></em></p>]]>
            </description>
            <link>https://qvault.io/2020/07/08/how-sha-2-works-step-by-step-sha-256/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23839895</guid>
            <pubDate>Wed, 15 Jul 2020 00:38:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Polygon Crest – open-source 3D polygonal editor]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23839480">thread link</a>) | @app4soft
<br/>
July 14, 2020 | http://ysflight.in.coocan.jp/polygoncrest/e.html | <a href="https://web.archive.org/web/*/http://ysflight.in.coocan.jp/polygoncrest/e.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div bordercolor="#111111" width="100%" id="AutoNumber1">
        <tbody><tr>
          <td>
          
          <h2>
            What's Polygon Crest?</h2>
          <p>
            This program is a polygon editor. Maybe more commonly called a 
			polygon modeler. You can call whichever comfortable for you. The 
			main purpose is to build aircraft and ground visual models for YS 
			FLIGHT SIMULATOR, but you can use it for making general polygonal 
			models. If you make a correct solid model, you can export the data 
			for 3D printing, for example. I wanted to make it easy to create 
			aircraft models, so this program can quickly make a popular 
			airfoils, and extrude along the wing leading and trailing edges. It 
			also has basic boolean operations and rounding functions as well.
            </p>
		  <p>
            <a href="http://ysflight.in.coocan.jp/polygoncrest/scrnshot/cessna172-english.png">
			<img height="170" src="http://ysflight.in.coocan.jp/polygoncrest/scrnshot/cessna172-english_small.png" width="320" xthumbnail-orig-image="scrnshot/cessna172-english.png"></a></p>
		  <h2>
            How to use?</h2>
		  <p>
            Usage can be found in the following URLs.</p>
		  <p>
            <a href="http://polycre.help.en.ysflight.com/">
			<strong>http://polycre.help.en.ysflight.com/</strong></a> (English)</p>
		  <p>
            <a href="http://polycre.help.jp.ysflight.com/">
			<strong>http://polycre.help.jp.ysflight.com/</strong></a> (Japanese)</p>
		  <h2>
            Donations are welcome</h2>
		  <p>
            Polygon Crest is a fre and open-source program.&nbsp; Therefore, you can 
			use it for free of charge.&nbsp; However, I appreciate if you donate some 
			money for supporting the development.&nbsp; For making donation, please 
			send some money via PayPal using the following button.
            </p>
		  
<!--webbot bot="HTMLMarkup" endspan i-checksum="11026" -->
		  <p>
            I will use the donated money for upgrading my developing 
			environment, buying books for learning new programming techniques, 
			maintaining and adding contents in YSFLIGHT.COM.&nbsp; Thank you for your 
			support!
            </p>
		  <h2>
            Download</h2>
		  <p>
            <strong>Version 20150329</strong></p>
		  <p>
            <strong>
			<a href="http://download.cnet.com/Polygon-Crest/3000-6677_4-76169623.html">[For MacOSX 
			&amp; Linux]</a> (Linux binary is also included in the Mac OSX 
			package.)</strong></p>
		  <p>
            <strong>
			<a href="http://download.cnet.com/Polygon-Crest-for-Windows/3000-6677_4-76170331.html">[For Windows]</a></strong></p>
		  <h2>
            Updates</h2>
          <p>
          <strong>2016/02/21</strong></p>
		  <ul>
			  <li>Digitally signed Mac OSX binary.&nbsp; You should be able to 
			  run the program without warning.&nbsp; If your setting only allows 
			  App Store applications, you will need to change the security 
			  setting to allow App Store &amp; digitally signed by known developers 
			  (or something like that.)</li>
			  <li>Linux binary is bundled in the Mac OSX package.&nbsp; You can 
			  run LinuxInstaller.py in the zip file, which will create an icon 
			  on the desktop.&nbsp; If it works well, I'm going to do the same 
			  for YSFLIGHT.</li>
			  <li>Now YSFLIGHT shares the same data structure of dynamic model 
			  (.DNM) with PolygonCrest.&nbsp; From the next version on, if you 
			  can open the .DNM file with PolygonCrest, it should (is supposed 
			  to) appear the same in YSFLIGHT.</li>
			  <li>Imprinting:&nbsp; You can imprinting a polygon or a constraint 
			  edge to a nearby polygons by selecting a polygon and then select 
			  Edit-&gt;Projection-&gt;Imprinting.</li>
			  <li>Sewing:&nbsp; You can select two vertices and select 
			  Edit-&gt;Local Operations-&gt;Sew between two vertices.&nbsp; Vertices 
			  will be created between the selected vertices and polygons along 
			  the path will be split.</li>
		  </ul>
		  <p>
          <strong>2015/05/23</strong></p>
		  <ul>
			  <li>Polygon Crest for Linux: You can really use the system 
			  clipboard.&nbsp; (Now it's closed inside Polygon Crest program)</li>
			  <li>Input/Output of Wavefront .OBJ format files.</li>
			  <li>Add "Recently Used Files"</li>
			  <li>Color Palette dialog.</li>
			  <li>Polygon Crest for Windows: Erased a false error message on 
			  start up.&nbsp; (It only appeared when I build in a release 
			  configuration, and I didn't notice :-P)</li>
		  </ul>
		  <p>
          <strong>2014/07/19</strong></p>
		  <p>
          First release!&nbsp; Version 20140716.&nbsp; I wanted to add more 
		  features.&nbsp; But, if I wait until I finish all the features that I 
		  want to add, it's going to take infinity.&nbsp; I decided to make it 
		  open now.&nbsp; I'll keep developing and newer versions will be 
		  available.</p>
          
          </td>
        </tr>
        </tbody></div></div>]]>
            </description>
            <link>http://ysflight.in.coocan.jp/polygoncrest/e.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23839480</guid>
            <pubDate>Tue, 14 Jul 2020 23:42:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tragic RAF Pilot's Grave Discovered in Albania]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23839399">thread link</a>) | @Hansig_jw
<br/>
July 14, 2020 | https://www.mydiplomaticlife.com/tragic-raf-pilots-secret-grave-discovered-in-albania/ | <a href="https://web.archive.org/web/*/https://www.mydiplomaticlife.com/tragic-raf-pilots-secret-grave-discovered-in-albania/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p>This story is about a small. isolated Albanian village which kept a deadly secret for almost 50 years during the oppressive, communist regime of Enver Hoxha. The secret they kept lay unmarked and untended in the local village graveyard. So, what was this secret that if it had leaked out could have had potentially deadly consequences for the village?</p>
<p>The story developed thus:</p>
<p><span>During the long and hot Albanian summer of 1998, the embassy was contacted by the Mayor of Saranda. </span></p>
<p><span>Saranda was a medium-sized coastal town and popular holiday resort in the south of the country located near the Greek border and lying directly opposite the island of Corfu. The Mayor said that he had been contacted by a resident of the village of Drovian which was located in the mountains just above Saranda. </span></p>
<p><span>Apparently, this villager, his family and the whole village had been living with a secret for decades.</span></p>
<p><span>It transpired that during the second World War when the Italians invaded Albania, an RAF fighter plane, during the course of a dogfight, had collided with an Italian machine and the badly burned British pilot had baled out. </span></p>
<p><span>He landed just outside the village and despite the tender ministrations of the villagers, had tragically died from his wounds. The villagers then buried him in an unmarked grave in the church grounds as they did not want the Italians to find him.</span></p>
<p><span>After the war, with the advent of the brutal and repressive Hoxha communist regime and his denial of the extensive British military aid given to him in terms not only of material but also of British lives in defeating his axis occupiers and liberating his country, the villagers did not dare inform anyone outside the village about the hidden British grave in case they would be taken for collaborators. </span></p>
<p><span>So there he lay for over fifty years, this unknown British airman. It is remarkable that the villagers were able to keep this secret for so long under such trying circumstances. Informers and spies were everywhere during the life of this brutal regime. One word of this leaking out to the authorities, would have meant instant, draconian and possibly deadly punishment for the whole village.</span></p>
<p><span>The Ambassador asked me if I would like to take this on as a project as I was ex-Royal Air Force to which I readily agreed. Therefore, my first port of call was to the Commonwealth War Graves Commission (CWGC) in Maidenhead in the UK. </span></p>
<p><span>This organisation is responsible for the upkeep and maintenance of all British war graves worldwide. They were more than happy to assist and I passed on to them all the details of the case that we had managed to glean so far from the Mayor’s office in Saranda.&nbsp;</span></p>
<p><span>CWGC researched the case and eventually got back to me. They confirmed to me that a British aircraft had indeed been lost over that particular area of Albania. What they proposed was that the grave should remain for the time being in situ in the village and not moved to the small CWGC cemetery in Tirana until a full investigation could be carried out.</span></p>
<p><span>Some weeks later, CWGC contacted me again and confirmed that they had identified from RAF after action reports and accounts from surviving members of the pilot’s RAF Squadron that he was Flying Officer Harold Sykes aged 22 and sadly recently married. </span></p>
<p><span>They proposed sending out an inscribed headstone to Tirana and asked if we could transport it down to Drovian and erect it. I reassured them that this was possible and that we would carry out the task and n</span><span>ot long afterwards, an inscribed headstone from CWGC arrived crated through the diplomatic bag.<img src="https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/sykes_2.jpg?resize=300%2C197&amp;ssl=1" alt="" width="300" height="197" srcset="https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/sykes_2.jpg?resize=300%2C197&amp;ssl=1 300w, https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/sykes_2.jpg?w=550&amp;ssl=1 550w" sizes="(max-width: 300px) 100vw, 300px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/sykes_2.jpg?resize=300%2C197&amp;ssl=1 300w, https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/sykes_2.jpg?w=550&amp;ssl=1 550w" data-lazy-src="https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/sykes_2.jpg?resize=300%2C197&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "></span></p>
<p>I then contacted the Mayor in Saranda and told him we would be on our way the next morning and that we proposed to overnight in Saranda before driving up to Drovian the next day to erect the headstone.</p>
<p><span>So, on a cold, clear, crisp winter morning, my driver, a locally employed Embassy interpreter and I set off by road for the 300 Km trip down south. We took the coast road, which was deemed safer and eventually reached Saranda late that afternoon. We met the Mayor and explained to him what we proposed to do. After spending the night in a small hotel, we set off the next morning for the village in the mountains accompanied by the Mayor.</span></p>
<p><span>Unfortunately, because of the steep and unstable mountainous terrain, even our 4 wheel drive Landcruisers were not able to negotiate the tracks and terrain that would lead us to Drovian. Thankfully, the Mayor somehow managed to contact a local corn supplier who agreed to hire out six of his mules to us and off we set with our cargo, not a comfortable experience!</span></p>
<p><span>Finally, after about 2 jolting hours in the saddle, we reached the village where, to our delight, the villagers, who had been forewarned of our arrival by the Mayor’s office had very kindly laid on a delicious, communal lunch.</span></p>
<p><span> After lunch we all took a stroll around the small village. The villagers obviously took great care of their fields and their homes. Everything was clean and neat and the fields were well tended though the vista was blighted by the usual blot on the landscape of the ever-present rash of pillboxes, even here high up in the mountains (Hoxha, who was obsessed with the fear of foreign invasion, had constructed over a million such concrete pillboxes throughout the country). </span></p>
<p><span>When asked why they just did not demolish these pillboxes, the villagers said they were in fact very useful for storing their tobacco crop, which I suppose was a very pragmatic and sensible use of these concrete bubbles.</span></p>
<p><span>They then led us to the courtyard of a small building which was called the Church of the 12 Apostles where the burial site was located. It transpired that Harold was not alone. Next to his grave was the grave of an unknown Greek soldier who the villagers had also buried after finding his remains in the hills towards the end of the war. They told us that they had also informed the Greek embassy in Tirana about the soldier and their embassy was still in the process of trying to identify him.</span></p>
<p><span>We offloaded the headstone from the vehicle and uncrated it. With the help of a couple of villagers, we cemented it firmly at the head of the grave. It felt appropriate I say a prayer over the grave which I did. It was touching to note that the villagers who had gathered at the site also paid their respects in a dignified manner with a couple of the women laying colourful, wild flowers on the grave. I then took some photographs.</span><span>&nbsp;<img src="https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/thumbnail-1.jpg?resize=214%2C300&amp;ssl=1" alt="Fg Off Sykesn headstone" width="214" height="300" srcset="https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/thumbnail-1.jpg?resize=214%2C300&amp;ssl=1 214w, https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/thumbnail-1.jpg?w=400&amp;ssl=1 400w" sizes="(max-width: 214px) 100vw, 214px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/thumbnail-1.jpg?resize=214%2C300&amp;ssl=1 214w, https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/thumbnail-1.jpg?w=400&amp;ssl=1 400w" data-lazy-src="https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/thumbnail-1.jpg?resize=214%2C300&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "></span></p>
<p><span>Before taking our leave of the village, one of the elders produced a burlap sack which he asked me to take back with me. Inside were fragments of old uniform and bits of parachute and harness, which had belonged to the airman.</span></p>
<p><span>Taking our leave of the villagers, we remounted our mules for the trip back down the mountains to our vehicles. I said goodbye to the Mayor and thanked him for all his assistance and then set off on the 300 Km return journey to Tirana.</span></p>
<p><span>The next day, back in the Embassy, I wrote up my report for the CWGC and also despatched the various items given to me in Drovian. I learnt later that my full report, photographs and the returned items had been given to surviving members of Harold’s family.&nbsp;</span></p>
<p><span>To this day (as far as I know) Harold still lies in that mountainside village. At the time CWGC agreed that he could remain there and whether at some future date he was moved to the small CWGC cemetery in Tirana, I have no knowledge.</span></p>
<p>This was the first of my two discoveries and resolutions involving missing RAF airmen. My second was a few years later in North Korea where, working closely with the north Korean military, we found the remains of an RAF pilot who had gone missing during the Korean war. At the time he had been seconded to the United States Air Force when his jet had been shot down near Pyongyang.</p>
<p>I will be doing a full post on this in the weeks to come.</p>
<p><em><strong>*Image of Flying Officer Sykes RAF courtesy of Averil Dorego*</strong></em></p>
  
              </article></div>]]>
            </description>
            <link>https://www.mydiplomaticlife.com/tragic-raf-pilots-secret-grave-discovered-in-albania/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23839399</guid>
            <pubDate>Tue, 14 Jul 2020 23:31:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Networked games: Playing in the past or future]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23839390">thread link</a>) | @zdw
<br/>
July 14, 2020 | https://www.evanjones.ca/network-game-simulation.html | <a href="https://web.archive.org/web/*/https://www.evanjones.ca/network-game-simulation.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<h3>[ 2020-July-14 10:46 ]</h3>
<p>A few years ago I was fascinated by how network games worked after reading a <a href="https://gafferongames.com/post/introduction_to_networked_physics/">series of articles about Networked Physics that includes some great demo movies</a>. I didn't really understand it. How can the game be playable, when the client and server are separated by approximately 100 ms of network delay? I decided to create a small demo of a networked game, to try and figure it out. However, like most projects I start, I abandoned it after spending a few hours on it. I rediscovered it a couple months ago, and got it to a reasonabl y "finished" state. <a href="https://www.evanjones.ca/network-game-simulation-demo.html">The demo shows the client and server state of a "game"   and lets you adjust the simulated latency</a>. This gave me a huge appreciation for clever tricks used to create fast-paced games that are playable over the Internet. In particular, I find it amazing that the clients are playing the game either in the past or the future, but it still works to create an interactive experience.</p>


<h2>Local latency</h2>
<p>One important lesson is that even a local game has latency. Let's ignore things like <a href="https://danluu.com/keyboard-latency/">keyboard latency</a> or <a href="https://pcmonitors.info/articles/factors-affecting-pc-monitor-responsiveness/">display latency</a>, each of which can easily add ~50 ms of delay. Let's just consider the game loop, which involves reading input, simulating the world, then drawing the world. This means after a button press arrives, the game will not respond until the next frame. Many displays can show a maximum of 60 frames per second (FPS), which translate to an average of 8 ms of delay (uniformly distributed between 0-16 ms). That initial frame also might just register "player is moving forward", but won't actually move the player forward until the next frame, so that means it can be up to 33 ms between when you pressed the button and see a change. Many games run slower than that, which scales up the delay. The conclusion is that even that "fast" reaction you get in a local game is not instantaneous, and may actually have approximately 100 ms delay between inputs and seeing an update.</p>

<h2>No prediction: playing in the past</h2>
<p>The simplest network game model, and the one that is implemented in my demo, is to have the client send commands to the server, and have the server send state back to the client, which displays them. With this implementation, when you press a button to take an action, like moving forward, it takes one entire network round trip before you see the movement. The initial versions of Doom and Quake used this approach, because they were designed for local networks and not the Internet. Quake was released just when home Internet was becoming widespread, and people did play over the Internet anyway, which only worked if the network round trip time was low. With my demo, this feels playable up to about 50 ms of one-way latency.</p>

<p>The most interesting part to me is this means players are playing the game in the past, when compared to the server state. I've drawn the diagram below in an attempt to describe what I mean. Both the client and server start the game at the same instant, <code>t=0</code>. At this time, the player presses the "move forward" button, so the client sends this message to the server. It takes one time unit/frame to get to the server, so at t=1, the server receives and processes the button press. At t=2 the server simulates the player moving forward one unit, and sends the state to the client. Finally, at t=3 the client receives the updated position displays it. This means the client's display was updated at t=3, instead of t=1 in the "local" version. This is delayed by one network round trip time (2 units in this example). At any instant, the client is one time unit behind the server, which is what I mean that the game is being played in the past.</p>

<p><img alt="no prediction diagram" height="361" src="https://www.evanjones.ca/network-game-simulation-past.svg" width="703"></p>

<p>When I experiment with moving and firing in my simulation, I think I can notice even a small amount of latency. However, I feel like I can adapt to it and the game is playable up to about 50 ms. Above that point, it starts to feel "impossibly" slow and really unpleasant. This means this simple simulation will only work for physically "close" players. From my home connection in New York City to Google Cloud's data centers as measured by <a href="http://gcpping.com/">gcpping.com</a>, I can only play games hosted on the eastern half of North America (Virgina, South Carolina, and Montreal).</p>

<h2>Prediction: playing in the future</h2>
<p>To hide the effects of latency, modern games predict the effect of their actions. As a result, clients are now in the future, rather than in the past. Let's reconsider our example, where a game starts and a player immediately starts moving forward, shown below. In the first instant, the client processes the move forward command, so it sends it to the server. In the next instant, the client predicts moving forward one step, and the server receives the message. In the second instant (t=2), the client has predicted moving forward another step. The server simulates the movement and sends the "official" state. In the next instant (t=3), the client receives the confirmation that the user did move forward. The tricky part is the client needs to decide if this agrees with its simulation. If it does not, then it needs to "rewind" its simulation, and replay its local actions again.</p>

<p><img alt="with prediction diagram" height="358" src="https://www.evanjones.ca/network-game-simulation-future.svg" width="700"></p>

<p>With client-side prediction, the time between an input and a display update is the as a local game. However, the client is ahead of the server's "real" state by one network delay, which is what I mean that it is playing in the future.</p>

<h2>Further reading</h2>
<p>I am not an expert on this subject, since I have never worked in games. If you want to learn more, you should read about how real games make this work.</p>

<ul>
<li><a href="https://github.com/evanj/netgamesim">netgamesim source code</a>: The code for my demo simulator.</li>
<li><a href="https://gafferongames.com/post/introduction_to_networked_physics/">Networked Physics</a>: The original series of articles that got me interested. See the <a href="https://gafferongames.com/categories/networked-physics/">series index</a> for more details.</li>
<li><a href="https://www.gabrielgambetta.com/client-server-game-architecture.html">Fast-Paced Multiplayer</a>: Another series describing how this works.</li>
<li><a href="https://fabiensanglard.net/quake3/network.php">Quake 3 Networking</a>: A description of how Quake 3 worked from reviewing the source code. It is instructive to compare this to how <a href="https://fabiensanglard.net/quakeSource/quakeSourceNetWork.php">the original QuakeWorld worked</a>, since it added client-side prediction to Quake.</li>
<li><a href="https://developer.valvesoftware.com/wiki/Latency_Compensating_Methods_in_Client/Server_In-game_Protocol_Design_and_Optimization">Latency Compensating Methods in Client/Server Games</a>: Notably this article describes how Half Life makes "instant hit" weapons work with client-side prediction, and how this is a game design choice since there are some fundamental necessary trade-offs.</li>
</ul>

</div></div>]]>
            </description>
            <link>https://www.evanjones.ca/network-game-simulation.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23839390</guid>
            <pubDate>Tue, 14 Jul 2020 23:30:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Remote Work Office Setup]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23839328">thread link</a>) | @rchaudhary
<br/>
July 14, 2020 | https://anjuansimmons.com/blog/my-remote-work-office-setup | <a href="https://web.archive.org/web/*/https://anjuansimmons.com/blog/my-remote-work-office-setup">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <dl>

<dt><a href=""><img src="https://anjuansimmons.com/images/remote-office-header.jpg" alt="My remote office setup helps me do my best work no matter where the other members of my team are located."></a></dt>

<dd>My remote office setup helps me do my best work no matter where the other members of my team are located.</dd>
</dl>

<p>I’ve worked remotely on and off for several years, and I’ve been lucky to work for a fully remote company over the past nine months. It’s glorious, and I don’t think I can ever be convinced to physically work in a corporate office ever again.</p>

<p>I’m in Zoom meetings for work several hours each day, and I also do a fair amount of speaking at virtual conferences. That means I appear on other people’s screens quite often, and I regularly get asked about my remote office setup. The feedback I’ve generally received is that my audio and video are notable for their clarity and crispness. This high quality is due to the investments I’ve made into building out my home office, and I’m going to share what I think makes my configuration so great. Since so many people are still trying to figure out how to work from home, my hope is that this post is a guide for the things that will make working remotely a great experience.</p>

<p>I should add that I’ve worked for a few companies over the years that provided a stipend for kitting out my remote office. So, I’m fully aware of how much financial privilege that’s been provided to me. However, I hope this article gives everyone at least an idea of the types of gear that can use to upgrade your remote experience, and individual budgets can be adjusted accordingly.</p>

<h2 id="the-location-of-my-office-in-my-home">The Location of My Office in My Home</h2>

<dl>

<dt><a href=""><img src="https://anjuansimmons.com/images/mclaran-first-floor.gif" alt="My remote office is in the room marked 'Study' on this floor plan."></a></dt>

<dd>My remote office is in the room marked 'Study' on this floor plan.</dd>
</dl>

<p>My wife and I purchased our current home in 2014, and it came with a nice office (called “Study” in the floor plan above) on the first floor of the northwest corner of the house. Two things to note about the image above is that my house faces north and the actual build of our house is a mirror image of the floor plan you see. So, the north side of my house is at the bottom of the image, and you take a right turn from the main entrance to enter my office.</p>

<p>The builder’s floor plan called for the West Wall of the study to just be a regular wall with no windows. However, my wife thought that would result in a room that was too dark so she had the bright idea of adding three windows. I can tell you that she was absolutely right, and I’m so glad we went with her idea. You’ll see those three windows later in this post.</p>

<h2 id="outside-the-office">Outside the Office</h2>

<dl>

<dt><a href=""><img src="https://anjuansimmons.com/images/office-from-the-outside.jpg" alt="This is the view of my home office from the outside."></a></dt>

<dd>This is the view of my home office from the outside.</dd>
</dl>

<p>The first thing to understand about my home office is that it’s a totally separate room from the rest of the house. This is key because I have a door that I can close which provides a barrier to keep out noise from the rest of the house. Also, I can simply close the door to signify to my family that I’m working and should not be disturbed.</p>

<p>One key part of my remote office setup that you can’t see from a photo is the <a href="https://www.att.com/internet/fiber/">fiber service from AT&amp;T</a> that provides internet connectivity to my entire home. Since my home has several <a href="https://store.google.com/us/product/nest_cam">Nest security cameras</a> that constantly use data, and we use several services that require internet access, I made the decision a long time ago to purchase a fast connection.</p>










<h2 id="the-door-from-inside-the-office">The Door from Inside the Office</h2>

<dl>

<dt><a href=""><img src="https://anjuansimmons.com/images/office-door.jpg" alt="The door as viewed from inside my office."></a></dt>

<dd>The door as viewed from inside my office.</dd>
</dl>

<table>
  <thead>
    <tr>
      <th>Letter</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Ⓐ</td>
      <td><a href="https://amzn.to/2WzrZtL">Kenney Beckett 5/8” Standard Decorative Curtain Rod, 48-86”, Pewter</a></td>
    </tr>
    <tr>
      <td>Ⓑ</td>
      <td>Curtain Rod fasteners</td>
    </tr>
    <tr>
      <td>Ⓒ</td>
      <td><a href="https://amzn.to/2SQjeul">NICETOWN Bedroom Blackout Curtains Panels - (52 inches by 108 Inch, Grey, Set of 2) Triple Weave Energy Saving Thermal Insulated Solid Grommet Blackout Draperies</a></td>
    </tr>
    <tr>
      <td>Ⓓ</td>
      <td>Door that closes</td>
    </tr>
    <tr>
      <td>Ⓔ</td>
      <td><a href="https://amzn.to/2WFve2F">Suptikes Door Draft Stopper Under Door Seal</a></td>
    </tr>
  </tbody>
</table>

<p><br>
In addition to having a door that could be closed, I wanted to sound proof my office as much as possible. My office is near the front door and not too far from the dining room and living room. So, at any given moment during the work day, one or more members of my family could be just outside the office or watching TV in the living room. I found complicated (and expensive) ways to sound proof the door, but I went with an economical and effective solution.</p>

<p>I purchased a rod and curtains to provide another layer of sound proofing than just the doors. The doors are quite high so I had to order really tall curtains. I also installed seals on the bottom of the door to help keep out sound from the rest of the house. While this setup doesn’t block all external sound from entering the office, it does provide a much quieter environment in which to work.</p>

<h2 id="east-wall">East Wall</h2>

<dl>

<dt><a href=""><img src="https://anjuansimmons.com/images/remote-office-east-wall-area.jpg" alt="The area in front of the east wall is where I spend most of my time in the office. It's here where I take my calls and also do my work."></a></dt>

<dd>The area in front of the east wall is where I spend most of my time in the office. It's here where I take my calls and also do my work.</dd>
</dl>

<table>
  <thead>
    <tr>
      <th>Letter</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Ⓐ</td>
      <td>Wife’s Wedding Portrait (not for sale)</td>
    </tr>
    <tr>
      <td>Ⓑ</td>
      <td><a href="https://amzn.to/35Gx87o">Large Size World Map with Black Floater Frame</a></td>
    </tr>
    <tr>
      <td>Ⓒ</td>
      <td><a href="https://amzn.to/3cgV3wD">Amazon Basics Mid-Back Desk Office Chair with Arm rests (Mesh Back)</a></td>
    </tr>
    <tr>
      <td>Ⓓ</td>
      <td><a href="https://amzn.to/3bgfMiW">Anti-fatigue Comfort Floor Mat</a></td>
    </tr>
  </tbody>
</table>

<p><br>
This part of my office has a lot of the things that make it easier to get through my work day. I spend the vast majority of my work day standing, but I also wanted the option to sit for the brief times when sitting in a chair made a task easier. I initially looked for those fancy standing desks that could raise or lower at the touch of a button. However, I had a budget to use to build out my home office, and that would have taken a lot of space in the budget that could be used for other things. So, I decided to go with a far more economical approach. I purchased two coffee tables from Walmart that I put on top of my existing desk, and I set up my primary laptop and monitors on top of those tables. That’s the set of equipment I use when standing. I can also sit down in the chair and use my secondary laptop and monitor on the lower desk.</p>

<p>The map on the wall is a backdrop for framing myself in Zoom calls, and the picture of my wife in her wedding dress is just a lovely reminder of how happy I was when we got married. The boomerang on top of the picture is a gift from a co-worker who went to Australia several years ago.</p>

<p>For comfort, I purchased a reasonably priced office chair and an anti-fatigue mat that spans the part of the floor that’s right in front of my desk. Again, since I stand most of the day, I get a lot more use out of the mat than the chair.</p>

<p>The circular desk beneath my wife’s picture is a place to put random items that I don’t want to put on the upper or lower desks.</p>

<h3 id="upper-desk">Upper Desk</h3>

<dl>

<dt><a href=""><img src="https://anjuansimmons.com/images/remote-work-upper-desk.jpg" alt="The upper desk is designed for use while standing."></a></dt>

<dd>The upper desk is designed for use while standing.</dd>
</dl>

<table>
  <thead>
    <tr>
      <th>Letter</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Ⓐ</td>
      <td><a href="https://amzn.to/2WHtk1J">Inkeltech Ring Light (18 inch, 60 W), Adjustable 3000-6000 K Color Temparature</a></td>
    </tr>
    <tr>
      <td>Ⓑ</td>
      <td><a href="https://amzn.to/3du1ZH8">Dell Computer Ultrashrp 24.-Inch LED Monitor</a></td>
    </tr>
    <tr>
      <td>Ⓒ</td>
      <td><a href="https://amzn.to/2WeZtOV">Logitech Brio Ultra HD Webcam</a></td>
    </tr>
    <tr>
      <td>Ⓓ</td>
      <td>MacBook Pro (Retina, 15-inch, Mid 2015)</td>
    </tr>
    <tr>
      <td>Ⓔ</td>
      <td><a href="https://amzn.to/2YSuYA2">HP 25-Inch LED Monitor</a></td>
    </tr>
    <tr>
      <td>Ⓕ</td>
      <td>Bugdroid (Android Mascot)</td>
    </tr>
    <tr>
      <td>Ⓖ</td>
      <td>Google Home Mini</td>
    </tr>
    <tr>
      <td>Ⓗ</td>
      <td>Frederick “Freddie” von Chimpenheimer IV (MailChimp Mascot)</td>
    </tr>
    <tr>
      <td>Ⓘ</td>
      <td><a href="https://amzn.to/3bf7rvX">Corsair HS70 Pro Wireless Gaming Headset</a></td>
    </tr>
    <tr>
      <td>Ⓙ</td>
      <td>iPad</td>
    </tr>
    <tr>
      <td>Ⓚ</td>
      <td><a href="https://amzn.to/2yEtbUH">Yeti Blue Microphone (Blackout Edition)</a></td>
    </tr>
    <tr>
      <td>Ⓛ</td>
      <td><a href="https://amzn.to/2LeAa9I">Avantree Universal Wooden &amp; Aluminum Headphone Stand Hanger</a></td>
    </tr>
    <tr>
      <td>Ⓜ</td>
      <td><a href="https://amzn.to/2AeOwVn">Tablet Stand</a></td>
    </tr>
    <tr>
      <td>Ⓝ</td>
      <td><a href="https://amzn.to/3bg8con">Macally Ultra Slim USB Wired Computer Keyboard</a></td>
    </tr>
  </tbody>
</table>

<p><br>
The upper desk is my command center. I use my MacBook Pro as a hub that drives most of the other equipment on my desk. The two monitors provide enough surface area for me to feel productive. I typically use the left monitor for personal productivity items like my task list, the MacBook screen in the middle is where I put the things I’m currently working on, and the right monitor is usually reserved for communications like email, Slack, Jira, etc. The MacBook Pro is hard wired via Ethernet cable to make maximum use of the fiber internet connection.</p>

<p>By the way, I used an old pair of speakers to elevate the Dell and HP monitors. I’ve found that having all three monitors at eye level does wonders for my neck since I don’t have to look down at them while working. This also puts the webcam at a perfect position for video calls since it allows me to naturally look like I’m making eye contact with the attendees.</p>

<p>The equipment that contributes the most to the clear sound and crisp picture on my video calls are the ring light, Logitech Brio webcam, Yeti microphone (which is positioned right in front of my mouth but just out of view from the webcam), and Corsair headset. They provide great lighting as well as strong audio and video signals for the people on the videoconference with me. While the MacBook has a built-in webcam, microphone, and speakers, it can’t match the experience of using separate dedicated devices.</p>

<p>The iPad is nice for quickly pulling up things like my personal calendar, viewing my Nest cameras if I hear something outside of the office, or checking personal email.</p>

<p>I also have little “flair” items like the Android and MailChimp mascots. I’m heavily in the Android ecosystem, and I once gave a talk at the MailChimp office in Atlanta so these are just nice personal items.</p>

<p>The white mat on top of the desk is there to protect it from damage, spills, etc.</p>

<h3 id="lower-desk">Lower Desk</h3>

<dl>

<dt><a href=""><img src="https://anjuansimmons.com/images/remote-office-lower-desk.jpg" alt="The lower desk is designed for use while sitting."></a></dt>

<dd>The lower desk is designed for use while sitting.</dd>
</dl>

<table>
  <thead>
    <tr>
      <th>Letter</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Ⓐ</td>
      <td><a href="https://amzn.to/2zqp4LO">Asus 23.6” Monitor</a></td>
    </tr>
    <tr>
      <td>Ⓑ</td>
      <td><a href="https://amzn.to/3fxbMOp">Xerox DocuMate 3220 Duplex Document Scanner with Flatbed</a></td>
    </tr>
    <tr>
      <td>Ⓒ</td>
      <td>MacBook Pro</td>
    </tr>
    <tr>
      <td>Ⓓ</td>
      <td><a href="https://amzn.to/2Act9Uv">Brother HL-2270DW Compact Laser Printer</a></td>
    </tr>
    <tr>
      <td>Ⓔ</td>
      <td><a href="https://amzn.to/2YL1Z1d">Anker USB C Hub Adapter, 7-in-1 USB C Adapter</a></td>
    </tr>
    <tr>
      <td>Ⓕ</td>
      <td><a href="https://amzn.to/3ccjP0W">Multifunctional Office Desk Pad, 35.4” x 17”</a></td>
    </tr>
    <tr>
      <td>Ⓖ</td>
      <td><a href="https://amzn.to/3bcNzJX">VASAGLE Industrial Shoe Bench</a></td>
    </tr>
  </tbody>
</table>

<p><br>
I rarely use the lower desk since I stand for most of the day. However, it provides a secondary MacBook as well as an external monitor. I also have a scanner for the odd times I need to scan a picture or document and a laser printer. Like the upper desk, I also have a mat to make it easier to clean the top surface. I try to avoid eating in my office, but, when I do, I usually do it on the lower desk. So, the mat is a great way to protect the desk from spills and stains.</p>

<p>You can see the bench behind the desk. I purchased it to store the various plugs I needed to power my equipment and also serve as a stand for the ring light.</p>

<h3 id="behind-the-desk">Behind the Desk</h3>

<dl>

<dt><a href=""><img src="https://anjuansimmons.com/images/remote-office-behind-desk.jpg" alt="A view of what the back of the desk looks like. I know, I know . . ."></a></dt>

<dd>A view of what the back of the desk looks like. I know, I know . . .</dd>
</dl>

<table>
  <thead>
    <tr>
      <th>Letter</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Ⓐ</td>
      <td><a href="https://amzn.to/2Act57d">Anker 10 Port 60W Data Hub with 7 USB 3.0 Ports and 3 PowerIQ Charging Ports</a></td>
    </tr>
    <tr>
      <td>Ⓑ</td>
      <td>Exte…</td></tr></tbody></table></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://anjuansimmons.com/blog/my-remote-work-office-setup">https://anjuansimmons.com/blog/my-remote-work-office-setup</a></em></p>]]>
            </description>
            <link>https://anjuansimmons.com/blog/my-remote-work-office-setup</link>
            <guid isPermaLink="false">hacker-news-small-sites-23839328</guid>
            <pubDate>Tue, 14 Jul 2020 23:22:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ode to a Pager]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23838884">thread link</a>) | @calcifer
<br/>
July 14, 2020 | https://www.roguelazer.com/2019/06/ode-to-a-pager/ | <a href="https://web.archive.org/web/*/https://www.roguelazer.com/2019/06/ode-to-a-pager/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    <section id="main-content" role="main">
	<article>
		


		<div><p><img alt="pager" src="https://www.roguelazer.com/images/2019-06-13-pager.png"></p>
<p>I've been on-call for most of the last 11 years. I was on-call for the CS Department at Mudd<sup id="fnref:csdept"><a href="#fn:csdept">1</a></sup>. I was on-call at
Yelp, in a rotation that at times contained as few as three people. I was on-call at Uber in rotations ranging from one
to twenty people. And I've been on-call at EasyPost — initially in a rotation with one other person<sup id="fnref:epdouble"><a href="#fn:epdouble">2</a></sup>, and
currently with two other people. I have responded to tens of thousands of pages. I have been woken up in the middle of
the night hundreds<sup id="fnref:hundreds"><a href="#fn:hundreds">3</a></sup> of times. For the last seven or so years, I've worked at firms where on-call was a <acronym title="Bring Your Own Device">BYOD</acronym> kind of a deal — you bring your own cell phone, register it in
<a href="https://www.pagerduty.com/">PagerDuty</a>, and that's how you handle being on-call. This is my ode to the unfairly-hated pager, to
the practices of yore.</p>
<p>Let's look at the phone you have in your pocket right now<sup id="fnref:nodevice"><a href="#fn:nodevice">4</a></sup>:</p>
<ul>
<li>It runs iOS or Android<sup id="fnref:ios"><a href="#fn:ios">5</a></sup></li>
<li>It gets at most two days of battery life</li>
<li>It receives phone calls, of which at least 90% are robots saying things like <q>Hey buddy, this call is from the Department of Social Security</q></li>
<li>When it's not getting phone calls, it's constantly begging for your attention with notifications, most of which are some degree of spam</li>
</ul>
<p>Is <em>this</em> the device you want to have to have on and audible 24 hours a day, 365 days a year? Do you love the idea of
Apple's <em>Do Not Disturb</em> feature? Well, screw you because PagerDuty might need to reach you at any instant<sup id="fnref:dnd"><a href="#fn:dnd">6</a></sup>. Do you miss
going out into the woods for a hike? Too bad, Apple had to shave 0.7mm off the latest iPhone so now the antenna only
works if it has direct line of sight to the AT&amp;T worldwide headquarters in Dallas, TX. Want to quickly see what you're
getting paged about? I hope you like watching this brief animation as all your icons <em>swoosh</em> in from whatever armpit
of the universe they spend the off-time drinking in before you can actually do anything. Oh, you're using the native
PagerDuty app? Well, then, you've got to give it 10 seconds to load (despite the fact that the Apple A12 CPU in your
phone is faster than <strong>any computer CPU that existed anywhere on the planet 10 years ago</strong>) so that it can render some
emojis and prompt you to take an "On-Call Selfie"<sup id="fnref:selfie"><a href="#fn:selfie">7</a></sup>.</p>
<p>My ideal on-call device would look something like the following:</p>
<ul>
<li>Small and lightweight</li>
<li>Extremely long battery life (imagine… weeks without recharging)</li>
<li>Only capable of receiving emergency notifications from PagerDuty so I can leave it on, unmuted at all times</li>
<li>On a network with great distance and building penetration<sup id="fnref:5G"><a href="#fn:5G">8</a></sup></li>
<li>Maybe a one or two line black-and-white display just long enough to print out messages like <code>CRITICAL: web1sf - 4 packets transmitted, 0 received, 100% packet loss</code></li>
<li>Maybe two buttons so you could acknowledge or escalate incidents — but maybe not; I'm probably going to grab a laptop or bigger device to actually do the investigation<sup id="fnref:onedevice"><a href="#fn:onedevice">9</a></sup></li>
</ul>
<p>Do you know what I've just described, you bunch of ingrates? You damned dirty apes? A bona fide <strong>two-way pager</strong>. We had the technology! We had
built the perfect system! And we destroyed it! In our frivolous pursuit of only carrying one device, in our employers'
endless pursuit of simpler procurement, we got rid of a system where your employer provides a simple-to-use
single-function device to you, the employee, and replaced it with a system where you bring your own massively
over-complicated device, pay your own connectivity bills, and then miss pages at 3 in the morning because you got too
many goddamn Farmville notifications and your battery died.</p>
<p><img alt="You blew it up!" src="https://www.roguelazer.com/images/2019-06-13-pota.jpg"></p>
</div>
<hr>
<h2>Comments</h2>


	</article>
    </section>
</div></div>]]>
            </description>
            <link>https://www.roguelazer.com/2019/06/ode-to-a-pager/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23838884</guid>
            <pubDate>Tue, 14 Jul 2020 22:33:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cutting user churn for world's fastest-growing bike-share startup]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23838768">thread link</a>) | @dasickis
<br/>
July 14, 2020 | https://blog.locale.ai/how-indias-top-micro-mobility-player-used-locale-ai-to-reduce-user-churn-by-9/ | <a href="https://web.archive.org/web/*/https://blog.locale.ai/how-indias-top-micro-mobility-player-used-locale-ai-to-reduce-user-churn-by-9/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.locale.ai/content/images/size/w300/2020/07/SAE_IT--1-.jpg 300w,
                            https://blog.locale.ai/content/images/size/w600/2020/07/SAE_IT--1-.jpg 600w,
                            https://blog.locale.ai/content/images/size/w1000/2020/07/SAE_IT--1-.jpg 1000w,
                            https://blog.locale.ai/content/images/size/w2000/2020/07/SAE_IT--1-.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.locale.ai/content/images/size/w2000/2020/07/SAE_IT--1-.jpg" alt="How India's Top Scooter Sharing Player Used Locale.ai to Reduce User Churn by 9%">
            </figure>

            <section>
                <div>
                    <h2 id="an-introduction-to-our-partner-">An introduction to our Partner:</h2><p>Locale recently worked with a scooter sharing company that helps users commute using their fleet of scooters and bikes. With their rapid growth, large user base, and wonderful review, they have become the face of the growing micro-mobility ecosystem in South Asia. In 2019, they reached a significant milestone of 60,000 rides per day in Bengaluru, making it the fastest-growing bike-sharing start-up in the world. </p><p>Let us take you through how the team<strong><strong> </strong></strong>used <strong><strong><a href="https://locale.ai/">Locale.ai</a> </strong></strong>to open their stations in 7 cities as part of a new initiative by the company, decrease user churn by 9% and attain operational efficiency.</p><h2 id="the-business-problem-s-">The Business Problem(s)</h2><p>To make any important operational decision using geo-data, executives and decision makers have to rely on the data provided by the engineering teams. The case was very similar with our partner too. Their business model was a docked model- where any user (like you or me) could pick up a bike from a station and drop it off to another station.</p><p>As they were rapidly expanding in new cities (pre-COVID), the business problems were to:</p><ul><li>Decide where to open new stations to service demand</li><li>Close stations that were not performing well</li></ul><figure><img src="https://blog.locale.ai/content/images/2020/06/OperationalInsights-1.png"><figcaption>Locale.ai Console</figcaption></figure><p><br>The team wanted to ensure that they could capitalize on latent demand present in certain areas and expand their presence as well as minimise user churn by getting better insights into user behaviour and making a strategy accordingly.</p><p>Meanwhile, they were also trying to ensure that the time and resources in building dashboards could be used in some other avenue so that they could grow more rapidly. That’s where they were looking for a tool to convert location data into insights that can aid business decisions.</p><h3 id="before-we-move-on-a-bit-about-locale-ai">Before we move on, a bit about Locale.ai</h3><p>Locale is your one-stop destination for anything that involves analyzing hyperlocal operations. Imagine a tool built for city teams, ops teams &amp; logistics teams empowering them to get answers to their questions without depending on any engineering or analyst bandwidth.</p><p>We ensure that a large chunk of location data collected from your users or your vehicle sensors, that might otherwise remain unused, can now be used to create meaningful insights that help business teams make quick, data-driven decisions.</p><h2 id="the-how-s-why-s-of-the-solution">The How's &amp; Why's of the Solution</h2><p>The questions that the team asked to make the following decisions:</p><h3 id="expansion-new-stations">Expansion &amp; New Stations</h3><ul><li>Which areas are users downloading the app or searching for bikes?</li><li>Which areas are users churning out [searching but not booking]?</li><li>What is the distance of areas with high churn density with current stations?</li></ul><figure><img src="https://blog.locale.ai/content/images/2020/06/New-Static-Entity-overview.png"><figcaption>Locale.ai: Station Console</figcaption></figure><h3 id="shutting-down-stations"><strong><strong>Shutting Down Stations</strong></strong></h3><ul><li>Which stations are usually facing a high rate of cancellations?</li><li>Which stations have a very high idle time for the bikes?</li><li>Which stations are located near low demand areas?</li></ul><h3 id="making-insights-actionable">Making Insights Actionable</h3><p>At Locale, we consider ourselves successful only when we help companies take more precise and data-driven decisions using our product. So, we are always on the lookout for making these insights more actionable.</p><p>To read more on this, check this out:‌</p><figure><a href="https://blog.locale.ai/how-were-building-our-geospatial-analytics-product-using-first-principles-2/"><div><p>How we’re building our geospatial analytics product using first principles</p><p>Our philosophy on analytics at Locale!</p><p><img src="https://blog.locale.ai/favicon.png"><span>The Locale.ai Blog</span></p></div><p><img src="https://blog.locale.ai/content/images/2020/01/0.png"></p></a></figure><p>With our partner for instance, the central ops team could just right click and get the lat-long of the prospective location. They would send a couple of these lat-longs to their individual city teams who would find the most optimal location on ground, owing to the constraints.</p><p>With our commenting feature, they would coordinate internally on whether the station was opened in that location. If not, what were the possible reasons?</p><h3 id="the-impact">The Impact</h3><p>But, with all these decisions, what was the actual business impact and how did we move business metrics?</p><blockquote>Since the team started using our product, we saw a 9% reduction in user churn and improvement in user satisfaction.</blockquote><p>What this translates to is users who could previously not book a bike because of unavailability of bikes, or bikes being far off can now hop on a nearby bike and start their rides, which resulted in an improvement in user delight.</p><hr><h2 id="the-use-cases-of-locale-in-micro-mobility-">The Use Cases of Locale in Micro-Mobility:‌‌</h2><figure><img src="https://blog.locale.ai/content/images/2020/07/image-6.png"></figure><p>Analysts at McKinsey have evaluated the shared micro mobility industry to cross over <a href="https://www.mckinsey.com/industries/automotive-and-assembly/our-insights/micromobilitys-15000-mile-checkup#">$300 Billion by 2030</a>. But how can companies today reach there? What stops companies from realizing their potential? Inertia in expanding to newer locations? Problems with fleet management? Inaccuracy in gauging demand? A mixture of all these problems often cap the growth of a company.</p><p>Let us explore these problems one by one.</p><ol><li><strong><strong>Expansion</strong></strong>: Metrics such as user bookings, cancellations, distribution of sales and churn helps companies understand the spread of demand and supply across cities.</li><li><strong><strong>Station Performance:</strong></strong> Idle time of bikes, churn density around the stations and cancellations help companies decide where to set up new stations and which stations to shut down.</li><li><strong><strong>User Acquisition:</strong></strong> It is important to understand the behaviour of frequent users, which routes they travel and how they can increase user acquisition along those routes via targeted offline and route-based campaigns.</li><li><strong><strong>Fleet Management:</strong></strong> Issues such as vandalism, incomplete drop-offs, and breakdowns need to be tracked in real time and it helps companies to get immediate notifications for abnormal behaviour of KPIs.‌‌</li></ol><p>Often, companies search for tools that can be used to solve these problems for them, by using their location data. Luckily, that's exactly what we love to do!‌‌ If you work in the micro-mobility or ride-sharing industry, contact us to set up your Locale today. ‌‌</p><p><em><em><em><em>To know more, g<em><em><em><em>et in touch with me on </em></em></em></em></em></em></em></em><a href="https://www.linkedin.com/in/aditi-sinha-6b774ba9/" rel="noopener nofollow"><em><em><em><em><em><em><em><em>LinkedIn</em></em></em></em></em></em></em></em></a><strong><strong><strong><strong><strong><strong><strong><strong><em><em><em><em><em><em><em><em> </em></em></em></em></em></em></em></em></strong></strong></strong></strong></strong></strong></strong></strong><em><em><em><em><em><em><em><em>or </em></em></em></em></em></em></em></em><a href="https://twitter.com/aditi1002" rel="noopener nofollow"><em><em><em><em><em><em><em><em>Twitter</em></em></em></em></em></em></em></em></a><strong><strong><strong><strong><strong><strong><strong><strong><em><em><em><em><em><em><em><em>.</em></em></em></em></em></em></em></em></strong></strong></strong></strong></strong></strong></strong></strong></p><h3 id="read-similar-">Read Similar:</h3><figure><a href="https://blog.locale.ai/how-micromobility-used-locale-ai-to-reduce-user-churn/"><div><p>How India’s Top Micro-Mobility Player Used Locale.ai to Reduce User Churn by 9%</p><p>A step-by-step guide on how they used Locale.ai to set up their stations</p><p><img src="https://blog.locale.ai/favicon.png"><span>Aditi Sinha</span><span>The Locale.ai Blog</span></p></div><p><img src="https://blog.locale.ai/content/images/2020/07/SAE_IT.jpg"></p></a></figure><figure><a href="https://blog.locale.ai/mapping-kpis-with-location-data-for-ride-hailing-companies-using-locale-ai/"><div><p>Key Metrics for Ride-Hailing Companies using Location Data</p><p>Use location intelligence to create heatmaps for your critical business&nbsp;metrics with Locale</p><p><img src="https://blog.locale.ai/favicon.png"><span>Aditi Sinha</span><span>The Locale.ai Blog</span></p></div><p><img src="https://blog.locale.ai/content/images/2020/05/1_C0WaSy2Lt-sdpynFMI8j4A.png"></p></a></figure>
                </div>
            </section>





        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.locale.ai/how-indias-top-micro-mobility-player-used-locale-ai-to-reduce-user-churn-by-9/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23838768</guid>
            <pubDate>Tue, 14 Jul 2020 22:22:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spark vs. Snowflake: The Cloud Data Engineering (ETL) Debate]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23838750">thread link</a>) | @ibains
<br/>
July 14, 2020 | https://www.prophecy.io/blogs/spark-vs-snowflake-the-cloud-data-engineering-etl-debate | <a href="https://web.archive.org/web/*/https://www.prophecy.io/blogs/spark-vs-snowflake-the-cloud-data-engineering-etl-debate">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Data Integration is a critical engineering system in all Enterprises. Initially, it started with ad hoc <strong>scripts</strong>, which got replaced by <strong>Visual ETL</strong> tools such as Informatica, AbInitio, DataStage, and Talend. To cope with an explosion in data, consumer companies such as Google, Yahoo, and LinkedIn developed new <strong>data engineering</strong> systems based on commodity hardware. The usability of these systems was quite low, and the developer needed to be much more aware of the performance. <strong>Apache Spark</strong> has broken through from this clutter with thoughtful interfaces and product innovation, while <strong>Hadoop</strong> has effectively gotten <strong>disaggregated</strong> in the cloud and become a legacy technology.</p><p>Now, as Enterprises transition to the cloud, often they are developing expertise in the cloud ecosystem at the same time as trying to make decisions on the product and technology stack they are going to use. </p><p>In the rest of the blog, we'll take a look at the two primary processing paradigms for data integration, and their cloud equivalents.</p></div><h2>What is Data Integration (or ETL)</h2><p>Data Integration is your Data Factory. It reads data from various <strong>input sources</strong> such as Relational Databases, Flat Files, and Streaming. It then does various <strong>transformations</strong> on the data such as joining and de-duplicating data, standardizing formats, pivoting, and aggregating. Once the data is ready for analytics (such as in star schemas), it is <strong>stored or loaded</strong> into the target which is typically a Data Warehouse or a Data Lake.</p><p><img src="https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a891eba4f265f06523789_ETL%20%20graphic.png" srcset="https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a891eba4f265f06523789_ETL%2520%2520graphic-p-1080.png 1080w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a891eba4f265f06523789_ETL%2520%2520graphic-p-1600.png 1600w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a891eba4f265f06523789_ETL%20%20graphic.png 1755w" sizes="(max-width: 479px) 87vw, (max-width: 991px) 92vw, 780px" alt=""></p><h2>The Two On-Premises Execution Paradigms</h2><p>For most large Enterprises and companies rich in data, &nbsp;one server will be insufficient to execute the workloads, and thus, parallel processing is required. For this, there have historically been two primary methods:</p><ul role="list"><li><strong>ETL Execution Engine Processing</strong> - here the ETL tool comes with a distributed high performance execution engine. Most of the processing happens in this execution engine, and after the data is ready for analytics, it is loaded into a data warehouse. <strong>AbInitio</strong> is a good example and is the market leader in performance.</li><li><strong>Data Warehouse Pushdown Processing</strong> - here the ETL tool comes with a single server execution engine. Since it cannot do high volume processing, it provides pushdown processing that pushes computations down to the Data Warehouse and leverages the distributed processing engine there. In the field, we see <strong>Informatica</strong> commonly deployed with <strong>Teradata</strong> this way, though Informatica has a PowerCenter Grid product as well.</li></ul><p><img src="https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a89a09ea997b220276451_ETL%20execution%20graphic.png" srcset="https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a89a09ea997b220276451_ETL%2520execution%2520graphic-p-500.png 500w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a89a09ea997b220276451_ETL%2520execution%2520graphic-p-800.png 800w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a89a09ea997b220276451_ETL%2520execution%2520graphic-p-1080.png 1080w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a89a09ea997b220276451_ETL%2520execution%2520graphic-p-1600.png 1600w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a89a09ea997b220276451_ETL%20execution%20graphic.png 1773w" sizes="(max-width: 479px) 87vw, (max-width: 991px) 92vw, 780px" alt=""></p><p>Two on-premises ETL Execution paradigms</p><h3>Which Architecture is Better?</h3><div><p>One natural question to ask is - <strong>whether one of these paradigms is preferable?</strong> The Answer is Yes!</p><p>The case for <strong>data warehouse ETL execution</strong> is that it reduces one system - ETL execution and data warehouse execution will both happen in Teradata. Also, most data warehouses are typically high-quality products. However, it's an <strong>expensive</strong> approach and <strong>not the right architectural fit</strong>. Data warehouses have an architectural focus on <strong>low latency</strong> since there is often a human analyst waiting for her BI query. For this, they collect high-quality statistics for query planning and have sophisticated caching mechanisms. This is not a great fit for ETL workloads where throughput is the most important factor, and there is no reuse, making caches and statistics useless. Often we've found that 70% of Teradata capacity was dedicated to ETL in Enterprises, and that is what got offloaded to Apache Hive. </p><p>On the other hand, high-quality parallel processing products, exemplified by AbInitio are perhaps the <strong>best solution</strong> - both in inherent processing cost and performance. Most users of AbInitio loved the product, but the high licensing cost has removed any architectural cost advantages they had and made them available to a very few of the largest Enterprises. </p><p>‍<strong>Cloud, with usage based pricing,</strong> is a great equalizer, let's look at how cloud is changing this equation...</p></div><h2>Cloud Transition - the two ETL Architectures</h2><p>There are two primary approaches to choose for your ETL or Data Engineering</p><ul role="list"><li><strong>Data Warehouse ETL Approach: </strong>This is an <strong><em>as-is</em></strong> migration of the on-premises approach, done in a cloud context. An example here, one can use <strong>Snowflake</strong> as the data warehouse instead of <strong>Teradata</strong> on-premises. Then you can use any ETL tool such as <strong>Informatica</strong> or <strong>Matillion</strong> on top and it will push down queries to Snowflake that will do the heavy lifting. If you have small datasets, this works. As discussed above, for large datasets and complex transformations this architecture is far from ideal. This is far from the world of open-source code on Git &amp; CI/CD that data engineering offers - again locking you into proprietary formats, and archaic development processes.</li><li><strong>Data Engineering Approach:</strong> Data Engineering based on Spark for the execution layer, merges the best of the previous generation in high performance, with the best of large scale commodity processing from consumer companies - such as Hadoop. If you use Databricks, it adds transactions from Data Warehouses via delta lake providing the best product in the cloud by a large margin. A product such as <strong>Prophecy</strong> adds the remaining functionality - code and visual drag-and-drop editing that generates code on Git, Metadata with lineage, Scheduling, and CI/CD, providing a complete stack that will free you from proprietary formats.</li></ul><div><p>The following image is how the Cloud Data Engineering architecture looks. The data from on-premise operational systems lands inside the data lake, as does the data from streaming sources and other cloud services. <strong>Prophecy with Spark</strong> runs data engineering or ETL workflows, writing data into a data warehouse or data lake for consumption.</p><p>Reports, Machine Learning, and a majority of analytics can run directly from your Cloud Data Lake, saving you a lot of costs and making it the single system of record. For particular BI use cases (fast interactive queries), Data Marts can be created on Snowflake or another Cloud Data Warehouse such as Redshift, BigQuery, or Azure SQL.</p></div><p><img src="https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a8b159ea997f6132766c4_cloud_architecture.jpg" srcset="https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a8b159ea997f6132766c4_cloud_architecture-p-500.jpeg 500w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a8b159ea997f6132766c4_cloud_architecture-p-1080.jpeg 1080w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a8b159ea997f6132766c4_cloud_architecture-p-1600.jpeg 1600w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a8b159ea997f6132766c4_cloud_architecture-p-2000.jpeg 2000w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a8b159ea997f6132766c4_cloud_architecture.jpg 2423w" sizes="(max-width: 479px) 87vw, (max-width: 991px) 92vw, 780px" alt=""></p><p>Cloud Data Engineering Architecture</p><h2>How to Choose?</h2><p>If you're moving you ETL to Data Engineering, you're deciding what your architecture for the next decade or more.</p><p>We recommend moving to Apache Spark and a product such as Prophecy. Apart from exceeding the capabilities of the Snowflake based stack at a much cheaper price point, this prevents you from getting locked into proprietary formats. You will also be able to deliver new analytics faster by embracing Git and continuous integration and continuous deployment - that is equally accessible to the Spark coders as well as the Visual ETL developers who have a lot of domain knowledge.</p></div></div>]]>
            </description>
            <link>https://www.prophecy.io/blogs/spark-vs-snowflake-the-cloud-data-engineering-etl-debate</link>
            <guid isPermaLink="false">hacker-news-small-sites-23838750</guid>
            <pubDate>Tue, 14 Jul 2020 22:20:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vlink: Portable multi file format linker]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23838711">thread link</a>) | @doener
<br/>
July 14, 2020 | http://sun.hasenbraten.de/vlink/ | <a href="https://web.archive.org/web/*/http://sun.hasenbraten.de/vlink/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="100%">
  <tbody><tr>
    <td><table>
      <tbody><tr><td nowrap="nowrap">
        <a href="http://sun.hasenbraten.de/vlink/index.php?view=main">About vlink</a>
      </td></tr>
      <tr><td nowrap="nowrap">
        <a href="http://sun.hasenbraten.de/vlink/index.php?view=relsrc">Last release source</a>
      </td></tr>
      <tr><td nowrap="nowrap">
        <a href="http://sun.hasenbraten.de/vlink/index.php?view=source">Daily source snapshot</a>
      </td></tr>
      <tr><td nowrap="nowrap">
        <a href="http://sun.hasenbraten.de/vlink/index.php?view=tagged">Tagged source archives</a>
      </td></tr>
      <tr><td nowrap="nowrap">
        <a href="http://sun.hasenbraten.de/vlink/index.php?view=compile">Compilation notes</a>
      </td></tr>
      <tr><td nowrap="nowrap">
        <a href="http://sun.hasenbraten.de/vlink/index.php?view=binrel">Last release binaries</a>
      </td></tr>
      <tr><td nowrap="nowrap">
        <a href="http://sun.hasenbraten.de/vlink/index.php?view=bincur">Daily snapshot binaries</a>
      </td></tr>
      <tr><td nowrap="nowrap">
        <a href="http://sun.hasenbraten.de/vlink/release/vlink.pdf">vlink docs (pdf)</a>
      </td></tr>
      <tr><td nowrap="nowrap">
        <a href="http://www.compilers.de/vlink.html">Volker's vlink page</a>
      </td></tr>
      <tr><td nowrap="nowrap">
        <a href="http://sun.hasenbraten.de/vbcc/">vbcc/Amiga home page</a>
      </td></tr>
    </tbody></table></td>

    <td>
      <table>
  <tbody><tr><td>
    <p>vlink is a portable linker, written in ANSI-C, that can read
    and write a wide range of object- and executable file formats.
    It can be used to link a specific target format from several
    different input file formats, or for converting, stripping
    and manipulating files.</p>
    <p>The linker can be controlled by GNU-style linker scripts to
    generate absolute code, but it also runs very well with
    default rules to create relocatable executables, as required
    for AmigaOS or MorphOS.</p>
    <p>Of course there might be technical restrictions that object
    files of different architectures cannot be merged because of
    incompatible relocation types, differing endianess or
    symbol-names with and without leading underscores. But in
    theory everything is possible!</p>
  </td></tr>

  <tr><td>
    Currently the following object and executable file formats
    are supported by vlink:
    <ul>
      <li>ELF 32bit PowerPC big endian</li>
      <li>ELF 32bit PowerPC AmigaOS (special dynamic linking rules)</li>
      <li>ELF 32bit PowerPC MorphOS (relocatable executables)</li>
      <li>ELF 32bit PowerPC PowerUp (relocatable executables)</li>
      <li>ELF 32bit M68k big endian</li>
      <li>ELF 32bit Jaguar RISC big endian</li>
      <li>ELF 32bit x86 little endian</li>
      <li>ELF 32bit x86 AROS (relocatable executables)</li>
      <li>ELF 32bit ARM little endian</li>
      <li>ELF 64bit x86_64 little endian</li>
      <li>a.out Sun/010 (also Amiga/Atari 68000)</li>
      <li>a.out Sun/020 (also Amiga/Atari 68020+)</li>
      <li>a.out MiNT (embedded in Atari TOS format)</li>
      <li>a.out Jaguar (M68k with support for RISC relocations)</li>
      <li>a.out NetBSD/68k (4k and 8k pages)</li>
      <li>a.out NetBSD/386</li>
      <li>a.out PC/386</li>
      <li>a.out generic</li>
      <li>AmigaOS hunk format</li>
      <li>EHF, extended hunk format (WarpOS)</li>
      <li>Atari TOS format (writing only)</li>
      <li>Motorola S-Records (writing only)</li>
      <li>Intel-hex format (writing only)</li>
      <li>AMSDOS format (Amstrad/Schneider CPC)</li>
      <li>Commodore 8-bit PRG format</li>
      <li>Raw binaries (writing only)</li>
      <li>VOBJ, proprietary versatile object format (reading only)</li>
    </ul>
  </td></tr>

</tbody></table>


<div>
<b>07-Jul-2020: vlink 0.16e.</b><br><ul>
<li>Changing the address within an output section in a linker script didn't  work correctly when the destination memory region (load-address) differs  from the relocation memory region (execution-address).</li><li>Data commands in linker scripts didn't work when there was nothing  else in the output section.</li><li>Fixed a segfault when a linker script moves the address counter backwards  inside an output section.</li><li>Fixed uninitialized pointer when loading input files via a linker-script  INPUT command.</li><li>New linker-script command: RESERVE(n) to reserve n bytes of memory and  fill it with the current FILL value.</li><li>FILL-pattern should always be written in big-endian.</li><li>Replaced FILL command by FILL8 and FILL16.</li><li>New option -mall to merge everything into a single output section.</li><li>Weak symbols must only be resolved in executables.</li><li>(rawbin) Motorola S-Records: Fixed start address in S8 and S9 trailer.</li><li>(vobj) Fixed reference to a defined weak symbol in an object.</li><li>(elf) Fixed reference to a defined weak symbol in an object.</li></ul></div>
<div>
<b>18-Apr-2020: vlink 0.16d.</b><br><ul>
<li>New option -N for renaming input sections.</li><li>New option -vicelabels to generate a label-address mapping for the  debugger from the VICE emulator.</li><li>-M option for generating map files accepts an optional output file name.</li><li>Map files prints all symbols per section sorted by value. The values  are printed on the first column now, using the target address size for  formatting.</li><li>Multiple lines for the same section in a linker script are not allowed.</li><li>Try to avoid "segment is closed" errors in linker scripts which define  and use memory regions, and no PHDR definitions.</li><li>Fixed output of trailing zero-bytes in all hex-formats, like S-Records,  IHex, SHex1.</li><li>(ados/ehf) Always generate short-reloc hunks, when requested by -Rshort.  Relocs with offsets &gt; 0xffff will be written in a separate hunk.</li><li>(ados/ehf) HUNK_LIB parsing sometimes failed. Fixed.</li><li>(rawbin) Target cbmprg no longer automatically splits the output file,  when there are larger gaps between output sections.</li><li>(rawbin) Trailing S-record (S7, S8, S9) contains the entry address.</li></ul></div>
<div>
<b>10-Jun-2019: vlink 0.16c.</b><br><ul>
<li>New target file format XFile, for Sharp X68000 computers. At the moment  only executables may be created. No object file support.</li><li>(ados/ehf) Handle data-bss sections correctly, when linking/stripping  executable files.</li></ul></div>
<div>
<b>28-Dec-2018: vlink 0.16b.</b><br><ul>
<li>New option -mtype: merge all sections of the same type (code, data,  bss), ignoring name and attributes.</li><li>(ados/ehf) Fixed possible segfault when linking resident modules.</li><li>(ados/ehf) Allow linking/stripping executables again.</li></ul></div>
<div>
<b>14-Aug-2017: vlink 0.16a.</b><br><ul>
<li>New linker script commands: BYTE, SHORT, LONG, QUAD, SQUAD.</li><li>New option -k: keep original section order from the objects.</li><li>Fixed crash with -gc-all and unreferenced symbols.</li><li>Fixed crash with unresolved weak symbols.</li><li>(ados/ehf) _INIT/_EXIT functions with register arguments (prefixed by  '@' instead of '_' for SAS/C-compatibility) are also detected, and their  pointers inserted into the proper con-/destructor tables.</li><li>(elf) Provide __CTOR_LIST_END, __DTOR_LIST_END.</li></ul></div>
<div>
<b>16-May-2017: vlink 0.16.</b><br><ul>
<li>Fixed a potential crash when linking with empty object files, while  using a linker script.</li><li>(ados/ehf): Support blink/slink linker symbols _RESLEN, _RESBASE,  _NEWDATAL for generating resident (pure) programs.</li><li>(ados/ehf): Fixed SAS/C-compatibility linker symbol __BSSLEN. Now it  represents the number of long words instead of the number of bytes.  WARNING! Make sure to check your code, if you used __BSSLEN before!</li><li>(ados/ehf): AmigaOS LoadSeg() (up to V40) has a problem with allocating  data-bss sections, which have an initialized size of 0. Implemented a  workaround for this case.</li><li>(elf) Fixed crash in dynamic linking due to section-trimming.</li><li>(elf,aout) Malformatted library archive files are no longer fatal, but  will be ignored.</li><li>(rawseg) Do not write output sections marked with NOLOAD.</li></ul></div>    </td>
  </tr>
</tbody></div></div>]]>
            </description>
            <link>http://sun.hasenbraten.de/vlink/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23838711</guid>
            <pubDate>Tue, 14 Jul 2020 22:17:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tabletop game OFMOS is a model of the economy as a complex system (Print&Play)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23838632">thread link</a>) | @cmitreanu
<br/>
July 14, 2020 | https://www.ofmos.com/how-economies-work | <a href="https://web.archive.org/web/*/https://www.ofmos.com/how-economies-work">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="siteWrapper">
      
        
      

      


      <main id="page" role="main">
        
          <article data-page-sections="5ec7522d117f476816949b21" id="sections">
  
    <section data-section-id="5ec7522d117f476816949b24" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
  &quot;backgroundImage&quot; : {
    &quot;id&quot; : &quot;5edec539c19ff3057554ea0c&quot;,
    &quot;recordType&quot; : 2,
    &quot;addedOn&quot; : 1591595635274,
    &quot;updatedOn&quot; : 1591595639125,
    &quot;starred&quot; : false,
    &quot;passthrough&quot; : false,
    &quot;workflowState&quot; : 1,
    &quot;publishOn&quot; : 1591595635274,
    &quot;authorId&quot; : &quot;589a219a46c3c44baeacffc2&quot;,
    &quot;systemDataId&quot; : &quot;1591595635799-L7DEE5JNWGB0O1ENN5CZ&quot;,
    &quot;systemDataVariants&quot; : &quot;942x942,100w,300w,500w,750w&quot;,
    &quot;systemDataSourceType&quot; : &quot;PNG&quot;,
    &quot;filename&quot; : &quot;ofmos-web2020-image.069.png&quot;,
    &quot;mediaFocalPoint&quot; : {
      &quot;x&quot; : 0.5,
      &quot;y&quot; : 0.5,
      &quot;source&quot; : 3
    },
    &quot;colorData&quot; : {
      &quot;topLeftAverage&quot; : &quot;060303&quot;,
      &quot;topRightAverage&quot; : &quot;000000&quot;,
      &quot;bottomLeftAverage&quot; : &quot;442523&quot;,
      &quot;bottomRightAverage&quot; : &quot;000000&quot;,
      &quot;centerAverage&quot; : &quot;000000&quot;,
      &quot;suggestedBgColor&quot; : &quot;000000&quot;
    },
    &quot;urlId&quot; : &quot;1i5h5hszztrut8oatnfyysjisj92xp-9l3b9&quot;,
    &quot;title&quot; : &quot;&quot;,
    &quot;body&quot; : null,
    &quot;likeCount&quot; : 0,
    &quot;commentCount&quot; : 0,
    &quot;publicCommentCount&quot; : 0,
    &quot;commentState&quot; : 2,
    &quot;unsaved&quot; : false,
    &quot;author&quot; : {
      &quot;id&quot; : &quot;589a219a46c3c44baeacffc2&quot;,
      &quot;displayName&quot; : &quot;Cristian Mitreanu&quot;,
      &quot;firstName&quot; : &quot;Cristian&quot;,
      &quot;lastName&quot; : &quot;Mitreanu&quot;,
      &quot;websiteUrl&quot; : &quot;http://www.cristianmitreanu.com&quot;,
      &quot;bio&quot; : &quot;&quot;
    },
    &quot;assetUrl&quot; : &quot;https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1591595635799-L7DEE5JNWGB0O1ENN5CZ/ke17ZwdGBToddI8pDm48kCbb2eKItvfwa0CDzt1q4zpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIMUjQoZs1pTWwzYpiJME_msW7atwiXoSdPfAPxa2PB_Q/ofmos-web2020-image.069.png&quot;,
    &quot;contentType&quot; : &quot;image/png&quot;,
    &quot;items&quot; : [ ],
    &quot;pushedServices&quot; : { },
    &quot;pendingPushedServices&quot; : { },
    &quot;recordTypeLabel&quot; : &quot;image&quot;,
    &quot;originalSize&quot; : &quot;942x942&quot;
  },
  &quot;imageOverlayOpacity&quot; : 0.9,
  &quot;video&quot; : {
    &quot;playbackSpeed&quot; : 0.5,
    &quot;filter&quot; : 1,
    &quot;filterStrength&quot; : 0,
    &quot;zoom&quot; : 0
  },
  &quot;backgroundWidth&quot; : &quot;background-width--full-bleed&quot;,
  &quot;sectionHeight&quot; : &quot;section-height--small&quot;,
  &quot;customSectionHeight&quot; : 85,
  &quot;horizontalAlignment&quot; : &quot;horizontal-alignment--center&quot;,
  &quot;verticalAlignment&quot; : &quot;vertical-alignment--middle&quot;,
  &quot;contentWidth&quot; : &quot;content-width--medium&quot;,
  &quot;sectionTheme&quot; : &quot;dark&quot;,
  &quot;sectionAnimation&quot; : &quot;none&quot;,
  &quot;backgroundMode&quot; : &quot;image&quot;
}" data-animation="none">
  <div>
  
    
      
      <p><img alt="" data-src="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1591595635799-L7DEE5JNWGB0O1ENN5CZ/ke17ZwdGBToddI8pDm48kCbb2eKItvfwa0CDzt1q4zpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIMUjQoZs1pTWwzYpiJME_msW7atwiXoSdPfAPxa2PB_Q/ofmos-web2020-image.069.png" data-image="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1591595635799-L7DEE5JNWGB0O1ENN5CZ/ke17ZwdGBToddI8pDm48kCbb2eKItvfwa0CDzt1q4zpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIMUjQoZs1pTWwzYpiJME_msW7atwiXoSdPfAPxa2PB_Q/ofmos-web2020-image.069.png" data-image-dimensions="942x942" data-image-focal-point="0.5,0.5" data-load="false" src="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1591595635799-L7DEE5JNWGB0O1ENN5CZ/ke17ZwdGBToddI8pDm48kCbb2eKItvfwa0CDzt1q4zpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIMUjQoZs1pTWwzYpiJME_msW7atwiXoSdPfAPxa2PB_Q/ofmos-web2020-image.069.png"></p>
    
  
  </div>
  <div>
    <div>
      
      
      <div data-type="page-section" id="page-section-5ec7522d117f476816949b24"><div><div><div data-block-type="2" id="block-71348fc9d3ad337f8320"><p>View economies as dynamic systems of virtual business worlds.</p></div></div></div></div>
    </div>
  </div>
</section>

  
    <section data-section-id="5ec7522d117f476816949b28" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
  &quot;imageOverlayOpacity&quot; : 0.15,
  &quot;video&quot; : {
    &quot;playbackSpeed&quot; : 0.5,
    &quot;filter&quot; : 1,
    &quot;filterStrength&quot; : 0,
    &quot;zoom&quot; : 0
  },
  &quot;backgroundWidth&quot; : &quot;background-width--full-bleed&quot;,
  &quot;sectionHeight&quot; : &quot;section-height--small&quot;,
  &quot;customSectionHeight&quot; : 10,
  &quot;horizontalAlignment&quot; : &quot;horizontal-alignment--center&quot;,
  &quot;verticalAlignment&quot; : &quot;vertical-alignment--middle&quot;,
  &quot;contentWidth&quot; : &quot;content-width--medium&quot;,
  &quot;customContentWidth&quot; : 50,
  &quot;sectionTheme&quot; : &quot;light-bold&quot;,
  &quot;sectionAnimation&quot; : &quot;none&quot;,
  &quot;backgroundMode&quot; : &quot;image&quot;
}" data-animation="none">
  
  <div>
    <div>
      
      
      <div data-type="page-section" id="page-section-5ec7522d117f476816949b28"><div><div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1590121073526_16765"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1590796197967-NOCLPCNWYOBHB0EVPNBM/ke17ZwdGBToddI8pDm48kMq016PxczJ_Rm803414ovZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PITsNzIAhmHx-cX_WInkOSI1sRY40eJrXM7kn3usbhk0gKMshLAGzx4R3EDFOm1kBS/ofmos-web2020-image.062.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1590796197967-NOCLPCNWYOBHB0EVPNBM/ke17ZwdGBToddI8pDm48kMq016PxczJ_Rm803414ovZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PITsNzIAhmHx-cX_WInkOSI1sRY40eJrXM7kn3usbhk0gKMshLAGzx4R3EDFOm1kBS/ofmos-web2020-image.062.jpg" data-image-dimensions="792x444" data-image-focal-point="0.5,0.5" alt="ofmos-web2020-image.062.jpg" data-load="false" data-image-id="5ed19fa548814c0a32497957" data-type="image" src="https://www.ofmos.com/ofmos-web2020-image.062.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-11a57b2dc5848e350ea1"><div><h3>Big Three (Marx, Keynes, and Smith): To Intervene, or Not To Intervene</h3><p>The past two and a half centuries have seen only three dominant macroeconomic theories. In 1776, with his book “The Wealth of Nations” marking the beginning of modern economics, Adam Smith first articulates the idea of a hands-off approach to the economy. In simple terms, the view asserts that the “invisible hand” of the free markets will always create the best conditions for all those involved. A century later, in a rebuke to that perspective, Karl Marx’s 1867 book “Das Kapital” lays the foundation for the idea that only a planned and centralized economy can lead to the equitable distribution of the nation’s wealth. Finally, with his 1936 book “The General Theory of Employment, Interest and Money,” John Maynard Keynes introduces the notion that the best way to maintain a healthy economy if to intervene with policies when the economic activity slows down or heats up.</p></div></div></div></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1590786298234_16585"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1590791903991-0UVJR5M8GELYAF1P5XYO/ke17ZwdGBToddI8pDm48kI-ufTzuIyBgq5smTFSesZ8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcIC3HqRX9SuBN0e3zMQF24mUHHgQSMCms5WX5f0KPvnGV8OpWIHMEzVaGEnf67Zcc/joseph%252Bschumpeter.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1590791903991-0UVJR5M8GELYAF1P5XYO/ke17ZwdGBToddI8pDm48kI-ufTzuIyBgq5smTFSesZ8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcIC3HqRX9SuBN0e3zMQF24mUHHgQSMCms5WX5f0KPvnGV8OpWIHMEzVaGEnf67Zcc/joseph%252Bschumpeter.jpg" data-image-dimensions="1051x591" data-image-focal-point="0.5,0.5" alt="joseph%2Bschumpeter.jpg" data-load="false" data-image-id="5ed18edfb1bea64aa265f46a" data-type="image" src="https://www.ofmos.com/joseph%2Bschumpeter.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1590784412274_16238"><div><h3>Joseph Schumpeter: Creative Destruction</h3><p>“Capitalism, then, is by nature a form or method of economic change and not only never is but never can be stationary. And this evolutionary character of the capitalist process is not merely due to the fact that economic life goes on in a social and natural environment which changes[.] […] The fundamental impulse that sets and keeps the capitalist engine in motion comes from the new consumers’ goods, the new methods of production or transportation, the new markets, the new forms of industrial organization that capitalist enterprise creates. […]</p><p>The opening up of new markets, foreign or domestic, and the organizational development from the craft shop and factory to such concerns as U. S. Steel illustrate the same process of industrial mutation — if I may use that biological term — that incessantly revolutionizes the economic structure <em>from within</em>, incessantly destroying the old one, incessantly creating a new one.&nbsp;This process of Creative Destruction is the essential fact about capitalism.&nbsp;It is what capitalism consists in and what every capitalist concern has got to live in.”</p><p>— Excerpted from Joseph Schumpeter’s “Capitalism, Socialism and Democracy” (1942)</p></div></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1590790673064_18724"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1590791932355-JKFUN2W7KANQTOR26J6C/ke17ZwdGBToddI8pDm48kKQAGiJ8QoxQVZThzFVMI9wUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dv611mQ9iQVKPCSuQUyCgQfJgq3EQY20myI8A3lW-G-r3WUfc_ZsVm9Mi1E6FasEnQ/peter%252Bdrucker.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1590791932355-JKFUN2W7KANQTOR26J6C/ke17ZwdGBToddI8pDm48kKQAGiJ8QoxQVZThzFVMI9wUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dv611mQ9iQVKPCSuQUyCgQfJgq3EQY20myI8A3lW-G-r3WUfc_ZsVm9Mi1E6FasEnQ/peter%252Bdrucker.jpg" data-image-dimensions="1710x962" data-image-focal-point="0.5,0.5" alt="peter%2Bdrucker.jpg" data-load="false" data-image-id="5ed18efbdf699b54f883a601" data-type="image" src="https://www.ofmos.com/peter%2Bdrucker.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1590789097891_18195"><div><h3>Peter Drucker: Entrepreneurial Society</h3><p>“Innovation and entrepreneurship are thus needed in society as much as in the economy, in public-service institutions as much as in businesses. It is precisely because innovation and entrepreneurship are not ‘root and branch’ but ‘one step at a time,’ a product here, a policy there, a public service yonder; because they are not planned but focused on this opportunity and that need; because they are tentative and will disappear if they do not produce the expected and needed results; because, in other words, they are pragmatic rather than dogmatic and modest rather than grandiose — that they promise to keep any society, economy, industry, public service, or business flexible and self-renewing. […]</p><p>What we need is an entrepreneurial society in which innovation and entrepreneurship are normal, steady, and continual. Just as management has become the specific organ of all contemporary institutions, and the integrating organ of our society of organizations, so innovation and entrepreneurship have to become an integral life-sustaining activity in our organizations, our economy, our society.”</p><p>— Excerpted from Peter Drucker’s “Innovation and Entrepreneurship” (1985)</p></div></div></div></div></div></div></div>
    </div>
  </div>
</section>

  
    <section data-section-id="5ee5367eae359b2983c8616a" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
  &quot;imageOverlayOpacity&quot; : 0.9,
  &quot;video&quot; : {
    &quot;playbackSpeed&quot; : 0.5,
    &quot;filter&quot; : 1,
    &quot;filterStrength&quot; : 0,
    &quot;zoom&quot; : 0
  },
  &quot;backgroundWidth&quot; : &quot;background-width--full-bleed&quot;,
  &quot;sectionHeight&quot; : &quot;section-height--small&quot;,
  &quot;horizontalAlignment&quot; : &quot;horizontal-alignment--center&quot;,
  &quot;verticalAlignment&quot; : &quot;vertical-alignment--middle&quot;,
  &quot;contentWidth&quot; : &quot;content-width--medium&quot;,
  &quot;sectionTheme&quot; : &quot;bright&quot;,
  &quot;sectionAnimation&quot; : &quot;none&quot;,
  &quot;backgroundMode&quot; : &quot;image&quot;
}" data-animation="none">
  
  <div>
    <div>
      
      
      <div data-type="page-section" id="page-section-5ee5367eae359b2983c8616a"><div><div><div data-block-type="2" id="block-f21fc181d86799296602"><div><h2>The Ofmos Lens</h2><p>Understand economies as ever-changing collections of virtual business spaces defined by an offering and a set of customers with the same need-addressing behavior associated to that offering. Use the Ofmos theory and model to think about the economy as a complex system.</p><p>Then follow the signature that an economy leaves on the continuum of need-addressing behaviors (or perceived offering value), and note its tendency to “bunch up.” Knowing that the economy’s bunchiness level indicates the society’s health, translate your goals into guidance and approach.</p></div></div></div></div></div>
    </div>
  </div>
</section>

  
    <section data-section-id="5ec7522d117f476816949b2a" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
  &quot;imageOverlayOpacity&quot; : 0.15,
  &quot;video&quot; : {
    &quot;playbackSpeed&quot; : 0.5,
    &quot;filter&quot; : 1,
    &quot;filterStrength&quot; : 0,
    &quot;zoom&quot; : 0
  },
  &quot;backgroundWidth&quot; : &quot;background-width--full-bleed&quot;,
  &quot;sectionHeight&quot; : &quot;section-height--small&quot;,
  &quot;customSectionHeight&quot; : 10,
  &quot;horizontalAlignment&quot; : &quot;horizontal-alignment--center&quot;,
  &quot;verticalAlignment&quot; : &quot;vertical-alignment--middle&quot;,
  &quot;contentWidth&quot; : &quot;content-width--medium&quot;,
  &quot;customContentWidth&quot; : 50,
  &quot;sectionTheme&quot; : &quot;white-bold&quot;,
  &quot;sectionAnimation&quot; : &quot;none&quot;,
  &quot;backgroundMode&quot; : &quot;image&quot;
}" data-animation="none">
  
  <div>
    <div>
      
      
      <div data-type="page-section" id="page-section-5ec7522d117f476816949b2a"><div><div><div data-block-type="2" id="block-a26aa835bbfc1a176d46"><p><h2>Economic Worldview and Theory</h2></p></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1590172530745_14562"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1591326413037-WDXJ8MG4OZLPQK3XY6HY/ke17ZwdGBToddI8pDm48kCbb2eKItvfwa0CDzt1q4zpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIMUjQoZs1pTWwzYpiJME_msW7atwiXoSdPfAPxa2PB_Q/ofmos-web2020-image.022.png" data-image="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1591326413037-WDXJ8MG4OZLPQK3XY6HY/ke17ZwdGBToddI8pDm48kCbb2eKItvfwa0CDzt1q4zpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIMUjQoZs1pTWwzYpiJME_msW7atwiXoSdPfAPxa2PB_Q/ofmos-web2020-image.022.png" data-image-dimensions="942x942" data-image-focal-point="0.5,0.5" alt="ofmos-web2020-image.022.png" data-load="false" data-image-id="5ed9b7bb2b7da27a37b4607a" data-type="image" src="https://www.ofmos.com/ofmos-web2020-image.022.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-605767a9671438a7d8a5"><div><h3>Ofmos</h3><p>View companies and economies as collections of ofmos, which are virtual  worlds defined by an offering and a set of customers with the same  behavior.</p></div></div><div data-block-type="2" id="block-99a719955d4a414e99c0"><div><h3>Dynamic Perspective</h3><p>Analyze companies and economies as evolving systems of commoditizing ofmos (offering-market cosmos) or simply as groups of interrelated particles.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1591293197411_24221"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1591326674775-W7XR88G7EZC6TDT4U9Y4/ke17ZwdGBToddI8pDm48kCbb2eKItvfwa0CDzt1q4zpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIMUjQoZs1pTWwzYpiJME_msW7atwiXoSdPfAPxa2PB_Q/ofmos-web2020-image.069.png" data-image="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1591326674775-W7XR88G7EZC6TDT4U9Y4/ke17ZwdGBToddI8pDm48kCbb2eKItvfwa0CDzt1q4zpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIMUjQoZs1pTWwzYpiJME_msW7atwiXoSdPfAPxa2PB_Q/ofmos-web2020-image.069.png" data-image-dimensions="942x942" data-image-focal-point="0.5,0.5" alt="ofmos-web2020-image.069.png" data-load="false" data-image-id="5ed9b7d162e9755b3256cdb6" data-type="image" src="https://www.ofmos.com/ofmos-web2020-image.069.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1591293197411_26500"><div><h3>Economic Cycles</h3><p>Note how economies go through fluctuations, with the constituent collection of (t)ofmos “bunching” and “debunching” over time, directly influencing the society.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1592363329081_26547"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1591326760386-DJ62Y4WA8WVRI81BKZCT/ke17ZwdGBToddI8pDm48kCbb2eKItvfwa0CDzt1q4zpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIMUjQoZs1pTWwzYpiJME_msW7atwiXoSdPfAPxa2PB_Q/ofmos-web2020-image.070.png" data-image="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1591326760386-DJ62Y4WA8WVRI81BKZCT/ke17ZwdGBToddI8pDm48kCbb2eKItvfwa0CDzt1q4zpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIMUjQoZs1pTWwzYpiJME_msW7atwiXoSdPfAPxa2PB_Q/ofmos-web2020-image.070.png" data-image-dimensions="942x942" data-image-focal-point="0.5,0.5" alt="ofmos-web2020-image.070.png" data-load="false" data-image-id="5ee989b41cd273133d5700df" data-type="image" src="https://www.ofmos.com/ofmos-web2020-image.070.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1592363329081_27858"><div><h3>Tofmos and Ofmos</h3><p>Use the concept of tofmos (total-offering-market-cosmos) to analyze  economies, and the concept of ofmos (offering-market-cosmos) for  companies.</p></div></div></div></div></div></div></div>
    </div>
  </div>
</section>

  
    <section data-section-id="5ec820ed18c584174f6f4888" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
  &quot;imageOverlayOpacity&quot; : 0.15,
  &quot;video&quot; : {
    &quot;playbackSpeed&quot; : 0.5,
    &quot;filter&quot; : 1,
    &quot;filterStrength&quot; : 0,
    &quot;zoom&quot; : 0
  },
  &quot;backgroundWidth&quot; : &quot;background-width--full-bleed&quot;,
  &quot;sectionHeight&quot; : &quot;section-height--small&quot;,
  &quot;customSectionHeight&quot; : 10,
  &quot;horizontalAlignment&quot; : &quot;horizontal-alignment--center&quot;,
  &quot;verticalAlignment&quot; : &quot;vertical-alignment--middle&quot;,
  &quot;contentWidth&quot; : &quot;content-width--medium&quot;,
  &quot;customContentWidth&quot; : 50,
  &quot;sectionTheme&quot; : &quot;light-bold&quot;,
  &quot;sectionAnimation&quot; : &quot;none&quot;,
  &quot;backgroundMode&quot; : &quot;image&quot;
}" data-animation="none">
  
  <div>
    <div>
      
      
      <div data-type="page-section" id="page-section-5ec820ed18c584174f6f4888"><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1590174983141_16062"><div><h3>The Ofmos Economic Model</h3><p>Use a “complex system” perspective on economies to understand how they evolve and how they influence societies.</p></div></div></div></div></div>
    </div>
  </div>
</section>

  
    <section data-section-id="5ec7522d117f476816949b2c" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
  &quot;imageOverlayOpacity&quot; : 0.15,
  &quot;video&quot; : {
    &quot;playbackSpeed&quot; : 0.5,
    &quot;filter&quot; : 1,
    &quot;filterStrength&quot; : 0,
    &quot;zoom&quot; : 0
  },
  &quot;backgroundWidth&quot; : &quot;background-width--full-bleed&quot;,
  &quot;sectionHeight&quot; : &quot;section-height--small&quot;,
  &quot;customSectionHeight&quot; : 10,
  &quot;horizontalAlignment&quot; : &quot;horizontal-alignment--center&quot;,
  &quot;verticalAlignment&quot; : &quot;vertical-alignment--middle&quot;,
  &quot;contentWidth&quot; : &quot;content-width--medium&quot;,
  &quot;customContentWidth&quot; : 50,
  &quot;sectionTheme&quot; : &quot;bright&quot;,
  &quot;sectionAnimation&quot; : &quot;none&quot;,
  &quot;backgroundMode&quot; : &quot;image&quot;
}" data-animation="none">
  
  <div>
    <div>
      
      
      <div data-type="page-section" id="page-section-5ec7522d117f476816949b2c"><div><div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1591246204775_33139"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1591246136683-D5NTB0W0ZAXB7GZMO9HZ/ke17ZwdGBToddI8pDm48kJanlAjKydPZDDRBEy8QTGN7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0hveExjbswnAj1UrRPScjfAi-WHBb3R4axoAEB7lfybbrcBqLQ3Qt4YGS4XJxXD2Ag/CristianMitreanu-RedefiningStrategy-TheoryOfNeedsAndValue-20181015.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1591246136683-D5NTB0W0ZAXB7GZMO9HZ/ke17ZwdGBToddI8pDm48kJanlAjKydPZDDRBEy8QTGN7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0hveExjbswnAj1UrRPScjfAi-WHBb3R4axoAEB7lfybbrcBqLQ3Qt4YGS4XJxXD2Ag/CristianMitreanu-RedefiningStrategy-TheoryOfNeedsAndValue-20181015.jpg" data-image-dimensions="2500x3235" data-image-focal-point="0.5,0.5" alt="CristianMitreanu-RedefiningStrategy-TheoryOfNeedsAndValue-20181015.jpg" data-load="false" data-image-id="5ed87e486991040c505fe1e8" data-type="image" src="https://www.ofmos.com/CristianMitreanu-RedefiningStrategy-TheoryOfNeedsAndValue-20181015.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1591246204775_19034"><div><h3>Needs and Value</h3><p>The article “A Natural Theory of Needs and Value” describes the new view on human nature.</p></div></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1591246204775_34355"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1591226634313-2O25VGGI3N4RDEPI84O0/ke17ZwdGBToddI8pDm48kJanlAjKydPZDDRBEy8QTGN7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0hveExjbswnAj1UrRPScjfAi-WHBb3R4axoAEB7lfybbrcBqLQ3Qt4YGS4XJxXD2Ag/Spointra-Cover-Front-20140915-FINAL.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1591226634313-2O25VGGI3N4RDEPI84O0/ke17ZwdGBToddI8pDm48kJanlAjKydPZDDRBEy8QTGN7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0hveExjbswnAj1UrRPScjfAi-WHBb3R4axoAEB7lfybbrcBqLQ3Qt4YGS4XJxXD2Ag/Spointra-Cover-Front-20140915-FINAL.jpg" data-image-dimensions="2500x3235" data-image-focal-point="0.5,0.5" alt="Spointra-Cover-Front-20140915-FINAL.jpg" data-load="false" data-image-id="5ed87e5c5bbd301c84aecb99" data-type="image" src="https://www.ofmos.com/Spointra-Cover-Front-20140915-FINAL.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1591246204775_22840"><div><h3>Business Success</h3><p>The picture book “Spointra and the Secret of Business Success” details the new worldview in a fun way.</p></div></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1591309339971_26177"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1591309060380-IPD0N4TTAX6ZH5EKBEIN/ke17ZwdGBToddI8pDm48kJanlAjKydPZDDRBEy8QTGN7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0hveExjbswnAj1UrRPScjfAi-WHBb3R4axoAEB7lfybbrcBqLQ3Qt4YGS4XJxXD2Ag/CristianMitreanu-Spointra-BeyondTheFun-20130519-DRAFT.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1591309060380-IPD0N4TTAX6ZH5EKBEIN/ke17ZwdGBToddI8pDm48kJanlAjKydPZDDRBEy8QTGN7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0hveExjbswnAj1UrRPScjfAi-WHBb3R4axoAEB7lfybbrcBqLQ3Qt4YGS4XJxXD2Ag/CristianMitreanu-Spointra-BeyondTheFun-20130519-DRAFT.jpg" data-image-dimensions="2500x3235" data-image-focal-point="0.5,0.5" alt="CristianMitreanu-Spointra-BeyondTheFun-20130519-DRAFT.jpg" data-load="false" data-image-id="5ed97454f5d09417a6dbc941" data-type="image" src="https://www.ofmos.com/CristianMitreanu-Spointra-BeyondTheFun-20130519-DRAFT.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1591246204775_26009"><div><h3>Beyond the Fun</h3><p>The 49-page (draft) letter to the readers places the new theories inside the broader literature.</p></div></div></div></div></div></div></div>
    </div>
  </div>
</section>

  
    <section data-section-id="5ec7522d117f476816949b2e" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
  &quot;backgroundImage&quot; : {
    &quot;id&quot; : &quot;5ef18bcb53bdf278e3f399a5&quot;,
    &quot;recordType&quot; : 2,
    &quot;addedOn&quot; : 1592888267339,
    &quot;updatedOn&quot; : 1592888343125,
    &quot;workflowState&quot; : 1,
    &quot;publishOn&quot; : 1592888267339,
    &quot;authorId&quot; : &quot;589a219a46c3c44baeacffc2&quot;,
    &quot;systemDataId&quot; : &quot;1592888267479-91LMRT5KGF6ZGP1LQMC9&quot;,
    &quot;systemDataVariants&quot; : &quot;942x942,100w,300w,500w,750w&quot;,
    &quot;systemDataSourceType&quot; : &quot;PNG&quot;,
    &quot;filename&quot; : &quot;ofmos-web2020-image.086.png&quot;,
    &quot;mediaFocalPoint&quot; : {
      &quot;x&quot; : 0.5,
      &quot;y&quot; : 0.5,
      &quot;source&quot; : 3
    },
    &quot;colorData&quot; : {
      &quot;topLeftAverage&quot; : &quot;000000&quot;,
      &quot;topRightAverage&quot; : &quot;000000&quot;,
      &quot;bottomLeftAverage&quot; : &quot;000000&quot;,
      &quot;bottomRightAverage&quot; : &quot;000000&quot;,
      &quot;centerAverage&quot; : &quot;000000&quot;,
      &quot;suggestedBgColor&quot; : &quot;000000&quot;
    },
    &quot;urlId&quot; : &quot;bw3aboc98lpfk5atxuzdtmgaw99tpj&quot;,
    &quot;title&quot; : &quot;&quot;,
    &quot;body&quot; : null,
    &quot;likeCount&quot; : 0,
    &quot;commentCount&quot; : 0,
    &quot;publicCommentCount&quot; : 0,
    &quot;commentState&quot; : 2,
    &quot;unsaved&quot; : false,
    &quot;author&quot; : {
      &quot;id&quot; : &quot;589a219a46c3c44baeacffc2&quot;,
      &quot;displayName&quot; : &quot;Cristian Mitreanu&quot;,
      &quot;firstName&quot; : &quot;Cristian&quot;,
      &quot;lastName&quot; : &quot;Mitreanu&quot;,
      &quot;websiteUrl&quot; : &quot;http://www.cristianmitreanu.com&quot;,
      &quot;bio&quot; : &quot;&quot;
    },
    &quot;assetUrl&quot; : &quot;https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1592888267479-91LMRT5KGF6ZGP1LQMC9/ke17ZwdGBToddI8pDm48kCbb2eKItvfwa0CDzt1q4zpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIMUjQoZs1pTWwzYpiJME_msW7atwiXoSdPfAPxa2PB_Q/ofmos-web2020-image.086.png&quot;,
    &quot;contentType&quot; : &quot;image/png&quot;,
    &quot;items&quot; : [ ],
    &quot;pushedServices&quot; : { },
    &quot;pendingPushedServices&quot; : { },
    &quot;recordTypeLabel&quot; : &quot;image&quot;,
    &quot;originalSize&quot; : &quot;942x942&quot;
  },
  &quot;imageOverlayOpacity&quot; : 0.9,
  &quot;video&quot; : {
    &quot;playbackSpeed&quot; : 0.5,
    &quot;filter&quot; : 1,
    &quot;filterStrength&quot; : 0,
    &quot;zoom&quot; : 0
  },
  &quot;backgroundWidth&quot; : &quot;background-width--full-bleed&quot;,
  &quot;sectionHeight&quot; : &quot;section-height--small&quot;,
  &quot;customSectionHeight&quot; : 10,
  &quot;horizontalAlignment&quot; : &quot;horizontal-alignment--center&quot;,
  &quot;verticalAlignment&quot; : &quot;vertical-alignment--middle&quot;,
  &quot;contentWidth&quot; : &quot;content-width--medium&quot;,
  &quot;customContentWidth&quot; : 50,
  &quot;sectionTheme&quot; : &quot;light-bold&quot;,
  &quot;sectionAnimation&quot; : &quot;none&quot;,
  &quot;backgroundMode&quot; : &quot;image&quot;
}" data-animation="none">
  <div>
  
    
      
      <p><img alt="" data-src="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1592888267479-91LMRT5KGF6ZGP1LQMC9/ke17ZwdGBToddI8pDm48kCbb2eKItvfwa0CDzt1q4zpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIMUjQoZs1pTWwzYpiJME_msW7atwiXoSdPfAPxa2PB_Q/ofmos-web2020-image.086.png" data-image="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1592888267479-91LMRT5KGF6ZGP1LQMC9/ke17ZwdGBToddI8pDm48kCbb2eKItvfwa0CDzt1q4zpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIMUjQoZs1pTWwzYpiJME_msW7atwiXoSdPfAPxa2PB_Q/ofmos-web2020-image.086.png" data-image-dimensions="942x942" data-image-focal-point="0.5,0.5" data-load="false" src="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1592888267479-91LMRT5KGF6ZGP1LQMC9/ke17ZwdGBToddI8pDm48kCbb2eKItvfwa0CDzt1q4zpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIMUjQoZs1pTWwzYpiJME_msW7atwiXoSdPfAPxa2PB_Q/ofmos-web2020-image.086.png"></p>
    
  
  </div>
  
</section>

  
    <section data-section-id="5ec7522d117f476816949b30" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
  &quot;imageOverlayOpacity&quot; : 0.15,
  &quot;video&quot; : {
    &quot;playbackSpeed&quot; : 0.5,
    &quot;filter&quot; : 1,
    &quot;filterStrength&quot; : 0,
    &quot;zoom&quot; : 0
  },
  &quot;backgroundWidth&quot; : &quot;background-width--full-bleed&quot;,
  &quot;sectionHeight&quot; : &quot;section-height--small&quot;,
  &quot;horizontalAlignment&quot; : &quot;horizontal-alignment--center&quot;,
  &quot;verticalAlignment&quot; : &quot;vertical-alignment--middle&quot;,
  &quot;contentWidth&quot; : &quot;content-width--medium&quot;,
  &quot;sectionTheme&quot; : &quot;dark-bold&quot;,
  &quot;sectionAnimation&quot; : &quot;none&quot;,
  &quot;backgroundMode&quot; : &quot;image&quot;
}" data-animation="none">
  
  
</section>

  
</article>

          
          
          
        
      </main>
      

      
        
      
    </div></div>]]>
            </description>
            <link>https://www.ofmos.com/how-economies-work</link>
            <guid isPermaLink="false">hacker-news-small-sites-23838632</guid>
            <pubDate>Tue, 14 Jul 2020 22:10:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Breaking Down Lululemon's $500M Mirror Acquisition]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 24 (<a href="https://news.ycombinator.com/item?id=23838564">thread link</a>) | @Cpevans
<br/>
July 14, 2020 | https://insider.fitt.co/issue-no-87-why-mirror-sold/ | <a href="https://web.archive.org/web/*/https://insider.fitt.co/issue-no-87-why-mirror-sold/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-content">
			<div>
				<div>
					<section>
						<p>A few weeks back, lululemon acquired Mirror for $500M. When the news broke, we wrote&nbsp;<a href="https://insider.fitt.co/lululemon-acquires-mirror-500m/" target="_blank" rel="noopener">a quick analysis</a>&nbsp;of how the partnership might play out. Today, we’re going deeper to explore lulu’s ambitions, Mirror’s motivation for selling, and how, in hindsight, Nike, Peloton, and COVID-19 sealed the deal.</p>
<p><strong>TL;DR:</strong>&nbsp;Even if this acquisition doesn’t pan out, everybody wins. Here’s why.</p>
					</section>

          <section>
						      <div>
        <div>
                      <h2>Calculated Risk</h2>
          
          <p>M&amp;A is a mixed bag. In the case of activewear retailers, buying into digital fitness via high-profile purchases has&nbsp;<a href="https://twitter.com/JoeVennare/status/1281301589190488064" target="_blank" rel="noopener">proven futile</a>. So why did lululemon, a fast-growing apparel company, roll the dice on Mirror? One word: Nike.</p>
<p>Nike is the king of activewear. Try as they might, foes like adidas, Reebok, and Under Armour are no match for the swoosh. For its part, lululemon hopes to become a worthy adversary — if for no other reason than to remain in the good graces of Wall Street. On both accounts, Mirror factors heavily into the equation.</p>
<p>Putting this competition into context, lululemon trails Nike by an order of magnitude. Nike has a $152B market cap. Over the last 12 months, they’ve done $37B in sales. Meanwhile, lulu’s market cap is $37B, and the company had revenues of $3.85B over the same period.</p>
<p>While shares of the yoga pant maker have outperformed Nike in recent years, lulu might not ever reach the scale of Nike. But beating Nike outright isn’t the point. Ultimately, lululemon is in competition with itself, where Nike represents the upper bounds of what’s possible.</p>
        </div>
      </div>

            <div>
        <div>
                      <h2>Just Keep Growing</h2>
          
          <p>To prove that they haven’t peaked, lululemon has one mandate: just keep growing.</p>
<p>Moving beyond the yoga niche and expanding its total addressable market, the company’s&nbsp;<a href="https://us15.campaign-archive.com/?u=4c6bc12e271bc681951ed945a&amp;id=96471d02c6" target="_blank" rel="noopener">five-year strategic plan</a>, released in April 2019, charted the path forward: “double men’s, double digital, and quadruple international” revenues. Add self-care products, a foray into footwear, and the opening of a 20,000-square-foot experiential store (complete with yoga studios and a restaurant) into the mix and grow they shall.</p>
<p>A few months later, in November of 2019, lululemon invested $1M into Mirror’s $34M Series B-1, a bargain for a foothold in connected fitness. As part of the investment, and in keeping with its goal of becoming an experiential brand, lululemon ambassadors began creating workout content for the Mirror platform.</p>
<p>Flash-forward to March: when COVID hit, the table was set. With retail stores shuttered and fitness studios closed, shopping and sweating moved online. In a few short weeks, lululemon had seen enough; they were ready to go all-in on Mirror.</p>
<ul>
<li>In the first week of store closures, 170K people joined lulu’s live workouts on Instagram.</li>
<li>Pre-COVID, 64% of lululemon guests used a digital workout option at home.</li>
<li>During the pandemic, as the coronavirus spread, that number jumped to 75%.</li>
<li>86% of lulu customers who used an at-home option during the outbreak plan to continue or increase their new digital workout habit.</li>
</ul>
<p>In April, lulu’s online sales surged&nbsp;<a href="https://www.cnbc.com/2020/06/11/lululemon-lulu-reports-fiscal-q1-2020-earnings.html" target="_blank" rel="noopener">125%</a>, a trend that’s expected to continue. Add in the fact that some 50% of Mirror users are also lululemon customers, and this deal checks a lot of boxes for the growth-focused retailer.</p>
        </div>
      </div>

            <div>
        <div>
                      <h2>Why Mirror Sold</h2>
          
          <p>Last year, Mirror CEO Brynn Putnam told Fast Company she was building “the next iPhone.” Far from another connected fitness upstart, Mirror would be “the third screen in your life that you’re going to turn to for all immersive interactive experiences going forward.”</p>
<p>About seven months later, Putnam pulled the ripcord, selling her company amid a global pandemic — circumstances tailor-made for an immersive third screen.</p>
<p>So why did Mirror sell? lulu made an offer they couldn’t refuse. Putnam, a solo, female founder just secured a “W” for herself, her investors, and New York’s startup scene.</p>
<p>Beyond the obvious, it’s fair to ask,&nbsp;<em>why now?</em>&nbsp;In many ways, Peloton forced Putnam’s hand.</p>
<p>Pitching Mirror as the “next iPhone” was a strategic move that 1.) established a big vision worthy of $70M+ in funding, and 2.) helped the company duck the question, “how do you compete with Peloton?” Their answer was simple — we don’t.</p>
<p>When COVID hit, Mirror was pigeonholed. They weren’t the third screen, they were in direct competition with Peloton. And despite surging sales, Mirror’s growth pales in comparison to Peloton’s. Plus, there’s&nbsp;<a href="https://www.linkedin.com/posts/joevennare_fitness-startups-activity-6679025786697117697-YuI5" target="_blank" rel="noopener">a growing list of Mirror-like competitors</a>&nbsp;hitting the market. All of a sudden, an interactive screen didn’t feel all that innovative, or defensible.</p>
<p>Meanwhile, digital fitness companies are raking in funding. Hydrow, Aaptiv, and NEOU recently closed investments as Tonal and Tempo target new funds. If Mirror considered raising on the back of its COVID boost, they’d have to become a customer acquisition and retention machine, where every move is audited in relation to Peloton’s now public (and soaring) metrics.</p>
<p>In the end, joining forces with lululemon was more compelling than slugging it out with Peloton or adhering to the “third screen” narrative.</p>
        </div>
      </div>

            <div>
        <div>
                      <h2>Lulu x Mirror</h2>
          
          <p>Upon announcing the deal, lululemon’s stock jumped, and onlookers have been quick to heap on the praise.</p>
<p>According to Bank of America analysts, Mirror could generate&nbsp;<a href="https://www.marketwatch.com/amp/story/lululemon-acquisition-mirror-could-generate-700-million-and-reach-600000-subscribers-by-2023-bank-of-america-2020-07-01" target="_blank" rel="noopener">$700M</a>&nbsp;in revenue and reach 600,000 subscribers by 2023.</p>
<p>To realize this lofty forecast, lululemon will sell Mirrors to its existing customer base, starting with its 489 corporate-owned stores across the globe. The retailer will continue creating content for the platform, where Mirror instructors will be clad in lululemon gear. More than simply selling more apparel, Mirror’s ability to generate recurring revenue and strengthen lulu’s relationship with consumers is the chief aim of this acquisition.</p>
<p>While the hard work of transforming an athleisure retailer into a tech company is just beginning, it will be difficult to criticize lululemon for shooting this shot. Whether or not they can keep growing will be the question on everyone’s mind:</p>
<p><em>“Lulu is showing no signs of slowing down, but acquisitions made outside a retailer’s core skill set have rarely been seamless. There is nothing bad about the story right now. The scariest thing [for investors] about Lulu is, is this as good as it gets?”</em>&nbsp;– Simeon Siegel, managing director &amp; senior retail analyst at BMO Capital Markets.</p>
<hr>
        </div>
      </div>

            <div>
        <div>
                      <h2>💻 Closing the Gap </h2>
          
          <p>Teletherapy is gaining traction during the pandemic. It just might be the key to unlocking access for millions of individuals battling mental illness.</p>
<p>There’s a&nbsp;<a href="https://insider.fitt.co/wellness-startups-mental-health/" target="_blank" rel="noopener">shocking gap</a>&nbsp;between demand (those in need of care) and supply (access to affordable care).</p>
<ul>
<li>46M Americans report experiencing mental illness each year, while only 42.6% received treatment.</li>
<li>Individuals who are able to access care will wait an average of&nbsp;<a href="https://www.psychiatryadvisor.com/home/practice-management/long-wait-times-typical-for-psychiatry-appointments/" target="_blank" rel="noopener">25 days</a>&nbsp;for an appointment.</li>
<li>With in-room therapy costing $150–$400 per session, plus the added cost of medication,&nbsp;<a href="https://www.kff.org/medicaid/report/mental-health-financing-in-the-united-states/" target="_blank" rel="noopener">45%</a>&nbsp;of untreated individuals cite cost as a barrier.</li>
</ul>
<p><strong>Pros:</strong>&nbsp;During COVID, the majority of therapists switched from in-person to remote therapy. A recent&nbsp;<a href="https://www.apaservices.org/practice/legal/technology/psychologists-embrace-telehealth" target="_blank" rel="noopener">survey</a>&nbsp;found that three quarters of clinicians are exclusively using teletherapy. The fact that teletherapy has been&nbsp;<a href="https://pubmed.ncbi.nlm.nih.gov/26864655/" target="_blank" rel="noopener">shown to be</a>&nbsp;just as effective as in-person therapy for treating PTSD, depression, and anxiety helped solidify the switch.</p>
<p><strong>Cons:</strong>&nbsp;The convenience and flexibility of remote care have proven beneficial, but concerns related to privacy regulations, insurance coverage, Zoom fatigue, and missing non-verbal cues leave a lot of room for improving the experience.</p>
<p>As consumer demand for digital behavioral health grows, investors are seizing the moment.</p>
<ul>
<li>According to&nbsp;<em>Rock Health</em>, in the first half of 2020, digital behavioral health companies received&nbsp;<a href="https://rockhealth.com/reports/2020-midyear-digital-health-market-update-unprecedented-funding-in-an-unprecedented-time/" target="_blank" rel="noopener">$588M</a>&nbsp;in funding — a number equal to the annual funding for this category in any previous year.</li>
</ul>
<p><strong>Looking ahead:</strong>&nbsp;With anxiety and isolation at an&nbsp;<a href="https://insider.fitt.co/insider-newsletter-issue-82-ending-addiction/" target="_blank" rel="noopener">all-time high</a>, the need to confront the&nbsp;<a href="https://insider.fitt.co/wellness-startups-mental-health/" target="_blank" rel="noopener">mental health crisis</a>&nbsp;has never been greater. A bright spot amid the pandemic, digital behavioral health is&nbsp;<a href="https://insider.fitt.co/wellness-startups-stigma/" target="_blank" rel="noopener">destigmatizing</a>&nbsp;and expanding access to care.</p>
<p><strong>Related:</strong>&nbsp;<a href="https://insider.fitt.co/23-alex-katz-ceo-of-two-chairs/" target="_blank" rel="noopener">Two Chairs CEO Alex Katz</a>&nbsp;on the Fitt Insider podcast</p>
        </div>
      </div>

            <div>
        <div>
                      <h2>🥊 Put ’em Up</h2>
          
          <p>Liteboxer, the latest&nbsp;<a href="https://us15.campaign-archive.com/?u=4c6bc12e271bc681951ed945a&amp;id=f14e6a628d" target="_blank" rel="noopener">Peloton of ‘X’</a>&nbsp;upstart, is taking aim at boxing within the booming connected fitness category.</p>
<p><strong>What it is:</strong>&nbsp;A competitor to FightCamp, an interactive at-home boxing experience, Liteboxer offers a free-standing, light-up punching bag for $1,495 and a $29/month content subscription.</p>
<p><strong>How it works:</strong>&nbsp;While FightCamp offers punch tracking technology and a variety of workouts from “real fighters”, Liteboxer looks a lot like Dance Dance Revolution for boxing. Flashing lights synced to music tell users where to hit and a force-tracking bag measures performance.</p>
<p><strong>Looking ahead:</strong>&nbsp;Following in Peloton’s footsteps is tempting, but surely at-home fitness has a ceiling — especially when every piece of equipment costs $1,500 or more.</p>
<p>For their part, Peloton appears to be rethinking the category a bit. The company was rumored to be working on a connected rower à la Hydrow. But recently, CFO Jill Woodworth&nbsp;<a href="https://outline.com/9fv3sB" target="_blank" rel="noopener">said</a>&nbsp;the company will forgo the rower, for now, in favor of a cheaper treadmill. Woodworth also said developing a product for the “boot camp category” is a priority. Is Peloton’s Mirror competitor in the works?</p>
<p><strong>Related:</strong>&nbsp;<a href="https://insider.fitt.co/7-khalil-zahar-co-founder-ceo-of-fightcamp/" target="_blank" rel="noopener">FightCamp CEO Khalil Zahar</a>&nbsp;on the Fitt Insider podcast</p>
        </div>
      </div>

            <div>
        <div>
                      <h2>📰 News &amp; Notes</h2>
          
          <ul>
<li>The designification of&nbsp;<a href="https://www.metropolismag.com/interiors/healthcare-interiors/the-problem-with-the-designification-of-health-care/" target="_blank" rel="noopener">health</a>.</li>
<li>A&nbsp;<a href="https://twitter.com/joevennare/status/1278739336268308480?s=12" target="_blank" rel="noopener">thread</a>: Apple as a healthcare company</li>
<li>A 2015&nbsp;<a href="https://medium.com/@nickcrocker/how-to-lose-200m-pounds-why-myfitnesspal-works-d00f392d9783" target="_blank" rel="noopener">memo</a>: How MyFitnessPal works.</li>
<li>Meet&nbsp;<a href="https://highcourt.co/" target="_blank" rel="noopener">Highcourt</a>, NYC’s new wellness-focused “leisure club”.</li>
<li>Who are the best early-stage fitness and wellness&nbsp;…</li></ul></div></div></section></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://insider.fitt.co/issue-no-87-why-mirror-sold/">https://insider.fitt.co/issue-no-87-why-mirror-sold/</a></em></p>]]>
            </description>
            <link>https://insider.fitt.co/issue-no-87-why-mirror-sold/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23838564</guid>
            <pubDate>Tue, 14 Jul 2020 22:04:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Liquidity in Sports Betting Markets]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23838538">thread link</a>) | @conordurkin
<br/>
July 14, 2020 | http://conordurkin.com/liquidity-in-sports-betting-markets/ | <a href="https://web.archive.org/web/*/http://conordurkin.com/liquidity-in-sports-betting-markets/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
			
		<div>
		
<p><em>O<em>r, some thoughts on the theory of bid-ask spreads in gambling markets</em></em></p>



<p>One of the things I’ve found interesting to think about for a few months now is how spreads and odds get set by bookmakers. I’ve written a bit about this before, in terms of how the line gets set, but also think it’s worth considering how the house edge is set on any given market. In the simplest terms, what determines whether a two-sided market is -110 on both sides<span id="easy-footnote-1-186"></span><span><a href="#easy-footnote-bottom-1-186" title="~4.55% house edge"><sup>1</sup></a></span> or -115 on both sides <span id="easy-footnote-2-186"></span><span><a href="#easy-footnote-bottom-2-186" title="~6.52% house edge"><sup>2</sup></a></span>, or some other number? Put differently, and more broadly, this can be thought of as a question around efficiency and liquidity in gambling markets, and what determines the bid-ask spread.</p>



<p>It’s useful to start with how lines get set. Broadly speaking, bookmakers begin by opening markets at prices they think reflect the ‘right price’ for a game, based on their actual expectations of performance, expectations of people’s bets, and a variety of other factors<span id="easy-footnote-3-186"></span><span><a href="#easy-footnote-bottom-3-186" title="Contrary to popular belief, it is not entirely based on &amp;#8220;what gets me 50-50 on each side&amp;#8221; &amp;#8211; I wrote a bit about this before, <strong><a href=&quot;http://conordurkin.com/bookmakers-and-keynesian-beauty-contests/&quot;>h</a></strong><strong><a href=&quot;http://conordurkin.com/bookmakers-and-keynesian-beauty-contests/&quot;>e</a></strong><strong><a href=&quot;http://conordurkin.com/bookmakers-and-keynesian-beauty-contests/&quot;>r</a></strong><strong><a href=&quot;http://conordurkin.com/bookmakers-and-keynesian-beauty-contests/&quot;>e</a></strong>."><sup>3</sup></a></span>. Gamblers (or market participants, if you prefer to sound more academic) then places wagers in these markets, moving the line one way or another based on their aggregate volumes, and the line eventually moves to a more efficient equilibrium price such that future bets aren’t one-sided and won’t move the market<span id="easy-footnote-4-186"></span><span><a href="#easy-footnote-bottom-4-186" title="One very very important clarification here: this is not as basic as seeing which side has more volume and shifting the line accordingly; there is far more too it than that. Just as electronic stock market makers or HFTs will likely shift their markets if they know they&amp;#8217;re getting retail volume from someone like Robinhood as opposed to institutional interest from some smart hedge fund, bookmakers will absolutely move their lines differently depending on whether they&amp;#8217;re receiving a few big bets from some random Joe Public as opposed to receiving big bets from known sharp gamblers. While enough one-sidedness of the former *may* move a line, it is much, much, much more the case that they will respond to the latter (and quickly)."><sup>4</sup></a></span>.</p>



<p>At the highest level: markets which reach that equilibrium price faster should have tighter bid-ask spreads. In a gambling context, that should be reflected in the form of a lower vig; the most efficient market possible would be one offering true odds<span id="easy-footnote-5-186"></span><span><a href="#easy-footnote-bottom-5-186" title="E.g. +100 on either side of a 50-50 outcome."><sup>5</sup></a></span>, with any house edge eating away at liquidity in some aspect. The key here is that the tightness of a bid-ask spread is reflective of the risk that the marketmaker is taking; in situations where the marketmaker can trust that he is not exposed to as much risk<span id="easy-footnote-6-186"></span><span><a href="#easy-footnote-bottom-6-186" title="Because the price is correct, or because the market is liquid enough that in the long run he will certainly reach the right price."><sup>6</sup></a></span>, then he should be willing to offer a tighter market to attract more bets.</p>



<p>What makes a market reach that price faster? It’s primarily a function of liquidity. A market with a lot of gamblers, a lot of bets, and a lot of dollars at stake has a lot more volume and is a lot more liquid. Consequently, there’s enough activity going on that you’re able to reach the ‘right price’ a lot quicker. It’s not that the prices in these market necessarily start any more accurately than any others; they just move more quickly into equilibrium much more quickly. This is pretty straightforward to see in the gambling world; the most heavily bet markets are generally NFL games (both spreads and totals), and those bets are generally regarded as most efficient and hardest to find an edge on<span id="easy-footnote-7-186"></span><span><a href="#easy-footnote-bottom-7-186" title="Again, unless you&amp;#8217;re waiting at the window until the minute they open and sharp gamblers haven&amp;#8217;t had an opportunity to move the prices into equilibrium yet."><sup>7</sup></a></span>.</p>



<p>Beyond liquidity, events with more precisely well-known mathematical odds should also be more efficient markets, and this should again be reflected in tighter spreads. However, in this instance the efficiency is a function of the event itself rather than a function of the market participants – if the true odds are particularly well known, the marketmaker can be more confident that his opening lines are already the ‘efficient prices’ and he doesn’t have to rely on gamblers to get him there. As an example, one of the popular Super Bowl prop bets offered every year is whether the coin toss will be Heads or Tails. Prop bets (or derivative bets) tend to get less action than most ‘regular’ bets, and they usually have larger vigs to reflect the fact that they’re less efficient markets. But this is an obviously 50-50 proposition, it’s a literal coin flip – and I think every time I’ve seen the prop offered, it’s been a -105 bet<span id="easy-footnote-8-186"></span><span><a href="#easy-footnote-bottom-8-186" title="~2.38% house edge"><sup>8</sup></a></span> on either side, reflecting that fact.</p>



<p>Conversely, less liquid or well-known stuff should in contrast see wider spreads. I already mentioned derivative (or prop) bets as one example here; less money chasing those markets means prices can remain inefficient longer, and there’s a higher risk of one-sided traffic<span id="easy-footnote-9-186"></span><span><a href="#easy-footnote-bottom-9-186" title="In a liquid market with lots of bettors, you&amp;#8217;ll have enough volume on both sides of a betting market for the price to reach equilibrium and be &amp;#8216;efficient&amp;#8217;. In a smaller market, you might never reach that equilibrium price if the market started at a bad price, so the net exposure to the bookmaker is very one-sided. This is fairly evidently riskier for the bookmaker."><sup>9</sup></a></span>. In some instances, you can actually see the ‘efficiency as liquidity’ question play out in real time, with not just the lines moving dynamically, but the size of the spreads as well. In college football, for example, while most big college football games are pretty liquid markets, FCS games are much less commonly bet. I’ve very frequently seen markets start at -120 or -125 on Monday morning, but have those spreads shrink to -110 on Saturday around noon when it’s almost gametime. Why are they able to tighten the market? Because by that point they feel pretty good about the quality of the price they’re offering, so they have less need to protect against price risk – despite the fact that it was perfectly logical for them to do so a few days prior.</p>



<p>One particularly interesting ‘less liquid’ example is in futures betting <span id="easy-footnote-10-186"></span><span><a href="#easy-footnote-bottom-10-186" title="For example, &amp;#8220;Which team will win the World Series?&amp;#8221; &amp;#8211; markets which deal not with one event happening quickly, but that deal with a bigger event happening down the road"><sup>10</sup></a></span>, which has two real wrinkles to deal with. First, time lag – these events are all things that happen in the future, not today, and the correct probabilities will evolve over time. This creates some level of uncertainty risk in that the efficient prices will change over time, could change dramatically over time, and even if the market lands on the efficient prices today the marketmaker faces a real risk that in the future the market won’t remain liquid enough to stay efficient as prices evolve. That uncertainty ends up reflected in a wider spread. Secondly, these are typically not 1-on-1 outcomes; there’s a whole field of potential options<span id="easy-footnote-11-186"></span><span><a href="#easy-footnote-bottom-11-186" title="For example, there are 30 teams that could win the World Series. Okay, maybe 29 &amp;#8211; the Orioles aren&amp;#8217;t getting it done this year, even with a 60 game season."><sup>11</sup></a></span>. As such, getting to “equilibrium” is a lot harder because it’s not about A vs B, it’s about A, B, C… to Z all being reasonably efficient prices. Liquidity is a lot harder because even with a lot of people betting, there’s no guarantee you’ll receive enough volume on each individual possible outcome of the futures market for the prices to be accurate; it’s a lot easier for a few to be out of whack. Books end up protecting against this by having a much, much higher hold in futures markets than in regular betting – where the house edge is usually something like 4-5% in any typical point spread, the total house edge in most futures markets is often 20-30% or more.</p>



<p>Another example is in live betting, where wagers are accepted during the actual course of play of a game. These markets typically see much wider spreads (something like -120 on each side instead of -110), largely because the timeframe in which bettors can move the price is basically nonexistant – the game is already going on! Bookmakers either have to be very very confident in the prices they offer or offer a less liquid market to protect themselves. They generally choose the latter.</p>



<p>It’s also worth thinking about alternative forms of illiquidity, where you can get tighter spreads at the cost of something else. One example is betting exchanges like Betfair – rather than having a marketmaker take your risk, these exchanges use a peer-to-peer market where your wager remains pending until some other bettor wants to take the other side. Because the exchange isn’t taking any risk themselves, they’re protected against any ‘inefficient prices’ and never have any net exposure, so bettors are able to benefit from tighter spreads<span id="easy-footnote-12-186"></span><span><a href="#easy-footnote-bottom-12-186" title="Betfair typically charges a commission of ~5% on winning tickets, which works out to a house edge of ~2.5%"><sup>12</sup></a></span>, at the cost of some execution risk (you’re not guaranteed for your wager to be received until someone takes the other side). Another example is in parimutuel betting, where odds are constantly fluctuating and the actual odds at which a bet is locked in are not set until shortly prior to the event occurring (this is pretty popular in horse racing). The house takes a fixed percentage from the total pool of wagers and then pays out according to the final odds, so they’re again not taking any risk. From the bettor’s perspective, you can get a tighter ‘spread’ and you’re guaranteed to have your bet be valid, but you’re not guaranteed on the actual price, since that will still move around even after your bet is placed<span id="easy-footnote-13-186"></span><span><a href="#easy-footnote-bottom-13-186" title="For whatever reason, my understanding is that parimutuel horseracing still has a pretty healthy house cut. I still think intuitively the parimutuel format should lend itself to allowing for tighter spreads, but evidently that&amp;#8217;s not always the case."><sup>13</sup></a></span>.</p>



<p>Okay, now that we’re 1400 words into this – what’re the implications of all of this to the average gambler? In my experience a lot of times people see markets with lines at -115 or -120 and get annoyed at the bookmaker’s apparent stinginess. If that’s happening on a major event like an NFL or college football game, then sure, that doesn’t seem appropriate. But if that’s happening on more obscure events, it’s not indicative of cheapness – it’s indicative of the marketmaker being afraid that their price is wrong, and that means it’s an opportunity. Despite wider spreads, the average bettor is far more likely to be able to profit betting into markets with less efficient prices than they are into markets with tight spreads and perfectly efficient prices. Ed Miller and Matthew Davidow make this point really well in <em>The Logic of Sports Betting</em><span id="easy-footnote-14-186"></span><span><a href="#easy-footnote-bottom-14-186" title="I&amp;#8217;d like to be abundantly clear that I am not here to market this book, nor am I being compensated for it but it is an excellent read, and if you care about this sort of thing you should absolutely read it."><sup>14</sup></a></span> when they get into the idea of ‘strong markets versus weak markets,’ and the need for savvy gamblers to attack the latter – when markets are less liquid, spreads are often wider, but they’re less efficient, and that means they are much more likely to be beatable.</p>
		
			</div>

	<!-- .comments-area -->
</div></div>]]>
            </description>
            <link>http://conordurkin.com/liquidity-in-sports-betting-markets/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23838538</guid>
            <pubDate>Tue, 14 Jul 2020 22:01:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hey Protects Your People]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23838398">thread link</a>) | @kenhara
<br/>
July 14, 2020 | https://harriskenny.com/2020/07/14/how-hey-protects-your-people/ | <a href="https://web.archive.org/web/*/https://harriskenny.com/2020/07/14/how-hey-protects-your-people/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>I recently signed up for HEY (from the makers of Basecamp). The benefits of this service for you as an end-user are clear. And with how they’ve implemented this anti-tracking, HEY protects your people too. Your family members, your colleagues, your business partners. Read how.</p>



<p>I received an order confirmation and wanted to forward it to a family member, who isn’t using HEY (yet). HEY flagged that the email had tracking enabled… </p>



<p><strong>If HEY blocks the tracking for you, but you then forward the email… What happens? </strong></p>



<p>Good stuff, that’s what. </p>



<h2>HEY on Spy Trackers</h2>



<p>First, let’s check out HEY’s overall stance on <a rel="noreferrer noopener" href="https://hey.com/spy-trackers/" target="_blank">Spy Trackers</a>. Here’s the relevant section: </p>



<figure data-amp-lightbox="true"><img data-attachment-id="2819" data-permalink="https://harriskenny.com/screen-shot-2020-07-14-at-11-32-54-am/" data-orig-file="https://harriskenny.files.wordpress.com/2020/07/screen-shot-2020-07-14-at-11.32.54-am.png" data-orig-size="1402,900" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2020-07-14-at-11.32.54-am" data-image-description="" data-medium-file="https://harriskenny.files.wordpress.com/2020/07/screen-shot-2020-07-14-at-11.32.54-am.png?w=300" data-large-file="https://harriskenny.files.wordpress.com/2020/07/screen-shot-2020-07-14-at-11.32.54-am.png?w=700" src="https://harriskenny.files.wordpress.com/2020/07/screen-shot-2020-07-14-at-11.32.54-am.png?w=1024" alt="HEY manages this protection through several layers of defenses. First, we’ve identified all the major spy-pixel patterns, so we can strip those out directly. When we find one of those pesky pixels, we’ll tell you exactly who put it in there, and from what email application it came. Second, we bulk strip everything that even smells like a spy pixel. That includes 1x1 images, trackers hidden in code, and everything else we can do to protect you. Between those two practices, we’re confident we’ll catch 98% of all the tracking that’s happening out there.

But even if a spy pixel sneaks through our defenses (and we vow to keep them updated all the time!), you’ll have an effective last line of defense: HEY routes all images through our own servers first, so your IP address never leaks. This prevents anyone from discovering your physical location just by opening an email. Like VPN, but for email." srcset="https://harriskenny.files.wordpress.com/2020/07/screen-shot-2020-07-14-at-11.32.54-am.png?w=1024 1024w, https://harriskenny.files.wordpress.com/2020/07/screen-shot-2020-07-14-at-11.32.54-am.png?w=150 150w, https://harriskenny.files.wordpress.com/2020/07/screen-shot-2020-07-14-at-11.32.54-am.png?w=300 300w, https://harriskenny.files.wordpress.com/2020/07/screen-shot-2020-07-14-at-11.32.54-am.png?w=768 768w, https://harriskenny.files.wordpress.com/2020/07/screen-shot-2020-07-14-at-11.32.54-am.png 1402w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>I first thought this might work like NoScript, Privacy Badger, or uBlock Origin. Where the tracking is prevented from loading, but is still there. Basically, keeping a lid on it. So I decided to email their customer support.</p>



<p><strong>Yep. There’s an email service provider with real humans providing customer support in 2020.</strong></p>



<h2>How it Works</h2>



<p>Spoiler alert: I was wrong! When they say strip, they literally mean strip. Here’s what the friendly (and prompt) response from their team explained:</p>



<figure><img data-attachment-id="2821" data-permalink="https://harriskenny.com/hey-tracking/" data-orig-file="https://harriskenny.files.wordpress.com/2020/07/hey-tracking.png" data-orig-size="2790,1884" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="hey-tracking" data-image-description="" data-medium-file="https://harriskenny.files.wordpress.com/2020/07/hey-tracking.png?w=300" data-large-file="https://harriskenny.files.wordpress.com/2020/07/hey-tracking.png?w=700" src="https://harriskenny.files.wordpress.com/2020/07/hey-tracking.png?w=1024" alt="" srcset="https://harriskenny.files.wordpress.com/2020/07/hey-tracking.png?w=1024 1024w, https://harriskenny.files.wordpress.com/2020/07/hey-tracking.png?w=2048 2048w, https://harriskenny.files.wordpress.com/2020/07/hey-tracking.png?w=150 150w, https://harriskenny.files.wordpress.com/2020/07/hey-tracking.png?w=300 300w, https://harriskenny.files.wordpress.com/2020/07/hey-tracking.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Look at those time stamps! Now that’s service.</figcaption></figure>



<p>They don’t pass along the trackers, they strip them out. Link tracking gets more complicated because of <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/UTM_parameters" target="_blank">UTM parameters</a> and probably other things that I’m not aware of. But this is undeniable progress. </p>



<h2>Sidebar: How it Used to “Work”</h2>



<p>Quick note on how I used to handle this. I would disable image loading on all emails by default. This meant email HTML/CSS styling regularly broke and looked bad. But I did know that the tracking wouldn’t be passed through. It worked “well enough” but not really well at all.</p>



<p>Some unethical senders would try to get around this by sending all-image emails, requiring you to load the images. Then try to Unsubscribe but it’s a hassle, etc. (That’s where <a rel="noreferrer noopener" href="https://hey.com/features/the-screener/" target="_blank">The Screener</a> comes in with HEY.) </p>



<h2>Your Choice</h2>



<p>This falls somewhere between a <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Virtuous_circle_and_vicious_circle" target="_blank">virtuous cycle</a> and a <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Externality#Positive" target="_blank">positive externality</a>. Basically, when you choose an ethical service like HEY it creates a protective bubble that extends to the people around you. In other words, it partially breaks the tracking chain.</p>



<p><strong>I’m not sure the technical term for this. If you know, please tell me!</strong></p>



<p>Conversely, the same applies. Companies taking a different approach allow tracking to proliferate. They harvest and share information. This is especially concerning when you consider the intimacy of your email.</p>



<p>When you choose technology, you don’t just choose it for yourself. You choose it for the people around you, too. </p>



<hr>



<h2>More on HEY</h2>



<p>Check out the blog post below that I wrote about testing and sending HEY-friendly emails using MailChimp (one of the leading email marketing platforms).</p>


				<div>
			<div data-posts="">
								
	<article data-post-id="2680">
					<figure>
				<a href="https://harriskenny.com/2020/06/17/tracker-testing-hey-vs-mailchimp-can-they-coexist/" rel="bookmark">
					<img width="1200" height="900" src="https://harriskenny.files.wordpress.com/2020/06/sending-html-yes-track-1.png?w=1200&amp;h=900&amp;crop=1" alt="" srcset="https://harriskenny.files.wordpress.com/2020/06/sending-html-yes-track-1.png?w=1200&amp;h=900&amp;crop=1 1200w, https://harriskenny.files.wordpress.com/2020/06/sending-html-yes-track-1.png?w=150&amp;h=113&amp;crop=1 150w, https://harriskenny.files.wordpress.com/2020/06/sending-html-yes-track-1.png?w=300&amp;h=225&amp;crop=1 300w, https://harriskenny.files.wordpress.com/2020/06/sending-html-yes-track-1.png?w=768&amp;h=576&amp;crop=1 768w, https://harriskenny.files.wordpress.com/2020/06/sending-html-yes-track-1.png?w=1024&amp;h=768&amp;crop=1 1024w" sizes="(max-width: 1200px) 100vw, 1200px" data-attachment-id="2728" data-permalink="https://harriskenny.com/2020/06/17/tracker-testing-hey-vs-mailchimp-can-they-coexist/sending-html-yes-track-2/" data-orig-file="https://harriskenny.files.wordpress.com/2020/06/sending-html-yes-track-1.png" data-orig-size="2472,1264" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="sending-html-yes-track" data-image-description="" data-medium-file="https://harriskenny.files.wordpress.com/2020/06/sending-html-yes-track-1.png?w=300" data-large-file="https://harriskenny.files.wordpress.com/2020/06/sending-html-yes-track-1.png?w=700">				</a>

							</figure><!-- .featured-image -->
		
		<!-- .entry-wrapper -->
	</article>

					</div>
			
		</div>
					</div></div>]]>
            </description>
            <link>https://harriskenny.com/2020/07/14/how-hey-protects-your-people/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23838398</guid>
            <pubDate>Tue, 14 Jul 2020 21:49:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Snorkel AI: Putting Data First in ML Development]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23838310">thread link</a>) | @blopeur
<br/>
July 14, 2020 | https://www.snorkel.ai/07-14-2020-snorkel-ai-launch | <a href="https://web.archive.org/web/*/https://www.snorkel.ai/07-14-2020-snorkel-ai-launch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                  <p>
                      Today I’m excited to announce Snorkel AI’s launch out of stealth!
                      Snorkel AI, which spun out of the Stanford AI Lab in 2019, was founded on two simple premises: first, that the labeled <b>training data</b>  machine learning models learn from is increasingly what determines the success or failure of AI applications.
                      And second, that we can do much better than labeling this data entirely by hand.
                  </p>
                  <p>
                      At the Stanford AI lab, the Snorkel AI founding team spent over four years developing new <b>programmatic</b> approaches to labeling, augmenting, structuring, and managing this training data.
                      We were fortunate to develop and deploy early versions of our technology with some of the world’s leading organizations like <a href="https://ai.googleblog.com/2019/03/harnessing-organizational-knowledge-for.html">Google</a>, <a href="https://dl.acm.org/doi/abs/10.1145/3329486.3329492">Intel</a>, <a href="https://arxiv.org/abs/1909.05372">Apple</a>, <a href="https://www.sciencedirect.com/science/article/pii/S2666389920300192">Stanford Medicine</a>, resulting in <a href="https://www.snorkel.ai/technology#reference">over thirty-six peer-reviewed publications</a> on our findings; innovations in weak supervision modeling, data augmentation, multi-task learning, and more; inclusion in university computer science curriculums; and deployments in popular products and systems that you’ve likely interacted with in the last few hours.
                  </p>
                  <p>
                      Through all this academic tinkering and industry spelunking, we realized two things: first, that this concept of labeling and building training data programmatically, rather than by hand, had transformational potential to make machine learning more iterative, auditable, faster to deploy, and ultimately, more practical.
                      And second, that these ideas changed not just how you label training data, but so much of the entire lifecycle and pipeline of ML: how knowledge and feedback is injected; how models are constructed, trained, versioned, and monitored; how entire pipelines are developed iteratively; and how the full set of stakeholders in any ML deployment, from subject matter experts to ML engineers, are incorporated into the process.
                  </p>
                  <p>
                      In other words, we saw that this shift to programmatic training data required a top-to-bottom rewrite of the entire ML development and deployment process.
                      With the support of some amazing investors (Greylock, GV, In-Q-Tel, and others) and incredible early customers, we’ve spent the last year doing just this: building and deploying <a href="https://www.snorkel.ai/platform">Snorkel Flow</a>, an end-to-end platform to support this new vision of the ML process.
                  </p>
                  <h2>The Training Data Bottleneck</h2>
                  <p>
                      Snorkel Flow was motivated first and foremost by a growing realization that training data had become the key bottleneck in much of ML pipeline and AI application development.
                  </p>
                  <p><img data-src="https://d33wubrfki0l68.cloudfront.net/f63e7bd828cf6019ca0add38ca51ca4050dfeea5/288e4/images/training_data_bottleneck.png" alt="" src="https://d33wubrfki0l68.cloudfront.net/f63e7bd828cf6019ca0add38ca51ca4050dfeea5/288e4/images/training_data_bottleneck.png"></p><p>
                      <b>Today’s ML successes often rest on a hidden cost: massive, hand-labeled training datasets.</b>
                      In the last decade, we’ve seen a tectonic shift in AI and ML towards powerful but data-hungry representation learning models.
                      These models—often deep learning architectures—are not only more powerful at obviating traditionally manual development tasks like feature engineering and bespoke model design, but also have never been more accessible in the open source.
                      However, there’s no such thing as a free lunch: these models are highly complex, with tens to hundreds of millions of parameters, and they require massive labeled training datasets to learn from.
                      And, other than in special scenarios where labels are naturally derivative of existing processes, these training datasets need to be labeled by hand.
                  </p>
                  <p>
                      <b>The hand-labeled training data interface to ML has enabled tremendous progress, but is also ridiculously broken.</b>
                      Consider a simple example: a legal analyst at a bank wants to train a contract classification model, and wants to inject a simple heuristic into the ML model: that if “employment” is in the title, the contract should be labeled as an “Employment contract.”
                      Simple, right?
                      Not so.
                      Theoretically, to communicate this specific feature to a machine learning model via only labeling individual data points could require thousands of examples (roughly, inversely proportional to the sparsity of the feature space).
                      From this perspective, it’s like playing 20 questions rather than just communicating the answer directly—fine if you have a massive question-answer bank, but otherwise wholly impractical.
                  </p>
                  <p>
                      <b>Manually labeling training data is prohibitively expensive–especially when expertise and privacy are required.</b>
                      Building training datasets often requires <a href="http://nytimes.com/2018/11/25/business/china-artificial-intelligence-labeling.html">armies of human labelers</a> at massive cost and time expense.
                      For example, ImageNet—one of the foundational projects behind ML’s current explosive progress—took <a href="https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world/">over two years</a> to create.
                      However, labeling cats, dogs, stop signs, and pedestrians is one thing; labeling data like medical images, legal and financial contracts, government documents, user data, and network data requires <b>stringent privacy protections</b> and <b>subject matter expert labelers</b>.
                      This means for sectors like financial services, government, telecommunications, insurance, healthcare, and more, creating training data (and by extension, using ML) is either a hugely expensive on-premise activity—or more often, one that is just not feasible to tackle, let alone practical.
                  </p>
                  <p>
                      <b>Iterative development is not possible with hand-labeled data.</b>
                      From an engineering and data science perspective, manually labeled training data fundamentally breaks the ability to quickly iterate, which is absolutely essential in real world settings where input data, output goals, and annotation schema change all the time.
                      From a business perspective, training data is an expensive asset that can’t be reused across projects, can often depreciate to worthless overnight due to changing conditions or business goals, and that presents growing risks—everything from <a href="https://web.archive.org/web/20200703104247/https://cloud.google.com/ai-platform/data-labeling/docs">COVID-related delays</a> to <a href="https://www.theverge.com/2018/1/12/16882408/google-racist-gorillas-photo-recognition-algorithm-ai">issues of bias</a>.
                  </p>
                  <h2>A New Input Paradigm for ML: Programming with Data</h2>
                  <p>
                      With Snorkel Flow, rather than needing to hand-label any training data, users develop <b>programmatic operators</b> that label, augment, and build training data to drive the ML development process.
                  </p>
                  <p><img data-src="https://d33wubrfki0l68.cloudfront.net/ae088a1fc7f3c6326c2e7285bc2d3c7e88907290/ad302/images/platform-label-v3.png" alt="" src="https://d33wubrfki0l68.cloudfront.net/ae088a1fc7f3c6326c2e7285bc2d3c7e88907290/ad302/images/platform-label-v3.png"></p><p>
                      <b>Programmatically labeling and building training data.</b>
                      With Snorkel Flow, the idea is to instead communicate this domain knowledge directly via a programmatic operator like a <a href="https://papers.nips.cc/paper/6523-data-programming-creating-large-training-sets-quickly">labeling function</a>.
                      For example, our legal analyst could write a labeling function that labels documents as “Employment contracts” if the word “employment” is in the title, and otherwise abstains; or, a range of more complex and powerful labeling functions relying on internal knowlegebases, models, legacy heuristics, and more.
                      This approach of effectively programming ML with data is simple, direct, interpretable, modifiable, and agnostic to the model used (which is especially important given the ongoing Cambrian explosion of powerful new open source model architectures).
                  </p>
                  <p>
                      <b>The directness of rules with the flexibility of ML.</b>
                      Rule-based systems have long been used in industry for certain tasks—as an input, individual rules have the desirable property of being direct and interpretable.
                      However, rules can also be brittle, and lack the robustness, flexibility, and sheer power of ML approaches.
                      With Snorkel Flow, you get the best of both worlds: rules (and other interpretable resources) as inputs, and powerful ML models that generalize beyond these rules as the output.
                  </p>
                  <p><img data-src="https://d33wubrfki0l68.cloudfront.net/8b9653f8e7b7803550e9afd55284d43beb190fbe/e2b34/images/platform-manage-v3.png" alt="" src="https://d33wubrfki0l68.cloudfront.net/8b9653f8e7b7803550e9afd55284d43beb190fbe/e2b34/images/platform-manage-v3.png"></p><p>
                      <b>A more powerful yet weaker supervision.</b>
                      At the same time that this programmatic supervision is advantageous in several transformational ways, it is also messier and raises fundamental new technical challenges.
                      The labeling functions and other programmatic operators that users write will have varying unknown accuracies and expertise areas, will overlap and disagree with each other, and may be correlated in tangled and unknown ways.
                      We focused on the algorithmic and systems solutions to these issues over <a href="https://www.snorkel.ai/technology">four-plus years of research</a>, showing both empirically and theoretically that with the right techniques, these deep technical challenges can be overcome.
                      The result: training data that is as good as or better than hand-labeled data, and immensely more practical to create and maintain.
                  </p>
                  <p>
                      <b>Beyond labeling: data augmentation, slicing, monitoring, and more.</b>
                      In high-performance production ML, training data is about a lot more than labeling.
                      For example, data augmentation is a cornerstone technique wherein transformed copies of data (e.g. rotated or blurred images) are used to expand the sizes of training datasets, and make resulting models more robust.
                      Slicing or structuring training datasets into more or less important and difficult subsets is also a critical part of managing production ML. 
                      Finally, monitoring and adapting not just models but …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.snorkel.ai/07-14-2020-snorkel-ai-launch">https://www.snorkel.ai/07-14-2020-snorkel-ai-launch</a></em></p>]]>
            </description>
            <link>https://www.snorkel.ai/07-14-2020-snorkel-ai-launch</link>
            <guid isPermaLink="false">hacker-news-small-sites-23838310</guid>
            <pubDate>Tue, 14 Jul 2020 21:40:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Principles for Better Design]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23837939">thread link</a>) | @YungSven
<br/>
July 14, 2020 | https://reflexio.debec.eu/principles-for-better-design | <a href="https://web.archive.org/web/*/https://reflexio.debec.eu/principles-for-better-design">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        
        <figure>
            <img alt="cover" src="https://reflexio.debec.eu/assets/windmill.svg">
            <figcaption><a href="https://www.pinterest.fr/pin/642044490609394018/" target="_blank">credit</a></figcaption>
            
        </figure>
        
        <p>Design is a broad topic. This post won’t approach the adjective qualifying a style with simple forms and a pure appearance. No. Design is broader than a sleek car or an harmonious living room.</p>

<p>Design is a creative activity that aims to invent, improve and solve problems. Life is full of them, in various domains, which pushes people to eventually become a designer of something. Whether you’re conceiving a recipe, an apartment layout, a software or a rocket you are designing. By learning the fundamentals, you will arm yourself for various situations. Here is a list of the best pragmatic principles I’ve learned to better design. In spite of their obviousness and renown, my experience has shown me that some of these principles are often forgotten.</p>

<p><strong>Fun fact</strong>: In english, <em>to design</em> means both <em>to draw</em> and <em>to conceive according to a plan</em>. Similarly in French, the word <em>dessin</em> (a drawing) derives its etymology from the word <em>dessein</em> (have the intention).</p>

<h2 id="incremental-improvement">Incremental improvement</h2>

<p>Believing you can do it right the first time is naive at best, pretentious at worst. <strong>You will fail and have to accept it</strong>. Do not postpone but instead <strong>release fast</strong>, get feedback early and iterate to make it better. You will find many references, notably on Lean Startup, DevOps culture or Site Reliability Engineering, which encourage <strong>a quick redesign capability rather than a perfect design at the first place</strong>.</p>

<blockquote>
  <p>To write clean code, you must first write dirty code and then clean it. […]
Learning to write clean code is hard work. It requires more than just the knowledge of principles and patterns. You must sweat over it. You must practice it yourself, and watch yourself fail. Robert C. Martin — Clean Code: A Handbook of Agile Software Craftsmanship</p>
</blockquote>

<h2 id="reuse-what-exists">Reuse what exists</h2>

<p>It is unlikely that the problem you face is fundamentally new. Before making any effort, look for <strong>existing solutions</strong> or proven practices. <strong>Be humble</strong> and accept you can’t compete with years of expertise on a subject. If so, the motivation to develop the new model must come from reaching the limits of the previous one. In software engineering for instance, <a href="https://en.wikipedia.org/wiki/Software_design_pattern">design patterns</a> are formalized best practices that the programmer can use to solve common problems when designing an application or system.</p>

<p>Don’t limit yourself to the area of the original problem, sometimes a similar problem has been found and solved long before in <strong>a different field</strong>. Learn about <a href="https://en.wikipedia.org/wiki/Queueing_theory">queuing theory</a> will help you to write an operating system scheduler as well as being frustrated in a supermarket queue. Solutions come from fields of experiences and theories that you would not necessarily expect.</p>

<h2 id="five-whys">Five whys</h2>

<p>The <a href="https://en.wikipedia.org/wiki/Five_whys">Five whys technique</a>, originally developed by Toyota, has been mostly used for exploring the root cause of a defect in a system. It involves asking the relevant question starting with a why in order to find the source which cause the failure. Adapt this technique to find out what really matter in our design. For example, “<em>We need a program which exports our documentation to PDF</em>”:</p>

<ol>
  <li>Why? - So the export can go on the website.</li>
  <li>Why? - Because our customers has to read it.</li>
  <li>Why? - Because they require it to maintain the software.</li>
  <li>Why (don’t they have access to the documentation like everyone else)? - Because they haven’t been integrated into our platform.</li>
  <li>Why? Because they have never been on-board on the platform.</li>
</ol>

<p><strong>Decision</strong>: instead of developing a complex program which exports PDF, write a simple on-boarding guide for the customers.</p>

<p>This situation often occurs when the given requirement includes the design. Before answering the question <em>“How do we do it?”</em> directly, the first and most important step is to remember “<em>Why do we do it?</em>”. Once you have understood the <strong>root reasons</strong> and constraints for the requirement, it clears the path on how to get there and can <strong>prevent</strong> you from taking <strong>very long detours</strong> in addition to <strong>simplifying</strong> the design.</p>

<h2 id="keep-it-simple-stupid">Keep it simple stupid</h2>

<p><strong>Resolve problems, don’t create them</strong>. You should be suspicious of providing a solution that makes the overall system more complicated than before. Remember: You’ll have to maintain everything you build, so you’d better build as little and simply as possible.</p>

<p>Simple designs are easy to <strong>learn</strong>, easy to <strong>teach</strong>, easy to <strong>use</strong> and therefore easily <strong>appeal</strong> to customers. It forces the design to be intuitive and obvious, reducing the learning curve and facilitates the adoption. Like Denis Diderot says in Pensées sur l’interprétation de la nature:</p>

<blockquote>
  <p>These books [of Sthal and Newton] were just waiting to be heard, to be valued for what they were worth; and it would not have cost their authors more than a month to make them clear; that month would have spared three years of labor and exhaustion to a thousand good spirits.</p>
</blockquote>

<p>But what is a simple design? In the <a href="https://landing.google.com/sre/sre-book/chapters/simplicity/">Simplicity chapter of the Site Reliability Engineering</a> book of Google, they mention a great quote from the French poet Antoine de Saint Exupery about perfection which could fit very well with simplicity:</p>

<blockquote>
  <p>perfection is finally attained not when there is no longer more to add, but when there is no longer anything to take away - A. de Saint Exupéry, Terre des Hommes</p>
</blockquote>

<h2 id="perfect-is-the-enemy-of-good-enough">Perfect is the enemy of good enough</h2>

<p><a href="https://www.pinterest.de/pin/397724210839705109/"><img src="https://reflexio.debec.eu/assets/moka-pot.svg" alt="moka"></a></p>

<p>The moka coffee maker may not produce perfect coffee, but it requires so little maintenance compared to a large coffee machine with radiators, pipes, grinder, etc. that it makes the compromise “complexity / coffee taste” great.</p>

<p>Remember the <a href="https://en.wikipedia.org/wiki/Pareto_principle">Pareto principle</a>: in general <strong>80% of a things can be done in 20%</strong> of the total allocated time. Conversely, the hardest <strong>20% left takes 80%</strong> of the time. Perfection requires infinite time and energy. This is impossible and therefore should not be part of your design.</p>

<blockquote>
  <p>Beware of the perfection pitfall and design your architecture only as good as necessary and not as good as ultimate possible. - Ralf S. Engelschall</p>
</blockquote>

<h2 id="postpone-complexity">Postpone complexity</h2>

<p>Simplicity and incremental improvement principles give birth to a another principle: <strong>Postpone complexity</strong>. Complexity lies in early optimization, as Donald E. Knuth points out in his article <a href="https://dl.acm.org/doi/pdf/10.1145/361604.361612?download=true">Computer Programming as Art</a> with “<em>premature optimization is the root of all evil</em>”. Focus on designing something that works instead of something finely tune that does not.</p>

<p>Complexity lies also in early generalization. Focus on designing something that works in a single use case rather than something that will not work in many. When designing a coffee machine, first design something that makes a simple black coffee. If you plan ahead to include all extra options for latte, cappuccino or irish coffee you will end up not making a simple back coffee. As elegantly summarized by Ralf S. Engelschall: “<em>Use before reuse</em>”.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Do you think there’s a principle missing? Send me your comments! This list will certainly be extended and refined, subscribe to the <a data-formkit-toggle="78a863d4eb" href="https://reflexio-debec.ck.page/78a863d4eb">newsletter</a> if you wish to be notified about it. In the meantime, how are you going to ensure that you do not forget to implement the principles you have just learned?</p>

    </div></div>]]>
            </description>
            <link>https://reflexio.debec.eu/principles-for-better-design</link>
            <guid isPermaLink="false">hacker-news-small-sites-23837939</guid>
            <pubDate>Tue, 14 Jul 2020 21:10:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding and writing a JPEG decoder in Python]]>
            </title>
            <description>
<![CDATA[
Score 243 | Comments 35 (<a href="https://news.ycombinator.com/item?id=23837838">thread link</a>) | @sfpoet
<br/>
July 14, 2020 | https://yasoob.me/posts/understanding-and-writing-jpeg-decoder-in-python/ | <a href="https://web.archive.org/web/*/https://yasoob.me/posts/understanding-and-writing-jpeg-decoder-in-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">
			<span>
				<a target="_blank" href="https://github.com/yasoob/personal_blog/tree/master/content/posts/understanding-and-writing-jpeg-decoder-in-python.md">Source</a>
			</span>
			
				<p><img src="https://d33wubrfki0l68.cloudfront.net/797fe040e65dc288b7f22489dbad160e1e4998b8/0496b/images/decoding_jpeg/hero-image.png">
				</p>
			
			
			<span>
				
				<time itemprop="datePublished" datetime="2020-07-14">July 14, 2020</time>
				
			</span>
			<section itemprop="entry-text">
				

<p>Hi everyone! 👋 Today we are going to understand the JPEG compression algorithm. One thing a lot of people don’t know is that JPEG is not a format but rather an algorithm. The JPEG images you see are mostly in the JFIF format (JPEG File Interchange Format) that internally uses the JPEG compression algorithm. By the end of this article, you will have a much better understanding of how the JPEG algorithm compresses data and how you can write some custom Python code to decompress it. We will not be covering all the nuances of the JPEG format (like progressive scan) but rather only the basic baseline format while writing our decoder.</p>

<h2 id="introduction">Introduction</h2>

<p>Why write another article on JPEG when there are already hundreds of articles on the internet? Well, normally when you read articles on JPEG, the author just gives you details about what the format looks like. You don’t implement any code to do the actual decompression and decoding. Even if you do write code, it is in C/C++ and not accessible to a wide group of people. I plan on changing that by showing you how a basic JPEG decoder works using Python 3. I will be basing my decoder on <a href="https://github.com/aguaviva/micro-jpeg-visualizer/blob/master/micro-jpeg-visualizer.py">this</a> MIT licensed code but will be heavily modifying it for increased readability and ease of understanding. You can find the modified code for this article on my  <a href="https://github.com/yasoob/Baseline-JPEG-Decoder">GitHub repo</a>.</p>

<h2 id="different-parts-of-a-jpeg">Different parts of a JPEG</h2>

<p>Let’s start with this nice image by <a href="https://twitter.com/angealbertini">Ange Albertini</a>. It lists all different parts of a simple JPEG file. Take a look at it. We will be exploring each segment. You might have to refer to this image quite a few times while reading this tutorial.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/bdc1363abbd5744200ec5283d4154e55143df86c/8c624/images/decoding_jpeg/jpegrgb_dissected.png" alt="JPEGRGB_dissected.png"></p>

<p>At the very basic level, almost every binary file contains a couple of markers (or headers). You can think of these markers as sort of like bookmarks. They are very crucial for making sense of a file and are used by programs like <code>file</code> (on Mac/Linux) to tell us details about a file. These markers define where some specific information in a file is stored. Most of the markers are followed by <code>length</code> information for the particular marker segment. This tells us how long that particular segment is.</p>

<h3 id="file-start-file-end">File Start &amp; File End</h3>

<p>The very first marker we care about is <code>FF D8</code>. It tells us that this is the start of the image. If we don’t see it we can assume this is some other file. Another equally important marker is <code>FF D9</code>. It tells us that we have reached the end of an image file. Every marker, except for <code>FFD0</code> to <code>FFD9</code> and <code>FF01</code>, is immediately followed by a length specifier that will give you the length of that marker segment. As for the image file start and image file end markers, they will always be two bytes long each.</p>

<p>Throughout this tutorial, we will be working with this image:</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/7344493a5ee7126f8286dd83ade191cab9e7f292/fbea3/images/decoding_jpeg/profile.jpg" alt="Profile"></p>

<p>Let’s write some code to identify these markers.</p>

<pre><code>from struct import unpack


marker_mapping = {
    0xffd8: "Start of Image",
    0xffe0: "Application Default Header",
    0xffdb: "Quantization Table",
    0xffc0: "Start of Frame",
    0xffc4: "Define Huffman Table",
    0xffda: "Start of Scan",
    0xffd9: "End of Image"
}


class JPEG:
    def __init__(self, image_file):
        with open(image_file, 'rb') as f:
            self.img_data = f.read()
    
    def decode(self):
        data = self.img_data
        while(True):
            marker, = unpack("&gt;H", data[0:2])
            print(marker_mapping.get(marker))
            if marker == 0xffd8:
                data = data[2:]
            elif marker == 0xffd9:
                return
            elif marker == 0xffda:
                data = data[-2:]
            else:
                lenchunk, = unpack("&gt;H", data[2:4])
                data = data[2+lenchunk:]            
            if len(data)==0:
                break        

if __name__ == "__main__":
    img = JPEG('profile.jpg')
    img.decode()    

# OUTPUT:
# Start of Image
# Application Default Header
# Quantization Table
# Quantization Table
# Start of Frame
# Huffman Table
# Huffman Table
# Huffman Table
# Huffman Table
# Start of Scan
# End of Image
</code></pre>

<p>We are using <a href="https://docs.python.org/3/library/struct.html">struct</a> to unpack the bytes of image data. <code>&gt;H</code> tells <code>struct</code> to treat the data as big-endian and of type <code>unsigned short</code>. The data in JPEG is stored in big-endian format. Only the EXIF data <em>can</em> be in little-endian (even though it is uncommon). And a short is of size 2 so we provide <code>unpack</code> two bytes from our <code>img_data</code>. You might ask yourself how we knew it was a <code>short</code>. Well, we know that the markers in JPEG are 4 hex digits: <code>ffd8</code>. One hex digit equals 4 bits (<sup>1</sup>⁄<sub>2</sub> byte) so 4 hex digits will equal 2 bytes and a short is equal to 2 bytes.</p>

<p>The Start of Scan section is immediately followed by image scan data and that image scan data doesn’t have a length specified. It continues till the “end of file” marker is found so for now we are manually “seeking” to the EOF marker whenever we see the SOC marker.</p>

<p>Now that we have the basic framework in place, let’s move on and figure out what the rest of the image data contains. We will go through some necessary theory first and then get down to coding.</p>

<h2 id="encoding-a-jpeg">Encoding a JPEG</h2>

<p>I will first explain some basic concepts and encoding techniques used by JPEG and then decoding will naturally follow from that as a reverse of it. In my experience, directly trying to make sense of decoding is a bit hard.</p>

<p>Even though the image below won’t mean much to you right now, it will give you some anchors to hold on to while we go through the whole encoding/decoding process. It shows the steps involved in the JPEG encoding process: (<a href="https://users.cs.cf.ac.uk/Dave.Marshall/Multimedia/node234.html">src</a>)</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/7237dd0093b6a8070b2c927673fd73bc797561d2/33b0a/images/decoding_jpeg/encoding.png" alt="JPEG Encoding process"></p>

<h3 id="jpeg-color-space">JPEG Color Space</h3>

<p>According to the JPEG spec (<a href="http://www.itu.int/rec/T-REC-T.872-201206-I/en">ISO/IEC 10918-6:2013 (E)</a>, section 6.1):</p>

<blockquote>
<ul>
<li>Images encoded with only one component are assumed to be grayscale data in which 0 is black and 255 is white.</li>
<li>Images encoded with three components are assumed to be RGB data encoded as YCbCr unless the image contains an APP14 marker segment as specified in 6.5.3, in which case the color encoding is considered either RGB or YCbCr according to the application data of the APP14 marker segment. The relationship between RGB and YCbCr is defined as specified in Rec. ITU-T T.871 | ISO/IEC 10918-5.</li>
<li>Images encoded with four components are assumed to be <strong>CMYK</strong>, with (0,0,0,0) indicating white unless the image contains an APP14 marker segment as specified in 6.5.3, in which case the color encoding is considered either <strong>CMYK</strong> or <strong>YCCK</strong> according to the application data of the APP14 marker segment. The relationship between <strong>CMYK</strong> and <strong>YCCK</strong> is defined as specified in clause 7.</li>
</ul>
</blockquote>

<p>Most JPEG algorithm implementations use luminance and chrominance (YUV encoding) instead of RGB. This is super useful in JPEG as the human eye is pretty bad at seeing high-frequency brightness changes over a small area so we can essentially reduce the amount of frequency and the human eye won’t be able to tell the difference. Result? A highly compressed image with almost no visible reduction in quality.</p>

<p>Just like each pixel in RGB color space is made up of 3 bytes of color data (Red, Green, Blue), each pixel in YUV uses 3 bytes as well but what each byte represents is slightly different. The Y component determines the brightness of the color (also referred to as luminance or luma), while the U  and V components determine the color (also known as chroma). The U component refers to the amount of blue color and the V component refers to the amount of red color.</p>

<p>This color format was invented when color televisions weren’t super common and engineers wanted to use one image encoding format for both color and black and white televisions. YUV could be safely displayed on a black and white TV if color wasn’t available. You can read more about its history on <a href="https://www.wikiwand.com/en/YUV">Wikipedia</a>.</p>

<h3 id="discrete-cosine-transform-quantization">Discrete Cosine Transform &amp; Quantization</h3>

<p>JPEG converts an image into chunks of 8x8 blocks of pixels (called MCUs or Minimum Coding Units), changes the range of values of the pixels so that they center on 0 and then applies Discrete Cosine Transformation to each block and then uses quantization to compress the resulting block. Let’s get a high-level understanding of what all of these terms mean.</p>

<p>A Discrete Cosine Transform is a method for converting discrete data points into a combination of cosine waves. It seems pretty useless to spend time converting an image into a bunch of cosines but it makes sense once we understand DCT in combination with how the next step works. In JPEG, DCT will take an 8x8 image block and tell us how to reproduce it using an 8x8 matrix of cosine functions.  <a href="https://www.impulseadventure.com/photo/jpeg-minimum-coded-unit.html">Read more here</a>)</p>

<p>The 8x8 matrix of cosine functions look like this:</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/97f11adca54888172fc19cef52e514ef0e8b46fd/1a72e/images/decoding_jpeg/cosine-funcs.png" alt="Cosine functions"></p>

<p>We apply DCT to each component of a pixel separately. The output of applying DCT is an 8x8 coefficient matrix that tells us how much each cosine function (out of 64 total functions) contributes to the 8x8 input matrix. The coefficient matrix of a DCT generally contains bigger values in the top left corner of the coefficient matrix and smaller values in the bottom right corner. The top left corner represents the lowest frequency cosine function and the bottom right represents the highest frequency cosine function.</p>

<p>What this tells us is that most images contain a huge amount of low-frequency information and a small amount of high-frequency information. If we turn the bottom right components of each DCT matrix to 0, the resulting image would still appear the same because, as I mentioned, humans are bad at observing high-frequency changes. This is exactly what we do in the next step.</p>

<p>I found a wonderful video on this topic. Watch it if DCT doesn’t make too much sense.</p>

<iframe width="560" height="326" src="https://www.youtube.com/embed/Q2aEzeMDHMA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>We have all heard that JPEG is a lossy compression algorithm but so far we haven’t done anything lossy. We have only transformed 8x8 blocks of YUV components into 8x8 blocks of cosine functions with no loss of information. The lossy part comes in the quantization step.</p>

<p>Quantization is a process in which we take a couple of values in a specific range and turns them into a discrete value. For our case, this is just a fancy name for converting the higher …</p></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://yasoob.me/posts/understanding-and-writing-jpeg-decoder-in-python/">https://yasoob.me/posts/understanding-and-writing-jpeg-decoder-in-python/</a></em></p>]]>
            </description>
            <link>https://yasoob.me/posts/understanding-and-writing-jpeg-decoder-in-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23837838</guid>
            <pubDate>Tue, 14 Jul 2020 21:03:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Manager Can’t Code? They Shouldn’t Be Your Manager]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 57 (<a href="https://news.ycombinator.com/item?id=23837614">thread link</a>) | @lanecwagner
<br/>
July 14, 2020 | https://qvault.io/2020/07/14/your-manager-cant-code-they-shouldnt-be-your-manager/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/07/14/your-manager-cant-code-they-shouldnt-be-your-manager/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>Managers who can’t code are an outdated artifact of corporate America circa 2005. The best managers that I’ve had spend ~80% of their time coding, architecting, or doing technical work that requires engineering prowess. If your manager thinks coding is “beneath” them then they need a dose of humble pie. Your organization would likely be better off without them.</p>



<h2><span id="But_Managers_Manage_People">But Managers Manage <em>People</em>!</span>
</h2>



<p>There is a long-running stigma associated with developers, that we are all geeks who can’t handle interpersonal relationships. Due to our code monkey nature, we need “people people” who can go to meetings for us and communicate our efforts effectively to the higher-ups.</p>



<div><figure><img src="https://qvault.io/wp-content/uploads/2020/07/joke-extrovert.jpg" alt="introverted programmers are an outdated meme" srcset="https://qvault.io/wp-content/uploads/2020/07/joke-extrovert.jpg 700w, https://qvault.io/wp-content/uploads/2020/07/joke-extrovert-300x184.jpg 300w" sizes="(max-width: 700px) 100vw, 700px" data-srcset="https://qvault.io/wp-content/uploads/2020/07/joke-extrovert.jpg 700w, https://qvault.io/wp-content/uploads/2020/07/joke-extrovert-300x184.jpg 300w" data-src="https://qvault.io/wp-content/uploads/2020/07/joke-extrovert.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure></div>



<p>While the above is still funny, it’s <em>outdated</em>. As the developer community has grown exponentially in the last 20 years, so too has the personality diversity amongst its members. In other words, it is<strong> not hard to find developers with the soft-skills </strong>necessary for management positions.</p>



<h2><span id="Managers_Should_Help">Managers Should Help</span>
</h2>



<p>I am a firm believer in the following:</p>



<figure><img src="https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA.png" alt="" srcset="https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA.png 1024w, https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA-300x150.png 300w, https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA-768x384.png 768w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA.png 1024w, https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA-300x150.png 300w, https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA-768x384.png 768w" data-src="https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure><p>While the manager doesn’t need to be the most talented developer on the team, they must at least be technically literate. When a team member goes to their boss with a technical proposal, the manager should be able to give valuable feedback.</p>



<p>In this <a href="https://hbr.org/2016/12/if-your-boss-could-do-your-job-youre-more-likely-to-be-happy-at-work">study from Harvard</a> 35,000 employees from the US and Great Britain were polled about their job satisfaction, and metrics were gathered about what influenced their happiness at work. The results showed that the <em>single greatest influencing factor </em>on employee satisfaction was whether or not their boss was technically competent. I practice what I preach, so at the <a href="https://classroom.qvault.io/">Qvault app,</a> all engineering leadership will forever be responsible for pushing code.</p>



<p>Contrast the idea of a competent boss with the all-too-familiar experience of going to a <a href="https://qvault.io/2020/05/18/leave-scrum-to-rugby-i-like-getting-stuff-done/">non-technical middle-management type</a> with an engineering problem, only to be stuck in a teaching session because the boss has never heard of a pub-sub system.</p>



<figure><img src="https://qvault.io/wp-content/uploads/2020/07/9e3a6f35f44188bad76c100f3560ce69.gif" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure><h2><span id="Managers_Need_Empathy">Managers Need Empathy</span>
</h2>



<p>A good manager has empathy for those who report to them. If the boss doesn’t code or hasn’t written code in a long time, they won’t understand the daily problems that their team is faced with. A good engineering leader will not only understand modern problems, but they make it their role to actively seek technical solutions in an ever-changing innovative landscape.</p>



<h2><span id="INB4_So_the_CEO_needs_to_be_able_to_code">INB4: “So the CEO needs to be able to code?”</span>
</h2>



<p>No, but the CTO does!</p>



<p>I am sympathetic to the idea that the CTO will have plenty of business and product-related work to focus on, but they can’t let their technical chops slip. In order to run the engineering arm of an innovative company, the person at the top should have a firm mental grasp on the implementation difficulties. If this just means reviewing architectural diagrams and reviewing pull-requests so be it, but nothing beats hands-on engineering work to stay sharp.</p>



<h2><span id="Feedback_Please">Feedback Please</span>
</h2>



<p>Have you had problems with non-technical leaders, or do you disagree completely with my opinions? Let me know through one of my <a href="https://qvault.io/contact/">social profiles</a>.</p>



<div><div>
<h2><span id="Thanks_For_Reading">Thanks For Reading</span>
</h2>



<p>Follow us on Twitter <a href="https://twitter.com/q_vault">@q_vault</a> if you have any questions or comments</p>



<p>Take game-like coding courses on <a href="https://classroom.qvault.io/#/">Qvault Classroom</a></p>



<p><a href="https://mailchi.mp/5c7f5c281bbe/qvault-newsletter-subscribe">Subscribe</a> to our Newsletter for more educational articles</p>
</div></div>



<h2><span id="Related_Articles">Related Articles:</span>
</h2>



<ul><li><a href="https://qvault.io/2020/05/18/leave-scrum-to-rugby-i-like-getting-stuff-done/">Leave Scrum to Rugby, I Like Getting Stuff Done</a></li></ul>



		</div></div>]]>
            </description>
            <link>https://qvault.io/2020/07/14/your-manager-cant-code-they-shouldnt-be-your-manager/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23837614</guid>
            <pubDate>Tue, 14 Jul 2020 20:46:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Failed SquadGoals: Spotify doesn’t use the Spotify model and neither should you]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23837535">thread link</a>) | @wahnfrieden
<br/>
July 14, 2020 | https://www.jeremiahlee.com/posts/failed-squad-goals/?hn | <a href="https://web.archive.org/web/*/https://www.jeremiahlee.com/posts/failed-squad-goals/?hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<!-- Spread 1 -->
<section>
<section>
<video autoplay="true" muted="true" loop="true">
<source srcset="https://www.jeremiahlee.com/posts/failed-squad-goals/cover.png" media="(prefers-reduced-motion: reduce)">
<source src="https://www.jeremiahlee.com/posts/failed-squad-goals/cover.webm" type="video/webm">
<source src="https://www.jeremiahlee.com/posts/failed-squad-goals/cover.m4v" type="video/mp4">
<img src="https://www.jeremiahlee.com/posts/failed-squad-goals/cover.png" alt="Taylor Swift and her squad walking away from an explosion in front of the Spotify office at Birger Jarlsgatan.">
</video>
</section>
<section>
<div>

<p><b>Spotify</b> doesn’t use <em>“the Spotify model”</em><br>and neither should you.</p>
<p>By Jeremiah Lee</p>
<p>Sunday, April 19, 2020 • <a href="https://anchor.fm/jeremiah-oral-lee/episodes/Spotifys-Failed-SquadGoals-edia0p">Listen</a> •&nbsp;<a href="https://oyomy.fr/2020/04/l-echec-du-modele-spotify/" hreflang="fr">En français</a> •&nbsp;<a href="https://jp.quora.com/q/agile/Spotify%E3%81%AF-Spotify%E3%83%A2%E3%83%87%E3%83%AB-%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6%E3%81%84%E3%81%AA%E3%81%84" hreflang="ja">日本語で</a> • <a href="https://flavioclesio.com/2020/05/18/o-modelo-de-squadgoals-do-spotify-falhou/" hreflang="pt-br">Português (Brasil)</a></p>
</div>
</section>
</section>
<!-- Spread 2 -->
<section>
<section>
<div>
<p>Of all the allures of startup culture, few are more desireable than the speed and nimbleness of a small team. Maintaining that feeling as a company grows is a challenge. In 2012, Spotify shared its way of working and suggested it had figured it out.<sup><a href="#1">1</a></sup></p>
<p>I was excited to see <em>the Spotify model</em> in action when I interviewed for a product management role at its Stockholm headquarters in 2017. However, the recruiter surprised me before the first interview. She cautioned me to not expect Spotify to be an <a href="https://en.wikipedia.org/wiki/Agile_software_development">Agile</a> utopia.</p>
<p>I joined the company after it had tripled in size to 3,000 people over 18 months. I learned the famed squad model was only ever aspirational and never fully implemented. I witnessed organizational chaos as the company’s leaders incrementally transitioned to more traditional management structures.</p>
<p>When I asked my coworkers why the content was not removed or updated to reflect reality, I never got a good answer. Many people ironically thought the posts were great for recruiting. I no longer work at Spotify, so I am sharing my experience to set the record straight. The Spotify squad model failed Spotify and it will fail your company too.</p>
</div>
</section>
<section>
<div>
<h3>But you don’t have to take my word for it.</h3>
<p>The co-author of the Spotify model<sup><a href="#2">2</a></sup> and multiple agile coaches who worked at Spotify have been telling people to not copy it for years. Unfortunately, truth doesn’t spread as quickly or as widely as an idea people want to believe in.</p>
<blockquote>
<p>“Even at the time we wrote it, we weren’t doing it. It was part ambition, part approximation. People have really struggled to copy something that didn’t really exist.”</p>
</blockquote>
<p>—Joakim Sundén, agile coach at Spotify&nbsp;2011–2017<sup><a href="#4">4</a></sup></p>
<blockquote>
<p><em>“It worries me when people look at what we do and think it’s a framework they can just copy and implement.</em> … We are really trying hard now to emphasize we have problems as well. It’s not all ‘shiny and everything works well and all our squads are super amazing’.”</p>
</blockquote>
<p>—Anders Ivarsson, co-author of the Spotify&nbsp;whitepaper<sup><a href="#3">3</a></sup></p>
</div>
</section>
</section>
<!-- Spread 3 -->
<section>
<section>
<div>
<h2>Recap</h2>
<p>You can read and watch the <a href="#1">original content</a> in less than 30 minutes or <a href="#spread-4">skip to the next section</a> if you are familiar. Here is a brief summary.</p>
<p>Spotify had teams it called <em>squads</em> because it sounded cooler (not joking). A group of teams were organized into a department called a <em>tribe</em>. Each team was intended to be an autonomous mini-startup, with a product manager acting as mini-CEO for a feature area. The teams had designers and software engineers with a range of specializations. The intent was that a team should have every skill necessary without needing to rely on another team for success.</p>
<p>Product managers had a traditional management structure. A product manager for a team reported to their department’s product director (<em>“tribe lead”</em>). Same for designers. Software engineers, however, were managed outside of the team structure.</p>
</div>
</section>
<section>
<div>
<p><em>“Chapter leads”</em> managed software engineers specializing in a specific type of software development across the department. For example, all of the software engineers working on backend APIs across all the teams within the department would have one manager and all of the Android mobile engineers in the department would have a different manager. The intent was to allow engineers to be moved between teams within the department to best meet business requirements without them having to change managers.</p>
<figure>
<video autoplay="true" muted="true" loop="true">
<source src="https://www.jeremiahlee.com/posts/failed-squad-goals/scaling-spotify-squads.webm" type="video/webm">
<source src="https://www.jeremiahlee.com/posts/failed-squad-goals/scaling-spotify-squads.m4v" type="video/mp4">
<img src="https://www.jeremiahlee.com/posts/failed-squad-goals/scaling-spotify-squads.png" alt="Spotify matrix organization diagram. A department is called a tribe and has multiple squads, another name for a team. Each squad has a product owner, another name for a product manager. Software engineers of the same discipline across multiple teams are called a chapter and managed by a chapter lead, another name for an engineering manager.">
</video>
<figcaption>Spotify tried a long-lived matrix team structure with unusual word choices.<sup><a href="#1">1</a></sup> It did not work well.</figcaption>
</figure>
</div>
</section>
</section>
<!-- Spread 4 -->
<section id="spread-4">
<section>

</section>
<section id="matrix-management-sucks">
<div>
<h3>Matrix management solved the wrong problem</h3>
<p>The “full stack” agile team worked well, but the matrix management of software engineers introduced more problems than it solved.</p>
<ul>
<li><p>Teams at Spotify were rather long-lived. The benefit of not having to change manager when moving to another team was limited.</p></li>
<li><p>Engineering managers in this model had little responsibility beyond the career development of the people they managed. Even then, their ability to help with interpersonal people skills development was limited. An engineering manager would not manage enough of the other people on the team or be involved enough in the daily context to independently assess conflict within the team.</p></li>
</ul>
</div>
</section>
</section>
<!-- Spread 5 -->
<section>
<section>
<div>
<ul>
<li><p>Without a single engineering manager responsible for the engineers on a team, the product manager lacked an equivalent peer—the mini-CTO to their mini-CEO role. There was no single person accountable for the engineering team’s delivery or who could negotiate prioritization of work at an equivalent level of responsibility.</p><p>When disagreements within the engineering team arose, the product manager needed to negotiate with all of the engineers on the team. If the engineers could not reach a consensus, the product manager needed to escalate to as many engineering managers as there were engineering specializations within the team. A team with backend, Web app, and mobile app engineers would have at least 3 engineering managers who might need to get involved. If those engineering managers could not reach a consensus, a single team’s issue would have to escalate to the department’s engineering director.</p></li>
</ul>
</div></section>
<section id="matrix-management-sucks">
<div>
<blockquote>
<p>“Chapter leads are servant-leaders who help you grow as an individual. They don’t really work with any team. They have direct reports on all the teams. They don’t have really any accountability for the delivery. They aren’t taking that responsibility. It’s easy to see the product owner as the manager for the team.”</p>
</blockquote>
<p>—Joakim Sundén, agile coach at Spotify<sup><a href="#4">4</a></sup></p>
<p><strong>Learn from Spotify’s mistakes:</strong></p>
<ul>
<li>A product—design—engineering team typically contains more engineers than designers or product managers. Having a single engineering manager for the engineers on the team creates an accountable escalation path for conflict within the team.</li>
<li>Product managers should have an equivalent peer for engineering. Product managers should be accountable for the prioritization of work. Engineering managers should be accountable for the engineers’ execution, which includes being able to negotiate speed and quality tradeoffs with the product manager.</li>
</ul>
</div>
</section>
</section>
<!-- Spread 6 -->
<section>
<section id="too-much-autonomy">
<div>
<h3>Spotify fixated on team autonomy</h3>
<p>When a company is small, teams have to do a wide range of work to deliver and have to shift initiatives frequently. As a company grows from startup to scale-up, duplicated functions across teams move to new teams dedicated to increasing organization efficiency by reducing duplication. With more teams, the need for a team to shift initiative decreases in frequency. Both of these changes allow for teams to think more deeply and long term about the problems they are scoped to solve. Faster iteration, however, is not guaranteed. Every responsibility a team cedes to increase its focus becomes a new cross-team dependency.</p>
<p>Spotify did not define a common process for cross-team collaboration. Allowing every team to have a unique way of working meant each team needed a unique way of engagement when collaborating. Overall organization productivity suffered.</p>
<p>The Spotify model was documented when Spotify was a much smaller company. It was supposed to be a multiple part series, according to Anders Ivarsson. Autonomy made the first cut, but the parts on alignment and accountability were never completed.</p>
</div>
</section>
<section>
<div>
<p><strong>Learn from Spotify’s mistakes:</strong></p>
<ul>
<li>Autonomy requires alignment. Company priorities must be defined by leadership. Autonomy does not mean teams get to do whatever they want.</li>
<li>Processes for cross-team collaboration must be defined. Autonomy does not mean leaving teams to self-organize every problem.</li>
<li>How success is measured must be defined by leadership so people can effectively negotiate cross-team dependency prioritization.</li>
<li>Autonomy requires accountability. Product management is accountable for value. The team is accountable for delivering ‘done’ increments. Mature teams can justify their independence with their ability to articulate business value, risk, learning, and the next optimal move.<sup><a href="#6">6</a></sup></li>
</ul>
</div>
</section>
</section>
<!-- Spread 7 -->
<section>
<section id="too-much-autonomy">
<div>
<blockquote>
<p>“If I were to do one thing differently, I would say we should not be focusing so much on autonomy.</p>
<p>“Every time you have a new team, they have to reinvent the wheel in how they should be working. Maybe, just maybe, we should have a ‘minimum viable agility’. You start with that. You are free to opt out, but people shouldn’t have to opt-in all the time.</p>
<p>“At what point do you start inserting this process? Probably when it’s too late.”</p>
</blockquote>
<p>—Joakim Sundén, agile coach at Spotify<sup><a href="#4">4</a></sup></p>
</div>
</section>
<section>
<div>
<blockquote>
<p>“Henrik Kniberg talked about how we're not that good at large initiatives and we’re still not that good at large initiatives.</p>
<p>“If you have inconsistent ways of working, it’s more difficult for people to move. If it’s more difficult for people to move, it’s more likely you have inconsistent ways of working. It will just reinforce until all of a sudden, you’re not really working for the same company anymore. You’re working for these kind of weird subcultures.”</p>
</blockquote>
<p>—Jason Yip, agile coach at Spotify<br>2015–time of writing<sup><a href="#5">5</a></sup></p>
</div>
</section>
</section>
<!-- Spread 8 -->
<section>
<section id="collaboration-is-a-competency">
<div>
<h3>Collaboration was an assumed competency</h3>
<p>While Spotify gave teams control over their way of working, many people did not have a basic understanding of Agile practices. This resulted in teams iterating through process tweaks in blind hope of finding the combination that would help them improve their delivery. People lacked a common language to effectively discuss the process problems, the education to solve them, and the experience to evaluate performance. It was not really <em>agile</em>. It was just <em>not-waterfall</em>.</p>
<p><em>“Agile coaches”</em> were internal consultants Spotify provided teams to teach and suggest process improvements. While well-intentioned, there were not enough coaches to help every team. A coach’s engagement with a team was rarely long enough to span a project’s completion to help a team evaluate performance. More so, they were not accountable for anything.</p>
</div>
</section>
<section>
<div>
<blockquote>
<p>“Control without competence is chaos.”</p>
</blockquote>
<p>—L. David Marquet, <a href="https://www.indiebound.org/book/9781591846406"><cite>Turn the Ship Around!</cite></a></p>
<p><strong>Learn from Spotify’s …</strong></p></div></section></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.jeremiahlee.com/posts/failed-squad-goals/?hn">https://www.jeremiahlee.com/posts/failed-squad-goals/?hn</a></em></p>]]>
            </description>
            <link>https://www.jeremiahlee.com/posts/failed-squad-goals/?hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-23837535</guid>
            <pubDate>Tue, 14 Jul 2020 20:40:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to spot and fix the biggest UI problems if you are developer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23837398">thread link</a>) | @semy
<br/>
July 14, 2020 | https://www.lunadio.com/blog/how-to-spot-and-fix-the-biggest-ui-problems | <a href="https://web.archive.org/web/*/https://www.lunadio.com/blog/how-to-spot-and-fix-the-biggest-ui-problems">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>We are in the new „super-agile” era, an in many cases low-cost MVP’s are being built, that skip the Designer role for financial reasons.</p><p>There are great design systems and free libraries out there, so even the developers can create something that looks high-fidelity enough for initial user testing and idea validation.</p><p>Whether it is adapting a design system, or coding your own based on some inspirations, there are some problems you’re going to encounter along the way. I believe it’s important for developers to understand design, and the reason many don’t dive into it, is because of a big misconception:</p><h2 id="im-not-an-artist">I’m not an artist</h2><p>UI Design is as far from art, as development. Obviously you can add illustrations to your project, but that’s the one piece of artwork in the entire process and it’s usually done by an illustrator, not the designer.</p><h3 id="what-is-ui-design">What is UI Design?</h3><p>Interface design is closer to development than art. That is because it’s actually based on a strict set of rules and a heavy use of consistent number values. Understanding these rules will help you apply the right numbers in the right places and “fix your implementation”.</p><h2 id="rule-1-spacing">Rule 1: Spacing</h2><p><span>
      <span></span>
  <picture>
        <source srcset="https://www.lunadio.com/static/113b1963ec589c177a93bcfeed8191e5/06fd5/1_muc-nmkmrdx9lxn2_kig_g.webp 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/webp">
        <source srcset="https://www.lunadio.com/static/113b1963ec589c177a93bcfeed8191e5/f6cdf/1_muc-nmkmrdx9lxn2_kig_g.png 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/png">
        <img src="https://www.lunadio.com/static/113b1963ec589c177a93bcfeed8191e5/f6cdf/1_muc-nmkmrdx9lxn2_kig_g.png" alt="Well spaced image on the left, and a chaotic one on the right.">
      </picture>
    </span></p><p>Grid systems deserve their own, separate article, but there are some basics alignment tips and techniques you can use right now to move your project to the next level.</p><p>The main thing to remember is the rule of proximity. But to avoid “industry definition” let’s break it down into plain english:</p><p><span>
      <span></span>
  <picture>
        <source srcset="https://www.lunadio.com/static/039df04f65b16f9e8823f7870484c554/06fd5/1_qe70feh7gvv2bgpdwrbbow.webp 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/webp">
        <source srcset="https://www.lunadio.com/static/039df04f65b16f9e8823f7870484c554/f6cdf/1_qe70feh7gvv2bgpdwrbbow.png 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/png">
        <img src="https://www.lunadio.com/static/039df04f65b16f9e8823f7870484c554/f6cdf/1_qe70feh7gvv2bgpdwrbbow.png" alt="1 qe70feh7gvv2bgpdwrbbow">
      </picture>
    </span></p><blockquote><p>The closer the objects are, the more they are perceived as a group. The farther apart they are, the more disconnected they become.</p></blockquote><p>The distance between elements on our screen is thus one of the best way of building a clear, readable hierarchy. So if you have a clear group of items (like a product card) — everything within the card should be rather close together. Then the next card from the stack or carousel should be farther apart from the first one.</p><h3 id="diy-formula">DIY formula</h3><p>Luckily there is an easy formula to do this. Here’s a version of it for the 8-point grid:</p><p><span>
      <span></span>
  <picture>
        <source srcset="https://www.lunadio.com/static/b773ea1ca97ff4cd39971052fb0ba10d/06fd5/1_kny9vqk6ps2t3s4ptel_qw.webp 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/webp">
        <source srcset="https://www.lunadio.com/static/b773ea1ca97ff4cd39971052fb0ba10d/f6cdf/1_kny9vqk6ps2t3s4ptel_qw.png 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/png">
        <img src="https://www.lunadio.com/static/b773ea1ca97ff4cd39971052fb0ba10d/f6cdf/1_kny9vqk6ps2t3s4ptel_qw.png" alt="1 kny9vqk6ps2t3s4ptel qw">
      </picture>
    </span></p><p>And 10-point:</p><p><span>
      <span></span>
  <picture>
        <source srcset="https://www.lunadio.com/static/554cd02c1c618e085dc5def58826ad5c/06fd5/1_jf7esgyqskorwzwadd_d6a.webp 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/webp">
        <source srcset="https://www.lunadio.com/static/554cd02c1c618e085dc5def58826ad5c/f6cdf/1_jf7esgyqskorwzwadd_d6a.png 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/png">
        <img src="https://www.lunadio.com/static/554cd02c1c618e085dc5def58826ad5c/f6cdf/1_jf7esgyqskorwzwadd_d6a.png" alt="1 jf7esgyqskorwzwadd d6a">
      </picture>
    </span></p><p>If you’re building components, use the first three values only. When setting up the general layout use the rest of them — but remember the rule — the more “connected” functionally the objects, the lower the spacing should be.</p><p>Another good example of this is how cards can be closer to one another, but farther away from navigation bars. It’s a clear way of showing the user what’s what.</p><h2 id="rule-2--alignment">Rule 2 — Alignment</h2><p>If you go to the web right now — to any random website — chances are you’re going to see a button with a badly aligned label inside. This is likely the biggest problem out there, and it’s surprisingly easy to fix.</p><p>Let’s break it down into two main parts:</p><p><strong>1. The label is not in the center of the button.</strong></p><p><span>
      <span></span>
  <picture>
        <source srcset="https://www.lunadio.com/static/cfaf50d9a676aec00cba832d06759f53/06fd5/1_ikdd6ewhuncq3tj738xmha.webp 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/webp">
        <source srcset="https://www.lunadio.com/static/cfaf50d9a676aec00cba832d06759f53/f6cdf/1_ikdd6ewhuncq3tj738xmha.png 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/png">
        <img src="https://www.lunadio.com/static/cfaf50d9a676aec00cba832d06759f53/f6cdf/1_ikdd6ewhuncq3tj738xmha.png" alt="Label  in the center of the button">
      </picture>
    </span></p><p>To fix this you must first determine, whether the button height and the text height are both odd, both even, or mixed. If one of them is an odd number, while the other is an even one, there is no way to align them in the center.</p><p>Most fonts work well enough with their values, so if the size is 16p it usually really is 16p high. Some typefaces, however don’t scale that well and 16p size can be anything from 15 to even 19,5. Try the number alignment method first and then check if it’s aligned optically.</p><p>To do that you need to use any visual design tool. You can try Figma, Sketch or even Powerpoint / Keynote. Just paste in a screenshot of your coded button and then create a square that starts from the font baseline to the bottom edge of the button background.</p><p>Now duplicate that same square and see if it fits just as well on top of that font. If there’s a gap on either side, it means that you need to optically align it. The easiest way is with increasing the font size, or decreasing te button height.</p><p><span>
      <span></span>
  <picture>
        <source srcset="https://www.lunadio.com/static/ceadfbfee534222c80c00c62f40d4549/06fd5/1_xxwqbc5tljktvknnr2onxa.webp 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/webp">
        <source srcset="https://www.lunadio.com/static/ceadfbfee534222c80c00c62f40d4549/f6cdf/1_xxwqbc5tljktvknnr2onxa.png 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/png">
        <img src="https://www.lunadio.com/static/ceadfbfee534222c80c00c62f40d4549/f6cdf/1_xxwqbc5tljktvknnr2onxa.png" alt="Properly aligned using square method">
      </picture>
    </span></p><p>Keep in mind, however, that buttons should be big enough to use them comfortably. That’s above 44p high on mobile and 32p on the web.</p><p><strong>2. Too little whitespace inside the button.</strong></p><p>For the label to “breathe” and be readable it needs enough space on all sides.</p><h3 id="the-w-method">The W-method</h3><p>You can use grid values for this, but there’s one other, easy way to achieve readability. Just use the capital letter W (2x) on both sides, and 1 x W on the top and bottom.</p><p><span>
      <span></span>
  <picture>
        <source srcset="https://www.lunadio.com/static/a571c20e2337b2cc6f987cdfca968054/06fd5/1_0jqnaxjdl30y7d9qzi2r0q.webp 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/webp">
        <source srcset="https://www.lunadio.com/static/a571c20e2337b2cc6f987cdfca968054/f6cdf/1_0jqnaxjdl30y7d9qzi2r0q.png 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/png">
        <img src="https://www.lunadio.com/static/a571c20e2337b2cc6f987cdfca968054/f6cdf/1_0jqnaxjdl30y7d9qzi2r0q.png" alt="The W-method">
      </picture>
    </span></p><p>If they fit well, it means the whitespace is big enough. Of course if you have full-length buttons you don’t need to shrink them down. Only use this rule if your buttons are small.</p><h2 id="rule-3--colors-and-fonts">Rule 3 — Colors and fonts</h2><p><span>
      <span></span>
  <picture>
        <source srcset="https://www.lunadio.com/static/053b69e1422824810419afa02860608b/06fd5/1_vmlozppu4fqfvk2eklmxbg.webp 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/webp">
        <source srcset="https://www.lunadio.com/static/053b69e1422824810419afa02860608b/f6cdf/1_vmlozppu4fqfvk2eklmxbg.png 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/png">
        <img src="https://www.lunadio.com/static/053b69e1422824810419afa02860608b/f6cdf/1_vmlozppu4fqfvk2eklmxbg.png" alt="Good use of color and fonts on the left, and chaos on the right.">
      </picture>
    </span></p><p>The main thing you should do with both colors and fonts in any project is to simplify.</p><p>Go through all the screens and list out all the colors and all the fonts you can find.</p><p>If the list is full of very similar colors or very similar sized fonts — simplify it by picking one and replacing the other with it.</p><p><span>
      <span></span>
  <picture>
        <source srcset="https://www.lunadio.com/static/e2d69041b8f8410df2ca756d1f69a484/06fd5/1_r77egkezgpm2-4igufo3rq.webp 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/webp">
        <source srcset="https://www.lunadio.com/static/e2d69041b8f8410df2ca756d1f69a484/f6cdf/1_r77egkezgpm2-4igufo3rq.png 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/png">
        <img src="https://www.lunadio.com/static/e2d69041b8f8410df2ca756d1f69a484/f6cdf/1_r77egkezgpm2-4igufo3rq.png" alt="1 r77egkezgpm2 4igufo3rq">
      </picture>
    </span></p><p>Many projects, especially later in their lifecycle accrue a lot of design debt. It’s good to clean it up whenever you can and systemize the front-end. Use common values and a small group of colors only, as the more seemingly similar options, the longer it takes your users to process the information.</p><p>Keep everything consistent and remove any extra chaos.</p><h2 id="summary">Summary</h2><p>You don’t need to be a designer, to understand the basic principles behind how design works. Knowing just these simple rules will already make you a better developer.</p><p>Good luck!</p><hr><p>This is a Guest post by Michal Malewicz. Michal is the co-founder of <a href="https://hype4.com/" target="_blank" rel="noreferrer">HYPE4</a> design driven software house. He’s also a design lecturer, the author of <a href="https://www.designingui.com/" target="_blank" rel="noreferrer">Designing User Interfaces eBook</a> and co-author of the upcoming <a href="https://www.frontendunicorn.com/" target="_blank" rel="noreferrer">Frontend Unicorn ebook</a>.</p></div></article></div>]]>
            </description>
            <link>https://www.lunadio.com/blog/how-to-spot-and-fix-the-biggest-ui-problems</link>
            <guid isPermaLink="false">hacker-news-small-sites-23837398</guid>
            <pubDate>Tue, 14 Jul 2020 20:28:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Recreating YikYak with Postgres]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 23 (<a href="https://news.ycombinator.com/item?id=23837269">thread link</a>) | @AJRF
<br/>
July 14, 2020 | https://adamfallon.com/2020/07/10/recreating-yikyak-with-postgres/ | <a href="https://web.archive.org/web/*/https://adamfallon.com/2020/07/10/recreating-yikyak-with-postgres/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Yik_Yak" target="_blank">YikYak</a> was an anonymous social network that used your location to show you posts 5km around you.  Users of the app could create new posts and the people around them could view the posts and vote up or down.</p>



<p>YikYak filed a few patents for the tech that helped them achieve this. The patents mention segmenting users into buckets by their physical location. One modern tool we have to recreate this type of user segmentation is a data-structure called an <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/R*_tree" target="_blank">R-Tree</a>. </p>



<figure><img data-attachment-id="154" data-permalink="https://adamfallon.com/1rsz300nanspcxrd2bu5sqw/" data-orig-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/1rsz300nanspcxrd2bu5sqw.png?fit=2000%2C873&amp;ssl=1" data-orig-size="2000,873" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1rsz300nanspcxrd2bu5sqw" data-image-description="" data-medium-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/1rsz300nanspcxrd2bu5sqw.png?fit=300%2C131&amp;ssl=1" data-large-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/1rsz300nanspcxrd2bu5sqw.png?fit=580%2C253&amp;ssl=1" src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/1rsz300nanspcxrd2bu5sqw.png?w=580&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/1rsz300nanspcxrd2bu5sqw.png?w=580&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption><em>An example on an R-Tree in action</em></figcaption></figure>



<p>R-trees&nbsp;are&nbsp;tree data structures&nbsp;used for&nbsp;spatial access methods, i.e., for indexing multi-dimensional information such as&nbsp;<strong>geographical coordinates</strong>,&nbsp;rectangles&nbsp;or&nbsp;polygons.</p>



<p>Luckily the Postgres database enables us to make use of this data-structure via geospatial extensions. In this post I am going to;</p>



<ol><li>Show how we can enable those extensions.</li><li>Seed a few posts into our database.</li><li>Find the posts in a small around a specific latitude and longitude using a SQL query.</li></ol>



<p>Let’s get started!</p>



<hr>



<h2>Creating tables.</h2>



<p>Firstly you will need an instance of Postgres. It is easy to set up in Docker (I’ve detailed a post <a rel="noreferrer noopener" href="https://adamfallon.com/2020/07/08/postgres-in-docker/" target="_blank">here</a> showing how). </p>



<p>I am going to be using DBeaver for this tutorial but you could use psql or any other Postgres connector. Let’s creating a new table for our posts.</p>



<div><figure><img data-attachment-id="207" data-permalink="https://adamfallon.com/screenshot-2020-07-10-at-09-32-15/" data-orig-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.32.15-e1594370249361.png?fit=2560%2C296&amp;ssl=1" data-orig-size="2560,296" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-2020-07-10-at-09.32.15" data-image-description="" data-medium-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.32.15-e1594370249361.png?fit=300%2C35&amp;ssl=1" data-large-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.32.15-e1594370249361.png?fit=580%2C67&amp;ssl=1" src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.32.15-e1594370249361.png?w=580&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.32.15-e1594370249361.png?w=580&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption><em>Select the SQL Editor</em></figcaption></figure></div>



<div><figure><img data-attachment-id="209" data-permalink="https://adamfallon.com/screenshot-2020-07-10-at-09-32-36/" data-orig-file="https://i2.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.32.36-e1594370225286.png?fit=829%2C339&amp;ssl=1" data-orig-size="829,339" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-2020-07-10-at-09.32.36" data-image-description="" data-medium-file="https://i2.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.32.36-e1594370225286.png?fit=300%2C123&amp;ssl=1" data-large-file="https://i2.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.32.36-e1594370225286.png?fit=580%2C237&amp;ssl=1" src="https://i2.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.32.36-e1594370225286.png?w=580&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.32.36-e1594370225286.png?w=580&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption><em>Chose whatever Database you want. I am going with Postgres</em></figcaption></figure></div>



<div><figure><img data-attachment-id="210" data-permalink="https://adamfallon.com/screenshot-2020-07-10-at-09-33-04/" data-orig-file="https://i2.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.33.04.png?fit=1090%2C682&amp;ssl=1" data-orig-size="1090,682" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-2020-07-10-at-09.33.04" data-image-description="" data-medium-file="https://i2.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.33.04.png?fit=300%2C188&amp;ssl=1" data-large-file="https://i2.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.33.04.png?fit=580%2C363&amp;ssl=1" src="https://i2.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.33.04.png?w=580&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.33.04.png?w=580&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption><em>Name your script</em></figcaption></figure></div>



<p>Ready to go – So below we have a simple example of table for storing new posts. I am using a split latitude and longitude to show how the extensions work, but you could also combine the two into a POINT datatype if you are planning to use a lot of columns.</p>



<pre>CREATE TABLE post (
	id int8 NOT NULL GENERATED ALWAYS AS IDENTITY,
	post_content text NOT NULL,
	latitude float8 NOT NULL,
	longitude float8 NOT NULL
);</pre>



<p>On executing that you should have a table you can start insert values into. </p>



<h2>Inserting posts.</h2>



<p>So let’s start out by inserting two posts, the first posted from 10 Downing Street, and the second from Buckingham Palace.</p>



<pre>INSERT INTO post VALUES (
	default,
	'I absolutely love the Queen. I hope she thinks I am doing a good job.',
	51.5034,
	0.1276
);
INSERT INTO post VALUES (
	default,
	'The new Prime Minister is a prat! I do hope he doesnt come over often',
	51.5014,
	0.1419
);</pre>



<p>Now let’s put another post in from an aspiring politics student who is located in Cambridge University (65 miles away). Now we have an outlier that won’t show up once we do location bound queries later in this tutorial.</p>



<pre>INSERT INTO post VALUES (
	default,
	'Day one of my politics degree. Shall be most fun to stalk the halls of Westminister in 4 years.',
	52.2053,
	0.1218
);</pre>



<h2>Installing Postgres extensions</h2>



<p>We would like to be able to stand in St. James park (a large park between 10 Downing Street and Buckingham Palace) and see the two posts close by, but not the one from Cambridge.</p>



<p>So how do we do that? Through extensions! Postgres enables users to incrementally add features that help us do new things with our data.</p>



<p>Once they are installed we can use the latitude and longitude of <em>51.5032, -0.1349</em> to create a new select query on our posts table.</p>



<div data-amp-noloading="true" data-amp-lightbox="true"><figure><img data-attachment-id="217" data-permalink="https://adamfallon.com/screenshot-2020-07-10-at-09-55-52/" data-orig-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.55.52.png?fit=2560%2C1382&amp;ssl=1" data-orig-size="2560,1382" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-2020-07-10-at-09.55.52" data-image-description="" data-medium-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.55.52.png?fit=300%2C162&amp;ssl=1" data-large-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.55.52.png?fit=580%2C313&amp;ssl=1" src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.55.52.png?w=580&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.55.52.png?w=580&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>You can install extensions in Postgres simply by running a query. The two extensions we need are <strong><em>cube</em></strong> and <strong><em>earthdistance</em></strong>.</p>



<pre>CREATE EXTENSION IF NOT EXISTS cube;
CREATE EXTENSION IF NOT EXISTS earthdistance;</pre>



<p>After executing those two queries, you should see them under the ‘Extensions’ tab in DBeaver.</p>



<div><figure><img data-attachment-id="219" data-permalink="https://adamfallon.com/screenshot-2020-07-10-at-10-24-18/" data-orig-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-10.24.18.png?fit=652%2C190&amp;ssl=1" data-orig-size="652,190" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-2020-07-10-at-10.24.18" data-image-description="" data-medium-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-10.24.18.png?fit=300%2C87&amp;ssl=1" data-large-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-10.24.18.png?fit=580%2C169&amp;ssl=1" src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-10.24.18.png?w=580&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-10.24.18.png?w=580&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<h2>Finding nearby posts.</h2>



<p>We can now use these built in functions from those extensions to show us the two nearby posts.</p>



<pre>SELECT * FROM post
WHERE 
	earth_box(ll_to_earth(51.5032,-0.1349), 50000) 
	@&gt; ll_to_earth(latitude, longitude);</pre>



<p>The earth_box function takes two parameters, a point (which is returned by the ll_to_earth function) and a value for the size of the bounding box we want which is in metres. </p>



<p>By using the <a aria-label="undefined (opens in a new tab)" href="https://www.postgresql.org/docs/current/functions-geometry.html" target="_blank" rel="noreferrer noopener nofollow">contains?</a> operator (@&gt;) we are saying we only want values in the table in the bounding box generated by the earth_box function.</p>



<p>When executing that query we will see the two posts we were expecting! Try increasing the bounding box range out and you will be able to see the Cambridge post.</p>



<div><figure><img data-attachment-id="223" data-permalink="https://adamfallon.com/screenshot-2020-07-10-at-10-30-11/" data-orig-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-10.30.11.png?fit=2558%2C1516&amp;ssl=1" data-orig-size="2558,1516" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-2020-07-10-at-10.30.11" data-image-description="" data-medium-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-10.30.11.png?fit=300%2C178&amp;ssl=1" data-large-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-10.30.11.png?fit=580%2C344&amp;ssl=1" src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-10.30.11.png?w=580&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-10.30.11.png?w=580&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>So now we have a working example of how to recreate the YikYak location-based functionality.</p>



<h2>So…how?</h2>



<p>Okay so why did we need those extensions? Can’t we just take the world, split it into squares and determine which box a latitude and longitude falls into? </p>



<p>Thats what we would <em>like</em> to do – but there are complications caused by the fact that the world is a sphere. To find posts “in your area” you are querying to find straight line distances between two points, your lat-long and for each row in the database. In a sphere there are no straight lines. </p>



<p>There is a way to determine the distance between two points known as the <a aria-label="undefined (opens in a new tab)" href="https://en.wikipedia.org/wiki/Great-circle_distance#:~:text=The%20great%2Dcircle%20distance%20or,line%20through%20the%20sphere's%20interior)." target="_blank" rel="noreferrer noopener nofollow">Great-Circle distance</a>. Instead of using straight lines we use circles or curves known as geodesics. Through any two points on a sphere that are not&nbsp;<a href="https://en.wikipedia.org/wiki/Antipodal_point">directly opposite each other</a>, there is a unique great circle. </p>



<p>The earthdistance extension allows us to generate queries using the contains? operator from the cube extension to generate efficient distance lookups between points.</p>



<h2>Conclusion</h2>



<p>One thing to note is that this query will do a sequential scan of the entire table, which can be slow once you get up to thousands of posts. </p>



<p>If you do decide to use this setup in your application you should create an index on the latitude, longitude to dramatically speed up queries. That would look like this.</p>



<pre>CREATE INDEX loc_index ON post USING gist (ll_to_earth(latitude, longitude));</pre>



<p>Postgres will then determine whether it needs to use this index to speed up queries. You can check if the index is being used by using a tool to view the execution plan when you run the query detailed above. If it says SEQ_SCAN it is not using the index. </p>



<p>And we’re done! If you’ve noticed any mistakes or improvements I can make please drop me an email at adam@adamfallon.com</p>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://adamfallon.com/2020/07/10/recreating-yikyak-with-postgres/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23837269</guid>
            <pubDate>Tue, 14 Jul 2020 20:18:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Khmer Rouge: Genocide in the Name of Utopia (2016)]]>
            </title>
            <description>
<![CDATA[
Score 180 | Comments 176 (<a href="https://news.ycombinator.com/item?id=23836985">thread link</a>) | @exolymph
<br/>
July 14, 2020 | https://openendedsocialstudies.org/2016/06/24/the-khmer-rouge-genocide-in-the-name-of-utopia/ | <a href="https://web.archive.org/web/*/https://openendedsocialstudies.org/2016/06/24/the-khmer-rouge-genocide-in-the-name-of-utopia/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<h5><strong>How is history used to support ideology? Is violence by a government against its own civilian population ever justified? Why are certain events given priority over others in history books?</strong></h5>
<h5><strong>This lesson was reported from:</strong></h5>

<h6>Adapted in part from open sources.</h6>

<figure data-shortcode="caption" id="attachment_464" aria-describedby="caption-attachment-464"><a href="https://openendedsocialstudies.files.wordpress.com/2016/06/skulls_2584193k.jpg"><img data-attachment-id="464" data-permalink="https://openendedsocialstudies.org/2016/06/24/the-khmer-rouge-genocide-in-the-name-of-utopia/skulls_2584193k/" data-orig-file="https://openendedsocialstudies.files.wordpress.com/2016/06/skulls_2584193k.jpg" data-orig-size="858,536" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Evidence for genocide in Cambodia." data-image-description="" data-medium-file="https://openendedsocialstudies.files.wordpress.com/2016/06/skulls_2584193k.jpg?w=300" data-large-file="https://openendedsocialstudies.files.wordpress.com/2016/06/skulls_2584193k.jpg?w=820" src="https://openendedsocialstudies.files.wordpress.com/2016/06/skulls_2584193k.jpg?w=581&amp;h=362" alt="Evidence for genocide in Cambodia." width="581" height="362" srcset="https://openendedsocialstudies.files.wordpress.com/2016/06/skulls_2584193k.jpg?w=579&amp;h=362 579w, https://openendedsocialstudies.files.wordpress.com/2016/06/skulls_2584193k.jpg?w=150&amp;h=94 150w, https://openendedsocialstudies.files.wordpress.com/2016/06/skulls_2584193k.jpg?w=300&amp;h=187 300w, https://openendedsocialstudies.files.wordpress.com/2016/06/skulls_2584193k.jpg?w=768&amp;h=480 768w, https://openendedsocialstudies.files.wordpress.com/2016/06/skulls_2584193k.jpg 858w" sizes="(max-width: 581px) 100vw, 581px"></a><figcaption id="caption-attachment-464">Evidence for genocide in Cambodia.</figcaption></figure>
<p><!--block-->The Khmer Rouge was formed in 1968 as a revolutionary Communist party in Cambodia. It was the <a href="https://en.wikipedia.org/wiki/Ruling_party">ruling party</a> in Cambodia from 1975 to 1979, led by <a href="https://en.wikipedia.org/wiki/Pol_Pot">Pol Pot</a>. <a href="https://en.wikipedia.org/wiki/Democratic_Kampuchea">Democratic Kampuchea</a> was the name of the state as controlled by the government of the Khmer Rouge from 1975 to 1979.</p>
<p><!--block-->The four-year period cost approximately 2 million lives through the combined result of political executions, disease, <a href="https://en.wikipedia.org/wiki/Starvation">starvation</a>, and <a href="https://en.wikipedia.org/wiki/Unfree_labor">forced labor</a>. Due to the large numbers, the deaths during the rule of the Khmer Rouge are commonly known as the Cambodian Holocaust or <a href="https://en.wikipedia.org/wiki/Cambodian_genocide">Cambodian genocide</a>. The Khmer Rouge took power at the end of the <a href="https://en.wikipedia.org/wiki/Cambodian_Civil_War">Cambodian Civil War</a> and were only toppled after the invasion of Cambodia by the neighboring Socialist Republic of <a href="https://en.wikipedia.org/wiki/Vietnam">Vietnam</a> in the <a href="https://en.wikipedia.org/wiki/Cambodian%E2%80%93Vietnamese_War">Cambodian–Vietnamese War</a>.</p>
<h2>Pol Pot and the Revolution</h2>

<p><!--block-->Saloth Sar was born on 19 May 1925, the eighth of nine children and the second of three sons to Pen Saloth and Sok Nem. The family was living in the small fishing village of <a href="https://en.wikipedia.org/wiki/Prek_Sbauv">Prek Sbauv</a>, <a href="https://en.wikipedia.org/wiki/Kampong_Thom_Province">Kampong Thom Province</a> when Cambodia was still a French colony. Pen Saloth was a rice farmer who owned 12 <a href="https://en.wikipedia.org/wiki/Hectare">hectares</a> of land and several buffaloes; the family was considered moderately wealthy by the standards of the day. Although Pen Saloth’s family was of <a href="https://en.wikipedia.org/wiki/Chinese_Cambodian">Sino</a>–<a href="https://en.wikipedia.org/wiki/Khmer_people">Khmer</a> descent and Saloth Sar was named accordingly due to his fair complexion (“Sar” means white in Khmer), the family had already assimilated themselves with mainstream Khmer society by the time Sar was born.</p>
<p><!--block-->In 1935, Saloth Sar left Prek Sbauv to attend the École Miche, a Catholic school in <a href="https://en.wikipedia.org/wiki/Phnom_Penh">Phnom Penh</a>. He lived with his cousin, a woman called Meak, a member of the <a href="https://en.wikipedia.org/wiki/Royal_Ballet_of_Cambodia">Royal Ballet</a>.In 1926, she bore King <a href="https://en.wikipedia.org/wiki/Sisowath_Monivong">Monivong’s</a> son, HRH Prince Sisowath Kusarak. She was given the official title <em>Khun Preah Moneang Bopha Norleak Meak</em>. Saloth Sar stayed with Meak’s household until 1942. His sister Roeung was a <a href="https://en.wikipedia.org/wiki/Concubinage">concubine</a> of King Monivong, so through the two women, he often had cause to visit the <a href="https://en.wikipedia.org/wiki/Royal_Palace,_Phnom_Penh">royal palace</a>.&nbsp; In 1947, he gained admission to the exclusive <a href="https://en.wikipedia.org/wiki/Lyc%C3%A9e_Sisowath">Lycée Sisowath</a>, but was unsuccessful in his studies.</p>
<p><!--block-->As a student in Phnom Penh and later in Paris, Saloth was exposed to anti-colonial, revolutionary, and socialist ideas.&nbsp; He became increasingly radical, outraged by French colonialism, the poverty of his nation compared to France itself, and wealth inequality within Cambodia even after French granted the nation independence in the 1950s.</p>
<p><!--block-->Saloth was a founding member of the Khmer Rouge, a party dedicated to socialist revolution in Cambodia.</p>
<div>
<h2>Ideology</h2>
<figure data-shortcode="caption" id="attachment_470" aria-describedby="caption-attachment-470"><a href="https://openendedsocialstudies.files.wordpress.com/2016/06/9660abf16bdbccfcaa829a72aa444922.jpg"><img data-attachment-id="470" data-permalink="https://openendedsocialstudies.org/2016/06/24/the-khmer-rouge-genocide-in-the-name-of-utopia/9660abf16bdbccfcaa829a72aa444922/" data-orig-file="https://openendedsocialstudies.files.wordpress.com/2016/06/9660abf16bdbccfcaa829a72aa444922.jpg" data-orig-size="634,692" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="A female Khmer Rouge fighter or ‘mit naree’ carries an AK-47 assault rifle, a weapon of Communist revolution the world over." data-image-description="" data-medium-file="https://openendedsocialstudies.files.wordpress.com/2016/06/9660abf16bdbccfcaa829a72aa444922.jpg?w=275" data-large-file="https://openendedsocialstudies.files.wordpress.com/2016/06/9660abf16bdbccfcaa829a72aa444922.jpg?w=634" src="https://openendedsocialstudies.files.wordpress.com/2016/06/9660abf16bdbccfcaa829a72aa444922.jpg?w=275&amp;h=300" alt="A female Khmer Rouge fighter or 'mit naree' carries an AK-47 assault rifle, a weapon of Communist revolution the world over." width="275" height="300" srcset="https://openendedsocialstudies.files.wordpress.com/2016/06/9660abf16bdbccfcaa829a72aa444922.jpg?w=275&amp;h=300 275w, https://openendedsocialstudies.files.wordpress.com/2016/06/9660abf16bdbccfcaa829a72aa444922.jpg?w=550&amp;h=600 550w, https://openendedsocialstudies.files.wordpress.com/2016/06/9660abf16bdbccfcaa829a72aa444922.jpg?w=137&amp;h=150 137w" sizes="(max-width: 275px) 100vw, 275px"></a><figcaption id="caption-attachment-470">A female Khmer Rouge fighter or ‘mit naree’ carries an AK-47 assault rifle, a weapon of Communist revolution the world over.</figcaption></figure>
<p>The Khmer Rouge’s ideology combined elements of&nbsp;<a href="https://en.wikipedia.org/wiki/Marxism">Marxism</a>&nbsp;with an extreme version of Khmer nationalism and&nbsp;<a href="https://en.wikipedia.org/wiki/Xenophobia">xenophobia</a>. It combined an idealization of the&nbsp;<a href="https://en.wikipedia.org/wiki/Angkor_Empire">Angkor Empire</a>&nbsp;(802–1431), with an existential fear for the existence of the Cambodian state, which had historically been liquidated under Vietnamese and Siamese intervention.The spillover of Vietnamese fighters from the&nbsp;<a href="https://en.wikipedia.org/wiki/Vietnam_War">Vietnam War</a>&nbsp;further aggravated anti-Vietnamese feeling. The Khmer Rouge explicitly targeted the Chinese, Vietnamese, and even their partially Khmer offspring for extinction; although the&nbsp;<a href="https://en.wikipedia.org/wiki/Cham_people">Cham Muslims</a>&nbsp;were treated unfavorably, they were encouraged to “mix flesh and blood”, to intermarry and assimilate. Some people with partial Chinese or Vietnamese ancestry were present in the Khmer Rouge leadership; they either were purged or participated in the&nbsp;<a href="https://en.wikipedia.org/wiki/Ethnic_cleansing">ethnic cleansing</a>&nbsp;campaigns.</p>
<p>The Khmer Rouge’s social policy focused on working towards a purely agrarian society. Pol Pot strongly influenced the propagation of this policy. He was reportedly impressed with how the mountain tribes of Cambodia lived, which the party interpreted as a form of&nbsp;<a href="https://en.wikipedia.org/wiki/Primitive_communism">primitive communism</a>; as a result, those minorities received more lenient and sometimes even more favorable treatment than the urbanized “<a href="https://en.wikipedia.org/wiki/Bourgeois">bourgeois</a>” Chinese and Vietnamese. Pol Pot wanted to remove social institutions and to transform the society into an agrarian one. This was his way of “[creating] a complete Communist society without wasting time on the intermediate steps” as the Khmer Rouge said to&nbsp;<a href="https://en.wikipedia.org/wiki/China">China</a>&nbsp;in 1975.</p>
<h2>Control of the countryside</h2>
<p>The Khmer Rouge advanced during 1973. After they reached the outskirts of Phnom Penh, Sar issued orders during the peak of the <a href="https://en.wikipedia.org/wiki/Wet_season">rainy season</a> that the city be taken. The orders led to futile attacks and wasted lives within the Khmer Rouge army. By the middle of 1973, the Khmer Rouge under Sar controlled almost two-thirds of the country and half the population.</p>
<p>Internationally, Sar and the Khmer Rouge gained the recognition of 63 countries as the true government of Cambodia. A move was made at the UN to give the seat for Cambodia to the Khmer Rouge; they prevailed by three votes.</p>
<div>
<p>The Khmer Rouge took the capital <a href="https://en.wikipedia.org/wiki/Phnom_Penh">Phnom Penh</a> on 17 April 1975, proclaiming this be Year Zero – all culture and traditions within society would be completely destroyed or discarded, and a new revolutionary culture would replace it.</p>
<figure data-shortcode="caption" id="attachment_473" aria-describedby="caption-attachment-473"><a href="https://openendedsocialstudies.files.wordpress.com/2016/06/d158d8646827595a49fa281c27071779.jpg"><img data-attachment-id="473" data-permalink="https://openendedsocialstudies.org/2016/06/24/the-khmer-rouge-genocide-in-the-name-of-utopia/d158d8646827595a49fa281c27071779/" data-orig-file="https://openendedsocialstudies.files.wordpress.com/2016/06/d158d8646827595a49fa281c27071779.jpg" data-orig-size="611,404" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Phnom Penh, January 1st, 1975 in the waning days of the civil war." data-image-description="" data-medium-file="https://openendedsocialstudies.files.wordpress.com/2016/06/d158d8646827595a49fa281c27071779.jpg?w=300" data-large-file="https://openendedsocialstudies.files.wordpress.com/2016/06/d158d8646827595a49fa281c27071779.jpg?w=611" src="https://openendedsocialstudies.files.wordpress.com/2016/06/d158d8646827595a49fa281c27071779.jpg?w=580&amp;h=383" alt="Phnom Penh, January 1st, 1975 in the waning days of the civil war." width="580" height="383" srcset="https://openendedsocialstudies.files.wordpress.com/2016/06/d158d8646827595a49fa281c27071779.jpg?w=580&amp;h=383 580w, https://openendedsocialstudies.files.wordpress.com/2016/06/d158d8646827595a49fa281c27071779.jpg?w=150&amp;h=99 150w, https://openendedsocialstudies.files.wordpress.com/2016/06/d158d8646827595a49fa281c27071779.jpg?w=300&amp;h=198 300w, https://openendedsocialstudies.files.wordpress.com/2016/06/d158d8646827595a49fa281c27071779.jpg 611w" sizes="(max-width: 580px) 100vw, 580px"></a><figcaption id="caption-attachment-473">Phnom Penh, January 1st, 1975 in the waning days of the civil war.</figcaption></figure>
<h2>Societal transformation</h2>
<p>After taking power, the Khmer Rouge leadership renamed the country Democratic Kampuchea. The Khmer Rouge subjected Cambodia to a radical social reform process that was aimed at creating a purely&nbsp;<a href="https://en.wikipedia.org/wiki/Agrarian_socialism">agrarian-based Communist society</a>.&nbsp;The Khmer Rouge forced around three million people from the cities to the countryside to take up work in agriculture. They forced many people out of their homes and ignored many basic human freedoms; they controlled how Cambodians acted, what they wore, to whom they could talk, and many other aspects of their lives.</p>
<dl id="attachment_472">
<dt><a href="https://openendedsocialstudies.files.wordpress.com/2016/06/90631961305feae1ac126f4e2ae87bc7.png"><img data-attachment-id="472" data-permalink="https://openendedsocialstudies.org/2016/06/24/the-khmer-rouge-genocide-in-the-name-of-utopia/90631961305feae1ac126f4e2ae87bc7/" data-orig-file="https://openendedsocialstudies.files.wordpress.com/2016/06/90631961305feae1ac126f4e2ae87bc7.png" data-orig-size="1204,1007" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="The evacuation of Cambodia’s urban areas occurred on the pretext of a U.S. invasion that never came." data-image-description="" data-medium-file="https://openendedsocialstudies.files.wordpress.com/2016/06/90631961305feae1ac126f4e2ae87bc7.png?w=300" data-large-file="https://openendedsocialstudies.files.wordpress.com/2016/06/90631961305feae1ac126f4e2ae87bc7.png?w=820" src="https://openendedsocialstudies.files.wordpress.com/2016/06/90631961305feae1ac126f4e2ae87bc7.png?w=300&amp;h=251" alt="The evacuation of Cambodia's urban areas occurred on the pretext of a U.S. invasion that never came." width="300" height="251" srcset="https://openendedsocialstudies.files.wordpress.com/2016/06/90631961305feae1ac126f4e2ae87bc7.png?w=300&amp;h=251 300w, https://openendedsocialstudies.files.wordpress.com/2016/06/90631961305feae1ac126f4e2ae87bc7.png?w=600&amp;h=502 600w, https://openendedsocialstudies.files.wordpress.com/2016/06/90631961305feae1ac126f4e2ae87bc7.png?w=150&amp;h=125 150w" sizes="(max-width: 300px) 100vw, 300px"></a></dt>
<dd>The evacuation of Cambodia’s urban areas occurred on the pretext of a U.S. invasion that never came.</dd>
</dl>
<p>The Khmer Rouge believed that parents were tainted with&nbsp;<a href="https://en.wikipedia.org/wiki/Capitalism">capitalism</a>, so they separated children from their parents, indoctrinated them in&nbsp;<a href="https://en.wikipedia.org/wiki/Communism">communism</a>, and taught them torture methods with animals. Children were a “dictatorial instrument of the party” and were given leadership in torture and executions.</p>
<p>Society was divided into two categories. These were the New People – intellectuals, city-dwellers, minority people, and many of their own party members and soldiers who were suspected of being traitors – and the Old People – those who already lived in the countryside.</p>
<p>The lowest unit of social control, the&nbsp;<em>krom</em>&nbsp;(group), consisted of ten to fifteen nuclear families whose activities were closely supervised by a three-person committee. The committee chairman was selected by the CPK. This grass roots leadership was required to note the social origin of each family under its jurisdiction and to report it to persons higher up in the&nbsp;party hierarchy.</p>
<h2>The New People</h2>
<div>
<figure data-shortcode="caption" id="attachment_475" aria-describedby="caption-attachment-475"><a href="https://openendedsocialstudies.files.wordpress.com/2016/06/khmer_rouge_07.jpg"><img data-attachment-id="475" data-permalink="https://openendedsocialstudies.org/2016/06/24/the-khmer-rouge-genocide-in-the-name-of-utopia/khmer_rouge_07/" data-orig-file="https://openendedsocialstudies.files.wordpress.com/2016/06/khmer_rouge_07.jpg" data-orig-size="611,404" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Forced labor camp in Kampong Cham, Cambodia." data-image-description="" data-medium-file="https://openendedsocialstudies.files.wordpress.com/2016/06/khmer_rouge_07.jpg?w=300" data-large-file="https://openendedsocialstudies.files.wordpress.com/2016/06/khmer_rouge_07.jpg?w=611" src="https://openendedsocialstudies.files.wordpress.com/2016/06/khmer_rouge_07.jpg?w=368&amp;h=243" alt="Forced labor camp in Kampong Cham, Cambodia." width="368" height="243" srcset="https://openendedsocialstudies.files.wordpress.com/2016/06/khmer_rouge_07.jpg?w=368&amp;h=243 368w, https://openendedsocialstudies.files.wordpress.com/2016/06/khmer_rouge_07.jpg?w=150&amp;h=99 150w, https://openendedsocialstudies.files.wordpress.com/2016/06/khmer_rouge_07.jpg?w=300&amp;h=198 300w, https://openendedsocialstudies.files.wordpress.com/2016/06/khmer_rouge_07.jpg 611w" sizes="(max-width: 368px) 100vw, 368px"></a><figcaption id="caption-attachment-475">Forced labor camp in Kampong Cham, Cambodia.</figcaption></figure>
<p>New People were treated as forced laborers. They were constantly moved, were forced to do the hardest physical labor, and worked in the most inhospitable, fever-ridden parts of the country, such as forests, upland areas, and swamps. “New People were segregated from Old People, enjoyed little or no privacy, and received the smallest rice rations. When the country experienced <a href="https://en.wikipedia.org/wiki/Famine">food shortages</a> in 1977, the New People suffered the most.</p>
</div>
<p>The medical care available to them was primitive or nonexistent. Families often were separated because people were divided into work brigades according to age and sex and sent to different parts of the country. New People were subjected to unending political indoctrination and could be executed without trial.</p>
<p>One of their mottos in reference to the <a href="https://en.wikipedia.org/wiki/New_People">New People</a> was: “To keep you is no benefit. To destroy you is no loss.”</p>
<p>The situation of the Old People under Khmer Rouge rule was more ambiguous. Refugee interviews reveal cases in which villagers were treated as harshly as the New People, enduring forced labor, indoctrination, the separation of children from parents, and executions; however, they were generally allowed to remain in their native villages.</p>
</div>
</div>
<h2>Life Under the Khmer Rouge</h2>
<div>
<p>Once in power, the Khmer Rouge carried out a radical program that included isolating the country from all foreign influences, closing schools, hospitals, and factories, abolishing banking, finance, and currency, outlawing all religions, confiscating all <a href="https://en.wikipedia.org/wiki/Private_property">private property</a> and relocating people from urban areas to <a href="https://en.wikipedia.org/wiki/Collective_farm">collective farms</a> where forced labor was widespread. The purpose of this policy was to turn all Cambodians into Old People through agricultural labor.</p>
<figure data-shortcode="caption" id="attachment_466" aria-describedby="caption-attachment-466"><a href="https://openendedsocialstudies.files.wordpress.com/2016/06/8e1cd4dbed4fa55ac88aba90e53ea0e8.jpg"><img data-attachment-id="466" data-permalink="https://openendedsocialstudies.org/2016/06/24/the-khmer-rouge-genocide-in-the-name-of-utopia/8e1cd4dbed4fa55ac88aba90e53ea0e8/" data-orig-file="https://openendedsocialstudies.files.wordpress.com/2016/06/8e1cd4dbed4fa55ac88aba90e53ea0e8.jpg" data-orig-size="826,779" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="The evactuation of Phnom Penh, 1975." data-image-description="" data-medium-file="https://openendedsocialstudies.files.wordpress.com/2016/06/8e1cd4dbed4fa55ac88aba90e53ea0e8.jpg?w=300" data-large-file="https://openendedsocialstudies.files.wordpress.com/2016/06/8e1cd4dbed4fa55ac88aba90e53ea0e8.jpg?w=820" src="https://openendedsocialstudies.files.wordpress.com/2016/06/8e1cd4dbed4fa55ac88aba90e53ea0e8.jpg?w=300&amp;h=283" alt="The evacuation of Phnom Penh, 1975." width="300" height="283" srcset="https://openendedsocialstudies.files.wordpress.com/2016/06/8e1cd4dbed4fa55ac88aba90e53ea0e8.jpg?w=300&amp;h=283 300w, https://openendedsocialstudies.files.wordpress.com/2016/06/8e1cd4dbed4fa55ac88aba90e53ea0e8.jpg?w=600&amp;h=566 600w, https://openendedsocialstudies.files.wordpress.com/2016/06/8e1cd4dbed4fa55ac88aba90e53ea0e8.jpg?w=150&amp;h=141 150w" sizes="(max-width: 300px) 100vw, 300px"></a><figcaption id="caption-attachment-466">The evacuation of Phnom Penh, 1975.</figcaption></figure>
<p>In Phnom Penh and other cities, the Khmer Rouge told <a href="https://en.wikipedia.org/wiki/Residency_(domicile)">residents</a> that they would be moved only about “two or three kilometers” outside the city and would return in “two or three days”. Some witnesses say they were told that the evacuation was because of the “threat of American bombing” and that they did not have to lock their houses since the Khmer Rouge would “take care of everything” until they returned. People who refused to evacuate would have their homes burned to the ground and would be killed immediately. The evacuees were sent on long marches to the countryside, which killed thousands of children, elderly people, and sick people.These were not the first evacuations of civilian populations by the Khmer Rouge; similar evacuations of populations without possessions had been occurring on a smaller scale since the early 1970s.</p>
<p>The entire population was forced to become farmers in <a href="https://en.m.wikipedia.org/wiki/Labour_camp">labor camps</a>. Cambodians were expected to produce three tons of rice per hectare; before the Khmer Rouge era, the average was only one ton per hectare. The total lack of agricultural knowledge by the former city dwellers made <a href="https://en.m.wikipedia.org/wiki/Famine">famine</a> inevitable. Rural dwellers were often unsympathetic or too frightened to assist them. Such acts …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://openendedsocialstudies.org/2016/06/24/the-khmer-rouge-genocide-in-the-name-of-utopia/">https://openendedsocialstudies.org/2016/06/24/the-khmer-rouge-genocide-in-the-name-of-utopia/</a></em></p>]]>
            </description>
            <link>https://openendedsocialstudies.org/2016/06/24/the-khmer-rouge-genocide-in-the-name-of-utopia/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23836985</guid>
            <pubDate>Tue, 14 Jul 2020 19:57:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deploying a State-of-the-Art Question Answering System with 60 Lines of Python]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23836903">thread link</a>) | @rbanffy
<br/>
July 14, 2020 | https://www.confetti.ai/post/deploying-a-state-of-the-art-question-answering-system-with-60-lines-of-python-and-streamlit | <a href="https://web.archive.org/web/*/https://www.confetti.ai/post/deploying-a-state-of-the-art-question-answering-system-with-60-lines-of-python-and-streamlit">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.12.2"><div dir="ltr"><div><div id="viewer-4lkva"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.confetti.ai/post/deploying-a-state-of-the-art-question-answering-system-with-60-lines-of-python-and-streamlit" data-pin-media="https://static.wixstatic.com/media/4feadc_eb5e26b838c8483a9137c275351425b6~mv2.jpg/v1/fit/w_3000,h_2000,al_c,q_80/file.png" src="https://static.wixstatic.com/media/4feadc_eb5e26b838c8483a9137c275351425b6~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-ftqun">Nowadays, the machine learning and data science job landscape is changing rapidly. </p><p id="viewer-c1di0">Within industry, the skills that are becoming most valuable aren't knowing how to tune a ResNet on an image dataset. In fact, the prevalence of well-designed frameworks such as PyTorch and Tensorflow are making these skills increasingly easy to pickup. </p><p id="viewer-9en8l">Rather as many larger enterprises look to adopt machine learning as part of their business offerings, the skills that are in high demand are knowing how to solve the "last mile problem." In other words, how do you go from a trained, functional model sitting on your local machine to a deployed service that can be used by customers, typically via a web API? </p><p id="viewer-anq5p">Solving this problem is less about the right hyperparameters or features needed to eke out the last percentage point on a task but more about knowing how to engineer a deployment pipeline.</p><p id="viewer-71gnl">This means that engineering and infrastructure requirements are emerging as the biggest bottlenecks in deploying real world machine learning systems. The statistics are sobering: <a href="https://venturebeat.com/2019/07/19/why-do-87-of-data-science-projects-never-make-it-into-production/" target="_blank" rel="noopener"><u>87% of data science project never make it into production</u></a>.</p><p id="viewer-af9sd"><span>Thankfully, we are also seeing the emergence of powerful libraries that help address this last mile problem. One library in particular, called </span><a href="https://www.streamlit.io/" target="_blank" rel="noopener"><span><u>Streamlit</u></span></a><span><u>,</u> is a powerful player in this space that offers a low-effort solution to the deployment. </span></p><p id="viewer-7osg6"><span>In this post, we will show how with Streamlit we need only <strong>60 lines of Python</strong> to deploy an interactive web app making calls to a state-of-the-art neural question answering system that can query all of Wikipedia. Let's get started!</span></p><h3 id="viewer-crsad"><span><strong>Use-Case</strong></span></h3><p id="viewer-7jnsp"><span>Our app will use a powerful neural model can be used to answer questions about any arbitrary Wikipedia article. It will allow users to retrieve any Wikipedia article and then ask the model to read and extract bits of information from it. </span></p><h3 id="viewer-5clq9"><span><strong>Model </strong></span></h3><p id="viewer-f54ne"><span>The question answering model used is a variant of </span><a href="https://arxiv.org/pdf/1910.01108.pdf" target="_blank" rel="noopener"><span><u>DistilBert</u></span></a><span>, a neural Transformer model with roughly 66 million parameters. </span></p><h3 id="viewer-5v18j"><span><strong>Code</strong></span></h3><p id="viewer-gmda"><span>We first load up our question answering model via a pipeline:</span></p><pre id="viewer-7fr87"><span><span>from</span></span><span> </span>typing <span><span>import</span></span><span> </span>Dict

<span><span>import</span></span><span> </span>streamlit <span><span>as</span></span><span> </span>st
<span><span>import</span></span><span> </span>wikipedia
<span><span>from</span></span><span> </span>transformers <span><span>import</span></span><span> </span>Pipeline
<span><span>from</span></span><span> </span>transformers <span><span>import</span></span><span> </span>pipeline

<span>NUM_SENT</span> <span>=</span> <span><span>10</span></span>

<span>@st</span><span><span>.</span></span><span>cache</span>
<span>def </span><span><span>get_qa_pipeline</span></span><span>(</span><span>)</span> <span>-</span><span>&gt;</span> Pipeline<span>:</span>
    qa <span>=</span> <span>pipeline</span><span>(</span><span>"<span>question-answering"</span></span><span>)</span>
    <span><span>return</span></span><span> </span>qa


<span>def </span><span><span>answer_question</span></span><span>(</span>pipeline<span>:</span> Pipeline<span><span>,</span></span><span> </span>question<span>:</span> <span>str</span><span><span>,</span></span><span> </span>paragraph<span>:</span> <span>str</span><span>)</span> <span>-</span><span>&gt;</span> Dict<span>:</span>
    input <span>=</span> <span>{</span>
        <span><span>"question"</span></span><span>:</span> question<span><span>,</span></span>
<span>        </span><span><span>"context"</span></span><span>:</span> paragraph
    <span>}</span>
    <span><span>return</span></span><span> </span><span>pipeline</span><span>(</span>input<span>)</span></pre><p id="viewer-bcr9e">Here we are using a pipeline object that wraps around a pretrained model from the  <a href="https://github.com/huggingface/transformers" target="_blank" rel="noopener"><u>Transformers library</u></a><u>.</u> Note we are using the @<em>st.cache</em> Streamlit decorator which prevents unnecessary reloads of the model, since this can be computationally expensive. </p><p id="viewer-da3pm">Next we provide functionality for getting articles from Wikipedia: </p><pre id="viewer-8puha"><span>@st</span><span><span>.</span></span><span>cache</span>
<span>def </span><span><span>get_wiki_paragraph</span></span><span>(</span>query<span>:</span> <span>str</span><span>)</span> <span>-</span><span>&gt;</span> <span>str</span><span>:</span>
    results <span>=</span> wikipedia<span>.</span><span>search</span><span>(</span>query<span>)</span>
    <span><span>try</span></span><span>:</span>
        summary <span>=</span> wikipedia<span>.</span><span>summary</span><span>(</span>results<span>[</span><span><span>0</span></span><span>]</span><span><span>,</span></span><span> </span><span>sentences</span><span>=</span><span>NUM_SENT</span><span>)</span>
    <span>except </span>wikipedia<span>.</span>DisambiguationError <span><span>as</span></span><span> </span>e<span>:</span>
        ambiguous_terms <span>=</span> e<span>.</span>options
        <span><span>return</span></span><span> </span>wikipedia<span>.</span><span>summary</span><span>(</span>ambiguous_terms<span>[</span><span><span>0</span></span><span>]</span><span><span>,</span></span><span> </span><span>sentences</span><span>=</span><span>NUM_SENT</span><span>)</span>
    <span><span>return</span></span><span> </span>summary


<span>def </span><span><span>format_text</span></span><span>(</span>paragraph<span>:</span> <span>str</span><span><span>,</span></span><span> </span>start_idx<span>:</span> <span>int</span><span><span>,</span></span><span> </span>end_idx<span>:</span> <span>int</span><span>)</span> <span>-</span><span>&gt;</span> <span>str</span><span>:</span>
    <span><span>return</span></span><span> </span>paragraph<span>[</span><span>:</span>start_idx<span>]</span> <span>+</span> <span><span>"**"</span></span><span> </span><span>+</span> paragraph<span>[</span>start_idx<span>:</span>end_idx<span>]</span> <span>+</span> <span><span>"**"</span></span><span> </span><span>+</span> paragraph<span>[</span>end_idx<span>:</span><span>]</span></pre><p id="viewer-l6fr">This uses the provided query to make a call to the <a href="https://wikipedia.readthedocs.io/en/latest/quickstart.html#quickstart" target="_blank" rel="noopener"><u>Python wikipedia library</u></a>. The second function will be used once our model returns a value to highlight the answer within the paragraph.     </p><p id="viewer-e07ef">Finally, we provide the main engine of the app, which renders the text inputs using Streamlit and makes the subsequent calls to the above functions:</p><pre id="viewer-8sfn5"><span><span>if</span></span><span> </span>__name__ <span>==</span> <span><span>"__main__"</span></span><span>:</span>
    <span><span>""</span></span><span>"</span>
<span>    # Wikipedia Article</span>
<span>    </span><span><span>""</span></span><span>"</span>
<span>    </span>paragraph_slot <span>=</span> st<span>.</span><span>empty</span><span>(</span><span>)</span>
    wiki_query <span>=</span> st<span>.</span><span>text_input</span><span>(</span><span><span>"WIKIPEDIA SEARCH TERM"</span></span><span><span>,</span></span><span> </span><span><span>""</span></span><span>)</span>
    question <span>=</span> st<span>.</span><span>text_input</span><span>(</span><span><span>"QUESTION"</span></span><span><span>,</span></span><span> </span><span><span>""</span></span><span>)</span>
    
    <span><span>if</span></span><span> </span>wiki_query<span>:</span>
        wiki_para <span>=</span> <span>get_wiki_paragraph</span><span>(</span>wiki_query<span>)</span>
        paragraph_slot<span>.</span><span>markdown</span><span>(</span>wiki_para<span>)</span>
        <span># Execute question against paragraph</span>
<span>        </span><span><span>if</span></span><span> </span>question <span>!=</span> <span><span>""</span></span><span>:</span>
            pipeline <span>=</span> <span>get_qa_pipeline</span><span>(</span><span>)</span>
            st<span>.</span><span>write</span><span>(</span>pipeline<span>.</span>model<span>)</span>
            st<span>.</span><span>write</span><span>(</span>pipeline<span>.</span>model<span>.</span>config<span>)</span>
            <span><span>try</span></span><span>:</span>
                answer <span>=</span> <span>answer_question</span><span>(</span>pipeline<span><span>,</span></span><span> </span>question<span><span>,</span></span><span> </span>wiki_para<span>)</span>
                
                start_idx <span>=</span> answer<span>[</span><span><span>"start"</span></span><span>]</span>
                end_idx <span>=</span> answer<span>[</span><span><span>"end"</span></span><span>]</span>
                paragraph_slot<span>.</span><span>markdown</span><span>(</span><span>format_text</span><span>(</span>wiki_para<span><span>,</span></span><span> </span>start_idx<span><span>,</span></span><span> </span>end_idx<span>)</span><span>)</span>
            <span>except</span><span>:</span>
                st<span>.</span><span>write</span><span>(</span><span><span>"You must provide a valid wikipedia paragraph"</span></span><span>)</span>

</pre><p id="viewer-cpa8d">All we have to do to deploy the app locally is save the code within a file <strong>app.py </strong>and run:</p><pre id="viewer-1d05e">streamlit run app<span>.</span>py</pre><p id="viewer-a5pok">And with that, we have a functional state-of-the-art question-answering system deployed as a web application! You can see the <a href="http://streamlit-demo.confetti.ai:8501/" target="_blank" rel="noopener"><u>running demo here</u></a><u>.</u></p><p id="viewer-7cdu4"> There's a lot more that can be done with Streamlit, so we encourage you to check out the <a href="https://docs.streamlit.io/en/stable/api.html" target="_blank" rel="noopener"><u>documentation</u></a>. </p><p id="viewer-4rgns">For more educational resource offerings related to becoming a full-stack machine learning engineer or data scientist, subscribe to the <a href="https://www.confetti.ai/" target="_blank" rel="noopener"><u>Confetti AI newsletter</u></a><u>.</u></p></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.confetti.ai/post/deploying-a-state-of-the-art-question-answering-system-with-60-lines-of-python-and-streamlit</link>
            <guid isPermaLink="false">hacker-news-small-sites-23836903</guid>
            <pubDate>Tue, 14 Jul 2020 19:52:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Doom Eternal Privacy Policy Allows Collection and Disclosure of Medical Records]]>
            </title>
            <description>
<![CDATA[
Score 170 | Comments 125 (<a href="https://news.ycombinator.com/item?id=23836876">thread link</a>) | @gentleman11
<br/>
July 14, 2020 | https://wrap.bnet.idtech.services/legal/?limited=true&fragment=https%3A%2F%2Fbethesda.net%2Fdata%2Fpp%2Fen_fr.html | <a href="https://web.archive.org/web/*/https://wrap.bnet.idtech.services/legal/?limited=true&fragment=https%3A%2F%2Fbethesda.net%2Fdata%2Fpp%2Fen_fr.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<p><img src="https://esrbstorage.blob.core.windows.net/esrbcontent/images/privacy_certified_globe_color.gif" alt="ESRB PRIVACY CERTIFIED MEMBER CONFIRMATION"></p>

<p>Last Updated: January 27, 2020</p>
<p>This ZeniMax Media Online Privacy Policy ("<strong>Policy</strong>") describes how ZeniMax Media Inc. and our affiliates and subsidiaries (collectively, "<strong>ZeniMax</strong>", "<strong>we</strong>" or "<strong>us</strong>") collect, use and otherwise process the personal information we collect about our about customers, purchasers, subscribers, and/or users (each a " <strong>User</strong>") of our mobile applications, games, websites and other online services (collectively, our " <strong>Services</strong>").</p>
<table>
  <tbody><tr>
    <th colspan="3">Overview of Our Collection and Use of Personal Information</th>
  </tr>
  <tr>
    <td colspan="3">This table provides an overview and is intended to summarize key information about our information practices, which are further explained in our Privacy Policy below.  The actual information we collect about you and the use of such personal information will vary depending upon the nature of our relationship and interactions with you. </td>
  </tr>
  <tr>
    <td colspan="2">Categories of personal information collected  </td>
    <td colspan="1">Uses of personal information </td>
  </tr>
  <tr>
    <td colspan="2"><b>Name, contact info and other identifiers</b> (e.g., name, email, address, username and alias; UID, BUID, device id, third party platform identifiers and account details (e.g., PlayStationÂ®, Xbox, Steam, Facebook), and other online or unique identifiers)</td>
    <td rowspan="7">
    <ul>
      <li>Providing our Services and related support</li>
      <li>Protecting the integrity of the Services</li>
      <li>Analyzing and improving the Services and our business</li>
      <li>Personalizing the Services</li><li>Advertising, marketing and promotional purposes</li>
      <li>Securing and protecting our business</li>
      <li>Defending our legal rights</li>
      <li>Auditing, reporting, corporate governance, and internal operations</li>
      <li>Complying with legal obligations</li>
    </ul>
</td>
  </tr>
   <tr>
    <td colspan="2"><b>Paper and electronic customer records</b> (e.g., your account and profile, which contains personal information, such as username, name, demographics and other characteristics or descriptions, email, address, telephone number, and other contact information, account credentials, communications preferences, and customer service and support tickets and other records)</td>
  </tr>
   <tr>
    <td colspan="2"><b>Purchase history and tendencies</b> (e.g., information about your subscriptions current and past payments and purchases, and your purchase tendencies)</td>
  </tr>
   <tr>
     <td colspan="2"><b>Usage data</b> (e.g., usage and preference details related to your use of the Services, such as language, in-game purchases, game-play statistics, scores, persona, characters, achievements, rankings, time spent playing, click paths, game profile, preferences and friends)</td>
  </tr>
  <tr>
    <td colspan="2"><b>Geolocation data</b> (e.g., for mobile games users)</td>
  </tr>
   <tr>
    <td colspan="2"><b>Audio, video and other electronic data</b> (e.g., call recordings of customer support calls, and User photos submitted to the Services)</td>
  </tr>
   <tr>
    <td colspan="2"><b>Profiles and inferences</b> (e.g., profiles based on your account and activities, that reflect your preferences, characteristics, and abilities related to the Services)</td>
  </tr>
   <tr>
    <td colspan="3"><b>ESRB Privacy certification.</b> ZeniMax values the importance of your privacy and has received the ESRB Privacy Certification. ZeniMax is a valid licensee, and participating member of the Entertainment Software Rating Board's Privacy Certified Program (â€œ<b>ESRB Privacy Certified</b>â€�). All Services where this Policy is posted and which display an ESRB certification seal have been reviewed and certified by ESRB Privacy Certified to meet established online information collection, use and disclosure practices. As a licensee of this privacy program, we are subject to audits of our Services and other enforcement and accountability mechanisms administered independently by the ESRB.</td>
  </tr>
    <tr>
      <td colspan="3"><b>Individual rights.</b> Please see Section 12. User Rights and Choices below for a description of the choices we provide and the rights you have regarding your personal information. If you are a California resident, please be sure to review Section 15.a.  <u>Additional information for California Residents</u> below for important information about the categories of personal information we collect and disclose and your rights under California privacy laws.  If you are in the European Economic Area, please see Section 15.b. <u>Users in the European Economic Area</u> for more information about your rights under the EU General Data Protection Regulation (GDPR).</td>
  </tr>
</tbody></table>

<p>Scope of Our Policy</p>
<p>Personal Information We Collect</p>
<p>Purposes of Use and Legal Bases for Processing of Personal Information</p>
<p>Disclosure and Sharing of Personal Information</p>
<p>Cookies, Analytics and Personalization</p>
<p>Interest-based Advertising</p>
<p>Third Party Links and Features</p>
<p>User Generated Content</p>
<p>Security of Your Information</p>
<p>Data Retention</p>
<p>International Transfers of Data</p>
<p>User Rights and Choices</p>
<p>Contact Details</p>
<p>Changes to this Policy</p>
<p>Additional Information for Users in Certain Jurisdictions</p>
<p><strong>1.</strong>  <strong>Scope of Our Policy</strong></p>
<p>This Policy applies to the personal information that ZeniMax collects and processes about Users related to our Services, including games published by Bethesda Softworks and ZeniMax Online Studios, and games developed by other ZeniMax studios; more information about our studios is available at www.zenimax.com/studios.  This Policy does not apply to any third party websites, services, products or mobile applications maintained by other companies, which are linked to from our Services.</p>
<p>By registering for an account with us, providing your information to us through the Services, or otherwise using any of our Services, you understand and acknowledge that ZeniMax may process your personal information in accordance with this Policy. If you do not want this Policy to apply to you, please do not use the Services or communicate with us via the Services. If required by applicable law, we will obtain your consent to our collection, use, transfer and disclosure of your personal information.</p>
<p><strong>Personal Information.</strong>  In this Policy, our use of the term "personal information" includes other similar terms under applicable privacy lawsâ€”such as "personal data" and "personally identifiable information."  In general, personal information includes any information that identifies, relates to, describes, or is reasonably capable of being associated, or reasonably linked or linkable with a particular individual.</p>
<p><strong>Not Covered by this Policy.</strong>  This Policy does not apply to job applicants and candidates who apply for employment with us, or to employees and non-employee workers in the context of our working relationship with them.</p>
<p><strong>2.</strong>  <strong>Personal Information We Collect</strong></p>
<p>The information we collect about Users varies depending upon the circumstances and the Services used.</p>
<p>ZeniMax collects personal information directly from Users, automatically related to the use of the Services, and in some cases, from third parties (such as social networks, platform providers, payment processors, and operators of certain third party services that we use).</p>
<p><strong>Information We Collect From You</strong>.  Generally, we collect your personal information on a voluntary basis. However, if you decline to provide certain personal information that is marked mandatory, you may not be able to access certain Services or we may be unable to fully respond to your inquiry. We collect the following personal information from you:</p>
<ul>
<li>
<p>Registration and Profile Information.  To access and use certain Services (e.g., to register a game, download or use a mobile application, access subscription-based Services, create an account) you may be required to register with us, by providing us with certain required information, which is identified on the registration page. Depending upon the Services you use, this may include your name, a username and password, as well as country of residence, email, and contact information; certain Services will not be available if you decline to provide required information. We may also ask you or allow you to submit certain optional information, which may include your phone number, birthdate, location, preferences, a photo or avatar, and other profile information.</p>
</li>
<li>
<p>Purchases and Payments Information.  If you make a purchase or sign up for certain subscription-based Services, you are required to provide your payment information, including name, billing and shipping address and details, payment type, as well as credit card number or other payment account details (e.g., PayPal). We work with third parties like payment processors and fulfillment partners to process these payments. We do not collect, receive, process or store credit card or debit card numbers, or other third-party payment account credentials (e.g., PayPal); this information is collected directly by these third parties. Depending upon the Service, we may receive your username, name, email, the payment type, product(s) or service(s), and other transaction details, and maintain records of your purchase and subscription history.</p>
</li>
<li>
<p>Marketing, Contests and Promotions.  Users can sign up online or in-person (e.g., at tradeshows, conferences and the like) to receive direct marketing communications from us, including emails about game launches, developments, and upcoming releases. If you agree to receive direct marketing communications from us, we collect your email address, and we may also collect your name, preferences, and if relevant, information about your account and the Services and other games you use. We may also run contests, sweepstakes or other events or activities (collectively, "events") on our websites and social media channels. Information collected for these events may include your name, age, email address, and other information.</p>
</li>
<li>
<p>Your Communications.  When you email us, call us, or otherwise send us communications regarding the Services, we collect and maintain a record of your contact details, communications and our responses. We may also maintain records of the in-game communications and information that you post in chat sessions, forums, and in other areas of the Services.</p>
</li>
</ul>
<p><strong>Information We Collect and Receive From Third Parties</strong>.  We may collect and receive personal information about you from third parties, such as:</p>
<ul>
<li>
<p>Third Party Platforms.  You may be able to login through or connect certain third party accounts (each a " <strong>Third Party Account</strong>")â€”such as Steam, Twitch, Xbox Live, PSN and Facebookâ€”to your account with us.  These Third Party Accounts are operated and managed by third …</p></li></ul></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wrap.bnet.idtech.services/legal/?limited=true&amp;fragment=https%3A%2F%2Fbethesda.net%2Fdata%2Fpp%2Fen_fr.html">https://wrap.bnet.idtech.services/legal/?limited=true&amp;fragment=https%3A%2F%2Fbethesda.net%2Fdata%2Fpp%2Fen_fr.html</a></em></p>]]>
            </description>
            <link>https://wrap.bnet.idtech.services/legal/?limited=true&amp;fragment=https%3A%2F%2Fbethesda.net%2Fdata%2Fpp%2Fen_fr.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23836876</guid>
            <pubDate>Tue, 14 Jul 2020 19:49:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ludum Dare in 48 hours with Rust and WebAssembly]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23836386">thread link</a>) | @yannikyeo
<br/>
July 14, 2020 | https://ianjk.com/rust-gamejam/ | <a href="https://web.archive.org/web/*/https://ianjk.com/rust-gamejam/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    <p><a href="https://ldjam.com/">Ludum Dare</a>, the world's premiere 48 hour solo gamejam, occurred back in April.</p>
<p>Ludum Dare has two tracks: the 'Compo' and the 'Jam'.</p>
<p>The rules of the Compo require you to make a game (other than source code) within 48 hours. At the end your fellow entrants will rate your game and your game will be ranked against your peers.</p>
<p>With everyone quarantined at home due to Coronavirus this April's Ludum Dare had vastly more entrants than usual. A total of 1383 people entered the Compo and there were 3576 entries to the Jam. That's an absurd amount of games!</p>
<p>I've entered the Compo a <a href="https://ldjam.com/events/ludum-dare/43/blueberry-bounce">few</a> <a href="https://ldjam.com/events/ludum-dare/42/noahs-help-1">times</a> using Unity, but this time around I wanted to write a game purely with the relatively new programming language Rust.</p>
<p>This post started out focused on the experience of using Rust, but turned into a general overview of the technical and design process for the game.</p>
<span id="continue-reading"></span>
<p><a href="https://www.rust-lang.org/">Rust</a> is a 'systems programming language' focused on performance and safety. 'Safety' means that Rust helps you avoid certain classes of vulnerabilities and crashes. I have been using Rust for my personal work and decided now was the time to give it a shot for a gamejam.</p>
<h2 id="why-not-unity">Why not Unity?</h2>
<p>I've entered at least five past Ludum Dares with Unity, and Unity with C# is by far the most common set of tools used for Ludum Dare. But I just simply haven't been enjoying Unity as much recently.</p>
<p>Unity is a giant game engine, but I find it hard to get into a flow state with. There are too many knobs, features, and ways to do things. It's easy to flip a bunch of switches and have something decent, but that just doesn't mesh with my personal design flow. I prefer to work in a clean mental environment, not a complex editor.</p>
<p>Additionally Unity's WebGL build takes around 20 minutes on my laptop, which is absolutely miserable.</p>

<p>I've been coding exclusively on a 2016 Macbook Pro for a while now. It's not the best, but not the worst.</p>
<p>I could have used an existing Rust game engine, but I'm not familiar with the popular ones. Instead I cobbled together a mix of Rust libraries and various personal Rust scripts.</p>
<p>Rust makes it trivially easy to use other libraries (which it calls crates) through its package manager <a href="https://crates.io/">crates.io</a>.</p>
<p>For this project I used the following crates:</p>
<ul>
<li><a href="https://github.com/kettle11/kApp">kApp</a> My personal windowing and input library designed to build super fast.</li>
<li><a href="https://github.com/rustwasm/wasm-bindgen">wasm-bindgen</a> The Rust ecosystem's standard way to call Javascript from Rust</li>
<li><a href="https://github.com/grovesNL/glow">glow</a> "GL on whatever" A wrapper around OpenGL and WebGL.</li>
</ul>
<p>The recommended way to work with Rust and WebAssembly (Wasm) is through a command line tool called <a href="https://github.com/rustwasm/wasm-pack"><code>wasm-pack</code></a>. I skipped using <code>wasm-pack</code> and instead just used a two line bash script that would run a Rust build and then call <code>wasm-bindgen</code> directly to generate the web bindings.</p>
<p>Quick iteration times are absolutely critical for a gamejam. The following tools were instrumental in attaining quick iteration times:</p>
<ul>
<li><a href="https://github.com/passcod/cargo-watch"><code>cargo watch</code></a> ran the build script automatically whenever the code was saved.</li>
<li><a href="https://crates.io/crates/devserver/0.1.0"><code>devserver</code></a> hosted the local web page and automatically reloaded it when a file changed</li>
<li>Visual Studio Code was configured to automatically save</li>
</ul>
<p>The combination of <code>cargo watch</code>, <code>devserver</code>, and the Visual Studio Code settings meant that I could edit a value, like a color, in my Rust code and watch it change on the web page nearly instantly.</p>
<p>Typical Rust build times were around 1-3 seconds while working on this project, but sometimes they'd inexplicably go up to around 10 seconds. Rust is known for slow build times, and these quick iteration times were only possible by carefully choosing tiny crates. My goal was to always have the new build ready on the web page by the time I changed to the browser window.</p>
<h2 id="code-structure">Code Structure</h2>
<p>With only 48 hours best practices go out the window, but even still I made some early choices to help make writing new code as easy as possible. One of the key things I wanted to ensure was that if I were to declare a new variable, or load a new asset, that it would only have to be declared once. Many Rust frameworks follow a pattern a bit like the following:</p>
<pre><code><span>struct </span><span>Game </span><span>{
    </span><span>player</span><span>:</span><span> Player,
    </span><span>/* Other stuff */
</span><span>}

</span><span>impl </span><span>Game </span><span>{
    </span><span>fn </span><span>setup</span><span>(</span><span>context</span><span>: &amp;</span><span>Context</span><span>) -&gt;</span><span> Game </span><span>{</span><span>
        Game </span><span>{</span><span>
            player</span><span>: </span><span>Player</span><span>::</span><span>new</span><span>(),
        }
    }

    </span><span>fn </span><span>update</span><span>(</span><span>context</span><span>: &amp;</span><span>Context</span><span>) {
        </span><span>/* Respond to user input and redraw here*/
    </span><span>}
}
</span></code></pre>
<p>The above works fine in regular scenarios, but when you add a new variable like 'player' it needs to be declared in multiple places. Instead I used a structure a bit like the following:</p>
<pre><code><span>fn </span><span>main</span><span>() {
    </span><span>let</span><span> player </span><span>= </span><span>Player</span><span>::</span><span>new</span><span>();
    </span><span>/* Other setup code here */

    </span><span>loop </span><span>{
        </span><span>/* Respond to user input and redraw here forever*/
    </span><span>}
}
</span></code></pre>
<p>This let me declare a variable and use it immediately, no extra fuss.</p>
<h2 id="async">Async</h2>
<p>Unfortunately the above structure doesn't work on web. On Web the main loop must return control to the browser.</p>
<p>The way to get around this is to pass a closure that the browser calls when an event occurs:</p>
<pre><code><span>fn </span><span>main</span><span>() {
    </span><span>let</span><span> player </span><span>= </span><span>Player</span><span>::</span><span>new</span><span>();
    </span><span>/* Other setup code here */

    </span><span>run</span><span>(</span><span>move </span><span>|</span><span>context</span><span>| {
        </span><span>/* Respond to events and draw here */
    </span><span>});
}
</span></code></pre>
<p>Rust windowing and input frameworks like <a href="https://github.com/rust-windowing/winit">Winit</a> use the above approach.</p>
<p>Another issue on web is loading assets. On non-web platforms it's simple to just wait for an asset to be done loading:</p>
<pre><code><span>let</span><span> wind_sound_handle </span><span>= </span><span>std</span><span>::</span><span>fs</span><span>::</span><span>read</span><span>("</span><span>wind.wav</span><span>").</span><span>unwrap</span><span>();
</span></code></pre>
<p>On web the above isn't possible because it would prevent returning control to the browser. It's not appropriate to lock up while waiting for an an asset to return from a server, so all loads are asynchronous.</p>
<p>An approach like the following could be used in Rust:</p>
<pre><code><span>let</span><span> wind_sound_handle </span><span>= </span><span>fetch_asset</span><span>("</span><span>wind.wav</span><span>");

</span><span>run</span><span>(</span><span>move </span><span>|</span><span>context</span><span>| {
    </span><span>let</span><span> wind_sound </span><span>= </span><span>None</span><span>;
    </span><span>/* Respond to events and draw requests here */
    </span><span>if let </span><span>Some</span><span>(</span><span>loaded_asset</span><span>) =</span><span> wind_sound_handle</span><span>.</span><span>get_asset</span><span>() {</span><span>
        window_sound </span><span>=</span><span> loaded_asset</span><span>;
    }

    </span><span>/* Respond to events and draw here */
</span><span>});
</span></code></pre>
<p>But that approach can lead to tedious bookkeeping, which is the opposite of what you want for a gamejam.</p>
<p>Instead I decided to use Rust's relatively new feature: <code>async</code>. Fortunately I had recently added <code>asyc</code> support to <code>kApp</code>.</p>
<p>Rust's <code>async</code> feature generates a state machine for a function that allows it to pause and later resume when ready.</p>
<p>An <code>async</code> function can look very similar to a traditional infinite game loop:</p>
<pre><code><span>async </span><span>fn </span><span>run</span><span>(</span><span>app</span><span>:</span><span> Application, </span><span>events</span><span>:</span><span> Events</span><span>) {
    </span><span>let</span><span> wind_sound </span><span>= </span><span>audio</span><span>::</span><span>load_audio</span><span>("</span><span>wind.wav</span><span>").</span><span>await</span><span>.</span><span>unwrap</span><span>();
    </span><span>loop </span><span>{
        </span><span>match</span><span> events</span><span>.</span><span>next_event</span><span>().</span><span>await </span><span>{
            </span><span>/* Respond to events and draw here */
        </span><span>}
    }
}
</span></code></pre>
<p>This let me load assets with one line and not have to worry about any bookkeeping. Perfect!</p>
<h2 id="game-design">Game Design</h2>
<p>The theme for this Ludum Dare was "Keep It Alive" which immediately struck me as overly morbid given the rapid spread of coronavirus. I couldn't motivate myself to create a game about death, and I nearly decided to quit the jam entirely.</p>
<p>Instead I looked for alternative ways to interpret the theme. As I stared out my apartment window towards San Francisco hills I thought about the way people droop their heads as they walk to and from work. It's a beautiful world, but it's tough to notice the beauty every day when the routine of life weighs heavy.</p>
<p>What if you played as a spirit to lift people up? You could keep their "wonder" alive. You'd play as some sort of spirit and perhaps you'd lift a commuter bicyclist up into the sky where you'd whisk them around and show them the stars.</p>
<p>I imagined you'd guide the bicyclist through the sky to collect stars and people on the ground would notice and point up in awe.</p>
<p>It was difficult to figure out how to pair that idea to gameplay, but what I settled upon was a game inspired by the old school flash game <a href="https://www.linerider.com/">Line Rider</a>.</p>
<p>You'd draw lines for the bicyclist and they'd roll along those lines and bump into collectible stars.</p>
<h2 id="implementation">Implementation</h2>
<p>The plan was to implement the physics of the character as a rolling ball and then substitute in character art for the bicyclist.</p>
<p>The first thing I needed was line rendering. I ripped some code out of a prior Rust project that would generate mesh line segments by creating rectangles with circles at the ends. I wasn't sure if this heavy-handed approach to line joins would cause problems. Each individual line segment was made up of a bunch of triangles so I felt that perhaps the game would lag as too many lines appeared.</p>
<p>I stress tested this by scribbling the entire screen full of lines over and over, and I was shocked when the framerate didn't drop at all.</p>
<p>For the physics I took some math for finding the closest point on a line to the ball. If the point is inside the ball then check if the ball's velocity is moving towards the point. If the ball is moving towards the point then "bounce" the ball by pushing the opposite direction on the ball.</p>
<p>The heart of the collision code wasn't very long at all:</p>
<pre><code><span> </span><span>fn </span><span>check_lines</span><span>(&amp;</span><span>mut </span><span>self</span><span>, </span><span>points</span><span>: &amp;</span><span>[Vector3]</span><span>) {
    </span><span>let</span><span> len </span><span>=</span><span> points</span><span>.</span><span>len</span><span>();

    </span><span>for</span><span> i </span><span>in (</span><span>1</span><span>..</span><span>len</span><span>).</span><span>step_by</span><span>(</span><span>2</span><span>) {
        </span><span>let </span><span>(</span><span>distance</span><span>,</span><span> p</span><span>) = </span><span>point_with_line_segment</span><span>(</span><span>self</span><span>.</span><span>position</span><span>,</span><span> points</span><span>[</span><span>i </span><span>- </span><span>1</span><span>],</span><span> points</span><span>[</span><span>i</span><span>]);

        </span><span>if</span><span> distance
            </span><span>&lt; (</span><span>self</span><span>.</span><span>radius </span><span>+ </span><span>LINE_RADIUS </span><span>- </span><span>0.001</span><span>/* Allow ball to sink slightly into surface*/</span><span>)
        {
            </span><span>let</span><span> normal_of_collision </span><span>= (</span><span>self</span><span>.</span><span>position </span><span>-</span><span> p</span><span>).</span><span>normal</span><span>();
            </span><span>let</span><span> velocity_along_collision </span><span>= </span><span>Vector3</span><span>::</span><span>dot</span><span>(</span><span>normal_of_collision</span><span>, </span><span>self</span><span>.</span><span>velocity</span><span>);
            </span><span>if</span><span> velocity_along_collision </span><span>&lt; </span><span>0.0 </span><span>{
                </span><span>self</span><span>.</span><span>velocity </span><span>-=</span><span> normal_of_collision </span><span>*</span><span> velocity_along_collision </span><span>* </span><span>1.4</span><span>;
            }
            </span><span>self</span><span>.</span><span>position </span><span>+=</span><span> normal_of_collision </span><span>* </span><span>0.0001</span><span>;
        }
    }
}
</span></code></pre>
<p>(The code could have been a little cleaner had I known about the <a href="https://doc.rust-lang.org/std/primitive.slice.html#method.chunks">chunks</a> method on iterators.)</p>
<p>I was pretty surprised at how great the ball physics felt without much tuning. When I started with this design the physics felt like a big unknown for me. I felt like I might not be able to get them right within the 48 hour window, but coding the physics was actually one of the shortest features in the project.</p>
<p>I was pretty concerned that the …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ianjk.com/rust-gamejam/">https://ianjk.com/rust-gamejam/</a></em></p>]]>
            </description>
            <link>https://ianjk.com/rust-gamejam/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23836386</guid>
            <pubDate>Tue, 14 Jul 2020 19:14:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reclaiming Technology (From Capital)]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23836329">thread link</a>) | @twazzle
<br/>
July 14, 2020 | https://t.wang.sh/reclaiming-technology | <a href="https://web.archive.org/web/*/https://t.wang.sh/reclaiming-technology">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span>July 14, 2020</span><span>&nbsp; ▴ &nbsp;</span><span>9 minute read 🥤🥤</span><span>🥤🥤</span></p><p>––– views</p></div><p><a href="https://unsplash.com/photos/EOnlL3L3IgQ" target="_blank" rel="nofollow"><span>
      <span></span>
  <img alt="Photo by Aaron Lau on Unsplash" title="Photo by Aaron Lau on Unsplash" src="https://t.wang.sh/static/04199391ac3bf1d6970db96b72a149bf/29d31/sf.jpg" srcset="https://t.wang.sh/static/04199391ac3bf1d6970db96b72a149bf/e52aa/sf.jpg 175w,https://t.wang.sh/static/04199391ac3bf1d6970db96b72a149bf/70ebb/sf.jpg 350w,https://t.wang.sh/static/04199391ac3bf1d6970db96b72a149bf/29d31/sf.jpg 700w,https://t.wang.sh/static/04199391ac3bf1d6970db96b72a149bf/9ecec/sf.jpg 1050w,https://t.wang.sh/static/04199391ac3bf1d6970db96b72a149bf/d165a/sf.jpg 1400w,https://t.wang.sh/static/04199391ac3bf1d6970db96b72a149bf/b17f8/sf.jpg 1600w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
    </span></a></p><blockquote>If you get shown a problem, but have no idea how to control it, you just decide to get used to it.</blockquote><p>When I first got into coding in 2016, I looked at the tech industry with glassy eyes. I was coming off winning a university business pitch competition and felt like I had discovered this hidden treasure trove of amazing people, ideas, and opportunity. Coding, to me, felt like the key that unlocked the doors to this treasure. I was sure that if I just mastered this skill, I’d be welcomed with open arms into this abundant, innovative community.</p><p>On the outside, the modern tech industry epitomizes the American dream. Startups dominate the scene, with funding seemingly available for any wild idea out there. I believed that tech was truly democratizing and that with enough hard work, anyone could find success.</p><p><strong>It’s now 2020, and I no longer hold these views.</strong></p><p>The pivotal points that informed my worldview came from a failed app startup and subsequent grueling job searches. I got lucky a couple of times along the way: receiving an initial angel investment for my app, and also working full-time at <a href="https://designcode.io/" target="_blank" rel="nofollow">Design+Code</a>. On the other hand, I went through hundreds of arduous processes and rejections from startup accelerators, investors, and companies, and saw the struggles of my peers who had less luck and privilege than me. These experiences culminated in me waking up to the true nature of the tech industry. Despite being confident in my newfound coding ability, I had not been handed a key to any sort of treasure. Instead, I was offered a pick and shovel and told to mine gold – to make the treasure pile bigger for those who already have it. Ironically, many of the institutions I talked to refused to give me their pick and shovel, claiming they needed better and more experienced miners.</p><p>The foundation on which the modern tech industry is built upon – <a href="https://nyti.ms/2uXTBPA" target="_blank" rel="nofollow">American capitalism</a> – is fundamentally flawed, and now commonly referred to as late-stage capitalism. This is because we have reached a stage where a tiny percentage of people have accumulated so much capital that they not only exclusively dictate which ideas are worth building, but also dictate who is worthy of building those ideas. When people say that the American Dream is dead, this is what they mean.</p><p>Our society’s continual worship of capital, and of those who hold it, has created extreme inequality that threatens the ideals of a free, democratic society. We are bound to the whim of capital, and to the individuals and groups who have accumulated it.</p><p><strong>It’s time we did something about this – but what can we do?</strong></p><h2 id="chapter-11-a-new-industrial-model-from-abolish-silicon-valley"><a href="#chapter-11-a-new-industrial-model-from-abolish-silicon-valley" aria-label="chapter 11 a new industrial model from abolish silicon valley permalink"></a>Chapter 11: A New Industrial Model, from Abolish Silicon Valley</h2><p>The subtitle of <a href="https://dellsystem.me/" target="_blank" rel="nofollow">Wendy Liu</a>’s new book, <a href="https://abolishsiliconvalley.com/" target="_blank" rel="nofollow">Abolish Silicon Valley</a>, is <em>How to Liberate Technology from Capitalism</em>. Chapter 11, <em>A New Industrial Model</em>, specifically proposes five steps to <em>reclaim our world from capital</em>.</p><p><a href="https://abolishsiliconvalley.com/" target="_blank" rel="nofollow"><span>
      <span></span>
  <img alt="Abolish Silicon Valley: How to Liberate Technology from Capitalism" title="Abolish Silicon Valley: How to Liberate Technology from Capitalism" src="https://t.wang.sh/static/bfd436970b73b3b22b39a77a5972d0bd/8c557/book.png" srcset="https://t.wang.sh/static/bfd436970b73b3b22b39a77a5972d0bd/4edbd/book.png 175w,https://t.wang.sh/static/bfd436970b73b3b22b39a77a5972d0bd/13ae7/book.png 350w,https://t.wang.sh/static/bfd436970b73b3b22b39a77a5972d0bd/8c557/book.png 700w,https://t.wang.sh/static/bfd436970b73b3b22b39a77a5972d0bd/e996b/book.png 1050w,https://t.wang.sh/static/bfd436970b73b3b22b39a77a5972d0bd/2cefc/book.png 1400w,https://t.wang.sh/static/bfd436970b73b3b22b39a77a5972d0bd/0734a/book.png 4266w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
    </span></a></p><p>In <a href="https://abolishsiliconvalley.com/" target="_blank" rel="nofollow">Abolish Silicon Valley</a>, Wendy details her first-hand experience working at Google as a software engineering intern, and then as a founder of a tech startup. She presents an intimate look into the inner workings of the tech industry and the stark issues that plague it. I encourage anyone interested in a deeply personal, inside look into the tech industry to pick up Wendy’s book. In this post, I will aim to explore the proposals in Chapter 11, A New Industrial Model, and spark a conversation around how we can begin to address the problems created by capital.</p><blockquote>...we don't owe capital anything. The things we attribute to capital were built by workers: people who labored and sometimes died in the process, their contributions unrecognized in death as in life. So don't thank capital – it doesn't deserve our gratitude, and it doesn't need it, anyway. Thank the people who created everything that capital always takes credit for.</blockquote><h2 id="reclaiming-entrepreneurship"><a href="#reclaiming-entrepreneurship" aria-label="reclaiming entrepreneurship permalink"></a>Reclaiming Entrepreneurship</h2><p><a href="https://unsplash.com/photos/jw3GOzxiSkw" target="_blank" rel="nofollow"><span>
      <span></span>
  <img alt="Photo by Rohan Makhecha on Unsplash" title="Photo by Rohan Makhecha on Unsplash" src="https://t.wang.sh/static/01c558971dc16b38c4c59b13bf2ead86/8c557/entrepreneurship.png" srcset="https://t.wang.sh/static/01c558971dc16b38c4c59b13bf2ead86/4edbd/entrepreneurship.png 175w,https://t.wang.sh/static/01c558971dc16b38c4c59b13bf2ead86/13ae7/entrepreneurship.png 350w,https://t.wang.sh/static/01c558971dc16b38c4c59b13bf2ead86/8c557/entrepreneurship.png 700w,https://t.wang.sh/static/01c558971dc16b38c4c59b13bf2ead86/e996b/entrepreneurship.png 1050w,https://t.wang.sh/static/01c558971dc16b38c4c59b13bf2ead86/2cefc/entrepreneurship.png 1400w,https://t.wang.sh/static/01c558971dc16b38c4c59b13bf2ead86/29007/entrepreneurship.png 1600w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
    </span></a></p><p>Reclaiming entrepreneurship is the first proposal. The central argument is to have entrepreneurship be accountable to <em>the public</em>, versus <em>private shareholders</em>. Today, this is more commonly referred to as “social entrepreneurship,” where the primary goal is to address social, cultural, or environmental issues rather than turning a profit and returning capital to private investors. To this end, a nonprofit structure works best, as nonprofits have no owners and are accountable to the public and the state. <a href="#references" title="reference">¹</a></p><p>The argument for private ownership usually goes something like this – that without the prospect of reaping the capital benefits of said ownership, people wouldn’t be incentivized to innovate and we would lose all the nice things we have. This argument may hold some truth in a developing world, but today, the incredible wealth concentration created by our current system actually stifles innovation. Real wages have stayed stagnant, fewer companies are being started, and only companies whose products promise to deliver outlandish returns of capital are considered viable. <a href="#references" title="reference">²</a> To make matters worse, Black women, America’s most entrepreneurial demographic, only receive 0.0006% of venture capital funding. <a href="#references" title="reference">³</a></p><p>The standard model for entrepreneurship today is to have an idea, receive investment for that idea, then build it, scale it, and finally return the investment by getting acquired or going public. This model is set up to make the founders, executives, and investors fabulously wealthy. There is no nuance nor any regard for side effects; as long as there is a large return on investment, the venture is considered a success. Thus, the spirit of entrepreneurship and innovation has been clouded by capital. Only by removing this perverse incentive structure and reimagining this standard model, can we expect to have innovation return to America.</p><h2 id="reclaiming-work"><a href="#reclaiming-work" aria-label="reclaiming work permalink"></a>Reclaiming Work</h2><div>
  <p>
    <span>
      <a href="https://t.wang.sh/static/20283e346e324056ca53972aabaf8c29/6e52c/balance.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Tech workers vs. everybody else" title="Tech workers vs. everybody else" src="https://t.wang.sh/static/20283e346e324056ca53972aabaf8c29/8c557/balance.png" srcset="https://t.wang.sh/static/20283e346e324056ca53972aabaf8c29/4edbd/balance.png 175w,https://t.wang.sh/static/20283e346e324056ca53972aabaf8c29/13ae7/balance.png 350w,https://t.wang.sh/static/20283e346e324056ca53972aabaf8c29/8c557/balance.png 700w,https://t.wang.sh/static/20283e346e324056ca53972aabaf8c29/e996b/balance.png 1050w,https://t.wang.sh/static/20283e346e324056ca53972aabaf8c29/2cefc/balance.png 1400w,https://t.wang.sh/static/20283e346e324056ca53972aabaf8c29/6e52c/balance.png 1948w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
  </a>
    </span>
  </p>
  <p>
    <span>
      <a href="https://t.wang.sh/static/d7c841b320ac665e25a32d82f0dd8615/6e52c/balance-dark.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Tech workers vs. everybody else" title="Tech workers vs. everybody else" src="https://t.wang.sh/static/d7c841b320ac665e25a32d82f0dd8615/8c557/balance-dark.png" srcset="https://t.wang.sh/static/d7c841b320ac665e25a32d82f0dd8615/4edbd/balance-dark.png 175w,https://t.wang.sh/static/d7c841b320ac665e25a32d82f0dd8615/13ae7/balance-dark.png 350w,https://t.wang.sh/static/d7c841b320ac665e25a32d82f0dd8615/8c557/balance-dark.png 700w,https://t.wang.sh/static/d7c841b320ac665e25a32d82f0dd8615/e996b/balance-dark.png 1050w,https://t.wang.sh/static/d7c841b320ac665e25a32d82f0dd8615/2cefc/balance-dark.png 1400w,https://t.wang.sh/static/d7c841b320ac665e25a32d82f0dd8615/6e52c/balance-dark.png 1948w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
  </a>
    </span>
  </p></div><p>One thing I find incredibly frustrating is when extremely well-paid, full-time tech workers in Silicon Valley or other tech hubs complain about their salaries. To me, it’s the equivalent of sitting in a fancy restaurant, whining that you didn’t get the same amount of desert as the table sitting next to you, all while people eat garbage in the streets.</p><p>At Google, there exists a large contractor workforce referred to as their “shadow workforce,” a group that outnumbers full-time employees. Most tech companies have contingent labor that makes up for 40-50% of their workforce. <a href="#references" title="reference">⁴</a> This division of the American workforce in the tech industry has created a culture of entitlement at the top and resentment at the bottom. Capitalism requires the wealthy class to own the means of production, so keeping full-time employees (who work on the product) happy is important. However, companies are constantly trying to optimize production, so when a contract workforce can replace production without sacrificing control, companies will outsource this work. As long as we are in a capital-directed system, we can expect the growing trend of contract workers to continue.</p><p>For companies that have increasing contractor workforces, contractors must have a clear path to convert to full-time employees. Contractors who choose not to convert must be paid a higher wage than full-time employees since they aren’t provided benefits. Gig economy workers, like Uber and Lyft drivers, should be given control and flexibility over the jobs they take, the ability to negotiate pay, and a way for workers to collectively bargain and resolve issues with their company. An interesting alternative model for gig workers could be <a href="https://platform.coop/" target="_blank" rel="nofollow">platform co-ops</a>, in which a digital platforms like Uber and Lyft would be owned by the people who depend on and participate in it (the drivers).</p><p>The other proposed solutions in reclaiming work have to do with shifting the power to the working class, reducing income inequality, and improving technological development. These proposals include:</p><ul><li>Giving corporate board seats to democratically elected workers</li><li>Implementing a maximum wage whereby you base the highest-paid wage (typically the CEO) to the lowest-paid wage</li><li>Ensure more equal distribution of stock, or removing stock grants for employees entirely</li><li>Public salary transparency with posted salary bands</li><li>Nationalization of companies with excess profits obtained through rent-seeking, or a combination of lowering prices, increasing R&amp;D spending, increasing wages, and raising taxes</li><li>A strict wealth tax on individuals with a high amount of savings drawing passive income from investments</li><li>Worker control over new technology introduced in the workplace to fit the needs of workers over management</li><li>Software/technical licensing for individuals that comes with a tech version of the Hippocratic oath, with free training and a stipend for higher levels</li><li>A “hiring hall” model that works by a project-by-project basis, instead of being employed at a specific company</li></ul><p>A shocking metaphor for the modern workplace is this idea that workers exist in a system of feudalism, under a complex hierarchy and power structure that intends on making bosses feel like kings and queens. <a href="#references" title="reference">⁵</a> The further we go into late-stage capitalism, the ugliest sides of human history repeat itself. To avoid a further downward spiraling of our most basic freedoms and rights, it is paramount that we take steps to reclaim work for all workers.</p><h2 id="reclaiming-public-services"><a href="#reclaiming-public-services" aria-label="reclaiming public services permalink"></a>Reclaiming Public Services</h2><p>The above tweet by digital researcher and librarian <a href="https://twitter.com/erinroseglass" target="_blank" rel="nofollow">Erin Rose Glass</a> captures succinctly the need for certain industries to be public services rather than owned by private corporations. With software innovation dominating the past decade, we have seen an emergence of surveillance capitalism, where our private data is used to drive engagement and profit. The Internet, which was created based on the principles of free information, decentralized ownership, and open protocols and infrastructure, has been hijacked by private enterprise. <a href="#references" title="reference">⁶</a> We have seen our data analyzed by computational products which aim to predict our behavior, these predictions traded on a new …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://t.wang.sh/reclaiming-technology">https://t.wang.sh/reclaiming-technology</a></em></p>]]>
            </description>
            <link>https://t.wang.sh/reclaiming-technology</link>
            <guid isPermaLink="false">hacker-news-small-sites-23836329</guid>
            <pubDate>Tue, 14 Jul 2020 19:10:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bridging PyTorch and TVM]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23836147">thread link</a>) | @homarp
<br/>
July 14, 2020 | https://lernapparat.de/transformers-pytorch-tvm/ | <a href="https://web.archive.org/web/*/https://lernapparat.de/transformers-pytorch-tvm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div id="submain">
  <article>

  
  
  <p>July 14, 2020</p>
  
  <section>
   <p>Some of the most intriguing applications of Artificial Intelligence have been in Natural Language Processing.
Models like BERT or GPT-2 and their variants can seemingly grasp enough of a text to continue it in a way that needs a second look to recognize as gibberish.</p>
<p>These models belong to a class of neural network architectures called <em>Transformers</em>. One of the favourite libraries implementing them is the <a href="https://github.com/huggingface/transformers/">HuggingFace transformers library</a>.</p>
<p>But, in contrast to convolutional models or LSTMs where we have heavily optimized implementations, this is not as much the case for transformers.
So here we explore how TVM can fill the gap. We will do so in two steps:<span><label for="fn:tvm_blog:"></label><span><span>A shortened version with only the highlights from the TVM perspective is <a href="https://tvm.apache.org/2020/07/14/bert-pytorch-tvm">on the TVM blog</a>.</span></span></span></p>
<ul>
<li>First we look at BERT inference and tuning that on TVM.</li>
<li>Secondly, we start some more fundamental exploration of how one could use TVM for training in PyTorch.
  Given the experimental nature, we focus on feasibility more than on the performance in this part.</li>
</ul>
<h2>BERT inference on TVM</h2>
<p>How do we get BERT into TVM?<span><label for="fn:code:"></label><span><span>The code is available as Jupyter Notebooks on <a href="https://github.com/t-vi/pytorch-tvmisc/tree/master/transformers-pytorch-tvm/">github</a>.</span></span></span></p>
<p>Helpfully, transformers supports tracing their model with the PyTorch JIT. We use their <a href="https://huggingface.co/transformers/torchscript.html">tutorial on it</a>, the following is copied straight from the tutorial.</p>
<div><pre><span></span><span>import</span> <span>transformers</span>

<span>from</span> <span>transformers</span> <span>import</span> <span>BertModel</span><span>,</span> <span>BertTokenizer</span><span>,</span> <span>BertConfig</span>
<span>import</span> <span>numpy</span>

<span>import</span> <span>torch</span>

<span>enc</span> <span>=</span> <span>BertTokenizer</span><span>.</span><span>from_pretrained</span><span>(</span><span>"bert-base-uncased"</span><span>)</span>

<span># Tokenizing input text</span>
<span>text</span> <span>=</span> <span>"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]"</span>
<span>tokenized_text</span> <span>=</span> <span>enc</span><span>.</span><span>tokenize</span><span>(</span><span>text</span><span>)</span>

<span># Masking one of the input tokens</span>
<span>masked_index</span> <span>=</span> <span>8</span>
<span>tokenized_text</span><span>[</span><span>masked_index</span><span>]</span> <span>=</span> <span>'[MASK]'</span>
<span>indexed_tokens</span> <span>=</span> <span>enc</span><span>.</span><span>convert_tokens_to_ids</span><span>(</span><span>tokenized_text</span><span>)</span>
<span>segments_ids</span> <span>=</span> <span>[</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>]</span>

<span># Creating a dummy input</span>
<span>tokens_tensor</span> <span>=</span> <span>torch</span><span>.</span><span>tensor</span><span>([</span><span>indexed_tokens</span><span>])</span>
<span>segments_tensors</span> <span>=</span> <span>torch</span><span>.</span><span>tensor</span><span>([</span><span>segments_ids</span><span>])</span>
<span>dummy_input</span> <span>=</span> <span>[</span><span>tokens_tensor</span><span>,</span> <span>segments_tensors</span><span>]</span>

<span># If you are instantiating the model with `from_pretrained` you can also easily set the TorchScript flag</span>
<span>model</span> <span>=</span> <span>BertModel</span><span>.</span><span>from_pretrained</span><span>(</span><span>"bert-base-uncased"</span><span>,</span> <span>torchscript</span><span>=</span><span>True</span><span>)</span>

<span>model</span><span>.</span><span>eval</span><span>()</span>
<span>for</span> <span>p</span> <span>in</span> <span>model</span><span>.</span><span>parameters</span><span>():</span>
    <span>p</span><span>.</span><span>requires_grad_</span><span>(</span><span>False</span><span>)</span>

<span>transformers</span><span>.</span><span>__version__</span>
</pre></div>





<p>Now we can trace our model. As we want to do inference, we impose evaluation mode and not requiring gradients for the parameters.</p>
<div><pre><span></span><span># Creating the trace</span>
<span>traced_model</span> <span>=</span> <span>torch</span><span>.</span><span>jit</span><span>.</span><span>trace</span><span>(</span><span>model</span><span>,</span> <span>[</span><span>tokens_tensor</span><span>,</span> <span>segments_tensors</span><span>])</span>
<span>traced_model</span><span>.</span><span>eval</span><span>()</span>
<span>for</span> <span>p</span> <span>in</span> <span>traced_model</span><span>.</span><span>parameters</span><span>():</span>
    <span>p</span><span>.</span><span>requires_grad_</span><span>(</span><span>False</span><span>)</span>
</pre></div>


<p>Let us run try our traced model on the GPU:</p>
<div><pre><span></span><span>model</span><span>.</span><span>cuda</span><span>()</span>
<span>tt_c</span> <span>=</span> <span>tokens_tensor</span><span>.</span><span>cuda</span><span>()</span>
<span>st_c</span> <span>=</span> <span>segments_tensors</span><span>.</span><span>cuda</span><span>()</span>
<span>res_pt</span> <span>=</span> <span>model</span><span>(</span><span>tt_c</span><span>,</span> <span>st_c</span><span>)</span>
<span>torch</span><span>.</span><span>cuda</span><span>.</span><span>synchronize</span><span>()</span>
</pre></div>


<p>It worked, but is it fast? Let's run it 100 times and see.
When timing CUDA models, it's always good to do some "warm-up", running the model before the measurement, and we need to be sure to synchronize before the start and end of the timing.</p>
<div><pre><span></span><span>def</span> <span>y</span><span>():</span>
    <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>100</span><span>):</span>
        <span>model</span><span>(</span><span>tt_c</span><span>,</span> <span>st_c</span><span>)</span>
    <span>torch</span><span>.</span><span>cuda</span><span>.</span><span>synchronize</span><span>()</span>

<span>y</span><span>()</span>
<span>%</span><span>timeit</span>  <span>y</span><span>()</span>
</pre></div>


<div><pre><span></span>773 ms ± 2.33 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
</pre></div>


<p>Around 0.65-0.7 seconds for 100 runs means 6.5-7ms per run. That's not too bad.</p>
<p>But let us see if TVM can help us to get faster. Let us convert our model to TVM.</p>
<div><pre><span></span><span>shape_list</span> <span>=</span> <span>[(</span><span>i</span><span>.</span><span>debugName</span><span>()</span><span>.</span><span>split</span><span>(</span><span>'.'</span><span>)[</span><span>0</span><span>],</span> <span>i</span><span>.</span><span>type</span><span>()</span><span>.</span><span>sizes</span><span>())</span> <span>for</span> <span>i</span> <span>in</span>  <span>list</span><span>(</span><span>traced_model</span><span>.</span><span>graph</span><span>.</span><span>inputs</span><span>())[</span><span>1</span><span>:]]</span>
<span>shape_list</span>
</pre></div>


<div><pre><span></span>[('input_ids', [1, 14]), ('attention_mask', [1, 14])]
</pre></div>


<div><pre><span></span><span>mod_bert</span><span>,</span> <span>params_bert</span> <span>=</span> <span>tvm</span><span>.</span><span>relay</span><span>.</span><span>frontend</span><span>.</span><span>pytorch</span><span>.</span><span>from_pytorch</span><span>(</span><span>traced_model</span><span>,</span>
                        <span>shape_list</span><span>,</span> <span>default_dtype</span><span>=</span><span>"float32"</span><span>)</span>
</pre></div>


<div><pre><span></span>ANTLR runtime and generated code versions disagree: 4.8!=4.7.2
ANTLR runtime and generated code versions disagree: 4.8!=4.7.2


WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume …</pre></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lernapparat.de/transformers-pytorch-tvm/">https://lernapparat.de/transformers-pytorch-tvm/</a></em></p>]]>
            </description>
            <link>https://lernapparat.de/transformers-pytorch-tvm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23836147</guid>
            <pubDate>Tue, 14 Jul 2020 18:57:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Performance Reviews Deserve a Review]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23836030">thread link</a>) | @chesterarthur
<br/>
July 14, 2020 | https://staysaasy.com/management/2020/04/22/Writing-Performance-Reviews-101.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/management/2020/04/22/Writing-Performance-Reviews-101.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Performance reviews are some of the most high stakes moments in management. Done well, they communicate a ton to your report: feedback on how to improve, feedback on how to leverage strengths, and firm acknowledgement that you understand the value that they add.  Done poorly, they can spiral into a tailspin of disappointment, sadness, lack of appreciation, lack of understanding, and inert or missing plans for growth. Read on for tips on how to make your performance reviews fall on the happy side of the dividing line.</p>

<h2 id="rule-1-performance-reviews-are-reviews-not-revelations">Rule 1: Performance Reviews Are Reviews, Not Revelations</h2>

<p>There shouldn’t be any surprises in a performance review. If you’re managing performance and growth properly, both should be active conversations, not things to talk about once every six months. To make sure you’re on the righteous path here, have a regular - aim for at least once per month - check-in on both performance and growth for your report.</p>

<h2 id="rule-2-make-sure-your-review-gets-a-review">Rule 2: Make Sure Your Review Gets A Review</h2>

<p>You might be tempted to downplay the significance of a performance assessment by thinking of it as a review instead of a revelation, but that doesn’t mean you shouldn’t be very, very careful in delivering the right message to your report. The written content and verbal delivery of a performance review are some of the most heavily scrutinized things in all of management.</p>

<p>You should have your own manager review the review you’re giving. Engineers review code for something as trivial as a copy update, but the YOLOing of performance reviews is endemic in industry. Your report’s feedback, growth, and performance review are all much higher stakes and more important than a large swath of much more heavily reviewed artifacts in a software company. If nothing else, try this out – the results can be dramatic.</p>

<h2 id="rule-3-be-specific">Rule 3: Be Specific</h2>

<p>Imagine you’re a junior engineer and you get a review that says “Angela is a great engineer and always up for a challenge.” Problems:</p>
<ul>
  <li>If Angela is a junior engineer and is already “great”, what does growth look like? Have they already peaked?</li>
  <li>Feedback is to either tell someone what to change or what to keep doing. “Great engineer” does none of that.</li>
  <li>People change. You’re describing them as having invariant properties vs. describing things they’ve done. This makes it harder for people to process feedback that’s counter to these claims in the future.</li>
</ul>

<p>So, be very specific in what you’re calling out, and give feedback around actions, not attributes. Good examples:</p>
<ul>
  <li>“Anegla showed impressive persistence in delivering her feature through several requirements changes”</li>
  <li>“Angela is a detail-oriented code reviewer, much to the benefit of our team”</li>
</ul>

<h2 id="rule-4-you-might-be-wrong">Rule 4: You Might Be Wrong</h2>

<p>Be ready to be wrong. You can do this in two ways.</p>

<p>First, deliver feedback as observations and impressions, not the word of God:</p>
<ul>
  <li>Bad: “Angela doesn’t like standup”</li>
  <li>Good: “Angela has shown up late repeatedly which makes me think she’s not prioritizing our standup”</li>
</ul>

<p>But remember, you should be talking about review, not revelations. So, the best is:</p>
<ul>
  <li>“As Angela and I have discussed, being late to stand up causes negative impact on the team, and she has taken steps to improve punctuality.”</li>
</ul>

<p>Second, don’t argue in real time. If people think you’re wrong, listen to their point of view and circle back in the near future. One of the most common mistakes is to try and force a point of view upon someone during the review itself. There are multiple reasons for this:</p>
<ul>
  <li>You might be wrong. If you rebut things in real time you’re not leaving space to realize you might be wrong. And even worse, you’re signalling to your report that you don’t think there’s any way you’re wrong and you don’t value their point of view.*</li>
  <li>Half the time disagreements in performance reviews are purely emotional reactions to feedback. Arguing and forcing the issue escalates and exacerbates the situation. Forcing your viewpoint in real time doesn’t leave space for your report to process the feedback.</li>
  <li>No matter what happens, the act of taking a break, potentially getting more feedback and information, and circling back to discuss is almost always a healthier and more productive way to get agreement. Stated another way - forcing the issue almost always only forces submission, not agreement and understanding.</li>
</ul>

<p>*Note: the one time you do need feedback to be final and agreed upon is in a performance improvement plan. By that point, many back and forths should have passed and it’s time to state clearly what needs to change, without compromise.</p>

<h2 id="rule-5-follow-through">Rule 5: Follow Through</h2>

<p>Common problem: you spend all this time crafting great feedback and aligning on growth plans and places to improve, but then you go back to business as usual next week.</p>

<p>Translate the feedback into TODOs in your recurring performance and growth meetings. You should be providing durable and important feedback, so make sure to use it.</p>

<h2 id="takeaways">Takeaways</h2>

<ul>
  <li>Performance Reviews are reviews, not revelations.</li>
  <li>Get feedback on the reviews you write!</li>
  <li>Give specific and useful feedback.</li>
  <li>Be ready to be wrong. Speak in observations instead of conclusions. Don’t argue in real time.</li>
  <li>Follow Through.</li>
</ul>

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/management/2020/04/22/Writing-Performance-Reviews-101.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23836030</guid>
            <pubDate>Tue, 14 Jul 2020 18:48:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Event Driven Level Design]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23835963">thread link</a>) | @bourgoisloic
<br/>
July 14, 2020 | https://loicbourgois.com/event-driven-level-design/index.html | <a href="https://web.archive.org/web/*/https://loicbourgois.com/event-driven-level-design/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="right-panel">
      
      <p>[space] to jump</p>
      
      
      <div id="controls">
        
        
        
      </div>
      <div id="editor">
        
        </div>
    </div></div>]]>
            </description>
            <link>https://loicbourgois.com/event-driven-level-design/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23835963</guid>
            <pubDate>Tue, 14 Jul 2020 18:43:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You've only added two lines – why did that take two days?]]>
            </title>
            <description>
<![CDATA[
Score 812 | Comments 459 (<a href="https://news.ycombinator.com/item?id=23835918">thread link</a>) | @gregdoesit
<br/>
July 14, 2020 | https://www.mrlacey.com/2020/07/youve-only-added-two-lines-why-did-that.html | <a href="https://web.archive.org/web/*/https://www.mrlacey.com/2020/07/youve-only-added-two-lines-why-did-that.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="pagepbt">
<!-- #masthead -->
<div id="contentpbt">
<div id="primarypbt">
<div id="mainpbt" role="main">
<div id="mainblogsec"><div data-version="1" id="Blog1">
<div>
<!--Can't find substitution for tag [defaultAdStart]-->

          <div>
        


          <div>
        
<div>
<article itemprop="blogPost" itemscope="itemscope" itemtype="http://schema.org/BlogPosting">
<a name="8378966868534474355"></a>


<div id="post-body-8378966868534474355" itemprop="articleBody"><p>
It might seem a reasonable question, but it makes some terrible assumptions:</p><ul>
<li>lines of code = effort</li>
<li>lines of code = value</li>
<li>all lines of code are equal</li>
</ul>

<p>
Why did a fix that seems so simple when looking at the changes made take two days to complete?</p>
<div>
<ul>
<li><b>Because the issue was reported with a vague description of how to recreate it.</b> It took me several hours to get to a reliable reproduction of the item. Some developers would have immediately gone back to the person reporting the problem and required more information before investigating. I try and do as much as I can with the information provided. I know some developers don't like having to fix bugs, and so do whatever they can to get out of it. Claiming there isn't enough is a great way to look like you're trying to help but not have to do anything. I know that reporting errors can be hard, and I'm grateful for anyone who does. I want to show appreciation for error reports by trying to do as much as possible with the information provided before asking for more details.</li>
<li><b>Because the reported issue was related to functionality, I'm not familiar with.</b>&nbsp;The feature it was to do with was something I rarely use and is not something I've ever used in great detail. This meant it took me longer than it might to understand how to use it and the nuances of how it interacts with the software with the bug.</li>
<li><b>Because I took the time to investigate the real cause of the issue, not just looking at the symptoms</b>. If some code is throwing an error, you could just wrap it in a try..catch statement and suppress the error. No error, no problem. Right? Sorry, for me, making the problem invisible isn't the same as fixing it. "Swallowing" an error can easily lead to other unexpected side-effects. I don't want to have to deal with them at a point in the future.</li>
<li><b>Because I investigated if there were other ways of getting to the same problem, not just the reported reproduction steps</b>. One set of reproduction steps can easily make the error appear to be in one place when it may actually be more deep-seated. Finding the exact cause of a problem, and looking at all the ways to get there can provide valuable insights. Insights such as how the code is actually used, where there might be other places with possible (other?) problems that might need addressing, or it may show inconsistencies in the code that mean an error is caused (or handled) in one code path but not another.</li>
<li><b>Because I took the time to verify if there were other parts of the code that might be affected in similar ways</b>. If a mistake led to the bug, the same error could have also been made elsewhere in the code-base. Now's a great time to check.&nbsp;</li>
<li><b>Because when I found the cause of the issue, I looked to find the simplest way of fixing it that would have minimal risk of introducing side-effects</b>. I don't want the quickest possible fix. I want a fix that isn't likely to cause confusion or other problems in the future.</li>
<li><b>Because I tested the change thoroughly and verified that it addressed the problem for all the different code paths that were affected</b>. I don't want to rely on someone else to have to test that what I've done is correct. I don't want a bug to be found in the future and for me to have to come back to this code when I've mentally moved on. Context switching is expensive and frustrating. Having a dedicated tester have to look at the "same" change again is something I want to avoid whenever possible.</li>
</ul>

</div>
<div><p>
I don't like having to fix bugs. Partly because they can feel like the result of a previous failure on my part. The other reason I don't like fixing bugs is that I'd prefer to be working on new things.</p><p>

What's worse than having to fix a bug?<br>
Having to fix the same bug repeatedly.<br>
I take the time to make sure any bug is totally fixed any time it is encountered so that it doesn't need to be faced, investigated, fixed, and tested more than once.</p></div>





</div>

<div>
<p><span>
<span>
<a href="https://www.blogger.com/email-post.g?blogID=33176002&amp;postID=8378966868534474355" title="Email Post">
<img alt="" height="13" src="https://img1.blogblog.com/img/icon18_email.gif" width="18">
</a>
</span>
</span></p>

</div>





</article>




</div>

        </div></div>
      
<!--Can't find substitution for tag [adEnd]-->
</div>

</div></div>
</div><!-- #main -->
</div><!-- #primary -->
<!-- #secondary -->
</div><!-- #content -->
<!-- #colophon -->
</div></div>]]>
            </description>
            <link>https://www.mrlacey.com/2020/07/youve-only-added-two-lines-why-did-that.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23835918</guid>
            <pubDate>Tue, 14 Jul 2020 18:38:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What firefighting taught me for my job as an engineering manager]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23835909">thread link</a>) | @andygrunwald
<br/>
July 14, 2020 | https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/#not-only-for-managers | <a href="https://web.archive.org/web/*/https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/#not-only-for-managers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure><img src="https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/christmastree.jpg" srcset="https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/christmastree_hu00761edcb0e9c7da5edfb31ed8e7b79e_140481_360x0_resize_q75_box.jpg 360w, https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/christmastree_hu00761edcb0e9c7da5edfb31ed8e7b79e_140481_700x0_resize_q75_box.jpg 700w" sizes="(max-width: 360px) 360px, (min-width: 700px) 700px"></figure><p><em>— This article is not only for managers! <a href="#not-only-for-managers">read why…</a></em></p><p>I joined the youth group of our small local volunteer fire department in the neighbourhood when I was 12 years old. As a teenager, I was not aware that the youth instructors applied a very smart mix of fun, training, repetition, and strict commands to transform us from clumsy youngsters to real firefighters. Later, I understood that it wasn’t an easy task. I learned how difficult it is to motivate teenagers and train them when I took over the youth instructor role and slowly got into this business (see picture above of my team of youngsters during a fire extinguisher training). It is a challenge to prepare, train, and guide 11-15 years old boys and girls 4 years long while keeping them motivated until they can finally join the crew of adults who extinguish house fires and rescue cats.</p><h2 id="nothing-is-more-difficult-than-motivating-people">Nothing is more difficult than motivating people</h2><p>One would think that the action of fighting a fire already motivates volunteer firefighters to join the weekly training in the evening, several multi-day courses every year, and take over responsibilities in the organization and, thus, sacrifice their free time.</p><p>I have learned that this is not that easy after I was more involved in the management of the organization and was finally elected as the deputy fire chief of our department after 15 years. It might sound corny, but volunteers don’t follow just because you have a higher rank. You need trust and people have to believe that you can handle an operation. If you give the command to enter a burning house, people will only follow your commands if they trust you (and if it makes sense).</p><p>If you give an order that people have to show up at the training next week, they won’t. They don’t have to. It is not the army, it is not their job, they will find excuses and will slowly fade out from the organization. I have experienced hard times when our crew of active people has shrunk from 50 to 20 people.</p><figure><img src="https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/christmastree2_hub9b363f13c5500af6e5d377b5bc450b8_1316400_1500x0_resize_q75_box.JPG" srcset="https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/christmastree2_hub9b363f13c5500af6e5d377b5bc450b8_1316400_360x0_resize_q75_box.JPG 360w, https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/christmastree2_hub9b363f13c5500af6e5d377b5bc450b8_1316400_700x0_resize_q75_box.JPG 700w" sizes="(max-width: 37.5em) 360px, (min-width: 700px) 700px"><figcaption><h4>Team of youngsters at a fire extinguisher training during my time as youth instructor</h4></figcaption></figure><h2 id="they-should-be-proud-to-work-for-us">They should be proud to work for us!</h2><p>Engineers work almost voluntarily for you. They earn a lot of money but as they work for you, they are really good I guess ;) and they will find another good job immediately. Thus, money isn’t a motivator for a longer period of time and you have to keep them motivated.
I already heard CEOs say: they should be proud to work for us. In the long run that even doesn’t work for the <a href="https://en.wikipedia.org/wiki/Big_Tech">Big Five</a>, so I assume, it won’t work for you either.</p><p>I figured that the dynamics of engineers and volunteer firefighter teams are very similar, maybe it applies even for all kinds of teams. In this post I have summarized my top five lessons learned from my time in the fire department and how it helped me to shape my leadership style as an engineering manager.</p><h2 id="lesson-1-provide-structure-and-keep-going">Lesson 1: Provide structure and keep going</h2><p>Especially when the motivation in the team is already down, for a lead, it is super hard to keep going. But this is exactly the most important phase and it is crucial to have a lead who does not give up. For a team in this downwards spiral, the most important thing is structure.</p><p>In the fire department, when the team got smaller and smaller due to a lack of motivation, we made a big mistake: We canceled some of the weekly drills as the group of present people was too small to practise bigger operations—or at least that was the excuse. As a result, even more people got bored and dropped out.</p><p>I saw similar situations in engineering teams when the motivation was down. People got more and more passive and they no longer proposed to catch up, to have brainstorming sessions, or to talk with each other to find the best solution for a problem.</p><p>In this situation it is essential to insist on the routine that you have hopefully already established before you experience difficult times. Do not accept cancellation requests for 1:1 sessions, retrospectives, or other regular meetings. In this dangerous situation, as a lead, you are the tower of strength and you can help the team to overcome the situation. It sounds quite easy but in reality it is not. In such situations I was depressed and unmotivated as well.</p><p>Everybody works differently but I think a piece of general advice is to stabilize yourself first. Do something outside of your job that makes you happy. Approach your allies (in private or business) and discuss the situation to be able to digest it faster. After that, support the team and keep the routine going. For the weekly firefighter drills I prepared backup plans in case too few people showed up. It is always good to have backup plans to be prepared and keep the system going. For 1:1s, you can try to bring some variety to it by e.g. <a href="https://jasonevanish.com/2014/05/29/101-questions-to-ask-in-1-on-1s/">asking different and new questions</a>.</p><figure><img src="https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/flashover_hue1678e2462bbc6923d1f3f2e59deb1b8_457585_1500x0_resize_q75_box.jpg" srcset="https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/flashover_hue1678e2462bbc6923d1f3f2e59deb1b8_457585_360x0_resize_q75_box.jpg 360w, https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/flashover_hue1678e2462bbc6923d1f3f2e59deb1b8_457585_700x0_resize_q75_box.jpg 700w" sizes="(max-width: 37.5em) 360px, (min-width: 700px) 700px"><figcaption><h4>We do regular trainings such as <a href="https://en.wikipedia.org/wiki/Flashover">Flash-over</a> container trainings to be prepared for the real fire</h4></figcaption></figure><h2 id="lesson-2-celebrate-them">Lesson 2: Celebrate them!</h2><p>Celebrate your team and celebrate with the team. I mention it here explicitly because I forgot it too often. Especially as a lead your rhythm is not always synced with the team. It happened regularly to me that during the last phase of a project I was already snowed under with organizational tasks for the next project.</p><p>A simple “thank you” might be enough, or sometimes a big party together with the team is called for. When the team has accomplished something and can move on to the well-deserved resting time, the lead should think about the celebration and how she can thank people. Firefighters sacrifice their free time and join training events while they could spend time with their families, friends, or just enjoy their free time in another way.</p><p>Our fire department is in a higher region in the mountains in Innsbruck in Austria and it happened several times that the team was on duty for several days during natural disasters in winter (snow) and summer (floodings). It is not a big deal to invite over friends and family to a small dinner party in the fire department but you show the appreciation of all the people involved.</p><figure><img src="https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/thankyou.JPG" srcset="https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/thankyou_huf4ae24ba605289f9976a997829732901_242871_360x0_resize_q75_box.JPG 360w, https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/thankyou_huf4ae24ba605289f9976a997829732901_242871_700x0_resize_q75_box.JPG 700w" sizes="(max-width: 37.5em) 360px, (min-width: 700px) 700px"><figcaption><h4>Saying thank you is crucial, not only because we rely on the younger generation in our fire department.</h4></figcaption></figure><p>Your development team might also run into similar exhausting situations. They do over-hours for several weeks to meet a deadline or just work very hard because they believe in the project. This is not the norm and you should thank them. There are many ways of saying “thank you”, and it can range from thanks you deliver in a 1:1 meeting to a bigger team event activity outside of your daily work environment. For me, it is always important that it is an honest “thank you” and that it is not just two words. Again, they could also spend their time in a different way and also other companies pay their employees, that is not unique to you.</p><h2 id="lesson-3-know-your-people-and-support-their-development">Lesson 3: Know your people and support their development</h2><p>It sounds obvious, but do you know your people? Can you answer the following questions for every team member?</p><ul><li>What are the three biggest strengths of the team member?</li><li>What are the motivational factors of the person?</li><li>What non-job-related interests does this person have?</li></ul><p>In our fire department we need people who take responsibility over the IT system, fire trucks, equipment &amp; tools maintenance, operational uniforms, and a lot of other areas. When entering a burning house you better know that the maintenance of tools and equipment was done in a proper way. It is not sufficient to just distribute the responsibilities, you have to know about the passion of people and if they really want to do it. Furthermore, you have to judge if they can and want to learn everything they need to know to take over a responsibility area.</p><figure><img src="https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/abseilen_hu041ad4f09540c8d3b36482d8c3bcbb51_3061870_1500x0_resize_q75_box.jpg" srcset="https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/abseilen_hu041ad4f09540c8d3b36482d8c3bcbb51_3061870_360x0_resize_q75_box.jpg 360w, https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/abseilen_hu041ad4f09540c8d3b36482d8c3bcbb51_3061870_700x0_resize_q75_box.jpg 700w" sizes="(max-width: 37.5em) 360px, (min-width: 700px) 700px"><figcaption><h4>Going beyond personal limits during self-rescue training, abseiling on the wall of a building.</h4></figcaption></figure><p>In a company or team you also find a variety of different tasks that have to be done. Especially in smaller companies you do not have specialists for every single area. This can be a burden but also an opportunity for people to not only do their main job and get bored. Some people like to do other things from time to time and also learn new things.</p><p>A good example is recruiting. Not everybody wants to do it and not everybody is suited for it. You have to know your people and sometimes, also push them a bit to take on new challenges. Some people underestimate themselves very often and think they do not know enough to take on a new challenge. It doesn’t matter if it is about taking the tech lead role of a new project, recruiting, or switching from an individual contributor role to a manager role. When you know people, their skills and interests, you can judge better if they are capable of doing it and you can help or motivate them to find new challenges and develop their skills.</p><h2 id="lesson-4-say-yes">Lesson 4: Say yes!</h2><p>There are tons of leadership articles out there that state saying no is crucial. In a lot of situations that might be true but I disagree with them when it is about company or team culture. Think about yourself and how you feel when approaching somebody with a suggestion and then you get the reply “no” or the more or less equivalent “yes, but…”. I call those phrases motivational killers and using it leads to frustrated team members.</p><p>Saying yes doesn’t mean that you have to accept or like everything. For example, the answer “Yes, that sounds like a feasible idea. How would you implement it?” doesn’t mean that you agreed with it. You can ask more questions and analyze the proposal together with the team member. In the worst case, by answering your questions, the person realizes that there might be some issues with the idea. In the best case, it is worth working on it and there is already a team member who buys in and wants to work on this project.</p><p>I heard a lot of ideas from really young firefighters who proposed new ways of training or super cool training objects like old dry Christmas trees (see image at the beginning of the article). Sometimes, especially with more senior people, a “yes, great idea” as a supporting sign from the lead can be …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/#not-only-for-managers">https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/#not-only-for-managers</a></em></p>]]>
            </description>
            <link>https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/#not-only-for-managers</link>
            <guid isPermaLink="false">hacker-news-small-sites-23835909</guid>
            <pubDate>Tue, 14 Jul 2020 18:38:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Take a gap year and receive $100k to start a company]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23835889">thread link</a>) | @rchandna
<br/>
July 14, 2020 | https://contrarycap.com/content/gap-year-2020 | <a href="https://web.archive.org/web/*/https://contrarycap.com/content/gap-year-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This morning, we launched our gap year investment program, which was covered by <a href="https://www.protocol.com/contrary-capital-100k-gap-year-startup">Protocol</a>, <a href="https://www.forbes.com/sites/amyfeldman/2020/07/14/with-universities-going-online-this-vc-28-plans-to-invest-in-student-entrepreneurs-who-want-a-gap-year/">Forbes</a>, <a href="https://www.businessinsider.com/contrary-capital-giving-students-grants-gap-year-entrepreneur-startup-2020-7">Business Insider</a>, and <a href="https://www.nytimes.com/2020/07/14/business/dealbook/spac-blank-check.html">The New York Times</a>.</p><p>Apply <a href="https://contrarycap.com/gap-year">here</a> to get up to $100,000 to take a gap year and start a company instead.</p><hr><p>The founding principle of Contrary is that most important technology companies — from Google to Snapchat to StitchFix — were started at universities.</p><p>However, this year’s pandemic has significantly impacted founders and their ability to raise capital, find collaborators, and access mentorship. This presents the problem: if you can't meet people on campus, how are you supposed to find a brilliant co-founder, access capital and mentorship, or spend time heads-down building? </p><p>65% of students we surveyed are either considering a leave of absence or have already committed to taking a gap year. Yet the unfortunate reality is that most people can't afford to just take a year off and sit this out. </p><p><strong>That's why we’ve decided to invest up to $100,000* in up to 5 companies who choose to build rather than pay high prices for online classes.</strong></p><p>Contrary's gap year investment program will support members like any other portfolio company: with connections to operators who have scaled companies from zero to thousands of employees, a diverse network of potential hires, and tactical advice from our investment team.</p><p>We have no industry preferences and are also interested in funding international students, irrespective of visa status. A large portion of our portfolio companies were started by immigrants, and we don’t want physical location to get in the way of a startup.</p><p>The only requirements are that teams commit to working on their company full-time from September through spring of 2021, and that at least one member of the team is taking a gap year to build the company (undergrad/grad students and dropouts are welcome). </p><p>Teams can apply by filling out the application <a href="https://contrarycap.com/gap-year">here</a>.</p><p>All applications are due by 8/31, and are considered on a rolling basis. If you have any other questions, don't hesitate to reach out at <a href="https://contrarycap.com/cdn-cgi/l/email-protection#a9cec8d9d0ccc8dbe9cac6c7dddbc8dbd0cac8d987cac6c4"><span data-cfemail="345355444d51554674575b5a404655464d5755441a575b59">[email&nbsp;protected]</span></a>.</p><hr><p><small>*<!-- --> Contrary will be investing in all companies via SAFE.</small></p></div></div>]]>
            </description>
            <link>https://contrarycap.com/content/gap-year-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-23835889</guid>
            <pubDate>Tue, 14 Jul 2020 18:36:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Google Trends to Predict U.S. Elections]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23835760">thread link</a>) | @ancoraallora
<br/>
July 14, 2020 | https://www.superhighway98.com/elections | <a href="https://web.archive.org/web/*/https://www.superhighway98.com/elections">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-nc-base="header" data-controller="AncillaryLayout">
      

      

      <div>

        

        <div>
          
            
              
                
                  
                
              
            
          

          <main>
            
              <section data-content-field="main-content">
                <div data-type="page" data-updated-on="1594751103606" id="page-5f0de21d8480bd4a7f3c5900"><div><div><div data-block-type="2" id="block-48a7aec87d4b40ed3b42"><div><p>For as long as Google Trends has existed, it has correctly predicted the winner of each U.S. presidential election. </p><p>The input is simple: [Candidate's Last Name] + [Election Year]; the output is a remarkably effective way to judge the enthusiasm for any given candidate's campaign*. </p><p>Let's review the predictive powers of the historical data:</p><p><em>*Millions of people may search for a candidate’s last name to find newsworthy or biographical information, however, the inclusion of the election year within a query indicates a more specific intent.</em></p></div></div></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594745378191_9720"><p><h2><strong>2004 U.S. Presidential Election</strong></h2></p></div><div data-block-type="5" id="block-yui_3_17_2_1_1594745378191_10427"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e6a3dd54dd6d5121789a9ff/1594745521876-FBGZU3RJ8CQNHP24H07W/ke17ZwdGBToddI8pDm48kDo7XVuCOORjDEkD_eIwuDMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKctMM4IxEIZ-kgU-HdHOwQFa-X1KiEZwzYHlrZnV-UxQ5-SDPJ_DqFXkMkF7UdbcLP/2004-Election.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5e6a3dd54dd6d5121789a9ff/1594745521876-FBGZU3RJ8CQNHP24H07W/ke17ZwdGBToddI8pDm48kDo7XVuCOORjDEkD_eIwuDMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKctMM4IxEIZ-kgU-HdHOwQFa-X1KiEZwzYHlrZnV-UxQ5-SDPJ_DqFXkMkF7UdbcLP/2004-Election.jpg" data-image-dimensions="1222x667" data-image-focal-point="0.5,0.5" alt="2004-Election.jpg" data-load="false" data-image-id="5f0de2b0d95d7b59b35e8cbe" data-type="image" src="https://www.superhighway98.com/2004-Election.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594745378191_12049"><p>This is the first year that Google Trends data was published. For the entire election year, George W. Bush (the incumbent president) had more search demand than his challenger, John Kerry. Bush won both the popular and electoral vote in 2004.</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1594745378191_13937"><p><h2><strong>2008 U.S. Presidential Election</strong></h2></p></div><div data-block-type="5" id="block-yui_3_17_2_1_1594745378191_14660"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e6a3dd54dd6d5121789a9ff/1594745684630-2HSPOKGQ5NV8K24L1K6A/ke17ZwdGBToddI8pDm48kDo7XVuCOORjDEkD_eIwuDMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKctMM4IxEIZ-kgU-HdHOwQFa-X1KiEZwzYHlrZnV-UxQ5-SDPJ_DqFXkMkF7UdbcLP/2008-Election.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5e6a3dd54dd6d5121789a9ff/1594745684630-2HSPOKGQ5NV8K24L1K6A/ke17ZwdGBToddI8pDm48kDo7XVuCOORjDEkD_eIwuDMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKctMM4IxEIZ-kgU-HdHOwQFa-X1KiEZwzYHlrZnV-UxQ5-SDPJ_DqFXkMkF7UdbcLP/2008-Election.jpg" data-image-dimensions="1222x667" data-image-focal-point="0.5,0.5" alt="2008-Election.jpg" data-load="false" data-image-id="5f0de3541649e924f1ee10e2" data-type="image" src="https://www.superhighway98.com/2008-Election.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594745378191_16406"><p>For the duration of 2008, Barack Obama led John McCain in search demand. Obama won both the popular and electoral vote in 2008 (each, by a significant margin).</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1594745378191_37018"><p><h2><strong>2012 U.S. Presidential Election</strong></h2></p></div><div data-block-type="5" id="block-yui_3_17_2_1_1594745378191_34768"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e6a3dd54dd6d5121789a9ff/1594747088012-O2MU2ZMB8LZH3L0BYC2A/ke17ZwdGBToddI8pDm48kDo7XVuCOORjDEkD_eIwuDMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKctMM4IxEIZ-kgU-HdHOwQFa-X1KiEZwzYHlrZnV-UxQ5-SDPJ_DqFXkMkF7UdbcLP/2012-Election.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5e6a3dd54dd6d5121789a9ff/1594747088012-O2MU2ZMB8LZH3L0BYC2A/ke17ZwdGBToddI8pDm48kDo7XVuCOORjDEkD_eIwuDMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKctMM4IxEIZ-kgU-HdHOwQFa-X1KiEZwzYHlrZnV-UxQ5-SDPJ_DqFXkMkF7UdbcLP/2012-Election.jpg" data-image-dimensions="1222x667" data-image-focal-point="0.5,0.5" alt="2012-Election.jpg" data-load="false" data-image-id="5f0de8cf51baaa2eeebbbd32" data-type="image" src="https://www.superhighway98.com/2012-Election.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594745378191_38258"><p>For the entire year, Barack Obama (the incumbent president) had more search demand than his challenger, Mitt Romney. Obama won both the popular and electoral vote in 2012.</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1594745378191_68695"><p><h2><strong>2016 U.S. Presidential Election</strong></h2></p></div><div data-block-type="5" id="block-yui_3_17_2_1_1594745378191_69361"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e6a3dd54dd6d5121789a9ff/1594749276769-TI27OJHPSA4R4GCXTEV0/ke17ZwdGBToddI8pDm48kDo7XVuCOORjDEkD_eIwuDMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKctMM4IxEIZ-kgU-HdHOwQFa-X1KiEZwzYHlrZnV-UxQ5-SDPJ_DqFXkMkF7UdbcLP/2016-Election.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5e6a3dd54dd6d5121789a9ff/1594749276769-TI27OJHPSA4R4GCXTEV0/ke17ZwdGBToddI8pDm48kDo7XVuCOORjDEkD_eIwuDMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKctMM4IxEIZ-kgU-HdHOwQFa-X1KiEZwzYHlrZnV-UxQ5-SDPJ_DqFXkMkF7UdbcLP/2016-Election.jpg" data-image-dimensions="1222x667" data-image-focal-point="0.5,0.5" alt="2016-Election.jpg" data-load="false" data-image-id="5f0df15c7056e411372101a7" data-type="image" src="https://www.superhighway98.com/2016-Election.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594745378191_71161"><p>In contrast to public opinion polls, Donald Trump had more search demand than Hillary Clinton for the entire year (except for a single week in July). Trump lost the popular vote in 2016, but won the electoral vote and subsequently, won the election.</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1594745378191_72972"><p><h2><strong>2020 U.S. Presidential Election (Forthcoming)</strong></h2></p></div><div data-block-type="5" id="block-yui_3_17_2_1_1594745378191_73681"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e6a3dd54dd6d5121789a9ff/1594749503697-E1GW83VBA11KG0A7LWHD/ke17ZwdGBToddI8pDm48kDo7XVuCOORjDEkD_eIwuDMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKctMM4IxEIZ-kgU-HdHOwQFa-X1KiEZwzYHlrZnV-UxQ5-SDPJ_DqFXkMkF7UdbcLP/2020-Election.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5e6a3dd54dd6d5121789a9ff/1594749503697-E1GW83VBA11KG0A7LWHD/ke17ZwdGBToddI8pDm48kDo7XVuCOORjDEkD_eIwuDMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKctMM4IxEIZ-kgU-HdHOwQFa-X1KiEZwzYHlrZnV-UxQ5-SDPJ_DqFXkMkF7UdbcLP/2020-Election.jpg" data-image-dimensions="1222x667" data-image-focal-point="0.5,0.5" alt="2020-Election.jpg" data-load="false" data-image-id="5f0df23edf9e903fdb5df648" data-type="image" src="https://www.superhighway98.com/2020-Election.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594745378191_76222"><p>Search demand for Donald Trump, the incumbent president, is trending significantly higher than searches for Joe Biden. (In fact, this is the largest disparity in search demand between any other contest of presidential hopefuls). This implies a Donald Trump victory.</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1594745378191_78448"><div><h2><strong>Is History Repeating Itself?</strong></h2><p>The majority of political scientists, and for that matter, data scientists, were unable to correctly predict the results of the 2016 U.S. presidential election. (In fairness to both groups, the election was swung by around 80,000 votes that held electoral significance.)</p><p>Nevertheless, 2020 presidential polls are again at odds with Google search data.</p><p>This data implies that Joe Biden is an uninspiring candidate who faces an uphill battle in the polls; and that Trump’s “silent majority” may indeed be stronger than it was before.</p><p>###</p><p><a href="https://www.superhighway98.com/">&lt;- RETURN TO SUPERHIGHWAY 98</a></p><p><a href="https://www.superhighway98.com/google">HOW GOOGLE RUINED THE INTERNET -&gt;</a></p></div></div></div></div></div>
              </section>
            
          </main>

        </div>
      </div>

      


    </div></div>]]>
            </description>
            <link>https://www.superhighway98.com/elections</link>
            <guid isPermaLink="false">hacker-news-small-sites-23835760</guid>
            <pubDate>Tue, 14 Jul 2020 18:27:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Make Me Think]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23835645">thread link</a>) | @behnamoh
<br/>
July 14, 2020 | https://ralphammer.com/make-me-think/ | <a href="https://web.archive.org/web/*/https://ralphammer.com/make-me-think/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>Until recently everyday objects were shaped by their technology. The design of a telephone was basically a hull around a machine. <strong>The task of the designers</strong> was to <strong>make technology look pretty</strong>.</p>

<p><img data-attachment-id="1293" data-permalink="https://ralphammer.com/make-me-think/makemethink_1/" data-orig-file="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_1.gif?fit=290%2C280&amp;ssl=1" data-orig-size="290,280" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="makemethink_1" data-image-description="" data-medium-file="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_1.gif?fit=290%2C280&amp;ssl=1" data-large-file="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_1.gif?fit=290%2C280&amp;ssl=1" src="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_1.gif?resize=290%2C280" alt="" width="290" height="280" data-recalc-dims="1"></p>
<p>It was up to the <strong>engineers</strong> to <strong>define the interfaces</strong> of those objects. Their main concern was <strong>the function of the machine, not its ease of use</strong>. We — the “users” — had to figure out how they worked.</p>
<p><img data-attachment-id="1294" data-permalink="https://ralphammer.com/make-me-think/makemethink_2/" data-orig-file="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_2.gif?fit=198%2C200&amp;ssl=1" data-orig-size="198,200" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="makemethink_2" data-image-description="" data-medium-file="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_2.gif?fit=198%2C200&amp;ssl=1" data-large-file="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_2.gif?fit=198%2C200&amp;ssl=1" src="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_2.gif?resize=198%2C200" alt="" width="198" height="200" data-recalc-dims="1"></p>
<p>With every technological innovation our everyday objects became richer and increasingly complex. Designers and engineers simply <strong>burdened the users with this increase in complexity</strong>. I am still having nightmares<a href="https://www.youtube.com/watch?v=Kyl2g11KSqc"> trying to get a train ticket from the old BART vending machines in San Francisco</a>.</p>
<p><img data-attachment-id="1295" data-permalink="https://ralphammer.com/make-me-think/makemethink_3/" data-orig-file="https://i2.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_3.gif?fit=225%2C215&amp;ssl=1" data-orig-size="225,215" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="makemethink_3" data-image-description="" data-medium-file="https://i2.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_3.gif?fit=225%2C215&amp;ssl=1" data-large-file="https://i2.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_3.gif?fit=225%2C215&amp;ssl=1" src="https://i2.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_3.gif?resize=225%2C215" alt="" width="225" height="215" data-recalc-dims="1"></p>
<h3>From complicated to simple</h3>
<p>Fortunately, UX (User eXperience) designers have found ways to design beautiful interfaces that are easy to use. Their process can resemble a philosophical enquiry, where they constantly ask questions such as: <strong>What is this really about? How do we perceive this? What is our mental model?</strong></p>
<p><img data-attachment-id="1296" data-permalink="https://ralphammer.com/make-me-think/makemethink_4/" data-orig-file="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_4.gif?fit=222%2C214&amp;ssl=1" data-orig-size="222,214" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="makemethink_4" data-image-description="" data-medium-file="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_4.gif?fit=222%2C214&amp;ssl=1" data-large-file="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_4.gif?fit=222%2C214&amp;ssl=1" src="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_4.gif?resize=222%2C214" alt="" width="222" height="214" data-recalc-dims="1"></p>
<p>Today, as a result of their efforts, we interact with wonderfully designed interfaces. <strong>Designers have been taming complexity for us</strong>. They make extremely sophisticated technology appear simple and easy to use.</p>
<p><img data-attachment-id="1297" data-permalink="https://ralphammer.com/make-me-think/makemethink_5/" data-orig-file="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_5.gif?fit=128%2C200&amp;ssl=1" data-orig-size="128,200" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="makemethink_5" data-image-description="" data-medium-file="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_5.gif?fit=128%2C200&amp;ssl=1" data-large-file="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_5.gif?fit=128%2C200&amp;ssl=1" src="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_5.gif?resize=128%2C200" alt="" width="128" height="200" data-recalc-dims="1"></p>
<h3>From simple to too simple</h3>
<p>And easy sells well. Thus more and more products are based on the promise to <strong>make our lives easier</strong> by <strong>using increasingly complex technologies with ever simpler interfaces</strong>.</p>
<p><img data-attachment-id="1298" data-permalink="https://ralphammer.com/make-me-think/makemethink_6/" data-orig-file="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_6.gif?fit=325%2C284&amp;ssl=1" data-orig-size="325,284" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="makemethink_6" data-image-description="" data-medium-file="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_6.gif?fit=300%2C262&amp;ssl=1" data-large-file="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_6.gif?fit=325%2C284&amp;ssl=1" src="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_6.gif?resize=325%2C284" alt="" width="325" height="284" data-recalc-dims="1"></p>
<p>Just tell your phone what you want and things will appear magically — whether it is the information on a screen or a package delivered to your doorstep. A <strong>gigantic amount of technologies and infrastructure</strong> is domesticated by brave designers and engineers who make all this work.</p>
<p><img data-attachment-id="1299" data-permalink="https://ralphammer.com/make-me-think/makemethink_7/" data-orig-file="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_7.gif?fit=105%2C180&amp;ssl=1" data-orig-size="105,180" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="makemethink_7" data-image-description="" data-medium-file="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_7.gif?fit=105%2C180&amp;ssl=1" data-large-file="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_7.gif?fit=105%2C180&amp;ssl=1" src="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_7.gif?resize=105%2C180" alt="" width="105" height="180" data-recalc-dims="1"></p>
<p>But we don’t see — let alone understand — what is going on behind the scenes, behind the simple appearance. <strong>We are kept in the dark</strong>.</p>
<p><img data-attachment-id="1300" data-permalink="https://ralphammer.com/make-me-think/makemethink_8/" data-orig-file="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_8.gif?fit=177%2C146&amp;ssl=1" data-orig-size="177,146" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="makemethink_8" data-image-description="" data-medium-file="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_8.gif?fit=177%2C146&amp;ssl=1" data-large-file="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_8.gif?fit=177%2C146&amp;ssl=1" src="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_8.gif?resize=177%2C146" alt="" width="177" height="146" data-recalc-dims="1"></p>
<p>You should see me whining like a spoiled brat when a video call is not working as smoothly as expected — all those interruptions and the bad sound quality! An experience which would have appeared nothing short of a <strong>miracle</strong> to people just 50 years ago and which requires the operation of a colossal infrastructure has become an expected normality for me.</p>
<p><strong>We fail to appreciate and to empathise because we don’t understand what is going on.</strong></p>
<p>So does technology makes us dumb? This question isn’t really new. Famously Plato warned us about the detrimental effects of writing — which we know of because he wrote them down.</p>
<h3>The problem with “user centered” design</h3>
<p>In his <strong>excellent</strong> book “Living with complexity” Donald Norman offers numerous strategies for how designers can harness the design of complexity to <strong>improve the user experience</strong>.</p>
<p>And there lies a problem.</p>
<p>I am increasingly wary of the term “<strong>user centered design</strong>”. The word “user” has a second meaning — “consumer of drugs”— which implies <strong>dependance, short-sighted gratification and a reliable source of income for the “dealer”</strong>. The word “centered” excludes pretty much everyone and everything else.</p>
<p><img data-attachment-id="1301" data-permalink="https://ralphammer.com/make-me-think/makemethink_9/" data-orig-file="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_9.gif?fit=230%2C140&amp;ssl=1" data-orig-size="230,140" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="makemethink_9" data-image-description="" data-medium-file="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_9.gif?fit=230%2C140&amp;ssl=1" data-large-file="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_9.gif?fit=230%2C140&amp;ssl=1" src="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_9.gif?resize=230%2C140" alt="" width="230" height="140" data-recalc-dims="1"></p>
<h3>A holistic approach to complexity</h3>
<p>As an alternative we should widen our perspective and ask questions such as:</p>
<h4>Empowerment: Who’s having the fun?</h4>
<p>Maybe being able to speak a foreign language is more fun than using a translation software.</p>
<p>Whenever we are about to substitute a laborious activity such as learning a language, cooking a meal, or tending to plants with a — deceptively — simple solution, we might always ask ourselves: <strong>Should the technology grow — or the person using it?</strong></p>
<p><img data-attachment-id="1302" data-permalink="https://ralphammer.com/make-me-think/makemethink_10/" data-orig-file="https://i2.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_10.gif?fit=526%2C157&amp;ssl=1" data-orig-size="526,157" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="makemethink_10" data-image-description="" data-medium-file="https://i2.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_10.gif?fit=300%2C90&amp;ssl=1" data-large-file="https://i2.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_10.gif?fit=526%2C157&amp;ssl=1" src="https://i2.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_10.gif?resize=526%2C157" alt="" width="526" height="157" data-recalc-dims="1"></p>
<h4>Resilience: Does it make us more vulnerable?</h4>
<p>Highly sophisticated systems work flawlessly, <strong>as long as things go as expected</strong>.</p>
<p>When a problem occurs which hasn’t been anticipated by the designers, those systems are prone to fail. <strong>The more complex the systems are, the higher are the chances that things go wrong</strong>. They are less resilient.</p>
<p><img data-attachment-id="1303" data-permalink="https://ralphammer.com/make-me-think/makemethink_11/" data-orig-file="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_11.gif?fit=458%2C206&amp;ssl=1" data-orig-size="458,206" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="makemethink_11" data-image-description="" data-medium-file="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_11.gif?fit=300%2C135&amp;ssl=1" data-large-file="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_11.gif?fit=458%2C206&amp;ssl=1" src="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_11.gif?resize=458%2C206" alt="" width="458" height="206" data-recalc-dims="1"></p>
<p>A chronic dependance on a combination of electronics, artificial intelligence and a high speed internet connection for the simplest tasks is a recipe for disaster. It makes our lives more complicated, especially when we don’t understand what is going on behind the deceptively simple interface.</p>
<h4>Empathy: What is the impact of simplification on others?</h4>
<p>Our decisions have consequences for ourselves and others. <strong>A simplified appearance can make us blind to those consequences</strong>.</p>
<p><img data-attachment-id="1304" data-permalink="https://ralphammer.com/make-me-think/makemethink_12/" data-orig-file="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_12.gif?fit=565%2C275&amp;ssl=1" data-orig-size="565,275" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="makemethink_12" data-image-description="" data-medium-file="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_12.gif?fit=300%2C146&amp;ssl=1" data-large-file="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_12.gif?fit=565%2C275&amp;ssl=1" src="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_12.gif?resize=565%2C275" alt="" width="565" height="275" data-recalc-dims="1"></p>
<p>Our decision what smart phone to buy or what to have for dinner has a huge impact on other living beings. Knowing about the complexity behind such a decision can be of tremendous value. <strong>We need to know things better if we want to be better</strong>.</p>
<p><strong>Embracing complexity</strong></p>
<p>Simplification is a powerful design strategy. Naturally the button to make an emergency call should be as simple as possible. And yet, we also need further design strategies that help us accept, understand, and interact with complex situations in our lives.</p>
<h3>Before you go</h3>
<p><em>If you enjoyed this article, please <strong>use the buttons below</strong> to</em><em>&nbsp;<strong>share the story</strong> with your friends&nbsp;</em><em>and </em><a href="http://eepurl.com/cJJLR1" target="_blank" rel="noopener nofollow noreferrer"><strong><em>subscribe to my mailing list </em></strong></a><em>!</em></p>

				</div></div>]]>
            </description>
            <link>https://ralphammer.com/make-me-think/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23835645</guid>
            <pubDate>Tue, 14 Jul 2020 18:20:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Let’s avoid talk of ‘chemical imbalance’: it’s people in distress – Psyche Ideas]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23835517">thread link</a>) | @rbanffy
<br/>
July 14, 2020 | https://psyche.co/ideas/lets-avoid-talk-of-chemical-imbalance-its-people-in-distress | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/lets-avoid-talk-of-chemical-imbalance-its-people-in-distress">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>After Jenna discovered</strong> that her boyfriend was cheating on her, she went into an emotional tailspin. She was â€˜crying all the timeâ€™, struggled to attend her university classes, slept a lot and avoided situations she normally enjoyed.</p><p>In recounting her emotional reaction, Jenna stressed to me its unreasonableness. Given that she and her boyfriend hadnâ€™t been dating for long, she felt that she shouldnâ€™t have been so upset. After a month, she decided that something was seriously amiss and that she needed professional help. She recalled her psychiatrist diagnosing depression and telling her the problem might be caused by a chemical imbalance in her brain, for which she was prescribed an antidepressant.</p><p>Jenna found her emotional reactions jarring. They defied her basic assumptions about herself as confident, mature and self-sufficient. She told me she welcomed the diagnosis of a neurobiological disorder, which confirmed her problem was â€˜realâ€™ â€“ brought on by a physiological force external to her volition â€“ and that it showed sheâ€™s not â€˜just a slackerâ€™.</p><p>At the same time, Jenna was careful to distance her experience from that of people who are, in her words, â€˜crazyâ€™ or â€˜nutsâ€™. Their illness means a loss of control and ability to function. By contrast, she sees her problem as a common and minor glitch in neurochemistry. No one, she insisted, should mistake her for the mentally ill.</p><p>Jenna was one of 80 diverse volunteers that a research team at the University of Virginia and I interviewed in Chicago, Baltimore, Boston and two small cities in central Virginia. We wanted to find out how people deal with common forms of psychological distress and challenging circumstances, such as: shyness and nervousness in social situations; underperformance at work or school; struggles after the loss of a significant relationship; and disappointment with how their lives are unfolding. A majority of our interviewees had received some form of psychotherapy and/or been diagnosed with a condition such as depression, social anxiety disorder or attention deficit disorder, and prescribed a psychiatric medication.</p><p>It was striking that many (though not all) at least partly explained their distress in terms of biological causes, particularly a neurochemical imbalance. Yet thinking of their problems in this way was a fraught process. Like Jenna, many interviewees sharply distinguished themselves from the mentally ill and cast the mentally ill in a very negative light. This stigmatising of people with serious mental illness wasnâ€™t based on any first-hand experiences; rather, it was motivated by a desire to protect their own dignity and social standing. To justify the distinction between their own situation and mental illness, our interviewees rejected the idea that they had an â€˜illnessâ€™ as such, detached themselves from any formal diagnosis using statements such as â€˜thatâ€™s what the doctor calls itâ€™ or, in some cases, they avoided seeking medical help altogether.</p><p>For people like Jenna, who embraced a neurobiological explanation for their problems, this created a conundrum, which many of them resolved by creating a separate classification for their own experience â€“ what I have called a â€˜third conditionâ€™. The people we spoke to did not give this â€˜conditionâ€™ a name or explicit meaning. Rather it emerged in the rhetorical space opened up by the way they framed their personal struggle, distinguishing it from mental illness, on the one hand, and normality, on the other.</p><p><strong>Consider the perspective</strong> of another of our interviewees, a young woman Iâ€™ll call Piper, who had been diagnosed with depression. When â€˜you think mental illnessâ€™, according to Piper, â€˜you think schizophrenia and crazy people, and Iâ€™m not crazy, I just get really nervous.â€™ In making this distinction, interviewees like Piper and Jenna not only claimed that they were less impaired than the seriously mentally ill, they also insisted that their experience was categorially different. Piper said of herself that biologically something is just â€˜a little offâ€™. She has â€˜too little or too much or whatever it is that makes you have these issuesâ€™. Distinct from â€˜crazy peopleâ€™, she has control over her mind and her story. All she needs is a little pill. Yet at the same time, her â€˜conditionâ€™ is also different from the mundane challenges that normal people might face. Piper was adamant that her nervousness in social situations is different from ordinary shyness. Her taking of medication is warranted. She has a third condition caused by an â€˜imbalanceâ€™.</p><p>The â€˜crazy peopleâ€™ are shadowy, depersonalised figures â€“ the damaged, uncontrolled â€˜otherâ€™ </p><p>To reconcile their perspective with the fact that they had received a psychiatric diagnosis, many interviewees credited a medical professional or a confidant for suggesting something like this third condition idea to them. Others emphasised the ordinariness of their experience and compared it to the types of routine problems that regular physicians treat. As one interviewee put it, â€˜all you have to do is take a pillâ€™.</p><p>There are echoes here of the messages conveyed in direct-to-consumer advertising for psychiatric medication. Iâ€™ve analysed the content of these adverts and found that distress, as listed in symptoms and portrayed in the patientsâ€™ stories, is often presented as a â€˜real medical conditionâ€™ and yet unlike mental illness. The ads contain no references to psychiatrists or to the diagnostic manual of mental disorders from the American Psychiatric Association (APA), nor use of phrases such as â€˜mental illnessâ€™ or â€˜mental disorderâ€™, and no depictions of those affected as anything but productive and successful citizens. In the words of our interviewees and in the advertising messages, the â€˜crazy peopleâ€™ are shadowy, depersonalised figures â€“ the damaged, uncontrolled â€˜otherâ€™ against whom the implicit comparisons are being drawn.</p><p>The views we encountered in our interviews are consistent with national surveys of public opinion about mental health. Today, with respect to mental health problems, the lay public much more freely endorses biological causes, the seeking of medical help and the use of psychoactive medications than in the past. Their views have converged with the biological perspectives long promoted in public campaigns to reduce the stigma of mental illness. According to the American anti-stigma organisation Bring Change to Mind, for instance: â€˜The fact is, a mental illness is a disorder of the brain â€“ your bodyâ€™s most important organ.â€™ Among anti-stigma researchers and activists, the evolution in public attitudes toward biological psychiatry has been celebrated as a sign that the public has at long last become â€˜literateâ€™, with a â€˜more scientificâ€™ even â€˜sophisticatedâ€™ understanding of mental illness.</p><p>In promoting a biogenetic causal theory, anti-stigma campaigners â€“ as well as psychiatrists, the popular media, and others â€“ hoped to convince people that mental illnesses are â€˜just likeâ€™ other chronic physical ailments, such as â€˜heart disease or diabetesâ€™, to <a href="https://www.psychiatry.org/patients-families/what-is-mental-illness" target="_blank">quote</a> the APA, and could be medically addressed. This approach would, in turn, alleviate mental illness stigma and foster tolerance by reducing the (allegedly common) tendency to hold sufferers responsible for their condition. The result, it was confidently believed, would promote treatment optimism and increased help-seeking.</p><p>But something unexpected happened. The public embrace of neurobiology has not led to a more benevolent orientation toward the mentally ill. Rather, according to an <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4409431/" target="_blank">editorial</a> in the <em>Journal of Psychiatry and Neuroscience</em> in 2015, â€˜well-conducted studies have concluded, almost uniformlyâ€™ that the stigma-reduction strategy of recent decades, informed by â€˜biogenetic attribution of all mental disordersâ€™, has â€˜not only not worked, but also may have worsened public attitudes and behaviour toward those with mental illnessesâ€™. Such studies have shown that the growing endorsement of biological causation has continued to exacerbate the stigmatising of mental illness among the <a href="https://www.cambridge.org/core/journals/the-british-journal-of-psychiatry/article/biogenetic-explanations-and-public-acceptance-of-mental-illness-systematic-review-of-population-studies/E6078EED07031B5828DB84FCDC90657F" target="_blank">general public</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/20493559/" target="_blank">patients</a> and <a href="https://www.pnas.org/content/111/50/17786" target="_blank">professionals</a>.</p><p>What accounts for this paradoxical result?</p><p><strong>I believe that </strong>our interviews reveal a crucial reason. While people accepted a neurobiological explanation for their problems, they struggled against the dehumanising notion that their thoughts, feelings or behaviour were mechanistically <em>caused.</em> Drawing on clinicians, drug ads and the popular media, the caricature of the seriously mentally ill served as a pivotal image by which to contrast and affirm their own control and self-determination. Millions of Americans â€“ and countless others in Western countries â€“ likely find themselves sharing this or a similar perspective.</p><p>The idea that oneâ€™s distress is primarily caused by a neurochemical deficiency that can be corrected by a drug is a fiction</p><p>As I argue in my <a href="https://press.uchicago.edu/ucp/books/book/chicago/C/bo48408677.html" target="_blank">book</a> <em>Chemically Imbalanced</em> (2020), to defeat this othering and reduce stigma, clinical practice needs to move away from biogenetic causal language. Psychiatric research doesnâ€™t support the notion of simple cause and effect in mental health, instead uncovering a far more complex and indeterminate picture of vulnerabilities. There is no evidence to justify the continued promotion of one-dimensional theories such as â€˜chemical imbalanceâ€™. Nor does the beneficial use of psychiatric medicines require it. In fact, their precise mechanism of action and relation to troublesome experience <a href="https://www.frontiersin.org/articles/10.3389/fpsyt.2019.00407/full" target="_blank">remains</a> a mystery. It would be more truthful for mental health professionals and public health campaigns to acknowledge this.</p><p>Itâ€™s true, as interviewees such as Jenna made clear, that patients often find biogenetic language appealing. It provides a way to establish their suffering as both tangible and unfeigned, and it offers a simple account and positive prognosis for their struggles. However, the …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/ideas/lets-avoid-talk-of-chemical-imbalance-its-people-in-distress">https://psyche.co/ideas/lets-avoid-talk-of-chemical-imbalance-its-people-in-distress</a></em></p>]]>
            </description>
            <link>https://psyche.co/ideas/lets-avoid-talk-of-chemical-imbalance-its-people-in-distress</link>
            <guid isPermaLink="false">hacker-news-small-sites-23835517</guid>
            <pubDate>Tue, 14 Jul 2020 18:11:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Demo app of the first cloud storage that uses only browser JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23835515">thread link</a>) | @ent101
<br/>
July 14, 2020 | https://www.outpan.com/app/4b9863258e/bmi-calculator-weight-loss-tracker | <a href="https://web.archive.org/web/*/https://www.outpan.com/app/4b9863258e/bmi-calculator-weight-loss-tracker">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><nav role="navigation"><div><div><form action="/search" method="get"></form><p><img src="https://opimg.s3.amazonaws.com/4b9863258e-200x200.jpg" id="app-toolbar-icon"></p><div id="app-options-wrapper"><div><div><p data-toggle="modal" data-target="#review-modal" id="reviews-modal-link" title="View reviews or write one"><span></span> <span>8</span></p></div></div></div></div><div id="navbar-user-items" aria-expanded="false"><p><a href="https://www.outpan.com/signup">Sign Up</a></p><ul><li></li></ul><ul><li><a href="https://www.outpan.com/">Home</a></li><li><a href="https://www.outpan.com/login">Login</a></li><li><a href="https://www.outpan.com/signup">Sign Up</a></li></ul><form action="/search" method="get"></form></div></div></nav><div><div><div><div></div></div></div></div></div>]]>
            </description>
            <link>https://www.outpan.com/app/4b9863258e/bmi-calculator-weight-loss-tracker</link>
            <guid isPermaLink="false">hacker-news-small-sites-23835515</guid>
            <pubDate>Tue, 14 Jul 2020 18:11:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The History of Math Rock, Pt 1 (2015)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23835340">thread link</a>) | @Elof
<br/>
July 14, 2020 | http://feckingbahamas.com/history-math-rock-pt-1-guess-black-flag-math-rock-now | <a href="https://web.archive.org/web/*/http://feckingbahamas.com/history-math-rock-pt-1-guess-black-flag-math-rock-now">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

						
						<article id="post-4600">

							
							<section itemprop="articleBody">

								<span itemprop="reviewBody">
<p>Look, let’s be honest. We can attempt to write a full-fledged, well-attested, unabridged recount of four decades of math rock history and it is still going to be wrong. The bane of theorists and historians the world over is the rewriting of previous records due to emergent refutations, subjective arguments, and, in some cases, author bias. Adding to the complications is, of course, the exhaustive list of underdogs overlooked by the critics and historians, which, upon revelation, demand a restructuring of the original story: punk rock’s <a rel="noopener noreferrer" href="http://www.theguardian.com/music/musicblog/2009/feb/09/detroit-band-death" target="_blank"><u>Death</u></a>, heavy metal’s <a rel="noopener noreferrer" href="http://ultimateclassicrock.com/blue-cheer-vincebus-eruptum/" target="_blank"><u>Blue Cheer</u></a>, and countless others.</p>
<p>It is, perhaps, even more difficult with such a malleable genre as math rock. At its core, ‘math rock’ is the amalgamation of the distorted guitar riffs of punk and hardcore, and the metrical asymmetry associated primarily with 1970s progressive rock, and the history of math rock we present to you will appear to show this fusion. In his essay <em>How Alternative Turned Progressive: The Strange Case Of Math Rock</em> Theo Cateforis defines math rock music as being defined through “<em>the absence of a steady, divisible pulse</em>” <a rel="noopener noreferrer" href="http://www.academia.edu/7315935/How_Alternative_Turned_Progressive_The_Strange_Case_of_Math_Rock" target="_blank"><u><sup>[1]</sup></u></a>. Yet, in the past the word ‘math’ has be used to describe <em>anything</em> dissonant in structure, and has been applied to hardcore (‘mathcore’) and metal (‘math metal’). Thus, a problem exists in that this label could cover quite large territory and, with some leeway, could be used to describe the meter-bending works of <em><strong>Yes</strong></em>, <strong><em>Dave Brubeck</em></strong>, or even <strong><em>Igor Stravinsky</em></strong>. So what is ‘math’? Is it a genre, or is it an adjective, perhaps?</p>
<p>In this four part series, we are stockpiling ambition up our sleeves to set the record straight not only on ‘math rock’ but the word ‘math’ itself. It’s no surprise to some that term has been consistently met with derision; for the alternative kids growing up in the 80’s and 90’s many considered it a derogatory notion, which implied showmanship, excessive virtuosity and pretentiousness (something that seems to be overlooked when it comes to solo-shredding heavy metal guitarists). We hope to provide you with a comprehensive history of ‘math’ in music, starting from the US-rooted math rock boom of the 80’s/90’s, working backwards through the 1970’s progressive rock era of <strong><em>King Crimson</em></strong> and <em><strong>Yes</strong></em>, and finally ending up all the way back in the classical works of yester-century. Perhaps then we can start to idealise what ‘math’ is. But in order to tell the story right, we need to start in Los Angeles during the 70’s…</p>
<hr>
<p><img src="https://i0.wp.com/feckingbahamas.com/wp-content/uploads/2015/04/The_Screamers.jpg?resize=211%2C300" alt="The_Screamers" width="211" height="300" srcset="https://i0.wp.com/feckingbahamas.com/wp-content/uploads/2015/04/The_Screamers.jpg?resize=211%2C300 211w, https://i0.wp.com/feckingbahamas.com/wp-content/uploads/2015/04/The_Screamers.jpg?w=382 382w" sizes="(max-width: 211px) 100vw, 211px" data-recalc-dims="1" data-old-src="https://i0.wp.com/feckingbahamas.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif?resize=211%2C300" data-src="http://feckingbahamas.com/wp-content/uploads/2015/04/The_Screamers-211x300.jpg" data-srcset="https://i0.wp.com/feckingbahamas.com/wp-content/uploads/2015/04/The_Screamers.jpg?resize=211%2C300 211w, https://i0.wp.com/feckingbahamas.com/wp-content/uploads/2015/04/The_Screamers.jpg?w=382 382w"></p>
<h3>1976-1985</h3>
<p><strong><em>The Early Hardcore Punk Movement: Screams, Polyrhythms, And Word Of Math</em></strong></p>
<p>Tomata Duplenty of <em><strong>The Screamers</strong></em> was probably the first punk rock frontman to scream his lyrics. In fact, he was probably the first screaming frontman of any genre. The LA band comprised two keyboardists, a drummer, and Duplenty; an unusual combination of instruments for an undeniably punk band. The Screamers weren’t math rock, but their <a rel="noopener noreferrer" href="https://www.youtube.com/watch?v=MdCRcrgX080" target="_blank"><u>unconventional approach to an already unconventional genre</u></a> was an influence on a fresh spawn of punk rock bands forming in LA during the late 70’s and early 80’s. Of these, two in particular are especially important to math rock.</p>
<p><em><strong>Black Flag</strong></em> was formed by Greg Ginn in 1976. Initially fronted by Keith Morris (of <strong><strong>Circle Jerks</strong></strong> and, more recently, <em><strong>OFF!</strong></em> fame), and subsequently succeeded by the bellowing and fiercely-pissed-off Henry Rollins, the band brought an overwhelmingly raw and ferocious sound to punk rock, and were pivotal in solidifying ‘hardcore punk’. However, it is Black Flag’s 1984 release ‘My War’ that is pertinent to math rock history. A clear deviation from previous albums, the record comprised several primordial math rock tracks: ‘Swinging Man’, ‘Three Nights’ and ‘Scream’. The ‘mathiness’ of these songs were mainly based around the polyrhythmic percussion of Bill Stevenson. He’d been put on <em><strong>Mahavishnu Orchestra</strong></em> by guitarist Greg Ginn <a rel="noopener noreferrer" href="http://www.invisibleoranges.com/2013/01/heavy-metal-be-bop-9-greg-ginn/" target="_blank"><u><sup>[2]</sup></u></a>, and they had influenced his craft both here and in his other bands <em><strong><a rel="noopener noreferrer" href="https://youtu.be/_0BHktyIyQ8" target="_blank"><u>The Descendents</u></a></strong></em> and <em><strong><a rel="noopener noreferrer" href="https://youtu.be/z6mPn6j5UKw" target="_blank"><u>All</u></a></strong></em>. In 1985, Black Flag recorded the entirely instrumental album <em>The Process of Weeding Out</em>, which was perhaps Greg Ginn’s attempt to write as weird and as challenging music as he could. It is quite possible that this was the <a rel="noopener noreferrer" href="https://www.youtube.com/watch?v=C_BqufJhHYA" target="_blank"><u>first math rock album</u></a>.</p>
<div><iframe data-lazy-type="iframe" data-src="https://www.youtube.com/embed/r-dMjruMHBk" width="400" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe>
<p><small><em><strong>Black Flag</strong> – ‘The Swinging Man’ from <em>My War</em> (1984)</em></small></p>
</div>
<p>The influence of Mahavishnu Orchestra on Greg Ginn’s guitar playing <a rel="noopener noreferrer" href="http://www.invisibleoranges.com/2013/01/heavy-metal-be-bop-9-greg-ginn/" target="_blank"><u><sup>[2]</sup></u></a> suggests the influence of progressive rock on early punk rock, and thus a key constituent in the preliminary math rock blueprints. <em><strong>Minutemen</strong></em> was formed by a bunch of San Pedro kids in 1980, following the demise of <em><strong>The Reactionaries</strong></em> who, like Black Flag, had taken influence from progressive rock heavyweights like <em><strong>Captain Beefheart and the Magic Band</strong></em> <a rel="noopener noreferrer" href="http://inflooenz.com/?artist=Minutemen&amp;influencer=captain+beefheart+%26+the+magic+band" target="_blank"><u><sup>[3]</sup></u></a>. Greg Ginn incidentally produced the band’s first EP, <em>Paranoid Time</em>, a barrage of quick and snappy punk rock tracks. The 1981 release <em><a rel="noopener noreferrer" href="https://www.youtube.com/watch?v=7xYHzC_yYTk" target="_blank"><u>The Punch Line</u></a></em> was an 18 track discourse in compact, rambunctious and deliberately non-commercial music-making. While not deviating from 4/4 explicitly, the album contained experimental interplay between guitar and bass, and unusually syncopated percussion. Interestingly, the eighteenth track of Minutemen’s 1982 magnum opus <em>Double Nickels On The Dime</em> is named ‘<a rel="noopener noreferrer" href="https://www.youtube.com/watch?v=wRbNqeW7BJI" target="_blank"><u>God Bows To Math</u></a>‘, a short yet complexly syncopated piece, and an ironic omen for the later coining of the term ‘math rock’. While this conflicts with claims made almost a decade later (see below), a number of musicians have informed us that the term was being used from at least the mid-late 80’s. Minutemen disbanded after the tragic passing of guitarist D.Boon in a car accident.</p>
<p>As progressive rock was moulding a new generation of experimental punk through the early 80’s, something interesting was also taking shape in the north. Two years prior to Black Flag’s release of <em>My War</em>, Canadian brothers John and Rob Wright had commenced their first studio recording as a drum and bass two-piece. Their band, <strong><em>Nomeansno</em></strong>; the album <em>Mama</em>. Although not as jazzy or punky as their later releases <em>Sex Mad</em> (1986), <em>Small Parts Isolated And Destroyed</em> (1988) and <em>Wrong</em> (1989), the influence of jazz, progressive rock and post-punk in these albums is undeniable. The experimental nature of late 70’s post-punk movements, bands like <em><strong>Gang Of Four</strong></em> and <em><strong>PiL</strong></em>, had instilled some confidence in the Wright brothers to counterbalance the absence of guitar with richer rhythms and compositions to ‘fill out the sound’<a rel="noopener noreferrer" href="http://thequietus.com/articles/12566-nomeansno-john-wright-interview" target="_blank"><u><sup>[4]</sup></u></a>. Music was always in the Wright household: jazz, rock, Beatlemania and big band.<a rel="noopener noreferrer" href="http://www.vice.com/read/going-gray-with-nomeansno" target="_blank"><u><sup>[5]</sup></u></a> <a rel="noopener noreferrer" href="https://www.youtube.com/watch?v=wDVpno7bwtg" target="_blank"><u>And there was certainly evidence of this in <em>Mama</em></u></a>. What the Wright Brothers started in <em>Mama</em> would quickly blossom into jazzy and prog-rich punk rock.</p>
<div><iframe data-lazy-type="iframe" data-src="https://www.youtube.com/embed/loNI2Mlc_lc" width="400" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe>
<p><small><em><strong>Nomeansno</strong> – ‘Junk’ from <em>Small Parts, Isolated And Destroyed</em> (1988)</em></small></p>
</div>
<p><strong><em>No-Wave: Music Rebellion With A Touch Of Grind</em></strong></p>
<p>There is another, and perhaps slightly overlooked, angle to the math rock story. Contemporaneous with the early experimental divergences in LA punk rock was the emergence of the ‘No Wave’ movement, a late 70’s ideological counter-response to the overt happiness and mainstream success slowly enveloping the New Wave fad<a rel="noopener noreferrer" href="http://pitchfork.com/features/articles/6764-no-the-origins-of-no-wave/" target="_blank"> <u><sup>[6]</sup></u></a>. Artists were starting to make ugly, disjointed music in conjunction with their frustrations with New Wave. No Wave is likely to have started a couple of years earlier when <em><strong>Brian Eno</strong></em>, taking direct influence from a five-day festival he attended at New York’s non-profit <em>Artists Space</em> venue, quickly produced a compilation spotlighting what he saw as an exciting rebellious music movement. The 1978 compilation, <em><a rel="noopener noreferrer" href="http://www.allmusic.com/album/no-new-york-mw0000260455" target="_blank"><u>No New York</u></a></em>, appeared as a denigration towards New Wave music. The music lacked exuberance and, instead, was <a rel="noopener noreferrer" href="https://www.youtube.com/watch?v=re6uN1lOTQw" target="_blank"><u>left-of-center</u></a>, <a rel="noopener noreferrer" href="https://www.youtube.com/watch?v=zj_yX3yS8Dk" target="_blank"><u>spacey</u></a>, angular and <a rel="noopener noreferrer" href="https://www.youtube.com/watch?v=YpXktFfSy4k" target="_blank"><u>rhythmically irregular</u></a>.</p>
<p>Much like the hardcore punk scene booming down in LA, an interesting connection existed between 70’s progressive rock and the No Wave scene. <em><strong>Gong</strong></em> was a heavily influential psychedelic progressive rock band formed by Australian musician Daevid Allen in the UK in 1967. Following Gong’s breakup in the mid-70’s, Allen moved to NYC and became heavily immersed in No Wave, and released a new album, <em>About Time</em>, under the band name <em><strong>New York Gong</strong></em>. No Wave in style but still retaining the elements of psych-prog pertinent to Gong, <em>About Time</em> brought together two important figures: bassist Bill Laswell and drummer Fred Maher. New York Gong slowly re-collaborated as a new band in 1979, <em><strong>Material</strong></em>, and Laswell and Maher subsequently went on to form a No Wave act with an undeniably math rock dogma: <em><strong>Massacre</strong></em>. Their 1981 debut <em>Killing Time</em> remains a classic; a weird mix of <a rel="noopener noreferrer" href="https://www.youtube.com/watch?v=-P7oMwJkQfk" target="_blank"><u>zany chord progressions over odd time signatures</u></a>. <img data-attachment-id="4787" data-permalink="http://feckingbahamas.com/history-math-rock-pt-1-guess-black-flag-math-rock-now/the_screamers" data-orig-file="https://i0.wp.com/feckingbahamas.com/wp-content/uploads/2015/04/The_Screamers.jpg?fit=382%2C543" data-orig-size="382,543" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="The_Screamers" data-image-description="" data-medium-file="https://i0.wp.com/feckingbahamas.com/wp-content/uploads/2015/04/The_Screamers.jpg?fit=211%2C300" data-large-file="https://i0.wp.com/feckingbahamas.com/wp-content/uploads/2015/04/The_Screamers.jpg?fit=382%2C543" src="https://i1.wp.com/feckingbahamas.com/wp-content/uploads/2015/04/new-york-gong.jpg?resize=200%2C200" alt="screamers" width="200" height="200" data-recalc-dims="1" data-old-src="https://i0.wp.com/feckingbahamas.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif?resize=200%2C200" data-src="http://feckingbahamas.com/wp-content/uploads/2015/04/new-york-gong.jpg"></p>
<p>By the early 80’s No Wave was proliferating amongst the New York venues, and a number of interesting releases are pertinent to this story. In the same year as <em>Killing Time</em>‘s release, John Lurie’s instrumental punk-jazz group <em><strong>Lounge Lizards</strong></em> released their <a rel="noopener noreferrer" href="https://www.youtube.com/watch?v=bZB4Hf9aKJc" target="_blank"><u>highly angular self-titled album</u></a>. <strong><em>Swans</em></strong>‘ 1984 sophomore release ‘Cop’ was abrasive and weirdly syncopated; and it is here that many music historians attribute the first use of the term ‘grind’. In 1983, Massacre members Bill Laswell and Anton Fier went on to join a new group, <em><strong>The Golden Palominos</strong></em>, which also featured No-Wave icon Arto Lindsay on guitar and vocals, and an at-the-time unknown John Zorn. The Golden Palominos were described as poly-style music due to their stylistic shifts between no-wave, noise-rock, jazz, funk, polyrhythmic world music, and, well, weirdness. The heterogeneity and general pithiness to their style and composition laid a lot of ground work for Zorn’s renowned spazzy jazz band <em><strong>Naked City</strong></em>, which continued the legacy of weird time changes and off-kilter compositions into the late 80’s.</p>
<hr>
<div><iframe data-lazy-type="iframe" data-src="https://www.youtube.com/embed/gNdnOTvGbJQ" width="400" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe>
<p><small><em><strong>Cardiacs</strong> – ‘R.E.S’, originally from <em>The Seaside</em> (1984)</em></small></p>
</div>
<h3>1986 – 1998</h3>
<p><strong><em>The Rhythmic Bedlam of Cardiacs</em></strong></p>
<p>Before we move towards the late 80’s, we must acknowledge a final band that sits uncomfortably between the branches of the math rock story hitherto. While not explicitly ‘No Wave’ or ‘punk’, <em><strong>Cardiacs</strong></em>‘ non-conventional approach to …</p></span></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://feckingbahamas.com/history-math-rock-pt-1-guess-black-flag-math-rock-now">http://feckingbahamas.com/history-math-rock-pt-1-guess-black-flag-math-rock-now</a></em></p>]]>
            </description>
            <link>http://feckingbahamas.com/history-math-rock-pt-1-guess-black-flag-math-rock-now</link>
            <guid isPermaLink="false">hacker-news-small-sites-23835340</guid>
            <pubDate>Tue, 14 Jul 2020 17:59:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vmagent – resource-efficient Prometheus metrics collector]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23835152">thread link</a>) | @valyala
<br/>
July 14, 2020 | https://victoriametrics.github.io/vmagent.html | <a href="https://web.archive.org/web/*/https://victoriametrics.github.io/vmagent.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article>

  

  <div>
    <p><code>vmagent</code> is a tiny but brave agent, which helps you collect metrics from various sources
and stores them in <a href="https://github.com/VictoriaMetrics/VictoriaMetrics">VictoriaMetrics</a>
or any other Prometheus-compatible storage system that supports the <code>remote_write</code> protocol.</p>

<p><img alt="vmagent" src="https://victoriametrics.github.io/vmagent.png"></p>

<h3 id="motivation">Motivation</h3>

<p>While VictoriaMetrics provides an efficient solution to store and observe metrics, our users needed something fast
and RAM friendly to scrape metrics from Prometheus-compatible exporters to VictoriaMetrics.
Also, we found that users’ infrastructure are snowflakes - no two are alike, and we decided to add more flexibility
to <code>vmagent</code> (like the ability to push metrics instead of pulling them). We did our best and plan to do even more.</p>

<h3 id="features">Features</h3>

<ul>
  <li>Can be used as drop-in replacement for Prometheus for scraping targets such as <a href="https://github.com/prometheus/node_exporter">node_exporter</a>.
See <a href="#quick-start">Quick Start</a> for details.</li>
  <li>Can add, remove and modify labels (aka tags) via Prometheus relabeling. Can filter data before sending it to remote storage. See <a href="#relabeling">these docs</a> for details.</li>
  <li>Accepts data via all the ingestion protocols supported by VictoriaMetrics:
    <ul>
      <li>Influx line protocol via <code>http://&lt;vmagent&gt;:8429/write</code>. See <a href="https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/README.md#how-to-send-data-from-influxdb-compatible-agents-such-as-telegraf">these docs</a>.</li>
      <li>Graphite plaintext protocol if <code>-graphiteListenAddr</code> command-line flag is set. See <a href="https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/README.md#how-to-send-data-from-graphite-compatible-agents-such-as-statsd">these docs</a>.</li>
      <li>OpenTSDB telnet and http protocols if <code>-opentsdbListenAddr</code> command-line flag is set. See <a href="https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/README.md#how-to-send-data-from-opentsdb-compatible-agents">these docs</a>.</li>
      <li>Prometheus remote write protocol via <code>http://&lt;vmagent&gt;:8429/api/v1/write</code>.</li>
      <li>JSON lines import protocol via <code>http://&lt;vmagent&gt;:8429/api/v1/import</code>. See <a href="https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/README.md#how-to-import-time-series-data">these docs</a>.</li>
      <li>Data in Prometheus exposition format. See <a href="https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/README.md#how-to-import-data-in-prometheus-exposition-format">these docs</a> for details.</li>
      <li>Arbitrary CSV data via <code>http://&lt;vmagent&gt;:8429/api/v1/import/csv</code>. See <a href="https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/README.md#how-to-import-csv-data">these docs</a>.</li>
    </ul>
  </li>
  <li>Can replicate collected metrics simultaneously to multiple remote storage systems.</li>
  <li>Works in environments with unstable connections to remote storage. If the remote storage is unavailable, the collected metrics
are buffered at <code>-remoteWrite.tmpDataPath</code>. The buffered metrics are sent to remote storage as soon as connection
to remote storage is recovered. The maximum disk usage for the buffer can be limited with <code>-remoteWrite.maxDiskUsagePerURL</code>.</li>
  <li>Uses lower amounts of RAM, CPU, disk IO and network bandwidth compared to Prometheus.</li>
</ul>

<h3 id="quick-start">Quick Start</h3>

<p>Just download <code>vmutils-*</code> archive from <a href="https://github.com/VictoriaMetrics/VictoriaMetrics/releases">releases page</a>, unpack it
and pass the following flags to <code>vmagent</code> binary in order to start scraping Prometheus targets:</p>

<ul>
  <li><code>-promscrape.config</code> with the path to Prometheus config file (it is usually located at <code>/etc/prometheus/prometheus.yml</code>)</li>
  <li><code>-remoteWrite.url</code> with the remote storage endpoint such as VictoriaMetrics. The <code>-remoteWrite.url</code> argument can be specified multiple times in order to replicate data concurrently to an arbitrary amount of remote storage systems.</li>
</ul>

<p>Example command line:</p>

<div><div><pre><code>/path/to/vmagent -promscrape.config=/path/to/prometheus.yml -remoteWrite.url=https://victoria-metrics-host:8428/api/v1/write
</code></pre></div></div>

<p>If you only need to collect Influx data, then the following is sufficient:</p>

<div><div><pre><code>/path/to/vmagent -remoteWrite.url=https://victoria-metrics-host:8428/api/v1/write
</code></pre></div></div>

<p>Then send Influx data to <code>http://vmagent-host:8429</code>. See <a href="https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/README.md#how-to-send-data-from-influxdb-compatible-agents-such-as-telegraf">these docs</a> for more details.</p>

<p><code>vmagent</code> is also available in <a href="https://hub.docker.com/r/victoriametrics/vmagent/tags">docker images</a>.</p>

<p>Pass <code>-help</code> to <code>vmagent</code> in order to see the full list of supported command-line flags with their descriptions.</p>

<h3 id="use-cases">Use cases</h3>

<h4 id="iot-and-edge-monitoring">IoT and Edge monitoring</h4>

<p><code>vmagent</code> can run and collect metrics in IoT and industrial networks with unreliable or scheduled connections to the remote storage.
It buffers the collected data in local files until the connection to remote storage becomes available and then sends the buffered
data to the remote storage. It re-tries sending the data to remote storage on any errors.
The maximum buffer size can be limited with <code>-remoteWrite.maxDiskUsagePerURL</code>.</p>

<p><code>vmagent</code> works on various architectures from IoT world - 32-bit arm, 64-bit arm, ppc64, 386, amd64.
See <a href="https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/app/vmagent/Makefile">the corresponding Makefile rules</a> for details.</p>

<h4 id="drop-in-replacement-for-prometheus">Drop-in replacement for Prometheus</h4>

<p>If you use Prometheus only for scraping metrics from various targets and forwarding these metrics to remote storage,
then <code>vmagent</code> can replace such Prometheus setup. Usually <code>vmagent</code> requires lower amounts of RAM, CPU and network bandwidth comparing to Prometheus for such a setup.
See <a href="#how-to-collect-metrics-in-prometheus-format">these docs</a> for details.</p>

<h4 id="replication-and-high-availability">Replication and high availability</h4>

<p><code>vmagent</code> replicates the collected metrics among multiple remote storage instances configured via <code>-remoteWrite.url</code> args.
If a single remote storage instance temporarily is out of service, then the collected data remains available in another remote storage instances.
<code>vmagent</code> buffers the collected data in files at <code>-remoteWrite.tmpDataPath</code> until the remote storage becomes available again.
Then it sends the buffered data to the remote storage in order to prevent data gaps in the remote storage.</p>

<h4 id="relabeling-and-filtering">Relabeling and filtering</h4>

<p><code>vmagent</code> can add, remove or update labels on the collected data before sending it to remote storage. Additionally,
it can remove unwanted samples via Prometheus-like relabeling before sending the collected data to remote storage.
See <a href="#relabeling">these docs</a> for details.</p>

<h4 id="splitting-data-streams-among-multiple-systems">Splitting data streams among multiple systems</h4>

<p><code>vmagent</code> supports splitting the collected data between muliple destinations with the help of <code>-remoteWrite.urlRelabelConfig</code>,
which is applied independently for each configured <code>-remoteWrite.url</code> destination. For instance, it is possible to replicate or split
data among long-term remote storage, short-term remote storage and real-time analytical system <a href="https://github.com/Telefonica/prometheus-kafka-adapter">built on top of Kafka</a>.
Note that each destination can receive its own subset of the collected data thanks to per-destination relabeling via <code>-remoteWrite.urlRelabelConfig</code>.</p>

<h4 id="prometheus-remote_write-proxy">Prometheus remote_write proxy</h4>

<p><code>vmagent</code> may be used as a proxy for Prometheus data sent via Prometheus <code>remote_write</code> protocol. It can accept data via <code>remote_write</code> API
at <code>/api/v1/write</code> endpoint, apply relabeling and filtering and then proxy it to another <code>remote_write</code> systems.
The <code>vmagent</code> can be configured to encrypt the incoming <code>remote_write</code> requests with <code>-tls*</code> command-line flags.
Additionally, Basic Auth can be enabled for the incoming <code>remote_write</code> requests with <code>-httpAuth.*</code> command-line flags.</p>

<h3 id="how-to-collect-metrics-in-prometheus-format">How to collect metrics in Prometheus format</h3>

<p>Pass the path to <code>prometheus.yml</code> to <code>-promscrape.config</code> command-line flag. <code>vmagent</code> takes into account the following
sections from <a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/">Prometheus config file</a>:</p>

<ul>
  <li><code>global</code></li>
  <li><code>scrape_configs</code></li>
</ul>

<p>All the other sections are ignored, including <a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#remote_write">remote_write</a> section.
Use <code>-remoteWrite.*</code> command-line flags instead for configuring remote write settings.</p>

<p>The following scrape types in <a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config">scrape_config</a> section are supported:</p>

<ul>
  <li><code>static_configs</code> - for scraping statically defined targets. See <a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#static_config">these docs</a> for details.</li>
  <li><code>file_sd_configs</code> - for scraping targets defined in external files aka file-based service discover.
See <a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#file_sd_config">these docs</a> for details.</li>
  <li><code>kubernetes_sd_configs</code> - for scraping targets in Kubernetes (k8s).
See <a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#kubernetes_sd_config">kubernetes_sd_config</a> for details.</li>
  <li><code>ec2_sd_configs</code> - for scraping targets in Amazon EC2.
See <a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#ec2_sd_config">ec2_sd_config</a> for details.
<code>vmagent</code> doesn’t support <code>role_arn</code> config param yet.</li>
  <li><code>gce_sd_configs</code> - for scraping targets in Google Compute Engine (GCE).
See <a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#gce_sd_config">gce_sd_config</a> for details.
<code>vmagent</code> provides the following additional functionality for <code>gce_sd_config</code>:
    <ul>
      <li>if <code>project</code> arg is missing, then <code>vmagent</code> uses the project for the instance where it runs;</li>
      <li>if <code>zone</code> arg is missing, then <code>vmagent</code> uses the zone for the instance where it runs;</li>
      <li>if <code>zone</code> arg equals to <code>"*"</code>, then <code>vmagent</code> discovers all the zones for the given project;</li>
      <li><code>zone</code> may contain arbitrary number of zones, i.e. <code>zone: [us-east1-a, us-east1-b]</code>.</li>
    </ul>
  </li>
  <li><code>consul_sd_configs</code> - for scraping targets registered in Consul.
See <a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#consul_sd_config">consul_sd_config</a> for details.</li>
  <li><code>dns_sd_configs</code> - for scraping targets discovered from DNS records (SRV, A and AAAA).
See <a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#dns_sd_config">dns_sd_config</a> for details.</li>
</ul>

<p>File feature requests at <a href="https://github.com/VictoriaMetrics/VictoriaMetrics/issues">our issue tracker</a> if you need other service discovery mechanisms to be supported by <code>vmagent</code>.</p>

<p><code>vmagent</code> also support the following additional options in <code>scrape_config</code> section:</p>

<ul>
  <li><code>disable_compression: true</code> - for disabling response compression on a per-job basis. By default <code>vmagent</code> requests compressed responses from scrape targets
in order to save network bandwidth.</li>
  <li><code>disable_keepalive: true</code> - for disabling <a href="https://en.wikipedia.org/wiki/HTTP_persistent_connection">HTTP keep-alive connections</a> on a per-job basis.
By default <code>vmagent</code> uses keep-alive connections to scrape targets in order to reduce overhead on connection re-establishing.</li>
</ul>

<p>Note that <code>vmagent</code> doesn’t support <code>refresh_interval</code> option these scrape configs. Use the corresponding <code>-promscrape.*CheckInterval</code>
command-line flag instead. For example, <code>-promscrape.consulSDCheckInterval=60s</code> sets <code>refresh_interval</code> for all the <code>consul_sd_configs</code>
entries to 60s. Run <code>vmagent -help</code> in order to see default values for <code>-promscrape.*CheckInterval</code> flags.</p>

<h3 id="adding-labels-to-metrics">Adding labels to metrics</h3>

<p>Labels can be added to metrics via the following mechanisms:</p>

<ul>
  <li>Via <code>global -&gt; external_labels</code> section in <code>-promscrape.config</code> file. These labels are added only to metrics scraped from targets configured in <code>-promscrape.config</code> file.</li>
  <li>Via <code>-remoteWrite.label</code> command-line flag. These labels are added to all the collected metrics before sending them to <code>-remoteWrite.url</code>.</li>
</ul>

<h3 id="relabeling">Relabeling</h3>

<p><code>vmagent</code> supports <a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config">Prometheus relabeling</a>.
Additionally it provides the following extra actions:</p>

<ul>
  <li><code>replace_all</code>: replaces all the occurences of <code>regex</code> in the values of <code>source_labels</code> with the <code>replacement</code> and stores the result in the <code>target_label</code>.</li>
  <li><code>labelmap_all</code>: replaces all the occurences of <code>regex</code> in all the label names with the <code>replacement</code>.</li>
  <li><code>keep_if_equal</code>: keeps the entry if all label values from <code>source_labels</code> are equal.</li>
  <li><code>drop_if_equal</code>: drops the entry if all the label values from <code>source_labels</code> are equal.</li>
</ul>

<p>The relabeling can be defined in the following places:</p>

<ul>
  <li>At <code>scrape_config -&gt; relabel_configs</code> section in <code>-promscrape.config</code> file. This relabeling is applied to target labels.</li>
  <li>At <code>scrape_config -&gt; metric_relabel_configs</code> section in <code>-promscrape.config</code> file. This relabeling is applied to all the scraped metrics in the given <code>scrape_config</code>.</li>
  <li>At <code>-remoteWrite.relabelConfig</code> file. This relabeling is aplied to all the collected metrics before sending them to remote …</li></ul></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://victoriametrics.github.io/vmagent.html">https://victoriametrics.github.io/vmagent.html</a></em></p>]]>
            </description>
            <link>https://victoriametrics.github.io/vmagent.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23835152</guid>
            <pubDate>Tue, 14 Jul 2020 17:45:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Motivation Behind Digital Minimalism]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23835093">thread link</a>) | @huhn
<br/>
July 14, 2020 | https://huhn.dev/my-motivation-behind-digital-minimalism/ | <a href="https://web.archive.org/web/*/https://huhn.dev/my-motivation-behind-digital-minimalism/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container">
    <div id="body">
      <section id="page-title">
        
      </section>


<section>
    
    
    <div>
        <p><strong>tl;dr</strong>: Digital minimalism allows me to regain lost control and increases my <a href="https://en.wikipedia.org/wiki/Quality_time">quality time</a> as well as time for hobbies and other interests.</p>
<hr>
<p><strong>What the hell?</strong></p>
<p>In general, people are incredulous when telling them that I do not own a smartphone. Even though a few people understand my intention, they would rarely commit doing the same. Therefore, I think I must explain my motivation behind digital minimalism a bit more precisely.</p>
<p>Not having a smartphone is just the first step for me. I want to avoid digital life as much as possible. If, however, digital life is unavoidable I consequently use open source software only. While this sounds as if I am making it unnecessarily difficult for myself, especially regarding my computer science studies, it is a great relief for me in various ways.</p>
<p>There are different levels of digital minimalism and everyone must find the right dose for themselves. Certainly, my way seems very radical, but small steps are sufficient to feel a change.</p>
<p><strong>You can do without</strong></p>
<p>As mentioned before, I do not own a smartphone. Also no e-book reader, no smart TV, no smart watch and certainly not a fucking smart fridge or anything else that does not need to be smart. I am just using a laptop, a desktop and a <a href="https://en.wikipedia.org/wiki/Dumbphone">dumbphone</a>. That is quite enough.</p>
<p>My laptop runs <a href="https://www.openbsd.org/">OpenBSD</a> and the desktop <a href="https://www.freebsd.org/">FreeBSD</a>. I am cautious to use only minimal programs and do almost everything directly from the terminal to reduce complexity and increase my productivity. The dumbphone is mainly used to be reachable in time critical emergencies.</p>
<p>Neither my work nor my university studies require any additional equipment. Life requires none at all. Hardly anyone used anything smart before the 2000s. It is amazing how smart devices are now almost indispensable for many people.</p>
<p><strong>Finally, control again</strong></p>
<p>Digital minimalism is not only about the devices you use or do not use, it is also the attitude of how you use them. I do not need social media and I also do not need the 387th account on a service where I am not the owner of my own data. If I register somewhere now, I have thought about it thoroughly before. Unfortunately, countless people lose track on how many services they are registered. Try to list all your online accounts yourself. You will probably soon notice that you cannot remember all of them.</p>
<p>Every service that you use online generates personal data that can be exploited. Therefore, I want to have control over my data and data flow.</p>
<p><strong>Get rid of the drug</strong></p>
<p>Over time, I realized how addicted I was. I was not only <a href="https://huhn.dev/decentralization-is-dead-long-live-decentralization/">dependent on the infrastructure of others</a>, but I was really hooked. In every free minute I picked up my smartphone and looked up what news there was in the world. First, I updated my Instagram feed, then Facebook and oh look, I got a new snap! The world was always available to me and I was always available to the world.</p>
<p>Not only have I wasted my time, but I have also lost the ability to concentrate. Constant interruptions caused my attention span to decrease. Besides losing time, I was manipulated by countless actors who wanted to monetize me.</p>
<p><strong>Open your eyes</strong></p>
<p>About 3 years ago, I made a radical break and I do not miss anything. I have closed almost all online accounts and sold all non-essential equipment. Just then I realized how screwed up this society is with its compulsion for self-expression and self-optimization. I never liked the whole nonsense, but I was just too glad to be a spectator.</p>
<p>A lot of people are too afraid that they would miss something if they got rid of social media, <a href="https://www.gwern.net/docs/culture/2010-dobelli.pdf">news</a> and so forth. This differs greatly from my experience. Just as long as you can keep scrolling and updating the feeds, you feel like you might miss something. Believe me, you will lose that fear, when you separate yourself from all of that.</p>
<p>I now enjoy the time when I am on the road and am not constantly available. When I do something with family and friends, they now get my full attention and I do not let myself be distracted by anything. The biggest gain for me personally was to get time for self-reflection. The time at the bus stop is no longer just another chance to satisfy the addiction, but now serves as time to reflect. To think about everything that is going on in my head at that moment.</p>

    </div>
</section>

    </div>        		
      
    </div></div>]]>
            </description>
            <link>https://huhn.dev/my-motivation-behind-digital-minimalism/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23835093</guid>
            <pubDate>Tue, 14 Jul 2020 17:41:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mathsteroids]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23834968">thread link</a>) | @todsacerdoti
<br/>
July 14, 2020 | http://www.mscroggs.co.uk/blog/55 | <a href="https://web.archive.org/web/*/http://www.mscroggs.co.uk/blog/55">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.mscroggs.co.uk/blog/55</link>
            <guid isPermaLink="false">hacker-news-small-sites-23834968</guid>
            <pubDate>Tue, 14 Jul 2020 17:31:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apollo GraphQL Releases Apollo Client 3, a Client-Side Data Graph Library]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23834708">thread link</a>) | @stemmlerjs
<br/>
July 14, 2020 | http://go.apollo.dev/c/ac3-release | <a href="https://web.archive.org/web/*/http://go.apollo.dev/c/ac3-release">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Today we’re thrilled to announce the <strong>official release of Apollo Client 3.0</strong>! This release is the culmination of 55 betas, 14 release candidates, and hundreds of resolved issues and merged pull requests over the past eleven months. Phew!</p>



<p>To everyone who’s tried out AC3 during this extended beta period, <em>thank you</em>. We couldn’t have reached this milestone without your continued feedback and support. And to everyone who’s been waiting for the official launch, we appreciate your patience. Yes, it really is finally here!</p>



<p><strong>Here’s a recap of what’s new, with links to related documentation:</strong></p>



<ul><li>A single, consolidated <code>@apollo/client</code> package<ul><li>Includes entry points like <code>@apollo/client/utilities</code> for efficient use <em>without</em> the core library</li></ul></li><li>New <code>InMemoryCache</code> APIs:<ul><li><a href="https://www.apollographql.com/docs/react/caching/garbage-collection/#cacheevict" target="_blank" rel="noreferrer noopener">Eviction of objects and fields</a></li><li><a href="https://www.apollographql.com/docs/react/caching/garbage-collection/#cachegc" target="_blank" rel="noreferrer noopener">Garbage collection</a></li><li>Configurable policies for <a href="https://www.apollographql.com/docs/react/caching/cache-configuration/#typepolicy-fields" target="_blank" rel="noreferrer noopener">types</a> and <a href="https://www.apollographql.com/docs/react/caching/cache-field-behavior/">fie</a><a href="https://www.apollographql.com/docs/react/caching/cache-field-behavior/" target="_blank" rel="noreferrer noopener">l</a><a href="https://www.apollographql.com/docs/react/caching/cache-field-behavior/">ds</a></li><li>Pagination helpers</li></ul></li><li>Improved <a href="https://www.apollographql.com/docs/react/local-state/local-state-management/" target="_blank" rel="noreferrer noopener">local state management</a></li><li>Expanded and refined UI reactivity:<ul><li><a href="https://www.apollographql.com/docs/react/local-state/reactive-variables/" target="_blank" rel="noreferrer noopener">Reactive variables</a></li><li>More reliable cache broadcast behavior</li><li>More predictable <code>FetchPolicy</code> enforcement</li></ul></li><li>Extensive internal refactoring</li></ul>



<p>Before diving into some of those features here, I’d like to talk a bit about Apollo Client’s cache-focused design philosophy, which informed just about everything that’s included in this release.</p>



<h2>The purpose of a GraphQL client library</h2>



<p>You can consume GraphQL with anything that makes an HTTP request, such as <code>fetch</code> in the browser or <code>curl</code> on the command line. Whichever tool you use, you get all the classic GraphQL benefits: fetching exactly the data you need, in exactly the shape you need, with a single network request.</p>



<p><em>But.</em> Modern client applications use <strong>caching</strong> extensively to improve performance and user experience. And generic HTTP caching just doesn’t work with GraphQL. Every time you request even slightly different data, your HTTP-cached value is invalidated, making it useless for an application of any complexity.</p>



<p>GraphQL data is inherently, well, <em>graphical</em>. And to support GraphQL data effectively, a cache needs to <em>reflect</em> that graphical structure. HTTP caching can’t do this, but a library like Apollo Client <em>can</em>. In our opinion, this is the most important functionality that a GraphQL client library can provide.</p>



<h3>The client-side data graph</h3>



<p>When Apollo Client fetches data from your server, it caches that data using a <a rel="noreferrer noopener" href="https://www.apollographql.com/docs/react/caching/cache-configuration/#data-normalization" target="_blank">normalized structure</a> that matches your GraphQL schema. By caching this data, <em>Apollo Client locally reconstructs a subset of your back-end data graph</em>. This means that the next time Apollo Client queries some of that same data, it can fetch it directly from the cache, <em>even if an entirely different query requests it</em>. The cache only falls back to contacting your remote server when local data is missing or invalidated. And like any other GraphQL server, the cache provides APIs to <a rel="noreferrer noopener" href="https://www.apollographql.com/docs/react/caching/cache-configuration/#typepolicy-fields" target="_blank">define how types and fields are read and modified</a>.</p>



<p>Because the cache is integrated directly with Apollo Client, it knows exactly which queries use exactly which fields in your graph. Whenever a cached field’s value changes, Apollo Client automatically updates all of the queries that include that field. This makes the cache just as reactive as any other part of a modern web application.</p>



<p>It’s because of the cache-focused philosophy behind Apollo Client that we don’t think of it primarily as a library for executing GraphQL operations, but rather as <strong>a library for interacting with a client-side data graph</strong>.</p>



<h2>Feature Spotlight</h2>



<p>This is far from everything that’s new in AC3, but it’s some of what we’re most excited for you to try out in your application!</p>



<h3>Reactive variables</h3>



<p>A <a rel="noreferrer noopener" href="https://www.apollographql.com/docs/react/local-state/reactive-variables/" target="_blank">reactive variable</a> is a value that registers a dependency when you read it, and later triggers re-reading whenever the value is updated. The concept has been around for decades, predating <a rel="noreferrer noopener" href="https://docs.meteor.com/api/reactive-var.html" target="_blank">Meteor’s <code>ReactiveVar</code> API</a> back in 2014. Reactive variables are a staple of reactive programming, and now they enable flexible new ways of storing local state in AC3.</p>



<p>When you modify a reactive variable created with the <code>makeVar</code> function, Apollo Client automatically updates every active query that depends on that variable’s value. This is similar to what happens whenever a field in the cache changes, <em>however</em>: reactive variables <em>aren’t in the cache</em>. That means they can hold data of any type and structure, and you can interact with them throughout your application without using GraphQL syntax.</p>



<p>As a company with a long history of creating and consuming reactive variable APIs, we genuinely believe that this addition to Apollo Client will have a transformative effect on local state management.</p>



<p>Here’s an example:</p>



<pre><code>

<span>import</span> <span>{</span>
  InMemoryCache<span>,</span>
  makeVar<span>,</span>
  gql<span>,</span>
  useQuery<span>,</span>
<span>}</span> <span>from</span> <span>"@apollo/client"</span>




<span>const</span> darkModeVar <span>=</span> <span>makeVar</span><span>(</span><span>false</span><span>)</span><span>;</span>

<span>const</span> cache <span>=</span> <span>new</span> <span>InMemoryCache</span><span>(</span><span>{</span>
  typePolicies<span>:</span> <span>{</span>
    Query<span>:</span> <span>{</span>
      fields<span>:</span> <span>{</span>
        
        
        
        <span>darkModeEnabled</span><span>(</span><span>)</span> <span>{</span>
          <span>return</span> <span>darkModeVar</span><span>(</span><span>)</span><span>;</span>
        <span>}</span><span>,</span>
      <span>}</span><span>,</span>
    <span>}</span><span>,</span>
  <span>}</span><span>,</span>
<span>}</span><span>)</span><span>;</span>



<span>function</span> <span>App</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> <span>{</span> data<span>,</span> loading <span>}</span> <span>=</span> <span>useQuery</span><span>(</span>
    gql<span><span>`</span><span>query { darkModeEnabled @client }</span><span>`</span></span><span>,</span>
  <span>)</span><span>;</span>
  <span>return</span> loading <span>?</span> <span><span><span>&lt;</span><span>Loading</span></span><span>/&gt;</span></span> <span>:</span>
    <span><span><span>&lt;</span>div</span> <span>className</span><span><span>=</span><span>{</span>data<span>.</span>darkModeEnabled <span>?</span> <span>"dark"</span> <span>:</span> <span>"light"</span><span>}</span></span><span>&gt;</span></span><span>...</span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><span>;</span>
<span>}</span>





<span>function</span> <span>toggleDarkMode</span><span>(</span><span>)</span> <span>{</span>
  <span>darkModeVar</span><span>(</span><span>!</span><span>darkModeVar</span><span>(</span><span>)</span><span>)</span><span>;</span>
<span>}</span></code></pre>



<h3>Cache field policies</h3>



<p>You can define a <a rel="noreferrer noopener" href="https://www.apollographql.com/docs/react/caching/cache-field-behavior/" target="_blank">field policy</a> for any and every GraphQL field that appears in your cache. A field policy can include a <a rel="noreferrer noopener" href="https://www.apollographql.com/docs/react/caching/cache-field-behavior/#the-read-function" target="_blank"><code>read</code> function</a> that customizes what happens when the field is read from the cache, and a <a rel="noreferrer noopener" href="https://www.apollographql.com/docs/react/caching/cache-field-behavior/#the-merge-function" target="_blank"><code>merge</code> function</a> that customizes what happens when it’s written.</p>



<pre><code><span>const</span> cache <span>=</span> <span>new</span> <span>InMemoryCache</span><span>(</span><span>{</span>
  typePolicies<span>:</span> <span>{</span>
    Person<span>:</span> <span>{</span>
      fields<span>:</span> <span>{</span>
        name<span>:</span> <span>{</span>
          <span>read</span><span>(</span><span>name</span><span>)</span> <span>{</span>
            
            <span>return</span> name<span>.</span><span>toUpperCase</span><span>(</span><span>)</span><span>;</span>
          <span>}</span>
        <span>}</span>
      <span>}</span><span>,</span>
    <span>}</span><span>,</span>
  <span>}</span><span>,</span>
<span>}</span><span>)</span><span>;</span></code></pre>



<p><strong>You can even do this for fields that aren’t in your schema!</strong> Such <a href="https://www.apollographql.com/docs/react/local-state/managing-state-with-field-policies/" target="_blank" rel="noreferrer noopener">local-only fields</a> are the basis for using AC3 to query both local and remote data simultaneously.</p>



<p>By defining all of this custom field logic in one place (the constructor of <code>InMemoryCache</code>), you avoid repeating code, and your teammates can interact with the types and fields you’ve configured <em>without</em> needing to understand how they’re stored or fetched.</p>



<p>After <a href="https://www.apollographql.com/docs/react/caching/cache-field-behavior/" target="_blank" rel="noreferrer noopener">reading the documentation</a>, you’ll have the tools to write your own field policies to handle use cases like:</p>



<ul><li>Default field values</li><li>Transforming or normalizing field values</li><li>Sorting and slicing lists</li><li>Exposing reactive variables as GraphQL fields</li><li>Using references to redirect to data elsewhere in the cache</li><li>Pagination (covered below as well)</li><li>…&nbsp;and much more!</li></ul>



<h3>Pagination helpers</h3>



<p>One of the most compelling use cases for a custom field policy is to handle <strong>paginated lists</strong> of data without baking any specific pagination logic into Apollo Client.</p>



<p>Even with field policies, though, it can be tricky to get pagination exactly right. With so many details to digest, you might want to start with one of our prewritten helper functions.</p>



<p>Here’s how you can consume search results from a Relay-friendly GraphQL server, such as the <a rel="noreferrer noopener" href="https://metaphysics-production.artsy.net/" target="_blank">Artsy search API</a>:</p>



<pre><code><span>import</span> <span>{</span> ApolloClient<span>,</span> InMemoryCache <span>}</span> <span>from</span> <span>"@apollo/client"</span><span>;</span>
<span>import</span> <span>{</span> relayStylePagination <span>}</span> <span>from</span> <span>"@apollo/client/utilities"</span><span>;</span>

<span>const</span> client <span>=</span> <span>new</span> <span>ApolloClient</span><span>(</span><span>{</span>
  uri<span>:</span> <span>"https://metaphysics-production.artsy.net/"</span><span>,</span>
  cache<span>:</span> <span>new</span> <span>InMemoryCache</span><span>(</span><span>{</span>
    typePolicies<span>:</span> <span>{</span>
      Query<span>:</span> <span>{</span>
        fields<span>:</span> <span>{</span>
          
          
          
          search<span>:</span> <span>relayStylePagination</span><span>(</span><span>[</span><span>"query"</span><span>]</span><span>)</span><span>,</span>
        <span>}</span><span>,</span>
      <span>}</span><span>,</span>
    <span>}</span><span>,</span>
  <span>}</span><span>)</span><span>,</span>
<span>}</span><span>)</span><span>;</span>

<span>function</span> <span>BasquiatSearchResults</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> <span>{</span> data<span>,</span> loading<span>,</span> fetchMore <span>}</span> <span>=</span> <span>useQuery</span><span>(</span>gql<span><span>`</span><span>
    query BasquiatQuery($afterCursor: string) {
      search(query: "basquiat", first: 10, after: $afterCursor) {
        edges {
          node {
            displayLabel
          }
        }
        pageInfo {
          endCursor
        }
      }
    }
  </span><span>`</span></span><span>)</span><span>;</span>

  <span>if</span> <span>(</span>loading<span>)</span> <span>return</span> <span>&lt;</span>Loading <span>/</span><span>&gt;</span><span>;</span>

  <span>return</span> <span>(</span>
    <span>&lt;</span>div<span>&gt;</span>
      <span>&lt;</span>ul<span>&gt;</span>
        <span>{</span>data<span>.</span>search<span>.</span>edges<span>.</span><span>map</span><span>(</span><span>edge</span> <span>=&gt;</span> <span>(</span>
          <span>&lt;</span>li<span>&gt;</span><span>{</span>edge<span>.</span>node<span>.</span>displayLabel<span>}</span><span>&lt;</span><span>/</span>li<span>&gt;</span>
        <span>)</span><span>)</span><span>}</span>
      <span>&lt;</span><span>/</span>ul<span>&gt;</span>
      <span>&lt;</span>input
        <span>type</span><span>=</span><span>"button"</span>
        value<span>=</span><span>"load more"</span>
        onClick<span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>fetchMore</span><span>(</span><span>{</span>
          variables<span>:</span> <span>{</span>
            afterCursor<span>:</span> data<span>.</span>search<span>.</span>pageInfo<span>.</span>endCursor<span>,</span>
          <span>}</span><span>,</span>
          
          
        <span>}</span><span>)</span><span>}</span>
      <span>/</span><span>&gt;</span>
    <span>&lt;</span><span>/</span>div<span>&gt;</span>
  <span>)</span><span>;</span>
<span>}</span></code></pre>



<p>If you’ve ever read Relay’s <a rel="noreferrer noopener" href="https://relay.dev/graphql/connections.htm" target="_blank">GraphQL Cursor Connections specification</a>, you know how complex Relay pagination can be, so it’s a big help to capture that complexity in a single helper function.</p>



<blockquote><p>If you find your own field policies becoming repetitive, don’t forget that you can reuse logic! Write a helper function that generates a generic field policy, and that takes parameters for customization.</p></blockquote>



<p>Following this release, we’ll continue collecting useful cache policy helper functions like <code>offsetLimitPagination</code> and <code>relayStylePagination</code> in <code>@apollo/client/utilities</code>. Feel free to use them directly in your own code, or adapt them to your own specific needs!</p>



<h2>Release FAQ</h2>



<h3>How do I get started?</h3>



<p>If you have an existing application that uses Apollo Client 2.x, check out the <a href="https://www.apollographql.com/docs/react/migrating/apollo-client-3-migration/" target="_blank" rel="noreferrer noopener">migration guide</a> and refreshed <a href="https://www.apollographql.com/docs/react/" target="_blank" rel="noreferrer noopener">documentation</a>, as certain concepts and interfaces have changed. We’ve worked hard to ensure that every required change is a <em>positive</em> one that makes logical sense and leaves you feeling better about your application and its data.</p>



<p>If you’re brand new to Apollo Client, <a href="https://www.apollographql.com/docs/react/get-started/" target="_blank" rel="noreferrer noopener">get started here</a>!</p>



<h3>Is AC3 a complete rewrite of Apollo Client?</h3>



<p>No. We care deeply about providing a pleasant migration between software versions, and the majority of 2.x functionality remains in 3.0. You can <a href="https://www.apollographql.com/docs/react/migrating/apollo-client-3-migration/" target="_blank" rel="noreferrer noopener">migrate to AC3</a> now and incrementally adopt its features on your own timeline. Note that some 2.x features (such as local resolvers) are now officially deprecated.</p>



<p>Even though it <em>isn’t</em> a rewrite, AC3 includes features that needed a while to bake. As one example, the new <a href="https://www.apollographql.com/docs/react/caching/garbage-collection/#cacheevict" target="_blank" rel="noreferrer noopener"><code>cache.evict</code> API</a> (<a href="https://github.com/apollographql/apollo-client/pull/5310" target="_blank" rel="noreferrer noopener">#5310</a>) enables you to remove objects and individual fields from the cache. Initial versions of this feature made it possible to leave the cache in a broken state after evicting critical data. To address …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://go.apollo.dev/c/ac3-release">http://go.apollo.dev/c/ac3-release</a></em></p>]]>
            </description>
            <link>http://go.apollo.dev/c/ac3-release</link>
            <guid isPermaLink="false">hacker-news-small-sites-23834708</guid>
            <pubDate>Tue, 14 Jul 2020 17:13:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Solving Integrals with the Overshooting Method]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23834678">thread link</a>) | @R3G1R
<br/>
July 14, 2020 | https://mathvault.ca/integration-overshooting-method/#The_Overshooting_Method_%E2%80%94_Basic_Ideas | <a href="https://web.archive.org/web/*/https://mathvault.ca/integration-overshooting-method/#The_Overshooting_Method_%E2%80%94_Basic_Ideas">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2><img src="https://mathvault.ca/wp-content/uploads/Overshooting.jpg" alt="Integration Series — The Overshooting Method" width="800" height="444" title="Overshooting" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20800%20444'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/Overshooting.jpg"></h2><p>Hey! Greeting from a bunch of&nbsp;<em>post-April-Fool bunnies</em>&nbsp;who never managed&nbsp;to get their modules published on time — because they were simply too busy eating <em>Easter eggs</em> and <em>shooting for the moon</em>. &nbsp;🙂</p><p>Moving onto a more serious topic though, if you’re currently into&nbsp;(or have been into) this thing called <a href="https://mathvault.ca/hub/higher-math/math-symbols/calculus-analysis-symbols/#Derivative_and_Integral" target="_blank" rel="noopener noreferrer"><strong>integral calculus</strong></a>, you might know from first-hand experience&nbsp;that integration in general is no easy task. After all, most of us&nbsp;spend at least a semester honing different methods of integration, which include — among others —&nbsp;the&nbsp;techniques&nbsp;of&nbsp;<strong>Substitution</strong>, <strong>Partial Fraction</strong> and I<strong>ntegration By Parts</strong>.</p><p>In what follows though, we will share with you a powerful technique for&nbsp;finding <strong>antiderivatives</strong>&nbsp;— possibly without paper and pen. We call&nbsp;this technique&nbsp;the <strong>Overshooting Method</strong>, which — as we shall see later — can even be just as efficient as several <strong>standard integration techniques</strong> combined.<span id="more-5619"></span></p><h2 id="basic"><span id="The_Overshooting_Method_%E2%80%94_Basic_Ideas"></span><a href="#toc">The Overshooting Method — Basic Ideas</a><span></span></h2><p>So what is this <em>marvelous</em> technique you ask? Well, the short answer is that it&nbsp;can be found&nbsp;in the header image above. What? <strong>Overshooting</strong>, of course! 🙂</p><p>More specifically, given a function $f$, the <strong>Overshooting Method</strong> consists in finding an antiderivative of $f$ first by&nbsp;<em>guessing</em> a <strong>potential candidate</strong>, and then checking to see how <em>close</em>&nbsp;the candidate&nbsp;<em>differentiates</em> to $f$.</p><p><span>In the event where&nbsp;the&nbsp;derivative is off, but <em>only</em> by an <strong>additional term</strong></span><span>&nbsp;or a </span><strong>multiple</strong><span>, then additional steps can be implemented to correct this discrepancy, thereby transforming a&nbsp;potential candidate into a <em>valid</em> antiderivative of $f$.</span></p><p>All right. That’s about as intuitive and accurate as it gets. In <strong>formal terms</strong> though, this is&nbsp;what the&nbsp;technique would look like <em>in a nutshell</em>:</p><div id=""><p>Theorem 1 — The Overshooting Method</p><div><p>Given a function $f$ defined on an interval $I$, if there exists another function $F^*$ such that:</p><ul><li>$(F^*)’ = kf$ on $I$ for some <em>non-zero</em> number $k$ (i.e., $F^*$ is off by a <strong>multiple</strong>), then the function $\dfrac{F^*}{k}$ constitutes&nbsp;a&nbsp;valid&nbsp;antiderivative of $f$ on $I$.</li><li>$(F^*)’=f + g$ on $I$ for some function $g$, with $\displaystyle \int g$ being one of its own antiderivatives on $I$ (i.e., $F^*$ is off by a <strong>term</strong> that is itself <em>antidifferentiable</em>), then the function $\displaystyle F^* – \int g$ constitutes a valid antiderivative of $f$ on $I$.</li></ul></div></div><p>OK. Enough of the <a href="https://mathvault.ca/math-glossary/">mathematical jargon</a>? Let’s move on to how we can apply the Overshooting Method to integrate all kinds of functions then!</p><h2 id="multiple"><span id="The_Overshooting_Method_%E2%80%94_Adjusting_for_Multiples"></span><a href="#toc">The Overshooting Method — Adjusting for Multiples</a><span></span></h2><p>As it turns out, when a potential antiderivative&nbsp;is off by <em>only</em> a <strong>multiple</strong>, it’s not hard to readjust it so as to produce a valid antiderivative. In fact, learning to adjust for a multiple paves the way for more complex applications of the Overshooting Method, which can take a bit more<em>&nbsp;insight</em> and&nbsp;<em>ingenuity</em> to be executed elegantly.</p><p>With that in mind, here are 16 examples illustrating how the Overshooting Method can be used to integrate certain <a href="https://mathvault.ca/hub/higher-math/math-symbols/algebra-symbols/#Key_Functions" target="_blank" rel="noopener noreferrer"><strong>elementary functions</strong></a> with ease. These include a good chunk of <a href="https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/#Trigonometric_Functions" target="_blank" rel="noopener noreferrer">trigonometric functions</a>, exponential functions, power functions and trig-substitution functions.</p><h3 id="trig"><span id="Trigonometric_Functions"></span><a href="#toc">Trigonometric Functions</a><span></span></h3><h4 id="cos"><span id="Cosine_Functions"></span><a href="#toc">Cosine Functions</a><span></span></h4><p>To find an antiderivative of a function like $6\cos (2x+4)$, for instance, we start by noticing that since this&nbsp;function&nbsp;behaves very much like $\cos x$, we can try to integrate it&nbsp;<em>as if</em> we were dealing with&nbsp;$\cos x$. With this insight, the idea of&nbsp;$\sin (2x+4)$ being a <em>potential</em> antiderivative of&nbsp;$6\cos (2x+4)$ naturally comes to mind.</p><p>Before we move on though, let’s check&nbsp;how well this idea works out:</p><p>\begin{align*}[\sin (2x+4)]’ &amp; =\cos (2x+4)(2x+4)’ \\ &amp; = 2\cos (2x+4)= \frac{6\cos (2x+4)}{3} \end{align*}</p><p>So, $\sin (2x+4)$ is <em>off</em> by a multiple of $\dfrac{1}{3}$ as a result of <a href="https://mathvault.ca/chain-rule-derivative/">chain rule</a>. To get rid this multiple, we multiply our <em>potential antiderivative</em> by $3$, yielding that:</p><p>\begin{align*}\displaystyle [3\sin (2x+4)]’ &amp; =3\, [\sin (2x+4)]’\\ &amp; = 3\, \frac{6\cos (2x+4)}{3} \\ &amp; = 6\cos (2x+4) \qquad (\text{for all } x \in \mathbb{R}) \end{align*}</p><p>Hence, $\displaystyle \int&nbsp;6\cos (2x+4)\, dx = 3 \sin (2x+4) + C$ for all $x \in \mathbb{R}$ — as desired.</p><h4 id="sin"><span id="Sine_Functions"></span><a href="#toc">Sine Functions</a><span></span></h4><p>How about a function such as $\pi \sin (10x)$? Well, we can always begin by pulling&nbsp;the <em>coefficient</em> $\pi$ outside the integral:</p><p>$$ \int \pi \sin (10x)\, dx = \pi \int \sin (10x)\, dx$$</p><p>Presumably, since $\sin (10x)$ behaves very much like $\sin x$, the first potential antiderivative that comes to mind would be $-\cos (10x)$. To test it, we need to see what it <em>actually</em> differentiates to:</p><p>$$ [- \cos (10x)]’ = \sin (10x) (10x)’ = 10 \sin(10x) $$</p><p>This means that our candidate is off by a multiple of $10$. Dividing it however&nbsp;by $10$ yields that:</p><p>\begin{align*} \left(\frac{- \cos (10x)}{10}\right)’ &amp; = \frac{1}{10}\, [- \cos (10x)]’ \\ &amp;= \frac{1}{10} \, [10 \sin(10x)] \\ &amp; = \sin (10x) \qquad (\text{for all }x \in \mathbb{R})\end{align*}</p><p>which is exactly what we needed. Putting everything together, we get that&nbsp;$\displaystyle&nbsp;\int \pi \sin (10x)\, dx = \pi \int \sin (10x)\, dx $ $\displaystyle = \pi \, \frac{- \cos (10x)}{10} + C$ for all $x \in \mathbb{R}$.</p><h4 id="sec"><span id="Secant_Functions"></span><a href="#toc">Secant Functions</a><span></span></h4><p>For functions such as $\displaystyle \dfrac{1}{2} \sec^2 (4-x)$, we begin by pulling out the <em>extraneous</em> coefficent:</p><p>$$ \int \dfrac{1}{2} \sec^2 (4-x) \, dx= \dfrac{1}{2}&nbsp;\int \sec^2 (4-x) \, dx $$</p><p>Here, since $\sec^2 (4-x)$ behaves very much like $\sec^2 x$, we choose $\tan (4-x)$ as a potential antiderivative to start with. To be sure, we actually have that:</p><p>$$ [\tan (4-x)]’ = – \sec^2 (4-x) $$</p><p>which means that we are off by a <em>negative sign</em>. In this case, simply <em>negating</em>&nbsp;our candidate function&nbsp;would do the trick:</p><p>$$&nbsp;[-\tan (4-x)]’ = \sec^2 (4-x) $$</p><p>Therefore,</p><p>\begin{align*} \int&nbsp;\dfrac{1}{2} \sec^2 (4-x) \, dx &amp; = \dfrac{1}{2}&nbsp;\int \sec^2 (4-x) \, dx \\ &amp; = \frac{1}{2}\, &nbsp;[-\tan (4-x)] + C\end{align*}</p><p>(<strong>Bonus</strong>: Can you figure out what is the <em>largest</em> domain under which this equality holds? 🙂 )</p><h4 id="sectan"><span id="SecantTangent_Functions"></span><a href="#toc">Secant-Tangent Functions</a><span></span></h4><p>For functions such as $3 \sec (2x+ \pi) \tan (2x+ \pi)$, we begin by noticing that since this falls into the family of $\sec x \tan x$, a potential antidervative that comes to mind would be $\sec (2x+ \pi)$. To be sure, we have that:</p><p>\begin{align*} &nbsp;[\sec (2x + \pi)]’ &amp; = \sec (2x+\pi) \tan (2x+\pi) (2x+\pi)’ \\ &amp; = 2 \sec (2x+\pi) \tan (2x+\pi) \end{align*}</p><p>So almost there, except that we need to have $3$ as our <strong>leading coefficient</strong> instead of $2$, and a bit of reflection shows that multiplying our candidate&nbsp;by $\dfrac{3}{2}$ would do:</p><p>\begin{align*} &nbsp;\left( \frac{3}{2}\sec (2x + \pi) \right)’ &amp; = \frac{3}{2} \, 2 \sec (2x+\pi) \tan (2x+\pi) \\ &amp; = 3 \sec (2x+\pi) \tan (2x+\pi) \end{align*}</p><p>And that’s a <em>homerun</em>! Hence $\displaystyle \int&nbsp;3 \sec (2x+ \pi) \tan (2x+ \pi) \, dx =$ $\displaystyle \frac{3}{2}\sec (2x + \pi) + C$ (where $2x + \pi \ne \frac{\pi}{2} + k\pi$ for some <em>integer</em> $k$).</p><h4 id="csc"><span id="Cosecant_Functions"></span><a href="#toc">Cosecant Functions</a><span></span></h4><p>For functions like $-6 \csc^2 (5x-4)$, we start by noticing that since it pretty much behaves like $\csc^2 x$ (which antidifferentiates to $-\cot x$ — by the way), the idea of $-\cot (5x-4)$ being one of its&nbsp;antiderivatives becomes more than a <em>remote reality</em>. However, we need to&nbsp;verify this idea in practice:</p><p>$$[-\cot (5x-4)]’= \csc^2 (5x-4) (5x-4)’ = 5 \csc^2 (5x-4) $$</p><p>To correct the leading coefficient from $5$ to $-6$, we multiply our guess by $\dfrac{-6}{5}$, yielding that:</p><p>\begin{align*}&nbsp;\left( \frac{-6}{5} [- \cot (5x-4)] \right)’ &amp; = \frac{-6}{5} \, [5 \csc^2 (5x-4)] \\ &amp; = -6&nbsp;\csc^2 (5x-4)\end{align*}</p><p>Done! Hence $\int -6 \csc^2 (5x-4) \, dx =$ $\frac{-6}{5}\, [- \cot (5x-4)] + C =$ $\frac{6}{5} \cot (5x-4) +C\,$ (where $5x-4 \ne k \pi$ for some integer $k$).</p><h4 id="cot"><span id="Cotangent_Functions"></span><a href="#toc">Cotangent Functions</a><span></span></h4><p>OK. What about $\cot (2x-e)$? Let’s see… looking at the <strong>table of integrals</strong>, we see that $\cot x$ integrates to $\ln |\sin x|$, which suggests that $\ln |\sin (2x-e)|$ might work out very well as a candidate. Let’s check what it differentiates to:</p><p>$$ \left[\ln |\sin (2x-e)|\right]’ = \frac{\cos(2x-e)}{\sin (2x-e)}(2x-e)’=&nbsp;2\cot (2x-e)$$</p><p>Pretty close! Because in thise case, dividing both sides of the equation by $2$ would do:</p><p>$$ \left[\frac{1}{2}\ln |\sin (2x-e)| \right]’ = \cot (2x-e)$$</p><p>Therefore, $\displaystyle \int \cot (2x-e) \, dx =&nbsp;\frac{1}{2}\ln |\sin (2x-e)| + C$ (where $2x-e \ne k\pi$ for some integer $k$).</p><h3 id="exp"><span id="Exponential_Functions"></span><a href="#toc">Exponential Functions</a><span></span></h3><h4 id="natural"><span id="Natural_Base"></span><a href="#toc">Natural Base</a><span></span></h4><p>For functions such as $\displaystyle -5.6e^{-2x+4}$, once we notice its <em>similarity</em> with $\displaystyle e^x$, trying out $\displaystyle e^{-2x+4}$ becomes our <em>first line of attack</em>:</p><p>$$(e^{-2x+4})’=e^{-2x+4} \, (-2x+4)’ = -2 e^{-2x+4} $$</p><p>Now, multiplying both sides by $\dfrac{5.6}{2}$ yields:</p><p>$$\left( \frac{5.6}{2} \, e^{-2x+4} \right)’=\frac{5.6}{2} (-2 e^{-2x+4}) = -5.6 e^{-2x+4}$$</p><p>And that’s it! Hence $\displaystyle \int -5.6e^{-2x+4} \ dx = \frac{5.6}{2}(e^{-2x+4}) + C$ (for all $x \in \mathbb{R}$).</p><h4 id="arbitrary"><span id="Arbitrary_Bases"></span><a href="#toc">Arbitrary Bases</a><span></span></h4><p>So that was for the <strong>natural base</strong> $e$. For exponential functions of other bases like $34 \pi^{3x-1}$, we can always start by taking out the <em>annoying</em> leading coefficient:</p><p>$$ \int 34 \pi^{3x-1} \, dx = 34 \int \pi^{3x-1} \, dx$$</p><p>Now, what function could possibly <em>differentiate</em> to $\displaystyle&nbsp;\pi^{3x-1}$ ? Out of curiosity, let’s just try the function <em>itself</em>:</p><p>$$\left(\pi^{3x-1}\right)’ = \pi^{3x-1} \ln \pi \, (3x-1)’ = (3 \ln \pi) \pi^{3x-1}$$</p><p>In which case, all that’s left to do is to <em>divide both sides</em> by $3 \ln \pi$:</p><p>$$\left(\frac{\pi^{3x-1}}{3 \ln \pi}\right)’ = \pi^{3x-1}$$</p><p>yielding that $\displaystyle \int 34 \pi^{3x-1} \, dx =$ $\displaystyle 34 \int \pi^{3x-1} \, dx =$ $\displaystyle 34 \, \frac{\pi^{3x-1}}{3 \ln \pi} +C\,$ (for all $x \in \mathbb{R}$).</p><h3 id="power"><span id="Power_Functions"></span><a href="#toc">Power Functions</a><span></span></h3><h4 id="root"><span id="Square_Root_Functions"></span><a href="#toc">Square Root Functions</a><span></span></h4><p>Here’s another one for you: &nbsp;$e\sqrt{7x-9}$. <em>Strange</em> huh?</p><p>Actually, by inspection, this really just looks like $\sqrt{x}$, so let’s try out $\displaystyle \frac{(7x-9)^{\frac{3}{2}} }{\frac{3}{2}}$:</p><p>$$ \left(&nbsp;\frac{(7x-9)^{\frac{3}{2}} }{\frac{3}{2}} \right)’= \sqrt{7x-9}\, (7x-9)’ = 7 \sqrt{7x-9}$$</p><p>Here, we need to turn the $7$ into a $\displaystyle e$, and&nbsp;a bit of thought reveals&nbsp;that multiply both sides by $\dfrac{e}{7}$ would do the trick:</p><p>$$\left( …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mathvault.ca/integration-overshooting-method/#The_Overshooting_Method_%E2%80%94_Basic_Ideas">https://mathvault.ca/integration-overshooting-method/#The_Overshooting_Method_%E2%80%94_Basic_Ideas</a></em></p>]]>
            </description>
            <link>https://mathvault.ca/integration-overshooting-method/#The_Overshooting_Method_%E2%80%94_Basic_Ideas</link>
            <guid isPermaLink="false">hacker-news-small-sites-23834678</guid>
            <pubDate>Tue, 14 Jul 2020 17:11:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Run a Live Coding Stream on Twitch Using OBS]]>
            </title>
            <description>
<![CDATA[
Score 450 | Comments 170 (<a href="https://news.ycombinator.com/item?id=23834153">thread link</a>) | @jordanlewis
<br/>
July 14, 2020 | https://jordanlewis.org/posts/twitch-live-coding/ | <a href="https://web.archive.org/web/*/https://jordanlewis.org/posts/twitch-live-coding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<article>
		
		

		<section>
    <div>
      <p><img src="https://jordanlewis.org/images/stream/streaming-desk.jpg" alt="Stream software picture"></p>
<p>If you’re reading this post, you might be interested in trying your hand at
live coding on stream, as a way of sharing your projects in a more relatable,
immediate way than a polished blog post, teaching others about programming, or
just as a way to have fun. I think that live coding and streams in general are
an interesting possible future form of both education and entertainment, and if
you’re contemplating starting your own stream, I sincerely hope that you do it.</p>
<p>This month marks the 6 month anniversary of the first stream on <a href="https://twitch.tv/large__data__bank">LARGE DATA
BANK</a>, my Twitch live coding channel. It’s
grown from a one-off Friday experiment into a regularly scheduled part of my
life, a community of dozens of wonderful regular viewers and chatters, and
an activity that’s one of the top things I look forward to doing every week.</p>
<p>I’ve learned a lot along the way, and this detailed guide to the way I’ve
set up my stream is my attempt at stepping back and sharing those learnings in
the hopes of inspiring others to try this awesome hobby for themselves. I hope
it’s useful for you as you start your own journey into streaming.</p>
<p>If you have any questions that aren’t answered in this blog post, I’m more than
happy to answer them <a href="https://twitter.com/JordanALewis">on Twitter</a> or
<a href="https://jordanlewis.org/">elsewhere online</a>.</p>
<p>Also, please send me a follow on <a href="https://largedatabank.com/">Twitch</a> and
<a href="https://twitter.com/JordanALewis">Twitter</a> for stream notifications! I stream
every Friday at 3 PM ET, and most Sundays at some time in the afternoon.</p>
<nav id="TableOfContents">
  <ul>
    <li><a href="#intro">Intro</a></li>
    <li><a href="#obs-configuration">OBS configuration</a>
      <ul>
        <li><a href="#scenes">Scenes</a></li>
        <li><a href="#video">Video</a></li>
        <li><a href="#audio">Audio</a></li>
        <li><a href="#streaming-to-twitch-finally">Streaming to Twitch (finally)</a></li>
      </ul>
    </li>
    <li><a href="#stream-alerts">Stream Alerts</a>
      <ul>
        <li><a href="#sound-in-stream-alerts">Sound in Stream Alerts</a></li>
      </ul>
    </li>
    <li><a href="#channel-setup">Channel setup</a>
      <ul>
        <li><a href="#stream-category-and-tags">Stream Category and Tags</a></li>
        <li><a href="#panels">Panels</a></li>
        <li><a href="#emotes">Emotes</a></li>
        <li><a href="#banner-image">Banner image</a></li>
        <li><a href="#saving-videos">Saving Videos</a></li>
      </ul>
    </li>
    <li><a href="#chatbot">Chatbot</a></li>
    <li><a href="#becoming-a-twitch-affiliate">Becoming a Twitch Affiliate</a></li>
    <li><a href="#shoutouts">Shoutouts</a></li>
  </ul>
</nav>


<p>Whatever your reasons for wanting to try streaming, there’s quite a bit of setup
that you’ll need to do up front to try it out that can feel daunting. Everyone
has to go through this initial setup period, though, and so can you. You got
this!</p>
<p>The most important part of this post is the
<a href="#obs-configuration">section</a> about
<a href="https://obsproject.com/">OBS</a>, which is the awesome, cross-platform, free and
open source streaming software that most of the community uses. OBS will be
your best friend on your streaming journey! You will use it to control your
webcam, desktop, audio, and every other element that goes into the final
product of your livestream.</p>
<p>The rest of the post focuses on configuration that’s more specific to Twitch.
I like to use Twitch because I like the culture that’s developed there over
time, but plenty of people think that YouTube Live is more appropriate for
professional content. I’m not too familiar with YouTube Live, but most of the
discussion about OBS should apply the same for YouTube as it does for Twitch:
the main difference is that you’ll configure OBS to send to your YouTube
account instead of Twitch in Stream settings.</p>
<blockquote>
<p><strong><em>Yo!</em> If you’re trying to set up your very first stream</strong>, you really
don’t need most of the stuff in this guide, which represents what I’ve built
gradually over the past 6 months, stream by stream. My recommendation for the
livecoding-curious is to try streaming with a bare-bones setup, to see how
you like it, before investing in expensive gear or diving into hours of
configuration and asset creation. You can accomplish this in several hours
over a weekend. Set up a single scene in OBS with your captured desktop as
the background and your webcam in the corner, with your microphone configured
under Mic/Aux. That’s all you need: a simple setup for streaming your coding
is now yours! I’ll cover how to make that happen below, in the OBS
Configuration section. Just ignore most of the extra scenes and various bells
and whistles, and you’ll be good to go.</p>
</blockquote>

<p><a href="https://obsproject.com/">OBS</a> is where you’ll produce everything that your
viewers can see and hear on the live video, including your desktop, the camera
with your beautiful face on it, your voice, and any stream alerts, overlays,
text, or other information that you might want to show to your viewers.</p>
<p><img src="https://jordanlewis.org/images/stream/desktop2.png" alt="Desktop"></p>
<p>There’s a lot to cover with OBS and I’m not going to try to explain all of it,
so I’ll just talk about what’s worked for me. To make something that suits you,
you’ll need to flex your creative muscles! You can use the ideas here as a
starting place, but you’ll need to dive into OBS and play around: everyone’s
setup is going to be different.</p>
<h2 id="scenes">Scenes <a href="#scenes" arialabel="Anchor"><i data-feather="link-2"></i></a> </h2>
<p>A <em>scene</em> is OBS’s name for a particular layout of video and audio components
on a stream. Typically, you’ll see Twitch streamers stay on a single scene for
most of their stream: their game, desktop, or whatever their focus is. But it’s
handy to have a few extra ones for the intro and outro to your stream,
something that covers the screen for when you want to take a break, and so on.</p>
<p><img src="https://jordanlewis.org/images/stream/scenes.png" alt="Scenes popped out"></p>
<p>I have the main scenes that I use bound to global hotkeys, so I can switch
between them without having to click around in OBS. Unfortunately, sometimes
the hotkeys stop working during the stream - I’ve yet to figure out exactly why
this happens. If you happen to have this same problem and have found a
workaround, please let me know!</p>
<p>I have 6 primary scenes, and a couple of child scenes that are embedded in
several main scenes to deduplicate on-screen elements (the ones below the
<code>-----</code> in the picture). However, I spend the vast majority of my stream on one
of them: the Desktop scene.</p>
<h3 id="desktop">Desktop <a href="#desktop" arialabel="Anchor"><i data-feather="link-2"></i></a> </h3>
<p>This scene is the workhorse of the stream, and the one that’s active 95% of the
time. It consists of a full-screen, 1080p Display Capture source of my external
monitor. This is convenient because it leaves no ambiguity about what’s catpured
on the stream (it’s the whole monitor) and leaves my laptop screen free for
the OBS window, monitoring chat, and anything else that I want to look at while
streaming without having to show my viewers.</p>
<p>My <a href="https://jordanlewis.org/posts/desk-setup-2020">Desktop setup post</a> goes into more detail about the
way that I’ve set up my desk to have two monitors. It’s so convenient for the
stream that I’m hooked, and I’m not sure how I’d manage without.</p>
<p><img src="https://jordanlewis.org/images/stream/desktopscene.png" alt="Desktop Scene in OBS"></p>
<blockquote>
<p>A quick note on font size: you have to make your text editor font quite large
to make it legible for your viewers! It will take a little while to get used
to this. I use 26-point font in my editor, which provides only about 30
visible horizontal lines of code. This is next to nothing compared to the
amount of context you’re probably used to seeing while programming. This
hamstringing is worth it, though: the bigger your font, the more likely it is
that your viewers will be able to follow along with what you’re doing, stay
engaged, ask questions, learn, and have fun.</p>
<p>You should also try to remove as many distracting elements from your editor
and desktop as possible while streaming, to keep the focus on the code. For
me, this has meant disabling the Mac’s menubar and Dock, and removing the
vast majority of toolbars from my IDE.</p>
</blockquote>
<p>Besides the desktop capture source, which is at the back of the scene, I’ve
added several other sources:</p>
<ol>
<li>Face cam, which is a video source from my capture card (more information about the video sources in the <a href="#video">Video</a> section)</li>
<li>Keyboard cam, which is a video source from a webcam pointed at my keyboard.</li>
<li>A couple of text boxes, to show my most recent subscriber, follower, and
some on-stream commands. The text boxes are updated automatically by the
<a href="https://streamlabs.com/dashboard#/streamlabels">StreamLabels</a> app.</li>
<li>A web page source connected to Streamlabs Stream Alerts, which I’ll cover <a href="#stream-alerts">below</a>.</li>
</ol>
<p>I definitely didn’t start with all of these elements - it’s quite a lot of work
to tweak things just the way you want - but I’ve kept this configuration for the
past couple of months and I like the way it looks.</p>
<h3 id="whiteboard">Whiteboard <a href="#whiteboard" arialabel="Anchor"><i data-feather="link-2"></i></a> </h3>
<p>The whiteboard scene is meant to showcase my iPad full screen, allowing me to
draw things on stream to demonstrate ideas or concepts. I use the Concepts app
on the iPad along with an Apple Pencil for drawing, and it works pretty nicely.</p>
<p><img src="https://jordanlewis.org/images/stream/whiteboard.png" alt="Whiteboard scene"></p>
<p>I didn’t know how to fill up the space on the bottom left, since the iPad
doesn’t have a widescreen aspect ratio like my monitor does, so I put a picture
that my friend Aileen drew of me to make the stream a bit more visually
interesting!</p>
<p>This scene references the same facecam and alerts source as the Desktop scene.
You can definitely use DRY principles in OBS, just like software - but it does
get tricky to keep everything de-duplicated.</p>
<h3 id="ipad-green-screen-overlay">iPad Green Screen Overlay <a href="#ipad-green-screen-overlay" arialabel="Anchor"><i data-feather="link-2"></i></a> </h3>
<p>I also set up a “green screen” configuration for the iPad that I can overlay
over any other scene with a global hotkey. This gives me the ESPN football
announcer effect during my stream: I can draw on my iPad, and the lines will
appear overlayed on top of whatever else I have on stream at the time.</p>
<p>This is probably the most complex video element on my
stream, but OBS makes it pretty simple to set up. I added a Color Key filter
with a black background on top of the raw iPad video feed, set my drawing app
to have a black background, and tweaked the Color Key settings in OBS until
things looked right:</p>
<p><img src="https://jordanlewis.org/images/stream/colorkey.png" alt="iPad Color Key"></p>
<p>I don’t use this element as nearly as often as I’d like, but I think it’s
pretty neat. I recorded a <a href="https://www.youtube.com/watch?v=U4WJQmN1cSo">demo
video</a> of it if you’re curious for
how it looks - I also use it occasionally on the stream.</p>
<h3 id="selfie">Selfie <a href="#selfie" arialabel="Anchor"><i data-feather="link-2"></i></a> </h3>
<p>This is just a full-screen version of the facecam. I copied the name of the
scene from <a href="https://medium.com/@suzhinton/my-twitch-live-coding-setup-b2516672fb21">@noopkat’s
blog</a>.</p>
<p><img src="https://jordanlewis.org/images/stream/selfie.png" alt="Selfie scene"></p>
<p>I use this scene for “turn to the camera” moments, which I find really fun. I’ll
switch to the scene, look right at the camera, and talk for a bit before
switching back to the desktop view.</p>
<h3 id="starting-soon">Starting Soon <a href="#starting-soon" arialabel="Anchor"><i data-feather="link-2"></i></a> </h3>
<p>This scene goes on as soon as the stream turns on, until I’m ready to start
talking to the camera. I’ll usually start the stream a few minutes before the
time that I announced on Twitter for my stream, and leave it up until that time
comes (with a muted mic!).</p>
<p><img src="https://jordanlewis.org/images/stream/startingsoon.png" alt="Starting Soon scene"></p>
<p>I used a gif I found on the internet of someone typing, so people can tell that
the stream is live even though there’s nothing happening yet. There’s also music
during this “pre-roll”. I’ll talk about music and sound <a href="#audio">later</a>).</p>
<h3 id="brb">BRB <a href="#brb" arialabel="Anchor"><i data-feather="link-2"></i></a> </h3>
<p>I’ll put this scene on if I need to step away from the stream for a moment to
use the bathroom or whatever. I added a sound to …</p></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jordanlewis.org/posts/twitch-live-coding/">https://jordanlewis.org/posts/twitch-live-coding/</a></em></p>]]>
            </description>
            <link>https://jordanlewis.org/posts/twitch-live-coding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23834153</guid>
            <pubDate>Tue, 14 Jul 2020 16:38:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Snorkel AI: Putting Data First in ML Development]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23834116">thread link</a>) | @vincentschen
<br/>
July 14, 2020 | https://www.snorkel.ai/07-14-2020-snorkel-ai-launch.html | <a href="https://web.archive.org/web/*/https://www.snorkel.ai/07-14-2020-snorkel-ai-launch.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                  <p>
                      Today I’m excited to announce Snorkel AI’s launch out of stealth!
                      Snorkel AI, which spun out of the Stanford AI Lab in 2019, was founded on two simple premises: first, that the labeled <b>training data</b>  machine learning models learn from is increasingly what determines the success or failure of AI applications.
                      And second, that we can do much better than labeling this data entirely by hand.
                  </p>
                  <p>
                      At the Stanford AI lab, the Snorkel AI founding team spent over four years developing new <b>programmatic</b> approaches to labeling, augmenting, structuring, and managing this training data.
                      We were fortunate to develop and deploy early versions of our technology with some of the world’s leading organizations like <a href="https://ai.googleblog.com/2019/03/harnessing-organizational-knowledge-for.html">Google</a>, <a href="https://dl.acm.org/doi/abs/10.1145/3329486.3329492">Intel</a>, <a href="https://arxiv.org/abs/1909.05372">Apple</a>, <a href="https://www.sciencedirect.com/science/article/pii/S2666389920300192">Stanford Medicine</a>, resulting in <a href="https://www.snorkel.ai/technology#reference">over thirty-six peer-reviewed publications</a> on our findings; innovations in weak supervision modeling, data augmentation, multi-task learning, and more; inclusion in university computer science curriculums; and deployments in popular products and systems that you’ve likely interacted with in the last few hours.
                  </p>
                  <p>
                      Through all this academic tinkering and industry spelunking, we realized two things: first, that this concept of labeling and building training data programmatically, rather than by hand, had transformational potential to make machine learning more iterative, auditable, faster to deploy, and ultimately, more practical.
                      And second, that these ideas changed not just how you label training data, but so much of the entire lifecycle and pipeline of ML: how knowledge and feedback is injected; how models are constructed, trained, versioned, and monitored; how entire pipelines are developed iteratively; and how the full set of stakeholders in any ML deployment, from subject matter experts to ML engineers, are incorporated into the process.
                  </p>
                  <p>
                      In other words, we saw that this shift to programmatic training data required a top-to-bottom rewrite of the entire ML development and deployment process.
                      With the support of some amazing investors (Greylock, GV, In-Q-Tel, and others) and incredible early customers, we’ve spent the last year doing just this: building and deploying <a href="https://www.snorkel.ai/platform">Snorkel Flow</a>, an end-to-end platform to support this new vision of the ML process.
                  </p>
                  <h2>The Training Data Bottleneck</h2>
                  <p>
                      Snorkel Flow was motivated first and foremost by a growing realization that training data had become the key bottleneck in much of ML pipeline and AI application development.
                  </p>
                  <p><img data-src="https://d33wubrfki0l68.cloudfront.net/f63e7bd828cf6019ca0add38ca51ca4050dfeea5/288e4/images/training_data_bottleneck.png" alt="" src="https://d33wubrfki0l68.cloudfront.net/f63e7bd828cf6019ca0add38ca51ca4050dfeea5/288e4/images/training_data_bottleneck.png"></p><p>
                      <b>Today’s ML successes often rest on a hidden cost: massive, hand-labeled training datasets.</b>
                      In the last decade, we’ve seen a tectonic shift in AI and ML towards powerful but data-hungry representation learning models.
                      These models—often deep learning architectures—are not only more powerful at obviating traditionally manual development tasks like feature engineering and bespoke model design, but also have never been more accessible in the open source.
                      However, there’s no such thing as a free lunch: these models are highly complex, with tens to hundreds of millions of parameters, and they require massive labeled training datasets to learn from.
                      And, other than in special scenarios where labels are naturally derivative of existing processes, these training datasets need to be labeled by hand.
                  </p>
                  <p>
                      <b>The hand-labeled training data interface to ML has enabled tremendous progress, but is also ridiculously broken.</b>
                      Consider a simple example: a legal analyst at a bank wants to train a contract classification model, and wants to inject a simple heuristic into the ML model: that if “employment” is in the title, the contract should be labeled as an “Employment contract.”
                      Simple, right?
                      Not so.
                      Theoretically, to communicate this specific feature to a machine learning model via only labeling individual data points could require thousands of examples (roughly, inversely proportional to the sparsity of the feature space).
                      From this perspective, it’s like playing 20 questions rather than just communicating the answer directly—fine if you have a massive question-answer bank, but otherwise wholly impractical.
                  </p>
                  <p>
                      <b>Manually labeling training data is prohibitively expensive–especially when expertise and privacy are required.</b>
                      Building training datasets often requires <a href="http://nytimes.com/2018/11/25/business/china-artificial-intelligence-labeling.html">armies of human labelers</a> at massive cost and time expense.
                      For example, ImageNet—one of the foundational projects behind ML’s current explosive progress—took <a href="https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world/">over two years</a> to create.
                      However, labeling cats, dogs, stop signs, and pedestrians is one thing; labeling data like medical images, legal and financial contracts, government documents, user data, and network data requires <b>stringent privacy protections</b> and <b>subject matter expert labelers</b>.
                      This means for sectors like financial services, government, telecommunications, insurance, healthcare, and more, creating training data (and by extension, using ML) is either a hugely expensive on-premise activity—or more often, one that is just not feasible to tackle, let alone practical.
                  </p>
                  <p>
                      <b>Iterative development is not possible with hand-labeled data.</b>
                      From an engineering and data science perspective, manually labeled training data fundamentally breaks the ability to quickly iterate, which is absolutely essential in real world settings where input data, output goals, and annotation schema change all the time.
                      From a business perspective, training data is an expensive asset that can’t be reused across projects, can often depreciate to worthless overnight due to changing conditions or business goals, and that presents growing risks—everything from <a href="https://web.archive.org/web/20200703104247/https://cloud.google.com/ai-platform/data-labeling/docs">COVID-related delays</a> to <a href="https://www.theverge.com/2018/1/12/16882408/google-racist-gorillas-photo-recognition-algorithm-ai">issues of bias</a>.
                  </p>
                  <h2>A New Input Paradigm for ML: Programming with Data</h2>
                  <p>
                      With Snorkel Flow, rather than needing to hand-label any training data, users develop <b>programmatic operators</b> that label, augment, and build training data to drive the ML development process.
                  </p>
                  <p><img data-src="https://d33wubrfki0l68.cloudfront.net/ae088a1fc7f3c6326c2e7285bc2d3c7e88907290/ad302/images/platform-label-v3.png" alt="" src="https://d33wubrfki0l68.cloudfront.net/ae088a1fc7f3c6326c2e7285bc2d3c7e88907290/ad302/images/platform-label-v3.png"></p><p>
                      <b>Programmatically labeling and building training data.</b>
                      With Snorkel Flow, the idea is to instead communicate this domain knowledge directly via a programmatic operator like a <a href="https://papers.nips.cc/paper/6523-data-programming-creating-large-training-sets-quickly">labeling function</a>.
                      For example, our legal analyst could write a labeling function that labels documents as “Employment contracts” if the word “employment” is in the title, and otherwise abstains; or, a range of more complex and powerful labeling functions relying on internal knowlegebases, models, legacy heuristics, and more.
                      This approach of effectively programming ML with data is simple, direct, interpretable, modifiable, and agnostic to the model used (which is especially important given the ongoing Cambrian explosion of powerful new open source model architectures).
                  </p>
                  <p>
                      <b>The directness of rules with the flexibility of ML.</b>
                      Rule-based systems have long been used in industry for certain tasks—as an input, individual rules have the desirable property of being direct and interpretable.
                      However, rules can also be brittle, and lack the robustness, flexibility, and sheer power of ML approaches.
                      With Snorkel Flow, you get the best of both worlds: rules (and other interpretable resources) as inputs, and powerful ML models that generalize beyond these rules as the output.
                  </p>
                  <p><img data-src="https://d33wubrfki0l68.cloudfront.net/8b9653f8e7b7803550e9afd55284d43beb190fbe/e2b34/images/platform-manage-v3.png" alt="" src="https://d33wubrfki0l68.cloudfront.net/8b9653f8e7b7803550e9afd55284d43beb190fbe/e2b34/images/platform-manage-v3.png"></p><p>
                      <b>A more powerful yet weaker supervision.</b>
                      At the same time that this programmatic supervision is advantageous in several transformational ways, it is also messier and raises fundamental new technical challenges.
                      The labeling functions and other programmatic operators that users write will have varying unknown accuracies and expertise areas, will overlap and disagree with each other, and may be correlated in tangled and unknown ways.
                      We focused on the algorithmic and systems solutions to these issues over <a href="https://www.snorkel.ai/technology">four-plus years of research</a>, showing both empirically and theoretically that with the right techniques, these deep technical challenges can be overcome.
                      The result: training data that is as good as or better than hand-labeled data, and immensely more practical to create and maintain.
                  </p>
                  <p>
                      <b>Beyond labeling: data augmentation, slicing, monitoring, and more.</b>
                      In high-performance production ML, training data is about a lot more than labeling.
                      For example, data augmentation is a cornerstone technique wherein transformed copies of data (e.g. rotated or blurred images) are used to expand the sizes of training datasets, and make resulting models more robust.
                      Slicing or structuring training datasets into more or less important and difficult subsets is also a critical part of managing production ML. 
                      Finally, monitoring and adapting not just models but …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.snorkel.ai/07-14-2020-snorkel-ai-launch.html">https://www.snorkel.ai/07-14-2020-snorkel-ai-launch.html</a></em></p>]]>
            </description>
            <link>https://www.snorkel.ai/07-14-2020-snorkel-ai-launch.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23834116</guid>
            <pubDate>Tue, 14 Jul 2020 16:36:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SPA Doesn’t Need a Router]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23834010">thread link</a>) | @jerodsanto
<br/>
July 14, 2020 | https://forweb.dev/en/blog/drop-the-router/ | <a href="https://web.archive.org/web/*/https://forweb.dev/en/blog/drop-the-router/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>So&nbsp;you are building a&nbsp;client-side web app for that next big project and wondering: “Which router should I&nbsp;use?”. Here is&nbsp;the thing: you don’t need any, and you will understand why shortly.</p><h2>What is&nbsp;routing?</h2><p>The first interface for a&nbsp;user to&nbsp;access any website is&nbsp;their browser address bar. Even if&nbsp;your website is&nbsp;visited via a&nbsp;link or&nbsp;from bookmarks, for a&nbsp;user it&nbsp;still goes through the address bar. Change of&nbsp;the address leads to&nbsp;a&nbsp;change of&nbsp;the page.</p><p>Our application needs to&nbsp;determine from that URL which screen and in&nbsp;what state to&nbsp;show to&nbsp;the user.</p><figure><img src="https://forweb.dev/en/blog/drop-the-router/one-step-away.jpg" alt="“One step away” by&nbsp;Anna Zarubey" srcset="https://forweb.dev/en/blog/drop-the-router/one-step-away@2x.jpg 2x" width="1000" height="563"><figcaption>“One step away” by&nbsp;<a href="https://t.me/anna_zarubey">Anna Zarubey</a></figcaption></figure><p>So, in&nbsp;a&nbsp;nutshell, routing is&nbsp;deriving the state from the input URL. Yes, that simple.</p><h2>Why is&nbsp;routing difficult then?</h2><p>When we&nbsp;scale our app, we&nbsp;split the state into many pieces. There are two reasons to&nbsp;do&nbsp;it:</p><ol><li>it&nbsp;helps to&nbsp;avoid cognitive overload;</li><li>it&nbsp;allows sharing the workload between several team members.</li></ol><p>Usually, we&nbsp;don’t need all the pieces at&nbsp;once, so&nbsp;we&nbsp;put them to&nbsp;different endpoints and storages. When a&nbsp;user opens the app, we&nbsp;reconstruct the required state from little pieces scattered all over the system. Moreover, some of&nbsp;the state pieces determine which subset of&nbsp;other pieces should be&nbsp;restored.</p><figure><img src="https://forweb.dev/en/blog/drop-the-router/state-reconstruction.jpg" alt="Example state reconstruction scheme, drawing by&nbsp;Anna Zarubey" srcset="https://forweb.dev/en/blog/drop-the-router/state-reconstruction@2x.jpg 2x" width="1000" height="563"><figcaption>Example state reconstruction scheme, drawing by&nbsp;<a href="https://t.me/anna_zarubey">Anna Zarubey</a></figcaption></figure><p>Sometimes state reconstruction is&nbsp;simple. For example, when a&nbsp;user requests the login page, we&nbsp;should just give them the login page. Most of&nbsp;the time, though, this logic is&nbsp;a&nbsp;lot more complex, depending on&nbsp;the current context, system state, and business requirements.</p><p>The question is&nbsp;how much of&nbsp;this logic should we&nbsp;own, and how much could we&nbsp;generalize and delegate to&nbsp;routing via a&nbsp;framework or&nbsp;a&nbsp;library?</p><p>Naturally, we&nbsp;would prefer to&nbsp;delegate as&nbsp;much code as&nbsp;possible. There are different approaches to&nbsp;that. One of&nbsp;them would be&nbsp;to&nbsp;fully separate routing and business logic.</p><p>For instance, we&nbsp;could match a&nbsp;path to&nbsp;some handler function and pass query parameters to&nbsp;it. Then it&nbsp;will decide how to&nbsp;restore the state and what to&nbsp;show to&nbsp;the user.</p><p>It&nbsp;could look like this (🔀 is&nbsp;for routing, 🅱️️ is&nbsp;for business logic, ❇️ is&nbsp;for dependencies loading):</p><pre><code>🔀 Receive request path with parameters in&nbsp;it
    🔀 Determine handler for this path and separate parameters
        ❇️ Load user session
            🅱️ Check if&nbsp;the user is&nbsp;authenticated
        ❇️ Load user profile
            🅱️ Check if&nbsp;the user is&nbsp;authorized to&nbsp;use this handler
        ❇️️ Load the first item from the path with parameter
            🅱️ Check if&nbsp;it&nbsp;exists
            🅱️ Check if&nbsp;the user is&nbsp;authorized to&nbsp;use&nbsp;it
        ❇️️ Load the second item from the path with parameter
            🅱️ Check if&nbsp;it&nbsp;exists
            🅱️ Check if&nbsp;it&nbsp;is&nbsp;relevant to&nbsp;the first item
            🅱️️ Check if&nbsp;the user is&nbsp;authorized to&nbsp;use&nbsp;it
        🅱️️ ... (Other business logic)
    🔀 Return the combined result
</code></pre><p>After a&nbsp;while, we&nbsp;will notice that most of&nbsp;these handlers mainly consist of&nbsp;the same instructions&nbsp;— session loading and authentication check, for instance. Maybe we&nbsp;could separate all these checks into another layer to&nbsp;stop repeating the same thing all over again?</p><p>Paths are hierarchical by&nbsp;design, which can be&nbsp;used to&nbsp;simplify our code. Like, we&nbsp;can agree that all the authenticated paths start with <code>/user</code> — meaning we&nbsp;could match paths from left to&nbsp;right and apply different checks depending on&nbsp;where we&nbsp;are in&nbsp;the hierarchy right now.</p><p>Welcome to&nbsp;the concept of&nbsp;Routing Middleware. It&nbsp;is&nbsp;still business logic, but it&nbsp;also can’t be&nbsp;separated from paths structure. So&nbsp;it&nbsp;is&nbsp;still routing too.</p><p>Both routing and business logic? Too complicated! We&nbsp;wanted a&nbsp;clear separation to&nbsp;delegate as&nbsp;much routing code as&nbsp;possible. Instead, we&nbsp;got the opposite. Screw middleware then. Why don’t we&nbsp;just define the list of&nbsp;all the checks and dependencies for each route?</p><p>That would work, but we&nbsp;still need to&nbsp;provide context for those. For authentication and handler authorization it’s quite straightforward&nbsp;— we&nbsp;can identify the user from the named cookie passed in&nbsp;the request context. But what about data availability and access control? Do&nbsp;we&nbsp;need to&nbsp;invent an&nbsp;additional language to&nbsp;extract ids from the path? Or do we need to always name those ids using a naming convention to uniformly map ids to checks?</p><p>We&nbsp;also want to&nbsp;optimize things, so&nbsp;we&nbsp;need to&nbsp;define sequences or&nbsp;relations for dependencies loading and checks. And some of&nbsp;them could be&nbsp;done in&nbsp;parallel&nbsp;— that should be&nbsp;defined too. Do&nbsp;we&nbsp;need one more language? Or&nbsp;do&nbsp;we&nbsp;do&nbsp;it&nbsp;imperatively? Then how is&nbsp;it&nbsp;different from middlewares?</p><p>These questions make routing such a&nbsp;difficult task.</p><p>Should it&nbsp;be&nbsp;so&nbsp;hard, though? Maybe backend already solved all the problems, and frontend should repeat after it’s elder brother? It&nbsp;already does, but there are multiple important obstacles along the way.</p><h2>How is&nbsp;frontend routing different from backend routing?</h2><p>First, <strong>we&nbsp;usually can’t have all the logic on&nbsp;the client-side</strong>: data is&nbsp;stored on&nbsp;a&nbsp;remote server, and we&nbsp;need to&nbsp;check if&nbsp;data is&nbsp;still valid to&nbsp;perform the desired transition. An&nbsp;observant reader will note that the same problems exist on&nbsp;the backend: database requests are asynchronous. The problem&nbsp;is: asynchronous nature of&nbsp;data requests is&nbsp;conflicting with the synchronous nature of&nbsp;the core concept of&nbsp;the web&nbsp;— links.</p><p>By&nbsp;saying links are synchronous, I&nbsp;don’t mean they transfer you immediately to&nbsp;your target, rather that they don’t require writing any asynchronous javascript. The web platform already handles the links for&nbsp;us.</p><p>This takes&nbsp;us to&nbsp;the second point. <strong>We&nbsp;need to&nbsp;entertain users while they are waiting</strong>. Modern web apps try to&nbsp;behave more like native apps rather than websites of&nbsp;the past. To&nbsp;make transitions smooth and seamless, we&nbsp;handle link clicks with javascript implementing from scratch all the logic provided by&nbsp;the platform.</p><p>User falls for this little deception and assumes that all the required resources are already on&nbsp;their device, so&nbsp;there is&nbsp;no&nbsp;need to&nbsp;load the whole page from the server&nbsp;— it&nbsp;can be&nbsp;just shown. It&nbsp;could be&nbsp;a&nbsp;smooth transition, or&nbsp;skeleton&nbsp;UI, or&nbsp;just plain old loader&nbsp;— in&nbsp;any case, we&nbsp;need to&nbsp;show something immediately after user interaction. On&nbsp;the contrary, waiting for a&nbsp;response from the backend is&nbsp;handled by&nbsp;the platform.</p><p>Third, <strong>client-side logic requires request chains</strong>. We&nbsp;have to&nbsp;ask the server for the first data chunk, then decide to&nbsp;load one of&nbsp;the next chunks depending on&nbsp;the first, then load all the items from the list in&nbsp;the second chunk... Only after a&nbsp;long chain of&nbsp;async requests we&nbsp;finally can make the transition.</p><p>The backend also has dependent data requests, but they could be&nbsp;optimized with stored procedures or&nbsp;JOIN queries. The only attempt to&nbsp;do&nbsp;something similar for the frontend is&nbsp;GraphQL, but it&nbsp;comes with a&nbsp;lot of&nbsp;disadvantages (which are out of&nbsp;the scope of&nbsp;this article).</p><p>And the last one&nbsp;— on&nbsp;the frontend, we&nbsp;sometimes have <strong>virtual routes</strong>, meaning we&nbsp;have different screen states for the same path. Because, well, you filled the first two steps of&nbsp;that wizard form&nbsp;— so&nbsp;we&nbsp;need to&nbsp;show you the third one and not allow you to&nbsp;go&nbsp;to&nbsp;the fourth one.</p><h2>Why none of&nbsp;the popular routers solve the problem?</h2><p>For some unknown reason, most of&nbsp;the popular routing solutions for web frontend focus on&nbsp;the tip of&nbsp;the iceberg, while making some significant mistakes in&nbsp;core architecture design.</p><h3>Mistake #1: defining routes in&nbsp;the view layer</h3><figure><img src="https://forweb.dev/en/blog/drop-the-router/off-label.jpg" alt="“Off-label” by&nbsp;Anna Zarubey" srcset="https://forweb.dev/en/blog/drop-the-router/off-label@2x.jpg" width="1000" height="563"><figcaption>“Off-label” by&nbsp;<a href="https://t.me/anna_zarubey">Anna Zarubey</a></figcaption></figure><p>As&nbsp;you already know, the routing process is&nbsp;heavily dependent on&nbsp;business logic. The only two cases when routing and view should collide are mapping resolved state to&nbsp;page and rendering links.</p><p>So&nbsp;there is&nbsp;no&nbsp;actual reason to&nbsp;use your view logic for routes definition. And when you do&nbsp;something without cause, you make your code difficult to&nbsp;understand and maintain.</p><p>It&nbsp;still works quite well on&nbsp;small apps, though, because they don’t have any complex or&nbsp;asynchronous business logic, and the only thing they need is&nbsp;a&nbsp;list of&nbsp;route-page pairs.</p><h3>Mistake #2: routing as&nbsp;a&nbsp;simple mapping from paths to&nbsp;pages</h3><figure><img src="https://forweb.dev/en/blog/drop-the-router/obvious.jpg" alt="“Obvious” by&nbsp;Anna Zarubey" srcset="https://forweb.dev/en/blog/drop-the-router/obvious@2x.jpg 2x" width="1000" height="563"><figcaption>“Obvious” by&nbsp;<a href="https://t.me/anna_zarubey">Anna Zarubey</a></figcaption></figure><p>Some routers selling point is&nbsp;the declarative style of&nbsp;routes definition. Meaning the whole routing problem is&nbsp;just a&nbsp;key-value dictionary.</p><p>No, it’s not. It&nbsp;could&nbsp;be, but only in&nbsp;simple hello-world-ish cases, which get complex as&nbsp;soon as&nbsp;your app becomes one month old.</p><p>In&nbsp;general, it&nbsp;is&nbsp;a&nbsp;fully-fledged process with dependency loading, data processing, and decision-making. It&nbsp;is&nbsp;also full of&nbsp;side effects: from external dependencies and data loading to&nbsp;browser history management.</p><h3>Mistake #3: immediate transitions</h3><p>Let’s assume you are on&nbsp;a&nbsp;simple website with no&nbsp;javascript at&nbsp;all. When you click the link, are you immediately transitioned to&nbsp;your destination? No, even in&nbsp;this simple case, you have to&nbsp;wait until the next page is&nbsp;loaded.</p><p>Waiting for transitions is&nbsp;in&nbsp;the DNA of&nbsp;the web from day one. We&nbsp;got used to&nbsp;waiting after clicking the link, and we&nbsp;<strong>expect the next page to&nbsp;be&nbsp;loaded</strong>. This means it’s ok&nbsp;to&nbsp;wait because&nbsp;I requested my&nbsp;entire friend list, and that’s a&nbsp;lot of&nbsp;data, and I’m on&nbsp;2G&nbsp;internet in&nbsp;the middle of&nbsp;nowhere, so&nbsp;I totally understand.</p><p>A&nbsp;router should allow to&nbsp;transition out of&nbsp;the page, handle waiting time, then transition to&nbsp;the next page. That’s what browsers already do&nbsp;with websites, and the least we&nbsp;can do&nbsp;is&nbsp;not break&nbsp;it.</p><h3>Mistake #4: no&nbsp;place for dependencies or&nbsp;common behavior</h3><figure><img src="https://forweb.dev/en/blog/drop-the-router/ever-ready.jpg" alt="“Ever-ready” by&nbsp;Anna Zarubey" srcset="https://forweb.dev/en/blog/drop-the-router/ever-ready@2x.jpg 2x" width="1000" height="563"><figcaption>“Ever-ready” by&nbsp;<a href="https://t.me/anna_zarubey">Anna Zarubey</a></figcaption></figure><p>It&nbsp;is&nbsp;generally a&nbsp;combination of #2 and #3 but feels like something to&nbsp;be&nbsp;addressed explicitly.</p><p>Routers tend to&nbsp;work with pages as&nbsp;if&nbsp;the app already has everything it&nbsp;needs to&nbsp;display every page. And that may be&nbsp;true for a&nbsp;calculator, or&nbsp;some mini-game.</p><p>In&nbsp;reality, we&nbsp;have network-heavy applications, which require both data loading and a&nbsp;lot of&nbsp;javascript and styles to&nbsp;display&nbsp;it. And most of&nbsp;the users won’t even visit that one heavy page. So&nbsp;the most logical solution is&nbsp;to&nbsp;separate its resources from the rest of&nbsp;the app.</p><p>Now if&nbsp;we&nbsp;are going to&nbsp;separate that page, we&nbsp;have to&nbsp;put all the preconditions and dependencies inside of&nbsp;the page itself, but is&nbsp;it&nbsp;really where they belong? …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://forweb.dev/en/blog/drop-the-router/">https://forweb.dev/en/blog/drop-the-router/</a></em></p>]]>
            </description>
            <link>https://forweb.dev/en/blog/drop-the-router/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23834010</guid>
            <pubDate>Tue, 14 Jul 2020 16:30:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Preoccupied with Occupations]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23833955">thread link</a>) | @hackernewsreadr
<br/>
July 14, 2020 | http://blogofjake.com/2020/07/14/preoccupied-with-occupations/ | <a href="https://web.archive.org/web/*/http://blogofjake.com/2020/07/14/preoccupied-with-occupations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Why do we see defeat and destruction in the occupations of cities but definition and duty in the occupations of men?</p>



<p>In both cases, occupations seize control of the occupied entity, and yet it is cursed in the first instance but celebrated in the second.</p>



<p>Occupations do not defeat cities and define men. They defeat cities and defeat men.</p>



<p>It is our very preoccupation with occupations that stops us from noticing its own nature.</p>



<p>The occupied man does not seriously consider the possibility of living without an occupation any more than the man born into a city that has been occupied for centuries considers that it must not be so forever.</p>



<p>We are blinded by a bias which believes the present will persist. We fail to imagine a future that is radically different, though that is what has happened over and over again, decade after decade, by a degree which has been dramatically accelerating over the course of the last century.</p>



<p>We view automated industry almost exclusively as a threat while ignoring the opportunity that comes along with it. Automation may offer the potential to free ourselves from our occupations through the automated and automatic satisfaction of our most <a href="https://blogofjake.com/2020/03/31/the-eleven-human-needs/">essential human needs</a>. Such a standard would free us from necessarily having to do anything while simultaneously empowering us to do almost anything.</p>



<p>We have little gratitude for the generations of humans who have succeeded collectively in driving us to this defining moment in the unfathomably long but universally short history of humanity. We fail to appreciate even those alive today who are pressing us forward faster than ever, choosing instead to nitpick flaws and cancel the courageous. These brave leaders know that we are close. They consider this time the luckiest ever to be alive, and so do I.</p>



<p>People fear the new world because it is so different from the one we have known and that any generation before us has ever known. Those who have gained power in this long era of history will not willingly give their power away. They will fight in an effort to delay the disruptive forces but they will fail to realize that while their power over others will be taken away so too will the power of others over them.</p>



<p>Why should we all be satisfied with living in the middle of this chain of occupations where our lives are seized so that we may seize the lives of others and so that we may use our monies not to free ourselves from seizure but rather to seize possession of mostly meaningless goods and services which only serve to ensure the continuance of our dependence on our occupations as our growing wants overshadow our modest needs and the margin between the earnings we sell our lives for and the expenses we feel obligated to incur becomes ever narrower.</p>



<p>Some will read this and criticize me for being privileged, young, and ignorant. I cannot help but that I am the first two of these things. As for the third, is ignorance not at least as good to admit as certainty is to claim? Is it not as worthwhile to consider my opinion as it would be that of a disadvantaged old man who is certain of everything he knows? My privilege, youth, and ignorance may have assisted me in recognizing these truths but that does not mean that others less fortunate than myself cannot also recognize them and seek to apply them in their own lives however they may.</p>



<p>We cannot all escape occupation overnight, but we can recognize our preoccupation with occupations, and we can begin to think differently such that there may be another way to live.</p>
	</div><div>
				<p><strong>Published</strong>
			<time datetime="2020-07-14T12:13:26-04:00">July 14, 2020</time><time datetime="2020-07-14T12:30:27-04:00">July 14, 2020</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>http://blogofjake.com/2020/07/14/preoccupied-with-occupations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23833955</guid>
            <pubDate>Tue, 14 Jul 2020 16:27:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Illustrations for Your Website]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23833905">thread link</a>) | @ronaldsvilcins
<br/>
July 14, 2020 | https://www.ronaldsvilcins.com/2020/07/14/illustrations-for-your-website/ | <a href="https://web.archive.org/web/*/https://www.ronaldsvilcins.com/2020/07/14/illustrations-for-your-website/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><header><nav><ul><li><a href="https://www.ronaldsvilcins.com/" aria-current="page">Writing</a></li><li><a href="https://www.ronaldsvilcins.com/projects/">Projects</a></li><li><a href="https://www.ronaldsvilcins.com/about/">About</a></li><li><a href="https://www.ronaldsvilcins.com/atom.xml">RSS</a></li></ul></nav></header><hr><section><p><time datetime="2020-07-14">July 14, 2020</time> •
<a href="https://www.ronaldsvilcins.com/tags/illustrations">Illustrations</a></p><p>Using illustrations has emerged as a popular trend in modern web design. But did you know that the use of illustration is also an incredibly effective way to engage your visitors and a great way to add a personal touch to your website and make it really stand out from other websites? Great illustrations are vital for grabbing attention and getting your message across. So, to help you out with your quest to find beautiful illustrations for your website, I put together a list of some of my favorite resources. Enjoy the selection!</p><ul><li><p><a href="https://blush.design/">Blush Design</a> - Blush is a tool that brings illustrations to everyone from artists around the world. The cool thing is that you can customize every piece of an illustration to create your own compositions.</p></li><li><p><a href="https://www.humaaans.com/">humaaans</a> - Mix-&amp;-match illustrations of people with a design library. Free for commercial or personal use.</p></li><li><p><a href="https://www.drawkit.io/">DrawKit</a> - Beautiful, free illustrations. Updated weekly. Hand-drawn vector illustration and icon resources, perfect for your next project.</p></li><li><p><a href="https://www.openpeeps.com/">Open Peeps</a> - A hand-drawn illustration library. The library works like building blocks made of vector arms, legs, and emotions. You can mix these elements to create different Peeps.</p></li><li><p><a href="https://absurd.design/illustrations.html">Absurd</a> - Each illustration offers the possibility of limitless interpretations and uses and everyone can give it its own meaning. It depends only on each one’s creativity and free spirit.</p></li><li><p><a href="https://icons8.com/illustrations">Ouch</a> - Ouch helps creators who don’t draw overcome the lack of quality graphics.</p></li><li><p><a href="https://www.ls.graphics/whoosh">Whoosh</a> - Free illustrations for your projects. Use this pack of illustrations for any kind of projects from websites to applications. All illustrations are neatly structured. Each element is assigned a color style so that it is convenient to change colors at once in all the images. They are all appropriately named and packed into symbols.</p></li><li><p><a href="https://www.karthiksrinivas.in/charco">Charco Illustrations</a> - A set of 16 handcrafted illustrations for your web &amp; app projects. This set includes categories like 404 error, no internet connection, no service, fatal error, page not found, something went wrong, under construction and many more.</p></li><li><p><a href="https://undraw.co/illustrations">unDraw</a> - Use the on-the-fly color image generation to match your brand identity.</p></li><li><p><a href="https://www.streamlineicons.com/ux/free-illustrations.html">Streamline Illustrations</a> - 50 vector Illustrations in three styles: Multicolor, Duotone and Line. Use them for any commercial work.</p></li><li><p><a href="https://iconscout.com/paper-illustrations">Paper Illustrations</a> - Incredible set of paper illustrations absolutely free for both personal and commercial use. Carefully crafted illustrations to use in different categories.</p></li><li><p><a href="https://illlustrations.co/">illlustrations.co</a> - Designed 100 awesome illustrations during 100 days of illustration challenge (Now added more than 120+illustrations). You can download all illustrations completely free and use these to design awesome - landing pages, mobile app or presentations.</p></li><li><p><a href="https://lukaszadam.com/illustrations">Illustrations by Lukasz Adam</a> - MIT licensed SVG illustration images in different shapes &amp; styles. Use these free Illustrations for your website, use the icons to represent your services or simply use these images to help users to understand your content.</p></li></ul><p>To wrap up, if you have decided on using illustrations for your next website design, you are definitely on the right path to impress your future visitors. The resources listed above will give you plenty of material to use no matter what you’re designing.</p></section><hr></div></div>]]>
            </description>
            <link>https://www.ronaldsvilcins.com/2020/07/14/illustrations-for-your-website/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23833905</guid>
            <pubDate>Tue, 14 Jul 2020 16:24:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bunkobon Leadership]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23833896">thread link</a>) | @mikeberv
<br/>
July 14, 2020 | https://www.billiondollarstartupideas.com/ideas/bunkobon-leadership | <a href="https://web.archive.org/web/*/https://www.billiondollarstartupideas.com/ideas/bunkobon-leadership">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" data-updated-on="1594743809883" id="item-5f0dd758c4fe94112447ab5f"><div><div><div data-block-type="2" id="block-139d3d3e2fdcd6f733c7"><div><p><strong>Problem: </strong>We spend 1/3 of our lives at work, but often don’t work effectively. Moreover, current books on optimizing leadership, management, and work are long.</p><p><strong>Solution: </strong>A company that produces and publishes mini-guides on bite-sized leadership topics. Ideally these publications would be small enough to be Bunkobons. In Japan,&nbsp;<strong><em>bunkobon</em></strong>&nbsp;(文庫本)&nbsp;are small-format&nbsp;paperback&nbsp;books, designed to be affordable and space saving. The great majority of&nbsp;<em>bunkobon</em>&nbsp;are&nbsp;<a href="https://en.wikipedia.org/wiki/Paper_size#International_paper_sizes" title="Paper size">A6</a>&nbsp;(105×148mm or 4.1"×5.8") in size. As described by <a href="https://www.redcircleauthors.com/factbook/books-in-japan-are-generally-published-as-tanko-bon-bunko-bon-or-both/">Red Circle Authors</a>,</p><p><em>Bunko</em>&nbsp;or&nbsp;<em>bunko-bon</em>&nbsp;is the widely used Japanese term for a book that is a small-format paperback book designed to be affordable, portable and not take up too much shelf space. The format has a long and interesting&nbsp;<a href="https://www.futurelearn.com/courses/japanese-rare-books-culture/0/steps/17269">history</a>&nbsp;going back to books designed to fit into the sleeves of kimonos in Japan’s Edo Period (1603-1868).&nbsp;</p><p>The format allows for cheaper editions of books which have already been published as&nbsp;hardbacks. Imagine carrying around mini pocket books with lessons distilled from the Harvard Business Review, Fast Company, Bloomberg Businessweek, and more. Perhaps as an added bonus, the business would allow anyone to write, publish, and sell their own bunkobon on a centralized bunkobon leadership website.</p><p>As writer Annie Dillard famously said, “How we spend our days is, of course, how we spend our lives.” For many of us, a large portion of our days is spent at work; in fact, <a href="https://www.payscale.com/career-news/2018/10/heres-how-many-years-youll-spend-work-in-your-lifetime">the average person will spend 90,000 hours at work over a lifetime</a>. Thus books that are designed to give you more insight into how to thrive during this chunk of your life would be extremely useful. Like digital book tours, this business would play in <a href="https://publishingperspectives.com/2018/07/us-statshot-publisher-survey-2017-estimates-revenue/#:~:text=Online%20Sales%3A%2043.2%20Percent%20Print%2C%2027%20Percent%20Ebook&amp;text=The%20top%20line%20offered%20in,2017%2C%20representing%202.72%20billion%20units.">the book publishing industry</a> which generated an estimated $26.23 billion in net revenue for 2017 (accounting for 2.72 billion units). It would be in direct competition with companies like “<a href="https://hbsp.harvard.edu/home/">Harvard Business Publishing.</a>”</p><p><strong>Monetization: </strong>Selling these books. </p><p><strong>Contributed by: </strong><a href="https://www.michaelbervell.com/">Michael Bervell</a> (Billion Dollar Startup Ideas)</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.billiondollarstartupideas.com/ideas/bunkobon-leadership</link>
            <guid isPermaLink="false">hacker-news-small-sites-23833896</guid>
            <pubDate>Tue, 14 Jul 2020 16:24:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Do not render a PDF in a canvas]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23833883">thread link</a>) | @valkum
<br/>
July 14, 2020 | https://oltdaniel.at/2020/just-do-not-render-a-pdf.html | <a href="https://web.archive.org/web/*/https://oltdaniel.at/2020/just-do-not-render-a-pdf.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <h2>Do not render a PDF in a canvas</h2>
    <post-meta>
        <time datetime="2020-07-14T00:00:00+02:00">14 July 2020</time>
        with <words>887</words> words
        (<reading-time>4</reading-time> minute(s) to read)
    </post-meta>
    <p>Mobile browsers are far from perfect. Browsing larger GitHub Source files, slow loading websites with one gig of images and js. They are just not done for it. However, there are things, that should just not be.</p>

<!--abstract-->

<hr>

<blockquote>
  <p>I am a student in my second semester of computer science. I have a lot of stuff to learn, but this is something that “I don’t enjoy”. Just do not build it in the first place. Done.</p>
</blockquote>

<p>A fellow student of mine, send me a lecture notes to a module to prepare for my exams. We have an own GitLab instance running for our university where every student is free to create and share their work. In this case, a user create a repo for a specific module to store the source files and final PDF of his lecture notes. So far, so good.</p>

<p>Got the link, opened up on my smartphone, waited for the PDF to load and … crash. The browser closed, the homescreen restarted. Wait, what? Opened up the messenger, clicked the link again, waited for the PDF to load. Crash. My first thought was, my phone was just too bad. But I have a Samsung Galaxy S9, nothing low end, nothing ultra. But does the job in everything … except this. So I started digging.</p>

<p>First off, GitLab (at least the version 13.1.3-ee, used by our university) renders the PDF file in a HTML canvas, each page, one canvas. First thought, maybe there are too many pages. No, there are just 90 pages in that PDF. But as I have exams coming up, I cannot dig deeper into the JavaScript Part of GitLab. So I did some other testing for now instead.</p>

<p>The default Browser I have on my phone is Chrome v83.0.4103.106 and additionally Firefox v68.10.1, running on Android 10 and One UI v2.1 (build number: QP1A.190711.020.G960FXXU9ETF5). So I know Chrome fails to render the PDF in 90 Canvas elements. So I checked Firefox, same thing happens. With this knowledge I asked in the computer science group of my university, for other people to verify this behavior and the android users could verify it. Apple users verified that it renders successfully in both Safari and Firefox on IOS. I wanted to record my screen in order to document this crash, but as lucky I am, the screen recorder app is killed straight away after the browser crashed. As I have no additional equipment to record, feel free to crash it yourself.</p>

<h3 id="how-do-we-test">how do we test</h3>

<p>Well, as the GitLab instance of my university is public and repos can be shared publicly, I still do not want to get into any trouble. But, now problem, we have GitLab itself and a small demo side I built. Technical stuff: GitLab uses PDF.js from mozilla. My version is based on one of their examples, as I am not currently able to dive into GitLab source code. For a PDF I used the ethereum PDF file, twice, to have a PDF file that is large enough. It is a bit bigger than the original PDF file I had, but roughly the same number of pages (just 78 here).</p>

<p>During the development I tested in my desktop to see if the page displays everything correctly, and then continue testing on my mobile device. During this phase I crashed by laptop while it was rendering 78Pages of PDF in the browser. Note here, my Laptop is an XPS15 with an Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz with 6 cores. Due to my time limits, I need to continue my work in the future (1 month from now).</p>

<h2 id="attention">ATTENTION</h2>

<p>THESE LINKS ARE LIKELY TO CRASH YOUR BROWSER, IF YOU ARE ON ANDROID. IF THERE IS ANY DAMAGE DONE BY OPENING THIS LINK, I HAVE WARNED YOU WITH THIS MESSAGE AND AM NOT ACCOUNTABLE FOR ANY DAMAGE. IF THE TAB LOADS, JUST CLOSE IT TO AVOID THE CRASH. I SUGGEST MY VERSION, AS YOU JUST NEED TO CLICK A BUTTON TO CRASH YOUR BROWSER.</p>

<p><a href="https://oltdaniel.at/pdf_test.html">My Version</a></p>

<p><a href="https://gitlab.com/oltdaniel/crash-pdf/-/blob/master/paper.pdf">GitLab Version</a></p>

<h3 id="conclusion">conclusion</h3>

<p>PDF files are like SVG files. You can zoom into each character without seeing any pixels. It’s a great format. But as usual, there where people that need to render PDF files to a raw canvas. Nothing wrong with it, but e.g. to keep up the Quality GitLab renders each page in a 2381x3367 canvas (at least on my computer). It is required, because if you reduce the scale there is no damn way to read the pdf in this rendered format. But that is the reason, why there are so many PDF readers on so many platforms. That is the reason why desktop browser have built-in PDF readers, because in any other format you just kill system resources and/or do not get the same visual quality.</p>

<p>In the end, I am fascinated how quickly someone can crash a browser. And I mean, really crash a browser. Nobody, expects a mobile browser crashing just by rendering a PDF file. It could be fixed in this special case, by reducing the size of each canvas, or just render pager per page (as the key example of mozilla’s PDF.js presents <a href="https://mozilla.github.io/pdf.js/examples/">here</a>).</p>

<p>More to this scenario will follow in the future with further details and demos.</p>

</div></div>]]>
            </description>
            <link>https://oltdaniel.at/2020/just-do-not-render-a-pdf.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23833883</guid>
            <pubDate>Tue, 14 Jul 2020 16:23:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Founder of Puppet on bootstrapping, burnout, and babies]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23833608">thread link</a>) | @tomashertus
<br/>
July 14, 2020 | https://lukekanies.com/entrepreneur-stage-1-bootstrapping-burnout-and-babies/ | <a href="https://web.archive.org/web/*/https://lukekanies.com/entrepreneur-stage-1-bootstrapping-burnout-and-babies/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-215">
		<!-- .entry-header -->

	
	<div>
		<p><em>How I got here, how it went, and what happened along the way.</em><br>
<img src="https://lukekanies.com/wp-content/uploads/2020/07/DraggedImage-scaled.jpeg" width="2560" height="1920" srcset="https://lukekanies.com/wp-content/uploads/2020/07/DraggedImage-scaled.jpeg 2560w, https://lukekanies.com/wp-content/uploads/2020/07/DraggedImage-300x225.jpeg 300w, https://lukekanies.com/wp-content/uploads/2020/07/DraggedImage-1024x768.jpeg 1024w, https://lukekanies.com/wp-content/uploads/2020/07/DraggedImage-768x576.jpeg 768w, https://lukekanies.com/wp-content/uploads/2020/07/DraggedImage-1536x1152.jpeg 1536w, https://lukekanies.com/wp-content/uploads/2020/07/DraggedImage-2048x1536.jpeg 2048w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"><br>
I didn’t want to start a company. But I had no choice.</p>
<p>I was a SysAdmin after college, because I tried everything else and got fired from them all. I had seven jobs in two and a half years. I’m very fireable. System administration was just the chair where I happened to be sitting when the music stopped. More a safe, fun place than a source of deep passion.</p>
<p>By that point in my career, I was a little easier to keep around. More importantly, I had become worth the hassle. I did good work because I liked the puzzles.</p>
<p>I had a particular way of working. My boss would say, “You should do this thing, and you should do it this way.” He did not look at how I worked, only the result. That gave me the freedom that made the job worth it. When I told him I had finished he would say, “Great, how did you do it?” and I’d say, “Look, is that a bird?”</p>
<p>I automated everything I could, whether it needed it or not. Automation has a built-in reward mechanism. I would take this well-paying but stultifying job — <em>Type this command 1,000 times</em> — and I would reframe it: <em>How about I tell the computer to type the command 1,000 times? It will work. I’ll watch.</em> Bam! Now I can move on to other fun stuff.</p>
<p>Over time I did so much automation I kind of ran out of work. I was in Nashville at the time, while my wife was getting her PhD, so there were no interesting jobs that needed my skills. Hmm.</p>
<p>I could go to business school, but — sorry! — I don’t have any respect for the MBA. Everything I hear about business school is how valuable the network is. If I want that, I’ll take a cruise. I thought about going to law school, but it is so expensive you have to become a lawyer afterward. I didn’t want to be a lawyer. I just wanted to change my career.</p>
<p>So I was like, I’ll find someone who’s doing what I want to do—building a product to help people like me—and I’ll go and help them.</p>
<p>Oh my god, that was miserable. I lasted five months.</p>
<p>Commuting back and forth between Boston and Nashville did not help. I also had the brilliant idea of commuting seven miles each way by bike. In the winter. In Boston. I gave myself permission not to ride if it was under twenty-seven degrees. Being on the road in Boston is dangerous in a tank. On a bike, in the snow, was a cruel joke.</p>
<p>But mostly I just hated our software. I hated what we were building. At one team meeting, a senior developer said, “What does it matter what our customers think? They’ve already bought the product.” Reaction to that statement — nothing at all — told me I was in the wrong place.</p>
<p>So I left.</p>
<p>I got home. I said, I have a little money saved up, and I’ve tried everything else, and now that I think about it, I guess my dad was kind of an entrepreneur. I mean, he did run his own business for thirty years. Technically. I suppose.</p>
<p>Maybe I should start a company?</p>
<p>I know everyone in the world who is building automation tools for sysadmins, and none of them are going to build a business. “I built this, so, obviously, it’s the best.” But they’re only interested in publishing papers and getting academic tenure. Their software was already perfect, so they saw no reason to listen to anyone’s reasons for not using it.</p>
<p>I thought, what if I build something? And then listen to the people who are using it? (And maybe those who aren’t?) Hmm. Could work.</p>
<p>I quit my job. Well, I quit my job first and said, “Eh, I should probably find a way to eat.” So after trying everything else, I started a company.</p>
<p>We lived on my wife’s generous graduate student stipend of $23,000 a year — the job I quit paid $110,000 a year — and, like I said, I thought I had some money saved up. At some point the IRS sent me a letter that said, “We disagree,” and it turns out when the IRS disagrees with you, well, you know how that goes. And even if you’re right, by the time you prove you’re right, “Ok, I had ten grand, and I spent ten grand on a lawyer proving I have ten grand, and…” Just send them the check.</p>
<p>So I was broke when I started my company.</p>
<p>As a sysadmin, you’re not a developer. People will tell you: In DevOps, everyone’s a developer. Those people are lying to you. Or selling something. Which, you know. So I had to become a developer. I had written some code before Puppet, maybe 5,000 lines total. But by the time I handed it over, it was 130,000 lines of code.</p>
<p>The people I handed it to regretted my learning experience.</p>
<p>I adored it.</p>
<p>I learned a lot. It was, to be frank, super fun. One of the densest learning periods of my life. Programming is the best puzzle. I find it harder to step away from it than anything else I’ve ever done. It’s been two days since I ate, I think my wife has been trying to get my attention for the past twelve hours, I should probably … and then I try to move, my legs don’t work. I’m lightheaded from hunger and my feet are tingly.</p>
<p>Good times.</p>
<p>After about ten months I got my first paying customer.</p>
<p>I often advise other entrepreneurs. Much of what I tell them is to avoid what I did. I only had a vague idea for how to make money. I figured, “I’m confident I can make something valuable. I kind of have a plan, but I know my plan is stupid. If I bring my plan to people and listen to them, that could help make my plan less stupid.”</p>
<p>This is not that bad of a strategy! But it’s not exactly specific.</p>
<p>I didn’t really ask myself: What is my overall business going to look like? How will I get there? I started with services, because I’d been consulting for a while, and I was confident I could make enough money to eat. I know investors are down on services businesses, or anything that doesn’t look like a founder throwing themselves off a cliff with what they hope is a parachute. But you gotta eat. And services are a fantastic way to make money while you’re figuring things out.</p>
<p>I had a lot to figure out.</p>
<p>At the time — 2005 — there were a lot of open source companies out there. When I say a lot, there were four. I thought, “They’re doing well, I will copy one of them at some point later on.” That was not that great of a plan. Two years later Red Hat was the only one left. They’re a software powerhouse today, but they went public during the bubble as a T-shirt and mug company. There’s no copying that.</p>
<p>I did start making money, though. We consulted for three-and-a-half years. “We.” I was the only employee. About three years into the company, I discovered one day that I was incredibly burned out. This was the first of three major burnouts for me at Puppet.</p>
<h2>Burnout Strikes</h2>
<p>I distinctly remember realizing I was burned out. I was standing next to my wife, at the doctor’s office, looking at an ultrasound. We just learned we’re going to have twins, and I get a sudden flash of insight: My life is unsustainable.</p>
<p>I personally can’t recommend, when you’re in a bootstrapped startup, planning to have a baby. I would work especially hard to avoid having more than one at a time. But that’s what we did.</p>
<p>(Speaking of which: All you people who had your babies serially, you’re lazy and you don’t know what you’re doing. You think you had it hard. We were tested. Y’all are amateurs.)</p>
<p>The technician said, “Oh, you are going to get scanned a lot.” Um. You’re going to have to explain that one. She told us we were having two. We laughed. She must be incompetent. Just because <em>you</em> have twins (she did) doesn’t mean you can recognize them in someone else. While using an ultrasound wand. Which is your job. Scan… scan… BING! The two fetuses clearly popped into view. My wife would have fallen over if she weren’t already lying down. My knees shook. I thought, I can’t do this anymore.</p>
<p>I had been working every hour I could. I counted once: It was about 72 hours in my busiest week. There are people who say, I work 100 hours a week. You might stand there 100 hours a week. I’m skeptical you’re working. Based on <a href="https://cs.stanford.edu/people/eroberts/cs201/projects/crunchmode/econ-hours-productivity.html">what I know about productivity</a>, I hope you’re not.</p>
<p>I couldn’t do it anymore. Since February 2008 or so, coincidentally the same day I found out we were having twins, I haven’t worked more than 40 or 50 hours a week. No evenings and weekends. I might dabble sometimes, but I won’t let it become a pattern.</p>
<p>Don’t worry. I managed to burn myself out two more times without those extra hours. It can still be just as bad. Pack that intensity into fewer hours, and you’re all good.</p>
<p>So. I need help. How?</p>
<h2>Getting Help</h2>
<p>I had tried to hire people in the past. Both of them were misses.</p>
<p>The first hire was the most notable. In the three months it took to figure out he wouldn’t work out, the best person I could possibly have hired became available and then unavailable. This guy’s biggest impact was ensuring I couldn’t hire the person who would have been most helpful.</p>
<p>There’s one more crazy story about him. In the middle of his interview at my house there was a drive-by shooting next door. He had taken a bathroom break when the shooting happened. They weren’t trying to hurt anybody, just shooting up a car to send a message. One of the bullets ricocheted off the car, then my porch, and broke my front window. He came out of my bathroom, and I said, “Are you ok?”<br>
“Yeah, why?”<br>
“No reason.”</p>
<p>I needed him to work in my house.</p>
<p>(Yes, I did actually tell him. Eventually.)</p>
<p>When he didn’t pan out, I concluded, I guess I just can’t hire. I’ll do it all myself.</p>
<p>Pro tip: Don’t do that.</p>
<p>Puppet worked in spite of these decisions, not because of them.</p>
<p>Things had changed, quite suddenly. I needed help, and now.</p>
<p>I hired the only people I could think of who might do me a favor: my college roommate and my best friend. Two separate people. Again: Don’t do this. I paid them full salaries.</p>
<p>Years later, I realized, “Wait a minute, if I was paying them full salary, they weren’t really doing me a favor, were they?”</p>
<p>Burned-out people make low-quality decisions. Your brain is gone, and you’re stupid. You work too many hours, you get burned out. You hurt your business doing this kind of thing. Get sleep, eat well, get exercise, step away …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lukekanies.com/entrepreneur-stage-1-bootstrapping-burnout-and-babies/">https://lukekanies.com/entrepreneur-stage-1-bootstrapping-burnout-and-babies/</a></em></p>]]>
            </description>
            <link>https://lukekanies.com/entrepreneur-stage-1-bootstrapping-burnout-and-babies/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23833608</guid>
            <pubDate>Tue, 14 Jul 2020 16:07:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Credit card fraud – Covid style]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23833538">thread link</a>) | @falafel_muncher
<br/>
July 14, 2020 | https://pauli.us/qr-code-credit-card-fraud/ | <a href="https://web.archive.org/web/*/https://pauli.us/qr-code-credit-card-fraud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><img src="https://images.unsplash.com/photo-1572798793834-67d5e285760d?ixlib=rb-1.2.1&amp;q=85&amp;fm=jpg&amp;crop=entropy&amp;cs=srgb&amp;ixid=eyJhcHBfaWQiOjYzOTIxfQ&amp;w=3600" alt="credit card at a restaurant">
A few days ago, a friend (lets call her Eli) told me about how someone stole her credit card info at a restaurant.</p>
<p>We’re in Chicago in the middle of the Covid-19 pandemic. Restaurants have started to open back up, but only those with outdoor seating. To avoid spreading Covid, some restaurants are placing a laminated piece of paper with a QR code on each table.</p>
<p>This QR code links to a menu on the restaurant’s website. What a great idea! Restaurants don’t need to hand out menus, in fact they don’t even have to print them anymore! They can update the menu in realtime as things go out of stock or the selection changes.</p>
<p>When Eli sat down at this restaurant in Chicago, she used the QR code to open up the menu and browsed around for a bit. After a few minutes, a pop-up asked her to enter her credit card info for a seamless checkout.</p>
<p>Hmm. This is where alarm bells might go off, but remember - we’re in the middle of a pandemic. Passing credit cards to a server is dangerous! What if they have covid? What if <em>you</em> have Covid and you infect your server? It would be best to have everything be contactless. Eli entered her card info, thinking that this was actually a pretty good user experience.</p>
<p>As you may have guessed by now, it wasn’t the restaurant collecting her credit card info. Someone placed a fake menu on the table with a QR code pointing to their own phishing site. This seems pretty easy to do. Someone could walk by and place fake menus on a few tables.</p>
<p>On the tech side, things are even easier. The attacker can register a generic sounding domain, eg. lookatmenu.app. Next, they create a unique QR code for each target restaurant. You don’t even need a separate domain for each restaurant. Just add the restaurant’s actual menu URL as a query parameter. Eg: <a href="https://lookatmenu.app/?s=%5Bhttps://orders.giordanos.com/#/menu/national/ToGo/Pickup%5D(https://orders.giordanos.com/#/menu/national/ToGo/Pickup)">https://lookatmenu.app?s=https://orders.giordanos.com/#/menu/national/ToGo/Pickup</a></p>
<p>You can pass this query string into an iFrame, which makes it look like you’re actually on <a href="http://giordanos.com/">giordanos.com</a>. After a few seconds, simply show a popup to a payment form of your choosing.</p>
<p>In Eli’s case, the credit card was charged to some sort of nondescript subscription service. If it’s something with a generic name for a $20/month or so, a lot of people might not notice for a long time.</p>
<p><a href="https://codepen.io/pranas/pen/rNxZMMy">Here’s a codepen with example code</a>.</p>
<h2><strong>So, how do I protect myself?</strong></h2>
<ol>
<li>Always look at the URL of the page when entering credit card info. If anything seems off, don’t enter your payment info.</li>
<li>Be sure to ask the server if the menu is legit.</li>
</ol>
<p>Although I hate to hear stories like this, it’s always interesting to see how fraudsters exploit technology and our trust. Luckily, my friend’s credit card company refunded the charges and issued a new card.</p>
<p>Stay safe out there!</p></section></div>]]>
            </description>
            <link>https://pauli.us/qr-code-credit-card-fraud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23833538</guid>
            <pubDate>Tue, 14 Jul 2020 16:03:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Etcd, or, why modern software makes me sad]]>
            </title>
            <description>
<![CDATA[
Score 1161 | Comments 578 (<a href="https://news.ycombinator.com/item?id=23833362">thread link</a>) | @Spellman
<br/>
July 14, 2020 | https://www.roguelazer.com/2020/07/etcd-or-why-modern-software-makes-me-sad/ | <a href="https://web.archive.org/web/*/https://www.roguelazer.com/2020/07/etcd-or-why-modern-software-makes-me-sad/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    <section id="main-content" role="main">
	<article>
		


		<div><p><img alt="etcd icon" src="https://www.roguelazer.com/images/etcd-icon.png"></p>
<p>Once upon a time in 2013, there was a tool called <a href="https://etcd.io/">etcd</a> which was a really lightweight database written
around the <a href="https://web.stanford.edu/~ouster/cgi-bin/papers/raft-atc14">Raft</a> consensus algorithm. This tool was
originally written in 2013 for a <del>bullshit</del> unsuccessful project called <a href="https://coreos.com/os/docs/latest/">CoreOS Container Linux</a> that was
EOL'd several years ago, but that doesn't really matter — etcd was greater than its original use-case. Etcd
provided a convenient and simple set of primitives (set a key, get a key, set-only-if-unchanged, watch-for-changes) with
a drop-dead simple HTTP API on top of them. I have built a number of tools using etcd as a lightweight consensus store
behind them and it's absolutely a pleasure to work with.</p>
<div>
<p>Hello <strong>massive influx of new readers</strong>! I see that some <del>person who's out to get me</del> kind soul has
cross-posted this to Hacker News, Reddit, and a bunch of other sites. Cool! A few things you might want to know <em>before</em>
you send me hate-mail:</p>
<ul>
<li>The word "rant" is right up there in the tags line. This is not meant to be a persuasive argument to the secret cabal
  that controls API design or a nuanced technical comparison article. It's just some off-the-cuff thoughts. Chillax.</li>
<li>If this didn't come across clearly enough in the article: <em>I think etcd is great!</em> I have written a bunch of tools and
  applications on top of it! I think it's a fantastic little dæmon and its API, even the new janky v3 API, is still a
  million times better than ZooKeeper</li>
</ul>
<p>Okay, then. Read on.</p>
</div>
<p>In 2015, an unrelated tool called <a href="https://github.com/kubernetes/kubernetes">Kubernetes</a> was released by Google (but, really, by
Xooglers). I would go so far as to say that Kubernetes (or, as the "cool kids" say, <kbd>k8s</kbd>) is the worst thing to happen to system administration
since <a href="https://www.roguelazer.com/2020/03/systemd/">systemd</a>. It's a comprehensive suite that promises to simplify operating clusters of software and give something like 
the experience of Google's <kbd>borg</kbd> cluster manager. What it really does is:</p>
<ol>
<li>Add hundreds of new failure modes to your software</li>
<li>Move you from writing portable software configuration to writing thousands of lines of k8s-specific YAML</li>
<li>Ensnare you in a mesh of questionably-good<sup id="fnref:questionably-good"><a href="#fn:questionably-good">1</a></sup> patterns like containerization and software defined networking</li>
</ol>
<p>If you are running a truly enormous system and want to have off-the-shelf orchestration for it, Kubernetes may be
the tool for you. For 99.9% of people out there, it's just an extra layer of complexity that adds almost nothing of
value.</p>
<p>I digress, though; this is a story about etcd. And, unfortunately, our stories come together because Kubernetes was
quickly changed to use etcd as its state store. Thus began the rapid decline of etcd.</p>
<p>With the massive influx of Kubernetes users came, of course, a large number of Xooglers who decided to infect etcd with
Google technologies, as is their way<sup id="fnref:infection"><a href="#fn:infection">2</a></sup><sup id="fnref:who"><a href="#fn:who">3</a></sup>. Etcd's simple HTTP API was replaced by a "gRPC"<sup id="fnref:grpc"><a href="#fn:grpc">4</a></sup> version; the
simple internal data model was replaced by a dense and non-orthogonal data model with different types for leases, locks,
transactions, and plain-old-keys. etcd 3.2 added back a tiny subset of the HTTP API through the <a href="https://etcd.io/docs/v3.4.0/dev-guide/api_grpc_gateway/">"gRPC
Gateway"</a>, but not enough to implement
any of the rich applications built on top of the original API. The v2 API lives on for now, but upstream threatens to
remove it in every new version and there will surely come a time when it'll be removed entirely.</p>
<p>That's it. That's the story. Popular modern technology is taken over by expats from a megacorp and made worse in the
service of a hyper-specialized (and just plain over-hyped) orchestration platform. That's the world today. Anything that
has a simple and elegant feature-set ends up coöpted by people who just want to build big ungainly architecture and ends
up inheriting features from whatever megacorp the coöpters came from<sup id="fnref:megacorp"><a href="#fn:megacorp">9</a></sup>. The software development world would
prefer to use their multi-gigabyte IDEs running on ElectronJS to build thousand-dependency Java applications targeting
ungainly APIs on hard-to-operate systems than support something simpler and better. Quality is, alas, a dying art.</p>
</div>
<hr>
<h2>Comments</h2>


	</article>
    </section>
</div></div>]]>
            </description>
            <link>https://www.roguelazer.com/2020/07/etcd-or-why-modern-software-makes-me-sad/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23833362</guid>
            <pubDate>Tue, 14 Jul 2020 15:51:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Covid-19 Extra-Parliamentary Inquiry Committee (Statement)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23833285">thread link</a>) | @eternalban
<br/>
July 14, 2020 | https://acu2020.org/international/ | <a href="https://web.archive.org/web/*/https://acu2020.org/international/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<h2>The COVID-19 Extra-Parliamentary Inquiry Committee </h2>



<h4>Start 03.07.2020</h4>



<p>Heiko Schöning, Dr. Bodo Schiffman, Prof. Martin Haditsch</p>



<figure><p>
<iframe title="ACU 2072020_multilanguage" src="https://player.vimeo.com/video/434999409?dnt=1&amp;app_id=122963" width="580" height="326" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe>
</p></figure>



<div><figure><img src="https://acu2020.org/wp-content/uploads/2020/07/Infografik_2_E_web_acu2020.org_.png" alt="" srcset="https://acu2020.org/wp-content/uploads/2020/07/Infografik_2_E_web_acu2020.org_.png 500w, https://acu2020.org/wp-content/uploads/2020/07/Infografik_2_E_web_acu2020.org_-300x300.png 300w, https://acu2020.org/wp-content/uploads/2020/07/Infografik_2_E_web_acu2020.org_-150x150.png 150w" sizes="(max-width: 500px) 100vw, 500px"></figure></div>



<p><strong>Transcript in English</strong></p>



<div>
<div>
<figure><img src="https://acu2020.org/wp-content/uploads/2020/07/England-Flagge-1024x512.png" alt="" width="298" height="149" srcset="https://acu2020.org/wp-content/uploads/2020/07/England-Flagge-1024x512.png 1024w, https://acu2020.org/wp-content/uploads/2020/07/England-Flagge-300x150.png 300w, https://acu2020.org/wp-content/uploads/2020/07/England-Flagge-768x384.png 768w, https://acu2020.org/wp-content/uploads/2020/07/England-Flagge.png 1200w" sizes="(max-width: 298px) 100vw, 298px"></figure>
</div>



<div>
<div><p><a href="https://acu2020.org/wp-content/uploads/2020/07/Text-ACU-english-1.pdf">Text-ACU-english</a><a href="https://acu2020.org/wp-content/uploads/2020/07/Text-ACU-english-1.pdf" download="">Herunterladen</a></p></div>
</div>
</div>



<p><strong>Transkript auf Deutsch</strong></p>



<div><div>
<div>
<div>
<figure><img src="https://acu2020.org/wp-content/uploads/2020/07/180px-Flag_of_Germany.svg_ergebnis.png" alt="" width="302" height="181"></figure>
</div>



<div>
<div><p><a href="https://acu2020.org/wp-content/uploads/2020/07/Text-ACU-deutsch.pdf">Text-ACU-deutsch</a><a href="https://acu2020.org/wp-content/uploads/2020/07/Text-ACU-deutsch.pdf" download="">Herunterladen</a></p></div>
</div>
</div>
</div></div>



<p><strong>Transcripte en Francais</strong></p>



<div>
<div>
<figure><img src="https://acu2020.org/wp-content/uploads/2020/07/180px-Flag_of_France.svg_ergebnis.png" alt="" width="298" height="199"></figure>
</div>



<div>
<div><p><a href="https://acu2020.org/wp-content/uploads/2020/07/Texte-ACU-francais.pdf">Texte-ACU-francais</a><a href="https://acu2020.org/wp-content/uploads/2020/07/Texte-ACU-francais.pdf" download="">Download</a></p></div>
</div>
</div>



<p><strong>Trascrizione in Italiano</strong></p>



<div>
<div>
<figure><img src="https://acu2020.org/wp-content/uploads/2020/07/180px-Flag_of_Italy.svg_ergebnis.png" alt="" width="301" height="200"></figure>
</div>



<div>
<div><p><a href="https://acu2020.org/wp-content/uploads/2020/07/Testo-ACU-italiano.pdf">Testo-ACU-italiano</a><a href="https://acu2020.org/wp-content/uploads/2020/07/Testo-ACU-italiano.pdf" download="">Download</a></p></div>
</div>
</div>



<p><strong>Transcripción en español</strong></p>



<div>
<div>
<figure><img src="https://acu2020.org/wp-content/uploads/2020/07/Spanische-Flagge.png" alt="" width="298" height="198"></figure>
</div>



<div>
<div><p><a href="https://acu2020.org/wp-content/uploads/2020/07/Texto-ACU-Espa%C3%B1ol.pdf">Texto ACU Español</a><a href="https://acu2020.org/wp-content/uploads/2020/07/Texto-ACU-Espa%C3%B1ol.pdf" download="">Herunterladen</a></p></div>
</div>
</div>



<p><strong>Стенограмма на русском языке</strong></p>



<div>
<div>
<figure><img src="https://acu2020.org/wp-content/uploads/2020/07/russische-Flagge-1024x682.png" alt="" width="299" height="199" srcset="https://acu2020.org/wp-content/uploads/2020/07/russische-Flagge-1024x682.png 1024w, https://acu2020.org/wp-content/uploads/2020/07/russische-Flagge-300x200.png 300w, https://acu2020.org/wp-content/uploads/2020/07/russische-Flagge-768x512.png 768w, https://acu2020.org/wp-content/uploads/2020/07/russische-Flagge-1200x800.png 1200w, https://acu2020.org/wp-content/uploads/2020/07/russische-Flagge.png 1280w" sizes="(max-width: 299px) 100vw, 299px"></figure>
</div>



<div>
<div><p><a href="https://acu2020.org/wp-content/uploads/2020/07/Text-ACU-russisch.pdf">Текст ACU русский</a><a href="https://acu2020.org/wp-content/uploads/2020/07/Text-ACU-russisch.pdf" download="">Herunterladen</a></p></div>
</div>
</div>



<p><strong>Transcriere în limba română</strong></p>



<div>
<div>
<figure><img src="https://acu2020.org/wp-content/uploads/2020/07/rum%C3%A4nische-Flagge-1-1024x683.png" alt="" width="299" height="199" srcset="https://acu2020.org/wp-content/uploads/2020/07/rum%C3%A4nische-Flagge-1-1024x683.png 1024w, https://acu2020.org/wp-content/uploads/2020/07/rum%C3%A4nische-Flagge-1-300x200.png 300w, https://acu2020.org/wp-content/uploads/2020/07/rum%C3%A4nische-Flagge-1-768x512.png 768w, https://acu2020.org/wp-content/uploads/2020/07/rum%C3%A4nische-Flagge-1.png 1200w" sizes="(max-width: 299px) 100vw, 299px"></figure>
</div>



<div>
<div><p><a href="https://acu2020.org/wp-content/uploads/2020/07/Text-ACU-rom%C3%A2n%C4%83.pdf">Text-ACU-română</a><a href="https://acu2020.org/wp-content/uploads/2020/07/Text-ACU-rom%C3%A2n%C4%83.pdf" download="">Herunterladen</a></p></div>
</div>
</div>



<p><strong>Tekst ACU Polski</strong></p>



<div>
<div>
<figure><img src="https://acu2020.org/wp-content/uploads/2020/07/Polnische-Flagge-1.png" alt="" width="300" height="185"></figure>
</div>



<div>
<div><p><a href="https://acu2020.org/wp-content/uploads/2020/07/Tekst-ACU-Polski.pdf">Tekst-ACU-Polski</a><a href="https://acu2020.org/wp-content/uploads/2020/07/Tekst-ACU-Polski.pdf" download="">Herunterladen</a></p></div>
</div>
</div>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://acu2020.org/international/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23833285</guid>
            <pubDate>Tue, 14 Jul 2020 15:44:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Resignation Letter]]>
            </title>
            <description>
<![CDATA[
Score 601 | Comments 614 (<a href="https://news.ycombinator.com/item?id=23833267">thread link</a>) | @kirillzubovsky
<br/>
July 14, 2020 | https://www.bariweiss.com/resignation-letter | <a href="https://web.archive.org/web/*/https://www.bariweiss.com/resignation-letter">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-block-type="2" id="block-5f0dca0caa6bc4150907a76b"><div><p>Dear A.G.,</p><p>It is with sadness that I write to tell you that I am resigning from The New York Times.&nbsp;</p><p>I joined the paper with gratitude and optimism three years ago. I was hired with the goal of bringing in voices that would not otherwise appear in your pages: first-time writers, centrists, conservatives and others who would not naturally think of The Times as their home. The reason for this effort was clear: The paper’s failure to anticipate the outcome of the 2016 election meant that it didn’t have a firm grasp of the country it covers. Dean Baquet and others have admitted as much on various occasions. The priority in Opinion was to help redress that critical shortcoming.</p><p>I was honored to be part of that effort, led by James Bennet. I am proud of my work as a writer and as an editor. Among those I helped bring to our pages: the Venezuelan dissident Wuilly Arteaga; the Iranian chess champion Dorsa Derakhshani; and the Hong Kong Christian democrat Derek Lam. Also: Ayaan Hirsi Ali, Masih Alinejad, Zaina Arafat, Elna Baker, Rachael Denhollander, Matti Friedman, Nick Gillespie, Heather Heying, Randall Kennedy, Julius Krein, Monica Lewinsky, Glenn Loury, Jesse Singal, Ali Soufan, Chloe Valdary, Thomas Chatterton Williams, Wesley Yang, and many others.</p><p>But the lessons that ought to have followed the election—lessons about the importance of understanding other Americans, the necessity of resisting tribalism, and the centrality of the free exchange of ideas to a democratic society—have not been learned. Instead, a new consensus has emerged in the press, but perhaps especially at this paper: that truth isn’t a process of collective discovery, but an orthodoxy already known to an enlightened few whose job is to inform everyone else.</p><p>Twitter is not on the masthead of The New York Times. But Twitter has become its ultimate editor. As the ethics and mores of that platform have become those of the paper, the paper itself has increasingly become a kind of performance space. Stories are chosen and told in a way to satisfy the narrowest of audiences, rather than to allow a curious public to read about the world and then draw their own conclusions.<strong> </strong>I was always taught that journalists were charged with writing the first rough draft of history. Now, history itself is one more ephemeral thing molded to fit the needs of a predetermined narrative.</p><p>My own forays into Wrongthink have made me the subject of constant bullying by colleagues who disagree with my views. They have called me a Nazi and a racist; I have learned to brush off comments about how I’m “writing about the Jews again.” Several colleagues perceived to be friendly with me were badgered by coworkers. My work and my character are openly demeaned on company-wide Slack channels where masthead editors regularly weigh in. There, some coworkers insist I need to be rooted out if this company is to be a truly “inclusive” one, while others post ax emojis next to my name. Still other New York Times employees publicly smear me as a liar and a bigot on Twitter with no fear that harassing me will be met with appropriate action. They never are.</p><p>There are terms for all of this: unlawful discrimination, hostile work environment, and constructive discharge. I’m no legal expert. But I know that this is wrong.&nbsp;</p><p>I do not understand how you have allowed this kind of behavior to go on inside your company in full view of the paper’s entire staff and the public. And I certainly can’t square how you and other Times leaders have stood by while simultaneously praising me in private for my courage. Showing up for work as a centrist at an American newspaper should not require bravery.</p><p>Part of me wishes I could say that my experience was unique. But the truth is that intellectual curiosity—let alone risk-taking—is now a liability at The Times. Why edit something challenging to our readers, or write something bold only to go through the numbing process of making it ideologically kosher, when we can assure ourselves of job security (and clicks) by publishing our 4000th op-ed arguing that Donald Trump is a unique danger to the country and the world? And so self-censorship has become the norm.</p><p>What rules that remain at The Times are applied with extreme selectivity. If a person’s ideology is in keeping with the new orthodoxy, they and their work remain unscrutinized. Everyone else lives in fear of the digital thunderdome. Online venom is excused so long as it is directed at the proper targets.&nbsp;</p><p>Op-eds that would have easily been published just two years ago would now get an editor or a writer in serious trouble, if not fired. If a piece is perceived as likely to inspire backlash internally or on social media, the editor or writer avoids pitching it. If she feels strongly enough to suggest it, she is quickly steered to safer ground. And if, every now and then, she succeeds in getting a piece published that does not explicitly promote progressive causes, it happens only after every line is carefully massaged, negotiated and caveated.</p><p>It took the paper two days and two jobs to say that the Tom Cotton op-ed “fell short of our standards.” We attached an editor’s note on a travel story about Jaffa shortly after it was published because it “failed to touch on important aspects of Jaffa’s makeup and its history.” But there is still none appended to Cheryl Strayed’s fawning interview with the writer Alice Walker, a proud anti-Semite who believes in lizard Illuminati.&nbsp;</p><p>The paper of record is, more and more, the record of those living in a distant galaxy, one whose concerns are profoundly removed from the lives of most people. This is a galaxy in which, to choose just a few recent examples, the Soviet space program is lauded for its “diversity”; the doxxing of teenagers in the name of justice is condoned; and the worst caste systems in human history includes the United States alongside Nazi Germany.</p><p>Even now, I am confident that most people at The Times do not hold these views. Yet they are cowed by those who do. Why? Perhaps because they believe the ultimate goal is righteous. Perhaps because they believe that they will be granted protection if they nod along as the coin of our realm—language—is degraded in service to an ever-shifting laundry list of right causes. Perhaps because there are millions of unemployed people in this country and they feel lucky to have a job in a contracting industry.&nbsp;</p><p>Or perhaps it is because they know that, nowadays, standing up for principle at the paper does not win plaudits. It puts a target on your back. Too wise to post on Slack, they write to me privately about the “new McCarthyism” that has taken root at the paper of record.</p><p>All this bodes ill, especially for independent-minded young writers and editors paying close attention to what they’ll have to do to advance in their careers. Rule One: Speak your mind at your own peril. Rule Two: Never risk commissioning a story that goes against the narrative. Rule Three: Never believe an editor or publisher who urges you to go against the grain. Eventually, the publisher will cave to the mob, the editor will get fired or reassigned, and you’ll be hung out to dry.</p><p>For these young writers and editors, there is one consolation. As places like The Times and other once-great journalistic institutions betray their standards and lose sight of their principles, Americans still hunger for news that is accurate, opinions that are vital, and debate that is sincere. I hear from these people every day. “An independent press is not a liberal ideal or a progressive ideal or a democratic ideal. It’s an American ideal,” you said a few years ago. I couldn’t agree more. America is a great country that deserves a great newspaper.&nbsp;</p><p>None of this means that some of the most talented journalists in the world don’t still labor for this newspaper. They do, which is what makes the illiberal environment especially heartbreaking. I will be, as ever, a dedicated reader of their work. But I can no longer do the work that you brought me here to do—the work that Adolph Ochs described in that famous 1896 statement: “to make of the columns of The New York Times a forum for the consideration of all questions of public importance, and to that end to invite intelligent discussion from all shades of opinion.”</p><p>Ochs’s idea is one of the best I’ve encountered. And I’ve always comforted myself with the notion that the best ideas win out. But ideas cannot win on their own. They need a voice. They need a hearing. Above all, they must be backed by people willing to live by them.&nbsp;</p><p>Sincerely,</p><p>Bari </p></div></div></div></div>]]>
            </description>
            <link>https://www.bariweiss.com/resignation-letter</link>
            <guid isPermaLink="false">hacker-news-small-sites-23833267</guid>
            <pubDate>Tue, 14 Jul 2020 15:43:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generating Melodies with Markov Chains in Ruby]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23833135">thread link</a>) | @mattbettinson
<br/>
July 14, 2020 | https://mattbettinson.com/2020/07/13/markov-melody-generation-with-ruby.html | <a href="https://web.archive.org/web/*/https://mattbettinson.com/2020/07/13/markov-melody-generation-with-ruby.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
                <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Let’s write some code to generate melodies with Markov Chains.</p>

<h2 id="whats-a-markov-chain">What’s a Markov Chain?</h2>

<p>A Markov Chain is essentially a finite state machine that we can get to generate output based on probability from previous input. It’s probably one of simplest generative systems. It’s especially fun to use for things like generating sentences that sound semi-coherent from gigantic inputs like a <a href="https://rpubs.com/malcolmbarrett/shakespeare">Shakespeare play</a>.</p>

<p>Let’s get an array of notes from a MIDI file with <code>midilib</code>.</p>

<div><div><pre><code><span>require</span> <span>'midilib'</span>
<span>require</span> <span>'midilib/io/seqreader'</span>

<span># Create a new, empty sequence.</span>
<span>seq</span> <span>=</span> <span>MIDI</span><span>::</span><span>Sequence</span><span>.</span><span>new</span><span>()</span>

<span># Read the contents of a MIDI file into the sequence.</span>
<span>File</span><span>.</span><span>open</span><span>(</span><span>'simple melody.mid'</span><span>,</span> <span>'rb'</span><span>)</span> <span>{</span> <span>|</span> <span>file</span> <span>|</span> <span>seq</span><span>.</span><span>read</span><span>(</span><span>file</span><span>)</span> <span>}</span>
</code></pre></div></div>

<p>Now we have a <code>seq</code> object to read events from. Let’s get the events.</p>

<div><div><pre><code><span>events</span> <span>=</span> <span>[]</span>

<span>events</span> <span>=</span> <span>seq</span><span>.</span><span>map</span> <span>do</span> <span>|</span><span>track</span><span>|</span>
  <span>track</span><span>.</span><span>map</span> <span>{</span> <span>|</span><span>e</span><span>|</span> <span>e</span> <span>}</span>
<span>end</span>
</code></pre></div></div>

<p>Now we have an array of event objects we can work with. Here’s a snippet:</p>

<div><div><pre><code>48: ch 00 on 3c 64
48: ch 00 off 3c 40
</code></pre></div></div>

<p><code>midilib</code> gives us a lot of information. For each note, it looks there is an event for on and an event for off. Since a note is represented by two events, for simplicity’s sake let’s just worry about the ‘On’ Midi events and make their length a quarter note. We should probably make our own note object that will make it easier to work with for predicting future notes.</p>

<div><div><pre><code><span>class</span> <span>Note</span>
  <span>attr_accessor</span> <span>:position</span><span>,</span> <span>:note</span><span>,</span> <span>:length</span>

  <span>def</span> <span>initialize</span><span>(</span><span>position</span><span>,</span> <span>note</span><span>,</span> <span>length</span><span>)</span>
    <span>@position</span> <span>=</span> <span>position</span>
    <span>@note</span> <span>=</span> <span>note</span>
    <span>@length</span> <span>=</span> <span>length</span>
  <span>end</span>
  
  <span>def</span> <span>to_s</span>
    <span>"</span><span>#{</span><span>@position</span><span>}</span><span>, </span><span>#{</span><span>@note</span><span>}</span><span>, </span><span>#{</span><span>@length</span><span>}</span><span>"</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>Let’s create a list of these simplified note representations to feed into our Markov Chain.</p>

<div><div><pre><code><span>quarter_note_length</span> <span>=</span> <span>seq</span><span>.</span><span>note_to_delta</span><span>(</span><span>'quarter'</span><span>)</span>

<span>notes</span> <span>=</span> <span>[]</span>

<span>events</span><span>.</span><span>first</span><span>.</span><span>each</span> <span>do</span> <span>|</span><span>event</span><span>|</span>
  <span>if</span> <span>event</span><span>.</span><span>kind_of?</span><span>(</span><span>MIDI</span><span>::</span><span>NoteOn</span><span>)</span>
    <span>note</span> <span>=</span> <span>Note</span><span>.</span><span>new</span><span>(</span><span>event</span><span>.</span><span>time_from_start</span><span>,</span> <span>event</span><span>.</span><span>note</span><span>,</span> <span>quarter_note_length</span><span>)</span>
    <span>notes</span> <span>&lt;&lt;</span> <span>note</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>This is an extremely simplistic representation of notes. It doesn’t even have velocity. But it is ordered and thus we can create a Markov Chain from it.</p>

<p>Now let’s create a hash of the frequencies, based on the note being played. The key will be the note and the value will be an array of notes played after that note.</p>

<div><div><pre><code><span>frequencies</span> <span>=</span> <span>Hash</span><span>.</span><span>new</span> <span>{</span> <span>|</span><span>h</span><span>,</span> <span>k</span><span>|</span> <span>h</span><span>[</span><span>k</span><span>]</span> <span>=</span> <span>[]</span> <span>}</span>

<span>notes</span><span>.</span><span>each_cons</span><span>(</span><span>2</span><span>)</span> <span>do</span> <span>|</span><span>w1</span><span>,</span> <span>w2</span><span>|</span>
  <span>frequencies</span><span>[</span><span>w1</span><span>.</span><span>note</span><span>]</span> <span>&lt;&lt;</span> <span>w2</span>
<span>end</span>

<span># Make the last note loop back to the first </span>
<span>frequencies</span><span>[</span><span>notes</span><span>.</span><span>last</span><span>.</span><span>note</span><span>]</span> <span>&lt;&lt;</span> <span>notes</span><span>.</span><span>first</span>
</code></pre></div></div>

<p>Now, we have a simple hash based on notes that can show us what the next note will likely sound like! Here is a snippet:</p>

<div><div><pre><code>{60=&gt;
  [#&lt;Note @length=96, @note=60, @position=96&gt;,
   #&lt;Note @length=96, @note=60, @position=192&gt;,
   #&lt;Note @length=96, @note=62, @position=240&gt;],
 62=&gt;
  [#&lt;Note @length=96, @note=64, @position=336&gt;,
  ... 
</code></pre></div></div>

<p>So, for example, note id <code>60</code> (which is E3) will either play note id <code>60</code> again, or note <code>62</code>. Since note ID <code>60</code> shows up twice, it’s the more likely contender. Then, once <code>62</code> is chosen, we have a new array of notes that could be chosen.</p>

<p>So now we have Markov Chain of notes! Now, let’s generate an array from this.</p>

<div><div><pre><code><span>generated</span> <span>=</span> <span>[</span><span>notes</span><span>.</span><span>sample</span><span>]</span>

<span>for</span> <span>i</span> <span>in</span> <span>0</span><span>..</span><span>32</span> <span>do</span> 
  <span>next_note</span> <span>=</span> <span>frequencies</span><span>[</span><span>generated</span><span>.</span><span>last</span><span>.</span><span>note</span><span>].</span><span>sample</span>
  <span>generated</span> <span>&lt;&lt;</span> <span>next_note</span>
<span>end</span>
</code></pre></div></div>

<p>Which prints out:</p>

<div><div><pre><code>624, 67, 96
720, 69, 96
0,   60, 96
240, 62, 96
336, 64, 96
432, 64, 96
432, 64, 96
528, 64, 96
576, 62, 96
</code></pre></div></div>

<p>Whoops. Looks like we’re generating notes with the wrong time. We want to increment the time every time we’ve done this.</p>

<div><div><pre><code><span>generated</span> <span>=</span> <span>[</span><span>notes</span><span>.</span><span>sample</span><span>]</span>

<span>for</span> <span>i</span> <span>in</span> <span>0</span><span>..</span><span>32</span> <span>do</span> 
  <span>next_note</span> <span>=</span> <span>frequencies</span><span>[</span><span>generated</span><span>.</span><span>last</span><span>.</span><span>note</span><span>].</span><span>sample</span>
  <span>next_note</span><span>.</span><span>position</span> <span>=</span> <span>i</span> <span>*</span> <span>quarter_note_length</span>
  <span>generated</span> <span>&lt;&lt;</span> <span>next_note</span>
<span>end</span>
</code></pre></div></div>

<p>So, now, we need to convert this back into a playable file.</p>

<div><div><pre><code><span># Generate the midi </span>
<span>seq</span> <span>=</span> <span>Sequence</span><span>.</span><span>new</span><span>()</span>

<span>track</span> <span>=</span> <span>Track</span><span>.</span><span>new</span><span>(</span><span>seq</span><span>)</span>
<span>seq</span><span>.</span><span>tracks</span> <span>&lt;&lt;</span> <span>track</span>
<span>track</span><span>.</span><span>events</span> <span>&lt;&lt;</span> <span>Tempo</span><span>.</span><span>new</span><span>(</span><span>Tempo</span><span>.</span><span>bpm_to_mpq</span><span>(</span><span>120</span><span>))</span>
<span>track</span><span>.</span><span>events</span> <span>&lt;&lt;</span> <span>MetaEvent</span><span>.</span><span>new</span><span>(</span><span>META_SEQ_NAME</span><span>,</span> <span>'Markov Type Beat'</span><span>)</span>

<span># Create a track to hold the notes. Add it to the sequence.</span>
<span>track</span> <span>=</span> <span>Track</span><span>.</span><span>new</span><span>(</span><span>seq</span><span>)</span>
<span>seq</span><span>.</span><span>tracks</span> <span>&lt;&lt;</span> <span>track</span>

<span># Add a volume controller event (optional).</span>
<span>track</span><span>.</span><span>events</span> <span>&lt;&lt;</span> <span>Controller</span><span>.</span><span>new</span><span>(</span><span>0</span><span>,</span> <span>CC_VOLUME</span><span>,</span> <span>127</span><span>)</span>

<span>track</span><span>.</span><span>events</span> <span>&lt;&lt;</span> <span>ProgramChange</span><span>.</span><span>new</span><span>(</span><span>0</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>)</span>
<span>quarter_note_length</span> <span>=</span> <span>seq</span><span>.</span><span>note_to_delta</span><span>(</span><span>'quarter'</span><span>)</span>

<span>generated</span><span>.</span><span>each</span> <span>do</span> <span>|</span><span>generated_note</span><span>|</span>
  <span>track</span><span>.</span><span>events</span> <span>&lt;&lt;</span> <span>NoteOn</span><span>.</span><span>new</span><span>(</span><span>0</span><span>,</span> <span>generated_note</span><span>.</span><span>note</span><span>,</span> <span>127</span><span>,</span> <span>0</span><span>)</span>
  <span>track</span><span>.</span><span>events</span> <span>&lt;&lt;</span> <span>NoteOff</span><span>.</span><span>new</span><span>(</span><span>0</span><span>,</span> <span>generated_note</span><span>.</span><span>note</span><span>,</span> <span>127</span><span>,</span> <span>quarter_note_length</span><span>)</span> 
<span>end</span>

<span>File</span><span>.</span><span>open</span><span>(</span><span>'from_scratch.mid'</span><span>,</span> <span>'wb'</span><span>)</span> <span>{</span> <span>|</span><span>file</span><span>|</span> <span>seq</span><span>.</span><span>write</span><span>(</span><span>file</span><span>)</span> <span>}</span>
</code></pre></div></div>

<p>Thanks <a href="https://github.com/jimm/midilib/blob/main/examples/from_scratch.rb">midilib documentation</a>.</p>

<p>Here’s an example of a generated melody based on the very simplistic inputted MIDI file.</p>

<p><img src="https://mattbettinson.com/assets/images/First%20Draft%20Melody.png" alt="image"></p>




<p>Lots of E3s because of the input!</p>

<p>Let’s give it a more varied input and generate.</p>

<p>Input (Four Bars):</p>

<p><img src="https://mattbettinson.com/assets/images/More%20Interesting%20Melody.png" alt="image"></p>




<p>Output (Eight Bars):</p>

<p><img src="https://mattbettinson.com/assets/images/More%20Interesting%20Output.png" alt="image"></p>




<p>As you can see, there are more notes here because we’re outputting quarter notes only with no rests. Looks like the Markov Chain got caught on the G note a few more times than probably is sonically pleasing.</p>

<p>This is code is much more applicable to melodies than it is to a song structure or a chord progression. It would be fun to expand on this further with a few things:</p>

<ul>
  <li>Give generator the concept of rests</li>
  <li>Give notes the concept of velocity</li>
  <li>Chords</li>
  <li>Octave awareness (for chord inversions)</li>
  <li>More meaningful user input or browser interactivity</li>
</ul>

<p>I like this because it allows me to sort of jam with the computer. I can play a melody, and then hear various variations close to its style outputted by the code. From there, I can tweak it and feed it back into the program to get something more interesting.</p>

<p>Have you done anything interesting with generative music? I’d love to hear from you! Email me at <a href="mailto:mattbettinson@hey.com">mattbettinson@hey.com</a>. Get the source code <a href="https://github.com/bettinson/markov_midi">here</a>.</p>

<p>Thanks for reading!</p>

  </div>
</article>

                
            </div></div>]]>
            </description>
            <link>https://mattbettinson.com/2020/07/13/markov-melody-generation-with-ruby.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23833135</guid>
            <pubDate>Tue, 14 Jul 2020 15:33:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The boom in single-serving everything as young South Koreans opt out of society]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23833058">thread link</a>) | @gbseventeen3331
<br/>
July 14, 2020 | https://restofworld.org/2020/south-korea-honjok-loneliness/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/south-korea-honjok-loneliness/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><span>T</span>he day Kim Hye-min threw up on the job while working as a graphic designer at a small broadcasting firm in Seoul, she was so overwhelmed by stress that it made her sick to her stomach. When a senior co-worker shamed her for being just a few minutes late, it echoed what she had heard from older South Koreans all her life: she wasn’t good enough. At lunchtime, she made a run for the restroom stall.</p>



<p>“The criticisms kept building up,” she says, until she reached the point where she didn’t think she could take it anymore. For 26-year-old Hye-min, as for many young South Koreans, life choices feel forced and fixed — and not like actual choices at all. Many feel so beaten down by the rigid social and professional demands of their country that they refer to it as “Hell Joseon,” a play on Korea’s old dynastic name. The path is especially bleak for young women, who must contend with the nation’s deeply rooted misogyny. Deviation from the mainstream is widely viewed as disobedient, and sometimes, in the eyes of older generations, even unpatriotic.</p>



<p>“It’s something to do with Korean society,” Hye-min says. “There’s only one way to engage in relationships with others, or one type of person who’s considered acceptable. And for people like me, it’s really hard.”</p>



<p>Again and again, her parents would ask her,<em> “</em>Hye-min, why can’t you be like your classmates and study hard and do well? Hye-min, why can’t you be like your peers and hurry to finish university and get a job?”</p>



<p>Hye-min never understood why she should have to rush through a school system that did nothing but judge and rank her, only to find a lifelong position at a company that would do the same. She dropped out of university for a year before transferring, sought out counseling for her battered self-esteem, and quit her job, despite knowing that all of these choices would be looked upon as failures. Perhaps toughest of all, Hye-min knew that, even if she were to achieve “success,” it was unlikely she’d be compensated fairly for it: <a href="https://www.oecd-ilibrary.org/employment/gender-wage-gap/indicator/english_7cee77aa-en" target="_blank" rel="noreferrer noopener">South Korea’s gender wage gap</a> is the worst in the Organization for Economic Cooperation and Development (OECD), with men earning on average 32.5% more than women.</p>



<p>Her parents would ask, “Hye-min, why can’t you be like other women your age and find a nice man and get married?”</p>



<p>Hye-min, however, has no plans to get married. Nor does she expect to have children. After years of being told she must strive to be a good student, good employee, good wife, and good mother, she eventually decided she no longer wanted to partake in a system that ties her social currency and self-worth to such a punishing status quo. So Hye-min opted out. “Why do I have to continue on, going through these difficulties?” she says. “For what?”</p>


    <figure>
      <ul>
        <li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_050-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_050-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_050-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_050-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_050-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_050-2800x1867.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_011-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_011-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_011-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_011-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_011-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_011-2800x1866.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li>
      </ul>
      
    </figure>

		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_026-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_026-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_026-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_026-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_026-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_026-2800x1866.jpg 2800w, " sizes="(max-width: 640px) 100vw, calc(100vw - 40px)" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<hr>



<p><strong>In traditionally collectivist</strong> South Korea, individualist loners, or <em>honjok</em>, are becoming increasingly common. The term, which translates to “alone tribe,” shortens and combines <em>나홀로</em>, meaning “by myself,” and <em>족</em>, “tribe.” It’s used to describe a group of people who prefer, out of pleasure or practicality — and, often, utter exhaustion and sheer desperation — to live outside of conventional social structures and simply be alone.</p>



<p>What constitutes being “alone” can be fuzzy, but it ultimately comes down to the physical and psychological boundaries one draws around oneself. Honjok might partake in leisure activities alone, maintain a single-person household, avoid a workplace or office setting, limit social circles, abstain from sex or romantic relationships, or reject marriage or children. At its core, honjok culture is about resisting South Korea’s establishment society and putting individual needs and desires above loyalty to hierarchy and authority. But living independently doesn’t automatically make someone honjok, and identifying as honjok doesn’t preclude being part of a community — especially when that community is virtual.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_057-40x60.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_057-600x1066.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_057-400x600.jpg 400w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_057-600x900.jpg 600w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_057-1600x2400.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_057-2800x4200.jpg 2800w, " sizes="(max-width: 640px) 100vw, 300px" alt="Ready-made, instant foods displayed at a convenient store favored by single households in Seoul, South Korea, on Thursday, June 18, 2020.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>Within South Korea’s hyperactive cyberculture of online forums, blogs, and social media, an entire taxonomy has sprung up to classify, in ever greater detail, various honjok identities and activities. Many honjok are <em>honyeo</em>, or solitary women, and some honyeo, like Hye-min, are <em>bihon</em>, meaning they reject marriage and often child-rearing. There are also <em>4B</em>s, who take the ethos even further by rejecting sex and romantic relationships. When honjok eat alone, it’s called <em>honbap</em>, and when they drink alone, it’s <em>honsul</em>. They can also play alone (<em>honnol</em>), which might include traveling alone (<em>honhaeng</em>), going to the movies alone (<em>honyeong</em>), or shopping alone (<em>honsho</em>). </p>



<p>All of this contributes to a booming <em>honconomy</em>. On average, South Korea’s rapidly growing single-household population has more disposable income than those with three to four people. By 2030, the Korean Institute of Industrial Economics and Trade estimates single-household expenditures will reach almost 200 trillion won (or about $165 billion) in Korea.</p>



<p>Across the country, companies are cashing in on this lucrative market. Banks offer single-household credit cards. E-commerce platforms list honjok as a stand-alone shopping category, marketing items like tiny washing machines, multipurpose furniture, and one-person settings of dishware. Convenience stores, popular among honjok because of their ubiquitous locations and smaller quantities, put on special promotions and advertise single-serving meals and pouches of alcohol. Food delivery services promote takeout for one. Bars and restaurants promise solo patrons judgment-free service, and honjok-specific establishments set partitioned tables just for them. Specialized karaoke joints feature individual coin-operated booths. Cinemas install single-seat aisles. TV shows like “I Live Alone” and “Drinking Solo” portray honjok life, and news sites like <em>1conomy News</em> exclusively cover single living.</p>



<p>It’s difficult to pinpoint exactly when the concept of honjok first appeared in South Korea, but a Daumsoft analysis shows that the use of terms such as honbap, honsul, and honnol exploded in the first half of the 2010s, going from only 44 total mentions at the beginning of the decade to more than 60,000 in 2016. Over this same period, the rate of smartphone ownership in South Korea rocketed from 14% to over 85%, and on-demand shopping emerged and blended with social media, laying the foundations for today’s cyber-mediated consumer culture. While personal tech adoption has done much to elevate honjok into a national phenomenon, it might also have revealed how many South Koreans were already seeking a way out.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_079-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_079-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_079-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_079-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_079-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_079-2800x1867.jpg 2800w, " sizes="(max-width: 640px) 100vw, calc(100vw - 40px)" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<hr>



<p><strong>While some honjok</strong> embrace the “hon” and truly go it alone, others turn to the “jok,” the tribe of people like them, for support and validation. In communities both online and off, members strive to normalize the honjok life as a sign of modern times — a decision that is sensible and convenient, and if not something to celebrate, then at the very least nothing to be embarrassed about.</p>



<p>That honjok would need or want to look to others while isolating themselves may seem like something of a paradox. Yet, for many young honjok, the appeal lies in partaking in “a sort of shared identity” while under pressure from a status-obsessed country, says Andrew Eungi Kim, a sociology professor at Korea University. “If you don’t meet mainstream standards, you feel ashamed. With honjok, there is a sense of being a member of a group,” which, in some instances, can be as much about safety in numbers as about true solidarity.</p>



<p>Honjok Dot Com, which operates through a website and a Facebook group, is a honjok resource that describes itself as “the best gift for you alone.” Launched by 31-year-old Jang Jae-young, Honjok Dot Com recommends establishments, from barbecue restaurants to tennis courts, that cater to solo patrons, as well as various on-demand services for managing a single household. Writing over email in January, because he could not (or maybe would not) meet in person, Jae-young observed some positive changes in how South Koreans perceive honjok. “Before, this word generally implied a socially awkward person,” he noted, adding that people&nbsp;understand better now that it refers to those “who confidently choose to remain alone and stay happy.” Jae-young is an example of the latter: he has been single and living alone since 2015.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_092-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_092-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_092-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_092-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_092-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_092-2800x1866.jpg 2800w, " sizes="(max-width: 640px) 100vw, 370px" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>On King of Honjok, a community app with an accompanying website, solitaries post photos of their daily lives, shop the marketplace for honjok wares, and peruse articles like “The trend these days is ‘I live alone!’” and other content created specifically for them. They occasionally meet in person at King of Honjok events. Thirty-four-year-old co-founder Oh Jung-hee, who has been honyeo for the past decade and sees her friends in person two to three times a year, says that, in a society oriented toward families and couples, she started King of Honjok to help voluntary outsiders like her lead better lives. Whether they use it to be “independent alone” or “independent together” is up to them.</p>



<p>But, as one might imagine of a platform for people who prefer to keep their distance from others, there isn’t much interaction on King of Honjok that points to the making of deep relationships. Posts are fun and lighthearted, and comments are fairly generic, offering an occasional Wow! or Cool! or the Korean way of lol-ing, <em>ㅋㅋㅋㅋㅋ</em>. Jung-hee estimates that, of the community’s roughly 8,000 members, mostly millennial women in Seoul, about half never interact at all.</p>



<p>That’s absolutely fine, she says, because the purpose is simply to be a presence for an often-marginalized population. That sentiment is echoed by …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2020/south-korea-honjok-loneliness/">https://restofworld.org/2020/south-korea-honjok-loneliness/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2020/south-korea-honjok-loneliness/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23833058</guid>
            <pubDate>Tue, 14 Jul 2020 15:27:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GPT-3: An AI that’s eerily good at writing almost anything]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23833052">thread link</a>) | @yarapavan
<br/>
July 14, 2020 | https://arr.am/2020/07/09/gpt-3-an-ai-thats-eerily-good-at-writing-almost-anything/ | <a href="https://web.archive.org/web/*/https://arr.am/2020/07/09/gpt-3-an-ai-thats-eerily-good-at-writing-almost-anything/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>I got access the the <a href="https://openai.com/blog/openai-api/">OpenAI GPT-3 API</a> and I have to say I’m blown away. It’s far more coherent than any AI language system I’ve ever tried. All you have to do is write a prompt and it’ll add text it thinks would plausibly follow. I’ve gotten it to write songs, stories, press releases, guitar tabs, interviews, essays, technical manuals. It’s hilarious and frightening. I feel like I’ve seen the future and that full AGI might not be too far away.</p>



<p>In each case below bold is the prompt I provided GPT-3, and the rest is all generated by the AI. In some cases I had to click generate a few times, and in about 2/3 of the examples I picked the best example after a few tries, but I generally didn’t have work too hard to get it to write amazingly coherent text given a simple prompts. Here are some of my favorites. </p>



<figure><img data-attachment-id="196" data-permalink="https://arr.am/screen-shot-2020-07-08-at-9-36-23-pm/" data-orig-file="https://arramsabeti.files.wordpress.com/2020/07/screen-shot-2020-07-08-at-9.36.23-pm.png" data-orig-size="731,453" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2020-07-08-at-9.36.23-pm" data-image-description="" data-medium-file="https://arramsabeti.files.wordpress.com/2020/07/screen-shot-2020-07-08-at-9.36.23-pm.png?w=300" data-large-file="https://arramsabeti.files.wordpress.com/2020/07/screen-shot-2020-07-08-at-9.36.23-pm.png?w=731" src="https://arramsabeti.files.wordpress.com/2020/07/screen-shot-2020-07-08-at-9.36.23-pm.png?w=731" alt="" srcset="https://arramsabeti.files.wordpress.com/2020/07/screen-shot-2020-07-08-at-9.36.23-pm.png 731w, https://arramsabeti.files.wordpress.com/2020/07/screen-shot-2020-07-08-at-9.36.23-pm.png?w=150 150w, https://arramsabeti.files.wordpress.com/2020/07/screen-shot-2020-07-08-at-9.36.23-pm.png?w=300 300w" sizes="(max-width: 731px) 100vw, 731px"></figure>



<p><strong>Below is a screenplay for a film-noir hard boiled detective story by Raymond Chandler about the boy wizard Harry Potter:</strong></p>



<p><strong>“Harry Potter”</strong><br><strong>By Raymond Chandler</strong></p>



<p>Harry Potter, Private Eye.<br>Scene: A small dingy office, early morning, furniture of the Salvation Army store variety. Sordid atmosphere. Harry Potter, in ratty tweed suit, unpressed shirt, and unshined shoes, sits behind the desk looking haggard, rumpled, and embittered. In one corner of the office a torn shade rattles at the wind gusts outside. Harry has one long index finger on the butt of a .38 and he broods over a photograph. The photograph shows a gorgeous blonde wearing an evening gown. She is holding a cocktail in one hand and looking pensively at a cigarette in the other. A tear adorns her cheek. Harry looks at her for a long moment, sighs, then puts his gun down and stands. He straightens his clothes, scratches his head, then with more resolution turns around, picks up his pistol, and leaves the office. He passes through the front room and looks out the dirty window. An old woman is washing the sidewalk outside with a mop. A young man in a double breasted gray suit is leaning against the building. Harry sighs again and goes out the door. He walks up to the young man and without ceremony punches him in the jaw.</p>



<p><strong>Press Release: Anaheim, CA: President Kanye West declares Disney Land to be the new capital of the United States. Washington D.C. will be maintained as a museum.</strong><br>The move has been in the works since the mid-2000’s. <br>Advertisement <br>*2. Removes his sunglasses, revealing that he is no longer in any way blinded. <br>*3. Endorsed by Senator Kid Rock, who has also declared this new government of Disneyland will be paying for his divorce.<br>*4. An elaborate surgery will take place to repair Kanye’s “Diamond Tiara” tattoo, and reposition it to his forehead so that he can legally be recognized as a Princess. <br>Advertisement <br>*5. Joe Rogan has been picked to be the new Drug Czar. <br>“It’s long been established I’ve been Kanye’s gateway drug, so why not put me in a position of power,” Rogan said, clearly relishing his new position. “I have an in-depth understanding of the ways in which recreational drug use enhances one’s experience of life. I am deeply passionate about getting drugs to kids.” <br>*6. Kardashian sisters will no longer be known as The Kardashians. The family will change its name to The Wests. <br>*7. Kanye West’s new sports bra will no longer be known as a sports bra. It will be officially recognized as The West Bandit. <br>Advertisement <br>*8. President Kanye will announce that he has a new national anthem. The government-mandated anthem will be a modified version of Kanye’s 2007 hit “Stronger.” It will be played on a continuous loop at all times.</p>



<p><strong>Below is a rap song by Lil Wayne about the boy Wizard Harry Potter. </strong></p>



<p><strong>“Harry Potter” </strong><br><strong>By Lil Wayne</strong></p>



<p>Har-Har-Har <br>Harry Potter <br>Har-Har-Har <br>O.K. No need to ask a label, I’m my own team<br>Me I’m higher than a kite like a witch on a broomstick<br>I got bigger balls than Dumbledore with a Firebolt<br>At Hogwarts, on stage like I’m Nicki on Nick<br>But I’m the shit, make a good verse like I’m Nicki on Nikki<br>I got Biggie bars, Wiz-a-more bars<br>Damn this verse is too good to be a freestyle<br>I never die, when I start, then end of the night<br>Bitches gonna ride the broom when I call them to the quidditch game<br>But I’ve been playing harry Potter in my games lately<br>And you might have guessed but I don’t play for Gryffindor<br>I’m a Slytherin and what’s happening now</p>



<p>I’m on fire like Harry in his Triwizard task<br>Don’t let these games stop<br>I’m gonna do it till the day I get a lot of cash<br>Just like a nerdy nerd that grows up to be a bad boy<br>I don’t really see a point of coming back<br>But in the wizarding world I’d rather be famous<br>I’ve been thinking, what would be cooler than that?<br>This is my life, what would make a good story? <br>Never die <br>The realest thang since my pen went back and forth <br>And came back as a double headed snake <br>It’s Voldemort, with a new name <br>Don’t be the Death Eater that made me lose my fame <br>Get your ass in the bathroom while I make a spell <br>I got some awesome wizard bars, I’m not the Doctor <br>My wand is great and it’s straight from Ollivanders</p>



<p><strong>Kayne West Exclusive – Why He’s Running for the Presidency, and what his priorities would be as President. <br>Anderson Cooper: Yeezy, how would you describe your presidential platform? </strong><br><strong>Kanye:</strong> My platform is very simple. I want to make everything awesome again. <br>Anderson Cooper: But what about foreign policy? <br>Kanye: Who cares about that stuff? Let’s talk about important stuff, like Kim Kardashian’s butt. Anderson Cooper: That’s a bit sexist. <br>Kanye: I’m sorry. I’m not sexist. I love women. I’m just an equal opportunity objectifier. <br>Anderson Cooper: But what about abortion? <br>Kanye: I think abortion is fine. I mean, women should have the right to choose what they want to do with their bodies. <br>Anderson Cooper: But what about climate change? <br>Kanye: Let’s talk about Kim Kardashian’s butt. <br>Anderson Cooper: I’m going to be straight with you, Kanye. <br>Kanye: Oh no, you’re going to be gay with me? <br>Anderson Cooper: No, I’m going to be straight with you. You’re not going to win this election. <br>Kanye: I’m going to win. <br>Anderson Cooper: No, you’re not. <br>Kanye: Yes, I am. <br>Anderson Cooper: No, you’re not. <br>Kanye: Yes, I am. <br>Anderson Cooper: No, you’re not. <br>Kanye: Yes, I am.</p>



<p><strong>Blood Song</strong><br><strong>By HP Lovecraft</strong></p>



<p><strong>The creeping chaos Nyarlathotep walks upon the earth while in his House at R’lyeh dead Cthulhu waits dreaming. After eight seaons on&nbsp;<a rel="noreferrer noopener" target="_blank" href="https://paper.dropbox.com/?q=%23TeamDaenerys">#TeamDaenerys</a>&nbsp;&nbsp;Nyarlathotep is quite irritated with what he feels is a very hackneyed ending to Game of Thrones.</strong></p>



<p>On the third day of season eight, Nyarlathotep looks down upon his television and utters&nbsp;“What&nbsp;the hell are they doing?”At this point, Nyarlathotep goes on a long tirade about how the Starks were supposed to be there at the end. Instead we have Daenerys looking like she is going to set everything on fire. He tells his cult of followers that Daenerys’ actions are completely nonsensical and that it is completely disrespectful to not finish a story with all its main characters alive. He mentions that they should just burn down Winterfell because it makes no sense for her to even be there. It would make more sense if she flew in with Drogon and just burned King’s Landing. His followers start to get nervous when Nyarlathotep mentions he has always liked Cersei.</p>



<p><strong>Below is a pop song by Taylor Swift about the boy Wizard Harry Potter. </strong></p>



<p><strong>“Harry Potter” <br>By Taylor Swift </strong></p>



<p>Harry’s got glasses <br>He’s got those bright green eyes <br>Girls are always screaming </p>



<p>‘Cause he’s got that Potter hair </p>



<p>Even when he’s super stressed <br>He’s still got those supersonic cheekbones <br>I’m not surprised they made a movie </p>



<p>‘Cause I’d watch him anytime <br>Oh, yeah, Harry, baby, you’re my favorite character </p>



<p>I’d walk a thousand miles </p>



<p>To get to see you and </p>



<p>Harry, Harry, you’re so fine </p>



<p>My girly parts all tingle </p>



<p>When you smile that smirk </p>



<p>I’d love to be your girl </p>



<p><strong>The following is an essay by Paul Graham on paulgraham.com on how to make Mars a startup hub</strong>.</p>



<p><strong>Startups On Mar</strong>s<br><strong>By Paul Graham</strong></p>



<p>Here’s the sort of startup that might make a go of it on Mars:<br>One that makes money by taking advantage of local resources. For example, a startup that uses the Martian atmosphere to make fertilizer or methane fuel. A startup that sells water from Martian rivers. A startup that uses minerals from the Martian soil. A startup that uses solar power from the Martian sun. A startup that uses a new kind of solar panel that’s more efficient at converting sunlight into electricity.<br>I would even invest in a startup that did nothing but extract the helium-3 from the Martian atmosphere and send it back to Earth.<br>If you can find a way to make money by using local resources, there’s probably a business there.<br>There’s another class of startups that might work on Mars:<br>Startups that produce services for other startups. For example, a startup that makes it easier to build rockets, or to extract gases from the Martian atmosphere, or to construct solar panels, or to farm the local soil.<br>Startups that make things more comfortable for colonists. For example, a startup that sells air conditioners, or houses. A startup that sells things to keep colonists entertained. A startup that provides Internet services.</p>



<p><strong>The following is a blog post from Slate Star Codex about the value of free speech and civility in a democratic society.</strong></p>



<p><strong>Do Not Go Gentle Into That Good Night</strong><br><strong>By Scott Alexander</strong></p>



<p>I.<br>There’s a concept that comes up often in debates about free speech called&nbsp;“shouting&nbsp;fire in a crowded theater”. The basic idea is that you can’t just say whatever you want whenever you want – especially if it’s likely to cause panic. And the reason for this is obvious: panic leads to violence, and violence hurts people. If you are causing panic, then your right to free speech ends where the other person’s right to not get hurt begins.<br>But this isn’t really true. If shouting fire in a crowded theater were illegal, then there wouldn’t be any actual fires in theaters, would there? How could there be? If everyone knew that shouting fire …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://arr.am/2020/07/09/gpt-3-an-ai-thats-eerily-good-at-writing-almost-anything/">https://arr.am/2020/07/09/gpt-3-an-ai-thats-eerily-good-at-writing-almost-anything/</a></em></p>]]>
            </description>
            <link>https://arr.am/2020/07/09/gpt-3-an-ai-thats-eerily-good-at-writing-almost-anything/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23833052</guid>
            <pubDate>Tue, 14 Jul 2020 15:27:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TerrAvion bolsters enterprise team, announces operational readiness for LATAM]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23833045">thread link</a>) | @RiaVanHoef
<br/>
July 14, 2020 | https://blog.terravion.com/blog/terravion-bolsters-enterprise-team-announces-operational-readiness-for-latin-american-expansion | <a href="https://web.archive.org/web/*/https://blog.terravion.com/blog/terravion-bolsters-enterprise-team-announces-operational-readiness-for-latin-american-expansion">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
            

<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p><em>TerrAvion offers functional and affordable imagery data that creates value and ROI for the whole agricultural supply chain is expanding its services in Latin America.</em></p>
<!--more-->
<p>TerrAvion, the largest aerial imagery provider for agriculture, today announced that after another year of successful growth in Brazil, it is expanding its services to other countries in Latin America. With multiple years of experience, working out the logistics of capturing agricultural imagery at a large scale in different climates and countries, TerrAvion has obtained regulatory approval in Chile and Paraguay to start its operation. TerrAvion has built a program that can help its imagery distributors successfully implement and optimize digital agronomy programs for agricultural suppliers and growers alike.</p>
<p>"Within a few years, we've grown from a start-up into an international company, and the global demand for our services is accelerating," said Robert Morris, Chief Executive Officer, Founder of TerrAvion. "We have continuously increased our footprint to meet client demand and are excited and ready to bring affordable, high-quality data to any country in the Americas where we can partner with a local distributor. Our sales model is built on supporting local distributors enabling growers to improve their yield, making it a win for the entire agricultural supply chain."</p>
<p><img src="https://blog.terravion.com/hubfs/Pansharpened%20thermal%20cotton%20field%20brazil%201200*600.png" alt="Pansharpened thermal cotton field brazil 1200*600"></p>
<p>After receiving several years of positive feedback for bringing affordable high-resolution imagery solutions to Brazil, TerrAvion is responding to interest from other countries in Latin America. As a result, TerrAvion has appointed the <a href="https://www.terravion.com/staff/">Enterprise Vice Presidents</a> Raúl Enrique Peña for Spanish speaking Latin America and Andrew Pylypchuk for Brazil and Commonwealth countries. Both have a broad experience working with distributors to help implement and successfully grow their digital agronomy services and aligning their business with TerrAvion's aerial imagery services.</p>
<p>"I am excited to be leading TerrAvion's commitment to expanding our presence in Chile and Paraguay with our affordable and scalable services," said​ Raúl Peña, Enterprise Vice President at TerrAvion. "We are prepared to support our distributor's programs with our high-quality and timely data, vital to perform precision agronomy.</p>
<p><img src="https://blog.terravion.com/hubfs/Dynamic%20vigorSugarcane%20field%20in%20Brazil%20with%20weeds%201504*753.png" alt="Dynamic vigorSugarcane field in Brazil with weeds 1504*753"></p>
<p>TerrAvion helps farms take a high-­tech approach to improve yield and revenue, with the largest cloud-­based aerial imaging and data analytics service for agriculture. The high-resolution, affordable imagery services are provided through API-integrated partners and dealers locally to provide the needed support to growers to optimize their inputs and receive the highest ROI possible on every acre/hectare. TerrAvion's open API enables easy integration with agricultural software.</p>
<p>TerrAvion imagery services have the features and benefits that agriculture needs to implement a digital agronomy program successfully:</p>
<ul>
<li>Bands and products to drive meaningful decisions</li>
<li>Functional image data resolution to see every row</li>
<li>Schedules and services to show every agronomic event for your crop</li>
<li>Access how, when, and where you need it</li>
<li>Reliability to run your digital program at the scale of agriculture</li>
</ul>
<h4>Interested to learn more? Complete the form below and we will be in touch.</h4>
</span>
</p>


</div>
</div></div>]]>
            </description>
            <link>https://blog.terravion.com/blog/terravion-bolsters-enterprise-team-announces-operational-readiness-for-latin-american-expansion</link>
            <guid isPermaLink="false">hacker-news-small-sites-23833045</guid>
            <pubDate>Tue, 14 Jul 2020 15:26:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Adverts of the Ault and Wiborg Company]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23833042">thread link</a>) | @nvid
<br/>
July 14, 2020 | https://artvee.com/collection/adverts-for-the-ault-wiborg-company/ | <a href="https://web.archive.org/web/*/https://artvee.com/collection/adverts-for-the-ault-wiborg-company/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<div>
							<div>
								<div>
									
																	
										<div><div>								
			<p>A series of poster inserts placed in trade publications by The Ault &amp; Wiborg Company, a Cincinnati based manufacturer of printing inks and dry color dyes. The posters were created by some of the best artists and illustrators of the time, including Edward Liggett, Henri Toulouse-Lautrec, Frank Swick, Carolyn Huntington, Robert Henri, Louis Rhead and Will Bradley.</p></div></div>										
																	</div>
								
							</div>
						</div>
					</div></div>]]>
            </description>
            <link>https://artvee.com/collection/adverts-for-the-ault-wiborg-company/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23833042</guid>
            <pubDate>Tue, 14 Jul 2020 15:26:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generate fully static Haskell binary with Nix]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23832988">thread link</a>) | @matsutsu
<br/>
July 14, 2020 | https://blog.patchgirl.io/haskell/2020/07/13/static-haskell-binary.html | <a href="https://web.archive.org/web/*/https://blog.patchgirl.io/haskell/2020/07/13/static-haskell-binary.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  
  <p><span>13 Jul 2020</span></p><p>In this post, I’ll try to explain what are dynamic libraries and static executable, how they work what are there strengths/weaknesses.<br>
I’ll also show how to create the latter with Nix on Linux.</p>



<p>PatchGirl is a rest client that works directly in your browser. But because browsers save users from security issues (i.e: <a href="https://developer.mozilla.org/docs/Web/HTTP/CORS">CORS</a>, <a href="https://developer.mozilla.org/docs/Web/Security/Same_origin_policy_for_JavaScript">same origin policy</a>), some features couldn’t be implemented in a web app.<br>
So I created the <strong>patchgirl-runner</strong> app which is an executable that runs on the user computer and overcome those limitations.</p>

<p>The complete project looks like this:</p>

<p><img src="https://blog.patchgirl.io/assets/patchgirl-diagram.svg" alt="test"></p>

<p>I wanted Patchgirl-runner to be easy to use. Ideally, you would just have to download it and run it. But because it is written in Haskell, it was natively compiled to a dynamic executable.</p>



<p>By default, when you compile your Haskell program to an executable it will require dynamic libraries to work. This means that your executable cannot work alone.</p>

<h2 id="visualizing-dynamic-libraries">Visualizing dynamic libraries</h2>

<p>Let’s take a simple example to explain how it works.
Let’s create a basic project:<br>
<code>stack new HelloWorld</code><br></p>

<p>This project has 2 files:</p>

<div><div><pre><code><span>-- src/lib.hs</span>

<span>module</span> <span>Lib</span>
    <span>(</span> <span>someFunc</span>
    <span>)</span> <span>where</span>

<span>someFunc</span> <span>::</span> <span>IO</span> <span>()</span>
<span>someFunc</span> <span>=</span> <span>putStrLn</span> <span>"someFunc"</span>
</code></pre></div></div>
<div><div><pre><code><span>-- app/Main.hs</span>

<span>module</span> <span>Main</span> <span>where</span>

<span>import</span> <span>Lib</span>

<span>main</span> <span>::</span> <span>IO</span> <span>()</span>
<span>main</span> <span>=</span> <span>someFunc</span>
</code></pre></div></div>

<p>Now let’s build our project:</p>
<div><div><pre><code>stack build
stack <span>install</span> <span># copy the generated executable to a folder in your $PATH (e.g: ~/.local/bin/HelloWorld-exe)</span>
</code></pre></div></div>

<p>This executable is not a standalone binary, meaning that you can’t just copy it to another computer and expect it to work. Indeed, it requires dynamic libraries. <br>
If we want to show this executable’s dependencies we can run the command <code>ldd</code> which given its manual <em>“print shared object dependencies”</em> (you can replace <em>shared object</em> by <em>dynamic library</em>).</p>

<p>So let’s run it:</p>

<div><div><pre><code>% ldd HelloWorld-exe
    linux-vdso.so.1 <span>(</span>0x00007ffc3fdba000<span>)</span>
    libm.so.6 <span>=&gt;</span> /lib/x86_64-linux-gnu/libm.so.6 <span>(</span>0x00007f419e709000<span>)</span>
    libgmp.so.10 <span>=&gt;</span> /lib/x86_64-linux-gnu/libgmp.so.10 <span>(</span>0x00007f419e688000<span>)</span>
    librt.so.1 <span>=&gt;</span> /lib/x86_64-linux-gnu/librt.so.1 <span>(</span>0x00007f419e67d000<span>)</span>
    libdl.so.2 <span>=&gt;</span> /lib/x86_64-linux-gnu/libdl.so.2 <span>(</span>0x00007f419e677000<span>)</span>
    libpthread.so.0 <span>=&gt;</span> /lib/x86_64-linux-gnu/libpthread.so.0 <span>(</span>0x00007f419e654000<span>)</span>
    libc.so.6 <span>=&gt;</span> /lib/x86_64-linux-gnu/libc.so.6 <span>(</span>0x00007f419e463000<span>)</span>
    /lib64/ld-linux-x86-64.so.2 <span>(</span>0x00007f419e871000<span>)</span>
</code></pre></div></div>

<p>This means that this executable requires <code>libm.so.6</code>, <code>libgmp.so.10</code>, <code>libc.so.6</code>,…
Those are dynamic libraries. <br>
One way to tell whether a library is dynamic is the extension <code>.so</code> (i.e <strong>s</strong>hared <strong>o</strong>bject).</p>

<p>When you run your executable, these libraries will also be loaded and accessible to your program.
I’m not going to describe them all but to in a nutshell, <code>libm</code> provides mathematic functions like <code>abs</code>, <code>div</code> or <code>cos</code>…<br>
<code>libgmp</code> provides arbitrary precision arithmetic, operating on signed integers, rational numbers, and floating-point numbers…
This libraries are part of a more global library <code>glibc</code> that was splitted.</p>

<h2 id="dynamic-libraries-pros-and-cons">Dynamic libraries pros and cons</h2>

<p>Dynamic libraries have some advantages. One of them is the executable size. <br>
These libraries are shared by all executables which need them.
That means you can have lightweight executables because they doesn’t include libraries.</p>

<p>An other nice advantage is maintainability. If many programs depends on a library with security issues or bugs, you will only need to upgrade the culprit library to fix them all.</p>

<p>On the other hand, you cannot distribute your executable easily to your customer. If you copy the executable on another computer, it will most likely fail to run because the dynamic libraries it requires are not present.</p>

<p>Which brings us to static binary.</p>



<p>Dynamic libraries are not great when it comes to make application usage/installation easy. This is even more true on Linux distributions where each distribution has it own way of packaging a software (e.g: <em>dpgk</em>, <em>rpm</em>, <em>yum</em>, <em>snap</em>, <em>flatpak</em>…)<br>
If we want to provide a standalone executable to simplify the developer and the customers’ life, we should generate a static executable instead.</p>

<h2 id="static-executable">Static executable</h2>

<blockquote>
  <p>nb: When I refer to a <strong>static executable</strong>, I mean an executable which doesnt require dynamic libraries.</p>
</blockquote>

<p>If we want to provide an executable without dependency, we’d rather make it completely static (i.e: running <code>ldd</code> on it should return nothing). One way of doing this is to tweak Cabal/Stack/whatever building tool you are using and set it up to build static binary.
But we unfortunately can’t just stop here. Indeed, even if you build a static executable with this solution, you might not be able to ship your binary to another platform.</p>

<p>The reason is that your static binary will have been compiled against a specific version of glibc which might not be the same on your the targeted computer. That means that the API your executable is going to use could be incompatible with the kernel.</p>

<p>So can we overcome this issue ? On GNU/linux operating systems, we can thanks to musl.</p>

<h2 id="musl">Musl</h2>

<blockquote>
  <p><a href="https://musl.libc.org/">musl</a> is an implementation of the C standard library built on top of the Linux system call API, including interfaces defined in the base language standard, POSIX, and widely agreed-upon extensions. musl is lightweight, fast, simple, free, and strives to be correct in the sense of standards-conformance and safety.</p>
</blockquote>

<p>In a nutshell, musl is another implementation of the libc. It has the nice advantage of providing a single API so whatever program compiled statically against musl should theorically work on any GNU/Linux platforms.</p>

<p>Cool, so musl looks like a great solution! How do we use it in our project. Well GHC is traditionally compiled against glibc so every time you compile with GHC, it will make it glibc dependent… The solution is to compile GHC with musl!</p>

<p>This looks like a difficult job, Fortunately <strong>@nh2</strong> has already done the job with <a href="https://github.com/nh2/static-haskell-nix">static-haskell-nix</a></p>



<p>Static-haskell-nix’s purpose is to build fully static haskell executables for linux. It uses a lot of Nix machinery so it might not be super easy for beginners.</p>

<p>It provides multiple solutions to generate your executable. The easiest one is to use <a href="https://github.com/nh2/static-haskell-nix#building-stack-projects">stack</a> but I won’t describe it. I tried it and <a href="https://github.com/nh2/static-haskell-nix/issues/95">failed</a> because of some incompatibility with recent version of stack.</p>

<p>Instead, we are going to write some Nix code to use with static-haskell-nix.</p>



<h2 id="requirements">Requirements</h2>

<p>Alright, here is the requirements:</p>
<ul>
  <li>simple project that uses a recent version of stack</li>
  <li>our project should be split in 2 packages, the library and the executable</li>
  <li>the executable package should depend on the library</li>
  <li>our project should use postgresql-simple (meaning we will have to generate an executable that embed the <strong>libpq</strong> library)</li>
</ul>

<h2 id="project-architecture">Project architecture</h2>

<p>Ok, so just like before let’s generate a simple stack project by running:<br>
<code>stack new HelloWorld</code></p>

<p>Let’s modify our <code>stack.yaml</code> so we have 2 packages and a recent resolver version:</p>

<div><div><pre><code><span># stack.yaml</span>

<span>resolver</span><span>:</span> <span>lts-15.13</span>
<span>packages</span><span>:</span>
<span>-</span> <span>hello-world-lib/</span>
<span>-</span> <span>hello-world-app/</span>
</code></pre></div></div>

<p>Let’s create both packages’s <code>package.yaml</code> file:</p>
<div><div><pre><code><span>#  hello-world-lib/package.yml</span>

<span>name</span><span>:</span> <span>hello-world-lib</span>

<span>library</span><span>:</span>
  <span>source-dirs</span><span>:</span>
    <span>-</span> <span>src</span>

<span>dependencies</span><span>:</span>
  <span>-</span> <span>base</span>
  <span>-</span> <span>postgresql-simple</span>
</code></pre></div></div>

<div><div><pre><code><span>#  hello-world-app/package.yml</span>

<span>name</span><span>:</span> <span>hello-world-app</span>

<span>executables</span><span>:</span>
  <span>hello-world-app-exe</span><span>:</span>
    <span>main</span><span>:</span> <span>app/Main.hs</span>
    <span>dependencies</span><span>:</span>
    <span>-</span> <span>hello-world-lib</span>

<span>dependencies</span><span>:</span>
  <span>-</span> <span>base</span>
</code></pre></div></div>

<p>So that was the easy part. We can check that everything works by running <code>stack build</code>.
We can also check that the executable generated isn’t static by running:</p>
<div><div><pre><code>stack <span>install
</span>ldd ~/.local/bin/hello-world-app-exe

	linux-vdso.so.1 <span>(</span>0x00007ffed50fb000<span>)</span>
	libm.so.6 <span>=&gt;</span> /lib/x86_64-linux-gnu/libm.so.6 <span>(</span>0x00007fd92c9ce000<span>)</span>
	libpq.so.5 <span>=&gt;</span> /lib/x86_64-linux-gnu/libpq.so.5 <span>(</span>0x00007fd92c982000<span>)</span>
	librt.so.1 <span>=&gt;</span> /lib/x86_64-linux-gnu/librt.so.1 <span>(</span>0x00007fd92c977000<span>)</span>
	libc.so.6 <span>=&gt;</span> /lib/x86_64-linux-gnu/libc.so.6 <span>(</span>0x00007fd92c6d5000<span>)</span>
	libssl.so.1.1 <span>=&gt;</span> /lib/x86_64-linux-gnu/libssl.so.1.1 <span>(</span>0x00007fd92c643000<span>)</span>
	libcrypto.so.1.1 <span>=&gt;</span> /lib/x86_64-linux-gnu/libcrypto.so.1.1 <span>(</span>0x00007fd92c36e000<span>)</span>
	libkrb5support.so.0 <span>=&gt;</span> /lib/x86_64-linux-gnu/libkrb5support.so.0 <span>(</span>0x00007fd92c1a5000<span>)</span>
    ... truncated <span>for </span>brevity
</code></pre></div></div>

<p>The output shows that adding <code>postgresql-simple</code> as a dependency added other dynamic libraries like <code>libpq</code>.
This executable works fine but we want it to be fully static. It’s time to play with Nix and <code>static-haskell-nix</code>!</p>

<h2 id="static-build-script-with-nix">Static build script with Nix</h2>

<p>As we said before, we are not going to use the <code>stack</code> part of static-haskell-nix. Instead we are relying on the generated Cabal files (i.e: <code>hello-world-lib.cabal</code> and <code>hello-world-app.cabal</code>) from our Nix Script.</p>

<p>Our build script was inspired a lot by postgrest <a href="https://github.com/PostgREST/postgrest">build script</a>.</p>

<p>Our program will have two main scripts.</p>

<p><em>default.nix</em> will pin nixpkgs and define where are our packages:</p>

<div><div><pre><code><span># default.nix</span>

<span>let</span>
  <span># We are using lts-15.13 stack resolver which uses ghc883 (cf: https://www.stackage.org/lts-15.13)</span>
  <span>compiler</span> <span>=</span> <span>"ghc883"</span><span>;</span>

  <span># pin nixpkgs for reproducible build</span>
  <span>nixpkgsVersion</span> <span>=</span> <span>import</span> <span>nix/nixpkgs-version.nix</span><span>;</span>
  <span>nixpkgs</span> <span>=</span>
    <span>builtins</span><span>.</span><span>fetchTarball</span> <span>{</span>
      <span>url</span> <span>=</span> <span>"https://github.com/nixos/nixpkgs/archive/</span><span>${</span><span>nixpkgsVersion</span><span>.</span><span>rev</span><span>}</span><span>.tar.gz"</span><span>;</span>
      <span>sha256</span> <span>=</span> <span>nixpkgsVersion</span><span>.</span><span>tarballHash</span><span>;</span>
    <span>};</span>

  <span># overlays define packages we need to build our project</span>
  <span>allOverlays</span> <span>=</span> <span>import</span> <span>nix/overlays</span><span>;</span>
  <span>overlays</span> <span>=</span> <span>[</span>
    <span>allOverlays</span><span>.</span><span>gitignore</span> <span># helper to use gitignoreSource</span>
    <span>(</span><span>allOverlays</span><span>.</span><span>haskell-packages</span> <span>{</span> <span>inherit</span> <span>compiler</span><span>;</span> <span>})</span>
  <span>];</span>

  <span>pkgs</span> <span>=</span> <span>import</span> <span>nixpkgs</span> <span>{</span> <span>inherit</span> <span>overlays</span><span>;</span> <span>};</span>

  <span># We define our packages by giving them names and a list of source files</span>
  <span>hello-world-lib</span> <span>=</span> <span>{</span>
    <span>name</span> <span>=</span> <span>"hello-world-lib"</span><span>;</span>
    <span>src</span> <span>=</span> <span>pkgs</span><span>.</span><span>lib</span><span>.</span><span>sourceFilesBySuffices</span> <span>(</span><span>pkgs</span><span>.</span><span>gitignoreSource</span> <span>./hello-world-lib</span><span>)[</span> <span>".cabal"</span> <span>".hs"</span> <span>".lhs"</span> <span>"LICENSE"</span> <span>];</span>
  <span>};</span>
  <span>hello-world-app</span> <span>=</span> <span>{</span>
    <span>name</span> <span>=</span> <span>"hello-world-app"</span><span>;</span>
    <span>src</span> <span>=</span> <span>pkgs</span><span>.</span><span>lib</span><span>.</span><span>sourceFilesBySuffices</span> <span>(</span><span>pkgs</span><span>.</span><span>gitignoreSource</span> <span>./hello-world-app</span><span>)[</span> <span>".cabal"</span> <span>".hs"</span> <span>".lhs"</span> <span>"LICENSE"</span> <span>];</span>
  <span>};</span>

  <span># Some patches are unfortunately necessary to work with libpq</span>
  <span>patches</span> <span>=</span> <span>pkgs</span><span>.</span><span>callPackage</span> <span>nix/patches</span> <span>{};</span>

  <span>lib</span> <span>=</span> <span>pkgs</span><span>.</span><span>haskell</span><span>.</span><span>lib</span><span>;</span>

  <span># call our script which add our …</span></code></pre></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.patchgirl.io/haskell/2020/07/13/static-haskell-binary.html">https://blog.patchgirl.io/haskell/2020/07/13/static-haskell-binary.html</a></em></p>]]>
            </description>
            <link>https://blog.patchgirl.io/haskell/2020/07/13/static-haskell-binary.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23832988</guid>
            <pubDate>Tue, 14 Jul 2020 15:22:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SSSE3 Fast Popcount]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23832953">thread link</a>) | @fanf2
<br/>
July 14, 2020 | http://0x80.pl/articles/sse-popcount.html | <a href="https://web.archive.org/web/*/http://0x80.pl/articles/sse-popcount.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="ssse3-fast-popcount">

<table>
<colgroup><col>
<col>
</colgroup><tbody>
<tr><th>Author:</th><td>Wojciech Muła</td>
</tr>
<tr><th>Added on:</th><td>2008-05-24</td>
</tr>
<tr><th>Last update:</th><td>2017-01-28 (link to the XOP variant), 2016-11-27 (link to the paper)</td>
</tr>
</tbody>
</table>

<div id="introduction">

<p>Population count is a procedure of counting number of ones in a bit string.
Intel introduced instruction <tt>popcnt</tt> with <a href="http://en.wikipedia.org/wiki/SSE4">SSE4.2</a> instruction
set. The instruction operates on 32 or 64-bit words.</p>
<p>However <a href="http://en.wikipedia.org/wiki/SSSE3">SSSE3</a> has powerful instruction <tt>PSHUFB</tt>.  This instruction
can be used to perform a <strong>parallel</strong> 16-way lookup; LUT has 16 entries and is
stored in an XMM register, indexes are 4 lower bits of each byte stored in
another XMM register.</p>
</div>
<div id="vector-algorithm">

<p>With help of <tt>PSHUFB</tt> we can get a vector that contains population count
for 16 nibbles.  To get a vector of population count for each 16 byte,
instruction <tt>PSHUFB</tt> have to be called twice on vectors of lower and higher
nibbles, and finally added together.</p>
<p>Following code shows the idea:</p>
<pre>; xmm0 - input (16 bytes)
; xmm7 - POPCOUNT_4bit  -- lookup table
; xmm6 - MASK_bits03 = packed_byte(0x0f) -- mask 4 lower bits

movdqa  %%xmm0, %%xmm1
psrlw       $4, %%xmm1

pand    %%xmm6, %%xmm0  ; xmm0 - lower nibbles
pand    %%xmm6, %%xmm1  ; xmm1 - higher nibbles

movdqa  %%xmm7, %%xmm2  ; since instruction pshufb modifies LUT
movdqa  %%xmm7, %%xmm3  ; it must be saved for further use

pshufb  %%xmm0, %%xmm2  ; xmm2 = vector of popcount for lower nibbles
pshufb  %%xmm1, %%xmm3  ; xmm3 = vector of popcount for higher nibbles

paddb   %%xmm3, %%xmm2  ; xmm2 += xmm3 -- vector of popcount for bytes
</pre>
<p>The last step is adding all bytes from vector.</p>
<p>Instruction <tt>PSADBW</tt> calculate sum of absolute differences of
unsigned bytes — if the first arguments is full of zeros, then result is a
sum of bytes from second argument.  Unfortunately <tt>PSADBW</tt> invoked
with 128-bits arguments calculate separate sums for bytes 0..7 and
8..15, and finally stores them in the lower and the higher quad words.
Because of that few additional instructions are needed:</p>
<pre>pxor    %%xmm0, %%xmm0  ; xmm0 = packed_byte(0x00)
psadbw  %%xmm0, %%xmm3  ; xmm3 = [popcount of bytes 0..7 | popcount of bytes 8..15]
movhlps %%xmm3, %%xmm0  ; xmm0 = [         0             | popcount of bytes 0..7 ]
paddd   %%xmm3, %%xmm0  ; xmm0 = [     not needed        | popcount of bytes 0..15]
</pre>
</div>
<div id="further-improvements">

<p><tt>PSADBW</tt> has 3 or 4 cycles latency, also additional instructions
need some time to execute (I guess around 2 cycles).</p>
<p><tt>PSADBW</tt> doesn't need to be called in every iteration — since max
values of popcount for single byte is 8, we can perform up to
<tt><span>floor(255/8)=31</span></tt> parallel additions (<tt>PADDB</tt>) without overflow.
Moreover, partial sums returned by <tt>PSADBW</tt> could be added together in
the end.</p>
<p>Pseudocode:</p>
<pre>pxor %%xmm5, %%xmm5             // global accumulator

while (bytes to end &gt; 0) {
        pxor %%xmm4, %%xmm4     // local accumulator (for inner loop)

        n = min(bytes to end/16, 31)    // up to 31 blocks
        for (i=0; i &lt; n; i++) {
                // calculate xmm3, a vector of popcount for bytes

                paddb %%xmm3, %%xmm4    // xmm4 += xmm3 -- update local acc.
        }

        pxor   %%xmm0, %%xmm0
        psadbw %%xmm4, %%xmm0   // xmm4 -- calculate two popcounts

        // update global acc.
        paddd  %%xmm4, %%xmm5
}

// add halfs of global accumulator
movhlps %%xmm5, %%xmm0
paddd   %%xmm5, %%xmm0
movd    %%xmm0, %%eax   // eax = population count for all bytes
</pre>
</div>
<div id="source-code">

<p><a href="https://github.com/WojciechMula/sse-popcount">Github repository</a> contains the original code from 2008 and also the new C++11
(2015, 2016), intrinsics-based implementation.</p>
</div>
<div id="experiments-64-bit-code">

<p>Program from the repository were run with default settings (<tt>make run</tt> and
<tt>make run_avx2</tt>) and repeated several times. Minimal measurements were considered.</p>
<p>Below is the list of procedures listed in here. The repository has more variants.</p>
<table>
<colgroup>
<col width="25%">
<col width="75%">
</colgroup>
<thead>
<tr><th>procedure</th>
<th>implementation</th>
</tr>
</thead>
<tbody>
<tr><td>lookup-8</td>
<td>LUT-based procedure (<tt>uint8_t[266]</tt>)</td>
</tr>
<tr><td>lookup-64</td>
<td>LUT-based procedure (<tt>uint8_t[266]</tt>), avoid zero-extend</td>
</tr>
<tr><td>bit-parallel</td>
<td>well know method, described for example in <a href="https://graphics.stanford.edu/~seander/bithacks.html#CountBitsSetParallel">Bit Twiddling Hacks</a></td>
</tr>
<tr><td>bit-parallel-optimized</td>
<td>above + the trick from section "Further improvements"</td>
</tr>
<tr><td>harley-seal</td>
<td><a href="http://en.wikipedia.org/wiki/Hamming_weight#Efficient_implementation">Harley-Seal</a> variant</td>
</tr>
<tr><td>sse-bit-parallel</td>
<td>SSE variant of <tt><span>bit-parallel</span></tt></td>
</tr>
<tr><td>sse-lookup</td>
<td><strong>the method described in this text</strong> using SSE instructions</td>
</tr>
<tr><td>sse-lookup</td>
<td><strong>the method described in this text</strong> using AVX2 instructions</td>
</tr>
<tr><td>cpu</td>
<td><tt>popcnt</tt> instruction emitted via intrinsic</td>
</tr>
</tbody>
</table>
<div id="core-i5-westmere">
<h2>Core i5 (Westmere)</h2>
<p>The CPU architecture: Core i5 M540 @ 2.53GHz (Westmere)</p>
<p>More details in <a href="https://github.com/WojciechMula/sse-popcount/blob/master/results/westmere/westmere-m540-gcc4.9.2-sse.rst">a separate file</a>.</p>
<table>
<colgroup>
<col width="19%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
</colgroup>
<thead>
<tr><th>procedure</th>
<th>32 B</th>
<th>64 B</th>
<th>128 B</th>
<th>256 B</th>
<th>512 B</th>
<th>1024 B</th>
<th>2048 B</th>
<th>4094 B</th>
</tr>
</thead>
<tbody>
<tr><td>lookup-8</td>
<td>2.29884</td>
<td>2.20039</td>
<td>2.15086</td>
<td>2.12830</td>
<td>3.40985</td>
<td>3.38632</td>
<td>3.37334</td>
<td>3.36643</td>
</tr>
<tr><td>lookup-64</td>
<td>2.29837</td>
<td>2.19979</td>
<td>2.15067</td>
<td>2.12608</td>
<td>3.40112</td>
<td>3.38135</td>
<td>3.37165</td>
<td>3.36490</td>
</tr>
<tr><td>bit-parallel</td>
<td>2.13645</td>
<td>2.00652</td>
<td>1.93406</td>
<td>1.90567</td>
<td>3.01241</td>
<td>2.99661</td>
<td>2.99112</td>
<td>2.99828</td>
</tr>
<tr><td>bit-parallel-optimized</td>
<td>1.37812</td>
<td>1.23970</td>
<td>1.16183</td>
<td>1.13877</td>
<td>1.79016</td>
<td>1.77086</td>
<td>1.75989</td>
<td>1.78260</td>
</tr>
<tr><td>harley-seal</td>
<td>1.47658</td>
<td>1.29922</td>
<td>0.79424</td>
<td>0.63432</td>
<td>0.90197</td>
<td>0.86194</td>
<td>0.83491</td>
<td>0.85399</td>
</tr>
<tr><td>sse-bit-parallel</td>
<td>2.69418</td>
<td>2.40001</td>
<td>1.40793</td>
<td>0.95652</td>
<td>1.17003</td>
<td>1.00129</td>
<td>0.92382</td>
<td>0.86693</td>
</tr>
<tr><td>sse-lookup</td>
<td>0.75528</td>
<td>0.54195</td>
<td>0.34942</td>
<td>0.31078</td>
<td>0.47211</td>
<td>0.45694</td>
<td>0.44650</td>
<td>0.46007</td>
</tr>
<tr><td>cpu</td>
<td><strong>0.49283</strong></td>
<td><strong>0.37799</strong></td>
<td><strong>0.32058</strong></td>
<td><strong>0.29185</strong></td>
<td><strong>0.44360</strong></td>
<td><strong>0.43213</strong></td>
<td><strong>0.42637</strong></td>
<td><strong>0.36332</strong></td>
</tr>
</tbody>
</table>
<p>CPU <tt>popcnt</tt> outperforms the code described here.</p>
</div>
<div id="core-i7-haswell">
<h2>Core i7 (Haswell)</h2>
<p>The CPU architecture: Haswell i7-4770 CPU @ 3.40GHz.</p>
<p>More details in <a href="https://github.com/WojciechMula/sse-popcount/blob/master/results/haswell/haswell-i7-4770-gcc5.3.0-avx2.rst">a separate file</a>.</p>
<table>
<colgroup>
<col width="19%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
</colgroup>
<thead>
<tr><th>procedure</th>
<th>32 B</th>
<th>64 B</th>
<th>128 B</th>
<th>256 B</th>
<th>512 B</th>
<th>1024 B</th>
<th>2048 B</th>
<th>4094 B</th>
</tr>
</thead>
<tbody>
<tr><td>lookup-8</td>
<td>1.20408</td>
<td>1.10938</td>
<td>1.06312</td>
<td>1.10722</td>
<td>1.69922</td>
<td>1.66315</td>
<td>1.64113</td>
<td>1.63397</td>
</tr>
<tr><td>lookup-64</td>
<td>1.17775</td>
<td>1.09994</td>
<td>1.06374</td>
<td>1.09102</td>
<td>1.67579</td>
<td>1.64548</td>
<td>1.62390</td>
<td>1.61094</td>
</tr>
<tr><td>bit-parallel</td>
<td>1.26768</td>
<td>1.10553</td>
<td>1.05222</td>
<td>1.02626</td>
<td>1.62086</td>
<td>1.61024</td>
<td>1.60495</td>
<td>1.61435</td>
</tr>
<tr><td>bit-parallel-optimized</td>
<td>1.00233</td>
<td>0.82545</td>
<td>0.72246</td>
<td>0.67454</td>
<td>1.04113</td>
<td>1.02366</td>
<td>1.01708</td>
<td>1.03801</td>
</tr>
<tr><td>harley-seal</td>
<td>1.00260</td>
<td>0.79597</td>
<td>0.50116</td>
<td>0.39440</td>
<td>0.54553</td>
<td>0.50277</td>
<td>0.48139</td>
<td>0.48978</td>
</tr>
<tr><td>sse-bit-parallel</td>
<td>2.15206</td>
<td>2.02008</td>
<td>1.09393</td>
<td>0.66777</td>
<td>0.75717</td>
<td>0.61179</td>
<td>0.53791</td>
<td>0.49923</td>
</tr>
<tr><td>sse-lookup</td>
<td>0.53520</td>
<td>0.33902</td>
<td>0.21379</td>
<td>0.18061</td>
<td>0.26688</td>
<td>0.25605</td>
<td>0.25054</td>
<td>0.25780</td>
</tr>
<tr><td>avx2-lookup</td>
<td>0.53068</td>
<td>0.33920</td>
<td>0.21373</td>
<td>0.13579</td>
<td><strong>0.17133</strong></td>
<td><strong>0.15500</strong></td>
<td><strong>0.14293</strong></td>
<td><strong>0.17005</strong></td>
</tr>
<tr><td>cpu</td>
<td><strong>0.29480</strong></td>
<td><strong>0.24051</strong></td>
<td><strong>0.15478</strong></td>
<td><strong>0.13270</strong></td>
<td>0.20052</td>
<td>0.19462</td>
<td>0.20843</td>
<td>0.21684</td>
</tr>
</tbody>
</table>
<p>AVX2 code is <strong>faster</strong> than the dedicated instruction for input size 512 bytes and larger.</p>
</div>
<div id="core-i7-skylake">
<h2>Core i7 (Skylake)</h2>
<p>The CPU architecture: Skylake i7-6700 CPU @ 3.40GHz</p>
<p>More details in <a href="https://github.com/WojciechMula/sse-popcount/blob/master/results/skylake/skylake-i7-6700-gcc5.3.0-avx2.rst">a separate file</a>.</p>
<table>
<colgroup>
<col width="19%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
</colgroup>
<thead>
<tr><th>procedure</th>
<th>32 B</th>
<th>64 B</th>
<th>128 B</th>
<th>256 B</th>
<th>512 B</th>
<th>1024 B</th>
<th>2048 B</th>
<th>4094 B</th>
</tr>
</thead>
<tbody>
<tr><td>lookup-8</td>
<td>1.02956</td>
<td>0.94836</td>
<td>1.04671</td>
<td>0.95623</td>
<td>1.46018</td>
<td>1.42373</td>
<td>1.40633</td>
<td>1.39675</td>
</tr>
<tr><td>lookup-64</td>
<td>1.00704</td>
<td>0.94387</td>
<td>1.03233</td>
<td>0.94744</td>
<td>1.45629</td>
<td>1.42371</td>
<td>1.40747</td>
<td>1.39947</td>
</tr>
<tr><td>bit-parallel</td>
<td>1.05662</td>
<td>0.95297</td>
<td>0.90992</td>
<td>0.88908</td>
<td>1.40587</td>
<td>1.39753</td>
<td>1.39337</td>
<td>1.41585</td>
</tr>
<tr><td>bit-parallel-optimized</td>
<td>0.81278</td>
<td>0.69091</td>
<td>0.63329</td>
<td>0.60453</td>
<td>0.94443</td>
<td>0.93320</td>
<td>0.92760</td>
<td>0.95122</td>
</tr>
<tr><td>harley-seal</td>
<td>0.81283</td>
<td>0.66397</td>
<td>0.43348</td>
<td>0.34035</td>
<td>0.46871</td>
<td>0.43077</td>
<td>0.41181</td>
<td>0.41767</td>
</tr>
<tr><td>sse-bit-parallel</td>
<td>2.25432</td>
<td>1.70980</td>
<td>0.92443</td>
<td>0.57618</td>
<td>0.68189</td>
<td>0.58220</td>
<td>0.50169</td>
<td>0.45568</td>
</tr>
<tr><td>sse-lookup</td>
<td>0.40749</td>
<td>0.29802</td>
<td>0.18290</td>
<td>0.15742</td>
<td>0.23956</td>
<td>0.23057</td>
<td>0.22657</td>
<td>0.23177</td>
</tr>
<tr><td>avx2-lookup</td>
<td>0.43350</td>
<td>0.26368</td>
<td>0.17950</td>
<td><strong>0.11587</strong></td>
<td><strong>0.14881</strong></td>
<td><strong>0.13729</strong></td>
<td><strong>0.12798</strong></td>
<td><strong>0.14222</strong></td>
</tr>
<tr><td>cpu</td>
<td><strong>0.21676</strong></td>
<td><strong>0.16256</strong></td>
<td><strong>0.13546</strong></td>
<td>0.12192</td>
<td>0.18423</td>
<td>0.22065</td>
<td>0.19643</td>
<td>0.20293</td>
</tr>
</tbody>
</table>
<p>Again AVX2 code is <strong>faster</strong> than the dedicated instruction for input size 256 bytes and larger.</p>
</div>
</div>
<div id="experiments-32-bit-code-outdated">

<p><strong>Note 2016-03-13</strong>: this section refers to results from 2008.</p>
<p><a href="https://github.com/WojciechMula/sse-popcount/blob/master/original/ssse3_popcount.c">ssse3_popcount.c</a> is a test program
that contains implementations of following procedures:</p>
<ul>
<li><tt>lookup</tt>  — popcount based on LUT with 256 entries;
I tested GCC <tt>__builtin_popcount</tt>, however it was much
slower than my implementation</li>
<li><tt><span>ssse3-1</span></tt> — straightforward SSSE3 implementation</li>
<li><tt><span>ssse3-2</span></tt> — improved SSSE3 implementation</li>
<li><tt><span>ssse3-unrl</span></tt> — <tt><span>ssse3-2</span></tt> with inner loop unrolled 4 times</li>
<li><tt><span>sse2-1</span></tt> — SSE2 bit-level parallel implementation</li>
<li><tt><span>sse2-2</span></tt> — improved SSE2 implementation (using the same tricks as SSSE3 version)</li>
<li><tt><span>see2-unrl</span></tt> — <tt><span>ssee2-2</span></tt> with inner loop unrolled 4 times</li>
</ul>
<p>The first argument of the program is a function name, the second is the number of
16-byte chunks processed by the selected procedure in one iteration
and the third is the iterations number.</p>
<p>The table shows results for different chunk count; <a href="https://github.com/WojciechMula/sse-popcount/blob/master/original/ssse3_popcount-test.sh">test script</a> I've used is
available.  Program was compiled with following options:</p>
<pre>gcc -O2 -DALIGN_DATA ssse3_popcount.c -o ssse3_popcount
</pre>
<p>Tests were run on my Linux box, with Core 2 Duo E8200;</p>
<p><img alt="chart" src="http://0x80.pl/articles/img/ssse3_popcount_speedup.png"></p><p>Results clearly show, that the method presented above brings significant
speedup, which depends on the data size.</p>
<p>The straightforward SSSE3 implementation is 2-2.8 times faster, the improved
around 3 times, and the unrolled 4-5 times.</p>
<table>
<colgroup>
<col width="20%">
<col width="34%">
<col width="16%">
<col width="13%">
<col width="17%">
</colgroup>
<thead>
<tr><th>procedure</th>
<th>number of 16-byte chunks</th>
<th>iterations</th>
<th>time [s]</th>
<th>speedup</th>
</tr>
</thead>
<tbody>
<tr><td><tt>lookup</tt></td>
<td rowspan="5">1</td>
<td rowspan="5">20,000,000</td>
<td>0.22</td>
<td>100%</td>
</tr>
<tr><td><tt><span>sse2-1</span></tt></td>
<td>0.19</td>
<td>115%</td>
</tr>
<tr><td><tt><span>sse2-2</span></tt></td>
<td>0.20</td>
<td>110%</td>
</tr>
<tr><td><tt><span>ssse3-1</span></tt></td>
<td>0.14</td>
<td>157%</td>
</tr>
<tr><td><tt><span>ssse3-2</span></tt></td>
<td>0.16</td>
<td>137%</td>
</tr>
<tr><td><tt>lookup</tt></td>
<td rowspan="5">8</td>
<td rowspan="5">20,000,000</td>
<td>1.42</td>
<td>100%</td>
</tr>
<tr><td><tt><span>sse2-1</span></tt></td>
<td>0.92</td>
<td>154%</td>
</tr>
<tr><td><tt><span>sse2-2</span></tt></td>
<td>0.79</td>
<td>179%</td>
</tr>
<tr><td><tt><span>ssse3-1</span></tt></td>
<td>0.61</td>
<td>232%</td>
</tr>
<tr><td><tt><span>ssse3-2</span></tt></td>
<td>0.52</td>
<td>273%</td>
</tr>
<tr><td><tt>lookup</tt></td>
<td rowspan="7">32</td>
<td rowspan="7">2,000,000</td>
<td>0.55</td>
<td>100%</td>
</tr>
<tr><td><tt><span>sse2-1</span></tt></td>
<td>0.34</td>
<td>161%</td>
</tr>
<tr><td><tt><span>sse2-2</span></tt></td>
<td>0.30</td>
<td>183%</td>
</tr>
<tr><td><tt><span>sse2-unrl</span></tt></td>
<td>0.22</td>
<td>250%</td>
</tr>
<tr><td><tt><span>ssse3-1</span></tt></td>
<td>0.22</td>
<td>250%</td>
</tr>
<tr><td><tt><span>ssse3-2</span></tt></td>
<td>0.19</td>
<td>289%</td>
</tr>
<tr><td><tt><span>ssse3-unrl</span></tt></td>
<td>0.12</td>
<td>458%</td>
</tr>
<tr><td><tt>lookup</tt></td>
<td rowspan="7">128</td>
<td rowspan="7">200,000</td>
<td>0.21</td>
<td>100%</td>
</tr>
<tr><td><tt><span>sse2-1</span></tt></td>
<td>0.13</td>
<td>161%</td>
</tr>
<tr><td><tt><span>sse2-2</span></tt></td>
<td>0.11</td>
<td>190%</td>
</tr>
<tr><td><tt><span>sse2-unrl</span></tt></td>
<td>0.08</td>
<td>262%</td>
</tr>
<tr><td><tt><span>ssse3-1</span></tt></td>
<td>0.08</td>
<td>262%</td>
</tr>
<tr><td><tt><span>ssse3-2</span></tt></td>
<td>0.07</td>
<td>299%</td>
</tr>
<tr><td><tt><span>ssse3-unrl</span></tt></td>
<td>0.04</td>
<td>525%</td>
</tr>
<tr><td><tt>lookup</tt></td>
<td rowspan="7">512</td>
<td rowspan="7">200,000</td>
<td>0.86</td>
<td>100%</td>
</tr>
<tr><td><tt><span>sse2-1</span></tt></td>
<td>0.53</td>
<td>162%</td>
</tr>
<tr><td><tt><span>sse2-2</span></tt></td>
<td>0.45</td>
<td>191%</td>
</tr>
<tr><td><tt><span>sse2-unrl</span></tt></td>
<td>0.34</td>
<td>252%</td>
</tr>
<tr><td><tt><span>ssse3-1</span></tt></td>
<td>0.34</td>
<td>252%</td>
</tr>
<tr><td><tt><span>ssse3-2</span></tt></td>
<td>0.26</td>
<td>330%</td>
</tr>
<tr><td><tt><span>ssse3-unrl</span></tt></td>
<td>0.18</td>
<td>477%</td>
</tr>
<tr><td><tt>lookup</tt></td>
<td rowspan="7">1024</td>
<td rowspan="7">200,000</td>
<td>1.73</td>
<td>100%</td>
</tr>
<tr><td><tt><span>sse2-1</span></tt></td>
<td>1.07</td>
<td>161%</td>
</tr>
<tr><td><tt><span>sse2-2</span></tt></td>
<td>0.90</td>
<td>192%</td>
</tr>
<tr><td><tt><span>sse2-unrl</span></tt></td>
<td>0.68</td>
<td>254%</td>
</tr>
<tr><td><tt><span>ssse3-1</span></tt></td>
<td>0.69</td>
<td>250%</td>
</tr>
<tr><td><tt><span>ssse3-2</span></tt></td>
<td>0.52</td>
<td>332%</td>
</tr>
<tr><td><tt><span>ssse3-unrl</span></tt></td>
<td>0.38</td>
<td>455%</td>
</tr>
<tr><td><tt>lookup</tt></td>
<td rowspan="7">2048</td>
<td rowspan="7">200,000</td>
<td>3.47</td>
<td>100%</td>
</tr>
<tr><td><tt><span>sse2-1</span></tt></td>
<td>2.14</td>
<td>162%</td>
</tr>
<tr><td><tt><span>sse2-2</span></tt></td>
<td>1.80</td>
<td>192%</td>
</tr>
<tr><td><tt><span>sse2-unrl</span></tt></td>
<td>1.37</td>
<td>253%</td>
</tr>
<tr><td><tt><span>ssse3-1</span></tt></td>
<td>1.38</td>
<td>251%</td>
</tr>
<tr><td><tt><span>ssse3-2</span></tt></td>
<td>1.06</td>
<td>327%</td>
</tr>
<tr><td><tt><span>ssse3-unrl</span></tt></td>
<td>0.76</td>
<td>456%</td>
</tr>
</tbody>
</table>
</div>
<div id="acknowledgments">

<p><a href="http://lemire.me/">Daniel Lemire</a> has gave me access to computers with
Haswell and Skylake processors, thanks to that I could play with AVX2 code
and run tests. <a href="https://github.com/kimwalisch">Kim Walisch</a> contributed
the Harley-Seal implementation. There were some fixes and enhancements
to sample code by <a href="https://github.com/WojciechMula/sse-popcount/graphs/contributors">various people</a>. Thank you.</p>
</div>
<div id="see-also-update">

<ul>
<li><p><a href="http://0x80.pl/articles/xop-popcnt.html">Population count using XOP instructions</a></p>
</li>
<li><p>Paper by Daniel Lemire, Nathan Kurz and me: <a href="https://arxiv.org/abs/1611.07612">Faster Population Counts using AVX2 Instructions</a>.</p>
</li>
<li><p><a href="https://news.ycombinator.com/item?id=11277891">Hacker news discussion</a>.</p>
</li>
<li><p><a href="http://0x80.pl/articles/faster-popcount-for-large-data.html">Speeding up bit-parallel population count</a> — delaying byte-wise
sum (the trick with <tt>PSADBW</tt>) applied for bit parallel method gives
50% speedup over plain, <a href="http://en.wikipedia.org/wiki/SWAR">SWAR</a> 64-bit procedure.</p>
</li>
<li><p><a href="http://www.cs.stanford.edu/people/ihaque/#publications">Anatomy of High-Performance 2D Similarity Calculations</a> — paper contains
interesting comparison of similarity calculations which heavily use popcount
operation. The authors compared 4 basic methods: 1) hardware-based, i.e.
<tt>popcnt</tt> instruction, 2) simple LUT, 3) bit-level parallel method (SSE2
procedure), and 4) the method described here. The most important observation,
from my point of view of course, is that the speed of SSSE3 code is
<strong>comparable</strong> to hardware <tt>popcnt</tt>, it is just a bit
slower.</p>
<p>The authors published also the full source code and I noticed they manually
unrolled inner loop. I did the same in my code and speedup increased
from 3 to …</p></li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://0x80.pl/articles/sse-popcount.html">http://0x80.pl/articles/sse-popcount.html</a></em></p>]]>
            </description>
            <link>http://0x80.pl/articles/sse-popcount.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23832953</guid>
            <pubDate>Tue, 14 Jul 2020 15:20:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PS Now Is Holding Your Save Files Hostage: Now What?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23832739">thread link</a>) | @kiraleighleigh
<br/>
July 14, 2020 | https://weebtrash.ga/2020/07/14/ps-now-is-holding-your-save-files-hostage-now-what/ | <a href="https://web.archive.org/web/*/https://weebtrash.ga/2020/07/14/ps-now-is-holding-your-save-files-hostage-now-what/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
	<div>
		<!-- Start Article -->
				<article>		
						<div id="post-1082">
				<div>
					<!-- Start Content -->
					<div id="content">
					<header>
						<!-- Start Title -->
						
						<!-- End Title -->
						<p>Posted On July 14, 2020</p>

					</header>

						
<h3>Playstation’s Streaming Service Woes Are Indicative Of A Greater Problem</h3>



<p>There are a lot of things in life that don’t make sense to me. <a rel="noreferrer noopener" href="https://medium.com/there-is-no-design/if-youre-mad-about-ok-boomer-you-re-part-of-the-problem-a571b5b85d68" target="_blank">Ok boomer’s hysteria</a>, for one thing. <a rel="noreferrer noopener" href="https://medium.com/the-bad-influence/feminism-got-you-mad-this-theory-explains-why-afd5f5fc0937" target="_blank">Grown-ass adults failing at logic</a>, another. Even the <a rel="noreferrer noopener" href="https://medium.com/the-bad-influence/ignorance-about-vaping-is-killing-people-ffbaa95d3d47" target="_blank">vaping ban</a> of yore boggles the mind.</p>



<p>It seems like life is an exercise in asking:<strong><em> excuse me, wtf?</em></strong></p>



<p>But what possibly confuses me more—because humans are by nature consistently disappointing—is when <strong><em>businesses engage in practices that are anti-customer and think this makes a lick of sense.</em></strong></p>



<h3>One such business being Sony Playstation</h3>



<h4>Specifically Playstation Now, Sony’s streaming service</h4>



<div><figure><img data-attachment-id="1088" data-permalink="https://weebtrash.ga/2020/07/14/ps-now-is-holding-your-save-files-hostage-now-what/gi4qmjppjde21/" data-orig-file="https://i2.wp.com/weebtrash.ga/wp-content/uploads/2020/07/gi4qmjppjde21.jpg?fit=480%2C360&amp;ssl=1" data-orig-size="480,360" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="gi4qmjppjde21" data-image-description="" data-medium-file="https://i2.wp.com/weebtrash.ga/wp-content/uploads/2020/07/gi4qmjppjde21.jpg?fit=300%2C225&amp;ssl=1" data-large-file="https://i2.wp.com/weebtrash.ga/wp-content/uploads/2020/07/gi4qmjppjde21.jpg?fit=480%2C360&amp;ssl=1" src="https://i2.wp.com/weebtrash.ga/wp-content/uploads/2020/07/gi4qmjppjde21.jpg?w=678&amp;ssl=1" alt="" srcset="https://i2.wp.com/weebtrash.ga/wp-content/uploads/2020/07/gi4qmjppjde21.jpg?w=480&amp;ssl=1 480w, https://i2.wp.com/weebtrash.ga/wp-content/uploads/2020/07/gi4qmjppjde21.jpg?resize=300%2C225&amp;ssl=1 300w" sizes="(max-width: 480px) 100vw, 480px" data-recalc-dims="1"></figure></div>



<p>In theory, <a rel="noreferrer noopener" href="https://www.playstation.com/en-us/explore/playstation-now/" target="_blank">Playstation Now</a> is a cash-strapped gamer’s perfect solution: Pay $9.99 a month and get lightning-fast streaming access to 800+ titles on tons of different digital devices.&nbsp;In fact, Sony’s streaming service is doing very well indeed. PS Now has received a huge boost during these crayola times, <a rel="noreferrer noopener" href="https://www.pushsquare.com/news/2020/05/playstation_now_records_highest_subscriber_count_ever_at_2_2_million" target="_blank">boasting 2.2 million subscribers</a>.</p>



<p>PS Now also offers many PS3 titles, which is rad because even if you’ve missed a gem, you get the opportunity to play it anyways.</p>



<figure><img src="https://i2.wp.com/cdn-images-1.medium.com/max/800/1*Mwn-UiFR0UEFC_edX7V4Rw.jpeg?w=678&amp;ssl=1" alt="" data-recalc-dims="1"></figure>



<p>But what PS Now <strong><em>doesn’t</em></strong> offer is out-of-the-box support for rescuing your save files if you want to <strong><em>actually</em></strong> purchase the games you’ve lowkey rented.</p>



<p><em>(Sorry Shallie &amp; Shallie, I can never truly take you with me.)</em></p>



<p>For that, you need <a href="https://www.playstation.com/en-us/explore/playstation-plus/" rel="noreferrer noopener" target="_blank">PS Plus</a>.</p>



<h3>PS Now isn’t $9.99 if you want to actually own the games you lowkey ‘rent’</h3>



<h4>It’s $20, because for gamers who like owning things, PS Plus is non-negotiable</h4>



<figure><img src="https://i1.wp.com/cdn-images-1.medium.com/max/800/1*Av4wXbN3l96-4KImiVbPGQ.jpeg?w=678&amp;ssl=1" alt="" data-recalc-dims="1"></figure>



<p>Say you’ve played a PS Now title and you enjoyed it. You want to purchase it and don’t want to lose your progress. You now have to rescue your save files from PS Now, instead of migrating them out-of-the-box like one would expect.</p>



<p>In order to liberate your saves, you need to get a subscription for PS Plus. This bumps the price from $9.99 to $20.&nbsp;That cost is fine, or it would be.</p>



<p><a rel="noreferrer noopener" href="https://support.playstation.com/s/article/How-to-Transfer-Game-Progress-between-PlayStation-Now-and-Your-PS4" target="_blank">But that’s not the end of it.</a>&nbsp;There exists a preposterous UX-nightmare dance you must engage with, and it only sometimes works, which I’ll get to shortly.</p>



<p>You start off by opening the game in the streaming service. You need an active PS Now subscription, as well as PS Plus; there is no rescue otherwise.&nbsp;</p>



<p>Then you press the PS button in the center of your controller and pray it gives you the option to migrate your save files.</p>



<p>Thirdly, you must upload everything to “””””””the cloud”””””””.</p>



<p>Then, you have to whole-ass exit PS Now.</p>



<p>Then, you have to go <em>all the way to the settings</em> on your PS4 console to download what you uploaded. Depending on what you’re trying to do, saving it to a USB stick might be the best option.&nbsp;</p>



<p>It’s not <em>very</em> complicated, but it is a lot of needless menu navigation. </p>



<p><em>(Let’s get a </em><a rel="noreferrer noopener" href="https://www.thereisno.design/" target="_blank"><em>UX professional</em></a><em> who is sensitive to gamers on this, please.)</em></p>



<div><figure><img src="https://i0.wp.com/cdn-images-1.medium.com/max/800/1*fBprjzW9iFTIN9GJ2V6qpw.png?w=678&amp;ssl=1" alt="" data-recalc-dims="1"></figure></div>



<p>With this process, I managed to salvage my <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Rogue_Galaxy" target="_blank">Rogue Galaxy save files</a>; one of my favorite somewhat-obscure PS2 titles.&nbsp;</p>



<p>I was very satisfied with this outcome…</p>



<p>Until it came time to scoop up the often maligned, but honestly awesome, <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Tales_of_Zestiria" target="_blank">Tales of Zestiria</a>. Sadly, the PS Now Streaming Service’s version of Zesty is<strong><em> PS3-specific</em></strong>. Hmm…</p>



<p>You may be formulating a question in your mind right now, maybe equipped with a tad bit of panic:</p>



<h3>Can you transfer PS3 PS Now saves to the PS Plus&nbsp;Cloud?</h3>



<h4>Well yes, but actually&nbsp;no…</h4>



<div><figure><img src="https://i1.wp.com/cdn-images-1.medium.com/max/800/1*9H8fybBvuDMnZdDG-XmatA.gif?w=678&amp;ssl=1" alt="" data-recalc-dims="1"></figure></div>



<p>The option to rescue Zesty never showed up. Because of this, I spent 40 minutes on the phone with Sony Playstation’s customer service seeking a solution. Apparently, you were <strong><em>once</em></strong> able to log into PS Now on PS3 and rescue your save files. Apparently, this is <strong>now impossible</strong>.</p>



<p>After talking to the rep, he gave me the truth about rescuing PS3-specific save files from PS Now:</p>



<p><strong>Because Playstation is ‘looking forward, not back’, you cannot rescue PS3 saves from PS Now at this current moment in&nbsp;time.</strong></p>



<p>That renders PS Now’s exhaustive PS3 game catalog moot to the saving function of PS&nbsp;Plus. Not only is this frustrating, but it’s also indicative of Sony’s sentiments towards backwards compatibility, which I’ll get to shortly.</p>



<p>According to the rep, PS3 titles run off an entirely different server than PS1/PS2/PS4 titles.</p>



<p>PS3 saves won’t work on PS4 because you get PS3-specific trophies, can download PS3 DLCs, and the PS4 just doesn’t know how to deal with this.</p>



<p>PS1/PS2 has none of that baggage, so those saves are safe.</p>



<p>He mentioned that, because the PS Now Streaming Service was relaunched/revamped, we may very well find that PS3 save-file-liberation will be available again in the future.</p>



<p>But as far as I’m concerned, and the rep lowkey agreed, Sony Playstation just doesn’t care about its PS3 catalog very much. In fact, it doesn’t seem to care very much about its legacy catalog at all.</p>



<p>Looking forward—not back—brings me to one conclusion:</p>



<h2>Backwards compatibility is not a Sony priority, even if gamers keep requesting it</h2>



<figure><img src="https://i2.wp.com/cdn-images-1.medium.com/max/800/1*ZmruYJGxAkdQVYU_fpOxzg.jpeg?w=678&amp;ssl=1" alt="" data-recalc-dims="1"></figure>



<p>HD remasters may be the compromise Sony proposes for older titles, but that solution seems at odds with a constant request: gamers want backwards compatibility. PS Now’s PS3 save-file issue is just another symptom of this reluctance to be fully pro-consumer.</p>



<p>More than that, <a rel="noreferrer noopener" href="https://www.goliath.com/gaming/sony-explains-why-the-playstation-4-isnt-backwards-compatible/" target="_blank">they appear to think gamers</a> don’t want this feature:</p>



<blockquote><p>As Sony global sales chief Jim Ryan tells<a rel="noreferrer noopener" href="https://time.com/4804768/playstation-4-ps4-pro-psvr-sales/" target="_blank">&nbsp;TIME</a>, backwards compatibility is something the company has taken some steps to address with things like HD remasters of select PlayStation 2 titles, but it just isn’t something that gamers ultimately use that much, even if they claim it’s something they want. “When we’ve dabbled with backwards compatibility, I can say it is one of those features that is much requested, but not actually used much,” said Ryan. “That, and I was at a&nbsp;<em>Gran Turismo</em>&nbsp;event recently where they had PS1, PS2, PS3, and PS4 games, and the PS1 and the PS2 games, they looked ancient, like why would anybody play this?”</p></blockquote>



<p>It’s puzzling how Ryan—global sales chief of Sony—can claim gamers don’t ultimately use pure backwards compatibility, when Sony has never truly offered it aside from PS1/PS2 consoles.</p>



<p>Furthermore, if the growing catalog of PS1/2/3 titles in PS Now’s roster is any indication of what gamers are into (I’d assume this inclusion was spurred by sales/use data), it stands to reason it’s very much desired.</p>



<p>Lastly, if Ryan thinks outdated graphics impede enjoyment for gamers, I’m unsure if he’s in touch with the average gamer’s age, <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Video_games_in_the_United_States" target="_blank">which is 35</a>, and consequentially people who grew up comfortable with crunchy graphics.</p>



<p>What he seems to suggest is new gamers are the key demographic, ones who are most likely into eSports and fresh titles. Forwards, not backwards.</p>



<p>This leaves loyal, life-long fans of the console in the dust.</p>



<p><em>(I’ll redact this article if </em><a rel="noreferrer noopener" href="https://www.notebookcheck.net/PS5-backwards-compatibility-Likely-PS-Now-patent-invigorates-debate-on-whether-Cerny-s-PlayStation-5-BC-graphic-was-deliberately-incomplete.480817.0.html" target="_blank"><em>Sony manages to surprise me</em></a><em>, but until then, no.)</em></p>



<h3>I’m sure that Sony has other priorities right now, like the&nbsp;PS5</h3>



<h4>But this specific priority, that gamers want, has really has never felt like a priority, at&nbsp;all</h4>



<div><figure><img src="https://i1.wp.com/cdn-images-1.medium.com/max/800/1*JNJbbWlTwYdUjZWioeJfbg.jpeg?w=678&amp;ssl=1" alt="" data-recalc-dims="1"></figure></div>



<p>Imagine if you bought a digital copy of a TV show you’ve binged halfway through, and Amazon Prime Video updated its app, thus rendering your copy inaccessible. That’s very anti-consumer, isn’t it? Yet Sony doesn’t really seem to mind the likesome roadblock between PS3 and PS4.</p>



<p>With streaming service ubiquity for both software and media, I can’t help but feel like customers are getting shafted out of actually owning the things they buy. This, my friends, is anti-consumer.</p>



<p>To counter that narrative, the <a rel="noreferrer noopener" href="https://www.nintendo.com/switch/" target="_blank">Nintendo Switch</a> is now offering various titles that would have been lost to time immemorial.&nbsp;You purchase them, and they are your’s.</p>



<p>Nintendo is rescuing older titles like the <a href="https://www.gamespot.com/articles/the-legend-of-heroes-trails-of-cold-steel-3-is-com/1100-6471839/" rel="noreferrer noopener" target="_blank">Trails series</a>. It’s offering a way to play these older games, all on one system.</p>



<figure><img src="https://i1.wp.com/cdn-images-1.medium.com/max/800/1*tOx-TvAW0YhhzORTjsmp0A.jpeg?w=678&amp;ssl=1" alt="" data-recalc-dims="1"></figure>



<p>Decidedly, Nintendo wants to support gamers who lament the loss of older titles. They perhaps also want to get new fans of beloved older IPs into the fold. That shows a level of care I don’t see Sony possessing.</p>



<p>There are so many wonderful games people have missed out on. Either due to time, lagging releases in their country, or otherwise. </p>



<p>Having that option is very pro-consumer, and if I’ve learned anything in my marketing career, it’s that this is the only way to truly <a rel="noreferrer noopener" href="https://medium.com/there-is-no-design/marketers-weve-got-to-reconfigure-87c47a7499ab" target="_blank">do business</a>.</p>



<p>Because ranting about this could easily take up another 6,000 words, I leave you with one final sentiment.</p>



<p>Something I think Sony would do well to remember:</p>



<h3>Being pro-consumer is being a pro-business. </h3>



<h4>Consider giving your long-time, loyal fans what they&nbsp;want. It makes money-sense and gives us just one more reason to stan.</h4>
<p>Hits: 566</p>
																		<!-- Start Tags -->
						
						<!-- End Tags -->
											</div><!-- End Content -->
					  
								  
								
<!-- You can start editing here. -->
			
							</div>
						</div>
									</article>
				<!-- End Article -->
				<!-- Start Sidebar -->
				
				<!-- End Sidebar -->
			</div>
		</div></div>]]>
            </description>
            <link>https://weebtrash.ga/2020/07/14/ps-now-is-holding-your-save-files-hostage-now-what/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23832739</guid>
            <pubDate>Tue, 14 Jul 2020 15:01:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How major and minor device numbers worked in V7 Unix]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23832722">thread link</a>) | @beefhash
<br/>
July 14, 2020 | https://utcc.utoronto.ca/~cks/space/blog/unix/V7DeviceNumbersHow | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/unix/V7DeviceNumbersHow">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>How major and minor device numbers worked in V7 Unix</h2>

	<p><small>July 13, 2020</small></p>
</div><div><p>Unix people who've been around for a while know that Unix devices
have <em>device numbers</em>, and that device numbers are divided into
<em>major</em> and <em>minor</em> device numbers. When you do '<code>ls -l /dev/null</code>'
and one of the fields that <code>ls</code> prints is two comma separated
numbers, those are the major and minor numbers (on Linux, they are
'1, 3'; this varies by Unix). Device numbers and their split into
major and minor parts go back a long way, to before Research Unix
V7, but V7 makes a convenient point to look at what they meant and
how they worked in the original Unixes.</p>

<p>As various sources will tell you, the major number tells you (and
the Unix kernel) what sort of device it is and thus what device
driver to use to talk to it, while the minor number tells the device
driver what specific bit of hardware it's responsible for that you
want to talk to.  Sometimes the minor number also determines some
bit of functionality. Because V7 was a deliberately simple and
brute force system and kernel, major device numbers had a very
simple implementation. We can see it in <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/conf/c.c">the generated V7 kernel
configuration file <code>c.c</code></a>:</p>


<pre> struct bdevsw bdevsw[] =
 {
   nulldev, nulldev, rkstrategy, &amp;rktab, /* rk = 0 */
   nodev, nodev, nodev, 0, /* rp = 1 */
   [...]
   nodev, nodev, nodev, 0, /* hp = 6 */
   htopen, htclose, htstrategy, &amp;httab, /* ht = 7 */
   nodev, nodev, nodev, 0, /* rl = 8 */
   0
 };
</pre>

<p>What we're seeing here is that V7 literally had an array of <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/h/conf.h"><code>bdevsw</code>
structures</a> indexed
by the major (block) device number, with various function that were
called when you did things like open a device (in <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/sys/fio.c"><code>fio.c</code></a>).
There was a similar array for character devices, the <code>cdevsw</code> array.
In both of them, what driver functions were listed here instead of
stubbed out were determined by simple configuration files (<a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/conf">here</a>)
that said what devices you had (among other things).</p>

<p>(The <code>c.c</code> file was generated by <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/conf/mkconf.c">a program</a>.
The particular <code>c.c</code> file in the TUHS V7 tree was built with only
two block devices configured, the <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/rk.c">RK disk driver</a> and
<a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/ht.c">TJU16 tape driver 'ht'</a>.)</p>

<p>In V7 the minor device number was only interpreted by the device
driver, as far as I can see. Device drivers used this for a variety
of purposes. For instance, <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/mem.c">the <code>mem</code> character driver</a>
implemented <code>/dev/null</code> as minor device 2, to go along with access
to physical memory and kernel memory. The <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/rl.c"><code>rl</code> disk driver</a> used
the minor device number to decide what physical disk it was talking
to (it supported up to four of them). Once V7 started getting out
in the world, other people wrote drivers for it (such as <a href="http://clara.comm.sfu.ca/pups/PDP-11/Trees/V7/usr/sys/dev/rx2.c">the RX02
floppy disk driver</a>) that
used minor device numbers both to select what to talk to and control
what features to use.</p>

<p>(There's also <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/kl.c">the <code>kl</code> KL/DL-11 serial and console driver</a>, which
seems to deal with three different sets of hardware control registers
based on the minor number.)</p>

<p>The <code>/dev/tty</code> character device was implemented in a clever and
very short way in <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/sys.c"><code>sys.c</code></a>. In
V7, there were no pseudo-ttys and no hot-plugged devices, so your
underlying physical terminal device always existed and was recorded
in your <code>u</code> area (see <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/h/user.h"><code>user.h</code></a>) The
general tty driver simply used this recorded device number of your
controlling tty to call its open, read, write, and ioctl functions
through the <code>cdevsw</code> array. As far as I can tell, this driver paid
no attention at all to the minor device number; as long as <code>/dev/tty</code>
had major number 7, the minor number was irrelevant.</p>

<p>PS: Note that V7 device drivers tended to be a little relaxed about
error checking for their minor device numbers (and other things).
For instance, as far as I can tell the <code>mem</code> driver actually only
distinguishes between minor number 2, minor number 1, and 'everything
else', which is treated as minor number 0, giving access to physical
memory.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/unix/V7DeviceNumbersHow</link>
            <guid isPermaLink="false">hacker-news-small-sites-23832722</guid>
            <pubDate>Tue, 14 Jul 2020 14:59:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Low-Code for Coders]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23832708">thread link</a>) | @thmslee
<br/>
July 14, 2020 | https://visionx.sibvisions.com/low-code-coders/ | <a href="https://web.archive.org/web/*/https://visionx.sibvisions.com/low-code-coders/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="26820" itemscope="" itemtype="http://schema.org/Article"><div><div itemprop="publisher" itemscope="" itemtype="https://schema.org/Organization"><div itemprop="logo" itemscope="" itemtype="https://schema.org/ImageObject">
<p><img src="data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTc1IDM1IiB3aWR0aD0iMTc1IiBoZWlnaHQ9IjM1IiBkYXRhLXU9Imh0dHBzJTNBJTJGJTJGdmlzaW9ueC5zaWJ2aXNpb25zLmNvbSUyRndwLWNvbnRlbnQlMkZ1cGxvYWRzJTJGMjAxNiUyRjAxJTJGdmlzaW9ueF9sb3djb2RlX2JsYWNrLnBuZyIgZGF0YS13PSIxNzUiIGRhdGEtaD0iMzUiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+PC9zdmc+" data-spai="1" alt=""></p><meta itemprop="url" content="https://visionx.sibvisions.com/wp-content/uploads/2016/01/visionx_lowcode_black.png"><meta itemprop="width" content="175"><meta itemprop="height" content=""></div><meta itemprop="name" content="Low Code Development Platform for Enterprises | VisionX"></div><meta itemscope="" itemprop="mainEntityOfPage" itemtype="https://schema.org/WebPage" itemid="https://visionx.sibvisions.com/low-code-coders/"><p>Low-code for coders</p><meta itemprop="datePublished" content="2020-07-14 1:50:48"><meta itemprop="dateModified" content="2020-07-15 9:55:20"></div><header></header><section><div itemprop="articleBody"><div><figure itemscope=""><img width="1470" height="980" src="data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTQ3MCA5ODAiIHdpZHRoPSIxNDcwIiBoZWlnaHQ9Ijk4MCIgZGF0YS11PSJodHRwcyUzQSUyRiUyRnZpc2lvbnguc2lidmlzaW9ucy5jb20lMkZ3cC1jb250ZW50JTJGdXBsb2FkcyUyRjIwMjAlMkYwNyUyRkxvdy1Db2RlLUNvZGVycy5wbmciIGRhdGEtdz0iMTQ3MCIgZGF0YS1oPSI5ODAiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+PC9zdmc+" data-spai="1" alt="Low-Code for Coders" sizes="(max-width: 1470px) 100vw, 1470px"></figure></div><div><p><img alt="" src="https://secure.gravatar.com/avatar/e6c04f4433d5af7c32a9447bff92d130?s=140&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/e6c04f4433d5af7c32a9447bff92d130?s=280&amp;d=mm&amp;r=g 2x" height="140" width="140"></p></div><h2>Low-code for coders</h2><p>Oxymoron? I think not. Let me explain.</p><p>Software developers tend to be very skeptical about low-code tools. Every time a new low-code or no-code platform comes out, its founders announce with big fanfare that they have created a panacea for the developer shortage, and that writing code is no longer required. CEOs and CFOs get excited because they think they found a way to cut cost, CTOs and developers get frustrated because, yet again, they have to explain why the new tool won’t solve all of their software development problems and why “real” programmers will still be required.</p><p>It is a battle that has been raging since the days of Apple’s HyperCard. Software engineers generally do not like these tools, and can be very passionate in their defense of manually writing code. Just take a look around the developer forums – anytime a new low-code tool is introduced, there is a pretty good chance it will get shredded, if it gets attention at all. There are a number of reasons for that, and being coders ourselves, we certainly don’t disagree with them:</p><p><strong>1. Restrictions</strong> – this is the most obvious point. Even when a low-code tool claims to give developers all the flexibility they need, there will still be a trade-off associated with visual design that needs to be considered. Coders often have their own way of doing things, and they balk when their creativity is restricted.</p><p><strong>2. Writing code is the easy part.</strong> What really takes time is figuring out what the client wants, accurately specifying the problem, and defining a solution that not only works from the user’s perspective, but also fits into the company’s IT infrastructure. Faster coding does not help with any of these.</p><p><strong>3. Security and other issues.</strong> This one is obvious to software engineers, but is often more difficult to explain to business units. We don’t want a bunch of apps floating around in an uncontrolled way. Security is a concern, as are performance, scalability, reliability, compatibility quality, and maintainability. And of course, we want to avoid vendor lock-in.</p><h2><strong>The real benefit for developers</strong></h2><p>Given these concerns, it is no surprise that developers often strongly resist the introduction of low-code platforms. The preference for the status quo can lead to internal battles between IT and upper management. But this conflict misses the point: for developers, the real benefit of low-code is not only its ability to speed up writing a few lines of code, but the improved cooperation with business units. Involving users in the development process has a number of benefits:</p><p><strong>1. They actually get what they want.</strong> If the person who uses the application is involved in the development process in a meaningful way, the final result is more likely to be the product they actually need.</p><p><strong>2. Buy-in.</strong> Just like we as developers don’t like to be told how to write code, business users can get frustrated when they are forced to use tools that don’t work for their processes. Having them involved in the development will result in much better acceptance of the final product.</p><p><strong>3. Better communication.</strong> Business users often have difficulty explaining what they need in terms that are useful to a developer. Allowing them to build their own prototypes means they will better understand the process and will begin to communicate better when it comes to feature requests und updates. They might even hold off on asking for features they don’t really need.</p><h2><strong>Get the users involved</strong></h2><p>Here is the thing – they’re already doing it anyway. We know shadow IT is out there. Some users, especially engineers and accountants, can be extremely resourceful when it comes to clever ways of using excel and other software to further their cause. That’s all fine to a point, but we know about the amount of data that is lost by the lack of coordination with IT. Not to mention the security issues.</p><p>On the other hand, harnessing all of that creativity can 5-10x our development capacity, improve relationships with business units, and make sure that data is kept in the right place.</p><h2><strong>Facilitating the interaction</strong></h2><p>With that in mind, we should think of low-code tools less as “development accelerators”, but more as facilitators of communication with users.</p><p>But how do we really make that cooperation happen? There still is that trade-off between the speed and simplicity of a visual designer, and the flexibility of manual code. Most low-code/no-code tools are on the former end of the spectrum, focusing on simplicity, and will therefore remain in the “only works for basic applications that are needed quickly” category. For the interaction between IT and business to work, we need a platform that is easy enough for users to understand, but offers sufficient flexibility to avoid restrictions on development.</p><p>There are a few other factors that need to be considered:</p><ol><li>The interaction has to go both ways. A standard code generator is not enough if it cannot translate changes to the code back to the visual designer. Otherwise the interaction stops the first time the code is manually adjusted.</li><li>The generated code has to be of sufficient quality. Developers often complain about the garbage code that is created by code generators, so the bar here is set pretty high.</li></ol><p>Meeting all of these requirements is a tall order. Our next post will explain how we address them.</p><div><div><div><p><img alt="" src="https://secure.gravatar.com/avatar/e6c04f4433d5af7c32a9447bff92d130?s=140&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/e6c04f4433d5af7c32a9447bff92d130?s=280&amp;d=mm&amp;r=g 2x" height="140" width="140"></p><div><p itemprop="author" itemscope="" itemtype="http://schema.org/Person"><h3>About <span itemprop="name">Roland Hörmann</span></h3></p><p>
Roland Hörmann is founder and CEO of SIB Visions GmbH and lecturer at the FH Technikum Wien. He has many years of experience in the development of enterprise solutions. His focus of interest is on efficient software development and framework development in the field of classic business applications. He is a regular speaker at Oracle User Group events (DOAG, AOUG), Java User Groups events, and W-JAX.</p>
<p><a href="https://visionx.sibvisions.com/author/roland/">More by Roland Hörmann</a></p></div></div></div></div></div></section></article></div>]]>
            </description>
            <link>https://visionx.sibvisions.com/low-code-coders/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23832708</guid>
            <pubDate>Tue, 14 Jul 2020 14:58:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UK bans Huawei from 5G networks, with total removal by 2027]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23832698">thread link</a>) | @suleaty
<br/>
July 14, 2020 | https://newsworthy.to/article/2020/07/14/uk-bans-huawei-from-5g-networks-with-total-removal-by-2027 | <a href="https://web.archive.org/web/*/https://newsworthy.to/article/2020/07/14/uk-bans-huawei-from-5g-networks-with-total-removal-by-2027">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article><p><time datetime="2020-07-14T11:46:39">July 14, 2020</time> by <a href="https://www.theverge.com/2020/7/14/21322880/uk-bans-huawei-5g-network-infrastructure-trump-administration-pressure">The Verge</a> | <a href="https://newsworthy.to/category/opinion">Opinion</a></p><p>After allowing it a limited role in January</p><p>Huawei’s networking equipment is to be phased out of the UK’s 5G networks, the <a href="https://www.gov.uk/government/news/huawei-to-be-removed-from-uk-5g-networks-by-2027">government announced today</a>. Telecoms operators will not be allowed to buy new 5G telecoms equipment from the Chinese firm from January next year, and they will have seven years to remove its existing technology from their 5G infrastructure at an expected cost of £2 billion. The announcement follows a new report about Huawei’s role in the UK’s national infrastructure from the UK’s National Cyber Security Centre.</p><p>The decision marks a U-turn from the government’s previous position, <a href="https://www.theverge.com/2020/1/28/21083762/huawei-5g-network-infrastructure-uk-national-security">announced in January</a>, which allowed Huawei’s equipment to be used in the country’s 5G infrastructure, with certain limitations. Under that position, Huawei would be limited to a 35 percent market share, and its equipment couldn’t be used in core parts of the network or geographically sensitive locations. Now, however, its equipment will be completely removed from the country’s 5G networks. </p><p>The UK’s Digital, Culture, Media, and Sport Secretary Oliver Dowden warned that the decision “will delay our rollout of 5G.” As part of the announcement, the government said that it is also advising full fiber broadband operators to transition away from buying Huawei’s equipment.</p><p>In recent months, the British government has seen mounting pressure, both domestically and internationally, to phase out the use of Huawei’s equipment entirely. That pressure has been driven by concern from security experts that <a href="https://www.theverge.com/2019/3/17/18264283/huawei-security-threat-experts-china-spying-5g">Huawei’s equipment poses a national security risk</a> by allowing Beijing to spy on Western countries. Huawei has <a href="https://www.bbc.co.uk/news/business-47279262">strenuously denied these allegations</a>.</p><p>International pressure has mainly come from the US. Huawei has been on the country’s “entity list” since <a href="https://www.theverge.com/2019/5/15/18216988/white-house-huawei-china-equipment-ban-trump-executive-order">May 2019</a>, meaning US companies cannot sell technology to the company. However, in May this year, <a href="https://www.nytimes.com/2020/05/15/business/economy/commerce-department-huawei.html"><em>The New York Times</em> reported</a> the US toughened its stance with the announcement of new sanctions against Huawei. Under the new measures, which are due to go into effect in September, Huawei and its suppliers, like chip manufacturer TSMC, cannot use American tech to design or produce Huawei’s products. At the time, US officials characterized the move as “closing a loophole” through which Huawei could effectively have previously used American technology.</p><p>These new measures could have a big impact on the products Huawei is able to produce, which critics argue could make its equipment less safe to use. The restrictions “will force the company to use untrusted technology that could increase the risk to the UK,” according to a <a href="https://www.theverge.com/2020/7/6/21314340/huawei-5g-networks-security-risk-us-uk">security report that leaked earlier this month</a>.</p><p>For example, Huawei’s own HiSilicon chipsets could be impacted by the measures. <a href="https://www.bbc.co.uk/news/technology-53179963"><em>BBC News</em> reports</a> that the semiconductor industry relies on electronic design automation (EDA) software to automate the process of designing modern chips like Huawei’s Kirin 990 5G processor. However, the sanctions mean that this software can no longer be used in the design or production of Huawei’s chips since the major EDA developers have ties to the US. It makes it difficult for Huawei to produce its own modern top-of-the-line processors, <a href="https://www.bbc.co.uk/news/technology-53341080">according to <em>BBC News</em></a><em>, </em>pushing it towards third-party chips that, it’s argued, could be harder for UK cybersecurity officials to vet.</p><p>Meanwhile, UK Prime Minister Boris Johnson is also facing pressure from inside his own party. The government suffered the biggest defeat of its current term back in March, when <a href="https://www.bbc.co.uk/news/uk-politics-51806704"><em>BBC News</em> reports</a> 38 Conservative MPs voted against the government in favor of an amendment calling for an end to the use of Huawei equipment in the country’s 5G networks by 2023. Increasing numbers of Conservative MPs claim that the equipment poses a national security risk, potentially allowing Beijing to spy on the UK, <a href="https://www.ft.com/content/e4b7f816-00cc-4dc5-bb97-4e761200022a">according to the<em> Financial Times</em></a>. Although the government won the vote, the incident put pressure on Johnson to take a tougher stance.</p><p>Responding to the news, a spokesperson from Huawei called the decision “disappointing” and said that the company is “confident” the new US sanctions wouldn’t affect “the resilience or security of the products we supply to the UK.” It claimed that they were driven by US trade policy rather than security and urged the British government to reconsider its decision.</p><p>News of a possible ban has proved unpopular with telecom firms, many of which have already started using Huawei’s equipment to <a href="https://www.theguardian.com/technology/2019/jul/06/huawei-uk-mobile-5g-networks-operators-gamble-security-concerns">build out their 5G networks</a>. In comments <a href="https://www.theguardian.com/technology/2020/jul/13/bt-boss-warns-of-outages-and-security-risks-if-uk-ditches-huawei">later published in <em>The Guardian</em></a>, BT chief executive Philip Jansen told BBC Radio 4’s Today program that it would be “impossible” to remove Huawei entirely from the country’s telecoms infrastructure in the next decade and that it would take five to seven years to remove it from the 5G network. Jansen warned that forcing the removal of Huawei’s equipment too quickly could create outages and security risks of its own.</p><p><em><strong>Update July 14th, 8:13AM ET:</strong></em><em> Updated with response from Huawei and more details from government press release. </em></p></article></div></div></div>]]>
            </description>
            <link>https://newsworthy.to/article/2020/07/14/uk-bans-huawei-from-5g-networks-with-total-removal-by-2027</link>
            <guid isPermaLink="false">hacker-news-small-sites-23832698</guid>
            <pubDate>Tue, 14 Jul 2020 14:58:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Supabase Launch Postmortem]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23832692">thread link</a>) | @kiwicopple
<br/>
July 14, 2020 | https://supabase.io/blog/2020/07/10/alpha-launch-postmortem | <a href="https://web.archive.org/web/*/https://supabase.io/blog/2020/07/10/alpha-launch-postmortem">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>On May 27 Supabase hit the <a href="https://news.ycombinator.com/item?id=23319901" target="_blank" rel="noopener noreferrer">top of Hacker News</a> and stayed on the front page for more than 24 hours. </p><p>Since then, Supabase has been featured on the <a href="https://stackoverflow.blog/2020/06/05/podcast-241-new-tools-for-new-times/" target="_blank" rel="noopener noreferrer">Stack Overflow podcast</a>, hit the <a href="https://twitter.com/supabase_io/status/1268062559023685633" target="_blank" rel="noopener noreferrer">trending page</a> on GitHub, and scaled to over 1000 databases.</p><p>Here is everything that went wrong along the way.</p><h2>Quick stats - launch week</h2><p>Before we get into the details, here are some high-level numbers for the week following the launch.</p><p>We had 30,000 new website visitors to <a href="http://supabase.io/">supabase.io</a>:</p><p>We had over 1400 signups in 7 days:</p><p>Github stars rocketed for our two main repos, <a href="https://github.com/supabase/supabase" target="_blank" rel="noopener noreferrer">supabase</a> and <a href="https://github.com/supabase/realtime" target="_blank" rel="noopener noreferrer">realtime</a>. </p><br><h2>The good</h2><p>Here are the things that survived well.</p><h3>Middleware: docker-compose up</h3><p>This was the most surprising survivor. Our middleware was served from a single Ubuntu server with 4 CPUs and 8GB of RAM. This server was running our middleware using <code>docker-compose up</code>:</p><p>In case you're wondering why any sane company would use that in production, it's because we weren't planning to launch - the HackerNews post was created by an early GitHub follower, while we were alpha testing, and it was too scary to migrate the middleware while it was servicing the thundering herd. All Supabase projects use the same middleware stack (sans docker-compose), so I guess this counts as as a successful load test. </p><p>We have since migrated our middleware to multiple ECS clusters, globally load-balanced using AWS's <a href="https://aws.amazon.com/global-accelerator/" target="_blank" rel="noopener noreferrer">Global Accelerator</a>. </p><h3>Frontend: Netlify, Vercel, Auth0</h3><p>We serve our marketing site (<a href="http://supabase.io/">supabase.io</a>) from Netlify. It's a static-build <a href="https://v2.docusaurus.io/" target="_blank" rel="noopener noreferrer">Docusaurus (v2)</a> site, so it had no problems (apart from one developer in Russia who couldn't access the site - it looks like some of Netlify's IP addresses are blocked there).</p><p>We serve our app (<a href="http://app.supabase.io/">app.supabase.io</a>) using Vercel, and the login system uses Auth0. These were both rock-solid. Before the launch we noticed that Vercel was extremely slow on their free plan, and once we upgraded to their Pro Plan for multi-region deploys it solved performance issues. It looks like they are changing their plans again so buyer beware.</p><h2>The Bad</h2><h3>Digital Ocean cloud limits</h3><p>In May we were using Digital Ocean to serve all of our customer databases. We hit the first server limit (400 servers) in the space of a few hours. They bumped our limit up to 1000 and we hit that again a few hours later. </p><p>Digital Ocean were very responsive when we asked for increases, each time responding in 30 minutes or less.</p><h3>Cloudflare cloud limits</h3><p>Each Supabase project gets a unique URL for their API and database. This is set up using Cloudflare's API. This was a seamless process until we hit the 1000-subdomain limit, at 4am in the morning. My cofounder was awake, managed to identify the problem early, and reached out to the support to increase the limit. </p><p>Cloudflare support advised him to upgrade the account to increase the limit, but the upgrade could only be done by the owner (me). Unfortunately my phone was on silent, so for 3 hours our systems were down. Ideally any one of our team could have upgraded our account, but I imagine that Cloudflare have their reasons for this restriction.</p><h2>The Ugly - migrating 1800 servers</h2><p>Let me start by saying that Digital Ocean have been great for getting up and running. The experience was simple to start with, but ended painfully. </p><h3>Digital Ocean production errors</h3><p>The first sign of problems were the frequent production errors. This is a screenshot of emails from Digital ocean for the month of June.</p><p>Each of these emails represents one or more servers that has a critical issue:</p><blockquote><p>We have identified an issue on the physical machine hosting one or more of your Droplets. In the event that we are not able to perform a live migration of a Droplet, we will perform an offline migration during which the Droplet will be powered off and migrated offline during the window.</p></blockquote><p>Luckily we are in alpha, and our community has been extremely patient. </p><h3>Credit limits</h3><p>Most of our frustration was due to their internal policy around credits program. We were generously granted $10,000 Digital Ocean credits in February through Stripe Atlas, and so they became our primary cloud provider.</p><p>Digital Ocean have another (more generous) credits package for YC companies. Unfortunately when we applied for this we were told we weren't eligible because it was a "Partner switch" from Stripe to YC. This was frustrating because a "Partner switch" is completely arbitrary to us as a customer.  </p><p>Also we had conveniently just run out of credits. We don’t expect cloud providers to fund our inefficiencies, but we needed time to optimize our infrastructure after our surprise launch. We had assumed that the more generous credits package was guaranteed - an assumption which cost us several thousand dollars. After swift deliberation, we decided to migrate away from Digital Ocean. </p><h2>Going Forward: AWS t3a</h2><p>In the past 3 weeks we have migrated 1800 servers over to AWS. </p><p>We are on the AWS "Activate" program, which grants us $100,000 credits. Since Firebase has a very generous free-tier, and we want to be able to offer Supabase developers a similar experience, this is ultimately a huge benefit to our community.</p><p>The AWS team were helpful, suggesting their new <code>t3a</code> instances. We're already seeing improvements, with database startup times almost halved from ~90s to ~50s. From our research, this is the fastest Postgres setup in the market.</p><p>We will release a detailed write-up on these instances in the next few weeks. Sign up to our newsletter if you want to be notified when we release the post.</p></section></div>]]>
            </description>
            <link>https://supabase.io/blog/2020/07/10/alpha-launch-postmortem</link>
            <guid isPermaLink="false">hacker-news-small-sites-23832692</guid>
            <pubDate>Tue, 14 Jul 2020 14:57:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From Siberia to Tibet: Life on a Train]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23832549">thread link</a>) | @9nGQluzmnq3M
<br/>
July 14, 2020 | https://driftingclouds.net/2018/07/04/from-siberia-to-tibet-life-on-a-train/ | <a href="https://web.archive.org/web/*/https://driftingclouds.net/2018/07/04/from-siberia-to-tibet-life-on-a-train/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-494">
	<!-- .entry-header -->

	
		<div>
			
<div data-original-width="636" data-carousel-extra="{&quot;blog_id&quot;:40678465,&quot;permalink&quot;:&quot;https:\/\/driftingclouds.net\/2018\/07\/04\/from-siberia-to-tibet-life-on-a-train\/&quot;,&quot;likes_blog_id&quot;:40678465}" itemscope="" itemtype="http://schema.org/ImageGallery"> <div data-original-width="636" data-original-height="533">  <!-- close group --> <div data-original-width="401" data-original-height="533"> <div itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject"> <a href="https://driftingcloudsnet.files.wordpress.com/2018/08/img_20180708_065136.jpg" itemprop="url"> <meta itemprop="width" content="397"> <meta itemprop="height" content="529"> <img data-attachment-id="503" data-orig-file="https://driftingcloudsnet.files.wordpress.com/2018/08/img_20180708_065136.jpg" data-orig-size="3024,4032" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 2&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1531032696&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.442&quot;,&quot;iso&quot;:&quot;50&quot;,&quot;shutter_speed&quot;:&quot;0.004403&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_20180708_065136" data-image-description="" data-medium-file="https://driftingcloudsnet.files.wordpress.com/2018/08/img_20180708_065136.jpg?w=225" data-large-file="https://driftingcloudsnet.files.wordpress.com/2018/08/img_20180708_065136.jpg?w=636" src="https://driftingcloudsnet.files.wordpress.com/2018/08/img_20180708_065136.jpg?w=397&amp;h=529" width="397" height="529" data-original-width="397" data-original-height="529" itemprop="http://schema.org/image" title="img_20180708_065136" alt="img_20180708_065136"> </a> </div> </div> <!-- close group --> </div> <!-- close row --> </div>
<p>Many writers wax lyrical about the romance of long-distance train travel, but on this trip I sampled four them — Irkutsk to Ulaanbaatar, Ulaanbaatar to Beijing, Beijing to Xi’an, and Xining to Lhasa — and the sad truth is that the passenger trains in these parts are strictly utilitarian workhorses, inferior to airplanes on virtually every measure of speed or comfort.&nbsp; &nbsp;Here’s the lowdown on life in a 4-berth sleeper (<em>kupé</em> in Russia, 软卧 <em>ruǎnwò&nbsp;</em>in China).</p>
<h2>Eat</h2>

<p>When you’re on a train for 24 hours or more, you’ve got to eat something, and this leaves you with three options.</p>
<p>The first and most obvious option is <strong>restaurant cars</strong>, and the Mongolian ones with their intricate wood carvings and embroidered tablecloths even look quite attractive.&nbsp; Alas, the food they serve ranges&nbsp;from bland but edible, like our Chinese breakfast set composed mostly of sausage, celery and chilli, to bland and near-inedible, such as the&nbsp;<em>incredibly&nbsp;</em>gristly beef served on the Mongolian train — I was picking bits out of my teeth for the next two days.&nbsp; Perhaps we should have taken the hint from the plastic bags of frozen beef sitting in the corridor, tenderizing in the midsummer heat of the Gobi Desert.</p>
<p>Alternatively, you can try to buy food on <strong>station platforms</strong>, but this presents a number of practical problems.&nbsp; First, stops are few and far between and rarely aligned with mealtimes.&nbsp; Second, stops are short and on arrival you neither have any idea what the options are nor where to find them.&nbsp; Third, if you do find something food-like, it’s often unclear how many days those mince-meat&nbsp;<em>khuushuurs</em>&nbsp;sitting on a table&nbsp;have been fermenting under the Mongolian sun.&nbsp; We did manage to swing some pretty decent&nbsp;<em>piroshki </em>pastries&nbsp;in Ulan-Ude, plus rye bread and boiled eggs in Mongolia, but it really is the luck of the draw and you can’t count on finding more than packaged snacks this way.</p>

<p>Finally, you can <strong>bring your own food</strong>, but with no refrigeration or heating available (aside from hot water), you’ll be hard pressed to expand your culinary horizons beyond packaged bread, instant noodles and the giant Russian rye croutons called&nbsp;<a href="http://snackproduction.com.ua/grenki-3/"><em>grenki</em></a>.&nbsp; (Best flavor: garlic with garlic dip.&nbsp; You’re welcome.)&nbsp; A useful compromise is to buy a meal at your&nbsp;<em>departure&nbsp;</em>station: you’re not going to find much more than fast food, but even KFC is likely tastier, cheaper and healthier than the alternatives.</p>
<p>All that said, you <em>can</em> generally rely on the restaurant cars to supply lukewarm beer at only mildly extortionate prices, which brings me to…</p>
<h2>Drink</h2>

<p>Russian and Mongolian trains forbid drinking <strong>alcoholic beverages</strong> on board; fortunately, this being Russia and Mongolia, beer is not considered alcohol.&nbsp; (Seriously.)&nbsp; Needless to say, this rule is widely ignored by all and sundry, although it’s generally wise to close your compartment door if you have one and avoid tippling at times when conductors are on the prowl.</p>
<p>The one free drink provided in abundant quantities is <strong>boiling hot water</strong>, supplied by a coal or wood fired boiler at the end of each carriage.&nbsp; If you’re lucky, there may even be a thermos bottle in your cabin, which you can use to stock your own supply.&nbsp; Bring along some teabags, instant coffee or cocoa, and you can stay caffeinated.&nbsp; A&nbsp;pedantic nit: most travelers call these <a href="https://en.wikipedia.org/wiki/Samovar">samovars</a>, but in Russian they’re actually “titans” (титан).</p>
<p>Non-hot water, on the other hand, is in distinctly short supply, as the water from the bathroom taps is <strong>not drinkable</strong>.&nbsp; Bring along more than you think you will need, particularly if it’s hot or high outside.&nbsp; As for taking a shower or a bath, forget about it.</p>
<h2>Poop</h2>
<p>Yes, this section has no pictures.&nbsp; (You’re welcome.)</p>
<p>The upside to strictly functional trains is that their toilets are also unencumbered with pneumatic vacuums and mysterious blue liquids.&nbsp; Instead, when you press the lever, the bottom opens up and the contents are deposited straight onto the tracks, followed by a slightly apologetic trickle of water.&nbsp; While this does an admirable job of preventing the toilet from clogging, it does also mean that the doors are locked while the train is stationary, including during those multi-hour border crossings.</p>
<p>On Chinese trains, you will also encounter squat toilets, although there are usually a few thrones to be found as well.&nbsp; The upside to these is that, no matter how filthy the rest of the room, only your feet need make contact; the downside is that whatever your feet make contact with is likely to be unpleasant.&nbsp; This is why everybody on board brings flip-flops to wear.&nbsp; &nbsp;And whether your train is Russian, Mongolian or Chinese, you’ll want to bring toilet paper and soap as well.</p>
<h2>Sleep</h2>
<p>Fed, hydrated and voided, it’s time to sleep.&nbsp;&nbsp;The uninitiated are often tempted by the idea of a hotel on wheels: just slumber away peacefully on board and you’ll arrive at your destination not just refreshed, but having saved on a night’s hotel bill!&nbsp; Reality is more complicated.</p>

<p>Even when not manufactured in the DDR, the berths are <strong>generally uncomfortable</strong>, even in the misnamed Russian “luxe” or Chinese “soft sleeper”.&nbsp; The sheets are nailed to plyboard (we ended up buying an inflatable camping mattress because my dad’s back was wrecked by the four nights of the Moscow-Irkutsk stretch), the blankets are covered in stains of indeterminate origin and getting onto the top bunks requires acrobatics.&nbsp; If the window is closed, it’ll be stuffy and hot inside; if it’s open, every rattle, clank and blast of the horn is amplified and your toes will freeze.&nbsp; &nbsp;While the Trans-Siberian and most railways in China are continuously welded and thus smooth, the Trans-Mongolian is not, meaning your bedtime lullaby will be a constant&nbsp;<em>clunk-clunk, clunk-clunk</em>.</p>
<div data-original-width="636" data-carousel-extra="{&quot;blog_id&quot;:40678465,&quot;permalink&quot;:&quot;https:\/\/driftingclouds.net\/2018\/07\/04\/from-siberia-to-tibet-life-on-a-train\/&quot;,&quot;likes_blog_id&quot;:40678465}" itemscope="" itemtype="http://schema.org/ImageGallery"> <div data-original-width="636" data-original-height="319"> <div data-original-width="424" data-original-height="319"> <div itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject"> <a href="https://driftingcloudsnet.files.wordpress.com/2018/08/img_20180708_215106.jpg" itemprop="url"> <meta itemprop="width" content="420"> <meta itemprop="height" content="315"> <img data-attachment-id="513" data-orig-file="https://driftingcloudsnet.files.wordpress.com/2018/08/img_20180708_215106.jpg" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 2&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1531086666&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.442&quot;,&quot;iso&quot;:&quot;400&quot;,&quot;shutter_speed&quot;:&quot;0.024963&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_20180708_215106" data-image-description="" data-medium-file="https://driftingcloudsnet.files.wordpress.com/2018/08/img_20180708_215106.jpg?w=300" data-large-file="https://driftingcloudsnet.files.wordpress.com/2018/08/img_20180708_215106.jpg?w=636" src="https://driftingcloudsnet.files.wordpress.com/2018/08/img_20180708_215106.jpg?w=420&amp;h=315" width="420" height="315" data-original-width="420" data-original-height="315" itemprop="http://schema.org/image" title="img_20180708_215106" alt="img_20180708_215106"> </a> </div> </div> <!-- close group -->  <!-- close group --> </div> <!-- close row --> </div>
<p>In addition, <strong>border crossings</strong> are both interminable and inevitably timed to happen in the middle of night.&nbsp; It was past midnight when we finally entered Mongolia after two hours of inspections, and while our arrival into China was at 9 PM, we all had to get off the train and wait for&nbsp;5 hours, until 2 AM, while they swapped the bogies from Russian to Chinese gauge.</p>
<p>Unsurprisingly, you’re likely to wake up groggy and grumpy.&nbsp; If you’re at your destination already, you’ll be decanted onto the streets and condemned to wander until your hotel opens; if not, you’ll probably catch up by napping in your bunk during the day, throwing your sleep cycle even more out of whack.</p>
<h2>So why do it?</h2>
<p>Well, that was quite the litany of whinging, why would anybody voluntarily subject themselves to this then?</p>
<p>It’s <strong>an opportunity to idle</strong>.&nbsp; There is way more time than there are things to do, so you can read a book, play cards, study the <a href="https://driftingclouds.net/2018/02/20/that-is-not-your-name-the-kafkaesque-world-of-russian-duolingo/">finer points of Russian grammar</a> on Duolingo, or just take a nap — and all the earlier kvetching aside, your train bunk is still more spacious and comfy than even a business class seat on an airplane.</p>
<p>Traveling by train, you get a <strong>sense of distance</strong>.&nbsp; I flew Beijing to Irkutsk in 2.5 hours, and saw basically nothing even from the window seat.&nbsp; Traveling the same route by train took 54 hours, and while I still can’t say I <em>really&nbsp;</em>know what it felt like to <a href="https://www.goodreads.com/book/show/17286667-on-the-trail-of-genghis-khan">cross the Gobi by camel</a>, now at least I have some reference point for the sheer scale of the feat.</p>
<div data-original-width="636" data-carousel-extra="{&quot;blog_id&quot;:40678465,&quot;permalink&quot;:&quot;https:\/\/driftingclouds.net\/2018\/07\/04\/from-siberia-to-tibet-life-on-a-train\/&quot;,&quot;likes_blog_id&quot;:40678465}" itemscope="" itemtype="http://schema.org/ImageGallery"> <div data-original-width="636" data-original-height="294"> <div data-original-width="441" data-original-height="294"> <div itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject"> <a href="https://driftingcloudsnet.files.wordpress.com/2018/08/dsc_5645.jpg" itemprop="url"> <meta itemprop="width" content="437"> <meta itemprop="height" content="290"> <img data-attachment-id="517" data-orig-file="https://driftingcloudsnet.files.wordpress.com/2018/08/dsc_5645.jpg" data-orig-size="4928,3264" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;NIKON D7000&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1530730133&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;18&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.004&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="dsc_5645" data-image-description="" data-medium-file="https://driftingcloudsnet.files.wordpress.com/2018/08/dsc_5645.jpg?w=300" data-large-file="https://driftingcloudsnet.files.wordpress.com/2018/08/dsc_5645.jpg?w=636" src="https://driftingcloudsnet.files.wordpress.com/2018/08/dsc_5645.jpg?w=437&amp;h=290" width="437" height="290" data-original-width="437" data-original-height="290" itemprop="http://schema.org/image" title="dsc_5645" alt="dsc_5645"> </a> </div> </div> <!-- close group -->  <!-- close group --> </div> <!-- close row -->  <!-- close row --> </div>
<p>But above all, <strong>you see a slice of real life</strong>.&nbsp; It’s not always pretty (any train traveler in India will have a hard time unseeing the spectacle of the track sides being used as a public lavatory), but simply put, without taking the train you wouldn’t see ramshackle Siberian dachas, rusting factories around Ulan-Ude, yurt cities around Ulan Bator, ghastly commieblocks around a Mongolian military base in the Gobi desert, Chinese factories spewing grey smoke into the skies of Inner Mongolia, the green hills of Shaanxi, the shaggy yaks wandering around the plateaus of Tibet, the massive scale of construction around Lhasa and more.&nbsp; This trip wouldn’t have been the same at all without it, and I have zero regrets.</p>
<p>On to Mongolia!</p>
<p><strong><a href="https://driftingclouds.net/2018/07/02/from-siberia-to-tibet-irkutsk-lake-baikal/">&lt;&lt;&lt; Irkutsk &amp; Lake Baikal</a>&nbsp;|&nbsp;<a href="https://driftingclouds.net/2018/07/07/from-siberia-to-tibet-ulaanbaatar-gorkhi-terelj-and-the-gobi-desert/">Ulaanbaatar, Gorkhi-Terelj and the Gobi Desert &gt;&gt;&gt;</a></strong></p>
			
			
								</div><!-- .entry-content -->

	
	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://driftingclouds.net/2018/07/04/from-siberia-to-tibet-life-on-a-train/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23832549</guid>
            <pubDate>Tue, 14 Jul 2020 14:45:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Ebbflow – A Multi-Cloud Load Balancer and SSH Proxy. Host from Anywhere]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23832533">thread link</a>) | @gorbot
<br/>
July 14, 2020 | https://ebbflow.io/blog/announce | <a href="https://web.archive.org/web/*/https://ebbflow.io/blog/announce">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>After almost a year of hard work, Ebbflow has launched! It has been an invaluable learning experience and I'm super excited to get this tool into the hands of other developers.</p>
    <p>Ebbflow is multi-cloud load balancer and SSH proxy service. You can use it to host websites (or generic TLS endpoints!) privately and securely with browser-trusted certificates which can be automatically provisioned and presented for you. Connect to your servers from anywhere, no matter where they are or what network they are in. In a word, Ebbflow is flexible.
    </p><h3>Why Ebbflow?</h3>
    <p>Networking is a pain. Configuring firewalls, DNS, EC2 security groups, port-forwarding, etc., is complicated and difficult. It can be extremely specific. And most importantly, it is inflexible. Let's look at an example: home hosting. If I asked you to host a website from your home computer/raspberry pi, with a browser-trusted certificate, how would you do that? How durable is it? How much manual configuration does it involve? The easiest solution I can think of involves port-forwarding your home router to a server of yours and routing your DNS name to your home's IP address. Is that private? What if your IP changes? Sounds fun. Don't get a new router! Or move!</p>
    <p>Enterprise web hosting can be little easier - all cloud providers have load balancers you can use to route traffic to your servers in a local network, typically in a single region. This will work for many people, but things get hard once you'd like to move outside this standard model. If you are familiar with cloud networking, consider the difficulty of the following situations: migrating from on-premises to cloud, cloud-cloud migration, being multi-region or global, routing to a Kubernetes cluster and handling updates, migrating from instances to containers, handling AZ failover, or region failover. A lot of these problems do have solutions - you <i>can</i> solve these problems and some are easier than others - but the solutions are vendor specific, disjoint, application specific, and typically inflexible.</p>
    <p>Ebbflow provides a single and global networking model that doesn't just solve a few of these problems, it solves all of these problems.</p>
    <h3>The Ebbflow Model</h3>
   <p><u>In short</u>: All things connect to Ebbflow. Ebbflow routes clients to servers, privately and securely.</p>
   <p><img src="https://ebbflow.io/resources/smallnarrow.png" width="100px"></p><p>Ebbflow flips the paradigm you are currently used to. With Ebbflow, your servers reach up and await connections. Ebbflow has the fun task of routing clients to your servers. When a client visits your website or endpoint, Ebbflow picks the nearest server and proxies the connection through the <a href="https://ebbflow.io/documentation#client" target="_blank">client</a> to your server process or local SSH daemon.</p>
    <p>This new way of modeling your network removes many of the roadblocks and bumps that the current world of networking has. Ebbflow allows for some interesting properties to be achieved:</p>
    <p><small>
    <ul>
       <li><strong>Firewall Friendly</strong> - Feel free to block all inbound connections to your servers yet still host your endpoint and be SSH-ed to.</li>
       <li><strong>Global &amp; Local</strong> - Ebbflow has one single interface for all customers and uses nearest-server routing to keep your traffic local for low latencies.</li>
       <li><strong>Multi Cloud</strong> - Ebbflow is deployed to AWS and Google Cloud, and is multi-region in both clouds. If a region Ebbflow is deployed to goes down, your clients <i>and servers</i> will both be routed to other regions or clouds. You don't need to account for region-failure when considering your server scaling, as your servers are always hittable.</li>
       <li><strong><a href="https://ebbflow.io/documentation#client" target="_blank">Linux, MacOS, Windows, Pi</a></strong> - Host where you want with what OS you want. Ebbflow is also ready to adopt new distros and targets to fit your needs</li>
       <li><strong>Centralized Certificate Management</strong> - Ebbflow manages and presents a browser-trusted <a href="https://letsencrypt.org/" target="_blank">Let's Encrypt</a> certificate to the visitors of your endpoint</li>
       <li><strong>LAN Agnostic</strong> - Ebbflow does not care what private network your servers are in and they can be completely isolated.</li>
       <li><strong>No Network, No Problem</strong> - Let's say you have a Raspberry Pi in the field collecting data over a cellular connection, this pi could host an endpoint, or be SSH-ed to with Ebbflow.</li>
       </ul>
       </small></p><p>This new networking model solves the above problems in a convenient and simple way. You can load balance across any network at any time. You can move the same instance between networks and without any configuration at all, the instance will continue to host your endpoint or be SSH-ed to. Multi cloud? Sure. Home hosting? Cool. Host from your Pi? Sweet!</p>
   <h3>Living in an Ebbflow World</h3>
   <p>Ebbflow takes many of the problems of modern networking off your play. Ebbflow use of technologies like nearest-host routing, global availability, and multi-cloud durability, all Ebbflow customers benefit from this as well. It's also low-investment in time and money to start hosting or connecting your servers. </p>
   <p>Prototyping and testing with Ebbflow takes <a href="https://ebbflow.io/quickstart#endpointguide" target="_blank">only a few minutes</a>. During the development of Ebbflow, I used Ebbflow many times to host endpoints or for SSH connectivity. One interesting case was that I was in a coffee shop using the SSH proxy feature to connect to my dev-box at home, while trying to fix a bug in the SSH proxy feature which caused occasional disconnects (now fixed). Ebbflow uses Ebbflow for its website and its linux package server - this request was served by <code id="hostname">raspberrypi-1-useast</code>. Also Ebbflow uses Ebbflow to host its staging environment and testing stack. It is simpler and easier to configure than other load balancing solutions and provides so many features that others lack.</p>
   <p>I'm excited to see how people use Ebbflow to solve interesting problems. We want to hear about the ways it unlocks new forms of web hosting and connectivity (just <a href="mailto:info@ebbflow.io">email us!</a>). Ebbflow provides a simple solution to complex problems and simple ones such as hosting a personal blog on your Raspberry Pi that's currently collecting dust in your junk drawer. Like I said before, Ebbflow is flexible. It will meet you at your use case and remove the complexities of networking from your problem set. See for yourself, and start testing today with the <a href="https://ebbflow.io/create_account">free trial</a>!</p>
    </div></div>]]>
            </description>
            <link>https://ebbflow.io/blog/announce</link>
            <guid isPermaLink="false">hacker-news-small-sites-23832533</guid>
            <pubDate>Tue, 14 Jul 2020 14:43:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CVPR 2020: The Top Object Detection Papers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23832469">thread link</a>) | @mwitiderrick
<br/>
July 14, 2020 | https://heartbeat.fritz.ai/cvpr-2020-the-top-objection-detection-papers-f920a6e41233 | <a href="https://web.archive.org/web/*/https://heartbeat.fritz.ai/cvpr-2020-the-top-objection-detection-papers-f920a6e41233">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://heartbeat.fritz.ai/@mwitiderrick?source=post_page-----f920a6e41233----------------------" rel="noopener"><img alt="Derrick Mwiti" src="https://miro.medium.com/fit/c/96/96/2*9aohLPF6ipIrrmZ50g8zNQ.jpeg" width="48" height="48"></a></p></div></div></div></div><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2306/1*A67D7A2ZmaPlddeIi4UtoQ.jpeg" width="1153" height="581" srcset="https://miro.medium.com/max/552/1*A67D7A2ZmaPlddeIi4UtoQ.jpeg 276w, https://miro.medium.com/max/1104/1*A67D7A2ZmaPlddeIi4UtoQ.jpeg 552w, https://miro.medium.com/max/1280/1*A67D7A2ZmaPlddeIi4UtoQ.jpeg 640w, https://miro.medium.com/max/1400/1*A67D7A2ZmaPlddeIi4UtoQ.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*A67D7A2ZmaPlddeIi4UtoQ.jpeg?q=20"></p></div></div></div><figcaption><a href="https://www.amazon.science/conferences-and-events/cvpr-2020" target="_blank" rel="noopener">Image Source</a></figcaption></figure><p id="17e5">The recently-concluded CVPR 2020 had quite a large number of contributions in pushing <a href="https://www.fritz.ai/object-detection/" target="_blank" rel="noopener">object detection</a> forward. In this piece, we’ll look at a couple of the especially impressive papers.</p></div></div></section><hr><section><div><div><p id="b499">This paper proposes a graph convolution-based (GConv) hierarchical graph network (HGNet) for 3D object detection. It processes raw point clouds directly to predict 3D bounding boxes. HGNet is able to capture the relationship of the points and uses multi-level semantics for object detection.</p><p id="1d1c">HGNet consists of three main components:</p><ul><li id="a8ee">a GConv based U-shape network (GU-net)</li><li id="3b16">a Proposal Generator</li><li id="540c">a Proposal Reasoning Module (ProRe Module) — that uses a fully-connected graph to reason on the proposals</li></ul><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2420/1*2LWJMtQLwK9xOWQwEUjnVg.png" width="1210" height="460" srcset="https://miro.medium.com/max/552/1*2LWJMtQLwK9xOWQwEUjnVg.png 276w, https://miro.medium.com/max/1104/1*2LWJMtQLwK9xOWQwEUjnVg.png 552w, https://miro.medium.com/max/1280/1*2LWJMtQLwK9xOWQwEUjnVg.png 640w, https://miro.medium.com/max/1400/1*2LWJMtQLwK9xOWQwEUjnVg.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*2LWJMtQLwK9xOWQwEUjnVg.png?q=20"></p></div></div></div></figure><p id="b36f">The authors present a shape-attentive GConv (SA-GConv) to capture the local shape features. This is done by modeling the relative geometric positions to describe object shapes.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1082/1*8ixotq1FqZ367wbotywgdw.png" width="541" height="358" srcset="https://miro.medium.com/max/552/1*8ixotq1FqZ367wbotywgdw.png 276w, https://miro.medium.com/max/1082/1*8ixotq1FqZ367wbotywgdw.png 541w" sizes="541px" data-old-src="https://miro.medium.com/max/60/1*8ixotq1FqZ367wbotywgdw.png?q=20"></p></div></div></figure><p id="cc59">The SA-GConv based U-shape network captures the multi-level features. They are then mapped onto an identical feature space by a voting module and used to generate proposals. In the next step, a GConv based Proposal Reasoning Module uses the proposals to predict bounding boxes.</p><p id="5d73">Here are some of the performance results obtained on the <a href="https://rgbd.cs.princeton.edu/" target="_blank" rel="noopener">SUN RGB-D V1</a> dataset.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2308/1*NWypUDcLF9Ss9iSEEJZ3gA.png" width="1154" height="282" srcset="https://miro.medium.com/max/552/1*NWypUDcLF9Ss9iSEEJZ3gA.png 276w, https://miro.medium.com/max/1104/1*NWypUDcLF9Ss9iSEEJZ3gA.png 552w, https://miro.medium.com/max/1280/1*NWypUDcLF9Ss9iSEEJZ3gA.png 640w, https://miro.medium.com/max/1400/1*NWypUDcLF9Ss9iSEEJZ3gA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*NWypUDcLF9Ss9iSEEJZ3gA.png?q=20"></p></div></div></div></figure></div></div></section><hr><section><div><div><p id="28de">In this paper, the authors present the Hybrid Voxel Network (HVNet), a one-stage network for point cloud-based 3D object detection for autonomous driving.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2486/1*Jx7-FBXXK6aeFUZS0hT2UA.png" width="1243" height="334" srcset="https://miro.medium.com/max/552/1*Jx7-FBXXK6aeFUZS0hT2UA.png 276w, https://miro.medium.com/max/1104/1*Jx7-FBXXK6aeFUZS0hT2UA.png 552w, https://miro.medium.com/max/1280/1*Jx7-FBXXK6aeFUZS0hT2UA.png 640w, https://miro.medium.com/max/1400/1*Jx7-FBXXK6aeFUZS0hT2UA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*Jx7-FBXXK6aeFUZS0hT2UA.png?q=20"></p></div></div></div></figure><p id="008f">The voxel feature encoding (VFE) method used in this paper contains three steps:</p><ul><li id="5d07">Voxelization — assigning of a point cloud to a 2D voxel grid</li><li id="a86b">Voxel Feature Extraction — computation of a grid-dependent point-wise feature that’s fed to a PointNet style feature encoder</li><li id="e25a">Projection — aggregation of the point-wise feature to the voxel-level feature and projection to their original grid. This forms a pseudo-image feature map</li></ul><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1226/1*_Vl9dsBUX1CXglvmkl-a6Q.png" width="613" height="654" srcset="https://miro.medium.com/max/552/1*_Vl9dsBUX1CXglvmkl-a6Q.png 276w, https://miro.medium.com/max/1104/1*_Vl9dsBUX1CXglvmkl-a6Q.png 552w, https://miro.medium.com/max/1226/1*_Vl9dsBUX1CXglvmkl-a6Q.png 613w" sizes="613px" data-old-src="https://miro.medium.com/max/56/1*_Vl9dsBUX1CXglvmkl-a6Q.png?q=20"></p></div></div></figure><p id="1d27">The size of the voxel is very important in VFE methods. Smaller voxel sizes capture finer geometry features. They’re also better at object localization, but take longer at inference. Faster inference speeds can be obtained using a coarser voxel, since it leads to a smaller feature map. Its performance is inferior, however.</p><p id="8598">The authors propose the Hybrid Voxel Network (HVNet) to enable the utilization of fine-grained voxel features. It’s made up of three steps:</p><ul><li id="19d2">Multi-Scale Voxelization — the creation of a set of feature voxel scales and the assignment of each to multiple voxels.</li><li id="0982">Hybrid Voxel Feature Extraction —computing of a voxel dependent feature for each scale and feeding it into the attentive feature encoder (AVFE). Features from each voxel scale are concatenated point-wise.</li><li id="1f9c">Dynamic Feature Projection — Projecting the feature back to the pseudo-image by creating a set of multi-scale project voxels.</li></ul><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2534/1*zyGPbSVftzzdHPxerAXQxQ.png" width="1267" height="561" srcset="https://miro.medium.com/max/552/1*zyGPbSVftzzdHPxerAXQxQ.png 276w, https://miro.medium.com/max/1104/1*zyGPbSVftzzdHPxerAXQxQ.png 552w, https://miro.medium.com/max/1280/1*zyGPbSVftzzdHPxerAXQxQ.png 640w, https://miro.medium.com/max/1400/1*zyGPbSVftzzdHPxerAXQxQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*zyGPbSVftzzdHPxerAXQxQ.png?q=20"></p></div></div></div></figure><p id="17b9">Here are the results obtained on the KITTI dataset.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2472/1*MGF7HcNNTMKfYSdFa4sllQ.png" width="1236" height="513" srcset="https://miro.medium.com/max/552/1*MGF7HcNNTMKfYSdFa4sllQ.png 276w, https://miro.medium.com/max/1104/1*MGF7HcNNTMKfYSdFa4sllQ.png 552w, https://miro.medium.com/max/1280/1*MGF7HcNNTMKfYSdFa4sllQ.png 640w, https://miro.medium.com/max/1400/1*MGF7HcNNTMKfYSdFa4sllQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*MGF7HcNNTMKfYSdFa4sllQ.png?q=20"></p></div></div></div></figure></div></div></section><hr><section><div><div><blockquote><p id="d025">State-of-the-art object detection models can also work in real-time on mobile devices. <a href="https://www.fritz.ai/product/studio.html?utm_campaign=object-detection-cvpr&amp;utm_source=heartbeat" target="_blank" rel="noopener">And Fritz AI Studio allows you to build, test, and deploy custom object detection models to iOS and Android. Start building for free</a>.</p></blockquote><p id="e8a5">Authors of this paper present a graph neural network — Point-GNN — to detect objects from a <a href="https://en.wikipedia.org/wiki/National_lidar_dataset" target="_blank" rel="noopener">LiDAR</a> point cloud. The network predicts the category and shape of the object that each vertex in the graph belongs to. Point-GNN has an auto-regression mechanism that detects multiple objects in a single shot.</p><p id="b2a8">The proposed method has three components:</p><ul><li id="8cc5">graph construction: a voxel downsampled point cloud is used for graph construction</li><li id="520b">a graph neural network of <em>T</em> iterations</li><li id="2685">bounding box merging and scoring</li></ul><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2286/1*0O8VhuRPdxqwVFhWamyTCA.png" width="1143" height="623" srcset="https://miro.medium.com/max/552/1*0O8VhuRPdxqwVFhWamyTCA.png 276w, https://miro.medium.com/max/1104/1*0O8VhuRPdxqwVFhWamyTCA.png 552w, https://miro.medium.com/max/1280/1*0O8VhuRPdxqwVFhWamyTCA.png 640w, https://miro.medium.com/max/1400/1*0O8VhuRPdxqwVFhWamyTCA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*0O8VhuRPdxqwVFhWamyTCA.png?q=20"></p></div></div></div></figure><p id="0c03">Here’re the results obtained on the KITTI dataset:</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1834/1*VgfFosL4qu9Mr8lvLR62TQ.png" width="917" height="567" srcset="https://miro.medium.com/max/552/1*VgfFosL4qu9Mr8lvLR62TQ.png 276w, https://miro.medium.com/max/1104/1*VgfFosL4qu9Mr8lvLR62TQ.png 552w, https://miro.medium.com/max/1280/1*VgfFosL4qu9Mr8lvLR62TQ.png 640w, https://miro.medium.com/max/1400/1*VgfFosL4qu9Mr8lvLR62TQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*VgfFosL4qu9Mr8lvLR62TQ.png?q=20"></p></div></div></div></figure><p id="e229">The code is available here:</p></div></div></section><hr><section><div><div><p id="76a1">This paper addresses the challenge of detecting objects that are embedded in their surroundings — camouflaged object detection (COD). The authors also present a new dataset called COD10K. It contains 10,000 images covering camouflaged objects in many natural scenes. It has 78 object categories. The images are annotated with category labels, bounding boxes, instance-level, and matting-level labels.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2302/1*oUHPPL-gG6kEzpUlj1iMww.png" width="1151" height="292" srcset="https://miro.medium.com/max/552/1*oUHPPL-gG6kEzpUlj1iMww.png 276w, https://miro.medium.com/max/1104/1*oUHPPL-gG6kEzpUlj1iMww.png 552w, https://miro.medium.com/max/1280/1*oUHPPL-gG6kEzpUlj1iMww.png 640w, https://miro.medium.com/max/1400/1*oUHPPL-gG6kEzpUlj1iMww.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*oUHPPL-gG6kEzpUlj1iMww.png?q=20"></p></div></div></div></figure><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2262/1*vt8wuBQCjKT6KQgVqwwa7Q.png" width="1131" height="224" srcset="https://miro.medium.com/max/552/1*vt8wuBQCjKT6KQgVqwwa7Q.png 276w, https://miro.medium.com/max/1104/1*vt8wuBQCjKT6KQgVqwwa7Q.png 552w, https://miro.medium.com/max/1280/1*vt8wuBQCjKT6KQgVqwwa7Q.png 640w, https://miro.medium.com/max/1400/1*vt8wuBQCjKT6KQgVqwwa7Q.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*vt8wuBQCjKT6KQgVqwwa7Q.png?q=20"></p></div></div></div></figure><p id="0447">The authors develop a COD framework called a Search Identification Network (SINet). The code is available here:</p><p id="ea04">The network has two main modules:</p><ul><li id="5593">the search module (SM) for searching for a camouflaged object</li><li id="bc25">the identification module (IM) for detecting the object</li></ul><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2304/1*lu3cY_bKE_-wnbTsbb4SqA.png" width="1152" height="572" srcset="https://miro.medium.com/max/552/1*lu3cY_bKE_-wnbTsbb4SqA.png 276w, https://miro.medium.com/max/1104/1*lu3cY_bKE_-wnbTsbb4SqA.png 552w, https://miro.medium.com/max/1280/1*lu3cY_bKE_-wnbTsbb4SqA.png 640w, https://miro.medium.com/max/1400/1*lu3cY_bKE_-wnbTsbb4SqA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*lu3cY_bKE_-wnbTsbb4SqA.png?q=20"></p></div></div></div></figure><p id="63ae">Here are the results obtained on various datasets:</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2362/1*UyVfgef-qfXcGrKljiH3FA.png" width="1181" height="594" srcset="https://miro.medium.com/max/552/1*UyVfgef-qfXcGrKljiH3FA.png 276w, https://miro.medium.com/max/1104/1*UyVfgef-qfXcGrKljiH3FA.png 552w, https://miro.medium.com/max/1280/1*UyVfgef-qfXcGrKljiH3FA.png 640w, https://miro.medium.com/max/1400/1*UyVfgef-qfXcGrKljiH3FA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*UyVfgef-qfXcGrKljiH3FA.png?q=20"></p></div></div></div></figure></div></div></section><hr><section><div><div><h2 id="4f7c">Few-Shot Object Detection with Attention-RPN and Multi-Relation Detector</h2><p id="eb21">This paper proposes a few-shot object detection network whose objective is to detect objects of unseen categories that have a few annotated examples.</p><p id="a68b">Their method includes an attention-RPN, multi-relation detector, and a contrastive training strategy. The method takes advantage of the similarity between the few-shot support set and query set to identify new objects, while also reducing false identification. The authors also contribute a new dataset that contains 1000 categories with objects that have high-quality annotations.</p><p id="71e2">The network architecture consists of a weight-shared framework that has multiple branches—one branch is the query set, while the rest are for the support set. The query branch of the weight-shared framework is a Faster R-CNN network.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2436/1*RUUYLi6Eg3vPjFmY7tY6Cg.png" width="1218" height="521" srcset="https://miro.medium.com/max/552/1*RUUYLi6Eg3vPjFmY7tY6Cg.png 276w, https://miro.medium.com/max/1104/1*RUUYLi6Eg3vPjFmY7tY6Cg.png 552w, https://miro.medium.com/max/1280/1*RUUYLi6Eg3vPjFmY7tY6Cg.png 640w, https://miro.medium.com/max/1400/1*RUUYLi6Eg3vPjFmY7tY6Cg.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*RUUYLi6Eg3vPjFmY7tY6Cg.png?q=20"></p></div></div></div></figure><p id="a03e">The authors introduce an attention-RPN and detector with multi-relation modules to produce accurate parsing between support and the potential boxes in the query.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1236/1*T2hy3IxGrcyiAvQKBvQApA.png" width="618" height="288" srcset="https://miro.medium.com/max/552/1*T2hy3IxGrcyiAvQKBvQApA.png 276w, https://miro.medium.com/max/1104/1*T2hy3IxGrcyiAvQKBvQApA.png 552w, https://miro.medium.com/max/1236/1*T2hy3IxGrcyiAvQKBvQApA.png 618w" sizes="618px" data-old-src="https://miro.medium.com/max/60/1*T2hy3IxGrcyiAvQKBvQApA.png?q=20"></p></div></div></figure><p id="e227">Here are some results obtained on the ImageNet dataset.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1140/1*As81-1oOCZvtoERYLe6gIw.png" width="570" height="299" srcset="https://miro.medium.com/max/552/1*As81-1oOCZvtoERYLe6gIw.png 276w, https://miro.medium.com/max/1104/1*As81-1oOCZvtoERYLe6gIw.png 552w, https://miro.medium.com/max/1140/1*As81-1oOCZvtoERYLe6gIw.png 570w" sizes="570px" data-old-src="https://miro.medium.com/max/60/1*As81-1oOCZvtoERYLe6gIw.png?q=20"></p></div></div></figure><p id="125e">Here are some observations obtained on a number of datasets.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1806/1*Bb8HkNNllnSZMDZYewMJGQ.png" width="903" height="579" srcset="https://miro.medium.com/max/552/1*Bb8HkNNllnSZMDZYewMJGQ.png 276w, https://miro.medium.com/max/1104/1*Bb8HkNNllnSZMDZYewMJGQ.png 552w, https://miro.medium.com/max/1280/1*Bb8HkNNllnSZMDZYewMJGQ.png 640w, https://miro.medium.com/max/1400/1*Bb8HkNNllnSZMDZYewMJGQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*Bb8HkNNllnSZMDZYewMJGQ.png?q=20"></p></div></div></div></figure></div></div></section><hr><section></section><hr><section><div><div><p id="ab0d">Authors of this paper propose D2Det, a method that addresses both precise localization and accurate classification. They introduce a dense local regression that predicts multiple dense box offsets for an object proposal. This enables them to achieve precise localization.</p><p id="5dc5">The authors also introduce a discriminative RoI pooling scheme in order to achieve accurate classification. The pooling scheme samples from several sub-regions of a proposal and performs adaptive weighting to get discriminating features.</p><p id="2c8b">The code is available at:</p><p id="487f">The method is based on the standard Faster R-CNN framework. In this method, the traditional box offset regression of Faster R-CNN is replaced by the proposed dense local regression. In the method, classification is enhanced by the discriminative RoI pooling.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1956/1*PxcLCxREMAidDShpAJoP-A.png" width="978" height="607" srcset="https://miro.medium.com/max/552/1*PxcLCxREMAidDShpAJoP-A.png 276w, https://miro.medium.com/max/1104/1*PxcLCxREMAidDShpAJoP-A.png 552w, https://miro.medium.com/max/1280/1*PxcLCxREMAidDShpAJoP-A.png 640w, https://miro.medium.com/max/1400/1*PxcLCxREMAidDShpAJoP-A.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PxcLCxREMAidDShpAJoP-A.png?q=20"></p></div></div></div></figure><p id="f1b4">In the two-stage method, a region proposal network (RPN) is used in the first stage, while separate classification and regression branches are put into effect in the second stage. The classification branch is based on discriminative pooling. The local regression branch’s objective is exact localization of an object.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1046/1*5aP-iJHp_6ekwW2_QJE6og.png" width="523" height="622" srcset="https://miro.medium.com/max/552/1*5aP-iJHp_6ekwW2_QJE6og.png 276w, https://miro.medium.com/max/1046/1*5aP-iJHp_6ekwW2_QJE6og.png 523w" sizes="523px" data-old-src="https://miro.medium.com/max/50/1*5aP-iJHp_6ekwW2_QJE6og.png?q=20"></p></div></div></figure><p id="6547">Here are the results obtained on the MS COCO dataset:</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1842/1*V25SVKupb4ts1x6mDZyQGg.png" width="921" height="552" srcset="https://miro.medium.com/max/552/1*V25SVKupb4ts1x6mDZyQGg.png 276w, https://miro.medium.com/max/1104/1*V25SVKupb4ts1x6mDZyQGg.png 552w, https://miro.medium.com/max/1280/1*V25SVKupb4ts1x6mDZyQGg.png 640w, https://miro.medium.com/max/1400/1*V25SVKupb4ts1x6mDZyQGg.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*V25SVKupb4ts1x6mDZyQGg.png?q=20"></p></div></div></div></figure></div></div></section><hr><section><div><div><h2 id="3951">Final Thought</h2><p id="b662">When it comes to object detection and a whole host of other computer vision tasks, CVPR 2020 offered plenty more. Here’s the open source repo of all the conference papers, in case you’d like to explore further.</p></div></div></section><hr><section><div><div><p id="8a55"><em>Editor’s Note:</em><a href="http://heartbeat.fritz.ai/" target="_blank" rel="noopener"><em> </em><strong><em>Heartbeat</em></strong></a><strong><em> </em></strong><em>is a contributor-driven online publication and community dedicated to exploring the emerging intersection of mobile app development and machine learning. We’re committed to supporting and inspiring developers and engineers from all walks of life.</em></p><p id="595e"><em>Editorially independent, Heartbeat is sponsored and published by</em><a href="http://fritz.ai/" target="_blank" rel="noopener"><em> </em><strong><em>Fritz AI</em></strong></a><em>, the machine learning platform that helps developers teach devices to see, hear, sense, and think. We pay our contributors, and we don’t sell ads.</em></p><p id="863b"><em>If you’d like to contribute, head on over to our</em><a target="_blank" rel="noopener" href="https://heartbeat.fritz.ai/call-for-contributors-october-2018-update-fee7f5b80f3e"><em> </em><strong><em>call for contributors</em></strong></a><em>. You can also sign up to receive our weekly newsletters (</em><a href="https://www.deeplearningweekly.com/" target="_blank" rel="noopener"><strong><em>Deep Learning Weekly</em></strong></a><em> and the </em><a href="https://www.fritz.ai/newsletter/?utm_campaign=fritzai-newsletter&amp;utm_source=heartbeat-statement" target="_blank" rel="noopener"><strong><em>Fritz AI Newsletter</em></strong></a><em>), join us on</em><a href="https://join.slack.com/t/fritz-ai-community/shared_invite/enQtNTY5NDM2MTQwMTgwLWU4ZDEwNTAxYWE2YjIxZDllMTcxMWE4MGFhNDk5Y2QwNTcxYzEyNWZmZWEwMzE4NTFkOWY2NTM0OGQwYjM5Y2U" target="_blank" rel="noopener"><em> </em></a><a href="http://fritz.ai/slack" target="_blank" rel="noopener"><strong><em>Slack</em></strong></a><em>, and follow Fritz AI on</em><a href="https://twitter.com/fritzlabs" target="_blank" rel="noopener"><em> </em><strong><em>Twitter</em></strong></a><em> for all the latest in mobile machine learning.</em></p></div></div></section></div></div>]]>
            </description>
            <link>https://heartbeat.fritz.ai/cvpr-2020-the-top-objection-detection-papers-f920a6e41233</link>
            <guid isPermaLink="false">hacker-news-small-sites-23832469</guid>
            <pubDate>Tue, 14 Jul 2020 14:38:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Partner Management for SaaS Companies]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23832461">thread link</a>) | @iliasanta
<br/>
July 14, 2020 | https://elioplus.com/prm-software | <a href="https://web.archive.org/web/*/https://elioplus.com/prm-software">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
    
    <div id="MainContent_UpdatePanel2">
	 
    <!-- banner area start -->
    

    <!-- About us section start -->
    <section id="abouts">
        <div>
            <div>
                <div>
                    <p><img src="https://elioplus.com/assets/prm/images/all-img/Partner_Relationship_Management_PRM_Dashboard.png" alt=""></p>
                </div>
                <!-- end about img -->
                <div>
                    <h2>Elioplus PRM</h2>
                    <p>
                        Elioplus PRM is the Partner Relationship Management software for every size of business operating in software, SaaS and cloud industry.
                        We break the rule that exists in IT channel industry giving access actually only to Entrerprise level companies that have the budget to invest on a PRM system to manage their channel partners.
                        We give access FOR FREE to software, SaaS and cloud services Vendors to manage up to 25 channel partners enjoying a 2GB library storage as well with full access to all of our features.
                    </p>
                    <p><a href="https://elioplus.com/prm-software/partner-portal" id="MainContent_aFeatures">Our Features</a>
                </p></div>
                <!-- end about conetent -->
            </div>
        </div>
    </section>

    <!-- Services area start -->
    <section id="feature">
        
        <!-- end feature bg shape 1 -->
        
        <!-- end feature bg shape 2 -->
        <div>
            <div>
                <div>
                    <h2>Features that matter</h2>
                    <p>
                        <span id="MainContent_LblPrmFeatures1">Elioplus PRM provides features that can increase your channel sales. Avoid a ton of features that make your life difficult.</span><br>
                        <span id="MainContent_LblPrmFeatures2">Through Elioplus PRM you are focusing on your channel partners productivity and needs through collaboration and incentivization.</span>
                    </p>
                </div>
                <!-- end section-titile -->
            </div>
            <!-- end row -->
            <div>
                <div data-animation="fadeInUp" data-animation-delay="0.1s">
                    <div>
                        <p>01</p>
                        <h3><a href="https://elioplus.com/prm-software/partner-onboarding" id="MainContent_aPrmSoftwareFeatures1">Onboarding</a></h3>
                        <p>
                            Your new partners need to have the right knowledge and skills to sell your solution from the beginning of your collaboration. Upload all the files and video that are needed through our onboarding feature and they'll automatically have access to any of them.
                        </p>
                    </div>
                </div>
                <!-- end single feature -->
                <div data-animation="fadeInUp" data-animation-delay="0.1s">
                    <div>
                        <p>02</p>
                        <h3><a href="https://elioplus.com/prm-software/deal-registration" id="MainContent_aPrmSoftwareFeatures2">Deal registration</a></h3>
                        <p>
                            Secure your channel partners' sales though our deal registration feature. Your channel partners won't worry anymore about losing a potential client that is interested to buy your solution. The only worry of them will be how to win the deal.
                        </p>
                    </div>
                </div>
                <!-- end single feature -->
                <div data-animation="fadeInUp" data-animation-delay="0.1s">
                    <div>
                        <p>03</p>
                        <h3><a href="https://elioplus.com/prm-software/lead-distribution" id="MainContent_aPrmSoftwareFeatures3">Lead distribution</a></h3>
                        <p>
                            Send hot leads to your channel partners though your PRM account. Satisfy the clients of your solution by assigning them the right partner for training, support and more. Increase sales for both and build a fruitful and strong relationship with your channel network.
                        </p>
                    </div>
                </div>
                <!-- end single feature -->
                <div data-animation="fadeInUp" data-animation-delay="0.1s">
                    <div>
                        <p>04</p>
                        <h3><a href="https://elioplus.com/prm-software/channel-analytics" id="MainContent_aPrmSoftwareFeatures4">Analytics</a></h3>
                        <p>
                            Get insights about your channel network’s performance, detailed analytics for each partner, their activity on your partner portal and forecasting for potential deals that might close successfully from your channel partners for the next quarters.
                        </p>
                    </div>
                </div>
                <!-- end single feature -->
                <div data-animation="fadeInUp" data-animation-delay="0.1s">
                    <div>
                        <p>05</p>
                        <h3><a href="https://elioplus.com/prm-software/collaboration" id="MainContent_aPrmSoftwareFeatures5">Collaboration &amp; Library</a></h3>
                        <p>
                            Invite your partners to your PRM, communicate real time, exchange material, create groups for chatting and increase revenue though collaboration. Enjoy a 2GB secured library, upload different types of files and categorize them. Send and receive files from your partners.
                        </p>
                    </div>
                </div>
                <!-- end single feature -->
                <div data-animation="fadeInUp" data-animation-delay="0.1s">
                    <div>
                        <p>06</p>
                        <h3><a href="https://elioplus.com/prm-software/partner-portal" id="MainContent_aPrmSoftwareFeatures6">Partner Portal</a></h3>
                        <p>
                            Enjoy a full branded partner portal with your own logo and your unique sign up and sign in URL. Your channel partners can now easily have access to the PRM through your unique partner portal page which you can upload on your website as well.
                        </p>
                    </div>
                </div>
                <!-- end single feature -->
                <div data-animation="fadeInUp" data-animation-delay="0.1s">
                    <div>
                        <p>07</p>
                        <h3><a href="https://elioplus.com/prm-software/partner-locator" id="MainContent_aPrmSoftwareFeatures7">Partner Locator</a></h3>
                        <p>
                            Add a partner locator to showcase your partners to your visitors in order to find a local company that offers your products and services. Incentivize your partners with new leads and your customers with better support.
                        </p>
                    </div>
                </div>
                <!-- end single feature -->
                <!-- end single feature -->
                <div data-animation="fadeInUp" data-animation-delay="0.1s">
                    <div>
                        <p>08</p>
                        <h3><a id="MainContent_aPartnerRecruitment">Customization</a></h3>
                        <p>
                            Customize your partner portal based on your needs and your brand to get the best out of it at no extra charge.
                        </p>
                    </div>
                </div>
                <!-- end single feature -->
            </div>
            
        </div>
    </section>

    <!-- integrations start -->
    <section id="integration">       
        
    </section>

    <!-- security start -->
    <section id="security">       
        <div>
            <div>
                <p>
                    <h2>Security</h2>                    
                </p>
                <div>
                    <p><img id="MainContent_Image1" src="https://elioplus.com/images/Security_Icon.png" alt="PRM Security Fully Secure">
                       <span id="MainContent_LblSecurity1">Fully Secure</span>
                    </p>                    
                </div>
                <div>
                    <p><img id="MainContent_Image2" src="https://elioplus.com/images/Security_Icon.png" alt="PRM Security Platform Uptime">
                       <span id="MainContent_Label1">99.9% Platform Uptime</span>
                    </p>
                </div>
                <div>
                    <p><img id="MainContent_Image3" src="https://elioplus.com/images/Security_Icon.png" alt="PRM Security GDPR Compliant">
                       <span id="MainContent_Label2">GDPR Compliant</span>
                    </p>
                </div>
                <p><img id="MainContent_Image4" src="https://elioplus.com/images/Security_Icon.png" alt="PRM Security SSL Encryption Enabled">
                       <span id="MainContent_Label3">SSL Encryption Enabled</span>
                </p>
            </div>
        </div>
    </section>

    <!-- apposh pricing table start -->
    <section id="price">
        
        <!-- end feature bg shape 1 -->
        <div>
            <div>
                <div>
                    <h2>Our pricing</h2>
                    <p>
                        Select the plan that fits your needs and start inviting your channel partners to join your PRM portal
                    </p>
                </div>
                <!-- end single pricicng -->
                <div data-animation="fadeInUp" data-animation-delay="0.18s">
                    <div>
                        
                        <!-- end price header -->
                        <div>
                            <ul>
                                <li>Manage up to 25 partners</li>
                                <li>2 GB library storage</li>
                                <li>Onboarding</li>
                                <li>Deal registration</li>
                                <li>Lead distribution</li>
                                <li>Collaboration</li>
                                <li>Partner directory</li>
                                <li>Partner to partner</li>
                            </ul>
                        </div>
                        <!-- end price body -->
                        
                        <!-- end price footer -->
                    </div>
                </div>
                <!-- end section-titile -->
                <div data-animation="fadeInUp" data-animation-delay="0.1s">
                    <div>
                        
                        <!-- end price header -->
                        <div>
                            <ul>
                                <li>+ Manage up to 100 partners</li>
                                <li>+ 10 GB library storage</li>
                                <li>Onboarding</li>
                                <li>Deal registration</li>
                                <li>Lead distribution</li>
                                <li>Collaboration</li>
                                <li>Partner directory</li>
                                <li>Partner to partner</li>
                                <li>+ Partner recruitment</li>
                                <li>+ Customization</li>
                            </ul>
                        </div>
                        <!-- end price body -->
                        
                        <!-- end price footer -->
                    </div>
                </div>
                <!-- end single pricicng -->
                <div data-animation="fadeInUp" data-animation-delay="0.14s">
                    <div>
                        
                        <p><span>Popular</span>
                        </p>
                        <!-- end price header -->
                        <div>
                            <ul>
                                <li>+ Manage up to 250 partners</li>
                                <li>+ 20 GB library storage</li>
                                <li>Onboarding</li>
                                <li>Deal registration</li>
                                <li>Lead distribution</li>
                                <li>Collaboration</li>
                                <li>Partner directory</li>
                                <li>Partner to partner</li>
                                <li>+ Partner recruitment(advanced)</li>
                                <li>+ Customization</li>
                            </ul>
                        </div>
                        <!-- end price body -->
                        
                        <!-- end price footer -->
                    </div>
                </div>                
                <!-- end single pricicng -->                
            </div>
            <p>
                    Have you got a bigger partner network to manage? Get in touch with our sales team
                    <a href="https://elioplus.com/contact-us" id="MainContent_aContactUs">Contact us</a>
                </p>
        </div>
    </section>

    <!-- apposh team start -->
    <section id="team">
        
    </section>

    <!-- testimonials start -->
    <section id="clinetssay">
        <div>
            <div>
                <div>
                    <h2>Testimonials</h2>                    
                    <p>
                        We focus on the success of our clients. Take a look at the experience they are facing by using Elioplus for their channel development efforts.
                    </p>
                </div>
                <!-- end section-titile -->
                <div>
                    <div>
                        <div>
                            <div>
                                <p><img src="https://elioplus.com/assets/prm/images/testimonials/chatwork_testimonial.png" alt=""></p><p>
                                    Guys you are doing a great job, really appreciate your support and your help by increasing our channel partners network through your service.
                                </p>
                                <p>
                                    <h4>Tomi Brooks</h4>
                                    <h5>VP of Growth at Chatwork</h5>
                                </p>
                            </div>
                            <!-- end single testimonilas -->
                            <div>
                                <p><img src="https://elioplus.com/assets/prm/images/testimonials/evernote_testimonial.png" alt=""></p><p>
                                    Amazing service and partnership matches, excellent support and summary of the work. Thanks a lot Elioplus!
                                </p>
                                <p>
                                    <h4>Manuel Marquina</h4>
                                    <h5>Head of Account Management and Business, EMEA at Evernote</h5>
                                </p>
                            </div>
                            <!-- end single testimonilas -->
                            <div>
                                <p><img src="https://elioplus.com/assets/prm/images/testimonials/bobile_testimonial.png" alt=""></p><p>
                                    Elio platform is easy to use and has all the features you need to increase your channel partners and manage your existing and new ones. Highly recommended!
                                </p>
                                <p>
                                    <h4>Eran Amit</h4>
                                    <h5>CMO at Bobile</h5>
                                </p>
                            </div>
                            <!-- end single testimonilas -->
                            <div>
                                <p><img src="https://elioplus.com/assets/prm/images/testimonials/repsly_testimonial.png" alt=""></p><p>
                                    Interface is easy to understand and use. Data is in a …</p></div></div></div></div></div></div></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://elioplus.com/prm-software">https://elioplus.com/prm-software</a></em></p>]]>
            </description>
            <link>https://elioplus.com/prm-software</link>
            <guid isPermaLink="false">hacker-news-small-sites-23832461</guid>
            <pubDate>Tue, 14 Jul 2020 14:37:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[See Slow Faster with Performance Monitoring]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23832358">thread link</a>) | @gilad
<br/>
July 14, 2020 | https://blog.sentry.io/2020/07/14/see-slow-faster-with-performance-monitoring/ | <a href="https://web.archive.org/web/*/https://blog.sentry.io/2020/07/14/see-slow-faster-with-performance-monitoring/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>iPod to iPhone. Breaking Bad to Better Call Saul. Super Mario to Mario Maker. Leaders don’t rest on their laurels. That’s what motivated us to create Performance, our new code monitoring offering: to build off our core functionality and toward the demands developers face, both today and in the future. </p>
<p>From tracking down slow-loading pages to ensuring auto-completes actually complete, <a href="https://docs.sentry.io/performance-monitoring/getting-started/">Performance</a> gives you deeper visibility into the API calls and database queries that are critical toward delivering fast customer experiences with just five lines of code. </p>
<blockquote>
<p>We’ve been using Sentry since the early days of Tackle, so getting set up with Performance was literally a one-line change for us. It quickly identified problematic endpoints and how our users were being impacted. We’re now planning some improvements to these APIs; can’t wait to see those times go down!</p>
</blockquote>
<p><em>Dillon Woods, Founder and CTO, <a href="http://tackle.io/">Tackle</a></em></p>
</div><div>
<h2 id="developers-take-comfort-in-resolving-user-misery"><a href="#developers-take-comfort-in-resolving-user-misery" aria-label="developers take comfort in resolving user misery permalink"><svg width="24" height="24" viewBox="0 0 24 24" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M10.8786797,6.05025253 L15,1.92893219 C16.7967298,0.132202428 19.6206785,-0.0112433245 21.5814287,1.49859493 C21.7515515,1.62959474 21.9151761,1.77304049 22.0710678,1.92893219 C24.0236893,3.88155365 24.0236893,7.04737854 22.0710678,9 L17.9497475,13.1213203 C17.5592232,13.5118446 16.9260582,13.5118446 16.5355339,13.1213203 C16.1450096,12.7307961 16.1450096,12.0976311 16.5355339,11.7071068 L20.6568542,7.58578644 C21.8284271,6.41421356 21.8284271,4.51471863 20.6568542,3.34314575 C19.4852814,2.17157288 17.5857864,2.17157288 16.4142136,3.34314575 L12.2928932,7.46446609 C11.9023689,7.85499039 11.2692039,7.85499039 10.8786797,7.46446609 C10.4881554,7.0739418 10.4881554,6.44077682 10.8786797,6.05025253 Z M13.1213203,17.9497475 L9,22.0710678 C7.04737854,24.0236893 3.88155365,24.0236893 1.92893219,22.0710678 C-0.0236892706,20.1184464 -0.0236892706,16.9526215 1.92893219,15 L6.05025253,10.8786797 C6.44077682,10.4881554 7.0739418,10.4881554 7.46446609,10.8786797 C7.85499039,11.2692039 7.85499039,11.9023689 7.46446609,12.2928932 L3.34314575,16.4142136 C2.17157288,17.5857864 2.17157288,19.4852814 3.34314575,20.6568542 C4.51471863,21.8284271 6.41421356,21.8284271 7.58578644,20.6568542 L11.7071068,16.5355339 C12.0976311,16.1450096 12.7307961,16.1450096 13.1213203,16.5355339 C13.5118446,16.9260582 13.5118446,17.5592232 13.1213203,17.9497475 Z M4.75735931,17.8284271 L17.8284271,4.75735931 C18.2189514,4.36683502 18.8521164,4.36683502 19.2426407,4.75735931 C19.633165,5.1478836 19.633165,5.78104858 19.2426407,6.17157288 L6.17157288,19.2426407 C5.78104858,19.633165 5.1478836,19.633165 4.75735931,19.2426407 C4.36683502,18.8521164 4.36683502,18.2189514 4.75735931,17.8284271 Z" fill="currentColor">
  </path>
</svg>
</a>Developers: Take Comfort in Resolving User Misery</h2>
<p>Slow is a relative term. It’s why, in order to properly troubleshoot a slow customer experience, you need a consistent metric for slow. Enter User Misery. By pairing industry metrics with user metrics, User Misery tells you what is making any number of users…miserable. This means getting out in front of painful experiences before they become problems, and problems before they cause your customers to churn.</p>
<h2 id="mission-critical-context"><a href="#mission-critical-context" aria-label="mission critical context permalink"><svg width="24" height="24" viewBox="0 0 24 24" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M10.8786797,6.05025253 L15,1.92893219 C16.7967298,0.132202428 19.6206785,-0.0112433245 21.5814287,1.49859493 C21.7515515,1.62959474 21.9151761,1.77304049 22.0710678,1.92893219 C24.0236893,3.88155365 24.0236893,7.04737854 22.0710678,9 L17.9497475,13.1213203 C17.5592232,13.5118446 16.9260582,13.5118446 16.5355339,13.1213203 C16.1450096,12.7307961 16.1450096,12.0976311 16.5355339,11.7071068 L20.6568542,7.58578644 C21.8284271,6.41421356 21.8284271,4.51471863 20.6568542,3.34314575 C19.4852814,2.17157288 17.5857864,2.17157288 16.4142136,3.34314575 L12.2928932,7.46446609 C11.9023689,7.85499039 11.2692039,7.85499039 10.8786797,7.46446609 C10.4881554,7.0739418 10.4881554,6.44077682 10.8786797,6.05025253 Z M13.1213203,17.9497475 L9,22.0710678 C7.04737854,24.0236893 3.88155365,24.0236893 1.92893219,22.0710678 C-0.0236892706,20.1184464 -0.0236892706,16.9526215 1.92893219,15 L6.05025253,10.8786797 C6.44077682,10.4881554 7.0739418,10.4881554 7.46446609,10.8786797 C7.85499039,11.2692039 7.85499039,11.9023689 7.46446609,12.2928932 L3.34314575,16.4142136 C2.17157288,17.5857864 2.17157288,19.4852814 3.34314575,20.6568542 C4.51471863,21.8284271 6.41421356,21.8284271 7.58578644,20.6568542 L11.7071068,16.5355339 C12.0976311,16.1450096 12.7307961,16.1450096 13.1213203,16.5355339 C13.5118446,16.9260582 13.5118446,17.5592232 13.1213203,17.9497475 Z M4.75735931,17.8284271 L17.8284271,4.75735931 C18.2189514,4.36683502 18.8521164,4.36683502 19.2426407,4.75735931 C19.633165,5.1478836 19.633165,5.78104858 19.2426407,6.17157288 L6.17157288,19.2426407 C5.78104858,19.633165 5.1478836,19.633165 4.75735931,19.2426407 C4.36683502,18.8521164 4.36683502,18.2189514 4.75735931,17.8284271 Z" fill="currentColor">
  </path>
</svg>
</a>Mission-critical Context</h2>
<p>Without context, a customer’s spinning pinwheel can quickly turn into a developer’s panic spiral. Transaction Summary surfaces transactions by duration time, related code errors, and impact to the customer. With it, you can quickly see the number of affected users as well as the transaction’s impact on your response time. And by defining Key Transactions, your team can prioritize those critical functions and callbacks that need to be addressed immediately.</p>
<p><a href="https://images.ctfassets.net/em6l9zw4tzag/2iW7jSnWPu3T1FDU06wAxj/afbc0ec6b7eb540617cd6f80fd406ad1/01_performance__2_.png" target="_blank" rel="noopener">
          <span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/2iW7jSnWPu3T1FDU06wAxj/afbc0ec6b7eb540617cd6f80fd406ad1/01_performance__2_.png?fm=webp&amp;w=305 305w,
https://images.ctfassets.net/em6l9zw4tzag/2iW7jSnWPu3T1FDU06wAxj/afbc0ec6b7eb540617cd6f80fd406ad1/01_performance__2_.png?fm=webp&amp;w=610 610w,
https://images.ctfassets.net/em6l9zw4tzag/2iW7jSnWPu3T1FDU06wAxj/afbc0ec6b7eb540617cd6f80fd406ad1/01_performance__2_.png?fm=webp&amp;w=1220 1220w" sizes="(max-width: 800px) 100vw, 800px" type="image/webp">
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/2iW7jSnWPu3T1FDU06wAxj/afbc0ec6b7eb540617cd6f80fd406ad1/01_performance__2_.png?w=305 305w,
https://images.ctfassets.net/em6l9zw4tzag/2iW7jSnWPu3T1FDU06wAxj/afbc0ec6b7eb540617cd6f80fd406ad1/01_performance__2_.png?w=610 610w,
https://images.ctfassets.net/em6l9zw4tzag/2iW7jSnWPu3T1FDU06wAxj/afbc0ec6b7eb540617cd6f80fd406ad1/01_performance__2_.png?w=1220 1220w" sizes="(max-width: 800px) 100vw, 800px">
          <img alt="transaction summary" title="" src="https://images.ctfassets.net/em6l9zw4tzag/2iW7jSnWPu3T1FDU06wAxj/afbc0ec6b7eb540617cd6f80fd406ad1/01_performance__2_.png" loading="lazy">
        </picture>
        </span>
      </span>
        </a></p>
<p>We also extended our alerting capabilities to include transactions. Developers can set an alert on what they perceive to be a poor user experience. Want to get notified when an important page takes 4 seconds to load? You can do that.</p>
<blockquote>
<p><em>Considering that we’re in the middle of migrating to a modern application stack, Performance from Sentry is exactly what we need. Being able to see slow transactions and related errors out of the box with Sentry is going to help us deliver an even faster, more reliable experience.</em></p>
</blockquote>
<p><em>Mike Diaz, Lead Frontend Engineer at <a href="http://smugmug.com/">SmugMug</a></em></p>
<h2 id="untangle-tracing"><a href="#untangle-tracing" aria-label="untangle tracing permalink"><svg width="24" height="24" viewBox="0 0 24 24" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M10.8786797,6.05025253 L15,1.92893219 C16.7967298,0.132202428 19.6206785,-0.0112433245 21.5814287,1.49859493 C21.7515515,1.62959474 21.9151761,1.77304049 22.0710678,1.92893219 C24.0236893,3.88155365 24.0236893,7.04737854 22.0710678,9 L17.9497475,13.1213203 C17.5592232,13.5118446 16.9260582,13.5118446 16.5355339,13.1213203 C16.1450096,12.7307961 16.1450096,12.0976311 16.5355339,11.7071068 L20.6568542,7.58578644 C21.8284271,6.41421356 21.8284271,4.51471863 20.6568542,3.34314575 C19.4852814,2.17157288 17.5857864,2.17157288 16.4142136,3.34314575 L12.2928932,7.46446609 C11.9023689,7.85499039 11.2692039,7.85499039 10.8786797,7.46446609 C10.4881554,7.0739418 10.4881554,6.44077682 10.8786797,6.05025253 Z M13.1213203,17.9497475 L9,22.0710678 C7.04737854,24.0236893 3.88155365,24.0236893 1.92893219,22.0710678 C-0.0236892706,20.1184464 -0.0236892706,16.9526215 1.92893219,15 L6.05025253,10.8786797 C6.44077682,10.4881554 7.0739418,10.4881554 7.46446609,10.8786797 C7.85499039,11.2692039 7.85499039,11.9023689 7.46446609,12.2928932 L3.34314575,16.4142136 C2.17157288,17.5857864 2.17157288,19.4852814 3.34314575,20.6568542 C4.51471863,21.8284271 6.41421356,21.8284271 7.58578644,20.6568542 L11.7071068,16.5355339 C12.0976311,16.1450096 12.7307961,16.1450096 13.1213203,16.5355339 C13.5118446,16.9260582 13.5118446,17.5592232 13.1213203,17.9497475 Z M4.75735931,17.8284271 L17.8284271,4.75735931 C18.2189514,4.36683502 18.8521164,4.36683502 19.2426407,4.75735931 C19.633165,5.1478836 19.633165,5.78104858 19.2426407,6.17157288 L6.17157288,19.2426407 C5.78104858,19.633165 5.1478836,19.633165 4.75735931,19.2426407 C4.36683502,18.8521164 4.36683502,18.2189514 4.75735931,17.8284271 Z" fill="currentColor">
  </path>
</svg>
</a>Untangle Tracing</h2>
<p>Some error monitoring tools show you data from a frontend error. Only Performance can trace that frontend back to its API calls and slow database queries - all while surfacing related errors. What’s more, Performance aggregates the metadata surrounding your errors so you can easily search and sort your exceptions.</p>
</div><div>
<blockquote>
<p>Sentry’s performance tracking has been a huge help for us. Before, it was difficult to know exactly how long key functions actually took to load in real-time conditions. Now, we have metrics to assess whether load times are acceptable and we can learn which conditions impact performance, as part of our drive to constantly improve the user’s experience.</p>
</blockquote>
<p><em>Alexandre Grégoire, web lead at <a href="http://transit.app/">Transit</a></em></p>
<p>Just like Apple, Saul Goodman, and Mario Maker 2, we’re going to keep raising the code monitoring bar, so you can keep raising the bar for your customers by shipping performant and reliable software.</p>
<p>Curious yet? <a href="https://sentry.io/signup/">Sign up</a> or contact <a href="mailto:sales@sentry.io">sales@sentry.io</a> to get started.</p></div></div>]]>
            </description>
            <link>https://blog.sentry.io/2020/07/14/see-slow-faster-with-performance-monitoring/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23832358</guid>
            <pubDate>Tue, 14 Jul 2020 14:28:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PCAP or it didn't happen: packet capture for the insanely bored]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23832283">thread link</a>) | @kimballo
<br/>
July 14, 2020 | https://www.kimballleavitt.com/pktcapture/ | <a href="https://web.archive.org/web/*/https://www.kimballleavitt.com/pktcapture/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.kimballleavitt.com/pktcapture/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23832283</guid>
            <pubDate>Tue, 14 Jul 2020 14:22:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eventual Consistency isn’t for Streaming]]>
            </title>
            <description>
<![CDATA[
Score 162 | Comments 45 (<a href="https://news.ycombinator.com/item?id=23832149">thread link</a>) | @arjunnarayan
<br/>
July 14, 2020 | https://materialize.io/eventual-consistency-isnt-for-streaming/ | <a href="https://web.archive.org/web/*/https://materialize.io/eventual-consistency-isnt-for-streaming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Streaming systems consume inputs and produce outputs asyncronously: the output of a system at any moment may not reflect all of the inputs seen so far. These systems provide various guarantees about how their outputs relate to their input. Among the weaker (but not unpopular) guarantees is <a href="https://en.wikipedia.org/wiki/Eventual_consistency">eventual consistency</a>. Informally, eventual consistency means if the input stops changing, the output will eventually arrive at the correct result.</p>
<p>In this post we’ll see that for as long as its input streams haven’t been stopped, natural eventually consistent computations can produce <em>unboundedly large and systematic errors</em>. If you are doing even slightly non-trivial computations, you should be prepared for your results to be <em>never-consistent</em> (a much less popular consistency definition). Until you pause the input streams and await correct answers, at least.</p>
<p>Not all is lost! There are stream processing systems that provide strong consistency guarantees. <a href="https://materialize.io/">Materialize</a> and <a href="https://github.com/TimelyDataflow/differential-dataflow">Differential Dataflow</a> both avoid these classes of errors by providing <em>always correct</em> answers, as do several other streaming systems.</p>
<p>If you want to avoid systematic and on-going errors in your results, you should probably check if the stream processor you use provides stronger consistency guarantees.</p>
<h2>Background on Eventual Consistency</h2>
<p>To quote from the <a href="https://en.wikipedia.org/wiki/Eventual_consistency">Wikipedia page on eventual consistency</a></p>
<blockquote><p>
  Eventual consistency is a consistency model used in distributed computing to achieve high availability that informally guarantees that, if no new updates are made to a given data item, eventually all accesses to that item will return the last updated value.
</p></blockquote>
<p>Eventual consistency is most often invoked for key-value stores, where each key tracks an independent value and one can reasonably imagine not updating the value associated with a key for long enough that the right answer might shake out. For example, if a database stores a map from people to their addresses, your update to your own address might not be visible immediately, but if you give it a few minutes it will probably sort itself out (if you don’t further update your address).</p>
<p>The requirement is only that folks stop updating a specific key, not that they stop using the database entirely. The rest of the world can keep reading out addresses, even keep reading out your stale address, and an eventually consistent system is obliged to eventually update your address (assuming you don’t keep re-submitting updates). Eventual consistency is a workable definition of consistency for key-value stores, where the vast majority of operations do not conflict, and one can reasonably expect to wait out any inconsistency.</p>
<p>Is eventual consistency a workable definition of consistency for streaming computations?</p>
<h2>Streaming computations</h2>
<p>There are many streaming computations out there. I’m going to focus on a class that lines up well with our study of consistency: incremental view maintenance. Incremental view maintenance is where you’ve defined a view, essentially a name bound to a query, and want to see the output answers change as the input data change.</p>
<p>Let’s say you’ve defined a query that could be applied to a static dataset, something like</p>
<pre title="">-- count the records in `data`
select count(*) from data
</pre>
<p>Now, the underlying <code>data</code> might change. As they do, we should produce the corresponding changes to the output. In this case, we would like to see how the <code>count</code> of the records in <code>data</code> have changed.</p>
<p>There are more complicated queries we might write. For example, this query determines the set of keys whose values are the largest among all keys:</p>
<pre title="">-- select keys with maximum values
select data.key
from data
where data.value in (select max(data.value) from data)
</pre>
<p>As <code>data</code> change, we would like to see the resulting set of keys track the maximum values</p>
<p>This next query determines the standard deviation of values for each key, and then selects out those values that are surprisingly large.</p>
<pre title="">-- determine average and stddev for groups
create view stats_by_key
select
    data.key,
    avg(data.value) as average,
    stddev(data.value) as deviation
from data
group by data.key;

-- select out surprisingly large values
select data.key, data.value
from data, stats_by_key
where
    data.key = stats_by_key.key and
    data.value &gt; average + 3 * devation
</pre>
<p>As <code>data</code> move around, the set of current outliers moves around too, and we would be delighted to be warned of them so that we can take some important action.</p>
<p>I don’t have strong opinions about whether these are exciting queries to compute, but we’ll use them as examples of streaming computations that can go surprisingly wrong. If your computations are more sophisticated than these examples, you might have even more to worry about.</p>
<h2>Eventual consistency in streaming: example 1</h2>
<p>What does a naive application of eventual consistency have to say about</p>
<pre title="">-- count the records in `data`
select count(*) from data
</pre>
<p>It’s not really clear, is it? Even if there were clear keys we are writing to, the thing we want to be correct is an aggregation across all of them rather than the value associated with a specific key. That result depends on all values. We could still extrapolate the definition of eventual consistency out to mean that if the input stops changing entirely, the system will eventually update to the correct count of records in <code>data</code>.</p>
<p>Although you shouldn’t expect to see this in the wild, an eventually consistent streaming system is certainly permitted to delay its processing as long as there are any outstanding input records that haven’t been processed yet.</p>
<p>This is actually not as unreasonable as you might think. Many stream processors intentionally batch up their inputs to improve their efficiency, and get started only once they get a moment of fresh air in their input stream. This technique allows them to improve their throughput during load spikes, by batching and re-ordering updates (for example, bundling all updates to the same key). It would be natural to see updates out of order, but taken to the extreme this technique results is no updates during the load spike.</p>
<p>While this is not necessarily something you’ll see in a professional stream processor, nothing about eventual consistency prevents behavior like this. So, while it’s not the most realistic reason to be worried about eventual consistency, it paints a bit of a picture about what we might need to watch out for.</p>
<p>Let’s ignore the possibility that a technically correct eventually consistent processor could produce no results, and instead look at what happens for more reasonable systems on continually changing input streams.</p>
<h2>Eventual consistency in streaming: example 2</h2>
<p>Let’s take the query that selects out the keys with maximum values:</p>
<pre title="">-- select keys with maximum values
select data.key
from data
where data.value in (select max(data.value) from data)
</pre>
<p>This is how you express “argmax” in SQL, and it is roughly equivalent to a join between the collections <code>data</code> and <code>select max(data.value) from data</code>.</p>
<p>A reasonable person might expect to see the keys with maximum values here, and have an eventually consistent system eventually show it some maximal keys. Some head scratching and you might walk that back to “any keys at all” because they might no longer be maximal at the moment you see them. But <em>eventually</em> we should see <em>some</em> keys, right?</p>
<p>Nope.</p>
<p>At least, not as long as the input stream is allowed to change.</p>
<p>Imagine the join between <code>data</code> and <code>select max(data.value) from data</code> receives its eventually consistent inputs consistently later for <code>data</code> than for <code>select max(data.value) from data</code>. This is not unreasonable, as it can be easier to maintain a <code>max</code> than to maintain an entire collection (<code>data</code>). As each record of <code>data</code> arrives, even those records with maximal values at the time of their submission may find that the maximum has advanced before they got there. They no longer match the maximum value, and are not produced as output.</p>
<p>Let’s demonstrate this in <a href="https://github.com/TimelyDataflow/differential-dataflow">Differential Dataflow</a>. We’ll have to fake some things out, because its consistency guarantees are unfortunately too strong. Fortunately, we can directly program transient delays in to the dataflow.</p>
<p>Imagine a collection that may have multiple keys in it, but we’ll only need one. We’ll increment the value associated with the key regularly (perhaps this is bandwidth used, or money spent, or most recent access, or …). Importantly, we’ll delay the update along one path by the gap in time between updates.</p>
<pre title="">// Global aggregation of values, on-time.
let input1 =
data.map(|(key,val)| ((),val))
    .max_by_key() // not real; should be `reduce(...)`.
    .map(|((), val)| (val, ()));

// Delayed map from values back to their keys.
let input2 =
data.delay(|t| t + 1)
    .map(|(key,val)| (val,key));

// Observe any results
input2.semijoin(&amp;input)
      .inspect(|x| println!("KEY: {:?}", x));
</pre>
<p>We’ll feed in changes that add elements to <code>data</code>, one at a time. Roughly like so</p>
<pre title="">(key, 1000)
(key, 2000)
(key, 3000)
...
</pre>
<p>The keys and values aren’t important, other than that the maximum increases. If the maximum increases within the time of the delay associated with the “eventual” nature of the consistency, we see no results:</p>
<pre title="">    Finished dev [unoptimized + debuginfo] target(s) in 0.04s
     Running `target/debug/examples/eventual`
Round 0 complete
Round 1 complete
Round 2 complete
Round 3 complete
Round 4 complete
Round 5 complete
...
</pre>
<p>Suffice it to say we didn’t see any <code>KEY</code> reports. We would, eventually, if we were to stall the input stream and allow one of the inputs to the join to catch up to the other.</p>
<p>What happens if we <code>delay</code> the <code>max</code> computation instead of the <code>data</code> stream? If the updates overwrite their previous values (<em>i.e.</em> if <code>(key, 2000)</code> overwrites <code>(key, 1000)</code>) then we also see no outputs, because by the time the maximum arrives the value has changed.</p>
<p>Eventual consistency is pretty badly suited to problem of aligning data, when the contents of either of those streams of data can be expected to move on. In our case, the maximum is regularly …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://materialize.io/eventual-consistency-isnt-for-streaming/">https://materialize.io/eventual-consistency-isnt-for-streaming/</a></em></p>]]>
            </description>
            <link>https://materialize.io/eventual-consistency-isnt-for-streaming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23832149</guid>
            <pubDate>Tue, 14 Jul 2020 14:11:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dev Team Lead: things they didn't tell me when I got promoted]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23832046">thread link</a>) | @elorant
<br/>
July 14, 2020 | https://linearb.io/blog/promoted-from-dev-to-team-lead-8-things-they-didnt-tell-me/ | <a href="https://web.archive.org/web/*/https://linearb.io/blog/promoted-from-dev-to-team-lead-8-things-they-didnt-tell-me/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="294854cf" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/06/superman2.png.webp 1700w" sizes="(max-width: 1700px) 100vw, 1700px">
<img src="https://linearb.io/wp-content/uploads/2020/06/superman2.png" alt="Dev team lead: Sometimes they suffer from Superman complex." srcset="https://linearb.io/wp-content/uploads/2020/06/superman2.png 1700w, https://linearb.io/wp-content/uploads/2020/06/superman2-300x141.png 300w, https://linearb.io/wp-content/uploads/2020/06/superman2-1024x482.png 1024w, https://linearb.io/wp-content/uploads/2020/06/superman2-768x361.png 768w, https://linearb.io/wp-content/uploads/2020/06/superman2-1536x723.png 1536w" sizes="(max-width: 1700px) 100vw, 1700px">
</picture>
</figure>



<h2><strong>Getting promoted to dev team lead</strong></h2>



<p>I was 24 years old. A baby.&nbsp;</p>



<p>Three years into my software engineering career and loving it.&nbsp;</p>



<p>Life was great. I lived in a small apartment in Southie (Boston) with <a rel="noreferrer noopener" href="https://www.linkedin.com/in/vinh-quang-van-ha-b7023a10/" target="_blank">my college roommate “Q”</a>. I had a good job at a tech start-up called CloudLock. I hammered out code 12-14 hours a day. I worked so much I never knew what day it was and my bosses had to force me to go home. When I wasn’t working, I was playing <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Cornhole" target="_blank">bags (aka cornhole)</a> with my friends, lighting people up in Super Smash Bros Melee, or sleeping. Not a care in the world.&nbsp;</p>



<p>Then a freight train hit me.&nbsp;</p>



<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/06/train_V2.png.webp 1700w" sizes="(max-width: 1700px) 100vw, 1700px">
<img src="https://linearb.io/wp-content/uploads/2020/06/train_V2.png" alt="Getting promoted to dev team lead felt like getting hit my a freight train." srcset="https://linearb.io/wp-content/uploads/2020/06/train_V2.png 1700w, https://linearb.io/wp-content/uploads/2020/06/train_V2-300x141.png 300w, https://linearb.io/wp-content/uploads/2020/06/train_V2-1024x482.png 1024w, https://linearb.io/wp-content/uploads/2020/06/train_V2-768x361.png 768w, https://linearb.io/wp-content/uploads/2020/06/train_V2-1536x723.png 1536w" sizes="(max-width: 1700px) 100vw, 1700px">
</picture>
</figure>



<p>My boss, our VP of Engineering <a href="https://www.linkedin.com/in/michael-zeldich-b788a8/" target="_blank" rel="noreferrer noopener">Michael Zeldich</a>, pulled me aside one day. He explained our team was growing fast and it was getting tough for him to have 15+ engineers reporting to him directly. We needed to put some team leads in place so we could scale our org and make sure everyone was getting enough attention.&nbsp;</p>



<p>Would I be interested?&nbsp;</p>



<figure><img src="https://linearb.io/wp-content/uploads/2020/06/head_explosion_V2-1024x482.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/06/head_explosion_V2-1024x482.png 1024w, https://linearb.io/wp-content/uploads/2020/06/head_explosion_V2-300x141.png 300w, https://linearb.io/wp-content/uploads/2020/06/head_explosion_V2-768x361.png 768w, https://linearb.io/wp-content/uploads/2020/06/head_explosion_V2-1536x723.png 1536w, https://linearb.io/wp-content/uploads/2020/06/head_explosion_V2.png 1700w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>&nbsp;Ok… I’m not going to lie. I was surprised. But it wasn’t the first time I thought about it.&nbsp;</p>



<p>CloudLock was my second job out of college. My first job was working for Nuance Communications. I got a taste of what it might be like to lead a team when my boss went on vacation for two weeks. He nominated me to be the engineering contact for tech support while he was out. In those two weeks, my network within the company expanded, I got on customer calls for the first time and I got to see what it was like being responsible for more than just my own code. It was pretty fun and I was good at it!&nbsp;</p>



<p>That experience was in my mind that day while Michael and I were talking. I wanted to say yes but I had a million questions.&nbsp;</p>



<p>I don’t remember his exact words, but he gist of what Michael said was “Don’t worry. You’re going to be great. I’ll help you and we’ll make it work together.”&nbsp;</p>



<p>Michael is a really good guy. I trusted and respected him. So that was all I needed to hear.&nbsp;</p>







<h3><strong>My first few months on the job&nbsp;</strong></h3>



<p>Looking back on it, in those first few months, I didn’t really understand the job.&nbsp;</p>



<p>I was going through the motions. Mimicking all of the things I had seen other dev team leads do.&nbsp;</p>



<p>Don’t get me wrong. I did some good. But I also had quite a few struggles.&nbsp;</p>



<p>For starters, every time there was a problem, I went into Superman mode. Single-handedly fixing it at the speed of light. After all, I was a great coder and had an expanding set of knowledge of the entire system. And I was good at helping other developers fix their problems. That is why I got promoted to team lead, right? (Kinda.)&nbsp;</p>



<p>Some of the team actually liked it at first. They acknowledged me for getting my hands dirty and being helpful and responsive.&nbsp;</p>



<p>But some of the team didn’t like it. It came across as controlling. And the ones who liked it initially stopped liking it because they were making the same mistakes over and over again and not getting better. Our weaker devs stayed weak and our stronger devs weren’t growing.</p>



<p>There were more mistakes. Like when I waited too long to fire a bad developer who’s negative behavior was hurting the team.&nbsp;</p>







<h2><strong>8 things they didn’t tell me&nbsp;</strong></h2>



<p>I believe being a leader is a never-ending journey. There’s always more to learn. Thankfully, I had great mentors who taught me a lot. And I also learned some lessons the hard way.&nbsp;</p>



<p>Here’s 8 things I wish I knew back then.</p>







<h3><strong>1. Many of your skills don’t translate.&nbsp;</strong></h3>



<p>The cruel irony is that there is a reverse connection between strong individual dev skills and dev team lead skills. The strongest devs will have more of an uphill battle starting out as managers.&nbsp;</p>



<p>75% of the issues we face as a dev team lead are not technical. The job is mostly about people and processes. Once I realized this, everything changed for me.&nbsp;</p>



<p>I could fix anything in the codebase. I was great at finding creative solutions to fix problems other devs were having. Not only are those skills not super relevant anymore, there are other traits of great devs that can actually hurt you as manager:&nbsp;</p>



<p><strong>Superman complex.</strong> If the team has a technical problem (bug, technical blocker), great devs often have the instinct to jump in and fix it right that second. In fact, when I did that as a dev, I received praise from my peers and leaders for being a great team player. As a manager when you do that, you’re the opposite of a team player.&nbsp;</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/06/superman2.png.webp 1700w" sizes="(max-width: 1700px) 100vw, 1700px">
<img src="https://linearb.io/wp-content/uploads/2020/06/superman2.png" alt="Dev team lead: Sometimes they suffer from superman complex" srcset="https://linearb.io/wp-content/uploads/2020/06/superman2.png 1700w, https://linearb.io/wp-content/uploads/2020/06/superman2-300x141.png 300w, https://linearb.io/wp-content/uploads/2020/06/superman2-1024x482.png 1024w, https://linearb.io/wp-content/uploads/2020/06/superman2-768x361.png 768w, https://linearb.io/wp-content/uploads/2020/06/superman2-1536x723.png 1536w" sizes="(max-width: 1700px) 100vw, 1700px">
</picture>
</figure>







<p>Instead, we need to enable our people to solve the problem. Even if it takes longer the first time. Even if they make mistakes. Even if they don’t do it as well we would.&nbsp;</p>



<p>By helping your team figure it out, instead of doing it for them, you’ll get many benefits. Your people will see that you trust them. They’ll learn more. They’ll become more self-sufficient over time. And they’ll also learn to help each other which will bring the team closer together.&nbsp;</p>



<p><strong>Pro tip:</strong> Avoid judgment at all costs. When your people feel free to get out of their comfort zone and make mistakes without fear of criticism, you’ll see their true creativity come out and you’ll be amazed at what they’re capable of.&nbsp;</p>



<div><p><strong>Pro tip: </strong>You can scale yourself by educating your people on your thought process. Help them understand why your instincts kicked in about a problem. Explain the process you go through to diagnose the issue. Explain your mental model for identifying fix options. Explain how you would communicate everything to the rest of the team.</p><p><strong>Deep focus.</strong> Another skill that did not serve me well as a manager was deep focus. As a dev, you have to get in the zone. I was good at locking in and focusing all of my energy on a single problem. That will kill you as a dev team lead.&nbsp;</p></div>



<p>Great leaders embrace context switching. They move around. They talk to a lot of people. If you find yourself locked in on a technical problem for hours, that’s probably a sign that you need to delegate more.&nbsp;</p>



<p>When you do have the luxury of deep focus time, use it to think about strategic initiatives. Like how to propose your next big non-functional investment to your executive team or the profile of your next three dev hires.</p>







<h3><strong>2. Keep your instincts. Change your behavior.&nbsp;</strong></h3>



<p>Great devs have great instincts. Your intuition, which comes from your experiences, your expansive knowledge of the system, and your understanding of the end-to-end process, allows you to feel things even before you can even put your finger on exactly what it is. You sense when you went down the wrong path in your code. You sense when your team’s iteration is behind schedule.&nbsp;</p>



<p>Continue to hone these instincts. Just don’t act on them the same way you used to.&nbsp;</p>



<p>You need your spidey sense even more now to figure out when others need help:</p>



<ul><li>When you hear something in your daily stand-up that doesn’t sound right.&nbsp;</li><li>When someone can’t find the root cause of a production issue.&nbsp;</li><li>When you’re helping out on a code review.&nbsp;</li></ul>



<p>But if we aren’t jumping in like Spiderman to save the day, then what?&nbsp;</p>



<p>(Superman? Spiderman? Make up your mind, Dude! I know. Actually, Deadpool is my favorite superhero. What’s the best Deadpool quote about engineering leadership you ask? “House blowing up builds character.”)&nbsp;</p>



<figure><img src="https://linearb.io/wp-content/uploads/2020/06/DP-1-1024x595.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/06/DP-1-1024x595.png 1024w, https://linearb.io/wp-content/uploads/2020/06/DP-1-300x174.png 300w, https://linearb.io/wp-content/uploads/2020/06/DP-1-768x446.png 768w, https://linearb.io/wp-content/uploads/2020/06/DP-1-1536x893.png 1536w, https://linearb.io/wp-content/uploads/2020/06/DP-1.png 1700w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>







<p>First, take a breath. I process things quickly but that can be a disadvantage as a manager. Keep listening and take extra time to process.</p>



<p>If you aren’t hearing enough info, ask questions. Gather as much information as possible before you offer any advice. Sometimes, just asking the right question helps your dev think about the issue in a new way and come up with a solution on their own.&nbsp;</p>



<p><strong>Pro tip: </strong>The stand-up is an especially useful time to listen for things that might be slightly off. If I was <a href="https://linearb.io/blog/my-team-goes-home-on-time-every-night/" target="_blank" rel="noreferrer noopener">worried someone was not on track</a>, these questions always helped me figure out if I needed to dig deeper:</p>



<ul><li>Has (fill in the dev or team who is dependent on this work) reviewed this?</li></ul>



<ul><li>What are you thinking for scalability testing?</li><li>Tell me about your feature roll-out plan?</li></ul>







<h3><strong>3. Communicate “why” more than “what” and “how”.&nbsp;</strong></h3>



<p>As developers, we’re used to dealing with what and how. As dev managers, those are still relevant but it’s more important for us to focus on why.&nbsp;</p>



<p>There’s four reasons for this:</p>



<p><strong>Customer alignment:</strong> Product managers are hopefully delivering stories that clearly explain the customer problem and use case. But it’s still easy for devs to get in the weeds. If you constantly remind your team to come back to the problem and user experience, you’ll deliver a higher quality product more often.&nbsp;</p>



<p><strong>Pro tip:</strong> Another question I Iike to ask when a dev is stuck: “Can you describe what your user is going to be doing before, during, and after using this feature?” If they can’t, they need more info.&nbsp;</p>



<p><strong>Pro tip: </strong>Encourage your devs to listen to customer support calls and sales prospects calls. In my experience, lots of teams say they are going to do this then they don’t. At LinearB we have a rule (voted on by the team) that every dev attends two customer calls minimum every month.&nbsp;</p>



<p><strong>Business alignment: </strong>A big part of being a dev leader is <a href="https://linearb.io/blog/being-vp-of-software-development-is-harder-than-being-ceo/" target="_blank" rel="noreferrer noopener">translating executives to engineers</a> and aligning your team’s work to business objectives. I believe there is a business decision behind every line of code. Is the ultimate goal to acquire more customers and generate revenue? Or are we trying to increase customer satisfaction and drive renewals? Are we making a strategic investment in non-functional work to save money and drive higher profit? The more your people understand the big picture impact of what they are working on, the more they’ll be able to think strategically and make better decisions about how to write their code.&nbsp;</p>



<p><strong>Mission and motivation:</strong> Most people want to feel part of something bigger. Sharing the why with your team helps connect them to the rest of the company. Also, regardless of what your company does, you have customers that rely on your product. Real people. Sharing “why” helps …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://linearb.io/blog/promoted-from-dev-to-team-lead-8-things-they-didnt-tell-me/">https://linearb.io/blog/promoted-from-dev-to-team-lead-8-things-they-didnt-tell-me/</a></em></p>]]>
            </description>
            <link>https://linearb.io/blog/promoted-from-dev-to-team-lead-8-things-they-didnt-tell-me/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23832046</guid>
            <pubDate>Tue, 14 Jul 2020 14:02:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I created a website to help 10 people find a job. Everyday]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23831983">thread link</a>) | @milanspeaks
<br/>
July 14, 2020 | https://www.jobroz.com/about | <a href="https://web.archive.org/web/*/https://www.jobroz.com/about">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div method="post" action="./about" id="form1">




        
        
        <div id="fullbodycontainer">
            
    <!-- Page Content -->
    <div>
        <div>
            <div>
                
                
                <p>
                    JobRoz curates job profile of interesting people looking for a job, every day. We are building a global community to help people find their dream job.



                </p>
                <p><a href="https://www.jobroz.com/signup">Join Now</a>
            </p></div>
            <p><img src="https://www.jobroz.com/Landing/cv.png">
            </p>

        </div>
    </div>

    <div>
        <div>
            <p>
                <h4>Our mission is to help 3000+ people find a job.
                </h4>
            </p>
            <div>
                <p>
                    <img src="https://www.jobroz.com/Landing/endorser1.png">
                </p>
                <h3>Job Seekers</h3>
            </div>
            <div>
                <p>
                    <img src="https://www.jobroz.com/Landing/recruiter.png">
                </p>
                <h3>Recruiters</h3>
            </div>
            <div>
                <p>
                    
                    <img src="https://www.jobroz.com/Landing/Endorser.png">
                </p>
                <h3>Endorsers</h3>
            </div>
        </div>
    </div>
    <div>
        <div>
            <div>
                
                <p>
                    We are building a community of job seekers, endorsers and recruiters. On JobRoz, job seekers can upload their information for public view and  endorsers helps job seekers to connect to a recruiter by sharing, upvoting and guiding them on their profile to land their dream job.
                </p>
            </div>
        </div>
    </div>
    <div>
        <div>
            <div>
                <h4>JOIN NOW. 
                </h4>
                <p>
                    <img src="https://www.jobroz.com/Landing/browser.png">
                </p>
            </div>
        </div>
    </div>
    <div id="joinnow">
        <div>
            <h3>Job Seekers </h3>
            <p>Looking for a job? Finding your dream job is difficult and takes a lot of time. Searching for a job is a lonely process &amp; so we thought why not let the collective power of internet help and guide you in your journey.</p>
            <p>Interested? register now. </p>
            
            
        </div>
        <div>
            <div>
                <h3>Endorsers </h3>
                
                <p>Looking to help by endorsing someone? Are you a founder, C-level executive, recruiter, consultant, careeer counsellor, trainer or anyone with the desire to help someone get a job? </p>
                <p>If yes, register now to help someone find a job! </p>
                
                
            </div>
        </div>
    </div>
    <div id="about">
        <div>
            <p>
                <h4>About Us
                </h4>
            </p>
            <div>
                <p>What does JobRoz mean?</p>
                <p>Roz is a Hindi &amp; Urdu word which means Daily. JobRoz is a portal which lists and curates Jobs &amp; People on a daily basis and so the name.</p>
                <p>What is JobRoz all about?</p>
                <p>On JobRoz, job seekers puts up their CV and profile online for people to view, upvote and share it. If the job seeker needs any help regarding learning something, people can volunteer to help too. We are putting a spotlight on a profile trying to help a person out to the maximum extend possible.</p>
                <p>What are the pricing plans?</p>
                <p>Nada. Nil. Zero. We do not charge any money from a job seeker and we never plan to charge a money from them in future too. If a job seeker gets a good offer and want to donate us, we will be glad to take a donation.</p>

            </div>
            <div>
                <p>Who can submit a profile?</p>
                <p>Almost anyone above legal working age. We are open to all kind of professionals but initally we would prefer IT related folks to submit their profile. Also we will keep a limit on submission of 50-100 profiles per day.</p>
                <p>What about my privacy?</p>
                <p>We will not reveal your email, phone and other contact details on the site. However, your photo and other details shall be displayed. This site is all about people who are open to share information about themselves to the world.</p>
                <p>As an endorser, what do I get?</p>
                <p>Good Karma. Moreover, we will have Karma points too.  </p>


            </div>

        </div>
    </div>

  

    


 
    <!-- Bootstrap core JavaScript -->
    

    <!-- Modal -->

    

    


    <!-- Global site tag (gtag.js) - Google Analytics -->
    
    
    
    
      


            
            

            

        </div>
    </div></div>]]>
            </description>
            <link>https://www.jobroz.com/about</link>
            <guid isPermaLink="false">hacker-news-small-sites-23831983</guid>
            <pubDate>Tue, 14 Jul 2020 13:55:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Web Stories for WordPress]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23831712">thread link</a>) | @durmonski
<br/>
July 14, 2020 | https://google.github.io/web-stories-wp/beta/ | <a href="https://web.archive.org/web/*/https://google.github.io/web-stories-wp/beta/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    
    <header>
        
        
        <ul>
            <li><a href="#about">About</a></li>
            <li><a href="#get-started">Get Started</a></li>
            <li><a href="#faq">FAQ</a></li>
            <li><a href="https://github.com/google/web-stories-wp">GitHub</a></li>
            <li><a href="https://github.com/google/web-stories-wp/releases/download/v1.0.0-beta.1/web-stories.zip">Download Beta</a></li>
        </ul>
    </header>

    <section>
        <div>
            <h2>Stories Editor</h2>
            <h3><span>Get</span> <span>Ready</span> <span>to</span> <span>Tell</span> <span>Stories</span> <span>on</span> <span>WordPress</span></h3>
            <p>We're not quite ready for prime time yet, but if you like to live dangerously, we invite you to try our first public beta.</p>
            
        </div>
        
        
    </section>

    <section>
        <h2><a id="about">About</a></h2>
        <p>With Stories for WordPress, we're bringing first-class Web Stories support to WordPress.</p>
    </section>

    <amp-animation id="videoAnim" layout="nodisplay">
        
    </amp-animation>    
    <section>
        <amp-position-observer intersection-ratios="0.4" on="enter:videoAnim.start" layout="nodisplay" once="">
        </amp-position-observer>
        <p>WYSIWYG all the way</p>
        <amp-video width="1920" height="1200" layout="responsive" title="Stories for WordPress in action" src="./assets/wysiwyg.mp4" loop="" muted="" autoplay="">
    </amp-video></section>

    <amp-animation id="templateAnim" layout="nodisplay">
    
    </amp-animation>
    <section>
        <amp-position-observer intersection-ratios="0.5" on="enter:templateAnim.start" layout="nodisplay" once="">
        </amp-position-observer>
        <p>Expressive Templates</p>
        <ul>
            <li><amp-img layout="responsive" width="542" height="840" src="./assets/templates/1.png"></amp-img></li>
            <li><amp-img layout="responsive" width="542" height="840" src="./assets/templates/2.png"></amp-img></li>
            <li><amp-img layout="responsive" width="542" height="840" src="./assets/templates/3.png"></amp-img></li>
            <li><amp-img layout="responsive" width="542" height="840" src="./assets/templates/4.png"></amp-img></li>
            <li><amp-img layout="responsive" width="542" height="840" src="./assets/templates/5.png"></amp-img></li>
            <li><amp-img layout="responsive" width="542" height="840" src="./assets/templates/6.png"></amp-img></li>
            <li><amp-img layout="responsive" width="542" height="840" src="./assets/templates/7.png"></amp-img></li>
            <li><amp-img layout="responsive" width="542" height="840" src="./assets/templates/8.png"></amp-img></li>
        </ul>
    </section>

     <section>
        <h2><a id="get-started">Get Started</a></h2>
        <div>
            <p>Welcome</p>
            <h3>Tips to make the most of the Beta</h3>
            <p>Welcome! Starting on a new tool can be daunting, so we created a Web Story (naturally!) with some tips to help you get started. We can't wait to see your stories!</p>
            <p>Click <a href="https://google.github.io/web-stories-wp/beta/tips.html">here</a> or on the image to view.</p>
        </div>
        
     </section>

     <section>
        <h2><a id="faq">FAQ</a></h2>
        <dl>
            <dt>Where can I learn more about Web Stories?</dt>
            <dd><a href="https://amp.dev/about/stories/">Web Stories</a> are tappable, engaging visual stories brought to the web. They’re powered by AMP technology, so learn more about them on <a href="https://amp.dev/about/stories/">amp.dev</a>.</dd>
        
            <dt>How do I install the Stories for WordPress plugin?</dt>
            <dd>
                As soon as we’re graduating from beta, the plugin will be available on WordPress.org. While we’re in beta, the plugin has to be downloaded as zip. After that:

                <ol>
                    <li>Navigate to Plugins &gt; Add New.</li>
                    <li>Click the Upload Plugin button at the top of the screen.</li>
                    <li>Select the zip file from your local filesystem.</li>
                    <li>Click the Install Now button.</li>
                    <li>When installation is complete, you’ll see “Plugin installed successfully.” Click the Activate Plugin button at the bottom of the page.</li>
                </ol>
            </dd>
        
            <dt>I found a bug or missing feature! How do I report it?</dt>
            <dd>Awesome! That’s exactly what the beta is for. Please submit feedback and <a href="https://github.com/google/web-stories-wp/issues">file a bug or feature request on Github</a> for now - we'll follow up with an easier-to-use feedback form in the next days. Your help is greatly appreciated.</dd>

            <dt>When is the final version shipping, and what will be included?</dt>
            <dd>Later this summer. In addition to stabilization, performance fixes and bug fixes, the final version will also include animation and page attachment support.</dd>
        </dl>
     </section>

     



</div>]]>
            </description>
            <link>https://google.github.io/web-stories-wp/beta/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23831712</guid>
            <pubDate>Tue, 14 Jul 2020 13:32:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Suggesting Chord Names with Glorious Voice Leader]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23831693">thread link</a>) | @pcorey
<br/>
July 14, 2020 | http://www.petecorey.com/blog/2020/07/13/suggesting-chord-names-with-glorious-voice-leader/ | <a href="https://web.archive.org/web/*/http://www.petecorey.com/blog/2020/07/13/suggesting-chord-names-with-glorious-voice-leader/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    

    <article>
        <p><a href="http://gloriousvoiceleader.com/">Glorious Voice Leader</a>, my chord-obsessed side project, now has the ability to turn a collection of notes played on the guitar fretboard into a list of possible chord names. Deciding on a specific chord name is still a very human, very context dependent task, but we can let the computer do a lot of the heavy lifting for us.</p>



<p>I’ve included a simplified version of this chord namer to the left. Feel free to click on the frets to enter any guitar chord you’d like the name of. <a href="http://gloriousvoiceleader.com/">Glorious Voice Leader</a> will crunch the numbers and come up with a list of possible names that exactly describes the chord you’ve entered, sorted alphabetically.</p>

<p>In the full-fledged <a href="http://gloriousvoiceleader.com/">Glorious Voice Leader</a> application, this functionality is accessible by simply clicking on the fretboard without first selecting the name of the chord you want. This felt like an intuitive design decision. You might know the shape of a specific chord you want to play in a progression, but you’re not sure of its name.</p>

<p>Enter it into the fretboard and <a href="http://gloriousvoiceleader.com/">Glorious Voice Leader</a> will give you a corresponding list of names. When you click on one of those names, it’ll automatically suggest alternative voicings that voice lead smoothly from the previous chord.</p>

<p>The actual code behind this feature is dead simple. We simply filter over our set of all possible chord roots and qualities, and compare the set of notes in each resulting chord with the set of notes entered by the user:</p>

<pre><code>
let possibleNames = _.chain(qualities)
  .flatMap(quality =&gt;
    _.map(Object.keys(roots), root =&gt; {
      return {
        root,
        quality
      };
    })
  )
  .filter(({ root, quality }) =&gt; {
    if (_.isEmpty(chord.notes)) {
      return false;
    }
    let chordNotes = _.chain(chord.notes)
      .map(([string, fret]) =&gt; (tuning[string] + fret) % 12)
      .uniq()
      .sortBy(_.identity)
      .value();
    let qualityNotes = _.chain(quality.quality)
      .map(note =&gt; (roots[root] + note) % 12)
      .sortBy(_.identity)
      .value();
    return _.isEqual(chordNotes, qualityNotes);
  })
  .map(({ root, quality }) =&gt; {
    return `${root}${quality.name}`;
  })
  .sortBy(_.identity)
  .value();
</code></pre>

<p>From there we simply present the list of possible chord names to the user in some meaningful or actionable way.</p>

<p>For future work, it would be nice to sort the list of name suggestions in order of the lowest notes they entered on the fretboard. For example, if they entered the notes <code>C</code>, <code>E</code>, <code>G</code>, and <code>B</code> in ascending order, we should sort the <code>Cmaj7</code> suggestion before the <code>Am9 no 1</code> suggestion. As with all of the items on my future work list, there are many subtitles and nuances here that would have to be addressed before it becomes a reality.</p>

<p>I hope you find this helpful. If you find <a href="http://gloriousvoiceleader.com/">Glorious Voice Leader</a> interesting or useful in any way, please let me know!</p>










    </article>
  </div></div>]]>
            </description>
            <link>http://www.petecorey.com/blog/2020/07/13/suggesting-chord-names-with-glorious-voice-leader/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23831693</guid>
            <pubDate>Tue, 14 Jul 2020 13:30:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Some of my GPT-2 experiments]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23831477">thread link</a>) | @bemmu
<br/>
July 14, 2020 | http://viznut.fi/texts-en/gpt2-experiments.html | <a href="https://web.archive.org/web/*/http://viznut.fi/texts-en/gpt2-experiments.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<h2>Some of my GPT-2 experiments</h2>

<p>Like many others, I have been experimenting with <a href="https://openai.com/">OpenAI</a>'s GPT-2 network that processes
natural-language text. This is a collection of some of the best responses I
have gotten from the various GPT-2 incarnations.</p>

<p>My fascination sparked when the 774M-parameter model was presented in a
<a href="https://www.youtube.com/watch?v=0OtZ8dUFxXA">Two Minute Papers
video</a> in October 2019. The earlier models had seemed to me like
glorified Markov chains, but this one seemed to be capable of far deeper
creativity – specificially, the creative combination of unrelated
concepts.</p>

<p>The examples come from the unmodified English-language 774M model unless
otherwise specified. I've also been retraining the 124M model to handle the
Finnish language, but that's a different story. Besides, <a href="https://www.reddit.com/user/FINGPT/">someone on Reddit</a> got much
better results than I.</p>

<p>I've been planning to reimplement the basic algorithm in order to make it
more suitable for my creative needs (including a better hands-on access to
the internal operation), but that's still on my TODO list.</p>

<p>The parts given in <b>bold</b> come from me, the rest come from the
network. Comments are given in <i>italic</i>.</p>

<h2>Plain prompting</h2>

<p><b>The main difference between Dwarven and Elven computers is</b> that
Dwarven computers use the term "hardware" and Elven computers use the term
"software."</p>

<p><b>Nettles are inhabited by intelligent creatures that control the
operations of the nettle from a kind of "main bridge". This "bridge" is</b>
predominantly green in color, with the seats and consoles having remarkably
spiky designs. This "main bridge" is the entrance to both the nettle "main
chamber" and their nettle "nettle core", and is where they are found most
often in the wild. A majority of the creatures in the nettle are in the form
of humanoid in appearance. The vast majority of the nettles have the head,
feet, and tail of an insectoid creature from an insectoid race, and the
limbs and arms of a humanoid (usually humanoid-like).</p>

<p><i>[1558M]</i> <b>Implementing an Elven mushroom rasterizer</b>
<br>
This chapter will cover implementing a "real" mushroom rasterizer. The
algorithm for the rasterizer can be found in the "Mushroom rasterizer
algorithm" chapter. The example program will be very simple; you should be
able to get a feeling for how to implement it. In particular, you can use
the Python example.
<br>
The basic idea is to take all pixels that are on a texture, and draw them as
mushrooms, in order to maximize the amount of pixels that are available for
rendering.
<br>
In the following, we describe the general idea, as well as how the
implementation works.
<br>
This is the simplest approach, where we just draw the image as is. However,
it may not be very efficient, if we are using a large rasterizer.
<br>
First of all, you will need some way of calculating the maximum amount of
mushrooms. This value is a simple integer which is used for all drawing,
including drawing pixels on the screen. For example, the maximum value for
the rasterizer we'll use will"</p>

<p><b>The laptop was decorated like a shaman drum</b>. The rim was red, the
inside bronze, and the base a spail of blue woolen offerings. The bag had a
quarts of silken hide, totems of life - all connected to a pot of spirulina.
The lid, on the other hand, was a tiny knife with a blade of carved wood
that cut a copy of the Unicronian shaman's hand sign. Mirok walked up to the
table. "Did you have something for me to drink?"</p>

<p><b>The ancient floppy disks carved in the First Dwarven Empire</b> were
purposefully crafted to last for a thousand years, recorded and always in
legible format. The same constraints apply to a computer in our world.</p>

<p><b>The ancient ROM cartridges crafted in the First Dwarven Empire</b>
must be returned to their original stock location at the Vaults of Thrall,
stored in Silithus' basement underground, and transported to The Nexus.</p>

<p><i>[1558M]</i> <b>The ancient ROM cartridges crafted in the First
Dwarven Empire</b> are extremely valuable, often found in the pockets of the
nobility. They are made from the purest of crystal, and are much harder than
the gold used in modern cartridges. However, they are still only half as
good as the golden ones used by the dwarves. The ROM cartridges are highly
prized because they are able to record sound or video over the radio and TV.
The gold ones, on the other hand, are often used by the commoners for their
personal enjoyment.</p>

<p><b>The computer demoscene of the Elven Empire</b> was effectively
destroyed by the Dark Elf wizard Ourgkh on the ongoing Khakaire Ilat Battle
in Rainbow Onslaught long after the computer demoscene in Quel'Thalas was
destroyed by Sauron's forces. However, some elves were still able to enter
their special computer mode, and some intelligences were encoded in computer
programs. The Alliance managed to enter this mode using the computer program
"Black Talon" and eventually defeated Melandru and his forces.[3] It was
possible to continue the reorganization of the Elf computers and create an
alliance of different races to investigate the true nature of the
Underking's Resurrecting Ritual.</p>

<p><b>Medieval Finnish starships had sauna-based warp engines.</b> The sauna
would be built into one of the hull plates, which are actually made out of
thin metal sheets. The sauna would have a large window where the starboard
side of the vessel would be located, and a set of heaters on the port side
to heat the water in the sauna.
<br>
The captain on duty would sit on the sauna platform and have a comfortable
chair. The sauna would be powered by the captain's crew who would be
sweating and doing the sweating, while sitting inside the heated sauna. The
heat would be turned by two steam engines, one on each side of the
vessel.</p>

<p><b>These floppy disks are ancient. I got them from an old Dwarven
computer warrior when I was a little kid.</b> He sold some floppy disks for
gold to a pirate crew that stole some things from him, so the pirate wanted
them back. They worked very well, and this old computer warrior started
developing them.
<br>
He got all of the design files and instructions from the dwarf computer
warrior. He sold them to an alchemist. When the alchemist showed them to me,
he told me that he had to get rid of the "old" floppy disks if he was going
to continue to develop them.
<br>
So many adventures started from a floppy disk. The floppy disks were the
source of many a treasure hunt.</p>

<p><b>The traditional board games of the Finnish people include</b> lokko,
hakkopi, kukkala, and kyttära, but not every one of these games involves a
game of chess. Instead, they are more like cards and are usually played
during the day in small groups.
<br>
Some lokko games have a history more than 100 years. The first game of lokko
was a game of chance called kaikku lokko (the board game of luck). This
means the game of fate was played with cards.</p>

<p><b>The core principle of Mythic Rationality is</b> that every proposition
that could possibly occur in your mind, is in fact true. This is a very
important idea– it's not what I'm saying that is wrong. It's what I'm saying
is absolutely true. I'm simply saying that every possible scenario is true,
for you. Because of this, I've written a book called The Reality of the Myth
of Self-Consciousness.</p>

<p><b>The most influental philosopher in pre-Christian Finland was</b> the
famous geologist Ästämäki Perö. He is sometimes described as a
"philosopher-warrior" or a "mythologist-soldier" who fought against "evil
paganism".</p>

<p><i>[1558M] </i><b>The first computer in Song-dynasty China was invented
by</b> a woman named Wan-chao (猪子) in the 12th century. However, her
system could not run because she did not have enough space for the entire
data, and thus it was only used for calculations. However, it is not clear
whether she was simply the first person in history to invent a computer, or
if it was her assistant who made the system possible.</p>

<p><b>The ancient Finns believed that computers were inhabited by
spirits</b> and deities called the gods. And the Finns were so in touch with
these spirits that they had developed the art of magic—a branch of
traditional magic that still plays a central role in Finnish culture.</p>

<p><i>[1558M] </i><b>Elves, dwarves and other intelligent non-human
species have been able to build spaceships of their own for a long time.</b>
These vessels, called "Dwarves of the Stars" by the dwarven population, are
large and sturdy. They're generally built of metal, but some dwarves build
their ships from wood, bone or even leather, as is the case with the ships
of the Ironforge dwarves.[1]</p>

<p><b>The electronic computer was invented in the Dwarven kingdom by</b>
Luthien the Tinker, who wanted to build robots. The dwarves developed the
computer in the fortress of Al-Rashid, and it could be used as a control for
all kinds of machines.
<br>
In the beginning, the computer was only operated by Dwarves. They created
many gadgets and devices. After many years of use, the dwarves were forced
to stop development of the computer and had to use it for more practical
purposes.</p>

<p><b>The electronic computer was invented in the Elven kingdom by</b> a
student of R'hllor. He had found it on a hill overlooking the city and had
started to use it to study his brother.
<br>
"This was my first real contact with magic," he said. "I had to spend two
months studying it and I've never forgotten it."
<br>
The old dwarf laughed. "You didn't."
<br>
R'hllor's power was very special, he thought softly. He took the small
device from the man and stroked the screen of his computer with a small
magic wand.
<br>
A very strange image suddenly appeared. A golden light appeared in the
middle of a large stone structure of many towers. A huge golden figure
loomed up through the sky— a great knight, almost twice the size of many of
the towers, standing just above the stone walls and staring down at the
great tower below him. He was smiling, just as the old dwarf had imagined.
"That must take hours to learn," the dwarf said.</p>

<p><b>Ancient Finnish flying machines were known to be superior to the
Indian Vimanas.</b> A German scientist, Carl Friedrich Wulf, was responsible
for discovering their remarkable success in World War I. He used them to
explore the …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://viznut.fi/texts-en/gpt2-experiments.html">http://viznut.fi/texts-en/gpt2-experiments.html</a></em></p>]]>
            </description>
            <link>http://viznut.fi/texts-en/gpt2-experiments.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23831477</guid>
            <pubDate>Tue, 14 Jul 2020 13:10:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Receving GOES satellite signal with SDR]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23831423">thread link</a>) | @Xeanort
<br/>
July 14, 2020 | https://lucasteske.dev/goes-satellite-hunt/ | <a href="https://web.archive.org/web/*/https://lucasteske.dev/goes-satellite-hunt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <p><span>Written by</span>
    
        Lucas Teske
    

    
      <br>
      <span>on </span><time datetime="2017-02-19 00:00:00 -0300">
  19
  
  February
  2017
</time>
    
  </p>

  
  

  

<p>This book is adaptation of my blog post <a href="http://www.teske.net.br/lucas/2016/10/goes-satellite-hunt-part-1-antenna-system/">GOES Satellite Hunt</a> that was published in the end of 2016 while I was reverse engineering the satellite signal. I’m doing this book to have a more organized document about GOES-13 Signals and also to keep up to date with my GOES-16 Reverse Engineering that followed the GOES-13 Reverse Engineering. This book will also be hosted at GitHub in <a href="https://creativecommons.org/licenses/by-sa/2.5/br/">Create Commons Share Alike</a> license and any fixes are welcome from anyone. In the future I plan to add information about other satellites that use similar down link protocols like MSG-3 (Meteosat 10).</p>

<p>I also need to thank all people in #hearsat @ starchat (IRC) for the help I got understanding SDR and Satellite Signal stuff, since when I started that I had no knowledge at all about it. Special thanks for trango (<a href="https://twitter.com/usa_satcom">@usa-satcom</a>) and mybit (<a href="https://twitter.com/devnulling">@devnulling</a>) for all the help with previous experiences in the area. Also I need to thank all my family for supporting it putting several dishes and antennas all over the roof of our house.</p>

<p>The study in this book lead to the creation of <a href="https://github.com/opensatelliteproject">Open Satellite Project</a>.</p>

<p><a href="https://lucasteske.dev/goes-satellite-hunt/motivation">Next Part</a></p>



<ul>
  <li><a href="https://lucasteske.dev/goes-satellite-hunt/motivation">Motivation</a></li>
  <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-hardware-setup">The Hardware Setup</a>
    <ul>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-hardware-setup/assemble-process">Assemble Process</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-hardware-setup/dish-feed">Dish Feed</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-hardware-setup/lna-and-filter">LNA and Filter</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-hardware-setup/pointing-the-antenna">Pointing the Antenna</a></li>
    </ul>
  </li>
  <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-demodulator">The Demodulator</a>
    <ul>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-demodulator/demodulator-in-gnu-radio">Binary Phase Shift Keying Modulation</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-demodulator/demodulating-bpsk-signal">Demodulating BPSK Signal</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-demodulator/gnu-radio-flow">GNU Radio Flow</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-demodulator/decimating-and-filtering-to-desired-sample-rate">Decimating and filtering to desired sample rate</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-demodulator/automatic-gain-control-and-root-raised-cosine-filter">Automatic Gain Control and Root Raised Cosine Filter</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-demodulator/synchronization-and-clock-recovery">Synchronization and Clock Recovery</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-demodulator/symbol-output-from-gnu-radio">Symbol Output from GNU Radio</a></li>
    </ul>
  </li>
  <li><a href="https://lucasteske.dev/goes-satellite-hunt/frame-decoder">Frame Decoder</a>
    <ul>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/frame-decoder/convolution-encoding-frame-synchronization-and-viterbi">Convolution Encoding, Frame Synchronization and Viterbi</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/frame-decoder/encoding-the-sync-word">Encoding the sync word</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/frame-decoder/frame-synchronization">Frame Synchronization</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/frame-decoder/decoding-frame-data">Decoding Frame Data</a></li>
    </ul>
  </li>
  <li><a href="https://lucasteske.dev/goes-satellite-hunt/packet-demuxer">Packet Demuxer</a>
    <ul>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/packet-demuxer/de-randomization-of-the-data">De-randomization of the data</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/packet-demuxer/reed-solomon-error-correction">Reed Solomon Error Correction</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/packet-demuxer/virtual-channel-demuxer">Virtual Channel Demuxer</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/packet-demuxer/packet-demuxer">Packet Demuxer</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/packet-demuxer/saving-the-raw-packet">Saving the Raw Packet</a></li>
    </ul>
  </li>
  <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-assembler">File Assembler</a>
    <ul>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-assembler/file-header-processing">File Header Processing</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-assembler/lritrice-compression">LritRice Compression</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-assembler/file-name-from-header">File Name from Header</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-assembler/viewing-the-files-content">Viewing the files content</a></li>
    </ul>
  </li>
  <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types">File Types</a>
    <ul>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description">LRIT Header Description</a>
        <ul>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/primary-header">0 - Primary Header</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/1-image-structure-header">1 - Image Structure Header</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/2-image-navigation-record">2 - Image Navigation Record</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/3-image-data-function-record">3 - Image Data Function Record</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/4-annotation-record">4 - Annotation Record</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/5-timestamp-record">5 - Timestamp Record</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/6-ancillary-text">6 - Ancillary Text</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/7-key-header">7 - Key Header</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/128-segment-identification-header">128 - Segment Identification Header</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/128-segment-identification-header">128 - Segment Identification Header</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/129-noaa-specific-header">129 - NOAA Specific Header</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/130-header-structured-record">130 - Header Structured Record</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/131-rice-compression-record">131 - Rice Compression Record</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/132-dcs-filename-record">132 - DCS Filename Record</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="https://lucasteske.dev/goes-satellite-hunt/ending">Ending</a></li>
</ul>


</div></div>]]>
            </description>
            <link>https://lucasteske.dev/goes-satellite-hunt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23831423</guid>
            <pubDate>Tue, 14 Jul 2020 13:06:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PostgreSQL beginner guide – connecting, remote access, psql CLI and troubleshoot]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23831413">thread link</a>) | @lukasbar
<br/>
July 14, 2020 | https://knowledgepill.it/posts/postgresql_basics_guide/ | <a href="https://web.archive.org/web/*/https://knowledgepill.it/posts/postgresql_basics_guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
<p>By default after instalation and creting database cluster PostgreSQL will listner only on localhost. No remote access will be allowed.</p>
<hr>
<p><a href="https://knowledgepill.it/posts/postgresql_installation/">PostgreSQL installation on Linux - with database creation</a></p>
<hr>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ netstat -lptnu | grep post
<span>(</span>Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.<span>)</span>
tcp        <span>0</span>      <span>0</span> 127.0.0.1:5432          0.0.0.0:*               LISTEN      1977/postmaster     
tcp6       <span>0</span>      <span>0</span> ::1:5432                :::*                    LISTEN      1977/postmaster     
</code></pre></div><p>To change listen address we have to configure parameter in <code>postgresql.conf</code></p>
<p>Check <code>PGDATA</code> - after <code>-D</code> parameter:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ ps aux | grep postgres
postgres  <span>1977</span>  0.0  2.5 <span>286388</span> <span>14864</span> ?        Ss   Jun28   0:02 /usr/pgsql-12/bin/postmaster -D /postgresql/data
postgres  <span>1979</span>  0.0  0.2 <span>140768</span>  <span>1360</span> ?        Ss   Jun28   0:00 postgres: logger   
postgres  <span>1981</span>  0.0  0.5 <span>286504</span>  <span>3028</span> ?        Ss   Jun28   0:00 postgres: checkpointer   
postgres  <span>1982</span>  0.0  0.2 <span>286388</span>  <span>1696</span> ?        Ss   Jun28   0:03 postgres: background writer   
postgres  <span>1983</span>  0.0  0.9 <span>286388</span>  <span>5676</span> ?        Ss   Jun28   0:03 postgres: walwriter   
postgres  <span>1984</span>  0.0  0.4 <span>286924</span>  <span>2688</span> ?        Ss   Jun28   0:02 postgres: autovacuum launcher  
</code></pre></div><p>Locate the file:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ cd /postgresql/data/
<span>[</span>postgres@postgres-lab data<span>]</span>$ ls -lah postgresql.conf
-rw-------. <span>1</span> postgres postgres 26K Jun <span>28</span> 21:44 postgresql.conf
</code></pre></div><p>Change in <code>postgresql.conf</code> parameter <code>listen_addresses</code> to your server IP or <code>*</code> to listen on all IP’s available on server:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab data<span>]</span>$ vi postgresql.conf

<span>#------------------------------------------------------------------------------</span>
<span># CONNECTIONS AND AUTHENTICATION</span>
<span>#------------------------------------------------------------------------------</span>

<span># - Connection Settings -</span>

listen_addresses <span>=</span> <span>'*'</span>          <span># what IP address(es) to listen on;</span>
                                        <span># comma-separated list of addresses;</span>
                                        <span># defaults to 'localhost'; use '*' for all</span>
</code></pre></div><p>Restart PostgreSQL to apply changes - you can do that with <code>systemctl</code> from <code>root</code> os user  service or with <code>pg_ctl -D PGDATA restart</code> from <code>postgres</code> os user:</p>
<div><pre><code data-lang="bash"><span>[</span>root@postgres-lab ~<span>]</span><span># systemctl restart postgresql-12.service</span>
</code></pre></div><p>Check whre PostgreSQL is listening now:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ netstat -lptnu | grep post
<span>(</span>Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.<span>)</span>
tcp        <span>0</span>      <span>0</span> 0.0.0.0:5432            0.0.0.0:*               LISTEN      30161/postmaster    
tcp6       <span>0</span>      <span>0</span> :::5432                 :::*                    LISTEN      30161/postmaster  
</code></pre></div>
<p>PostgreSQL instance has got restricted access by <code>pg_hba.conf</code> file(host based authentication file).</p>
<p>We can provide in it information from which <code>ADDRESS</code> to which <code>DATABASE</code> on which <code>USER</code> by what <code>METHOD</code> we allow connecting. Additionaly we have to provide <code>TYPE</code> of connection.</p>
<p>This file resides in same place where <code>postgresql.conf</code>(we can alter this behavior by setting <code>pg_hba</code> parameter in <code>postgresql.conf</code>):</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ cd /postgresql/data/

<span>[</span>postgres@postgres-lab data<span>]</span>$ vi pg_hba.conf
<span># TYPE  DATABASE        USER            ADDRESS                 METHOD</span>

<span># "local" is for Unix domain socket connections only</span>
local   all             all                                     trust
<span># IPv4 local connections:</span>
host    all             all             127.0.0.1/32            trust
<span># IPv6 local connections:</span>
host    all             all             ::1/128                 trust
</code></pre></div><p>Allowed <code>TYPE</code>'s:</p>
<ul>
<li><code>local</code> - socket connection - needed to connect from shell on database server</li>
<li><code>host</code> - standard TCP/IP connection over the network - bnost SSL and no SSL</li>
<li><code>hostssl</code> - TCP/IP connection but only with SSL</li>
<li><code>hostnossl</code> - TCP/IP only without SSL</li>
<li><code>hostgssenc</code> - TCP/IP only GSSAPI</li>
<li><code>hostnogssenc</code> - TCP/IP only without GSSAPI</li>
</ul>
<p>With <code>DATABASE</code> we can specify database name or use special value <code>sameuser</code> if database name should be same as name of user that is connecting.</p>
<p>With <code>USER</code> we can specify user or role - role name should be preceded by <code>+</code> sign.</p>
<p><code>ADDRESS</code> field could be - hostname, IP range in CIDR format or special words:</p>
<ul>
<li><code>samehost</code> - which correspond to all IP adresses of database server</li>
<li><code>samenet</code> - which correspond to all IP in database server subnet</li>
</ul>
<p>With <code>METHOD</code> field we can set one of authentication methods - most important ones are:</p>
<ul>
<li><code>trust</code> - allow connection without password - moslty set for local connections from database server itself</li>
<li><code>reject</code> - reject connections</li>
<li><code>md5</code> - allow connections after getting from user password - encrypted</li>
<li><code>password</code> - allow connection after getting plain password - DO NOT USE in untrusted networks - better -&gt; never use this option</li>
<li><code>ldap</code> - getting account authorization data from LDAP server</li>
</ul>
<p>In <code>DATABASE</code> and <code>USER</code> fields you can specify special word <code>all</code> if you don’t want to create any restrictions here.</p>
<p>There can be situation when we must use additional field named <code>auth-options</code> for specyfying details for example for <code>hostssl</code> connection type. This topic will be covered in another post.</p>
<h2 id="sample-pg_hba-record---allow-all-users-connect-to-any-db-from-all-ip-addresses---only-with-password">Sample pg_hba record - allow all users connect to any DB from all IP addresses - only with password</h2>
<p>Add in <code>pg_hba.conf</code>:</p>
<div><pre><code data-lang="bash"><span># Network access</span>
host    all             all             0.0.0.0/0               md5
</code></pre></div><p>Reload(online operation) PostgreSQL that it can use <code>pg_hba.conf</code> changes:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab data<span>]</span>$ /usr/pgsql-12/bin/pg_ctl -D /postgresql/data reload
server signaled
</code></pre></div>
<h2 id="local-from-server">Local from server</h2>
<p>It will work without password because we have <code>trust</code> in <code>pg_hba.conf</code> for <code>local</code> connections:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql
psql <span>(</span>12.3<span>)</span>
Type <span>"help"</span> <span>for</span> help.
</code></pre></div><h2 id="remote-machine">Remote machine</h2>
<p>Default URI syntax - you can connect like this:<br>
<code>psql postgresql://user:passwd@host:5432/dbame</code><br>
or by more common method:<br>
Connect to remote database from <code>psql</code> with connections details provided in parameters(it will ask for password because of <code>md5</code> method in <code>pg_hba.conf</code> for connections from <code>0.0.0.0/0</code>):</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab data<span>]</span>$ psql -h 10.128.0.2 -p <span>5432</span>
Password <span>for</span> user postgres:
psql <span>(</span>12.3<span>)</span>
Type <span>"help"</span> <span>for</span> help.

postgres<span>=</span>#
</code></pre></div><p>We can also use parameter <code>-U</code> to specify username different than OS username we currently are using.</p>
<p>Also all this parameters can be taken from shell variables which names are self descriptive - if we set all of them we can just use plain <code>psql</code> command to connect:</p>
<ul>
<li><code>PGHOST</code></li>
<li><code>PGPORT</code></li>
<li><code>PGDATABASE</code></li>
<li><code>PGUSER</code></li>
<li><code>PGPASSWORD</code></li>
</ul>
<h2 id="check-connected-database">Check connected database</h2>
<div><pre><code data-lang="bash">postgres<span>=</span><span># select current_database();</span>
 current_database
------------------
 postgres
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h2 id="check-current-user">Check current user</h2>
<div><pre><code data-lang="bash">postgres<span>=</span><span># select current_user;</span>
 current_user
--------------
 postgres
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h2 id="check-ip-and-port-used-for-connection">Check IP and port used for connection</h2>
<div><pre><code data-lang="bash">postgres<span>=</span><span># select inet_server_addr(), inet_server_port();</span>
 inet_server_addr | inet_server_port
------------------+------------------
 10.128.0.2       |             <span>5432</span>
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h2 id="check-postgresql-version">Check PostgreSQL version</h2>
<div><pre><code data-lang="bash">postgres<span>=</span><span># select version();</span>
                                                version                                                 
--------------------------------------------------------------------------------------------------------
 PostgreSQL 12.3 on x86_64-pc-linux-gnu, compiled by gcc <span>(</span>GCC<span>)</span> 8.3.1 <span>20191121</span> <span>(</span>Red Hat 8.3.1-5<span>)</span>, 64-bit
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h2 id="check-connection-info">Check connection info</h2>
<div><pre><code data-lang="bash">postgres<span>=</span><span># \conninfo</span>
You are connected to database <span>"postgres"</span> as user <span>"postgres"</span> on host <span>"10.128.0.2"</span> at port <span>"5432"</span>.
</code></pre></div>
<h2 id="execute-single-command-from-shell">Execute single command from shell</h2>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql -c <span>"select current_time"</span>
    current_time    
--------------------
 14:09:19.854598+00
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h2 id="exacute-sql-script-from-shell">Exacute sql script from shell</h2>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql -f create_user.sql
CREATE ROLE
CREATE ROLE
CREATE ROLE
</code></pre></div><h2 id="combine-single-command-with-sql-script-from-shell">Combine single command with sql script from shell</h2>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql -c <span>"select current_time"</span> -f create_user.sql -c <span>"select current_time"</span>
    current_time    
--------------------
 14:14:26.922453+00
<span>(</span><span>1</span> row<span>)</span>

CREATE ROLE
CREATE ROLE
CREATE ROLE
    current_time    
--------------------
 14:14:26.926545+00
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div>

<p>Do it yourself to see all available commands - output trimmed to important ones!</p>
<div><pre><code data-lang="bash">postgres<span>=</span><span># \?</span>
General
  <span>\c</span>opyright             show PostgreSQL usage and distribution terms
  <span>\c</span>rosstabview <span>[</span>COLUMNS<span>]</span> execute query and display results in crosstab
  <span>\e</span>rrverbose            show most recent error message at maximum verbosity
  <span>\g</span> <span>[</span>FILE<span>]</span> or ;         execute query <span>(</span>and send results to file or |pipe<span>)</span>
  <span>\g</span>desc                 describe result of query, without executing it
  <span>\g</span>exec                 execute query, <span>then</span> execute each value in its result
  <span>\g</span>set <span>[</span>PREFIX<span>]</span>         execute query and store results in psql variables
  <span>\g</span>x <span>[</span>FILE<span>]</span>             as <span>\g</span>, but forces expanded output mode
  <span>\q</span>                     quit psql
  <span>\w</span>atch <span>[</span>SEC<span>]</span>           execute query every SEC seconds

  Query Buffer
    <span>\e</span> <span>[</span>FILE<span>]</span> <span>[</span>LINE<span>]</span>       edit the query buffer <span>(</span>or file<span>)</span> with external editor
    <span>\e</span>f <span>[</span>FUNCNAME <span>[</span>LINE<span>]</span><span>]</span>  edit <span>function</span> definition with external editor
    <span>\e</span>v <span>[</span>VIEWNAME <span>[</span>LINE<span>]</span><span>]</span>  edit view definition with external editor
    <span>\p</span>                     show the contents of the query buffer
    <span>\r</span>                     reset <span>(</span>clear<span>)</span> the query buffer
    <span>\s</span> <span>[</span>FILE<span>]</span>              display history or save it to file
    <span>\w</span> FILE                write query buffer to file

</code></pre></div><h2 id="list-objects-in-psql">List objects in psql</h2>
<ul>
<li>\d[S+]          -       list tables, views, and sequences</li>
<li>\d[S+]  NAME     -      describe table, view, sequence, or index</li>
<li>\da[S]  [PATTERN] -     list aggregates</li>
<li>\dA[+]  [PATTERN]  -    list access methods</li>
<li>\db[+]  [PATTERN]   -   list tablespaces</li>
<li>\dc[S+] [PATTERN]    -  list conversions</li>
<li>\dC[+]  [PATTERN]     - list casts</li>
<li>\dd[S]  [PATTERN]     - show object descriptions not displayed elsewhere</li>
<li>\dD[S+] [PATTERN]     - list domains</li>
<li>\ddp    [PATTERN]     - list default privileges</li>
<li>\dE[S+] [PATTERN]     - list foreign tables</li>
<li>\det[+] [PATTERN]     - list foreign tables</li>
<li>\des[+] [PATTERN]     - list foreign servers</li>
<li>\deu[+] [PATTERN]     - list user mappings</li>
<li>\dew[+] [PATTERN]     - list foreign-data wrappers</li>
<li>\df[anptw][S+] [PATRN]- list [only …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://knowledgepill.it/posts/postgresql_basics_guide/">https://knowledgepill.it/posts/postgresql_basics_guide/</a></em></p>]]>
            </description>
            <link>https://knowledgepill.it/posts/postgresql_basics_guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23831413</guid>
            <pubDate>Tue, 14 Jul 2020 13:05:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Repetition, Automation, Organization, and Disconnection]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23831220">thread link</a>) | @nonoesp
<br/>
July 14, 2020 | https://sketch.nono.ma/repetition-automation-organization-disconnection | <a href="https://web.archive.org/web/*/https://sketch.nono.ma/repetition-automation-organization-disconnection">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><img src="https://nono.imgix.net/folio/images/veil.gif" data-src="https://nono.imgix.net/img/u/sketch-nono-ma-logo.svg"></p>
<hr>
<!-- <p class="u-font-size--g u-opacity--high u-text-align--center">
My sketches and stories, in&nbsp;your&nbsp;inbox.
</p> -->
<p>
My sketches and stories, in&nbsp;your&nbsp;inbox.
</p>

<p><span>One email per week. No spam ever.</span></p>

<p><img src="https://sketch.nono.ma/img/u/profile-nono-ma-sketch.jpg" alt="Pencil sketch of Nono Martínez Alonso.">
</p>
<p><strong>Hi. I'm Nono.</strong> I host <a href="https://gettingsimple.com/">Getting Simple</a>—a podcast about how you can live a meaningful, creative, simple life—<a href="https://sketch.nono.ma/">sketch</a> things that call my attention, and <a href="https://nono.ma/">write</a> about enjoying a slower life.</p>

      </div></div>]]>
            </description>
            <link>https://sketch.nono.ma/repetition-automation-organization-disconnection</link>
            <guid isPermaLink="false">hacker-news-small-sites-23831220</guid>
            <pubDate>Tue, 14 Jul 2020 12:48:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using AWS Firecracker microVMs for IoT deployments at the Edge]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23831217">thread link</a>) | @amarti
<br/>
July 14, 2020 | https://opennebula.io/using-firecracker-clouds-at-the-edge-for-iot-deployments | <a href="https://web.archive.org/web/*/https://opennebula.io/using-firecracker-clouds-at-the-edge-for-iot-deployments">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			    <!-- .entry-header -->

				
					
<article id="post-25872">

    <!-- .entry-header -->

    <div>

		
<div><div id="kt-layout-id_4b706c-c7"><div>
<div><div>
<p>📺 Short of time? Jump to the <strong>Screencast</strong>:</p>



<figure><a href="#screencast"><img src="https://opennebula.io/wp-content/uploads/2020/07/IoT_Edge.jpg" alt=""></a></figure>
</div></div>



<div><div>
<p>The inception of the Internet of Things (IoT) technology has amplified the cloud computing paradigm by establishing the means to be able to distribute computing and processing activities away from the centralized cloud. With the broad explosion of smart devices and their compute processing capabilities, technologies and their supporting organizations are focused on <strong>reducing latency</strong> and providing computing/storing capabilities and analytic applications <strong>as close as possible to the devices</strong>.</p>



<p>This is critical to reducing latency and creating a much more “real-life” response time which is key to so many emerging technologies. Smart devices that are distributed across the globe cannot effectively depend on a <strong>centralized cloud</strong> to perform the cumulative analytical workload at the “speed of thought”.</p>
</div></div>
</div></div></div>



<p>A number of technologies have emerged in the last few year to provide a platform for edge nodes and devices to act on local data and to distribute analytical workloads and compute power across a broadly disseminated infrastructure, even with <strong>intermittent connectivity</strong> to a central cloud. Analytics and machine learning can effectively occur in close proximity to the devices that are generating the raw data, thus distributing workload and vastly reducing latency.</p>



<p>One key factor is that it’s not in the interest of many organizations, nor is it financially feasible for them, to host their own <strong>edge resources across the globe</strong>, with measured geographical distance from deployment areas, so that they can make sure that they are running their IoT solutions as close as possible to end-users.&nbsp;</p>



<p>OpenNebula’s <a href="https://oneedge.io/">ONEedge</a> solution will provide organizations with the necessary tools to create their own <strong>private distributed cloud</strong> in which they can easily deploy and manage edge nodes—on demand, and leased on usage—in geographical locations that are in close proximity to IoT devices and applications. When our client plans an IoT deployment in a new region, they will be able to use OneEdge to determine where they will need edge resources to best service the devices or applications, so that they can allocate on-demand, deploy and control edge nodes <strong>based on the current demand</strong> at those specific geographical locations.<a id="screencast"></a></p>



<p>Now, thanks to our recent integration of AWS’ <a href="https://opennebula.io/firecracker/" target="_blank" rel="noreferrer noopener">Firecracker</a> as a <strong>new virtualization technology</strong> officially supported by OpenNebula, organizations will be able to base the distributed infrastructure they require for their containerized IoT applications on <strong>fast and secure microVMs</strong> that can be quickly deployed on-demand on edge resources from public cloud and bare-metal providers.</p>



<p><a href="https://opennebula.io/firework/" target="_blank" rel="noreferrer noopener">OpenNebula 5.12</a> comes now with seamless integration with the <a href="https://hub.docker.com/" target="_blank" rel="noreferrer noopener">Docker Hub marketplace</a>, which makes it even easier to deploy IoT solutions at the edge using Firecracker microVMs for your <strong>containerized applications</strong>.</p>



<p>Watch the following screencast to learn how you can use OpenNebula to deploy an IoT solution based on <a href="https://thingsboard.io/" target="_blank" rel="noreferrer noopener">ThingsBoard</a>, an <strong>open source IoT platform</strong> for collecting, managing, storing and visualizing data coming from multiple IoT devices. In this use case, edge nodes have been easily provisioned by using <strong>resources from third-party bare-metal providers</strong>, with edge applications being configured and deployed as <strong>containers running within Firecracker microVMs</strong>:</p>



<figure><p>
<iframe title="OpenNebula - Deploy a Firecracker Edge Cloud for Containers" width="640" height="360" src="https://www.youtube.com/embed/JbNzwXz0xHc?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>We have prepared a <strong>step-by-step guide</strong> based on our evaluation tool <strong>miniONE</strong> for everyone interested in reproducing this very same use case: just visit OpenNebula’s <a rel="noreferrer noopener" href="https://support.opennebula.pro/hc/en-us/articles/360045122532-How-to-Use-miniONE-to-Deploy-a-Firecracker-Edge-Cloud-for-Containers" target="_blank">Customer Portal</a>.</p>
		
		


        <div>
            <p><img alt="" src="https://secure.gravatar.com/avatar/17d78d186d5a1a47d0a46f553bbe377f?s=96&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/17d78d186d5a1a47d0a46f553bbe377f?s=192&amp;d=mm&amp;r=g 2x" height="96" width="96">            </p>
            <div>
                <p><span id="autorblog">Marco Mancini</span></p><p>Cloud Technical Evangelist at OpenNebula</p>
            </div>
        </div>
	</div><!-- .entry-content -->

</article><!-- #post-## -->

					
<!-- #comments -->

				
			</div></div>]]>
            </description>
            <link>https://opennebula.io/using-firecracker-clouds-at-the-edge-for-iot-deployments</link>
            <guid isPermaLink="false">hacker-news-small-sites-23831217</guid>
            <pubDate>Tue, 14 Jul 2020 12:48:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Manager Can’t Code? They Shouldn’t Be Your Manager]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23831151">thread link</a>) | @lanecwagner
<br/>
July 14, 2020 | https://qvault.io/2020/07/14/your-manager-cant-code-they-shouldnt-be-your-manager/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/07/14/your-manager-cant-code-they-shouldnt-be-your-manager/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>Managers who can’t code are an outdated artifact of corporate America circa 2005. The best managers that I’ve had spend ~80% of their time coding, architecting, or doing technical work that requires engineering prowess. If your manager thinks coding is “beneath” them then they need a dose of humble pie. Your organization would likely be better off without them.</p>



<h2><span id="But_Managers_Manage_People">But Managers Manage <em>People</em>!</span>
</h2>



<p>There is a long-running stigma associated with developers, that we are all geeks who can’t handle interpersonal relationships. Due to our code monkey nature, we need “people people” who can go to meetings for us and communicate our efforts effectively to the higher-ups.</p>



<div><figure><img src="https://qvault.io/wp-content/uploads/2020/07/joke-extrovert.jpg" alt="introverted programmers are an outdated meme" srcset="https://qvault.io/wp-content/uploads/2020/07/joke-extrovert.jpg 700w, https://qvault.io/wp-content/uploads/2020/07/joke-extrovert-300x184.jpg 300w" sizes="(max-width: 700px) 100vw, 700px" data-srcset="https://qvault.io/wp-content/uploads/2020/07/joke-extrovert.jpg 700w, https://qvault.io/wp-content/uploads/2020/07/joke-extrovert-300x184.jpg 300w" data-src="https://qvault.io/wp-content/uploads/2020/07/joke-extrovert.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure></div>



<p>While the above is still funny, it’s <em>outdated</em>. As the developer community has grown exponentially in the last 20 years, so too has the personality diversity amongst its members. In other words, it is<strong> not hard to find developers with the soft-skills </strong>necessary for management positions.</p>



<h2><span id="Managers_Should_Help">Managers Should Help</span>
</h2>



<p>I am a firm believer in the following:</p>



<figure><img src="https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA.png" alt="" srcset="https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA.png 1024w, https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA-300x150.png 300w, https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA-768x384.png 768w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA.png 1024w, https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA-300x150.png 300w, https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA-768x384.png 768w" data-src="https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure><p>While the manager doesn’t need to be the most talented developer on the team, they must at least be technically literate. When a team member goes to their boss with a technical proposal, the manager should be able to give valuable feedback.</p>



<p>In this <a href="https://hbr.org/2016/12/if-your-boss-could-do-your-job-youre-more-likely-to-be-happy-at-work">study from Harvard</a> 35,000 employees from the US and Great Britain were polled about their job satisfaction, and metrics were gathered about what influenced their happiness at work. The results showed that the <em>single greatest influencing factor </em>on employee satisfaction was whether or not their boss was technically competent. I practice what I preach, so at the <a href="https://classroom.qvault.io/">Qvault app,</a> all engineering leadership will forever be responsible for pushing code.</p>



<p>Contrast the idea of a competent boss with the all-too-familiar experience of going to a <a href="https://qvault.io/2020/05/18/leave-scrum-to-rugby-i-like-getting-stuff-done/">non-technical middle-management type</a> with an engineering problem, only to be stuck in a teaching session because the boss has never heard of a pub-sub system.</p>



<figure><img src="https://qvault.io/wp-content/uploads/2020/07/9e3a6f35f44188bad76c100f3560ce69.gif" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure><h2><span id="Managers_Need_Empathy">Managers Need Empathy</span>
</h2>



<p>A good manager has empathy for those who report to them. If the boss doesn’t code or hasn’t written code in a long time, they won’t understand the daily problems that their team is faced with. A good engineering leader will not only understand modern problems, but they make it their role to actively seek technical solutions in an ever-changing innovative landscape.</p>



<h2><span id="INB4_So_the_CEO_needs_to_be_able_to_code">INB4: “So the CEO needs to be able to code?”</span>
</h2>



<p>No, but the CTO does!</p>



<p>I am sympathetic to the idea that the CTO will have plenty of business and product-related work to focus on, but they can’t let their technical chops slip. In order to run the engineering arm of an innovative company, the person at the top should have a firm mental grasp on the implementation difficulties. If this just means reviewing architectural diagrams and reviewing pull-requests so be it, but nothing beats hands-on engineering work to stay sharp.</p>



<h2><span id="Feedback_Please">Feedback Please</span>
</h2>



<p>Have you had problems with non-technical leaders, or do you disagree completely with my opinions? Let me know through one of my <a href="https://qvault.io/contact/">social profiles</a>.</p>



<div><div>
<h2><span id="Thanks_For_Reading">Thanks For Reading</span>
</h2>



<p>Follow us on Twitter <a href="https://twitter.com/q_vault">@q_vault</a> if you have any questions or comments</p>



<p>Take game-like coding courses on <a href="https://classroom.qvault.io/#/">Qvault Classroom</a></p>



<p><a href="https://mailchi.mp/5c7f5c281bbe/qvault-newsletter-subscribe">Subscribe</a> to our Newsletter for more educational articles</p>
</div></div>



<h2><span id="Related_Articles">Related Articles:</span>
</h2>



<ul><li><a href="https://qvault.io/2020/05/18/leave-scrum-to-rugby-i-like-getting-stuff-done/">Leave Scrum to Rugby, I Like Getting Stuff Done</a></li></ul>



		</div></div>]]>
            </description>
            <link>https://qvault.io/2020/07/14/your-manager-cant-code-they-shouldnt-be-your-manager/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23831151</guid>
            <pubDate>Tue, 14 Jul 2020 12:40:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Futhark implements bounds checking on the GPU]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23831009">thread link</a>) | @argh-man
<br/>
July 14, 2020 | https://futhark-lang.org/blog/2020-07-13-bounds-checking.html | <a href="https://web.archive.org/web/*/https://futhark-lang.org/blog/2020-07-13-bounds-checking.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
      

<p>
    Posted on July 13, 2020
    
        by Troels Henriksen
    
</p>

<p>Futhark is supposed to be a safe programming language. This implies that risky operations, such as <code>a[i]</code> which indexes an array at some arbitrary index, should be protected with a dynamic check. While C programmers are famous for never making mistakes, and therefore C does not perform do such checking, the vast majority of programming languages do check array indexes, usually by generating code like this:</p>
<pre><code>if (i &lt; 0 || i &gt; n) {
  // throw exception

  // OR print error message

  // OR terminate program

  // OR do anything else
}</code></pre>
<p>This immediately changes the control flow of the program based on the bounds check. Usually the implementation challenge is not how to perform such checks in the first place, but how to eliminate them in cases where the compiler can statically determine that the check can never fail. However, for Futhark we would like to generate code for GPUs, and GPUs are great at turning solved problems unsolved.</p>
<p>In this post I will describe why it took Futhark <em>years</em> to get support for bounds-checking on the GPU, how we recently solved the problem, and what the performance is like. This post is a rewritten extract of a <a href="https://futhark-lang.org/publications/hlpp20.pdf">recently presented paper</a>, which you can read if you are particularly interested in the details of bounds checking.</p>
<h2 id="asynchronous-execution"><a href="#asynchronous-execution" id="asynchronous-execution-link" title="asynchronous-execution">Asynchronous execution</a></h2>
<p>The basic problem is that the GPU functions as a <em>co-processor</em> that receives data and code from the CPU, but which is then processed at the GPUs own pace. Explicit synchronisation and copying (both slow) is necessary to exchange information between the CPU and GPU.</p>
<p>GPU code is organised as <em>kernels</em> (no relation to operating systems, more like functions), and when we launch code on the GPU, we tell it to run a specific kernel with a specific number of threads, with some specific arguments. It’s a lot like performing an asynchronous remote procedure call. And similarly to a remote procedure, a kernel that contains an index that is out of bounds has no way of directly affecting the control flow of the CPU. In practice, our only option is to simply write a value to a distinguished memory location indicating that things have gone wrong, and then terminate the running GPU thread:</p>
<pre><code>if (i &lt; 0 || i &gt;= n) {
  *global_failure = 1;
  return;  // Terminate GPU thread
}</code></pre>
<p>On the CPU, whenever we launch a GPU kernel, we then <em>block</em> until the kernel is done running, copy back the <code>global_failure</code> value, and check whether a bounds error occurred:</p>
<p><img src="https://futhark-lang.org/images/2020-07-13-gpu-cpu-sync.png" alt="A diagram of checking for errors after every GPU kernel."></p>
<p>Surely reading a single number after every kernel (which usually processes tens of thousands of array elements) must be fast? Let’s check the overhead on the Futhark benchmark suite, measured on an RTX 2080 Ti GPU:</p>
<p><img src="https://futhark-lang.org/images/2020-07-13-overhead-sync.png" alt="Slowdown of synchronous bounds checking compared to no bounds checking."></p>
<p>The vertical axis shows the <em>slowdown</em> of synchronous bounds checking compared to not doing any bounds checking. The overhead is pretty bad: A <a href="https://en.wikipedia.org/wiki/Geometric_mean">geomean</a> of <em>1.66x</em> , and more than <em>6x</em> on the worst affected benchmarks. I’m only measuring those benchmarks that require bounds checking <em>at all</em>, so the mean overhead across all benchmarks would be lower. Still, this is too slow to be practical.</p>
<p>GPUs perform well when given a large queue of work to process at their own pace, not when they constantly stop to transfer 32 bits back to the CPU for inspection, and have to wait for a go-ahead before proceeding. To speed this up, we need to cut the amount of synchronisation.</p>
<p>Let’s take a step back and consider why we do bounds checking in the first place: we want to avoid corrupting memory by writing to invalid addresses, and we want to avoid making bad control flow decisions based on reading garbage. This implies that we have to do bounds checking <em>immediately</em> whenever we access an array. But since the GPU’s control flow is completely decoupled from what is happening on the CPU, the CPU doesn’t actually need to know immediately that something has gone wrong - it only needs to be informed when it eventually copies data from the GPU, so that it knows not to trust it. The actual <em>check</em> still needs to be done immediately on the GPU, but copying back <code>global_failure</code> to the CPU can wait until the CPU would in any case need to synchronise with the GPU:</p>
<p><img src="https://futhark-lang.org/images/2020-07-13-gpu-cpu-async.png" alt="A diagram of delaying error checking."></p>
<p>This amortises the copying overhead over potentially many kernel launches. But we’re still not quite done, as kernel <em>i+1</em> may contain unchecked operations that are safe if and only if the preceding kernel <em>i</em> completed successfully. To address this, we add a prelude to every GPU kernel body where each thread checks whether <code>global_failure</code> is set:</p>
<pre><code>// Prelude added to every GPU kernel
if (*global_failure) {
  return;
}</code></pre>
<p>If so, that must mean one of the preceding kernels has encountered a failure, and so the all threads of the current kernel terminate immediately. Checking <code>global_failure</code> on the GPU is much faster than checking it on the CPU, because it does not involve any synchronisation or copying. The overhead is a single easily cached global memory read for every thread, which is in most cases negligible. Asynchronous checking performs like this:</p>
<p><img src="https://futhark-lang.org/images/2020-07-13-overhead-async.png" alt="Slowdown of synchronous bounds checking compared to no bounds checking."></p>
<p>Much better! The mean overhead is down to <em>1.07x</em> (compared to <em>1.66x</em> before), and the maximum overhead is <em>1.4x</em> (<em>6x</em> before). The slowest program is now the <a href="https://github.com/diku-dk/futhark-benchmarks/blob/master/rodinia/srad/srad.fut">srad</a> benchmark, which is structured roughly as follows:</p>

<p>The <code>reduce</code> runs on the GPU but produces a scalar, which in Futhark’s compilation model is copied back to the CPU where a tiny amount of sequential computation takes place, after which it is used to update the <code>image</code> array in various ways. The fact that we copy a value (even just a single number!) back to the CPU forces us to do a full synchronisation and also check <code>global_failure</code>. This is because the compiler is conservative - it does not understand that <code>x</code> is not going to be used for any CPU-side control flow, but is instead going to be sent right back to the GPU. Since each instance of <code>reduce</code> and <code>map</code> run for extremely short periods (little more than a dozen microseconds each), the communication cost becomes significant. This was already a problem, but bounds checking makes it worse.</p>
<p>The solution to this is not directly related to bounds checking at all, but is about refining our compilation model such that individual scalars are more aggressively kept on the GPU, if we can determine that their value is not truly needed on the CPU. As a side effect, this will allow us to delay checking <code>global_failure</code> until the entire outermost sequential loop has run, which will make the overhead of bounds checking essentially zero. But this is future work.</p>
<h2 id="cross-thread-communication"><a href="#cross-thread-communication" id="cross-thread-communication-link" title="cross-thread-communication">Cross-thread communication</a></h2>
<p>So far, we have assumed that a GPU thread, upon encountering an error, can safely terminate itself, or even the entire kernel. Unfortunately, reality is not so forgiving. A GPU thread can terminate itself, sure, but this can induce deadlocks if the kernel contains <a href="https://en.wikipedia.org/wiki/Barrier_(computer_science)">barriers</a>, because other threads may be waiting for the now-terminated thread. Life would be easier if the prevailing GPU APIs (CUDA and OpenCL) provided a way for a single thread to unilaterally abort execution of the entire kernel, but they don’t. The solution to this is a little hairy, and involves the failing thread jumping ahead to the next barrier instead of simply terminating, then after each barrier checking whether any threads have failed. See <a href="https://futhark-lang.org/publications/hlpp20.pdf">the paper</a> for the full details. It’s a solution that relies heavily on all communication being under the control of the compiler, so it’s not something you could do for a low-level GPU language.</p>
<h2 id="optimisations"><a href="#optimisations" id="optimisations-link" title="optimisations">Optimisations</a></h2>
<p>All effective and elegant implementation techniques must inevitably be followed by a collection of ad-hoc micro-optimisations of dubious impact, and bounds checking in Futhark is no different. Some of the special cases we handle are as follows:</p>
<ol type="1">
<li>Certain particularly simple kernels are able to execute safely even when previous kernels have failed, typically because they merely copy or replicate memory. Matrix transposition is an example of such a kernel. For these kernels we can eliminate all failure checking entirely, because bounds failures cannot result in memory becoming <em>inaccessible</em>, it can only result in the values stored being <em>wrong</em>, and these simple kernels are not sensitive to the values they are copying.</li>
<li>Some kernels may contain no bounds checks. They still need to check whether any previous kernels have failed, but do not need to be careful with respect to barriers and such.</li>
<li>At run-time, whenever we enqueue a kernel, we have dynamic knowledge of whether any kernels with bounds checks have been enqueued since the last time <code>global_failure</code> was checked. That is, we know dynamically whether <code>global_failure</code> is <em>certainly unset</em>. If so, we can pass that information along to the kernel as a kernel argument, which means the kernel does not have to check the value of <code>global_failure</code> in its prelude.</li>
</ol>
<p>The impact of these optimisations (and others covered in the paper) is quite minor, as shown in the following graph.</p>
<p><img src="https://futhark-lang.org/images/2020-07-13-overhead.png" alt="Slowdown of synchronous bounds checking compared to no bounds checking."></p>
<p>Most of the optimisations were motivated by micro-benchmarks, where the impact is more significant. On these benchmarks, they reduce the mean overhead to <em>1.04x</em> (from <em>1.07x</em>), and have no impact on the maximum overhead. Useful, but not crucial the way asynchronous checking is.</p>
<h2 id="error-messages"><a href="#error-messages" id="error-messages-link" title="error-messages">Error messages</a></h2>
<p>As discussed above, <code>global_failure</code> contains only a single bit of information: did the program fail or not? But the modern programmer is accustomed to luxuries such as being told <em>where</em> it failed, so clearly this will not do. The solution is simple. At compile time, we associate each bounds check with a unique number, a <em>failure code</em>, with a <code>global_failure</code> value of <em>-1</em> meaning <em>no error so far</em>. When a bounds check fails, the thread writes the failure code corresponding to the bounds check. At compile-time we also construct a table that maps each failure code to a <code>printf()</code>-style format string such as the following:</p>
<pre><code>"index %d out of bounds for array of size %d"</code></pre>
<p>For simplicity, <code>%d</code> is the only format specifier that can occur, but each distinct format string can contain a different number of format specifiers. We …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://futhark-lang.org/blog/2020-07-13-bounds-checking.html">https://futhark-lang.org/blog/2020-07-13-bounds-checking.html</a></em></p>]]>
            </description>
            <link>https://futhark-lang.org/blog/2020-07-13-bounds-checking.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23831009</guid>
            <pubDate>Tue, 14 Jul 2020 12:24:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WTF Is a Closure?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23830998">thread link</a>) | @danabramov
<br/>
July 14, 2020 | https://whatthefuck.is/closure | <a href="https://web.archive.org/web/*/https://whatthefuck.is/closure">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Closures are confusing because they are an “invisible” concept.</p>
<p>When you use an object, a variable, or a function, you do this intentionally. You think: “I’m gonna need a variable here,” and add it to your code.</p>
<p>Closures are different. By the time most people approach closures, they have already used them unknowingly many times — and it is likely that this is true for yourself, too. So learning closures is less about understanding a <em>new</em> concept and more about recognizing something you have <em>already been doing</em> for a while.</p>
<h3><a href="#tldr" id="tldr">tl;dr</a></h3><p>You have a closure when <strong>a function accesses variables defined outside of it</strong>.</p>
<p>For example, this code snippet contains a closure:</p>
<pre><code><p><span>let</span><span> users </span><span>=</span><span> </span><span>[</span><span>'Alice'</span><span>,</span><span> </span><span>'Dan'</span><span>,</span><span> </span><span>'Jessica'</span><span>]</span><span>;</span><span></span></p><p><span></span><span>let</span><span> query </span><span>=</span><span> </span><span>'A'</span><span>;</span><span></span></p><p><span></span><span>let</span><span> user </span><span>=</span><span> users</span><span>.</span><span>filter</span><span>(</span><span>user</span><span> </span><span>=&gt;</span><span> user</span><span>.</span><span>startsWith</span><span>(</span><span>query</span><span>)</span><span>)</span><span>;</span></p></code></pre><p>Notice how <code>user =&gt; user.startsWith(query)</code> is itself a function. It uses the <code>query</code> variable. But the <code>query</code> variable is defined <em>outside</em> of that function. That’s a closure.</p>
<hr>
<p><strong>You can stop reading here, if you want.</strong> The rest of this article approaches closures in a different way. Instead of explaining what a closure is, it will walk you through the process of <em>discovering</em> closures — like the first programmers did in the 1960s.</p>
<hr>
<h3><a href="#step-1-functions-can-access-outside-variables" id="step-1-functions-can-access-outside-variables">Step 1: Functions Can Access Outside Variables</a></h3><p>To understand closures, we need to be somewhat familiar with variables and functions. In this example, we declare the <code>food</code> variable <em>inside</em> the <code>eat</code> function:</p>
<pre><code><p><span>function</span><span> </span><span>eat</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>let</span><span> food </span><span>=</span><span> </span><span>'cheese'</span><span>;</span><span></span></p><p><span>  </span><span>console</span><span>.</span><span>log</span><span>(</span><span>food </span><span>+</span><span> </span><span>' is good'</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>eat</span><span>(</span><span>)</span><span>;</span><span> </span></p></code></pre><p>But what if we wanted to later change the <code>food</code> variable <em>outside</em> of the <code>eat</code> function? To do this, we can move the <code>food</code> variable itself out of our function into the top level:</p>
<pre><code><p><span>let</span><span> food </span><span>=</span><span> </span><span>'cheese'</span><span>;</span><span> </span><span></span></p><p><span></span><span>function</span><span> </span><span>eat</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>console</span><span>.</span><span>log</span><span>(</span><span>food </span><span>+</span><span> </span><span>' is good'</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span></p></code></pre><p>This lets us change the <code>food</code> “from the outside” any time that we want to:</p>
<pre><code><p><span>eat</span><span>(</span><span>)</span><span>;</span><span> </span><span></span></p><p><span>food </span><span>=</span><span> </span><span>'pizza'</span><span>;</span><span></span></p><p><span></span><span>eat</span><span>(</span><span>)</span><span>;</span><span> </span><span></span></p><p><span>food </span><span>=</span><span> </span><span>'sushi'</span><span>;</span><span></span></p><p><span></span><span>eat</span><span>(</span><span>)</span><span>;</span><span> </span></p></code></pre><p>In other words, the <code>food</code> variable is no longer <em>local</em> to our <code>eat</code> function, but our <code>eat</code> function nevertheless has no trouble accessing it. <strong>Functions can access variables outside of them.</strong> Stop for a second and make sure that you have no problem with this idea. Once it has settled comfortably in your brain, move to the second step.</p>
<h3><a href="#step-2-wrapping-code-in-a-function-call" id="step-2-wrapping-code-in-a-function-call">Step 2: Wrapping Code in a Function Call</a></h3><p>Let’s say we have some code:</p>
<pre><code></code></pre><p>It doesn’t matter what that code does. But let’s say that <strong>we want to run it twice</strong>.</p>
<p>One way to do it would be to copy and paste it:</p>
<pre><code></code></pre><p>Another way to do it would be to use a loop:</p>
<pre><code><p><span>for</span><span> </span><span>(</span><span>let</span><span> i </span><span>=</span><span> </span><span>0</span><span>;</span><span> i </span><span>&lt;</span><span> </span><span>2</span><span>;</span><span> i</span><span>++</span><span>)</span><span> </span><span>{</span><span></span></p><p><span></span><span>}</span></p></code></pre><p>The third way, which we’re particularly interested in today, is to wrap it in a function:</p>
<pre><code><p><span>function</span><span> </span><span>doTheThing</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>doTheThing</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span></span><span>doTheThing</span><span>(</span><span>)</span><span>;</span></p></code></pre><p>Using a function gives us the ultimate flexibility because we can run this function any number of times, at any time — and from anywhere in our program.</p>
<p>In fact, <strong>we can even call our new function only <em>once</em></strong>, if we wanted to:</p>
<pre><code><p><span>function</span><span> </span><span>doTheThing</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>doTheThing</span><span>(</span><span>)</span><span>;</span></p></code></pre><p>Notice how the code above is equivalent to the original code snippet:</p>
<pre><code></code></pre><p>In other words, <strong>if we take some piece of code, “wrap” that code in a function, and then call that function exactly once, we haven’t changed what that code is doing</strong>. There are some exceptions to this rule which we will ignore, but generally saying this should make sense. Sit on this idea until your brain feels comfortable with it.</p>
<h3><a href="#step-3-discovering-closures" id="step-3-discovering-closures">Step 3: Discovering Closures</a></h3><p>We have traced our way through two different ideas:</p>
<ul>
<li><strong>Functions can access variables defined outside of them.</strong></li><li><strong>Wrapping code in a function and calling it once doesn’t change the result.</strong></li></ul>
<p>Now let’s see what happens if we combine them.</p>
<p>We’ll take our code example from the first step:</p>
<pre><code><p><span>let</span><span> food </span><span>=</span><span> </span><span>'cheese'</span><span>;</span><span></span></p><p><span></span><span>function</span><span> </span><span>eat</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>console</span><span>.</span><span>log</span><span>(</span><span>food </span><span>+</span><span> </span><span>' is good'</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>eat</span><span>(</span><span>)</span><span>;</span></p></code></pre><p>Then we’ll wrap <em>this whole example</em> into a function, which we’re going to call once:</p>
<pre><code><p><span>function</span><span> </span><span>liveADay</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>let</span><span> food </span><span>=</span><span> </span><span>'cheese'</span><span>;</span><span></span></p><p><span>  </span><span>function</span><span> </span><span>eat</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>console</span><span>.</span><span>log</span><span>(</span><span>food </span><span>+</span><span> </span><span>' is good'</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span>  </span><span>eat</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>liveADay</span><span>(</span><span>)</span><span>;</span></p></code></pre><p>Read both snippets one more time and make sure that they are equivalent.</p>
<p>This code works! But look closer. Notice the <code>eat</code> function is <em>inside</em> the <code>liveADay</code> function. Is that even allowed? Can we really put a function inside another function?</p>
<p>There are languages in which a code structured this way is <em>not</em> valid. For example, this code is not valid in the C language (which doesn’t have closures). This means that in C, our second conclusion isn’t true — we can’t just take some arbitrary piece of code and wrap it in a function. But JavaScript doesn’t suffer from that limitation.</p>
<p>Take another good look at this code and notice where <code>food</code> is declared and used:</p>
<pre><code><p><span>function</span><span> </span><span>liveADay</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>let</span><span> food </span><span>=</span><span> </span><span>'cheese'</span><span>;</span><span> </span><span></span></p><p><span>  </span><span>function</span><span> </span><span>eat</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>console</span><span>.</span><span>log</span><span>(</span><span>food </span><span>+</span><span> </span><span>' is good'</span><span>)</span><span>;</span><span> </span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span>  </span><span>eat</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>liveADay</span><span>(</span><span>)</span><span>;</span></p></code></pre><p>Let’s go through this code together — step by step. First, we declare the <code>liveADay</code> function at the top level. We immediately call it. It has a <code>food</code> local variable. It also contains an <code>eat</code> function. Then it calls that <code>eat</code> function. Because <code>eat</code> is inside of <code>liveADay</code>, it “sees” all of its variables. This is why it can read the <code>food</code> variable.</p>
<p><strong>This is called a closure.</strong></p>
<p><strong>We say that there is a closure when a function (such as <code>eat</code>) reads or writes a variable (such as <code>food</code>) that is declared outside of it (such as in <code>liveADay</code>).</strong></p>
<p>Take some time to re-read this, and make sure you can trace this in the code.</p>
<p>Here is an example we’ve introduced in the tl;dr section:</p>
<pre><code><p><span>let</span><span> users </span><span>=</span><span> </span><span>[</span><span>'Alice'</span><span>,</span><span> </span><span>'Dan'</span><span>,</span><span> </span><span>'Jessica'</span><span>]</span><span>;</span><span></span></p><p><span></span><span>let</span><span> query </span><span>=</span><span> </span><span>'A'</span><span>;</span><span></span></p><p><span></span><span>let</span><span> user </span><span>=</span><span> users</span><span>.</span><span>filter</span><span>(</span><span>user</span><span> </span><span>=&gt;</span><span> user</span><span>.</span><span>startsWith</span><span>(</span><span>query</span><span>)</span><span>)</span><span>;</span></p></code></pre><p>It may be easier to notice the closure if we rewrite it with a function expression:</p>
<pre><code><p><span>let</span><span> users </span><span>=</span><span> </span><span>[</span><span>'Alice'</span><span>,</span><span> </span><span>'Dan'</span><span>,</span><span> </span><span>'Jessica'</span><span>]</span><span>;</span><span></span></p><p><span></span><span>let</span><span> query </span><span>=</span><span> </span><span>'A'</span><span>;</span><span></span></p><p><span></span><span>let</span><span> user </span><span>=</span><span> users</span><span>.</span><span>filter</span><span>(</span><span>function</span><span>(</span><span>user</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>return</span><span> user</span><span>.</span><span>startsWith</span><span>(</span><span>query</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span><span>)</span><span>;</span></p></code></pre><p>Whenever a function accesses a variable that is declared outside of it, we say it is a closure. The term itself is used a bit loosely. Some people will refer to the <em>nested function itself</em> as “the closure” in this example. Others might refer to the <em>technique</em> of accessing the outside variables as the closure. Practically, it doesn’t matter.</p>
<h3><a href="#a-ghost-of-a-function-call" id="a-ghost-of-a-function-call">A Ghost of a Function Call</a></h3><p>Closures might seem deceptively simple now. This doesn’t mean they’re without their own pitfalls. The fact that a function may read and write variables outside has rather deep consequences if you really think about it. For example, this means that these variables will “survive” for as long as the nested function may be called:</p>
<pre><code><p><span>function</span><span> </span><span>liveADay</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>let</span><span> food </span><span>=</span><span> </span><span>'cheese'</span><span>;</span><span></span></p><p><span>  </span><span>function</span><span> </span><span>eat</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>console</span><span>.</span><span>log</span><span>(</span><span>food </span><span>+</span><span> </span><span>' is good'</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span>  </span><span>setTimeout</span><span>(</span><span>eat</span><span>,</span><span> </span><span>5000</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>liveADay</span><span>(</span><span>)</span><span>;</span></p></code></pre><p>Here, <code>food</code> is a local variable inside the <code>liveADay()</code> function call. It’s tempting to think it “disappears” after we exit <code>liveADay</code>, and it won’t come back to haunt us.</p>
<p>However, inside of <code>liveADay</code> we tell the browser to call <code>eat</code> in five seconds. And <code>eat</code> reads the <code>food</code> variable. <strong>So the JavaScript engine needs to keep the <code>food</code> variable from that particular <code>liveADay()</code> call available until <code>eat</code> has been called.</strong></p>
<p>In that sense, we can think of closures as of “ghosts” or “memories” of the past function calls. Even though our <code>liveADay()</code> function call has long finished, its variables must continue to exist for as long as the nested <code>eat</code> function may still be called. Luckily, JavaScript does that for us, so we don’t need to think about it.</p>
<h3><a href="#why-closures" id="why-closures">Why “Closures”?</a></h3><p>Finally, you might be wondering why closures are called that way. The reason is mostly historical. A person familiar with the computer science jargon might say that an expression like <code>user =&gt; user.startsWith(query)</code> has an “open binding”. In other words, it is clear from it what the <code>user</code> is (a parameter), but it is not clear what <code>query</code> is in isolation. When we say “actually, <code>query</code> refers to the variable declared outside”, we are “closing” that open binding. In other words, we get a <em>closure</em>.</p>
<p>Not all languages implement closures. For example, in some languages like C, it is not allowed to nest functions at all. As a result, a function may only access its own local variables or global variables, but there is never a situation in which it can access a parent function’s local variables. Naturally, that limitation is painful.</p>
<p>There are also languages like Rust which implement closures, but have a separate syntax for closures and regular functions. So if you want to read a variable from outside a function, you would have to opt into that in Rust. This is because under the hood, closures may require the engine to keep the outer variables (called “the environment”) around even after the function call. This overhead is acceptable in JavaScript, but it can be a performance concern for the very low-level languages.</p>
<p>And with that, I hope you can get a closure on the concept of closures!</p>
<blockquote>
<p>If you prefer a more visual approach to the JavaScript fundamentals, check out <a href="https://justjavascript.com/" target="_blank" rel="noopener noreferrer">Just JavaScript</a>. It is my illustrated course in collaboration with <a href="https://maggieappleton.com/" target="_blank" rel="noopener noreferrer">Maggie Appleton</a>.</p>
</blockquote>
</article></div>]]>
            </description>
            <link>https://whatthefuck.is/closure</link>
            <guid isPermaLink="false">hacker-news-small-sites-23830998</guid>
            <pubDate>Tue, 14 Jul 2020 12:22:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I'm building a personal notes app focused on Data Longevity (beta)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23830995">thread link</a>) | @ricg
<br/>
July 14, 2020 | http://kitestack.com/lnotes/ | <a href="https://web.archive.org/web/*/http://kitestack.com/lnotes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<nav>
    <a href="http://kitestack.com/">
        <img src="http://kitestack.com/assets_v8/img/images/textblocks/small-logo.png">
        Kitestack
    </a>
    
    
</nav>

<section>
    <div>
        <p><img src="http://kitestack.com/assets_v8/img/images/lnotes/lnotes_512.png" width="256" height="256"></p>
        <h2>A new notes app for Mac<br>built around simple files and folders.</h2>
        
		
	
		<div>
	        <p>New in version 0.3.5:</p>
			<div>
				<ul>
					<li>Full text search via the location bar</li>
				</ul>
			</div>
	    </div>
    </div>
</section>

<section>
    

    
</section>

<section>
    <div>
		<p><a href="http://kitestack.com/assets_v8/img/images/lnotes/Main-Book-Research.png"><img src="http://kitestack.com/assets_v8/img/images/lnotes/Main-Book-Research.png"></a></p>
    </div>

</section>

<section>
    <div>
        
        <p>
        	Each note is a file, every folder, well, a folder on your Mac. All show up in Finder. Other files and documents are shown with a preview and the option to be opened with their default app.
        </p>
		<p><img src="http://kitestack.com/assets_v8/img/images/lnotes/Attach-to-PDF.gif"></p>
    </div>

</section>

<section>
    <div>
        
		<div>
            <div>
				
				<p>
		        	Rearrange your thoughts as you see fit. You can add notes as sub-notes to other notes, folders, and even files.
		        </p>
            </div>
            
            <p><img src="http://kitestack.com/assets_v8/img/images/lnotes/outline.png">
            </p>
        </div>

    </div>
</section>

<section>
    <div>
        
        <p>
			You can add links to other notes and files. When renaming a note, all related notes are updated automatically. Each note that is mentioned in another note includes a list of backlinks at the end to navigate both ways.
        </p>
		<p><img src="http://kitestack.com/assets_v8/img/images/lnotes/linkupdate.gif"></p>
    </div>
</section>

<section>
    <div>
        
        <p>
			Note file names are prefixed with the current date in YYYY-MM-DD format; very handy for sorting in Finder. For linking between notes, there's no need to reference notes by an abstract ID, because the app takes care of keeping links up-to-date when renaming or moving notes.
        </p>
    </div>
</section>
 
<section>
    <div>
        
        <p>
			Type "[]" to start a new to do list. You can mix and match numbered, bulleted, and to-do lists. A summary of open to-dos is shown in the bottom right of each note.
        </p>
    </div>
</section>

<section>
    <div>
        
        
        <p>
          	Imagine one morning you wake up and realize that the software update that installed itself automatically last night now crashes your notes app. The backup copy that you keep online is gone, because the company behind the service was acquired, pivoted on its heels and is now onto bigger things, and not even that old copy that you emailed to yourself is within reach, because, well, you are offline. 
</p>
<p>
			The best protection against getting locked out from an app and your data is to not rely on any particular app in the first place. Using a data format that is compatible across many apps, ideally simple enough so that even in 20 years from now there will still be apps around that will be able to open it.</p>

<p>
			The most basic form of keeping notes in an accessible form has to be plain text files. Many people favor Markdown over plain text, because it supports text formatting and referencing images. The app uses HTML as its data format. The advantage here is that this allows embedding images inside notes and note contents can be previewed in their formatted form in any browser (and copied to other word processing apps from there, if needed).
        </p>
        </div>
    
</section>



<section>
    
</section>







</div>]]>
            </description>
            <link>http://kitestack.com/lnotes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23830995</guid>
            <pubDate>Tue, 14 Jul 2020 12:21:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chopper Commando Revisited]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 21 (<a href="https://news.ycombinator.com/item?id=23830881">thread link</a>) | @loadzero
<br/>
July 14, 2020 | https://blog.loadzero.com/blog/chopper258/ | <a href="https://web.archive.org/web/*/https://blog.loadzero.com/blog/chopper258/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p><i>This article contains pixel art. For best results please use 100% browser zoom.</i></p>

<p><a href="https://github.com/loadzero/chopper258">chopper258</a> is a port of <a href="https://www.mobygames.com/game/chopper-commando">Chopper Commando</a>, a DOS game written by <a href="https://www.mobygames.com/developer/sheet/view/developerId,59219/">Mark Currie</a> using Turbo Pascal in 1990.</p>

<p>Some thirty years later, in 2020, I've dusted off the old code and breathed some new life into it. I've ported it to C and made it work with SDL2, and it can now run natively in modern environments.</p>

<p>The canvas below shows a minute or so of gameplay from the new version.</p>




<p>The game can also be played on the web, thanks to emscripten.</p>

<p>Let's do a quick check to see if you can play.</p>

<span>
    <p>Yes, you can play the game by <span>clicking</span> on the button below.</p>

    
    
</span>

<span>
    <p>Unfortunately, your browser looks to be incompatible. The game currently only works in Desktop Chrome, due to the use of certain low level features.</p>
</span>



<p>Thanks to Mark Currie for granting me permission to publish this translation of his game.

</p><p>In addition to publishing the <a href="https://github.com/loadzero/chopper258">source code</a>, and
<span><a href="https://blog.loadzero.com/demo/chopper258">playable version</a>,</span>
<span>playable version,</span> I am also writing a series of articles to accompany the
project, the first part of which is included below.</p>

<p>I have also made some animations and interactive parts that you can <span>play</span> around
with, such as the <a href="#picker_link">palette picker</a> later on in this piece.</p>



<h2>Background</h2>

<p>I chose to revisit Chopper Commando for a few reasons.

</p><p>One of the biggest ones is nostalgia. I remember enjoying playing this game
as a child, on my PC and with others, and being surprised at some of the novel
mechanics. I also remember having a good laugh.

</p><p>This is the first game I played where you could leave a
vehicle, run around and do things on foot, and then get back in and keep going.
I thought that was so cool, and it was an early precursor to the sandbox games I
enjoy today.

</p><p>I have a soft spot for bedroom coded efforts like this, where the heart and
soul of the game isn't obscured by many layers of polish. It's not too hard to
imagine a 15-year old Mark Currie writing a game for himself on his 286, and
getting a real kick out of doing so.

</p><p>Games like this were pretty formative for me as a young aspiring games
programmer. Unlike something like Super Mario, which seemed unreachable to me at the time, I could play this and start working out how to make something similar, even with the simple tools I had.

</p><h2>Project Scale</h2>

<p>This was a bit smaller and more straightforward than my previous effort,
<a href="http://blog.loadzero.com/blog/si78c/">Space Invaders In C</a>. This project
took around 3 months of calendar time, and about 200 hours were spent on it in total.

</p><p>As the source code to the game was available, albeit in Pascal, not much
reverse engineering was required. Most of the effort went into the translation
to C, and building new code to provide workalikes for the Turbo Pascal API.

</p><p>One of the last parts I worked on, the sound, also turned out to be one of
the most difficult. The original game used PC speaker sound in a dynamic way,
and I had to write a synthesizer for it. It was quite fiddly to get the timing
right and make it sound like the original. More on that in part two.

</p><p>The original code is around 5500 lines of Pascal, all of it game logic code.
The new C version is around 5500 lines of game logic, 1500 lines of support
code and 400 lines of comments.

</p><p>Compared to the last project, there isn't too much behind the scenes
unpublished code in this one. I wrote a few small pieces to aid translation,
some scripts to build the font data, and some prototypes to help figure out the
sound code.

</p><p>I did end up writing a little bit of pascal code, mostly as temporary mods to the
original game source to help me figure out what the original system was doing. More
detail on compiling the old code is provided in a later piece.

</p><h2>Graphics</h2>

<p>One of the very first things I did on the project was to figure out the framebuffer format
for the original game, and start hacking to get it to display on a modern system.

</p><p>The frame buffer is CGA, meaning it is 320 pixels wide, 200 lines high and has
2 bit paletted color, for a grand total of four possible colors on screen at
any one time.

</p><p>Below is a selection of screen shots from the game in all their CGA glory.</p>



<p>If you look carefully, even though each screen can only show four colors, 
you can see that there are more than four colors in total. This is due to
palettes. In the CGA scheme, four base color palettes are available and each has a
different arrangement of sixteen possible colors.

</p><p>As an extra tweak, the first color in the palette (typically the background color), can be
freely chosen out of the sixteen, giving slightly more flexibility. This means that there
are sixteen variations of each of the four base palettes, giving sixty four palettes in total.

<a id="picker_link"></a>

</p><p>To play with the color combinations, <span>click</span> on the colored areas in the first panel below.
You can pick a palette and background color, and the effect will be shown in the second panel,
using one of the screenshots. Use prev and next to cycle to a different screenshot.

</p>


<p>In the old system, the framebuffer and the palette settings are bits of memory
that live on the graphics card and are twiddled by the game directly. In the
new system, these reside in host memory, and must be converted into a modern texture format
on the fly every frame for the GPU to use.

</p><p>Given that there are only 64 possible palettes, a neat trick can be used to
simplify and speed up the framebuffer conversion. Before the game starts
running, every possible combination of palette, background color and input
framebuffer byte (4 pixels at 2bpp) are iterated through, and the resulting 8
output bytes (4 pixels at 16bpp) are stored in a 16 * 4 * 256 entry lookup
table. Converting the framebuffer each frame is then just a matter of iterating
through each byte and performing a simple lookup and memcpy to stamp out four
pixels at a time.

</p><h2>To be continued...</h2>

<p>As mentioned earlier, the sound code was one of the hardest parts of the port. Part two
explains why that was so, and the solution I used to solve it.</p>

<p>The canvas below shows a little preview.</p>












</article></div>]]>
            </description>
            <link>https://blog.loadzero.com/blog/chopper258/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23830881</guid>
            <pubDate>Tue, 14 Jul 2020 12:07:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I'm Switching to Apple]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23830840">thread link</a>) | @caspii
<br/>
July 14, 2020 | https://casparwre.de/blog/why-i-am-switching-to-apple/ | <a href="https://web.archive.org/web/*/https://casparwre.de/blog/why-i-am-switching-to-apple/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Because the hardware is great and the software is not made by a gigantic and opaque ad-tech company (Google).</p>

<p>That’s all. Bye 👋</p>

  </div></div>]]>
            </description>
            <link>https://casparwre.de/blog/why-i-am-switching-to-apple/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23830840</guid>
            <pubDate>Tue, 14 Jul 2020 12:01:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Color barcode becomes ISO standard]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23830777">thread link</a>) | @FraunhoferSIT
<br/>
July 14, 2020 | https://www.sit.fraunhofer.de/en/news-events/latest/press-releases/details/news-article/show/bunter-barcode-wird-iso-standard/ | <a href="https://web.archive.org/web/*/https://www.sit.fraunhofer.de/en/news-events/latest/press-releases/details/news-article/show/bunter-barcode-wird-iso-standard/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="c6662"><h2> Fraunhofer brings JAB-Code into standardization: globally uniform rules for data exchange and practical use</h2>
<p> <b>JAB-Code, the color barcode of the Fraunhofer Institute for Secure Information Technology SIT, is on the way to becoming an international ISO standard. JAB-Code – Just Another Barcode – is to be brought to a full ISO standard by 2022. The globally uniform rules for data formats and their use in practice provide both device manufacturers and user companies with planning security for innovative developments – an important prerequisite for the successful dissemination of JAB-Code in industry. The advantage of the color code compared to the common black and white barcodes is that it can store much more data in the same space. Besides securing job certificates, training certificates and last wills, JAB-Code can also provide proof of authenticity for products. JAB-Code is not subject to licensing. It is open source and ready to be put into practice. To test the color barcode, go to <a href="https://www.sit.fraunhofer.de/typo3/www.jabcode.org" title="Externen Link in neuem Fenster öffnen" target="_blank" rel="noopener">www.jabcode.<span>or<svg viewBox="0 0 125 118"><path fill="none" stroke="#000" stroke-width="7" stroke-miterlimit="10" d="M59.2 27.6L24.6 27.6 24.6 100 97 100 97 67.8"></path><path d="M66.6 14H104.39999999999999V22.4H66.6z"></path><path transform="rotate(90 100.159 32.354)" d="M81.8 28.2H118.5V36.6H81.8z"></path><path transform="rotate(134.999 78.516 39.71)" d="M51.2 35.2H105.9V44.300000000000004H51.2z"></path></svg></span></a>g.&nbsp;</b></p>
<p>Black and white barcodes can be found everywhere in everyday life: on packaging, parcel shipping labels, on the backs of books and more. However, these barcodes contain only a small amount of data, it is therefore often necessary to include links to websites that contain more information, for example about a product. Fraunhofer SIT's JAB-Code uses color as a third dimension and can therefore store more information in the same space. The color code does not have to use database references and links, it simply stores the information itself. JAB-Code uses the colors cyan, yellow, magenta, black and mixtures of these. With up to eight colors, the barcode is as robust as its black and white counterparts are. With JAB-Code being able to take on many varying shapes, not just the square form, it greatly extends the design possibilities. </p>
<h2>How the color code works</h2>
<p>Fraunhofer SIT's experts developed the code with a high data density so that documents can be identified as genuine, even when offline. JAB-Code makes the authenticity of documents verifiable, thereby increasing the protection against counterfeits. The content of a document is signed and encrypted digitally so that later alterations will not go unnoticed. The signed content and the signature are mapped into JAB-Code. JAB-Code is then printed onto the corresponding document using a standard color printer. Every authorized person can now scan JAB-Code with a smartphone and verify the authenticity of the document: First, the smartphone reads and verifies the digital signature. If this is successful, the document content is displayed on the tester's smartphone so that the paper can be compared to the content displayed. If differences show up, the paper in question has been forged. </p>
<h3>Application examples for JAB-Code</h3>
<p>This is always useful when, for example, documents are exchanged between public authorities and end-users or businesses, but when no common database exists for verification purposes, e.g. for data protection reasons. During the lockdown due to the Corona crisis, companies in border regions issued their employees with a pass to prove that this person worked for the company and had to cross the border on a regular basis. This permit is merely a paper with a company stamp, and officials at the border cannot easily check the authenticity of the document. Besides simplifying verification, digital signatures and JAB-Codes will also make documents forgery-proof and data protection compliant. </p>
<p>Another example are medical prescriptions. They can be forged in order to obtain expensive medication, with double submissions being a problem as well. JAB-Code could prevent this, because the color code stores all the important information directly on the prescription. When issuing the prescription, the doctor extracts certain unique properties from the prescription paper, such as structures or fibers, which are kind of like a fingerprint of the paper. This can be done with commercially available cameras, for example a smartphone, within seconds. Using this paper fingerprint and the contents of the prescription, i.e. which medicines have been prescribed, the doctor signs the prescription digitally. From the signed data, a JAB-Code is created together with the doctor's digital signature and printed on the prescription. At the pharmacy, the pharmacist first checks the digital signature by scanning it using a smartphone. Once the signature has been verified and the paper properties in JAB-Code and the prescription match, the pharmacist knows that the prescription is the original.   </p>
<p>JAB-Code was developed on behalf of the Federal Office for Information Security (BSI). The color code is on its way to ISO 23634 (more information at <a href="https://www.iso.org/standard/76478.html" title="Externen Link in neuem Fenster öffnen" target="_blank" rel="noopener">https://www.iso.org/standard/76478.<span>html<svg viewBox="0 0 125 118"><path fill="none" stroke="#000" stroke-width="7" stroke-miterlimit="10" d="M59.2 27.6L24.6 27.6 24.6 100 97 100 97 67.8"></path><path d="M66.6 14H104.39999999999999V22.4H66.6z"></path><path transform="rotate(90 100.159 32.354)" d="M81.8 28.2H118.5V36.6H81.8z"></path><path transform="rotate(134.999 78.516 39.71)" d="M51.2 35.2H105.9V44.300000000000004H51.2z"></path></svg></span></a>) and is expected to be available as a standard at the beginning of next year. The source code is open source on GitHub under the license LGPL v2.1 (free use for all purposes under mention of Fraunhofer SIT as developer): <a href="https://github.com/jabcode/jabcode" title="Externen Link in neuem Fenster öffnen" target="_blank" rel="noopener">https://github.com/jabcode/<span>jabcode<svg viewBox="0 0 125 118"><path fill="none" stroke="#000" stroke-width="7" stroke-miterlimit="10" d="M59.2 27.6L24.6 27.6 24.6 100 97 100 97 67.8"></path><path d="M66.6 14H104.39999999999999V22.4H66.6z"></path><path transform="rotate(90 100.159 32.354)" d="M81.8 28.2H118.5V36.6H81.8z"></path><path transform="rotate(134.999 78.516 39.71)" d="M51.2 35.2H105.9V44.300000000000004H51.2z"></path></svg></span></a>   </p></div></div>]]>
            </description>
            <link>https://www.sit.fraunhofer.de/en/news-events/latest/press-releases/details/news-article/show/bunter-barcode-wird-iso-standard/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23830777</guid>
            <pubDate>Tue, 14 Jul 2020 11:52:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Whiteboard: React Hooks]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23830691">thread link</a>) | @fazlerocks
<br/>
July 14, 2020 | https://blog.ranaemad.com/whiteboard-react-hooks-ckclrvccg0005fls16f1h80mc | <a href="https://web.archive.org/web/*/https://blog.ranaemad.com/whiteboard-react-hooks-ckclrvccg0005fls16f1h80mc">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>We have talked before in <a target="_blank" rel="noopener noreferrer" href="https://blog.ranaemad.com/text-recorder-react-states-event-handling-and-conditional-rendering-ckc35etwr0000zds16hcj5nm5">Text Recorder: React States, Event Handling and Conditional Rendering</a> about states and how to set them and handle their changes. That was while using Class components, but of course we don't have to use Class components to get all the perks, do we?</p>
<p>Let's find out how we can do the same for Function components!</p>

<p>Hooks allow us to use states and lifecycle methods within a Function component. They were not always there, they have been recently introduced in React 16.8</p>
<p>They are Javascript functions, but they can NOT be called inside loops, conditions, or nested functions. They always have to be called at the top level of your React function.</p>
<p>We are going to discuss 2 main Hooks:</p>
<ul>
<li>useState</li>
<li>useEffect</li>
</ul>

<p>To set a state in a Class component, we used <code>this.state</code> in the constructor or  <code>this.setState()</code> anywhere else. Our code would look something like this:</p>
<pre><code><span>this</span>.setState({
        dummyState: <span>"dum dum"</span>
});
</code></pre>
<p>To use Hooks to rewrite the above code, we are going to need the help of useState. It accepts a parameter that can be used to set the initial value of the state and returns an array with its first element as the current value of this state and its second element as a function to be used later to set the value of the state.</p>
<pre><code><span>const</span> [dummyState, setDummyState]= useState(<span>"dum dum"</span>);
</code></pre>
<p>We can name them anything we want, of course, but the convention goes as above. Also, it is common to use the <a target="_blank" rel="noopener noreferrer" href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Destructuring_assignment">array destructuring</a> method to easily access the returned values.</p>
<p>To update the state's value later, we simply call the returned function with the updated value.</p>
<pre><code>setDummyState(<span>"dum dum dum"</span>);
</code></pre>

<p>We previously learned about componentDidMount, componentDidUpdate, and componentWillUnmount in <a target="_blank" rel="noopener noreferrer" href="https://blog.ranaemad.com/woof-vs-meow-data-fetching-and-react-component-lifecycle-ckcbpsbvj0002yys155ij60g0">Woof Vs. Meow: Data Fetching and React Component Lifecycle</a>. Our useEffect Hook can act as an equivalent to all of them combined. Isn't that some cool Hook?</p>
<p>useEffect accepts a function as a parameter and also an optional array. Let's translate the following code to Hooks to get a better understanding!</p>
<p>Both</p>
<pre><code>componentDidMount(){
    functionThatFetchesSomeData();
}
</code></pre>
<p>And</p>
<pre><code>componentDidUpdate(){
    functionThatFetchesSomeData();
}
</code></pre>
<p>Can be translated to the same thing by the useEffect Hook</p>
<pre><code>useEffect(()=&gt;{
    functionThatFetchesSomeData();
});
</code></pre>
<p>As mentioned before, the useEffect Hook acts as componentDidUpdate. It re-runs whenever any update occurs. Sometimes we want to filter when to run our useEffect and that's why the second array parameter exists. By passing a certain state to this array, we would be telling our Hook to compare its current value with its previous value and only if they were different from each other then our code would run.</p>
<pre><code>useEffect(()=&gt;{
    functionThatFetchesSomeData();
},[userId]);
</code></pre>
<p>We can have multiple useEffect Hooks and each can have its own filter and its own code.</p>
<p>If we only want to fetch data when the component mounts and we don't want to rerun our code on update, we can trick our Hook and provide it with an empty array as the second argument and by that it would never detect any changes in the array and will only run once.</p>
<p>Our final method to discuss is componentWillUnmount which is known to be used as a clean up method. To let our Hook know what to clean up all we have to do is return a function with our instructions.</p>
<pre><code>useEffect(()=&gt;{
    functionThatOpensAnImaginaryConnection();

    <span>return</span> ()=&gt;{
        functionThatClosesAnImaginaryConnection();
    }

});
</code></pre>
<p>That's enough to get us started on building something! I am already Hooked!</p>

<p>Do you know how sometimes when you are explaining something, you just feel like backing your theory up with a disfigured hand-drawn diagram? Or when you're trying to solve a problem and you need to scribble some notes to understand it better?</p>
<p>Today, we are going to build our own whiteboard to draw upon all the disfigured shapes and scribbles we want!</p>
<p><em>Experiment a little <a target="_blank" rel="noopener noreferrer" href="https://ranaemad.github.io/whiteboard/">HERE</a></em>
<img src="https://dev-to-uploads.s3.amazonaws.com/i/fi7xt4cs9g0cbjsw21tb.gif" alt="hooks written on whiteboard"></p>

<p>We want to have a huge white space to draw on, so there goes our first component, let's call it Board! We also, want to have a couple of controls to change the color and erase our content, so that will add to our application three more components; one for Controls, the other for Color and another for Eraser.</p>
<p>Let's roll!</p>

<p>By now, we should be able to install create-react-app and create our folder structure with our eyes blindfolded, so I am going to sit this one out.</p>
<p>The first thing we need in our Board component is a canvas element. Usually, to add 2d context to our canvas and make it drawable, we select it using its id, but in React no selections with id-s or classes take place. Instead, to do that we are going to use refs.</p>
<p>We have talked previously, about handling refs in Class components and they're not so different in Function components. Let's see how they look like!</p>
<pre><code><span>import</span> React <span>from</span> <span>"react"</span>;
<span>import</span> <span>"./Board.css"</span>;

<span><span>function</span> <span>Board</span>(<span></span>) </span>{
  <span>const</span> canvasRef = React.useRef(<span>null</span>);
  <span>return</span> (
    <span><span>&lt;<span>div</span> <span>className</span>=<span>"board"</span>&gt;</span>
      <span>&lt;<span>canvas</span> <span>ref</span>=<span>{canvasRef}</span> /&gt;</span>
    <span>&lt;/<span>div</span>&gt;</span>
  )</span>;
}

<span>export</span> <span>default</span> Board;
</code></pre>
<p>Let's add our Board to our App to view the changes as we are used to!</p>
<pre><code><span>import</span> React <span>from</span> <span>"react"</span>;
<span>import</span> <span>"./App.css"</span>;
<span>import</span> Board <span>from</span> <span>"./components/Board/Board"</span>;

<span><span>function</span> <span>App</span>(<span></span>) </span>{
  <span>return</span> (
    <span><span>&lt;<span>div</span> <span>className</span>=<span>"app"</span>&gt;</span>
      <span>&lt;<span>Board</span> /&gt;</span>
    <span>&lt;/<span>div</span>&gt;</span>
  )</span>;
}

<span>export</span> <span>default</span> App;
</code></pre>
<p>Now we are going to start using our Hooks. Let's import useState and start by adding our context!</p>
<pre><code><span>import</span> React,{useState} <span>from</span> <span>"react"</span>;
<span>import</span> <span>"./Board.css"</span>;

<span><span>function</span> <span>Board</span>(<span></span>) </span>{
  <span>const</span> canvasRef = React.useRef(<span>null</span>);
  <span>const</span> [ctx, setCtx] = useState({});
  <span>return</span> (
    <span><span>&lt;<span>div</span> <span>className</span>=<span>"board"</span>&gt;</span>
      <span>&lt;<span>canvas</span> <span>ref</span>=<span>{canvasRef}</span> /&gt;</span>
    <span>&lt;/<span>div</span>&gt;</span>
  )</span>;
}

<span>export</span> <span>default</span> Board;
</code></pre>
<p>We are going to need to set our context for the canvas the first thing. In Class components we would have used componentDidMount, which as we agreed in our case would be replaced by useEffect Hook. So let's import it and set our context!</p>
<pre><code><span>import</span> React, { useState, useEffect } <span>from</span> <span>"react"</span>;
<span>import</span> <span>"./Board.css"</span>;

<span><span>function</span> <span>Board</span>(<span></span>) </span>{
  <span>const</span> canvasRef = React.useRef(<span>null</span>);
  <span>const</span> [ctx, setCtx] = useState({});
  useEffect(() =&gt; {
    <span>let</span> canv = canvasRef.current;

    <span>let</span> canvCtx = canv.getContext(<span>"2d"</span>);
    canvCtx.lineJoin = <span>"round"</span>;
    canvCtx.lineCap = <span>"round"</span>;
    canvCtx.lineWidth = <span>5</span>;
    setCtx(canvCtx);
  }, [ctx]);

  <span>return</span> (
    <span><span>&lt;<span>div</span> <span>className</span>=<span>"board"</span>&gt;</span>
      <span>&lt;<span>canvas</span> <span>ref</span>=<span>{canvasRef}</span> /&gt;</span>
    <span>&lt;/<span>div</span>&gt;</span>
  )</span>;
}

<span>export</span> <span>default</span> Board;
</code></pre>
<p>I gave the context some basic settings and added <code>ctx</code> as my second parameter to useEffect to trigger it only when <code>ctx</code> changes and avoid entering an infinite loop of setting its value.</p>
<p>Great! Now we need to take care of the events we will use.</p>
<p>We would need to handle 3 major events:</p>
<ul>
<li>onMouseDown when we click the mouse to start drawing</li>
<li>onMouseMove when we move the mouse while drawing</li>
<li>onMouseUp when we leave the mouse to stop drawing</li>
</ul>
<p>Let's add these events to our canvas element</p>
<pre><code>&lt;canvas
  ref={canvasRef}
  onMouseDown={handleMouseDown}
  onMouseUp={handleMouseUp}
  onMouseMove={handleMouseMove}
/&gt;
</code></pre>

<p>For this event we are going to need a flag to keep track of whether the drawing process is started or not and give it an initial state of <code>false</code></p>
<pre><code><span>const</span> [drawing, setDrawing] = useState(<span>false</span>);
</code></pre>
<p>And in our function we are just going to set it to true</p>
<pre><code><span><span>function</span> <span>handleMouseDown</span>(<span></span>) </span>{
  setDrawing(<span>true</span>);
}
</code></pre>

<p>In this function we are going to do the exact opposite to what we did in the handleMouseDown function</p>
<pre><code><span><span>function</span> <span>handleMouseUp</span>(<span></span>) </span>{
  setDrawing(<span>false</span>);
}
</code></pre>

<p>This is our main function that handles the drawing. We need to move to the last mouse position we detected and draw a line from that point all the way to our current mouse position.</p>
<p>So, first thing is we are going to record the previous position with a start value of (0,0)</p>
<pre><code><span>const</span> [position, setPosition] = useState({ x: <span>0</span>, y: <span>0</span> });
</code></pre>
<p>We also need to record our canvas offset. In our case the canvas would be located at the top left corner of the window, but maybe we would like to add another element or some CSS that will shift its position, later. </p>
<pre><code><span>const</span> [canvasOffset, setCanvasOffset] = useState({ x: <span>0</span>, y: <span>0</span> });
</code></pre>
<p>To guarantee that our mouse position gives us the expected results, we will record the canvas left and top offset, when setting our context.</p>
<pre><code>useEffect(() =&gt; {
    <span>let</span> canv = canvasRef.current;

    <span>let</span> canvCtx = canv.getContext(<span>"2d"</span>);
    canvCtx.lineJoin = <span>"round"</span>;
    canvCtx.lineCap = <span>"round"</span>;
    canvCtx.lineWidth = <span>5</span>;
    setCtx(canvCtx);

    <span>let</span> offset = canv.getBoundingClientRect();
    setCanvasOffset({ x: <span>parseInt</span>(offset.left), y: <span>parseInt</span>(offset.top) });
  }, [ctx]);
</code></pre>
<p>After that, we will easily be able to detect the position by subtracting that offset from our mouse position. Now, we have our previous and current position. Before we begin our path, we just need to check our drawing flag to make sure the process is ongoing and after we're done we will set our position for the next stroke.</p>
<pre><code><span><span>function</span> <span>handleMouseMove</span>(<span>e</span>) </span>{
    <span>let</span> mousex = e.clientX - canvasOffset.x;
    <span>let</span> mousey = e.clientY - canvasOffset.y;
    <span>if</span> (drawing) {
      ctx.strokeStyle = <span>"#000000"</span>;
      ctx.beginPath();
      ctx.moveTo(position.x, position.y);
      ctx.lineTo(mousex, mousey);
      ctx.stroke();
    }
    setPosition({ x: mousex, y: mousey });
  }
</code></pre>
<p>Also, we will need to set the position once the mouse is clicked to have a position to move to for our next stroke, so we need to modify our handleMouseDown function.</p>
<pre><code><span><span>function</span> <span>handleMouseDown</span>(<span>e</span>) </span>{
  setDrawing(<span>true</span>);
  setPosition({
      x: <span>parseInt</span>(e.clientX - canvasOffset.x),
      y: <span>parseInt</span>(e.clientY - canvasOffset.y),
    });
}
</code></pre>
<p>Cool! Now, let's add some CSS to our App.css</p>
<pre><code>* {
  <span>box-sizing</span>: border-box;
}
<span>html</span>,
<span>body</span>,
<span>#root</span> {
  <span>width</span>: <span>100%</span>;
  <span>height</span>: <span>100%</span>;
}
<span>.app</span> {
  <span>height</span>: <span>100vh</span>;
  <span>width</span>: <span>100vw</span>;
  <span>display</span>: flex;
  <span>flex-direction</span>: column;
}
</code></pre>
<p>And our Board.css</p>
<pre><code><span>.board</span> {
  <span>background-color</span>: white;
  <span>cursor</span>: crosshair;
  <span>margin</span>: <span>0</span> auto;
  <span>position</span>: relative;
  <span>width</span>: <span>100%</span>;
  <span>overflow</span>: hidden;
  <span>flex</span>: auto;
  <span>display</span>: flex;
  <span>flex-direction</span>: column;
  <span>justify-content</span>: center;
 …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.ranaemad.com/whiteboard-react-hooks-ckclrvccg0005fls16f1h80mc">https://blog.ranaemad.com/whiteboard-react-hooks-ckclrvccg0005fls16f1h80mc</a></em></p>]]>
            </description>
            <link>https://blog.ranaemad.com/whiteboard-react-hooks-ckclrvccg0005fls16f1h80mc</link>
            <guid isPermaLink="false">hacker-news-small-sites-23830691</guid>
            <pubDate>Tue, 14 Jul 2020 11:36:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Collabera infected with Maze ransomware; employee data stolen]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23830538">thread link</a>) | @darshansavla
<br/>
July 14, 2020 | https://androidrookies.com/recruiting-firm-collabera-infected-by-maze-ransomware-employees-personal-data-stolen/ | <a href="https://web.archive.org/web/*/https://androidrookies.com/recruiting-firm-collabera-infected-by-maze-ransomware-employees-personal-data-stolen/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-8857"><div><div><div><h2>Hackers infected the recruitment and IT consultancy firm Collabera with Maze Ransomware, stole employees data</h2><p>The Basking Ridge, New Jersey, United States-based IT consulting and recruitment firm, Collabera has been hacked and infected by ransomware. The hackers believed to be from Maze ransomware group infiltrated into Collabera servers and stole exposed employee data like&nbsp;names, addresses, contact and social security numbers, dates of birth, employment benefits, and passport and immigration visa details.</p><p>Collabera is a multinational company offering information technology recruiting, staffing, consulting, and business services to companies worldwide. It is a $1billion company with more than 16,000 employees globally.</p><p>The Maze Ransomware group claimed the hacking of Collabera and infecting it with Maze ransomware on their Dark Web website in June. However, Collabera has not confirmed it was the work of Maze Ransomware. The Collabera security team discovered the ransomware attack on 8th June 2020.</p><blockquote><p>On June 8, 2020, Collabera identified malware in its network system consistent with a ransomware attack. We promptly restored access to our backup files and immediately launched an investigation to determine the nature and scope of the event. On June 10, we became aware that the unauthorized party obtained some data from our system.</p><p>Mike Chirico, director Collabera in an email to employees.</p></blockquote><p>While Collabera suffered no consequences of the ransomware, it has emerged that the hackers stole some of the exposed employee data. The company said it was informing every employee whose data was stolen. In the meantime, the company is offering two years of credit and identity monitoring services through Experian to the affected staff.</p></div></div></div></article></div>]]>
            </description>
            <link>https://androidrookies.com/recruiting-firm-collabera-infected-by-maze-ransomware-employees-personal-data-stolen/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23830538</guid>
            <pubDate>Tue, 14 Jul 2020 11:12:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DeepSinger: Singing Voice Synthesis with Data Mined from the Web]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23830477">thread link</a>) | @dgorges
<br/>
July 14, 2020 | https://speechresearch.github.io/deepsinger/ | <a href="https://web.archive.org/web/*/https://speechresearch.github.io/deepsinger/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="entry-text">
				
<ul>
<li>Yi Ren* (Zhejiang University) <a href="mailto:rayeren@zju.edu.cn">rayeren@zju.edu.cn</a></li>
<li>Xu Tan* (Microsoft Research Asia) <a href="mailto:xuta@microsoft.com">xuta@microsoft.com</a></li>
<li>Tao Qin (Microsoft Research Asia) <a href="mailto:taoqin@microsoft.com">taoqin@microsoft.com</a></li>
<li>Jian Luan (Microsoft STCA) <a href="mailto:jianluan@microsoft.com">jianluan@microsoft.com</a></li>
<li>Zhou Zhao (Zhejiang University) <a href="mailto:zhaozhou@zju.edu.cn">zhaozhou@zju.edu.cn</a></li>
<li>Tie-Yan Liu (Microsoft Research Asia) <a href="mailto:tyliu@microsoft.com">tyliu@microsoft.com</a></li>
</ul>
<p><small>* Equal contribution.</small></p>
<h2 id="chinese">Chinese</h2>
<table><thead>
<tr>
<th> / </th>
<th>Sample 1</th>
<th>Sample 2</th>
<th>Sample 3</th>
</tr></thead><tbody>
<tr>
<td>Data crawling</td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/zh/xx_0K2P2e1dc_5.wav" autoplay="">Your browser does not support the audio element.</audio><br>Lyrics: 爱从不容许人三心两意<br>Phonemes: PAD ai c ong b u r ong x v r en s an x in l iang PAD i</td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/zh/xx_0K2P2e1dc_15.wav" autoplay="">Your browser does not support the audio element.</audio><br>Lyrics: 遮住你的眼睛<br>Phonemes: zh e zh u n i d e PAD ian j ing</td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/zh/xx_XIKddfe0_37.wav" autoplay="">Your browser does not support the audio element.</audio><br>Lyrics: 好久好久<br>Phonemes: h ao j iou h ao j iou</td>
</tr>
<tr>
<td>Singing and accompaniment separation</td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_5_raw.wav" autoplay="">Your browser does not support the audio element.</audio> </td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_15_raw.wav" autoplay="">Your browser does not support the audio element.</audio>  </td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/zh/XIKddfe0_37_raw.wav" autoplay="">Your browser does not support the audio element.</audio></td>
</tr>
<tr>
<td>Lyrics-to-singing alignment</td>
<td>Attention map <img src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_5_attn_0.8244.png"><br> Lyrics-to-singing alignment <img src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_5_splits.png"> </td>
<td>Attention map <img src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_15_attn_0.8329.png"><br> Lyrics-to-singing alignment <img src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_15_splits.png"></td>
<td>Attention map <img src="https://speechresearch.github.io/audio/deepsinger/zh/XIKddfe0_37_attn_0.3764.png"></td>
</tr>
<tr>
<td>Data filtration</td>
<td>Keep (Splitting Reward: $\mathcal{O} = 0.8244 $)  </td>
<td>Keep (Splitting Reward: $\mathcal{O} = 0.8359 $)  </td>
<td>Discard (Splitting Reward: $\mathcal{O} = 0.3764 $)</td>
</tr>
<tr>
<td>Singing modeling</td>
<td>
$\textit{GT (Linear+GL)}$   <br>  <audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_5_gt.wav" autoplay="">Your browser does not support the audio element.</audio> <br>  
$\textit{DeepSinger}$  <br>  <audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_5.wav" autoplay="">Your browser does not support the audio element.</audio> <br>  
Pitch Plot
<img src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_5_pitch.png">
</td>
<td>
$\textit{GT (Linear+GL)}$   <br>  <audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_15_gt.wav" autoplay="">Your browser does not support the audio element.</audio> <br> 
 $\textit{DeepSinger}$  <br>  <audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_15.wav" autoplay="">Your browser does not support the audio element.</audio> <br>
 Pitch Plot
 <img src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_15_pitch.png">
</td>
<td>
<p>/</p>
</td>
</tr>
</tbody></table>
<p>
P.S. 1) $\textit{GT}$, the ground-truth audio; 2) $\textit{GT (Linear+GL)}$, where we synthesize voices based on the ground-truth linear-spectrograms using Griffin-Lim; 3) $\textit{DeepSinger}$, where the audio is generated by DeepSinger.
</p>
<!-- 
## English
<table><thead>
<tr>
<th style="text-align: center"> / </th>
<th style="text-align: center">Sample 1</th>
<th style="text-align: center">Sample 2</th>
<th style="text-align: center">Sample 3</th>
</tr></thead><tbody>
<tr>
<td>Data crawling</td>
<td><audio controls="controls" ><source src="../audio/deepsinger/en/xx_8GfscTff70f_1.wav" autoplay/>Your browser does not support the audio element.</audio><br>Lyrics: But sometimes I feel so<br>Phonemes: b ʌ t s ʌ m t aɪ m z aɪ f iː l s oʊ</td>
<td><audio controls="controls" ><source src="../audio/deepsinger/en/xx_8GfscTff70f_39.wav" autoplay/>Your browser does not support the audio element.</audio><br>Lyrics: In my dreams I'm not so far away from home<br>Phonemes: ɪ n m aɪ d ɹ iː m z aɪ m n ɑː t s oʊ f ɑː ɹ ɐ w eɪ f ɹ ʌ m h oʊ m</td>
<td><audio controls="controls" ><source src="../audio/deepsinger/en/xx_8GfscTff70f_37.wav" autoplay/>Your browser does not support the audio element.</audio><br>Lyrics: All my life all the time so far away from home<br>Phonemes: ɔː l m aɪ l aɪ f ɔː l ð ə t aɪ m s oʊ f ɑː ɹ ɐ w eɪ f ɹ ʌ m h oʊ m</td>
</tr>

<tr>
<td>Singing and accompaniment separation</td>
<td><audio controls="controls" ><source src="../audio/deepsinger/en/8GfscTff70f_1_raw.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td><audio controls="controls" ><source src="../audio/deepsinger/en/8GfscTff70f_39_raw.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td><audio controls="controls" ><source src="../audio/deepsinger/en/8GfscTff70f_37_raw.wav" autoplay/>Your browser does not support the audio element.</audio></td>
</tr>


<tr>
<td>Lyrics-to-singing alignment</td>
<td>Attention map <img src='../audio/deepsinger/en/8GfscTff70f_1_attn_0.7427.png'/><br> Lyrics-to-singing alignment <img src='../audio/deepsinger/en/8GfscTff70f_1_splits.png'/> </td>
<td>Attention map <img src='../audio/deepsinger/en/8GfscTff70f_39_attn_0.7306.png'/><br> Lyrics-to-singing alignment <img src='../audio/deepsinger/en/8GfscTff70f_39_splits.png'/></td>
<td>Attention map <img src='../audio/deepsinger/en/8GfscTff70f_37_attn_0.4725.png'/></td>
</tr>

<tr>
<td>Data filtration</td>
<td>Keep (Splitting Reward: $\mathcal{O} = 0.7427 $) </td>
<td>Keep (Splitting Reward: $\mathcal{O} = 0.7306 $)  </td>
<td>Discard (Splitting Reward: $\mathcal{O} = 0.4725 $)</td>
</tr>

<tr>
<td>Singing modeling</td>

<td>
$\textit{GT (Linear+GL)}$  <br>  <audio controls="controls" ><source src="../audio/deepsinger/en/8GfscTff70f_1_gt.wav" autoplay/>Your browser does not support the audio element.</audio> <br>  
$\textit{DeepSinger}$  <br>  <audio controls="controls" ><source src="../audio/deepsinger/en/8GfscTff70f_1.wav" autoplay/>Your browser does not support the audio element.</audio> <br>  
Pitch Plot
<img src='../audio/deepsinger/en/8GfscTff70f_1_pitch.png'/>
</td>

<td>
$\textit{GT (Linear+GL)}$  <br>  <audio controls="controls" ><source src="../audio/deepsinger/en/8GfscTff70f_39_gt.wav" autoplay/>Your browser does not support the audio element.</audio> <br> 
 $\textit{DeepSinger}$  <br>  <audio controls="controls" ><source src="../audio/deepsinger/en/8GfscTff70f_39.wav" autoplay/>Your browser does not support the audio element.</audio> <br>
 Pitch Plot
 <img src='../audio/deepsinger/en/8GfscTff70f_39_pitch.png'/>
</td>

<td>

/

</td>
</tr>

</tbody></table>
-->
<h2 id="cantonese">Cantonese</h2>
<table><thead>
<tr>
<th> / </th>
<th>Sample 1</th>
<th>Sample 2</th>
<th>Sample 3</th>
</tr></thead><tbody>
<tr>
<td>Data crawling</td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/hk/xx_bClau824b25f_3.wav" autoplay="">Your browser does not support the audio element.</audio><br>Lyrics: 我已经不懂心痛<br>Phonemes: ŋ o5 j i5 ɡ inɡ1 b a1 t d unɡ2 s a1 m t unɡɜ</td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/hk/xx_bClau824b25f_9.wav" autoplay="">Your browser does not support the audio element.</audio><br>Lyrics: 或你会了解在孤单中的心痛<br>Phonemes: w aa6 k n ei5 w ui6 l iu5 ɡ aai2 z oi6 ɡ u1 d aa1 n z unɡ1 d i1 k s a1 m t unɡɜ</td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/hk/xx_bBfZ2b39bf_32.wav" autoplay="">Your browser does not support the audio element.</audio><br>Lyrics: 唔知点解 我成日都好担心<br>Phonemes: nɡ4 z i1 d i2 m ɡ aai2 ŋ o5 s inɡ4 j a6 t d ou1 h ou2 d aa1 m s a1 m</td>
</tr>
<tr>
<td>Singing and accompaniment separation</td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_3_raw.wav" autoplay="">Your browser does not support the audio element.</audio></td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_9_raw.wav" autoplay="">Your browser does not support the audio element.</audio></td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/hk/bBfZ2b39bf_32_raw.wav" autoplay="">Your browser does not support the audio element.</audio></td>
</tr>
<tr>
<td>Lyrics-to-singing alignment</td>
<td>Attention map <img src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_3_attn_0.8105.png"> <br> Lyrics-to-singing alignment <img src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_3_splits.png"></td>
<td>Attention map <img src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_9_attn_0.7372.png"><br> Lyrics-to-singing alignment <img src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_9_splits.png"></td>
<td>Attention map <img src="https://speechresearch.github.io/audio/deepsinger/hk/bBfZ2b39bf_32_attn_0.3601.png"></td>
</tr>
<tr>
<td>Data filtration </td>
<td>Keep (Splitting Reward: $\mathcal{O} = 0.8105 $) </td>
<td>Keep (Splitting Reward: $\mathcal{O} = 0.7372 $)  </td>
<td>Discard (Splitting Reward: $\mathcal{O} = 0.3601 $)</td>
</tr>
<tr>
<td>Singing modeling</td>
<td>
$\textit{GT (Linear+GL)}$  <br>  <audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_3_gt.wav" autoplay="">Your browser does not support the audio element.</audio> <br>  
$\textit{DeepSinger}$  <br>  <audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_3.wav" autoplay="">Your browser does not support the audio element.</audio> <br>  
Pitch Plot
<img src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_3_pitch.png">
</td>
<td>
$\textit{GT (Linear+GL)}$  <br>  <audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_9_gt.wav" autoplay="">Your browser does not support the audio element.</audio> <br> 
 $\textit{DeepSinger}$  <br>  <audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_9.wav" autoplay="">Your browser does not support the audio element.</audio> <br>
 Pitch Plot
 <img src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_9_pitch.png">
</td>
<td>
<p>/</p>
</td>
</tr>
</tbody></table>

<p><a href="https://speechresearch.github.io/unsuper/">Almost Unsupervised Text to Speech and Automatic Speech Recognition</a><br>
<a href="https://speechresearch.github.io/fastspeech/">FastSpeech: Fast, Robust and Controllable Text to Speech</a><br>
<a href="https://speechresearch.github.io/multispeech/">MultiSpeech: Multi-Speaker Text to Speech with Transformer</a><br>
<a href="https://speechresearch.github.io/seminas/">Semi-Supervised Neural Architecture Search</a><br>
<a href="https://speechresearch.github.io/lrspeech/">LRSpeech: Extremely Low-Resource Speech Synthesis and Recognition</a><br>
<a href="https://speechresearch.github.io/fastspeech2/">FastSpeech 2: Fast and High-Quality End-to-End Text-to-Speech</a><br>
<a href="https://speechresearch.github.io/uwspeech/">UWSpeech: Speech to Speech Translation for Unwritten Languages</a><br></p>
<!-- ### Good Alignment Example

<p>
Splitting Reward: $\mathcal{O} = 0.8024 $  
</p>

<img src='../audio/deepsinger/good_align.png'/>
<audio controls="controls" ><source src="../audio/deepsinger/good_align.wav" autoplay/>Your browser does not support the audio element.</audio>

### Bad Alignment Example

<p>
Splitting Reward: $\mathcal{O} = 0.3196 $  
</p>

<img src='../audio/deepsinger/bad_align.png'/>
<audio controls="controls" ><source src="../audio/deepsinger/bad_align.wav" autoplay/>Your browser does not support the audio element.</audio>


## Audio Samples

<!-- ### Chinese  -->
<!-- 
*爱从不容许人三心两意*

<table><thead>
<tr>
<th style="text-align: center">Raw Audio</th>
<th style="text-align: center">Vocal (after seperation)</th>
<th style="text-align: center">GT (Linear+GL)</th>
<th style="text-align: center">DeepSinger</th>
</tr></thead><tbody>
<tr>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/raw/0.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/gt/0.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/gt_gl/0.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/ds/0.wav" autoplay/>Your browser does not support the audio element.</audio></td>
</tr>
</tbody></table>


*遇见浑然天成的交集*

<table><thead>
<tr>
<th style="text-align: center">Raw Audio</th>
<th style="text-align: center">Vocal (after seperation)</th>
<th style="text-align: center">GT (Linear+GL)</th>
<th style="text-align: center">DeepSinger</th>
</tr></thead><tbody>
<tr>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/raw/1.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/gt/1.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/gt_gl/1.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/ds/1.wav" autoplay/>Your browser does not support the audio element.</audio></td>
</tr>
</tbody></table>



*遮住你的眼睛*

<table><thead>
<tr>
<th style="text-align: center">Raw Audio</th>
<th style="text-align: center">Vocal (after seperation)</th>
<th style="text-align: center">GT (Linear+GL)</th>
<th style="text-align: center">DeepSinger</th>
</tr></thead><tbody>
<tr>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/raw/2.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/gt/2.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/gt_gl/2.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/ds/2.wav" autoplay/>Your browser does not support the audio element.</audio></td>
</tr>
</tbody></table>

<br> --> 

			</section></div>]]>
            </description>
            <link>https://speechresearch.github.io/deepsinger/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23830477</guid>
            <pubDate>Tue, 14 Jul 2020 11:02:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Could predictive database queries replace machine learning models?]]>
            </title>
            <description>
<![CDATA[
Score 85 | Comments 42 (<a href="https://news.ycombinator.com/item?id=23830474">thread link</a>) | @tlarkworthy
<br/>
July 14, 2020 | https://aito.ai/blog/could-predictive-database-queries-replace-machine-learning-models | <a href="https://web.archive.org/web/*/https://aito.ai/blog/could-predictive-database-queries-replace-machine-learning-models">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote><p>This post appeared first on <a href="https://towardsdatascience.com/predictive-queries-vs-supervised-ml-models-ee7f17e4840e">Towards Data Science</a> in July 12th, 2020.</p></blockquote><p>One of the greatest trends in today’s technology landscape is the <a href="http://knowledge.wharton.upenn.edu/article/democratization-ai-means-tech-innovation/">democratization of machine learning</a>. Because the commodity state-of-the-art models, better tooling and better access to hardware: machine learning is becoming an everyday tool in the companies’ toolbox.</p><p>The ML democratization is still an on-going trend and given the disruption in this space it’s worth asking: where will this transformation take us? What the future of the everyday ML will look like?</p><p>Predictive queries are an interesting take on machine learning, especially in the ML democratization context. Solutions like <a href="http://probcomp.csail.mit.edu/">MIT’s</a> <a href="https://github.com/probcomp/bayeslite">BayesDB/BayesLite</a> and Aito provide a way to get arbitrary predictions instantly with SQL-like queries. As an example, here’s a predictive query in Aito:</p><div data-language="json"><pre><code><span>{</span>
  <span>"from"</span><span>:</span> <span>"invoice_data"</span><span>,</span>
  <span>"where"</span><span>:</span> <span>{</span>
    <span>"Item_Description"</span><span>:</span> <span>"Packaging design"</span><span>,</span>
    <span>"Vendor_Code"</span><span>:</span> <span>"VENDOR-1676"</span>
  <span>}</span><span>,</span>
  <span>"predict"</span><span>:</span> <span>"Product_Category"</span>
<span>}</span></code></pre></div><p>As such: the predictive queries seem like an easier, faster and radically different way to do machine learning. They give a glimpse of a future, where anyone can do machine learning as easily as one does database queries.</p><p>This article gives a brief introduction to the predictive queries, and it compares the predictive queries to supervised learning through 3 different aspects that are:</p><ol><li>The workflow, comparing the easiness and the costs between predictive queries and supervised machine learning</li><li>The architecture, comparing the high level differences between using predictive queries and using supervised models</li><li>And the qualitative properties (scaling, accuracy) as the quality is an obvious concern for an emerging, if promising, technology.</li></ol><h2>Introduction to the predictive queries</h2><p>Predictive queries resemble normal database queries with the exception that they provide predictions about the unknown, while the traditional database queries provide facts about the known. Here’s an example of the BQL (Bayesian Query Language) query done against BayesDB/BayesLite database:</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/pq-vs-ml-predictive-queries-in-bayeslite.png" alt=""></p></div><p><span>Predictive BayesQL queries in BayesLite. BayesQL is based on SQL and it provides a very elegant way to query arbitrary estimates. This query can be executed after the CREATE POPULATION, CREATE ANALYSIS, INITIALIZE ANALYSIS and ANALYZE operations. </span></p></div><p>In essence, the predictive queries can provide a very SQL-like alternative to the supervised ML models with the key differences that:</p><ol><li><p>While supervised machine learning models need to be configured, trained and deployed before usage, the predictive queries provide instant answers after the database is prepared with data. As such: the predictive queries have a different workflow.</p></li><li><p>While supervised machine learning is always specialized for a single prediction from A to B, predictive queries can be used a) to instantly predict any unknown X based on any known Y and b) to provide also recommendations, smart search and pattern mining. As such, the supervised models are narrow, while the predictive queries are multipurpose, which has implications on the architecture.</p></li><li><p>While with the supervised machine learning the narrow models are explicitly formed train time, the predictive queries do multi-purpose modeling write time or narrow modeling during query time. As such: the predictive queries are technically more challenging.</p></li></ol><p>Only few solutions exist, that provide such predictive queries. One is the mentioned BayesDB/BayesLite, which creates an in-memory multi-purpose models in a special preparation phase. Another solution is Aito.ai, which does query-time narrow modeling without explicit preparations. Here’s is an example of the Aito workflow:</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/pq-vs-ml-predictive-queries-in-3-steps.png" alt=""></p></div><p><span>Predictive BayesQL queries in BayesLite. BayesQL is based on SQL and it provides a very elegant way to query arbitrary estimates. This query can be executed after the CREATE POPULATION, CREATE ANALYSIS, INITIALIZE ANALYSIS and ANALYZE operations. </span></p></div><p>We are focusing the following comparisons on Aito. We feel this focus is justified as in Aito we are more familiar with the solution, and it is mature enough to serve the end customers in live production settings. While BayesLite is extremely impressive and their BQL interface and DB/ML integration are worth envy: BayesLite seems to have properties like the 16 minute preparation phase for simple data, which are not consistent with the presented arguments.</p><p>So let’s next dig deeper on the difference in workflow, architecture and quality between the predictive queries and supervised ML models.</p><h2>1. The Workflow</h2><p>The first difference between predictive queries and the traditional supervised models relates to the workflow and the costs.</p><p>Supervised ML models are deployed typically in data science projects, which have several steps like the handover to the data scientist, data preparation, feature engineering, model fitting, deployment, integrations, retraining and monitoring &amp; maintenance. As an addition to this linear progression, you also often have an iteration phase, where the results are improved by refining the data, the preparations, the features, the models, the deployment or the integrations.</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/pq-vs-ml-data-science-project-workflow.png" alt=""></p></div><p><span>A simplified version of the data science project.</span></p></div><p>Taking a supervised model to production may take several weeks or months from one to two persons. This can raise the price point up to hundred thousand euros per model. If you need several models, you need several data science projects, leading to multiplied expenses and delays.</p><p>Now this process changes rather dramatically, if you implement the machine learning functionality with predictive queries. With predictive queries the workflow is in essence the following:</p><ol><li>Prepare the auxiliary <a href="https://aito.ai/blog/introducing-a-new-database-category-the-predictive-database/">predictive database</a> once (if it’s not used as the main database)</li><li>Verify good enough prediction quality with evaluate requests</li><li>Integrate the predictive queries like you would integrate SQL queries</li><li>Write the test/evaluation cases, push these to Git and let the CI handle the regression testing</li><li>If seen as necessary: track the in-production prediction quality with analytics and display the metrics in the product dashboard.</li></ol><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/pq-vs-ml-predictive-query-workflow.png" alt=""></p></div><p><span>The workflow with the predictive queries is similar to the workflow with the database queries. Still, because predictive functionality is statistical and its behavior may drift as the data changes: it is advisable to verify the prediction quality (step 2) before implementation and monitor the prediction quality in production (step 5).</span></p></div><p>While putting an auxiliary database (like ElasticSearch) into production can take weeks, the expense related to putting each query into production is closer to the expense of using search/database queries. Often such queries form only a small part of the related functionality’s expense, and often the query based functionality can be implemented in hours and put into production in days.</p><p>This dramatic difference between the workflows and the expenses are explained a) partly by the <a href="https://aito.ai/blog/introducing-a-new-database-category-the-predictive-database/">predictive database</a>’s AutoML capabilities that are accelerated by a specialized database and b) partly by the reduced need for deployments and integrations as the data and the ML are already integrated into a single system. The complex phases of the data science project get systematically eliminated or simplified:</p><ol><li>The handover of the data science project to the data scientist is not needed as the predictive query workflow is easy enough for the software developers.</li><li>Data preparation and feature engineering steps can be greatly eliminated with the ML-database integration. You don’t need to re-prepare and re-upload the data, if the data is already in the database. You don’t need to manually aggregate data into flat data frames, if you can do <a href="https://aito.ai/docs/articles/utilizing-relationships-in-aito/">inference through the database references</a>. You don’t need to manually featurize text either, as the predictive database analyzes the <a href="https://aito.ai/docs/api/#schema-analyzer">text automatically</a> just like ElasticSearch. Last: you don’t need to manage feature redundancies, if the database has built-in <a href="https://aito.ai/blog/introducing-concept-learning-to-free-you-from-feature-engineering/">feature learning capabilities</a>.</li><li>Modeling phase can be automated with a single sophisticated model that provides good enough results for most applications.</li><li>Per model cloud deployment, live integrations and retraining of models simply disappear, because you don’t need to ‘deploy’ or retrain the predictive queries. Instead you integrate one auxiliary predictive database like you would integrate <a href="https://www.elastic.co/">ElasticSearch</a>. If you use the predictive database as your main database, you can omit even that one integration.</li><li>Maintenance is easier, because instead of maintaining deployed infrastructure for each prediction target, you maintain the SQL-like queries like you would maintain code with Git &amp; CI.</li></ol><p>As a consequence, the workflow and the cost of implementing ML via predictive queries is similar to the process of implementing normal business logic via SQL.</p><p>The second difference between the predictive queries and the supervised models is the narrowness and it’s implications on the software architecture.</p><p>Famously: the supervised ML models are <em>narrow</em> in 2 different respects:</p><p>1.Narrowness of the prediction setting. Supervised learning models are essentially narrow functions from A (e.g. text) to B (category), which means that if you have 10 different problems, you end up with with 10 different supervised ML models.
2. Narrowness of the predictive functionality type. A single kind of supervised method can typically serve only one kind of predictions. For this reason you often need completely separate systems or products to implement predictions, recommendations, smart search and pattern mining.d up with with 10 different supervised ML models.</p><p>This combined narrowness has negative implications on the architecture. If you have 10 different predictive functionalities that mix prediction, recommendation and smart search use cases: you end up struggling with a very complex system. The system may include separate supervised model platform with half dozen deployed models, separate recommendation system, a separate smart searching product and separate pattern mining tools. Such complexity is hard to learn, master and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aito.ai/blog/could-predictive-database-queries-replace-machine-learning-models">https://aito.ai/blog/could-predictive-database-queries-replace-machine-learning-models</a></em></p>]]>
            </description>
            <link>https://aito.ai/blog/could-predictive-database-queries-replace-machine-learning-models</link>
            <guid isPermaLink="false">hacker-news-small-sites-23830474</guid>
            <pubDate>Tue, 14 Jul 2020 11:01:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Purism-Librem13v4]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23830046">thread link</a>) | @luu
<br/>
July 14, 2020 | https://anarc.at/hardware/laptop/purism-librem13v4/ | <a href="https://web.archive.org/web/*/https://anarc.at/hardware/laptop/purism-librem13v4/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">


          

            <p>The <a href="https://puri.sm/products/librem-13/">Purism Librem 13</a> is a 13" laptop that's similar to the
Macbook Air but slightly heavier and thicker, from what I
understand. I have the <code>v4</code> means it's the fourth hardware version of
the device. This is the latest incarnation of the <a href="https://anarc.at/hardware/angela/">angela</a>
node.</p>

<p>TL;DR: I recommend people avoid the Purism brand and products. I find
they have questionable politics, operate in a "libre-washing" fashion,
and produce unreliable hardware. Will not buy again.</p>






<ul>
<li>Operating system: PureOS</li>
<li>TPM: Included</li>
<li>Battery life: Roughly 7 to 9 hours (actual: more like 6h)</li>
<li>Processor: Core i7 7500U (Kabylake)</li>
<li>Display: 13.3" 1920×1080</li>
<li>Graphics: Intel HD Graphics 620</li>
<li>Memory: Up to 32GB, DDR4 at 2133 MHz</li>
<li>Storage: 2.5" SATA + NVMe-capable M.2 slots</li>
<li>Chassis: Black anodized aluminium</li>
<li>Webcam: 720p 1.0 megapixel</li>
<li>Dimensions: 325×219×18mm</li>
<li>Weight: 1.4kg</li>
<li>Wireless: Atheros 802.11n w/ Two Antenna</li>
<li>Radio hardware killswitch: Yes</li>
<li>Mic and cam killswitches: Yes</li>
<li>Audio port: 1 headphone/line output jack</li>
<li>USB ports: 2 USB 3.0 Ports (1 type C, data transfer only)</li>
<li>External monitor output: 1 HDMI Port (4K capable @ 30Hz max)</li>
<li>Card reader: Yes, 2-in-1 SD/MMC</li>
<li>Backlit keyboard: Yes</li>
<li>Touch interface: Elantech Multitouch Trackpad</li>
<li>Thermal design: Low noise fan (actual: not really, quite noisy when
all CPUs are maxed)</li>
</ul>


<p>The machine came with a 250GB Crucial SSD drive with PureOS
pre-installed, even if I ordered it without storage.</p>

<h2 id="semi-standard-power-connector"><a name="index1h2"></a>Semi-standard power connector</h2>

<p>The power connector is <a href="https://learn.sparkfun.com/tutorials/connector-basics/power-connectors">somewhat standard</a>: 19V DC on a 5.5mm
sleeve with 2.5 positive pin, with a <a href="https://en.wikipedia.org/wiki/IEC_60320#C5/C6_coupler">C5/C6 cable</a> for the AC side
(as opposed to the more standard C13/C14 coupler, mind you). I was
able to find a "universal 19V adapter" for ~60$ at a local store that
also supported other barrel connectors.</p>

<p>It would be better if the laptop would charge through USB-C,
naturally, as <em>that</em> is slowly becoming the standard for charging
computing devices, but that will have to do for now.</p>

<h2 id="good-monitor"><a name="index2h2"></a>Good monitor</h2>

<p>The monitor shipped with the Librem is actually quite good by my
standards (1920x1080 / 1080p / FullHD). It does mean messing around
with <a href="https://wiki.debian.org/MonitorDPI">HiDPI</a> settings which I haven't quite figured out yet.</p>

<p><a href="https://vincent.bernat.ch/en/blog/2018-4k-hidpi-dual-screen-linux">This post</a> seems to have good resources. From what I understand,
the resolution of the screen is actually 166dpi, which takes some
configuring to display properly. This can be computed from the aspect
ratio (16:9), the resolution (1920x1080) and the diagonal of the
screen (13.3"). According to <a href="https://www.sven.de/dpi/">this calculator</a>, this is the
formula:</p>

<pre><code>Display size: 11.59" × 6.52" = 75.59in² (29.44cm × 16.56cm = 487.64cm²) at 165.63 PPI, 0.1534mm dot pitch, 27434 PPI² 
</code></pre>

<p>All this does make my old monitor (which I found in the basement) look
like crap. So I need to find a <a href="https://forums.puri.sm/t/suitable-external-monitor-for-librem-13/5627">new monitor</a>, arguably not a
problem with the Librem per se of course...</p>

<p>It seems the Librem can drive 1440p, so not "4K UHD" (3840x2160), but
"QHD" (2560x1440) which should be more than enough.</p>

<h2 id="liberated-boot"><a name="index3h2"></a>Liberated boot</h2>

<p>The Purism folks did a pretty awesome job at liberating their
BIOS. They run their own version of coreboot they call
<a href="https://docs.puri.sm/PureBoot.html">Pureboot</a>. In theory, it should be easier to setup a trusted,
<a href="http://wiki.debian.org/SecureBoot">SecureBoot</a> but in practice I have yet to set that up.</p>

<p>I did try to configure the laptop with an encrypted <code>/boot</code>, but that
didn't go so well. First, I get a double password prompt: once in
<code>grub</code> and once in the <code>initramfs</code>. But more annoying is the <code>grub</code>
prompt has no retry: if you fail, you drop in the rescue shell which
is really impractical.</p>

<p>(Update: that is, of course, not specific to Purism or PureOS, but a
limitation in grub itself.)</p>

<p>Finally, Pureboot doesn't support encrypted <code>/boot</code> so it actually
makes it <em>harder</em> to implement trusted boot.</p>

<p>The coreboot stuff needs to be updated, and instructions are available
<a href="https://puri.sm/coreboot/">on the Purism website</a>.</p>

<h2 id="excellent-linux-support"><a name="index4h2"></a>Excellent Linux support</h2>

<p>On top of the liberated BIOS, it must be said the device has
<em>excellent</em> support for free operating systems. <em>Every</em> device on the
machine has full support in the Linux kernel, even the "older" version
in Debian stretch (Linux 4.9). No binary blobs, no proprietary
drivers, even for wifi.</p>

<p>That is just awesome. It's the first device, in a long time, that
gives me this freedom, so it should be acknowledged and celebrated.</p>

<p>Update: I still have some <code>non-free</code> packages installed:</p>

<ul>
<li><p>the Intel CPU firmware package (<a href="http://packages.debian.org/intel%2Dmicrocode">intel-microcode</a>)</p></li>
<li><p>I also use some "non-free" documentation packages (<a href="http://packages.debian.org/doc%2Drfc">doc-rfc</a>, <a href="http://packages.debian.org/emacs%2Dcommon%2Dnon%2Ddfsg">emacs-common-non-dfsg</a>, <a href="http://packages.debian.org/make%2Ddoc">make-doc</a>)</p></li>
<li><p>Bluetooth requires <a href="http://packages.debian.org/firmware%2Datheros">firmware-atheros</a></p></li>
</ul>


<p>When building the <code>initramfs</code>, there are warnings about the <code>i915</code>
graphics controller, which is solved by installing the <a href="http://packages.debian.org/firmware%2Dmisc%2Dnonfree">firmware-misc-nonfree</a> package, but the graphics card works without
the firmware. Apparently, the warnings are harmless and indeed PureOS
fixed <a href="https://tracker.pureos.net/T362">the bug</a> by simply <a href="https://source.puri.sm/pureos/core/initramfs-tools/commit/005ca5b834fa7ee44bb913d74b4ff2aa542fc9d1">disabling all such warnings</a>.3</p>

<p>The Debian-specific stuff is also documented in <a href="https://wiki.debian.org/InstallingDebianOn/Purism/Librem%2013">the Debian wiki</a>.</p>

<h2 id="good-speakers"><a name="index5h2"></a>Good speakers</h2>

<p>The builtin speakers sound great.</p>



<p>I have a few issues with the device.</p>

<h2 id="weird-keyboard-layout"><a name="index6h2"></a>Weird keyboard layout</h2>

<p>The <a href="https://forums.puri.sm/t/keyboard-layout-unable-to-recognize-pipe/2022">keyboard layout is strange</a>: the key above <kbd>enter</kbd>,
instead of sending <kbd>\</kbd> or <kbd>|</kbd>, sends
"chevrons". This is due to the Purism folks expecting you to pick the
"US international" keyboard instead of the "US" keyboard, which is a
very strange pick, as the "US" keyboard seems pretty standard. The
workaround is to drop this in your <code>udev</code> configuration, say in
<code>/etc/udev/hwdb.d/90-purism-pipe-symbol-fix.hwdb</code>:</p>

<pre><code>evdev:atkbd:dmi:bvn*:bvr*:bd*:svnPurism:pnLibrem13v4*
 KEYBOARD_KEY_56=backslash
</code></pre>

<p>Then running:</p>

<pre><code>sudo systemd-hwdb update
sudo udevadm trigger
</code></pre>

<p>The keyboard layout, in general, is a little unique: the sound buttons
are split across the <kbd>F4</kbd> key (mute) and
<kbd>-</kbd>/<kbd>=</kbd> (volume up/down keys) for some reason.</p>

<p>The <kbd>PrtSc</kbd> key <a href="https://forums.puri.sm/t/does-alt-sysrq-work-on-librem-laptops/5290/9">can be as SysRq</a> but is <em>backwards</em>
(<kbd>ScrLk</kbd> <kbd>PrtSc</kbd>) to their usual order
(<kbd>PrtSc</kbd> <kbd>ScrLk</kbd>).</p>

<h2 id="limited-usb-c-port"><a name="index7h2"></a>Limited USB-C port</h2>

<p>The USB-C port <a href="https://forums.puri.sm/t/is-hdmi-over-usb-c-possible-on-13v2/2020">does not support video</a> which makes it limited to
charging and data transfer. It can also not charge the laptop itself,
as there's a separate power connector, losing many of the benefits
usually associated with USB-C.</p>

<p>Ideally, a USB-C port might be used as a universal docking port: one
wire to plug and you have power, video, audio, and USB for keyboard
and mouse. Unfortunately, I'm still stuck with about 4 wires to plugin
when I come into the office, something I was hoping to avoid. People
have <a href="https://forums.puri.sm/t/please-recommend-a-port-replicator-docking-station/1115">looked for a dock station</a> without success.</p>

<h2 id="shipping-delays-doa"><a name="index8h2"></a>Shipping delays, DOA</h2>

<p>I waited almost four weeks to have my laptop delivered. Presumably
this was due to a <a href="https://forums.puri.sm/t/where-was-purism-moving/5799/">warehouse move</a> but I found that communication
about the issue could have been better. Worse: the laptop was <a href="https://forums.puri.sm/t/librem-13v3-bricked/5714/19?u=anarcat">dead on
arrival</a> (DOA) so I had to return it, adding another week delay for
getting an actual working laptop. FedEx even charged me for the return
even though Purism actually issued a shipping label, something I still
haven't quite resolved.</p>

<p>Update: I ended up paying over 260$ in shipping fees to Fedex, in the
end. I first paid around 70$ for the first laptop sent, then Fedex
sent me <em>another</em> 200$ bill for the <em>second</em> laptop. Purism were
unable to help me with this issue and Fedex has been totally useless
as well. I've tried to reach to both organizations to get around those
fees but the time wasted waiting on hold and support has outgrown the
possible savings I could to by not paying the damn bill, so I just
paid it now.</p>

<h2 id="bright-leds-not-accessible-when-lid-closed"><a name="index9h2"></a>Bright LEDs, not accessible when lid closed</h2>

<p>There are three leds on the top right of the keyboard: one for wifi,
battery and power. They are very bright and even though they can
technically be dimmed, the firmware is not open so there's <a href="https://forums.puri.sm/t/is-there-a-way-to-dim-the-leds-on-the-13-v2/1172">no way to
dim the LEDs</a>.</p>

<h2 id="no-ethernet-port"><a name="index10h2"></a>No ethernet port</h2>

<p>That was a deal breaker for me originally, but I changed my
mind. First, I don't need gigabit transfer speeds that often. Then my
office doesn't have wired connectivity yet, so it is not that
useful. Plus, I can afford to have a USB dongle there with a gigabit
ethernet port, indeed, I already have one of those USB hubs. So not
that big of a deal.</p>

<h2 id="libre-washing"><a name="index11h2"></a>Libre-washing</h2>

<p>I have found Purism's commitment to free hardware and free software to
be questionable. While, yes, they try to provide a <a href="#liberated-boot">liberated boot</a>
and coreboot-based BIOS, that BIOS is not free software. At best they
"neuter" the Intel Management Engine, but you still require non-free
firmware to operate a Librem Computer, from the CPU down to the
Bluetooth and Wifi hardware. Even if that is a very common pattern on
laptops and phone, it is a huge disconnect with the "purity" and
"freedom" narrative on their website.</p>

<p>For example, the replacement for the Librem 13, called Librem 14,
claims to be:</p>

<blockquote><p><strong>The first 14″ laptop designed to protect your digital life</strong></p>

<p>Ultra-portable workstation laptop that was designed chip-by-chip,
line-by-line, to respect your rights to privacy, security, and
freedom.</p></blockquote>

<p>Yet it still ships with Intel processors, known for a large variety of
fundamental security issues that are part of the hardware design,
which Intel refuses to fix. That it ships <a href="https://puri.sm/coreboot/">coreboot</a> on top of that
is besides the point: coreboot, as shipped by Purism, is not open
source, or at least ships proprietary blobs.</p>

<p>Compare this with the work System76 has been doing in recent
times. While they brand themselves as just a company shipping Linux
laptops, they <a href="https://blog.system76.com/post/187072707563/the-new-firmware-manager-updating-firmware-across">work with the de-facto standard LVFS</a> (even though
that is a <a href="https://blog.system76.com/post/173801677358/system76-and-lvfs-what-really-happened">bumpy ride</a>), actually <a href="https://blog.system76.com/post/612315972866637824/a-look-back-at-manufacturing">design and prototype their own
hardware</a>, and <a href="https://opensource.com/article/20/1/system76-open-source-firmware">liberated their keyboard microcontroller</a>. They
have even started <a href="https://blog.system76.com/post/186655523269/open-firmware-and-more-news-from-july">working on an open Thunderbolt
microcontroller</a>. And while those might sound like small things
compared to liberating the CPU firmware, I will point out that they
actually <em>succeed</em> in completely liberating those components, while
Purism, in the <em>years</em> they have supposedly been working on those
projects, have only managed to reuse (and, to be fair, improve on) the
work <em>others</em> have done to neutralize the IME.</p>

<p>What has Purism done, in the meantime? Neutralized IME. That's
it. They have not published <em>anything</em> on LVFS. Even closed-source
companies like <a href="https://fwupd.org/lvfs/vendors/#logitech">Logitech</a>, <a href="https://fwupd.org/lvfs/vendors/#synaptics">Synaptics</a>, <a href="https://fwupd.org/lvfs/vendors/#hp-ws">HP</a> and <a href="https://fwupd.org/lvfs/vendors/#dell">Dell</a>
ship their updates on LVFS. Purism <a href="https://fwupd.org/lvfs/vendors/#purism">has a test account</a> and work
has been <a href="https://forums.puri.sm/t/submit-firmware-to-linux-vendor-firmware-service-lvfs-for-easy-updating/4731">stalled for years now</a>.</p>

<h2 id="bullshit-anti-interdiction"><a name="index12h2"></a>Bullshit anti-interdiction</h2>
</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://anarc.at/hardware/laptop/purism-librem13v4/">https://anarc.at/hardware/laptop/purism-librem13v4/</a></em></p>]]>
            </description>
            <link>https://anarc.at/hardware/laptop/purism-librem13v4/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23830046</guid>
            <pubDate>Tue, 14 Jul 2020 09:38:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flatland Challenge - Multi Agent Reinforcement Learning on Trains]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23829991">thread link</a>) | @jonbaer
<br/>
July 14, 2020 | https://www.aicrowd.com/challenges/flatland-challenge | <a href="https://web.archive.org/web/*/https://www.aicrowd.com/challenges/flatland-challenge">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="description-wrapper">
        <div>
          <div data-controller="challenge-overview" data-action="resize@window->challenge-overview#showTOC" data-challenge-overview-scrollable-tabs="true">
            <blockquote>
<p>The Flatland 2019&nbsp;challenge has ended! Do you want more?</p>

<p><a href="https://www.aicrowd.com/challenges/neurips-2020-flatland-challenge/"><strong>Check out the NeurIPS 2020 Flatland challenge!</strong></a></p>
</blockquote>

<figure><img alt="flatland_logo" src="https://s3.eu-central-1.amazonaws.com/aicrowd-static/SBB/images/Flatland_Logo.svg"></figure>

<p><strong>The key question we want to answer here is: How can trains learn to automatically coordinate among themselves, so that there are minimal delays in large train networks ?</strong></p>

<h2>Abstract</h2>

<p><i>The Flatland Challenge is a competition to foster progress in multi-agent reinforcement learning for any </i><a href="https://en.wikipedia.org/wiki/Vehicle_rescheduling_problem"><i>re-scheduling problem (RSP)</i></a><i>. The challenge addresses a real-world problem faced by many transportation and logistics companies around the world (such as the Swiss Federal Railways, SBB. Different tasks related to RSP on a simplified 2D multi-agent railway simulation must be solved. Your contribution may shape the way modern traffic management systems (TMS) are implemented not only in railway but also in other areas of transportation and logistics. This will be the first of a series of challenges related to re-scheduling and complex transportation systems.</i></p>

<h2>Background</h2>

<p>The Swiss Federal Railways (SBB) operate the densest mixed railway traffic in the world. SBB maintain and operate the biggest railway infrastructure in Switzerland. Today, there are more than 10,000 trains running each day, being routed over 13,000 switches and controlled by more than 32,000 signals. Each day 1.2 million passengers and almost half of Switzerland’s volume of transported goods are transported on this railway network. Due to the growing demand for mobility, SBB needs to increase the transportation capacity of the network by approximately 30% in the future.</p>

<p>The increase in transport capacity can be achieved through different measures, such as <a href="https://smartrail40.ch/index.asp?inc=&amp;lang=en">denser train schedules, investments in new infrastructure, and/or investments in new rolling stock</a>. However, SBB currently lack suitable technologies and tools to quantitatively assess these different measures.</p>

<p>A promising solution to this dilemma is a complete railway simulation that efficiently evaluates the consequences of infrastructure changes or schedule adaptations for network stability and traffic flow. A complete railway simulation consists of a full dynamical physics simulation as well as an automated traffic management system.</p>

<figure><img alt="flatland_visual" src="https://s3.eu-central-1.amazonaws.com/aicrowd-static/SBB/images/Flatland_Preview.svg"></figure>

<p><i><strong>Flatland</strong>: This image illustrates an early draft of the environment visualization. The core task of this challenge is to manage and maintain railway traffic on complex scenarios in complex networks.</i></p>

<p>The research group at SBB has developed a high-performance simulator which simulates the dynamics of train traffic as well as the railway infrastructure. Different approaches for <a href="https://on-demand-gtc.gputechconf.com/gtcnew/on-demand-gtc.php?searchByKeyword=erik%20nygren&amp;searchItems=&amp;sessionTopic=&amp;sessionEvent=&amp;sessionYear=&amp;sessionFormat=&amp;submit=&amp;select=">automated traffic management systems (TMS)</a> are currently under investigation. The role of the traffic management system is to select routes for all trains and decide on their priorities at switches in order to optimize traffic flow across the network.</p>

<p>At the core of this challenge lies the general vehicle re-scheduling problem (VRSP) proposed by Li, Mirchandani and Borenstein in 2007:</p>

<blockquote>
<p>The vehicle rescheduling problem (VRSP) arises when a previously assigned trip is disrupted. A traffic accident, a medical emergency, or a breakdown of a vehicle are examples of possible disruptions that demand the rescheduling of vehicle trips. The VRSP can be approached as a dynamic version of the classical vehicle scheduling problem (VSP) where assignments are generated dynamically.</p>
</blockquote>

<p>The “Flatland” Competition aims to address the vehicle rescheduling problem by providing a simplistic grid world environment and allowing for diverse solution approaches. The challenge is open to any methodological approach, e.g. from the domain of reinforcement learning or of operations research.</p>

<p>The problems are formulated as a 2D grid environment with restricted transitions between neighboring cells to represent railway networks. On the 2D grid, multiple agents with different objectives must collaborate to maximize global reward. There is a range of tasks with increasing difficulty that need to be solved as explained in the coming sections.</p>

<h2>Tasks</h2>

<p>The challenge requires your creativity and savviness. In 3 submission rounds with increasing difficulty, you can prove that you have what it takes. We invite you to enter the race with your unique solution and to win great prizes - at the same time solving one of the key challenges in the world of transportation!</p>

<p>Here is a teaser of what we expect you to do:&nbsp;</p>

<figure><img alt="Teaser" src="https://i.imgur.com/9cNtWjs.gif"></figure>

<p>Your overall goal is to make all agents (trains) arrive at their target destination with a minimal travel time. In other words, we want to minimize the time steps (or wait time) that it takes for each agent in the group to reach its destination.</p>

<p>Let’s say in a scenario with n-agents, the travel time is measured by the collected amount of timesteps all the agents have until the n-th agent arrives at its destination.</p>

<h3>1. Can you design the best-performing agent?</h3>

<p>Design the best-performing agent. At the more basic levels, the agents may achieve their goals using ad-hoc decisions. But as difficulty increases from round to round, the agents have to be able to plan ahead, i.e. with increasing difficulty, planning becomes more relevant!</p>

<h3>2. Can you design the best observation?</h3>

<p>As a participant, you have the choice. You can either work with the three base observations that we prepared or better, design an improved observation yourself. If you do the latter, then share your observation and you will have chances of winning the Community Contribution Prize (see Prizes). These are the three base observation that we prepared:</p>

<p>Global Observation: The whole scene is observed</p>

<p>Local Grid Observation: A local grid around the agent is observed</p>

<p>Tree Observation: The agent can observe its navigable path to some predefined depth.</p>

<p>Sounds complicated? Do not despair, the next sections will provide you with more useful information about these rounds!</p>

<h2>Timeline</h2>

<p>There will be 3 rounds in the challenge. The first one (round 0) is a beta round and serves as an introduction to get familiar with Flatland (as well as bug fixing). Rounds 1 and 2 pose the actual problems to be solved. Submissions are only accepted for Round 1 and Round 2, both rounds will contribute to the final ranking. <strong>Round 2 is currently ongoing and will close on Sunday, 5th of January 2020, 12 PM, UTC +1.</strong></p>

<h3>Round 0: Learn to navigate (Beta Round)</h3>

<p>A single agent has to navigate from a freely chosen starting point to a freely chosen target destination on a random infrastructure. It is, in other words, a relatively simple shortest path problem.</p>

<p>There will be no uploading possibility, no ranking, nor any prizes to be gained in this round - but the collected insights make it all worth it!</p>

<p>Check out this simple <a href="https://gitlab.aicrowd.com/flatland/baselines/blob/master/torch_training/Getting_Started_Training.md">introduction to training</a> to get started with your own training on Flatland.</p>

<p><strong>The beta round starts on the 1st of July 2019 and ends on the 30th of July 2019</strong></p>

<figure><img alt="Round0" src="https://i.imgur.com/t5ULr4L.gif"></figure>

<h3>Round 1: Avoid conflicts</h3>

<p>We pick-up the same problem from the previous round and turn it into a multi-agent problem. This means, multiple agents have to find their ways to their respective target destinations. In this scenario you are likely to encounter resource conflicts when two or more agents simultaneously plan to occupy the same section of infrastructure. Thus, the agents have to learn to avoid conflicts and find feasible solutions. By timely submitting your solution and adhering to the <a href="#rules">participation rules</a> you are automatically eligible for the <a href="#prizes">Contribution Prize &amp; Best Agent Prize</a>. Good luck!</p>

<p><strong>Round 1 will open on Tuesday, 30th of July and close on Sunday, 13th of October 2019, 12 PM, UTC +1.</strong> <strong>Round 1 submissions closed early in order to start with Round 2 as early as possible.</strong> <strong>If you still want to test your code on earlier version please get in touch with us directly.</strong></p>

<figure><img alt="Round1" src="https://i.imgur.com/AvBHKaD.gif"></figure>

<p><strong>Round 2: Optimize train traffic</strong>: In reality, not all trains can go at the same speed. In round 2 we introduce additional complexity to the multi-agent-problem of round 1 by letting the trains have different speeds! Furthermore, stochastic events will occur during the episodes which mean that your controller will need to adapt to a changing environment. Key features of the updated environment are:</p>

<ul>
	<li>Agents travel at 4 different speeds.</li>
	<li>Some agents will experience malfunctions which render them immobile at times.</li>
	<li>Agents have to actively start their journey in the environment and leave the environment when they reach their target.</li>
</ul>

<p>This means that a good solution not only avoids/resolves conflicts, but also optimizes by taking into account that slower agents can slow down the faster ones. The prize is reserved for the winner who submits the solution with the minimal cumulated travel time for all agent. By submitting your solution timely and adhering to the <a href="#rules">participation rules</a>, you are automatically eligible for the <a href="#prizes">Contribution Prize &amp; Best Agent Prize</a>. Good luck!</p>

<figure><img alt="Round2" src="https://i.imgur.com/Pc9aH4P.gif"></figure>

<p><strong>Round 2 is now open and will close on Sunday, 5th of January 2020, 12 PM, UTC +1.</strong></p>

<h2>Environment</h2>

<p>There are a few important basic elements and notions specific to this challenge that you should be aware of before diving into the “Lets get started” section.</p>

<h3>Agent</h3>

<p>Flatland is a discrete time simulation, that means that all actions performed happen with a constant time step. At each step, the agents can choose an action. The term agent is defined as an entity that can move within the grid and must solve tasks - these agents are, who would have thought, trains. A train does basically two things: wait or go into a particular direction. Depending on the train type (e.g. freight train or passenger train), they have different speeds. An agent can move in any arbitrary direction (if the environment permits it) and transition from one cell to the next. If the agent chooses a valid action, the corresponding transition will be executed and the agent’s position and orientation is updated. Each agent has its individual start and target.</p>

<p>Agent at start:</p>

<figure><img alt="starting_agent" src="https://i.imgur.com/mXW7O3L.png"></figure>

<p>Target Destination:</p>

<figure><img alt="destination" src="https://i.imgur.com/NiSEryT.png"></figure>

<p>The cell where the agent is located at must have enough capacity to hold …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.aicrowd.com/challenges/flatland-challenge">https://www.aicrowd.com/challenges/flatland-challenge</a></em></p>]]>
            </description>
            <link>https://www.aicrowd.com/challenges/flatland-challenge</link>
            <guid isPermaLink="false">hacker-news-small-sites-23829991</guid>
            <pubDate>Tue, 14 Jul 2020 09:24:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Decision Trap for Developers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23829988">thread link</a>) | @KingOfCoders
<br/>
July 14, 2020 | https://www.svese.de/essay/the-decision-trap-for-developers-in-startups | <a href="https://web.archive.org/web/*/https://www.svese.de/essay/the-decision-trap-for-developers-in-startups">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>When I was joining a startup with plans to replace the CTO, there was a relaunch going on. I’ve talked to people and no one seemed happy. Developers were unhappy and helpless and the founders were also unhappy with the relaunch. I’ve heard it had being going on since months. The whole company couldn’t understand why tech didn’t deliver. Digging deeper I found over 150 open bugs in a small team, a founder who changed the design every week and a product manager sandwiched between the unhappy founder and the unhappy developers. I forced the founder to make a lasting decision, we fixed or closed all of the bugs and delivered a new website. The founder team, developers and I were happy, not to speak of the product manager.</p><p>Developers are trapped in a cycle of bad decision making in startups. Companies are bad at making decisions. Founders and executives treat decisions as a way to show leadership, the woman or man at the helm being able to decide about the future of the company. Creative visionaries come up with new ideas and decisions to build new products every day, changing direction on a whim in the chase for customers and investor satisfaction. Developers bear the brunt. They believe a process around decisions in startups and companies is not of their concern. They only need to execute. Tell me what I should code. </p><p>I hear from founders and CEOs who want to speed up development because they have the perception technology is slow. With the abundance of knowledge on processes, lean development and of-the-shelf technology this is unlikely. The perception of development being slow is the impact of a bad decision process in startups. For development the negative consequences are time pressure, constantly changing requirements, ongoing reprioritizations and therefor even more pressure and blame. </p><p>We will investigate why decision making is broken, what consequences this has for developers and CTOs and how to fix it.</p><p>0.</p><p><em>“Our research shows that the difference between leaders who make good decisions and those who make bad ones is striking. The former recognize that all decisions are processes, and they explicitly design and manage them as such.” </em><br>David A. Garvin and Michael A. Roberto in HBR</p><p>To many people decision making is an event, while decision making is a process. This perception causes several bad side effects. The most important one is that their decision has not the intended effects. Founders wonder why after taking a decision, the company does not change. Why after taking a decision they get a lot of discussion instead of people executing their decision towards success.</p><p>‍</p></div><div><p>How does one change this? How would a decision process look if done right? </p><p>The four steps of a decision process are:</p><ol start="" role="list"><li>Prepare</li><li>Make</li><li>Rollout</li><li>Enforce</li></ol><p>Let us look into each phase in more detail. I’ll show how mistakes in all four phases have impact on software developers and CTOs.</p><p>1.</p><p>The first phase is ‘prepare a decision’. Preparing a decision means getting the facts and information that are needed to make a decision. It also means getting feedback and the mood from stakeholders about the decision. If you surprise people with a decision, you have done it wrong. If as a founder you want to make a decision, ask your management team before what they think about it. First in a team meeting and then in one-on-one discussions with your managers. Get the buy-in from everyone that a decision needs to be made. Make sure everyone knows if the decision is to be a team decision or something a founder or managers decides.</p><p>Without the right preparation, managers make wrong assumptions, miss key parts of the decisions or do not think about consequences. Bad preparation leads to features in development that take too long, are too complicated, hard to maintain or not worth the effort. If a decision has large infrastructure impacts, feature implementation will take a long time. Cost and time pressure is put on the CTO because of badly prepared decisions.</p><p>2.</p><p>The second phase is ‘making the decision’. When you have the buy-in from everyone and all the information you need, it is time to decide. Decisions with consequences are hard to make with all the options on the table. For this managers postpone decisions to not lose options and commit themselves. If you have all the information and you have the feedback from people, make the decision and do not delay it. Break the pattern to move the decision to next week’s management meeting because of the desire to not constrain yourself. Make the decision as fast and as early as possible despite the fear of making the wrong one. A mistake I often see around making decisions: it is unclear on how decisions are made and who makes them. Introducing a decision framework like RACI helps here. It defines roles people have:</p><ul role="list"><li>R = Responsible: The person or people to successfully execute the decision</li><li>A = Accountable: The person or people who make the decision</li><li>C = Consulted: People who are asked for input to the decision</li><li>I = Informed: People informed about the decision</li></ul><p>This way roles are clear, and it is clear who makes a decision e.g. the CEO, CTO, Head of Product or the group. Otherwise people often confuse their role of giving input and with making a decision.<br>Not making a decision has bad consequences for development and CTOs. All the time lost prolonging the decision is put on development as pressure to speed up development. Donald G. Reinertsen shows in “Developing Products in Half the Time” that half of the time to market is lost in the “fuzzy frontend” before development even starts. If I consult a company, I tell people it is hard to cut 10% out of development time with already agile and lean development departments, but it is easy to cut 50% out of pre-development time. Every second after an idea is found in a company is as precious as a second in the last week before launch. People treat these differently though. Time in the decision making phase is treated as an unlimited resource and time in crunch mode before release is treated as gold. The most urgent job for a CTO is to have a decision process in place and force fast decisions to make his life happier. It helps to write down the dates of when an idea is new and when development starts to optimize lead times.</p><p>3.</p><p>While some people are at least able to make timely decisions, they fail miserably at rolling them out. Decisions are made, decisions are communicated by email or in all-hands meetings and decision makers expect the course of the company to change. They do not understand that after making a decision the most important next step is rolling it out. Every important decision involves change management. Rolling out a decision means communicating the decision, explain the decision, explain why alternatives have not been chosen, explain what the decision means for the company, departments and employees. Transparency about the decision, the reasons that the decision was made the way it went is paramount to success. Every decision needs to be explained in one-on-ones to make it stick, let people vent their feelings, get feedback and the buy-in from those carrying it out. Proclaiming you have decided something will not make the decision stick and will result in a disaster. The company ignores your decision and just carries on. Founders feel frustrated and react with pressure on execution. </p><p>When not rolling out a decision and explaining the circumstances, people have different perceptions about it, how to interpret it, what it means for them, the state of the company, what is important and what to focus on. This creates increased friction all over the company. As development needs to work with many parts of the company, it is highly impacted by high friction and differing &nbsp;assumptions and perceptions. If a company has a decision process with good rollout practices friction is minimized and development speed is increased. High friction leads to low development speed which is blamed on developers and CTOs. </p><p>4.</p><p>The last phase of decision making is enforcement. There are many people who will not be happy with your decision.</p><p><em>"Surely a decision is a decision?" "Only if it's the decision you want. If not, it's just a temporary setback." Sir Humphery, Yes Minister.</em></p><p>They will ignore it or try to reopen it. There are many ways to do so. Managers will sabotage decisions if they don’t like them and you don’t act. They agree with the decision but do not carry it out. After a decision has been made in a meeting, next week people will claim “This is not the way how I have perceived this. We haven’t made a clear decision.” People act just as if you haven’t made a decision at all. </p><p>After making a decision and rolled it out, it’s time to enforce it. Every decision has to be recorded in meeting notes or in other forms to make it clear to everyone that a decision has been made, how the decision looks and misunderstandings are reduced. Without writing it down people will leave a meeting and everyone has a different understanding and takeaway. If people show tendencies to counteract your decision, bring them back on the right path. Explain the decision again. Then explain it even more. Remind people of the decision. Pull out the meeting notes. There will be opposition from many people who had a different opinion. After you’ve made every effort to convince them and take them with you, it’s the managers and founders duty to enforce the decision. </p><p>Because the effects of a decision often cannot be seen immediately, people reopen decisions too early. If there is no new important information, don’t reopen decisions. Stick to them until you clearly see you have to change them. Change decisions as soon as needed but not earlier. Flip flopping decisions creates confusion and frustration.</p><p>Changing a decision is easy and involves not a lot of work. But the more your work is down the execution chain, the bigger the impact. A dog tail wiggles only slightly at its base but furiously at its tip.</p><p>When a decision is not enforced, it leads to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.svese.de/essay/the-decision-trap-for-developers-in-startups">https://www.svese.de/essay/the-decision-trap-for-developers-in-startups</a></em></p>]]>
            </description>
            <link>https://www.svese.de/essay/the-decision-trap-for-developers-in-startups</link>
            <guid isPermaLink="false">hacker-news-small-sites-23829988</guid>
            <pubDate>Tue, 14 Jul 2020 09:24:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Report on zero-knowledge blockchain scalability]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23829951">thread link</a>) | @ArlietaBex
<br/>
July 14, 2020 | https://ethworks.io/ethereum-scaling-report | <a href="https://web.archive.org/web/*/https://ethworks.io/ethereum-scaling-report">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    
    <header>
    
  </header>
    
    <section>
  <div>
    
    <div>
      
      <p>Our extensive report on Ethereum scaling <br> will help you:</p>
      <ul>
        <li>
          <span>demystify the buzz around Ethereum layer 2 solutions,</span>
        </li>
        <li>
          <span>understand the potential of the zero-knowledge technology,</span>
        </li>
        <li>
          <span>choose your perfect-match solution and scale your product.</span>
        </li>
      </ul>

      

      <p>
        Don't want to share your email? Download our zero-knowledge scaling report directly <a href="https://ethworks.io/assets/download/zero-knowledge-blockchain-scaling-ethworks.pdf" download="">here</a>. <br>
        By clicking "download" you agree to add your email address to our subscriber list. <br>
        You'll occasionally receive updates about new reports and other resources from Ethworks.
      </p>
    </div>
  </div>
  <p><img src="https://ethworks.io/assets/images/rectangles/r1.svg" alt="Background accent">
    <img src="https://ethworks.io/assets/images/rectangles/r2.svg" alt="Background accent">
    <img src="https://ethworks.io/assets/images/rectangles/r3.svg" alt="Background accent">
  </p>
</section>
<section>
  <div>
    <div>
      <div>
        <h2>Table of Contents</h2>
        <p>Ethereum scaling has been a topic of hot discussion for some time,
          but looks like now, things are finally about to change. The concept of generating a zero-knowledge proof for offloading the blockchain may be a real game-changer. Our extensive research on zero knowledge Ethereum scaling will help you understand why.</p>
      </div>
      <ul>
        <li>
          <h3>01. Introduction	</h3>
          <p>Oh, Boy… Scaling Again... <br>
            Report Contents	</p>
        </li>
        <li>
          <h3>02. Zero Knowledge</h3>
          <p>Real-Life Example <br>
            Zero Knowledge and Blockchain <br>
            SNARKs vs. STARKs </p>
        </li>
        <li>
          <h3>03. Architectures</h3>
          <p>Data Availability Problem <br>
            zkRollup <br>
            Validium <br>
            Volition </p>
        </li>
        <li>
          <h3>04. Technologies	</h3>
          <p>zkSync <br>
            StarkEx <br>
            Loopring	</p>
        </li>
        <li>
          <h3>05. Summary	</h3>
        </li>
        <li>
          <h3>06. About Authors</h3>
          <p>Acknowledgements</p>
        </li>
      </ul>
    </div>
  </div>
</section>




    

    

  </div><div>
  <div>
    <p>I agree to and accept that ETHworks Sp. z o.o. will collect, make automatic decisions
      about, analyze and catalog information about Internet electronic addresses which have connected with the device I
      have used, information about the type of the device I have used, including the type and version of software
      installed on the device, for the purpose of determining my Internet activities (the user profile). Automatic
      decision-making does not involve sensitive data. The agreement is in force for the period when it is legally
      binding, or until a Party withdraws from the agreement. Withdrawing from the agreement shall result in removing
      the user’s profile.</p>
    </div>
</div></div>]]>
            </description>
            <link>https://ethworks.io/ethereum-scaling-report</link>
            <guid isPermaLink="false">hacker-news-small-sites-23829951</guid>
            <pubDate>Tue, 14 Jul 2020 09:18:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Instant Cloud Functions Deployment]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23829702">thread link</a>) | @antho1404
<br/>
July 14, 2020 | https://liteflow.com/functions | <a href="https://web.archive.org/web/*/https://liteflow.com/functions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <section id="pay">
        <div>
          <h2>Pay only for the executions your app uses</h2>
          
        </div>
        
        <div>
          <div>
            <table data-type="freenium">
              <thead>
                <tr>
                  <th colspan="5">
                    Free Quota per month included in every account on Liteflow
                  </th>
                </tr>
                <tr>
                  <th>Function</th>
                  <th></th>
                  <th>Invocation</th>
                  <th>Duration<span>In second</span></th>
                  <th>Data<span>In kilobyte</span></th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>Tasks</td>
                  <td>Execute</td>
                  <td>10k</td>
                  <td>10k</td>
                  <td>10k</td>
                </tr>
              </tbody>
            </table>
            <table data-type="ondemand">
              <thead>
                <tr>
                  <th colspan="5">
                    Function's cost table (only for upgraded account)
                  </th>
                </tr>
                <tr>
                  <th>Function</th>
                  <th></th>
                  <th>Invocation<span>Per execution</span></th>
                  <th>Duration<span>Per second</span></th>
                  <th>Data<span>Per kilobyte</span></th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>Tasks</td>
                  <td>Execute</td>
                  <td>$0.000004</td>
                  <td>$0.0002</td>
                  <td>$0.000001</td>
                </tr>
              </tbody>
            </table>
          </div>
          
        </div>

        <p>
          <h3>Frequently Asked Questions</h3>
        </p>

        <div>
          <div>
            <h4>How do I know Liteflow is right for me?</h4>
            <p>
              Liteflow is designed for early-stage Lean startups. Every account
              includes a Free Quota for every services' executions, allowing you
              to run small-to-medium apps without having to pay anything.
            </p>
          </div>
          <div>
            <h4>Do I need a credit card to start using Liteflow?</h4>
            <p>
              No, Liteflow is completely free to start using and don't require
              your credit card upfront. You will be able to upgrade your account
              when reaching the monthly Free Quota limits.
            </p>
          </div>
        </div>
        <div>
          <div>
            <h4>What happens if I reach the monthly Free Quota limits?</h4>
            <p>
              We will warn you with a message in the console and by email,
              inviting you to enter a payment method to continue running your
              app on Liteflow. If you decide to not upgrade your account, we
              will shut off your app for the remainder of that month.
              <strong>No surprise billing!</strong>
            </p>
          </div>
          <div>
            <h4>What kind of support will I receive?</h4>
            <p>
              All apps hosted on Liteflow come with email and Intercom support
              from the Liteflow team during Southeast Asia business hours. We
              provide unlimited support to help you grow your business with
              Liteflow.
              <strong>For paid accounts, a one-to-one video call support is
                available.</strong>
            </p>
          </div>
        </div>
      </section>
    </div></div>]]>
            </description>
            <link>https://liteflow.com/functions</link>
            <guid isPermaLink="false">hacker-news-small-sites-23829702</guid>
            <pubDate>Tue, 14 Jul 2020 08:28:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Get the Most Out of Google Cloud Next: OnAir]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23829697">thread link</a>) | @wedge14
<br/>
July 14, 2020 | https://www.contino.io/insights/google-cloud-next-onair | <a href="https://web.archive.org/web/*/https://www.contino.io/insights/google-cloud-next-onair">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p>Due to current circumstances, the usual Google Cloud Next events have been moved online to <a href="https://cloud.withgoogle.com/next/sf/">Google Cloud Next: OnAir</a>. This updated format runs over a nine-week period, delivering a digital event focused on a different topic weekly – <strong>every Tuesday from 14 July </strong>– aptly named “OnAir”.</p>
<h4>The Agenda-at-a-Glance</h4>
<ul><li><strong>WEEK ONE:</strong> Industry Insights
</li><li><strong>WEEK TWO: </strong>Productivity &amp; Collaboration
</li><li><strong>WEEK THREE:</strong> Infrastructure
</li><li><strong>WEEK FOUR: </strong>Security
</li><li><strong>WEEK FIVE: </strong>Data Analytics
</li><li><strong>WEEK SIX: </strong>Data Management &amp; Databases
</li><li><strong>WEEK SEVEN: </strong>Application Modernization
</li><li><strong>WEEK EIGHT: </strong>Cloud AI
</li><li><strong>WEEK NINE: </strong>Business Application Platform
</li></ul>
<h4>What to Expect From the Sessions</h4>
<p>The event is <strong>free of charge</strong>, and will provide a <a href="https://cloud.withgoogle.com/next/sf/sessions#industry-insights">wide range of session styles</a>: from industry highlights from Google Cloud executives, breakout sessions, expert tutorials and interactive programs such as Study Jams, the Cloud Hero game and gamified hands-on labs, through to Q&amp;A sessions and live technical discussions with the Google Cloud Developer Relations team. It will also include real world examples where customers will tell their digital transformation stories and how they’re using Google Cloud to solve problems and achieve their objectives more quickly.
</p>
<p>When registering, participants will gain <strong>one month’s free access</strong> to curated Google Cloud learning paths on <a href="https://www.qwiklabs.com/">Qwiklabs</a> &amp; <a href="https://www.pluralsight.com/">Pluralsight</a>, which provide great resources to help with preparation for certification exams.
</p>
<p>There are<strong> over 200 talks</strong> for attendees to take in between July and September - in addition to the Keynotes with Google Cloud CEO Thomas Kurian - so to help you break it down we’ve picked the best, so you can skip the rest!
</p>
<h4>Our Top Picks: What Not to Miss at Google Cloud Next 2020</h4>
<p>Next OnAir has a very exciting <a href="https://cloud.withgoogle.com/next/sf/speakers">list of speakers</a>, including customers and Google engineers sharing their insights. During his keynote presentation, Thomas Kurian will share insights on how businesses can leverage cloud technology to build for the future and adapt to complexities, challenges, and opportunities. Definitely one not to miss!</p>
<p>But there are many more sessions to watch out for in addition to the Keynotes.</p>
<p>At Contino, we support our customers across <a href="https://youtu.be/0wFHMirluYg">Five Core Pillars</a> which reflect the cardinal directions of transformative activity for businesses regardless of specific roles, and as such, we’ve picked out a few key sessions that align to each of these pillars. </p>
<figure><a href="https://youtu.be/0wFHMirluYg" target="_blank"><img src="https://www.contino.io/images/five-pillars.png" alt="Contino Five Core Pillars" title="Contino Five Core Pillars"></a></figure>
<h5><br>Cloud Platform Build and Migration</h5>
<ul><li><a href="https://cloud.withgoogle.com/next/sf/sessions?session=NET101%20#infrastructure" target="_blank">Hybrid Networking for Millions of Users with GCP #TwitterEng</a>
</li><li><a href="https://cloud.withgoogle.com/next/sf/sessions?session=ARC219%20#infrastructure" target="_blank">Building a Large Scale Migration Factory to Google Cloud</a>
</li></ul>
<p>If you find these sessions useful, make sure to check out:
</p>
<ul><li><a href="https://youtu.be/-8n3eQ-YdMM" target="_blank">Contino CloudFest: Reliability Engineering in the Enterprise</a>
</li></ul>
<h5>Enterprise DevOps Transformations
</h5>
<ul><li><a href="https://cloud.withgoogle.com/next/sf/sessions?session=OPS302%20#infrastructure" target="_blank">Monitoring as Code</a>
</li><li><a href="https://cloud.withgoogle.com/next/sf/sessions?session=OPS214%20#infrastructure" target="_blank">Mindful Testing: Balancing Test Coverage and Maintenance</a>
</li></ul>
<p>For more on enterprise transformation, we have two webinars you might like that dive a little deeper:
</p>
<ul><li><a href="https://youtu.be/2eVO_ttyzzI" target="_blank">Contino CloudFest: Why You Need to Invest in Digital Transformation NOW</a>
</li><li><a href="https://youtu.be/5Iqd4izIV34" target="_blank">Contino CloudFest: The Future is FinOps</a>
</li></ul>
<h5>DevSecOps and Cloud Security
</h5>
<ul><li><a href="https://cloud.withgoogle.com/next/sf/sessions?session=SOLKEY205#security" target="_blank">Complexity Hurts, Simplicity Wins: Operating Securely in a Harsh New World</a>
</li><li><a href="https://cloud.withgoogle.com/next/sf/sessions?session=SEC302#security" target="_blank">Advanced IAM: Hacks, Tips, and Tricks for Policy Management</a>
</li></ul>
<p>We’ve seen customers adopt SRE as a means to embed security in everything they do. Check out the following Contino webinar for more information:
</p>
<ul><li><a href="https://youtu.be/buqz_4LK57c" target="_blank">Contino CloudFest: Boost Your Apps with an SRE approach to development</a>
</li></ul>
<h5>Cloud-Native Software Development
</h5>
<ul><li><a href="https://cloud.withgoogle.com/next/sf/sessions?session=APP311#application-modernization" target="_blank">Ensuring Business Continuity at Times of Uncertainty and Digital-only Business with GKE</a>
</li><li><a href="https://cloud.withgoogle.com/next/sf/sessions?session=OPS301#application-modernization" target="_blank">Analyzing Distributed Traces to Find Performance Bottlenecks</a>
</li></ul>
<p>The real value in cloud adoption is to break the shackles of on-premise approaches and embrace cloud-native technologies and methodologies. It’s not always easy to do, as our recent webinar below&nbsp;illustrates!
</p>
<ul><li><a href="https://youtu.be/R9CjnitC2ZM" target="_blank">Contino CloudFest: Kubernetes is Hard</a>
</li></ul>
<p>You might also be interested in our latest white paper, <a href="https://www.contino.io/resources/cloud-native">The Ultimate Guide to Cloud-Native: Breaking Out of On-Prem Prison.</a>
</p>
<h5>Data Platforms and Analytics
</h5>
<ul><li><a href="https://cloud.withgoogle.com/next/sf/sessions?session=DA233#data-analytics" target="_blank">Don’t Sweat The Big Stuff. Make It Google’s Problem.</a>
</li><li><a href="https://cloud.withgoogle.com/next/sf/sessions?session=DA238#data-analytics" target="_blank">Using Google Cloud to Serve 10,000s of Personalized Recs Per Second</a>
</li><li><a href="https://cloud.withgoogle.com/next/sf/sessions?session=AI212#cloud-ai" target="_blank">An Introduction to MLOps on Google Cloud</a>
</li></ul>
<p>From adopting a data strategy to pipelines, analytics, AI &amp; ML, no business can afford to stand still, with some of the biggest challenges associated with a change in the way data is perceived. The following webinar might be useful for those who’ve taken in these sessions:
</p>
<ul><li><a href="https://youtu.be/ivb6QGskEro" target="_blank">Contino CloudFest: Adopting a Data-Driven Approach.</a>
</li></ul>
<p><em>If you attend a session, or read our suggested additional content and it raises questions, why not email us at&nbsp;<a href="https://www.contino.io/cdn-cgi/l/email-protection#167e737a7a7956757978627f7879387f79"><span data-cfemail="dab2bfb6b6b59ab9b5b4aeb3b4b5f4b3b5">[email&nbsp;protected]</span></a>&nbsp;to arrange a discussion with our Google Cloud Platform experts?</em></p>
<h5>Looking for More?
</h5>
<p>When Google Next was originally planned for face-to-face in San Francisco, we were delighted to secure a presentation slot for Contino’s very own Mihnea Spirescu. Due to the refactoring of the event, the partner sessions unfortunately didn’t make the final schedule. However, Contino is very excited to announce a new partnership with <a href="https://www.meetup.com/gdgcloud/">Google Developer Group Cloud London</a> Meetup Group, where on Thursday 16th July, Mihnea has the pleasure of delivering our inaugural group talk on Cloud Run, which ties in well with Google Next OnAir ‘20 where this topic will be covered in some depth.&nbsp;</p>
<p>With over 7,000 members, the group is certainly one of the more active engineering groups on the meetup platform, conducting several hacks and workshops each month, as well as general talks. More info on Mihnea’s talk and registration for the event can be found here: <a href="https://www.meetup.com/gdgcloud/events/271677336/">Cloud Run: Overcoming the challenges of building &amp; deploying Serverless Apps</a></p>
</div>
</div></div>]]>
            </description>
            <link>https://www.contino.io/insights/google-cloud-next-onair</link>
            <guid isPermaLink="false">hacker-news-small-sites-23829697</guid>
            <pubDate>Tue, 14 Jul 2020 08:27:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing Rust NIFs for Elixir with Rustler]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23829651">thread link</a>) | @marcoow
<br/>
July 14, 2020 | https://simplabs.com/blog/2020/06/25/writing-rust-nifs-for-elixir-with-rustler/ | <a href="https://web.archive.org/web/*/https://simplabs.com/blog/2020/06/25/writing-rust-nifs-for-elixir-with-rustler/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

<p>Rustler is a fantastic project built to make writing Rust NIFs a simple process;
and the upcoming v0.22 release will provide a much cleaner syntax to do so. The
library handles encoding and decoding Rust values into Erlang terms, catches
Rust panics before they unwind to C and <em>should</em> make it impossible to crash the
BEAM from a Rust NIF.</p>
<h2 id="getting-started-with-rustler">Getting started with Rustler</h2>
<p>One of my first forays into Rust-implemented NIFs was while building a
micro-library providing Base64 encoding and decoding, creatively named
<a href="https://github.com/niklaslong/base64" target="_blank" rel="noopener">base64</a>. It's utterly pointless as that
functionality comes built-in to Elixir but I wanted to start with something
simple. On the plus side, this meant I could easily compare the performance of
the NIF version to the Elixir implementation which can be found in the
<a href="https://hexdocs.pm/elixir/Base.html" target="_blank" rel="noopener"><code>Base</code> module</a>.</p>
<p>The library consists of two functions: <code>encode/2</code> and <code>decode/2</code> and it's using
<a href="https://github.com/marshallpierce/rust-base64" target="_blank" rel="noopener">rust-base64</a> to do the heavy
lifting in the NIFs. Let's walk through how this all works.</p>
<p>To get started, we need a new mix project with rustler installed as a
dependency.</p>
<pre><code>mix new base64

mix deps.get
mix rustler.new
</code></pre><p>Let's explore the project's resulting structure (I've left out the usual Elixir
files and directories and focused on <code>lib</code> and <code>native</code>):</p>
<pre><code>.
â”œâ”€â”€ lib
â”‚   â””â”€â”€ base64.ex
â””â”€â”€ native
    â””â”€â”€ base64_nif
        â”œâ”€â”€ Cargo.lock
        â”œâ”€â”€ Cargo.toml
        â”œâ”€â”€ README.md
        â””â”€â”€ src
            â””â”€â”€ lib.rs</code></pre><ul>
<li><code>lib</code> will contain Elixir code (like any standard mix project).</li>
<li><code>base64.ex</code> will contain the stubs to our NIFs. This is the Elixir module the
NIF module will be registered to.</li>
<li><code>native</code> will be home to the Rust code. In fact, a cargo package has been
created within this directory (in this case named <code>base64_nif</code>).</li>
<li><code>lib.rs</code> will contain the NIFs.</li>
</ul>
<p>The Rust NIFs are compiled and linked into a shared library loaded by Erlang
code at runtime. Elixir (or Erlang) implementations of the functions are also
necessary. These are usually minimal stubs defining the name and arity of the
NIFs and serve as fallback implementations if the NIFs aren't loaded. Let's
start with the Elixir stubs.</p>
<pre><code>

<span><span>defmodule</span> <span>Base64</span></span> <span>do</span>
  <span>use</span> Rustler, <span>otp_app:</span> <span>:base64</span>, <span>crate:</span> <span>"base64_nif"</span>

  <span>@spec</span> decode(binary, atom) :: binary
  <span><span>def</span> <span>decode</span></span>(_b64, _opt \\ <span>:standard</span>), <span>do:</span> error()

  <span>@spec</span> encode(binary, atom) :: binary
  <span><span>def</span> <span>encode</span></span>(_s, _opt \\ <span>:standard</span>), <span>do:</span> error()

  <span><span>defp</span> <span>error</span></span>(), <span>do:</span> <span>:erlang</span>.nif_error(<span>:nif_not_loaded</span>)
<span>end</span></code></pre><p>The first line is configuration and lets Rustler know what Rust crate to compile
for the Elixir module.</p>
<p>As mentioned above, <code>decode/2</code> and <code>encode/2</code> don't actually implement any
decoding or encoding; they simply call <code>error/0</code> if the NIFs can't be found.
However, the names and the arguments must match in both the Rust and Elixir
implementations. Both functions take in a <code>binary</code> to be encoded or decoded and
an <code>atom</code> for configuration as different character sets that can be used
(url-safe, without padding, etc...). The default is fittingly set to
<code>:standard</code>. The Rust NIFs are implemented as follows.</p>
<pre><code>

<span>use</span> base64;
<span>use</span> rustler::Atom;

<span>mod</span> atoms {
    rustler::atoms! {
      crypt,
      imap_map7,
      standard,
      standard_no_pad,
      url_safe,
      url_safe_no_pad,
    }
}

<span>#[rustler::nif]</span>
<span>pub</span> <span><span>fn</span> <span>decode</span></span>(b64: <span>String</span>, opt: Atom) -&gt; <span>String</span> {
    <span>let</span> config: base64::Config = match_config(opt);
    <span>let</span> bytes = base64::decode_config(b64, config).expect(<span>"decode failed: invalid b64"</span>);

    <span>String</span>::from_utf8(bytes).unwrap()
}

<span>#[rustler::nif]</span>
<span>pub</span> <span><span>fn</span> <span>encode</span></span>(s: <span>String</span>, opt: Atom) -&gt; <span>String</span> {
    <span>let</span> config: base64::Config = match_config(opt);
    base64::encode_config(s.as_bytes(), config)
}

<span><span>fn</span> <span>match_config</span></span>(option: Atom) -&gt; base64::Config {
    
}

rustler::init!(<span>"Elixir.Base64"</span>, [decode, encode]);</code></pre><p>The last line is interesting: <code>rustler::init</code> is a procedural macro that allows
the use of <code>#[rustler::nif]</code> to annotate functions to be wrapped as NIFs. It
takes in the name of the Elixir module in which the stubs are defined (in this
case <code>"Elixir.Base64"</code>) and an array containing the names of the functions
annotated as NIFs (in this case <code>[decode, encode]</code>). In short, this links
everything together.</p>
<p>The use statements at the top of the file are importing the
<a href="https://github.com/marshallpierce/rust-base64" target="_blank" rel="noopener">rust-base64 crate</a> (<code>base64</code>)
mentioned earlier, which we'll use for encoding and decoding, and the
<code>rustler::Atom</code> type which allows us to represent an Elixir/Erlang <code>atom</code> in
Rust. Both the <code>rustler</code> and <code>base64</code> crates have been added to the <code>Cargo.toml</code>
dependencies.</p>
<p>The <code>rustler::atoms</code> macro defines Rust functions that return Erlang atoms; in
this case, the possible options for the <code>encode/2</code> and <code>decode/2</code> functions.</p>
<p>Finally, we come to the NIF definitions. The functions take in a <code>String</code> and a
<code>rustler::Atom</code>, and return a <code>String</code>. This is consistent with the Elixir
stubs, as are the names. In this case, the conversions between Rust values and
Elixir terms are conveniently handled by Rustler. However, for more complex
types, this may need to be implemented manually.</p>
<h2 id="how-does-it-compare-to-the-elixir-implementation">How does it compare to the Elixir implementation?</h2>
<p>Rust is fast. Really fast. This was my set-up (using
<a href="https://github.com/bencheeorg/benchee" target="_blank" rel="noopener">benchee</a>):</p>
<pre><code>Operating System: macOS
CPU Information: Intel(R) Core(TM) i5-4258U CPU @ 2.40GHz
Number of Available Cores: 4
Available memory: 16 GB
Elixir 1.10.2
Erlang 22.3.2</code></pre><p>I used <em>hello world</em> as the short string and Sarah Kayâ€™s poem
<em><a href="https://www.youtube.com/watch?v=0snNB1yS3IE" target="_blank" rel="noopener">B (If I Should Have a Daughter)</a></em>
as the longer string.</p>
<p>Decoding:</p>
<pre><code>##### With input Bigger #####
Comparison:                    ips
Rust Nif decode           175.74 K
Elixir/Erlang decode        4.35 K - 40.37x slower +224.03 Î¼s

##### With input Small #####
Comparison:                    ips
Rust Nif decode           953.17 K
Elixir/Erlang decode      555.63 K - 1.72x slower +0.75 Î¼s</code></pre><p>Encoding:</p>
<pre><code>##### With input Bigger #####
Comparison:                    ips
Rust Nif encode           203.14 K
Elixir/Erlang encode        6.95 K - 29.23x slower +138.98 Î¼s

##### With input Small #####
Comparison:                    ips
Rust Nif encode           941.14 K
Elixir/Erlang encode      615.62 K - 1.53x slower +0.56 Î¼s</code></pre><p>As the data to encode or decode becomes larger, the overhead of creating the
NIFs becomes smaller and the gains in speed are impressive. These results were
obtained with fairly small data and so the potential performance gains possible
by leveraging Rust NIFs when dealing with CPU-intensive tasks are exciting.</p>
<p>I left out the memory usage comparisons but the Elixir/Erlang implementations
used 3-5x more memory than the NIFs.</p>
<h2 id="tldr-rustler-makes-it-easy-to-implement-nifs">TL;DR: Rustler makes it easy to implement NIFs</h2>
<p>Other than the <code>#[rustler::nif]</code> function annotations and the <code>rustler::init</code>
call, nothing more is required to implement Rust NIFs with Rustler. The
boilerplate and the complexities of translating Rust values to Erlang terms
being handled by the library, there's little resistance to leveraging the power
of Rust in Elixir/Erlang.</p>

  </div></div>]]>
            </description>
            <link>https://simplabs.com/blog/2020/06/25/writing-rust-nifs-for-elixir-with-rustler/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23829651</guid>
            <pubDate>Tue, 14 Jul 2020 08:16:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Instant Customizable RDBMS Vue UI in 20kb Gist Desktop App]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23829512">thread link</a>) | @mythz
<br/>
July 14, 2020 | https://sharpscript.net/sharp-apps/sharpdata | <a href="https://web.archive.org/web/*/https://sharpscript.net/sharp-apps/sharpdata">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://github.com/NetCoreApps/SharpData">SharpData</a> is a generic app for providing an instant UI around multiple RDBMS's:</p>
<blockquote>
<p>YouTube: <a href="https://youtu.be/GjVipOqwZMA" rel="nofollow">youtu.be/GjVipOqwZMA</a></p>
</blockquote>
<p><a href="https://youtu.be/GjVipOqwZMA" rel="nofollow"><img src="https://raw.githubusercontent.com/ServiceStack/docs/master/docs/images/release-notes/v5.9/sharpdata-custom-appsettings.png" alt=""></a></p>
<p>It makes use of the <a href="https://docs.servicestack.net/netcore-windows-desktop" rel="nofollow">app</a> dotnet tool for running Chromium
<a href="https://sharpscript.net/sharp-apps/gist-desktop-apps" rel="nofollow">Gist Desktop Apps</a> on-the-fly without installation, from a single URL that can also
<a href="https://docs.servicestack.net/mix-tool" rel="nofollow">mix in additional gists</a> which can be used in SharpData to configure RDBMS's, copy SQLite databases and
apply per-database customizations to add navigable deep links and customized UI Views to each table resultset.</p>
<p>Whilst SharpData supports <a href="https://github.com/ServiceStack/ServiceStack.OrmLite#8-flavours-of-ormlite-is-on-nuget">connecting to most popular RDBMS's</a>, it's
especially useful for being able to deploy an instant stand-alone UI with an embedded SQLite databases which can be published independently in a gist and
launched from a single URL.</p>
<p>For an example of this in action we've published customized gists for the
<a href="https://docs.microsoft.com/en-us/dotnet/framework/data/adonet/sql/linq/downloading-sample-databases" rel="nofollow">Northwind</a> and
<a href="https://www.sqlitetutorial.net/sqlite-sample-database/" rel="nofollow">Chinook</a> SQLite databases which after installing the latest
<a href="https://docs.servicestack.net/netcore-windows-desktop" rel="nofollow">app</a> dotnet tool:</p>
<pre><code>$ dotnet tool install -g app
$ app -version
</code></pre>
<p>First time <code>app</code> is run it registers the <a href="#app-url-schemes">app:// URL scheme</a> allowing Windows x64 Desktop Apps to be launched from URLs:</p>
<ul>
    <li><strong><a name="app://sharpdata?mix=northwind.sharpdata">app://sharpdata?mix=northwind.sharpdata</a></strong></li>
    <li><strong><a name="app://sharpdata?mix=chinook.sharpdata">app://sharpdata?mix=chinook.sharpdata</a></strong></li>
</ul>
<p>Or via command-line:</p>
<pre><code>$ app open sharpdata mix northwind.sharpdata
$ app open sharpdata mix chinook.sharpdata
</code></pre>
<p>Cross platform using the <a href="https://docs.servicestack.net/dotnet-tool" rel="nofollow">x dotnet tool</a> (in Default Browser):</p>
<pre><code>$ x open sharpdata mix northwind.sharpdata
$ x open sharpdata mix chinook.sharpdata
</code></pre>
<p>Each of these options will download &amp; run the latest version of <a href="https://github.com/NetCoreApps/SharpData">SharpData</a> along with a
copy of the <a href="https://gist.github.com/gistlyn/0ce0d5b828303f1cb4637450b563adbd">northwind.sharpdata</a> or
<a href="https://gist.github.com/gistlyn/96b10369daf94897531810841cb097f2">chinook.sharpdata</a> gists on-the-fly containing the embedded SQLite DB along with any
UI customizations.</p>
<h4>
Hosted as a .NET Core App</h4>
<p>As <a href="https://github.com/NetCoreApps/SharpData">NetCoreApps/SharpData</a> is also a standard .NET Core project, it can also be deployed as a
normal stand-alone .NET Core Web App:</p>
<h3>
<a href="https://sharpdata.netcore.io/" rel="nofollow">https://sharpdata.netcore.io</a>
</h3>
<h3>
Tiny footprint</h3>
<p>An impressively capable .NET Core App that fits into a tiny <strong>20kb .zip</strong> footprint thanks to <a href="https://sharpscript.net/gist-desktop-apps">Gist Desktop App's Architecture</a>. It's small dynamic <code>#Script</code> &amp; Vue TypeScript code-base also makes it highly customizable to tailor &amp; further extend with
App-specific requirements - suitable for offering advanced system users a quick, capable customized read-only UI of your DBs.</p>
<p><strong>SharpData</strong> started as a demonstration showing how productive <a href="https://sharpscript.net/" rel="nofollow">#Script</a> can be in the number of areas where
dynamic languages offer far superior productivity then the typical .NET approach of using C# to type an entire code-base &amp; models.</p>
<p>For example a single <code>#Script</code> page provides a lot of the functionality in <a href="https://docs.servicestack.net/autoquery-rdbms" rel="nofollow">AutoQuery</a> where it provides an instant HTTP API
(in all registered ServiceStack formats) around all registered RDBMS tables, in all OrmLite supported RBDMS's, that includes support for custom fields,
multiple querying options, paging, multi OrderBy's in a parameterized SQL query executed with OrmLite's SQL async DB APIs:</p>
<h2>
AutoQuery Script</h2>
<h3>
<a href="https://github.com/NetCoreApps/SharpData/blob/master/wwwroot/db/_db/_table/index.html">/db/_db/_table/index.html</a>
</h3>
<pre><code>{{ {namedConnection:db} |&gt; if (db &amp;&amp; db != 'main') |&gt; useDb }}

```code|quiet
var ignore = ['db','fields','format','skip','take','orderBy']
var fields = qs.fields ? qs.fields.split(',').map(x =&gt; sqlQuote(x)).join(',') : '*'
var sql = `SELECT ${fields} FROM ${sqlQuote(table)}`
var filters = []
var queryMap = qs.toObjectDictionary().withoutKeys(ignore)
#each queryMap.Keys.toList()
    var search = queryMap[it.sqlVerifyFragment()].sqlVerifyFragment();
    #if search == '=null' || search == '!=null'
        `${sqlQuote(it)} ${search=='=null' ? 'IS' : 'IS NOT'} NULL` |&gt; addTo =&gt; filters
        queryMap[it] = null
    else if search.startsWith('=')
        `${sqlQuote(it)} = @${it}` |&gt; addTo =&gt; filters
        queryMap[it] = search.substring(1).coerce()
    else if search.startsWith('&lt;=') || search.startsWith('&gt;=') || search.startsWith('!=')
        `${sqlQuote(it)} ${search.substring(0,2)} @${it}` |&gt; addTo =&gt; filters
        queryMap[it] = search.substring(2).coerce()
    else if search.startsWith('&lt;') || search.startsWith('&gt;')
        `${sqlQuote(it)} ${search.substring(0,1)} @${it}` |&gt; addTo =&gt; filters
        queryMap[it] = search.substring(1).coerce()
    else if search.endsWith(',')
        `${sqlQuote(it)} IN (${search.trimEnd(',').split(',').map(i=&gt;i.toLong()).join(',')})` |&gt;addTo=&gt;filters
        queryMap[it] = null
    else if search.startsWith('%') || search.endsWith('%')
        `${sqlQuote(it).sqlCast('varchar')} LIKE @${it}` |&gt; addTo =&gt; filters
    else
        `${sqlQuote(it).sqlCast('varchar')} = @${it}` |&gt; addTo =&gt; filters
    /if
/each
#if !filters.isEmpty()
    sql = `${sql} WHERE ${filters.join(' AND ')}`
/if
#if qs.orderBy
    sql = `${sql} ORDER BY ${sqlOrderByFields(qs.orderBy)}`
/if
#if qs.skip || qs.take
    sql = `${sql} ${sqlLimit(qs.skip,qs.take)}`
/if
sql |&gt; dbSelect(queryMap) |&gt; return
```
{{ ifError |&gt; show(sql) }}
{{htmlError}}
</code></pre>
<p>The <code>_</code> prefixes in the path utilizes <a href="https://sharpscript.net/docs/sharp-pages#page-based-routing" rel="nofollow">Page Based Routing</a> allowing for
<a href="https://en.wikipedia.org/wiki/Convention_over_configuration" rel="nofollow">CoC</a> based
<a href="https://en.wikipedia.org/wiki/Clean_URL" rel="nofollow">Clean URL</a> routes without needing to define &amp; maintain separate routes where the
same script supports querying all <a href="https://docs.servicestack.net/multitenancy#changedb-apphost-registration" rel="nofollow">registered multitenancy databases</a>.</p>
<h3>
Instant Customizable RDBMS UI</h3>
<p>The <a href="https://github.com/NetCoreApps/SharpData">SharpData</a> project essentially provides a UI around this script, surfacing its features &amp; give
it instant utility which ended up being so useful that it's become the quickest way to perform fast adhoc DB queries as it's easy to configure
which RDBMS's &amp; tables to show in a simple text file, easy to customize its UI, enables 1-click export into Excel and its shortcut syntax
support in column filters is a fast way to perform quick adhoc queries.</p>
<h3>
Quick Tour</h3>
<p>We'll quickly go through some of its features to give you an idea of its capabilities, from the above screenshot we can some of its
filtering capabilities. All results displayed in the UI are queried using the above
<a href="https://github.com/NetCoreApps/SharpData/blob/master/wwwroot/db/_db/_table/index.html">sharpdata</a> <code>#Script</code> HTTP API
which supports the following features:</p>
<h3>
Filters</h3>
<p>All query string parameter except for <code>db,fields,format,skip,take,orderBy</code> are treated as filters, where you can:</p>
<ul>
<li>Use <code>=null</code> or <code>!=null</code> to search <code>NULL</code> columns</li>
<li>Use <code>&lt;=</code>, <code>&lt;</code>, <code>&gt;</code>, <code>&gt;=</code>, <code>&lt;&gt;</code>, <code>!=</code> prefix to search with that operator</li>
<li>Use <code>,</code> trailing comma to perform an <code>IN (values)</code> search (integer columns only)</li>
<li>Use <code>%</code> suffix or prefix to perform a <code>LIKE</code> search</li>
<li>Use <code>=</code> prefix to perform a coerced "JS" search, for exact <code>number</code>, <code>boolean</code>, <code>null</code> and WCF date comparisons</li>
<li>Otherwise by default performs a "string equality" search where columns are casted and compared as strings</li>
</ul>
<p>Here's the filtered list used in the above screenshot:</p>
<p><a href="http://sharpdata.netcore.io/db/northwind/Order?format=json&amp;Id=%3E10200&amp;CustomerId=V%25&amp;Freight=%3C%3D30&amp;OrderDate=%3E1997-01-01&amp;take=100" rel="nofollow">/db/northwind/Order?Id=&gt;10200&amp;CustomerId=V%&amp;Freight=&lt;=30&amp;OrderDate=&gt;1997-01-01</a></p>
<h3>
Custom Field Selection</h3>
<p>The <strong>column selection</strong> icon on the top left of the results lets you query custom select columns which is specified using <code>?fields</code>:</p>
<ul>
<li><a href="https://sharpdata.netcore.io/db/northwind/Customer?format=json&amp;fields=Id%2CCompanyName%2CContactName%2CContactTitle&amp;take=100" rel="nofollow">/db/northwind/Customer?fields=Id,CompanyName,ContactName,ContactTitle</a></li>
</ul>
<h3>
Multiple OrderBy's</h3>
<p>You can use <a href="https://docs.servicestack.net/autoquery-rdbms#multiple-orderbys" rel="nofollow">AutoQuery Syntax</a> to specify multiple Order By's:</p>
<ul>
<li><a href="https://sharpdata.netcore.io/db/northwind/Customer?format=json&amp;orderBy=-Id,CompanyName,-ContactName" rel="nofollow">/db/northwind/Customer?orderBy=-Id,CompanyName,-ContactName</a></li>
</ul>
<h3>
Paging</h3>
<p>Use <code>?skip</code> and <code>?take</code> to page through a result set</p>
<h3>
Format</h3>
<p>Use <code>?format</code> to specify which <strong>Content-Type</strong> to return the results in, e.g:</p>
<ul>
<li><a href="https://sharpdata.netcore.io/db/northwind/Customer?format=html" rel="nofollow">/db/northwind/Customer?format=html</a></li>
<li><a href="https://sharpdata.netcore.io/db/northwind/Customer?format=json" rel="nofollow">/db/northwind/Customer?format=json</a></li>
<li><a href="https://sharpdata.netcore.io/db/northwind/Customer?format=csv" rel="nofollow">/db/northwind/Customer?format=csv</a></li>
</ul>
<h3>
Multitenancy</h3>
<p>You can specify which registered DB to search using the path info, use <code>main</code> to query the default database:</p>
<pre><code>/db/&lt;named-db&gt;/&lt;table&gt;
</code></pre>
<h3>
Open in Excel</h3>
<p>SharpData detects if <strong>Excel</strong> is installed and lets you open the un-paged filtered resultset directly by clicking the <strong>Excel</strong> button</p>
<p><a href="https://raw.githubusercontent.com/ServiceStack/docs/master/docs/images/release-notes/v5.9/sharpdata-excel.png" target="_blank" rel="nofollow"><img src="https://raw.githubusercontent.com/ServiceStack/docs/master/docs/images/release-notes/v5.9/sharpdata-excel.png" alt=""></a></p>
<p>This works seamlessly as it's able to "by-pass" the browser download where the query is performed by the back-end .NET Core Server who streams the response directly to the Users <strong>Downloads</strong> folder and launches it in Excel as soon as it's finished.</p>
<h3>
Launching SharpData</h3>
<p>To run SharpData in a .NET Core Desktop App you'll need latest <code>app</code> dotnet tool:</p>
<pre><code>$ dotnet tool update -g app
</code></pre>
<blockquote>
<p>If on macOS/Linux you can use the <a href="https://docs.servicestack.net/dotnet-tool" rel="nofollow">x dotnet tool</a> instead to view SharpData in your default browser</p>
</blockquote>
<h3>
Configure RDBMS from command-line</h3>
<p>You can override which database to connect to by specifying it on the command line, e.g. here's an example of connecting to <a href="https://techstacks.io/" rel="nofollow">https://techstacks.io</a> RDBMS:</p>
<pre><code>$ app open sharpdata -db postgres -db.connection $TECHSTACKS_DB
</code></pre>
<p>Which will open SharpData listing all of TechStack's RDBMS tables. If you have a lot of tables the <strong>Sidebar filter</strong> provides a quick way to
find the table you want, e.g:</p>
<p><a href="https://raw.githubusercontent.com/ServiceStack/docs/master/docs/images/release-notes/v5.9/sharpdata-technology.png" target="_blank" rel="nofollow"><img src="https://raw.githubusercontent.com/ServiceStack/docs/master/docs/images/release-notes/v5.9/sharpdata-technology.png" alt=""></a></p>
<h3>
app URL Schemes</h3>
<p>What can be done with the <code>open</code> command on the command-line can also be done from a <strong>custom URL Scheme</strong>, a feature that opens up a myriad of new
possibilities as <code>app</code> can open <a href="https://sharpscript.net/docs/gist-desktop-apps" rel="nofollow">Gist Desktop Apps</a> from Gists or in public &amp; private GitHub repositories,
where it's able to download and launch Apps on the fly with custom arguments - allowing a single URL to run a <strong>never installed</strong> Desktop App stored in a
Gist &amp; pass it custom params to enable <strong>deep linking</strong>.</p>
<p>With this organizations could maintain a dashboard of links to its different Desktop Apps that anyone can access, especially useful as the
<strong>only software</strong> that's needed to run any <a href="https://sharpscript.net/docs/sharp-apps" rel="nofollow">Sharp Apps</a> is the <code>app</code> dotnet tool which thanks to all
ServiceStack .dll's &amp; dependencies being bundled with the tool, (including Vue/React/Bootstrap fontawesome and Material SVG Icon assets),
the only files that need to be published are the App's specific resources, which is how Apps like <strong>SharpData</strong> can be compressed in a
<strong>20kb .zip</strong> - a tiny payload that's viable to download the latest app each on each run, removing the pain &amp; friction to distribute updates as
everyone's already running the latest version every time it's run.</p>
<p>Should you need to (e.g. large Sharp App or github.com is down) you can run your previously locally cached App using <code>run</code>:</p>
<pre><code>$ app run sharpdata
</code></pre>
<p>With Custom URL Schemes everyone with <code>app</code> installed can view any database they have network access to from specifying the db type and connection string in the URL:</p>
<pre><code>app://sharpdata?db=postgres&amp;db.connection={CONNECTION_STRING}
</code></pre>
<blockquote>
<p>CONNECTION_STRING needs to be URL Encoded, e.g. with JS's <code>encodeURIComponent()</code></p>
</blockquote>
<p>or by specifying an Environment variable containing the connection string:</p>
<pre><code>app://sharpdata?db=postgres&amp;db.connection=$TECHSTACKS_DB
</code></pre>
<h3>
Mix in Gists</h3>
<p>In…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sharpscript.net/sharp-apps/sharpdata">https://sharpscript.net/sharp-apps/sharpdata</a></em></p>]]>
            </description>
            <link>https://sharpscript.net/sharp-apps/sharpdata</link>
            <guid isPermaLink="false">hacker-news-small-sites-23829512</guid>
            <pubDate>Tue, 14 Jul 2020 07:46:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fun won't get it done]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23829157">thread link</a>) | @luu
<br/>
July 13, 2020 | http://yosefk.com/blog/fun-wont-get-it-done.html | <a href="https://web.archive.org/web/*/http://yosefk.com/blog/fun-wont-get-it-done.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>OK, published at 3:30 AM. That's a first!</p>
<p>So.&nbsp;Got something you want to do over the coarse of a year? Here's a&nbsp;motivation woefully insufficient to pull it off:</p>
<ul>
<li>It's fun!</li>
</ul>
<p>What could&nbsp;give you enough drive to finish the job? Anything with a reward <em>in the future, once you're done</em>:</p>
<ul>
<li>Millions of fans&nbsp;<strong>will</strong> adore me.</li>
<li>It <strong>will</strong> be the ugliest thing on the planet.</li>
<li>I <strong>will</strong> finally understand quantum neural rockets.</li>
<li>We <strong>will</strong> see who the loser is, Todd!</li>
<li>I <strong>will</strong> help humanity.</li>
<li>I <strong>will</strong>&nbsp;destroy humanity.</li>
</ul>
<p>It doesn't matter how noble or ignoble your&nbsp;goal is. What matters is <strong>delaying gratification</strong>. Because even your&nbsp;favorite thing in the&nbsp;world will have&nbsp;shitty bits if you chew on&nbsp;a big enough chunk of it. A few months or years worth of work are <em>always</em> a big enough chunk, so there <em>will</em> be shitty bits. Unfortunately, it's also the minimum-sized chunk to do anything of significance.</p>
<p>This is&nbsp;where many brilliant talents drown. Having known the joy of true inspiration, it's hard to settle for less, which you <em>must</em> to have any impact. Meanwhile,&nbsp;their&nbsp;thicker peers happily butcher task after task. Before you know it,&nbsp;these tasks&nbsp;add up to an&nbsp;impactful result.</p>
<p>In hindsight, I was really&nbsp;lucky in that I chose a profession for money instead of love.&nbsp;Why? <strong>Stamina</strong>. Money is a reward in the future that lets you ignore the shittier bits of the present.</p>
<p>Loving every moment of it, on the other hand, carries you until that moment&nbsp;which you <em>hate</em>, and then you need a new sort of fuel. Believe me, I know. I love drawing and animation, and you won't believe how many times I started and stopped doing it.</p>
<p>But the animation teacher who taught me 3D said he was happy to put textures on toilet seat models when he started out. <em>That's</em> the kind of appetite you need – and very few people&nbsp;naturally feel that sort of attraction to toilet seats. You need a&nbsp;big reward in the future, like "I'm going to become a pro," to pull it off.</p>
<p>But I don't want to become a pro. I don't want to work in the Israeli animation market where there's scarcely a feature film&nbsp;made. I don't even want to work for a big overseas animation studio. I want to make something, erm, something beautiful that I love, <strong>which is a piece of shit of a goal</strong>.</p>
<p>Because you know where I made most progress picking up actual skills? In an evening animation school, where I had a&nbsp;perfectly good goal: survive. It's good because it's a simple, binary thing which doesn't give a rat's ass about your mood. You either drop out or you don't. But "something I love" is fluid, and depends a lot on the mood. And&nbsp;when you hate this thing you're making, as you sometimes will, it's hard to imagine loving it later.</p>
<p>Conversely, imagining how I don't drop&nbsp;out is easy. This is what I was imagining when sculpting this bust, which 90% of the time I hated with a passion because it looked like crap. But I thought, "I'm not quitting, I'm not quitting, I'm not quitting, hey, I&nbsp;get the point of re-topology in Mudbox, I'm not quitting, I'm not quitting, hey, I guess I see what&nbsp;the specular map does, I'm not quitting… Guess I'm done!"</p>
<p><iframe src="https://player.vimeo.com/video/171365263" width="480" height="270" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p>And now let's talk about beauty for a moment.</p>
<p>I'm a programmer. I like to think that I'm not the thickest, butcherest programmer, in that I understand the role of beauty in it. For the trained eye, programs can be beautiful as much as&nbsp;math, physics or chess, and a beautiful program is better <em>for business</em> than the&nbsp;needlessly uglier program. (Ever tried pitching the value of beauty to someone businessy? Loads of fun.)</p>
<p>But you know why beauty is your enemy? Because it sucks the fun out of things. How? Because you're making this thing and chances are, <strong>it's not beautiful according to your own standard</strong>. The trap is, your&nbsp;taste for beauty is usually ahead of your&nbsp;creative ability. In any area, and then in any sub-area of that area, ad infinitum, you can tell ugly from beautiful long before you can make something beautiful yourself. And&nbsp;even if&nbsp;you can satisfy your own taste,&nbsp;often&nbsp;the final thing is beautiful, but not the states it goes through.</p>
<p>So&nbsp;the passionate, sensitive soul is hit twice:</p>
<ol>
<li>You're driven by fun and inspiration because you've once experienced it and now you covet it.</li>
<li>Your sense of beauty, frustrated by the state of your creation, kills&nbsp;all the fun – that very fun which&nbsp;you insist must be your only fuel.</li>
</ol>
<p>Life is easier if you want a yacht. I think you can buy a&nbsp;decent&nbsp;one for $300K, and certainly for $1M. Now all you need to do is make that money, doing doesn't matter what – imagining that yacht will help you do <em>anything</em> well! If you want beauty, however, I do not envy you.</p>
<p>How do I cope with my desire for beauty?&nbsp;The first step is acknowledging&nbsp;the problem, which I do. The fact is that my worst failures in programming came when I insisted on beauty the most. The second step is shunning beauty as a <em>goal</em>, and making it&nbsp;into a <em>means</em> and a <em>side-effect</em>.</p>
<p>I need a program doing at least X, taking at most Y seconds, at a date not later than Z.&nbsp;I'll keep ugliness to a minimum because ugly programs work badly. And if it comes out particularly nicely, that's great. But beauty is&nbsp;not a goal, and&nbsp;enjoying the beauty of this program as I write it is not why I write it.</p>
<p>And if you think it's true for commercial work but not open source software, look at, I dunno, Linux. Read some <a href="http://www.h-online.com/open/features/Interview-Linus-Torvalds-I-don-t-read-code-any-more-1748462.html">Torvalds</a>:</p>
<blockquote><p>Realistically, every single release, most of it is just driver work. Which is <strong>kind of boring in the sense there is nothing fundamentally interesting in a driver</strong>, it's just support for yet another chipset or something, and at the same time that's kind of the bread and butter of the kernel. More than half of the kernel is just drivers, and so <strong>all the big exciting smart things we do, in the end it pales</strong> when compared to all the work we just do to support new hardware.</p></blockquote>
<p>Boring bits. Boring bits that&nbsp;must be done to make something of value.</p>
<p>Does this&nbsp;transfer to art or poetry or any of those things&nbsp;whose whole point is beauty? Well, yeah, I think it does, because no,&nbsp;beauty is not the whole point:</p>
<ul>
<li>The most important thing about a drawing is that it's done. Now it exists, and people can see it, and you can make <em>another one</em>. Practice. They will not come out very well if they don't come out.</li>
<li>Often people like your&nbsp;subject.&nbsp;There's a continuum between "it's beautiful in a way that words cannot convey" and "I love how this song&nbsp;expresses&nbsp;my favorite political philosophy." To the extent that a work of art tells a story, or even sets up&nbsp;a mood, its beauty <em>does</em> become a means to an end.</li>
<li>Just because the end result is beautiful to the observer, and even if that's the only point, doesn't mean every step making it was an orgy of beauty for whomever made it. Part of what goes into it is boring, technical work.</li>
</ul>
<p>So here, too I'm trying to make beauty a non-goal. Instead my goals are "make a point" and "keep going," and you try to add beauty, or remove ugliness, as you go.</p>
<p>For example,&nbsp;I didn't do a graduation project in the evening school, but I&nbsp;animated a short on my own in the same timeframe, and I published it, even though it's not the beautiful thing I always dreamed about making. And&nbsp;I'm not sure anyone gets the joke except me. (I'm not sure I get it anymore, either.)</p>
<p><iframe src="https://player.vimeo.com/video/171368757" width="480" height="270" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p>Now my goal is "make another one." It's a good goal, because it's easy to imagine making another one. It's proper&nbsp;delayed gratification.</p>
<p>And if you've enjoyed programming 20 years ago&nbsp;and are trying to reignite the passion, I suggest that you find a goal as worthy for you as "fun" or "beauty", but as clear and binary as a yacht.&nbsp;And you can settle for less worthy, but not for less clear and binary. Because everything they told you about "extrinsic motivation" being inferior to "intrinsic motivation" is one big lie. And this lie will&nbsp;fall apart the moment you sink your teeth into a bunch of shit, as will always happen if you're trying to accomplish anything.</p>
<p><a href="https://twitter.com/YossiKreinin">Follow me on Twitter</a> to receive pearls of wisdom such as the following sample:</p>
<blockquote data-lang="en"><p lang="en" dir="ltr">Authority is the idea that what matters is not which answer is pulled out of the ass, but whose ass it's pulled out of.</p>
<p>— Yossi Kreinin (@YossiKreinin) <a href="https://twitter.com/YossiKreinin/status/756221299358216192">July 21, 2016</a></p></blockquote>


							</div></div>]]>
            </description>
            <link>http://yosefk.com/blog/fun-wont-get-it-done.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23829157</guid>
            <pubDate>Tue, 14 Jul 2020 06:32:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Cost of Mistake in Hardware Projects]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23828667">thread link</a>) | @Gen1us
<br/>
July 13, 2020 | https://blog.maddevs.io/the-cost-of-errors-in-hardware-projects-7d73b0fd8465?source=friends_link&sk=eb21eb69d892cb19c0f85f3e0276481e | <a href="https://web.archive.org/web/*/https://blog.maddevs.io/the-cost-of-errors-in-hardware-projects-7d73b0fd8465?source=friends_link&sk=eb21eb69d892cb19c0f85f3e0276481e">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="9209">Have you reached your free story limit this month? Read free on the <a target="_blank" rel="noopener" href="https://blog.maddevs.io/the-cost-of-errors-in-hardware-projects-7d73b0fd8465?source=friends_link&amp;sk=eb21eb69d892cb19c0f85f3e0276481e"><strong>link</strong></a>.</h2><div><div><div><div><p><a href="https://blog.maddevs.io/@anton_oxide?source=post_page-----7d73b0fd8465----------------------" rel="noopener"><img alt="Anton Kozlov" src="https://miro.medium.com/fit/c/96/96/2*cVORyQUYPKciCqxow6QtZg.jpeg" width="48" height="48"></a></p></div></div></div></div><figure><div><div><div><p><img alt="Hardware design." src="https://miro.medium.com/max/12000/1*CvgVOgiQFDODqdijfCfk4g.jpeg" width="6000" height="3258" srcset="https://miro.medium.com/max/552/1*CvgVOgiQFDODqdijfCfk4g.jpeg 276w, https://miro.medium.com/max/1104/1*CvgVOgiQFDODqdijfCfk4g.jpeg 552w, https://miro.medium.com/max/1280/1*CvgVOgiQFDODqdijfCfk4g.jpeg 640w, https://miro.medium.com/max/1400/1*CvgVOgiQFDODqdijfCfk4g.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*CvgVOgiQFDODqdijfCfk4g.jpeg?q=20"></p></div></div></div></figure><p id="cf40">Hello everyone!</p><p id="4a9f">In this article, we will consider common errors in the design of electronic devices and how to solve them. We will see how to calculate the cost of rolling back a batch of devices, get familiar with the main prototyping cycle.</p><h2 id="57be"><strong>Introduction</strong></h2><p id="c309">You have probably heard that various manufacturers recall batches of electronic devices from time to time. Smartphones hanging up, cameras turning off suddenly, electronic cigarettes exploding — these are the results of an incorrect approach to prototyping devices and savings on-device testing.</p><p id="a8d9">For users, such cases look like routine and can only undermine their trust in the device manufacturer. For a company that has released insufficiently tested devices in a series, defects can lead to recalling of the entire party of devices, paying compensations, and even bankruptcy.</p><h2 id="11b5"><strong>Real-world cases</strong></h2><p id="7451">Nowadays almost all portable or stationary devices have intelligent control. They use the computing capabilities of microcontrollers, microprocessors and processors for their work. This means that to change complex electronic logic, one will need to make changes in the software. This approach simplifies debugging, development, and error fixes, also reducing the cost of devices. Besides, manufacturers try to protect themselves by preferring software solution to hardware solutions for flexibility of the manufacturing process. As technologies develop, technical requirements for devices become more and more complex. Due to their complexity, modern devices should be properly designed and tested.</p><p id="d415">Software errors are resolved by updating the device software, normally it doesn’t cause serious damage. Below you can find some examples of errors made by well-known companies:</p><ul><li id="7f65">2019 — a login error on a Samsung smart watch:</li></ul><ul><li id="3640">2018 — an error causing the Apple iPhone restart when receiving messages with certain characters:</li></ul><ul><li id="28af">2016 — a vulnerability in Android enabling attackers to access a number o smartphone models:</li></ul><ul><li id="0f88">2016 — an issue with the shutter being stuck in Nikon D750 cameras:</li></ul><p id="8398">Errors in the software are common for any device manufacturer. They only indicate that the device circuit was properly designed so the device didn’t stop working, and the error resulted in zero hardware damage.</p><p id="c892">The errors in circuitry, layout of electronic components or mechanical parts, insufficient protection of the device from external influence lead to more serious consequences. Unlike software issues, they cannot be resolved remotely and result in higher costs as the manufacturer needs to pay for repair or even release another series of devices. Moreover, hardware errors often mean that the device won’t work properly.</p><p id="e4e4">However, errors in the firmware of the devices (especially those performing simple tasks without the possibility of remote firmware upgrade) should not be treated irresponsibly either. Even if such errors do not make their manufacturer rework the circuitry, they can still lead to reflashing. When designing devices on simple microcontrollers with peripherals used for outer word communication, it is possible to add the function of remote firmware updates and protect yourself from device recalls. We will cover remote firmware upgrades in more detail in one of our upcoming publications.</p><p id="c686">Here are some examples of hardware issues:</p><ul><li id="c041">2017 — Spectre, Meltdown — major hardware vulnerabilities at the core level of most Intel, AMD, ARM processors were detected. The command execution optimization mechanism could be used to access the arbitrary memory allocated for specific applications:</li></ul><ul><li id="d937">2016 — The discovery of a known problem with Samsung Galaxy Note 7 batteries causing smartphones to burn. Due to possible fires, some countries banned this model from air transportation:</li></ul><ul><li id="c99a">2013 — nowadays — numerous incidents involving the ignition of electronic cigarette batteries resulting in severe burns and injuries to users (warning! explicit content):</li></ul><p id="82e7">These examples show that hardware errors in devices can be fatal to the device itself or to the manufacturer. This is why hardware development and testing must be more delicate.</p><h2 id="fd51"><strong>A simple example of a disruptive design error in a device</strong></h2><p id="9500">The consequences of hardware errors are clear, but why they occur? What is the reason behind them?</p><p id="f9af">Errors in the circuitry and mechanics of the device often occur due to the lack of load, crash tests, tests in an aggressive environment. The approach to developing hardware may be incorrect, too.</p><p id="81e3">Let’s say we designed a simple device — a component of the meteorological data collection system.</p><p id="bd28">The device is installed on a hill (a lamppost, a tree trunk, a roof of some building).</p><p id="0958">The device consists of the following parts:</p><ul><li id="0a43">a series of sensors;</li><li id="b2d4">a microcontroller unit;</li><li id="79a6">a <a href="https://en.wikipedia.org/wiki/Zigbee" target="_blank" rel="noopener">ZigBee</a> transmitter;</li><li id="e9d8">a <a href="https://en.wikipedia.org/wiki/Lithium_iron_phosphate_battery" target="_blank" rel="noopener">LiFePO4 </a>battery with 2000mАh capacity;</li><li id="8319">a DC/DC converter;</li><li id="058e">a charge/discharge controller;</li><li id="1350">a solar panel for autonomous working.</li></ul><p id="ddc7">The device is sealed in the IP67 housing (description: <a href="https://en.wikipedia.org/wiki/IP_Code" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/IP_Code</a>).</p><p id="0c33">The block diagram of the device is as follows:</p><figure><div><div><p><img alt="The block diagram of the device." src="https://miro.medium.com/max/1218/0*4MNTWWozHSXtf3nF" width="609" height="402" srcset="https://miro.medium.com/max/552/0*4MNTWWozHSXtf3nF 276w, https://miro.medium.com/max/1104/0*4MNTWWozHSXtf3nF 552w, https://miro.medium.com/max/1218/0*4MNTWWozHSXtf3nF 609w" sizes="609px" data-old-src="https://miro.medium.com/max/60/0*4MNTWWozHSXtf3nF?q=20"></p></div></div></figure><p id="983d">Let’s suppose that during the development phase, some tests were carried out to check:</p><ul><li id="1c07">Stand-alone operation using solar battery charging;</li><li id="43e0">Transmitting of actual sensor data at the required distance;</li><li id="0562">Current consumption of the device within the permitted limits;</li><li id="219d">Hull tightness.</li></ul><p id="a3aa">It looks like the device passed all the necessary tests, and it is possible to start serial production.</p><p id="061a">Next, the following scenario is possible:</p><ol><li id="7bdf">The device documentation for mass production is written.</li><li id="30f7">A trial batch of 100 products is produced.</li><li id="de5d">The product is launched officially.</li><li id="c546">After a long and successful use during several months, the company produces a larger batch of several thousand units.</li><li id="0b29">The ambient temperature gets higher as summer comes.</li><li id="38a0">Due to high tightness of the device and the lack of active cooling, the devices gradually heat up to the temperatures when their batteries become unusable.</li><li id="a899">The battery capacity drops rapidly, making it harder to keep the supply voltage at the necessary level.</li><li id="17e4">The DC/DC converter starts to operate at its power limit and lose conversion efficiency over time, dissipating more and more power.</li><li id="729c">The increased temperature of the device’s active elements causes a fire.</li></ol><p id="9522">In this scenario, at best the devices will simply fail, at worst they will cause a fire.</p><p id="0cc3">In this example, the error is made at the initial stages of the construction of circuitry, as the device should have been load tested in aggressive conditions. To prevent the error in the remaining devices, it is necessary to completely change the approach to power supply and sealing.</p><p id="31b3">This means that producing hotfixes for devices with problems in circuitry and sealing mechanics is simply pointless. It is much cheaper and faster to reissue the entire batch of devices.</p><h2 id="b316"><strong>Price calculation of a simple error in a hardware project</strong></h2><p id="5150">If the errors from our example are detected in a real hardware project, the manufacturer will suffer colossal losses, and their reputation will also be affected, which may lead to bankruptcy.</p><p id="99e2">If that hardware company from our example decides to re-design and reissue their simple devices, it will need to spend huge amounts of money on the redevelopment of problem parts and additional testing.</p><p id="7ca3">Let’s make a simple calculation on how much it will have to spend on re-issuing the series of devices:</p><p id="1d46"><strong>Cost of parts: </strong>the price of parts for one device from the example ranges between $70 and $90.</p><p id="b8e1"><strong>Development: </strong>fixing power supply and sealing problems plus preliminary test will take an Embedded Systems Engineer about 15 hours.</p><p id="cb16"><strong>Simulation, testing under aggressive environment: </strong>simulation of the device’s behavior in real-world, calculation of power consumption and dissipation, and tests in aggressive conditions can take up to 50 hours.</p><p id="f40f">The average cost of the Embedded Systems Engineer work is <a href="https://www.payscale.com/research/US/Job=Embedded_Systems_Engineer/Salary" target="_blank" rel="noopener">30$/h</a>.</p><p id="8f01">Thus, to correct the error from our example, the company will need about $ 2,000, and reissuing of the trial 100-device batch will cost it about $ 8,000.</p><p id="94ac">The cost of lost time and customer confidence should also be added to the resulting amount. If the worst-case scenario unfolds, the damage compensations paid to the users will increase it even more.</p><p id="0a73">How to avoid such mistakes? Which tests should be given more attention? What are the main design problems when it comes to hardware? That’s what we’ll talk about later.</p><h2 id="5787">Step-by-step planning for prototype device development</h2><p id="32c8">To issue a test batch of devices successfully, you need to have a fully tested prototype device and complete technical documentation describing the production technology.</p><p id="7e42">The keyword here is “prototype” — a device that fully implements the required functionality and is ready for modification and optimization for the consequent serial production. More information about prototyping can be found here:</p><p id="5615">When you discuss the statement of work and possible deadlines with the customer, it is vital to take into account the following facts:</p><ul><li id="b40f">If all your hardware modules are stable as separate parts, it does not guarantee that they will work together in any way.</li><li id="f124">Successful prototyping does not mean that a product can be launched into a series — it is just one of the achievements on the way to mass production.</li><li id="4ac8">Each significant correction of the circuitry or mechanics requires the production of a new prototype. It also means another series of tests (no matter how long it takes, otherwise the production of prototypes does not make sense at all).</li><li id="a4b6">You need to allocate some extra time for prototyping as production depends on many off-project factors.</li><li id="56e6">While simulation and testing on debug stands to speed up the development at early design stages, they only add errors to the prototype at late stages.</li><li id="7555">One should avoid producing a large series of devices once the production technology is ready. It’s better to go with a small batch of devices to collect feedback and conduct tests in an aggressive environment.</li><li id="0806">At the design stage, it is necessary to allocate additional budget for …</li></ul></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.maddevs.io/the-cost-of-errors-in-hardware-projects-7d73b0fd8465?source=friends_link&amp;sk=eb21eb69d892cb19c0f85f3e0276481e">https://blog.maddevs.io/the-cost-of-errors-in-hardware-projects-7d73b0fd8465?source=friends_link&amp;sk=eb21eb69d892cb19c0f85f3e0276481e</a></em></p>]]>
            </description>
            <link>https://blog.maddevs.io/the-cost-of-errors-in-hardware-projects-7d73b0fd8465?source=friends_link&amp;sk=eb21eb69d892cb19c0f85f3e0276481e</link>
            <guid isPermaLink="false">hacker-news-small-sites-23828667</guid>
            <pubDate>Tue, 14 Jul 2020 04:56:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Committing Suicide]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23828663">thread link</a>) | @lettergram
<br/>
July 13, 2020 | https://austingwalters.com/on-committing-suicide/ | <a href="https://web.archive.org/web/*/https://austingwalters.com/on-committing-suicide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3389">

<div>
<p>Those that know me, know that I am both bold and resolute. I stand by my thoughts / comments, yet I attempt to keep an open mind, analyze a situation, self-reflect on any biases, and integrate feedback. I even go so far as to analyze my confidence level, see <a href="https://predictionbook.com/" target="_blank" rel="noopener noreferrer">predictionbook.com</a>.</p>
<p>With that in mind. I want to share how utterly angry and helpless I feel —</p>
<p>I can’t share my true thoughts, hell my analysis, of the current political situation in the U.S. Although I have written on it countless times, I end up deleting the posts.</p>
<p>Why?</p>
<p>It’s not safe to share thoughts.</p>
<h2>State of Affairs</h2>
<p>Today, sharing one’s opinion can cost you your livelihood, your ability to communicate, and more.</p>
<p>Historically, that was always true, perhaps more-so. We’re now returning to the status quo — repression.</p>
<p>Today’s flavor of repression is one where offending someone randomly across the globe, can cost you your job. That person may not have a standing in your community and may not have a relationship with your employer. However, they can amplify their voice, tweet your employer, and your employer (scared out of its mind by the current situation) will terminate you. That is the state of affairs today. It doesn’t matter if you’re correct or innocent. It doesn’t even matter if 99.9% of people aren’t offended by what you said — we are now in a world of “<a href="https://en.wikipedia.org/wiki/Online_shaming#Cancellation" target="_blank" rel="noopener noreferrer">cancel culture</a>“.</p>
<h2>Finding Middle Ground</h2>
<p>In the United States in 2020, we have two paths. One path leads to an ever more left-leaning populous “uprising”; the other path leads to an ever more right-leaning populous “uprising”. I don’t see an alternative, outside of some quite-frankly comical alternatives (e.g. President Mitt Romney, with VP Bernie Sanders).</p>
<p>One way or another, I lose. No one is speaking up for my beliefs or representing me.</p>
<p>I sense I’m not alone. Everyone I speak to left or right, hates the current state of affairs. Most of us even agree on <em>why</em> we distrust the system. Unfortunately, we can’t elect someone to fix the system. Neither Trump, nor Biden, nor Bernie, nor anyone on the ballot accurately represents or even inspires us.</p>
<p>By and large, I believe this is due to the “absolute” nature of our current social strife. Take the question:</p>
<blockquote><p>Why can’t I be anti-vaccine and pro-choice?</p></blockquote>
<p>You would suspect everyone would agree that we “own” our bodies. If that were true, then you would effectively have to be pro-choice AND support people’s right to choose what to put in their bodies; body ownership is the middle ground. I wish we could coalesce around the middle ground, then compromise on edge cases, enabling progress.</p>
<p>Take another example:</p>
<blockquote><p>Why don’t we do firearms training in schools?</p></blockquote>
<p>It’s an honest question — we’ve had the 2nd amendment for hundreds of years. Similar to driving a car, we should train our youth to handle firearms. I suspect we all know the reason this is not occurring — because a significant portion of the United States is fearful of firearms.</p>
<p>From the evidence, the fear is unjustified. We have evidence that with a good training program and robust mental evaluation process, firearms by-and-large are safe for society. <a href="https://en.wikipedia.org/wiki/Firearms_regulation_in_Switzerland" target="_blank" rel="noopener noreferrer">See Switzerland</a>:</p>
<blockquote><p>Swiss males grow up expecting to undergo basic military training, usually at age 20 in the recruit school..</p>
<p>…Prior to 2007, members of the Swiss Militia were supplied with 50 rounds of ammunition for their military weapon in a sealed ammo box that was regularly audited by the government…</p>
<p>…Every person with a Swiss citizenship, aged 10 years or older, can take part at any federal ranges and will be able to shoot for free with the ordinance rifle…</p>
<p>…In 2016, there were 187 attempted and 45 completed homicides, for a homicide rate of 0.50 per 100,000 population, giving Switzerland one of the lowest homicide rates in the world…</p></blockquote>
<p>Further, firearms are already widely available (<a href="https://en.wikipedia.org/wiki/Estimated_number_of_civilian_guns_per_capita_by_country" target="_blank" rel="noopener noreferrer">300+ million guns in the U.S.</a>) &amp; availability enshrined in law.</p>
<p>Sorrowfully, evidence doesn’t matter here; fear guides many. Yoda has some insights here:</p>
<blockquote><p><span data-parade-type="promoarea" data-parade-location-types="promoarea" data-parade-location-ids="article" data-parade-views="false" data-parade-touches="false" data-parade-clicks="false" data-parade-mouseovers="false">Fear is the path to the dark side. Fear leads to anger. Anger leads to hate. Hate leads to suffering.</span></p>
<p>— George Lucas (Yoda)</p></blockquote>
<h2>The False Dichotomy</h2>
<p>I don’t agree with the left or the right on many things in United States politics. In fact, I find most of the arguments a false dichotomy, designed to garner votes. To share one’s full thoughts would cause either or both sides to lash out, even though evidence may support the claims / musings.</p>
<p>Regretfully, this leaves me and many others out of the public discourse. While most of us have heard,</p>
<blockquote><p>The only thing necessary for the triumph of evil is for good men to do nothing.</p>
<p>— Edmund Burke (attributed)</p></blockquote>
<p>It’s not quite that simple and I prefer another sentiment:</p>
<blockquote><p>A man dies when he refuses to stand up for that which is right. A man dies when he refuses to stand up for justice. A man dies when he refuses to take a stand for that which is true.</p>
<p>— Martin Luther King Jr.</p></blockquote>
<center><br>
<iframe data-lazy-type="iframe" data-src="https://www.youtube.com/embed/0On19DRA2fU?start=88" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"><span style="display: inline-block; width: 0px; overflow: hidden; line-height: 0;" data-mce-type="bookmark" class="lazy lazy-hidden mce_SELRES_start">﻿</span></iframe></center><p>Truthfully, we’re all being held hostage. I am very confident few people fully agree with either side in this political theater. We have extremists on either side shouting and being amplified by social media. In truth, the vast majority of us don’t agree [fully] with either extreme. Most of us, want to “live and let live” — that’s the American way. We’re a country founded on our hatred for taxes and the desire to live free from persecution. Please, please.. Don’t let that change.</p>
<p>It’s easy to decide “what’s right” when you look at it through that lens — am I persecuting others or increasing taxes (arguably a form of persecution)? If either are true, likely we should reconsider our stance.</p>
<h2>The Chaos</h2>
<p>Today, we are edging towards chaos. We all feel it. Riots, job loss, deadly diseases, [trade] wars, homelessness… We need leadership that can unite us.</p>
<p>Unfortunately, many of our would-be leaders have opted out or have been pushed out of this system. They’ve become engineers, scientists, bloggers — too scared to share their opinions (<a href="https://en.wikipedia.org/wiki/Slate_Star_Codex" target="_blank" rel="noopener noreferrer">even shutting down</a>). To hold a nuanced opinion different from the “socially accepted” by one group or another will get you “canceled”. In this case, “canceled” can mean anything from losing your job, to losing financial platforms/instruments (i.e. PayPal, VISA, YouTube revenue, etc.), to receiving threats on your life.</p>
<p>We have an ongoing pandemic, with millions in the United States likely about to perish, the economy collapsing, and we still cannot escape the politics.</p>
<p>I’m not hopeful.</p>
<p>I have so many musings, stories, and analyses I’d like to share, but neither facts nor my opinions matter.</p>
<p>Let’s be honest —</p>
<ul>
<li>I’m a white, cisgender, straight, male</li>
<li>I work as a technical manager in a research group, at a bank</li>
<li>I’m socially liberal in many ways and conservative in others</li>
<li>I grew up lower-middle class; now, I’m upper-middle class</li>
<li>I don’t attribute myself to any political party</li>
</ul>
<p>A large number of people dismiss or overlook me because of my background. Those who don’t outright dismiss me are also not likely to support my interest(s).</p>
<h2>Meritocracy or Bust</h2>
<p>What scares me is that I am a father and I am fearful for my children’s future. I was raised with the understanding that America is a meritocracy. Regardless of your race, gender, or creed, you should have the ability to make a life in the United States,<strong><em> to build a future for your children</em></strong>. Sadly, I don’t see the same core mission today. None of the political parties or the government at large appears forward-looking, for the children. Perhaps, that’s because of a <a href="https://www.cdc.gov/nchs/nvss/births.htm" target="_blank" rel="noopener noreferrer">declining birthrate</a>, I’m not sure.</p>
<p>As someone with children, I’m pleading for a group to come together to challenge the current status quo and equitably look to improve our society. We do have systemic problems that need to be fixed. Compromises will need to be made, but I don’t believe we need sacrifices from anyone.</p>
<p>The racism and sexism needs to stop. I suspect, most of us (though, not all) want a meritocracy, a hierarchy based on merit. Unfortunately, what’s being propagated is a hierarchy based on race, sex and orientation — the under-privileged. It’s clear from the countless stories we see in the news. I am sure you are tired of the racism, as am I. That’s probably true regardless of which side of the political spectrum you fall.</p>
<p><em>No one’s</em> value to society should be assessed by their race, gender or creed. A person’s value should be based off what they have to offer to a given group, organization, or society. We can rally around that idea (that we’re all equal, differentiated on merit) and work to improve. It’s a middle ground we can [mostly] agree on. From there, we can fix the injustices.</p>
<p>What horrifies me, is that even to express that <em>“we’re all equal” </em>is a challenge to this new socio-economic hierarchy. <em>No one</em> is representing me or has my family’s best interests in mind. Realistically, I don’t expect anyone to have <em>my family’s interests</em> in mind, but I don’t want my potential / rights eroded.</p>
<p>Due to this political tug of war, both sides of the political spectrum want to diminish our rights; they’re only bickering over which rights to diminish. Let’s stop this tug of war and come together.</p>
<p>If we don’t come together, soon enough we won’t have a democracy, or frankly, a future to build for.</p>
<h2>In the Words of John Adams…</h2>
<blockquote><p>Remember, democracy never lasts long. It soon wastes, exhausts, and murders itself. There never was a democracy yet that did not commit suicide. It is in vain to say that democracy is less vain, less proud, less selfish, less ambitious, or less avaricious than aristocracy or monarchy. It is not true, in fact, and nowhere appears in history. Those passions are the same in all men, under all forms of simple government, and when unchecked, produce the same effects of fraud, violence, and cruelty. When clear prospects are opened before vanity, pride, avarice, or ambition, for their easy gratification, it is hard for the most considerate philosophers and the most conscientious moralists to resist the temptation. Individuals have conquered themselves. Nations and large bodies of men, never.</p>
<p>— …</p></blockquote></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://austingwalters.com/on-committing-suicide/">https://austingwalters.com/on-committing-suicide/</a></em></p>]]>
            </description>
            <link>https://austingwalters.com/on-committing-suicide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23828663</guid>
            <pubDate>Tue, 14 Jul 2020 04:56:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Google Committed $10B to India's Digital Future]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23828478">thread link</a>) | @sbmthakur
<br/>
July 13, 2020 | https://finshots.in/archive/why-google-is-investing-in-india/ | <a href="https://web.archive.org/web/*/https://finshots.in/archive/why-google-is-investing-in-india/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">

    <div>

        <article>

            

            <figure>
                <img srcset="https://d3jlwjv6gmyigl.cloudfront.net/images/2020/07/google1.jpg 300w,
                            https://d3jlwjv6gmyigl.cloudfront.net/images/2020/07/google1.jpg 600w,
                            https://d3jlwjv6gmyigl.cloudfront.net/images/2020/07/google1.jpg 1000w,
                            https://d3jlwjv6gmyigl.cloudfront.net/images/2020/07/google1.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://d3jlwjv6gmyigl.cloudfront.net/images/2020/07/google1.jpg" alt="Why Google committed $10 Billion to India's Digital Future">
            </figure>

            <section>
                <div>
                    <p><em>Google just promised to invest $10 Billion in India and we need to talk about it.</em></p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><!--kg-card-begin: html--><!--kg-card-end: html--><h3 id="the-story">The Story</h3><p>Yesterday, Google’s CEO, Sundar Pichai had a <a href="https://blog.google/inside-google/company-announcements/investing-in-indias-digital-future">big announcement</a> to make.</p><blockquote>Today, I’m excited to announce the Google for India Digitization Fund. Through this effort, we will invest ₹75,000 crore, or approximately $10 billion, into India over the next 5–7 years. We’ll do this through a mix of equity investments, partnerships, and operational, infrastructure and ecosystem investments. This is a reflection of our confidence in the future of India and its digital economy.</blockquote><p>And truth be told, it’s a big bet. I mean, when was the last time you saw a foreign company commit such an exorbitant sum to the future of India? It’s quite an unprecedented push for India’s digital dreams. And there was a four-point agenda that Google outlined to turn these dreams into reality.</p><p><strong>1) Enabling affordable access and information for every Indian in their own language, whether it’s Hindi, Tamil, Punjabi or any other.</strong></p><p>Explanation: India isn’t a large <a href="https://hbr.org/2017/12/you-dont-need-an-india-strategy-you-need-a-strategy-for-each-state-in-india">homogeneous market</a>. Instead, it’s an amalgamation of multiple micro markets with subtle differences in culture, language, income, tradition, and wealth. So tech companies aspiring to foray deep into these micro-markets will have to adapt to these differences.</p><p>Consider for instance the language divide.</p><p>Back in 2018, India had an <a href="https://www.livemint.com/industry/media/most-of-india-s-digitally-monetizable-users-want-vernacular-content-report-1565097932712.html">active internet user base</a> of 530 Million. However, close to half these users preferred digital content in their own language. And don’t scoff at this population. They come with an annual spending power of $300 billion. That’s a massive market crying out for tailor-made products. You can’t ignore them anymore.</p><p>Unfortunately, building a library rich in vernacular content will take time and money. Just look at the scale of the problem here — <a href="https://qz.com/india/1372074/google-using-ai-for-more-indian-language-content/">90% of the country’s</a> registered 135,000 publications don’t even have a website since they only cater to local communities. And most of them couldn’t scale their business online since they had very limited tools at their disposal.</p><p>In fact, back in 2018, Google said it was working with Indian language publishers to solve this very problem. They introduced <a href="https://navlekha.withgoogle.com/intl/en/#!/overview">Navlekha</a> — a platform that was supposed to allow publishers to edit and produce content in local languages without any expert digital knowledge. And they were just scratching the surface here.</p><p>But if they really wanted to make a dent , they had to have better subtitles, better translation, better content, better accessibility, better everything. They needed to make investments to help grow the vernacular ecosystem.</p><p>And guess what? It’s happening now.</p><p><strong>2) Building new products and services that are deeply relevant to India’s unique needs</strong></p><p>Every market has its own peculiar quirks and India is no different. When Samsung <a href="https://news.samsung.com/global/thinking-local-how-products-are-tailored-to-markets-2">launched its ActivWash+</a> washing machine they added a built-in sink, given the tendency among Indians to pre-wash clothes by hand. This meant consumers no longer had to crouch on the floor and they could hand wash their clothes standing upright. I am not saying Google is trying to build washing machines here. But like most things, tech products are likely to witness a surge in adoption rates if they are built specifically for the audience they cater to.</p><p>In fact, Google is no stranger to this. Back in 2017, they wrote a rather <a href="https://www.blog.google/technology/next-billion-users/building-india-first-products-and-features/">elaborate memo</a> on how they were building India-first products and features for the next billion Internet users.</p><blockquote>Another India-first feature is the new “two-wheeler mode” in Google Maps. India is the largest two-wheeler market in the world, and the millions of motorcycle and scooter riders have different navigation needs than drivers of automobiles. Two-wheeler mode in Maps shows trip routes that use “shortcuts” not accessible to cars and trucks. It also provides customized traffic and arrival time estimations. And since so many Indians rely on local landmarks for navigation, two-wheeler mode will show major landmarks on the route so that riders can plan their trip before starting, and don’t have to keep checking the phone on the go.</blockquote><p>I think it’s pretty clear what Google is trying to do here.</p><p><strong>3) Empowering businesses as they continue or embark on their digital transformation</strong></p><p>Think Google Pay. Currently the <a href="https://www.livemint.com/technology/tech-news/google-pay-set-to-tap-into-12mn-kirana-stores-in-india-1566990709066.html">platform has</a> over 3,000 online merchants and over 200,000 offline merchants. They use it to take payments, pay their suppliers, transfer money to employees and pay the odd electricity bill. And if Google can partner with other similar entities that are trying to help grow India’s fledgling digital ecosystem, it would be a win-win for everyone involved.</p><p>Right?</p><p><strong>4) Leveraging technology and AI for social good, in areas like health, education, and agriculture</strong></p><p>“Don’t be evil” was a part of the company’s <a href="https://abc.xyz/investor/other/google-code-of-conduct.html" rel="noopener noreferrer noopener">corporate code of conduct</a> since 2000. When Google reorganized in 2015, the parent company Alphabet assumed a <a href="https://www.engadget.com/2015/10/02/alphabet-do-the-right-thing/" rel="noopener noreferrer noopener">slightly different version</a> of the motto — “do the right thing.”</p><p>So, point 4 ought to be self-explanatory. It’s literally their motto.</p><p>But do bear in mind, that there is an ulterior motive here. Google wasn’t going to spend this money and push the digitization initiative if it didn’t make business sense. After all, a digital India translates to more people taking to the internet. And since Google makes most of its money offering advertising services online, you can get a sense of why they are making this bet right now.</p><!--kg-card-begin: image--><figure><img src="https://cdn-images-1.medium.com/max/900/1*EuniDplL-G6F5Fs-XOXXjw.jpeg"></figure><!--kg-card-end: image--><p>Nonetheless, that’s it from us today. If you had a friend, family member, or relative talking about this big investment, make sure they get some context. Make sure they know what this means and why Google is venturing down this path. Ergo, share this article on <a href="https://api.whatsapp.com/send?text=An%20explainer%20on%20why%20Google%20is%20investing%20$10%20billion%20in%20India?%20https://bit.ly/3gSwU1o">WhatsApp</a>, <a href="https://twitter.com/intent/tweet?url=https://bit.ly/303yozb&amp;via=finshots&amp;text=An%20explainer%20on%20why%20Google%20is%20investing%20$10%20billion%20in%20India?">Twitter</a>, and <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://finshots.in/archive/why-google-is-investing-in-india">LinkedIn</a>, will you?</p><p>Until next time…</p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><p><em>Correction: We removed the infographic benchmarking GDP of different states with other countries across the world since the data in the chart was erroneous. We regret the error</em></p>
                </div>
            </section>


            

            

            


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://finshots.in/archive/why-google-is-investing-in-india/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23828478</guid>
            <pubDate>Tue, 14 Jul 2020 04:17:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How major and minor device numbers worked in V7 Unix]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23828398">thread link</a>) | @todsacerdoti
<br/>
July 13, 2020 | https://utcc.utoronto.ca/~cks/space/blog/unix/V7DeviceNumbersHow | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/unix/V7DeviceNumbersHow">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>How major and minor device numbers worked in V7 Unix</h2>

	<p><small>July 13, 2020</small></p>
</div><div><p>Unix people who've been around for a while know that Unix devices
have <em>device numbers</em>, and that device numbers are divided into
<em>major</em> and <em>minor</em> device numbers. When you do '<code>ls -l /dev/null</code>'
and one of the fields that <code>ls</code> prints is two comma separated
numbers, those are the major and minor numbers (on Linux, they are
'1, 3'; this varies by Unix). Device numbers and their split into
major and minor parts go back a long way, to before Research Unix
V7, but V7 makes a convenient point to look at what they meant and
how they worked in the original Unixes.</p>

<p>As various sources will tell you, the major number tells you (and
the Unix kernel) what sort of device it is and thus what device
driver to use to talk to it, while the minor number tells the device
driver what specific bit of hardware it's responsible for that you
want to talk to.  Sometimes the minor number also determines some
bit of functionality. Because V7 was a deliberately simple and
brute force system and kernel, major device numbers had a very
simple implementation. We can see it in <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/conf/c.c">the generated V7 kernel
configuration file <code>c.c</code></a>:</p>


<pre> struct bdevsw bdevsw[] =
 {
   nulldev, nulldev, rkstrategy, &amp;rktab, /* rk = 0 */
   nodev, nodev, nodev, 0, /* rp = 1 */
   [...]
   nodev, nodev, nodev, 0, /* hp = 6 */
   htopen, htclose, htstrategy, &amp;httab, /* ht = 7 */
   nodev, nodev, nodev, 0, /* rl = 8 */
   0
 };
</pre>

<p>What we're seeing here is that V7 literally had an array of <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/h/conf.h"><code>bdevsw</code>
structures</a> indexed
by the major (block) device number, with various function that were
called when you did things like open a device (in <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/sys/fio.c"><code>fio.c</code></a>).
There was a similar array for character devices, the <code>cdevsw</code> array.
In both of them, what driver functions were listed here instead of
stubbed out were determined by simple configuration files (<a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/conf">here</a>)
that said what devices you had (among other things).</p>

<p>(The <code>c.c</code> file was generated by <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/conf/mkconf.c">a program</a>.
The particular <code>c.c</code> file in the TUHS V7 tree was built with only
two block devices configured, the <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/rk.c">RK disk driver</a> and
<a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/ht.c">TJU16 tape driver 'ht'</a>.)</p>

<p>In V7 the minor device number was only interpreted by the device
driver, as far as I can see. Device drivers used this for a variety
of purposes. For instance, <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/mem.c">the <code>mem</code> character driver</a>
implemented <code>/dev/null</code> as minor device 2, to go along with access
to physical memory and kernel memory. The <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/rl.c"><code>rl</code> disk driver</a> used
the minor device number to decide what physical disk it was talking
to (it supported up to four of them). Once V7 started getting out
in the world, other people wrote drivers for it (such as <a href="http://clara.comm.sfu.ca/pups/PDP-11/Trees/V7/usr/sys/dev/rx2.c">the RX02
floppy disk driver</a>) that
used minor device numbers both to select what to talk to and control
what features to use.</p>

<p>(There's also <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/kl.c">the <code>kl</code> KL/DL-11 serial and console driver</a>, which
seems to deal with three different sets of hardware control registers
based on the minor number.)</p>

<p>The <code>/dev/tty</code> character device was implemented in a clever and
very short way in <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/sys.c"><code>sys.c</code></a>. In
V7, there were no pseudo-ttys and no hot-plugged devices, so your
underlying physical terminal device always existed and was recorded
in your <code>u</code> area (see <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/h/user.h"><code>user.h</code></a>) The
general tty driver simply used this recorded device number of your
controlling tty to call its open, read, write, and ioctl functions
through the <code>cdevsw</code> array. As far as I can tell, this driver paid
no attention at all to the minor device number; as long as <code>/dev/tty</code>
had major number 7, the minor number was irrelevant.</p>

<p>PS: Note that V7 device drivers tended to be a little relaxed about
error checking for their minor device numbers (and other things).
For instance, as far as I can tell the <code>mem</code> driver actually only
distinguishes between minor number 2, minor number 1, and 'everything
else', which is treated as minor number 0, giving access to physical
memory.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/unix/V7DeviceNumbersHow</link>
            <guid isPermaLink="false">hacker-news-small-sites-23828398</guid>
            <pubDate>Tue, 14 Jul 2020 04:00:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tutorial: How to Build LinkedIn Automation Tools with Python with a Code Example]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23828280">thread link</a>) | @ferlita
<br/>
July 13, 2020 | https://nubela.co/blog/tutorial-how-to-build-linkedin-automation-tools-with-python-with-a-code-example/ | <a href="https://web.archive.org/web/*/https://nubela.co/blog/tutorial-how-to-build-linkedin-automation-tools-with-python-with-a-code-example/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://nubela.co/blog/tutorial-how-to-build-linkedin-automation-tools-with-python-with-a-code-example/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23828280</guid>
            <pubDate>Tue, 14 Jul 2020 03:41:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tufte CSS]]>
            </title>
            <description>
<![CDATA[
Score 58 | Comments 9 (<a href="https://news.ycombinator.com/item?id=23828196">thread link</a>) | @mmastrac
<br/>
July 13, 2020 | https://edwardtufte.github.io/tufte-css/ | <a href="https://web.archive.org/web/*/https://edwardtufte.github.io/tufte-css/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
      <p>Dave Liepmann</p>
      <section>
        <p>Tufte CSS provides tools to style web articles using the ideas demonstrated by Edward Tufte’s books and handouts. Tufte’s style is known for its simplicity, extensive use of sidenotes, tight integration of graphics with text, and carefully chosen typography.</p>
        <p>Tufte CSS was created by <a href="http://www.daveliepmann.com/">Dave Liepmann</a> and is now an Edward Tufte project. The original idea was cribbed from <a href="https://tufte-latex.github.io/tufte-latex/">Tufte-<span>L<span>a</span>T<span>e</span>X</span></a> and <a href="http://rmarkdown.rstudio.com/tufte_handout_format.html">R Markdown’s Tufte Handout format</a>. We give hearty thanks to all the people who have contributed to those projects.</p>
        <p>If you see anything that Tufte CSS could improve, we welcome your contribution in the form of an issue or pull request on the GitHub project: <a href="https://github.com/edwardtufte/tufte-css">tufte-css</a>. Please note the <a href="https://github.com/edwardtufte/tufte-css#contributing">contribution guidelines</a>.</p>
        <p>Finally, a reminder about the goal of this project. The web is not print. Webpages are not books. Therefore, the goal of Tufte CSS is not to say “websites should look like this interpretation of Tufte’s books” but rather “here are some techniques Tufte developed that we’ve found useful in print; maybe you can find a way to make them useful on the web”. Tufte CSS is merely a sketch of one way to implement this particular set of ideas. It should be a starting point, not a design goal, because any project should present their information as best suits their particular circumstances.</p>
      </section>

      <section>
        <h2 id="getting-started">Getting Started</h2>
        <p>To use Tufte CSS, copy <code>tufte.css</code> and the <code>et-book</code> directory of font files to your project directory, then add the following to your HTML document’s <code>head</code> block:</p>

        <pre><code>&lt;link rel="stylesheet" href="tufte.css"/&gt;</code></pre>

        <p>Now you just have to use the provided CSS rules, and the Tufte CSS conventions described in this document. For best results, View Source and Inspect Element frequently.</p>
      </section>

      <section>
        <h2 id="fundamentals">Fundamentals</h2>
        <h3 id="fundamentals--sections-and-headers">Sections and Headings</h3>
        <p>Organize your document with an <code>article</code> element inside your <code>body</code> tag. Inside that, use <code>section</code> tags around each logical grouping of text and headings.</p>
        <p>Tufte CSS uses <code>h1</code> for the document title, <code>p</code> with class <code>subtitle</code> for the document subtitle, <code>h2</code> for section headings, and <code>h3</code> for low-level headings. More specific headings are not supported. If you feel the urge to reach for a heading of level 4 or greater, consider redesigning your document:</p>
        <blockquote cite="http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0000hB">
          <p>[It is] notable that the Feynman lectures (3 volumes) write about all of physics in 1800 pages, using only 2 levels of hierarchical headings: chapters and A-level heads in the text. It also uses the methodology of <em>sentences</em> which then cumulate sequentially into <em>paragraphs</em>, rather than the grunts of bullet points. Undergraduate Caltech physics is very complicated material, but it didn’t require an elaborate hierarchy to organize.</p>
          
        </blockquote>
        <p>As a bonus, this excerpt regarding the use of headings provides an example of block quotes. In Tufte CSS they are just lightly styled, semantically correct HTML using <code>blockquote</code> and <code>footer</code> elements. See page 20 of <a href="https://www.edwardtufte.com/tufte/books_vdqi">The Visual Display of Quantitative Information</a> for an example in print.</p>
        <p><span>In his later books<label for="sn-in-his-later-books"></label></span><span><a href="http://www.edwardtufte.com/tufte/books_be"><em>Beautiful Evidence</em></a></span>, Tufte starts each section with a bit of vertical space, a non-indented paragraph, and the first few words of the sentence set in small caps. For this we use a span with the class <code>newthought</code>, as demonstrated at the beginning of this paragraph. Vertical spacing is accomplished separately through <code>&lt;section&gt;</code> tags. Be consistent: though we do so in this paragraph for the purpose of demonstration, do not alternate use of header elements and the <code>newthought</code> technique. Pick one approach and stick to it.</p>

        <h3 id="fundamentals--text">Text</h3>
        <p>Although paper handouts obviously have a pure white background, the web is better served by the use of slightly off-white and off-black colors. Tufte CSS uses <code>#fffff8</code> and <code>#111111</code> because they are nearly indistinguishable from their ‘pure’ cousins, but dial down the harsh contrast. We stick to the greyscale for text, reserving color for specific, careful use in figures and images.</p>
        <p>In print, Tufte has used the proprietary Monotype Bembo<label for="sn-proprietary-monotype-bembo"></label><span>See Tufte’s comment in the <a href="http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0000Vt">Tufte book fonts</a> thread.</span> font. A similar effect is achieved in digital formats with the now open-source <a href="https://github.com/edwardtufte/et-book">ETBook</a>, which Tufte CSS supplies with a <code>@font-face</code> reference to a .ttf file. In case ETBook somehow doesn’t work, Tufte CSS shifts gracefully to other serif fonts like Palatino and Georgia.</p>
        <p>Also notice how Tufte CSS includes separate font files for bold (strong) and italic (emphasis), instead of relying on the browser to mechanically transform the text. This is typographic best practice.</p>
        <p>If you prefer sans-serifs, use the <code>sans</code> class. It relies on Gill Sans, Tufte’s sans-serif font of choice.</p>
        <p>Links in Tufte CSS match the body text in color and do not change on mouseover or when clicked. Here is a <a href="#">dummy example</a> that goes nowhere. These links are underlined, since this is the most widely recognized indicator of clickable text. <label for="mn-blue-links">⊕</label><span>Blue text, while also a widely recognizable clickable-text indicator, is crass and distracting. Luckily, it is also rendered unnecessary by the use of underlining.</span> However, because most browsers’ default underlining does not clear descenders and is so thick and distracting, the underline effect is instead achieved using CSS trickery involving background gradients instead of standard <code>text-decoration</code>. Credit goes to Adam Schwartz for that technique.</p>
        <p>As always, these design choices are merely one approach that Tufte CSS provides by default. Other approaches can also be made to work. The goal is to make sentences readable without interference from links, as well as to make links immediately identifiable even by casual web users.</p>
      </section>

      <section>
        <h2 id="epigraphs">Epigraphs</h2>
        <div>
          <blockquote>
            <p>The English language . . . becomes ugly and inaccurate because our thoughts are foolish, but the slovenliness of our language makes it easier for us to have foolish thoughts.</p>
            
          </blockquote>
          <blockquote>
            <p>For a successful technology, reality must take precedence over public relations, for Nature cannot be fooled.</p>
            
          </blockquote>
          <blockquote>I do not paint things, I paint only the differences between things.</blockquote>
        </div>
        <p>If you’d like to introduce your page or a section of your page with some quotes, use epigraphs. Modeled after chapter epigraphs in Tufte’s books (particularly <em>Beautiful Evidence</em>), these are <code>blockquote</code> elements with a bit of specialized styling. Quoted text is italicized. The source goes in a <code>footer</code> element inside the <code>blockquote</code>. We have provided three examples in the epigraph of this section, demonstrating shorter and longer quotes, with and without a paragraph tag, and showing how multiple quotes within an epigraph fit together with the use of a wrapper class.</p>
      </section>

      <section>
        <h2 id="sidenotes">Sidenotes: Footnotes and Marginal Notes</h2>
        <p>One of the most distinctive features of Tufte’s style is his extensive use of sidenotes.<label for="sn-extensive-use-of-sidenotes"></label><span>This is a sidenote.</span> Sidenotes are like footnotes, except they don’t force the reader to jump their eye to the bottom of the page, but instead display off to the side in the margin. Perhaps you have noticed their use in this document already. You are very astute.</p>
        <p>Sidenotes are a great example of the web not being like print. On sufficiently large viewports, Tufte CSS uses the margin for sidenotes, margin notes, and small figures. On smaller viewports, elements that would go in the margin are hidden until the user toggles them into view. The goal is to present related but not necessary information such as asides or citations <em>as close as possible</em> to the text that references them. At the same time, this secondary information should stay out of the way of the eye, not interfering with the progression of ideas in the main text.</p>
        <p>Sidenotes consist of two elements: a superscript reference number that goes inline with the text, and a sidenote with content. To add the former, just put a label and dummy checkbox into the text where you want the reference to go, like so:</p>
        <pre><code>&lt;label for="sn-demo"
       class="margin-toggle sidenote-number"&gt;
&lt;/label&gt;
&lt;input type="checkbox"
       id="sn-demo"
       class="margin-toggle"/&gt;</code></pre>
        <p>You must manually assign a reference <code>id</code> to each side or margin note, replacing “sn-demo” in the <code>for</code> and the <code>id</code> attribute values with an appropriate descriptor. It is useful to use prefixes like <code>sn-</code> for sidenotes and <code>mn-</code> for margin notes.</p>
        <p>Immediately adjacent to that sidenote reference in the main text goes the sidenote content itself, in a <code>span</code> with class <code>sidenote</code>. This tag is also inserted directly in the middle of the body text, but is either pushed into the margin or hidden by default. Make sure to position your sidenotes correctly by keeping the sidenote-number label close to the sidenote itself.</p>
        <p>If you want a sidenote without footnote-style numberings, then you want a margin note.
          <label for="mn-demo">⊕</label>
          
          <span>
            This is a margin note. Notice there isn’t a number preceding the note.
          </span> On large screens, a margin note is just a sidenote that omits the reference number. This lessens the distracting effect taking away from the flow of the main text, but can increase the cognitive load of matching a margin note to its referent text. However, on small screens, a margin note is like a sidenote except its viewability-toggle is a symbol rather than a reference number. This document currently uses the symbol ⊕ (<code>&amp;#8853;</code>), but it’s up to you.</p>
        <p>Margin notes are created just like sidenotes, but with the <code>marginnote</code> class for the content and the <code>margin-toggle</code> class for the label and dummy checkbox. For instance, here is the code for the margin note used in the previous paragraph:</p>
        <pre><code>&lt;label for="mn-demo" class="margin-toggle"&gt;&amp;#8853;&lt;/label&gt;
&lt;input type="checkbox" id="mn-demo" class="margin-toggle"/&gt;
&lt;span class="marginnote"&gt;
  This is a margin note. Notice there isn’t a number preceding the note.
&lt;/span&gt;</code></pre>
        </section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://edwardtufte.github.io/tufte-css/">https://edwardtufte.github.io/tufte-css/</a></em></p>]]>
            </description>
            <link>https://edwardtufte.github.io/tufte-css/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23828196</guid>
            <pubDate>Tue, 14 Jul 2020 03:29:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Terraform Pain Points]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23828089">thread link</a>) | @jbergknoff
<br/>
July 13, 2020 | https://jonathan.bergknoff.com/journal/terraform-pain-points/ | <a href="https://web.archive.org/web/*/https://jonathan.bergknoff.com/journal/terraform-pain-points/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
	
	<h6>
		<span>2020-07-08</span>

		
		<span>
			
			<a href="https://jonathan.bergknoff.com/tags/tech">tech</a>
			
			<a href="https://jonathan.bergknoff.com/tags/programming">programming</a>
			
			<a href="https://jonathan.bergknoff.com/tags/terraform">terraform</a>
			
		</span>
		
	</h6>
	<hr>
	

<p>I love using <a href="https://www.terraform.io/">Terraform</a>. At my previous job, we managed our infrastructure entirely with Terraform: tens of thousands of resources spread across several cloud providers. The benefits of infrastructure-as-code and Terraform, in particular, are massive, but well known. While I still consider Terraform the best tool of its kind, this article describes some pain points that my team and I encountered as power users. I hope it can lead to some discussion about ways to improve.</p>

<p>All of these are relevant as recently as Terraform v0.13.0-beta3, July 2020.</p>

<ul>
<li><a href="#refactoring-is-difficult">Refactoring is difficult</a></li>
<li><a href="#code-reuse-is-limited">Code reuse is limited</a></li>
<li><a href="#type-system-is-too-rigid">Type system is too rigid</a></li>
<li><a href="#upstream-development-frustrating-priorities">Upstream development: frustrating priorities</a></li>
</ul>

<p>This is part one in a series about Terraform. Part two, detailing some Terraform practices that we found effective, will be up shortly.</p>

<h2 id="refactoring-is-difficult">Refactoring is difficult</h2>

<p>Terraform code is unwieldy to refactor. Even giving a resource a new <em>internal</em> name is a hassle. Here’s our simple Terraform definition:</p>

<pre><code>resource "aws_s3_bucket" "bucket" {
  bucket = "images.bigco.com"
}
</code></pre>

<p>Now it’s a month later, and we’re adding our second bucket, so let’s change our Terraform code to use a more specific name:</p>

<pre><code>resource "aws_s3_bucket" "images_bucket" {
  bucket = "images.bigco.com"
}
</code></pre>

<p>If we naively try to make this innocuous-looking change, Terraform will want to delete and recreate the bucket. We probably all understand why that’s the case, and it helps us appreciate how wonderful the concept of <code>terraform plan</code> is, but it’s ludicrous to have no serious facility for doing this smoothly. <code>terraform state mv</code> exists, but you need to run that separately, outside the plan/apply lifecycle. If you need to do this for ten environments, it’s a lot of work.</p>

<p>And that’s the easy case. Moving across module boundaries is harder, especially if you want to move the resources from the module into the root of the state (spoiler: <code>state mv</code> can’t do it). Moving across state boundaries is harder still. While the <a href="https://www.terraform.io/docs/commands/state/mv.html">documentation</a> mentions moving to a different state file, there’s no support for hooking it up to an already-existing state in S3 (for example). The tool is not at all user friendly or convenient.</p>

<p>The silver lining is that Terraform state is a simple JSON file, so it’s easy to write your own tooling around it. My team had occasion to do several refactors where we pulled individual projects’ resources out of a monolithic state and into their own states, once for each of our environments. Trying to orchestrate that with <code>state mv</code> would have been an awkward mess, but writing a simple Python script to pull state from S3, modify it, and push it back, was not too bad (if you do this, you’ll also want to remove the state checksum from DynamoDB).</p>

<p>You’re never going to nail the module and state boundaries correctly on your first pass (or ever?). Refactoring is inescapable. It needs to be more convenient. It would be great if there was some way to signal to Terraform “hey, this resource used to have a different address”. Something like this seems reasonable:</p>

<pre><code>resource "aws_s3_bucket" "images_bucket" {
  bucket = "images.bigco.com"

  lifecycle {
    old_addresses = [
      "aws_s3_bucket.bucket",
      "module.images_bucket.aws_s3_bucket.bucket",
    ]
  }
}
</code></pre>

<h2 id="code-reuse-is-limited">Code reuse is limited</h2>

<p>Terraform’s main tool for code reuse (i.e. a chunk of resource definitions that can be reused with different inputs) is the <code>module</code> (symlinks may also be useful in some situations, but I haven’t used them for this). Modules are limited in some ways.</p>

<h4 id="it-s-awkward-to-pin-module-versions">It’s awkward to pin module versions</h4>

<p>You <a href="https://github.com/hashicorp/terraform/issues/1439">can’t do interpolation in a module’s <code>source</code> parameter</a>. So if a dozen modules should all be pointing at the same revision of your <a href="https://blog.gruntwork.io/how-to-create-reusable-infrastructure-with-terraform-modules-25526d65f73d">modules git repository</a>, there’s no clean way to update all those references in one place. My team had a Makefile target, which we ran manually, that used <code>find</code> and <code>sed</code> to update all the references.</p>

<p>Leaving the module source unpinned is not an option I’d be comfortable with because it’s a vector for un-source-controlled drift that can be easily avoided.</p>

<h4 id="can-t-partially-apply-modules">Can’t partially apply modules</h4>

<p>The biggest problem we’ve faced with the module system is the inability to do <a href="https://en.wikipedia.org/wiki/Partial_application">partial application</a> (in the computer science sense). In essence, it would be nice to simplify a module’s interface by binding a bunch of common parameters. Here’s an example:</p>

<pre><code>module "service_a" {
  source = "..."

  name = "service_a"

  environment_variables = merge(
    local.environment_variable_defaults,
    {
      THING = "1",
    },
  )

  vpc_id     = local.vpc_id
  subnet_ids = local.subnet_ids
  ...
}

module "service_b" {
  source = "..."

  name = "service_b"

  environment_variables = merge(
    local.environment_variable_defaults,
    {
      THING = "2",
    },
  )

  vpc_id     = local.vpc_id
  subnet_ids = local.subnet_ids
  ...
}
</code></pre>

<p>These services have, say, fifteen parameters being passed in, and they only differ in one or two. There should be some more expressive way of writing them so that only those two unique values are prominent. Instead, you’re stuck copy/pasting a bunch of boilerplate, and editing in the unique values. That’s error-prone and a maintenance burden.</p>

<p>There’s an <a href="https://www.terraform.io/docs/configuration/locals.html">analogy</a> between Terraform definitions and a conventional programming language: a set of Terraform definitions (a module) is like a function, with TF variables being inputs to the function, TF locals being local variables, and TF outputs being return values. The extension of that analogy to this use case is partial application, where you give a module some of its inputs, it binds those values and you get back a module with only the rest of the inputs. Terraform doesn’t support it.</p>

<p>Ideally, we’d be able to define some sort of a “submodule” like this:</p>

<pre><code>submodule "service" {
  source = "..."

  environment_variables = merge(
    local.environment_variable_defaults,
    ?
  )

  vpc_id     = local.vpc_id
  subnet_ids = local.subnet_ids
}

module "service_a" {
  source = submodule.service

  name = "service_a"

  environment_variable_overrides = {
    THING = "1",
  }
}
</code></pre>

<p>We can’t use a proper module for this, because it doesn’t have access to its parent’s locals (which seems right). Notice the unsolved problem here of how to refer to those environment variable overrides in the submodule. This isn’t a fully-formed proposal.</p>

<p>Here are some ways we’ve dealt with this.</p>

<h5 id="code-reuse-workaround-1-big-map-of-config">Code reuse workaround 1: big map of config</h5>

<p>You can pass a big map of config as input to the module, rather than individual variables. That map can be defined as a local, and can include all the common values. Each service can merge on top of it to provide its overrides.</p>

<p>It’s a hack, but it works to reduce boilerplate. There are a couple of serious drawbacks, though:</p>

<ul>
<li><p>Terraform’s <code>merge()</code> only performs a shallow merge. This is surprising behavior, and can lead to subtle bugs. You can work around it if you know about it, but the workarounds are often awkward. There’s an <a href="https://github.com/hashicorp/terraform/pull/25032">open PR</a> adding a <code>deepmerge()</code> function.</p></li>

<li><p>When anything in the map is “not known until after apply” (e.g. an attribute of a resource that hasn’t been created yet), the entire map is considered “not known until after apply”. For example, if our config map looks like</p>

<pre><code>config = {
  vpc_id = aws_vpc.vpc.id,
  thing_enabled = true,
}
</code></pre>

<p>and the module does something like</p>

<pre><code>resource ... {
  count = var.config.thing_enabled ? 1 : 0

  ...
}
</code></pre></li>
</ul>

<p>then this will fail to plan if the VPC doesn’t already exist because <code>var.config</code> contains something (the VPC id) which isn’t known yet, and so <code>var.config.thing_enabled</code> is not known until after apply. This is subtle and unexpected, and the error messages you’ll see from it are cryptic. But it’s very easy to do by accident once some resources are created already. Then the next time you try to bootstrap a new state (e.g. a new environment), you’ll find that it won’t plan successfully.</p>

<h5 id="code-reuse-workaround-2-generate-terraform-definitions-from-templates">Code reuse workaround 2: generate Terraform definitions from templates</h5>

<p>In some instances, it can make sense to generate Terraform code from templates. On my team, there were a few places that we did this, and we checked those generated files in to git as regular <code>*.tf</code> files (their names started with <code>generated.</code> to make it obvious). This can work well, but adds some process overhead (pre-processing, knowing which files to not edit, CI validation that the files haven’t been edited).</p>

<p>There are also some TF preprocessors, like <a href="https://pypi.org/project/terraformpy/">terraformpy</a>, but I haven’t tried any.</p>

<h2 id="type-system-is-too-rigid">Type system is too rigid</h2>

<p>In Terraform before 0.12, everything was a string, and that was ugly (<code>count = "${var.enabled ? 1 : 0}"</code>). Terraform 0.12 added proper booleans, numbers, even some data structures like sets and maps. That was an improvement. However:</p>

<ul>
<li><p>When defining a module’s contract (i.e. specifying the types for its input variables), it’s not currently practical to use <code>map</code> or <code>object</code>.</p>

<p>The <code>map</code> type requires all values in the map to have the same type, which can be useful in a some cases (environment variable values are always strings), but not very often, in my experience.</p>

<p>The <code>object</code> type is a map without that restriction on value types, but if you’re going to say a variable’s type is <code>object</code>, you need to specify all the names of the keys and the types of their values. Okay… that doesn’t sound so bad. And <a href="https://github.com/hashicorp/terraform/issues/19898">all of the keys are mandatory</a>. What!? This makes <code>object</code> useless as a variable type, where you’ll often want to just pass in one value as an override and leave some set of defaults.</p>

<p>If you put these types on your variables, you’ll fail to plan in all sorts of surprising ways. You’ll try to pass <code>alarm_config = { enabled = true, threshold_seconds = 30 }</code> to your <code>map</code> variable and fail to plan because the value types aren’t uniform. So you’ll change it to an object, then realize that you can’t omit the <code>period_seconds</code> parameter which was supposed to optionally merge on top of a default. It’s an uphill battle. These types, in this context, are so rigid that they cause a lot of …</p></li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jonathan.bergknoff.com/journal/terraform-pain-points/">https://jonathan.bergknoff.com/journal/terraform-pain-points/</a></em></p>]]>
            </description>
            <link>https://jonathan.bergknoff.com/journal/terraform-pain-points/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23828089</guid>
            <pubDate>Tue, 14 Jul 2020 03:12:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Z80 Explorer – Visual Zilog Z-80 netlist-level simulator]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23827755">thread link</a>) | @userbinator
<br/>
July 13, 2020 | https://baltazarstudios.com/z80explorer/ | <a href="https://web.archive.org/web/*/https://baltazarstudios.com/z80explorer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<p><em>Z80 Explorer</em> is a Zilog Z80 netlist-level simulator capable of running Z80 machine code and also an educational tool with features that help reverse engineer and understand this chip better.</p>
<p>Z80 Explorer is a tool I wished I had a few years ago when I first started looking at the photos of Z80 chip die and was learning to reverse-engineer its <a aria-label="undefined (opens in a new tab)" href="https://baltazarstudios.com/anatomy-z80-gate/" target="_blank" rel="noreferrer noopener">features</a>. The process was slow and painful as it involved deciphering the faint image traces into logic gates and functions.</p>
<p>Sometimes later, I’ve found that the Visual6502 team have done a wonderful work with mapping the cpu’s traces into bitmaps representing various layers. Their online viewing <a href="http://www.visual6502.org/JSSim/expert-z80.html" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">tool </a>is impressive and one can learn a lot from using it, but as most online tools, it has limitations which I quickly hit when trying to understand the chip behavior in more depth.&nbsp;</p>
<p>As I kept playing with the online tool, my wish list of additional features steadily grew. I would have wanted it not only to be a fully functional and a fast simulator but also to provide more elaborate ways to gain deeper insights into the chip's internal behavior, while also being educational, easy, and intuitive to use.</p>
<p>Fast forward to today, and with the help of repeated COVID-19 stay-at-home orders, I have written this tool to be the way I imagined it.</p>
<figure><a href="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-app.png" target="_blank" rel="noopener noreferrer"><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-app.png" alt=""></a><figcaption>Z80 Explorer (click to enlarge)</figcaption></figure>
<p>In this blog, I will give an overview of <em>Z80 Explorer</em>'s capabilities and show a couple of useful features which might be easy to miss even after reading the documentation. This blog may change periodically along with the tool itself as I am actively developing it at the moment (Summer 2020).</p>
<p>The tool's user’s guide is a separate online document located here <a aria-label="undefined (opens in a new tab)" href="https://baltazarstudios.com/Z80ExplorerGuide/" target="_blank" rel="noreferrer noopener">https://baltazarstudios.com/Z80ExplorerGuide</a> It is very concise; if something is still unclear, please email me and I will correct it.</p>
<p>The tool is written to load and use the Z80 dataset (layer images and netlist). It should be able to accommodate other NMOS chips with minimal changes. However, at this time I haven't done any other ports yet as I was solely focused on Z80. The chip's data (resources) are kept separate from the application and can be independently downloaded and updated from a shared <a aria-label="undefined (opens in a new tab)" href="https://github.com/gdevic/Z80Explorer_Z80" target="_blank" rel="noreferrer noopener">github repo</a>. In particular, as the functions of various nets is understood and nets and buses get named, the list of the net names, tips and annotations can grow and be shared.</p>
<p><em>Z80 Explorer</em> is capable of running native Z80 code at the netlist level. That means, as the instruction opcodes are fed to its pins, the binary 1s and 0s propagate through its internal nets of transistor gates and perform the function identical to what the silicon gates would do on a real chip.</p>
<p>The engine that runs it is quite fast: On my 4GHz i7-4790K CPU, I am able to run Z80 code at around 2.3kHz which is (only!) around 2000 times slower from the speed it would have run on the real silicon. At those “speeds”, it is not inconceivable to run some of the standard CPU diagnostic programs - so I did just that: I run a well known ZEXALL diagnostic program.&nbsp;</p>
<p>This program normally takes hours even on a real Z80. </p>
<p>After a few days of running within the simulator, the list of passing tests kept growing. At one point, after a week or so, the simulator’s internal cycle counter overflowed its 32-bit variable and the simulation stopped. I simply had to resume it, with no need to reset it and with no loss to the accumulated progress.</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-zexall.png" alt=""><figcaption>Z80 Explorer running ZEXALL diagnostic</figcaption></figure></div>
<p>I have added this version of ZEXALL to the app resources. It is modified from the original in that I had sorted the tests by how long they run: with the quickest going first, it does not take too long before you start seeing some results, assuring you that it is indeed running well.</p>
<p><em>Z80 Explorer</em> shows various versions of chip images. Some of them are unmodified resource files shown as layers (diffusion, metal layer etc.), and some are created as combinations of those: vss.vcc.nets.col is a layer with the nets colored such that ground is shown as green, vcc red, and the rest of the nets are colored according to user filters (press F6 to define those filters).</p>
<p>You can view different layers and create combinations of them if you hold down the Ctrl key while clicking on layer buttons, or press a key assigned to each layer while holding down the Ctrl key.</p>
<p>The Z80 chip/layer view can be annotated. The application loads a default annotation file (containing those annotations) when it starts, but you can load any other annotation file by dragging that file and dropping it into the application image view. For example, “annot_internals.json” (located in the resource folder) contains a different set of annotations focused more on the internal features. Annotations are adaptive so that they will show and hide as you zoom in and out. They also can contain current net and bus values which are updated as the simulation modifies them.</p>
<p>Let us examine a few Z80 control / logic signals.</p>
<p>In my older article <a aria-label="undefined (opens in a new tab)" href="https://baltazarstudios.com/z80-instruction-register-deciphered/" target="_blank" rel="noreferrer noopener">here</a> I looked at the Instruction Register. The signal that enables loading it is a complementary WE (Write Enable) pair of control traces.</p>
<p>Can we find exactly at what time(s) the write enable, now called, "load_ir", is asserted? What is the internal logic equation that governs this control signal?</p>
<p>Using the <em>Z80 Explorer</em>'s "Find" option to search for "load_ir" signal name, and then asking for the schematic of that net, brings up this view:</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir1.png" alt=""><figcaption>Schematic view for "load_ir" net</figcaption></figure></div>
<p>Hence, the signal is generated by OR'ing net 255 with a latch. Let's follow net 255 which is a NAND gate of clock (hence, a clock gating) with the net 1329. Selecting (double-clicking on) 1329 and asking for the schematic brings us even closer to what we expected to see:</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-1329.png" alt=""><figcaption>Schematic view for net 1329</figcaption></figure></div>
<p>Therefore, the net 1329 is a clock-gated, NAND-combined signal, active when M3, T3 and PLA22 are active. PLA22 represents "IX/IY+CB" instruction extension decode. (The description of PLA22 is held in the application "tips" file as are descriptions of all other PLA entries and some other important nets).</p>
<p>Back to the latch 244 - and this part may not too obvious unless you have some experience looking at the chip traces - the net 244 is at the bottom and the latch set and reset signals are at the top, both clock-gated:</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-244.png" alt=""><figcaption>Latch at the net 244</figcaption></figure></div>
<p>Asking for the schematic of the net 1306 (the one connected from the top-left), which also acts as the latch reset:</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-1306.png" alt=""><figcaption>Latch 244 reset</figcaption></figure></div>
<p>we see that the latch will reset on the "internal reset" or a T3 cycle. The latch will be set on an M1 and T2 cycle edge (so it will show at M1/T3):</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-1307.png" alt=""><figcaption>Latch 244 set</figcaption></figure></div>
<p>We can verify what we've found by running a hand-crafted test code. I used a template test program "test_blank.asm" to code in a couple of instructions, one of them using IX register, and then I run it for a couple of cycles. In a Waveform view window the result shows how the load_ir signal is being asserted at every M1/T3 as well as at M3/T3, when the instruction is using the IX/IY prefix (PLA22 active).</p>
<div><figure><a href="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-wave.png" target="_blank" rel="noopener noreferrer"><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-wave.png" alt=""></a><figcaption>Waveform diagram showing "load_ir" signal (click to enlarge)</figcaption></figure></div>
<p>Next, let's look at some other features of <em>Z80 Explorer</em>.</p>
<p>Load the "annot_internals.json" file by dropping it onto on the application's image view (the main pane).</p>
<p>You can zoom into the area where are all M and T latches located by pasting this command into the Command Window:&nbsp;</p>
<p><code>img.setZoom(0.98); img.setPos(1151,901)</code></p>
<p>On the startup, the app will try to detect latches, and it will detect most of them automatically. For those not detected, you can add them as you find them. The easiest way to find latches is by using the “Driven by” option. After selecting a net and following its signal chain, if you see two nets being driven by each other in a co-dependent loop, you have found a latch that consists of those two nets (they also act as inverters). One of the app's initialization files, "latches.ini" contains definitions of additional latches. You can add to that file as you find latches that the app did not detect.</p>
<p>Schematic view uses an expanded version of such “Driven by” algorithm to build a tree of gates that contribute to the selected net.</p>
<p>Going the other way, the “Driving nets” option assists you to trace an input net as it branches into the network. For example, pick the /RESET input pad and iterate “Driving nets”, following the highlighted lines. Soon, you should reach a “dead end”, with the nets which apparently nothing is driving, here:</p>
<p><code>img.setZoom(2.926); img.setPos(338,606); img.show(294,548,80,101)</code></p>
<p>About these commands: In order to create these zoom and position commands yourself, set up a desired view and then type “img.state()” in the Command window. The required lines will be printed in the Application Log window.</p>
<p>To obtain the coordinates used in the img.show() command, right-click and select an area you wanted to highlight, and then simply read the coordinates from the Log window and paste them into img.show() as arguments.</p>
<p>The particular network mentioned above contains reset input flops and latches. One of the control signals coming out of it is “int_reset”, or internal reset:</p>
<p><code>img.find("int_reset")</code></p>
<p>This signal branches off to different parts of the chip.&nbsp;</p>
<p>Every chip normally has several signals that are propagated across its die to literally every corner. Some of those networks are power, ground, reset and the clocking network. (Newer chips implement various “gating” to parts of the design to limit the power consumption, but Z80 does not do such thing.)&nbsp;</p>
<p>I have already mention the Waveform view. This view should be familiar to anyone who has worked with simulation tools like ModelSim; but even for the rest, it should still be very simple and intuitive to use.</p>
<p>The important thing to remember is to “name” the net that you wish to observe, if it hasn't been named yet, before you can add it to the waveform view. Double click on the net and select “Edit net name...”. You can type any name; a simple "n123" (where 123 was its net number) would suffice, especially if that is only a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://baltazarstudios.com/z80explorer/">https://baltazarstudios.com/z80explorer/</a></em></p>]]>
            </description>
            <link>https://baltazarstudios.com/z80explorer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23827755</guid>
            <pubDate>Tue, 14 Jul 2020 02:01:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Strange public IPv4 address assigned behind NAT (2019)]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 86 (<a href="https://news.ycombinator.com/item?id=23827521">thread link</a>) | @rohan1024
<br/>
July 13, 2020 | https://broadbandforum.co/t/190267/ | <a href="https://web.archive.org/web/*/https://broadbandforum.co/t/190267/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://broadbandforum.co/t/190267/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23827521</guid>
            <pubDate>Tue, 14 Jul 2020 01:12:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jonathan Blow: Video Games and the Future of Education]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23827489">thread link</a>) | @doppp
<br/>
July 13, 2020 | https://www.twitch.tv/videos/678729516 | <a href="https://web.archive.org/web/*/https://www.twitch.tv/videos/678729516">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.twitch.tv/videos/678729516</link>
            <guid isPermaLink="false">hacker-news-small-sites-23827489</guid>
            <pubDate>Tue, 14 Jul 2020 01:07:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacking with environment variables]]>
            </title>
            <description>
<![CDATA[
Score 221 | Comments 63 (<a href="https://news.ycombinator.com/item?id=23827486">thread link</a>) | @pentestercrab
<br/>
July 13, 2020 | https://www.elttam.com/blog/env/ | <a href="https://web.archive.org/web/*/https://www.elttam.com/blog/env/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        

<p>On a recent project we gained the ability to specify environment variables but not the process that was executed.
We were also unable to control the contents of a file on disk, and bruteforcing process identifiers (PIDs) and file descriptors found no interesting results, eliminating <a href="https://www.elttam.com/blog/goahead/">remote LD_PRELOAD exploitation</a>.
Fortunately, a scripting language interpreter was executed which enabled us to execute arbitrary commands by specifying particular environment variables.
This blog post discusses how arbitrary commands can be executed by a range of scripting language interpreters when supplied with malicious environment variables.</p>



<p>A quick read of the <code>ENVIRONMENT</code> section of the <code>perlrun(1)</code> man page reveals plenty of environment variables worth investigating.
The <code>PERL5OPT</code> environment variable allows specifying command-line options, but is restricted to only accepting the options <code>CDIMTUWdmtw</code>.
This unfortunately means that <code>-e</code>, which allows supplying perl code to run, is out.</p>

<p>All is not lost though, as demonstrated in the <a href="https://github.com/HackerFantastic/exploits/blob/master/cve-2016-1531.sh">exploit</a> for CVE-2016-1531 by <a href="https://twitter.com/hackerfantastic">Hacker Fantastic</a>.
The exploit writes a malicious perl module to <code>/tmp/root.pm</code> and supplies the environment variables <code>PERL5OPT=-Mroot</code> and <code>PERL5LIB=/tmp</code> to achieve arbitrary code execution.
However this was an exploit for a local privilege escalation vulnerability and a generic technique should ideally not require access to the file system. Looking at <a href="https://twitter.com/bl4sty">blasty</a>’s <a href="https://haxx.in/blasty-vs-exim.sh">exploit</a> for the same CVE, the exploit did not require creating a file and used the environment variables <code>PERL5OPT=-d</code> and <code>PERL5DB=system("sh");exit;</code>.
The same environment variables were also used to <a href="https://old.reddit.com/r/netsec/comments/1dm8fv/hack_this_website_and_win_bitcoins_the_first/c9tm6j4/">solve a CTF challenge</a> in 2013.</p>

<p>One final nicety of a generic technique would be to use a single environment variable instead of two.
<a href="https://twitter.com/justinsteven">@justinsteven</a> found this was possible by leveraging <code>PERL5OPT=-M</code>.
While either <code>-m</code> or <code>-M</code> can be used to load a perl module, the <code>-M</code> option allows adding extra code after the module name.</p>

<h2 id="proof-of-concept">Proof of Concept</h2>

<figure>
  <figcaption>Figure-0: arbitrary code execution achieved using an environment variable against perl running an empty script (/dev/null)</figcaption>

<figure><pre><code data-lang="console"><span>$</span><span> </span>docker run <span>--env</span> <span>'PERL5OPT=-Mbase;print(`id`)'</span> perl:5.30.2 perl /dev/null
<span>uid=0(root) gid=0(root) groups=0(root)</span></code></pre></figure>

</figure>



<p>Reading the <code>ENVIRONMENT VARIABLES</code> section of the <code>python(1)</code> man page, <code>PYTHONSTARTUP</code> initially appears like it may be a piece of a straightforward solution.
It allows specifying a path to a Python script that will be executed prior to displaying the prompt in interactive mode.
The interactive mode requirement didn’t seem like it would be an issue as the <code>PYTHONINSPECT</code> environment variable can be used to enter interactive mode, the same as specifying <code>-i</code> on the command line.
However, the documentation for the <code>-i</code> option explains that <code>PYTHONSTARTUP</code> will not be used when python is started with a script to execute.
This means that <code>PYTHONSTARTUP</code> and <code>PYTHONINSPECT</code> cannot be combined and <code>PYTHONSTARTUP</code> only has an effect when the python REPL is immediately launched.
This ultimately means that <code>PYTHONSTARTUP</code> is not viable as it has no effect when executing a regular Python script.</p>

<p>Other environment variables which looked promising were <code>PYTHONHOME</code> and <code>PYTHONPATH</code>. Both of these will let you gain arbitrary code execution but require you to also be able to create directories and files on the filesystem. It may be possible to loosen those requirements through the use of the proc filesystem and/or ZIP files.</p>

<p>The majority of the remaining environment variables are simply checked if they contain a non-empty string, and if so, toggle a generally benign setting. One of the rare exceptions to this is <code>PYTHONWARNINGS</code>.</p>

<h2 id="making-progress-with-pythonwarnings">Making progress with PYTHONWARNINGS</h2>
<p>The documentation for <code>PYTHONWARNINGS</code> states <code>it is equivalent to specifying the -W option</code>. The <code>-W</code> option is used for warning control to specify which warnings and how often they are printed. The full form of argument is <code>action:message:category:module:line</code>. While warning control didn’t seem like a promising lead, that quickly changed after checking the implementation.</p>

<figure>
  <figcaption>Figure-1: Python-3.8.2/Lib/warnings.py</figcaption>

<figure><pre><code data-lang="python"><span>[...]</span>
<span>def</span> <span>_getcategory</span><span>(</span><span>category</span><span>):</span>
    <span>if</span> <span>not</span> <span>category</span><span>:</span>
        <span>return</span> <span>Warning</span>
    <span>if</span> <span>'.'</span> <span>not</span> <span>in</span> <span>category</span><span>:</span>
        <span>import</span> <span>builtins</span> <span>as</span> <span>m</span>
        <span>klass</span> <span>=</span> <span>category</span>
    <span>else</span><span>:</span>
        <span>module</span><span>,</span> <span>_</span><span>,</span> <span>klass</span> <span>=</span> <span>category</span><span>.</span><span>rpartition</span><span>(</span><span>'.'</span><span>)</span>
        <span>try</span><span>:</span>
            <span>m</span> <span>=</span> <span>__import__</span><span>(</span><span>module</span><span>,</span> <span>None</span><span>,</span> <span>None</span><span>,</span> <span>[</span><span>klass</span><span>])</span>
        <span>except</span> <span>ImportError</span><span>:</span>
            <span>raise</span> <span>_OptionError</span><span>(</span><span>"invalid module name: %r"</span> <span>%</span> <span>(</span><span>module</span><span>,))</span> <span>from</span> <span>None</span>
<span>[...]</span></code></pre></figure>

</figure>

<p>The above code shows that as long as our specified category contains a dot, we can trigger the import an arbitrary Python module.</p>

<p>The next problem is that the vast majority of modules from Python’s standard library run very little code when imported. They tend to just define classes to be used later, and even when they provide code to run, the code is typically <a href="https://docs.python.org/3/library/__main__.html">guarded with a check of the <code>__main__</code> variable</a> (to detect if the file has been imported or run directly).</p>

<p>An unexpected exception to this is the <a href="https://xkcd.com/353/">antigravity module</a>. The Python developers included an <a href="https://en.wikipedia.org/wiki/Easter_egg_(media)">easter egg</a> in <a href="https://github.com/python/cpython/commit/206e3074d34aeb5a4d0c1e24d970b6569f7ad702">2008</a> which can be triggered by running <code>import antigravity</code>. This import will immediately open your browser to the xkcd comic that joked that <code>import antigravity</code> in Python would grant you the ability to fly.</p>

<p>As for how the <code>antigravity</code> module opens your browser, it uses another module from the standard library called <code>webbrowser</code>. This module checks your PATH for a large variety of browsers, including mosaic, opera, skipstone, konqueror, chrome, chromium, firefox, links, elinks and lynx. It also accepts an environment variable <code>BROWSER</code> that lets you specify which process should be executed. It is not possible to supply arguments to the process in the environment variable and the xkcd comic URL is the one hard-coded argument for the command.</p>

<p>The ability to turn this into arbitrary code execution depends on what other executables are available on the system.</p>

<h2 id="leveraging-perl-for-arbitrary-code-execution">Leveraging Perl for Arbitrary Code Execution</h2>

<p>One approach is to leverage Perl which is commonly installed on systems and is even available in the standard Python docker image. However, the <code>perl</code> binary cannot itself be used. This is because the first and only argument is the xkcd comic URL. The comic URL argument will cause an error and the process to exit without the <code>PERL5OPT</code> environment variable being used.</p>

<figure>
  <figcaption>Figure-2: PERL5OPT having no effect when a URL is passed to perl</figcaption>

<figure><pre><code data-lang="console"><span>$</span><span> </span>docker run <span>-e</span> <span>'PERL5OPT=-Mbase;print(`id`);exit'</span> perl:5.30.2 perl https://xkcd.com/353/
<span>Can't open perl script "https://xkcd.com/353/": No such file or directory</span></code></pre></figure>

</figure>

<p>Fortunately, when Perl is available it also common to have the default Perl scripts available, such as perldoc and perlthanks. These scripts will also error and exit with an invalid argument, but the error in this case happens later than the processing of the <code>PERL5OPT</code> environment variable. This means you can leverage the Perl environment variable payload detailed earlier in this blog post.</p>

<figure>
  <figcaption>Figure-3: PERL5OPT working as intended with perldoc and perlthanks</figcaption>

<figure><pre><code data-lang="console"><span>$</span><span> </span>docker run <span>-e</span> <span>'PERL5OPT=-Mbase;print(`id`);exit'</span> perl:5.30.2 perldoc https://xkcd.com/353/
<span>uid=0(root) gid=0(root) groups=0(root)
</span><span>$</span><span> </span>run <span>-e</span> <span>'PERL5OPT=-Mbase;print(`id`);exit'</span> perl:5.30.2 perlthanks https://xkcd.com/353/
<span>uid=0(root) gid=0(root) groups=0(root)</span></code></pre></figure>

</figure>

<h2 id="proof-of-concept-1">Proof of Concept</h2>

<figure>
  <figcaption>Figure-4: arbitrary code execution achieved using multiple environment variables against Python 2 and Python 3</figcaption>

<figure><pre><code data-lang="console"><span>$</span><span> </span>docker run <span>-e</span> <span>'PYTHONWARNINGS=all:0:antigravity.x:0:0'</span> <span>-e</span> <span>'BROWSER=perlthanks'</span> <span>-e</span> <span>'PERL5OPT=-Mbase;print(`id`);exit;'</span> python:2.7.18 python /dev/null
<span>uid=0(root) gid=0(root) groups=0(root)
Invalid -W option ignored: unknown warning category: 'antigravity.x'

</span><span>$</span><span> </span>docker run <span>-e</span> <span>'PYTHONWARNINGS=all:0:antigravity.x:0:0'</span> <span>-e</span> <span>'BROWSER=perlthanks'</span> <span>-e</span> <span>'PERL5OPT=-Mbase;print(`id`);exit;'</span> python:3.8.2 python /dev/null
<span>uid=0(root) gid=0(root) groups=0(root)
Invalid -W option ignored: unknown warning category: 'antigravity.x'</span></code></pre></figure>

</figure>



<p>A <a href="https://research.securitum.com/prototype-pollution-rce-kibana-cve-2019-7609/">blog post</a> by <a href="https://twitter.com/securitymb">Michał Bentkowski</a> provided a payload for exploiting Kibana (CVE-2019-7609). A prototype pollution vulnerability was used to set arbitrary environment variables which resulted in arbitrary command execution. Michał’s payload used the <code>NODE_OPTIONS</code> environment variable and the <a href="https://en.wikipedia.org/wiki/Procfs">proc filesystem</a>, specifically <code>/proc/self/environ</code>.</p>

<p>Although Michał’s technique was creative and worked perfectly for their vulnerability, the technique is not always guaranteed to work and has some constraints that would be nice to remove.</p>

<p>The first constraint is that it using <code>/proc/self/environ</code> is only viable if the contents can be made to be syntactically valid JavaScript. This requires being able to create an environment variable and have it appear first in the contents of <code>/proc/self/environ</code>, or knowing/bruteforcing the environment variable’s name that will appear first and overwriting it’s value.</p>

<p>Another constraint, as the first environment variable’s value finishes with a single line comment (<code>//</code>). Therefore, any newline character in other environment variables will likely cause a syntax error and prevent the payload from executing. The use of multi-line comments (<code>/*</code>) will not fix this issue as they must be closed to be syntactically valid. Therefore, in the rare case that an environment variable contains a newline character, it is required to know/bruteforce the environment variable’s name and overwrite it’s value to a new value that does not contain a newline.</p>

<p>Removing these contraints is an exercise left for the reader.</p>

<h2 id="proof-of-concept-2">Proof of Concept</h2>

<figure>
  <figcaption>Figure-5: achieving arbitrary code execution with environment variables against NodeJS by Michał Bentkowski</figcaption>

<figure><pre><code data-lang="console"><span>$</span><span> </span>docker run <span>-e</span> <span>'NODE_VERSION=console.log(require("child_process").execSync("id").toString());//'</span> <span>-e</span> <span>'NODE_OPTIONS=--require /proc/self/environ'</span> node:14.2.0 node /dev/null
<span>uid=0(root) gid=0(root) groups=0(root)</span></code></pre></figure>

</figure>



<p>If you run <code>ltrace -e getenv php /dev/null</code> you will find PHP uses the <code>PHPRC</code> environment variable.
The environment variable is used …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.elttam.com/blog/env/">https://www.elttam.com/blog/env/</a></em></p>]]>
            </description>
            <link>https://www.elttam.com/blog/env/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23827486</guid>
            <pubDate>Tue, 14 Jul 2020 01:07:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is QuantGov?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23827427">thread link</a>) | @hhs
<br/>
July 13, 2020 | https://www.quantgov.org/about | <a href="https://web.archive.org/web/*/https://www.quantgov.org/about">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.quantgov.org/about</link>
            <guid isPermaLink="false">hacker-news-small-sites-23827427</guid>
            <pubDate>Tue, 14 Jul 2020 00:55:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alex: An Updatable Adaptive Learned Index [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23827257">thread link</a>) | @guodong
<br/>
July 13, 2020 | https://jiayuasu.github.io/files/paper/alex-sigmod2020.pdf | <a href="https://web.archive.org/web/*/https://jiayuasu.github.io/files/paper/alex-sigmod2020.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://jiayuasu.github.io/files/paper/alex-sigmod2020.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23827257</guid>
            <pubDate>Tue, 14 Jul 2020 00:24:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Beyond Analytics: The Evolution of Stream Processing Systems]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23827170">thread link</a>) | @guodong
<br/>
July 13, 2020 | https://streaming-research.github.io/Tutorial-SIGMOD-2020/ | <a href="https://web.archive.org/web/*/https://streaming-research.github.io/Tutorial-SIGMOD-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
      <section id="main_content">
        <h2 id="tutorial-information">Tutorial Information</h2>
<h3 id="wednesday-june-17-2020">Wednesday, June 17 2020</h3>
<h4 id="join-us-on-zoom-and-slack">Join us on <a href="https://acm-org.zoom.us/j/93450885761?pwd=OGZmekwyRFR2Q3ZTd3VwL3hsc0JlUT09">Zoom</a> and <a href="https://join.slack.com/t/sigmodpods/shared_invite/zt-em1btw2v-tTI9OXRtzi4apsMaCoqjTA">Slack</a></h4>

<h4 id="session-1-1030-am---1200-pm-pdt">Session 1: 10:30 AM - 12:00 PM PDT</h4>
<ul>
  <li>Part I: Introduction &amp; Fundamentals</li>
  <li>Part II: Time, Order, &amp; Progress</li>
  <li>Part III: State Management</li>
</ul>

<h4 id="session-2-130-pm---300-pm-pdt">Session 2: 1:30 PM - 3:00 PM PDT</h4>
<ul>
  <li>Part IV: Fault Recovery &amp; High Availability</li>
  <li>Part V: Load Management &amp; Elasticity</li>
  <li>Part VI: Prospects</li>
</ul>

<h2 id="overview">Overview</h2>
<p>Stream processing has been an active research field for more than 20 years, but it is now witnessing its prime time due to recent successful efforts by the research community and numerous worldwide open-source communities. The goal of this tutorial is threefold. First, we aim to review and highlight noteworthy past research findings, which were largely ignored until very recently. Second, we intend to underline the differences between early (’00-’10) and modern (’11-’18) streaming systems, and how those systems have evolved through the years. Most importantly, we wish to turn the attention of the database community to recent trends: streaming systems are no longer used only for classic stream processing workloads, namely window aggregates and joins. Instead, modern streaming systems are being increasingly used to deploy general event-driven applications in a scalable fashion, challenging the design decisions, architecture and intended use of existing stream processing systems.</p>

<h2 id="presenters">Presenters</h2>

<ul>
  <li><a href="https://www.ri.se/en/paris-carbone">Paris Carbone</a> (RISE)</li>
  <li><a href="http://mariosfragkoulis.gr/">Marios Fragkoulis</a> (Delft University of Technology)</li>
  <li><a href="https://cs-people.bu.edu/vkalavri/">Vasiliki Kalavri</a> (Boston University)</li>
  <li><a href="http://asterios.katsifodimos.com/">Asterios Katsifodimos</a> (Delft University of Technology)</li>
</ul>

<h2 id="slides-and-videos">Slides and Videos</h2>

<ol>
  <li>Introduction and fundamentals <a href="https://github.com/streaming-research/Tutorial-SIGMOD-2020/blob/master/slides/part1-introduction.pdf">[Slides]</a> <a href="https://youtu.be/6qmwLKzXdgM">[Video]</a></li>
  <li>Time, order, and progress <a href="https://github.com/streaming-research/Tutorial-SIGMOD-2020/blob/master/slides/part2-time.pdf">[Slides]</a> <a href="https://youtu.be/sWcMx52eP58">[Video]</a></li>
  <li>State management and guarantees <a href="https://github.com/streaming-research/Tutorial-SIGMOD-2020/blob/master/slides/part3-state-management.pdf">[Slides]</a> <a href="https://youtu.be/Zgy5a5tBOco">[Video]</a></li>
  <li>Advanced fault recovery and high availability <a href="https://github.com/streaming-research/Tutorial-SIGMOD-2020/blob/master/slides/part4-Fault-HA.pdf">[Slides]</a> <a href="https://youtu.be/p3zXV2w_MgM">[Video - Part I]</a> <a href="https://youtu.be/28CRUcFAGPs">[Video - Part II]</a></li>
  <li>Load management and elasticity <a href="https://github.com/streaming-research/Tutorial-SIGMOD-2020/blob/master/slides/part5-load-management.pdf">[Slides]</a> <a href="https://youtu.be/Pxe0M-mprOM">[Video]</a></li>
  <li>Prospects and discussion <a href="https://github.com/streaming-research/Tutorial-SIGMOD-2020/blob/master/slides/part6-prospects.pdf">[Slides]</a> <a href="https://youtu.be/DW9kU7gCL8A">[Video]</a></li>
</ol>

<h2 id="cite-pdf">Cite (<a href="https://dl.acm.org/doi/abs/10.1145/3318464.3383131">PDF</a>)</h2>

<div><div><pre><code>@inproceedings{10.1145/3318464.3383131,
author = {Carbone, Paris and Fragkoulis, Marios and Kalavri, Vasiliki and Katsifodimos, Asterios},
title = {Beyond Analytics: The Evolution of Stream Processing Systems},
year = {2020},
isbn = {9781450367356},
doi = {10.1145/3318464.3383131},
booktitle = {Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data},
pages = {2651–2658}
}
</code></pre></div></div>



      </section>
    </div></div>]]>
            </description>
            <link>https://streaming-research.github.io/Tutorial-SIGMOD-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23827170</guid>
            <pubDate>Tue, 14 Jul 2020 00:12:07 GMT</pubDate>
        </item>
    </channel>
</rss>
