<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 08 Jul 2020 08:17:12 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 08 Jul 2020 08:17:12 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[If you're a techno-optimist, you should read the Unabomber Manifesto]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23746087">thread link</a>) | @roelp_be
<br/>
July 6, 2020 | https://www.roelpeters.be/industrial-society-and-its-future-the-intelligent-yet-angry-writings-of-a-terrorist/ | <a href="https://web.archive.org/web/*/https://www.roelpeters.be/industrial-society-and-its-future-the-intelligent-yet-angry-writings-of-a-terrorist/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<h2>Preface to this blog post</h2>



<p>Why review a book from the hand of a notorious terrorist who killed three and maimed dozens of people? That seems like the right question to answer before continuing this blog post. <a href="https://en.wikipedia.org/wiki/Ted_Kaczynski">Theodore J. Kaczynski</a> is an extremely intelligent yet wounded man. He’s been a victim of cold-war era social experiments and, throughout his life, has always been an outsider. He retreated from society and lived like a hermit in the woods in Montana. Nevertheless, he was an activist in search of attention for his ideology and manifesto.</p>



<p>Numerous human lives have been sacrificed on the altars of freedom, ideology, and a better world. Wherever you position yourself on the political spectrum, from left to right, your heroes have blood on their hands. Reagan, Lenin, Bush, Mao, Napoleon, Robespierre, Obama, Chavez, Macron, Selassie, and Guevara, in one way or another, are responsible for the death and suffering of many. Yet we read their memoirs, manifestoes, and biographies. We have their posters on the walls of our children’s rooms. In this light, <strong>the refusal to read and review <em>Industrial Society and its Future</em> would be an act of hypocrisy. </strong></p>



<p>Finally, the central claim that technology is inherently bad for society is of relevance to this blog. I completely distance myself from the man’s actions, but his manifesto definitely struck a chord. I currently cannot think of a better way to scrutinize my techno-optimism than to write about it.</p>



<h2>The Power Process</h2>



<p><em>Industrial Society and its Future</em> is an essay of 232 numbered paragraphs in which Kaczynski explains what’s wrong with society, how it should be, and how we can get there. The most interesting parts of the essay describe the core concept of the <em>Power Process</em>, its consequences, and how technology has an impact on it.</p>



<p><strong>Human drives</strong> can be classified in three broad categories:</p>



<ul><li>Drives that can be satisfied with minimal effort: a walk around the block.</li><li>Drives that can be satisfied at the cost of serious effort: chopping down a tree for burning wood.</li><li>Drives that cannot be satisfied, no matter the effort one puts in it: somersault from a high cliff and survive it</li></ul>



<p>Kaczynski claims that <strong>all humans need a power process</strong>: (1) we all need goals, (2) effort to attain them, and (3) the attainment of some of these goals. Finally, it requires a degree of (4) autonomy. Consequently, the power process is part of the second category of human drives.</p>



<p>If unattained goals result in death, they are important. If the non-attainment of one’s goals is compatible with survival (i.e. not important), it will lead to defeatism, low self-esteem, and depression (as I explain later on). In the Western world, one only needs minimum effort to survive. Satisfying biological needs has been reduced to triviality. One can live off welfare checks, or have a bullshit job to satisfy physical needs. The only thing required is a minimal degree of obedience. Humans have given up autonomy and effort to attain the needs to survive — the important goals.  That’s why humans artificially create the four components of the power process for themselves: they are involved in <strong>surrogate activities</strong>: long-distance running, blogging, collecting stamps, gardening and even pursuing an academic career. </p>



<h2>Technology messes with the power process</h2>



<p>Kaczynski distinguishes between <strong>two kinds of technology</strong>: The first one is <strong>small-scale technology</strong>, like a mill or a water wheel. The second kind is <strong>organization-dependent technology</strong> that requires large-scale social organization: A refrigerator depends on complicated and industrially created parts and requires electricity. The first kind can produce real progress and freedom. The second kind has a negative impact on our freedom: the externalities outweigh the benefits. It’s <a href="https://en.wikipedia.org/wiki/Prisoner%27s_dilemma">the prisoner’s dilemma</a> on a global scale.</p>



<p>Since the Industrial Revolution, most new technologies are of the second kind. The wave of <em>smart</em> and <em>connected</em> devices and software that’s heading our way is no different. Algorithms can curate all available information on our timelines, only inviting more and more (fake?) articles to be produced. Autonomous cars are safer and offer the freedom to keep the hands of the wheel. Yet as self-driving cars are simply sensors on wheels, you will have zero privacy regarding your location. Self-service checkouts are supposed to be faster. Yet as supermarket customers more often use them, fewer registers with cashiers will be available, reducing human personal contact. Oh, and you need a loyalty card, which is digital-only, for which you need a smartphone.</p>



<p>Social and psychological problems arise when humans cannot go through the power process. <strong>In modern society, technology (especially of the second kind) tends to push drives into the first group</strong>: gathering food is now <a href="https://www.ubereats.com/">one tap away</a>.  Intimacy can be achieved by <a href="https://tinder.com/">swiping</a> or paying a <a href="https://www.pornhub.com/live">minimum fee</a>. Leisure can be found on <a href="https://www.netflix.com/be-en/">Netflix</a> or <a href="https://store.steampowered.com/">Steam</a>. Turn up the heat by asking your <a href="https://store.google.com/us/magazine/compare_thermostats">Nest</a>. </p>



<p>On the other hand,<strong> technology also moved other drives into the third category</strong>. With urbanization reaching record numbers; experiencing authenticity, harmony, nature, silence, and clean air is nearly impossible for many inhabitants of this planet.</p>



<p><strong>Some important goals that remain in the second category, like achieving status, can no longer be done autonomously</strong>. To reach the highest echelons of the corporate ladder, one needs to adhere to company culture, engage in networking, and pass opaque assessments. A management position is often at the goodwill of another manager, higher up.</p>



<p>The primitive man only had to fear disease and certain aspects of the environment. He could accept this stoically, or invent gods and demons. But these problems weren’t man-made, imposed on them by someone’s decision which he had no impact on. Although many of us create them for themselves, for others,<strong> surrogate activities do not suffice. The results are aggression, mental breakdowns, burnouts, depressions, mid-life crises, and declining fertility.</strong> As decisions are increasingly outsourced to <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing"><em>trustworthy </em>and <em>unbiased</em> machines</a> — think<a href="https://www.nytimes.com/2020/01/12/technology/facial-recognition-police.html"> facial recognition by police departments</a>, or <a href="https://www.technologyreview.com/2019/01/21/137783/algorithms-criminal-justice-ai/">algorithms sending people to jail</a> — hopelessness and rebellion will only increase.</p>



<p>In modern society, mental health is defined by how one behaves in accord with the needs of the system.</p>



<h2>Technology is a rational response to problems</h2>



<p>A compromise between freedom and technology is impossible because technology is a more powerful social force than the aspiration for freedom. That’s because each new technology appears to be desirable<strong> and only threatens our freedom later on</strong>. Motorized transport allows us to travel a lot farther. Yet once the adoption of cars reaches a critical threshold, one is <em>expected</em> to own a car: Local shops and public services disappear and become centralized in malls and government buildings. The internet allowed us to communicate with each other faster than ever. As companies adopted the internet, one can no longer apply for a job without an internet connection. Technology changes society as to make itself indispensable.</p>



<p>The following words read like a prophecy: “<em>Generally speaking, <strong>technological control over human behavior will probably not be introduced with a totalitarian intention</strong> or even through a conscious desire to restrict human freedom. Each new step in the assertion of control over the humankind will be taken as a rational response to a problem that faces society…”</em></p>



<p>For example, society has given up privacy to battle COVID-19 with apps and track&amp;trace strategies. Facebook promised us freedom of speech and unlimited reach, but without the financial means, you’re <a href="https://blog.hootsuite.com/facebook-algorithm/">shouting in a vacuum</a>. The Patriot Act (and the <a href="https://www.aclu.org/issues/national-security/privacy-and-surveillance/surveillance-under-patriot-act">mass surveillance technology</a> that came with it) was designed to battle terrorism but introduced legal arbitrariness. These three examples were all <strong>rational responses to existing problems but produced unforeseen externalities</strong>.</p>



<p>As technology makes itself indispensable, machines will take care of more and more tasks and “<em>on those who are employed, ever-increasing demands will be placed: the will need more training, more and more ability, and will have to be ever more reliable, conforming and docile, because they will be more and more like cells of a giant organism.</em>“</p>



<p>Think of the swarm of Uber or Lyft drivers who took a short training on how to use the app and are now driving people around in servile silence. Their data feeds the algorithm, and the algorithm thinks for them. <strong>The only thing left is to abide by the system.</strong></p>



<h2>Revolution</h2>



<p>Which brings us to Kaczynski’s “solution”. This topic lacks the depth and cunning analogies that can be found in the earlier chapters. His recipes aren’t new: one can find elements of <a href="https://en.wikipedia.org/wiki/Mikhail_Bakunin">Bakunist</a>, <a href="https://en.wikipedia.org/wiki/Cultural_hegemony">Gramscist</a>, and <a href="https://en.wikipedia.org/wiki/Foco">Debrayist</a> thinking.</p>



<p>Because technology is the strongest social force, <strong>gradual change is impossible</strong>. The only way to break this circle, this slippery slope to servitude to the machine, is a revolution. While the system might collapse under its own internal difficulties, Kaczynski claims we should promote social stress and instability in industrial society. Humanity should return to nature to live in small groups and to be in control of life-and-death issues: food, clothing, shelter, and defense. This is true freedom: the power to control the circumstances of one’s own life. It’s not an ideology, it’s Nature with a big N:</p>



<p><em>“We have no illusions about the feasibility of creating a new, ideal form of society. Our goal is only to destroy the existing form of society.”</em></p>



<h2>Final thoughts</h2>



<p>Manifestos are always dull, so I didn’t expect this book to be an enjoyable read. But quite a lot of insights were so masterfully crafted, that I often had to allow my mind to wander off in a quest to find (counter-)examples and arguments to what I just read. If you’re into political theory, this will be a treat.</p>



<p>Nevertheless, the structure of the book and the order of the chapters seemed strange to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.roelpeters.be/industrial-society-and-its-future-the-intelligent-yet-angry-writings-of-a-terrorist/">https://www.roelpeters.be/industrial-society-and-its-future-the-intelligent-yet-angry-writings-of-a-terrorist/</a></em></p>]]>
            </description>
            <link>https://www.roelpeters.be/industrial-society-and-its-future-the-intelligent-yet-angry-writings-of-a-terrorist/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23746087</guid>
            <pubDate>Mon, 06 Jul 2020 09:26:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New Stockholm Rail Network Map]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23745992">thread link</a>) | @omelekhin
<br/>
July 6, 2020 | https://spartrafikkarta.se/en | <a href="https://web.archive.org/web/*/https://spartrafikkarta.se/en">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://spartrafikkarta.se/en</link>
            <guid isPermaLink="false">hacker-news-small-sites-23745992</guid>
            <pubDate>Mon, 06 Jul 2020 09:06:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: 0 Password, never losing your password manager password]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23745988">thread link</a>) | @AutumnWu
<br/>
July 6, 2020 | https://www.bluespace.tech/blog/0password/ | <a href="https://web.archive.org/web/*/https://www.bluespace.tech/blog/0password/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        
        <p><img src="https://www.bluespace.tech/blog/0password/forgot-password.png"></p>
        <p>A few months ago, Scott Stein shared an article on CNet, <a href="https://www.cnet.com/news/password-managers-great-until-you-lose-access-world-password-day/">Password managers are great -- until you lose your password manager password</a>. Many people shared and retweeted the article. You know that feeling if you ever lost the password to your password manager.</p>
        <h2 id="why-do-password-managers-require-a-master-password">Why do password managers require a master password?</h2>
        <p>The earliest first generation password managers can manage passwords, by keeping them somewhere, but not protect them well.</p>
        <p>About 20 years ago, <a href="https://en.wikipedia.org/wiki/PBKDF2">PBKDF2</a> was recommended as a standard. It transforms a simple password into a complex key which can be used in cryptographic algorithms.</p>
        <p>Since then, lots of second and third generation password managers have been emerging. They derive encryption key from master password, then encrypt user data with the key. This is how it works:</p>
        <pre>            <code><p>graph TD

            subgraph 1. key derivation

            password --&gt; PBKDF2(PBKDF2)
            salt --&gt; PBKDF2
            PBKDF2 --&gt;|derive| key[[key]]

            end

            subgraph 2. encryption

            key --&gt; AES(AES)
            plaintext --&gt; AES
            AES --&gt; |encrypt| ciphertext[(ciphertext)]

            end

            style password fill:#fff, stroke: #aaa
            style ciphertext fill: #ddd, stroke: #aaa
            style salt fill:#fff
            style plaintext fill:#fff, stroke: #aaa
            </p></code>
        </pre>
        <blockquote>
        <p>In cryptography,</p>
        <ul>
        <li><code>plaintext</code> is unencrypted data intended to be encrypted;</li>
        <li><code>ciphertext</code> is the output of encryption of <code>plaintext</code>.</li>
        </ul>
        </blockquote>
        <p>To get the <code>plaintext</code> back, password managers derive the key just as above, but perform decrypt operation instead of encrypt operation in the second step.</p>
        <pre>            <code><p>graph TD

            subgraph 1. key derivation

            password --&gt; PBKDF2(PBKDF2)
            salt --&gt; PBKDF2
            PBKDF2 --&gt;|derive| key[[key]]

            end

            subgraph 2. decryption

            key --&gt; AES(AES)
            ciphertext[(ciphertext)] --&gt; AES
            AES --&gt; |decrypt| plaintext

            end

            style password fill:#fff, stroke: #aaa
            style salt fill:#fff
            style plaintext fill:#fff, stroke: #aaa
            style ciphertext fill:#ddd, stroke: #aaa
            </p></code>
        </pre>
        <p>I will not go deep for it in this article. If you are interested in the details, please checkout this series <a href="https://www.bluespace.tech/blog/evolution-of-password-manager/">The evolution of password manager</a>.</p>
        <p>Essentially, to encrypt user data, password managers must rely on some <strong>secret controlled by the user</strong>, so that hackers cannot get data from the ciphertext.</p>
        <h2 id="secret-in-security-chip">Secret in security chip</h2>
        <p><img src="https://www.bluespace.tech/blog/0password/security-chip.png" alt=""></p>
        <p><a href="https://developer.android.com/guide/topics/connectivity/nfc/hce#SecureElement">NFC card emulation with a secure element in Android.</a></p>
        <p>Nowadays, most smartphones, except some low-end ones, are equipped with a dedicated security chip(Trusted Execution Environment, Secure Element, or Secure Enclave in iOS). Emulated payment cards in iPhone and Android wallet apps are secured by this chip.</p>
        <p>Our fourth generation password manager, ID Guard Offline, can be safely used without a master password. The secret for encryption can be secured by the chip which is much more reliable than human brain. Again, if you are interested in how it works, please checkout <a href="https://www.bluespace.tech/blog/evolution-of-password-manager/fourth-generation-password-manager.html">The Evolution of Password Manager (4/4)</a>.</p>
        <h3 id="master-password">Master password</h3>
        <p>Scott Stein, the CNet staff, lost all his passwords because of forgetting master password. It is the nature of the algorithm above. In addition to using security chip protection, ID Guard Offline also offers master password protection (users can choose whether to use it). So our users may also encounter the same problem. We believe that availability is just as important as confidentiality to password managers and we need to resolve that problem.</p>
        <p>Some password manager providers allow user to reset master password, Google for example. If a user can reset master password and continue to view passwords stored previously, then those passwords are not secured by the master password.</p>
        <p>Our team of course do not compromise on security. The master password can never be reset. Then, is it possible to get the master password back when our user cannot recall it?</p>
        <h3 id="find-back-my-password">Find back my password</h3>
        <p>Some social services offer user account recovery with the help of trusted contacts when the user forgets the password. Here is how it works.</p>
        <ul>
        <li>The user is required to ask his/her trusted contacts to accomplish some tasks(e.g. sending a code).</li>
        <li>The service detects whether those trusted contacts complete the tasks.</li>
        <li>If so, the service lets the user login and asks he/she to reset password.</li>
        </ul>
        <p>Inspired by this, we have a simple idea: ask friends to help find password back. And finally, we perfected this design after several iterations.</p>
        <ol>
        <li>
            <p>Ask friends to save my password</p>
            
            <p>The first idea coming into our minds was just asking friends to save the password. When forgetting the password, ask a friend to tell me the password. It's like asking a friend to keep my house keys temporarily.</p>
            
            <p><img src="https://www.bluespace.tech/blog/0password/key.jpg" alt=""></p>
            
            <p>Obviously, this is not safe. Passwords are always meant to be kept secretly. Lots of users reuse their passwords, one leaked password can endanger a large number of accounts.</p>
            

        </li>
        <li>
            <p>Encrypt the password then send to friends</p>
            
            <p>Encryption is a good idea. The problem is how to choose/derive the encryption key. We cannot ask user to set another password to encrypt the password, right?</p>
            
            <img src="https://www.bluespace.tech/blog/0password/russian-doll.jpg" alt="">
            
            <p>Stay safe</p>
            
            <p>If the encryption does not depend on user's secret, the encryption key must be hardcoded. We will not make <a href="https://team-sik.org/sik-2016-022/">the same mistake like other password managers did years ago</a>.</p>
            
        </li>
        <li>
        <p>Encrypt the password with a key inside the security chip on smartphone, and send only the <code>ciphertext</code> to friends</p>
        <pre>            <code>
                <p>graph TD

                key[[key]] --&gt; AES(AES)
                password --&gt; AES
                AES --&gt;|encrypt| ciphertext[(password file)]

                key --&gt; phone[Secure Element]
                ciphertext --&gt; friend[saved by friend]

                style password fill:#fff, stroke: #aaa
                style ciphertext fill: #ddd, stroke: #aaa
                style phone fill: #b3d26a
                style friend fill: #acf
                </p></code>
            </pre>
            <p>In this proposal, a password file(<code>ciphertext</code>) is kept by each friend, but the <code>keys</code> are secured by the security chip on the phone.
            The password can be decrypted if a friend sends back the password file, when finding back the password.</p>
            <pre>                <code><p>graph TD

                subgraph 1. find back password

                masterPasswordKey[[key]] --&gt; masterPasswordAes(AES)
                masterPasswordCiphertext[(password file)] --&gt; masterPasswordAes
                masterPasswordAes --&gt;|decrypt| password

                end

                subgraph 2. key derivation

                password --&gt; PBKDF2(PBKDF2)
                salt --&gt; PBKDF2
                PBKDF2 --&gt;|derive| key[[key]]

                end

                subgraph 3. decryption

                key --&gt; AES(AES)
                ciphertext[(ciphertext)] --&gt; AES
                AES --&gt; |decrypt| plaintext

                end

                style masterPasswordCiphertext fill: #ddd, stroke: #aaa
                style password fill:#fff, stroke: #aaa
                style ciphertext fill: #ddd, stroke: #aaa
                style salt fill:#fff
                style plaintext fill:#fff, stroke: #aaa
                </p></code>
            </pre>
        <p>Friends are required to save the password file into ID Guard Offline, which is secured by the security chip on the phone. So hackers cannot steal the password file. This finding back master password mechanism does not weaken the security of the data stored in ID Guard Offline.</p>
        <ul>
        <li>If a hacker steals a user's phone and unlocks it(by screen PIN), he/she still needs to enter the master password.
        <ul>
        <li>If the hacker does not know the master password, he/she has to steal and unlock the phone of a friend, and crack ID Guard Offline app on that friend's phone, which is really hard.</li>
        </ul>
        </li>
        <li>If a hacker cracks and gets the password file from a friend, he/she cannot decrypt the ciphertext without the encryption key inside the security chip on the user's phone.</li>
        </ul>
        </li>
        </ol>
        <h3 id="how-to-setup-and-find-back-the-password">How to setup and find back the password?</h3>
        <p>So how to use it?</p>
        <ol>
        <li>
            <p>If you are using master password to unlock the app, go to the <code>Find back master password</code> setup view, enter your friend's name, and touch <code>Send</code> button.</p>
            
            <p><img src="https://www.bluespace.tech/blog/0password/send-password-file.png" alt=""></p>
            
        </li>
        <li>
            <p>Send the password file to your friend and ask him/her to save it in ID Guard Offline.</p>
            
            <p><img src="https://www.bluespace.tech/blog/0password/save-password-file.png" alt=""></p>
            
        </li>
        <li>
            <p>If you forget your master password, you can check out the list of friends who can help you.</p>
            
            <p><img src="https://www.bluespace.tech/blog/0password/friend-list.png" alt=""></p>
            
        </li>
        <li>
            <p>Ask a friend to send back the password file, open it with ID Guard Offline to unlock it. You need to change unlock method immediately.</p>
            
            <p><img src="https://www.bluespace.tech/blog/0password/unlock-successfully.png" alt=""></p>
            
        </li>
        </ol>
        <h3 id="comparison">Comparison</h3>
        <h4 id="recover-account-with-trusted-contacts">Recover account with trusted contacts</h4>
        <p>Trusted contacts must be very trustworthy when using the account recovery feature offered by social services. Otherwise, those "bad friends" can hack into my account by initializing the account recovery process and completing the tasks required by the service.</p>
        <p>We borrow the idea from social services, but in our design, friends can be somewhat dependable because they cannot decrypt my passwords without the key. Also, I can get my password back as long as one of my friends can give me the password file.</p>
        <h4 id="password-managers-can-reset-master-password">Password managers can reset master password</h4>
        <p>Both those …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.bluespace.tech/blog/0password/">https://www.bluespace.tech/blog/0password/</a></em></p>]]>
            </description>
            <link>https://www.bluespace.tech/blog/0password/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23745988</guid>
            <pubDate>Mon, 06 Jul 2020 09:06:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Critical flaw in OpenSSH Client allows targeted man-in-the-middle (MitM) attacks]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23745977">thread link</a>) | @darshansavla
<br/>
July 6, 2020 | https://androidrookies.com/critical-flaw-in-openssh-client-versions-5-7-to-8-3-allows-targeted-man-in-the-middle-mitm-attacks/ | <a href="https://web.archive.org/web/*/https://androidrookies.com/critical-flaw-in-openssh-client-versions-5-7-to-8-3-allows-targeted-man-in-the-middle-mitm-attacks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-8464"><div><div><div><h2>Researchers find critical flaw in OpenSSH Client versions 5.7 to 8.3 that allows targeted MitM attacks using information leakage in SSH Clients</h2><p>Security researchers from German security firm FZI have found a critical flaw in the OpenSSH Client version 5.7 to 8.3. The critical vulnerability in OpenSSH clients lies due to an information leak in the initial key exchange message of the SSH protocol.</p><p>OpenSSH Client is an SSH client is a program that allows users to establish a secure and authenticated SSH connections to SSH servers. The OpenSSH source code is available free to everyone via the Internet. The devs had released the OpenSSH Client version 8.3 on 27th May 2020. However, the security researchers from FZI say that even the newly released version is susceptible to MITM attack due to the flaw.</p><p>The OpenSSH Client flaw has <strong>Observable Discrepancy</strong> leading to an information leak in the algorithm negotiation. This allows man-in-the-middle attackers to target initial connection attempts (where no host key for the server has been cached by the client). The OpenSSH Client vulnerability has been issued the identifier – <a href="https://nvd.nist.gov/vuln/detail/CVE-2020-14145">CVE­-2020-­14145</a> and has a severity score of 4.7/10.</p><p>FZI says that any potential hacker can detect if an SSH client using the default configuration stores a host key for the target server. Once this is detected, the hacker can conduct a man-in-the-middle (MITM) attack on the clients that connect to a server for the first time and avoid clients that would show a warning because of a changed host key. Clients that connect to a server for the first time, ask the user to confirm the fingerprint of the host key. Users that compare the shown fingerprint by a known value are safe. However, many users rely on trust on first use and accept host keys without verification. These types of users are vulnerable to the MITM attack.</p><p>FZI states that they tested out their Proof of Concept in OpenSSH 8.2 and 8.3 portable and the tests showed that the host key algorithm list differs from the default list for all algorithm types that are not certificate-based, namely ECDSA, Ed25519, and RSA. This means that in the default configuration an attacker can identify users connecting to a server for the first time without false positives.</p><h2>Proof of Concept</h2><blockquote><p>$ ./ssh-detect.py -r OpenSSH-8.2-init.pcap<br> Client Key Exchange Init 192.168.102.1:33580 -&gt; 192.168.102.134:22</p><p>Host Key Algorithms:<br> <a href="https://androidrookies.com/cdn-cgi/l/email-protection" data-cfemail="9ffafcfbecfeb2ecf7feadb2f1f6ecebefadaaa9b2fcfaedebb2e9afaedff0effaf1ececf7b1fcf0f2">[email&nbsp;protected]</a><br> <a href="https://androidrookies.com/cdn-cgi/l/email-protection" data-cfemail="1277717661733f617a73203f7c7b616662212a263f717760663f642223527d62777c61617a3c717d7f">[email&nbsp;protected]</a><br> <a href="https://androidrookies.com/cdn-cgi/l/email-protection" data-cfemail="81e4e2e5f2e0acf2e9e0b3acefe8f2f5f1b4b3b0ace2e4f3f5acf7b1b0c1eef1e4eff2f2e9afe2eeec">[email&nbsp;protected]</a><br> <a href="https://androidrookies.com/cdn-cgi/l/email-protection" data-cfemail="acdfc781c9cfc8dfcd81dfc4cd9e81c2c5dfd8dc9e999a81cfc9ded881da9c9decc3dcc9c2dfdfc482cfc3c1">[email&nbsp;protected]</a><br> <a href="https://androidrookies.com/cdn-cgi/l/email-protection" data-cfemail="b0c3c3d89dd5d482858581899dd3d5c2c49dc68081f0dfc0d5dec3c3d89ed3dfdd">[email&nbsp;protected]</a><br> <a href="https://androidrookies.com/cdn-cgi/l/email-protection" data-cfemail="cab9a1e7b9b9a2e7afaef8fffffbf3e7a9afb8bee7bcfafb8aa5baafa4b9b9a2e4a9a5a7">[email&nbsp;protected]</a><br> <a href="https://androidrookies.com/cdn-cgi/l/email-protection" data-cfemail="d5a7a6b4f8a6bdb4e7f8e0e4e7f8b6b0a7a1f8a3e5e495baa5b0bba6a6bdfbb6bab8">[email&nbsp;protected]</a><br> <a href="https://androidrookies.com/cdn-cgi/l/email-protection" data-cfemail="235150420e504b42110e1116150e404651570e551312634c53464d50504b0d404c4e">[email&nbsp;protected]</a><br> <a href="https://androidrookies.com/cdn-cgi/l/email-protection" data-cfemail="97e4e4ffbae5e4f6baf4f2e5e3bae1a7a6d7f8e7f2f9e4e4ffb9f4f8fa">[email&nbsp;protected]</a><br> ecdsa-sha2-nistp256<br> ecdsa-sha2-nistp384<br> ecdsa-sha2-nistp521<br> <a href="https://androidrookies.com/cdn-cgi/l/email-protection" data-cfemail="d7a4bcfab2b4b3a4b6faa4bfb6e5fab9bea4a3a7e5e2e197b8a7b2b9a4a4bff9b4b8ba">[email&nbsp;protected]</a><br> ssh-ed25519<br> <a href="https://androidrookies.com/cdn-cgi/l/email-protection" data-cfemail="56253d7b25253e7b3332646363676f163926333825253e7835393b">[email&nbsp;protected]</a><br> rsa-sha2-512<br> rsa-sha2-256<br> ssh-rsa</p><p>Client Version: SSH-2.0-OpenSSH_8.2 (known)<br> Default algorithm list detected! Client doesn’t store host key.</p></blockquote><p>FZI states that they notified the OpenSSH Client devs about the vulnerability but they have taken no action. However, the GitHub page of OpenSSH Client shows that devs are working on version 8.4. But it is not known whether the new version will patch the <a href="https://nvd.nist.gov/vuln/detail/CVE-2020-14145">CVE­-2020-­14145</a> vulnerability.</p><h2>Mitigation of the OpenSSH Client vulnerability</h2><p>FZI says there are some configuration options in OpenSSH Client that can be used to mitigate the vulnerability. OpenSSH Client provides users alternative ways to validate host keys, namely SSHFP records and host certificates. These should be used if DNSSEC or a PKI are available.&nbsp; They can also enable UpdateHostKeys and set the option HostKeyAlgorithms after connecting to each server at least once.</p><p>You can download the FZI’s OpenSSH Client vulnerability report <a href="https://www.fzi.de/fileadmin/user_upload/2020-06-26-FSA-2020-2.pdf">here</a>(PDF).</p></div></div></div></article><div><h3>About Author</h3><section> <img alt="" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20100%20100'%3E%3C/svg%3E" data-src="https://secure.gravatar.com/avatar/076b4a64b03cee86288f1132004881ab?s=100&amp;d=mm&amp;r=g" data-srcset="https://secure.gravatar.com/avatar/076b4a64b03cee86288f1132004881ab?s=200&amp;d=mm&amp;r=g 2x" height="100" width="100" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><div> <p>Hacker, coder, Jouno by night
When a good man is hurt, all who would be called good must suffer with him</p></div></section></div></div>]]>
            </description>
            <link>https://androidrookies.com/critical-flaw-in-openssh-client-versions-5-7-to-8-3-allows-targeted-man-in-the-middle-mitm-attacks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23745977</guid>
            <pubDate>Mon, 06 Jul 2020 09:04:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Fatal Flaw of Ownership Semantics]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23745863">thread link</a>) | @signa11
<br/>
July 6, 2020 | https://www.gingerbill.org/article/2020/06/21/the-ownership-semantics-flaw/ | <a href="https://web.archive.org/web/*/https://www.gingerbill.org/article/2020/06/21/the-ownership-semantics-flaw/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article>
<header>
	
	
	<p>
		<span>2020-06-21</span>
		</p>
</header>
<p>I have been toying with a theoretical idea for the past 18 months off-and-on in my head and I have not fully articulated it aloud yet. It is regarding the concept of <em>Ownership Semantics</em> (OS) or <em>Move Semantics</em> in programming languages. Fundamentally this article is a criticism of the concept and states that the concept is a duality of traditional OOP but applied to a different area.</p>
<h2 id="general-definitions-of-terminology">General Definitions of Terminology</h2>
<p>A general list of definitions of terminology used within this article in order to minimize confusion.</p>
<ul>
<li>
<p>A <em>Value</em> is a datum with an associated type</p>
</li>
<li>
<p>A <em>(Data) Type</em> is an attribute of a value which encodes information about how the data value can be operated upon</p>
</li>
<li>
<p>An <em>Object</em> is a value with associated behaviour, and thus implies it has <em>agency</em></p>
</li>
<li>
<p>A <em>Class</em> is the data type of an <em>Object</em></p>
</li>
<li>
<p>A hierarchy of value ownership is a hierarchy of responsibility of values</p>
</li>
<li>
<p>An <em>Owned-Value</em> is a value which belongs to a hierarchy of value ownership, which implies it is governed by an <em>agent</em></p>
</li>
<li>
<p>An <em>Agent</em> is an actor with the capacity to act within a given environment</p>
</li>
<li>
<p>A <em>Model of Interpretation</em> is a way to view and analyse a subject</p>
</li>
<li>
<p>A <em>Paradigm</em> is a way of classifying models of structure of programming languages; a <em>Paradigm</em> is a <em>model of interpretation</em></p>
</li>
<li>
<p><em>Object Orient(at)ed Programming (OOP)</em> - A paradigm of structuring a program around the sole concept of <em>Objects</em>, commonly through coupling data and code into a single unit.</p>
</li>
<li>
<p><em>Ownership/Move Semantics (OS)</em> - Orientation around responsibility of values in a hierarchical fashion</p>
</li>
</ul>
<h2 id="foundations-of-the-object-orientation-paradigm">Foundations of the Object Orientation Paradigm</h2>
<p>Though the original conception of the term coined by Alan Kay<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> was never used as he intended it to be, the term <em>Object Orient(at)ed Programming (OOP)</em> has been commonly understood to be a paradigm of structuring a program around the concept of <em>Objects</em>, commonly through coupling data and code into a single unit. Many languages support multiple paradigms, including aspects for the OOP paradigm, but I would class those as multiparadigm rather than being <em>solely</em> an OOP language.</p>
<p>Most languages implement <em>Objects</em> and <em>Classes</em> in the Simula tradition; most of the notable OOP languages have a similar form by defining methods (member functions) within the class definition. Traditionally languages such as Java can be classed as <em>solely</em> an OOP language.</p>
<p>Most traditional OOP languages are based around the concept of <em>inheritance</em>, a mechanism of deriving a class data type from another class data type and retaining similar information. Most people generally view inheritance as a combination of <a href="https://en.wikipedia.org/wiki/Subtyping">subtyping</a> and <a href="https://en.wikipedia.org/wiki/Dynamic_dispatch">dynamic dispatch</a> through <a href="https://en.wikipedia.org/wiki/Virtual_method_table">virtual method tables (vtables)</a>. This has lead to many discussions asking whether a language can be called as OOP if it does not support inheritance<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.</p>
<p>In recent times, <em>inheritance</em> has been falling out of fashion in favour of <em>composition</em><sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>. This is mostly due to the issue of conforming a <em>class</em> to a strict (singular) hierarchy of agency when in reality, things can belong to many (if not infinite) categories and hierarchies, as well as another aspect which I will be discussing throughout this article.</p>
<p>There are many criticisms of OOP<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup><sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup><sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup><sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup><sup id="fnref:8"><a href="#fn:8" role="doc-noteref">8</a></sup><sup id="fnref:9"><a href="#fn:9" role="doc-noteref">9</a></sup> but my general criticism is that by placing emphasis on trying to solve problem in the type system, it shifts focus from the data structures and algorithms, <a href="https://www.gingerbill.org/article/2020/05/31/progamming-pragmatist-proverbs/#the-concept-of-programming">the core of what a program fundamentally is</a>.</p>
<p>Since objects themselves are being treated <em>as if</em> they have behaviour (not just type properties), they are effectively being treated as if they were <em>agents</em> in the program. This mental model has many conclusions, many of which cause issues.</p>
<p>In my article <a href="https://www.gingerbill.org/article/2020/05/31/progamming-pragmatist-proverbs/"><em>Pragmatism in Programming Proverbs</em></a>, I state:</p>
<blockquote>
<p>Object orientated programming is a form of misinterpreted and misapplied Aristotelian Metaphysics applied to a domain it was never meant to model</p>
</blockquote>
<p>What I mean by this statement is that <em>artificially</em> conforming any/all relationships between data and types to an artificial hierarchy of <em>agency</em> is a form of naïve-Aristotelian metaphysics. Since there is no actual <em>agency</em> in the programming objects, it is a partial fallacy. When trying to conform a program to have a particular structure when it does not naturally, the absence of a structure in a program is more useful than a bad structure.</p>
<h3 id="methods">Methods</h3>
<p>The concept of adding methods to classes/objects has proven useful to many. The real questions are:</p>
<ul>
<li>Why?</li>
<li>And how do people actually conceptualize methods on a day-to-day basis?</li>
</ul>
<p>For most people, I am going to bet that methods, in languages with an emphasis on inheritance rather than composition (such as C++ or Java), are treated as a way of categorizing and associating functions/procedures with a data record. There are a few reasons for this approach:</p>
<ul>
<li>Easy to organize and search for procedures by a data type</li>
<li>Allowing methods as a form of syntactic sugar for writing calls in a <em>subject verb object</em> manner e.g. <code>foo_do_thing(x, y)</code> vs <code>x.do_thing(y)</code></li>
<li>Mental model of behaviour for objects</li>
</ul>
<p>From experience, I have found that long time users of “OOP” languages eventually start treating methods primarily in the first two approaches.</p>
<p>I will not go into depth about the other main aspects of OOP such as encapsulation, local retention, forms of polymorphism, etc, as the hierarchical nature is the fundamental aspect of focus for this article. The (linear) hierarchy of agency is the main problem. The reason why people argue for <em>composition over inheritance</em> is that it flattens this linear hierarchy, reducing its effect. It is the transition from <a href="https://en.wikipedia.org/wiki/Nominal_type_system">nominal typing</a> to <a href="https://en.wikipedia.org/wiki/Structural_type_system">structural typing</a>, which is more flexible because many data structures and problems have a <em>non-linear</em> nature to them, which <em>linear</em> approaches <strong>cannot</strong> handle. When trying to adhere to the the strict hierarchical type system approaches, it leads to numerous issues because data is more commonly graph-like (non-linear) than tree-like (linear) for most problems. This strict hierarchy does occur with encapsulation at the object level too, a strict hierarchy of messages/references; this hierarchical nature arises from the concept agency itself, inheritance is not the root cause.</p>
<p><strong>n.b.</strong> Inheritance is not all bad and does have many real life practical uses, but these costs must be known before using them, like with any tool.</p>
<p><strong>n.b.</strong> The linearity is with regards to the data structures themselves and not the algorithms.</p>
<h2 id="foundations-of-the-ownership-semantics-paradigm">Foundations of the Ownership Semantics Paradigm</h2>
<p><a href="https://en.wikipedia.org/wiki/C%2B%2B">C++11</a> introduced the concept of <em>move semantics</em> or <em>ownership semantics</em> (OS), a way to minimize the copying of data through copy constructors. It utilizes the added concept of r-value references (<code>T &amp;&amp;</code>) as a means to do this. However, the concept began to be used for a lot more than its basic purpose. The concept adds the high level abstraction of “moving” objects rather than “copying” objects. Physically, a computer only ever copies and this high level abstraction, to treat objects <em>as if</em> they were “real objects”, is not what actually happens. It is also a <a href="https://en.wikipedia.org/wiki/Category_mistake">category error</a> to treat them as “real objects” since “real objects” and “programming objects” have little connection with each other ontologically. When a value or object is “moved”, this means is that the <em>responsibilities</em> of the resources of that object have been transferred to another object or environment—<em>agents</em>. In this case, ownership/move semantics is fundamentally based around the <em>responsibilities of values</em> by tracking value usage.</p>
<p>In this model of agency, the arena of agency can take on many forms, such as blocks, procedure bodies, or aggregate values. Therefore some <em>owned-values</em> also <em>own</em> other values, and thus a value could have agency.</p>
<p>If we were to call Ownership Semantics a paradigm, it would be the orientation around the <em>responsibility of values</em> in a hierarchical fashion, placing emphasis on this system of responsibility, shifting focus from data structures and algorithms.</p>
<p>The concept of <em>responsibility</em> and <em>ownership</em> is similar to the real world counter parts in that to own something means to have exclusive use and full responsibility over it.</p>
<p><a href="https://www.rust-lang.org/">Rust</a> is a multi-paradigm programming language but at its core is an Ownership-Orientated language. Everything in Rust has a concept of <em>“ownership”</em> and <em>lifetime</em> associated with it. Rust is designed around trying to be first and foremost “safe”, especially with regards to concurrency. Rust derives from the C++ family in terms of philosophy and style, but uses a more <a href="https://www.gingerbill.org/article/2018/03/12/on-the-aesthetics-of-the-syntax-of-declarations/">qualifier-focused</a> declaration syntax and many concepts from functional languages from the <a href="https://en.wikipedia.org/wiki/ML_%28programming_language%29">ML family</a>.</p>
<p><em>Lifetimes</em> are theoretically orthogonal to <em>ownership</em> but in practical, they usually are intrinsically coupled. I will not discuss the problems with object-based lifetimes in this article.</p>
<p>The following Rust code can be used to demonstrate this responsibility transfer between different capturing things such as <code>let</code> statements:</p>
<pre><code>pub struct Foo {
	value: i32,
}

fn main() {
	let foo = Foo{value: 123};
	let bar = foo; // the responsibility of `foo` is transferred to `bar`

	println!("{}", foo.value); // error: use of moved value: `foo.value`
	println!("{}", bar.value);
}

</code></pre>
<p>Rust is an immutable-by-default language, with the option to opt into mutability with <code>mut</code>. Immutability helps a lot with mathematical proofs for logic since things things can be “flattened” quite easily, however virtually all computers are fundamentally mutable things, even if the abstraction of immutability is a useful tool. As a result, the ownership semantics system requires a few more rules to take into account mutability, by adding the concept of “borrowing” through references. The general rules for the borrow checker are:</p>
<ul>
<li>Each value may have as many immutable borrows as you want</li>
<li>Each value may only have one mutable borrow at a time</li>
<li>Each value may not borrow immutably and mutably at the same time</li>
<li>Values will be “dropped” when the owning connecting goes out of scope</li>
<li>Taking a value by <code>self</code> <code>Drop</code>s the original value</li>
</ul>
<p>When using Rust (or move semantics to their full extent in C++11), most people will fight the borrow …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.gingerbill.org/article/2020/06/21/the-ownership-semantics-flaw/">https://www.gingerbill.org/article/2020/06/21/the-ownership-semantics-flaw/</a></em></p>]]>
            </description>
            <link>https://www.gingerbill.org/article/2020/06/21/the-ownership-semantics-flaw/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23745863</guid>
            <pubDate>Mon, 06 Jul 2020 08:39:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacker News Design Is Ugly]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 8 (<a href="https://news.ycombinator.com/item?id=23745595">thread link</a>) | @neilpanchal
<br/>
July 6, 2020 | https://neil.computer/notes/hacker-news-design-is-ugly/ | <a href="https://web.archive.org/web/*/https://neil.computer/notes/hacker-news-design-is-ugly/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <article>
        <h2>Hacker News Design is Ugly</h2>
        <p>This thing is straight up ugly. It is too simple, useful, pragmatic, dense and practical. Boring. These days the cool things are purple gradients, lots of negative space and loss of contrast. People on HN keep <a href="https://news.ycombinator.com/item?id=23199603">raving</a> about this design thing but boy they are so wrong.</p><p>Let's fix it.</p><h2 id="current-state">Current State</h2><p>This is what HN front-page looks like when you login. It has absolutely zero pop. Typical engineers, what do they know about design?</p><figure><img src="https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.35.01-PM.png" alt="" width="1938" height="2254" srcset="https://neil.computer/content/images/size/w600/2020/07/Screen-Shot-2020-07-05-at-11.35.01-PM.png 600w, https://neil.computer/content/images/size/w1000/2020/07/Screen-Shot-2020-07-05-at-11.35.01-PM.png 1000w, https://neil.computer/content/images/size/w1600/2020/07/Screen-Shot-2020-07-05-at-11.35.01-PM.png 1600w, https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.35.01-PM.png 1938w" sizes="(min-width: 720px) 720px"></figure><p>Let's make it pop, shall we?</p><h2 id="fixing-hn-design">Fixing HN Design</h2><p>First things first. <em>Padding</em>. When I am bored, running out of ideas, I like to do one thing that usually makes things 10x better. Padding is like a chef's knife in the kitchen. Know how to use it well and you'll be cutting through information rich UI like butter. It is what sets professional designers from these gray-beard types.</p><p>It is difficult to do it right, so please allow me to exemplify the process. First, add padding to the <code>body</code> tag.</p><figure><img src="https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.35.35-PM.png" alt="" width="1938" height="2254" srcset="https://neil.computer/content/images/size/w600/2020/07/Screen-Shot-2020-07-05-at-11.35.35-PM.png 600w, https://neil.computer/content/images/size/w1000/2020/07/Screen-Shot-2020-07-05-at-11.35.35-PM.png 1000w, https://neil.computer/content/images/size/w1600/2020/07/Screen-Shot-2020-07-05-at-11.35.35-PM.png 1600w, https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.35.35-PM.png 1938w" sizes="(min-width: 720px) 720px"></figure><p>See the difference? Holy crap. The UI just suddenly started <em>breathing</em>.</p><p>Let's add more spacing between this conjested highly dense information rich piece of shit.</p><figure><img src="https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.37.35-PM.png" alt="" width="1938" height="2254" srcset="https://neil.computer/content/images/size/w600/2020/07/Screen-Shot-2020-07-05-at-11.37.35-PM.png 600w, https://neil.computer/content/images/size/w1000/2020/07/Screen-Shot-2020-07-05-at-11.37.35-PM.png 1000w, https://neil.computer/content/images/size/w1600/2020/07/Screen-Shot-2020-07-05-at-11.37.35-PM.png 1600w, https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.37.35-PM.png 1938w" sizes="(min-width: 720px) 720px"></figure><p>The color orange is fine with me but it is not gonna get you through the design school and into the real world. The world today demands magenta. Magenta/Purple/Cyan all inspired by Stripe UI since 2015 or so and it really set the standard for a modern color palette. Throw your creativity and objectivity away, the trend dictates what we should choose<em>.</em> May be it PANTONE will come up with a <a href="https://www.pantone.com/color-intelligence/color-of-the-year/color-of-the-year-2020">color of the year</a> and it will change. But as per current design trends, purple is the safe choice.</p><figure><img src="https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.53.20-PM.png" alt="" width="2598" height="2254" srcset="https://neil.computer/content/images/size/w600/2020/07/Screen-Shot-2020-07-05-at-11.53.20-PM.png 600w, https://neil.computer/content/images/size/w1000/2020/07/Screen-Shot-2020-07-05-at-11.53.20-PM.png 1000w, https://neil.computer/content/images/size/w1600/2020/07/Screen-Shot-2020-07-05-at-11.53.20-PM.png 1600w, https://neil.computer/content/images/size/w2400/2020/07/Screen-Shot-2020-07-05-at-11.53.20-PM.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>BAM. What you didn't notice is I also got rid of all background colors to flatten things a bit. I hate borders which are a graphical device invented to create logical spatial layouts but those things are for boring websites for techy folks.</p><p>Next up. Pro tip: Border-radius. It is not as complicated as it sounds. Simply put, we like to make things rounded as allows us to compete for a one of those web design <a href="https://www.awwwards.com/">awwwards</a> and border-radius is a mandatory requirement before creating a <a href="https://dribbble.com/">dribbble</a> account. So we must comply without the thought of originality.</p><figure><img src="https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.54.51-PM.png" alt="" width="2598" height="2254" srcset="https://neil.computer/content/images/size/w600/2020/07/Screen-Shot-2020-07-05-at-11.54.51-PM.png 600w, https://neil.computer/content/images/size/w1000/2020/07/Screen-Shot-2020-07-05-at-11.54.51-PM.png 1000w, https://neil.computer/content/images/size/w1600/2020/07/Screen-Shot-2020-07-05-at-11.54.51-PM.png 1600w, https://neil.computer/content/images/size/w2400/2020/07/Screen-Shot-2020-07-05-at-11.54.51-PM.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>See? It really ties the web page together.</p><p>Those pesky informative sub-titles are jarring as it helps the user too much. Let's make it so that it loses contrast and fades away in the background. As a side effect, it makes the whole thing more minimal. Minimalism at all costs. Try to make things minimal by removing features and neutring functionality - no one will ever notice. </p><figure><img src="https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.55.33-PM.png" alt="" width="2598" height="2254" srcset="https://neil.computer/content/images/size/w600/2020/07/Screen-Shot-2020-07-05-at-11.55.33-PM.png 600w, https://neil.computer/content/images/size/w1000/2020/07/Screen-Shot-2020-07-05-at-11.55.33-PM.png 1000w, https://neil.computer/content/images/size/w1600/2020/07/Screen-Shot-2020-07-05-at-11.55.33-PM.png 1600w, https://neil.computer/content/images/size/w2400/2020/07/Screen-Shot-2020-07-05-at-11.55.33-PM.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>It looks minimal af.</p><p>That's all folks. Hacker News redesigned. These are the basics but if there is enough interest, I can probably make another tutorial on how to do <em>this</em>:</p><figure><img src="https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-06-at-12.05.17-AM.png" alt="" width="2510" height="2166" srcset="https://neil.computer/content/images/size/w600/2020/07/Screen-Shot-2020-07-06-at-12.05.17-AM.png 600w, https://neil.computer/content/images/size/w1000/2020/07/Screen-Shot-2020-07-06-at-12.05.17-AM.png 1000w, https://neil.computer/content/images/size/w1600/2020/07/Screen-Shot-2020-07-06-at-12.05.17-AM.png 1600w, https://neil.computer/content/images/size/w2400/2020/07/Screen-Shot-2020-07-06-at-12.05.17-AM.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>Until then, go here and browse some more trends to follow at the cost of authenticity, objectivity, originality, reasoning and fundamental understanding of how to design user interfaces: <a href="https://www.google.com/search?q=design+trends+2020">https://www.google.com/search?q=design+trends+2020</a></p>
        </article>
</div></div>]]>
            </description>
            <link>https://neil.computer/notes/hacker-news-design-is-ugly/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23745595</guid>
            <pubDate>Mon, 06 Jul 2020 07:40:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Handling deeplinks in iOS 14 and SwiftUI 2.0 with onOpenURL]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23745576">thread link</a>) | @dwltz
<br/>
July 6, 2020 | https://www.donnywals.com/handling-deeplinks-in-ios-14-with-onopenurl/ | <a href="https://web.archive.org/web/*/https://www.donnywals.com/handling-deeplinks-in-ios-14-with-onopenurl/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote><p>This article covers beta technology and it's up to date for Xcode 12 beta 1</p></blockquote><p>Starting with iOS 14, we can write apps that are fully built using SwiftUI, dropping the need to have <code>AppDelegate</code> and <code>SceneDelegate</code> files entirely. For as long as I remember, I've <a href="https://www.donnywals.com/handling-deeplinks-in-your-app/">handled deeplinks</a> in my <code>AppDelegate</code> and for the past year in the <code>SceneDelegate</code>. So when Apple introduced developers to this new <code>@main</code> annotated <code>App</code> struct style of building apps, I'm sure we all had the same question on our mind. How does the new <code>App</code> struct work with deeplinks and other tasks that are normally performed in the <code>AppDelegate</code>?</p><p>Luckily, Apple engineers made sure that handling deeplinks in our apps is still possible with the new <code>onOpenURL(perform:)</code> view modifier.</p><h2>Handling deeplinks with onOpenURL</h2><p>The new <code>onOpenURL(perform:)</code> view modifier is new in iOS 14. It allows developers to register a URL handler on their views so they can respond to URLs by modifying state for their views as needed.</p><p>This is vastly different from how we're used to dealing with URLs in UIKit and the <code>SceneDelegate</code> flow.</p><p>The old way of handling deeplinks requires you to handle each link in the <code>SceneDelegate</code> (or <code>AppDelegate</code>). You would have to manipulate the selected tab in a <code>UITabBarViewController</code>, or present a <code>UIViewController</code> by inspecting the current view controller hierarchy and pushing the needed <code>UIViewController</code> from right inside of the <code>SceneDelegate</code>.</p><p>In SwiftUI, you can use the <code>onOpenURL(perform:)</code> on the root of your scene as follows:</p><pre><code>@main
struct MyApplication: App {
  var body: some Scene {
    WindowGroup {
      ContentView()
        .onOpenURL { url in
          // handle the URL that must be opened
        }
    }
  }
}</code></pre><p>I will cover what it means exactly to handle the url in the next section of this article, but usually it will involve mutating some state to load and display the view associated with the URL that must be opened.</p><p>What's really neat is that you can specify multiple <code>onOpenURL</code> handlers throughout your app. This means that you can make multiple, smaller changes to your app state which means that you no longer have one place where all of your deeplink handling and view manipulation takes place.</p><p>Furthermore, <code>onOpenURL</code> is called when your app is in the foreground, background or not running at all. This means that there is now a single entry point for your app to handle URLs. Even if your app is relaunched after being force-closed.</p><p>In the next section, I will show you an example of how you can select a tab in a <code>TabView</code> depending on the URL that your app is requested to open. After that, I will show you how to navigate to a list item in a view that's embedded in a <code>TabView</code> by adding a second <code>onOpenURL</code> view modifier on a child <code>View</code> that contains a <code>List</code>.</p><h2>Activating a tab in a TabView when opening a URL</h2><p>In SwiftUI, views are a function of their state. This means that virtually everything in a SwiftUI application can be represented and manipulated as a data model. This means that we can represent the currently selected tab in a SwiftUI <code>TabView</code> as a property on an <code>App</code> struct.</p><p>The following code shows how:</p><pre><code>struct MyApplication: App {
  @State var activeTab = 0

  var body: some Scene {
    WindowGroup {
      TabView(selection: $activeTab) {
        HomeView()
          .tabItem {
            VStack {
              Image(systemName: "house")
              Text("Home")
            }
          }
          .tag(0)

        SettingsView()
          .tabItem {
            VStack {
              Image(systemName: "gearshape")
              Text("Settings")
            }
          }
          .tag(1)
      }
      .onOpenURL { url in
        // determine which tab should be selected and update activeTab
      }
    }
  }
}</code></pre><p>What's important to notice here is the <code>activeTab</code> property. This property is marked as <code>@State</code> and represents the selected tab in the <code>TabView</code>. When creating the <code>TabView</code>, I pass a binding to <code>activeTab</code> to the <code>TabView</code>'s initializer. Setting the <code>TabView</code> up like this means that updating <code>activeTab</code> will cause the <code>TabView</code> to update its selected tab as well.</p><p>Notice that I set a <code>tag</code> on the views that are added to the <code>TabView</code>. This <code>tag</code> is used to identify the <code>TabView</code>'s items. When <code>activeTab</code> matches one of the <code>tag</code>s associated with your views, the <code>TabView</code> will activate the matching tab.</p><p>In this case that means setting <code>activeTab</code> to <code>1</code> would activate the tab that displays <code>SettingsView</code>.</p><p>Let's see how you can implement <code>onOpenURL</code> to figure out and activate the correct tab. To do this, I'm going to introduce an extension on <code>URL</code>, and a new type called <code>TabIdentifier</code>:</p><pre><code>enum TabIdentifier: Hashable {
  case home, settings
}

extension URL {
  var isDeeplink: Bool {
    return scheme == "my-url-scheme" // matches my-url-scheme://&lt;rest-of-the-url&gt;
  }

  var tabIdentifier: TabIdentifier? {
    guard isDeeplink else { return nil }

    switch host {
    case "home": return .home // matches my-url-scheme://home/
    case "settings": return .settings // matches my-url-scheme://settings/
    default: return nil
    }
  }
}</code></pre><p>The code above is just a convient way to figure out which tab belongs to a <code>URL</code> without having to duplicate logic all over the app. If you decide to implement a similar object, the <code>isDeeplink</code> computed property should be updated according to the URLs you want to support. If you're implementing Universal Links, you'll want to check whether the <code>URL</code>'s <code>host</code> property matches your hostname. I've set up a very minimal check here for demonstration purposes where I only care about the URL scheme.</p><p>The <code>tabIdentifier</code> property is a computed property that uses the <code>host</code> property to determine which tab should be selected. For a Universal Link you'll probably want to use the <code>pathComponents</code> property and compare using the second entry in that array, depending on your mapping strategy. Again, I set this up to be very basic.</p><p>You can use this basic setup in the <code>App</code> struct as follows:</p><pre><code>struct MyApplication: App {
  @State var activeTab = TabIdentifier.home

  var body: some Scene {
    WindowGroup {
      TabView(selection: $activeTab) {
        HomeView()
          .tabItem {
            VStack {
              Image(systemName: "house")
              Text("Home")
            }
          }
          .tag(TabIdentifier.home) // use enum case as tag

        SettingsView()
          .tabItem {
            VStack {
              Image(systemName: "gearshape")
              Text("Settings")
            }
          }
          .tag(TabIdentifier.settings) // use enum case as tag
      }
      .onOpenURL { url in
        guard let tabIdentifier = url.tabIdentifier else {
          return
        }

        activeTab = tabIdentifier
      }
    }
  }
}</code></pre><p>Because I made <code>TabIdentifier</code> <code>Hashable</code>, it can be used as the <code>activeTab</code> identifier. Each tab in the <code>TabView</code> is associated with a <code>TabIdentifier</code> through their tags, and by reading the new <code>tabIdentifier</code> that I added to <code>URL</code> in my extension, I can easily extract the appropriate tab identifier associated with the URL that I need to open.</p><p>As soon as I assign the acquired <code>tabIdentifier</code> to <code>activeTab</code>, the <code>TabView</code> is updated marking the appropriate tab as selected along with displaying the appropriate <code>View</code>.</p><p>Of course this is only half of what you'll want to typically do when opening a deeplink. Let's take a look at activating a <code>NavigationLink</code> in a different view next.</p><h2>Handling a URL by activating the correct NavigationLink in a List</h2><p>You already know how to activate a tab in a <code>TabView</code> when your app needs to handle a URL. Often you'll also need to navigate to a specific detail page in the view that's shown for the selected tab item. The cleanest way I have found to do this, is by adding a second <code>onOpenURL</code> handler that's defined within the detail view that should activate your navigation link.</p><p>When you define multiple <code>onOpenURL</code> handlers, the system will call them all, allowing you to make small, local changes to your view's data model. Like selecting a tab in the <code>App</code> struct, and activating a <code>NavigationLink</code> in a child view. Before I show you how to do this, We'll need another extension on <code>URL</code> to extract the information we need to activate the appropriate <code>NavigationLink</code> in a <code>List</code>:</p><pre><code>enum PageIdentifier: Hashable {
  case todoItem(id: UUID)
}

extension URL {
  var detailPage: PageIdentifier? {
    guard let tabIdentifier = tabIdentifier,
          pathComponents.count &gt; 1,
          let uuid = UUID(uuidString: pathComponents[1]) else {
      return nil
    }

    switch tabIdentifier {
    case .home: return .todoItem(id: uuid) // matches my-url-scheme://home/&lt;item-uuid-here&gt;/
    default: return nil
    }
  }
}</code></pre><p>I've added a new enum called <code>PageIdentifier</code>. This enum has a single case with an associated value. This associated value represents the identifier of the object that I want to deeplink to. My app is a to-do app, and each to-do item uses a <code>UUID</code> as its unique identifier. This is also the identifier that's used in the deeplink. The approach above is similar to what I've shown in the previous section and if you decide you like my URL parsing approach, you'll have to make some modifications to adapt it in your app.</p><p>The next step is to implement the <code>HomeView</code>, and select the appropriate item from its list of items:</p><pre><code>struct HomeView: View {
  @StateObject var todoItems = TodoItem.defaultList // this is just a placeholder.  
  @State var activeUUID: UUID?

  var body: some View {
    NavigationView {
      List(todoItems) { todoItem in
        NavigationLink(destination: TodoDetailView(item: todoItem), tag: todoItem.id, selection: $activeUUID) {
          TaskListItem(task: todoItem)
        }
      }
      .navigationTitle(Text("Home"))
      .onOpenURL { url in
        if case .todoItem(let id) = url.detailPage {
          activeUUID = id
        }
      }
    }
  }
}</code></pre><p>Notice that my <code>HomeView</code> has a property called <code>activeUUID</code>. This property serves the exact same purpose that <code>activeTab</code> fulfilled in the previous section. It represents the identifier for the item that should be selected.</p><p>When creating my <code>Navigat…</code></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.donnywals.com/handling-deeplinks-in-ios-14-with-onopenurl/">https://www.donnywals.com/handling-deeplinks-in-ios-14-with-onopenurl/</a></em></p>]]>
            </description>
            <link>https://www.donnywals.com/handling-deeplinks-in-ios-14-with-onopenurl/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23745576</guid>
            <pubDate>Mon, 06 Jul 2020 07:37:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[C++?? A Critique of C++ (1992)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23745291">thread link</a>) | @alexeiz
<br/>
July 5, 2020 | https://www.modulaware.com/mdlt28.htm | <a href="https://web.archive.org/web/*/https://www.modulaware.com/mdlt28.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div face="Arial">
<hr>
<h3>The ModulaTor's Forum</h3>
<p>
Subject: Re: C++?? A C++ Critique
<br>From: Guenter Dotzel
<br>To: Ian Joyner &gt;INTERNET: ian@syacus.acus.oz.au
</p><p>
Ian, 
</p><p>
I'm concerned about the recent popularization of both C and C++. Either one of 
these languages seems to be pervasive when talking about a programming 
language. 
</p><p>
I enjoyed reading your article entitled "C++?? A C++ Critique" dated Nov-1992. 
Your article seems to clarify most aspects and rumors about C++. 
</p><p>
According to Prof. Gutknecht from ETH-Zuerich, who talked about the Tragedy 
of Programming Language Development at the 2nd European Modula-2 
Conference, Leicester/UK, Sep-1992, the main features that made C++ "the 
definite programming languages" are: 
</p><p>
C++ supports several programming paradigms and blends, gives access to all 
[abstraction] levels and encuroage breaks of abstraction, is not dangerous 
powerful, is a tricky and challenging game and has completely lost its identity. 
</p><p>
I think your article could help the not so programming language design sensitive 
average application programmers to get a feeling what C++ is all about. I 
assume that even Modula-2 and Oberon-2 programmers would be interested in 
reading your article to find some arguments against C++. I know that they often 
get asked Why don't you switch to modern, popular, high-level, OO-languages 
such as C++? 
</p><p>
As the editor of our monthly, non-commercial, pure-technical, Modula-2 and 
Oberon-2 related newsletter called The ModulaTor, I'd like to ask you for 
permission to publish your article in an upcoming issue of this newsletter. 
</p><p>
Greetings, Guenter 
</p><p>
From: ian@syacus.acus.oz.au
<br>Subject: Re: C++?? A C++ Critique
<br>To: 100023.2527@compuserve.com
<br>Date: Wed, 18 Nov 92 12:16:32 EST
</p><p>
Dear Guenter, 
</p><p>
I would be very pleased for you to publish the second edition of my article. 
Thanks for thinking of it. 
</p><p>
As for C++ being a modern language rather than Modula-2 of Oberon, the 
reverse is the case. I find it depressing to think that we are now stuck with a 
language full of compromises that were made for small machines of 25 years 
ago. The Algol style languages, and Pascal forward were designed to be much 
less technology dependent, and so are still relevant today. 
</p><p>
Anyway I think that those who have suffered C silently in the past are now 
finding a voice to be able to counter the criticism and arrogance of the C world to 
view all other languages as second rate, and old. I hope you find the critique 
useful and interesting. If so, please feel free to distribute it among your peers 
and friends. 
</p><p>
[Ed. note: additional notes received from Ian in Jun-1995 via Ruslan, a friend at 
IUE, Moscow:] 
</p><hr>
<p>
C++ is a language that is coming under ever more intense criticism. Bjarne 
Stroustrup finds this unfair, as he says the language delivers what they set out 
to do. However, C++ is a poor implementation of OO technology, and its 
shortcomings need to be criticised. One critique of C++ is my own C++?? 
Critique. 
</p><p>
Another appraisal of C++ as compared to Eiffel is in Richard Wiener's "Software 
Development using Eiffel: There can be life other than C++" (Prentice Hall), a 
very even handed treatment of the subject. 
</p><p>
Undoubtedly, one person who has set the watermark for OO technology is 
Bertrand Meyer, the creator of Eiffel. He has written several books describing 
object technology which should be read. He pulls no punches in his criticism of 
C++. The recommended <i>Bertrand Meyer</i> reading is 
<a href="http://www.amazon.com/exec/obidos/ASIN/0136291554/modulaware">
"Object-oriented Software Construction"</a>, 2nd edition, 1995,
and 
<a href="http://www.amazon.com/exec/obidos/ASIN/0131928333/modulaware">
"Object Success: A Managers guide to object orientation, 
its impact on the corporation and its use for 
reengineering the software process"</a>.
Both books Prentice Hall. 
</p><p>
I believe that Object-oriented technology has a lot to offer in helping with the 
problems faced by modern and complex software systems. However, to many 
object-oriented people, C++ is the biggest disappointment of all, bringing all the 
bad old ways and a lot of unnecessary complexity to object-orientation. You do 
not need a language so riddled with low level constructs. The correct way is to 
use a pure OO language, and only interface to C, or other low level languages 
through external mechanisms. That way will ensure maintainability, portability, 
and quality. 
</p><p>
I wish you success in your quest for building quality software cost effectively, 
and I think you will find part of the answer to the goal in Object-orientation, but 
not in C++. Critics of C++ are not religious fanatics and cranks as many C++ 
proponents would make out. We realise the shortcomings of C++, and advise 
looking into some of the better ways that are available. 
</p><hr>
Several sites have offered to make the C++?? Critique available by ftp. I would 
like to thank Indiana University, University of Western Australia, Brown 
University and IRISA/CNRS France for their help, and many other sites who 
have done this voluntarily without solicitation. The sites that I know about who 
have given me permission to advertise their service are: 
<pre>U.S West Indiana University:

      Machine:       moose.cs.indiana.edu
      IP #           129.79.254.191
      Directory:     pub
      Compressed:    cpp.crit/cpp.crit.ps.Z
      Hours:         After 6pm Eastern US Please

Australia/Asia University of Western Australia:

      Machine:       redback.cs.uwa.edu.au
      IP #           130.95.80.61
      Directory:     /Others/Quinn
      File:          c++.ps.Z
      Please read:   /ComSci/ReadMeAboutRedback

U.S East Brown University:

      Machine:       ftp.brown.edu
      Directory:     /pub/c++
      File:          C++-Critique-2ed.PS

France/Europe IRISA/CNRS:

      Machine:       irisa.irisa.fr
      IP #           131.254.254.2
      Directory:     pub/c++
      File:          cpp.crit.ps.Z
</pre>
<p>
Please observe Indiana's after hours embargo, as they have offered to do this 
completely voluntarily. 
</p><p>
Please report any problems to ian@syacus.acus.oz.au. Thank you. Also, if you 
need text or uncompressed postscript, please contact me directly. 
</p><p>
I hope you find the critique useful and interesting. If so, please feel free to 
distribute it among your peers and friends. 
</p><p>
Printing problems? 
</p><p>
If you find the file does not print, you might find that the control D (^D or EOT) as 
the first character in the file is upsetting your printer. Some printers seems to 
require this, and others don't. Just remove it if you have a problem. 
</p><p>
If there are carriage returns that your printer objects to remove all ^M 
characters. 
</p><p>
Some printers are fussy about the page size. I have formatted it for U.S Letter, 
as it is shorter than A4 and so should avoid any truncation problems. However, 
this is a problem for some A4 printers. If this is the case, replace the line: 
</p><p>
/oldDictCount countdictstack def {letter 
</p><p>
by 
</p><p>
/oldDictCount countdictstack def {a4 
</p><p>
The papertray command might have to be changed from 0 to 1. 
</p><p>
Otherwise, make sure that you have 'uncompress'ed the file, and that you are 
sending it to a PostScript printer. 
</p><pre>Ian Joyner  ACUS (Australian Centre for Unisys Software)    ian@syacus.acus.oz
"Where is the man with all the great directions?...You can't imagine it,
 how hard it is to grow, Can you imagine the order of the universe?" ABWH
Disclaimer:Opinions and comments are personal.
115-117 Wicks Rd, North Ryde, N.S.W Australia 2113
Tel 61-2-390 1328       Fax 61-2-390 1391
</pre>
<hr>
<h3>C++?? A Critique of C++ </h3>
<p>
(2nd Edition) 
</p><p>
© (1992) by Ian Joyner, c/- Unisys - ACUS, 115 Wicks Rd, North Ryde, Australia 
2113, Tel: +61-2-390 1328, Fax +61-2-390-1391, Email/Internet: 
ian@syacus.acus.oz.au 
</p><p>
[Editors note: Permission for publication in The ModulaTor was granted by the 
author in Nov-1992] 
</p><pre><span face="Courier"> Introduction..........................................................4

 The Role of a Programming Language....................................5
   Safety and Courtesy Concerns........................................8

 C++ Specific Criticisms...............................................8
   Virtual Functions...................................................8
   Pure Virtual Functions.............................................11
   The Nature of Inheritance..........................................12
   Function Overloading...............................................13
   Virtual Classes....................................................14
   Name overloading...................................................14
   Polymorphism and Inheritance.......................................16
   '.'  and '-&gt;'......................................................17
   Anonymous parameters in Class Definitions..........................17
   Nameless Constructors..............................................18
   Constructors and Temporaries.......................................18
   Optional Parameters................................................18
   Bad deletions......................................................19
   Local entity declarations..........................................19
   Members............................................................20
   Friends............................................................20
   Static.............................................................21
   Union..............................................................21
   Nested Classes.....................................................21
   Global Environments................................................22
   Header Files.......................................................22
   Class Interfaces...................................................23
   Class header declarations..........................................23
   Garbage Collection.................................................24
   Type-safe linkage..................................................25
   C++ and the software lifecycle.....................................26
   Reusability and Communication......................................27
   Reusability and …</span></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.modulaware.com/mdlt28.htm">https://www.modulaware.com/mdlt28.htm</a></em></p>]]>
            </description>
            <link>https://www.modulaware.com/mdlt28.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-23745291</guid>
            <pubDate>Mon, 06 Jul 2020 06:39:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Three things you should know before starting a Patreon page]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23745272">thread link</a>) | @exolymph
<br/>
July 5, 2020 | http://pencerw.com/feed/2020/6/24/three-things-all-creators-should-know-about-patreon | <a href="https://web.archive.org/web/*/http://pencerw.com/feed/2020/6/24/three-things-all-creators-should-know-about-patreon">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-0e74a9a2acebd70c05fe"><div><p>For the three years starting in April of 2017, I ran much of <a href="http://theprepared.org/newsletter" target="_blank">The Prepared’s</a> (and ultimately my family’s) income through Patreon. I started doing so as an experiment - one that by any measure has been a success. But while Patreon was instrumental in that process, I recommend that creators <strong>not</strong> structure their incomes and careers around Patreon. Here’s why.</p><p>Like many creators, I chose Patreon’s “pay by the creation” (rather than “pay by the month) mode. This directly incentivizes creators to continue doing the actual work, and keeps them accountable to the commitments they make. </p><p>But what Patreon doesn’t tell you is that fans can optionally set a monthly cap on their spending, and that cap can be arbitrarily low - even <strong>less than your per-creation commitment level.</strong> In other words, a reader of my weekly newsletter could pledge $5 per newsletter, but then set a $2 monthly cap. The worst part about this is that there’s literally nowhere in the Patreon backend that I can see this cap. I spoke to Patreon’s product team about this in late 2018, and they told me that the best thing I could do is to look at my creation-by-creation analytics at the end of the month and see which of my patrons paid for which creations; if a person doesn’t show up at the end of the month, then they must have set a cap.</p><p>This is a totally unscalable solution, and it makes the process of issuing patron rewards excruciatingly hard to manage. Creators need the ability to quickly and easily determine <strong>who</strong> is paying them for <strong>what</strong>; Patreon makes this impractically hard.</p><p>Further:</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1593267194369_49688"><div><ul data-rte-list="default"><li><p>Patreon provides email alerts for when a new patron makes a pledge, but has <strong>no email or push notifications for when patrons delete pledges.</strong> </p></li><li><p>Patreon has no creator-side notification system for declined charges or charges that are flagged for fraud. Worse yet, their patron-side notification system appears to be totally ineffective; many long time patrons (and personal friends of mine) were genuinely shocked to hear, many months later, that their monthly charges had been declined - leading to their pledges being automatically canceled by Patreon. Even worse, Patreon’s “Declines” page, which shows the total declined amount on a month by month basis, has no way of showing which patrons’ pledges were declined - you instead need to go into the “Relationship Manager” and filter by “Declined” to see whose charges have gone through, and when.</p></li><li><p>If you, as a creator, go through all of the effort to find charges that<em> </em>have been declined or marked as fraud, it can then be really difficult to recoup that revenue. This is mostly a result of the fact that most Patreon creators charge a small amount of money (a couple dollars) per month. In theory you could email or message the patron when their charge doesn’t go through, but in practice it feels a bit weird to be hounding someone over (say) $4. If the pledge was billed on an annual basis, though, it might be a big enough sum to warrant the effort. </p></li><li><p>Patreon uses accounting terms with little regard for their generally accepted meaning. See the screenshot above, which is titled “Earnings Projections” but then actually lists <em>gross revenue.</em> In accounting, <em>earnings</em> is the same as <em>profit - </em>it’s what a company has left <strong>after every expense is paid, </strong>whereas <em>gross revenue</em> is the total amount that a company takes in and doesn’t take into account expenses at all. In other words, Patreon is suggesting that the numbers here are what will be deposited into my bank account - but once Patreon takes their platform fees, it’ll actually be significantly less. This kind of sloppy terminology is all over Patreon’s creator backend, and no matter how you slice it is either the result of gross incompetence or a deliberate desire to deceive creators.</p></li></ul><p>Between credit card processing fees (2.9% plus $0.30 per transaction) and Patreon’s cut (between 5% and a whopping 12%), your earnings will be <em>significantly</em> less than your top line pledged amount. In practice, I saw total fees of between 8-12%. (Note: I signed up for Patreon before they shifted to tiered pricing, and now have a “Founder” Pro plan at a 5% platform fee rate. If you signed up for a Pro or Premium account today, you’d pay Patreon 3% or 7% more than I do, respectively.)</p><p>If Patreon were actively bringing customers to me - if normal people were just out there browsing Patreon for awesome things to support - then that might make sense. <strong>But the reality is that success on Patreon is inextricably tied to having your own platform and community.</strong> All Patreon does is manage recurring payment processing - a commodity service that many companies do for a drastically lower fee structure. Sure, ostensibly you can also be having conversations with patrons, generating some kind of community there, etc - but every step you take to encourage users to interact with you on Patreon, the more you undermine your own platform. In other words, Patreon engages in rent seeking - but they ultimately do it on <strong>your</strong> platform, and don’t bring a built-in audience with which to raise you higher.</p><p>When I transitioned off of Patreon, I moved to a combination of Quickbooks Online ($645/year; note that <a href="https://www.propublica.org/article/inside-turbotax-20-year-fight-to-stop-americans-from-filing-their-taxes-for-free" target="_blank">Intuit is a terrible company</a>) and Squarespace’s ($480/year) recurring products feature. The result is that my processing fees dropped dramatically. At my peak Patreon earnings, I was spending almost $300/month ($3600/year) on Patreon’s platform fees. My current revenue is roughly 3x what it was then, but I’m paying 68% less than I used to be.<strong> My current payments, web hosting, and accounting software outlay is $1,125 a year; if I had remained on Patreon my annual fees would be about $10,000.</strong></p><p>Okay, you’re saying - so Patreon isn’t the perfect all-in-one platform that will allow me to bill, chat with, and build my audience. But maybe it’s a piece of a larger puzzle?</p><p>It’s a great idea, but unfortunately Patreon does a terrible job integrating with the other services that I use to run my business.</p><p>The first thing I’d want from Patreon is an easy way to automatically share my content (which most creators distribute elsewhere - for me, it’s Mailchimp) to Patreon. But while Patreon does have a public API, it’s poorly developed (there is no sandbox/testing area, and the most recent updates to <a href="https://github.com/Patreon/patreon-python" target="_blank">their API libraries</a> are from January of 2019) and only allows browsing/looking up data on Patreon; you cannot post content to your Patreon account via the API. This lack of functionality also exists in Zapier’s implementation of the Patreon API: You can use Patreon as a trigger, but not as an action.</p><p>What this means is that creators are inherently tied to Patreon’s terrible, horrible, clicky clicky GUI. You are completely tied to the limitations that are built into Patreon’s web product, and don’t have the ability to build automations that’ll speed up your content and customer management.</p><p>Patreon also fails to integrate well with accounting software - something that flies in the face of their promise to give creators “the stability you need to build an independent creative&nbsp;career.” Their API (and Zapier’s implementation of it) only provides <em>pledge</em> activity, and is therefore inaccurate (caps, declines, and fraud aren’t factored in - it’s a guesstimate at what you might make in the future) in all of the ways described above.</p><p>I really can’t stress this enough: <strong>If your intention is to build a meaningful income, there are much better options out there than Patreon. </strong>What Patreon <em>does</em> offer is a quick way to see whether people on the internet will pay you a little money for something that you’re already doing for free. </p><p>This is a nontrivial thing, but it’s something that you should really think through before you start a Patreon page. If it’s a success, then it’ll likely make a lot of sense for you to transition <em>off</em> of Patreon at some point in the foreseeable future. That might be fine - especially if you’re really early on and success feels like a longshot - but The Prepared’s transition off of Patreon required a lot of management on my part and resulted in roughly 1/3 of my patrons dropping their pledges. </p><p>To be clear: I’m deeply appreciative of all of the people and companies who supported me through Patreon, and it really is true that those first couple of dollars made a big impact in the path of my career. But Patreon as a platform did remarkably little to support me along that journey, even after I became a moderately successful creator and took quite a bit of time to explain my frustrations to both their customer service &amp; user research teams.</p></div></div></div>]]>
            </description>
            <link>http://pencerw.com/feed/2020/6/24/three-things-all-creators-should-know-about-patreon</link>
            <guid isPermaLink="false">hacker-news-small-sites-23745272</guid>
            <pubDate>Mon, 06 Jul 2020 06:35:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to process more than 350K requests per month free using 3 free ETA services]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23745223">thread link</a>) | @Gen1us
<br/>
July 5, 2020 | https://blog.maddevs.io/how-to-make-three-paid-eta-services-one-free-6edc6affface | <a href="https://web.archive.org/web/*/https://blog.maddevs.io/how-to-make-three-paid-eta-services-one-free-6edc6affface">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://blog.maddevs.io/@meder33kg?source=post_page-----6edc6affface----------------------" rel="noopener"><img alt="Akkozov Meder" src="https://miro.medium.com/fit/c/96/96/2*87H69ujCEx7VLZYSZPQyig.jpeg" width="48" height="48"></a></p></div></div></div></div><figure><div><div><div><p><img alt="Estimated time of arrival." src="https://miro.medium.com/max/8000/1*q9EOHqrYhaLpY1ZIL0C4Qw.jpeg" width="4000" height="2172" srcset="https://miro.medium.com/max/552/1*q9EOHqrYhaLpY1ZIL0C4Qw.jpeg 276w, https://miro.medium.com/max/1104/1*q9EOHqrYhaLpY1ZIL0C4Qw.jpeg 552w, https://miro.medium.com/max/1280/1*q9EOHqrYhaLpY1ZIL0C4Qw.jpeg 640w, https://miro.medium.com/max/1400/1*q9EOHqrYhaLpY1ZIL0C4Qw.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*q9EOHqrYhaLpY1ZIL0C4Qw.jpeg?q=20"></p></div></div></div><figcaption>Estimated time of arrival</figcaption></figure><p id="cce6">This is a story on how to not spend even a penny by using three ETA (estimated time of arrival) services instead of one. Everything is based on my personal experience working as a back-end developer at GoDee project. GoDee is a start-up project that offers booking seats on a bus online. You could find more information about this project here:</p><p id="e338">GoDee is a public transportation service. Bus transportation by GoDee is more convenient than motorbikes common for Southeast Asia and cheaper than a taxi. The app-based system allows users to find an appropriate route, select the time, book the seat, and pay for the ride online. And one of the problems of GoDee is traffic jams that severely impact the user experience. Users get tired of waiting and get annoyed by trying to guess the bus arrival time. So, to make the commuting more convenient, it needed service to calculate the bus’s approximate arrival time, aka ETA.</p><p id="5226">Developing ETA from scratch would take at least a year. So, to speed up the process, GoDee decided to implement the Google Distance Matrix API tool. Later they developed their own Pifia micro-service.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/500/1*vq9Ao08BtAdAMx5OYhbSlA.gif" width="250" height="429" data-old-src="https://miro.medium.com/freeze/max/34/1*vq9Ao08BtAdAMx5OYhbSlA.gif?q=20"></p></div></div></figure><p id="b97d">Over time, the business grew, and the user base increased. We encountered a problem with increasing requests in the Google Distance Matrix API.</p><h2 id="8971">Why is this a problem?</h2><p id="2a4f">Because every request costs money, Google API provides 10.000 free queries per month, after which every 1.000 queries are charged $20. At that time, we had about 150,000 requests per month.</p><p id="7492">My mentor was very dissatisfied with that. And said that system should change caching to store ETA every 30 minutes. At that time, the system sent requests to the Google API every 3 seconds to get fresh data. However, such a caching algorithm wasn’t efficient, since minibuses were stuck in traffic. And so the distance only changed once every ten minutes. There was another nuance. For example, five users are asking for information about the same bus, and this is the same request. The cache solved this type of problem.</p><figure><div></div><figcaption>Сache Code</figcaption></figure><p id="8a43">The cache worked, but not for long since GoDee grew even further and faced the same problem — the number of queries has increased again.</p><p id="9a57">It was decided to replace the Google API with OSRM. Basically, OSRM is a service for building a route based on ETA (this is a rough but the short description, if you need details, here is the <a href="http://project-osrm.org/" target="_blank" rel="noopener">link</a>).</p><blockquote><p id="113f">The Open Source Routing Machine or OSRM is a C++ implementation of a high-performance routing engine for the shortest paths in road networks.</p><p id="15be">Wikipedia.</p></blockquote><p id="97d4">OSRM has one problem: it builds routes and calculates ETA without taking traffic into account. To solve this problem, I started looking for services that can provide information about traffic in the specified part of the city. HERE Traffic was providing the data I needed. After a little study of the documentation, I wrote a small code that gets traffic information every 30 minutes. And to upload traffic information to OSRM, I wrote a small script with the command <code>./osrm-contract data.osrm --segment-speed-file updates.csv</code> (more details <a href="https://github.com/Project-OSRM/osrm-backend/wiki/Traffic" target="_blank" rel="noopener">here</a>).</p><p id="cbda">Math time: every half of the hour, there is a request to HERE to get traffic information this are two requests per hour, that is, a day is 48 requests (24 * 2 = 48) and a month is about ≈ 1.488 (48*31 = 1.488) a year 17.520. Yes, we have these free requests from HERE for 15 years would be enough.</p><figure><div></div><figcaption>Code for getting traffic</figcaption></figure><p id="b1d9">Preliminary tests showed that the service works perfectly, but there is a problem, HERE gives traffic information in “gibberish” and the data does not match the OSRM format. In order for the information to fit, you need to use another service HERE for geocoding + OSRM (for getting points on the map). This is approximately 450.000 requests per month. Later, OSRM was abandoned because the number of requests exceeded the free limit. We didn’t give up and enabled the HERE Distance Matrix API and temporarily removed the Google Distance Matrix API. The logic HERE is simple: we send coordinates from point A to point B and get the bus arrival time.</p><figure><div></div></figure><p id="2e81">After we installed everything on the test server and started checking, we received the first feedback from the testers. They said that ETA reads the time incorrectly. We started looking for the problem, looked at logs (we used Data dog for logs), logs, and tests showed that everything works perfectly. We decided to ask about the problem in a little more detail, and it turned out that if the car is in traffic for 15 minutes, ETA shows the same time. We decided that this is because of the cache because it stores the original time and does not update it for 30 minutes.</p><p id="1d5a">We started looking for the problem, at the beginning we checked the data on the web version of the HERE Distance Matrix API (which is called we go here), everything worked fine, we received the same ETA. This problem was also checked on the google map service. There was no problem. The services themselves show this ETA. We explained everything to testers and businesses, and they accepted everything.</p><p id="18ce">Our team lead suggested connecting another ETA service and returning the Google API as a backup option and writing code with the logic of switching services (the switch was needed if the requests pass the free number of requests).</p><p id="e9c2">The code works the following way:</p><pre><span id="b4e7">val = getCount() // getting the number of queries used</span><span id="9ff9"><em>if</em> getMax() &lt;= val { // checking for the limit of free requests for the service used</span><span id="e935">newService = switchService(s) // // if the limit is reached, switch the service return</span><span id="cae7"><em>return</em> newService(from, to) // giving the logic of the new service </span></pre><p id="054f">We found the following Mapbox service, connected it, installed it, and it worked. As a result, our ETA had:</p><blockquote><p id="625d">“Here” — 250,000 free requests per month<br>Google — 10,000 free requests per month<br>Mapbox — 100,000 free requests per month</p></blockquote><p id="4def">Always look for alternatives, sometimes it happens that the business doesn't want to pay the money for the service and refuses it. As a developer who has worked hard on the service, you should bring the task to real use. This article describes how we were trying to connect more services for the free use of ETA because the business did not want to pay for the service.</p><p id="4330">P.S. As a developer, I believe that if the tool is good and does its job well, then you can pay for the tool’s services (or find Open source projects :D).</p><figure><div></div></figure></div></div></section></div></div>]]>
            </description>
            <link>https://blog.maddevs.io/how-to-make-three-paid-eta-services-one-free-6edc6affface</link>
            <guid isPermaLink="false">hacker-news-small-sites-23745223</guid>
            <pubDate>Mon, 06 Jul 2020 06:26:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Overcoming Serverless Limitations]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23745034">thread link</a>) | @linuxdude
<br/>
July 5, 2020 | https://talkingserverless.com/2020/07/05/overcoming-serverless-limitations/ | <a href="https://web.archive.org/web/*/https://talkingserverless.com/2020/07/05/overcoming-serverless-limitations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-330">

	

	
		<p><img width="2240" height="1260" src="https://talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?is-pending-load=1" alt="" data-attachment-id="333" data-permalink="https://talkingserverless.com/2020/07/05/overcoming-serverless-limitations/oakbur-quill-co-2/" data-orig-file="https://i0.wp.com/talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?fit=2240%2C1260&amp;ssl=1" data-orig-size="2240,1260" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Oakbur Quill Co." data-image-description="" data-medium-file="https://i0.wp.com/talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?fit=300%2C169&amp;ssl=1" data-large-file="https://i0.wp.com/talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?fit=1024%2C576&amp;ssl=1" data-lazy-srcset="https://i0.wp.com/talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?w=2240&amp;ssl=1 2240w, https://i0.wp.com/talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?resize=1536%2C864&amp;ssl=1 1536w, https://i0.wp.com/talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?resize=2048%2C1152&amp;ssl=1 2048w, https://i0.wp.com/talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?resize=1200%2C675&amp;ssl=1 1200w" data-lazy-sizes="(max-width: 2240px) 100vw, 2240px" data-lazy-src="https://talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">		</p><!-- .post-thumbnail -->

	
	<div>
		




<p>While Serverless provides<a href="https://talkingserverless.com/2020/05/12/serverless-a-developer-perspective/"> developers many advantages</a>, they also impose many constraints on developers in terms of architecture, deployment options, etc.. While these constraints<a href="https://talkingserverless.com/2020/06/08/top-considerations-for-serverless-developers/"> require developers</a> to change the way they develop and deploy their applications, there are many ways developers can overcome these limitations or find a workaround to manage them gracefully. As we attend meetups, we hear many questions/concerns from developers about the Serverless limitations. In this post, we will talk about some of the limitations and how developers can overcome these limitations.</p>



<ul><li><b>Stateful Applications:</b> Functions as a Service started off as a platform for stateless applications but the trend is changing slowly. It is possible to maintain the state between invocations using various data stores offered by the cloud providers but it came with enormous operational overhead, complexity, and runaway costs / poor SLAs when not managed properly. Now, many new vendors like<a href="https://go.zoho.com/yIl"> Zoho Catalyst</a> or Nimbella are offering FaaS platforms with integrated data stores, giving developers an easy option to build stateful applications</li><li><b>Mitigating DDOS:</b> Pay per invocation model of FaaS brings this question into focus as developers (and other decision-makers) ponder using FaaS in their organizations. The DDOS risk is not any different from DDOS attacks on applications running on containers or virtual machines but the correlation between the number of invocations of the function with costs amplifies the threat. In many cases, FaaS vendors may try to reduce the impact of DDOS but the users also bear the responsibility to mitigate the attacks. They can use services like Cloudflare to fend away DDOS attacks. They can also resort to throttling as a way to fend off DDOS attacks but, when used pre-emptively, it may end up impacting the application. Using an alerting mechanism for DDOS and then taking quick remediation like throttling may also help. Some FaaS providers like AWS allow developers to use API Gateway with a key, thereby, limiting the access to API gateways</li><li><b>Latency Issues:</b> When a Serverless platform is used to deploy a small component of a larger complex application, latency could be an impact as these components talk to the rest of the application through REST API calls. This latency in the inter-component communications along with the fact that that the other components of the application may be deployed using other services offered by the cloud provider from a different location may impact, adding latency. This can be mitigated using a loosely coupled architecture like Microservices architecture where FaaS can be used for one or more Microservices</li><li><b>Scaling Issues:</b> While using certain FaaS services for stateful applications, there could be scaling issues. Stress on the datastore could be timing out the requests sent through various API Gateway endpoints. One way to mitigate this is by using one endpoint for writing to the data store and one for reading the data. Now the load can be distributed better by using a Queuing service while writing to the datastore. For the most part, these constraints can be mitigated by using smarter architecture but it may not always be the possibility</li><li><b>Cold Start Problem:</b> Cold start may appear like a problem in FaaS but it is leveraged by cloud providers to provide the service at such low costs. Some providers impose cold start as a constraint but others keep the containers encapsulating the functions warm to avoid the cold start problem. If your application’s user experience cannot afford cold start, it is better to pick a provider who keeps the containers warm to avoid the cold start problem</li><li><b>Integration Testing:</b> One of the biggest problems faced by developers is Integration Testing. In traditional environments, developers will have all the components available locally and they can do the integration testing before the code is pushed into the DevOps pipeline. With FaaS, it is not possible. One way to overcome this limitation is to do the integration testing remotely with the cloud provider than doing it locally. Since FaaS provides a cost-effective way to deploy the application, using the service for dev and test is the right way to deploy applications. This also removes the usual friction that happens between developer and ops teams where each team blames the other for the application failures due to differences in environment</li><li><b>Vendor Lock-in:</b> Vendor lock-in is definitely a limitation with Serverless computing. Some vendors mitigate this risk by offering their service based on an open-source FaaS offering. However, this mitigation is superficial as most of the lock-in happens with the application dependencies like the database service used, etc.. Instead, our suggestion is to use disposable applications while using FaaS. FaaS reduces the cost of deploying applications but it also reduces the cost of developing applications. This combination of a reduction in development and deployment costs is the secret behind the success of FaaS. Disposable applications are applications that cost less to create a new application than change the application as you move from one type of service to another or move cloud providers. By using disposable applications, users need not worry about the lock-in costs and they can focus on building apps and deploying them quickly. When the time to change comes, they can just throw away the existing application and quickly build a new one</li></ul>



<p>Yes, Serverless computing adds lots of constraints for developers and these constraints help the cloud providers to offer the service at a very low cost. By understanding the limitations, developers can easily mitigate the impact of limitations.</p>

	</div><!-- .entry-content -->

	</article></div>]]>
            </description>
            <link>https://talkingserverless.com/2020/07/05/overcoming-serverless-limitations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23745034</guid>
            <pubDate>Mon, 06 Jul 2020 05:39:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Go lesson learned: sometimes I don't want to use goroutines if possible]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23744957">thread link</a>) | @todsacerdoti
<br/>
July 5, 2020 | https://utcc.utoronto.ca/~cks/space/blog/programming/GoWhenNotManyGoroutines | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/programming/GoWhenNotManyGoroutines">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>A Go lesson learned: sometimes I don't want to use goroutines if possible</h2>

	<p><small>July  5, 2020</small></p>
</div><div><p>We have a heavily NFS based server environment <a href="https://support.cs.toronto.edu/">here</a>, with <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSFileserverSetupIII">multiple NFS servers</a> and an IMAP server that accesses
all mailboxes over NFS. That IMAP server has had <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/LoadAverageIMAPImpactQuestion">ongoing issues
with elevated load averages</a>,
and what at least seems to be IMAP slowness. However, our current
metrics leave a lot of uncertainties about the effects of all of
this, because we basically only have a little bit of performance
data for a few IMAP operations. One thing I'd like to do is gather
some very basic Unix level NFS performance data from our IMAP server
and from some other machines, to see if I can see anything.</p>

<p>One very simple metric is how long it takes to read a little file
from every NFS filesystem we have mounted on a machine. As it
happens, we already have the little files (they're used for another
system management purpose), so all I need is a program to open and
read each one while timing how long it takes. There's an obvious
issue with doing this sequentially, which is that if there's a
single slow filesystem, it could delay everything else.</p>

<p>The obvious answer here was Go, goroutines, and some form of goroutine
pool. Because the goroutines just do IO (and they're only being
used to avoid one bit of IO delaying another separate bit), the
natural size of the goroutine pool is fairly large, say 50 to 100
goroutines (<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/ManyNFSFilesystemsWhy">we have a lot of NFS filesystems</a>).  This is quite easy and obvious
to implement in Go, so I put together a little Go program for it
and watched the numbers it generated as they jumped around.</p>

<p>Then, out of reflexive caution, I tried running the same program
with a goroutine pool size of 1, which more or less forced serial
execution (the pool goroutine infrastructure was still active but
there was only one worker goroutine doing all the reading). To my
surprise the 'time to read a file' number for all filesystems was
visibly and decidedly lower. I could run the program side by side
with the two different goroutine pool sizes and see this clearly.</p>

<p>Some thinking gave me a possible reason why this is so. My core
code does essentially the following (minus error checking):</p>

<blockquote><pre>start := time.Now()
file, err := os.Open(target)
n, err := file.Read(buffer)
duration := time.Now().Sub(start)
</pre>
</blockquote>

<p>This sequence makes two system calls and <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoSchedulerAndSyscalls">each system call is a
potential goroutine preemption point</a>. If
a goroutine gets preempted during either system call, it can only
record the finishing time once it's scheduled again (and finishes
the read, if it was preempted in the open). If there are 50 or more
goroutines all doing this, some of them could well be preempted and
then not scheduled for some time, and that scheduling delay will
show up in the final duration. When there aren't multiple goroutines
active, there should be very little scheduling delay and the recorded
durations (especially the longest durations) will be lower. And the
ideal situation for essentially no goroutine contention is of course
one goroutine.</p>

<p>(Technically this makes two more system calls to get the time at
the start and the end of the sequence, but on modern systems,
especially Linux, these don't take long enough to trigger <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoSchedulerAndSyscalls">Go's
system call preemption</a> and probably don't
even enter the kernel itself.)</p>

<p>Because I still worry about individual slow filesystems slowing
everything down (or stalls on some filesystems), my solution was a
more complicated work pool approach that starts additional worker
goroutines only when all of the current ones seem to have stalled
for too long.  If all goes well (and it generally does in my testing),
this runs with only one goroutine.</p>

<p>(My current code has the drawback that once the goroutine worker
pool expands, all of them stay active, which means that enough
slow filesystems early on in the checks could get me back to the
thundering herd problem. I'm still thinking about that issue.)</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/programming/GoWhenNotManyGoroutines</link>
            <guid isPermaLink="false">hacker-news-small-sites-23744957</guid>
            <pubDate>Mon, 06 Jul 2020 05:21:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Facebook Ads to Land an Interview at Reddit]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23744652">thread link</a>) | @shsachdev
<br/>
July 5, 2020 | https://www.careerfair.io/reviews/how-to-land-interview-using-fb-ads | <a href="https://web.archive.org/web/*/https://www.careerfair.io/reviews/how-to-land-interview-using-fb-ads">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p>
    The traditional way to get a job interview is to submit your resume and pray. 
    </p>
    <p>
    Everyone does this and it’s taken to be the default because it’s easy. You can send the same resume with the click of a button to totally different companies, no effort on your part other than preparing the resume.
    </p>
    <center>
            <img src="https://www.careerfair.io/assets_fbads/resume_blast.png" width="515" height="354" alt="">
              </center>


    
    <p>
    There’s no way to stand out, no uniqueness. 
    </p>
    <p>
    Generally, the way to get around this is to ask for a referral or to reach out to someone at the company for some sort of informational interview. Both of these methods allow for a more personalized approach to job hunting. 
    </p>
    <p>
    But is it possible to go even one step further? 
    </p>
    
    
    
    <p>
    In 2016, <a href="https://www.linkedin.com/in/dumbfounder/">Chris Seline</a> was coming off a failed startup and looking for new opportunities. 
    </p>
    <p>
    Unlike most other people, though, Chris wasn’t a fan of the resume blast method. 
    </p>
    <p>
    His strategy was to target specific companies and try to get noticed creatively rather than use the traditional channels and get lost in the shuffle. 
    </p>
    <p>
    Chris decided that he really wanted to work for Reddit. 
    </p>
    <p>
    His plan was to write a <a href="https://twicsy-blog.tumblr.com/post/135712326189/hey-reddit-lets-make-some-recommendations">blog post</a> and then email it to the CEO of Reddit. 
    </p>
    <p>
    The blog post is thorough - it’s 2000 words, technical, and you can tell a lot of effort was put into it. 
    </p>
    <p>
    Even if Chris had emailed his post to the Reddit CEO, there’s a strong chance he would have gotten an interview. 99% of applicants don’t put this much effort into an application and receiving such a personalized email is a positive signal. 
    </p>
    <p>
    But Chris didn’t just email him. 
    </p>
    
    
    
    <p>
    He decided to use Facebook Ads to target the CEO of Reddit (Steve Huffman). 
    </p>
    <p>
    Here’s how he did it:
    </p>
    <ol>
    
    <li>Find the Reddit CEO’s public Facebook profile
    
    </li><li>Use this to find out where he lived, what he liked, what he was interested in, etc
    
    </li><li>Use the above to run a super targeted FB Ads Campaign
    </li>
    </ol>
    <p>
    Note that Chris only wanted <em>one</em> person to click on this Ad, that’s why he had to go super targeted. 
    </p>

    <center>
        <img src="https://www.careerfair.io/assets_fbads/new_fb_ad.png" width="529" height="492" alt="">
          </center>
    
    
    
    
    <p>
    Chris ended up spending $10. The ad reached 197 people. 4 People clicked on it. One of them was the CEO of Reddit.
    </p>
    <p>
    Next thing you know, Reddit HR reached out to schedule an interview. Nicely done. 
    </p>
    <p>
    I contacted Chris to find out if he actually got the job - here’s what he said:
    </p>

    <blockquote>
    
        I did not. It turns out they were just starting a search for "head of search" at Reddit, and asked if I would like to interview for that job. That would have been my dream job, and definitely worth a move across the country, even with 3 kids and a wife in tow (I live in DC), so naturally I was very excited and said yes. But after a few talks they thought I didn't have enough experience with big companies, so they asked if I would be interested in an IC role. I was, but I wasn't willing to move across the country for that, and they didn't want to hire remote workers. So that was that.
        <span>Chris Seline</span>
    </blockquote>
   
    
    
    
    <p>
    The reason this is a fun story is because of the FB Ads. 
    </p>
    <p>
    But I think what people may gloss over is the amount of time and research Chris put into writing the blog post that he eventually showed to the Reddit CEO. 
    </p>
    <p>
    If we go back to the beginning of this case study, notice how I mentioned that just blasting a resume to a company signals nothing unique and frankly a lack of effort. 
    </p>
    <p>
    A good way to resolve problems is to invert them - if we do that here, we get the following:
    </p>

    <center>
        <img src="https://www.careerfair.io/assets_fbads/blast_v_tailored.png" width="536" height="225" alt="">
          </center>
    
    <p>
    Chris’ blog post was well researched, relevant, and made him stand out. The FB Ads targeting was just the cherry on top.
    </p>
    <p>
    Next time you see a job you really want to get, think about how you can go that one step further. 
    </p>
    <p>
    Thanks to Chris for responding to my email. You can read his original blog post on this <a href="https://twicsy-blog.tumblr.com/post/174063770074/how-i-targeted-the-reddit-ceo-with-facebook-ads-to">here</a>. 
    </p>
        </div></div>]]>
            </description>
            <link>https://www.careerfair.io/reviews/how-to-land-interview-using-fb-ads</link>
            <guid isPermaLink="false">hacker-news-small-sites-23744652</guid>
            <pubDate>Mon, 06 Jul 2020 04:18:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making a RISC-V OS in Rust: Userspace Processes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23744622">thread link</a>) | @azhenley
<br/>
July 5, 2020 | http://osblog.stephenmarz.com/ch11.html | <a href="https://web.archive.org/web/*/http://osblog.stephenmarz.com/ch11.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">
<p>This is chapter 11 of a multi-part series on <a href="http://osblog.stephenmarz.com/index.html">writing a RISC-V OS in Rust</a>.</p>
<p><a href="http://osblog.stephenmarz.com/index.html">Table of Contents</a> → <a href="http://osblog.stephenmarz.com/ch10.html">Chapter 10</a> → (Chapter 11)</p>

<p>1 Jun 2020: Patreon only</p>
<p>8 Jun 2020: Public</p>
<h2>Resources and References</h2>
<p>
The ELF standard can be found here: <a href="http://osblog.stephenmarz.com/files/elf.pdf">ELF File Format (PDF)</a>.
</p>
<h2>Introduction</h2>
<p>
This is the moment we've all been waiting for. Ten chapters of setup have led us to this moment--to finally be able to load a process from the disk and run it. The file format for executables is called ELF (executable and linkable format). I will go into some detail about it, but there are plenty of avenues you can explore with this one file type.
</p>
<h2>The ELF File Format</h2>
<p>
The executable and linkable format (ELF) is a widely used file format. If you've used Linux, you no doubt have seen it or the effects of it. This file format contains an ELF header, followed by program headers. Each time, we're telling the OS where the linker has mapped the executable sections. If you don't remember, we have a .text section for CPU instructions, .rodata for global constants, .data for global initialized variables, and .bss section for global uninitialized variables. In the ELF format, the compiler decides where to put these. Also, since we're using virtual memory addresses, the ELF header specifies the <em>entry point</em>, which is what we'll put in the program counter when scheduling a process for the first time.
</p>
<p>
<a href="http://osblog.stephenmarz.com/imgs/elf_format.png"><img src="http://osblog.stephenmarz.com/imgs/elf_format.png"></a>
</p>
<p>
[joke]My handwriting hasn't improved since I was 4[/joke]
</p>
<p>
Let's look at some Rust structures that will help us. These are in elf.rs.
</p>
<pre><code>
#[repr(C)]
pub struct Header {
    pub magic: u32,
    pub bitsize: u8,
    pub endian: u8,
    pub ident_abi_version: u8,
    pub target_platform: u8,
    pub abi_version: u8,
    pub padding: [u8; 7],
    pub obj_type: u16,
    pub machine: u16, // 0xf3 for RISC-V
    pub version: u32,
    pub entry_addr: usize,
    pub phoff: usize,
    pub shoff: usize,
    pub flags: u32,
    pub ehsize: u16,
    pub phentsize: u16,
    pub phnum: u16,
    pub shentsize: u16,
    pub shnum: u16,
    pub shstrndx: u16,
}
</code>
</pre>
<p>
All ELF files start with this ELF Header structure. The very top is 0x7f followed by capital ELF, which is 0x7f 0x45 0x4c and 0x46 as you can see below. I took a simple hexdump of the ls (list) command. You can see sure as sh*t that the magic is right there.
</p>
<p>
<a href="http://osblog.stephenmarz.com/imgs/ls_elf.png"><img src="http://osblog.stephenmarz.com/imgs/ls_elf.png"></a>
</p>
<p>
The rest of the fields will tell us for which architecture this ELF file was made. RISC-V has reserved 0xf3 as its machine type. So, when we load an ELF from the disk, we must make sure it's for the correct architecture. You'll also notice that <code>entry_addr</code> is up there too. This is a virtual memory address where <code>_start</code> begins. Our _start just simply calls main and then when main returns, it calls the exit system call. This is how most programs actually work, but they do a much more rigorous job including getting command line arguments and so forth. Right now, we don't have those.
</p>
<p>
The field that we need to know is the <code>phoff</code> field which specifies the program headers' offset. The program headers is a table of one or more program sections. I took a snapshot of ls (again) and the program headers. You can do the same using <code>readelf -l /bin/ls</code>. The code below shows how I read the ELF header in Rust.
</p>
<pre><code>
let elf_hdr;
unsafe {
  elf_hdr = (buffer.get() as *const elf::Header).as_ref().unwrap();
}
if elf_hdr.magic != elf::MAGIC {
  println!("ELF magic didn't match.");
  return;
}
if elf_hdr.machine != elf::MACHINE_RISCV {
  println!("ELF loaded is not RISC-V.");
  return;
}
if elf_hdr.obj_type != elf::TYPE_EXEC {
  println!("ELF is not an executable.");
  return;
}
</code>
</pre>
<p>
You can see that now we're at the program headers, which I took a snapshot of for /bin/ls.
</p>
<p>
<a href="http://osblog.stephenmarz.com/imgs/ls_program_headers.png"><img src="http://osblog.stephenmarz.com/imgs/ls_program_headers.png"></a>
</p>
<p>
The program headers have the following structure in Rust.
</p>
<pre><code>
#[repr(C)]
pub struct ProgramHeader {
    pub seg_type: u32,
    pub flags: u32,
    pub off: usize,
    pub vaddr: usize,
    pub paddr: usize,
    pub filesz: usize,
    pub memsz: usize,
    pub align: usize,
}
</code>
</pre>
<p>
/bin/ls uses shared libraries, but we're not that good, yet. So, the only program headers we care about are the ones shown by LOAD. These are the sections that we need to load into memory for our static binaries. In the ProgramHeader structure, we need seg_type to be LOAD. The flags tell us how to protect the virtual memory. There are three flags EXECUTE (1), WRITE (2), and READ (4). We also need the off (offset), which tells us where in the ELF file that section to load into the program memory is contained. Finally, the vaddr is what we need to point the MMU to where we loaded this section into memory. You can see how I did this in test.rs in the test_elf() function.
</p>
<pre><code>
for i in 0..elf_hdr.phnum as usize {
  let ph = ph_tab.add(i).as_ref().unwrap();
  if ph.seg_type != elf::PH_SEG_TYPE_LOAD {
    continue;
  }
  if ph.memsz == 0 {
    continue;
  }
  memcpy(program_mem.add(ph.off), buffer.get().add(ph.off), ph.memsz);
  let mut bits = EntryBits::User.val();
  if ph.flags &amp; elf::PROG_EXECUTE != 0 {
    bits |= EntryBits::Execute.val();
  }
  if ph.flags &amp; elf::PROG_READ != 0 {
    bits |= EntryBits::Read.val();
  }
  if ph.flags &amp; elf::PROG_WRITE != 0 {
    bits |= EntryBits::Write.val();
  }
  let pages = (ph.memsz + PAGE_SIZE) / PAGE_SIZE;
  for i in 0..pages {
    let vaddr = ph.vaddr + i * PAGE_SIZE;
    let paddr = program_mem as usize + ph.off + i * PAGE_SIZE;
    map(table, vaddr, paddr, bits, 0);
  }
}
</code>
</pre>
<p>
All I do with the code above is enumerate all of the program headers. The ELF header tells us how many there are via the phnum field. We then check the segment type to see if it is LOAD. If it isn't, we skip it. Then, we check to see if that segment actually contains anything. If not, there's no use in loading it. Then, we copy what we read from the filesystem (buffer) into the process' memory (program_mem). Since these are virtual memory address, the rest of the code determines how we should map the pages.
</p>
<h2>Executing the Process</h2>
<p>
We need to map a few things, including the stack and the program. Also, don't forget to set the program counter to the entry_addr!
</p>
<pre><code>
(*my_proc.frame).pc = elf_hdr.entry_addr;
(*my_proc.frame).regs[2] = STACK_ADDR as usize + STACK_PAGES * PAGE_SIZE;
(*my_proc.frame).mode = CpuMode::User as usize;
(*my_proc.frame).pid = my_proc.pid as usize;
(*my_proc.frame).satp = build_satp(SatpMode::Sv39, my_proc.pid as usize, my_proc.root as usize);
</code>
</pre>
<p>
In here, regs[2] is the stack pointer (SP). This must be valid and mapped, otherwise the process will immediately page fault. Now that everything is set up, our last bit of execution is to add it to the process list. When the scheduler gets around to it, it will run our newly minted process!
</p>
<pre><code>
if let Some(mut pl) = unsafe { PROCESS_LIST.take() } {
  println!(
            "Added user process to the scheduler...get ready \
            for take-off!"
  );
  pl.push_back(my_proc);
  unsafe {
    PROCESS_LIST.replace(pl);
  }
}
else {
  println!("Unable to spawn process.");
}
</code>
</pre>
<h2>Writing Userspace Programs</h2>
<p>
We don't have a C library, yet. However, I'm making the OS come close to the newlib, which is a small C-library mainly for embedded systems. For now, I made a small library called <code>startlib</code> that will get us off the ground, and I copied printf into it.
</p>
<pre><code>
.section .text.init
.global _start
_start:
  call	main
  li	a0, 93
  j 	make_syscall
</code>
</pre>
<p>
The _start is a special label that the compiler will use as the entry point address. Recall that we set this in the program counter when we made a new process. After main returns, we schedule a system call number 93, which is the <code>exit</code> system call. All this system call does is deschedule the process and free all of its resources.
</p>
<p>
There are other utilities, including printf in our small library, but let's make a simple program to see if we can get it to work. To be more robust, I'm going to stretch all of our available sections to see if they load properly.
</p>
<pre><code>
#include &lt;printf.h&gt;

const int SIZE = 1000;
int myarray[SIZE];
int another_array[5] = {1, 2, 3, 4, 5};

int main()
{
  printf("I'm a C++ program, and I'm running in user space. How about a big, Hello World\n");
  printf("My array is at 0x%p\n", myarray);
  printf("I'm going to start crunching some numbers, so gimme a minute.\n");
  for (int i = 0;i &lt; SIZE;i++) {
    myarray[i] = another_array[i % 5];
  }
  for (int i = 0;i &lt; 100000000;i++) {
    myarray[i % SIZE] += 1;
  }
  printf("Ok, I'm done crunching. Wanna see myarray[0]? It's %d\n", myarray[0]);
  return 0;
}
</code>
</pre>
<p>
The program doesn't really do anything useful, but it will see if system calls work as well as context switching. On QEMU, this takes around 5 to 8 seconds to run on my machine at home.
</p>
<p>
We then compile this using our C++ toolchain (if you have one). <code>riscv64-unknown-elf-g++ -Wall -O0 -ffreestanding -nostartfiles -nostdlib -static -march=rv64g -mabi=lp64d -I./startlib -L./startlib -o helloworld.elf helloworld.cpp -lstart</code>
</p>
<p>
If you don't have a toolchain, you can download my program here: <a href="http://osblog.stephenmarz.com/helloworld.elf">helloworld.elf</a>. This requires that you have the systems calls identical to mine since it goes by a system call number.
</p>
<h2>Uploading the Program</h2>
<p>
We can use Linux to upload our elf file.
</p>
<p>
<a href="http://osblog.stephenmarz.com/imgs/upload_hw.png"><img src="http://osblog.stephenmarz.com/imgs/upload_hw.png"></a>
</p>
<p>
Take note of the inode number (26) and the file size (14776). Yours might be different, so make sure you stat it! Modify test.rs and put your inode and file size at the top.
</p>
<pre><code>
let files_inode = 26u32; // Change to yours!
let files_size = 14776; // Change to yours!
let bytes_to_read = 1024 * 50;
let mut buffer = BlockBuffer::new(bytes_to_read);
let bytes_read = syscall_fs_read(
                                  8,
                                  files_inode,
                                  buffer.get_mut(),
                                  bytes_to_read as u32,
                                  0,
);
if bytes_read != files_size {
  println!(
            "Unable to load program at inode {}, which should \
            be {} bytes, got {}",
            files_inode, files_size, bytes_read
  );
  return;
}
</code>
</pre>
<p>
This will use our filesystem read call to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://osblog.stephenmarz.com/ch11.html">http://osblog.stephenmarz.com/ch11.html</a></em></p>]]>
            </description>
            <link>http://osblog.stephenmarz.com/ch11.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23744622</guid>
            <pubDate>Mon, 06 Jul 2020 04:11:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An introduction to civics in the 21st century]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23744433">thread link</a>) | @natural219
<br/>
July 5, 2020 | https://cjohnson.io/civics/ | <a href="https://web.archive.org/web/*/https://cjohnson.io/civics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <p>"Men, at some time, are masters of their fates;"</p>
        <p>The fault, dear Brutus, lies not in our stars --</p>
        <p>but in ourselves, that we are underlings"</p>
      </div>
      
      <h4>Introduction to civics in the 21st century</h4>
      <p>You are a young adult. You are upset about things going on in America. Maybe you are angry, scared, confused, depressed -- or maybe you feel a strange joy about everything burning down (I've certainly felt that). Maybe you're just so burned out from the insanity that is American politics that you just feel nothing at all anymore.</p>

      <p>Maybe you have some ideas on how to fix things; maybe if everyone adopted the tenets of Marxist socialism, everything would be solved. Maybe big government is the problem; if everyone with power and wealth just left us alone, we could fend for ourselves in peace. Maybe you're already doing good work at a business, philanthropy, or in the government, but you're troubled at how out-of-touch the rest of America seems. Maybe you've been radicalized into a weird internet philosophy, like neoreaction, or you listen to popular cathartic podcasts like <em>Chapo Trap House</em> (I love those guys).</p>

      <p>Maybe you don't have any ideas. You keep your head down, try to avoid the news and politics, and just focus on your work, your friends, and your health (good response, IMO!). Maybe you're so utterly depressed about everything that you've become a <a href="https://www.youtube.com/watch?v=x9yQhJ02Zbc">doomer</a>; you just want to see everything crumble, and the only activity you have energy for is laying down and rotting (trust me, been there too).</p>
      <p>I'm here to tell you that Iâ€¦â€¦...have absolutely no idea how to fix anything. Honestly, we're probably boned.</p>
      <p>The events of 2020 -- covid, BLM, whatever the hell is going on in Washington DC -- have just been mind-boggling, depressing, and terrifying beyond comprehension. Even worse, 2020 has arrived after decades of deterioration of American ideas and institutions; on the global stage, we are now a complete joke. Especially in the eyes of China; a rising great power that challenges us in ways we've never had to contend with before.</p>
      <p>I don't know how to fix America. But I do know one thing -- the boomers probably won't pull us out of this one. I have no problem with boomers; they're just old people, and eventually, boomerdom will come for us all. They've spent all their lives fighting the battles of the 20th century, and their efforts have kept us safe* and (relatively***) prosperous, while we watch Twitch streams, struggle to find a rewarding career, try to find love, and argue with each other about how best we should treat everybody.</p>
      <p>And honestly? None of this was our fault. We were just kids, teengaers, and fresh college graduates, as the grownups -- likely through benign negligence -- careened American society into the ground. But every year that passes, and the gerontocracy continues to prove its inability to deal with the 21st century (especially with the rise of digital technology), <br><strong>it increasingly becomes our responsibility to fix it.</strong></p>
      <p>Young people are way smarter, more empathetic, and more capable than the old guard imagine. I have some measure of faith that we'll eventually figure it out. But the boomers have one big advantage over us; they are, for the very large part, masters of practicing <em>civility</em>.</p>
      <p>This webpage is a short series of essays on the concept of <em>civics</em>, specifically targeted to the young adults of America. Briefly put, civics is the art of getting along in a democracy. It's quite possible that democracy itself is over (we discuss this in length in the last piece). But for now, if young people want to make effective change, and to make our slice of the world a better place, we need to practice being good citizens. These essays contain some ideas on how we might start doing that.</p>
      <p>==</p>
      <p>This series contains five main parts. It starts with a meditation on <em>black lives matter</em>. The brutal murder of George Floyd kicked off an incredible display of patriotic energy, setting off a series of dizzying events in June. It was this event that inspired me to begin writing; I wanted to do something, but couldn't clarify exactly what I could positively contribute. By the way; black lives matter. It's okay to say it.</p>
      <p>The second essay is a whirlwind tour of the critical -- and potentially lethal -- multitude of crises we face as a society. Many of these issues are purposefully downplayed in popular media, with the (admirable) intent of protecting people from mass panic. I actually agree with the principle of preventing mass panic, but at some point, we will have to learn about and face these problems head on. (If you're not used to ruminating on the collapse of civilization, this essay has the potential to cause anxiety). The second part addresses what we can do about it; the short answer is, mostly nothing.</p>
      <p>The third essay is actually a bit of a detour (this was originally supposed to be three parts), on recent developments in a niche internet community I've been a part of for years. If you want a window into the digital culture that raised me personally, this essay could be illustrative. It also contains some general considerations on the trials and tribulations of being an influential public figure. (In short, it's bad; if you can at all help it, don't become a public figure).</p>
      <p>The fourth essay ends with a grand discussion of different types of political systems. American-style democracy, for all the good it has done, is still just an experiment. It might not actually be around forever. We consider the alternative of totalitarianism, which is the logical step backwards if democratic-style governance proves itself to be ultimately infeasible. The meat of my argument is here; what it means to be a good citizen, and how we might get there.</p>
      <p>Finally, I say a few words on something very important to me.</p>
      <p>==</p>
      <p>Here are the essays. You can read them in any order; it might actually be best to start with part 4, since it contains the most actually new ideas -- if you're already familiar with how screwed we are, part 2 is mostly just a recap. I would love to hear any feedback, thoughts, or ideas you have when reading this; my contact information is at the bottom.</p>
      <div id="table-of-contents">
        <p><a href="https://cjohnson.io/civics/black-lives-matter">Part 1 [Prelude]</a>: Black lives matter</p>
        <p><a href="https://cjohnson.io/civics/america-in-2020">Part 2</a>: The state of America in 2020</p>
        <p><a href="https://cjohnson.io/civics/movements-and-communities">Part 2.5</a>: Movements vs communities</p>
        <p><a href="https://cjohnson.io/civics/scott-alexander">Part 3 [Interlude]</a>: The case of Scott Alexander</p>
        <p><a href="https://cjohnson.io/civics/on-good-citizens">Part 4</a>: On being a good citizen</p>
        <p><a href="https://cjohnson.io/civics/christianity">Part 5</a>: A brief note on Christianity</p>
        <p><a href="https://cjohnson.io/civics/writing">[Postlude 1]</a>: On writing</p>
        <p><a href="https://cjohnson.io/civics/philosophy">[Postlude 2]</a>: On philosophy</p>
      </div>
      <p>==</p>
      <p>General disclaimer on writing: I write in a very dense, long-winded style. I use some internet slang, some cuss words, and lots of ideas and concepts that are defined elsewhere. If you don't know what something means, try Googling it.</p>
      <p>Overall, I recommend going slow; this will probably take at least an hour to read, and many of the things I talk about are just poorly-defined shorthands for much larger discussions that have happened in the past, or in other forums. Feel free to skip over any section that seems confusing or weird. Finally, my advice for dense writing in general; it is best consumed sober.</p>
      <p>Thanks, and I hope you enjoy. If you want to connect, you can find me on Twitter at @spiderfoods, or you can send an email to inbox@cjohnson.io.</p>
    </div></div>]]>
            </description>
            <link>https://cjohnson.io/civics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23744433</guid>
            <pubDate>Mon, 06 Jul 2020 03:31:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spot the Difference: Leaking Metadata Warning]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23744222">thread link</a>) | @rwoll
<br/>
July 5, 2020 | https://theinternetbytes.com/2020/07/05/spot-the-difference-leaking-metadata-awareness/ | <a href="https://web.archive.org/web/*/https://theinternetbytes.com/2020/07/05/spot-the-difference-leaking-metadata-awareness/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <p>I took a picture of a pretty flower on my walk. When I got home, I logged on to
my email via a web browser and sent the picture (<code>original_flower.heic</code>) to a
privacy-focused friend along with a poem that I hoped they would enjoy.
They responded with a puzzle:</p>

<blockquote>
<p>Your photo (<code>original_flower.heic</code>) is attached along with another photo (<code>updated_flower.heic</code>) that’s nearly identical.</p>

<p>Spot the difference! :)</p>
</blockquote>

<p>Visually the photos looked identical. I confirmed their visual similarity via
a <a href="https://en.wikipedia.org/wiki/Perceptual_hashing">perceptual hashing</a> <a href="https://pypi.org/project/ImageHash/">tool</a>.
It wasn’t just my eyes! However, the hashes of the files themselves were different so
I suspected photo metadata must be different.
I ran the photos through <a href="https://exiftool.org/"><code>exiftool</code></a> and discovered the original photo I sent
(<code>original_flower.heic</code>) contained <strong>145</strong> different metadata attributes<sup id="fnref:1"><a href="#fn:1">1</a></sup> including
privacy-sensitive info like the time I took the photo and the exact location I took
the photos (i.e. GPS Coordinates) while the updated version (<code>updated_flower.heic</code>)
had most of these fields removed except for essential fields.</p>

<p>Most phones automatically record and embed sensitive time and location information
in photos and users unkowingly share this info with third-parties while only intending
to share the visual content of the photo. It would be helpful if the built-in photo
apps warn you when you are sharing a photo that this information will be sent and allow you to quickly remove it before
sharing. Additionally, browsers themselves should consider scanning files on upload
for sensitive metadata content and warn the user before completing the upload or provide a quick way for the sensitive info to be stripped right there in the upload dialog. (This would never be exhasutive, but
doing it for photos probably covers a lot of the cases where users accidentally share
more than they intended.)</p>

<p>If you are comfortable with the commandline, you can view photo metadata via:</p>

<pre><code>$ exiftool /path/to/photo.png
</code></pre>

<p>and remove non-essential fields via:</p>

<pre><code>$ exiftool -all= /path/to/photo.png
</code></pre>

<p>However, it would be neat to see OSes and browsers automatically provide this
option before data changes hands from the user to a third-party.</p>


    </section></div>]]>
            </description>
            <link>https://theinternetbytes.com/2020/07/05/spot-the-difference-leaking-metadata-awareness/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23744222</guid>
            <pubDate>Mon, 06 Jul 2020 02:51:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CoreBGP – Plugging in to BGP]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 8 (<a href="https://news.ycombinator.com/item?id=23744167">thread link</a>) | @jordanwhited
<br/>
July 5, 2020 | https://www.jordanwhited.com/posts/corebgp-plugging-in-to-bgp/ | <a href="https://web.archive.org/web/*/https://www.jordanwhited.com/posts/corebgp-plugging-in-to-bgp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<hr>
<p><img src="https://www.jordanwhited.com/posts/corebgp-plugging-in-to-bgp/cover.png" alt="cover"></p>
<hr>

<p><a href="https://tools.ietf.org/html/rfc4271" target="_blank">BGP</a> is one of many protocols that powers the Internet. Chances are you have heard of it, even if you don’t work in or around the computer networking space. If you aren’t familiar, I’ll try to provide some quick background:</p>
<ul>
<li>BGP is a <a href="https://en.wikipedia.org/wiki/Distance-vector_routing_protocol" target="_blank">distance-vector routing protocol</a> used to disseminate routing information.</li>
<li>A BGP speaker implements a <a href="https://en.wikipedia.org/wiki/Finite-state_machine" target="_blank">finite state machine</a> with 6 states:
<ul>
<li>Idle</li>
<li>Active</li>
<li>Connect</li>
<li>OpenSent</li>
<li>OpenConfirm</li>
<li>Established</li>
</ul>
</li>
<li>Inputs to the BGP FSM include messages, timer events, and administrative events.</li>
<li>Routing information is exchanged via UPDATE messages in the Established state.</li>
<li>BGP is extensible; speakers communicate their capabilities via OPEN messages.</li>
</ul>
<p>Expanding on that last bullet point, it’s difficult to summarize exactly how/where BGP is used due to its flexibility and extensibility. Various <a href="https://ietf.org/about/" target="_blank">IETF</a> Working Groups continue to publish BGP-related RFCs for a protocol that took shape in the early 90s. As the BGP landscape and application widens, we need software that enables us to keep up.</p>
<p>In this post I’ll provide some of my personal experience and history working with BGP, and introduce a new BGP library, <a href="https://github.com/jwhited/corebgp" target="_blank">CoreBGP</a>, which can be used to build the next generation of BGP-enabled applications.</p>

<p>In October of 2010 I attended my first <a href="https://www.nanog.org/" target="_blank">NANOG</a> meeting in Atlanta, GA after accidentally falling into the position of Network Operations Engineer at work. I worked for a modest-sized hosting provider at the time, and was intrigued with BGP. Upon arriving in Atlanta, I vaguely remember some confusion after telling a cab driver that the hotel I needed to be dropped at was on Peachtree St. I later learned that there are 71 streets in Atlanta with a variant of “Peachtree” in their name, according to <a href="https://en.wikipedia.org/wiki/Peachtree_Street#Nomenclature" target="_blank">Wikpedia</a>.</p>
<p>I got where I needed to go, eventually, and the first talk I attended was <a href="https://archive.nanog.org/meetings/nanog50/presentations/Sunday/NANOG50.Talk33.NANOG50-BGP-Techniques.pdf" target="_blank">BGP techniques for Internet Service Providers</a> by <a href="http://www.bgp4all.com.au/" target="_blank">Philip Smith</a>. Philip started with the basics before getting into the techniques used at ISPs. So many light bulbs went off for me during this talk. I have yet to see any other BGP presentation cover such a breadth of information but still do it in a way that is beginner-friendly, useful as a refresher for any expert, and just downright interesting.</p>
<p>Fast-forward 10 years and I’ve gained a fair share of experience operating networks that use BGP. In more recent years I’ve shifted to software engineering where I’ve had the opportunity to implement various BGP-enabled applications for network observability, data analytics, and SDN purposes.</p>
<p>Each time I started a new BGP-enabled app, I had to answer the following question – which existing BGP implementation should be its foundation?</p>

<p>Of the handful of open source BGP implementations out there, I’ve had hands-on experience with projects making use of:</p>
<ul>
<li><a href="https://bird.network.cz/" target="_blank">BIRD</a></li>
<li><a href="https://osrg.github.io/gobgp/" target="_blank">GoBGP</a></li>
<li><a href="https://www.opendaylight.org/what-we-do/odl-platform-overview" target="_blank">OpenDaylight</a></li>
<li><a href="https://www.quagga.net/" target="_blank">Quagga</a></li>
</ul>
<p>BIRD shines where a <a href="https://bird.network.cz/?get_doc&amp;v=20&amp;f=bird-5.html" target="_blank">rich policy language</a> is needed. GoBGP has a <a href="https://github.com/osrg/gobgp/tree/master/api" target="_blank">feature-rich gRPC API</a>, and can be embedded as a library. OpenDaylight’s BGP implementation is part of a larger SDN controller solution and has extensive support for <a href="https://docs.opendaylight.org/en/stable-oxygen/user-guide/bgpcep-guide/bgp/bgp-user-guide-linkstate-family.html" target="_blank">BGP-LS</a>. Quagga can reliably produce <a href="https://tools.ietf.org/html/rfc6396" target="_blank">MRT</a> dumps and has been around a long time, though I believe <a href="https://frrouting.org/" target="_blank">FRRouting</a> is now considered its successor.</p>
<p>These are all mature, established implementations. Some of them are in production at large ISPs, <a href="https://www.digitalocean.com/blog/scaling-droplet-public-networking/" target="_blank">Cloud Providers</a>, and <a href="https://joinup.ec.europa.eu/collection/open-source-observatory-osor/document/bird-manages-routing-worlds-largest-internet-exchanges-bird" target="_blank">Internet Exchange Points</a>. They are purpose-built and make various tradeoffs to suit their use cases (programming language, threading model, data structures, API, etc…).</p>
<p>But what if we are building something that doesn’t line up with the primary use cases of these widely used implementations? We may be locked in to decisions that are ultimately burdensome if we choose to build around them. Swapping in our own data structures for routing tables, or adding a new NLRI is non-trivial. Even if an implementation is intended to be embedded as library, it can still back us into a corner with resource consumption. There’s clearly a need to plug in or hook into specific parts of the BGP FSM, without inheriting decisions that went into a full-blown BGP daemon.</p>
<p>At the 27th IEEE International Conference On Network Protocols (ICNP), a group from the Université catholique de Louvain presented a paper on <code>The Case for Pluginized Routing Protocols</code>:</p>
<blockquote>
<p>Abstract—Routing protocols such as BGP and OSPF are key components of Internet Service Provider (ISP) networks. These protocols and the operator’s requirements evolve over time, but it often takes many years for network operators to convince their different router vendors and the IETF to extend routing protocols. Some network operators, notably in enterprise and datacenters have adopted Software Defined Networking (SDN) with its centralised control to be more agile. We propose a new approach to implement routing protocols that enables network operators to innovate while still using distributed routing protocols and thus keeping all their benefits compared to centralised routing approaches. We extend a routing protocol with a virtual machine that is capable of executing plugins. These plugins extend the protocol or modify its underlying algorithms through a simple API to meet the specific requirements of operators. We modify the OSPF and BGP implementations provided by FRRouting and demonstrate the applicability of our approach with several use cases.</p>
<p>— <!-- raw HTML omitted -->The Case for Pluginized Routing Protocols<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup><!-- raw HTML omitted --></p>
</blockquote>
<p>In their paper they present a method for plugging into a previously mentioned open-source BGP implementation, FRRouting. Plugins exist at a function level, either prior to invocation (PRE), as a replacement (REPLACE), or just before returning (POST). Much of their BGP plugin focus is around the reception of messages, and decisions made shortly after:</p>
<blockquote>
<p>The BGP daemon is also extended similarly. We add insertion points on functions receiving BGP messages from neighbours, on filters and inside the decision process. We also expose specific functions to the plugins that are executed by the uBPF VM.</p>
<p>— <!-- raw HTML omitted -->The Case for Pluginized Routing Protocols<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup><!-- raw HTML omitted --></p>
</blockquote>
<p>They take a clever approach with plugin sandboxing by leveraging a user space eBPF VM (<a href="https://github.com/iovisor/ubpf" target="_blank">uBPF</a>) linked to the FRRouting protocol implementation. Each plugin compiles to eBPF bytecode and runs inside of said VM. Plugins can be loaded and unloaded without impacting the primary protocol implementation. Using an eBPF VM also allowed them to utilise all the pre-existing Linux Kernel tooling.</p>
<p>I found this approach inspiring, but still not quite a match for my use cases:</p>
<ul>
<li>Plugins appear to be built around “incoming” events, or messages. What if I want to inject an UPDATE message to a peer irrespective of what FRRouting wants to send?</li>
<li>FRRouting was not built with this plugin model in mind. Changes/Updates to FRRouting will result in a maintenance headache for the VM hook points.</li>
<li>eBPF bytecode is typically compiled from C. Writing C can be time-consuming in comparison to more modern languages.</li>
<li>I need to be an FRRouting expert to do anything non-trivial.</li>
</ul>
<p>This experience and research led me to create CoreBGP, a BGP library that I could re-use across my BGP-enabled applications.</p>

<p>CoreBGP is a BGP library written in Go that implements the BGP FSM with an event-driven, pluggable model. It exposes an API that empowers the user to:</p>
<ul>
<li>send and validate OPEN message capabilities</li>
<li>handle “important” state transitions</li>
<li>handle incoming UPDATE messages</li>
<li>send outgoing UPDATE messages</li>
</ul>
<p>CoreBGP does not decode UPDATE messages (besides header validation), manage a routing table, or send its own UPDATE messages. These responsibilities are all passed down to the user. Therefore, the intended user is someone who wants that responsibility.</p>
<p>The primary building block of CoreBGP is a Plugin, defined by the following interface:</p>
<div><pre><code data-lang="go"><span>// Plugin is a BGP peer plugin.
</span><span></span><span>type</span> Plugin <span>interface</span> {
	<span>// GetCapabilities is fired when a peer's FSM is in the Connect state prior
</span><span></span>	<span>// to sending an Open message. The returned capabilities are included in the
</span><span></span>	<span>// Open message sent to the peer.
</span><span></span>	<span>GetCapabilities</span>(peer <span>*</span>PeerConfig) []<span>*</span>Capability

	<span>// OnOpenMessage is fired when an Open message is received from a peer
</span><span></span>	<span>// during the OpenSent state. Returning a non-nil Notification will cause it
</span><span></span>	<span>// to be sent to the peer and the FSM will transition to the Idle state.
</span><span></span>	<span>//
</span><span></span>	<span>// Per RFC5492 a BGP speaker should only send a Notification if a required
</span><span></span>	<span>// capability is missing; unknown or unsupported capabilities should be
</span><span></span>	<span>// ignored.
</span><span></span>	<span>OnOpenMessage</span>(peer <span>*</span>PeerConfig, capabilities []<span>*</span>Capability) <span>*</span>Notification

	<span>// OnEstablished is fired when a peer's FSM transitions to the Established
</span><span></span>	<span>// state. The returned UpdateMessageHandler will be fired when an Update
</span><span></span>	<span>// message is received from the peer.
</span><span></span>	<span>//
</span><span></span>	<span>// The provided writer can be used to send Update messages to the peer for
</span><span></span>	<span>// the lifetime of the FSM's current, established state. It should be
</span><span></span>	<span>// discarded once OnClose() fires.
</span><span></span>	<span>OnEstablished</span>(peer <span>*</span>PeerConfig, writer UpdateMessageWriter) UpdateMessageHandler

	<span>// OnClose is fired when a peer's FSM transitions out of the Established
</span><span></span>	<span>// state.
</span><span></span>	<span>OnClose</span>(peer <span>*</span>PeerConfig)
}
</code></pre></div><p>Here’s an example Plugin that logs when a peer enters/leaves an established state and when an UPDATE message is received:</p>
<div><pre><code data-lang="go"><span>type</span> plugin <span>struct</span>{}

<span>func</span> (p <span>*</span>plugin) <span>GetCapabilities</span>(c <span>*</span>corebgp.PeerConfig) []<span>*</span>corebgp.Capability {
	caps <span>:=</span> <span>make</span>([]<span>*</span>corebgp.Capability, <span>0</span>)
	<span>return</span> caps
}

<span>func</span> (p <span>*</span>plugin) <span>OnOpenMessage</span>(peer <span>*</span>corebgp.PeerConfig, capabilities []<span>*</span>corebgp.Capability) <span>*</span>corebgp.Notification {
	<span>return</span> <span>nil</span>
}

<span>func</span> (p <span>*</span>plugin) <span>OnEstablished</span>(peer <span>*</span>corebgp.PeerConfig, writer corebgp.UpdateMessageWriter) corebgp.UpdateMessageHandler {
	log.<span>Println</span>(<span>"peer established"</span>)
	<span>// send End-of-Rib
</span><span></span>	writer.<span>WriteUpdate</span>([]<span>byte</span>{<span>0</span>, <span>0</span>, <span>0</span>, <span>0</span>})
	<span>return</span> p.handleUpdate
}

<span>func</span> (p <span>*</span>plugin) <span>OnClose</span>(peer <span>*</span>corebgp.PeerConfig) {
	log.<span>Println</span>(<span>"peer closed"</span>)
}

<span>func</span> (p <span>*</span>plugin) <span>handleUpdate</span>(peer <span>*</span>corebgp.PeerConfig, u []<span>byte</span>) <span>*</span>corebgp.Notification {
	log.<span>Printf</span>(<span>"got update message of len: %d"</span>, <span>len</span>(u))
	<span>return</span> <span>nil</span>
}
</code></pre></div><p>Plugins are attached to peers when they are added to the Server, which manages their lifetime:</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.jordanwhited.com/posts/corebgp-plugging-in-to-bgp/">https://www.jordanwhited.com/posts/corebgp-plugging-in-to-bgp/</a></em></p>]]>
            </description>
            <link>https://www.jordanwhited.com/posts/corebgp-plugging-in-to-bgp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23744167</guid>
            <pubDate>Mon, 06 Jul 2020 02:39:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Forecasting the Weather with Neural Odes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23743860">thread link</a>) | @ChrisRackauckas
<br/>
July 5, 2020 | https://sebastiancallh.github.io/post/neural-ode-weather-forecast/ | <a href="https://web.archive.org/web/*/https://sebastiancallh.github.io/post/neural-ode-weather-forecast/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<p>Weather forecasting is a tricky problem. Traditionally, it has been done
by manually modelling weather dynamics using differential equations, but this
approach is highly dependent on us getting the equations right. To
avoid this problem, we can
use machine learning to <a href="https://ai.googleblog.com/2020/03/a-neural-weather-model-for-eight-hour.html" target="_blank">directly predict the weather</a>, which
let’s us make predictions without modelling the dynamics. However, this
approach requires huge amounts of data to reach good performance.
Fortunately, there is a middle ground: What if we instead use machine
learning to model the <em>dynamics</em> of the weather?</p>

<p>Instead of trying to model how the weather will look in the next time step, what if
we instead model how the weather changes between time steps? More concretely: What if we
learn the <em>differential equations</em> that govern the change in weather?
In this blog article we are going to use <a href="https://julialang.org/" target="_blank">Julia</a> and the <a href="https://github.com/SciML" target="_blank">SciML</a> ecosystem
to do just that. We are going to see how neural ordinary differential
equations (neural ODEs) relate to “regular” networks, how to train
them and see how they can extrapolate time series from just a tiny
amount of training data.</p>

<h2 id="neural-odes-for-time-series">Neural ODEs for time series</h2>

<p>To start us off, let’s talk about how <a href="https://arxiv.org/abs/1806.07366" target="_blank">neural ODEs</a> are used for time
series modeling.
Recall that in a standard machine learning setting we
would assume a discrete set of observations \(y_0, y_1, \dots y_k, \)  \( y_i \in
\mathbb{R}^n \) at time points
\(t_0, t_1, \dots t_k, \), \(t_i \in \mathbb{R} \) to be related through some function \( y_i =
f(t_i; \theta) \) where \( \theta \) are learnable parameters.
However, in a neural ODE we consider a continuous setting and
instead assume that the <em>change</em> in \(y\) is governed by an ODE</p>

<p>\[ \frac{\delta y}{\delta t} = f(y; \theta). \]</p>

<p>The goal is hence not to learn the relationship between \(y\) and
\(t\), but the underlying dynamics of change. If the
dynamics are constant, this has very powerful generalisation capabilities.
It is helpful to think of this formulation as “a neural network inside
an ODE” or maybe “an ODE with learnable parameters”. In fact, the “forward pass”
through a neural ODE is exactly solving an <a href="https://en.wikipedia.org/wiki/Initial%5Fvalue%5Fproblem" target="_blank">initial value problem</a>,
where \( y(t_0) \) is the input features and we replace hand-crafted
equations with a neural network. This means that a <em>single</em>
forward pass gives us an entire trajectory in contrast to e.g. <a href="https://www.deeplearningbook.org/contents/rnn.html" target="_blank">RNN</a>s,
where each forward pass through the model gives a single prediction.</p>

<p>To make this more concrete,
consider a forward pass for \(y(t_0) =
1.0\) where the model has been trained on \(f^{\star}(x) =
\exp(1.5x)\). A forward pass means inputting \(y(t_0)\) and then using
an ODE solver to step forward in time. When the ODE solver
evaluates \(f\), it uses a neural network to predict \( \frac{\delta y}{\delta t} \).</p>

<figure>
    <img src="https://sebastiancallh.github.io/ox-hugo/neural-ode-explanation.gif" alt="Figure 1: Solving a simple initial value problem using a trained neural ODE. The only difference from a &amp;ldquo;regular&amp;rdquo; initial value problem is that the ODE is governed by a neural network instead of a hand-crafted set of equations. Since the network has already been trained, it accurately model dynamics."> <figcaption>
            <p>Figure 1: Solving a simple initial value problem using a trained neural ODE. The only difference from a “regular” initial value problem is that the ODE is governed by a neural network instead of a hand-crafted set of equations. Since the network has already been trained, it accurately model dynamics.</p>
        </figcaption>
</figure>


<p>So how do we train a network inside an ODE? As long as we can
take gradients of \(\theta\) with respect to the loss we can train it
using standard gradient based methods. Fortunately,
<code>DiffEqFlux</code> takes care of everything required to do this for us.
There are <a href="https://docs.sciml.ai/latest/analysis/sensitivity/#Sensitivity-Algorithms-1" target="_blank">several strategies</a> that can be specified to compute
gradients, and depending on
the problem you might prefer one over the other. However, for this article
the default <code>InterpolatingAdjoint</code> will be perfectly fine.</p>

<h3 id="model-implementation">Model implementation</h3>

<p>Now that we have a good conceptual idea of the model, let’s see it
in practice. We are going to use <a href="https://github.com/JuliaDiffEq/DiffEqFlux.jl" target="_blank">DiffEqFlux</a> to do the heavy lifting, which combines the ODE
solvers of <a href="https://github.com/SciML/DifferentialEquations.jl" target="_blank">DifferentialEquations.jl</a> with the differentiable
programming capabilities of <a href="https://github.com/FluxML/Flux.jl" target="_blank">Flux.jl</a>. Using <code>DiffEqFlux</code>, we can simply
construct a neural network to model \(f\) and plug that into a <code>NeuralODE</code>
object. The <code>NeuralODE</code> object itself has a few additional important
hyper-parameters though. Firstly, we have to <a href="https://docs.sciml.ai/stable/solvers/ode%5Fsolve/" target="_blank">specify an ODE solver</a> and a time span to
solve on. We will use the <code>Tsit5</code> solver, which uses an explicit
method. Secondly, the parameters <code>reltol</code> and <code>abstol</code> let us configure the solution
error tolerance to trade off accuracy and training time.
Recall that a forward pass means solving an initial value problem,
hence a lower tolerance gives a more accurate solution, and in turn
better gradient estimates. But of course, this requires
more function evaluations and are consequently slower to compute.</p>


<div><pre><code data-lang="julia"><span>using</span> DiffEqFlux

<span>function</span> neural_ode(t, data_dim; saveat <span>=</span> t)
    f <span>=</span> FastChain(FastDense(data_dim, <span>32</span>, swish),
		     FastDense(<span>32</span>, <span>64</span>, swish),
		     FastDense(<span>64</span>, <span>32</span>, swish),
		     FastDense(<span>32</span>, data_dim))

    node <span>=</span> NeuralODE(f, (minimum(t), maximum(t)), Tsit5(),
		     saveat <span>=</span> saveat, abstol <span>=</span> <span>1e-9</span>,
		     reltol <span>=</span> <span>1e-9</span>)
<span>end</span></code></pre></div>
<h2 id="the-delhi-dataset">The Delhi dataset</h2>

<p>The <a href="https://www.kaggle.com/sumanthvrao/daily-climate-time-series-data" target="_blank">dataset</a> we are going to use comprises daily
measurements of the climate in Delhi over several years.
The entire dataset is a single time series, where the last part is
set aside for testing. We will combine both the train and test set though,
since we won’t even need half of the training set to fit a good model.
Let’s load up the data and visualize it.</p>


<div><pre><code data-lang="julia"><span>using</span> DataFrames, CSV
delhi_train <span>=</span> CSV<span>.</span>read(<span>"data/timeseries/dehli-temp/DailyDelhiClimateTrain.csv"</span>)
delhi_test <span>=</span> CSV<span>.</span>read(<span>"data/timeseries/dehli-temp/DailyDelhiClimateTest.csv"</span>)
delhi <span>=</span> vcat(delhi_train, delhi_test)</code></pre></div>
<figure>
    <img src="https://sebastiancallh.github.io/ox-hugo/delhi-data-visualisation.svg" alt="Figure 2: Visualisation of the raw data. There is a clear seasonal trend, but there are some extreme outliers among the pressure measurements, which make it difficult to see any patterns."> <figcaption>
            <p>Figure 2: Visualisation of the raw data. There is a clear seasonal trend, but there are some extreme outliers among the pressure measurements, which make it difficult to see any patterns.</p>
        </figcaption>
</figure>


<p>Something is off with the air pressure measurements, indicated by the
extreme outliers after 2016. However, prior to 2016 the measurements
show a nice periodic behavior.</p>

<figure>
    <img src="https://sebastiancallh.github.io/ox-hugo/pressure-prior-2016.svg" alt="Figure 3: Zooming in on the pressure before 2016 reveal the same pleasant seasonal behavior as in the other measurements."> <figcaption>
            <p>Figure 3: Zooming in on the pressure before 2016 reveal the same pleasant seasonal behavior as in the other measurements.</p>
        </figcaption>
</figure>


<p>As an aside, if you read the dataset description it claims that the <code>Mean pressure</code>
variable is measured in <a href="https://en.wikipedia.org/wiki/Standard%5Fatmosphere%5F(unit)" target="_blank">atm</a>. Now, I have never been to Delhi, but I have my doubts since that would
mean that the city of Delhi suffers under a <em>thousand atmospheres
worth of pressure</em>. While such a phenomenon would be pretty cool and without a doubt get
scientists excited, I think it is more likely the units simply got mixed up, and the
actual unit pressure is millibar. Anyway, let’s prepare the data for model training.</p>

<h3 id="data-pre-processing">Data pre-processing</h3>

<p>All the metrics vary a lot from day to day, so to emphasis the overall
trend in the data we will average the observations into months.</p>


<div><pre><code data-lang="julia"><span>using</span> Statistics
<span>using</span> Base<span>.</span>Iterators<span>:</span> take, cycle

delhi[<span>:</span>,<span>:</span>year] <span>=</span> <span>Float64</span><span>.</span>(year<span>.</span>(delhi[<span>:</span>,<span>:</span>date]))
delhi[<span>:</span>,<span>:</span>month] <span>=</span> <span>Float64</span><span>.</span>(month<span>.</span>(delhi[<span>:</span>,<span>:</span>date]))
df_mean <span>=</span> by(delhi,
	     [<span>:</span>year, <span>:</span>month],
	     <span>:</span>meantemp <span>=&gt;</span> mean,
	     <span>:</span>humidity <span>=&gt;</span> mean,
	     <span>:</span>wind_speed <span>=&gt;</span> mean,
	     <span>:</span>meanpressure <span>=&gt;</span> mean)
rename!(df_mean, [<span>:</span>year, <span>:</span>month, <span>:</span>meantemp,
		  <span>:</span>humidity, <span>:</span>wind_speed, <span>:</span>meanpressure])

df_mean[<span>!</span>,<span>:</span>date] <span>.=</span> df_mean[<span>:</span>,<span>:</span>year] <span>.+</span> df_mean[<span>:</span>,<span>:</span>month] <span>./</span> <span>12</span>;</code></pre></div>
<p>In addition to averaging, we will normalize the data. The features are
normalized to have zero mean and unit variance, and the temporal
dimension is shifted to start at \(0\). Finally, we take the first
\(20\) observations as our training data and leave the remaining for testing.</p>


<div><pre><code data-lang="julia">t <span>=</span> df_mean[<span>:</span>, <span>:</span>date] <span>|&gt;</span>
    t <span>-&gt;</span> t <span>.-</span> minimum(t) <span>|&gt;</span>
    t <span>-&gt;</span> reshape(t, <span>1</span>, <span>:</span>)

y <span>=</span> df_mean[<span>:</span>, features] <span>|&gt;</span>
    y <span>-&gt;</span> <span>Matrix</span>(y)<span>'</span> <span>|&gt;</span>
    y <span>-&gt;</span> (y <span>.-</span> mean(y, dims <span>=</span> <span>2</span>)) <span>./</span> std(y, dims <span>=</span> <span>2</span>)

T <span>=</span> <span>20</span>
train_dates <span>=</span> df_mean[<span>1</span><span>:</span>T, <span>:</span>date]
test_dates <span>=</span> df_mean[T<span>+</span><span>1</span><span>:</span><span>end</span>, <span>:</span>date]
train_t, test_t <span>=</span> t[<span>1</span><span>:</span>T], t[T<span>:</span><span>end</span>]
train_y, test_y <span>=</span> y[<span>:</span>,<span>1</span><span>:</span>T], y[<span>:</span>,T<span>:</span><span>end</span>];</code></pre></div>
<figure>
    <img src="https://sebastiancallh.github.io/ox-hugo/delhi-data-split.svg" alt="Figure 4: The normalized data split into test and train. This is what the model will &amp;ldquo;see&amp;rdquo; during training and evaluation."> <figcaption>
            <p>Figure 4: The normalized data split into test and train. This is what the model will “see” during training and evaluation.</p>
        </figcaption>
</figure>


<p>Since we are training our model using gradient descent, we run the
risk of getting stuck into a bad local minima. This is particularly
true when training on a periodic time series, since the model can easily
settle with predicting the time series mean. Mini-batching can be used to mitigate
this, but for this problem we are going to employ a <a href="https://diffeqflux.sciml.ai/dev/examples/local%5Fminima/" target="_blank">different method</a>.
We are going to train on the first couple of observations until
convergence, then introduce a few more observations. Then train until
convergence, introduce some more observations, etc… By doing this, we
let the model adapt to local changes, resulting in a better fit. The
code below implements this training procedure.</p>


<div><pre><code data-lang="julia"><span>using</span> OrdinaryDiffEq, Flux, Optim, CUDA, Random
CUDA<span>.</span>allowscalar(<span>false</span>)

<span>function</span> train(node, t, y, y0, θ <span>=</span> <span>nothing</span>; maxiters, lr)
    predict(θ) <span>=</span> <span>Array</span>(node(y0, θ))
    loss(θ) <span>=</span> <span>begin</span>
	    ŷ <span>=</span> predict(θ)
	    l <span>=</span> Flux<span>.</span>mse(ŷ, y)
	    <span>return</span> l, ŷ
    <span>end</span>

    losses <span>=</span> []
    params <span>=</span> []
    cb(θ, l, ŷ) <span>=</span> <span>begin</span>
	    push!(losses, l)
	    push!(params, copy(θ))
	    <span>false</span>
    <span>end</span>

    θ <span>=</span> θ <span>==</span> <span>nothing</span> <span>?</span> node<span>.</span>p <span>:</span> θ
    res <span>=</span> DiffEqFlux<span>.</span>sciml_train(loss, θ, ADAMW(lr),
				 maxiters <span>=</span> maxiters,
				 cb <span>=</span> cb, save_best <span>=</span> <span>true</span>)
    <span>return</span> res<span>.</span>minimizer, losses, params
<span>end</span>

Random<span>.</span>seed!(<span>1</span>);
y0 <span>=</span> train_y[<span>:</span>,<span>1</span>]
maxiters <span>=</span> <span>200</span>
losses <span>=</span> []
θs <span>=</span> []
θ <span>=</span> <span>nothing</span>
num_obs <span>=</span> <span>4</span><span>:</span><span>4</span><span>:</span>length(train_t)
<span>for</span> k <span>in</span> num_obs
    node <span>=</span> neural_ode(train_t[<span>1</span><span>:</span>k], size(y, <span>1</span>))
    θ, loss, param <span>=</span> train(node, train_t[<span>1</span><span>:</span>k], train_y[<span>:</span>,<span>1</span><span>:</span>k], y0, θ,
			   maxiters <span>=</span> maxiters, lr <span>=</span> <span>5e-3</span>);
    losses <span>=</span> vcat(losses, loss)
    θs <span>=</span> vcat(θs, param)
<span>end</span></code></pre></div>
<figure>
    <img src="https://sebastiancallh.github.io/ox-hugo/delhi-training2.gif" alt="Figure 5: Animation of training through incrementally adding observations. When new observations are added the loss curve makes a sudden jump, but quickly settles down again. This process successfully avoids bad local minima and results in a very nice fit."> <figcaption>
            <p>Figure 5: Animation of training through incrementally adding observations. When new observations are added the loss curve makes a sudden jump, but quickly settles down again. This process successfully avoids bad local minima and results in a very nice fit.</p>
        </figcaption>
</figure>


<p>The model trains in a minute or two and fits nicely to the training data.
Of course, a more interesting question is whether the model
generalises or not. We solve the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sebastiancallh.github.io/post/neural-ode-weather-forecast/">https://sebastiancallh.github.io/post/neural-ode-weather-forecast/</a></em></p>]]>
            </description>
            <link>https://sebastiancallh.github.io/post/neural-ode-weather-forecast/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23743860</guid>
            <pubDate>Mon, 06 Jul 2020 01:38:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What should we do about network-effect monopolies]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23743610">thread link</a>) | @dmnd
<br/>
July 5, 2020 | https://www.benkuhn.net/nwe/ | <a href="https://web.archive.org/web/*/https://www.benkuhn.net/nwe/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Many large companies today are software monopolies that give their product away for free to get monopoly status, then do <a href="https://github.com/uBlockOrigin/uBlock-issues/issues/338#issuecomment-496009417" target="_blank">the</a> <a href="http://www.fbpurity.com/news/important-news-facebooks-legal-team-have-told-me-i-am-banned-from-facebook-because-of-f-b-purity/" target="_blank">most</a> <a href="https://www.theverge.com/2019/6/28/19154220/grubhub-seamless-fake-restaurant-domain-names-commission-fees" target="_blank">horrible</a> <a href="https://www.nytimes.com/wirecutter/blog/amazon-counterfeit-fake-products/" target="_blank">things</a> <a href="https://www.theverge.com/2020/6/16/21293419/hey-apple-rejection-ios-app-store-dhh-gangsters-antitrust" target="_blank">once</a> <a href="https://www.polemicdigital.com/google-amp-go-to-hell/" target="_blank">they’ve</a> <a href="https://thetechnoskeptic.com/yelp-extortion-starring-role/" target="_blank">won</a>. (<a href="https://www.benkuhn.net/skinner/">Previously</a>, <a href="https://www.benkuhn.net/product/">previously</a>.) Can we do anything about this?</p><p>Unfortunately, “you’re the product” is a popular business model for a reason: businesses like Facebook would be really hard to support without them.</p><p>Facebook would be suicidal to charge its users money, because its entire selling point is that everyone uses it, and “everyone” <em>hates</em> paying money. In the US, Facebook makes over $25 per person on ads (<a href="https://www.statista.com/statistics/251328/facebooks-average-revenue-per-user-by-region/" target="_blank">source</a>). Can you imagine if instead of ads they tried to charge people $25 a year?</p><p>Even on the margin, anything that costs Facebook users also makes it less valuable for its remaining users—it’s a negative feedback loop. The same goes for any other site where users create value for other users, like Twitter or Craigslist or Yelp or Wikipedia. (It’s not an accident that these are some of the most stagnant popular websites!)</p><p>In fact, this is a fundamental problem with <a href="https://en.wikipedia.org/wiki/Network_effect" target="_blank">network effects</a> and low marginal costs. If a company wants to maintain a network effect, they need as many users as possible. If their marginal cost is low, then the easiest way to get users is to give the product away. To do that, they have to get paid by someone else. And when they start getting paid by someone else, they’ll inevitably start prioritizing that person’s interests.</p><p>Historically with other network-effect businesses, we’ve addressed this in a few different ways:</p><ul><li><p>regulation (e.g. local utilities)</p></li><li><p>breakups (e.g. Bell)</p></li><li><p>standardization and interoperability (e.g. email, the Web, cryptocurrency)</p></li></ul><p>So far for tech monopolies, people seem to be focused mostly on breakups—e.g. Facebook from Instagram/Whatsapp—but standardization seems to have produced much better outcomes in the past. (I like email and the Web a lot more than National Grid…) I’d be interested to see more exploration of that option!</p></article></div>]]>
            </description>
            <link>https://www.benkuhn.net/nwe/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23743610</guid>
            <pubDate>Mon, 06 Jul 2020 00:46:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lorentz Transformation Derivation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23743557">thread link</a>) | @keyboardman
<br/>
July 5, 2020 | https://leimao.github.io/blog/Lorentz-Transformation-Derivation/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Lorentz-Transformation-Derivation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>In my previous blog post <a href="https://leimao.github.io/blog/Special-Relativity/">“Special Relativity Explained”</a>, I have explained special relativity and its several key consequences based on the Lorentz transformation.</p>



<p>Since I did not give a derivation for Lorentz transformation last time, in this blog post, I would like to present the derivations in detail.</p>

<h3 id="postulates-of-special-relativity">Postulates of Special Relativity</h3>

<p>Lorentz transformation was derived based on the following two postulates only.</p>

<h4 id="first-postulate-principle-of-relativity">First Postulate (Principle of Relativity)</h4>

<p>The laws of physics take the same form in all inertial frames of reference.</p>

<h4 id="second-postulate-invariance-of-light-speed">Second Postulate (Invariance of Light Speed)</h4>

<p>As measured in any inertial frame of reference, light is always propagated in empty space with a definite velocity $c$ that is independent of the state of motion of the emitting body. It is also equivalent to say, the speed of light in free space has the same value $c$ in all inertial frames of reference.</p>

<h3 id="derivation">Derivation</h3>

<p>In the spacetime, we have two reference frames, a reference frame $S$ and another reference frame $S’$ moving at a velocity $v$ with respect to it. So the two reference frames in this scenario are inertial reference frame. The coordinate axes in each reference frame are parallel, i.e., the $x$ and $x’$ axes are parallel, the $y$ and $y’$ axes are parallel, and the $z$ and $z’$ axes are parallel, and remain mutually perpendicular. We assume the relative motion is along the coincident $xx’$ axes. At $t = t’ = 0$, the origins of both coordinate systems are the same, $(x,y,z) = (x’,y’,z’) = (0, 0, 0)$.</p>



<p>An event in the time space could be observed and recorded by the observers on the two reference frames using spacetime coordinates $(t,x,y,z)$ in the reference frame $S$ and $(t’,x’,y’,z’)$ in the reference frame $S’$, respectively.</p>



<p>We want to set up the mapping between $(t,x,y,z)$ and $(t’,x’,y’,z’)$ for the same event.</p>

<h4 id="lorentz-transformation-is-linear-transformation">Lorentz Transformation is Linear Transformation</h4>

<p>We propose the spacetime transformation from the reference frame $S$ to the reference frame $S’$ to have the following form.</p>



<p>Note that we could eliminate the variables $y$ and $z$ in the functions $f_t$ and $f_x$ because of $y$ and $z$ are constants.</p>



<p>Now that we have proposed the form of transformation, there could be an infinite number of transformations that satisfied the form. What exactly the transformation is?</p>



<p>Suppose we have two events, one event has coordinates $(t_1,x_1,y_1,z_1)$ observed in the reference frame $S$ and coordinates $(t’_1,x’_1,y’_1,z’_1)$ observed in the reference frame $S’$, another one has coordinates $(t_2,x_2,y_2,z_2)$ observed in the reference frame $S$ and coordinates $(t’_2,x’_2,y’_2,z’_2)$ observed in the reference frame $S’$. Note that because reference frame $S’$ is moving along the $xx’$ axes, $y_1 = y’_1$, $z_1 = z’_1$, $y_2 = y’_2$, $z_2 = z’_2$.</p>



<p>Without loss of generality, we set $t_1 = t^{\prime}_1 = 0$, $x_1 = x^{\prime}_1 = 0$.</p>





<p>The two events, $(t_1,x_1,y_1,z_1)$ and $(t_2,x_2,y_2,z_2)$ observed in reference frame $S$, $(t’_1,x’_1,y’_1,z’_1)$ and $(t’_2,x’_2,y’_2,z’_2)$ observed in reference $S’$ have become equivalent to $(0,0,y_1,z_1)$ and $(\Delta t,\Delta x,y_2,z_2)$ observed in reference frame $S$, $(0,0,y’_1,z’_1)$ and $(\Delta t^{\prime},\Delta x^{\prime},y’_2,z’_2)$ observed in reference $S’$.</p>



<p>Based on the principle of relativity assumption, the transformation still holds. We have</p>



<p>and</p>



<p>This means the distances and time elapsed could also be transformed using the exact transformation for coordinates!</p>



<p>Ignoring uninteresting $y$ and $z$, we could equivalently write</p>





<p>We set a column vector $p = [t, x]^{\top}$ and this $p$ is a tensor in physics. It is also equivalent to write</p>



<p>This is also further equivalent to</p>



<p>In the next step, we would like to further show</p>



<p>Similarly suppose we have two events, one event has coordinates $(t_1,x_1,y_1,z_1)$ observed in the reference frame $S$ and coordinates $(t’_1,x’_1,y’_1,z’_1)$ observed in the reference frame $S’$, another one has coordinates $(t_2,x_2,y_2,z_2)$ observed in the reference frame $S$ and coordinates $(t’_2,x’_2,y’_2,z’_2)$ observed in the reference frame $S’$. In addition, in the reference frame it is observed that $t_2 = k t_1$ and $x_2 = k x_1$. Based on the principal of relativity assumption, $t’_2 = k t’_1$ and $x’_2 = k x’_1$.</p>



<p>Because</p>





<p>Therefore,</p>



<p>Because we have shown that</p>



<p>This is exactly the <a href="https://en.wikipedia.org/wiki/Linear_map#Definition_and_first_consequences">definition of a linear function</a> for function $f$ ($f_t$ and $f_x$), and note that this linear function $f$ has no bias term. Therefore, $f(p) = Mp$ for some matrix $M \in \mathbb{R}^{2 \times 2}$, and Lorentz transformation is a linear transformation.</p>

<h4 id="lorentz-transformation">Lorentz Transformation</h4>

<p>Because Lorentz transformation is a linear transformation, we could assume</p>



<p>Then the problem is very like the machine learning regression problem where we have to find the values for parameter $A$, $B$, $C$, and $D$. To solve this regression problem, we need some concrete data.</p>



<p>Because the reference frame $S’$ is moving at velocity $v$ with respect to the reference frame $S$. At time $t$ in the reference frame $S$ and $t’$ in the reference frame $S’$, we know $x = vt$ in the reference frame $S$ overlaps with the origin $x’ = 0$ in the reference frame $S’$. Note that $x = vt + 1$ in the reference frame $S$ does not necessary overlaps with $x’ = 1$ in the reference frame $S’$, although this is true in <a href="https://en.wikipedia.org/wiki/Galilean_transformation">Galilean transformations</a>.</p>



<p>We found the relationships between $C$ and $D$.</p>



<p>In addition, because the reference frame $S$ is moving at velocity $-v$ with respect to the reference frame $S’$. At time $t$ in the reference frame $S$ and $t’$ in the reference frame $S’$, we know $x = 0$ in the reference frame $S$ overlaps with the origin $x’ = -vt$ in the reference frame $S’$.</p>



<p>We cancel the variable $t’$ and get</p>



<p>So</p>



<p>This reduced the number of free parameters from four to two.</p>



<p>There could many different ways to derive the values for $B$ and $D$, but usually the simplest way is to directly do thought experiments using light. Here is one thought experiment, and there could be many others.</p>



<p>Suppose we shot a beam of light in the reference frame $S’$, At time $t$ in the reference frame $S$ and $t’$ in the reference frame $S’$, the event of the head of the light beam has $x = ct$ in the reference frame $S$ and reference $x’ = ct’$ frame $S’$, where $c$ is the light speed constant, based on the invariance of light speed assumption.</p>



<p>We cancel the variable $t’$ and get</p>



<p>We could then get the relationship between $B$ and $D$</p>



<p>Now the linear transformation has become</p>



<p>We are able to derive the inverse transformation as well.</p>



<p>That the reference frame $S’$ is moving at a velocity $v$ with respect to the reference frame $S$ is equivalent to that the reference frame $S$ is moving at a velocity $-v$ with respect to the reference frame $S’$. Based on the principle of relativity assumption, the linear transformation also has the same form, which is</p>



<p>This means that</p>



<p>Therefore,</p>



<p>We often use $\gamma$ to represent this factor, and this factor is called Lorentz factor.</p>



<p>The linear transformation is called Lorentz transformation.</p>



<p>We could further include the other two dimensions for $yy’$ and $zz’$.</p>



<p>Sometimes, to make the transformation matrix symmetric, we have the following equivalent form.</p>



<p>where</p>



<p>This concludes the derivation.</p>

<h3 id="conclusions">Conclusions</h3>

<p>The derivation of Lorentz transformation is mathematically simple. It only requires to use the basic linear algebra, or even just high school math. However, since the transformation is against our common sense, and the derivation is only based on the two “simple” postulates, we have to be aware not to introduce additional assumptions during derivation.</p>



<p>In high school physics class or college physics class for non-physics-major students, the lecturers would usually just present the Lorentz transformation and skip the derivation in the lectures for special relativity.</p>

      <hr>
      
    </div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/Lorentz-Transformation-Derivation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23743557</guid>
            <pubDate>Mon, 06 Jul 2020 00:36:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Minimum Viable Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23743502">thread link</a>) | @shosti
<br/>
July 5, 2020 | https://eevans.co/blog/minimum-viable-kubernetes/ | <a href="https://web.archive.org/web/*/https://eevans.co/blog/minimum-viable-kubernetes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
  <section class="page">
  <article>
    <header>
      
    </header>

    
<p>
If you're reading this, chances are good that you've heard of Kubernetes. (If
you haven't, how exactly did you end up here?) But what actually is Kubernetes?
Is it <a href="https://kubernetes.io/">"Production-Grade Container Orchestration"</a>?  Is it a <a href="https://platform9.com/blog/kubernetes-as-a-cloud-native-operating-system-on-premises-too/">"Cloud-Native
Operating System"</a>? What do either of those phrases even mean?
</p>
<p>
To be completely honest, I'm not always 100% sure. But I think it's interesting
and informative to take a peek under the hood and see what Kubernetes actually
<em>does</em> under the many layers of abstraction and indirection. So just for fun,
let's see what the absolute bare minimum "Kubernetes cluster" actually looks
like. (It's going to be a lot more minimal than setting up Kubernetes <a href="https://github.com/kelseyhightower/kubernetes-the-hard-way">the hard
way</a>.)
</p>
<p>
I'm going to assume a basic familiarity with Kubernetes, Linux, and containers,
but nothing too advanced. By the way, this is all for learning/exploration
purposes, so don't run any of it in production!
</p>
<h2 id="headline-1">
Big Picture View
</h2>
<p>
Kubernetes has a lot of components and it's sometimes a bit difficult to keep
track of all of them. Here's what the overall architecture looks like according
to <a href="https://commons.wikimedia.org/w/index.php?curid=53571935">Wikipedia</a>:
</p>
<p>
<img src="https://eevans.co/blog/minimum-viable-kubernetes/k8s-arch.png" alt="k8s-arch.png" title="k8s-arch.png">
</p>
<p>
There are at least eight components listed in that diagram; we're going to be
ignoring most of them. I'm going to make the claim that the minimal thing you
could reasonably call Kubernetes consists of three essential components:
</p>
<ul>
<li>
<p>
kubelet
</p>
</li>
<li>
<p>
kube-apiserver (which depends on etcd as its database)
</p>
</li>
<li>
<p>
A container runtime (Docker in this case)
</p>
</li>
</ul>
<p>
Let's take a closer look at what each of these do, according to <a href="https://kubernetes.io/docs/concepts/overview/components/">the docs</a>. First,
<strong>kubelet</strong>:
</p>
<blockquote>
<p>
An agent that runs on each node in the cluster. It makes sure that containers
are running in a Pod.
</p>
</blockquote>
<p>
That sounds simple enough. What about the <strong>container runtime</strong>?
</p>
<blockquote>
<p>
The container runtime is the software that is responsible for running
containers.
</p>
</blockquote>
<p>
Tremendously informative. But if you're familiar with Docker, than you should
have a basic idea of what it does. (The details of the separation of concerns
between the container runtime and kubelet are actually a bit subtle, but I won't
be digging into them here.)
</p>
<p>
And the <strong>API server</strong>?
</p>
<blockquote>
<p>
The API server is a component of the Kubernetes control plane that exposes the
Kubernetes API. The API server is the front end for the Kubernetes control
plane.
</p>
</blockquote>
<p>
Anyone who's ever done anything with Kubernetes has interacted with the API,
either directly or through kubectl. It's the core of what makes Kubernetes
Kubernetes, the brain that turns the mountains of YAML we all know and love (?)
into running infrastructure. It seems obvious that we'll want to get it running
for our minimal setup.
</p>
<h2 id="headline-2">
Prerequisites If You Want to Follow Along
</h2>
<ul>
<li>
<p>
A Linux virtual or corporeal machine you're OK messing around with as
root (I'm using Ubuntu 18.04 on a VM).
</p>
</li>
<li>
<p>
That's it!
</p>
</li>
</ul>
<h2 id="headline-3">
The Boring Setup
</h2>
<p>
The machine we're using needs Docker installed. (I'm not going to dig too much
into how Docker and containers work; there are some <a href="https://blog.lizzie.io/linux-containers-in-500-loc.html">amazing rabbit holes</a> already
out there if you're interested.) Let's just install it using <code>apt</code>:
</p>
<div>
<div><pre><code data-lang="text">$ sudo apt install docker.io
$ sudo systemctl start docker</code></pre></div>
</div>
<p>
Next we'll need to get the Kubernetes binaries. We actually only need kubelet to
bootstrap our "cluster", since we can use kubelet to run the other server
components. We'll also grab kubectl to interact with our cluster once it's up
and running.
</p>
<div>
<div><pre><code data-lang="text">$ curl -L https://dl.k8s.io/v1.18.5/kubernetes-server-linux-amd64.tar.gz &gt; server.tar.gz
$ tar xzvf server.tar.gz
$ cp kubernetes/server/bin/kubelet .
$ cp kubernetes/server/bin/kubectl .
$ ./kubelet --version
Kubernetes v1.18.5</code></pre></div>
</div>
<h2 id="headline-4">
Off To The Races
</h2>
<p>
What happens when we try to run kubelet?
</p>
<div>
<div><pre><code data-lang="text">$ ./kubelet
F0609 04:03:29.105194    4583 server.go:254] mkdir /var/lib/kubelet: permission denied</code></pre></div>
</div>
<p>
kubelet needs to run as root; fair enough, since it's tasked with managing the
entire node. Let's see what the CLI options look like:
</p>
<div>
<div><pre><code data-lang="text">$ ./kubelet -h
&lt;far too much output to copy here&gt;
$ ./kubelet -h | wc -l
284</code></pre></div>
</div>
<p>
Holy cow, that's a lot of options! Thankfully we'll only need a couple of them
for our setup. Here's an option that looks kind of interesting:
</p>
<blockquote>
<p>
<code>--pod-manifest-path</code> string
</p>
<p>
Path to the directory containing static pod files to run, or the path to a
single static pod file. Files starting with dots will be ignored. (DEPRECATED:
This parameter should be set via the config file specified by the Kubelet's
–config flag. See
<a href="https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/">https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/</a> for
more information.)
</p>
</blockquote>
<p>
This option allows us to run <a href="https://kubernetes.io/docs/tasks/configure-pod-container/static-pod/">static pods</a>, which are pods that aren't managed
through the Kubernetes API. Static pods aren't that common in day-to-day
Kubernetes usage but are very useful for bootstrapping clusters, which is
exactly what we're trying to do here. We're going to ignore the loud deprecation
warning (again, don't run this in prod!) and see if we can run a pod.
</p>
<p>
First we'll make a static pod directory and run kubelet:
</p>
<div>
<div><pre><code data-lang="text">$ mkdir pods
$ sudo ./kubelet --pod-manifest-path=pods</code></pre></div>
</div>
<p>
Then, in another terminal/tmux window/whatever, we'll make a pod manifest:
</p>
<div>
<div><pre><code data-lang="text">$ cat &lt;&lt;EOF &gt; pods/hello.yaml
apiVersion: v1
kind: Pod
metadata:
  name: hello
spec:
  containers:
  - image: busybox
    name: hello
    command: ["echo", "hello world!"]
EOF</code></pre></div>
</div>
<p>
kubelet starts spitting out some warnings; other than that it anti-climatically
appears that nothing really happened. But not so! Let's check Docker:
</p>
<div>
<div><pre><code data-lang="text">$ sudo docker ps -a
CONTAINER ID        IMAGE                  COMMAND                 CREATED             STATUS                      PORTS               NAMES
8c8a35e26663        busybox                "echo 'hello world!'"   36 seconds ago      Exited (0) 36 seconds ago                       k8s_hello_hello-mink8s_default_ab61ef0307c6e0dee2ab05dc1ff94812_4
68f670c3c85f        k8s.gcr.io/pause:3.2   "/pause"                2 minutes ago       Up 2 minutes                                    k8s_POD_hello-mink8s_default_ab61ef0307c6e0dee2ab05dc1ff94812_0
$ sudo docker logs k8s_hello_hello-mink8s_default_ab61ef0307c6e0dee2ab05dc1ff94812_4
hello world!</code></pre></div>
</div>
<p>
kubelet read the pod manifest and instructed Docker to start a couple of
containers according to our specification. (If you're wondering about that
"pause" container, it's Kubernetes hackery that's used to reap zombie processes
—see <a href="https://www.ianlewis.org/en/almighty-pause-container">this blog post</a> for the gory details.) kubelet will run our <code>busybox</code>
container with our command and restart it ad infinitum until the static pod is
removed.
</p>
<p>
Let's congratulate ourselves: we've just figured out one of the world's most
convoluted ways of printing out text to the terminal!
</p>
<h2 id="headline-5">
Getting etcd running
</h2>
<p>
Our eventual goal is to run the Kubernetes API, but in order to do that we'll
need <a href="https://etcd.io/">etcd</a> running first. A static pod ought to fit the bill. Let's run a minimal
etcd cluster by putting the following in a file in the <code>pods</code> directory
(e.g. <code>pods/etcd.yaml</code>):
</p>
<div>
<div><pre><code data-lang="yaml"><span>apiVersion</span>: v1
<span>kind</span>: Pod
<span>metadata</span>:
  <span>name</span>: etcd
  <span>namespace</span>: kube-system
<span>spec</span>:
  <span>containers</span>:
  - <span>name</span>: etcd
    <span>command</span>:
    - etcd
    - --data-dir=/var/lib/etcd
    <span>image</span>: k8s.gcr.io/etcd:<span>3.4.3-0</span>
    <span>volumeMounts</span>:
    - <span>mountPath</span>: /var/lib/etcd
      <span>name</span>: etcd-data
  <span>hostNetwork</span>: <span>true</span>
  <span>volumes</span>:
  - <span>hostPath</span>:
      <span>path</span>: /var/lib/etcd
      <span>type</span>: DirectoryOrCreate
    <span>name</span>: etcd-data</code></pre></div>
</div>
<p>
If you've ever worked with Kubernetes, this kind of YAML file should look
familiar. There are only two slightly unusual things worth noting:
</p>
<ul>
<li>
<p>
We mounted the host's <code>/var/lib/etcd</code> to the pod so that the etcd data will
survive restarts (if we didn't do this the cluster state would get wiped every
time the pod restarted, which would be a drag even for a minimal Kubernetes
setup).
</p>
</li>
<li>
<p>
We set <code>hostNetwork: true</code> which, unsurprisingly, sets up the etcd pod to use
the host network instead of the pod-internal network (this will make it easier
for the API server to find the etcd cluster).
</p>
</li>
</ul>
<p>
Some quick sanity checks show that etcd is indeed listening on localhost and
writing to disk:
</p>
<div>
<div><pre><code data-lang="text">$ curl localhost:2379/version
{"etcdserver":"3.4.3","etcdcluster":"3.4.0"}
$ sudo tree /var/lib/etcd/
/var/lib/etcd/
└── member
    ├── snap
    │&nbsp;&nbsp; └── db
    └── wal
        ├── 0.tmp
        └── 0000000000000000-0000000000000000.wal</code></pre></div>
</div>
<h2 id="headline-6">
Running the API server
</h2>
<p>
Getting the Kubernetes API server running is even easier. The only CLI flag we
have to pass is <code>--etcd-servers</code>, which does what you'd expect:
</p>
<div>
<div><pre><code data-lang="yaml"><span>apiVersion</span>: v1
<span>kind</span>: Pod
<span>metadata</span>:
  <span>name</span>: kube-apiserver
  <span>namespace</span>: kube-system
<span>spec</span>:
  <span>containers</span>:
  - <span>name</span>: kube-apiserver
    <span>command</span>:
    - kube-apiserver
    - --etcd-servers=http://<span>127.0.0.1</span>:<span>2379</span>
    <span>image</span>: k8s.gcr.io/kube-apiserver:v1<span>.18.5</span>
  <span>hostNetwork</span>: <span>true</span></code></pre></div>
</div>
<p>
Put that YAML file in the <code>pods</code> directory and the API server will start. Some
quick <code>curl</code> ing shows that the Kubernetes API is listening on port 8080 with
completely open access—no authentication necessary!
</p>
<div>
<div><pre><code data-lang="text">$ curl localhost:8080/healthz
ok
$ curl localhost:8080/api/v1/pods
{
  "kind": "PodList",
  "apiVersion": "v1",
  "metadata": {
    "selfLink": "/api/v1/pods",
    "resourceVersion": "59"
  },
  "items": []
}</code></pre></div>
</div>
<p>
(Again, don't run this setup in production! I was a bit surprised that the
default setup is so insecure, but I assume it's to make development and testing
easier.)
</p>
<p>
And, as a nice surprise, kubectl works out of the box with no extra
configuration!
</p>
<div>
<div><pre><code data-lang="text">$ ./kubectl version
Client Version: version.Info{Major:"1", Minor:"18", GitVersion:"v1.18.5", GitCommit:"e6503f8d8f769ace2f338794c914a96fc335df0f", GitTreeState:"clean", BuildDate:"2020-06-26T03:47:41Z", GoVersion:"go1.13.9", Compiler:"gc", Platform:"linux/amd64"}
Server Version: version.Info{Major:"1", Minor:"18", GitVersion:"v1.18.5", GitCommit:"e6503f8d8f769ace2f338794c914a96fc335df0f", GitTreeState:"clean", BuildDate:"2020-06-26T03:39:24Z", GoVersion:"go1.13.9", Compiler:"gc", Platform:"linux/amd64"}
$ ./kubectl get pod
No resources found in default namespace.</code></pre></div>
</div>
<p>
Easy, right?
</p>
<h2 id="headline-7">
A Problem
</h2>
<p>
But digging a bit deeper, something seems amiss:
</p>
<div>
<div><pre><code data-lang="text">$ ./kubectl get pod -n kube-system
No resources found in kube-system namespace.</code></pre></div>
</div>
<p></p></article></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://eevans.co/blog/minimum-viable-kubernetes/">https://eevans.co/blog/minimum-viable-kubernetes/</a></em></p>]]>
            </description>
            <link>https://eevans.co/blog/minimum-viable-kubernetes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23743502</guid>
            <pubDate>Mon, 06 Jul 2020 00:26:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Transducers and Effects]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23743381">thread link</a>) | @lioeters
<br/>
July 5, 2020 | http://mikeinnes.github.io/2020/06/12/transducers.html | <a href="https://web.archive.org/web/*/http://mikeinnes.github.io/2020/06/12/transducers.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

  <p>Clojure has introduced a very interesting idea called ‘transducers’, which decouple sequence transformations (mapping, filtering etc) from sequence implementations like vectors, lazy lists and channels. Transducers and their benefits are well-covered elsewhere, but I’d like to explore some tradeoffs, and compare an alternative (and extremely hypothetical) design based on a staple of the functional programming world, effect handlers.</p>

<p>There are many useful operations that we can carry out on <em>sequences</em>, like mapping, filtering, interleaving, partitioning and so on. Ideally, we’d like to apply these tools to any sequence of values, including list data structures and strings but also channels and observables. Unfortunately, it’s common to have to <a href="https://github.com/ReactiveX/RxClojure">reimplement</a> each function we want for new sequences.</p>

<p>Abstracting over sequences is difficult, and requires a significantly more powerful approach than the usual polymorphism and data abstraction. To see why, imagine a somewhat-general <code>map</code> using <code>empty</code> and <code>conj</code>.</p>

<div><div><pre><code><span>(</span><span>defn</span><span> </span><span>map</span><span>'</span><span> </span><span>[</span><span>f</span><span> </span><span>xs</span><span>]</span><span>
  </span><span>(</span><span>loop</span><span> </span><span>[</span><span>xs</span><span> </span><span>xs</span><span>
         </span><span>ys</span><span> </span><span>(</span><span>empty</span><span> </span><span>xs</span><span>)]</span><span>
    </span><span>(</span><span>if</span><span> </span><span>(</span><span>empty?</span><span> </span><span>xs</span><span>)</span><span>
      </span><span>ys</span><span>
      </span><span>(</span><span>recur</span><span> </span><span>(</span><span>rest</span><span> </span><span>xs</span><span>)</span><span>
             </span><span>(</span><span>conj</span><span> </span><span>ys</span><span> </span><span>(</span><span>f</span><span> </span><span>(</span><span>first</span><span> </span><span>xs</span><span>)))))))</span><span>
</span></code></pre></div></div>

<p>Unfortunately, aside from the fact that this has the wrong ordering for some data structures, and could only work with channels if you have language-level coroutines (which Clojure, thanks to the JVM, doesn’t), this definition of <code>map</code> simply can’t be used to produce lazy sequences. Here’s how we implement the lazy version:</p>

<div><div><pre><code><span>(</span><span>defn</span><span> </span><span>map</span><span>'</span><span> </span><span>[</span><span>f</span><span> </span><span>xs</span><span>]</span><span>
  </span><span>(</span><span>lazy-seq</span><span>
   </span><span>(</span><span>when</span><span> </span><span>(</span><span>not</span><span> </span><span>(</span><span>empty?</span><span> </span><span>xs</span><span>))</span><span>
     </span><span>(</span><span>cons</span><span> </span><span>(</span><span>f</span><span> </span><span>(</span><span>first</span><span> </span><span>xs</span><span>))</span><span> </span><span>(</span><span>map</span><span>'</span><span> </span><span>f</span><span> </span><span>(</span><span>rest</span><span> </span><span>xs</span><span>))))))</span><span>
</span></code></pre></div></div>

<p>The problem is that the basic structure of the code has changed, from an iterative (tail recursive) form ideal for eager data structures to the context-preserving recursion needed for laziness. Other constructs, like channels, might require yet different organisation, eg as a state machine.</p>

<p>Clojure resolves this with two insights:</p>

<ol>
  <li>A <em>process</em> (eg working with lists or channels in some way) can usually be seen as a kind of <code>fold</code>, with an appropriate <em>step function</em> of the form <code>result –&gt; input –&gt; result</code>.</li>
  <li><code>map</code>, <code>filter</code> and friends extend processes by <em>wrapping</em> the step function, eg <code>step' = (result, input) –&gt; step(result, f(input))</code> to map <code>f</code> alongside whatever was happening before.</li>
</ol>

<p>Processes can therefore accept step-wrapping functions (transducers) to alter their behaviour. The upshot is that you can create and compose objects representing mapping, filtering etc and use them generically on channels, sequences, vectors and so on.</p>

<p>To solve our <code>map</code> problem, we can write data structure production and lazy-sequence production (or channel production, or …) as a single ‘transducible process’. Functions like <code>map</code> and <code>filter</code> become transducers which we can hand to these processes to modify their behaviour. Thus we can write <code>map</code> only once, yet use it with many sequence types.</p>

<h2 id="a-sequence-of-caveats">A sequence of caveats</h2>

<p>The problem that transducers solve is an important one; transducers themselves are elegant in conception and clean to work with as a user. However, if you look into how transducers are put together under the hood – or try to implement one yourself – you might find them less easy on the eyes.</p>

<div><div><pre><code><span>;; Guess what this function does for your next lockdown quiz</span><span>
</span><span>(</span><span>defn</span><span> </span><span>take</span><span> </span><span>[</span><span>n</span><span>]</span><span>
  </span><span>(</span><span>fn</span><span> </span><span>[</span><span>rf</span><span>]</span><span>
    </span><span>(</span><span>let</span><span> </span><span>[</span><span>nv</span><span> </span><span>(</span><span>volatile!</span><span> </span><span>n</span><span>)]</span><span>
      </span><span>(</span><span>fn</span><span>
        </span><span>([]</span><span> </span><span>(</span><span>rf</span><span>))</span><span>
        </span><span>([</span><span>result</span><span>]</span><span> </span><span>(</span><span>rf</span><span> </span><span>result</span><span>))</span><span>
        </span><span>([</span><span>result</span><span> </span><span>input</span><span>]</span><span>
          </span><span>(</span><span>let</span><span> </span><span>[</span><span>n</span><span> </span><span>@</span><span>nv</span><span>
                </span><span>nn</span><span> </span><span>(</span><span>vswap!</span><span> </span><span>nv</span><span> </span><span>dec</span><span>)</span><span>
                </span><span>result</span><span> </span><span>(</span><span>if</span><span> </span><span>(</span><span>pos?</span><span> </span><span>n</span><span>)</span><span>
                          </span><span>(</span><span>rf</span><span> </span><span>result</span><span> </span><span>input</span><span>)</span><span>
                          </span><span>result</span><span>)]</span><span>
            </span><span>(</span><span>if</span><span> </span><span>(</span><span>not</span><span> </span><span>(</span><span>pos?</span><span> </span><span>nn</span><span>))</span><span>
              </span><span>(</span><span>ensure-reduced</span><span> </span><span>result</span><span>)</span><span>
              </span><span>result</span><span>)))))))</span><span>
</span></code></pre></div></div>

<p>The elegance of transducers is somewhat eroded as we try to make them more general, and even then they have significant limitations. In particular:</p>

<ul>
  <li>Transducers like <code>dedupe</code> and <code>take</code> create stateful step functions, which adds extra constraints needed for correctness.</li>
  <li>Others like <code>take-while</code> need an explicit cancellation mechanism, and you want to be careful not to double-wrap the cancellation. Handling initialisation and completion adds yet more burden to implementations.</li>
  <li>Transducible processes themselves <a href="https://clojure.org/reference/transducers#_creating_transducible_processes">can be hard to implement</a>, mainly because of the above concerns, but it’s also because some things (eg lazy sequences) <a href="https://github.com/clojure/clojure/blob/30a36cbe0ef936e57ddba238b7fa6d58ee1cbdce/src/jvm/clojure/lang/TransformerIterator.java">aren’t naturally built with <code>fold</code></a>.</li>
  <li>There is no support for functions that take or produce multiple sequences (<code>interleave</code>, <code>concat</code>, <code>split-with</code> etc).</li>
</ul>

<h2 id="an-effective-alternative">An effective alternative</h2>

<p>Consider the following notation for <code>mapping</code> and <code>filtering</code>, inspired by <a href="https://docs.microsoft.com/en-us/dotnet/fsharp/language-reference/sequences">F#’s list comprehensions</a>. I’m using a hypothetical C/Koka-like syntax here but all my examples could be converted to simple Clojure equivalents (<code>loop</code>/<code>recur</code> and explicit passing of variables, <code>for</code>, etc).</p>

<div><div><pre><code><span>fn</span> <span>mapping</span><span>(</span><span>f</span><span>,</span> <span>xs</span><span>)</span> <span>{</span>
  <span>for</span> <span>x</span> <span>in</span> <span>xs</span> <span>{</span>
    <span>yield</span><span>(</span><span>f</span><span>(</span><span>x</span><span>))</span>
  <span>}</span>
<span>}</span>

<span>fn</span> <span>filtering</span><span>(</span><span>f</span><span>,</span> <span>xs</span><span>)</span> <span>{</span>
  <span>for</span> <span>x</span> <span>in</span> <span>xs</span> <span>{</span>
    <span>if</span> <span>f</span><span>(</span><span>x</span><span>)</span> <span>{</span>
      <span>yield</span><span>(</span><span>x</span><span>)</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>As a notation, this seems abstract enough. There’s no dependence on how we get values (<code>xs</code> could be anything and iteration can use a generic protocol). It avoids expressing how we build an output sequence, or even whether we do, just what values appear in it. F# lets us omit the <code>yield</code> (eg <code>for x in xs –&gt; x^2</code>), which makes things look more like a traditional list comprehension, but for clarity we’ll keep them explicit.</p>

<p>The key idea is to make this code run via <em>effect handlers</em> (implemented in F#, with lexical scope, as ‘computation expressions’<sup id="fnref:1"><a href="#fn:1">1</a></sup>), which let us plug in a definition of <code>yield</code>. Effect handlers have their origin in strongly-typed functional programming but they are really quite lisp-y, and can be thought of as resumable exceptions.<sup id="fnref:2"><a href="#fn:2">2</a></sup></p>

<p>At the simplest, we can just create an empty array and append to it each time a value is <code>yield</code>ed:</p>

<div><div><pre><code><span>ys</span> <span>=</span> <span>[]</span>
<span>handle</span> <span>{</span>
  <span>mapping</span><span>(</span><span>f</span><span>,</span> <span>xs</span><span>)</span>
<span>}</span> <span>with</span> <span>yield</span><span>(</span><span>x</span><span>)</span> <span>{</span>
  <span>ys</span> <span>=</span> <span>append</span><span>(</span><span>ys</span><span>,</span> <span>x</span><span>)</span>
  <span>resume</span><span>()</span>
<span>}</span>
<span>return</span> <span>ys</span>
</code></pre></div></div>

<p><code>yield(x)</code> is a bit like throwing an exception, except that after handling it we can jump back to where we were with <code>resume</code>.</p>

<p>Instead of building a list, we can do a map-reduce without any intermediate collection being constructed.</p>

<div><div><pre><code><span>sum</span> <span>=</span> <span>0</span>
<span>handle</span> <span>{</span>
  <span>mapping</span><span>(</span><span>f</span><span>,</span> <span>xs</span><span>)</span>
<span>}</span> <span>with</span> <span>yield</span><span>(</span><span>x</span><span>)</span> <span>{</span>
  <span>sum</span> <span>+=</span> <span>x</span>
  <span>resume</span><span>()</span>
<span>}</span>
<span>return</span> <span>sum</span>
</code></pre></div></div>

<p>This can compile down to the tight loop we want for simple data structures.<sup id="fnref:3"><a href="#fn:3">3</a></sup> But what’s going to be really mind-bending is how straightforwardly we can turn our loop into a lazy sequence.</p>

<div><div><pre><code><span>ys</span> <span>=</span> <span>handle</span> <span>{</span>
  <span>mapping</span><span>(</span><span>f</span><span>,</span> <span>xs</span><span>)</span>
  <span>nil</span>
<span>}</span> <span>with</span> <span>yield</span><span>(</span><span>x</span><span>)</span> <span>{</span>
  <span>cons</span><span>(</span><span>x</span><span>,</span> <span>LazySeq</span><span>(</span><span>resume</span><span>))</span>
<span>}</span>
</code></pre></div></div>

<p>What’s happening here is that <code>yield</code> doesn’t call <code>resume</code>, so the loop gets paused the first time it is called, and the whole block returns a <code>cons</code>. <code>resume</code> will get called when we try to access the tail of <code>ys</code>, restarting the loop. The loop hits the next <code>yield</code>, suspends, and returns a new <code>cons</code> with item two and a new <code>resume</code>, and so on. Eventually the <code>mapping</code> will finish and <code>resume</code> returns <code>nil</code>, completing the list.<sup id="fnref:4"><a href="#fn:4">4</a></sup></p>

<p><code>mapping</code> here takes on the role of transducer, expressing what <code>map</code> does abstractly without nailing down the details. Effect handlers then allow us to instantiate <code>mapping</code> as a set of concrete processes, and potentially very different ones depending on the context. In all we can achieve the same core goal in a wonderfully expressive way.</p>

<p>With this in mind, we can blend Clojure’s <code>into</code> and F#’s <code>seq</code> into one list comprehension construct which picks the appropriate <code>yield</code> handler for the kind of sequence we are building.</p>

<div><div><pre><code><span>fn</span> <span>map</span><span>(</span><span>f</span><span>,</span> <span>xs</span><span>)</span> <span>{</span>
  <span>into</span> <span>empty</span><span>(</span><span>xs</span><span>)</span> <span>{</span>
    <span>for</span> <span>x</span> <span>in</span> <span>xs</span> <span>{</span>
      <span>yield</span><span>(</span><span>f</span><span>(</span><span>x</span><span>))</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This <code>map</code> can behave appropriately, and generate efficient code, whether <code>xs</code> is a vector, persistent list, lazy list, string, channel, observable, promise or whatever, which solves our generic implementation problem. And we can compose pipelines just like we did before with <code>(-&gt;&gt; xs (map f) (filter g))</code>.<sup id="fnref:5"><a href="#fn:5">5</a></sup></p>

<p>As F# has shown, this way of defining sequence transformations is really expressive. If we want to cancel we can just break out of the loop (or the loop/recur equivalent).</p>

<div><div><pre><code><span>// Take while</span>
<span>for</span> <span>x</span> <span>in</span> <span>xs</span> <span>{</span>
  <span>if</span> <span>f</span><span>(</span><span>x</span><span>)</span> <span>{</span>
    <span>yield</span><span>(</span><span>x</span><span>)</span>
  <span>}</span> <span>else</span> <span>{</span>
    <span>break</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>If we need state, a local variable is enough, since the loop has its own scope.</p>

<div><div><pre><code><span>// Dedupe</span>
<span>last</span> <span>=</span> <span>nil</span>
<span>for</span> <span>x</span> <span>in</span> <span>xs</span> <span>{</span>
  <span>if</span> <span>x</span> <span>!=</span> <span>last</span> <span>{</span>
    <span>yield</span><span>(</span><span>x</span><span>)</span>
  <span>}</span>
  <span>last</span> <span>=</span> <span>x</span>
<span>}</span>
</code></pre></div></div>

<p>Concatenating sequences is easy, because we can happily have multiple loops, and <code>interleave</code> is easy because we can put <code>yield</code> wherever we want. We can even use nested loops, and I’d argue that the intent is clearer in these than even the simplest transducer implementations. They strike close to the essence of the transformation, without any incidental complexity.</p>

<div><div><pre><code><span>// Concat</span>
<span>for</span> <span>x</span> <span>in</span> <span>xs</span> <span>{</span> <span>yield</span><span>(</span><span>x</span><span>)</span> <span>}</span>
<span>for</span> <span>y</span> <span>in</span> <span>ys</span> <span>{</span> <span>yield</span><span>(</span><span>y</span><span>)</span> <span>}</span>
<span>// Interleave</span>
<span>for</span> <span>(</span><span>x</span><span>,</span> <span>y</span><span>)</span> <span>in</span> <span>zip</span><span>(</span><span>xs</span><span>,</span> <span>ys</span><span>)</span> <span>{</span>
  <span>yield</span><span>(</span><span>x</span><span>)</span>
  <span>yield</span><span>(</span><span>y</span><span>)</span>
<span>}</span>
<span>// Cartesian Product</span>
<span>for</span> <span>x</span> <span>in</span> <span>xs</span> <span>{</span>
  <span>for</span> <span>y</span> <span>in</span> <span>ys</span> <span>{</span>
    <span>yield</span><span>((</span><span>x</span><span>,</span> <span>y</span><span>))</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>We can even imagine supporting multiple output sequences, so long as there’s some way of identifying them, for example to partition a channel into matching and non-matching events.</p>

<div><div><pre><code><span>// Split-with</span>
<span>into</span> <span>empty</span><span>(</span><span>xs</span><span>)</span> <span>-&gt;</span> <span>(</span><span>trues</span><span>,</span> <span>falses</span><span>)</span> <span>{</span>
  <span>for</span> <span>x</span> <span>in</span> <span>xs</span> <span>{</span>
    <span>if</span> <span>f</span><span>(</span><span>x</span><span>)</span> <span>{</span>
      <span>yield</span><span>(</span><span>trues</span><span>,</span> <span>x</span><span>)</span>
    <span>}</span> <span>else</span> <span>{</span>
      <span>yield</span><span>(</span><span>falses</span><span>,</span> <span>x</span><span>)</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<h2 id="asynchronous-evolution">Asynchronous Evolution</h2>

<p>The above examples, taking things from one bunch of sequences and putting them into another bunch, might begin to look familiar. That’s because the Shyamalan-esque twist to this story is that Clojure <em>already had this abstraction all along</em>, via the <a href="https://github.com/clojure/core.async">core.async</a> library. The relationship of <code>go</code> blocks to our generalised list comprehensions is that</p>

<ol>
  <li>Instead of iterating <code>for x in xs</code> we have an explicit <code>&lt;!</code> (take) operation, which is itself an effect; it suspends the code and falls back to a handler, which can <code>resume</code> with a value when one is available.</li>
  <li><code>yield</code> is replaced by the <code>&gt;!</code> (put) effect.</li>
  <li>Both <code>&gt;!</code> and <code>&lt;!</code> are linked to identities (channels), which means multiple inputs and outputs are supported.</li>
</ol>

<p>So we can draw a clear path from list comprehensions to async blocks, two features which might not seem all that related at first, by generalising in some ways and specialising in others. This …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://mikeinnes.github.io/2020/06/12/transducers.html">http://mikeinnes.github.io/2020/06/12/transducers.html</a></em></p>]]>
            </description>
            <link>http://mikeinnes.github.io/2020/06/12/transducers.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23743381</guid>
            <pubDate>Mon, 06 Jul 2020 00:10:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust for JavaScript Developers – Functions and Control Flow]]>
            </title>
            <description>
<![CDATA[
Score 101 | Comments 39 (<a href="https://news.ycombinator.com/item?id=23743363">thread link</a>) | @rkwz
<br/>
July 5, 2020 | http://www.sheshbabu.com/posts/rust-for-javascript-developers-functions-and-control-flow/ | <a href="https://web.archive.org/web/*/http://www.sheshbabu.com/posts/rust-for-javascript-developers-functions-and-control-flow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This is the third part in a series about introducing the Rust language to JavaScript developers. Here are the past chapters:</p>
<ol>
<li><a href="http://www.sheshbabu.com/posts/rust-for-javascript-developers-tooling-ecosystem-overview/">Tooling Ecosystem Overview</a></li>
<li><a href="http://www.sheshbabu.com/posts/rust-for-javascript-developers-variables-and-data-types/">Variables and Data Types</a></li>
</ol>
<h2 id="Functions"><a href="#Functions" title="Functions"></a>Functions</h2><p>Rust’s function syntax is pretty much similar to the one in JavaScript.</p>
<pre><code><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> income <span>=</span> <span>100</span><span>;</span>
  <span>let</span> tax <span>=</span> <span>calculate_tax</span><span>(</span>income<span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"{}"</span><span>,</span> tax<span>)</span><span>;</span>
<span>}</span>

<span>fn</span> <span>calculate_tax</span><span>(</span>income<span>:</span> i32<span>)</span> <span>-&gt;</span> i32 <span>{</span>
  <span>return</span> income <span>*</span> <span>90</span> <span>/</span> <span>100</span><span>;</span>
<span>}</span></code></pre>
<p>The only difference you might see above is the type annotations for arguments and return values.</p>
<p>The <code>return</code> keyword can be skipped and it’s very common to see code without an explicit return. If you’re returning implicitly, make sure to remove the semicolon from that line. The above function can be refactored as:</p>
<pre><code>fn main() {
  let income = 100;
  let tax = calculate_tax(income);
  println!("{}", tax);
}

fn calculate_tax(income: i32) -&gt; i32 {
<span>- return income * 90 / 100;</span>
<span>+ income * 90 / 100</span>
}</code></pre>
<h2 id="Arrow-Functions"><a href="#Arrow-Functions" title="Arrow Functions"></a>Arrow Functions</h2><p>Arrow functions are a popular feature in modern JavaScript - they allow us to write functional code in a concise way.</p>
<p>Rust has something similar and they are called “Closures”. The name might be a bit confusing and would require getting used to because in JavaScript, closures can be created using both normal and arrow functions.</p>
<p>Rust’s closure syntax is very similar to JavaScript’s arrow functions:</p>
<p><strong>Without arguments:</strong></p>
<pre><code>
<span>let</span> greet <span>=</span> <span>(</span><span>)</span> <span>=</span><span>&gt;</span> console<span>.</span><span>log</span><span>(</span><span>"hello"</span><span>)</span><span>;</span>

<span>greet</span><span>(</span><span>)</span><span>;</span> </code></pre>
<pre><code>
<span>let</span> greet <span>=</span> <span>||</span> <span>println!</span><span>(</span><span>"hello"</span><span>)</span><span>;</span>

<span>greet</span><span>(</span><span>)</span><span>;</span> </code></pre>
<p><strong>With arguments:</strong></p>
<pre><code>
<span>let</span> greet <span>=</span> <span>(</span>msg<span>)</span> <span>=</span><span>&gt;</span> console<span>.</span><span>log</span><span>(</span>msg<span>)</span><span>;</span>

<span>greet</span><span>(</span><span>"good morning!"</span><span>)</span><span>;</span> </code></pre>
<pre><code>
<span>let</span> greet <span>=</span> <span>|</span>msg<span>:</span> <span>&amp;</span>str<span>|</span> <span>println!</span><span>(</span><span>"{}"</span><span>,</span> msg<span>)</span><span>;</span>

<span>greet</span><span>(</span><span>"good morning!"</span><span>)</span><span>;</span> </code></pre>
<p><strong>Returning values:</strong></p>
<pre><code>
<span>let</span> add <span>=</span> <span>(</span>a<span>,</span> b<span>)</span> <span>=</span><span>&gt;</span> a <span>+</span> b<span>;</span>

<span>add</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span><span>;</span> </code></pre>
<pre><code>
<span>let</span> add <span>=</span> <span><span>|</span>a<span>:</span> i32<span>,</span> b<span>:</span> i32<span>|</span></span> <span>-&gt;</span> i32 <span>{</span> a <span>+</span> b <span>}</span><span>;</span>

<span>add</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span><span>;</span> </code></pre>
<p><strong>Multiline:</strong></p>
<pre><code>
<span>let</span> add <span>=</span> <span>(</span>a<span>,</span> b<span>)</span> <span>=</span><span>&gt;</span> <span>{</span>
  <span>let</span> sum <span>=</span> a <span>+</span> b<span>;</span>
  <span>return</span> sum<span>;</span>
<span>}</span><span>;</span>

<span>add</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span><span>;</span> </code></pre>
<pre><code>
<span>let</span> add <span>=</span> <span><span>|</span>a<span>:</span> i32<span>,</span> b<span>:</span> i32<span>|</span></span> <span>-&gt;</span> i32 <span>{</span>
  <span>let</span> sum <span>=</span> a <span>+</span> b<span>;</span>
  <span>return</span> sum<span>;</span>
<span>}</span><span>;</span>

<span>add</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span><span>;</span> </code></pre>
<p>Here’s a cheatsheet:<br><img src="http://www.sheshbabu.com/images/2020-rust-for-javascript-developers-3/image-2.png" alt=""></p>
<p>Closures don’t need the type annotations most of the time, but I’ve added them here for clarity.</p>
<h2 id="If-Else"><a href="#If-Else" title="If Else"></a>If Else</h2><pre><code><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> income <span>=</span> <span>100</span><span>;</span>
  <span>let</span> tax <span>=</span> <span>calculate_tax</span><span>(</span>income<span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"{}"</span><span>,</span> tax<span>)</span><span>;</span>
<span>}</span>

<span>fn</span> <span>calculate_tax</span><span>(</span>income<span>:</span> i32<span>)</span> <span>-&gt;</span> i32 <span>{</span>
  <span>if</span> income <span>&lt;</span> <span>10</span> <span>{</span>
    <span>return</span> <span>0</span><span>;</span>
  <span>}</span> <span>else</span> <span>if</span> income <span>&gt;=</span> <span>10</span> <span>&amp;&amp;</span> income <span>&lt;</span> <span>50</span> <span>{</span>
    <span>return</span> <span>20</span><span>;</span>
  <span>}</span> <span>else</span> <span>{</span>
    <span>return</span> <span>50</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre>
<h2 id="Loops"><a href="#Loops" title="Loops"></a>Loops</h2><p>While loops:</p>
<pre><code><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> <span>mut</span> count <span>=</span> <span>0</span><span>;</span>

  <span>while</span> count <span>&lt;</span> <span>10</span> <span>{</span>
    <span>println!</span><span>(</span><span>"{}"</span><span>,</span> count<span>)</span><span>;</span>
    count <span>+=</span> <span>1</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre>
<p>Normal <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/for" target="_blank" rel="noopener">for loops</a> don’t exist in Rust, we need to use <code>while</code> or <code>for..in</code> loops. <code>for..in</code> loops are similar to the <code>for..of</code> loops in JavaScript and they loop over an iterator.</p>
<pre><code><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> numbers <span>=</span> <span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>,</span> <span>5</span><span>]</span><span>;</span>

  <span>for</span> n <span>in</span> numbers<span>.</span><span>iter</span><span>(</span><span>)</span> <span>{</span>
    <span>println!</span><span>(</span><span>"{}"</span><span>,</span> n<span>)</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre>
<p>Notice that we’re not iterating directly over the array but instead using the <code>iter</code> method of the array.</p>
<p>We can also loop over <a href="https://doc.rust-lang.org/reference/expressions/range-expr.html" target="_blank" rel="noopener">ranges</a>:</p>
<pre><code><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>for</span> n <span>in</span> <span>1</span><span>..</span><span>5</span> <span>{</span>
    <span>println!</span><span>(</span><span>"{}"</span><span>,</span> n<span>)</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre>
<h2 id="Iterators"><a href="#Iterators" title="Iterators"></a>Iterators</h2><p>In JavaScript, we can use array methods like map/filter/reduce/etc instead of <code>for</code> loops to perform calculations or transformations on an array.</p>
<p>For example, here we take an array of numbers, double them and filter out the elements that are less than 10:</p>
<pre><code><span>function</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> numbers <span>=</span> <span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>,</span> <span>5</span><span>]</span><span>;</span>

  <span>let</span> double <span>=</span> <span>(</span>n<span>)</span> <span>=</span><span>&gt;</span> n <span>*</span> <span>2</span><span>;</span>
  <span>let</span> less_than_ten <span>=</span> <span>(</span>n<span>)</span> <span>=</span><span>&gt;</span> n <span>&lt;</span> <span>10</span><span>;</span>

  <span>let</span> result <span>=</span> numbers<span>.</span><span>map</span><span>(</span>double<span>)</span><span>.</span><span>filter</span><span>(</span>less_than_ten<span>)</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>result<span>)</span><span>;</span> 
<span>}</span></code></pre>
<p>In Rust, we can’t directly use map/filter/etc over vectors, we need to follow these steps:</p>
<ol>
<li>Convert the vector into an iterator using <code>iter</code>, <code>into_iter</code> or <code>iter_mut</code> methods</li>
<li>Chain <code>adapters</code> such as map/filter/etc on the iterator</li>
<li>Finally convert the iterator back to a vector using <code>consumers</code> such as <code>collect</code>, <code>find</code>, <code>sum</code> etc</li>
</ol>
<p>Here’s the equivalent Rust code:</p>
<pre><code><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> numbers <span>=</span> <span>vec!</span><span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>,</span> <span>5</span><span>]</span><span>;</span>

  <span>let</span> double <span>=</span> <span><span>|</span>n<span>:</span> <span>&amp;</span>i32<span>|</span></span> <span>-&gt;</span> i32 <span>{</span> n <span>*</span> <span>2</span> <span>}</span><span>;</span>
  <span>let</span> less_than_10 <span>=</span> <span><span>|</span>n<span>:</span> <span>&amp;</span>i32<span>|</span></span> <span>-&gt;</span> bool <span>{</span> <span>*</span>n <span>&lt;</span> <span>10</span> <span>}</span><span>;</span>

  <span>let</span> result<span>:</span> Vec<span>&lt;</span>i32<span>&gt;</span> <span>=</span> numbers<span>.</span><span>iter</span><span>(</span><span>)</span><span>.</span><span>map</span><span>(</span>double<span>)</span><span>.</span><span>filter</span><span>(</span>less_than_10<span>)</span><span>.</span><span>collect</span><span>(</span><span>)</span><span>;</span>

  <span>println!</span><span>(</span><span>"{:?}"</span><span>,</span> result<span>)</span><span>;</span> 
<span>}</span></code></pre>
<p>You should be able to understand most of the code above but you might notice few things off here:</p>
<ul>
<li>The usage of <code>&amp;</code> and <code>*</code> in the closure</li>
<li>The <code>Vec&lt;i32&gt;</code> type annotation for the <code>result</code> variable</li>
</ul>
<p>The <code>&amp;</code> is the reference operator and the <code>*</code> is the dereference operator. The <code>iter</code> method instead of copying the elements in the vector, it passes them as references to the next adapter in the chain. This is why we use <code>&amp;i32</code> in the map’s closure (double). This closure returns <code>i32</code> but <a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.filter" target="_blank" rel="noopener">filter</a> calls its closure (less_than_10) with reference so that’s why we need to use <code>&amp;i32</code> again. To dereference the argument, we use the <code>*</code> operator. We’ll cover this in more detail in future chapters.</p>
<p>Regarding <code>Vec&lt;i32&gt;</code>, so far we haven’t added type annotations to variables as Rust can infer the types automatically, but for <code>collect</code>, we need to be explicitly tell Rust that we expect a <code>Vec&lt;i32&gt;</code> output.</p>
<p>Aside from map and filter, there are ton of other <a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html" target="_blank" rel="noopener">useful adapters</a> that we can use in iterators.</p>
<p>Thanks for reading! Feel free to follow me in <a href="https://twitter.com/sheshbabu" target="_blank" rel="noopener">Twitter</a> for updates :)</p>
</div></div>]]>
            </description>
            <link>http://www.sheshbabu.com/posts/rust-for-javascript-developers-functions-and-control-flow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23743363</guid>
            <pubDate>Mon, 06 Jul 2020 00:07:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I’m Writing a Book on Cryptography]]>
            </title>
            <description>
<![CDATA[
Score 171 | Comments 23 (<a href="https://news.ycombinator.com/item?id=23743218">thread link</a>) | @gedigi
<br/>
July 5, 2020 | https://www.cryptologie.net/article/504/why-im-writing-a-book-on-cryptography/ | <a href="https://web.archive.org/web/*/https://www.cryptologie.net/article/504/why-im-writing-a-book-on-cryptography/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p>I’ve now been writing a book on <strong>applied cryptography</strong> for a year and a half.
I’m nearing the end of my journey, as I have one last ambitious chapter left to write: next-generation cryptography (a chapter that I’ll use to talk about cryptography that will become more and more practical: post-quantum cryptography, homomorphic encryption, multi-party computation, and zk-SNARKs).</p>
<p>I’ve been asked multiple times <strong>why write a new book about cryptography?</strong> and <strong>why should I read your book?</strong>.
To answer this, you have to understand when it all started…</p>
<h2>Diagrams are everything</h2>
<p>Today if you want to learn about almost anything, you just google it.
Yet, for cryptography, and depending on what you're looking for, resources can be quite lacking.</p>
<p>It all started a long time ago.
For a class, I had to implement a <a href="https://www.paulkocher.com/doc/DifferentialPowerAnalysis.pdf">differential power analysis attack</a>, a breakthrough in cryptanalysis as it was the first side-channel attack to be published.
A differential power analysis uses the power consumption of a device during an encryption to leak its private key.
At the time, I realized that great papers could convey great ideas with very little emphasis on understanding.
I remember banging my head against the wall trying to figure out what the author of the white paper was trying to say.
Worse, I couldn’t find a good resource that explained the paper.
So I banged my head a bit more, and finally I got it.
And then I thought I would help others.
So I drew some diagrams, animated them, and recorded myself going over them.
That was <a href="https://www.youtube.com/watch?v=gbqNCgVcXsM">my first screencast</a>.</p>
<p>This first step in education was enough to make me want to do more.
I started making more of these videos, and started writing more articles about cryptography on this blog (today totaling more than 500 articles).</p>
<p><img alt="we want to know" src="https://www.cryptologie.net/upload/we_want_to_know.png"></p>
<p>I realized early that diagrams were extremely helpful to understand complicated concepts, and that strangely most resources in the field shied away from them.</p>
<p>For example, anyone in cryptography who thinks about AES-CBC would immediately think about the following wikipedia diagram:</p>
<p><img alt="aes cbc" src="https://www.cryptologie.net/upload/600px-CBC_encryption.svg_.png"></p>
<p>So here I was, trying to explain everything I learned, and thinking hard about what sorts of simple diagrams could easily convey these complex ideas.
That’s when I started thinking about a book, years and years before <a href="https://manning.com/">Manning Publications</a> would reach out to me with a book deal.</p>
<h2>The applied cryptographer curriculum</h2>
<p> I hadn’t started cryptography due to a long-life passion.
I had finished a bachelor in theoretical mathematics and didn’t know what was next for me.
I had also been programming my whole life, and I wanted to reconcile the two.
Naturally, I got curious about cryptography, which seemed to have the best of both world, and started reading the different books at my disposal.
I quickly discovered my life's calling.</p>
<p>Some things were annoying me though. In particular, the long introductions that would start with history.
I was only interested in the technicalities, and always had been.
I swore to myself, if I ever wrote a book about cryptography, I would not write a single line on Vigenère ciphers, Caesar ciphers, and others.</p>
<p>And so after applying to the masters of Cryptography at the university of Bordeaux, and obtaining a degree in the subject, I thought I was ready for the world.
Little did I know.
What I thought was a very applied degree actually lacked a lot on the real world protocols I was about to attack.
I had spent a lot of time learning about the mathematics of elliptic curves, but nothing about how they were used in cryptographic algorithms.
I had learned about LFSRs, and ElGamal, and DES, and a series of other cryptographic primitives that I would never see again.</p>
<p>When I started working in the industry at Matasano, which then became NCC Group, my first gig was to audit <a href="https://www.openssl.org/">OpenSSL</a> (the most popular TLS implementation).
Oh boy, did it hurt my brain.
I remember coming back home every day with a strong headache.
What a clusterfuck of a library.
I had no idea at the time that I would years later become a co-author of TLS 1.3.</p>
<p><img alt="sign" src="https://www.cryptologie.net/upload/7._Note_that_digital_signatures_are_specified_with_a_hash_function,_allowing_you_to_.png"></p>
<p>But at that point I was already thinking: this is what I should have learned in school.
The knowledge I’m getting now is what would have been useful to prepare me for the real world.
After all, I was now a security practitioner specialized in cryptography.
I was reviewing real-world cryptographic applications.
I was doing the job that one would wish they had after finishing a cryptography degree.
I implemented, verified, used, and advised on what cryptographic algorithms to use.</p>
<p>This is the reason I’m the first reader of the book I’m writing.
This is what I would have written to my past self in order to prepare me for the real world.</p>
<h2>The use of cryptography is where most of the bugs are</h2>
<p>My consulting job led me to audit many real world cryptographic applications like the <a href="https://www.nccgroup.com/us/about-us/newsroom-and-events/blog/2015/may/openssl-audit/">OpenSSL</a>, the <a href="https://www.nccgroup.trust/globalassets/our-research/us/public-reports/2018/final_public_report_ncc_group_google_encryptedbackup_2018-10-10_v1.0.pdf">encrypted backup system of Google</a>, the <a href="https://blog.cloudflare.com/ncc-groups-cryptography-services-audit-of-tls-1-3/">TLS 1.3 implementation of Cloudflare</a>, the <a href="https://letsencrypt.org/2015/04/14/ncc-group-audit.html">certificate authority protocol of Let’s Encrypt</a>, the <a href="https://www.nccgroup.com/us/our-research/zcash-overwinter-consensus-and-sapling-cryptography-review/">sapling protocol of Zcash</a>, the <a href="https://blog.nucypher.com/security-audits--round-1--3/">threshold proxy re-encryption scheme of NuCypher</a> and dozens and dozens of other real-world cryptographic applications that I unfortunately cannot mention publicly.</p>
<p>Early in my job, I was tasked to audit the custom protocol a big corporation (that I can’t name) had written to encrypt their communications.
It turns out that, they were signing everything but the ephemeral keys, which completely broke the whole protocol (as one could have easily replaced the ephemeral keys).
A rookie mistake from anyone with some experience with secure transport protocols, but something that was missed by people who thought they were experienced enough to roll their own crypto.
I remember explaining the vulnerability at the end of the engagement, and a room full of engineers turning silent for a good 30 seconds.</p>
<p>This story repeated itself many times during my career.
There was this time where while auditing a cryptocurrency for another client, I found a way to forge transactions from already existing ones (due to some ambiguity of what was being signed).
Looking at TLS implementations for another client, I found some subtle ways to break an RSA implementation, which in turned transformed into a white paper (with one of the inventor of RSA) leading to a number of <a href="https://eprint.iacr.org/2018/1173">Common Vulnerabilities and Exposures (CVEs) reported to a dozen of open source projects</a>.
More recently, reading about Matrix as part of writing my book, I realized that their authentication protocol was completely broken, <a href="https://matrix.org/security-disclosure-policy/">leading to a complete break of their end-to-end encryption</a>.</p>
<p><img alt="comic" src="https://www.cryptologie.net/upload/HEY_MERE_S_AN.png"></p>
<p>There’s so many details that can unfortunately collapse under you, when making use of cryptography.
At that point, I knew I had to write something about it.
This is why my book contains many of these anecdotes.</p>
<p>As part of the job, I would review cryptography libraries and applications in a multitude of programming languages.
I discovered bugs (for example <a href="https://cryptologie.net/article/347/my-first-cve-o/?utm_content=buffer5c408&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer">CVE-2016-3959</a> in Golang’s standard library), I researched ways that libraries could fool you into misusing them (for example see my paper <a href="https://eprint.iacr.org/2016/644">How to Backdoor Diffie-Hellman</a>), and I advised on what libraries to use.
Developers never knew what library to use, and I always found the answer to be tricky.</p>
<p>I went on to invent the <a href="https://discocrypto.com/">disco protocol</a>, and wrote a fully-featured cryptographic library in less than 1,000 lines of code in several languages.
Disco only relied on two cryptographic primitives: the permutation of SHA-3 and curve25519.
Yes, from only these two things in 1,000 lines of code a developer could do any type of authenticated key exchange, signatures, encryption, MACs, hashing, key derivation, etc.
This gave me a unique perspective as to what a good cryptographic library was supposed to be.</p>
<p>I wanted my book to contain these kind of practical insights.
So naturally, the different chapters contain examples on how to do crypto in different programming languages, using well-respected cryptographic libraries.</p>
<h2>A need for a new book?</h2>
<p>As I was giving <a href="https://www.blackhat.com/us-17/training/beyond-the-beast-a-broad-survey-of-crypto-vulnerabilities.html">one of my annual cryptography training at Black Hat</a>, one student came to me and asked if I could recommend a good book or online course on cryptography.
I remember advising the student to read <a href="http://toc.cryptobook.us/">the book from Boneh &amp; Shoup</a> and <a href="https://crypto.stanford.edu/~dabo/courses/OnlineCrypto/">Cryptography I from Boneh on Coursera</a>.</p>
<p>The student told me “<em>Ah, I tried, it’s too theoretical!</em>”.
This answer stayed with me.
I disagreed at first, but slowly realized that they were right.
Most of these resources were pretty heavy in math, and most developers interacting with cryptography don’t want to deal with math.
 What else was there for them?
The other two somewhat respected resources at the time were Applied Cryptography and Cryptography Engineering (both from Schneier).
But these books were starting to be quite outdated.
Applied Cryptography spent 4 chapters on block ciphers, with a whole chapter on cipher modes of operation but none on authenticated encryption.
Cryptography Engineering had a single mention of elliptic curve cryptography (in a footnote).</p>
<p>On the other hand, many of my videos or blog posts were becoming good primary references for some cryptographic concepts.</p>
<p><strong>I knew I could do something special</strong>.</p>
<p>Gradually, many of my students started becoming interested in cryptocurrencies, asking more and more questions on the subject.
At the same time, I started to audit more and more cryptocurrency applications.
I finally moved to a job at Facebook to work on <a href="https://libra.org/">Libra</a>.
Cryptocurrency was now one of the hottest field to work on, mixing a multitude of extremely interesting cryptographic primitives that so far had seen no real-world use case (zero knowledge proofs, aggregated signatures, threshold cryptography, multi-party computations, consensus protocols, cryptographic accumulators, verifiable random functions, verifiable delay functions, ... the list goes on)</p>
<p><strong>I was now in a unique position</strong>.</p>
<p>I knew I could write something that would tell students, developers, consultants, security engineers, and others, what modern applied cryptography was all about.</p>
<p><img alt="book" src="https://www.cryptologie.net/upload/needs_to_send_a_let.png"></p>
<p>This was going to be a book with very little …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cryptologie.net/article/504/why-im-writing-a-book-on-cryptography/">https://www.cryptologie.net/article/504/why-im-writing-a-book-on-cryptography/</a></em></p>]]>
            </description>
            <link>https://www.cryptologie.net/article/504/why-im-writing-a-book-on-cryptography/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23743218</guid>
            <pubDate>Sun, 05 Jul 2020 23:45:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Summary: Designing Data-Intensive Applications by Martin Kleppmann]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23743185">thread link</a>) | @hoanhan101
<br/>
July 5, 2020 | https://hoanhan101.github.io/2020/07/05/design-data-intensive-apps | <a href="https://web.archive.org/web/*/https://hoanhan101.github.io/2020/07/05/design-data-intensive-apps">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main"><article role="article"><p>Principles and practicalities of data systems and how to build data-intensive applications.</p><time datetime="2020-07-05T00:00:00-04:00"> July 5, 2020 · 30 mins read · <a href="https://hoanhan101.github.io/category/System-design-notes">System design notes</a><hr> </time><h2 id="i-4-fundamental-ideas-that-we-need-in-order-to-design-data-intensive-applications">I. 4 fundamental ideas that we need in order to design data-intensive applications.</h2><ul><li>Reliable, scalable, maintainable applications.<ul><li>Reliability means continuing to work correctly, even when things go wrong. Common faults and preventions include:<ul><li>Hardware faults: hard disks crash, blackout, incorrect network configuration,…<ul><li>Add redundancy to individual hardware components to reduce the failure rate.</li><li>As long as we can restore a backup onto a new machine quickly, the downtime is not fatal.</li></ul></li><li>Software faults: bug, out of shared resources, unresponsive service, cascading failure,…<ul><li>There’s no quick solution other than thorough testing, measuring, monitoring, analyzing.</li></ul></li><li>Human errors: design error, configuration error,…<ul><li>Enforce good design, good practice and training.</li><li>Decouple the places where people make the most mistake.</li><li>Automate testing: unit test, integration test, end-to-end test.</li><li>Allow quick recovery rollback strategy.</li><li>Set up details monitoring</li></ul></li></ul></li><li>Scalability describes a system’s ability to cope with increased load.<ul><li>Describing load: requests per second, read/write radio, active users, cache hit rate,…</li><li>Describing performance:<ul><li>When you increase a load parameter, keep system resources unchanged, how is performance affected?</li><li>When you increase a load parameter, how much do you increase the resources if you want to keep performance unchanged?</li></ul></li><li>Approaches for coping with load:<ul><li>Scaling up (vertical scaling): move to a more powerful machine.</li><li>Scaling out (horizontal scaling): distribute the load across different machines.</li></ul></li></ul></li><li>Maintainability focuses on 3 design principles:<ul><li>Operability: make it easy for operation teams to keep the system running smoothly.<ul><li>Provide monitoring system health.</li><li>Support for automation and integration tools.</li><li>Have Good documentation.</li></ul></li><li>Simplicity: make it easy for new engineers to understand the system.<ul><li>Provide good abstraction layers that allow us to extract parts of a large system into well-defined, reusable components.</li></ul></li><li>Evolvability: make it easy for engineers to make changes.<ul><li>Follow agile approach.</li></ul></li></ul></li></ul></li><li>Data models and query languages.<ul><li>Data started out being represented as one big tree, though it wasn’t good for representing many-to-many relationships models, so the relational model was invented.</li><li>However, some applications didn’t fit well into the relational model, non-relational NoSQL was born:<ul><li>Document database: self-contained documents, rare relationships between one model and another.</li><li>Graph database: anything is related to everything.</li></ul></li></ul></li><li>Storage and retrieval.<ul><li>Data structres that power your database:<ul><li>Hash indexes:<ul><li>Basically key-value pairs where each key is mapped to a byte offset in the data file.</li><li>Can also split it into smaller chunks/segments for easy storing.</li><li>Even though it’s easy to understand and implement, it has memory constrains that the hash table must fit in memory. Also range queries are not efficient since hashed keys are not put next to each other.</li></ul></li><li>Sorted String Table (SSTable) and Log-Structured Merge-Tree (LSM-trees):<ul><li>SSTable maintains a list of key-value pairs that is sorted by key.</li><li>The table can also be split into smaller segments and merging is simple as it is sorted.</li><li>Maintaining a sorted structure on disk is possible, though keeping it in memory is easy as we can use a tree data structure such as Red-Black trees or AVL trees (memtable).</li><li>If the database crashes, memtable might be lost though we can keep a separate log for it, inspired by LSM-tree indexing structure.</li></ul></li><li>B-trees:<ul><li>Like SSTables, B-trees keep key-value pairs sorted by key, which allows efficient key-value lookups and range queries.</li><li>Instead of breaking down the database into variable-size segments and always writing sequentially, B-trees break into fixed-size blocks/pages and reading/writing one page at a time.</li><li>Every modification is first written to a write-ahead log (WAL) so that the index can be restored to a consistent state after a crash.</li></ul></li></ul></li><li>Transactional processing or analytic?<ul><li>The basic database access pattern is similar to processing business transaction (create, read, update, delete record), as known as online transaction processing (OLTP).</li><li>Since OLTP are expected to be highly available as they’re critical to the operation of the business, they’re reluctant to let business analysts run ad-hoc analytic queries.</li><li>A data warehouse is a separate database that analysts can query without affecting OLTP operations.<ul><li>Data is extracted from OLTP databases, transformed into an analysis-friendly schema, cleaned up, and then loaded into the data warehouse.</li><li>A big advantage of using a separate data warehouse is that the data warehouse can be optimized for analytic access patterns.</li><li>2 popular schemas that data are stored in are star schema, snowflake schema.</li></ul></li></ul></li><li>Column-oriented storage:<ul><li>In most OLTP databases, storage is laid out in a row-oriented fashion: all the values from one row of a table are stored next to each other. In the column-oriented storage, all the values are stored from each column together instead.</li><li>Since the sequences of values for each column are often look repetitive (distinct values are small), they often lend themselves well to compression.</li></ul></li><li>Aggregation:<ul><li>Since data warehouse queries often involve an aggregate function, such as COUNT, SUM, AVG, MIN or MAX, we can cache these aggregated values that are used often.</li><li>One way of creating such a cache is a materialized view, while data cube is a special case.</li></ul></li></ul></li><li>Encoding and evolution.<ul><li>Formats for encoding data.<ul><li>Many languages come with built-in support for encoding in-memory objects to byte sequences though they are not used because it’s language-specific and don’t show good performance.</li><li>JSON, XML are widely known, supported due to the fact that they are simple, can be used by many languages and have built-in support for web browser. However, there are a lot of ambiguity around the encoding of numbers and they also don’t support binary encoding (compact, efficient encoding). Hence the development of MessagePack, BSON, BJSON, and so on.</li><li>Thrift and Protocol Buffers are binary encoding libraries that require a schema for any data that is encoded, that is clearly defined forward and backward compatibility semantics. They come with a code generation tool that produces classes that implement the schema in various programming languages.</li><li>There’s is also a binary encoding library Avro that is good for processing large files as in Hadoop’s use cases.</li></ul></li><li>Modes of data flow (from one process to anther).<ul><li>Databases: the process writing to the database encodes the data, and the process reading from the database decodes it.</li><li>Calls to services, REST and RPC (gRPC): client encodes a request, server decodes the request and encodes a response, and client finally decodes the response.</li><li>Asynchronous message-passing (RabbitMQ, Apache Kafka): nodes send each other messages that are encoded by the sender and decoded by the recipient.</li></ul></li></ul></li></ul><h2 id="ii-replication-partitioningsharding-transactions-and-what-it-means-to-achieve-consistency-and-consensus-in-a-distributed-system">II. Replication, partitioning/sharding, transactions, and what it means to achieve consistency and consensus in a distributed system.</h2><ul><li>Replication.<ul><li>Why would you want to replicate data?<ul><li>Reduce latency by keeping data geographically close to users.</li><li>Increase availability.</li><li>Increase throughput.</li></ul></li><li>2 types of algorithms are leader-based replication and leaderless replication.</li><li>Leader-based replication:<ul><li>Workflow:<ul><li>One of the replicas is designed as the leader while others are followers.</li><li>Client must send write request to the leader though can send read request to both leader and followers.</li><li>After the leader writes data to its local storage, it sends the changes to all of its followers so that they can self apply accordingly.</li></ul></li><li>An important detail of a replicated system is whether the replication happens synchronously or asynchronously.<ul><li>Even though the advantage of synchronous replication is that followers is that the follower is guaranteed to have an up-to-date data, if the synchronous follower doesn’t respond, the write cannot be processed, thus the leader must block all writes and wait until one is available again.</li><li>It is impractical for all followers to be synchronous so leader-based replication is often configured to be completely asynchronous.</li></ul></li><li>From time to time, you need to set up new followers to increase the number of replicas, or to replace failed nodes. This can usually be done without downtime by maintaining a consistent snapshot of the leader’s database.</li><li>If the follower goes down, it can recover quite easily from its logs that it has received from the leader. Later when it’s able to talk to the leader again, it can request all the missing data and catch up to the leader.</li><li>If the leader goes down, a possible approach is failover: one of the followers needs to be promoted to be the new leader using a consensus algorithm, clients and followers need to be configured to talk to the new leader. However, failover can go wrong as well (two leaders, choosing the right timeout before the leader is declared dead,…) as there are no easy solutions to these.</li><li>Different implementation of replication logs:<ul><li>Statement-based replication: the leader logs every write request that it executes, and sends that statement log to its followers. Even though it seems reasonable, non-deterministic function, such as NOW() to get current date and time, is likely to generate a different value on each replica.</li><li>Write-ahead log (WAL) shipping: similar to B-tree’s approach where every modification is first written to a WAL, besides writing the log to disk, the leader also sends it to its followers so that they can build a copy of the exact same data structures as found on the leader.</li><li>Logical log replication: allow the replication log to be decoupled from the storage engine by using different log formats.</li><li>Trigger-based replication: register a trigger to only replicate subset of the data, or from one kind of database to another and so on.</li></ul></li><li>Replication lags:<ul><li>If the user view the data shortly after making the write, new data may have not yet reach the replica. In this case, we need …</li></ul></li></ul></li></ul></li></ul></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hoanhan101.github.io/2020/07/05/design-data-intensive-apps">https://hoanhan101.github.io/2020/07/05/design-data-intensive-apps</a></em></p>]]>
            </description>
            <link>https://hoanhan101.github.io/2020/07/05/design-data-intensive-apps</link>
            <guid isPermaLink="false">hacker-news-small-sites-23743185</guid>
            <pubDate>Sun, 05 Jul 2020 23:40:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Letters to a New Developer, the Book]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23743072">thread link</a>) | @mooreds
<br/>
July 5, 2020 | https://letterstoanewdeveloper.com/the-book/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/the-book/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-wrapper">
		<div id="content">

	<div id="primary">
		<main id="main" role="main">

			
				
<article id="post-7718" class="page">
			<!-- .entry-header -->
	<div>
		
<p>“Letters To a New Developer” is now a book! Here’s the cover:</p>



<figure><img data-attachment-id="7720" data-permalink="https://letterstoanewdeveloper.com/letters-to-a-new-developer/" data-orig-file="https://letterstoanewdeveloper.files.wordpress.com/2020/07/letters-to-a-new-developer.png" data-orig-size="827,1181" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="letters-to-a-new-developer" data-image-description="" data-medium-file="https://letterstoanewdeveloper.files.wordpress.com/2020/07/letters-to-a-new-developer.png?w=210" data-large-file="https://letterstoanewdeveloper.files.wordpress.com/2020/07/letters-to-a-new-developer.png?w=717" src="https://letterstoanewdeveloper.files.wordpress.com/2020/07/letters-to-a-new-developer.png?w=717" alt="" srcset="https://letterstoanewdeveloper.files.wordpress.com/2020/07/letters-to-a-new-developer.png?w=717 717w, https://letterstoanewdeveloper.files.wordpress.com/2020/07/letters-to-a-new-developer.png?w=105 105w, https://letterstoanewdeveloper.files.wordpress.com/2020/07/letters-to-a-new-developer.png?w=210 210w, https://letterstoanewdeveloper.files.wordpress.com/2020/07/letters-to-a-new-developer.png?w=768 768w, https://letterstoanewdeveloper.files.wordpress.com/2020/07/letters-to-a-new-developer.png 827w" sizes="(max-width: 717px) 100vw, 717px"><figcaption>The Cover of Letters to a New Developer</figcaption></figure>



<p>It’s based on this blog, with ideas, text and guest posts drawn from it. The format is similar: letters covering a variety of topics. However, all the content has been thoroughly reviewed, organized and rewritten. You’ll also see new letters covering topics such as why to build a personal board of advisors and discovering your wood lot (trust me, it makes sense when you read it).</p>



<p>The current launch date is <strong>Sep 9, 2020</strong>. You can pre-order it here:</p>



<ul><li><a href="https://www.indiebound.org/book/9781484260739">Indiebound</a></li><li><a href="https://bookshop.org/books/letters-to-a-new-developer-what-i-wish-i-had-known-when-starting-my-development-career/9781484260739">Bookshop</a></li><li><a href="https://www.amazon.com/Letters-New-Developer-Starting-Development/dp/1484260732/">Amazon</a></li><li><a href="https://www.barnesandnoble.com/w/letters-to-a-new-developer-dan-moore/1137054764">Barnes and Noble</a></li><li><a href="https://www.apress.com/us/book/9781484260739">Apress US website</a> (where you can buy the PDF) </li><li><a href="https://www.apress.com/gp/book/9781484260739">Apress European website</a></li></ul>



<p>Here’s the provisional table of contents:</p>



<ol><li>Introduction (they wouldn’t let me call it Chapter 0, even though developers start there)</li><li>Your first month</li><li>Questions</li><li>Writing</li><li>Tools</li><li>Practices</li><li>The Business</li><li> Learning</li><li>Mistakes</li><li>Career</li><li>Community</li></ol>



<p>If you’d rather be reminded when it is launches, please <a href="https://letterstoanewdeveloper.com/contact/">contact me and let me know</a>. You’ll also get a PDF of a sample letter.</p>
	</div><!-- .entry-content -->

	</article><!-- #post-## -->

				
			
		</main><!-- #main -->
	</div><!-- #primary -->

<!-- #secondary -->

		</div><!-- #content -->

		<!-- #colophon -->
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/the-book/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23743072</guid>
            <pubDate>Sun, 05 Jul 2020 23:24:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modern Object Pascal Introduction for Programmers]]>
            </title>
            <description>
<![CDATA[
Score 96 | Comments 36 (<a href="https://news.ycombinator.com/item?id=23742999">thread link</a>) | @eatonphil
<br/>
July 5, 2020 | http://newpascal.org/assets/modern_pascal_introduction.html | <a href="https://web.archive.org/web/*/http://newpascal.org/assets/modern_pascal_introduction.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<div>
<h2 id="_why">1. Why</h2>
<div>
<div>
<table>
<tbody><tr>
<td>
<p>Note</p>
</td>
<td>
This is a modified version of the original document from Michalis, because we (authors of <a href="http://newpascal.org/">http://newpascal.org/</a> and <a href="http://synopse.info/">http://synopse.info/</a> ) prefer the "mode delphi" without the "generic" / "specialize" keywords.
</td>
</tr>
</tbody></table>
</div>
<p>There are many books and resources about Pascal out there, but too many of them talk about the old Pascal, without classes, units or generics.</p>
<p>So I wrote this quick introduction to what I call <strong>modern Object Pascal</strong>. Most of the programmers using it don’t really call it <em>"modern Object Pascal"</em>, we just call it  <em>"our Pascal"</em>. But when introducing the language, I feel it’s important to emphasize that it’s a modern, object-oriented language. It evolved a <strong>lot</strong> since the old (Turbo) Pascal that many people learned in schools long time ago. Feature-wise, it’s quite similar to C++ or Java or C#.</p>
<div>
<ul>
<li>
<p>It has all the modern features you expect — classes, units, interfaces, generics…​</p>
</li>
<li>
<p>It’s compiled to a fast, native code,</p>
</li>
<li>
<p>It’s very type safe,</p>
</li>
<li>
<p>High-level but can also be low-level if you need it to be.</p>
</li>
</ul>
</div>
<p>It also has excellent, portable and open-source compiler called the <em>Free Pascal Compiler</em>, <a href="http://freepascal.org/">http://freepascal.org/</a> . And an accompanying IDE (editor, debugger, a library of visual components, form designer) called <em>Lazarus</em> <a href="http://lazarus.freepascal.org/">http://lazarus.freepascal.org/</a> . Myself, I’m the creator of <em>Castle Game Engine</em>, <a href="https://castle-engine.io/">https://castle-engine.io/</a> , which is a cool portable 3D and 2D game engine using this language to create games on many platforms (Windows, Linux, MacOSX, Android, iOS, web plugin).</p>
<p>This introduction is mostly directed at programmers who already have experience in other languages. We will not cover here the meanings of some universal concepts, like <em>"what is a class"</em>, we’ll only show how to do them in Pascal.</p>
</div>
</div>
<div>
<h2 id="_basics">2. Basics</h2>
<div>
<div>
<h3 id="__hello_world_program">2.1. "Hello world" program</h3>
<div>
<div>
<pre><code data-lang="pascal"><span>{$mode delphi}</span> 

<span>program</span> MyProgram; 
<span>begin</span>
  Writeln(<span><span>'</span><span>Hello world!</span><span>'</span></span>);
<span>end</span>.</code></pre>
</div>
</div>
<p>This is a complete program that you can <em>compile</em> and <em>run</em>.</p>
<div>
<ul>
<li>
<p>If you use the command-line FPC, just create a new file <code>myprogram.lpr</code> and execute <code>fpc myprogram.lpr</code>.</p>
</li>
<li>
<p>If you use <em>Lazarus</em>, create a new project (menu <em>Project</em> → <em>New Project</em> → <em>Simple Program</em>). Save it as <code>myprogram</code> and paste this source code as the main file. Compile using the menu item <em>Run → Compile</em>.</p>
</li>
<li>
<p>This is a command-line program, so in either case — just run the compiled executable from the command-line.</p>
</li>
</ul>
</div>
<p>The rest of this article talks about the Object Pascal language, so don’t expect to see anything more fancy than the command-line stuff. If you want to see something cool, just create a new GUI project in <em>Lazarus</em> (<em>Project</em> → <em>New Project</em> → <em>Application</em>).
Voila — a working GUI application, cross-platform, with native look everywhere, using a comfortable visual component library. The <em>Lazarus</em> and <em>Free Pascal Compiler</em> come with lots of ready units for networking, GUI, database, file formats (XML, json, images…​), threading and everything else you may need. I already mentioned my cool <em>Castle Game Engine</em> earlier:)</p>
</div>
<div>
<h3 id="_functions_procedures_primitive_types">2.2. Functions, procedures, primitive types</h3>
<div>
<div>
<pre><code data-lang="pascal"><span>{$mode delphi}</span>

<span>program</span> MyProgram;

<span>procedure</span> MyProcedure(<span>const</span> A: Integer);
<span>begin</span>
  Writeln(<span><span>'</span><span>A + 10 is: </span><span>'</span></span>, A + <span>10</span>);
<span>end</span>;

<span>function</span> MyFunction(<span>const</span> S: <span>string</span>): <span>string</span>;
<span>begin</span>
  Result := S + <span><span>'</span><span>strings are automatically managed</span><span>'</span></span>;
<span>end</span>;

<span>var</span>
  X: Single;
<span>begin</span>
  Writeln(MyFunction(<span><span>'</span><span>Note: </span><span>'</span></span>));
  MyProcedure(<span>5</span>);

  
  X := <span>15</span> / <span>5</span>;
  Writeln(<span><span>'</span><span>X is now: </span><span>'</span></span>, X); 
  Writeln(<span><span>'</span><span>X is now: </span><span>'</span></span>, X:<span>1</span>:<span>2</span>); 
<span>end</span>.</code></pre>
</div>
</div>
<p>To return a value from a function, assign something to the magic <code>Result</code> variable. You can read and set the <code>Result</code> freely, just like a local variable.</p>
<div>
<div>
<pre><code data-lang="pascal"><span>function</span> MyFunction(<span>const</span> S: <span>string</span>): <span>string</span>;
<span>begin</span>
  Result := S + <span><span>'</span><span>something</span><span>'</span></span>;
  Result := Result + <span><span>'</span><span> something more!</span><span>'</span></span>;
  Result := Result + <span><span>'</span><span> and more!</span><span>'</span></span>;
<span>end</span>;</code></pre>
</div>
</div>
<p>You can also treat the function name (like <code>MyFunction</code> in example above) as the variable, to which you can assign. But I would discourage it in new code, as it looks "fishy" when used on the right side of the assignment expression. Just use <code>Result</code> always when you want to read or set the function result.</p>
<p>If you want to call the function itself recursively, you can of course do it. If you’re calling a parameter-less function recursively, be sure to specify the parenthesis (even though in Pascal you can usually omit the parentheses for a parameter-less function), this makes a recursive call to a parameter-less function different from accessing this function’s current result. Like this:</p>
<div>
<div>
<pre><code data-lang="pascal"><span>function</span> ReadIntegersUntilZero: <span>string</span>;
<span>var</span>
  I: Integer;
<span>begin</span>
  Readln(I);
  Result := IntToStr(I);
  <span>if</span> I &lt;&gt; <span>0</span> <span>then</span>
    Result := Result + <span><span>'</span><span> </span><span>'</span></span> + ReadIntegersUntilZero();
<span>end</span>;</code></pre>
</div>
</div>
<p>You can call <code>Exit</code> to end the execution of the procedure or function before it reaches the final <code>end;</code>. If you call parameter-less <code>Exit</code> in a function, it will return the last thing you set as <code>Result</code>. You can also use <code>Exit(X)</code> construct, to set the function result and exit <strong>now</strong> — this is just like <code>return X</code> construct in C-like languages.</p>
<div>
<div>
<pre><code data-lang="pascal"><span>function</span> AddName(<span>const</span> ExistingNames, NewName: <span>string</span>): <span>string</span>;
<span>begin</span>
  <span>if</span> ExistingNames = <span><span>'</span><span>'</span></span> <span>then</span>
    Exit(NewName);
  Result := ExistingNames + <span><span>'</span><span>, </span><span>'</span></span> + NewName;
<span>end</span>;</code></pre>
</div>
</div>
</div>
<div>
<h3 id="_testing_if">2.3. Testing (if)</h3>
<p>Use <code>if .. then</code> or <code>if .. then .. else</code> to run some code when some condition is satisfied. Unlike in the C-like languages, in Pascal you don’t have to wrap the condition in parenthesis.</p>
<div>
<div>
<pre><code data-lang="pascal"><span>var</span>
  A: Integer;
  B: boolean;
<span>begin</span>
  <span>if</span> A &gt; <span>0</span> <span>then</span>
    DoSomething;

  <span>if</span> A &gt; <span>0</span> <span>then</span>
  <span>begin</span>
    DoSomething;
    AndDoSomethingMore;
  <span>end</span>;

  <span>if</span> A &gt; <span>10</span> <span>then</span>
    DoSomething
  <span>else</span>
    DoSomethingElse;

  
  B := A &gt; <span>10</span>;
  <span>if</span> B <span>then</span>
    DoSomething
  <span>else</span>
    DoSomethingElse;
<span>end</span>;</code></pre>
</div>
</div>
<p>The <code>else</code> is paired with the last <code>if</code>. So this works as you expect:</p>
<div>
<div>
<pre><code data-lang="pascal"><span>if</span> A &lt;&gt; <span>0</span> <span>then</span>
  <span>if</span> B &lt;&gt; <span>0</span> <span>then</span>
    AIsNonzeroAndBToo
  <span>else</span>
    AIsNonzeroButBIsZero;</code></pre>
</div>
</div>
<p>While the example with nested <code>if</code> above is correct, it is often better to place the nested <code>if</code> inside a <code>begin</code> …​ <code>end</code> block in such cases. This makes the code more obvious to the reader, and it will remain obvious even if you mess up the indentation. The improved version of the example is below. When you add or remove some <code>else</code> clause in the code below, it’s obvious to which condition it will apply (to the <code>A</code> test or the <code>B</code> test), so it’s less error-prone.</p>
<div>
<div>
<pre><code data-lang="pascal"><span>if</span> A &lt;&gt; <span>0</span> <span>then</span>
<span>begin</span>
  <span>if</span> B &lt;&gt; <span>0</span> <span>then</span>
    AIsNonzeroAndBToo
  <span>else</span>
    AIsNonzeroButBIsZero;
<span>end</span>;</code></pre>
</div>
</div>
</div>
<div>
<h3 id="_logical_relational_and_bit_wise_operators">2.4. Logical, relational and bit-wise operators</h3>
<p>The <em>logical operators</em> are called <code>and</code>, <code>or</code>, <code>not</code>, <code>xor</code>. Their meaning is probably obvious (search for <em>"exclusive or"</em> if you’re unsure what <em>xor</em> does:). They take <em>boolean arguments</em>, and return a <em>boolean</em>. They can also act as <em>bit-wise operators</em> when both arguments are integer values, in which case they return an integer.</p>
<p>The <em>relational (comparison)</em> operators are <code>=</code>, <code>&lt;&gt;</code>, <code>&gt;</code>, <code>&lt;</code>, <code>&lt;=</code>, <code>&gt;=</code>. If you’re accustomed to C-like languages, note that in Pascal you compare two values (check are they equal) using a single equality character <code>A = B</code> (unlike in C where you use <code>A == B</code>). The special <em>assignment</em> operator in Pascal is <code>:=</code>.</p>
<p>The <em>logical (or bit-wise) operators have a higher precedence than relational operators</em>. So you may need to use parenthesis around some expressions.</p>
<p>For example this is a compilation error:</p>
<div>
<div>
<pre><code data-lang="pascal"><span>var</span>
  A, B: Integer;
<span>begin</span>
  <span>if</span> A = <span>0</span> <span>and</span> B &lt;&gt; <span>0</span> <span>then</span> ... </code></pre>
</div>
</div>
<p>The above fails to compile, because the compiler sees the bit-wise <code>and</code> inside: <code>(0 and B)</code>.</p>
<p>This is correct:</p>
<div>
<div>
<pre><code data-lang="pascal"><span>var</span>
  A, B: Integer;
<span>begin</span>
  <span>if</span> (A = <span>0</span>) <span>and</span> (B &lt;&gt; <span>0</span>) <span>then</span> ...</code></pre>
</div>
</div>
<p>The <em>short-circuit evaluation</em> is used. Consider this expression:</p>
<div>
<div>
<pre><code data-lang="pascal"><span>if</span> MyFunction(X) <span>and</span> MyOtherFunction(Y) <span>then</span>...</code></pre>
</div>
</div>
<div>
<ul>
<li>
<p>It’s guaranteed that <code>MyFunction(X)</code> will be evaluated first.</p>
</li>
<li>
<p>And if <code>MyFunction(X)</code> returns <code>false</code>, then the value of expression is known (the value of <code>false and whatever</code> is always <code>false</code>), and <code>MyOtherFunction(Y)</code> will not be executed at all.</p>
</li>
<li>
<p>Analogous rule is for <code>or</code> expression. There, if the expression is known to be <code>true</code> (because the 1st operand is <code>true</code>), the 2nd operand is not evaluated.</p>
</li>
<li>
<p>This is particularly useful when writing expressions like</p>
<div>
<div>
<pre><code data-lang="pascal"><span>if</span> (A &lt;&gt; <span>nil</span>) <span>and</span> A.IsValid <span>then</span>...</code></pre>
</div>
</div>
<p>This will work OK, even when <code>A</code> is <code>nil</code>.</p>
</li>
</ul>
</div>
</div>
<div>
<h3 id="_testing_single_expression_for_multiple_values_case">2.5. Testing single expression for multiple values (case)</h3>
<p>If a different action should be executed depending on the value of some expression, then the <code>case .. of .. end</code> statement is useful.</p>
<div>
<div>
<pre><code data-lang="pascal"><span>case</span> SomeValue <span>of</span>
  <span>0</span>: DoSomething;
  <span>1</span>: DoSomethingElse;
  <span>2</span>: <span>begin</span>
       IfItsTwoThenDoThis;
       AndAlsoDoThis;
     <span>end</span>;
  <span>3</span>..<span>10</span>: DoSomethingInCaseItsInThisRange;
  <span>11</span>, <span>21</span>, <span>31</span>: AndDoSomethingForTheseSpecialValues;
  <span>else</span> DoSomethingInCaseOfUnexpectedValue;
<span>end</span>;</code></pre>
</div>
</div>
<p>The <code>else</code> clause is optional. When no condition matches, and there’s no <code>else</code>, then nothing happens.</p>
<p>In you come from C-like languages, and compare this with <code>switch</code> statement in these languages, you will notice that there is no automatic <em>fall-through</em>. This is a deliberate blessing in Pascal. You don’t have to remember to place <code>break</code> instructions. In every execution, <em>at most one</em> branch of the <code>case</code> is executed, that’s it.</p>
</div>
<div>
<h3 id="_enumerated_and_ordinal_types_and_sets_and_constant_length_arrays">2.6. Enumerated and ordinal types and sets and constant-length arrays</h3>
<p>Enumerated type in Pascal is a very nice, opaque type. You will probably use it much more often than enums in other languages:)</p>
<div>
<div>
<pre><code data-lang="pascal"><span>type</span>
  TAnimalKind = (akDuck, akCat, akDog);</code></pre>
</div>
</div>
<p>The convention is to prefix the enum names with a two-letter shortcut of type name, hence <code>ak</code> = shortcut for <em>"Animal Kind"</em>. This is a useful convention, since the enum names are in the unit (global) namespace. So by prefixing them with <code>ak</code> prefix, you minimize the chances of collisions with other identifiers.</p>
<div>
<table>
<tbody><tr>
<td>
<p>Note</p>
</td>
<td>
The collisions in names are not a show-stopper. It’s Ok for different units to define the same identifier. But it’s a good idea to try to avoid the collisions anyway, to keep code simple to understand and grep.
</td>
</tr>
</tbody></table>
</div>
<div>
<table>
<tbody><tr>
<td>
<p>Note</p>
</td>
<td>
You can avoid placing enum names in the global namespace by directive <code>{$scopedenums on}</code>. This means you will have to access them qualified by a type name, like <code>TAnimalKind.akDuck</code>. The need for <code>ak</code> prefix disappears in this situation, and you will probably just call the enums <code>Duck, Cat, Dog</code>. This is …</td></tr></tbody></table></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://newpascal.org/assets/modern_pascal_introduction.html">http://newpascal.org/assets/modern_pascal_introduction.html</a></em></p>]]>
            </description>
            <link>http://newpascal.org/assets/modern_pascal_introduction.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742999</guid>
            <pubDate>Sun, 05 Jul 2020 23:15:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New Black Face: Neuland and Lithos as Stereotypography (2004)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23742978">thread link</a>) | @cardamomo
<br/>
July 5, 2020 | https://linedandunlined.com/archive/new-black-face/ | <a href="https://web.archive.org/web/*/https://linedandunlined.com/archive/new-black-face/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<header>
			
		</header>

		<blockquote>
  <p>“The Neuland Question comes up regularly, and alas without much resolution….” –Jonathan Hoefler</p>
</blockquote>

<p>The “Neuland Question” to which Jonathan Hoefler refers involves not just Neuland, a “display” typeface hand-carved in 1923 by Rudolf Koch (<a href="#p1">Plate 1</a>), but also Lithos, another “display” typeface digitally created in 1989 by Carol Twombly (<a href="#p2">Plate 2</a>). The Question can be put simply: How did these two typefaces come to signify Africans and African-Americans, regardless of how a designer uses them, and regardless of the purpose for which their creators originally intended them? The investigation of this question has four parts: first, an examination of the environments in which Koch and Twombly created the original typefaces; second, an examination of the graphic culture that surrounded African-Americans prior to the creation of Neuland through a close viewing of tobacco ephemera; third, an examination of the Art Deco (French Modern) style, the graphic culture most prevalent in the United States at the time of Neuland’s release; and finally, an examination of the ways designers use Neuland and Lithos today.</p>

<h2 id="plate-1"><a name="p1">Plate 1</a></h2>

<p><img src="https://linedandunlined.com/images/neuland/01.jpg" alt="Neuland"></p>

<h2 id="plate-2"><a name="p2">Plate 2</a></h2>

<p><img src="https://linedandunlined.com/images/neuland/02.jpg" alt="Lithos"></p>

<p>Rudolf Koch was born in 1876 and had a career that was both uninteresting and undistinguished until he enlisted in the German Army in 1907 to fight in World War I. Upon returning from the war, he commented to his close friend Siegfried Guggenheim that he was “profoundly stirred” by his experiences (10). The horrors of war inspired Koch to seek religion for himself and then preach the benefits of a religious life to his countrymen. Having experimented with the art of calligraphy shortly before enlisting, Koch returned to the art after WWI with the intention of making bold, noticeable typefaces that would shout to other Germans that following God’s path would help them find comfort from the trauma of war. Guggenheim notes, “Koch’s fonts after the war were designed for broadsides, postcards, etc. – not books [… they were designed] to demonstrate his religious fervency” (11–13). Neuland was such a face. Yale University Printer John Gambell suggests that Koch designed the face with the intent of making a modern version of the German black letter (or black face) style. Black letter fonts were used at the time for the setting of important texts, especially Bibles and church-related documents. Koch’s “new black face” attempted to preserve the flared, interlocking forms of the traditional black letter style, while at the same time adopting the sans-serif style around which modernists, like Paul Renner, were building their typefaces. Renner’s Futura, the quintessential example of modernist typography, was designed in 1927, only four years after the Klingspor Type Foundry released Koch’s Neuland (Rock).</p>

<p>Koch’s settings of Neuland in the original German specimen book published by the Klingspor Type Foundry support Gambell’s suggestion. He sets the type with minimal leading and kerning as black letter was typically set (<a href="#p345">Plate 3</a>). He inserts woodcuts and Greek cross-shaped (+) ampersands as well (<a href="#p345">Plate 4</a>), a common practice with black letter texts. However, Koch broke with black letter typesetting standards by stripping Neuland of the delicately interlocking serifs commonly used in black letter typography. The result, a font composed of heavy black forms, was visible from great distances and easily distinguishable from lighter-weight typefaces on a page. These qualities made Neuland suitable to advertising. Koch even attempted to set a classified ad in Neuland at the end of the German specimen book (<a href="#p345">Plate 5</a>).</p>

<h2 id="plates-3-4-and-5"><a name="p345">Plates 3, 4, and 5</a></h2>

<p><img src="https://linedandunlined.com/images/neuland/03-04-05.jpg" alt="Koch lettering"></p>

<p>By the time Neuland reached the United States, its distributor, the Continental Typefounder’s Association, had little interest in Neuland’s uses as a modern black letter, and the specimen book that they prepared promoted Neuland as exclusively an advertising typeface, a “type that attracts attention” (Koch, Loose File, “Klingspor Type Foundry”). The American specimen book showed Neuland used in advertising settings from bank bonds to drywall contracting (<a href="#p6">Plate 6</a>). Because of the absence of a black letter tradition in the United States and because of the way the Continental Typefounder’s Association promoted Neuland, Koch’s intentions for the font were entirely lost immediately after its introduction in America.</p>

<h2 id="plate-6"><a name="p6">Plate 6</a></h2>

<p><img src="https://linedandunlined.com/images/neuland/06.jpg" alt="Neuland specimen"></p>

<p>Just as Koch was trying to modernize an ancient form of writing with Neuland in 1923, so too was Carol Twombly with Lithos in 1989. Jonathan Hoefler suggests that “Lithos [is] an interpretation of ancient lapidary writing.” Twombly herself corroborates this:</p>

<blockquote>
  <p>Inscriptions honoring public figures or dedications for temples were intended for public viewing in ancient Greece. Geometric letterforms, free of adornment were chiseled into the stone. These basic shapes are the inspiration for Lithos.</p>
</blockquote>

<p>Letterforms like those that inspired Lithos can be seen not only on ancient Greek temples, but also on many modern buildings built in the Classical or Gothic styles, such as on the front entrance to Sterling Memorial Library at Yale University. In his famous book <em>The Elements of Typographic Style</em>, critic Robert Bringhurst notes that many modern typefaces take their inspiration from architectural sources, and, indeed, many of Twombly’s typefaces, like Lithos, come from ancient architecture: Trajan, a serifed face, evolved from carvings on columns in ancient Rome; and Charlemagne, another serifed face, evolved from carvings found in Byzantine temples.</p>

<p>Although Twombly left Trajan and Charlemagne relatively unaltered from their original forms, she made a substantial alteration in Lithos. Twombly decided to create a bold weight for Lithos in addition to its book weight, even though bold-weighted letterforms were nonexistent in ancient Greece. John Gambell suggests that Twombly “may have felt the font was not marketable today without a bold weight.” Regardless of her reasons, Lithos’ bold-weighted anachronism is now Neuland’s bastard child. Lithos’ flared edges, heavy lines, square characters, and pen-like strokes are analogous to Neuland’s trademark elements, and the fonts are virtually identical to the untrained eye. Indeed, Lithos’ close formal approximation to Neuland makes it virtually interchangeable with Neuland for designers working on African and African-American projects.</p>

<p>Because Lithos follows Neuland historically and formally, and because printers and designers used Neuland in African and African-American projects before Twombly even conceived Lithos, the resolution of the Neuland Question rests in reconstructing Neuland’s history.</p>

<p>Primarily because of both constant anti-African-American sentiment and the socioeconomic status of African-Americans during and after the Civil War, African-American graphic culture in the United States prior to Neuland’s release in 1923 and before the Harlem Renaissance in general was unimportant at best and nonexistent at worst. In short, African-Americans did not have the buying power or the social acceptance required to cultivate a significant graphic culture. What graphic culture they did have centered around their depiction in advertisements for products associated with slavery: tobacco and cotton.</p>

<p>Tremendous amounts of ephemera surrounded the tobacco industry from the 1850s until the 1930s, much of which involved racist uses of African-Americans as mascots. Much of this ephemera took the form of trading cards given out in general stores, on street corners, or wherever tobacco was sold (<a href="#p7">Plate 7</a>). These trading cards were common media for advertising from the 1850s to the 1930s, and generally involved a caricatured picture of a “Negro” and a slogan in dialect (“Sho’ fly, git away from dar”) on the front and information about the product on the back (<a href="#p8">Plate 8</a>). As tobacco companies had to make these cards cheaply and copiously, the text on the back of these cards was often poorly set with cheap woodblock type rather than with more expensive metal type.</p>

<p>While today woodblock type has a certain nostalgic appeal, designers and typophiles (typographic historians and typography enthusiasts) into the 1950s saw woodblock letters as nothing but lower-class. Immediately upon its release, designers and typophiles linked Neuland’s forms with woodblock type and responded accordingly. In his book <em>Typographic Milestones</em>, typophile Allan Haley charges “Neuland is not considered a particularly practical, useful, or attractive typeface” (70). He later reiterates his point, saying, “[Neuland is] not especially attractive, nor even very useful […] its realistic applications are quite limited” (73). Typophiles like Haley frequently omitted Neuland from typographic histories altogether, and Neuland soon became a member of the family of fonts that designers call “garbage type”: esoteric, inelegant, difficult to set, and destined, like tobacco ephemera, for the garbage. Neuland’s figurative status as “garbage type” became a literal truth when, as popular design legend has it, printers threw the face away after becoming frustrated with the extraordinary weight of the thick lead letters and the large amount of space the alphabet consumed in their often small print shops.</p>

<h2 id="plate-7"><a name="p7">Plate 7</a></h2>

<p><img src="https://linedandunlined.com/images/neuland/07.jpg" alt="Trade cards"></p>

<h2 id="plate-8"><a name="p8">Plate 8</a></h2>

<p><img src="https://linedandunlined.com/images/neuland/08.jpg" alt="Trade cards"></p>

<p>Apart from being perceived as cheap “garbage,” woodblock type carried with it a legacy of cultural stereotype. Woodblock type was also known as “circus type” because of its frequent use in promoting circuses. An entire culture of “stereotypography” developed around these playful woodblock typefaces as certain “circus types” came to stand for stereotypical visual associations that Americans held about the cultures that the “circus types” were designed to represent. For example, circus promoters used the woodblock type Tokyo when promoting performers from the Orient (<a href="#p9">Plate 9</a>). Hometown, another “circus type,” is a near match for Neuland (<a href="#p10">Plate 10</a>), as is Othello, a heavy (black) sign-lettering typeface whose name alludes to the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://linedandunlined.com/archive/new-black-face/">https://linedandunlined.com/archive/new-black-face/</a></em></p>]]>
            </description>
            <link>https://linedandunlined.com/archive/new-black-face/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742978</guid>
            <pubDate>Sun, 05 Jul 2020 23:13:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remotely upgrading OpenWrt 15.05 to 19.07 on NAND flash boards]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23742942">thread link</a>) | @todsacerdoti
<br/>
July 5, 2020 | https://gir.st/blog/upgrading-openwrt.html | <a href="https://web.archive.org/web/*/https://gir.st/blog/upgrading-openwrt.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><a href="https://gir.st/">Home</a> | <a href="https://gir.st/blog">Blog</a> | <a href="https://gir.st/blog/upgrading-openwrt.html"><b>Upgrading OpenWrt (guide)</b></a>



<p>This guide will explain how to remotely, i.e. without having physical access to the machine, upgrade an embedded device from OpenWrt 15.05 or lower to LEDE 17.01 or OpenWrt 18.06/19.07. This process is usually not possible on systems equipped with NAND flash storage due to the root file system having been switched from yaffs2 to UBIFS without an official migration path in newer releases.
</p><p>This guide was written for our migration of Mikrotik Routerboard 450G, but should be applicable to a wide range of devices and possibly even manufacturers. Apply your usual judgement for when to deviate from the instructions.

</p><h2>Overview</h2>
<p>On a high level, the upgrade will take place in three parts: First, we prepare a specialized image (kernel + minimal initramfs) that fits solely within the "kernel" partition (<code>/dev/mtdblock5</code> on a Routerboard 450G). Secondly, we will replace the currently installed kernel with our boot image and boot from it. Finally, we transfer the stock <code>sysupgrade.bin</code> and our backup <code>tar.gz</code> and flash it using the official method—sysupgrade(8).

</p><figure> <!-- draw.io is neat :) -->
<svg width="312px" height="81px" viewBox="-0.5 -0.5 312 81"><!--{{{-->
<ellipse cx="60" cy="40" rx="60" ry="40" fill="#ffffff" stroke="#000000"></ellipse>
<text x="59.5" y="36.5" fill="#000000" font-family="Helvetica" font-size="12px" text-anchor="middle">Prepare bespoke</text>
<text x="59.5" y="50.5" fill="#000000" font-family="Helvetica" font-size="12px" text-anchor="middle">initramfs image</text>
<path d="M 120 40 L 173.63 40" fill="none" stroke="#000000" stroke-miterlimit="10"></path>
<path d="M 178.88 40 L 171.88 43.5 L 173.63 40 L 171.88 36.5 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10"></path>

<ellipse cx="240" cy="40" rx="60" ry="40" fill="#ffffff" stroke="#000000"></ellipse>
<text x="239.5" y="36.5" fill="#000000" font-family="Helvetica" font-size="12px" text-anchor="middle">Replace kernel and</text>
<text x="239.5" y="50.5" fill="#000000" font-family="Helvetica" font-size="12px" text-anchor="middle">boot custom image</text>
<path d="M 300 40 L 353.63 40" fill="none" stroke="#000000" stroke-miterlimit="10"></path>
<path d="M 358.88 40 L 351.88 43.5 L 353.63 40 L 351.88 36.5 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10"></path>


</svg><!--}}}--><svg width="312px" height="81px" viewBox="311 -0.5 312 81"><!--{{{-->
<path d="M 300 40 L 353.63 40" fill="none" stroke="#000000" stroke-miterlimit="10"></path>
<path d="M 358.88 40 L 351.88 43.5 L 353.63 40 L 351.88 36.5 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10"></path>


<ellipse cx="420" cy="40" rx="60" ry="40" fill="#ffffff" stroke="#000000"></ellipse>
<text x="419.5" y="36.5" fill="#000000" font-family="Helvetica" font-size="12px" text-anchor="middle">Transfer and flash</text>
<text x="419.5" y="50.5" fill="#000000" font-family="Helvetica" font-size="12px" text-anchor="middle">stock OpenWrt</text>
<path d="M 480 40 L 533.63 40" fill="none" stroke="#000000" stroke-miterlimit="10"></path>
<path d="M 538.88 40 L 531.88 43.5 L 533.63 40 L 531.88 36.5 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10"></path>

<ellipse cx="581" cy="40" rx="41" ry="40" fill="#ffffff" stroke="#000000"></ellipse>
<path d="M 549.2 44.08 C 549.2 56.25 563.44 66.12 581 66.12 C 598.56 66.12 612.8 56.25 612.8 44.08" fill="none" stroke="#000000" stroke-width="1.63" stroke-miterlimit="10"></path>
<path d="M 553.39 41.63 L 545.02 46.53" fill="#ffffff" stroke="#000000" stroke-miterlimit="10"></path>
<path d="M 608.61 41.63 L 616.98 46.53" fill="#ffffff" stroke="#000000" stroke-miterlimit="10"></path>
<ellipse cx="562.59" cy="28.57" rx="2.5102040816326534" ry="6.530612244897959" fill="#ffffff" stroke="#000000" stroke-width="4.9"></ellipse>
<ellipse cx="599.41" cy="28.57" rx="2.5102040816326534" ry="6.530612244897959" fill="#ffffff" stroke="#000000" stroke-width="4.9"></ellipse>
</svg><!--}}}-->
<figcaption>High level strategy</figcaption>
</figure>
<p>In the following steps, I will start with a bulleted list of the tasks, then explain them in detail.

</p><h2>Step 0: Backing up and checking compatibility</h2>
<ul>
<li>Prepare a backup with <kbd>sysupgrade -b /tmp/config.tar.gz</kbd>
</li><li>Verify the target device uses SLC NAND with <kbd>dmesg | grep nand</kbd>
</li></ul>
<p>If you intend to keep your current configuration, you should follow the <a href="https://openwrt.org/docs/guide-user/installation/generic.sysupgrade#preparing_for_an_openwrt_upgrade">Preparing To Upgrade</a> section from the OpenWrt documentation. <kbd>sysupgrade -b /tmp/config.tar.gz</kbd> should get you close. Keep in mind that OpenWrt has been overhauled dramatically, and changes to your configuration will probably be necessary.
</p><p>But before we can initiate the upgrade, we need to make sure your NAND flash is compatible with UBIFS. For a <a href="https://lists.openwrt.org/pipermail/openwrt-devel/2018-October/014454.html">short period of time in 2010</a>, Mikrotik installed cheaper and less reliable <abbr title="multi level cell">MLC</abbr> flash chips instead of the more reliable <abbr title="single level cell">SLC</abbr> ones. UBIFS predates MLC flash and will destroy it even when just reading from it due to a lack of an error correction daemon to fix the constantly occurring bitflips; the kernel will refuse to operate on such chips.
<br>To find out if you are affected, issue <kbd>dmesg | grep nand</kbd>. This command will return information about the chip on your device, including the type of NAND technology used (SLC or MLC). Flash storage from Samsung, Winbond, Numonyx or Micron is supposedly safe, while Hynix requires a closer look. Sadly, there is nothing you can do but to decommission the device if it has an MLC flash.
<!--<p>Side note: the <i>why</i> is pretty interesting, but would go far beyond the scope of this guide, so I'll just link you to the <a href="https://lists.openwrt.org/pipermail/openwrt-devel/2018-October/014324.html">mailing list thread</a> and the <a href="https://en.wikipedia.org/wiki/Multi-level_cell">MLC Wikipedia page</a>.-->
</p><details><summary>Sample <code>dmesg</code> output</summary>
SLC example:
<pre>[    2.252914] nand: device found, Manufacturer ID: 0x20, Chip ID: 0xdc
[    2.259309] nand: ST Micro NAND04GW3B2DN6
[    2.263313] nand: 512 MiB, <b>SLC</b>, erase size: 128 KiB, page size: 2048, OOB size: 64</pre>
MLC example:
<pre>[    0.825198] nand: device found, Manufacturer ID: 0xec<!--not actually hynix' ID-->, Chip ID: 0xdc
[    0.831588] nand: Hynix NAND 512MiB 3,3V 8-bit
[    0.836191] nand: 512MiB, <b>MLC</b>, page size: 2048, OOB size: 64</pre>
</details>

<h2>Step 1: Preparing an OpenWrt boot image</h2>
<ul>
<li>Set up an <a href="https://openwrt.org/docs/guide-developer/quickstart-build-images">OpenWrt build environment</a>, and configure it to include just the bare minimum
</li><li>Push additional files into your image using the <code>files/</code> directory
</li><li>Build <code>openwrt-*-vmlinux-initramfs-lzma.elf</code> with <kbd>make FILES=files/</kbd>
</li></ul>
<p>To get around the problem that the old kernel can't read the new filesystem and vice versa, we temporarily boot into a self-contained <i>initramfs</i> environment. This is essentially just a Linux kernel that has its own file system embedded and lives entirely in the kernel partition. Given our size constraints (~3.4MB), this image needs to be stripped down as much as possible and only come with a basic configuration to reach your network.
</p><p>Begin by following the <a href="https://openwrt.org/docs/guide-developer/quickstart-build-images">Quick Image Building Guide</a>. Start off by verifying that your build environment is working correctly by compiling a normal OpenWrt image by just modifying the Target System settings. <!--Note that the build system (not just during <code>feeds update</code>, but during <code>make</code> as well) requires connecting to a multitude of external hosts, so you might need an exception from your corporate firewall if you are behind such one. The error message in non-verbose mode is quite cryptic.-->
</p><p>When you feel ready, reissue <kbd>make menuconfig</kbd> and disable as much packages as possible. A <code>&lt;*&gt;</code> or <code>[*]</code> indicates that the package will be pre-installed and take up precious disk space. However, you must install an ssh daemon (dropbear) and the sysupgrade tool. You could also directly modify the <code>.config</code> file in your OpenWrt build environment.
</p><details><summary>Sample <code>.config</code> file</summary>
<pre><!--{{{-->
CONFIG_MODULES=y
CONFIG_HAVE_DOT_CONFIG=y
CONFIG_TARGET_ar71xx=y
CONFIG_TARGET_ar71xx_mikrotik=y
CONFIG_TARGET_ar71xx_mikrotik_DEVICE_nand-large=y
CONFIG_HAS_SUBTARGETS=y
CONFIG_HAS_DEVICES=y
CONFIG_TARGET_BOARD="ar71xx"
CONFIG_TARGET_SUBTARGET="mikrotik"
CONFIG_TARGET_PROFILE="DEVICE_nand-large"
CONFIG_TARGET_ARCH_PACKAGES="mips_24kc"
CONFIG_DEFAULT_TARGET_OPTIMIZATION="-Os -pipe -mno-branch-likely -mips32r2 -mtune=24kc"
CONFIG_CPU_TYPE="24kc"
CONFIG_LINUX_4_14=y
CONFIG_DEFAULT_base-files=y
CONFIG_DEFAULT_busybox=y
CONFIG_DEFAULT_dnsmasq=y
CONFIG_DEFAULT_dropbear=y
CONFIG_DEFAULT_firewall=y
CONFIG_DEFAULT_fstools=y
CONFIG_DEFAULT_ip6tables=y
CONFIG_DEFAULT_iptables=y
CONFIG_DEFAULT_iwinfo=y
CONFIG_DEFAULT_kmod-ath9k=y
CONFIG_DEFAULT_kmod-gpio-button-hotplug=y
CONFIG_DEFAULT_kmod-ipt-offload=y
CONFIG_DEFAULT_kmod-usb-ledtrig-usbport=y
CONFIG_DEFAULT_kmod-usb-ohci=y
CONFIG_DEFAULT_kmod-usb2=y
CONFIG_DEFAULT_libc=y
CONFIG_DEFAULT_libgcc=y
CONFIG_DEFAULT_logd=y
CONFIG_DEFAULT_mtd=y
CONFIG_DEFAULT_nand-utils=y
CONFIG_DEFAULT_netifd=y
CONFIG_DEFAULT_odhcp6c=y
CONFIG_DEFAULT_odhcpd-ipv6only=y
CONFIG_DEFAULT_opkg=y
CONFIG_DEFAULT_ppp=y
CONFIG_DEFAULT_ppp-mod-pppoe=y
CONFIG_DEFAULT_swconfig=y
CONFIG_DEFAULT_uboot-envtools=y
CONFIG_DEFAULT_uci=y
CONFIG_DEFAULT_uclient-fetch=y
CONFIG_DEFAULT_urandom-seed=y
CONFIG_DEFAULT_urngd=y
CONFIG_DEFAULT_wpad-basic=y
CONFIG_AUDIO_SUPPORT=y
CONFIG_GPIO_SUPPORT=y
CONFIG_PCI_SUPPORT=y
CONFIG_USB_SUPPORT=y
CONFIG_USB_GADGET_SUPPORT=y
CONFIG_BIG_ENDIAN=y
CONFIG_USES_INITRAMFS=y
CONFIG_USES_SQUASHFS=y
CONFIG_USES_MINOR=y
CONFIG_HAS_MIPS16=y
CONFIG_NAND_SUPPORT=y
CONFIG_mips=y
CONFIG_ARCH="mips"
CONFIG_TARGET_ROOTFS_INITRAMFS=y
CONFIG_TARGET_INITRAMFS_COMPRESSION_LZMA=y
CONFIG_EXTERNAL_CPIO=""
CONFIG_TARGET_ROOTFS_TARGZ=y
CONFIG_TARGET_ROOTFS_SQUASHFS=y
CONFIG_TARGET_SQUASHFS_BLOCK_SIZE=256
CONFIG_TARGET_UBIFS_FREE_SPACE_FIXUP=y
CONFIG_TARGET_UBIFS_JOURNAL_SIZE=""
CONFIG_SHADOW_PASSWORDS=y
CONFIG_KERNEL_BUILD_USER=""
CONFIG_KERNEL_BUILD_DOMAIN=""
CONFIG_KERNEL_PRINTK=y
CONFIG_KERNEL_CRASHLOG=y
CONFIG_KERNEL_SWAP=y
CONFIG_KERNEL_DEBUG_FS=y
CONFIG_KERNEL_KALLSYMS=y
CONFIG_KERNEL_DEBUG_KERNEL=y
CONFIG_KERNEL_DEBUG_INFO=y
CONFIG_KERNEL_AIO=y
CONFIG_KERNEL_FHANDLE=y
CONFIG_KERNEL_FANOTIFY=y
CONFIG_KERNEL_MAGIC_SYSRQ=y
CONFIG_KERNEL_COREDUMP=y
CONFIG_KERNEL_ELF_CORE=y
CONFIG_KERNEL_PRINTK_TIME=y
CONFIG_KERNEL_CGROUPS=y
CONFIG_KERNEL_FREEZER=y
CONFIG_KERNEL_CGROUP_FREEZER=y
CONFIG_KERNEL_CGROUP_DEVICE=y
CONFIG_KERNEL_CGROUP_PIDS=y
CONFIG_KERNEL_CPUSETS=y
CONFIG_KERNEL_CGROUP_CPUACCT=y
CONFIG_KERNEL_RESOURCE_COUNTERS=y
CONFIG_KERNEL_MM_OWNER=y
CONFIG_KERNEL_MEMCG=y
CONFIG_KERNEL_MEMCG_KMEM=y
CONFIG_KERNEL_CGROUP_SCHED=y
CONFIG_KERNEL_FAIR_GROUP_SCHED=y
CONFIG_KERNEL_RT_GROUP_SCHED=y
CONFIG_KERNEL_BLK_CGROUP=y
CONFIG_KERNEL_NET_CLS_CGROUP=y
CONFIG_KERNEL_NETPRIO_CGROUP=y
CONFIG_KERNEL_NAMESPACES=y
CONFIG_KERNEL_UTS_NS=y
CONFIG_KERNEL_IPC_NS=y
CONFIG_KERNEL_USER_NS=y
CONFIG_KERNEL_PID_NS=y
CONFIG_KERNEL_NET_NS=y
CONFIG_KERNEL_DEVPTS_MULTIPLE_INSTANCES=y
CONFIG_KERNEL_POSIX_MQUEUE=y
CONFIG_KERNEL_SECCOMP_FILTER=y
CONFIG_KERNEL_SECCOMP=y
CONFIG_KERNEL_IP_MROUTE=y
CONFIG_KERNEL_SQUASHFS_FRAGMENT_CACHE_SIZE=3
CONFIG_KERNEL_CC_OPTIMIZE_FOR_PERFORMANCE=y
CONFIG_USE_SSTRIP=y
CONFIG_USE_UCLIBCXX=y
CONFIG_PKG_CHECK_FORMAT_SECURITY=y
CONFIG_PKG_ASLR_PIE_REGULAR=y
CONFIG_PKG_CC_STACKPROTECTOR_REGULAR=y
CONFIG_KERNEL_CC_STACKPROTECTOR_REGULAR=y
CONFIG_KERNEL_STACKPROTECTOR=y
CONFIG_PKG_FORTIFY_SOURCE_1=y
CONFIG_PKG_RELRO_FULL=y
CONFIG_BINARY_FOLDER=""
CONFIG_DOWNLOAD_FOLDER=""
CONFIG_LOCALMIRROR=""
CONFIG_AUTOREBUILD=y
CONFIG_BUILD_SUFFIX=""
CONFIG_TARGET_ROOTFS_DIR=""
CONFIG_EXTERNAL_KERNEL_TREE=""
CONFIG_KERNEL_GIT_CLONE_URI=""
CONFIG_BUILD_LOG_DIR=""
CONFIG_EXTRA_OPTIMIZATION="-fno-caller-saves -fno-plt"
CONFIG_TARGET_OPTIMIZATION="-Os -pipe -mno-branch-likely -mips32r2 -mtune=24kc"
CONFIG_SOFT_FLOAT=y
CONFIG_USE_MIPS16=y
CONFIG_EXTRA_BINUTILS_CONFIG_OPTIONS=""
CONFIG_EXTRA_GCC_CONFIG_OPTIONS=""
CONFIG_GDB=y
CONFIG_USE_MUSL=y
CONFIG_SSP_SUPPORT=y
CONFIG_BINUTILS_VERSION_2_31_1=y
CONFIG_BINUTILS_VERSION="2.31.1"
CONFIG_GCC_VERSION="8.3.0"
CONFIG_LIBC="musl"
CONFIG_TARGET_SUFFIX="musl"
CONFIG_IB=y
CONFIG_IB_STANDALONE=y
CONFIG_TARGET_PREINIT_SUPPRESS_STDERR=y
CONFIG_TARGET_PREINIT_TIMEOUT=2
CONFIG_TARGET_PREINIT_IFNAME=""
CONFIG_TARGET_PREINIT_IP="192.168.1.1"
CONFIG_TARGET_PREINIT_NETMASK="255.255.255.0"
CONFIG_TARGET_PREINIT_BROADCAST="192.168.1.255"
CONFIG_TARGET_INIT_PATH="/usr/sbin:/usr/bin:/sbin:/bin"
CONFIG_TARGET_INIT_ENV=""
CONFIG_TARGET_INIT_CMD="/sbin/init"
CONFIG_TARGET_INIT_SUPPRESS_STDERR=y
CONFIG_PER_FEED_REPO=y
CONFIG_FEED_packages=y
CONFIG_FEED_luci=y
CONFIG_FEED_routing=y
CONFIG_FEED_telephony=y
CONFIG_PACKAGE_base-files=y
CONFIG_PACKAGE_busybox=y
CONFIG_BUSYBOX_CUSTOM=y
CONFIG_BUSYBOX_DEFAULT_HAVE_DOT_CONFIG=y
CONFIG_BUSYBOX_DEFAULT_INCLUDE_SUSv2=y
CONFIG_BUSYBOX_DEFAULT_LONG_OPTS=y
CONFIG_BUSYBOX_DEFAULT_SHOW_USAGE=y
CONFIG_BUSYBOX_DEFAULT_FEATURE_VERBOSE_USAGE=y
CONFIG_BUSYBOX_DEFAULT_FEATURE_COMPRESS_USAGE=y
CONFIG_BUSYBOX_DEFAULT_LFS=y
CONFIG_BUSYBOX_DEFAULT_FEATURE_DEVPTS=y
CONFIG_BUSYBOX_DEFAULT_FEATURE_PIDFILE=y
CONFIG_BUSYBOX_DEFAULT_PID_FILE_PATH="/var/run"
CONFIG_BUSYBOX_DEFAULT_FEATURE_PREFER_APPLETS=y
CONFIG_BUSYBOX_DEFAULT_BUSYBOX_EXEC_PATH="/proc/self/exe"
CONFIG_BUSYBOX_DEFAULT_FEATURE_SYSLOG=y
CONFIG_BUSYBOX_DEFAULT_PLATFORM_LINUX=y
CONFIG_BUSYBOX_DEFAULT_CROSS_COMPILER_PREFIX=""
CONFIG_BUSYBOX_DEFAULT_SYSROOT=""
CONFIG_BUSYBOX_DEFAULT_EXTRA_CFLAGS=""
CONFIG_BUSYBOX_DEFAULT_EXTRA_LDFLAGS=""
CONFIG_BUSYBOX_DEFAULT_EXTRA_LDLIBS=""
CONFIG_BUSYBOX_DEFAULT_INSTALL_APPLET_SYMLINKS=y
CONFIG_BUSYBOX_DEFAULT_PREFIX="./_install"
CONFIG_BUSYBOX_DEFAULT_NO_DEBUG_LIB=y
CONFIG_BUSYBOX_DEFAULT_FEATURE_BUFFERS_GO_ON_STACK=y</pre></details></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gir.st/blog/upgrading-openwrt.html">https://gir.st/blog/upgrading-openwrt.html</a></em></p>]]>
            </description>
            <link>https://gir.st/blog/upgrading-openwrt.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742942</guid>
            <pubDate>Sun, 05 Jul 2020 23:08:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing a winning 4K intro in Rust]]>
            </title>
            <description>
<![CDATA[
Score 266 | Comments 63 (<a href="https://news.ycombinator.com/item?id=23742870">thread link</a>) | @Dowwie
<br/>
July 5, 2020 | https://www.codeslow.com/2020/07/writing-winning-4k-intro-in-rust.html | <a href="https://web.archive.org/web/*/https://www.codeslow.com/2020/07/writing-winning-4k-intro-in-rust.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-4371838969983872321" itemprop="description articleBody">
<div><p><span>I recently wrote my first 4K intro in Rust and released it at the Nova 2020 where it took first place in the new school intro competition. Writing a 4K intro is quite involved and requires you to master many different areas at the same time. Here I will focus on what I learned about making Rust code as small as possible.</span></p><p><iframe allowfullscreen="" height="322" src="https://www.youtube.com/embed/SIkkYRQ07tU" width="387" youtube-src-id="SIkkYRQ07tU"></iframe></p><p>You can view the demo on<span>&nbsp;</span><a href="https://www.youtube.com/watch?v=SIkkYRQ07tU">youtube</a>, download the executable at<span>&nbsp;</span><a href="https://www.pouet.net/prod.php?which=85924">pouet</a><span>&nbsp;</span>or get the source code from<span>&nbsp;</span><a href="https://github.com/janiorca/sphere_dance">github</a></p><p>A 4K intro is a demo where the entire program ( including any data ) has two be 4096 bytes or less so it is important that the code is as space efficient as possible. Rust has a bit of a reputation for creating bloated executables so I wanted to find out if is possible to create very space efficient code with it.</p><p>The entire intro is written in a combination of Rust and glsl. Glsl is used for rendering everything on screen but Rust does everything else; world creation, camera and object control, creating instruments and playing music etc.</p><p>Some of the features I depend on, such as xargo, are not yet part of stable Rust so I use the nightly rust toolchain. To install and use the nightly toolchain as default you need the following rustup commands.</p><pre data-info="" data-role="codeBlock"><code>rustup toolchain install nightly
rustup default nightly
</code></pre><p>I use<span>&nbsp;</span><a href="http://crinkler.net/">crinkler</a><span>&nbsp;</span>to compress the object file generated by the rust compiler.</p><p>I also used<span>&nbsp;</span><a href="https://github.com/laurentlb/Shader_Minifier">shader minifier</a><span>&nbsp;</span>for pre-processing the<span>&nbsp;</span><code>glsl</code><span>&nbsp;</span>shader to make it smaller and more crinkler friendly. The shader minifier doesn't support output into<span>&nbsp;</span><code>.rs</code><span>&nbsp;</span>files so I ended up using its raw output and manually copying it into my<span>&nbsp;</span><a href="http://shader.rs/">shader.rs</a><span>&nbsp;</span>file. (In hindsight, I should have written something to automate that stage. Or even created a PR for shader minifier)</p><p>The starting point was the proof of concept code I developed earlier (<a href="https://www.codeslow.com/2020/01/writing-4k-intro-in-rust.html">https://www.codeslow.com/2020/01/writing-4k-intro-in-rust.html</a>) which I thought was pretty lean at the time. That article also goes into but more detail about setting up the<span>&nbsp;</span><code>toml</code><span>&nbsp;</span>file and how to use xargo for compiling tiny executable.</p><p>Many of the most effective size optimizations have nothing to do with clever hacks but are the result of rethinking the design.</p><p>My initial design had one part of the code creating the world, including placing the spheres and another part was responsible for moving the spheres. At some point I realized that the sphere placement and sphere moving code were doing very similar things and I could merge them into one sightly more complicated function that did both. Unfortunately, this type of optimization can make the code less elegant and readable.</p><p>At some point you have to look at the compiled assembly code to understand what the code gets compiled into and what size optimizations are worth it. The Rust compiler has a very useful option,<span>&nbsp;</span><code>--emit=asm</code><span>&nbsp;</span>for outputting assembler code. The following command creates a<span>&nbsp;</span><code>.s</code><span>&nbsp;</span>assembly file;</p><pre data-info="" data-role="codeBlock"><code>xargo rustc --release --target i686-pc-windows-msvc -- --emit=asm
</code></pre><p>It is not necessary to be an expert in assembler to benefit from studying the assembler output but it definitely helps to have a basic understanding assembler syntax. The release version uses<span>&nbsp;</span><code>opt-level = "z</code><span>&nbsp;</span>which causes the compiler to optimize for the smallest possible size. This can make it a bit tricky to work out which part of the assembly code corresponds to which part of the Rust code.</p><p>I discovered that the Rust compiler can be surprisingly good at minimizing code; getting rid of unused code and unnecessary parameters and folding code. It can also do some strange things which is why it is essential to occasionally study the resulting assembly code.</p><p>I worked with two versions of the code; one version does logging and allows the viewer to manipulate the camera which is used for creating interesting camera paths. Rust allows you to define<span>&nbsp;</span><strong>features</strong><span>&nbsp;</span>that you can use to optionally include bits of functionality. The<span>&nbsp;</span><code>toml</code><span>&nbsp;</span>file has a<span>&nbsp;</span><strong>[features]</strong><span>&nbsp;</span>section that lets you declare the available features and their dependencies. My 4K intro has the following section in the<span>&nbsp;</span><code>toml</code><span>&nbsp;</span>file;</p><pre data-info="toml" data-role="codeBlock"><span>[</span><span>features</span><span>]</span>
<span>logger</span> <span>=</span> <span>[</span><span>]</span>
<span>fullscreen</span> <span>=</span> <span>[</span><span>]</span>
</pre><p>Neither of the optional features has dependencies so they effectively work as being conditional compilation flags. The conditional blocks of code are preceded by<span>&nbsp;</span><code>#[cfg(feature)]</code><span>&nbsp;</span>statement. Using features in itself does not make the code smaller but it makes development process much nicer when you easily switch between different feature sets.</p><pre data-info="rust" data-role="codeBlock">        <span>#[cfg(feature = "fullscreen")]</span>
        <span>{</span>
            
        <span>}</span>

        <span>#[cfg(not(feature = "fullscreen"))]</span>
        <span>{</span>
            
        <span>}</span>
</pre><p>Having inspected the compiled code I am certain that only the selected features get included in the compiled code.</p><p>One of the main uses of<span>&nbsp;</span><strong>features</strong><span>&nbsp;</span>was to enable logging and error checking for the debug build. The code loading and compiling the glsl shader failed frequently and without useful error messages it would have been extremely painful to find the problems.</p><p>When putting code inside an<span>&nbsp;</span><code>unsafe{}</code><span>&nbsp;</span>block I sort of assumed that all safety checks would be disabled within this block but this is not true, all the usual checks are still applied and these checks can be expensive.</p><p>By default Rust range checks all array accesses. Take the following Rust code</p><pre data-info="rust" data-role="codeBlock">    delay_counter <span>=</span> sequence<span>[</span> play_pos <span>]</span><span>;</span>
</pre><p>Before doing the table look up the compiler would insert code that checks that play_pos is not indexing past the end of sequence and panic if that was the case. This adds considerable size to the code as there can be a lot of table look-ups like this.</p><p>Converting the above code into</p><pre data-info="rust" data-role="codeBlock">    delay_counter <span>=</span> <span>*</span>sequence<span>.</span><span>get_unchecked</span><span>(</span> play_pos <span>)</span><span>;</span>
</pre><p>tells the compiler to not perform any range checks and just do the table look-up. This is clearly a potentially dangerous operation and can thus only be performed within an<span>&nbsp;</span><code>unsafe</code><span>&nbsp;</span>code block</p><p>Initially all my loops used the idiomatic rust way of doing loops, using the<span>&nbsp;</span><code>for x in 0..10</code><span>&nbsp;</span>syntax which I just assumed would be compiled into tightest possible loop. Surprisingly, this was not the case. The simplest case;</p><pre data-info="rust" data-role="codeBlock"><span>for</span> x <span>in</span> <span>0</span><span>..</span><span>10</span> <span>{</span>
    
<span>}</span>
</pre><p>would get translated into assembly code that did the following;</p><pre data-info="" data-role="codeBlock"><code>    setup loop variable
loop:
    check for loop condition    
    if loop finished, jump to end
    // do code inside loop
    unconditionally jump to loop
end:
</code></pre><p>whereas if did the following rust code</p><pre data-info="rust" data-role="codeBlock"><span>let</span> x <span>=</span> <span>0</span><span>;</span>
<span>loop</span><span>{</span>
    
    x <span>+=</span> <span>1</span><span>;</span>
    <span>if</span> i <span>==</span> <span>10</span> <span>{</span>
        <span>break</span><span>;</span>
    <span>}</span>
<span>}</span>
</pre><p>would get directly compiled into;</p><pre data-info="" data-role="codeBlock"><code>    setup loop variable
loop:
    // do code inside loop
    check for loop condition    
    if loop not finished, jump to loop
end:
</code></pre><p>Note that the loop condition is checked at the end of each loop which makes the unconditional jump unnecessary. This is small space saving for one loop but they do add up when there are 30 loops in the program.</p><p>The other, much harder to understand, problem with the idiomatic Rust loop is that in some cases it the compiler would add some additional iterator setup code that really bloated the code. I never fully understood what triggered this additional iterator setup as it was always trivial to replace the<span>&nbsp;</span><code>for {}</code><span>&nbsp;</span>constructs with a<span>&nbsp;</span><code>loop{}</code><span>&nbsp;</span>construct.</p><p>I spent a lot of time optimizing the<span>&nbsp;</span><code>glsl</code><span>&nbsp;</span>code and one of the best class of optimizations ( which also usually made the code run faster) was to operate on an entire vector at a time instead of operating at a component at a time.</p><p>For example, the ray tracing code use a fast<span>&nbsp;</span><a href="http://www.cse.yorku.ca/~amana/research/grid.pdf">grid traversal algorithm</a><span>&nbsp;</span>to check which parts of the map each ray visits. The original algorithm considers each axis separately but it is possible to rewrite the algorithm so it considers all axes at the same time and does not need any branches. Rust doesn't really have a native vector type like glsl but you can use intrinsics to tell it to use SIMD instructions.</p><p>To use intrinsics I would convert the following code</p><pre data-info="rust" data-role="codeBlock">        global_spheres<span>[</span> CAMERA_ROT_IDX <span>]</span><span>[</span> <span>0</span> <span>]</span> <span>+=</span> camera_rot_speed<span>[</span> <span>0</span> <span>]</span><span>*</span>camera_speed<span>;</span>
        global_spheres<span>[</span> CAMERA_ROT_IDX <span>]</span><span>[</span> <span>1</span> <span>]</span> <span>+=</span> camera_rot_speed<span>[</span> <span>1</span> <span>]</span><span>*</span>camera_speed<span>;</span>
        global_spheres<span>[</span> CAMERA_ROT_IDX <span>]</span><span>[</span> <span>2</span> <span>]</span> <span>+=</span> camera_rot_speed<span>[</span> <span>2</span> <span>]</span><span>*</span>camera_speed<span>;</span>
</pre><p>into</p><pre data-info="rust" data-role="codeBlock">        <span>let</span> <span>mut</span> dst<span>:</span>x86<span>:</span><span>:</span>__m128 <span>=</span> core<span>:</span><span>:</span>arch<span>:</span><span>:</span>x86<span>:</span><span>:</span><span>_mm_load_ps</span><span>(</span>global_spheres<span>[</span> CAMERA_ROT_IDX <span>]</span><span>.</span><span>as_mut_ptr</span><span>(</span><span>)</span><span>)</span><span>;</span>
        <span>let</span> <span>mut</span> src<span>:</span>x86<span>:</span><span>:</span>__m128 <span>=</span> core<span>:</span><span>:</span>arch<span>:</span><span>:</span>x86<span>:</span><span>:</span><span>_mm_load_ps</span><span>(</span>camera_rot_speed<span>.</span><span>as_mut_ptr</span><span>(</span><span>)</span><span>)</span><span>;</span>
        dst <span>=</span> core<span>:</span><span>:</span>arch<span>:</span><span>:</span>x86<span>:</span><span>:</span><span>_mm_add_ps</span><span>(</span> dst<span>,</span> src<span>)</span><span>;</span>
        core<span>:</span><span>:</span>arch<span>:</span><span>:</span>x86<span>:</span><span>:</span><span>_mm_store_ss</span><span>(</span> <span>(</span><span>&amp;</span><span>mut</span> global_spheres<span>[</span> CAMERA_ROT_IDX <span>]</span><span>)</span><span>.</span><span>as_mut_ptr</span><span>(</span><span>)</span><span>,</span> dst <span>)</span><span>;</span>
</pre><p>which would be quite a bit smaller ( but a lot less readable ). Sadly, for some reason this broke the debug build while working perfectly on the release build. Clearly, this is a problem with my intrinsics knowledge and not a problem with Rust. This is something I would spend more time on for my next 4K intro as the space saving were significant.</p><p>There are lot of standard Rust crates for loading OpenGL functions but by default they all load a very large set of OpenGL functions. Each loaded function takes up some space because the loader has to know its name. Crinkler does a very good job of compressing this kind of code but it is not able to completely get rid of the overhead so I had to create my own version<span>&nbsp;</span><code>gl.rs</code><span>&nbsp;</span>that only includes the OpenGL functions that are used in the code.</p><p>My first objective was to write a competitive proper 4K intro to prove that language was suitable for scenarios where every single byte counts and you really need low level control. Typically this has been the sole domain of assembler and C. The secondary objective was to write it using idiomatic Rust as much possible.</p><p>I think I was fairly successful on the first objective. At no point during the development did I feel that Rust was holding me back in any way or that I was sacrificing performance or capabilities because I was using Rust rather than C.</p><p>I was less successful on the second objective. There is far too much<span>&nbsp;</span><code>unsafe</code><span>&nbsp;</span>code that doesn't really need to be there.<span>&nbsp;</span><code>Unsafe</code><span>&nbsp;</span>has a corrupting effect; it is very easy to use<span>&nbsp;</span><code>unsafe</code><span>&nbsp;</span>code to quickly accomplish something (like using mutable statics) but once the unsafe code is there it begets more unsafe code and suddenly it …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.codeslow.com/2020/07/writing-winning-4k-intro-in-rust.html">https://www.codeslow.com/2020/07/writing-winning-4k-intro-in-rust.html</a></em></p>]]>
            </description>
            <link>https://www.codeslow.com/2020/07/writing-winning-4k-intro-in-rust.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742870</guid>
            <pubDate>Sun, 05 Jul 2020 23:00:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Poor Man's Cluster]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23742683">thread link</a>) | @FilingTrader
<br/>
July 5, 2020 | http://www.regressionist.com/2020/07/05/poor-mans-cluster/ | <a href="https://web.archive.org/web/*/http://www.regressionist.com/2020/07/05/poor-mans-cluster/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/06/cluster.jpg" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/06/cluster.jpg 765w, http://www.regressionist.com/wp-content/uploads/2020/06/cluster-300x229.jpg 300w, http://www.regressionist.com/wp-content/uploads/2020/06/cluster-624x476.jpg 624w" sizes="(max-width: 765px) 100vw, 765px"></figure>



<p>This part might just be me cargo-culting, but I feel like even a startup quant fund needs a compute cluster. I once even heard a joke that any self-respecting quant should be able expand their computational needs to fill an arbitrarily large number of servers. The cluster I’ve just built is a low-budget clunker, made of a motley bunch of leftover and refurbished servers, linked together with parts off eBay. But I’m very proud of it!</p>



<h2>Maximum compute per dollar</h2>



<div><p>New servers cost a fortune, and only a small fraction of the cost is for the actual CPU. These servers are designed for use cases that cannot tolerate downtime, where the administrators are remote, and where all the hardware and even software must be supported by some company with expensive contracts. In contrast, my cluster is designed only for research. Downtime is ok, as long as no data gets lost and I get get back up and running easily. So, my focus is only on maximizing performance given a limited budget. I’m optimizing for compute per dollar. (Incidentally, I’ve found the <a href="https://www.cpubenchmark.net/cpu_list.php">PassMark CPU mark</a> to accurately reflect how well each CPU can handle my workload.)</p><p>There is a stigma around buying refurbished enterprise grade equipment that I don’t understand. Basic compute servers that cost $25k three years ago now cost only $2.5k, refurbished at places like <a href="https://www.metservers.com/">metservers.com</a> or <a href="https://www.stalliontek.com/">stalliontek.com</a>. Both of these companies provide warranties, too. Even better, these are real servers that already exist and can be shipped to you immediately, rather than waiting months for new ones due to things like worldwide memory shortages. New <a href="https://store.mellanox.com/products/mellanox-mcx515a-ccat-connectx-5-en-network-interface-card-100gbe-single-port-qsfp28-pcie3-0-x16-tall-bracket-rohs-r6.html">Mellanox 100GbE</a> infiniband cards cost $795 each, but on <a href="https://www.ebay.com/sch/i.html?_nkw=Mellanox+ConnectX-3+56GbE&amp;_sacat=0&amp;LH_TitleDesc=0&amp;_osacat=0&amp;_odkw=Mellanox+ConnectX-3+56">eBay 56GbE cards</a> can be bought for $40 each.</p></div>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/07/R630_front.jpg" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/07/R630_front.jpg 598w, http://www.regressionist.com/wp-content/uploads/2020/07/R630_front-300x87.jpg 300w" sizes="(max-width: 598px) 100vw, 598px"></figure>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/07/R630_back.jpg" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/07/R630_back.jpg 594w, http://www.regressionist.com/wp-content/uploads/2020/07/R630_back-300x107.jpg 300w" sizes="(max-width: 594px) 100vw, 594px"></figure>



<h2>NVMe vs. memory</h2>



<p>Memory can really drive up the cost of a server, doubling or tripling the price. I don’t think loading up on RAM is cost-effective at scale. Instead, I recommend NVMe drives as an affordable alternative. Typical RAM for a refurbished Dell R630 server would be DDR4-2133, which has bandwidth of 136Gbps. The Samsung 970 EVO Plus 2TB NVMe drive has a read speed of 28Gbps. With the right software, an old infiniband card can max out its 56Gbps bandwidth by reading simultaneously from NVMe drives on only 2-3 other boxes in the cluster. For my workload, this is close enough to RAM speed that I/O ceases to be a bottleneck, and I can focus on just getting the computations done.</p>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/07/nvme_vs_ram.png" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/07/nvme_vs_ram.png 828w, http://www.regressionist.com/wp-content/uploads/2020/07/nvme_vs_ram-300x200.png 300w, http://www.regressionist.com/wp-content/uploads/2020/07/nvme_vs_ram-768x512.png 768w, http://www.regressionist.com/wp-content/uploads/2020/07/nvme_vs_ram-624x416.png 624w" sizes="(max-width: 828px) 100vw, 828px"></figure>



<p>I have also chosen to go with retail NVMe drives. They cost far less than enterprise NVMe drives, and they have the same speed (PCIe Gen 3.0 x4) as all but the very newest enterprise drives. The advantage of enterprise drives is the longer lifetime, measured in hundreds or thousands of Terabytes written). But I tend to read far more than I write. Another advantage is that some enterprise drives are dual-port. This is a high-availability feature that allows two hosts to access the same drive, keeping it connected in case of host failure. But as I’ve said, I don’t need expensive high-availability features.</p>



<h2>Distributed storage</h2>



<p>Having a distributed filesystem simplifies coding on a cluster. It makes it feel almost like just working on one big machine. Each job reads and writes to a shared filesystem that is mounted locally, using traditional posix system calls.</p>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/07/mfs_and_beegfs.png" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/07/mfs_and_beegfs.png 901w, http://www.regressionist.com/wp-content/uploads/2020/07/mfs_and_beegfs-300x142.png 300w, http://www.regressionist.com/wp-content/uploads/2020/07/mfs_and_beegfs-768x364.png 768w, http://www.regressionist.com/wp-content/uploads/2020/07/mfs_and_beegfs-624x296.png 624w" sizes="(max-width: 901px) 100vw, 901px"></figure>



<p>After searching out <a href="http://www.regressionist.com/2020/06/20/reviews-of-distributed-filesystems/">filesystem reviews</a>, I decided to use <strong>MooseFS</strong> for my robust storage. It is easy to configure. It can handle my collection of drives of all sizes, and is robust to the failure of a drive, or even an entire server. It also has a nice browser-based monitoring tool. I have set it up to store one copy of each data chunk on an SSD, and the replicated chunk on a regular spinning disk. The clients are configured to prefer SSD chunkservers, which makes reading reasonably fast. Note: chunkserver labels apply to the whole server, so don’t mix SSDs and HDDs in one server if you want to explicitly prioritize reading from SSDs.</p>



<p>I considered paying for MooseFS Pro, but decided it was too expensive. For a 20TB lifetime license for versions 3.x and 4.x, I was quoted $1,620, or $810 if it was for non-commercial use. The main two benefits of getting a Pro license are 1) getting the high-availability of multiple online master servers instead of just metaloggers, and 2) getting erasure coding for more efficient use of storage space. The erasure coding is interesting to me, but for slow storage, big disks are really cheap. So, storing multiple full copies of a file isn’t such a big deal.</p>



<p>For serious speed, I’ve chosen <strong>BeeGFS</strong> with NVMe drives. BeeGFS supports RDMA (remote direct memory access) with infiniband, so it can move data between boxes without involving the CPUs. It is very fast. It is also relatively easy to configure. I am treating this sort of like volatile storage, and I have not set up “buddy mirrors.” Since I will lose data if my hardware fails, I frequently rsync with the robust storage. I was disappointed to find out that even Pro BeeGFS doesn’t support erasure coding. It would make more sense to use with these expensive NVMe drives. However, erasure coding also slows down both reading and writing. So, I’m ok with giving up robustness in order to have one blazing fast filesystem.</p>



<h2>Conclusion</h2>



<p>Benchmarking a distributed filesystem is complicated and workload-dependent. But everything is working as I hoped. My cluster is mostly hyperconverged, with CPU and storage combined in each server. However, I do have some servers that are clients/CPU only. They are less powerful, so I keep them powered off until needed, to conserve energy. I got an APC AP7911A rack-mount PDU on eBay, so controlling power to the different ports is easy.</p>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/07/apc-1.png" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/07/apc-1.png 488w, http://www.regressionist.com/wp-content/uploads/2020/07/apc-1-300x225.png 300w" sizes="(max-width: 488px) 100vw, 488px"></figure>



<p>Building a cluster has been a lot of fun, and previously slow processes are now excitingly fast. But I’m anxious to begin real research now, and stop messing around with infrastructure.</p>



<h2>Appendix A, configuring infiniband on CentOS 7</h2>



<p>As a non-HPC guy, learning about infiniband, and getting the network functioning was the hardest part of building the cluster. It took me a long time, and lots of reading and trial-and-error. For that reason, I think it’s worth posting detailed instructions on what eventually worked for me. I don’t believe I’m getting all that is possible out of my infiniband network, but I’m still very pleased with it.</p>



<h3>The cards</h3>



<p>I went with 79DJ3 Mellanox ConnectX-3 CX353A FDR InfiniBand + 56GbE/ 40GbE Single QSFP+ RDMA cards. The most recent ones I ordered on eBay were $35 each. I believe the PCIe lanes cannot handle the full bandwidth of the dual-port cards, which is why I stayed with the simpler single-port card/setup. I did have to order replacement brackets for a couple of my high-profile-PCIe computers.</p>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/06/79DJ3.png" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/06/79DJ3.png 785w, http://www.regressionist.com/wp-content/uploads/2020/06/79DJ3-300x186.png 300w, http://www.regressionist.com/wp-content/uploads/2020/06/79DJ3-768x476.png 768w, http://www.regressionist.com/wp-content/uploads/2020/06/79DJ3-624x387.png 624w" sizes="(max-width: 785px) 100vw, 785px"></figure>



<h3>The cables</h3>



<p>I went with Mellanox MC2207130-0A1 1.5M IB FDR QSFP copper cables for about $20 each. Fiber optic cables are better for long distances, but these passive cables have worked perfectly.</p>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/06/FDR_cable-1024x768.jpg" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/06/FDR_cable-1024x768.jpg 1024w, http://www.regressionist.com/wp-content/uploads/2020/06/FDR_cable-300x225.jpg 300w, http://www.regressionist.com/wp-content/uploads/2020/06/FDR_cable-768x576.jpg 768w, http://www.regressionist.com/wp-content/uploads/2020/06/FDR_cable-1536x1152.jpg 1536w, http://www.regressionist.com/wp-content/uploads/2020/06/FDR_cable-624x468.jpg 624w, http://www.regressionist.com/wp-content/uploads/2020/06/FDR_cable.jpg 1600w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h3>The switch</h3>



<p>There are two switches that will work. The first is a small unmanaged switch, the Mellanox SX6005. It runs about $90 used:</p>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6005.png" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6005.png 807w, http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6005-300x201.png 300w, http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6005-768x514.png 768w, http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6005-624x418.png 624w" sizes="(max-width: 807px) 100vw, 807px"></figure>



<p>The second is the larger, managed, Mellanox SX6036. It runs about $300 used:</p>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6036-1024x353.jpg" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6036-1024x353.jpg 1024w, http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6036-300x103.jpg 300w, http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6036-768x264.jpg 768w, http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6036-1536x529.jpg 1536w, http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6036-624x215.jpg 624w, http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6036.jpg 1600w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>If you have more than one switch involved, you can daisy chain them together. You can even run multiple cables between them, which will reduce the bottleneck between the switches. No special configuration is necessary, just plug in multiple cables, and it will spread the load among them to some degree.</p>



<h3>Subnet manager</h3>



<p>There needs to be exactly one subnet manager for the infiniband network. The managed switch can provide this service, but you need to enable it in the configuration interface. The unmanaged switch cannot provide this service. In that case, you need to run a subnet manager on one server. <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/networking_guide/sec-configuring_the_subnet_manager">It is trivial to install on CentOS 7:</a></p>



<pre><code>yum install opensm
systemctl enable opensm
systemctl start opensm</code></pre>



<h3>Software</h3>



<p>I’m using CentOS 7 on my cluster, because at this time neither MooseFS nor BeeGFS supports CentOS 8. When I first played around with Ubuntu, it was much more difficult to get infiniband working. And I also had to downgrade its kernel to get BeeGFS working. I don’t think it is worth all that hassle, and CentOS 7 is working great.</p>



<pre><code># install packages
yum groupinstall "Infiniband Support"
yum install net-tools mstflint infiniband-diags iperf

# disable firewall
systemctl status firewalld
systemctl stop firewalld
systemctl disable firewalld

# disable SELINUX
nano /etc/selinux/config
# set, then reboot
SELINUX=disabled

# start the RDMA service
systemctl start rdma
systemctl enable rdma</code></pre>



<h3>Updating the card firmware</h3>



<p>After installing the infiniband card, find out the PCI address:</p>



<pre><code># Check the device’s PCI address
lspci | grep Mellanox
# 04:00.0 Network controller: Mellanox Technologies MT27500 Family [ConnectX-3]
# so "04:00.0" is the address</code></pre>



<p>Next, use the PCI address to find the card’s PSID, and note the current firmware version:</p>



<pre><code># Identify the adapter card's PSID (last line of the output)
mstflint -d 04:00.0 q
#Image type:            FS2
#FW Version:            2.32.5100
#FW Release Date:       3.9.2014
#Rom Info:              type=PXE version=3.4.306 proto=IB
#Device ID:             4099
#Description:           Node             Port1            Port2            Sys image
#GUIDs:                 e41d2d0300b2bdc0 e41d2d0300b2bdc1 e41d2d0300b2bdc2 e41d2d0300b2bdc3 
#MACs:                                       e41d2db2bdc1     e41d2db2bdc2
#VSD:                   
#PSID:                  DEL1100001019</code></pre>



<p>Now use the PSID to find the latest firmware version:</p>



<pre><code># Download the firmware BIN file from the Mellanox website that matches your card's PSID:
http://www.mellanox.com/page/firmware_table_dell?mtag=oem_firmware_download
Adapters
Dell EMC ConnectX-3 Firmware Download Center
2.42.5000
079DJ3
DEL1100001019
http://www.mellanox.com/downloads/firmware/fw-ConnectX3-rel-2_42_5000-079DJ3-FlexBoot-3.4.752.bin.zip</code></pre>
</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.regressionist.com/2020/07/05/poor-mans-cluster/">http://www.regressionist.com/2020/07/05/poor-mans-cluster/</a></em></p>]]>
            </description>
            <link>http://www.regressionist.com/2020/07/05/poor-mans-cluster/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742683</guid>
            <pubDate>Sun, 05 Jul 2020 22:33:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Triplebyte data download doesn’t give you all your data]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23742473">thread link</a>) | @wolfgang42
<br/>
July 5, 2020 | https://www.linestarve.com/blog/post/triplebyte-data-download/ | <a href="https://web.archive.org/web/*/https://www.linestarve.com/blog/post/triplebyte-data-download/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="<%= page.layout %>-<%= page.slug %>" itemscope="" itemprop="blogPost">
	<div>
		<div>
			<div>
				<p>In May of last year I decided to start looking for a new job, and started by taking <a href="https://triplebyte.com/">Triplebyte</a>’s quiz. Having passed that, I spent the next three months going through the rest of their process, from a <a href="https://triplebyte.com/interview_guide">two-hour remote interview</a> all the way through to final negotiations with the company whose offer I selected. Throughout the process they were extremely competent and helpful, and at the end of it all I had only good things to say about them. They made the whole process go extremely smoothly, answered all the questions I had and gave me a ton of advice on the whole process, and their screening process was not only great from the my perspective but also gave me confidence in the quality of all their candidates.</p>

<p>Then, a little over a month ago, I got an email announcing the upcoming launch of Triplebyte’s new public profiles. I thought they were was a neat idea, and made a note that I should turn mine on next time I started a job hunt. Then someone <a href="https://news.ycombinator.com/item?id=23279837">posted the email on Hacker News</a>, pointing out that buried in the middle of the email was the fact that these new profiles were going to be opt-<em>out,</em> and unless I turned it off in the next week my profile would become public. This understandably caused an uproar, which the Triplebyte CEO Ammon <a href="https://news.ycombinator.com/item?id=23280460">completely misinterpreted</a>, posting a series of <a href="https://news.ycombinator.com/item?id=23280120">inflammatory comments</a> that <a href="https://news.ycombinator.com/item?id=23280472">misunderstood what people were upset about</a> before vanishing. A few days later he came back with a very apologetic email explaining that they weren’t going to go through with it after all, though it received <a href="https://news.ycombinator.com/item?id=23303037">mixed reactions</a>, with a lot of people being concerned that the idea had been considered at all.</p>

<p>In the midst of all this, I submitted a request through the <a href="https://triplebyte.com/privacy-center">Triplebyte privacy center</a> to download my data. (I considered deleting my account, but decided to give them the benefit of the doubt until things settled down.) After approving the request by clicking an email link, I was informed that it might take up to 30 days to complete my request, so I settled down to wait. As the weeks passed, I thought that the sudden influx of requests must have overwhelmed whoever was responsible for gathering the data from all the systems it was stored in.</p>

<p>Then, 36 days after I first submitted the request, I got an email informing me that my data was now ready to be downloaded. I clicked the link in the email, and then another link on the next page, and finally I got—</p>

<p>A 2,917 byte JSON blob.</p>

<p><em>Odd,</em> I thought, <em>that seems like an awfully long time for so little data.</em> (It’s just over 81 bytes per day, in fact, though I realize that’s a silly metric.) Still, I was relieved to know that they hadn’t been gathering reams of data about me behind my back. Scanning over the minified data, it looked like all they had was my address, some information I’d given them about my past jobs and preferred languages, and a couple of recent IP addresses. Seemingly they hadn’t even kept any information at all about my job search with them.</p>

<p>Then I opened up the file in a JSON viewer and gradually realized: <em>this was not all the information they had.</em> It wasn’t even all of the information they were <em>willing to admit</em> they had—it was missing some obvious things, like the text descriptions on the <code>education</code> and <code>work experience</code> objects, which were prominently displayed on my profile page. As far as I can tell, all I got was a sloppy attempt at making it look at a casual glance like they’d given me what I asked for.</p>

<p>This raises serious concerns for me about Triplebyte, even more so than their plan to make profiles public by default, which started this all. That may well have been born of overenthusiastic naïvité, and was quickly rescinded after being exposed to public comment. After that fiasco, though, I would have expected them to double down on making sure that they were taking privacy seriously. They had over a month before sending me this data to fix any issues with the system, and instead they sent me some slapdash attempt at maybe giving me a whiff of my data.</p>

<p>Triplebyte (as they explain in their privacy center) “care deeply about how your personal information is used and shared,” but apparently not enough to actually put effort into getting it right when you ask for it.</p>

<p>(I’ve sent them an email asking what happened to the rest of the data, and will update this post when I get a response. As it’s the weekend I may not hear back for a few days.)</p>

			</div>
		</div>
	</div>
</article></div>]]>
            </description>
            <link>https://www.linestarve.com/blog/post/triplebyte-data-download/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742473</guid>
            <pubDate>Sun, 05 Jul 2020 22:02:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Design of modern OS for next century (1998)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23742432">thread link</a>) | @smallstepforman
<br/>
July 5, 2020 | http://testou.free.fr/www.beatjapan.org/mirror/www.be.com/products/beos/mediaos.html | <a href="https://web.archive.org/web/*/http://testou.free.fr/www.beatjapan.org/mirror/www.be.com/products/beos/mediaos.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<td><p><img src="http://testou.free.fr/www.beatjapan.org/mirror/www.be.com/products/beos/resources/mediaos_175.gif" width="175" height="94"></p>

<p><span size="-1">Technical White Paper</span><i><br clear="ALL"></i><b><span size="+3">The Media OS</span></b></p>

<p><i>The needs of digital content design, not to mention physics <br clear="ALL">and economics, are coming into conflict with current <br clear="ALL">OS
architectures. A new definition, the Media OS, <br clear="ALL">can unlock
the door to more powerful media-based personal <br clear="ALL">systems,
and extract more performance from the systems <br clear="ALL">we are using
today.</i></p>



<p>In 1985, a new concept in personal computing began to take hold. Known
as "desktop publishing" and sparked by graphical user interfaces
and the invention of the laser printer, this new use for PCs grew from a
special interest group into a major market that changed the face of paper
publishing, from newsletters to annual reports to advertising. And in the
process, computer-based publishing sold millions of people on the usefulness
of personal computers, and changed the very nature of their work.</p>

<p>A decade later, desktop publishing as we have known it is coming to an
end. It is not the message that is being changed, but the way the message
is being conveyed. CD-ROMs provide us with a high capacity distribution
mechanism that costs pennies to produce in volume. DVDs are on the horizon,
promising to obliterate the CD-ROM and take capacities to new levels. And
the Internet is rushing towards universal coverage, able to deliver any
type of information, to any user, for the cost of the communications channel
and an inexpensive server.</p>

<p>This <i>digital media</i> is changing the way the message is conveyed.
Instead of static images on a page, digital media presents us with a mix
of text, digital audio, digital video, two-way communications, and 3D graphics
and animations.</p>

<p>Content designers everywhere, already computerized by the previous revolution,
have taken to the new media like ducks to water, experimenting with audio,
video and graphics in a myriad of combinations.</p>

<p>In response to the demand of the new media, production lead times are
shrinking from months to days, or even hours. These digital designers are
using new sets of software tools to manipulate this high bandwidth information
in as real-time as possible.</p>

<p>And in the process, they are bringing the personal computer as we know
it to its knees.</p>



<hr><b>Today's Limitations</b><hr>

<p>The computing industry has grown up with promises of doubling processing
power and halving equipment costs every 18 months or so. That pace hasn't
slowed. We have vastly more powerful hardware today than we had even three
years ago.</p>

<p>But the demands of digital media are increasing the need for processing
power at an even faster rate. Digital design requires that we squeeze every
bit of performance out of our current systems, and that we look to opening
new avenues for gaining performance, even as microprocessors continue to
advance.</p>

<p>Unfortunately, in the process applications are exceeding what the current
generation of operating systems were designed to do. Almost all existing
systems were originally designed decades ago, when the idea of personal
computers dealing with real-time video, audio, communications and other
high-bandwidth applications was practically science fiction. Windows 95 has
its roots in DOS, Windows NT in the VAX systems originally designed by DEC,
Mac OS in the early ideas of Xerox Parc and Mach in the labs of Carnegie-Mellon,
both designed in the late 1970s.</p>

<p>As the importance of audio, video and interactive communications has
increased in recent years, we've had to devise increasingly clever -- and
complex -- methods of delivering the performance required of media-based
applications because the <i>foundations</i> of today's systems were simply
not designed with high-bandwidth media in mind.</p>

<p>One example of aging foundations is the use of multiple processors in
a single system. The architectures of most of today's mainstream operating
systems are optimized for execution on uniprocessor systems, an assumption
borne of the days when microprocessors were very expensive. Adding multiprocessor
(MP) capability to these systems is difficult, and often goes only half way.
To gain the maximum benefit, all operating system services and applications
must be written with MP capability in mind, something that is virtually
impossible to do without major disruption. Those of today's systems that
can make some use of multiple processors do so in a coarse-grain way, failing
to take maximum advantage of the hardware resources available.</p>

<p>In addition, as more and more features have been added to today's operating
systems, layers of software "silt" have built up upon their architectural
foundations. These layers deliver new services, route around services no
longer required, provide specialized functions for individual applications
that can't be delivered any other way, and, most of all, provide a level
of backward compatibility. Unfortunately, as this software silt builds up,
it consumes more of the computer's processing power and hardware resources.
And it adds to the complexity of the system -- reducing performance, lowering
stability, and lengthening the time it takes to deliver new software.</p>

<p>This increasing complexity has had two effects. First, customers are
paying for more expensive hardware than they should, just to obtain acceptable
performance with mainstream productivity applications. The effort to counteract
this problem forms the basis of the <i>network computer </i>(NC) concept
-- by simplifying operating systems, moving to modern applications, and removing
the silt, computing can become less expensive.</p>

<p>And second, users are not able to take advantage of the real processing
power that is inherent in today's advanced microprocessors because of the
operating systems silt that lies in the way, making media-based applications
more expensive, and less powerful, than they should be. Solving this problem
lies at the heart of the <i>Media OS</i> concept.</p>



<hr><b>The Necessities of Digital Media</b><hr>

<p>It's not enough to add a few features and call an operating system a
"Media OS." An operating system needs to be architected to deal
natively with digital media. Our experiences with today's generation of
personal computers provide a glimpse at what is necessary to create a true
media-based system, and to squeeze the most possible power out of a system's
hardware resources. From this experience, we can identify five broad areas
in which a media-based system must excel.</p>

<p><img src="http://testou.free.fr/www.beatjapan.org/mirror/www.be.com/products/beos/resources/proc_cycles_sm.gif" width="207" height="255"><b>Maximize Processing Power</b></p>

<p>The power of microprocessors continues to advance at a predictable pace.
However, the needs of digital content creators have outstripped even the
best efforts of microprocessor makers, and physics, to keep up. A Media
OS can't rely simply on single processors to handle the load, which means
that it must be <i>multiprocessor capable.</i></p>

<p>Why are multiprocessor systems important? Today, the power of personal
computer systems is generally dependent on a single microprocessor. This
means that we must wait for new, faster generations of microprocessors to
become available in order to build more powerful personal computers.</p>

<p>Multiprocessing gives us a way around this problem. First, it gives us
access to even more powerful systems. We can multiply the effect of increases
in microprocessor performance across multiple processors, rather than just
one. This can provide access to vastly more powerful systems than we have
today, yet with today's PC technologies.</p>

<p>Second, multiprocessing provides us with a more economical way of reaching
a given performance point. The highest performance processor, 400 MHz today,
costs significantly more than 300 MHz processors. Thus it can cost just
as much to put two 300 MHz processors into a system as it does to put a
single 400 MHz processor. Yet the two processors combined deliver 600 MHz
of available cycles. The result is that using a multiprocessor approach
opens a new axis for hardware manufacturers to explore in price-performance
-- leading to new performance levels and options for end users.<img src="http://testou.free.fr/www.beatjapan.org/mirror/www.be.com/products/beos/resources/price_perf_sm.gif" width="274" height="206"></p>

<p>Opening up new, multiprocessor-based solutions for the mainstream is
a key requirement as we take media design into the next century. There are
a number of other ways to maximize processor performance. For example, how
an operating system implements multiprocessor capability can be even more
important than the capability itself. We'll examine this further a bit later
in this discussion.</p>



<p><b>Graphics Power and Flexibility</b></p>

<p>In addition to consuming massive amounts of processing power, a key characteristic
of the work of digital designers is that it involves the manipulation of
graphics, preferably in real-time (manipulation with no "lag"
or processing time from the user's perspective.) To accomplish this, media-based
systems have to address two things involving graphics capabilities.</p>

<p>First they need to take advantage of specialized graphics coprocessors.
Graphics co-processing is a specialized type of multiprocessing that can
help increase the performance of a system dramatically. This is especially
true in 3D graphics and video compression and decompression, where 
function-specific chips can boost throughput significantly.</p>

<p>Second, the graphics capabilities must be flexible. The types of graphics
work being done by digital designers varies greatly. Some do more 3D work
than video, others more 2D than 3D, and so on. Because of this, a Media
OS must be flexible enough to allow hardware to be configured in the way
that's best for the end user. In addition, flexibility and modularity means
that graphics hardware can be upgraded as new, more powerful solutions become
available, or as the user's needs change.</p>



<p><b>Access to Large Amounts of Storage</b></p>

<p>Another key characteristic of digital design is the amount of data required.
We have moved from floppy storage, to hard drive storage, to CD-ROMs, providing
us with direct access to significantly more data than only a few years ago.
Average hard drive sizes have increased from a few hundred megabytes and
are now approaching 4 gigabytes.</p>

<p><img src="http://testou.free.fr/www.beatjapan.org/mirror/www.be.com/products/beos/resources/file_size.gif" width="189" height="192">
But this is nothing compared to what's going to be required
in the near future. One hour of digital …</p></td></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://testou.free.fr/www.beatjapan.org/mirror/www.be.com/products/beos/mediaos.html">http://testou.free.fr/www.beatjapan.org/mirror/www.be.com/products/beos/mediaos.html</a></em></p>]]>
            </description>
            <link>http://testou.free.fr/www.beatjapan.org/mirror/www.be.com/products/beos/mediaos.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742432</guid>
            <pubDate>Sun, 05 Jul 2020 21:57:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Contrarian view on closing files]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 90 (<a href="https://news.ycombinator.com/item?id=23742390">thread link</a>) | @coady
<br/>
July 5, 2020 | https://coady.github.io/posts/closing-files/ | <a href="https://web.archive.org/web/*/https://coady.github.io/posts/closing-files/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody text">
    <div>
<div>

<div>
<div>
<h2 id="Contrarian-view-on-closing-files.">Contrarian view on closing files.<a href="#Contrarian-view-on-closing-files.">¶</a>
</h2>
<p>It has become conventional wisdom to always explicitly close file-like objects, via context managers.
The <a href="https://google.github.io/styleguide/pyguide.html#311-files-and-sockets">google style guide</a>
is representative:</p>
<blockquote>
<p>Explicitly close files and sockets when done with them.
Leaving files, sockets or other file-like objects open unnecessarily has many downsides, including:</p>
<p>They may consume limited system resources, such as file descriptors.</p>
<ul>
<li>Code that deals with many such objects may exhaust those resources unnecessarily if they're not returned to the system promptly after use.</li>
<li>Holding files open may prevent other actions being performed on them, such as moves or deletion.</li>
<li>Files and sockets that are shared throughout a program may inadvertantly be read from or written to after logically being closed. If they are actually closed, attempts to read or write from them will throw exceptions, making the problem known sooner.</li>
</ul>
<p>Furthermore, while files and sockets are automatically closed when the file object is destructed, tying the life-time of the file object to the state of the file is poor practice, for several reasons:</p>
<ul>
<li>There are no guarantees as to when the runtime will actually run the file's destructor. Different Python implementations use different memory management techniques, such as delayed Garbage Collection, which may increase the object's lifetime arbitrarily and indefinitely.</li>
<li>Unexpected references to the file may keep it around longer than intended (e.g. in tracebacks of exceptions, inside globals, etc).</li>
</ul>
<p>The preferred way to manage files is using the "with" statement:</p>

<pre><code>with open("hello.txt") as hello_file:
    for line in hello_file:
        print line</code></pre>
</blockquote>
<h3 id="In-theory">In theory<a href="#In-theory">¶</a>
</h3>
<p>Good points, and why limit this advice to file descriptors?  Any resource may be limited or require exclusivity;  that's why they're called resources.  Similarly one should always explicitly call <code>dict.clear</code> when finished with a <code>dict</code>.  After all, "there are no guarantees as to when the runtime will actually run the &lt;object's&gt; destructor.  And "code that deals with many such objects may exhaust those resources unnecessarily", such as memory, or whatever else is in the <code>dict</code>.</p>
<p>But in all seriousness, this advice is applying a notably higher standard of premature optimization to file descriptors than to any other kind of resource.  There are plenty of Python projects that are guaranteed to run on CPython for a variety of reasons, where destructors are immediately called.  And there are plenty of Python projects where file descriptor usage is just a non-issue.  It's now depressingly commonplace to see this in <code>setup.py</code> files:</p>

</div>
</div>
</div>
<div>
<div>
<p>In&nbsp;[&nbsp;]:</p>
<div>
    <div>
<div><pre><span></span><span>with</span> <span>open</span><span>(</span><span>"README.md"</span><span>)</span> <span>as</span> <span>readme</span><span>:</span>
    <span>long_description</span> <span>=</span> <span>readme</span><span>.</span><span>read</span><span>()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div>

<div>
<p>Let's consider a practical example: a <code>load</code> function which is supposed to read and parse data given a file path.</p>
</div>
</div>
<div>
<div>
<p>In&nbsp;[&nbsp;]:</p>
<div>
    <div>
<div><pre><span></span><span>import</span> <span>csv</span>
<span>import</span> <span>json</span>

<span>def</span> <span>load</span><span>(</span><span>filepath</span><span>):</span>
    <span>"""the supposedly bad way"""</span>
    <span>return</span> <span>json</span><span>.</span><span>load</span><span>(</span><span>open</span><span>(</span><span>filepath</span><span>))</span>

<span>def</span> <span>load</span><span>(</span><span>filepath</span><span>):</span>
    <span>"""the supposedly good way"""</span>
    <span>with</span> <span>open</span><span>(</span><span>filepath</span><span>)</span> <span>as</span> <span>file</span><span>:</span>
        <span>return</span> <span>json</span><span>.</span><span>load</span><span>(</span><span>file</span><span>)</span>

<span>def</span> <span>load</span><span>(</span><span>filepath</span><span>):</span>
    <span>"""with a different file format"""</span>
    <span>with</span> <span>open</span><span>(</span><span>filepath</span><span>)</span> <span>as</span> <span>file</span><span>:</span>
        <span>return</span> <span>csv</span><span>.</span><span>reader</span><span>(</span><span>file</span><span>)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div>

<div>
<div>
<p>Which versions work correctly?  Are you sure?  If it's not immediately obvious why one of these is broken, that's the point.  In fact, it's worth trying out before reading on.</p>
<p>...</p>
<p>The <code>csv</code> version returns an iterator over a closed file.  It's a violation of procedural abstraction to know whether the result of <code>load</code> is lazily evaluated or not; it's just supposed to implement an interface.  Moreover, according to this best practice, it's <em>impossible</em> to write the <code>csv</code> version correctly.  As absurd as it sounds, it's just an abstraction that can't exist.</p>
<p>Defiantly clever readers are probably already trying to fix it.  Maybe like this:</p>

</div>
</div>
</div>
<div>
<div>
<p>In&nbsp;[&nbsp;]:</p>
<div>
    <div>
<div><pre><span></span><span>def</span> <span>load</span><span>(</span><span>filepath</span><span>):</span>
    <span>with</span> <span>open</span><span>(</span><span>filepath</span><span>)</span> <span>as</span> <span>file</span><span>:</span>
        <span>yield from</span> <span>csv</span><span>.</span><span>reader</span><span>(</span><span>file</span><span>)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div>

<div>
<div>
<p>No, it will not be fixed.  This version only appears to work by <em>not</em> closing the file until the generator is exhausted or collected.</p>
<p>This trivial example has deeper implications.  If one accepts this practice, then one must also accept that storing a file handle anywhere, such as on an instance, is also disallowed.  Unless of course that object then virally implements it owns context manager, ad infinitum.</p>
<p>Furthermore it demonstrates that often the context is not being managed locally.  If a file object is passed another function, then it's being used outside of the context.  Let's revisit the <code>json</code> version, which works because the file is fully read.  Doesn't a json parser have some expensive parsing to do after it's read the file?  It might even throw an error.  And isn't it desirable, trivial, <a href="https://github.com/python/cpython/blob/master/Lib/json/__init__.py#L274">and likely</a> that the implementation releases interest in the file as soon as possible?</p>
<p>So in reality there are scenarios where the supposedly good way could keep the file open <em>longer</em> than the supposedly bad way.  The original inline version does exactly what it's supposed to do: close the file when all interested parties are done with it.  Python uses garbage collection to manage shared resources.  Any attempt to pretend otherwise will result in code that is broken, inefficient, or reinventing reference counting.</p>
<p>A true believer now has to accept that <code>json.load</code> is a useless and dangerous wrapper, and that the only correct implementation is:</p>

</div>
</div>
</div>
<div>
<div>
<p>In&nbsp;[&nbsp;]:</p>
<div>
    <div>
<div><pre><span></span><span>def</span> <span>load</span><span>(</span><span>filepath</span><span>):</span>
    <span>with</span> <span>open</span><span>(</span><span>filepath</span><span>)</span> <span>as</span> <span>file</span><span>:</span>
        <span>contents</span> <span>=</span> <span>file</span><span>.</span><span>read</span><span>()</span>
    <span>return</span> <span>json</span><span>.</span><span>loads</span><span>(</span><span>contents</span><span>)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div>

<div>
<div>
<p>This line of reasoning reduces to the absurd: a file should never be passed or stored anywhere.  Next an example where the practice has caused real-world damage.</p>
<h3 id="In-practice">In practice<a href="#In-practice">¶</a>
</h3>
<p><a href="https://requests.readthedocs.io/en/master/">Requests</a> is one of the most popular python packages, and <a href="https://docs.python.org/3/library/http.client.html#module-http.client">officially recommended</a>.  It includes a <a href="http://requests.readthedocs.org/en/latest/user/advanced/#session-objects">Session</a> object which supports closing via a context manager.  The vast majority of real-world code uses the the top-level functions or single-use sessions.</p>

</div>
</div>
</div>
<div>
<div>
<p>In&nbsp;[&nbsp;]:</p>
<div>
    <div>
<div><pre><span></span><span>response</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>...</span><span>)</span>

<span>with</span> <span>requests</span><span>.</span><span>Session</span><span>()</span> <span>as</span> <span>session</span><span>:</span>
    <span>response</span> <span>=</span> <span>session</span><span>.</span><span>get</span><span>(</span><span>...</span><span>)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div>

<div>
<div>
<p>Sessions manage the connection pool, so this pattern of usage is establishing a new connection every time.  There are popular standard API clients which seriously do this, for every single request to the same endpoint.</p>
<p>Requests' documentation prominently states that "Keep-alive and HTTP connection pooling are 100% automatic".  So part of the blame may lay with that phrasing, since it's only "automatic" if sessions are reused.  But surely a large part of the blame is the dogma of closing sockets, and therefore sessions, explicitly.
The whole point of a connection pool is that it may leave connections open, so users who genuinely need this granularity are working at the wrong abstraction layer.  <code>http.client</code> is already builtin for that level of control.</p>
<p>Tellingly, requests' own top-level functions didn't always close sessions.  There's a long history to that code, including a <a href="https://github.com/kennethreitz/requests/commit/3155bc99362a8c6ab136b6a3bb999732617cd2e5">version that only closed sessions on success</a>.  An older version was <a href="https://github.com/kennethreitz/requests/issues/1882">causing warnings</a>, when run to check for such warnings, and was being blamed for the <em>appearance</em> of <a href="https://github.com/kennethreitz/requests/issues/1685">leaking memory</a>.  Those threads are essentially debating whether a resource pool is "leaking" resources.</p>

</div>
</div>
</div>
<div>

<div>
<div>
<h3 id="Truce">Truce<a href="#Truce">¶</a>
</h3>
<p>Prior to <code>with</code> being introduced in Python 2.5, it was <em>not</em> recommended that inlined reading of a file required a <code>try... finally</code> block.  Far from it, in the past idioms like <code>open(...).read()</code> and <code>for line in open(...)</code> were lauded for being succinct and expressive.  But if all this orphaned file descriptor paranoia was well-founded, it would have been a problem back then too.</p>
<p>Finally, let's address readability.  It could be argued (though it rarely is) that showing the reader when the file is closed has inherent value.  Conveniently, that tends to align with having opened the file for writing anyway, thereby needing an reference to it.  In which case, the readability is approximately equal, and potential pitfalls are more realistic.  But readability is genuinely lost when the file would have been opened in a inline expression.</p>
<p>The best practice is unjustifiably special-casing file descriptors, and not seeing its own reasoning through to its logical conclusion.  This author proposes advocating for <em>anonymous read-only</em> <code>open</code> expressions.  Your setup script is not going to run out of file descriptors because you wrote <code>open("README.md").read()</code>.</p>

</div>
</div>
</div>
</div>
    </div></div>]]>
            </description>
            <link>https://coady.github.io/posts/closing-files/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742390</guid>
            <pubDate>Sun, 05 Jul 2020 21:50:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Zola (static site generator) Workflow]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23742328">thread link</a>) | @0xC45
<br/>
July 5, 2020 | https://0xc45.com/blog/my-zola-workflow/ | <a href="https://web.archive.org/web/*/https://0xc45.com/blog/my-zola-workflow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<h2 id="overview">Overview</h2>
<p>To build this website, I use the <a href="https://www.getzola.org/">Zola static site engine</a>. So far, it has worked great. In this blog post, I will discuss my workflow improvements for using Zola, developing my blog posts, and publishing this website. As a quick intro, however, I will give a brief summary of the main features of Zola and why I chose to use it.</p>
<h3 id="what-is-zola">What is Zola?</h3>
<p>Zola advertises itself as a static site engine. It "compiles" Markdown content files, HTML templates (based on the <a href="https://tera.netlify.app/">Tera template engine</a>), and <a href="https://sass-lang.com/">Sass</a> styling into static HTML and CSS pages. This way, a Zola website does not require any server-side code to "render" the website pages.</p>
<p>In addition, Zola has several convenience features that one would want for a blog or website, such as built-in <a href="https://www.getzola.org/documentation/content/syntax-highlighting/">syntax highlighting</a>, simplified <a href="https://www.getzola.org/documentation/templates/pagination/">pagination</a>, and auto-generation of <a href="https://www.getzola.org/documentation/templates/feeds/">atom/rss feeds</a>.</p>
<p>So, Zola is an all-in-one tool for generating static websites. As a blog author, I can mainly focus on writing my blog post content (in Markdown). I don't have to worry too much about HTML syntax, CSS styling, linking, pagination, or my Atom feed (after the initial setup and creation of my site theme). When I'm done writing a blog post, I "generate" the static site with Zola. All of the repetitive and error-prone work is handled for me and the actual static website pages are produced.</p>
<h3 id="why-use-zola">Why use Zola?</h3>
<p>There are many competing static site generators out there. Zola is but one of many. Currently, Hugo and Jekyll are probably the two most popular static site generators. However, for this website, I chose to use Zola for a few reasons:</p>
<ul>
<li>It's simple. It doesn't have a ridiculous number of features that will confuse me and distract me from actually writing blog posts.</li>
<li>It's capable. It has all the feature that I need.</li>
<li>It's a relatively new project. Why not give it a try?</li>
</ul>
<h2 id="my-zola-workflow">My Zola Workflow</h2>
<p>Rather than repeat stuff you can find in the Zola documentation, in this blog post I will cover three of my personal "workflow hacks" for working with Zola. Hopefully at least a couple of these patterns are useful to you.</p>
<h3 id="git-pre-push-hook">Git pre-push Hook</h3>
<p>Because this blog is hosted on Github pages, <code>git push</code> is equivalent to publishing the site. Early on, I made the mistake of writing an entire blog post, but forgetting to "generate" the static site. So, I made a commit, pushed, and nothing happened.</p>
<p>To prevent myself from making this mistake again, I added a "pre-push" hook to my git repo. Now, git will refuse to push if the generated static site is out of date.</p>
<p>Here is my simple "pre-push" git hook:</p>
<pre><code><span>#!/usr/bin/env bash

</span><span>project_root</span><span>="$</span><span>( </span><span>git</span><span> rev-parse</span><span> --show-toplevel </span><span>)</span><span>"
</span><span>pushd </span><span>"$</span><span>{</span><span>project_root</span><span>}</span><span>" &amp;&gt; /dev/null || </span><span>exit</span><span> 1
</span><span>make </span><span>&amp;&gt; /dev/null
</span><span>num_diff_files</span><span>="$</span><span>( </span><span>git</span><span> diff</span><span> --name-only </span><span>| </span><span>wc -l </span><span>)</span><span>"
</span><span>num_untracked_files</span><span>="$</span><span>( </span><span>git</span><span> ls-files</span><span> --others --exclude-standard </span><span>| </span><span>wc -l </span><span>)</span><span>"
</span><span>if </span><span>[ </span><span>"$</span><span>{</span><span>num_diff_files</span><span>}</span><span>" != "</span><span>0</span><span>" </span><span>] </span><span>|| </span><span>[ </span><span>"$</span><span>{</span><span>num_untracked_files</span><span>}</span><span>" != "</span><span>0</span><span>" </span><span>] </span><span>; </span><span>then
  </span><span>echo </span><span>"</span><span>diff detected after running </span><span>\`</span><span>make</span><span>\`</span><span>, not pushing</span><span>"
  </span><span>exit</span><span> 1
</span><span>fi
</span><span>popd </span><span>&amp;&gt; /dev/null || </span><span>exit</span><span> 1
</span></code></pre>
<p>In summary, this git hook builds the site (with Zola) and then checks if any git diff is detected. If there is a git diff (or new, un-tracked file), the hook will prevent the <code>git push</code> from running.</p>
<p>As you might notice, this script depends on <code>make</code>. To build the website, I have a Makefile target (which will be discussed soon).</p>
<h3 id="docker-image">Docker Image</h3>
<p>Next, rather than install the <code>zola</code> binary on my base system, I decided to create a docker image that contains Zola. So, I now have a portable means to generate the site. In the future, I could potentially add some sort of continuous deployment automation to regenerate the site on every git push using this docker image. Additionally, the docker image locks Zola at a specific version (which I can be conscientious about upgrading).</p>
<p>Here is my Zola docker image: <a href="https://github.com/0xC45/zola-docker">https://github.com/0xC45/zola-docker</a>.</p>
<h3 id="makefile">Makefile</h3>
<p>Lastly, I use a Makefile to build the site. Because I use a docker image to run Zola, some of the commands are quite complicated. Particularly, it was somewhat difficult to set up UID/GID mapping and port binding. Using a Makefile documents the commands in code and saves me from having to remember them. Here is my Makefile:</p>
<pre><code><span>.PHONY</span><span>: all</span><span>
all</span><span>:</span><span>
	PROJECT_ROOT</span><span>=</span><span>"</span><span>$$(</span><span>git rev-parse --show-toplevel</span><span>)</span><span>" &amp;&amp; \
	docker run \
	  --rm \
	  -it \
	  -u </span><span>$$(</span><span>id -u </span><span>$${</span><span>USER</span><span>})</span><span>:</span><span>$$(</span><span>id -g </span><span>$${</span><span>USER</span><span>}) </span><span>\
	  -v "</span><span>$${</span><span>PROJECT_ROOT</span><span>}</span><span>:/site" \
	  zola:v0.11.0 \
	  bash -c 'cd /site &amp;&amp; zola build -o docs'</span><span>

.PHONY</span><span>: serve</span><span>
serve</span><span>:</span><span>
	PROJECT_ROOT</span><span>=</span><span>"</span><span>$$(</span><span>git rev-parse --show-toplevel</span><span>)</span><span>" &amp;&amp; \
	docker run \
	  --rm \
	  -it \
	  -u </span><span>$$(</span><span>id -u </span><span>$${</span><span>USER</span><span>})</span><span>:</span><span>$$(</span><span>id -g </span><span>$${</span><span>USER</span><span>}) </span><span>\
	  -v "</span><span>$${</span><span>PROJECT_ROOT</span><span>}</span><span>:/site" \
	  -p 127.0.0.1:1111:1111 \
	  zola:v0.11.0 \
	  bash -c 'cd /site &amp;&amp; zola serve -i 0.0.0.0'</span><span>

.PHONY</span><span>: </span><span>clean
</span><span>clean</span><span>:
	</span><span>rm -rf docs/
</span></code></pre>
<p>There are three main targets: <code>all</code>, <code>serve</code>, and <code>clean</code>.</p>
<ul>
<li><code>all</code>: This target generates the static site.</li>
<li><code>serve</code>: This target runs a "development" server on my local machine, allowing me to preview changes.</li>
<li><code>clean</code>: This target deletes the directory containing the generated static site.</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>So, there you have it. These are my custom workflow improvements for using the Zola static site engine. So far, Zola has been a fantastic utility for generating my blog site. Of course, it does not have all the features of other popular static site generators, but it's perfect for my use case. It's simple, easy to use, fast, and capable. I definitely recommend checking it out.</p>

    </section></div>]]>
            </description>
            <link>https://0xc45.com/blog/my-zola-workflow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742328</guid>
            <pubDate>Sun, 05 Jul 2020 21:43:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Experimenting with TypeScript 4.0's Variadic Tuple Types (Variadic Kinds)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23742046">thread link</a>) | @munchor
<br/>
July 5, 2020 | https://davidgomes.com/refactoring-some-code-to-use-typescripts-variadic-functions/ | <a href="https://web.archive.org/web/*/https://davidgomes.com/refactoring-some-code-to-use-typescripts-variadic-functions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        




<main id="site-main" role="main">
    <div>

        <article>

            


            <section>
                <p>I wrote some code over 2 years ago that can't be properly typed with either <a href="https://flow.org/">Flow</a> or <a href="https://www.typescriptlang.org/">TypeScript</a>, but with the introduction of <a href="https://github.com/microsoft/TypeScript/pull/39094">Variadic Tuple Types</a> coming in TypeScript 4.0, I decided to give this piece of code a second look.</p><p>We have a function called <code>innerJoin</code> which takes in 2+N arguments:</p><ol><li>A <code>comparator</code> function</li><li>A <code>merge</code> function</li><li>A variadic list of arrays that all have to be sorted the same way: <code>...arrs</code></li></ol><p>The inner join function loops through all of the arrays "at the same time", looks for items that need to be merged based on some "join predicate" (the <code>comparator</code> function) and then calls the <code>merge</code> function with all of those items to generate a "merged" item that will go on the end result array.</p><p>Here's an example of how to use this function in a very simple test case:</p><pre><code>function idComparator(a: { id: number }, b: { id: number }) {
    if (a.id &lt; b.id) {
        return -1;
    } else if (a.id === b.id) {
        return 0;
    } else {
        return 1;
    }
}

const array1 = [
    {
        id: 1,
        name: "David",
    },
    {
        id: 2,
        name: "Miguel",
    },
];

const array2 = [
    {
        id: 1,
        country: "Portugal",
    },
    {
        id: 2,
        country: "Portugal",
    },
    {
        id: 3,
        country: "USA",
    },
];

expect(
    innerJoin(idComparator, (a, b) =&gt; ({ ...a, ...b }), array1, array2)
).toEqual([
    {
        id: 1,
        name: "David",
        country: "Portugal",
    },
    {
        id: 2,
        name: "Miguel",
        country: "Portugal",
    },
]);
</code></pre><p>As you can see, a match was found for items 1 and 2, which resulted in a "merge" and item 3 was only present in one of the arrays, so it doesn't appear in the end result. A visualization of this algorithm can be seen here:</p><figure><img src="https://davidgomes.com/content/images/2020/05/merge_join.gif" alt=""></figure><p>So, how was this function implemented? (The comments should explain everything you need to know)</p><p><strong>inner-join.js</strong></p><p>(Notice that this is a JavaScript file which means that any potential type errors on it will go unnoticed)</p><pre><code>// This file's type definitions live in inner-join.d.ts, as we need to separate
// the type definition from the type implementation.

import _ from "lodash";

// All the arrays have to be sorted the same way. If not, the behavior
// of this function is *undefined*.
//
// A good visualization of this algorithm can be found here:
// http://sqlity.net/wp-content/uploads/2012/12/merge-join-algorithm.gif.
export default function innerJoin(comparator, merge, ...arrs) {
    const output = [];

    let iterators = _.fill(Array(arrs.length), 0);

    // We should only continue looping if none of the pointers is
    // at the end of their respective array. This is because we can
    // only match if we have a value from each array.
    const canContinue = () =&gt;
        _.every(arrs, (arr, index) =&gt; iterators[index] &lt; arr.length);

    // Gets all the current values by grabbing the value we are
    // currently pointing to for each array.
    const getAllValues = () =&gt;
        _.map(arrs, (arr, index) =&gt; arr[iterators[index]]);

    // Tests whether all current values match by comparing all of them
    // against the first element.
    const allValuesEqual = () =&gt;
        _.every(
            arrs,
            (arr, index) =&gt;
                comparator(arrs[0][iterators[0]], arr[iterators[index]]) === 0
        );

    while (canContinue()) {
        const values = getAllValues();
        const comparison = allValuesEqual();

        if (comparison) {
            output.push(merge(...values));
            iterators = _.map(iterators, it =&gt; ++it);
        } else {
            let minimumIndex = 0;

            let i;
            for (i = 1; i &lt; arrs.length; i++) {
                if (
                    comparator(
                        arrs[i][iterators[i]],
                        arrs[minimumIndex][iterators[minimumIndex]]
                    ) === -1
                ) {
                    minimumIndex = i;
                }
            }

            iterators[minimumIndex]++;
        }
    }

    return output;
}</code></pre><p>As you can see on the very first line of the <code>inner-join.js</code> file, the type definitions for this file live elsewhere: in <code>inner-join.d.ts</code>. Let's see what that file looks like:</p><p><strong>inner-join.d.ts</strong></p><pre><code>export default function innerJoin&lt;T1, T2, T3&gt;(
    comparator: (first: T1, second: T2) =&gt; -1 | 0 | 1,
    merge: (first: T1, second: T2) =&gt; T3,
    arr1: Array&lt;T1&gt;,
    arr2: Array&lt;T2&gt;
): Array&lt;T3&gt;;

export default function innerJoin&lt;T1, T2, T3, T4&gt;(
    comparator: (first: T1, second: T2 | T3) =&gt; -1 | 0 | 1,
    merge: (first: T1, second: T2, third: T3) =&gt; T4,
    arr1: Array&lt;T1&gt;,
    arr2: Array&lt;T2&gt;,
    arr3: Array&lt;T3&gt;
): Array&lt;T4&gt;;</code></pre><p>The <code>innerJoin</code> function is generic over an arbitrary number of types, so typing it alongside its implementation without variadic tuple types is not possible. So, we had to move its type definitions to a separate file. On the separate file, we hand-type the function's type definition for 4 and 5 arguments. If we ever need to call this function with more arguments, we'll have to manually add more type definitions in this file.</p><p>While this isn't great, it's also not a huge problem since we can easily generate 20 or 30 of these type definitions and not have to worry about it for a long time. Some open source libraries like <a href="https://github.com/reduxjs/reselect">reselect</a> have been doing <a href="https://github.com/reduxjs/reselect/blob/36f256b59b876705144147d409a73a3c4cb3c64d/src/index.d.ts#L21">this as well</a> for a long time.</p><h2 id="rewriting-our-code-using-typescript-4-0-s-variadic-tuple-types">Rewriting our code using TypeScript 4.0's Variadic Tuple Types</h2><p>The first thing we have to define is what <code>innerJoin</code> is generic <em>over.</em> That's easy, it is generic over 2 "things":</p><ul><li>A tuple type corresponding to the types of all the arrays that will be passed in (e.g., if generic over <code>[A, C]</code>, then it must receive as arguments <code>[Array&lt;A&gt;, Array&lt;C&gt;]</code>.</li><li>The output type of the join (e.g., if generic over <code>M</code>, it must return <code>Array&lt;M&gt;</code>).</li></ul><p>We can easily express this as:</p><pre><code>export default function innerJoin&lt;
    T extends unknown[], 
    MergedType
&gt;(
    ...
): MergedType { ... }</code></pre><p>Now let's think about the input types:</p><ul><li>The <code>comparator</code> function which receives 2 arguments: an element from the first array and an element from either one of the remaining arrays. This function has to return 0, -1 or 1.</li><li>The <code>merge</code> function which receives N arguments: on element from each of the input arrays. This function has to return an instance of <code>MergedType</code>.</li><li><code>arrs</code>: the list of input arrays.</li></ul><p>The <code>comparator</code> is a function that receives an argument with type <code>T[0]</code> (the type of the first element in the tuple) and another argument with the union type of all the other types in <code>T[1...N]</code>. We can use <code><a href="https://dev.to/kjleitz/comment/gb5d">DropFirstInTuple</a></code> and then use the <code>A[number]</code> syntax. What this syntax means is that we want to get the type of what we can index out of <code>A</code> with a <code>number</code> — if <code>A</code> is a tuple, then <code>A[number]</code> will correspond to the union type of all the element types of <code>A</code>). Here's all of that together:</p><pre><code>export default function innerJoin&lt;
    T extends unknown[], 
    MergedType
&gt;(
    comparator: (t1: T[0], tOther: DropFirstInTuple&lt;T&gt;[number]) =&gt; -1 | 0 | 1,
    ...
): MergedType { ... }</code></pre><p>(The <code>DropFirstInTuple</code> type was written by <a href="https://github.com/kjleitz">Keegan Leitz</a>, and I found it <a href="https://dev.to/kjleitz/comment/gb5d">here</a>)</p><p>The <code>merge</code> function is fairly simple to type:</p><pre><code>export default function innerJoin&lt;
    T extends unknown[], 
    MergedType
&gt;(
    comparator: (t1: T[0], tOther: DropFirstInTuple&lt;T&gt;[number]) =&gt; -1 | 0 | 1,
    merge: (...t: T) =&gt; MergedType,
    ...
): MergedType { ... }</code></pre><p>The list of input <code>arrs</code> is a little bit more challenging to type:</p><pre><code>export default function innerJoin&lt;
    T extends unknown[], 
    MergedType
&gt;(
    comparator: (t1: T[0], tOther: DropFirstInTuple&lt;T&gt;[number]) =&gt; -1 | 0 | 1,
    merge: (...t: T) =&gt; MergedType,
    ...arrs: { [K in keyof T]: Array&lt;T[K]&gt; }
): MergedType { ... }</code></pre><p><code>{ [K in keyof T]: Array&lt;T[K]&gt; }</code> can be explained as follows:</p><blockquote>For each key of <code>T</code> (<code>T</code> is a tuple type, so the keys are numbers like 0, 1, 2, etc.), we need the value to be an <code>Array&lt;T[K]&gt;</code>.</blockquote><p>To exemplify, if <code>T</code> is <code>[A, C]</code> then <code>{ [K in keyof T]: Array&lt;T[K]&gt; }</code> will be <code>[Array&lt; A&gt;, Array&lt;C&gt;]</code>.</p><p>Using TypeScript 4.0, we've been able to type our <code>innerJoin</code> function! However, there is a TypeScript error further down in the file:</p><pre><code>...
    const getAllValues = () =&gt;
        arrs.map((arr, index) =&gt; arr[iterators[index]]);

...

    if (comparison) {
        output.push(merge(...values));
...</code></pre><pre><code>Argument of type 'unknown[]' is not assignable to parameter of type 'T'.
  'unknown[]' is assignable to the constraint of type 'T', but 'T' could be instantiated with a different subtype of constraint 'unknown[]'.</code></pre><p>So the issue is that the TypeScript type checker doesn't understand that <code>getAllValues</code> returns a value of type <code>T</code>. If we try to annotate the output of <code>getAllValues</code> as <code>T</code>, we get the same error. The core issue is that we're <strong>mapping</strong> over a tuple type and so TypeScript just can't guess that the return type of <code>map</code> will be of type <code>T</code> since that would require the type checker understanding that <code>map</code> is an ordered traversal over a finite set of elements.</p><p>To get around this, we need to use a (dreaded) type assertion:</p><pre><code>// Gets all the current values by grabbing the value we are
// currently pointing to for each array.
// TYPE ASSERTION: This function leverages a type assertion which is
// something one should never do as they are not type safe. However, there
// is no other way to map over a tuple type and return another tuple type.
const getAllValues = () =&gt;
    arrs.map((arr, index) =&gt; arr[iterators[index]]) as T;</code></pre><p>And that's it! Here's the final <code>inner-join.ts</code>:</p><pre><code>// This file's type definitions live in inner-join.d.ts, as we need to separate
// the type definition from the type implementation.

import _ from "lodash";

// CREDIT to https://github.com/kjleitz for this type:
// https://dev.to/kjleitz/comment/gb5d

// Drops the first element of a tuple. Example:
//
//   type Foo = DropFirstInTuple&lt;[string, number, boolean]&gt;;
//   //=&gt; [number, boolean]
//
export type DropFirstInTuple&lt;T extends any[]&gt; = ((...args: T) =&gt; any) extends (arg: any, ...rest: infer U) =&gt; any ? U : T;

// All the arrays have to be sorted the same way. If …</code></pre></section></article></div></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://davidgomes.com/refactoring-some-code-to-use-typescripts-variadic-functions/">https://davidgomes.com/refactoring-some-code-to-use-typescripts-variadic-functions/</a></em></p>]]>
            </description>
            <link>https://davidgomes.com/refactoring-some-code-to-use-typescripts-variadic-functions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742046</guid>
            <pubDate>Sun, 05 Jul 2020 21:13:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Estimated Cost of the DMT Machine Elves Prime Factorization Experiment]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23741946">thread link</a>) | @palimpsests
<br/>
July 5, 2020 | https://qualiacomputing.com/2018/10/15/estimated-cost-of-the-dmt-machine-elves-prime-factorization-experiment/ | <a href="https://web.archive.org/web/*/https://qualiacomputing.com/2018/10/15/estimated-cost-of-the-dmt-machine-elves-prime-factorization-experiment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<blockquote><p>“Okay,” I said. “Fine. Let me tell you where I’m coming from. I was reading&nbsp;<a href="https://www.psychologytoday.com/blog/unique-everybody-else">Scott McGreal’s blog</a>, which has some&nbsp;<a href="https://www.psychologytoday.com/blog/unique-everybody-else/201210/dmt-aliens-and-reality-part-1">good</a>&nbsp;<a href="https://www.psychologytoday.com/blog/unique-everybody-else/201210/dmt-aliens-and-reality-part-2">articles</a>&nbsp;about so-called DMT entities, and mentions how they seem so real that users of the drug insist they’ve made contact with actual superhuman beings and not just psychedelic hallucinations. You know,&nbsp;<a href="http://smile.amazon.com/gp/product/0062506528/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0062506528&amp;linkCode=as2&amp;tag=slastacod-20&amp;linkId=BKGSPUHIEWFDXXWZ">the usual</a><img src="http://ir-na.amazon-adsystem.com/e/ir?t=slastacod-20&amp;l=as2&amp;o=1&amp;a=0062506528" alt="" width="1" height="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">&nbsp;Terence McKenna stuff. But in&nbsp;<a href="https://www.psychologytoday.com/blog/unique-everybody-else/201408/dmt-gateway-reality-fantasy-or-what">one</a>&nbsp;of them he mentions a paper by Marko Rodriguez called&nbsp;<a href="http://www.ayahuasca-info.com/data/articles/paralleldmt.pdf"><i>A Methodology For Studying Various Interpretations of the N,N-dimethyltryptamine-Induced Alternate Reality</i></a>, which suggested among other things that you could prove DMT entities were real by taking the drug and then asking the entities you meet to factor large numbers which you were sure you couldn’t factor yourself. So to that end, could you do me a big favor and tell me the factors of 1,522,605,027, 922,533,360, 535,618,378, 132,637,429, 718,068,114, 961,380,688, 657,908,494, 580,122,963, 258,952,897, 654,000,350, 692,006,139?</p>
<p>– <a href="http://slatestarcodex.com/2015/04/21/universal-love-said-the-cactus-person/">Universal Love, Said the Cactus Person</a>, by <a href="http://slatestarcodex.com/">Scott Alexander</a></p></blockquote>
<p>In the comments…</p>






<p>I was a little curious about how such a prime experiment would go and how much it would cost. It looks like one could probably run an experiment with a somewhat OK chance at success for under $1k.</p>
<p>We need to estimate the costs and probabilities of memorizing a suitable composite number, buying DMT, using DMT and getting the requisite machine-elf experience (far from guaranteed), being able to execute a preplanned action like asking about a prime, and remembering the answer.</p>
<div>
<p>1. The smallest RSA number not <a href="https://en.wikipedia.org/wiki/RSA_numbers#RSA-220">yet factored is 220 digits</a>. The RSA numbers themselves are useless for this experiment because if one did get the right factors, because it’s so extraordinarily unlikely for machine-elves to really be an independent reality, a positive result would only prove that someone had stolen the RSA answers or hacked a computer or something along the lines. RSA-768 was factored in 2009 using ~2000 CPU-years, so we need a number much larger; since Google has several million CPUs we might want something substantially larger, at least 800 digits. We know from mnemonists that numbers that large can be routinely memorized, and an 800 digit decimal can be <a href="http://www.recordholders.org/en/list/memory.html#numbers-1h">memorized in an hour</a>.&nbsp;Chao Lu memorized <a href="http://www.pi-world-ranking-list.com/lists/details/luchaointerview.html">67k digits of Pi in 1 year</a>. So the actual memorization time is not significant. How much training does it take to memorize 800 digits? I remember a famous example in WM research of how WM training does not necessarily transfer to anything, of a student taught to memorize digits, <a href="https://www.cmu.edu/dietrich/psychology/">Ericsson &amp; Chase</a>’s&nbsp;whose digit span went from ~7 to ~80 after 230 hours of training; digit span is much more demanding than a one-off memorization. <a href="https://publishup.uni-potsdam.de/opus4-ubp/frontdoor/deliver/index/docId/3846/file/1987_mnemonic.pdf">This</a> does something similar using more like 80 hours of training. Foer’s _Moonwalking With Einstein: The Art and Science of Remembering Everything_ doesn’t cover much more than a year or two and fairly undemanding training regimen, and he performed well. So I’m going to guess that to memorize a number which would be truly impressive evidence (and not simply evidence for a prank or misdeeds by a hobbyist, RSA employee, Google, or the NSA) would require ~30h of practice.<br>
2. some browsing of the DMT category on the current leading black-market suggests that 1g of DMT from a reputable seller costs ฿0.56 or ~$130. The linked paper says smoking DMT for a full trip requires 50mg/0.05g so our $130 buys ~19 doses.<br>
3. The <a href="http://www.ayahuasca-info.com/data/articles/paralleldmt.pdf">linked paper</a>&nbsp;says that 20% of Strassman’s injected-DMT trips give a machine-elf experience; hence the 1g will give an average of ~3-4 machine-elfs and 19 trips almost guarantees at least 1 machine-elf assuming 20% success-rate (1-(1-0.2)^19 = 98%). Since the 20% figure comes from injected DMT and DMT of a controlled high quality, probably this is optimistic for anyone trying out smoking DMT at home, but let’s roll with it.<br>
4. in a machine-elf experience, how often could we be lucid enough to wake up and ask the factoring question? No one’s mentioned trying so there’s no hard data, but we can borrow from a similar set of experiments in verifying altered states of consciousness, Laberge’s lucid dreaming experiments in which subjects had to exert control to wiggle their eyes in a fixed pattern. <a href="http://diyhpl.us/~bryan/papers2/dreaming/Lucidity%20Institute%20Research%20Papers.pdf#page=163">This study</a> gives several flows from # of nights to # of verifications, which all are roughly 1/3 – 1/4; so given our estimated 3-4 machine-elfs, we might be able to ask 1 time. If the machine-elves are guaranteed to reply correctly, then that’s all we need.<br>
5. at 30 hours of mnemonic labor valued at minimum wage of $8 and $130 for 19 doses, that gives us an estimate of $370 in costs to ask an average of once; if we amortize the memorization costs some more by buying 2g, then we instead spend $250 per factoring request for 2 tries; and so on down to a minimum cost of (130/19)*5 = $34 per factoring request. To get n=10 requests, we’d need to spend a cool ((30*8) + 10*130)=$1540.<br>
6. power analysis for a question like this is tricky, since we only need one response with the *right* factors; probably what will happen is that the machine-elfs will not answer or any answer will be ‘forgotten’. You can estimate other stuff like how likely the elves are to respond given 10 questions and 0 responses (flat prior’s 95% CI: 0-28%), or apply decision-theory to decide when to stop trying (tricky, since any reasonable estimate of the probability of machine-elves will tell you that at $35 a shot, you shouldn’t be trying at all).</p>
<p>Hence, you could get a few attempts at somewhere under $1k, but exactly how much depends sensitively on what fraction of trips you get elves and how often you manage to ask them; the DMT itself doesn’t cost *that* much per dose (like ~$7) but it’s the all the trips where you don’t get elves or you get elves but are too ecstatic to ask them anything which really kill you and drive up the price to $34-$250 per factoring request. Also, there’s a lot of uncertainty in all these estimates (who knows how much any of the quoted rates differ from person to person?).</p>
<p>I thought this might be a fun self-experiment to do, but looking at the numbers and the cost, it seems pretty discouraging.</p>
<hr>
<p><strong>Related Empirical Paradigms for Psychedelic Research</strong>:</p>
<ol>
<li><a href="https://qualiacomputing.com/2016/10/29/lsd-and-quantum-measurements-can-you-see-schrodingers-cat-both-dead-and-alive-on-acid/">LSD and Quantum Measurement</a> (an experiment that was designed, coded up, and conducted to evaluate whether one can experience multiple Everett branches at once while on LSD).</li>
<li><a href="https://qualiacomputing.com/2015/05/22/how-to-secretly-communicate-with-people-on-lsd/">How to Secretly Communicate with People on LSD</a>&nbsp;(a method called <em>Psychedelic Cryptography</em>&nbsp;which uses the slower qualia decay factor induced by psychedelics, aka. “tracers”, in order to encode information in gifs that you can only decode if you are sufficiently high on a psychedelic).</li>
<li><a href="https://qualiacomputing.com/2015/04/20/psychophysics-for-psychedelic-research-textures/">Psychophysics for Psychedelic Research: Textures</a>&nbsp;(an experimental method developed by <a href="http://cvcl.mit.edu/SUNSeminar/Balas_texture_VR06.pdf">Benjamin Bala</a>&nbsp;based on the <a href="http://www.cns.nyu.edu/~lcv/texture/">textural&nbsp;mongrel</a> paradigm proposed by&nbsp;<a href="http://www.cns.nyu.edu/~eero/">Eero Simoncelli</a>&nbsp;and extended to provide insights into psychedelic visual perception. See: <a href="http://scarlet.stanford.edu/teach/index.php/Psychophysical_assessments_of_Portilla_and_Simoncelli's_texture_synthesis_algorithm">analysis</a>).</li>
</ol>
</div>
					</div></div>]]>
            </description>
            <link>https://qualiacomputing.com/2018/10/15/estimated-cost-of-the-dmt-machine-elves-prime-factorization-experiment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741946</guid>
            <pubDate>Sun, 05 Jul 2020 21:01:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Risk management and RR ratio in trading, a quantitative approach]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23741918">thread link</a>) | @ohlongjohn
<br/>
July 5, 2020 | https://sublimetraders.com/cryptocurrency-market-analysis/risk-management-ratio-sizing-crypto-trades/ | <a href="https://web.archive.org/web/*/https://sublimetraders.com/cryptocurrency-market-analysis/risk-management-ratio-sizing-crypto-trades/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    
<p><strong>Contents in this article:</strong></p>



<ol><li><a href="#introduction">Opening note</a></li><li><a href="#portfolio">Portfolio</a></li><li><a href="#acc-size">Account Size</a></li><li><a href="#acc-risk">Account Risk</a></li><li><a href="#trade-risk">Trade Risk</a></li><li><a href="#pos-size">Position Sizing</a></li><li><a href="#final">Final Word</a></li></ol>



<h2 id="introduction">Introduction </h2>



<p>Be it small or large, any kind of portfolio needs proper risk management. The whole point of risk management is to allow you to continue trading, as simple as that. It keeps you for making repeated mistakes that can otherwise blow up your account . Keep in mind that one poorly managed trade can wipe out months or even years of consistent positive trading.</p>



<p>The basis of risk management is that it helps avoid making emotional decisions because we do make those type of decisions, we are either hyped or scared to win or lose more assets. With a strict trading plan your trading and investment decisions can be regulated easily. Coming up with a set of rules is the best way to go, each of us is different so not all the rules are the same but a few of them apply to everyone.</p>



<p>These rules have the purpose of managing risk, and eliminate rash decisions, they will allow you to stay in the game more than you would without them.</p>



<p>When creating your risk system you will need to take in mind factors like investment timeframe, risk tolerance, and how much you can risk. An important aspect that you should not forget is that recovering losses is more difficult than creating small profits. Psychologically it plays an enormous pressure on us to know that we started at $1000, we are down at $600 and we need to recover the initial investment. Some even go as far as quitting straight away after the first losses. Everything here is tied toghether, risk, psychology, trade amount, etc. We’ll dive deeper into the subject.</p>



<h2 id="portfolio">Portfolio</h2>



<p>A portfolio is the mix of all assets you hold or want to invest into. Portfolio diversification is a very important aspect of diversification and should be taken very seriously. A correctly diversified portfolio holds assets from real state to cryptocurrency (eg. Bitcoin, Ethereum, XRP). The portfolio can also be a division of trading accounts across different exchanges or brokers.</p>



<p>How about testing our services for free for&nbsp;<strong>7 days</strong>? Go for it, worst case scenario – you learn something new 👉 <a rel="noreferrer noopener" href="https://t.me/sublime_signals_payment_bot" target="_blank"><strong>interact with our bot</strong></a></p>



<h2 id="acc-size">Account Size</h2>



<p>Simple as it may sound, the account size is very important in risk management. The account size is part of your portfolio risk management plan. For beginners it is important to calculate, allocate and split the  account size into multiple smaller accounts. Multiple accounts, multiple strategies. Consider it as A/B testing, each account with it’s own starting balance, it’s own strategy. At the end of the month compare the winners with the losers and see what worked best…. <em><strong>Improvise, overcome, adapt.</strong></em> This also removes the possibility of risking too much.</p>



<p>One example would be : You beleave Bitcoin will go higher in the longterm and have some in your hardware wallet and some in your trading account, the smart thing to do is not to trade the BTC you have in your hardware wallet.</p>



<p>Allocating the capital is up you, you can split it in equal slices or any other way you want, <strong>just split it</strong>!</p>



<h2 id="acc-risk">Account Risk</h2>



<p>I am still amazed of how many people still don’t understand the difference between account risk and account size. The Account risk is determined by taking note of the account size. You will risk x% of your account size on a single trade.</p>



<p>Now there is a fixed rule for this , it’s <strong>called the 2% rule</strong> and basically it tells you to not risk more than 2% of your account size in one trade. This is where most people get it wrong . The 2% risk size does not mean you trade 2% of your account, it means the loss you might have must not exceed this limit.</p>



<p>In order to establish the 2% of risk you are willing to take on a trade, you first need to establish the entry, exit and stop loss of your trade. You also need to take into consideration that if you’re using leverage that will affect your losses.</p>



<div><p><strong>Risk/Reward ratio</strong><br>The risk reward ratio also called RR is the ratio between the possible losses and the possible winning , Risk / Reward. It helps us see if a trade is viable at a glance. <br>The higher the ratio, the better the trade(Ex. A ratio of 0,5/1 is bad , a ratio of 3/1 is good).<strong>The minimum accepted RR ratio at Sublime Traders is 1,7/1 and in rare cases.</strong></p><p>This part is where many cryptocurrency signal providers start to act funny, let me explain why. Because signal providers want to have as many signals as possible they post trades that have 1/1 Ratio or even lower. The problem here is obvious for seasoned traders, the thing is <strong>you can not be consistently profitable with a 1/1 RR ratio or lower, in fact the minimum is 1,5/1 and you really have to master your entries for this to be viable</strong>. </p></div>



<p>Let me explain further. Say you have a 3/1 RR ratio which is a good ratio, in the long run you win because for every trade you lose 1 and you win 3, this means you only need to win 3,33 trades out of 10 in order to be break even. With a ratio of 1/1 you can not possibly sustain constant profit because the risk and the rewards are the same.<br>I really can’t stress how important this aspect is please read several times until you understand this aspect perfectly, stop trading 1/1’s, it’s stupid😊</p>



<p><strong>Pro tip</strong> : The <strong>tradingview</strong> chart suite which has been <a rel="noreferrer noopener" href="https://sublimetraders.com/new-crypto-traders/10-trading-tools-every-crypto-trader-should-know/" target="_blank"><strong>reviewed here</strong></a> offers simple inputs for risk amount and risk reward ratio with the <strong>position tool</strong>.</p>



<figure><img src="https://sublimetraders.com/wp-content/uploads/2020/06/Screenshot-at-Jun-15-14-57-17.png" alt="" srcset="https://sublimetraders.com/wp-content/uploads/2020/06/Screenshot-at-Jun-15-14-57-17.png 908w, https://sublimetraders.com/wp-content/uploads/2020/06/Screenshot-at-Jun-15-14-57-17-300x243.png 300w, https://sublimetraders.com/wp-content/uploads/2020/06/Screenshot-at-Jun-15-14-57-17-768x621.png 768w, https://sublimetraders.com/wp-content/uploads/2020/06/Screenshot-at-Jun-15-14-57-17-370x300.png 370w, https://sublimetraders.com/wp-content/uploads/2020/06/Screenshot-at-Jun-15-14-57-17-85x70.png 85w" sizes="(max-width: 908px) 100vw, 908px"></figure>



<h2 id="trade-risk">Trade Risk</h2>



<p>So far we have our account size and account risk , let’s now determine the position size of a single trade. Losses are <strong>always</strong> part of the game so this needs to be taken into consideration when determining the entry size of your position. </p>



<p>Lets clear things out with a list of to do’s when posting a trade:</p>



<ul><li>Identify entry</li><li>Identify Take profit</li><li>Identify Stop Loss</li><li>Identify RR ratio</li><li>If ratio &gt; 1,7/1 then post trade (there you go, i created a short if statement for algo trading)</li></ul>



<h2 id="pos-size">Position sizing</h2>



<p>This part is the most difficult when setting up a trade. It takes into consideration or the elements we mentioned before.</p>



<p>Let’s take an example:</p>



<ul><li>Account size – $1000</li><li>Account risk – 2%</li><li>Distance to stop loss(invalidating point) – 5%</li></ul>



<pre>position size&nbsp;=&nbsp;account size&nbsp;x&nbsp;account risk&nbsp;/&nbsp;invalidation point
position size&nbsp;=&nbsp;$1000&nbsp;x&nbsp;0.02&nbsp;/&nbsp;0.05
position size = $400</pre>



<p>What this does it it protects your capital from heavy losses and it basically allows you to stay in the game. Remember to add trading fees to your calculation for bigger sizes. Trading fees vary from exchange to exchange but in general they are 0,1% on every trade for spot exchanges, and 0,075% for  takers on futures like <a href="https://partner.bybit.com/b/sublimetraders">Bybit</a> and -0,025 for makers (you get paid for limit orders).</p>



<h2 id="final">Final Word</h2>



<p>Our job is to provide clear <strong>entry</strong>, <strong>take profits</strong> and <strong>stop loss</strong> for every trade you post, you on the other hand need to manage your risk properly by following this guide or doing your own research.</p>
                    
                                            
                                    </div></div>]]>
            </description>
            <link>https://sublimetraders.com/cryptocurrency-market-analysis/risk-management-ratio-sizing-crypto-trades/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741918</guid>
            <pubDate>Sun, 05 Jul 2020 20:58:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comprehensive list of Dos-based palmtop computers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23741810">thread link</a>) | @Ijumfs
<br/>
July 5, 2020 | http://www.tankraider.com/DOSPALMTOP/list.html | <a href="https://web.archive.org/web/*/http://www.tankraider.com/DOSPALMTOP/list.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.tankraider.com/DOSPALMTOP/list.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741810</guid>
            <pubDate>Sun, 05 Jul 2020 20:46:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thoughts on the Raspberry Pi 4 and 10k TCP connections with Vert.x]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23741598">thread link</a>) | @asadawadia
<br/>
July 5, 2020 | https://aawadia.hashnode.dev/thoughts-on-the-raspberry-pi-4-10k-tcp-connections-with-vertx-ckc9huyxk0087mns121re4awv | <a href="https://web.archive.org/web/*/https://aawadia.hashnode.dev/thoughts-on-the-raspberry-pi-4-10k-tcp-connections-with-vertx-ckc9huyxk0087mns121re4awv">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>I recently picked up a Raspberry Pi 4 [4GB edition]. 
<img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1593971667034/LD9-XNgaz.jpeg?auto=format&amp;q=60" alt="B15DC608-54AE-476A-AE53-FCB3E3EC6889.jpg"></p>
<h2 id="background-context">Background Context</h2>
<p>I had been debating picking up a Linux system for some dev work. I don't like using Docker right from the get go as a dev environment. My general workflow for any project goes in the following steps - for a Kotlin project</p>
<ol>
<li>Run from IDE</li>
<li>Run from terminal via build tool such as maven or bazel</li>
<li>Compile to a fat jar and run using <code>java -jar &lt;project&gt;.jar</code></li>
<li>Run fat jar on a Linux server [now possible]</li>
<li>Run as a docker container</li>
<li>Run as a Kubernetes deployment</li>
</ol>
<p>I know many devs have jumped directly to step 5 but I think it is still important to make sure that steps 1-4 are compiling and running properly.  Step 1 is still important because other devs, who do not have context, will navigate to your project [in their IDE] to add new features or fix bugs. Very likely, they will add a bunch of print statements in the project and start making requests to see what the internals look like. I guess you could use the documentation on confluence but sometimes it is easier and faster to just log-dump the request. They should to be able to spin the service up easily when they have no context. The project should not fail to startup because a required environment variable was not set - set a sane default, log the behaviour [such as persistence disabled] and proceed.</p>
<p>If for any reason you think this is a lot of work - I present you Margaret Hamilton the lead developer on the Apollo mission standing next to the hard copy of the code base.
<img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1593974553056/BUndgAHNK.gif?auto=format,compress&amp;gif-q=60" alt="apollo.gif"></p>
<h2 id="vps-vs-raspberry-pi">VPS vs Raspberry Pi</h2>
<p>I was thinking of getting a digital ocean VPS - with the 1CPU 1GB ram costing about $5/month or $20 for the 2CPU 4GB ram. The monthly cost was definitely a factor since I was planning on running multiple things 24/7 and not just one small app. The advantage was being able to easily expose it on the internet for demo reasons. For an in house server, I would have to port forward on my router, which I was [and still am] not a big fan of. Ngrok [<a href="https://ngrok.com/" target="_blank">ngrok.com</a>] definitely could be a quick workaround. Another concern was that I love doing benchmarks and load testing. I did not want to cause any DDoS triggers on DO's end getting my account suspended or anything like that.</p>
<p>I picked up the CanaKit Raspberry Pi 4 Starter Kit (4GB RAM) from Amazon. Definitely a bit more expensive than I thought it was going to be all things considered. It was relatively easy to set up the heat sinks and the case. Hooked it up to a keyboard, mouse, and my TV to install the OS. I don't need a GUI so I installed the headless Raspberry Pi OS which is debian based [apt - not yum]. <code>raspberrypi.local</code> is set up to connect to the Pi.</p>
<pre><code>pi@raspberrypi ➜  ~ uname <span>-a</span>
Linux raspberrypi 4.19.118-v7l+ 
</code></pre><h2 id="what-s-running-on-it-">What's running on it?</h2>
<p>A server is useless if it is not running anything. I had a few things I knew I was going to set up. The first was a DNS level ad blocker pi hole [<a href="https://pi-hole.net/" target="_blank">pi-hole.net</a>]. Gave my Pi a static IP via DHCP reservation in my Rogers router and set up pi hole to block out any ads for all devices that used it as a DNS Server. Just this one application alone made the pi worth it. Pi hole helps quite a bit. Doesn't block everything [like ads on YouTube in mobile] but it is good enough. Also caches the DNS responses so browsing seems a bit zippier too. It is PHP based so it needs a webserver to call out to the php scripts - lighthttpd in this case. Not a big fan of this. Why are we still using PHP + web servers in 2020??</p>
<p>List of other things I set up not including things like zsh and htop:</p>
<ol>
<li>OpenJDK [OpenJ9 seems to have limited to no support for ARM]</li>
<li>Redis</li>
<li>Postgres</li>
<li>Grafana</li>
<li>Prometheus</li>
<li>MongoDB</li>
<li>InfluxDB [docker container]</li>
<li>Docker registry [docker container]</li>
<li>Node.js for Vue.js dev work</li>
<li>Caddy</li>
<li>Nginx [inactive]</li>
<li>rustc and go</li>
</ol>
<p>I set up gitea [ <a href="https://gitea.io/en-us" target="_blank">gitea.io/en-us</a> ] which is a self hosted git server as well - but the SSH permissions to push/pull got borked :(</p>
<p>I installed caddy as a reverse proxy for the pi to route to various services I have running behind it. Caddy is similar to nginx but with slightly easier configurations and automatic HTTPS setup.</p>
<pre><code>
localhost, raspberrypi.<span>local</span> {
     route / {
        respond <span>"{time.now.common_log} {system.os} {system.arch} {http.request.proto} {http.request.method} {http.request.uri}"</span>
    }
}
</code></pre><pre><code>➜  ~ curl -k https:
<span>05</span>/Jul/<span>2020</span>:<span>15</span>:<span>17</span>:<span>16</span> -<span>0400</span> linux arm HTTP/<span>2.0</span> GET /
</code></pre><h2 id="load-testing-and-10k-connections">Load testing and 10k connections</h2>
<p>Running wrk on Caddy [with logging turned on] I got the following results</p>
<pre><code>$ wrk -t <span>32</span> -c <span>64</span> -d20s https:
Running <span>20s</span> test @ https:
  <span>32</span> threads and <span>64</span> connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     <span>7.15</span>ms    <span>3.91</span>ms  <span>60.06</span>ms   <span>83.81</span>%
    Req/Sec   <span>291.33</span>     <span>36.82</span>   <span>390.00</span>     <span>74.65</span>%
  <span>185508</span> requests in <span>20.07s</span>, <span>25.12</span>MB read
Requests/sec:   <span>9241.25</span>
Transfer/sec:      <span>1.25</span>MB
</code></pre><p>Next I setup a Vert.x TCP server and used tcpkali [ <a href="https://github.com/satori-com/tcpkali" target="_blank">github.com/satori-com/tcpkali</a> ] to see if the Pi could handle 10k concurrent connections.</p>
<p>As always, I opted to use vert.x to create the tcp server. A tcp server in vert.x can be spun up very easily with the following lines of code</p>
<pre><code><span>val</span> vertx = Vertx.vertx()

vertx.createNetServer().connectHandler { 
  
  it.handler { 
    
  }
}.listen(<span>9091</span>)
</code></pre><p>I also added some prometheus metrics:</p>
<ol>
<li>Node exporter to get the system information of the pi during the load test</li>
<li>Micrometer bindings to get the JVM information</li>
<li>Vert.x metrics to get the net server connection count + a custom packet received counter</li>
</ol>
<p>The entire main function can be viewed in here - <a href="https://gist.github.com/asad-awadia/93ba7c1eba6d6b8a8a84e9f20721d983" target="_blank">gist.github.com/asad-awadia/93ba7c1eba6d6b8..</a></p>
<p>Then the test began using tcpkali <code>tcpkali -m '$' -r 10 -c 10k -T 240s --connect-rate=1000 &lt;pi-ip&gt;:9091</code></p>
<p>Some grafana screenshots:</p>
<p>Vert.x net server connections + packet received
<img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1593977834283/PQWiJouxr.png?auto=format&amp;q=60" alt="Screen Shot 2020-07-04 at 12.48.09 PM.png"></p>
<p>CPU usage
<img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1593977882225/wuc7a5Z-X.png?auto=format&amp;q=60" alt="Screen Shot 2020-07-04 at 12.47.17 PM.png"></p>
<p>JVM memory used - vert.x is really memory efficient
<img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1593977897137/fNbEQl2Xw.png?auto=format&amp;q=60" alt="Screen Shot 2020-07-04 at 12.47.05 PM.png"></p>
<p>Node exporter quick stats
<img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1593977918587/Z5FjhSwyO.png?auto=format&amp;q=60" alt="Screen Shot 2020-07-04 at 12.46.00 PM.png"></p>
<p>For a tiny little device it seems more than capable for a single dev. I would not use it as a build server for your company's production apps but to have an always on linux system available is really nice to have.</p>
</div></div>]]>
            </description>
            <link>https://aawadia.hashnode.dev/thoughts-on-the-raspberry-pi-4-10k-tcp-connections-with-vertx-ckc9huyxk0087mns121re4awv</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741598</guid>
            <pubDate>Sun, 05 Jul 2020 20:21:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It’s Time to Reassess the Developer Career Ladder]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23741511">thread link</a>) | @caution
<br/>
July 5, 2020 | https://cult.honeypot.io/reads/reassess-the-developer-career-ladder | <a href="https://web.archive.org/web/*/https://cult.honeypot.io/reads/reassess-the-developer-career-ladder">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The career ladder for software engineers is often confusing and inconsistent.&nbsp; Many people who go into software development tend to go in with tunnel vision - they don’t even think about the career ladder because they’re so focused on the next pay bump or the next feature release. Also, they know that there are at least two steps in the ladder to worry about before anything dramatic can happen: junior developers become mid level developers and mid level developers become senior developers. But what about after that?&nbsp;</p><p>A lot of the problems that developers complain about in the tech industry are nested within that question. If you’ve been coding for the last four or five years of your life, spending more time in front of the computer than in front of other people, chances are your social skills might have taken a hit. If you are an extrovert or even moderately outgoing, this probably wouldn’t be a big deal. But if you’ve always been the type to prefer staying indoors, or worse, preferred the company of computers over people, a manager is probably the last thing you want to be.</p><h3><b>The Problem with Promoting All Senior Developers to Managers</b></h3><p>Unfortunately many organizations promote senior developers to managerial roles. There is a mistaken assumption among people in leadership that those who develop a high level of expertise in their field will naturally be good at managing. They fail to consider that what makes a good software engineer and what makes a good manager can often be at odds with each other. Good developers are detail-oriented, deep thinkers who thrive on solving technical challenges that are, at the end of the day, either solved or not solved. Good managers can see the big picture, and thrive on solving problems at the organizational level that require negotiating with, compromising, and sometimes confronting other people.&nbsp; These types of problems rarely have a black and white outcome, and usually there is no tangible reward besides the relative happiness of the employees.&nbsp;&nbsp;</p><p>I have experienced this first hand with one of my past managers. He had an impressive looking resume, having worked on the ground level of many start-ups as CTO and founder, but he seemed to be much more proud of the fact that he had been coding for three decades. On the surface he seemed like he would make a good manager, probably because he exuded a great deal of confidence. Unfortunately it ended up being quite the opposite. It took months for leadership to take action despite many employee complaints. What was especially uncomfortable was the way the manager responded when he discovered he was under fire. At every 1:1 he would ask me directly for negative feedback I had about him, as if I would just tell him to his face. It was incredibly awkward, and demonstrated a complete failure of grasping social norms. Not to mention empathy for the other person in the room and how they might feel being asked such questions. He also seemed to believe that if nobody gave them the negative feedback to their face, that this must mean he was actually performing well.&nbsp;</p><p>Ultimately, this particular manager was much better suited to programming as an individual contributor rather than leading a team.&nbsp;</p><h3><b>Alternative pathways for senior developers</b></h3><p>Luckily, some companies have moved away from promoting all of their software engineers to managers. One alternative approach is to give software developers three different “tracks” to choose from. Developers can take on a range of leadership responsibilities depending on the track. For instance, there is the team lead track where senior engineers become lead developers that make some of the more challenging and difficult technical decisions for the team. They also help mentor their teammates but do not take on as many managerial duties as an engineering manager.&nbsp;</p><p>For developers who have no interest in taking on leadership duties, there is the option of becoming a software architect. These developers get to make technical decisions that usually impact the future of the company and are often trusted with the keys to the kingdom. These developers are the ones who understand how all the software fits together and have a mental model that includes every little nook and cranny of code.&nbsp;</p><p>The best part about having this three track system for promoting software engineers is that there is wiggle room to switch between tracks if a developer decides they want to try something different or if it turns out they are not well suited for the track they are on. It reduces the risk of creating terrible managers that end up causing other developers to quit or lose motivation. The personality and attitude of managers in an organization often influence the culture. It’s important for leadership to reach out to their direct reports and be able to identify and fix issues when they arise.&nbsp;</p><p>Unfortunately, even this three track system is not bulletproof. Favouritism, slowness in moving people to a different track, and poor promotion metrics can cause even the best system to fall apart. Start-ups can be especially vulnerable to developers that can suck up to the CEO and bypass formal processes. While large companies tend to have less of that problem, they often adopt ranking systems that may or may not be effective at identifying the best employees, depending on how easy it is to play the system and how many people fall between the cracks.&nbsp;</p><p>Muddying the waters even further is the fact that developers often switch jobs when they don’t see a path forward at their current company. My first official title when I broke into the field was “Software Engineer.” When I moved to DC it became “UI/UX Developer” and I negotiated a pretty hefty pay raise in light of the difference in cost of living from Missouri. The following job ended up giving me a senior title despite the fact that I had less than 2 years of experience in the industry. They gave developers seniority not purely based on years of experience, but based on that developer’s salary.&nbsp;</p><p>This led to a strange and somewhat uncomfortable situation for me when, two jobs later, I found myself back in a mid-level title. From an outsider’s perspective, it sort of looked like a demotion. I didn’t know whether to remove “senior” on my past positions on LinkedIn or whether that would end up hurting me more. It happens because there is no standard for rating a developer’s skill level across the industry, and certainly no standard for pay depending on that level.&nbsp;</p><h3><b>A potential solution?</b></h3><p>That is why some developers have been calling for the creation of an organization responsible for standardizing the requirements and skills that developers need across the United States in order to create a more level playing field and also a system that allows developers to advocate for themselves and figure out if they are being underpaid. Unlike these three track systems which still allow managers to make decisions based on their own opinion about a developer, a trade organization for developers would create a third party that holds managers accountable.&nbsp;</p><p>Certainly there are potential problems that could be introduced by a trade organization, but right now the software engineering industry is basically the wild west when it comes to promotions. You have developers with 10 years of experience being paid 45K alongside junior developers at start-ups making upwards of 100K. Underrepresented folks in tech are still seeing a gap between their paychecks and those of their white male counterparts. Every time I got a new job part of me felt like I was back at square one again. As technology becomes more and more complex and humans rely on it on a daily basis, it seems the lack of a trade industry could not only be problematic but even catastrophic.&nbsp;</p><h3><b>Technology Industry Standards Impact Millions</b></h3><p>Having no coding standard for, say, a social media company, might seem inconsequential, but when you have software operating planes and cars and security there are lives at stake. It’s not just about making developers’ lives easier and fairer, it’s about creating a system where technology can actually be reliable and not subject to the whims of a company CEO that wants to save some money by telling developers to cut corners. Developers and frankly, the human race, deserves better.&nbsp;</p></div></div>]]>
            </description>
            <link>https://cult.honeypot.io/reads/reassess-the-developer-career-ladder</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741511</guid>
            <pubDate>Sun, 05 Jul 2020 20:09:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[All about the upcoming Playstation 5]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23741507">thread link</a>) | @ezrakewa
<br/>
July 5, 2020 | https://www.4alltech.com/2020/07/when-does-ps5-appear-what-hardware-will.html | <a href="https://web.archive.org/web/*/https://www.4alltech.com/2020/07/when-does-ps5-appear-what-hardware-will.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<div id="post-body-8407308363661742376" itemprop="articleBody">
<meta content=" PS5 release, price, hardware: All information about the PlayStation 5      The PlayStation 5 is the successor to the PS4. So far, no design..." name="twitter:description">
<div id="adsense-target">
<p><span>PS5 release, price, hardware: All information about the PlayStation 5</span></p><p><a href="https://1.bp.blogspot.com/-jCSyAezVgZ8/XwIrvQTt6GI/AAAAAAAAAaU/6rrqXXf6ylYcHL3txXfpSEXY-uHSbF47gCLcBGAsYHQ/s1600/ps5family-peripherie_6103290.jpg" imageanchor="1"><img data-original-height="720" data-original-width="1280" height="360" src="https://1.bp.blogspot.com/-jCSyAezVgZ8/XwIrvQTt6GI/AAAAAAAAAaU/6rrqXXf6ylYcHL3txXfpSEXY-uHSbF47gCLcBGAsYHQ/s640/ps5family-peripherie_6103290.jpg" width="640"></a></p>
<p><span><br></span>
<br>
<span>The PlayStation 5 is the successor to the PS4. So far, no design, price or launch date are known. But there is still a lot of known information and many credible rumors. In this article we collect all information and news about the price, release, hardware and games.</span></p><p>

<span>We have collected all the information and rumors of the past few years for you so that you can find everything there is to know and expect about PlayStation 5 at a glance:</span><br>
<span><br></span>
<span><b>PS5 release - when does the console appear?</b></span><br>
<span>The most important question first: when will the PS5 come out? We know that, according to Sony's official statement, the next-gen console will appear at the end of 2020 , during the so-called Holiday Season (more or less the extended Christmas business. Everything is possible here from late October to mid-December).</span><br>
<span><br></span>
<span>According to Sony, the target release period is still certain despite the corona crisis. This was confirmed by Sony Interactive Entertainment President Jim Ryan in early April 2020.</span><br>
<span><br></span>
<span><b>Price - What will the PS5 cost?</b></span><br>
<span>The PS4 cost just under 400 euros for the launch , the PS4 Pro also went over the counter for 400 euros at the beginning. However, it is becoming increasingly unlikely that the PS5 will be offered at the same price. It will probably be more expensive than the PS4 and PS4 Pro .</span><br>
<span><br></span>
<span>What does Sony say about the PS5 price? According to Sonys Mark Cerny, the system architect of the PS5, the console "should offer a reasonable and attractive cost factor" . Hiroki Totoki, Chief Finanical Officer at Sony, said the price of the next-gen console also depends on the competition . Apparently, Sony is planning to undercut Microsoft again.</span><br>
<span><br></span>
<span>What are the rumors about the price? According to insiders, Sony is currently struggling to keep production costs below $ 450 . A Bloomberg report from April 2020 also fits in with this: Individual components are expensive and sometimes fiercely competitive, because different manufacturers would try to do so at the same time. According to Bloomberg, PS5 estimates are between $ 499 and $ 549.</span><br>
<span><br></span>
<span><b>PlayStation 5 design - what does the PS5 look like?</b></span><br>
<span>The PS5 was unveiled as part of Sony's reveal event on June 11th. The console is available in two models, one with a drive and one without. The latter is accordingly slimmer.</span><br>
<span>In addition to the missing drive and the slightly customized design, there are other differences between the standard model of the PS5 and the Digital Edition:</span><br>
<span>PS5 advertising slogan: The official slogan for the Next Gen console for the system is "Play Has No Limits", probably an allusion to the significantly increased speed of the system.</span><br>
<span><br></span>
<span>By the way, you can already put the PS5 in your apartment. At least as a virtual 3D model thanks to the corresponding AR app.</span><br>
<span><br></span>
<span><b>PS5 peripherals - This is the PlayStation 5 family</b></span><br>
<span>In addition to the actual PS5 console, Sony has also introduced some peripheral devices that belong to the expanded circle of the PlayStation family. If you want to stock up on it, you can choose among:</span><br>
<span><br></span>
<span>HD camera with two 1080p lenses</span><br>
<span>PULSE ED wireless headset</span><br>
<span>Media remote control</span><br>
<span>DualSense charging station</span><br>
<span><b><br></b></span></p><p><a href="https://1.bp.blogspot.com/-DDwTZYOD8RE/XwIr_UWQC7I/AAAAAAAAAac/Ct_ZL3kft0ANis5JnnsgRheCs__tFl2JgCLcBGAsYHQ/s1600/ps5-playstation-5-reveal_6103769.jpg" imageanchor="1"><img data-original-height="347" data-original-width="617" height="358" src="https://1.bp.blogspot.com/-DDwTZYOD8RE/XwIr_UWQC7I/AAAAAAAAAac/Ct_ZL3kft0ANis5JnnsgRheCs__tFl2JgCLcBGAsYHQ/s640/ps5-playstation-5-reveal_6103769.jpg" width="640"></a></p>
<p><span><b><br></b></span>
<span><b>Hardware specs of the PS5</b></span><br>
<span>The exact hardware details of the PlayStation 5 were revealed by Sony's console architect Mark Cerny in March 2020. Here are the key performance data:</span><br>
<span><br></span>
<span>CPU: eight-core Zen 2 with 3.5 GHz clocking</span><br>
<span>GPU: 10.28 teraflops, 36 CUs (RDNA 2)</span><br>
<span>RAM: 16GB GDDR6</span><br>
<span>Hard drive: 825GB SSD</span><br>
<span>Extended storage: SSD slot</span><br>
<span>Drive: 4K UHD Blu-Ray drive</span><br>
<span>For comparison: the standard PS4 only comes to 1.84 TeraFLOPS, the Pro to 4.2 TeraFLOPS.</span><br>
<span><br></span>
<span>About the CPU: The Zen 2 CPU comes from the manufacturer AMD and contains 8 cores, just like the PS4 Pro. It was probably just not necessary to top up here, after all the Zen architecture ensures that the PS5 should run significantly faster even at the same clock rate.</span><br>
<span><br></span>
<span>SSD ensures more speed</span><br>
<span>Although the storage capacity is slightly reduced compared to the PS4 Pro and Xbox Series X, as John Linnemann from Digital Foundry announced on Twitter, the speed of the hard drive (5.5GB / s Raw / 9GB / s Compressed) is "the craziest" the PS5 ". Not only is it already very fast from the pure values, the SSD should also be a lot faster than that of the Xbox Series X.</span><br>
<span><br></span>
<span>Speed ​​example: If 1GB of data was previously loaded from the PS4 in 20 seconds, 2GB of data should now be processed in 0.27 seconds.</span></p><p>

<span>More memory? The SSD hard drive storage of the PS5 can be expanded by the way . And that with standard external SSDs that are checked for compatibility by Sony. However, this will only be possible after the launch. In addition, the operating system of the PS5 significantly smaller than that of the PS4, which means that less memory is blocked by the OS.</span><br>
<span><br></span>
<span>Faster data processing speed: thanks to SSD, the PS5 is even 100 times faster than the PS4, according to Sony. Sony is referring to the data processing speed of the Next Gen console (not the loading speed in games).&nbsp;</span></p><p>

<span>The built-in SSD should also reduce the charging times by a multiple compared to the PS4 Pro .</span><br>
<span><br></span>
<span><span><br></span><span></span><span>PS5 is supposed to get by without loading screens.</span></span>
<span>In a video, Sony shows how fast the PS5 is actually . Using the example of Marvel's Spider-Man, the loading times of the Next Gen console are compared with the PS4 Pro - and the difference is huge, at least in this game.</span><br>
<span><br></span>
<span>In fact, Sony's vision is to eliminate the loading screens entirely. According to Sony, the ultra-fast SSD is the key to the next generation and the first step to make loading screens a thing of the past.</span><br>
<span><br></span>

<span><b>What should the graphics of the PS5 offer?</b></span><br>
<span>8K resolution confirmed: As Sony's systems engineer Mark Cerny revealed in an interview, the PS5 is said to support 8K resolution. Even 4K screens are not yet widespread, so you can imagine how many users can actually enjoy 8K content directly at launch (the short answer: everyone who has between 5,000 and 15,000 euros for an 8K monitor).</span><br>
<span><br></span>
<span>Ray tracing on the PS5.</span><br>
<span>When it comes to hardware, it is also important to know that ray tracing on the PS5 is not anchored in the software, but in the hardware. "There is ray tracing acceleration in the GPU unit," Cerny is quoted as saying.</span><br>
<span><br></span>
<span>More freedom in downloading and installing.</span><br>
<span>The use of storage space on the PS5 should become more economical due to the type of game installation . Games should be able to be saved in granular form, which means that only the parts of the title that we want to play have to be downloaded, for example only the multiplayer campaign of a title, when we are already through with the single player.</span><br>
<span><br></span>
<span>Blu-ray drive confirmed for PS5</span><br>
<span>Yes, the next PlayStation will definitely use physical storage media. System architect Mark Cerny confirmed this in an exclusive Wired article .</span><br>
<span><br></span>
<span>BluRays should continue to function as the medium, as Cerny also reveals. In contrast to the currently available PS4 Pro, the optical drive should also be able to be used as a 4k Blu-Ray player.</span><br>
<span><br></span>
<span><b>Improved heat management</b></span><br>
<span>According to a Bloomberg report , Sony "unusually" spends a lot of money on a PS5 cooling system . This could suggest that the sometimes extreme volume of the PS4 fans should be contained.</span><br>
<span><br></span>
<span>What many of you should also be very happy about is a statement by Cerny about the heat sensitivity of the PS5. If the PS4 was still on its knees when the outside temperature was high, this should change in the future:</span><br>
<span><br></span>
<span>"" All work processes of the PS5 run at the same performance level in every environment. The outside temperature is not critical. ""</span><br>
<span><br></span>
<span><b>PS5: downward compatibility confirmed</b></span><br>
<span>Clear answer: According to system architect Mark Cerny, the next hardware generation of the PlayStation family will be compatible with the PS4 software . Thanks to the existing drive, we can also insert and play our favorite titles of the current console generation on the PS5. The goal is to almost all offer over 4000 PS4 games - in improved quality.</span><br>
<span><br></span>
<span>Own PS4 mode: We now have more specific information on PS4 downward compatibility. The PS5 comes with its own mode for PS4 games, of which at least 100 are already available for launch. According to Sony, these were successfully tested on the PS5. However, it is not excluded that this catalog will be expanded at the start.</span><br>
<span><br></span>
<span>Also applies to PSVR: The PSVR headset is also taken into account in downward compatibility and will also connect to the PS5.</span><br>
<span><br></span>
<span>New engine is supposed to make retro titles even prettier: Sony is said to even be working on a so-called "remastering engine" that should allow older titles to be graphically enhanced. That would be comparable to the possibilities of the Xbox One X, for which old Xbox titles can also be optimized.</span><br>
<span><br></span>
<span><b>PS5: what about VR?</b></span><br>
<span>So far, it is only known that the PSVR headset of the PS4 will be backwards compatible on the new console. So far there are only various rumors and pending patents about a possible PSVR2 for the PS5, so far Sony has not commented on this topic.</span><br>
<span><br></span>
<span>PS5 controller: what can we expect from the DualSense?</span><br>
<span>The new controller that the PS5 will introduce was officially unveiled on April 7: it's called DualSense.</span><br>
<span>What can the new PS5 controller do?</span><br>
<span><br></span>
<span>haptic feedback</span><br>
<span>Adaptive trigger</span><br>
<span>Rechargeable batteries</span><br>
<span>Create Button replaces the Share Button</span><br>
<span>Built-in microphone</span><br>
<span>Lightbar now next to the touchpad</span><br>
<span><br></span>
<span>PS5 controller becomes backwards compatible</span><br>
<span>Similar to the PS5 itself, the DualSense should also be compatible with the PlayStation 4 . This can be found on the French PlayStation website.</span><br>
<span><br></span>
<span>The other way round, there are rumors that the PS4 controller can also be connected to the PS5 . However, this has not been confirmed.</span><br>
<span><br></span>
<span>At least three more years of support for the PS4</span><br>
<span>Even after the launch of the PS5, the previous generation should not be dropped. According to a presentation at an investor conference , the PS4 should remain the engine for Sony's profitability for at least three years.</span><br>
<span><br></span>
<span>how do you see it? What are your wishes for the PS5? And what do you think is not possible?</span></p>
</div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.4alltech.com/2020/07/when-does-ps5-appear-what-hardware-will.html">https://www.4alltech.com/2020/07/when-does-ps5-appear-what-hardware-will.html</a></em></p>]]>
            </description>
            <link>https://www.4alltech.com/2020/07/when-does-ps5-appear-what-hardware-will.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741507</guid>
            <pubDate>Sun, 05 Jul 2020 20:09:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Thinker]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23741488">thread link</a>) | @TheThinkerCEO
<br/>
July 5, 2020 | http://barisciencelab.tech/TheThinker.html | <a href="https://web.archive.org/web/*/http://barisciencelab.tech/TheThinker.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
 
  <!--<div id="preloader"></div>-->
    <!--<div id="content">-->

      

 <!--
 <script src="//code.jquery.com/jquery.min.js"></script>
<script>
$.get("ThinkMenu.html", function(data){
    $("#nav-placeholder").replaceWith(data);
});
</script>
 
 
 
 <div id="nav-placeholder"></div>
 -->
 
 
      <nav role="navigation" aria-label="main navigation">



  



    
	   
	   
  <br>
    <!--<button class="button is-info" id="showModal" style = "margin-top:-2vh;">Apply</button>-->

	
	

	<!--
     <div class="navbar-item">
        <div class="buttons">
          <a class="button is-primary" href = "https://forms.gle/21Yp4J9h9v45uDcA8" >
            <strong>Apply</strong>
          </a>
        </div>
      </div>
      -->
  
</nav>
  
  <div>
  <center>
<div>
  <p><span><p>The Thinker</p></span>   

  </p>
  <p><span><p><span><a href="http://barisciencelab.tech/TheThinker.html"><img src="https://i.imgur.com/laASlTU.png" alt=""></a></span>
  </p></span>
</p></div>
    
    </center>
    
  </div>
 
 
      <section>
  <div>


<!--
 <div class = "columns fifty">
    <div class = "column is-12">-->
   <!--
    <article class = "title is-child blue" style = "padding: 2%;">
        <center>
        
        <h2 class = "post__title">Read in another Language: </h2>
        
        
        <div id="google_translate_element"></div>

        <script type="text/javascript">
        function googleTranslateElementInit() {
          new google.translate.TranslateElement({pageLanguage: 'en'}, 'google_translate_element');
        }
        </script>
        
        <script type="text/javascript" src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script>
</center>
    </article>
    --><!--
    </div>
</div>-->

<!--
<section class="hero is-info" style = "margin-bottom:-5%;">
  <div class="hero-body">
    <div class="container">
      <h1 class="title appsnews">
        Congratulations!
      </h1>
      <h2 class="subtitle">
        <a href = "https://www.youtube.com/watch?v=1joMpCeueO0&t=994s"><b>Interviews here</b></a>. 11 Journalists have been accepted to <i>The Thinker</i>! Their Profiles will be released shortly. 
      </h2>
    </div>
  </div>
</section>-->



<br>
<div>
      <div>
        <article>
          <a href="">United States</a>

          <h2>Christians: Sinners or Saints?</h2>
          <p>Religions have their respective symbols, The jews have the Jewish Star, the Hindus have the Swastika, and the Christians have the Cross. But why a Cross? What is Christianity, really? Why was Jesus crucified? And what are my personal thoughts on Christianity? I. What are the basic functions of Christianity? We will discuss and then answer all of these, and set out to explore the intricate set of connections and rules that is Christianity. Come with me on this learning journey.</p>
          <figure>
    <img src="https://i2-prod.mirror.co.uk/incoming/article12562538.ece/ALTERNATES/s1227b/The-wedding-of-Prince-Harry-and-Meghan-Markle-Ceremony-St-Georges-Chapel-Windsor-Castle-Berkshi.jpg">
    <figcaption>
        Th prince and princess of England marrying in a catholic church.
    </figcaption>
</figure>
        </article>
      </div>

 <div>
        <article>
          
          <h2><a href="http://barisciencelab.tech/06022020Interview.html">"Education, not Violence", pleads Black Student</a></h2>
                     

          <p>Ithaca University Student and KIPP H.S. Graduate Christian supports the protests, but condemns the looters, echoing Booker T. Washington's philosophy that Eduaction, not violence, is the path to reform.</p>
          <figure>
    <img src="https://i.imgur.com/tjHNu1z.png">
    <figcaption>
        "I know it's easy to loot when you see others doing it, but please -- Rise above that. You gotta set a model, an example for others to follow" - Christian Brown
    </figcaption>
</figure>
        
        </article>
      </div>

    <!--   <div class="tile is-parent">
        <article class="tile is-child green post oneman">
          <a class="post__category" href="">United States</a>
          <h2 class="post__title">George Floyd Protests</h2>
          <div class="post__content">Relationship between Law Enforcement and Protestors have found Floyd as the catalyst for their (mutually-self assured) destruction. The protests have unified and equally divided a nation tore in anger. We await to see developments such as whether the largest cities around the nation implement a curfew in this distressing time. </div>
        </article>
      </div>-->
    </div>
  <div>

      <div>
        <article>
                <p><span>LIVE</span>
                  <span id="headlineTime"></span>
                </p>
              
   
          <h2><a href="http://barisciencelab.tech/Judaism.html">Ruthless Against Judaists</a></h2>
         <p>Jews have faced many a crisis. From the Israeli Palestinian Conflicts to the Holocaust, and from Adam and Eve to Jacob, we dive into the history of the religion that has stood strong in times of need. Exactly what has this religion faced, and where are its origins? Take a look at the history of how they've been mistreated and tyrannized, and the causes of which thousands of children and adults have been martyred. Let's look at a different perspective, and love all religions, even if they aren't ours. Get ready to put yourself in the shoes of the Jews. </p>
            
            <figure>
    <img src="https://haam.org/wp-content/uploads/2019/02/860373-efade7b2-1d47-11e4-8adb-938012f29f27.jpg">
    <figcaption>
        Jews have been persecuted by many religions, races, and empires for years. They were first maltreated by the Arabs, then the Brits, and finally the Germans. Take a look at the history of how they've been mistreated and tyrannized, and the causes of which thousands of children and adults have been martyred. </figcaption>
</figure>


        </article>
        
      </div>

      <div>
        <article>
           
          <h2><a href="http://barisciencelab.tech/Heinz.html">A Battle to Live: Life or Law?</a></h2>
          <p>Once upon a time, there was a man named Mr. Heinz. He was a poor man; he only made a thousand bucks a year. He saved up every single penny he could after a while, and that got him to 3,575 bucks a year. But on the fifth night of February 1977, Mr. Heinz faced a heart-wrenching dilemma: should he save his wife or break the law?</p>
        
        </article>
        
        
        <article>
           
          <h2><a href="http://barisciencelab.tech/06072020Interview.html" onmouseover="this.style.color='#ab0808'" onmouseout="this.style.color='#ff0000'">"Trump is a tragedy", Columbia Scientist</a></h2>
          <p>They've lived through some of the greatest moments in History: the moon landing, the birth of the UN, UNICEF, and WHO, and witnessed some of its worst -- the Holocaust, Nazi Germany, and COVID19, to name just a few. Indeed, what the von Gutfelds have lived through is little short of remarkable: the Holocaust, Hitler, and now COVID. </p>
        
        </article>
      </div>
    </div>
    
    

    <!-- FIRST ROW -->
   <!--
   <div class = "columns one">
       <div class = "column is-6">
           
            <article class="tile is-child tealish post fiveman">
          <a class="post__category" href="">America</a>
          <h2 class="post__title"><a href = "06132020Interview.html">"People are worth more than buildings", Columbia Graduate</a></h2>
          <div class="post__content">At a time of National Crisis, how do we grapple with our own responsibilities? This is the question I myself struggle to answer every day. But it doesn't have to be so: As Jordan Mahr of Columbia University exclaims, the socio-moral responsibilities of today are simply a consequence of our nation's high standing on Maslow's Hierarchy of Needs. It is because of this shared prestige and rare privilege that we are afforded the oppurtunity adress these difficult issues in the first place. </div>
                <figure class="imghvr-fade" style = "margin-top:-2vh; margin-left:2%;">
    <img src="JordanMahr.png" style = "width:110%">
    <figcaption>
        Jordan Mahr graduated from Columbia University in Theatre last year, in 2020. He was born in New Jersey and studied Drama and Performance with a Concentration in Acting at Columbia University and trained at the Royal Academy of Dramatic Art.  
    </figcaption>
</figure>
        </article>
        
         
       </div>
    
     <div class="tile is-vertical is-parent">
            <article class="tile is-child red post">
          <a class="post__category" href="">Politics</a>
          <h2 class="post__title"><a href = "06072020Interview.html" style = "color: red;" onMouseOver="this.style.color='#ab0808'"
   onMouseOut="this.style.color='#ff0000'">"Trump is a tragedy", Columbia Scientist</a></h2>
          <div class="post__content">They've lived through some of the greatest moments in History: the moon landing, the birth of the UN, UNICEF, and WHO, and witnessed some of its worst -- the Holocaust, Nazi Germany, and COVID19, to name just a few. Indeed, what the von Gutfelds have lived through is little short of remarkable: the Holocaust, Hitler, and now COVID. I can only look in awe as Columbia Adjunct Senior Research Scientist von Gutfeld laments at the state of American Leadership during a time of global crisis, giving a scalding rebuke of Trump and his reaction the Pandemic and Protests.</div>
                <figure class="imghvr-fade" style = "margin-top:-3vh; margin-left:2%;">
    <img src="https://i.imgur.com/r0WasA0.png" style = "width:110%"></a>
    <figcaption>
        They've lived through some of the greatest moments in History: the moon landing, the birth of the UN, UNICEF, and WHO, and witnessed some of its worst -- the Holocaust, Nazi Germany, and COVID19, to name just a few. 
    </figcaption>
</figure>
        </article>
           
     
      </div>
    </div>
    -->
    
    <div>
       <div>
              
      
            <article>
          
          
          <h2><a href="http://barisciencelab.tech/GestaltSwitch.html">What do you see?</a></h2>
          <p>Superposition is impossible. I want to be in London and New York at the same time, but I can't -- reality prohibits me. By extension, one can't get a head and tail from the same coin flip; nor can we have day and night simulatenously. With this law in mind, I want to ask you a question. It has no right answer, but it will demonstrate your thinking.</p>
                <center><figure>
    <img src="http://brainden.com/images/optical-illusions-big.gif">
    <figcaption>
        Do you see a young lady or an ugly old woman? If you see the young lady, look corefally at the ears -- they're the eyes of the old lady. If you look at the picture long enough, you should experience a 'Gestalt Switch'.
    </figcaption>
</figure></center>
        </article>
        
       </div>
       <div>
                <article>
         
         
          <h2><a href="http://barisciencelab.tech/Dowry.html">The Danger of Dowry</a></h2>
          <p>Dowry is like a social disease in some South Asian countries such as Bangladesh, Pakistan and India. Everyday women become victims because of dowry violence. Most of the groom's family demands dowry from the bride's family. </p>
          
        </article>
         <article>
          
          
          <h2><a href="http://barisciencelab.tech/TheOriginalRelativist.html">Galileo: The Original Relativist</a></h2>
          <p>The Catholic Church took 350 years to concede that Galileo was indeed right that the Copernican Model of the Solar System was correct. This was in 1992, when the Pope formally closed the 13-year investigation into the Church's condemnation of the reknowned Scientist. </p>
        </article>
           </div>
   </div>

    <!-- SECOND ROW -->
    <div>
      <div>
        <article>
          
          <h2><a href="http://barisciencelab.tech/AMileWideAnInchDeep.html">A Mile Wide and an Inch Deep Curriculum</a></h2>
          <p>America is known for excellence in education. No wonder, America won 385 out of 860 Nobel Prizes in which Harvard and Columbia together won 250 Prizes that is 29% of total Prize. However, there is a problem: K-12 Education is in crisis, which led to an educational revolution, of which Common Core is the outcome.</p>
                <figure>
    <img src="https://images.collegexpress.com/article/test-prep-tips-tricks-strategies-taking-SAT-ACT.jpg">
    <figcaption>
        The Common Core is an educational program launched by the National Governors Associatoin (NGA) and the Council of Chief State School Officers (CCSSO). It was established in 2010 in a hope to create a national, uniform cirriculum in Mathematics and Science.    </figcaption>
</figure>
        </article>
      </div>

      <div>
        <article>
          
          <h2><a href="http://barisciencelab.tech/06042020Interview.html" onmouseover="this.style.color='white'" onmouseout="this.style.color='white'">"It's all good", shouts Sikh</a></h2>
          <p>Mr. Ranbir, retired construction worker and evergreen optimist, hails from Punjab, India. "I love everybody", he says in broken English. "They say, 'we no like Muslims'. But no, I love everyone. Muslims, Hindu, Christian, everybody, everybody.".</p>
        </article>
        
        
        <article>
          <a href="">Science</a>
          <h2>The Story of SpaceX</h2>
          <p>Third time wasn't the charm for the now-nationally admired commercial space organization.</p>
        
        </article>
      </div>

      
    </div>

    <!-- THIRD ROW -->
    <div>
      <div>
        <div>
          <div>
            <article>
              <a href="">United States</a>
              <h2>A Nation in Distress</h2>
              <p>What does it take to break a nation? A democracy? The richest in the world? Now we know: a 7 mm virus and racism. These two make a dangerous combustion that mix the fire and fury of a nation tore down.</p>
          
            </article>
          </div>
          <div>
            <article>
              <a href="">India</a>
              <h2>The State of India</h2>
              <p>India is in a truly unique crisis: hunger has ravaged the poor, most of whom work in the informal economy. And the informal economy is more than 90% of India's economy, making the effects of unemployment all the more worse. </p>
            
            </article>
          </div>
          
          
          <div>
            <article>
              <a href="">Bangladesh</a>
              <h2>Hurricane Amphan Tears Bangladesh</h2>
              <p>She was at the height of her career when COVID19, Poverty, Hunger, Unemployment, and a killer Hurricane all struck at once. Will the eight largest nation in the world persevere as it did in 1974? Or will it fall to an untimely death?</p>
            
            </article>
          </div>
        </div>

        <div>
          <div>
            <article>
              <a href="">Women</a>
              <h2>A Mother's Worry</h2>
              <p>Lockdowns worldwide are still in-effect in many countries, and this has caused domestic abuse cases to shoot up. In addition, how can mothers and fathers alike educate their children during this time of remote learning?</p>
          
            </article>
          </div>
          <div>
            <article>
              <a href="">Science</a>
              <h2>The Galilean Man</h2>
              <p>For much of the 19th century, Galilean Transformations were the way to go to identify observers, events, and movements across space-time. Let's try to understand the theory behind it all.</p>
            
            </article>
          </div>
        </div>
      </div>

      <div>
        <article>
          <a href="">Pakistan</a>
          <h2>A Crash in Pakistan</h2>
          <p>The plane was traveling from Lahore to Karachi, when it crashed, killing 97 of 99 people aboard. 2 survivors recount their horror stories in their memorable encounter with death. COVID19 has uniquely affected the aviation industry, and although this is mere speculation -- the crash in Pakistan is most likely to exacerbate the problems. </p>
            <figure>
    <img src="https://gumlet.assettype.com/nationalherald%2F2020-05%2Fe05d32e5-62c5-4455-b04d-fcf24b0d955f%2Fpak_plane.jpg?rect=0%2C0%2C720%2C405&amp;auto=format%2Ccompress&amp;format=webp&amp;w=750&amp;dpr=1.0">
    <figcaption>
        The plane was heading from Lahore to Karachi, and crashed killing 97 of the 99 people aboard, including children.
    </figcaption>
</figure>
          
                      <figure>
    <img src="https://specials-images.forbesimg.com/imageserve/1196884876/960x0.jpg?fit=scale">
    <figcaption>
        In Pakistan, planes don't have to undergo background checks prior to flying, which may be one of the many factors contributing to the crash of the flight.
    </figcaption>
</figure>
        </article>
      </div>
    </div>

  </div>
  <!-- /container -->
</section>
<!--      
<div class="fancy-hr"><hr></div>

<center><p class="title is-3" width = "">From the Editor-In-Chief</p></center>
      
<center>      
<div class="fancy-hr"><hr></div>

 <div class="container" style = "width:50vw; height: 55vh;">
	<div id="player" data-plyr-provider="youtube" data-plyr-embed-id="-9lQ_CbCetw"></div>
</div>
          </center>-->


<center><p>Good News</p></center>
      
      

      <section>
  <div>
    <p>
      
      <h2>
        SpaceX Dragon succesfully 'soft-docked' with the ISS 
      </h2>
    </p>
    <br>
  </div>
  
</section>
      
      
      <section>
 
  

</section>

<div>
    <p>
      Brooklyn and Manhattan have been the center of most of the protests occuring in New York City. Queens has also recently erupted in protests driven by the death of George Floyd. Protests have recently escalated even further, reaching into violent territory: police have literally driven cars into protestors; protestors have lit police cars on fire, in return, and the whole city seems to be descending into the stages of preliminary stages of anarchy.
      </p>
    
    
</div>

            
      
      
        <section>
    <div>
      <div>
        <div>
          <div>
            <div>
              <figure>
                <img src="https://static01.nyt.com/newsgraphics/2020/05/29/floyd-protests-map/assets/images/ny-brooklyn-0530-1440.jpg" alt="a random image">
              </figure>
            </div>
            <div>
              <p>A Microcosm of the Future</p>
              <p>Are the riots, looting, and protests of America Today a sign of America from the future? But things have only been getting started. A problem much larger than COVID19 is emerging, and that is Global Warming. It is so existential that we have a hard time thinking about it, and thus acting on that fear. It is essential that we understand the present, should we hope to …</p></div></div></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://barisciencelab.tech/TheThinker.html">http://barisciencelab.tech/TheThinker.html</a></em></p>]]>
            </description>
            <link>http://barisciencelab.tech/TheThinker.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741488</guid>
            <pubDate>Sun, 05 Jul 2020 20:05:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The key points of Software Design X-Rays]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23741261">thread link</a>) | @nicoespeon
<br/>
July 5, 2020 | https://understandlegacycode.com/blog/key-points-of-software-design-x-rays/ | <a href="https://web.archive.org/web/*/https://understandlegacycode.com/blog/key-points-of-software-design-x-rays/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>How do you analyze a very large Legacy codebase?</p><p>Where do you start when your system is distributed across dozens of micro-services?</p><p>How do you identify development bottlenecks and prioritize refactoring?</p><p>In his book <!-- -->[Software Design X-Rays]<!-- -->(<a href="https://www.google.com/search?q=software+design+x-rays&amp;oq=soft">https://www.google.com/search?q=software+design+x-rays&amp;oq=soft</a>, Adam Tornhill presents a very unique approach to answer these questions. It’s a mix of software architecture and human psychology that generates powerful techniques to tackle large codebases.</p><p>Yet, I realized it’s not a very known book.</p><blockquote><p>I’ve read <a href="https://www.google.com/search?q=your+code+as+a+crime+scene">Your Code as a Crime Scene</a> from the same guy. How is this different?</p></blockquote><p>Well, “Software Design X-Rays” was written after “Your Code as a Crime Scene”. While the forensics flavor of the book was fun and all, Adam stopped referring it too much to avoid getting the reader distracted. The content is much more polished!</p><p>Let me give you my summary of what’s inside the book and why I think it can help you:</p><h2 id="tackle-technical-debt-with-behavioral-code-analysis"><a href="#tackle-technical-debt-with-behavioral-code-analysis" aria-label="tackle technical debt with behavioral code analysis permalink"></a>Tackle Technical Debt with Behavioral Code Analysis</h2><p>The book focuses on giving you the answers to these 3 questions:</p><ol><li>Where’s the code with the higher interest rate?</li><li>Does your architecture support the way your system evolves?</li><li>Are there any productivity bottlenecks for inter-team coordination?</li></ol><p>To do so, Adam presents a technique called <strong>Behavioral Code Analysis</strong>. It uses the information contained in your Version Control System (VCS) to help you make smart decisions on large codebases.</p><h3 id="identify-your-system-hotspots"><a href="#identify-your-system-hotspots" aria-label="identify your system hotspots permalink"></a>Identify your system Hotspots</h3><p>Technical Debt isn’t really a problem if you don’t have to maintain it.</p><p>Static analysis tools consider all debt to be equivalent. They report countless of code smells that you have no choice but to focus on the critical ones. Still, that leaves plenty of things to clean up!</p><p>That’s why you should use the time dimension to identify <strong>Hotspots</strong>: places where you should focus the Refactor efforts in a large codebase if you want to be super effective.</p><p><undefined>
  <a href="https://understandlegacycode.com/static/019e5f99d9ed31fd581770a1835f8ba1/4cf67/hotspots.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="hotspots" title="" src="https://understandlegacycode.com/static/019e5f99d9ed31fd581770a1835f8ba1/4cf67/hotspots.png" srcset="https://understandlegacycode.com/static/019e5f99d9ed31fd581770a1835f8ba1/00d96/hotspots.png 148w,https://understandlegacycode.com/static/019e5f99d9ed31fd581770a1835f8ba1/0b23c/hotspots.png 295w,https://understandlegacycode.com/static/019e5f99d9ed31fd581770a1835f8ba1/4cf67/hotspots.png 572w" sizes="(max-width: 572px) 100vw, 572px">
    </span>
  </span>
  
  </a>
    </undefined></p><p><undefined>
  <a href="https://understandlegacycode.com/static/00cdf44baa120d7c01e6f6c9536df456/11d19/code-that-matters.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="code that matters" title="" src="https://understandlegacycode.com/static/00cdf44baa120d7c01e6f6c9536df456/799d3/code-that-matters.png" srcset="https://understandlegacycode.com/static/00cdf44baa120d7c01e6f6c9536df456/00d96/code-that-matters.png 148w,https://understandlegacycode.com/static/00cdf44baa120d7c01e6f6c9536df456/0b23c/code-that-matters.png 295w,https://understandlegacycode.com/static/00cdf44baa120d7c01e6f6c9536df456/799d3/code-that-matters.png 590w,https://understandlegacycode.com/static/00cdf44baa120d7c01e6f6c9536df456/11d19/code-that-matters.png 800w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>If you want to learn how to generate and use these, I presented the technique in details:</p><ul><li><a href="https://understandlegacycode.com/blog/focus-refactoring-with-hotspots-analysis">Focus refactoring on what matters with Hotspots Analysis</a></li><li><a href="https://understandlegacycode.com/blog/convince-management-to-address-tech-debt-with-enclosure-diagrams">Convince managers to address Tech Debt with Enclosure Diagrams</a></li></ul><p>Interestingly, hotspots tend to stay here because people are afraid to tackle them. So they attract even more complexity and become problematic bottlenecks.</p><h3 id="loc-a-simple-and-efficient-indicator-of-code-complexity"><a href="#loc-a-simple-and-efficient-indicator-of-code-complexity" aria-label="loc a simple and efficient indicator of code complexity permalink"></a>LOC: a simple and efficient indicator of code complexity</h3><p>When it comes to evaluating the complexity of the code, many metrics compete. The most popular is probably Cyclomatic Complexity. Yet, it’s fascinating to see that the count of Lines Of Code (LOC) is often a <em>good enough</em> indicator!</p><p>As it’s a language-neutral metric, it’s very easy to generate regardless of your language tooling. You can use <a href="http://cloc.sourceforge.net/">cloc</a> for that:</p><pre data-language="bash" data-index="0"><p><code><span><span>cloc </span><span>.</span><span> --csv --quiet --report-file=your_project.csv</span></span></code></p></pre><p>Another language-neutral metric that works well is the <strong>Indentation Level</strong>. Indentation carries the meaning of logical splits. That’s a good indicator that code is complex.</p><p>The limit of using these is when you have a change in the coding style in the history of the project. But because these metrics are simple, it makes no sense to look at specific values and thresholds. <strong>It’s the trend that matters</strong>. That’s usually enough.</p><h3 id="evaluate-hotspots-with-complexity-trends"><a href="#evaluate-hotspots-with-complexity-trends" aria-label="evaluate hotspots with complexity trends permalink"></a>Evaluate Hotspots with Complexity Trends</h3><p>If you analyze the evolution of complexity of a file over time, you get the story of that file:</p><p><undefined>
  <a href="https://understandlegacycode.com/static/cb402f296f7492bb21a7edeee345b91e/48606/complexity-trend.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="complexity trend" title="" src="https://understandlegacycode.com/static/cb402f296f7492bb21a7edeee345b91e/799d3/complexity-trend.png" srcset="https://understandlegacycode.com/static/cb402f296f7492bb21a7edeee345b91e/00d96/complexity-trend.png 148w,https://understandlegacycode.com/static/cb402f296f7492bb21a7edeee345b91e/0b23c/complexity-trend.png 295w,https://understandlegacycode.com/static/cb402f296f7492bb21a7edeee345b91e/799d3/complexity-trend.png 590w,https://understandlegacycode.com/static/cb402f296f7492bb21a7edeee345b91e/48606/complexity-trend.png 701w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>That’s helpful to show the impact of refactoring to non-technical managers. That helps them visually see the effects of such work, and the results on team productivity.</p><h3 id="perform-x-rays-analysis-to-narrow-even-deeper"><a href="#perform-x-rays-analysis-to-narrow-even-deeper" aria-label="perform x rays analysis to narrow even deeper permalink"></a>Perform X-Rays analysis to narrow even deeper</h3><p>Once you identified Hotspots, you can apply the same logic at the file level to find the complex functions:</p><p><undefined>
  <a href="https://understandlegacycode.com/static/2e63aa78e40f6496f17d737b9ead73c8/11d19/x-ray.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="x ray" title="" src="https://understandlegacycode.com/static/2e63aa78e40f6496f17d737b9ead73c8/799d3/x-ray.png" srcset="https://understandlegacycode.com/static/2e63aa78e40f6496f17d737b9ead73c8/00d96/x-ray.png 148w,https://understandlegacycode.com/static/2e63aa78e40f6496f17d737b9ead73c8/0b23c/x-ray.png 295w,https://understandlegacycode.com/static/2e63aa78e40f6496f17d737b9ead73c8/799d3/x-ray.png 590w,https://understandlegacycode.com/static/2e63aa78e40f6496f17d737b9ead73c8/11d19/x-ray.png 800w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>This is what Adam calls “X-Ray analysis”. Here’s the rough recipe:</p><ol><li>Fetch the source code of the file for each revision from Git</li><li>Run a <code>git diff</code> for every revision to list the modifications</li><li>Match the <code>diff</code> results to the functions that existed in this version (parsing the code is necessary here)</li><li>Perform a Hotspot calculation for the functions<ul><li>Change Frequency = times a function was changed</li><li>Complexity = length or indentation level of the function</li><li>Combine them to calculate the score</li></ul></li></ol><p><undefined>
  <a href="https://understandlegacycode.com/static/2dd2ea002e1ba78bc3e7234740b86379/e7347/x-ray-results.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="x ray results" title="" src="https://understandlegacycode.com/static/2dd2ea002e1ba78bc3e7234740b86379/799d3/x-ray-results.png" srcset="https://understandlegacycode.com/static/2dd2ea002e1ba78bc3e7234740b86379/00d96/x-ray-results.png 148w,https://understandlegacycode.com/static/2dd2ea002e1ba78bc3e7234740b86379/0b23c/x-ray-results.png 295w,https://understandlegacycode.com/static/2dd2ea002e1ba78bc3e7234740b86379/799d3/x-ray-results.png 590w,https://understandlegacycode.com/static/2dd2ea002e1ba78bc3e7234740b86379/e7347/x-ray-results.png 849w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>With the Hotspot + X-Ray techniques, you can take a 400kLOC codebase and focus on the few hundred lines of code that will have the most impact if they are refactored.</p><p>It’s good to know you can perform a cheap X-Ray with git log, using the <code>-L</code> option:</p><pre data-language="bash" data-index="1"><p><code><span><span>git log -L:intel_crtc_page_flip:drivers/gpu/drm/i915/intel_display.c</span></span></code></p></pre><h2 id="coupling-in-time-where-surprises-happen"><a href="#coupling-in-time-where-surprises-happen" aria-label="coupling in time where surprises happen permalink"></a>Coupling in Time: where surprises happen</h2><p>You generally forget about the time dimension when you analyze the code to evaluate its design. That’s a mistake! <strong>Change Coupling</strong> is when files change together over time.</p><p><undefined>
  <a href="https://understandlegacycode.com/static/772eb927f6f8cbe7cc9a4f933ac7d6fd/3af27/change-coupling.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="change coupling" title="" src="https://understandlegacycode.com/static/772eb927f6f8cbe7cc9a4f933ac7d6fd/3af27/change-coupling.png" srcset="https://understandlegacycode.com/static/772eb927f6f8cbe7cc9a4f933ac7d6fd/00d96/change-coupling.png 148w,https://understandlegacycode.com/static/772eb927f6f8cbe7cc9a4f933ac7d6fd/0b23c/change-coupling.png 295w,https://understandlegacycode.com/static/772eb927f6f8cbe7cc9a4f933ac7d6fd/3af27/change-coupling.png 545w" sizes="(max-width: 545px) 100vw, 545px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>2 files might change together accidentally. But if they changed together in many commits, with a high degree of coupling, then there’s a high chance these 2 files are coupled!</p><p>This allows you to identify things that empirically belong together. If these files are not co-located, then there might be a problem with the current design. Maybe there’s a bad abstraction or maybe there’s copy-pasted code that keeps evolving together.</p><p>Expected coupling:</p><ul><li>highly-cohesive files (same module)</li><li>code &amp; tests</li></ul><p>Unexpected coupling:</p><ul><li>low-cohesive files (different modules)</li><li>surprising relationships</li></ul><p>Since you’re using git metadata to determine these coupling, it’s <strong>language agnostic</strong>. Therefore, you can detect coupling across stacks, like between front-end and back-end.</p><p>A limit of this technique is the commit patterns developers use. If a developer always commits tests and code independently, you can adapt the technique and consider commits from the same author in a 24h sliding window as “coupled together”. Usually, that’s good enough.</p><h3 id="identify-actual-code-duplication"><a href="#identify-actual-code-duplication" aria-label="identify actual code duplication permalink"></a>Identify actual code duplication</h3><p>Copy-paste is not bad in itself.</p><p>It’s only bad if you need to keep changing all occurrences together. Hence, if you integrate a metric of <em>Similarity</em> in your Change Coupling analysis, you can detect problematic copy-paste:</p><p><undefined>
  <a href="https://understandlegacycode.com/static/33313f1bcd8d42c2f66ef8fd55ac3875/388a9/change-coupling-copy-paste.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="change coupling copy paste" title="" src="https://understandlegacycode.com/static/33313f1bcd8d42c2f66ef8fd55ac3875/799d3/change-coupling-copy-paste.png" srcset="https://understandlegacycode.com/static/33313f1bcd8d42c2f66ef8fd55ac3875/00d96/change-coupling-copy-paste.png 148w,https://understandlegacycode.com/static/33313f1bcd8d42c2f66ef8fd55ac3875/0b23c/change-coupling-copy-paste.png 295w,https://understandlegacycode.com/static/33313f1bcd8d42c2f66ef8fd55ac3875/799d3/change-coupling-copy-paste.png 590w,https://understandlegacycode.com/static/33313f1bcd8d42c2f66ef8fd55ac3875/388a9/change-coupling-copy-paste.png 681w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>Fixing code duplication is often a quick win. It helps getting started in refactoring a Hotspot.</p><p>As a rule of thumb: <strong>things that are coupled should be co-located</strong>.</p><h2 id="the-principles-of-code-age"><a href="#the-principles-of-code-age" aria-label="the principles of code age permalink"></a>The Principles of Code Age</h2><p>Code is only desirable in 2 states:</p><ol><li>Very recent, because it’s fresh in your mind</li><li>Very old, because it means it has stabilized</li></ol><p>When you meet a very old code, you can encapsulate that into a library and extract it from your codebase. That’s less code to deal with, which is good for developers and onboarding!</p><p><strong>Old code usually has no bugs.</strong></p><p>A code that doesn’t stabilize is problematic. It usually means you need to patch it. Because you don’t know it very well, there’s a high chance of creating bugs by ignorance. By creating more bugs, you need to update the code again: it doesn’t stabilize.</p><h3 id="calculate-the-age-of-code"><a href="#calculate-the-age-of-code" aria-label="calculate the age of code permalink"></a>Calculate the age of code</h3><p>The algorithm is simple:</p><ol><li>List modified files with <code>git ls-files</code></li><li>Get the last modification date for each file with <code>git log -l --format="%ad" --date=short -- path/to/file</code></li><li>Calculate the age of the file</li></ol><p>If the codebase was not maintained for some time, consider the youngest one to be 0.</p><h3 id="refactor-towards-code-of-similar-age"><a href="#refactor-towards-code-of-similar-age" aria-label="refactor towards code of similar age permalink"></a>Refactor towards code of similar age</h3><p>Within the same packages, you can identify the code of different ages (very old AND very recent). Try to understand why some code fails to stabilize.</p><p>Maybe you’ll be able to extract parts of it that would actually stabilize.</p><p>Maybe you’ll identify different concepts that are mixed. So you can refactor the structure of the code:</p><p><undefined>
  <a href="https://understandlegacycode.com/static/54ecf644a3270956bb2619a3ed374ec2/fed2b/architecture.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="architecture" title="" src="https://understandlegacycode.com/static/54ecf644a3270956bb2619a3ed374ec2/fed2b/architecture.png" srcset="https://understandlegacycode.com/static/54ecf644a3270956bb2619a3ed374ec2/00d96/architecture.png 148w,https://understandlegacycode.com/static/54ecf644a3270956bb2619a3ed374ec2/0b23c/architecture.png 295w,https://understandlegacycode.com/static/54ecf644a3270956bb2619a3ed374ec2/fed2b/architecture.png 564w" sizes="(max-width: 564px) 100vw, 564px">
    </span>
  </span>
  
  </a>
    </undefined></p><h2 id="beyond-conways-law"><a href="#beyond-conways-law" aria-label="beyond conways law permalink"></a>Beyond Conway’s Law</h2><h3 id="development-congestion"><a href="#development-congestion" aria-label="development congestion permalink"></a>Development Congestion</h3><p>When you put too many developers on the same code, it’s hard to keep productive. That’s because the code constantly changes: the code you wrote three days ago is now different, so you have to constantly re-discover what it does. The risk of bug is high.</p><p>This is <em>Development Congestion</em>.</p><p>That’s why if you put more people on a late project, the project will be even later.</p><p>Code reviews and automated tests can mitigate the risk of bugs.</p><h3 id="the-problem-of-having-too-many-contributors"><a href="#the-problem-of-having-too-many-contributors" aria-label="the problem of having too many contributors permalink"></a>The problem of having too many contributors</h3><p><strong>Many minor contributors you have in the last 3 months = higher chances to have bugs</strong>.</p><p>That’s because contributors don’t have the full context of what they change.</p><p>With many contributors, <em>diffusion of responsibility</em> makes the codebase rot because each developer thinks someone else will take care of refactoring.</p><p>Also, many contributors lead to <em>process loss</em> (waste) due to communication overhead.</p><p>Thus, you need to introduce <strong>areas of responsibility</strong> to give teams full ownership. Other teams may contribute through PRs, but one team should own their part, be involved in reviews, and have the final word.</p><p>Finally, <strong>teams should have a broader knowledge boundary (what they know) than their operational boundary (what they change)</strong>. You can make that happen with:</p><ul><li>Teams demoing what they’re working on</li><li>Inter-teams code reviews to spread knowledge</li><li>Make people move between teams</li></ul><h3 id="calculating-the-diffusion-score"><a href="#calculating-the-diffusion-score" aria-label="calculating the diffusion score permalink"></a>Calculating the Diffusion score</h3><p>You can count the number of developers on a specific part of the code from git:</p><pre data-language="bash" data-index="2"><p><code><span><span>git shortlog -s --after=2020-01-12 -- some/module/path | wc -l</span></span></code></p></pre><p>If you analyze the distribution of contributions on a part of the code, you get a <em>Diffusion</em> score:</p><p><undefined>
  <a href="https://understandlegacycode.com/static/02bdece8d042cd9e25d429bfdb5b2c9e/4ba4a/diffusion-formula.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="diffusion formula" title="" src="https://understandlegacycode.com/static/02bdece8d042cd9e25d429bfdb5b2c9e/4ba4a/diffusion-formula.png" srcset="https://understandlegacycode.com/static/02bdece8d042cd9e25d429bfdb5b2c9e/00d96/diffusion-formula.png 148w,https://understandlegacycode.com/static/02bdece8d042cd9e25d429bfdb5b2c9e/0b23c/diffusion-formula.png 295w,https://understandlegacycode.com/static/02bdece8d042cd9e25d429bfdb5b2c9e/4ba4a/diffusion-formula.png 497w" sizes="(max-width: 497px) 100vw, 497px">
    </span>
  </span>
  
  </a>
    </undefined>
<undefined>
  <a href="https://understandlegacycode.com/static/cbb6e1f1ec465eacf6ddc572c3787682/b3297/diffusion-results.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="diffusion results" title="" src="https://understandlegacycode.com/static/cbb6e1f1ec465eacf6ddc572c3787682/b3297/diffusion-results.png" srcset="https://understandlegacycode.com/static/cbb6e1f1ec465eacf6ddc572c3787682/00d96/diffusion-results.png 148w,https://understandlegacycode.com/static/cbb6e1f1ec465eacf6ddc572c3787682/0b23c/diffusion-results.png 295w,https://understandlegacycode.com/static/cbb6e1f1ec465eacf6ddc572c3787682/b3297/diffusion-results.png 474w" sizes="(max-width: 474px) 100vw, 474px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>You can generate an enclosure diagram to identify bottlenecks in your large codebase:</p><p><undefined>
  <a href="https://understandlegacycode.com/static/9552981d4e14928c6b9520a0f25fee0c/c5652/diffusion-diagram.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="diffusion diagram" title="" src="https://understandlegacycode.com/static/9552981d4e14928c6b9520a0f25fee0c/c5652/diffusion-diagram.png" srcset="https://understandlegacycode.com/static/9552981d4e14928c6b9520a0f25fee0c/00d96/diffusion-diagram.png 148w,https://understandlegacycode.com/static/9552981d4e14928c6b9520a0f25fee0c/0b23c/diffusion-diagram.png 295w,https://understandlegacycode.com/static/9552981d4e14928c6b9520a0f25fee0c/c5652/diffusion-diagram.png 466w" sizes="(max-width: 466px) 100vw, 466px">
    </span>
  </span>
  
  </a>
    </undefined></p><h3 id="keep-a-decision-log"><a href="#keep-a-decision-log" aria-label="keep a decision log permalink"></a>Keep a decision log</h3><p><a href="https://understandlegacycode.com/blog/earn-maintainers-esteem-with-adrs">Architecture Decision Record (ADR)</a> are very useful to simply keep track of architectural decisions in the project.</p><p>They help people understand why and how decisions were taken in the past. This is useful to re-evaluate them later in the project, as well as spreading knowledge.</p><h3 id="a-few-management-pitfalls"><a href="#a-few-management-pitfalls" aria-label="a few management pitfalls permalink"></a>A few management pitfalls</h3><p>Adam gives a few pieces of advice to managers, referring to human psychology. Whether you’re a Tech Lead or a non-technical manager, these are gold.</p><p>First, you should never …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://understandlegacycode.com/blog/key-points-of-software-design-x-rays/">https://understandlegacycode.com/blog/key-points-of-software-design-x-rays/</a></em></p>]]>
            </description>
            <link>https://understandlegacycode.com/blog/key-points-of-software-design-x-rays/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741261</guid>
            <pubDate>Sun, 05 Jul 2020 19:37:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[‘Collapse of civilisation is the most likely outcome’: top climate scientists]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 35 (<a href="https://news.ycombinator.com/item?id=23741179">thread link</a>) | @1qazxsw23edc
<br/>
July 5, 2020 | https://voiceofaction.org/collapse-of-civilisation-is-the-most-likely-outcome-top-climate-scientists/ | <a href="https://web.archive.org/web/*/https://voiceofaction.org/collapse-of-civilisation-is-the-most-likely-outcome-top-climate-scientists/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
<p>Australia’s top climate scientist says “we are already deep into the trajectory towards collapse” of civilisation, which may now be inevitable because 9 of the 15 known global climate tipping points that regulate the state of the planet have been activated.</p>



<p>Australian National University emeritus professor Will Steffen (pictured) told <em>Voice of Action</em> that there was already a chance we have triggered a “global tipping cascade” that would take us to a less habitable “Hothouse Earth” climate, regardless of whether we reduced emissions.</p>



<p>Steffen says it would take 30 years at best (more likely 40-60 years) to transition to net zero emissions, but when it comes to tipping points such as Arctic sea ice we could have already run out of time. </p>



<p>Evidence shows we will also lose control of the tipping points for the <a rel="noreferrer noopener" href="https://www.theguardian.com/world/2019/jul/25/amazonian-rainforest-near-unrecoverable-tipping-point?CMP=share_btn_tw" data-type="https://www.theguardian.com/world/2019/jul/25/amazonian-rainforest-near-unrecoverable-tipping-point?CMP=share_btn_tw" target="_blank">Amazon rainforest</a>, the West Antarctic ice sheet, and the Greenland ice sheet in much less time than it’s going to take us to get to net zero emissions, Steffen says.</p>



<p>“Given the momentum in both the Earth and human systems, and the growing difference between the ‘reaction time’ needed to steer humanity towards a more sustainable future, and the ‘intervention time’ left to avert a range of catastrophes in both the physical climate system (e.g., melting of Arctic sea ice) and the biosphere (e.g., loss of the Great Barrier Reef), we are already deep into the trajectory towards collapse,” said Steffen.</p>



<p>“That is, the intervention time we have left has, in many cases, shrunk to levels that are shorter than the time it would take to transition to a more sustainable system.</p>



<p>“The fact that many of the features of the Earth System that are being damaged or lost constitute ‘tipping points’ that could well link to form a ‘tipping cascade’ raises the ultimate question: Have we already lost control of the system? Is collapse now inevitable?”</p>



<p>This is not a unique view – leading Stanford University biologists, who were first to reveal that we are already experiencing the sixth mass extinction on Earth, released <a href="https://www.theguardian.com/environment/2020/jun/01/sixth-mass-extinction-of-wildlife-accelerating-scientists-warn" data-type="https://www.theguardian.com/environment/2020/jun/01/sixth-mass-extinction-of-wildlife-accelerating-scientists-warn" target="_blank" rel="noreferrer noopener">new research this week</a> showing species extinctions are accelerating in an unprecedented manner, which may be a tipping point for the collapse of human civilisation.</p>



<p>Also in the past week <a rel="noreferrer noopener" href="https://www.smh.com.au/environment/climate-change/australia-among-global-hot-spots-as-droughts-worsen-in-warming-world-20200601-p54ydh.html?btis" data-type="https://www.smh.com.au/environment/climate-change/australia-among-global-hot-spots-as-droughts-worsen-in-warming-world-20200601-p54ydh.html?btis" target="_blank">research emerged</a> showing the world’s major food baskets will experience more extreme droughts than previously forecast, with southern Australia among the worst hit globally.</p>



<p>Steffen used the metaphor of the Titanic in one of his recent talks to describe how we may cross tipping points faster than the time it would take us to react to get our impact on the climate under control.</p>



<p>“If the Titanic realises that it’s in trouble and it has about 5km that it needs to slow and steer the ship, but it’s only 3km away from the iceberg, it’s already doomed,” he said.</p>



<h3>‘This is an existential threat to civilization’</h3>



<p>Steffen, along with some of the world’s most eminent climate scientists, laid out our predicament in the starkest possible terms in a <a href="https://www.nature.com/articles/d41586-019-03595-0" data-type="https://www.nature.com/articles/d41586-019-03595-0" target="_blank" rel="noreferrer noopener">piece for the journal Nature</a> at the end of last year.</p>



<p>They found that 9 of the 15 known Earth tipping elements that regulate the state of the planet had been activated, and there was now scientific support for declaring a state of planetary emergency. These tipping points can trigger abrupt carbon release back into the atmosphere, such as the release of carbon dioxide and methane caused by the irreversible thawing of the Arctic permafrost.</p>



<figure><img src="https://voiceofaction.org/wp-content/uploads/2020/06/tipping-points-climate-change-nature-comment-1.jpg" alt="" srcset="https://voiceofaction.org/wp-content/uploads/2020/06/tipping-points-climate-change-nature-comment-1.jpg 907w, https://voiceofaction.org/wp-content/uploads/2020/06/tipping-points-climate-change-nature-comment-1-300x209.jpg 300w, https://voiceofaction.org/wp-content/uploads/2020/06/tipping-points-climate-change-nature-comment-1-768x536.jpg 768w, https://voiceofaction.org/wp-content/uploads/2020/06/tipping-points-climate-change-nature-comment-1-143x100.jpg 143w, https://voiceofaction.org/wp-content/uploads/2020/06/tipping-points-climate-change-nature-comment-1-500x349.jpg 500w, https://voiceofaction.org/wp-content/uploads/2020/06/tipping-points-climate-change-nature-comment-1-690x482.jpg 690w" sizes="(max-width: 907px) 100vw, 907px"><figcaption>9 of 15 known Earth tipping points have been activated</figcaption></figure>



<p>“If damaging tipping cascades can occur and a global tipping point cannot be ruled out, then this is an existential threat to civilization,” they wrote.</p>



<p>“No amount of economic cost–benefit analysis is going to help us. We need to change our approach to the climate problem.</p>



<p>“The evidence from tipping points alone suggests that we are in a state of planetary emergency: both the risk and urgency of the situation are acute.”</p>



<p>Steffen is also the lead author of the heavily cited 2018 paper, <a rel="noreferrer noopener" href="https://www.pnas.org/content/115/33/8252" data-type="https://www.pnas.org/content/115/33/8252" target="_blank">Trajectories of the Earth System in the Anthropocene</a>, where he found that “even if the Paris Accord target of a 1.5°C to 2°C rise in temperature is met, we cannot exclude the risk that a cascade of feedbacks could push the Earth System irreversibly onto a ‘Hothouse Earth’ pathway.”</p>



<p>Steffen is a global authority on the subject of tipping points, which are prone to sudden shifts if they get pushed hard enough by a changing climate, and could take the trajectory of the system out of human control. Further warming would become self-sustaining due to system feedbacks and their mutual interaction.</p>



<p>Steffen describes it like a row of dominos and his concern is we are already at the point of no return, knocking over the first couple of dominos which could lead to a cascade knocking over the whole row.</p>



<p>“Some of these we think are vulnerable in the temperature range we’re entering into now,” said Steffen.</p>



<p>“If we get those starting to tip we could get the whole row of dominos tipping and take us to a much hotter climate even if we get our emissions down.”</p>



<p>Even the notoriously conservative United Nations Intergovernmental Panel on Climate Change (IPCC) has found that already with the 1.1°C of warming we have had to date, there was a moderate risk of tipping some of these – and the risk increased as the temperatures increased.</p>



<p>Steffen believes we are committed to at least a 1.5°C temperature rise given the momentum in the economic and climate system, but we still have a shot at staying under 2°C with urgent action.</p>



<h3>+4°C world would support &lt; 1 billion people</h3>



<p>Professor Hans Joachim Schellnhuber, director emeritus and founder of the Potsdam Institute for Climate Impact Research, believes if we go much above 2°C we will quickly get to 4°C anyway because of the tipping points and feedbacks, which would spell the end of human civilisation.</p>



<figure><img src="https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k-1024x680.jpg" alt="" srcset="https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k-1024x680.jpg 1024w, https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k-300x199.jpg 300w, https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k-768x510.jpg 768w, https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k-1536x1020.jpg 1536w, https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k-151x100.jpg 151w, https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k-500x332.jpg 500w, https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k-690x458.jpg 690w, https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k.jpg 2048w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>“There is a very big risk that we will just end our civilisation”: Professor Schellnhuber</figcaption></figure>



<p>Johan Rockström, the head of one of Europe’s leading research institutes, warned in 2019 that in a 4°C-warmer world it would be “difficult to see how we could accommodate a billion people or even half of that … There will be a rich minority of people who survive with modern lifestyles, no doubt, but it will be a turbulent, conflict-ridden world”.</p>



<p>Schellnhuber, one of the world’s leading authorities on climate change, said that if we continue down the present path “there is a very big risk that we will just end our civilisation. The human species will survive somehow but we will destroy almost everything we have built up over the last two thousand years.”</p>



<p>Schellnhuber said in a <a rel="noreferrer noopener" href="https://youtu.be/4PTRTwn3wrg" data-type="https://youtu.be/4PTRTwn3wrg" target="_blank">recent interview</a> that the IPCC report stating we could stay below 1.5°C of warming was “slightly dishonest” because it relies on immense negative emissions (pulling CO2 out of the air) which was not viable at global scale. He said 1.5°C was no longer achievable but it was still possible to stay under 2°C with massive changes to society.</p>



<p>If we don’t bend the emissions curve down substantially before 2030 then keeping temperatures under 2°C becomes unavoidable. The “carbon law” <a rel="noreferrer noopener" href="https://science.sciencemag.org/content/355/6331/1269" data-type="https://science.sciencemag.org/content/355/6331/1269" target="_blank">published in the journal Science</a> in 2017 found that, to hold warming below 2°C, emissions would need to be cut in half between 2020 and 2030.</p>



<p>Steffen told <em>Voice of Action</em> that the three main challenges to humanity – climate change, the degradation of the biosphere and the growing inequalities between and among countries – were “just different facets of the same fundamental problem”.</p>



<p>This problem was the “neoliberal economic system” that spread across the world through globalisation, underpinning “high production high consumption lifestyles” and a “religion built not around eternal life but around eternal growth”.</p>



<p>“It is becoming abundantly clear that (i) this system is incompatible with a well-functioning Earth System at the planetary level; (ii) this system is eroding human- and societal-well being, even in the wealthiest countries, and (iii) collapse is the most likely outcome of the present trajectory of the current system, as prophetically modelled in 1972 in the Limits to Growth work,” Steffen told <em>Voice of Action</em>.</p>



<h3>Eternal growth is not possible</h3>



<p>The <a href="https://www.clubofrome.org/report/the-limits-to-growth/" data-type="https://www.clubofrome.org/report/the-limits-to-growth/" target="_blank" rel="noreferrer noopener">Limits to Growth model</a> released by the Club of Rome in 1972 looked at the interplay between food production, industry, population, non-renewable resources and pollution.</p>



<p>The basic findings were that you can’t grow the system indefinitely as you will cause environmental and resource issues that will ultimately cause the whole global system to collapse (ABC’s This Day Tonight program covered it <a rel="noreferrer noopener" href="https://www.youtube.com/watch?v=cCxPOqwCr1I" data-type="https://www.youtube.com/watch?v=cCxPOqwCr1I" target="_blank">here</a>). At the time of the model’s release it accurately reproduced the historical data from 1900 to 1970.</p>



<p>A <a rel="noreferrer noopener" href="https://www.sciencedirect.com/science/article/abs/pii/S0959378008000435" data-type="https://www.sciencedirect.com/science/article/abs/pii/S0959378008000435" target="_blank">2008 study</a> by Graham Turner, then a senior CSIRO research scientist, used three decades of real-world historical data to conclude that the Limits to Growth model’s predictions were coming to pass: “30 years of historical data compare favourably with key features of a business-as-usual [BAU] scenario called the ‘standard run’ scenario, which results in collapse of the global system midway through the 21st century.”</p>



<figure><img src="https://voiceofaction.org/wp-content/uploads/2020/06/grahamturner-1024x547.jpg" alt="" srcset="https://voiceofaction.org/wp-content/uploads/2020/06/grahamturner-1024x547.jpg 1024w, https://voiceofaction.org/wp-content/uploads/2020/06/grahamturner-300x160.jpg 300w, https://voiceofaction.org/wp-content/uploads/2020/06/grahamturner-768x410.jpg 768w, https://voiceofaction.org/wp-content/uploads/2020/06/grahamturner-187x100.jpg 187w, https://voiceofaction.org/wp-content/uploads/2020/06/grahamturner-500x267.jpg 500w, https://voiceofaction.org/wp-content/uploads/2020/06/grahamturner-690x369.jpg 690w, https://voiceofaction.org/wp-content/uploads/2020/06/grahamturner.jpg 1226w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Former CSIRO scientist Graham Turner has been warning about collapse for decades</figcaption></figure>



<p>Turner ran updated figures through the model <a rel="noreferrer noopener" href="https://www.ingentaconnect.com/contentone/oekom/gaia/2012/00000021/00000002/art00010" data-type="https://www.ingentaconnect.com/contentone/oekom/gaia/2012/00000021/00000002/art00010" target="_blank">again in 2012</a> for another peer-reviewed paper, and <a rel="noreferrer noopener" href="https://sustainable.unimelb.edu.au/__data/assets/pdf_file/0005/2763500/MSSI-ResearchPaper-4_Turner_2014.pdf" data-type="https://sustainable.unimelb.edu.au/__data/assets/pdf_file/0005/2763500/MSSI-ResearchPaper-4_Turner_2014.pdf" target="_blank">again in 2014</a> when he had joined the University of Melbourne’s Sustainable Society Institute.</p>



<p>“Data from the forty years or so since the LTG study was completed indicates that the world is closely tracking the BAU scenario,” Turner concluded in the 2014 paper.</p>



<p>“It is notable that there does not appear to be other economy-environment models that have demonstrated such comprehensive and long-term data agreement.”</p>



<p>Turner semi-retired in 2015 but runs a small organic market garden on a rural property in the NSW south coast’s Bega Valley.</p>



<p>He and his wife grow most of their own food and live off grid powered by a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://voiceofaction.org/collapse-of-civilisation-is-the-most-likely-outcome-top-climate-scientists/">https://voiceofaction.org/collapse-of-civilisation-is-the-most-likely-outcome-top-climate-scientists/</a></em></p>]]>
            </description>
            <link>https://voiceofaction.org/collapse-of-civilisation-is-the-most-likely-outcome-top-climate-scientists/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741179</guid>
            <pubDate>Sun, 05 Jul 2020 19:27:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Destroyer2 – Open Source Battleship Game]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23741169">thread link</a>) | @unonymous
<br/>
July 5, 2020 | https://umcconnell.github.io/destroyer2/ | <a href="https://web.archive.org/web/*/https://umcconnell.github.io/destroyer2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="app" data-server-rendered="true"><div><header> <a href="https://umcconnell.github.io/destroyer2/" aria-current="page"><!----> <span>Destroyer2</span></a> </header>   <main aria-labelledby="main-title"><header><img src="https://umcconnell.github.io/destroyer2/logo.svg" alt="hero"> <!----> <p>
      A real-time multiplayer battleship game
    </p> <p><a href="https://umcconnell.github.io/destroyer2/guide/">
  Get Started →
</a></p></header> <div><div><h2>Fast</h2> <p>Enjoy great performance with Node.js™, Redis™ and WebSockets.</p></div><div><h2>Simple</h2> <p>Simple server setup and deployment. Check the guide for simple deployment instructions, including for Docker™!</p></div><div><h2>Powerful</h2> <p>Automatic room cleanup, network loss resilience, and more!</p></div></div> <div><h3 id="quick-start"><a href="#quick-start">#</a> Quick start</h3> <div><pre><code><span># Clone</span>
<span>git</span> clone https://github.com/umcconnell/destroyer2.git
<span>cd</span> destroyer2

<span># Setup</span>
<span># Make sure you have docker and docker-compose installed!</span>
./docker/deploy.sh simple

<span># Done!</span>
<span># Visit http://localhost:8080 to get started</span>
</code></pre></div></div> <!----></main></div></div></div>]]>
            </description>
            <link>https://umcconnell.github.io/destroyer2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741169</guid>
            <pubDate>Sun, 05 Jul 2020 19:24:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UBC quietly changes references to Taiwan amid sensitive political climate]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 6 (<a href="https://news.ycombinator.com/item?id=23741119">thread link</a>) | @abc-xyz
<br/>
July 5, 2020 | https://www.ubyssey.ca/news/taiwan-references-changed/ | <a href="https://web.archive.org/web/*/https://www.ubyssey.ca/news/taiwan-references-changed/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        <p>UBC has quietly made a significant change in the way it refers to Taiwan in its annual enrolment report.</p><p>In <a href="https://academic.ubc.ca/sites/vpa.ubc.ca/files/documents/2018-19%20Enrolment%20Report.pdf" target="_blank"><u>past reports</u></a>, the university simply listed the island as “Taiwan,” but in the recent <a href="https://bog3.sites.olt.ubc.ca/files/2020/01/4_2020.02_Enrolment-Annual-Report.pdf" target="_blank"><u>2019/20</u></a> enrolment report, it was lengthier: “Taiwan (Province of China).”</p><p>In a written statement from Kurt Heinrich, UBC Media Relations senior communications director, he said this is because in 2018, UBC’s data governance steering committee adopted International Organization for Standardization (ISO) data standards.</p>
<p>The ISO, which is recognized by the United Nations, has referred to Taiwan as “Province of China” <a href="https://www.taiwannews.com.tw/en/news/3812381" target="_blank"><u>since 1974</u></a> under ISO 3166, and the UN switched its recognition of China from the Republic of China (Taiwan) to the People’s Republic of China (Mainland China) in 1971.</p><p>In a later email, the university stated that the adoption of ISO standards was “necessary for the university’s successful transition to Workday,” UBC’s partner for its software overhaul that will replace aging systems. Elsewhere on UBC websites, however, the island is still referred to as “Taiwan.”</p><p>The nature of Taiwan’s sovereignty is a deeply political debate. Taiwan, which boasts its own democratically elected government, claims to be an independent nation. Mainland China, on the other hand, claims Taiwan to be an integral province of China.</p><p>“To put ‘Province of China’ after the name is to politicize the name,” said Dr. Timothy Brook, a UBC professor and an expert in Chinese history.</p>
<p>Many countries have <a href="https://www.newsweek.com/who-recognizes-taiwan-two-change-china-1460559" target="_blank"><u>switched their allegiance</u></a> from Taipei to Beijing in recent decades. In 1970, Canada severed diplomatic ties with Taipei in favour of Beijing, but Canada and Taiwan maintain strong trade and informal ties.</p><p>UBC’s decision to make the change to label Taiwan as a “Province of China” came at a low point in Chinese–Canadian relations, following the <a href="https://www.ctvnews.ca/world/trudeau-says-china-made-obvious-link-between-meng-and-two-michaels-1.4994128" target="_blank"><u>arrests</u></a> of Huawei CFO Meng Wanzhou in Vancouver, and the <a href="https://www.theglobeandmail.com/politics/article-china-suggests-it-will-free-two-michaels-if-canada-allows-huawei/" target="_blank"><u>two Michaels</u></a> in China, which Brook described as “political hostage taking.”</p><p>For UBC, the stakes for appeasing China are high. Huawei has granted <a href="https://nationalpost.com/news/meng-wanzhou-arrest-caused-ubc-leaders-concern-over-enrolment-fundraising-internal-documents-show" target="_blank"><u>$9.5 million</u></a> in funding for research projects at UBC in recent years, which continued even after Meng’s December 2018 arrest.</p><p>Chinese students make up more than one third of all international students at UBC. In 2019/20, international student tuition made up <a href="https://bog3.sites.olt.ubc.ca/files/2020/04/2.1_2020.04_Budget-Fiscal-2020-2021.pdf" target="_blank"><u>$507 million</u></a> in revenue compared to $386 million from domestic students. Rising Canadian–Chinese tensions have made UBC administrators fear potential impacts on Chinese student enrolment and funding.</p><p>In 2019, Vice-Provost International Murali Chandrashekaran sent an <a href="https://nationalpost.com/news/meng-wanzhou-arrest-caused-ubc-leaders-concern-over-enrolment-fundraising-internal-documents-show" target="_blank"><u>email</u></a> to colleagues calling for a campus-wide meeting to address this, “given our significant reliance on China for students/$.”</p><p>If diplomatic tensions reach a point where China restricts students from going to UBC, as<a href="https://www.ubyssey.ca/news/ubc-urges-saudi-arabia-students-to-contact-enrolment-services/" target="_blank"><u> Saudi Arabia did in 2018</u></a>, UBC could face a significant <a href="https://theprovince.com/pmn/news-pmn/canada-news-pmn/credit-agency-warns-big-risk-to-canadian-schools-if-china-pulls-students/wcm/268ed61c-89fd-41e0-8a2d-3aba815152e3" target="_blank"><u>credit risk</u></a>, according to prominent credit agency Moody’s.</p><p>Anxieties surrounding Chinese interference also exist at other Canadian universities. At McMaster University, a Chinese student group had its club status <a href="https://www.scmp.com/news/china/diplomacy/article/3036309/chinese-student-association-mcmaster-university-loses-appeal" target="_blank"><u>revoked</u></a> after allegations it reported a talk by a Uyghur–Canadian woman to the Chinese consulate. At the University of Toronto, Chemi Lhamo, student union president and Canadian of Tibetan origins, was met with widespread <a href="https://www.cbc.ca/news/canada/toronto/china-tibet-student-election-1.5019648" target="_blank"><u>backlash</u></a> by Chinese students after her election win.</p><p>Yves Tiberghien, a UBC political science professor focusing on China and the Asia-Pacific Region, said he “can’t imagine” that the change in recognition of Taiwan in the recent enrolment report was due to Chinese financial influence.</p><p>“If I had to guess,” he added, the technical committee that decided this likely “did not have the full knowledge” of the sensitive political nature of the Taiwan–China relationship.</p>
<p>According to Brook, however, it is “entirely possible” that there were some Chinese pressures. “I wouldn’t be surprised if every Chinese consulate in Canada was going around and looking at things like universities to see how [they] refer to Taiwan, but I have no evidence of this,” he said. “It would be entirely in keeping with the kind of broader diplomatic initiatives that the [People’s Republic of China]’s been making over the last five years.”</p><p>While the university claims the decision was made for technical purposes, it did not respond to a follow-up email asking whether the committee responsible for the change was aware of the political context around the name.</p><p>“I wish they hadn’t done it,” said Tiberghien. “I don’t think it’s a good idea because it’s stepping into something that’s raw right now … the last thing you want is to step into this now.”</p>
      
      </div></div>]]>
            </description>
            <link>https://www.ubyssey.ca/news/taiwan-references-changed/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741119</guid>
            <pubDate>Sun, 05 Jul 2020 19:15:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HiddenAds up to no good again and spreading via Android gaming apps]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23741108">thread link</a>) | @realpanzer
<br/>
July 5, 2020 | https://decoded.avast.io/jakubvavra/hiddenads-up-to-no-good-again-and-spreading-via-android-gaming-apps/ | <a href="https://web.archive.org/web/*/https://decoded.avast.io/jakubvavra/hiddenads-up-to-no-good-again-and-spreading-via-android-gaming-apps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1870">

                    
                    
                    
                    <div>
                        
<p>I recently discovered a large campaign of HiddenAds on the Google Play Store, spreading via gaming apps. The initial discovery was made through an apklab.io automated detection that was based on similar features of a previous HiddenAds campaign that was present on the Play Store. Upon further analysis of the app through <a href="https://www.apklab.io/">apklab.io</a>, Avast’s mobile threat intelligence platform, I was able to identify a wider campaign by comparing similar activities, features, and network traffic. In total, I found 47 apps.</p>



<p>The apps’ poor reviews on the Play Store, combined with their capability to hide their icon and display ads outside the apps confirmed that they are part of the HiddenAds family.</p>



<h2><strong>One app leads to 47&nbsp;</strong></h2>



<p>Once I determined that the <a href="https://play.google.com/store/apps/details?id=com.dancing.color.road.ball.run.music">Dancing Run</a> app I found belongs to the HiddenAds family, I utilized <a href="https://www.apklab.io/">apklab.io</a> to conduct a search for similar apps.&nbsp;</p>



<p>I started my search by looking at the app’s entry points, as apklab.io groups apps with the same activities, receivers and services. The ability to see how many apps share an entry point is a useful feature in identifying unique shared features, and helped me find a set of entry points created for the original app.</p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/twitter-thread-1.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/twitter-thread-1.png 1022w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/twitter-thread-1-300x173.png 300w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/twitter-thread-1-768x443.png 768w" sizes="(max-width: 1022px) 100vw, 1022px"><figcaption>Entrypoints section of apklab.io.</figcaption></figure></div>



<p>I then searched the apklab.io database for apps with these unique entry points by using <strong>service:com.alive.ALiveService. </strong>To further narrow down the search results, I added the <strong>is:PlayFrosting</strong> parameter to find similar apps on the Play Store.</p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/twitter-thread-2-1-1024x671.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/twitter-thread-2-1-1024x671.png 1024w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/twitter-thread-2-1-300x197.png 300w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/twitter-thread-2-1-768x503.png 768w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/twitter-thread-2-1.png 1064w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Filtering search results to narrow down APKs on Play Store.</figcaption></figure></div>



<p>Apklab.io allows various filtering criteria in its search. I conducted another search with <strong>f:HideApplicationIconFromLauncher </strong>to identify apps that hide their icon from the launcher.</p>



<p>Continuing the search, I was able to discover more similar apps using the network dump dynamic feature. It collects information on the app network activity and in this case a specific URL was accessed by several of these apps.</p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/URL-Dynamic-1024x429.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/URL-Dynamic-1024x429.png 1024w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/URL-Dynamic-300x126.png 300w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/URL-Dynamic-768x322.png 768w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/URL-Dynamic.png 1182w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Dynamic network dump results.</figcaption></figure></div>



<p>I used the URL search filter <strong>host:”res.resvivinew.com”</strong> and found additional HiddenAds apps that shared this URL connection.</p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/URL-Dynamic-search-1024x731.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/URL-Dynamic-search-1024x731.png 1024w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/URL-Dynamic-search-300x214.png 300w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/URL-Dynamic-search-768x548.png 768w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/URL-Dynamic-search.png 1052w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>URL search results find additional apps.</figcaption></figure></div>



<p>I combined these methods of searching with other accessed URLs and activities. I was able to detect over 200 HiddenAds APKs. Of these, 47 apps were active on the Play Store. Apklab.io is a great tool for initial discovery and assessment of how widespread a particular family of apps is.</p>



<h2><strong>Taking a closer look</strong></h2>



<p>When diving deeper into the apps’ code, it became apparent that the apps are in fact repackaged games with an added layer of HiddenAds code. The newer versions of these apps only had slightly different code, but overall the apps all have nearly identical HiddenAds code. The added code is intentionally obfuscated and contains the ability to hide the icon from the launcher. The apps wait for a period of time after installation, then initiate the hide icon process.</p>



<p>In <a href="https://www.apklab.io/apk.html?hash=523f50a5fac3aa3f8aaaa3dffa807c61e194b2c6a3c58eb77d89c24656dca829">Throw Master</a>, one of the apps I analyzed, a ten minute delay execution timer starts as soon as the app is installed. This allows enough time to play the first three free levels of the game. The game regularly checks the timer while in use. Meanwhile, a broadcast receiver monitors the USER_PRESENT broadcasts which indicates if the phone is unlocked. If it is, it resets the timer. Once the ten minute delay is reached, the hide icon job is triggered.</p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/Code-snipper-1.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/Code-snipper-1.png 556w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/Code-snipper-1-300x60.png 300w" sizes="(max-width: 556px) 100vw, 556px"><figcaption>Main launcher activity used in the hide icon process.</figcaption></figure></div>



<p>The process starts by disabling the main launcher activity, in this case <strong>SplashActivity</strong> is the main launcher activity.</p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/Code-snipper-2.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/Code-snipper-2.png 615w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/Code-snipper-2-300x95.png 300w" sizes="(max-width: 615px) 100vw, 615px"><figcaption>PackageManager used to disabled main launcher activity.</figcaption></figure></div>



<p><strong>PackageManager </strong>is used to hide the icon from the launcher through <strong>setComponentEnabledSetting</strong>. This setting disables the main launcher activity and as a side effect hides the app’s launcher icon. </p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/Code-snipper-3.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/Code-snipper-3.png 646w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/Code-snipper-3-300x142.png 300w" sizes="(max-width: 646px) 100vw, 646px"><figcaption>INSTALL_SHORTCUT is used to create a shortcut.</figcaption></figure></div>



<p>The app then creates a shortcut on the home screen using the <strong>INSTALL_SHORTCUT </strong>launcher action. The shortcut differs from a launcher icon in that, even if deleted, it doesn’t remove the application from the device.</p>



<p>The user may figure out the app is the source of the ads and delete the newly created shortcut, however, this will not remove the app from the device. To the users’ frustration, the ads will continue until the app is removed via the device app settings.</p>



<p>Once the icon is hidden, the apps start to display ads outside of the apps. The apps have the ability to display intrusive ads over other apps via banners and notifications. Several apps even open the browser to display additional ads.</p>



<h2>Play Store warning signs</h2>



<p>Another shared attribute of these apps is that the developer only has a single app on their developer profile with a generic email address. Similarly, the Terms of Service are identical for all of the apps, likely pointing to an organized campaign by one actor. These warning signs could potentially be recognized by users.</p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/app-dev-1.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/app-dev-1.png 695w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/app-dev-1-300x104.png 300w" sizes="(max-width: 695px) 100vw, 695px"><figcaption>Generic developer name and email address.</figcaption></figure></div>



<p>The developers likely spread out the apps under different developer profiles to avoid detection and to make the adware removal more difficult.</p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/app-dev-2-1.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/app-dev-2-1.png 866w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/app-dev-2-1-300x187.png 300w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/app-dev-2-1-768x479.png 768w" sizes="(max-width: 866px) 100vw, 866px"><figcaption>Single app attributed to each developer profile.</figcaption></figure></div>



<p>The app reviews are a potential telltale sign for the regular user as they showcase the frustration and malicious features present in the app.</p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/app-dev-3-1.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/app-dev-3-1.png 695w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/app-dev-3-1-253x300.png 253w" sizes="(max-width: 695px) 100vw, 695px"><figcaption>Users correctly point out the adware features of the app.</figcaption></figure></div>



<h2>Spread</h2>



<p>Combined, the apps have been downloaded more than 15 million times. Several of these apps have been on the Play Store since early May, contributing to their high downloads.</p>



<figure><table><tbody><tr><td><strong>App Name</strong></td><td><strong>Downloads</strong></td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.draw.color.number.paint.lvye">Draw Color by Number</a></td><td>1,000,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.skate.board.fly.chute.race">Skate Board</a><a href="https://play.google.com/store/apps/details?id=com.skate.board.fly.chute.race"> – New</a></td><td>1,000,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.differences.findout.spot10">Find Hidden Differences</a></td><td>1,000,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.shooter.master.bullet.puzzle.huahong">Shoot Master</a></td><td>1,000,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.love.finddifferences.sogoodgame">Spot Hidden Differences</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.dancing.color.road.ball.run.music">Dancing Run – Color Ball Run</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.find.five.differences.puzzle.dawang">Find 5 Differences</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.cut.wood.joyworker.woodgames">Joy Woodworker</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.throw.master.toss.jump.higher">Throw Master</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.throw.into.space.toss.high.up.hang">Throw into Space</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.divide.it.cut">Divide it – Cut &amp; Slice Game</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.tony.shoot.newmigame">Tony Shoot – NEW</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.assassin.legend.killer.attack.sanyi">Assassin Legend</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.stacking.guys.newbee.game">Stacking Guys</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.play.boy.face.game">Save Your Boy</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.walkthrough.knife.assassin.hunter.baoer">Assassin Hunter 2020</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.stealinggames.run">Stealing Run</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.fly.skater.newrace.rungame">Fly Skater 2020</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.sports.disc.fly.fight">Disc Go！</a></td><td>500,000</td></tr></tbody></table><figcaption><br>Most downloaded HiddenAds discovered on Play Store.</figcaption></figure>



<p>It appears the campaign initially targeted users in India and South East Asia. Based on previous HiddenAds campaigns, the apps likely spread through game ads focused in these regions. Due to the generic developer details and Terms of Service, I cannot pinpoint where the developers of these apps are from. The map below indicates the initial 200 downloads of the <a href="https://www.apklab.io/apk.html?hash=15d9f6ebe532dc631b73d66cfd1d8ae8a608a53628bfff63924a1ed07f356559">Find 5 Differences</a> app recorded by Avast Mobile Security. The other investigated apps share a similar trend of initial downloads.</p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/spread-map-1.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/spread-map-1.png 1015w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/spread-map-1-300x166.png 300w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/spread-map-1-768x425.png 768w" sizes="(max-width: 1015px) 100vw, 1015px"><figcaption>Map shows the % spread of first 200 downloads recorded by Avast.</figcaption></figure></div>



<p>I believe that the initial spread across other regions that can be seen in the map above, is likely “collateral damage” caused by the apps’ presence on the Play Store.</p>



<p>While this gives us a snapshot of the initial spread, the current prevalence of these apps differs. Based on Avast’s internal statistics, this HiddenAds campaign is currently most prevalent in Brazil, India and Turkey.</p>



<figure><table><tbody><tr><td><strong>Country</strong></td><td><strong>Share</strong></td></tr><tr><td>Brazil</td><td>21%</td></tr><tr><td>India</td><td>8.10%</td></tr><tr><td>Turkey</td><td>6.30%</td></tr><tr><td>Argentina</td><td>5.60%</td></tr><tr><td>Mexico</td><td>3.70%</td></tr></tbody></table><figcaption><br>Percentage spread of Avast users who have downloaded at least one of the HiddenAds apps in the last two weeks by country.</figcaption></figure>



<p>The HiddenAds campaign was able to spread globally due to its presence on the Play Store. Once the apps are removed from the Play Store, the user numbers will likely go down rapidly.</p>



<h2>Summary</h2>



<p>Thanks to <a href="https://www.apklab.io/">apklab.io</a>, we were able to find 47 apps violating Google’s developer <a href="https://play.google.com/about/monetization-ads/ads/">Ads</a> and <a href="https://play.google.com/about/spam-min-functionality/">Spam</a> policies, in addition to the original app we found. We have reported these to Google, and at the time of posting, Google removed 30 of the apps. Campaigns like HiddenAds apps may slip into the Play Store through obfuscating their true purpose or through incremental version updates that introduce intrusive ads and hide icon features once they have been downloaded by users. It is difficult to prevent future campaigns from making their way onto the Play Store, as the actors behind the campaign use one-off developer accounts for each uploaded app. Avast will monitor further developments of the HiddenAds campaigns through apklab.io features, as well as via automated detections.</p>



<h2>Samples</h2>



<p>Due to the number of samples, we’ve only selected the APKs that were present on the Play Store and put them into this <a href="https://docs.google.com/spreadsheets/d/19duB05JzEaXmxbW382Leby9d6gEnQbwEgI4u5Y0ZOJw/edit#gid=0">spreadsheet</a>.</p>



<h2>Tips on avoiding adware</h2>



<ul><li>Install a trustworthy antivirus app. Antivirus acts as a safety net and can protect you from adware.</li><li>Exercise caution when downloading apps. Read app reviews before installing a new app, carefully reading both positive and negative reviews. Notice if reviewers comment on whether or not the app does what it says it will do. If an app’s review includes comments like “this app doesn’t do what it promises” or “this app is packed with adware,” – think twice about downloading the app! &nbsp;Reviews like this are a sign that something isn’t right.</li><li>Always carefully check app permissions, closely looking to see if they make sense. Granting incorrect permissions can send sensitive data to cybercriminals, including information such as contacts stored on the device, media files and insights into personal chats. If anything seems out of the ordinary or beyond what seems appropriate, the app should not be downloaded.</li></ul>
                                            </div>

                </article></div>]]>
            </description>
            <link>https://decoded.avast.io/jakubvavra/hiddenads-up-to-no-good-again-and-spreading-via-android-gaming-apps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741108</guid>
            <pubDate>Sun, 05 Jul 2020 19:14:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Transport makes up only 6% of the greenhouse gas emissions from food]]>
            </title>
            <description>
<![CDATA[
Score 77 | Comments 69 (<a href="https://news.ycombinator.com/item?id=23741040">thread link</a>) | @shafyy
<br/>
July 5, 2020 | https://blog.yeticheese.com/eating-local-has-tiny-environmental-impact/ | <a href="https://web.archive.org/web/*/https://blog.yeticheese.com/eating-local-has-tiny-environmental-impact/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>There's a common misconception that eating locally produced foods is important from an environmental point of view. Even the <a href="https://twitter.com/UN/status/1188622911080415235">UN tweeted about it.</a> This is wrong.</p><p>Transport makes up only 6% of the greenhouse gas emissions from food:</p><figure><img src="https://blog.yeticheese.com/content/images/2020/07/How-much-of-GHGs-come-from-food-1-.png" alt="" width="3889" height="3935" srcset="https://blog.yeticheese.com/content/images/size/w600/2020/07/How-much-of-GHGs-come-from-food-1-.png 600w, https://blog.yeticheese.com/content/images/size/w1000/2020/07/How-much-of-GHGs-come-from-food-1-.png 1000w, https://blog.yeticheese.com/content/images/size/w1600/2020/07/How-much-of-GHGs-come-from-food-1-.png 1600w, https://blog.yeticheese.com/content/images/size/w2400/2020/07/How-much-of-GHGs-come-from-food-1-.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Source: <a href="https://ourworldindata.org/environmental-impacts-of-food">Our World in Data</a>.</figcaption></figure><p>The reason for this is that most foods are transported by ship and not plane. Only about 0.16% of food miles are done by plane:</p><figure><img src="https://blog.yeticheese.com/content/images/2020/07/share-food-miles-by-method.png" alt="" width="3400" height="2400" srcset="https://blog.yeticheese.com/content/images/size/w600/2020/07/share-food-miles-by-method.png 600w, https://blog.yeticheese.com/content/images/size/w1000/2020/07/share-food-miles-by-method.png 1000w, https://blog.yeticheese.com/content/images/size/w1600/2020/07/share-food-miles-by-method.png 1600w, https://blog.yeticheese.com/content/images/size/w2400/2020/07/share-food-miles-by-method.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Source: <a href="https://ourworldindata.org/grapher/share-food-miles-by-method">Our World in Data</a>.</figcaption></figure><p>It makes sense to try and avoid foods that are transported by air. Typically, those are foods which are highly perishable, such as asparagus, green beans and berries.</p><p>In some cases, eating local food even has a more negative impact on the environment than buying something that has been produced half way around the world. For example, heated greenhouses are energy intensive and can produce more greenhouse gases than transporting something for thousands of kilometers by water or road.</p><p>It's clear that avoiding meat and dairy has a much bigger impact on reducing greenhouse gas emissions.</p><p>So, why do people keep saying that we should eat local?</p><p>It could just be ignorance. However, I think that it's often a straw man argument pushed by interest groups that want to keep selling meat and dairy. It is something that is easy to do and seems to make sense on the surface to many people. Let's take another look at that UN tweet from before:</p><figure><img src="https://blog.yeticheese.com/content/images/2020/07/Screenshot-2020-07-05-at-7.18.44-PM.png" alt="" width="1194" height="634" srcset="https://blog.yeticheese.com/content/images/size/w600/2020/07/Screenshot-2020-07-05-at-7.18.44-PM.png 600w, https://blog.yeticheese.com/content/images/size/w1000/2020/07/Screenshot-2020-07-05-at-7.18.44-PM.png 1000w, https://blog.yeticheese.com/content/images/2020/07/Screenshot-2020-07-05-at-7.18.44-PM.png 1194w" sizes="(min-width: 720px) 720px"><figcaption>Source: <a href="https://twitter.com/UN/status/1188622911080415235">Tweet from @UN</a> on Oct 28, 2019.</figcaption></figure><p>In addition to eating local food, they also recommend unplugging unused appliances and using less hot water. Like avoiding plastic bags or plastic straws, this is good advice but a long shot from making a meaningful impact on climate change.</p><p>Arguments like these try to shift away the spot light from big companies who collectively make up a large chunk of the greenhouse gas emissions to individuals. People think that they did something meaningful by buying local food, which, as we have seen, is not the case.</p><p>I'm not saying that we shouldn't do those things. We absolutely should, but it shouldn't be the main talking points of organizations like the UN or WWF.</p><p>To make real change, we must eat less meat and dairy, move to more renewable energy sources and reduce air and road travel significantly.</p><p>PS: I'm only talking about the impact on climate change in this article. Eating local and organic food has other benefits such as supporting the local economy and in most cases it's a good idea to do it.</p><p>Comments or questions? Join in on the discussion on <a href="https://twitter.com/yeticheeseparty/status/1279850824378781697?s=20">this Twitter thread</a>. </p><!--kg-card-begin: html--><!-- Begin Mailchimp Signup Form -->


<div id="mc_embed_signup">
<p>
    Our plant-based Yeti Feta will be available to order soon. Leave your email below and we'll let you know when it's ready. (No newsletters or other shenanigans)
</p>

</div>

<!--End mc_embed_signup--><!--kg-card-end: html-->
			</section></div>]]>
            </description>
            <link>https://blog.yeticheese.com/eating-local-has-tiny-environmental-impact/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741040</guid>
            <pubDate>Sun, 05 Jul 2020 19:05:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self Organising WS2811 LEDs]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 6 (<a href="https://news.ycombinator.com/item?id=23741036">thread link</a>) | @iamflimflam1
<br/>
July 5, 2020 | https://blog.cmgresearch.com/2020/06/05/self-organising-ws2811-leds.html | <a href="https://web.archive.org/web/*/https://blog.cmgresearch.com/2020/06/05/self-organising-ws2811-leds.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Lots of LEDs? It’s not Christmas yet!</p>

<p>I had a big bundle of addressable WS2811 LED strings and an ESP-CAM board (an ESP32 dev board with a camera). There’s only one possible project that you can do with these components. Turn the disorganised chaos of lights into something a bit more organised.</p>

<p>As an added bonus I’ve ended up duplicating the image processing code in JavaScript so you don’t even need a camera on your ESP32 board - you can just use a plain dev board to drive the LEDs.</p>

<p>You can see the results of my efforts in the video below and I’ll run through a bit more detail of the code in the following text.</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/Ueim2Ko8VWo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>The full sample code can be found here: <a href="https://github.com/atomic14/self-organising-leds">https://github.com/atomic14/self-organising-leds</a></p>

<p>If you want to do this yourself then you will need an ESP32 dev board of some kind and of course you’ll need some kind of addressable LEDs. I’m using the <a href="https://github.com/FastLED/FastLED">FastLED</a> library for driving the LEDs so with some small code changes you can probably support pretty much any addressable LEDs.</p>

<p><img src="https://blog.cmgresearch.com/assets/article_images/2020-06-05-ws2811/boards.jpg" alt="ESP32 and ESP-CAM Boards"></p>

<p>Our challenge comes down to a very basic problem, given access to a stream of images from a camera identity the approximate locations of each LED in 2D space. Once you’ve done that it’s a simple problem to map from each LED’s x and y location onto a frame buffer containing the pattern you want to show.</p>

<p>There’s a bunch of boiler plate code to initialise the ESP-CAM - I took inspiration from the sample code <a href="https://randomnerdtutorials.com/esp32-cam-video-streaming-face-recognition-arduino-ide/">here</a> and copied the bits I needed to get the camera up and running.</p>

<p>An important change I’ve made is only capture greyscale images at the lowest framesize:</p>

<div><div><pre><code><span>config</span><span>.</span><span>pixel_format</span> <span>=</span> <span>PIXFORMAT_GRAYSCALE</span><span>;</span>
<span>config</span><span>.</span><span>frame_size</span> <span>=</span> <span>FRAMESIZE_QQVGA</span><span>;</span>
</code></pre></div></div>

<p>And then to grab a frame from the camera we simply do:</p>

<div><div><pre><code>    <span>camera_fb_t</span> <span>*</span><span>fb</span> <span>=</span> <span>esp_camera_fb_get</span><span>();</span>
    <span>Frame</span> <span>*</span><span>frame</span> <span>=</span> <span>new</span> <span>Frame</span><span>(</span><span>fb</span><span>);</span>
    <span>esp_camera_fb_return</span><span>(</span><span>fb</span><span>);</span>
</code></pre></div></div>

<p>With our Frame class grabbing a copy of the pixels along with the width and the height of the image.</p>

<div><div><pre><code><span>pixels</span> <span>=</span> <span>(</span><span>uint8_t</span> <span>*</span><span>)</span><span>malloc</span><span>(</span><span>fb</span><span>-&gt;</span><span>height</span> <span>*</span> <span>fb</span><span>-&gt;</span><span>width</span><span>);</span>
<span>memcpy</span><span>(</span><span>pixels</span><span>,</span> <span>fb</span><span>-&gt;</span><span>buf</span><span>,</span> <span>fb</span><span>-&gt;</span><span>height</span> <span>*</span> <span>fb</span><span>-&gt;</span><span>width</span><span>);</span>
<span>width</span> <span>=</span> <span>fb</span><span>-&gt;</span><span>width</span><span>;</span>
<span>height</span> <span>=</span> <span>fb</span><span>-&gt;</span><span>height</span><span>;</span>
<span>length</span> <span>=</span> <span>fb</span><span>-&gt;</span><span>width</span> <span>*</span> <span>fb</span><span>-&gt;</span><span>height</span><span>;</span>
</code></pre></div></div>

<p>The image below shows a frame grabbed from the ESP-CAM sensor.</p>

<p><img src="https://blog.cmgresearch.com/assets/article_images/2020-06-05-ws2811/grabbed-frame.png" alt="Grabbed Frame"></p>

<p>For the JavaScript version of this code it’s a bit more complicated. One of the biggest problems is that we need to be running over HTTPS to have access to the camera - more on this later….</p>

<div><div><pre><code><span>const</span> <span>stream</span> <span>=</span> <span>await</span> <span>navigator</span><span>.</span><span>mediaDevices</span><span>.</span><span>getUserMedia</span><span>({</span>
  <span>video</span><span>:</span> <span>{</span> <span>facingMode</span><span>:</span> <span>"</span><span>environment</span><span>"</span> <span>},</span>
  <span>audio</span><span>:</span> <span>false</span><span>,</span>
<span>});</span>
<span>const</span> <span>canPlayListener</span> <span>=</span> <span>()</span> <span>=&gt;</span> <span>{</span>
  <span>// the video is loaded and we can grab frames</span>
  <span>onVideoReady</span><span>(</span><span>video</span><span>);</span>
  <span>video</span><span>.</span><span>removeEventListener</span><span>(</span><span>"</span><span>canplay</span><span>"</span><span>,</span> <span>canPlayListener</span><span>);</span>
<span>};</span>
<span>video</span><span>.</span><span>addEventListener</span><span>(</span><span>"</span><span>canplay</span><span>"</span><span>,</span> <span>canPlayListener</span><span>);</span>
<span>video</span><span>.</span><span>srcObject</span> <span>=</span> <span>stream</span><span>;</span>
<span>video</span><span>.</span><span>play</span><span>();</span>
</code></pre></div></div>

<p>Once we have a video stream coming from the camera we can grab a frame by drawing the video to a canvas context and then getting the imageData from it.</p>

<div><div><pre><code><span>function</span> <span>getVideoFrame</span><span>(</span><span>video</span><span>:</span> <span>HTMLVideoElement</span><span>,</span> <span>canvas</span><span>:</span> <span>HTMLCanvasElement</span><span>)</span> <span>{</span>
  <span>const</span> <span>width</span> <span>=</span> <span>video</span><span>.</span><span>videoWidth</span><span>;</span>
  <span>const</span> <span>height</span> <span>=</span> <span>video</span><span>.</span><span>videoHeight</span><span>;</span>
  <span>const</span> <span>context</span> <span>=</span> <span>canvas</span><span>.</span><span>getContext</span><span>(</span><span>"</span><span>2d</span><span>"</span><span>);</span>
  <span>// draw the video to the canvas</span>
  <span>context</span><span>!</span><span>.</span><span>drawImage</span><span>(</span><span>video</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>width</span><span>,</span> <span>height</span><span>);</span>
  <span>// get the raw image bytes</span>
  <span>const</span> <span>imageData</span> <span>=</span> <span>context</span><span>!</span><span>.</span><span>getImageData</span><span>(</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>width</span><span>,</span> <span>height</span><span>);</span>
  <span>// convert to greyscale</span>
  <span>const</span> <span>bytes</span> <span>=</span> <span>new</span> <span>Uint8Array</span><span>(</span><span>width</span> <span>*</span> <span>height</span><span>);</span>
  <span>for</span> <span>(</span><span>let</span> <span>y</span> <span>=</span> <span>0</span><span>;</span> <span>y</span> <span>&lt;</span> <span>height</span><span>;</span> <span>y</span><span>++</span><span>)</span> <span>{</span>
    <span>for</span> <span>(</span><span>let</span> <span>x</span> <span>=</span> <span>0</span><span>;</span> <span>x</span> <span>&lt;</span> <span>width</span><span>;</span> <span>x</span><span>++</span><span>)</span> <span>{</span>
      <span>const</span> <span>r</span> <span>=</span> <span>imageData</span><span>.</span><span>data</span><span>[(</span><span>y</span> <span>*</span> <span>width</span> <span>+</span> <span>x</span><span>)</span> <span>*</span> <span>4</span><span>];</span>
      <span>const</span> <span>g</span> <span>=</span> <span>imageData</span><span>.</span><span>data</span><span>[(</span><span>y</span> <span>*</span> <span>width</span> <span>+</span> <span>x</span><span>)</span> <span>*</span> <span>4</span> <span>+</span> <span>1</span><span>];</span>
      <span>const</span> <span>b</span> <span>=</span> <span>imageData</span><span>.</span><span>data</span><span>[(</span><span>y</span> <span>*</span> <span>width</span> <span>+</span> <span>x</span><span>)</span> <span>*</span> <span>4</span> <span>+</span> <span>2</span><span>];</span>
      <span>// https://en.wikipedia.org/wiki/Grayscale#Converting_color_to_grayscale</span>
      <span>const</span> <span>grey</span> <span>=</span> <span>Math</span><span>.</span><span>min</span><span>(</span><span>255</span><span>,</span> <span>0.299</span> <span>*</span> <span>r</span> <span>+</span> <span>0.587</span> <span>*</span> <span>g</span> <span>+</span> <span>0.114</span> <span>*</span> <span>b</span><span>);</span>
      <span>bytes</span><span>[</span><span>y</span> <span>*</span> <span>width</span> <span>+</span> <span>x</span><span>]</span> <span>=</span> <span>grey</span><span>;</span>
    <span>}</span>
  <span>}</span>
  <span>return</span> <span>bytes</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p><img src="https://blog.cmgresearch.com/assets/article_images/2020-06-05-ws2811/phone-interface.png" alt="Phone Interface"></p>

<p>Now we can grab frames we just need to grab a frame with no LEDs lit, light one LED, grab another frame and then compare the two. The difference should tell us where the LED is. To avoid noise or small movements of the camera having a bit impact we apply a guassian blur to the captured frames before taking the difference.</p>

<p>This is a of course a very naive and simple algorithm and could easily be improved on.</p>

<p>In the C++ code of the ESP32 we do all this directly in code. In the JavaScript version we call API functions on the web interface of the ESP32 to turn LEDs on and off and once we’ve finished the processing send up the calculated positions of the LEDs to the board.</p>

<p>In our ESP32 code we create a framebuffer and draw patterns into it. We then use the locations of each LED to work out what color it should be.</p>

<p><img src="https://blog.cmgresearch.com/assets/article_images/2020-06-05-ws2811/organised.jpg" alt="Organised"></p>

<p>To solve the issue of needing HTTPS to access the camera and also needing the API calls to be HTTPS as well (we can’t mix content nowadays!) we need a way of serving both the UI and the API from the ESP32 web server over HTTPS. There are web servers that support HTTPS and self signed certificates available for the ESP32 but this leads to other problems and would require a rewrite of the device code. An easy workaround to this problem is to use a service such as <a href="https://ngrok.com/">ngrok</a> to provide a secure URL from the cloud through our computer to the ESP32 device. Slightly convoluted, but it works!</p>

<p>This in only needed if you are not using an ESP-CAM and have to use your phone’s camera for calibrating the LEDs. Sign up for a free acount with ngrok and then find the IP address of your ESP32 board:</p>

<div><div><pre><code>ping espcam.local
PING espcam.local (10.0.1.17): 56 data bytes
64 bytes from 10.0.1.17: icmp_seq=0 ttl=255 time=14.343 ms
64 bytes from 10.0.1.17: icmp_seq=1 ttl=255 time=6.493 ms
</code></pre></div></div>

<p>Take the IP-Address and ask ngrok to start proxying requests for us:</p>

<div><div><pre><code>ngrok http 10.0.1.17 -inspect=false
</code></pre></div></div>

<p>You’ll need steady hands - there’s quite a lot of latency going on so the space between turning an LED on and off and grabbing a frame can be quite large. I slightly moved as I was taking the frame to show the locations so the positions are slightly off.</p>

<p><img src="https://blog.cmgresearch.com/assets/article_images/2020-06-05-ws2811/located.png" alt="LED locations"></p>

<p>Checkout the video to see how well it works - surprising for such a simple algorithm.</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/Ueim2Ko8VWo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

          </div></div>]]>
            </description>
            <link>https://blog.cmgresearch.com/2020/06/05/self-organising-ws2811-leds.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741036</guid>
            <pubDate>Sun, 05 Jul 2020 19:04:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn about transaction isolation levels]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23740921">thread link</a>) | @lanraccoon
<br/>
July 5, 2020 | https://lanraccoon.com/2020/learn-about-transaction-isolation-levels/ | <a href="https://web.archive.org/web/*/https://lanraccoon.com/2020/learn-about-transaction-isolation-levels/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Databases are everywhere and they’re here to stay. If you’re a bit familiar with <a href="https://en.wikipedia.org/wiki/Relational_database">relational databases</a> you are probably familiar with transactions. Transactions are pretty powerful tools when working with databases. They allow multiple users to play nicely with each other while working on the same database. However, with more and more users connecting to the same database, you’re bound to run into performance issues sooner or later.&nbsp;</p>
<p>Powerful as they are, transactions are a double edge sword. Used incorrectly they can, and will eat up your database’s resources. Transaction isolation levels, are a way to fine-tune the I (Isolation) bit of ACID (Atomicity, Consistency, Isolation, Durability). You can increase concurrency if you are willing to make a compromise about what <em>Isolated </em>actually means.&nbsp;</p>
<h3>Isolation issues</h3>
<p>First things first, what can possibly go wrong ? Assuming that each statement abides by the ACID principles (which they are), when multiple statements are run by different users at the same time, you can run into issues such as:&nbsp;</p>
<ul><li><strong>Dirty reads</strong> – Data is being read while in the process of being updated. For example: Bob changes a row a part of a transaction. Alice reads that row and gets the data that is saved in the database. Bob then rolls back the transaction. In this case Alice has data that technically never existed.</li><li><strong>Non-repeatable reads</strong> – Subsequent reads don’t return consistent results. For example: Alice starts a transaction that reads data on a row. Bob changes that row and commits the changes. Alice, while in the same transaction, reads the same row again and gets a new value for the data.&nbsp;</li><li><strong>Phantom reads</strong> – Subsequent select statements may return different results. For example: Alice runs a select statement with a where clause that returns multiple rows. Bob inserts a row that fits with the where clause of the statement that Alice ran previously and commits the result. Alice runs the same select statement that she previously ran, and she now gets new rows as a result.&nbsp;</li></ul>
<h3>Database locks</h3>
<p>We saw what can go wrong, now let’s see how we can defend against it. Firstly, the tools: database locks. Once a transaction acquires a lock on a resource, they can limit the access other transactions have on that same resource by preventing other transactions from acquiring their locks. This, combined with the fact that each transaction needs to acquire the appropriate lock before they make operations, gives us a pretty comprehensive and mechanism that we can play with.</p>
<p>Different databases have different models for locks, but they share common patterns:</p>
<h4>Level:</h4>
<ul><li>Row level: Locks are placed on a single table row</li><li>Table level: Locks are placed on the table</li><li>Page level: This is an intermediary lock (between row and table) and applies to a page – a subset of the table rows, typically, the amount of data that can be read from the disk in a single disk operation.&nbsp;</li><li>Database level: As you can imagine, a&nbsp; lock that applies to the whole database.&nbsp;</li></ul>
<h4>Concurrency:&nbsp;</h4>
<ul><li><a href="https://docs.oracle.com/javadb/10.8.3.0/devguide/cdevconcepts842304.html">Shared locks</a>, also known as read locks. A shared lock on a resource is usually requested when a transaction wants to read data (i.e. select operations). Multiple transactions can acquire shared locks on a resource, meaning that multiple transactions can read data at the same time.</li><li><a href="https://docs.oracle.com/javadb/10.8.3.0/devguide/cdevconcepts842279.html">Exclusive locks</a>, also known as write-locks. An exclusive lock can only be acquired by a single transaction at a time. If there is another transaction who has a lock on the resource (shared or exclusive), the transaction will wait for the other transaction to release the locks. While a transaction holds an exclusive lock, no other transactions can acquire any locks on the resource (shared or exclusive)&nbsp;</li><li><a href="https://docs.oracle.com/javadb/10.8.3.0/devguide/cdevconcepts842385.html">Update locks</a>, are a more relaxed version of the exclusive lock. An update lock can be acquired on an object that has a shared lock on it. When the transaction is ready to update the object, it will convert the update lock into an exclusive lock. Please note that update locks can be acquired an object that has a shared lock on it, but a shared lock cannot be acquired on an object that has an update lock.&nbsp;</li></ul>
<h3>Transaction isolation level</h3>
<p>Transactions make use of these locks to implement different isolation levels. At a really high level, isolation levels are a way to balance concurrency with isolation. The higher the isolation level, the more restrictive locks are going to be, thus the more transactions will have to wait to acquire said locks, which will result in a lower total number of transaction. As they say, there’s no such a thing as a free lunch. These are the transaction isolation levels:</p>
<h4>Read uncommitted</h4>
<p>This is the most relaxed isolation level. It allows the current transaction to read data that hasn’t been committed by other transactions yet. Transactions don’t acquire any locks for resources. This can potentially result in reading that that is in the middle of modified by other transactions.&nbsp;</p>
<h4>Read committed</h4>
<p>The transaction can only read data that has been committed. The transaction acquires shared locks when reading resources and it releases them as soon as the read statement is complete. This means that we are only read data that has completed updating, but since we’re releasing the lock after each instruction, we can get different results on subsequent reads.&nbsp;</p>
<h4>Repeatable reads</h4>
<p>The transaction acquires a shared lock when it wants to read a resource and keeps the locks to the end of the transaction. As we keep shared locks throughout the transaction, we ensure that all reads return the same data, since we are keeping other transactions from modifying the data until the transaction ends.&nbsp;</p>
<h4>Snapshot</h4>
<p><sub>* This is available in SQL Server.&nbsp;</sub></p>
<p>All the reads inside the transaction return the data as it was available at beginning of the transaction. It’s as if the transaction takes a snapshot of the data at the beginning and uses that throughout the transaction. It’s functionally similar to the Serializable level described below, but it makes use of a slightly different mechanism to achieve that.&nbsp;</p>
<h4>Serializable</h4>
<p>This is the highest isolation level available. The transaction acquires read locks for resources that need to be read and keeps them for the duration of the transaction, thus ensuring that data, once read, it stays the same for the duration of the transaction. It also acquires exclusive locks when updating the data and releases them at the end of the transaction. Additionally, the transaction places row range locks on of any rows matching conditions in the current transaction, so that we avoid phantom reads.&nbsp;</p>
<h3>Conclusion</h3>
<p>To summarize, every time you use a transaction in your code, you should take a moment and consider the appropriate isolation level that is needed. You can just put everything as serializable and call it a day, but in most cases, such a strong restriction is not needed and you would only be introducing unnecessary delays into your database. For most cases, a choice between Read Committed and Repeatable Reads would be enough. Keep this table in your mind as it should help you decide. Always use the most relaxed isolation level your app can afford.&nbsp;</p>
<figure><table><tbody><tr><td></td><td><strong>Dirty Reads</strong></td><td><strong>Non-Repeatable Reads</strong></td><td><strong>Phantom Reads</strong></td></tr><tr><td><strong>Read uncommitted</strong></td><td><span>Maybe</span></td><td><span>Maybe</span></td><td><span>Maybe</span></td></tr><tr><td><strong>Read committed</strong></td><td><span>Never</span></td><td><span>Maybe</span></td><td><span>Maybe</span></td></tr><tr><td><strong>Repeatable reads</strong></td><td><span>Never</span></td><td><span>Never</span></td><td><span>Maybe</span></td></tr><tr><td><strong>Snapshot</strong></td><td><span>Never</span></td><td><span>Never</span></td><td><span>Never</span></td></tr><tr><td><strong>Serializable</strong></td><td><span>Never</span></td><td><span>Never</span></td><td><span>Never</span></td></tr></tbody></table></figure>
<h3>Further reading</h3>
<ul><li><a href="https://lanraccoon.com/2020/http-rest-api-cheatsheet/">HTTP – REST API – Cheatsheet</a></li><li><a href="https://lanraccoon.com/2019/jack-of-all-trades-general-programmer/">Jack of all trades – a case for a general programmer</a></li><li><a href="https://lanraccoon.com/2018/async-programming-models-part-1/">Async programming models part I</a></li><li><a href="https://lanraccoon.com/2018/async-programming-part-ii/">Async programming models part II</a></li></ul>


</div></div>]]>
            </description>
            <link>https://lanraccoon.com/2020/learn-about-transaction-isolation-levels/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740921</guid>
            <pubDate>Sun, 05 Jul 2020 18:48:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SemVer Considered Harmful]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23740913">thread link</a>) | @mikebike
<br/>
July 5, 2020 | https://jolynch.github.io/posts/semver_considered_harmful/ | <a href="https://web.archive.org/web/*/https://jolynch.github.io/posts/semver_considered_harmful/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>In the past ten years or so, <a href="https://semver.org/">Semantic Versioning</a> a.k.a
“SemVer” has become extremely popular in the software development world. The
idea is that libraries and services can convey information to users about how
the application programming interface
(<a href="https://en.wikipedia.org/wiki/Application_programming_interface">API</a>) of
that library/package/service is evolving just using the version number. This
information is conveyed through three dotted numbers that form a logical clock
for totally ordering changes to the software API:</p>

<center><h3>Semantic Version Numbers</h3></center>
<div><pre><code data-lang="text">====================== Specification ========================

Version = &lt;Major&gt;.&lt;Minor&gt;.&lt;Patch&gt;

Major: this number goes up when the public API breaks
Minor: this number goes up when the public API changes
Patch: this number goes up when the public API doesn't change

====================== Examples =============================

# A Minor API change happened, safe to upgrade
1.4.5 -&gt; 1.5.0

# API breakage, probably unsafe to upgrade
1.7.0 -&gt; 2.0.0

# Who knows what will happen
0.182.13 -&gt; 0.182.14
=============================================================</code></pre></div>

<p>Armed with this information, software developers can theoretically upgrade
without fear of the new version breaking their code.</p>



<p>I believe that this versioning scheme, in practice, is problematic and creates
a large amount of pain in our industry. Three concrete failure modes I witness
frequently are:</p>

<ol>
<li>Most packaging systems (deb, rpm, python, ruby, java, etc …) cannot
simultaneously install multiple major versions of the same package name.
This often leaves users unable to upgrade to the latest major version due to
(reasonable) fear of breakages.</li>
<li>Frequent major version bumps frequently break functional code, leading
to <a href="https://en.wikipedia.org/wiki/Dependency_hell">dependency hell</a> where
library/service authors mix and match min, max, and exact version pins on
major versions to try to work around various incompatibilities. These pins
inevitably conflict.</li>
<li>There is still no standard way to derive the source code which produced the
artifact or seeing the difference between two versions. This makes it hard
to verify how the API is breaking or whether it will break specific usage
patterns.</li>
</ol>

<p>There is also the somewhat annoying issue of the plethora of <code>0.X</code> artifacts,
which happen because developers, somewhat reasonably, don’t want to release
a public API they will have to stand behind until they can be certain they
can.</p>

<p>Ultimately these factors lead to software developers, myself included, viewing
dependency upgrades with great trepidation. Quite reasonably developers defend
themselves from breakage by either not upgrading their dependencies (unless
they are forced to), vendoring dependent code, or skipping dependencies all
together and just writing it themselves.</p>

<h2 id="reduce-the-fear-breaking-versions-must-cohabitate">Reduce the Fear: Breaking Versions Must Cohabitate</h2>

<p>The use of the major version number in SemVer to indicate API breakage is by
far the most problematic aspect of the design. In an ideal world, packaging
systems and programming languages would automatically namespace different major
versions, and code that depends on a particular major version would have all
references specifically reference the major version namespace. Unfortunately,
we do not live in an ideal world and most packaging systems simply don’t
support this.  Three examples that I personally struggle with frequently:</p>

<p><strong>Debian packages (<code>apt</code>/<code>aptitude</code> in particular)</strong>: You only get one version
and the higher one is almost always chosen even if that may break less-than
pins. A common practice with debian packages to work around these limitations
is to release new packages with a different name.</p>

<p><strong>Java libraries (<code>mvn</code>/<code>gradle</code> in particular)</strong>: In a given class path you
can only have one implementation of a given package. Even if you manage to
convince gradle or maven to pull down multiple versions of a <code>.jar</code>, good luck
getting the JVM to not pick one implementation arbitrarily. As a result, Java
developers often resort to hacks like
<a href="https://imperceptiblethoughts.com/shadow/">package path rewriting</a>.</p>

<p><strong>Python libraries (<code>pip</code> in particular)</strong>: While the Python community has
moved towards isolated virtual environments which does make this issue slightly
less of an issue (and with tools like <code>docker</code> or
<a href="https://github.com/spotify/dh-virtualenv"><code>dhvirtualenv</code></a> it gets even
better), you still can’t install multiple versions of the same package in the
same virtualenv. Most Python projects I am aware of either don’t work around
this and break all the things, or release multiple package names.</p>

<p>These problems are even worse for client libraries, where the library is wrapping a
remote (often backwards incompatible) API change. For me this has been one of the
hardest parts of upgrading distributed datastores that I work on because we
often can’t use the vanilla client libraries during migration (e.g.
<a href="https://curator.apache.org/">Curator</a> 2 vs Curator 4, Elasticsearch 2 vs 5,
etc …). In my experience with most client library upgrades you have to create
an internal company fork that renames and relocates the package so we can run
both datastore APIs at the same time and have the client gracefully migrate
from the old version to the new one.</p>

<p>In an ideal world, remote APIs would remain backwards compatible for at least a
single major version to give users an upgrade path, but I find that many
developers argue that they don’t need to remain backwards compatible across a
major version (this is what SemVer says after all …). I wish this argument
was soundly rejected.</p>

<p>How can we fix this problem given the current constraints we operate under?
Well, we are left with a reasonably simple option: <strong>put the API version
semantics in the name of the package.</strong> Some example API migrations where I
have been able to take advantage of this technique are:</p>

<ul>
<li><code>boto</code> to <code>boto3</code> (Python,
<a href="https://boto3.amazonaws.com/v1/documentation/api/latest/index.html">docs</a>):
An extremely prevalent library for accessing AWS services</li>
<li><code>elasticsearch</code> to <code>elasticsearch2</code> (Python, <a href="https://github.com/elastic/elasticsearch-py/issues/515">motivation</a>): A Python client library for the
Elasticsearch search engine.</li>
<li>Every Linux kernel package ever (the Linux kernel has this figured out!). The
Kernel not only prohibits breaking user-space, but they give their users a
great way to install multiple kernels at the same time.</li>
<li>Cassandra’s Thrift API
(<a href="https://github.com/Netflix/Astyanax">Netflix Astyanax</a>)
to Cassandra’s CQL API
(<a href="https://github.com/datastax/java-driver">Datastax Java Driver</a>): The client
drivers for the Cassandra database.</li>
</ul>

<h2 id="reduce-the-fear-binary-versions-can-be-traced-to-source">Reduce the Fear: Binary Versions Can be Traced to Source</h2>

<p>In my experience, software engineers spend a non trivial amount of time trying
to figure out “what actually changed between these two released versions”. One
of the explicit goals of <code>SemVer</code> was to help developers reason about change.
As a developer myself I accidentally break things in minor versions all the
time, so I understand that this can happen. I don’t mind the breakage as much
as being unable to debug what broke, since projects use many different ways of
relating released versions to code.</p>

<p>Some projects do use <a href="https://git-scm.com/book/en/v2/Git-Basics-Tagging">git
tags</a> to achieve this
auditability, but this isn’t mandatory so some (many?) projects don’t do it.
The commit id may, in some cases, be a better identifier since the commit id
must exist and <code>git</code> has a really easy way to view <a href="https://git-scm.com/docs/git-diff">changes between two
commits</a>. In fact, as far as I know, the
commit id is always easily comparable in practically every source control
system.</p>

<p><a href="https://en.wikipedia.org/wiki/Changelog">Changelogs</a> are also <em>nice</em>, but
while I can typically assume projects use source control since it is strictly
easier than not using source control, I don’t think it is reasonable to expect
developers, often working for free, to take the time to summarize their
software changes into English changelogs. Writing clear and actionable English
is difficult, potentially more difficult than the code itself. Certainly, I
appreciate every project maintainer who takes the time to summarize changes in
a release, but I don’t think it’s fair to <em>expect</em> it in the same way most
consumers of software expect producers to use source control.</p>



<p>Both of these problems can be remedied with a straightforward evolution to
<code>SemVer</code> in which we make some small changes to include a great deal more
semantic information in the package name and version number. I call it
semantic package names and it consists of two changes:</p>

<ol>
<li>Use package (=module) names to indicate an API has broken, not versions.</li>
<li>Attempt to include a source identifier in the version.</li>
</ol>

<p>For example, <code>elasicsearch5</code> is the python library that functions with the
Elasticsearch server version 5.  Applications such as Elasticsearch or
Cassandra release named packages that unambiguously communicate the major
version API that is supported by that package. One possible example for Apache
Cassandra might be <code>cassandra-21x</code>, <code>cassandra-30x</code>, <code>cassandra-311x</code>, and
<code>cassandra-40x</code> for the <code>2.1</code>, <code>3.0</code>, <code>3.11</code>, <code>4.0</code> branches respectively.</p>

<p>I know this is not new, many software projects already follow this kind of scheme
such as the Linux kernel (a.k.a “Never break userspace”) or the Go
<a href="https://golang.org/cmd/go/#hdr-Module_compatibility_and_semantic_versioning">programming language</a>.
I just believe that if every software project and language I interacted with
followed this pattern the whole industry would become more efficient and spend
less time fearing dependency updates. I have also found myself using this
technique internally to every company I’ve worked at to manage software change.</p>

<p>In addition to using semantic package names, I prefer when packages include a
fourth piece of metadata in their version number indicating the source version
that produced the artifact. Depending on the packaging system this is usually
either another dotted version (making it a four-tuple) or a <code>-</code> suffix.</p>

<center><h3> Better Semantic Versioning </h3></center>

<div><pre><code data-lang="text">====================== Specification ========================
&lt;Package Version&gt; = &lt;Package Name&gt;:&lt;Version Number&gt;
&lt;Version Number&gt;  = &lt;Major&gt;.&lt;Minor&gt;.&lt;Patch&gt;&lt;Identifier&gt;

Package Name: This name changes when the public API breaks
Major: this number goes up with "major" public API additions
Minor: this number goes up with "minor" public API additions
Patch: this number goes up on every release
Identifier: For packaging systems that support it, this
            string relates directly to a specific source
            code that produced the artifact.

An example of an identifier in git would be the first 8</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jolynch.github.io/posts/semver_considered_harmful/">https://jolynch.github.io/posts/semver_considered_harmful/</a></em></p>]]>
            </description>
            <link>https://jolynch.github.io/posts/semver_considered_harmful/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740913</guid>
            <pubDate>Sun, 05 Jul 2020 18:47:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to start a company without losing all your favorite stuff]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23740752">thread link</a>) | @RobbieStats
<br/>
July 5, 2020 | https://startomatic.com/blog/2020/06/24/how-to-start-a-company-without-maybe-losing-all-your-favorite-stuff-4.html | <a href="https://web.archive.org/web/*/https://startomatic.com/blog/2020/06/24/how-to-start-a-company-without-maybe-losing-all-your-favorite-stuff-4.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      <div>
  <div>
    <div>
      <div>
        <p>
          <span>June 24, 2020</span>
          /
          <span>
            by Andrew Fisher
          </span>
        </p>
        <h3><a href="https://startomatic.com/blog/2020/06/24/how-to-start-a-company-without-maybe-losing-all-your-favorite-stuff-4.html">How to start a company...without maybe losing all your favorite stuff</a></h3>
        <p><em>The TL;DR (“too long, didn’t read”) version: Corporations and LLCs are the best choice for almost all new businesses, and Startomatic can get yours formed with no guesswork and no headaches.</em></p>

<p><strong>Most founders</strong> have some idea of the variety of legal forms that they have to choose from when creating their new company. Who hasn’t heard of a corporation or a limited liability company (LLC)?</p>
<p>Only slightly less recognizable are entities like general partnerships (GPs), limited partnerships (LP’s) , sole proprietorships, and non-profit corporations.</p>
<p>And what about those more “exotic” choices - professional corporations (PCs), professional limited liability companies (PLLCs), and even <em>limited liability limited partnerships</em> (LLLPs) (holy cow)??</p>
<p>As if that’s not enough, where do “C-corporations” and “S-corporations” fit into all of this? Well… they don’t, really. But more on that later…&nbsp;</p>
<p>So any business founder has the right to be confused about choosing an entity type, and it’s no wonder so many feel the safe option is to seek out a business lawyer for solid advice. At Startomatic, we agree that lawyers can be <em>extremely </em>helpful in setting up many types of businesses with large or complex ownership bases, or those that are going to take in professional investment money (think venture capital investments in preferred stock) right after forming.&nbsp;</p>
<p>But <strong>for companies with just a few owners</strong> (somewhere south of 6-8) and a straightforward initial capital structure (all owners get the same type of equity), the best advice is <strong>KISS - Keep It Simple, Startups</strong>.&nbsp;</p>
<p><strong>THE AWESOMENESS OF LIMITED LIABILITY&nbsp;</strong></p>
<p>Your first question might be “why do I need an entity at all (and what the heck is an ‘entity’ anyway)?”&nbsp;</p>
<p><em>Entity </em>is the catch-all term lawyers use to describe corporations, LLCs, and all of the other types of legal business forms described above.&nbsp;&nbsp;</p>
<p>And the best reason for running your business as an entity? It’s because you probably like your car, and your house, and your priceless collection of Pink Floyd on vinyl. If you run your business as an entity, all of those items of personal property are off limits if your new business fails and owes your creditors (landlord, material suppliers, contractors) money. Without an entity between you and your business’s creditors, those creditors can sue you personally and take your records AND your record player.&nbsp;</p>
<p>But if your company is a corporation, LLC or other entity with the legal protection of <strong>limited liability</strong>, those creditors can only go after the assets of the company (in most cases). Your classic Camaro is safe.</p>
<p>Using an entity to run your company has some other benefits as well - it can be easier to get business banking services, buy (or be bought by) another company, and enter into contacts. But the number one reason is the beauty and safety of<em> limited liability</em>.&nbsp;</p>
<p><strong>CORPORATIONS - THE GRANDDADDY OF BUSINESS ENTITIES&nbsp;</strong></p>
<p>Cast your mind way back, so far back that avocado toast wasn’t even a thing yet, and you’ll get to the 1790s. That’s when corporations took off in the U.S., and there’s a reason they’re still the dominant business form for most companies, particularly large ones: <em>there’s no mystery about how corporations work</em>.&nbsp;</p>
<p>Every corporation is owned by its <em>shareholders </em>(or stockholders; the terms are interchangeable), managed by one or more <em>directors </em>(the “Board of Directors” or sometimes just the “Board”), and operated by its <em>officers </em>(President, Secretary, etc.)&nbsp;</p>
<p>For this reason, professional investors (think: venture capitalists) tend to prefer investing in corporations. It’s also possible to grant employees stock options (the ability to buy stock in the corporation in the future) to encourage them to do their best work and to stick around. Stock options just don’t work well in LLCs, for a number of reasons that are WAY too boring to go into here.&nbsp;</p>
<p>On the flip side, the well-defined structure of a corporation makes them less flexible and means there are more corporate “housekeeping” matters to occupy your precious business time and attention. And as always, taxes come into play: a corporation’s earnings may be taxed twice (yikes!), once at the corporation level, and again when earnings are distributed to the shareholders. (But see the discussion on S-corporations, below.)&nbsp;</p>
<p>Here’s the skinny on corporations:</p>
<p><strong>PROS of a Corporation:</strong></p>
<ul><li>Limited liability</li><li>Professional investors generally prefer corporations&nbsp;</li><li>Easy to issue equity incentives (stock or stock options) to employees and others</li></ul>
<p><strong>CONS of a Corporation:&nbsp;</strong></p>
<ul><li>Double taxation (without an S-election; see below)&nbsp;</li><li>Limited flexibility in management&nbsp;</li><li>Generally more complex to manage than an LLC&nbsp;</li></ul>
<p><strong>LLCS - THE CORPORATION’S YOUNGER, WILDER SIBLING&nbsp;</strong></p>
<p>Corporations were almost 200 years old when the limited liability company came onto the business scene in the 1990’s. LLCs are basically state-approved contracts creating companies with the key benefit of limited liability (hence their creative naming) but much more flexibility in management and ownership structure than corporations.&nbsp;</p>
<p>LLCs are owned by their <em>members </em>and are managed either directly by those members or by <em>managers</em>. If compared to corporations, members are similar to shareholders, and managers are like a combination of directors and officers.&nbsp;</p>
<p>The LLC’s major difference from corporations is that the contract governing the LLC (usually called an Operating Agreement or an LLC Agreement) can say pretty much whatever the owners want it to say. So the financial terms of investment, tax allocations, and cash distributions, as well as who makes the management decisions in the company, can be anything the members (owners) agree to.</p>
<p>Perhaps most beneficially, LLCs are usually subject to <strong>pass-through taxation </strong>by the IRS, which means the company’s profits (and losses) are “passed through” directly to the owners - avoiding the corporation’s double taxation issue described above. This is the same way partnerships are taxed.&nbsp;</p>
<p>While the LLC’s flexibility is appealing to some, it has the drawbacks of being unattractive to many investors, and making it so awkward to issue incentive compensation (stock options) that it’s generally not even worth trying.</p>
<p><strong>PROS of an LLC:</strong></p>
<ul><li>Limited liability, just like a corporation&nbsp;</li><li>Single level of taxation usually means tax savings&nbsp;</li><li>Flexibility in financial and management means the owners can decide exactly how they want the business to run&nbsp;</li><li>Fewer time-sucking administrative requirements than corporations</li></ul>
<p><strong>CONS of an LLC:&nbsp;</strong></p>
<ul><li>Professional investors generally prefer corporations&nbsp;</li><li>Nearly impossible to issue equity incentives to employees and others&nbsp;</li></ul>
<p><strong>TAXES ALWAYS COMPLICATE THINGS: THE S-ELECTION&nbsp;</strong></p>
<p>The<em> double taxation</em> problem of corporations does have a solution - but it’s one that comes with significant limitations (of course, darn that IRS…)&nbsp;</p>
<p>An<em> S-corporation</em> isn’t actually a <em>type </em>of corporation at all; it’s just a description of a corporation that has elected with the IRS to be taxed like a partnership. By making this election, the corporation doesn’t pay taxes on its income; instead, the shareholders report and pay taxes on the company’s earnings (and can take the losses) directly on their own tax returns. This is “pass-through” taxation, just like the default taxation of an LLC.&nbsp;</p>
<p>So what are the limits on an S-corporation? They’re pretty significant. An S-corporation:&nbsp;</p>
<ul><li>Can have no more than 100 shareholders&nbsp;</li><li>Can have only one class of stock (so no preferred stock, which is what outside investors usually want)&nbsp;</li><li>Can only have shareholders who are individuals (so no companies can be shareholders, again meaning many investors are shut out)&nbsp;</li><li>All shareholders must be U.S. citizens or lawful permanent residents&nbsp;</li></ul>
<p><em>OK, but then what’s a C-corporation?</em> Easy. It’s just a corporation that has not made an S-election.&nbsp;</p>
<p><strong>Should your <u>corporation </u>make an S-election?&nbsp;</strong></p>
<p><em>Probably yes</em>, if BOTH of the following are true: (a) you meet all of the basic requirements described in the section above, and (b) you don’t intend to raise funds from outside investors in the near term. Keep in mind that you can always change from an S-corporation to a C-corporation in the future - you just have to make a filing with the IRS (and of course there are a few <a href="https://www.irs.gov/forms-pubs/revoking-a-subchapter-s-election" target="_blank">restrictions</a>).&nbsp;</p>
<p><strong>Should your <u>LLC </u>make an S-election?&nbsp;</strong></p>
<p><em>Wait, so an LLC can make an s-election, and choose to be taxed like an S-corporation??</em> We hear you, this is confusing. For now, suffice it to say that there are some very specific circumstances in which an LLC might choose S-corporation taxation - and Startomatic supports that option - but generally speaking LLCs are better off without an S-election. We’ll blog more about this soon and link to it here when we do.</p>
<p><strong>HOW TO CHOOSE: CORPORATION OR LLC&nbsp;</strong></p>
<p>If you’re still unsure, take a look again at the lists of pros and cons above under the corporation and LLC sections. If you meet criteria for either entity and see benefits in each, in our experience the LLC offers more flexibility with less administrative headaches than a corporation, plus the automatic benefit of pass-through taxation, so it’s generally the right choice for new small businesses.&nbsp;&nbsp;</p>
<p><strong>SOLE PROPRIETORSHIPS ARE EASY… AND RISKY&nbsp;</strong></p>
<p>A quick note about <em>sole proprietorships</em>, which you may have heard of. A sole proprietorship is just running your business without an entity. It’s easy, fast, and usually free, but it’s missing the key benefit of limited liability (your classic Camaro isn’t safe any more), and for this reason it’s usually not a good choice.&nbsp;</p>
<p>That said, there are few businesses where the risk is so low that using a sole proprietorship may be a reasonable choice in order to save on filing fees and administrative work of setting up and operating an entity. For that reason, Startomatic will begin offering sole proprietorships in the near future - stay tuned.&nbsp;</p>
<p><strong>S…</strong></p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://startomatic.com/blog/2020/06/24/how-to-start-a-company-without-maybe-losing-all-your-favorite-stuff-4.html">https://startomatic.com/blog/2020/06/24/how-to-start-a-company-without-maybe-losing-all-your-favorite-stuff-4.html</a></em></p>]]>
            </description>
            <link>https://startomatic.com/blog/2020/06/24/how-to-start-a-company-without-maybe-losing-all-your-favorite-stuff-4.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740752</guid>
            <pubDate>Sun, 05 Jul 2020 18:26:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS Lambda Abuse]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23740734">thread link</a>) | @luminousmen
<br/>
July 5, 2020 | https://luminousmen.com/post/aws-lambda-abuse | <a href="https://web.archive.org/web/*/https://luminousmen.com/post/aws-lambda-abuse">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p>I have already written quite a lot about the <a href="https://luminousmen.com/post/how-to-start-your-blog-for-20-cents">serverless approach</a>, the AWS Lambda service in particular, and how I use it for my own personal purposes. In this post, we will walk once again through how AWS Lambda set up and running. We will talk about strategies to mitigate the impact of DDoS attacks (the days of DoS are long gone) and create fail-safe serverless applications. There is very little information on this topic, although it is quite important and most common when discussing AWS security.</p>
<p>P.S. Unfortunately, this post has not been sponsored.</p>
<hr>
<p>Briefly about AWS Lambda. AWS Lambda is an AWS computing service that allows us to run simple functions as FaaS in the cloud. AWS Lambda performs all administration for us, including server and operating system maintenance, resource allocation, automatic scaling, monitoring, and logging. All you have to do is provide code in one of the languages that AWS Lambda supports.</p>
<p>Advantages of using the AWS Lambda:</p>
<ul>
<li><strong>Cost-effective</strong>. You only pay when the service is running(but some services cost a lot).</li>
<li><strong>No ops</strong>. You do not need to manage anything yourself. AWS takes care of the operating system, deployment, scaling, and so on.</li>
<li><strong>Speed</strong>. The lambda itself goes up and runs very fast(but there are overhead on spinning up the runtime).</li>
<li><strong>Scalability</strong>. Functions can be run in parallel with limit depending on the region, from 1000 to 3000 copies maximum. And if you want, this limit can be increased.</li>
</ul>
<p>The work of AWS Lambda is quite simple and clear. The first time a function is called, an instance of a custom function is created, the runtime is created which passes on queries and answers between AWS Lambda and the function code. The function handler is started to handle the event. The source of the event(called trigger) can be a wide variety of things inside the AWS, the most popular triggers for the web I would call AWS CloudFront, AWS API Gateway, and AWS SQS. When the function has processed an event it returns a response and remains active — it waits for the next events to be passed. As more events arrive, the internal AWS Lambda schedulers direct them to the warm(already running) instances if there is one and create new instances as needed. When the number of requests decreases, AWS Lambda stops unused instances to free up the resources for other functions.</p>
<p>The number of instances of functions that serve requests at a given time is called <em>concurrency</em>. And this is essentially horizontal scalability inside the AWS Lambda. When requests arrive faster than your function can scale, or when your function is on the maximum concurrent level, the additional requests fail with the 429 status (too many requests).</p>
<p>In terms of security, each function of AWS Lambda works in its own isolated environment, with its own resources and file system. It stores code on an Amazon S3 and encrypts it at rest.</p>
<p>When you deploy an endpoint that is open to the world, you open it not only for use but also for abuse.</p>
<h2>DDoS 101</h2>
<p><img src="https://iamluminousmen-media.s3.amazonaws.com/media/aws-lambda-abuse/aws-lambda-abuse-2.JPG" alt="DDoS"></p>
<p>Imagine someone who wants to disrupt the bus system. Thousands of people get on the bus at the beginning of the route and ride aimlessly through the city from end to end without leaving at the stops. The transport keeps going, but in fact, the traffic is paralyzed. People are standing at intermediate stops and are sadly watching the crowded buses without being able to push through. People are unable to get home, and the bus company is suffering losses due to low passenger traffic.</p>
<p>This is easy to apply for web applications — basically, an attacker is trying to overload some component of the system to bring it to some critical point after which there will be a system failure, it can be a communication channel, a queue of requests or just an overload of the system handler.</p>
<p><img src="https://iamluminousmen-media.s3.amazonaws.com/media/aws-lambda-abuse/aws-lambda-abuse-3.JPG" alt="DNS DDoS"></p>
<p>Probably the most popular DDoS attack because of its cheapness and difficulty to block it is DNS (Domain Name Server) DDoS. In the DNS DDoS, the attacker tries to overwhelm the capacity of the target's DNS name servers in an attempt to prevent the name server query resolution. Blocking DNS makes the target application or website unavailable to users even if the rest of the infrastructure is running normally. Going back to the bus system analogy, imagine that the buses are running on schedule, they are empty and everything seems fine, but the bus doors just don't open — people just can't get in.</p>
<p>In AWS it is a bit more complicated because, as it has already been said, both management and scaling take place on the AWS side, and therefore control.</p>
<h2>AWS Lambda at scale</h2>
<p>AWS provides services and mechanisms to avoid common abuse methods but often, as with typical DDoS attacks, it doesn't know what traffic is and isn't abusive.</p>
<p>AWS itself is incredibly huge and has many regions, availability zones, and edge locations, which allows to eliminate bad traffic to some extent and absorbs the rest. But it is not enough just to use the lambda function thinking that AWS will do everything for you automatically. You can of course, but in the end, you can get either a broken service or a huge bill or all at once. AWS imposes limits on the number of concurrent handlers, you have to think about where the traffic is coming from, how DNS resolves, and if you use any external AWS services it sometimes makes sense to migrate them all inside AWS for more complete control. Services such as AWS Route53 and AWS CloudFront which allow you to take advantage of the variety of internal AWS infrastructure — which itself is built quite interestingly.</p>
<p><img src="https://iamluminousmen-media.s3.amazonaws.com/media/aws-lambda-abuse-1.JPG" alt="AWS"></p>
<p>I tried to illustrate an example of incoming traffic to lambda service located in one region. As you can see, there are many steps before you get to the lambda itself. It all starts with a DNS resolution of a record on one of the name servers in AWS Route53(this is the service that is responsible for name resolution and stuff) that is intentionally hosted on the edge locations so that clients from different networks and locations have their own quick way to the service while having more than one path in case of localized outages. Also, there is AWS CloudFront (you can use Lambda@Edge option in lambda) on the edge locations — it is a content delivery network for delivery of all static and dynamic content, which allows users not to go directly to the function if it is not necessary. So Route 53 can assign different users to the closest AWS CloudFront instances (which can already be in the same edge location) which can already have the necessary content. Sounds great, right?</p>
<p>An example of how it works step by step:</p>
<ul>
<li>When the request is sent by the user, the DNS resolves at the user's closest edge location where AWS Route 53 is located.</li>
<li>Route 53 forwards the request to the nearest edge location where AWS CloudFront is located.</li>
<li>Then, there can be two possibilities i.e. whether files requested are in cache or not. If files are in the cache then CloudFront returns them.</li>
<li>CloudFront compares the specifications in your distribution with the request. Then trigger the AWS Lambda function with the user request.</li>
<li>The origin server sends the requested files to the CloudFront edge location.</li>
<li>When the first byte of the requested files arrives, CloudFront starts sending the files to the user.</li>
<li>It also saves the files to the internal cache of CloudFront(for specified TTL) so they could be accessed easily in the future if the same or another user requests them.</li>
</ul>
<p>You can of course use the API Gateway in an edge-optimized mode in front of your API for about the same purposes (caching and function trigger). However, this is likely to be more expensive, the API Gateway charges for the size of the cache per hour, CloudFront charges per request, and data transfer. But of course, everything depends on the specific architecture, purpose and workload.</p>
<p>The API Gateway is essentially a proxy server that the user is accessing, and this proxy server is calling the lambda. Typically, the API Gateway can also do SSL certificate processing, load balancing, authorization and authentication, caching, request content compression. But it's not that effective under abuse as CloudFront.</p>
<h2>How to mitigate the impact</h2>
<p>As always, this requires a multi-level approach and everything depends very much on the specific architecture, the workflow, and of course the budget.</p>
<h3>Check your code</h3>
<p>Let's start with the dumbest and traditionally most effective method. Make sure your code does not "hang" on unexpected input. You should carefully check all edge cases and think about possible inputs that may cause function timeouts, <a href="https://en.wikipedia.org/wiki/ReDoS">ReDoS attacks</a>, or long payloads. An attacker may take advantage of this weakness.</p>
<h3>Configure alerts</h3>
<p>Another incredibly brilliant idea if you don't want to get a huge bill at some point — set up the billing alerts. It's very easy and fast to set up (it's better to do it through AWS Budgets than through AWS SNS and AWS Cloudwatch), but it's very useful — you will be informed in case of a problem.</p>
<p>Also, I would advise making limits on billing. Of course, everything depends on the specific business task of the service and maybe it's better to overpay, but have a working endpoint.</p>
<h3>Use throttling(reserved concurrency)</h3>
<p>We have already found out that the AWS Lambda provides multiple instances running concurrently to scale functions, but if you have several Lambda functions running at the same time and one of them is under abuse, the resources of other functions may be exhausted because of it. The AWS Lambda has a default limit on the number of concurrent executions per account per region. And if your functions exceed this limit, additional user requests will be throttled by AWS with 429 status as it was described earlier.</p>
<p>But the concurrency level can be set on per-function bases. Besides AWS Lambda, the API Gateway supports throttling as well. The defaults are reasonable, but you can alter them however you like. For example, you can allow 5 calls per second if it makes sense for your application, after which the API Gateway will block additional …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://luminousmen.com/post/aws-lambda-abuse">https://luminousmen.com/post/aws-lambda-abuse</a></em></p>]]>
            </description>
            <link>https://luminousmen.com/post/aws-lambda-abuse</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740734</guid>
            <pubDate>Sun, 05 Jul 2020 18:23:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Purpose of Persuasion]]>
            </title>
            <description>
<![CDATA[
Score 78 | Comments 40 (<a href="https://news.ycombinator.com/item?id=23740669">thread link</a>) | @apsec112
<br/>
July 5, 2020 | https://www.persuasion.community/p/the-purpose-of-persuasion | <a href="https://web.archive.org/web/*/https://www.persuasion.community/p/the-purpose-of-persuasion">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a target="_blank" href="https://cdn.substack.com/image/fetch/c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F76311586-b35a-4d2b-82b1-d8a8b6ca9b18_4522x3019.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F76311586-b35a-4d2b-82b1-d8a8b6ca9b18_4522x3019.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/76311586-b35a-4d2b-82b1-d8a8b6ca9b18_4522x3019.jpeg&quot;,&quot;height&quot;:972,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:6649732,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p>Friends,</p><p>I'm floored by the response of the past three days.</p><p>Once I hit <em>send</em>, this article will land in the inboxes of over 15,000 people. When we launched, my main fear was that the world would not be interested in a community that pledges to defend the values of a free society; now, my main fear is that we won't be able to live up to the hype.</p><p>So, here's my promise: We will do our very best to earn your trust. Some great articles will be coming your way soon. We are getting ready to announce more events and high-level members of the community. I hope you will join us for our inaugural townhall, which will take place next Sunday, July 12th, at 4pm EST. (Watch this space for the invite.) I'm very, very excited about what lies ahead. But I also know that it is hard to build this kind of community from the ground up, and that we will undoubtedly make mistakes along the way. Please bear with us when we do.</p><p>In the meanwhile, I want to take you a little deeper into the thinking that went into creating <em>Persuasion</em>. Why this project? Why now? And how can just a bunch of us—even if we are a much larger bunch than I could possibly have dreamed a few days ago—really make a difference to the future of free societies in the United States and around the world? The key to an answer lies in a short (and necessarily schematic) history of American intellectual life over the past half century. </p><p>Fifty years ago, the most important American institutions enjoyed a degree of legitimacy that is now hard to fathom. Nearly every American watched the news on one of the three network television stations. Nearly every American had a positive opinion of Princeton and Stanford. Nearly every Member of Congress believed that the advice of the Brookings Institution or the Council on Foreign Relations was to be taken seriously.&nbsp;</p><p>These institutions had much to recommend them: They gave the public a shared set of facts and assumptions, which could form the basis of political debate. And, though they never thought of their primary goal as fighting for the ideals of a free society, their operating system was philosophically liberal: From CBS to Harvard to Brookings, senior decision makers instinctively believed in values like free speech and due process.</p><p>However, these institutions also suffered from two important shortcomings. First, the people they admitted into their gilded halls only represented a small slice of America's population: sexism, racism and homophobia were <em>far</em> more prevalent in these institutions than they are today. The views they considered serious sometimes included the morally abhorrent.&nbsp;</p><p>Second, the realm of the “reasonable" was rather narrow. And, though this narrowness of debate constituted the lesser injustice, it was—at least in the short term—the cause of greater instability: Having come to believe that they could never quite speak in their own voices in the halls of the Brookings Institution or the column inches of the <em>New York Times</em>, a few assorted bands of malcontents started to cast around for an alternative. </p><p>Of these, the group that had the biggest impact on public life in America was a band of devoted conservatives, determined to create an ideological counter-establishment that could rival the mainstream.&nbsp;What started with <em>National Review</em>, an ideological fighting magazine, quickly grew into a sprawling and immensely powerful network of conservative institutions. The Heritage Foundation was set up to rival the influence of Brookings. The Federalist Society sought to change the ideological composition of America's judiciary. Fox News did its dismal best to spread the ideas of the conservative movement beyond the Beltway. A whole network of activist groups provided conservatives with an ideological foundation, a group of friends, and a professional home. Measured by its own ambitions,&nbsp;the movement was a staggering success.</p><p>Other minoritarian ideological movements took a page out of the same playbook. In 1960, a libertarian was a person with idiosyncratic views and no obvious political home. Then, the Institute for Humane Studies started to advocate libertarian ideas on college campuses, <em>Reason </em>took up their public defense, and a reinvigorated American Enterprise Institute set out to influence legislators on Capitol Hill. By 1980, the influence and intellectual self-confidence of libertarians had increased enormously.</p><p>The further left has always had its share of counter-establishment institutions. <em>The Nation</em>, after all, is one of the oldest magazines in the country, and some academic disciplines have long been at the forefront of leftist thought. But the left, too, has of late succeeded in building a more cohesive network of fighting institutions, as universities have become much more progressive, movements like the Democratic Socialists of America have awakened from decades of peaceful slumber, and publications like <em>Jacobin </em>have infused the movement with fresh intellectual energy.</p><p>Five or ten years ago, our potted history might have concluded here. Ideological movements from conservative to libertarian to leftist had fighting institutions of their own. Though philosophical liberals did not have a comparable home, they could confidently express their views within mainstream institutions.&nbsp;</p><p>But then those institutions started to change.</p><p>The story of that change has attracted an immense amount of attention over the past months. I won't bore you with a detailed recap of its most worrying manifestations, from the firing of James Bennet to the uncritical celebration of Robin DiAngelo. Nor do I want to suggest that these changes have completely delegitimized the mainstream: These institutions have not yet become wholly illiberal, and the advocates of a free society would be foolish to stop fighting for them.</p><p>But the erosion of values like free speech and due process within mainstream institutions does put philosophical liberals at a unique disadvantage. It is difficult to convey just how many amazing writers, journalists, and think-tankers—some young and some old, some relatively obscure and others very famous—have privately told me that they can no longer write in their own voices; that they are counting the days until they get fired; and that they don't know where to turn if they do. (Astonishingly, a number of them are far enough to the left to have supported Bernie Sanders in the primaries.)</p><p>This, to me, is a huge part of the reason why the defenders of the free society have seemed to lack conviction in recent months and years. Feeling, at best, begrudgingly tolerated by the institutions that employ them, they are always on the back foot: writing and speaking with one eye on Twitter, one eye on a hostile editor, and one eye on the attacks being shared on their own company’s Slack channel. (As you may have noticed, that requires too many eyes.)</p><p>But, if this situation helps to explain the collective lack of confidence among the advocates of a free society, it also points the way to an obvious solution. <strong>Instead of lamenting our loss of control over the establishment, we should follow the lead of other movements that have successfully built their own counter-establishment institutions.</strong><em>&nbsp;</em></p><p><em>That </em>is the goal I had in mind in starting <em>Persuasion</em>.</p><p>One core element of this project is a publishing platform explicitly devoted to debating, articulating, and defending the values of a free society. Emulating what <em>Reason</em>, <em>Jacobin,</em> and the <em>National Review</em> have accomplished within their own ideological traditions, I hope to create a space in which philosophical liberals can ask hard questions and come up with compelling answers. This requires both a commitment to a set of shared aspirations and enough diversity of opinion to force us to think very hard about how we can make the world a better place. This is a space for people who are open to changing their minds, but not their fundamental values.</p><p>But creating a modern reinvention of a fighting magazine, devoted to defending the ideals of a free society, is not my only ambition. If places like the <em>National Review</em> had a tremendous influence on our society, it is also because they became the nucleus of a cohesive community, which seeded a much wider archipelago of allied institutions. This is why I take the community element of <em>Persuasion</em>—all the live events, book clubs and social gatherings we'll experiment with over the coming months—so seriously. And it is also why I hope that this particular venture will spawn many formally independent organizations that share our founding values.</p><p>Before I close, let me say two quick words about some of the establishment institutions whose recent fate I have been lamenting. The first is that we must do what we can to preserve those universities, publications, and think tanks that still operate with fundamentally (small l) liberal assumptions. For example, I deeply love <em>The Atlantic</em>, and will continue to write for it. A small fighting institution that primarily addresses a devoted crowd of philosophical liberals neither is nor should be in competition with a large general interest magazine whose readership will always span a much broader ideological range. Part of the reason why we should articulate these values as clearly, forcefully, and persuasively as possible within these pages is to maximize the likelihood that they will continue to form the implicit operating system of vitally important publications like <em>The Atlantic</em>.&nbsp;</p><p>The second thing is that our ambition needs to extend beyond nostalgia. There is much to lament about the changes that have taken place in some of the country's most important institutions over the past years. But there is also much to criticize in what these institutions looked like at their supposed best. Our goal is not to return to a golden age that has, sadly, never existed; it is to build societies that live up to the noble and ambitious values of freedom and justice better than any society of the past.</p><p>The examples I have used here&nbsp;are very …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.persuasion.community/p/the-purpose-of-persuasion">https://www.persuasion.community/p/the-purpose-of-persuasion</a></em></p>]]>
            </description>
            <link>https://www.persuasion.community/p/the-purpose-of-persuasion</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740669</guid>
            <pubDate>Sun, 05 Jul 2020 18:16:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Deep Introduction to JIT Compilers: JITs are not very Just-in-time]]>
            </title>
            <description>
<![CDATA[
Score 278 | Comments 89 (<a href="https://news.ycombinator.com/item?id=23740655">thread link</a>) | @chrisseaton
<br/>
July 5, 2020 | https://carolchen.me/blog/jits-intro/ | <a href="https://web.archive.org/web/*/https://carolchen.me/blog/jits-intro/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  <header>
    
    
  </header>

  <main id="main">
    
<article>
  <header>
    
    
  </header>
  <section id="js-article">
    
<p><em>If you are familiar with how JITs generally work (if you get what the title is referring to), I recommend skimming this or going straight to reading <a href="https://carolchen.me/blog/jits-impls">How JIT Compilers are Implemented and Fast: Julia, Pypy, LuaJIT, Graal and More</a></em> </p>
<p>My mentor, <a href="https://chrisseaton.com/">Chris</a>, who took me from “what is a JIT” to where I am now once told me that compilers were just bytes in bytes out and not at all low-level and scary. This is actually fairly true, and it's fun to learn about compiler internals and often useful for programmers everywhere!</p>
<p>This blog post gives background on how programming languages are implemented and how JITs work. It'll introduce the implementation details of the Julia language, though it won't talk about specific implementation details or optimizations made by more traditional JITs. Check out <a href="https://carolchen.me/blog/jits-impls">How JIT Compilers are Implemented and Fast: Julia, Pypy, LuaJIT, Graal and More</a> to read about how meta-tracing is implemented, how Graal supports C extensions, the relationship of JITs with LLVM and more!</p>
<h2 id="how-programming-languages-are-implemented">How Programming Languages are Implemented<a href="#how-programming-languages-are-implemented" aria-label="Anchor link for: how-programming-languages-are-implemented"> <i></i></a>
</h2>
<p>When we run a program, it’s either interpreted or compiled in some way. The compiler/interpreter is sometimes referred to as the "implementation" of a language, and one language can have many implementations. You may have heard things like "Python is interpreted", but that really means the reference(standard/default) implementation of Python is an interpreter. Python is a language specification and <em>CPython</em> is the interpreter and implementation of Python. </p>
<p>An interpreter is a program that directly executes your code. Well-known interpreters are usually written in C. Ruby, Python and PHP are written in C. Below is a function that loosely models how an interpreter might work:</p>
<pre><code><span>func </span><span>interpret</span><span>(</span><span>code </span><span>string</span><span>) {
  </span><span>if </span><span>code </span><span>== </span><span>"print('Hello, World!')" </span><span>{
    </span><span>print</span><span>(</span><span>"Hello, World"</span><span>);
  } </span><span>else if </span><span>code </span><span>==</span><span> “</span><span>x </span><span>= </span><span>0</span><span>; </span><span>x </span><span>+= </span><span>4</span><span>; </span><span>print</span><span>(</span><span>x</span><span>)” {
    variable_x </span><span>:= </span><span>0 
    </span><span>variable_x </span><span>+= </span><span>4
    </span><span>print</span><span>(</span><span>x</span><span>)
  }
}
</span></code></pre>
<p>A compiler is a program that translates code from some language to another language, though it usually refers to a destination language that is a machine code. Examples of compiled languages are C, Go and Rust.</p>
<pre><code><span>func </span><span>compile</span><span>(</span><span>code </span><span>string</span><span>) {
  []</span><span>byte </span><span>compiled_code </span><span>= </span><span>get_machine_code</span><span>(</span><span>code</span><span>);
  </span><span>write_to_executable</span><span>(</span><span>compiled_code</span><span>);
}
</span></code></pre>
<p>The difference between a compiled and interpreted language is actually much more nuanced. C, Go and Rust are clearly compiled, as they output a machine code file - which can be understood natively by the computer. The compile and run steps are fully distinct.</p>
<p>However, compilers can translate to any target language (this is sometimes called transpiling). Java for example, has a two-step implementation. The first is compiling Java source to bytecode, which is an Intermediate Representation (IR). The bytecode is then JIT compiled - which involves interpretation.</p>
<p>Python and Ruby also execute in two steps. Despite being known as interpreted languages, their reference implementations actually compile the source down to a bytecode. You may have seen .pyc files (not anymore in Python3) which contain Python bytecode! The bytecode is then interpreted by a virtual machine. These interpreters use bytecode because programmers tend to care less about compile time, and creating a bytecode language allows the engineers to specify a bytecode that is as efficient to interpret as possible. </p>
<p>Having bytecode is how languages check syntax before execution (though they could technically just do a pass before starting the interpreter). An example below shows why you would want to check syntax before runtime.</p>
<pre><code><span>sleep</span><span>(</span><span>1000</span><span>)
bad syntax beep boop beep boop
</span></code></pre>
<p>Another important note is that interpreted languages are typically slower for various reasons, the most obvious being that they're executed in a higher level language that has overhead execution time. The main reason is that the dynamic-ness of the languages they tend to implement means that they need many extra instructions to decide what to do next and how to route data. People still choose to build interpreters over compilers because they're easier to build and are more suited to handle things like dynamic typing, scopes etc (though you could build a compiler that has the same features). </p>
<h3 id="so-what-is-a-jit">So What is a JIT?<a href="#so-what-is-a-jit" aria-label="Anchor link for: so-what-is-a-jit"> <i></i></a>
</h3>
<p>A JIT compiler doesn't compile code Ahead-Of-Time (AOT), but still compiles source code to machine code and therefore is not an interpreter. JITs compile code at runtime, while your program is executing. This gives the JITs flexibility for dynamic language features, while maintaining speed from optimized machine code output. JIT-compiling C would make it slower as we'd just be adding the compilation time to the execution time. JIT-compiling Python would be fast, as compilation + executing machine code can often be faster than interpreting, especially since the JIT has no need to write to a file (disk writing is expensive, memory/RAM/register writing is fast). JITs also improve in speed by being able to optimize on information that is only available at runtime.</p>
<h3 id="julia-a-jit-compiler-that-s-just-in-time">Julia: a JIT Compiler that's Just-in-time<a href="#julia-a-jit-compiler-that-s-just-in-time" aria-label="Anchor link for: julia-a-jit-compiler-that-s-just-in-time"> <i></i></a>
</h3>
<p>A common theme between compiled languages is that they're statically typed. That means when the programmer creates or uses a value, they’re telling the computer what type it is and that information is guaranteed at compile time.</p>
<p>Julia is dynamically typed, but internally Julia is much closer to being statically typed.</p>
<pre><code><span>function </span><span>multiply</span><span>(x, y)
  x </span><span>*</span><span> y
</span><span>end
</span></code></pre>
<p>Here is an example of a Julia function, which could be used to multiply integers, floats, vectors, strings etc (Julia allows operator overloading). Compiling out the machine code for <em>all</em> these cases is not very productive for a variety of reasons, which is what we'd have to do if we wanted Julia to be a compiled language. Idiomatic programming means that the function will probably only be used by a few combinations of types and we don't want to compile something that we don't use yet since that's not very jitty (this is not a real term).</p>
<p>If I were to code <code>multiply(1, 2)</code>, then Julia will compile a function that multiplies integers. If I then wrote <code>multiply(2, 3)</code>, then the already-compiled code will be used. If I then added <code>multiply(1.4, 4)</code>, another version of the function will be compiled. We can observe what the compilation does with <code>@code_llvm multiply(1, 1)</code>, which generates LLVM Bitcode (not quite machine code, but a lower-level Intermediate Representation).</p>
<pre><code><span>define i64 @julia_multiply_17232(i64, i64) {
top</span><span>:</span><span>
; ┌ @ int</span><span>.</span><span>jl</span><span>:</span><span>54</span><span> within `*'
   </span><span>%</span><span>2 </span><span>=</span><span> mul i64 </span><span>%</span><span>1</span><span>, </span><span>%</span><span>0</span><span>
; └
  ret i64 </span><span>%</span><span>2</span><span>
}
</span></code></pre>
<p>And with <code>multiply(1.4, 4)</code>, you can see how complicated it can get to compile even one more function. In AOT compiled Julia, all (some optimizations can be made to reduce) of these combinations would have to live in the compiled code even if only one was used, along with the control flow to delegate. </p>
<pre><code><span>define double @julia_multiply_17042(double, i64) {
top</span><span>:</span><span>
; ┌ @ promotion</span><span>.</span><span>jl</span><span>:</span><span>312</span><span> within `*'
; │┌ @ promotion</span><span>.</span><span>jl</span><span>:</span><span>282</span><span> within `promote'
; ││┌ @ promotion</span><span>.</span><span>jl</span><span>:</span><span>259</span><span> within `_promote'
; │││┌ @ number</span><span>.</span><span>jl</span><span>:</span><span>7</span><span> within `convert'
; ││││┌ @ float</span><span>.</span><span>jl</span><span>:</span><span>60</span><span> within `</span><span>Float64</span><span>'
       </span><span>%</span><span>2 </span><span>=</span><span> sitofp i64 </span><span>%</span><span>1</span><span> to double
; │└└└└
; │ @ promotion</span><span>.</span><span>jl</span><span>:</span><span>312</span><span> within `*' @ float</span><span>.</span><span>jl</span><span>:</span><span>405
   </span><span>%</span><span>3 </span><span>=</span><span> fmul double </span><span>%</span><span>2</span><span>, </span><span>%</span><span>0</span><span>
; └
  ret double </span><span>%</span><span>3</span><span>
}
</span></code></pre>
<p>The general strategy of “assume a type and compile/behave based on that” is called type inferencing, which Julia mildly uses in the examples above. There are a lot of other compiler optimizations that are made, though none of them are very specific to JITs as Julia may be better described as a lazy AOT compiler.</p>
<p>The simplicity of this kind of jitting makes it easy for Julia to also supply AOT compilation. It also helps Julia to benchmark very well, definitely a tier above languages like Python and comparable to C (I'd cite numbers, but those are always nuanced and I don't want to get into that).</p>
<h3 id="so-what-is-a-jit-take-two">So What is a JIT? Take Two.<a href="#so-what-is-a-jit-take-two" aria-label="Anchor link for: so-what-is-a-jit-take-two"> <i></i></a>
</h3>
<p>Julia is actually the jittiest JIT I'll discuss, but not the most interesting as a "JIT". It actually compiles code right before the code needs to be used -- just in time. Most JITs however (Pypy, Java, JS Engines), are not actually about compiling code just-in-time, but compiling <em>optimal code</em> at an optimal time. In some cases that time is actually never. In other cases, compilation occurs more than once. In a vast majority of the cases compilation doesn't occur until after the source code has been executed numerous times, and the JIT will stay in an interpreter as the overhead to compilation is too high to be valuable.</p>
<p><img src="https://carolchen.me/blog/img/jits/jitbrr.jpg" alt=""></p>
<p>The other aspect at play is generating <em>optimal code</em>. Assembly instructions are not created equal, and compilers will put a lot of effort into generating well-optimized machine code. Usually, it is possible for a human to write better assembly than a compiler (though it would take a fairly smart and knowledgeable human), because the compiler cannot dynamically analyze your code. By that, I mean things like knowing the possible range of your integers or what keys are in your map, as these are things that a computer could only know after (partially) executing your program. A JIT compiler can actually do those things because it interprets your code first and gathers data from the execution. Thus, JITs are expensive in that they interpret, and add compilation time to execution time, but they make it up in highly optimised compiled code. With that, the timing of compilation is also dependent on whether the JIT has gathered enough valuable information.</p>
<p>The cool part about JITs is that I was sort of lying when I said a JIT implementation of C could not be faster than existing compiled implementations. It would not be feasible to try, but jit-compiling C in the way I just described is not a strict superset of compiling a language and thus it is not logically impossible to compile code fast enough to make up for the compile+profile+interpreting time. If I "JIT compiled" C similarly to how Julia does it (statically compile each function as it's called), it would be impossible to …</p></section></article></main></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://carolchen.me/blog/jits-intro/">https://carolchen.me/blog/jits-intro/</a></em></p>]]>
            </description>
            <link>https://carolchen.me/blog/jits-intro/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740655</guid>
            <pubDate>Sun, 05 Jul 2020 18:14:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Multiple Dispatch in Julia]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 8 (<a href="https://news.ycombinator.com/item?id=23740622">thread link</a>) | @wikunia
<br/>
July 5, 2020 | https://opensourc.es/blog/basics-multiple-dispatch/ | <a href="https://web.archive.org/web/*/https://opensourc.es/blog/basics-multiple-dispatch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>From time to time I hear that my posts are a little bit too deep and complicated for beginners. I totally agree: especially in my newest series on <a href="https://opensourc.es/blog/constraint-solver-1">"How to build a constraint solver from scratch?"</a> which is probably a never ending series. I do like to blog about it and will continue but this series is different.</p>
<p>Julia is a relatively young language and not too many people are using it. It thrives in scientific computing but I believe that it can be used for general computing (probably where start up time is not that relevant) i.e. I do use it for creating this blog with <a href="https://franklinjl.org/">Franklin</a> which I blogged a bit about as well <a href="https://opensourc.es/blog/Franklin.jl">here</a>.</p>
<p>This series tries to explain some of the core concepts of Julia and maybe some packages to beginners. I, the explainer of this stuff here, am by no means an expert in any of these. If you know this blog then you might know that I'm trying to explain stuff directly after I've learned them to hopefully be able to communicate better than some people who do this their entire life and are experts in it. Blogs from experts are sometimes hard to follow for me, so maybe also for you. I'll let them proof read my blog post just to be sure that there is nothing wrong with what I explain ;)</p>
<p>Posts in this series can be reached over the side bar. </p>
<p>Post 2: <a href="https://opensourc.es/blog/basics-repl-revise">REPL &amp; Revise</a></p>
<p>Okay everyone ready?</p>

<h2 id="what_is_dispatch"><a href="#what_is_dispatch">What is dispatch?</a></h2>
<p>In every programming language there are <code>functions</code> which have the purpose of providing structure and reusability of code. The functions have a <code>name</code> and some <code>arguments</code>.  They are defined like</p>
<pre><code>def add(x, y):
    return x + y</code></pre>
<p>In Python this can be called with <code>add(2,3)</code> which gives the expected <code>5</code> but also <code>add("2","3")</code> gives <code>'23'</code> which might make sense or not depending on who you ask :D</p>
<p>Now how about <code>add("2", 3)</code> ?</p>
<p>This results in an error <code>TypeError: can only concatenate str (not "int") to str</code> which again can make sense. Well I would say it does but Javascript does something different:</p>
<pre><code>function add(x,y) {
    return x+y
}</code></pre>
<p>will produce <code>"23"</code> for that.</p>
<p>Then there are of course languages like <code>C++</code> where this all is not that simple because we need to introduce types:</p>
<pre><code>int add(int x, int y) {
  return x+y;
}</code></pre>
<p>There it is clear for everyone that it takes two <code>int</code> and returns one <code>int</code>. Because it is a compiled language we would get an error directly when trying to call it with <code>add("2", 3)</code>.</p>
<p>Now what is the point? We can see different concepts here with having static types as in C++ and dynamic typing in JS and Python. They both have pros and cons which is probably obvious.  The one is easier to reason about and the others are maybe easier to hack around with.</p>
<p>Let's go into dispatching on those three languages:</p>
<p>In Python it is: Ah okay the user wants to call <code>add</code>:</p>
<ul>
<li><p>We have the <code>add</code> function</p>
</li>
<li><p>Lets call it with the arguments.</p>
</li>
<li><p>Good that works as it expects two arguments and we have two.</p>
</li>
</ul>
<p>Then we might get to the point where the function doesn't work like for <code>add("2", 3)</code> and throw an error or it works out and the answer is returned. </p>
<p>It is basically the same in JS. There are possibility some "extensions" like Typescript where things might happen differently. I haven't programmed with any of those languages lately so keep that in mind.</p>
<p>In <code>C++</code> more things are going on as each variable has a static type and one can check directly whether this fits or not. This means as we can later see that there can be more functions with the same name. I'll explain the difference between function overloading and multiple dispatch in that part ;)</p>
<p>In all of these languages we can have classes such that we might have a class <code>Manufacturer</code> and we can define <code>add(self, thing)</code> or something like that and can call the function with  <code>manufacturer.add(thing)</code>. This can be kind of seen as single dispatch. Dispatch is basically the process of deciding which function to call. Here it depends on the type of <code>manufacturer</code>. Is it a <code>Manufacturer</code> or a <code>Box</code>? For a <code>Box</code> we might have defined a class <code>Box</code> and <code>add(self, box)</code> inside of it.</p>
<div><p>⚠ Note</p> <p>These examples are more from the Python world but hopefully convey the point.</p></div>
<p>For people coding in Julia for longer this might sound like a weird concept. Actually writing about it, I am thinking: How would I do some things, where I use multiple dispatch all the time (like in the ConstraintSolver) in one of those languages?</p>
<p>Before I explain multiple dispatch I want to note:</p>
<p>Yes there are ways in Python for single dispatching like <a href="https://www.blog.pythonlibrary.org/2016/02/23/python-3-function-overloading-with-singledispatch/">@singledispatch</a> but given that the main posts I found when searching are 3-4 years old I doubt that a lot are using it :D</p>
<p>And it is still single dispatch.</p>
<h2 id="how_does_dispatch_work_in_julia"><a href="#how_does_dispatch_work_in_julia">How does dispatch work in Julia?</a></h2>
<p>Now that there is that out of our way let us have a look at one example in Julia:</p>
<pre><code>add(x, y) = x+y</code></pre>
<p>just to show a neat little way of defining one-line functions... (or as they are called in Julia: Methods)</p>
<p>The interesting things is when you type this in the Julia REPL (Read-eval-print loop) you get:</p>
<pre><code>julia&gt; add(x, y) = x+y
add (generic function with 1 method)</code></pre>
<p>calling that function works basically like in Python (from the user perspective for now). It doesn't work for strings though.</p>
<div><p>⚠ Note</p> <p>Julia and <code>+</code> for strings: Julia is a mathematical language and <code>+</code> is commutative whereas concatenating strings is not. So <code>"2"+"3"</code> is not <code>"3"+"2"</code>. Therefore Julia decided to use <code>*</code> instead. Which is commutative for numbers but not matrices for example.</p></div>
<p>Okay where did I interrupt myself? ... Ah yeah so we have an <code>add</code> function with one method now in the REPL. That looks like we might be able to add a new one, right?</p>
<div><p>⚠ Note</p> <p>As correctly pointed out on <a href="https://www.reddit.com/r/Julia/comments/hfk3u3/basics_multiple_dispatch_start_of_a_new_series/fvykyl3?utm_source=share&amp;utm_medium=web2x">Reddit</a>: I use mostly the word function. In Julia there is actually a difference between functions and methods. There is one <code>+</code> function with a lot of different implementations: called methods.</p></div>
<pre><code>julia&gt; add(x,y) = 2x+y
add (generic function with 1 method)</code></pre>
<p>okay that did not work because it still allows all types of inputs (and throws an error later when it doesn't work) because the compiler had no way to decide which <strike> function</strike>method to call. </p>
<p>Should it guess? It just overwrites the old method.</p>
<p>A small side step again: Let's check what happens when we call <code>add("2", "3")</code>
</p><pre><code>julia&gt; add("a", "b")
ERROR: MethodError: no method matching *(::Int64, ::String)
Closest candidates are:
  *(::Any, ::Any, ::Any, ::Any...) at operators.jl:529
  *(::Missing, ::AbstractString) at missing.jl:174
  *(::T, ::T) where T&lt;:Union{Int128, Int16, Int32, Int64, Int8, UInt128, UInt16, UInt32, UInt64, UInt8} at int.jl:54
  ...
Stacktrace:
 [1] add(::String, ::String) at ./REPL[3]:1
 [2] top-level scope at REPL[4]:1</code></pre>
<p>That error occurs when calling <code>2x</code> where it figured that <code>2</code> is an integer and <code>x = "2"</code> is a string. It gives us information of what kind of types it can multiply.</p>
<p>Let's pick one: </p><pre><code>*(::T, ::T) where T&lt;:Union{Int128, Int16, Int32, Int64, Int8, UInt128, UInt16, UInt32, UInt64, UInt8} at int.jl:54</code></pre>
<p>This tells us that we can multiply two numbers of those types when they are the same. So <code>UInt8</code> with <code>UInt8</code> but I come to that syntax later.</p>
<p>You might wonder how many of those <code>*</code> <strike> functions</strike>methods there are: <code>357</code> is the answer which you get when typing</p>
<pre><code>julia&gt; methods(*)
...</code></pre>
<p>which gives you a long list with all kind of weird types where it sometimes spreads over several lines. I mean what is this? :D</p>
<pre><code>[345] *(A::LinearAlgebra.LQ{TA,S} where S&lt;:AbstractArray{TA,2}, B::Union{DenseArray{TB,1}, DenseArray{TB,2}, Base.ReinterpretArray{TB,1,S,A} where S where A&lt;:Union{SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray}, Base.ReinterpretArray{TB,2,S,A} where S where A&lt;:Union{SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray}, Base.ReshapedArray{TB,1,A,MI} where MI&lt;:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A&lt;:Union{Base.ReinterpretArray{T,N,S,A} where S where A&lt;:Union{SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray} where N where T, SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray}, Base.ReshapedArray{TB,2,A,MI} where MI&lt;:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A&lt;:Union{Base.ReinterpretArray{T,N,S,A} where S where A&lt;:Union{SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray} where N where T, SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray}, SubArray{TB,1,A,I,L} where L where I&lt;:Tuple{Vararg{Union{Int64, AbstractRange{Int64}, Base.AbstractCartesianIndex},N} where N} where A&lt;:Union{Base.ReinterpretArray{T,N,S,A} where S where A&lt;:Union{SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray} where N where T, Base.ReshapedArray{T,N,A,MI} where MI&lt;:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A&lt;:Union{Base.ReinterpretArray{T,N,S,A} where S where A&lt;:Union{SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray} where N where T, SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray} where N where T, DenseArray}, SubArray{TB,2,A,I,L} where L where I&lt;:Tuple{Vararg{Union{Int64, AbstractRange{Int64}, Base.AbstractCartesianIndex},N} where N} where A&lt;:Union{Base.ReinterpretArray{T,N,S,A} where S where A&lt;:Union{SubArra…</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://opensourc.es/blog/basics-multiple-dispatch/">https://opensourc.es/blog/basics-multiple-dispatch/</a></em></p>]]>
            </description>
            <link>https://opensourc.es/blog/basics-multiple-dispatch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740622</guid>
            <pubDate>Sun, 05 Jul 2020 18:10:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Get Used to Failure (2018)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23740513">thread link</a>) | @mooreds
<br/>
July 5, 2020 | https://letterstoanewdeveloper.com/2018/12/31/get-used-to-failure/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/2018/12/31/get-used-to-failure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>Dear new developer,</p>
<p>I was chatting with someone <a href="https://letterstoanewdeveloper.com/2018/10/24/join-a-meetup/">I met at a meetup</a> who was about to graduate from a bootcamp. I asked him what his advice to a new developer would be. He said that it would be “get used to failure, and get used to working through it.”</p>
<p>I thought that advice was great.</p>
<p>I often tell colleagues that “if it is easy, someone would have already automated it”. This means that when you are working on a software problem, the problem <strong>by definition</strong> hasn’t been solved within your organization (that you know of; I’ll come back to that). This means that you’ll most often be failing. Just like scientists who try to narrow down their scope of inquiry so they can have useful experiments, you’ll try to narrow down the problem and pattern match and research so that you can have a working solution. But just like the <a href="https://en.wikipedia.org/wiki/Michelson%E2%80%93Morley_experiment">best planned experiments fail</a>, so will you, often.</p>
<p>There are two additional complexities that software developers have that scientists do not.</p>
<p>The tools that software developers use are themselves software and are being developed. Imagine trying to build a house when the hammers and saws that you are using are themselves changing at a rapid pace. This means that the solution that may have worked in the past is suboptimal.</p>
<p>And the real world that scientists operate on and try to understand doesn’t often change daily. The business world that software developers operate on and try to understand can change on the whim of a person in authority. This is an <a href="https://en.wikipedia.org/wiki/No_Silver_Bullet">essential complexity</a> of software development.</p>
<p>This experience requires you to get used to failure, both at the micro and macro levels. And to keep going. You just need to be tenacious and realize that you’ll solve the problem. Also, recognize the frustration and realize that everyone is going through it. A coach once taught me that running is hard for everyone, whether you are running a 5 minute mile or a 10 minute mile. The same is true for development. Learning something new is difficult and frustrating, whether it’s your first programming language or the intricacies of a build and deployment process that is new to you.</p>
<p>Get used to failure and remember that everyone else encounters it.</p>
<p>I mentioned I’d return to the caveat that problems you tackle haven’t been solved “that you know of”. Back in the dark ages before the internet was widespread, distribution of software knowledge was slow and driven by email, bulletin boards, journals and books. Now we have google and stack overflow. This helps with coming up to speed on external software that will help you solve problems. I’ve yet to see an internal system that works well for sharing knowledge, but it is incumbent on you and your teams to search out solutions within your organization.</p>
<p>Once you have a problem defined (even partially), resist the temptation to dive in and start building a solution. Rather, pop your head up and ask around and see if anyone has solved your problem. Or even one third of it. You may or may not re-use their solution, but it will inform your solution even if you don’t.</p>
<p>Sincerely,</p>
<p>Dan</p>
	</div><div>
			<!-- .entry-auhtor -->
		<p><strong>Published</strong>
			<time datetime="2018-12-31T10:23:42-07:00">December 31, 2018</time><time datetime="2019-08-14T07:38:03-06:00">August 14, 2019</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/2018/12/31/get-used-to-failure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740513</guid>
            <pubDate>Sun, 05 Jul 2020 17:56:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JWT Authentication with Delphi (2017)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23740445">thread link</a>) | @todsacerdoti
<br/>
July 5, 2020 | http://blog.paolorossi.net/2017/04/27/jwt-authentication-with-delphi/ | <a href="https://web.archive.org/web/*/http://blog.paolorossi.net/2017/04/27/jwt-authentication-with-delphi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        
                        <h2>JWT authentication with Delphi. Part 1</h2>
                        
                    </div><div>
                        <div>
                            <!-- Articles Index -->  

  

<hr>

<p>  
This is the first article I will write about JWT and authentication technologies using Delphi, specifically I'll cover the topic of authentication (mostly in a HTTP world) using tokens (specifically JSON Web Tokens).  
</p>

<p>  
The Delphi library used in this article is the open source <a href="https://github.com/paolo-rossi/delphi-jose-jwt" target="_blank"><strong>delphi-jose-jwt</strong></a> library (created by me) and available on <a href="https://github.com/paolo-rossi/delphi-jose-jwt" target="_blank"><strong>GitHub</strong></a>. This library is listed on the <a href="https://jwt.io/" target="_blank"><strong>JWT.io</strong></a> site and  
it's already used in several projects (open source and commercial) but before we dive into the code let’s cover some basics about JWT's.  
</p>



<p>  
Authentication is the process of identifying someone (or something) determining that is who is claimed to be. Remember that in this article I will be speaking only about authentication and not authorization (that is giving individuals access to system objects based on their identity)  
</p>

<!-- WiRL -->  



<h2 id="sessionbasedauthentication">Session based authentication  </h2>

<p>  
In the HTTP world, applications have traditionally used session cookies to store authentication information. The mechanism relies on session IDs stored server-side. The session storage is typically an in-memory list/table (that is server-specific), or a separate session storage layer (often the back-end database).  
</p>

<p>  
In HTTP the communication is essentially stateless, so the cookie (that contains the session ID) is used by the server as a “key” to retrieve information about the client side (user or process). The cookie is created by the server and sent to the client, in the next request, the cookie is bounced back so the server can lookup the session ID in the session table.  
</p>

<p>Disadvantages of “cookie” based auth:</p>

<ul>
<li><strong>Sessions</strong>: Sessions are just stored on server’s memory</li>
<li><strong>Mobile</strong>: Native mobile apps seems to have problems working with cookies so if we need to query a remote API, maybe session auth is not the best solution.</li>
<li><strong>CSRF</strong>: (Cross-Site Request Forgery) If we go down the cookies way, you really need to do CSRF to avoid cross site requests. That is something we can forget when using JWT as you will see.</li>
<li><strong>CORS</strong>: (Cross-Origin Resource Sharing) Have you fight with CORS and cookies? No need to wrestle using JWT.</li>
</ul>

<h2 id="tokenbasedauthentication">Token based authentication  </h2>

<p>  
The main problem of a session based authentication is that the server must maintains a list of session to be able to “validate” the incoming request and that is a problem because only one server knows how to validate a client request (no scalability or availability).  
</p>

<p>  
So, token authentication was developed to solve problems of server-side session IDs. Using tokens instead of session IDs has the effect of lowering the server load and remove the need of storing an in-memory session table or having an expensive session storage layer (performance). JWT are stateless by definition so they are perfect for this task (more on that, later).  
</p>

<p>  
Before a token is created the user must, obviously, supply verifiable credentials (standard username/password pair, API keys, hardware IDs, or even tokens from another service) and consequently perform some sort of “login” action.  
</p>

<p>  
Keep in mind that JWT is not the only “standard” token representation out there, <b>SWT</b> (Simple Web Token) is (was) a proposed standard (Microsoft 2009) and <b>SAML</b> (Security Assertion Markup Language Token) is an open-standard for exchanging authentication and authorization data between parties based on XML (SAML 2.0, OASIS Standard 2005).  
</p>

<h2 id="oauth2">OAuth 2  </h2>

<p>  
Often I read about OAuth 2 and JWT as if they were comparable (and competing) standards… well, they are not!  
</p>

<p>  
OAuth 2 is an authorization framework that can employ JWT as the format for the OAuth 2 tokens, remember that OAuth2 is not an authentication protocol (because OAuth2 doesn’t know nothing about the user). OAuth 2 is a rather complex topic and I think I will write another article on this topic.  
</p>



<p>  
A JSON Web Token or JWT (pronounced “jot”) is a signed piece of data in JSON format and because it's signed the recipient (the server) can, and must, verify its authenticity.  
</p>

<p>  
The workflow is basically this: a user wants to authenticate so he sends the username and password (for example), the server validates the user and creates a (cryptographically) signed token and then sends it back to the user. The user sends the token with the next request and the server checks if the signature is genuine and (eventually) grants the access to the requested resource. In detail:  
</p>

<ol>
<li>The user sends username and password to an authentication service  </li>
<li>The authentication service responds with a signed JWT with information about the user  </li>
<li>The user requests a resource on the server sending the token back  </li>
<li>The server checks the signature and if it's genuine the access is granted</li>
</ol>

<!-- Linux Daemon -->  



<h2 id="afirstlooktoajwt">A first look to a JWT  </h2>

<p>This is what a JWT looks like:</p>

<pre><code><span>eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9</span>.<span>eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9</span>.<span>eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9</span></code>
</pre>

<p>The same JWT decoded:</p>

<pre><code>{
  "alg": "HS256",
  "typ": "JWT"
}
.
{
  "sub": "1234567890",
  "name": "John Doe",
  "admin": true
}
.
HMACSHA256(  
  base64UrlEncode(header),
  base64UrlEncode(payload),
  secret
)
</code></pre>

<p>As you can see the token is composed of three parts:</p>

<ol>
<li>In the first part (called <b>header</b>) are stored information about the signing algorithm and the type of payload (JWT)  </li>
<li>The second (the <b>payload</b>) contains the actual user data (claims)  </li>
<li>The third part is the <b>signature</b> computed (in this example) with the HMACSHA256 algorithm.</li>
</ol>

<h2 id="whatisjose">What is JOSE?  </h2>

<p>  
Before I talked about the Delphi JWT library <a href="https://github.com/paolo-rossi/delphi-jose-jwt" target="_blank"><strong>delphi-jose-jwt</strong></a>, but what is JOSE? (and no, is not my name!). <b>JOSE</b> stands for <b>JSON Object Signing and Encryption</b> and is a (set of) standard that provides a general approach to signing and encryption of any content. JOSE consists of several RFC:  
</p>

<ul>
<li><a href="https://tools.ietf.org/html/rfc7519">JWT (JSON Web Token)</a> describes representation of claims encoded in JSON</li>
<li><a href="https://tools.ietf.org/html/rfc7515">JWS (JSON Web Signature)</a> describes producing and handling signed messages</li>
<li><a href="https://tools.ietf.org/html/rfc7516">JWE (JSON Web Encryption)</a> describes producing and handling encrypted messages</li>
<li><a href="https://tools.ietf.org/html/rfc7518">JWA (JSON Web Algorithms)</a> describes cryptographic algorithms used in JOSE</li>
<li><a href="https://tools.ietf.org/html/rfc7517">JWK (JSON Web Key)</a> describes format and handling of cryptographic keys in JOSE</li>
</ul>

<p>  
<b>In a nutshell:</b> the JWT contains the claims, the JWS is the JWT when signed, the JWE is the JWT when encrypted, the JWA defines the algorithms used in JOSE and the JWK describes the handling of the cryptographic keys used in the process.  
</p>

<p>  
Often the term JWT is used when describing some other JOSE definitions so, for simplicity, in this article I will be using the term JWT.  
</p>

<h2 id="jwtandrest">JWT and REST  </h2>

<p>  
JWT have become very popular with the wide adoption of REST architectural style, but we can use JWT tokens to authenticate in various context, not only REST applications.  
</p>

<p>  
Tokens (and JWTs) are merely an authentication representations and so they can be used in multiple scenarios:  
</p>

<ul>
<li>REST services authentication</li>
<li>OAuth 2.0 communications</li>
<li>CSRF (Cross Site Request Forgery) protection schemes</li>
<li>More in general as session IDs (eventually inside a cookie)</li>
</ul>

<p>  
In this article(s) I will focus on REST technologies but I will give some example of using JWT in other contexts.  
</p>

<!-- Neon -->  



<h2 id="jwtbenefitsinarestfulservice">JWT benefits in a RESTful service  </h2>

<p>  
In his famous dissertation, Roy T. Fielding defines 6 constraints for (truly) RESTful services:  
</p>

<ol>
<li>Client/server architecture  </li>
<li>Stateless communication  </li>
<li>Cache (on the client)  </li>
<li>Uniform Interface  </li>
<li>Layered system  </li>
<li>Code on-demand</li>
</ol>

<p>  
The most important (to me) is the second (and consequently the third one) that states REST interactions between client and server must be stateless by nature.  
</p>

<p>  
That means that requests (from the client) must contain all of the information necessary to understand the request and so they cannot take advantage of any stored context on the server and this, unfortunately, includes the session table typically stored on servers (automatic session management is one of the most publicized features of HTTP server frameworks).  
</p>

<p>  
The second constraint (if satisfied) induces the properties of <b>visibility</b> (looking at a request is sufficient to visualize the interaction), <b>reliability</b> (failure of one request does not influence others), and <b>scalability</b> (a server can switch a request to another server). Given these advantages you can see why this constraint is so important when building a REST server! Oh, and remember that JWT helps you to achieve this goal because:  
</p>

<ul>
<li>Using JWTs there’s no need of sessions</li>
<li>Using JWTs there’s no need of session storage (on server)</li>
<li>Using JWTs there’s no need of garbage collection of expired sessions</li>
</ul>

<h2 id="conclusion">Conclusion  </h2>

<p>  
So, as you can see, JWT is a simple and yet powerful technology to accomplish several tasks.  
</p>

<p>  
In the next post I will explain in detail the JWT’s claims and we'll start to explore the <a href="https://github.com/paolo-rossi/delphi-jose-jwt" target="_blank"><strong>delphi-jose-jwt</strong></a> library features.  
</p>

<p>  
<img src="http://blog.paolorossi.net/content/images/2017/04/firma-round.png" width="200">  
</p>




                        </div>
                        
                    </div></div>]]>
            </description>
            <link>http://blog.paolorossi.net/2017/04/27/jwt-authentication-with-delphi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740445</guid>
            <pubDate>Sun, 05 Jul 2020 17:48:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Write That Down (2018)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23740444">thread link</a>) | @todsacerdoti
<br/>
July 5, 2020 | https://letterstoanewdeveloper.com/2018/12/28/write-that-down/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/2018/12/28/write-that-down/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><em>This is a guest blog post from John Obelenus. Enjoy.</em></p>
<p>Dear new developer,</p>
<p id="bfca">Even when I was a kid in school I hardly wrote things down. That’s why we had textbooks after all! I was baffled by other students in college furiously transcribing every word that came out of the professor’s mouth. Now I have a career in the world of software where we track everything. Git holds all the code commits, email is never really deleted, and project management and issue tracking tools keep track of what we’re doing and have done. How could anything go missing?</p>
<p id="7f29">I constantly looking for things and cannot find them. I get a bug report, look at the code and say to myself “That is obviously wrong, let’s fix it.” I look at the offending commit that introduced the bug (of course it was me). But what is not there? The reason for the change. So I look at the project management tool we use. And someone definitely asked for a change, but, I’m still not sure why. So I search through my email for the few days before I made the change, and…nothing. I still cannot really figure out why we all decided to make a change which introduced a bug.</p>
<p id="f3ec">Or, worse yet, someone asks for a change. All well and good. Then a month later, someone asks to change it back. So you shake your head and make the change. Then someone is confused why this is happening, and calls a meeting and invites you to help figure it out. What are you going to bring to this meeting? Did you write anything down? I never used to. Now I do.</p>
<p id="2737">Now I have a notepad next to my laptop. And I have a notebook on the shelf. I make better use of git messages and write down who asked for changes. When working on a feature, or a bug, and find something…“interesting” I make a Github wiki entry explaining it. I write a comment in the code base explaining it. There are two kinds of documentation — useful documentation, and redundant documentation.</p>
<p id="2f04">No doubt many people have told you to comment your code. I hope many people have told you never to comment a loop with <code>// loop over the array</code>. That is not increasing clarity, its just duplicating what the code is doing. Adding noise, not signal. My contention is that comments are rarely useful for explaining “What this code does…” but rather, explains “Because of X, we are going to do…”.</p>
<p id="50b8">Future you is going to be very happy if you start documenting the intent behind what you’re doing. Good code is easy to read. Bad code is capable of being understood with time. But code doesn’t tell you why you’re doing all this work in the first place. Maybe something has changed and you don’t even need this code anymore — deleting code is the most satisfying feeling. But you won’t know unless you know the intent, the purpose, of the code. And the rest of the folks you’re working with are going to be very happy as well.</p>
<p id="f74a">If you write everything down (and make it public), they won’t need to tap you on the shoulder when you’re in “The Zone” to ask. When someone wants to set a meeting to understand why things are “The Way They Are” you already captured that information. You can send them the link and kill the meeting (Ok, maybe killing meetings is more satisfying than killing code).</p>
<p id="2b74">We only have so much time in our life, and we already work long hours. Let’s make future us happier by writing things down, so we don’t have to figure it all out again. We figured it out once when we wrote the code. So capture the knowledge in that moment in time. And Write It Down!</p>
<p>Sincerely,</p>
<p>John Obelenus</p>
<p><a href="https://medium.com/@jobelenus/write-that-down-adf7baa3d92b">(Previously published at Medium)</a></p>
<p><em>John Obelenus solves problems and saves time through software and crushing entropy<br>
</em></p>

<p><em>J</em></p>
	</div><div>
			<!-- .entry-auhtor -->
		<p><strong>Published</strong>
			<time datetime="2018-12-28T19:38:58-07:00">December 28, 2018</time><time datetime="2019-02-03T09:41:16-07:00">February 3, 2019</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/2018/12/28/write-that-down/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740444</guid>
            <pubDate>Sun, 05 Jul 2020 17:48:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nine properties of logarithm: theory and examples]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23740417">thread link</a>) | @R3G1R
<br/>
July 5, 2020 | https://mathvault.ca/logarithm-theory/#Properties_of_Logarithm | <a href="https://web.archive.org/web/*/https://mathvault.ca/logarithm-theory/#Properties_of_Logarithm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://mathvault.ca/wp-content/uploads/Logarithm-Post.jpg" alt="The Ultimate Guide to Logarithm - Properties of Logarithm, Complex Logarithm and More!" width="800" height="480" title="Logarithm Post" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20800%20480'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/Logarithm-Post.jpg"></p><p>For the very vast majority of humans on earth, there is a topic found in the good&nbsp;old math textbooks that many of us still even dread contemplating about, as&nbsp;it seems to mess with our brain in a rather<em>&nbsp;particular</em> way.&nbsp; The name? <a href="https://en.wiktionary.org/wiki/logarithmus" target="_blank" rel="noopener noreferrer">$\displaystyle \text{Logarithmus}$</a> — or <strong>Logarithm</strong> in English to be sure!</p><p>As terrible-sounding as it is, logarithm seems to have this <em>distinct</em> characteristic of metaphorically leaving a <em>bad taste</em> in our mouth. In fact, even for those who managed to maneuver around&nbsp;it back in high school, logarithm still remains largely as an <em>evasive</em> concept. The <strong>“I-can-manipulate-expressions-without-understanding-anything” syndrome</strong>&nbsp;runs rampant when it comes to logarithm.</p><p>Indeed, here in North America, the&nbsp;grade school curriculum has the propensity of overemphasizing the&nbsp;<strong>mechanics</strong>&nbsp;at the expense of&nbsp;<strong>basic theory</strong>, leaving us with the <em>formidable</em> task of filling in the <em>logarithmic</em> knowledge gap, which includes — among others&nbsp;— the theory behind the <strong>properties of logarithm</strong>, and its intended <strong>computational use</strong> in handling&nbsp;numbers with an&nbsp;<strong>order of magnitude</strong> veering towards the extremes.</p><p>So with that in mind, if you think that the time might have finally come to tame this <em>monster</em> we call logarithm, then it would be our pleasure to congratulate your timing on this very honorable act. And if&nbsp;you are simply looking to&nbsp;explore further into the rabbit hole, that would be <em>doubly</em> appreciated as well, for regardless of your motivation, the <strong>taming</strong>/<strong>musing</strong> is on!&nbsp;&nbsp;🙂<span id="more-5976"></span></p><h2 id="review"><span id="Logarithm_%E2%80%94_A_Review"></span><a href="#toc">Logarithm — A Review</a><span></span></h2><h3 id="terms"><span id="Terminology"></span><a href="#toc">Terminology</a><span></span></h3><p>Given a <em>real number</em> $x$, one of the challenges in <strong>elementary algebra</strong> is to express $x$ as a <em>power</em> of another number $b$ (known as the <strong>base</strong>). More specifically, we are interested in finding a&nbsp;number $\Box$ such that:</p><p>\begin{equation*} x = b^\Box \end{equation*}</p><p>As it turns out, this problem — in the <em>crude</em> form that it currently is at least — needs to be patched up first&nbsp;before any meaningful discussion can take place. For example:</p><ul><li>If the base is <em>negative</em>, then its powers need not be necessarily&nbsp;<a href="https://mathvault.ca/math-glossary/#welldefined"><strong>well-defined</strong></a> (e.g., $\displaystyle (-e)^{\frac{1}{2}}$).</li><li>If the base is $\displaystyle 1$, then any power of it would be just $1$, in which case, it would be <em>impossible</em>&nbsp;for it to generate any&nbsp;number that’s not $1$. A&nbsp;similar remark applies to the case&nbsp;where&nbsp;the base is equal to $0$.</li></ul><p>For these reasons, in the context of <strong>power determination</strong>, it’s customary to require&nbsp;the&nbsp;base $b$ to be a <em>positive</em> number — that is not equal to $1$. While under this assumption, any power of $b$ would necessarily have to be <em>positive</em>, it would also transpire —under this setup — that <em>any</em>&nbsp;positive number can be expressed as a power of $b$ in a <em>unique</em> way. That is, as long as $x$ is <em>positive</em>, there will be a <em>unique</em> number $\Box$ (known as the&nbsp;<strong>exponent</strong>) such that:</p><p>\begin{equation*} x= b^{\Box} \end{equation*}</p><p>in which case, we will simply call $\Box$ the <strong>logarithm</strong> of $x$ (in base $b$). In other words, logarithm is basically what happens when we expressed a number as a <em>power</em>, and then take the <em>exponent</em> from that power —&nbsp;It gives&nbsp;us the <strong>magnitude</strong> of a number, with respect to the base in question.</p><p>For example, when we try to express the number $64$ as a power of $2$, we get that $64= 2^6$. This alone shows that $6$ is the logarithm of $64$ — &nbsp;with respect to the base $2$.</p><p>Notation-wise, the logarithm of $x$ in <strong>base</strong> $b$ is denoted by $\log_b x$, with $x$ also being called&nbsp;the <strong>argument</strong> of the logarithm. When considered as a function, $\log_b x$ is defined on all <em>positive</em> numbers — as long as&nbsp;the base $b$ is <strong>valid</strong> (i.e.,&nbsp;&nbsp;$\displaystyle b&gt;0, b \ne 1$) .</p><p>To begin,&nbsp;we first note that <em>regardless</em> of the value of the base $b$, we always have that:</p><ul><li>$\displaystyle \log_b 1 = 0$ (since $0$ is the number $b$ needs to be raised to yield $1$)</li><li>$\displaystyle \log_b b&nbsp;= 1$ (since $1$ is the number $b$ needs to be raised to yield $b$)</li><li>$\displaystyle \log_b \frac{1}{b} = -1$ (since $-1$ is the number $b$ needs to be raised to yield $\displaystyle \frac{1}{b}$)</li></ul><p>Because these results are almost immediate and sufficiently notable, we’ll simply&nbsp;refer to&nbsp;them as the&nbsp;<strong>trivial logarithmic identities</strong>.</p><p>In addition,&nbsp;since $\log_b x$ stands for the number which&nbsp;<em>exponentiates</em> to $x$, we also have that by definition:</p><p>\begin{align*}b^{\log_b x} &amp; = x \qquad (\text{for all }x&gt;0)\end{align*}</p><p>On the other hand,&nbsp;we also have that:</p><p>\begin{align*} \log_b (b^x) = x \qquad (\text{for all } x \in \mathbb{R}) \end{align*}</p><p>Since one can see by inspection that $x$ is precisely the number which exponentiates to $b^x$.</p><p>For&nbsp;example, since $\displaystyle \log_2 53$ is the number that $2$ needs to raise to yield $53$, we have that $\displaystyle 2^{\log_2 53} =53$. Similarly, since $\displaystyle 10^{-\pi}$ is a power of $10$ with the exponent $-\pi$, we can infer&nbsp;that $\displaystyle \log_{10} \left(10^{-\pi}\right) = -\pi$.</p><h3 id="10"><span id="Common_Logarithm_(Base_10)"></span><a href="#toc">Common Logarithm (Base 10)</a><span></span></h3><p>Being the inverse of the exponential function $\displaystyle 10^x$, the base-$10$ logarithmic function — also known as the&nbsp;<a href="https://en.wikipedia.org/wiki/Common_logarithm" target="_blank" rel="noopener noreferrer"><strong>common logarithm</strong></a> — is customarily denoted by $\log_{10} x$, $\log x$, or simply $\lg x$ for short. The common logarithm is of great interest to us, primarily&nbsp;due to the prevalence of the&nbsp;<strong>decimal number system</strong> in various cultures around the world.</p><div><p><strong>Caution</strong></p><p>Note that in older scientific texts and some textbooks in higher mathematics, $\log x$ can also refer to — and usually is — the <a href="#e">natural logarithm of base $e$</a>.</p></div><p>When the common logarithm of a number is calculated, the&nbsp;<em>decimal representation</em> of the logarithm is usually split into two parts: the integer component&nbsp;(a.k.a., <strong>characteristic</strong>) and the fractional component&nbsp;(a.k.a., <strong>mantissa</strong>). The characteristic in essence tells us &nbsp;the <strong>number of digits</strong> the original number has, and the mantissa hints at the extent to which this&nbsp;number is close to its next power of $10$. These are the facts that make common logarithm a&nbsp;particularly handy tool in determining the <strong>order of magnitude</strong> of an <em>exceptionally&nbsp;large</em> (or <em>small</em>) number.</p><p>For example, to figure out the magnitude of the number $50!$ (i.e., $50 \times \cdots \times 1$), we proceed to calculate its logarithm, yielding that: \[ \log (50!) \approx 64.483 \] which means that $50! \approx 10^{64.483} =$ $10^{64}10^{0.483} \approx$ $10^{64} \cdot 3.04$, suggesting that $50!$ is a $65$<em>-digit number</em> which starts with $3$ — the <strong>characteristic</strong> $64$ gives away the number of digits, and the <strong>mantissa</strong> $0.483$ reveals&nbsp;the rest about the number itself.</p><p>Take home message? There is no need to&nbsp;write out a number in full to figure out its <em>approximate size</em>!</p><h3 id="2"><span id="Binary_Logarithm_(Base_2)"></span><a href="#toc">Binary Logarithm (Base 2)</a><span></span></h3><p>Being the inverse of the exponential function $2^x$, the <a href="https://en.wikipedia.org/wiki/Binary_logarithm" target="_blank" rel="noopener noreferrer"><strong>binary logarithm</strong></a>&nbsp;function $\log_2 x$ is extensively used in the field of <strong>computer science</strong>, primarily due to the fact that computers store information in <strong>bits</strong> (i.e., digits which takes $0$ or $1$ as possible values).</p><p>Similar to the case in base $10$, binary logarithm can be used to figure out&nbsp;the number of digits&nbsp;of a positive integer&nbsp;in <a href="https://en.wikipedia.org/wiki/Binary_number#Counting_in_binary" target="_blank" rel="noopener noreferrer"><strong>binary representation</strong></a>. In addition, binary logarithm is also used to figure out the <em>depth</em> of a <a href="https://en.wikipedia.org/wiki/Binary_tree" target="_blank" rel="noopener noreferrer"><strong>binary tree</strong></a>, or even the <em>number of operations</em> required by certain <strong>computer algorithms</strong>&nbsp;(this falls into a topic known as&nbsp;<a href="https://en.wikipedia.org/wiki/Time_complexity" target="_blank" rel="noopener noreferrer"><strong>algorithmic time complexity</strong></a>).</p><p>Beyond&nbsp;the world of computers, binary logarithm is also used in&nbsp;<strong>music theory</strong> to conceptualize the <em>highness</em>&nbsp;of&nbsp;musical notes, based&nbsp;on the fundamental&nbsp;observation&nbsp;that <em>raising</em>&nbsp;a note by an <strong>octave</strong>&nbsp;increases the frequency of the note by&nbsp;<em>twofold</em>. As a result, it is often convenient to conceive a&nbsp;<strong>musical interval</strong>&nbsp;as the binary logarithm of the <a href="https://en.wikipedia.org/wiki/Interval_ratio" target="_blank" rel="noopener noreferrer"><strong>frequency ratio</strong></a>.</p><h3 id="e"><span id="Natural_Logarithm_(Base_$e$)"></span><a href="#toc">Natural Logarithm (Base $e$)</a><span></span></h3><p>In some textbooks concerned with a more rigorous development&nbsp;of&nbsp;<a href="https://en.wikipedia.org/wiki/Transcendental_function" target="_blank" rel="noopener noreferrer"><strong>transcendental functions</strong></a>, the base-$\displaystyle e$ logarithmic function — otherwise known as&nbsp;<strong>natural logarithm</strong>, $\log_e x$ or simply $\ln x$ — are sometimes defined as the <em>area</em>&nbsp;between the <strong>reciprocal function</strong>&nbsp;$\frac{1}{x}$ and the x-axis from $1$ to $x$ (hence the term <em>natural</em>).</p><div id="attachment_5991"><p><img aria-describedby="caption-attachment-5991" src="https://mathvault.ca/wp-content/uploads/Harmonic-Series.png" alt="Natural Logarithm and the Divergence of the Harmonic Series" width="295" height="230" title="Harmonic Series" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20295%20230'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/Harmonic-Series.png"></p><p id="caption-attachment-5991">Defined as the area underneath the reciprocal function, the function $\ln x$ increases without bound as $x$ increases, thereby showing that the <strong>Harmonic Series</strong> (i.e., $ \frac{1}{1} + \frac{1}{2}+ \ldots$ ) — whose area is even greater than that of $\ln x$ — diverges to $+ \infty$ as well.</p></div><p>Under this definition, it could be shown that the inverse of $\ln x$ is precisely the <strong>natural&nbsp;exponential function</strong> $e^x$, leading to the&nbsp;following&nbsp;<em>standard</em>&nbsp;definition of&nbsp;natural logarithm:</p><blockquote><h6>Given a positive number $x$,&nbsp;$\ln x$ denotes the number that $e$ needs to be raised, to&nbsp;become $x$.</h6></blockquote><p>Unlike the number $10$ — which is preferred due to the prevalence of&nbsp;<strong>decimal numbering system</strong> — the number $\displaystyle e$ is one of the <a href="https://mathvault.ca/hub/higher-math/math-symbols/#Constants" target="_blank" rel="noopener noreferrer">special constants</a>&nbsp;that&nbsp;pops up surprisingly often in various mathematical discourses —&nbsp;<em>irrespective</em> of the&nbsp;number system being chosen.&nbsp;As a result, mathematicians tend to consider base $e$ as more <em>natural</em> than base $10$ — even though some&nbsp;applied scientists and engineers beg to differ in various occasions…</p><p>Actually, to illustrate the scope of these&nbsp;<em>intellectual biases</em>&nbsp;among the scientific community, here’s an interesting account from <a href="https://en.wikipedia.org/wiki/Common_logarithm#History" target="_blank" rel="noopener noreferrer">Wikipedia</a>&nbsp;on the <strong>historical development</strong>&nbsp;of the&nbsp;notations for logarithms:</p><blockquote><h6>Because base 10 logarithms were most useful for computations, engineers generally simply wrote “log(x)” when they meant log<sub>10</sub>(x). Mathematicians, on the other hand, wrote “log(x)” when they meant log<sub>e</sub>(x) for the natural logarithm. Today, both notations are found. Since hand-held electronic calculators are designed by engineers rather than mathematicians, it became customary that they follow engineers’ notation. So the notation, according to which one writes “ln(x)” when the natural logarithm is intended, may have been further popularized by the very invention that made the use of “common logarithms” far less common, electronic calculators.</h6></blockquote><h3 id="arbitrary"><span id="Logarithm_of_an_Arbitrary_Base"></span><a href="#toc">Logarithm of an Arbitrary Base</a><span></span></h3><div id="attachment_6036"><p><img aria-describedby="caption-attachment-6036" src="https://mathvault.ca/wp-content/uploads/Graphs-of-Different-Logarithms.png" alt="Graphs of the Logarithmic Functions of base 2, e and 10" width="297" height="223" title="Graphs of Different Logarithms" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20297%20223'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/Graphs-of-Different-Logarithms.png"></p><p id="caption-attachment-6036">Graphs of the logarithmic functions of base $2$, $\displaystyle e$ and $10$. Note that&nbsp;<strong>binary logarithm</strong> attains $1$ when $x=2$, <strong>natural logarithm</strong>&nbsp;when $x=e$ and&nbsp;<strong>common logarithm</strong>&nbsp;only when $x=10$.</p></div><p>In addition to the three most …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mathvault.ca/logarithm-theory/#Properties_of_Logarithm">https://mathvault.ca/logarithm-theory/#Properties_of_Logarithm</a></em></p>]]>
            </description>
            <link>https://mathvault.ca/logarithm-theory/#Properties_of_Logarithm</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740417</guid>
            <pubDate>Sun, 05 Jul 2020 17:45:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[George Washington Statue Toppled by Portland Protesters on the Eve of Juneteenth]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23740401">thread link</a>) | @donald2025
<br/>
July 5, 2020 | https://blacklivesmatter-clothing.com/blogs/news/george-washington-statue-toppled-by-portland-protesters-on-the-eve-of-juneteenth | <a href="https://web.archive.org/web/*/https://blacklivesmatter-clothing.com/blogs/news/george-washington-statue-toppled-by-portland-protesters-on-the-eve-of-juneteenth">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article aria-labelledby="title-0">
  <div>
    <div>
      <div id="shopify-section-article-template">

<div>
  <p>&nbsp;&nbsp;&nbsp;&nbsp; A group of protesters gathered around a statue of George Washington in Portland, Oregon, on Thursday night and lit a fire on its head before pulling it to the ground. Washington, the nation’s first president, owned slaves but later in life began to oppose slavery and in his will ordered that his slaves be freed after his wife’s death.</p>
<p>&nbsp;Protests following Floyd’s death initially focused on the circumstances of his death and concerns about the police investigation, however, demonstrations have grown around the topic of monuments of historical figures.</p>
<p><span>After the founding father’s statue came crashing down, vandals defaced it with graffiti, then left it face-down in Rose City Park before fleeing around 11 p.m., the station reported.</span></p>
<p><span>"Maybe it's time for George Washington to go to a museum or go somewhere else," Johnson said</span></p>
<p><span>Johnson says he saw what happened late last night when the statue came down.<br>"It was not an angry mob, it was just people trying to take down something they did not like," Johnson said.</span></p>

<p><strong>George Washington statue torn down&nbsp;Portland, Thursday night 18, June, 2020</strong></p>
<p><img alt="" src="https://cdn.shopify.com/s/files/1/0402/2131/1132/files/George_Washington_statue_toppled_2048x2048.jpg?v=1592655866"></p>
<p>&nbsp;Activists first focused on monuments of Confederate leaders, who seceded from the union in defense of slavery. Since then, activists have gone on to target other controversial historical figures, such as&nbsp;Christopher Columbus and George Washington.</p>
<p>As of Friday morning, the statue remained on the ground, covered in spray paint. Some of the messages written on the toppled monument included: “BLM,” an acronym for Black Lives Matter; “You’re on native land;” “f— cops;” “white fragility;” and “no good cops.”</p>
<p>&nbsp;On Friday morning, Andy tweeted a video of the toppled statue:&nbsp;</p>

<blockquote>
<p lang="en" dir="ltr">Portland wakes up to see what antifa did overnight. A century old statue of George Washington was toppled &amp; set on fire with an American flag. “White fragility,” “Damn white men” &amp; other messages are written on the moment. On the ground nearby: “Defund white men.” <a href="https://t.co/zjrsZHJC9o">pic.twitter.com/zjrsZHJC9o</a></p>
— Andy Ngô (@MrAndyNgo) <a href="https://twitter.com/MrAndyNgo/status/1273969935497084930?ref_src=twsrc%5Etfw">June 19, 2020</a>
</blockquote>
<blockquote></blockquote>

<p><strong>&nbsp;George Washington statue in Portland toppled, protests continue Portland, June 19, 2020</strong></p>
<p><img src="https://cdn.shopify.com/s/files/1/0402/2131/1132/files/portland_6_2048x2048.jpg?v=1592663423" alt=""></p>
<p><span>A group of people tore down a statue of George Washington that stood on the lawn of the German American Society in Northeast Portland.</span></p>
<p><span><strong>Caesar the 'no drama llama' march protest in Portland Friday, June 19, 2020</strong></span></p>
<p><span>Caesar the 'no drama llama' offers support and love at protestors.&nbsp;Caesar has joined many marches and protests for a variety of groups promoting civil rights and equality and frequent charity events.<br></span></p>
<p><span>Caesar is one of 15 llamas who reside at McCool’s Mystic Llama Farm in Jefferson, Oregon, about 75 miles south of Portland. McCool said, "It was important to him to make the 150-mile round-trip drive with Caesar to lend support and hopefully a calming presence for both protesters and police officers."</span></p>
<p><img alt="" src="https://cdn.shopify.com/s/files/1/0402/2131/1132/files/portland_protests_2_2048x2048.jpg?v=1592654519"></p>
<p>&nbsp;Zane Sparling <strong>tweeted</strong>: "<span>George Washington statue in Portland will be removed by crane TODAY and put in storage. No long term decisions made regarding reinstallation."</span></p>
<p>&nbsp;Just spoke with the Regional Arts &amp; Culture Council.&nbsp;</p>
<blockquote>
<div lang="en" dir="ltr"><p>George Washington statue in Portland will be removed by crane TODAY and put in storage. No long term decisions made regarding reinstallation. </p><p>Spokeswoman for RACC says statue caused “harm” <a href="https://t.co/7S0wQUY68y">pic.twitter.com/7S0wQUY68y</a></p></div>
— Zane Sparling (@PDXzane) <a href="https://twitter.com/PDXzane/status/1274044114779009025?ref_src=twsrc%5Etfw">June 19, 2020</a>
</blockquote>
<blockquote></blockquote>
<p>
Matt Rashleigh <strong>tweeted</strong>: "The George Washington statue on NE Sandy in #Portland #Oregon has been pulled down and vandalized. Portland Police officers inspected the damage.&nbsp;<span><span>Someone left a note and a few dollars on it next to the spray painted bronze"</span></span></p><blockquote>
<p lang="en" dir="ltr">The George Washington statue on NE Sandy in <a href="https://twitter.com/hashtag/Portland?src=hash&amp;ref_src=twsrc%5Etfw">#Portland</a> <a href="https://twitter.com/hashtag/Oregon?src=hash&amp;ref_src=twsrc%5Etfw">#Oregon</a> has been pulled down and vandalized. Portland Police officers inspected the damage. Someone left a note and a few dollars on it next to the spray painted bronze. <a href="https://twitter.com/hashtag/koin6news?src=hash&amp;ref_src=twsrc%5Etfw">#koin6news</a> <a href="https://t.co/e5LYbDtvMa">pic.twitter.com/e5LYbDtvMa</a></p>
— Matt Rashleigh (@Matt_KOIN) <a href="https://twitter.com/Matt_KOIN/status/1273885631949594624?ref_src=twsrc%5Etfw">June 19, 2020</a>
</blockquote>

<p><span>Images from the scene show the statue lying face down on the ground and covered in graffiti that read: ‘Genocidal colonist’</span></p>
<p><span>A spokeswoman for the Regional Arts &amp; Culture Council — the nonprofit tasked with maintaining local public art — said a city crew would remove the statue by end of day Friday, June 19, for storage. No final decision about reinstallation has been made.</span></p>
<p><img src="https://cdn.shopify.com/s/files/1/0402/2131/1132/files/The_George_Washington_incident_1024x1024.jpg?v=1593956279" width="1024x1024" height="1024x1024"></p>
<h3><span>Support #BlackLivesMatter movement and get your&nbsp;<span><a href="https://blacklivesmatter-clothing.com/">"I CAN'T BREATHE" T-Shirt</a></span>, We're donating a percentage of every purchase to support&nbsp;</span></h3>
</div>


  <!-- /snippets/social-sharing.liquid -->







</div>
    </div>
  </div>
</article></div>]]>
            </description>
            <link>https://blacklivesmatter-clothing.com/blogs/news/george-washington-statue-toppled-by-portland-protesters-on-the-eve-of-juneteenth</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740401</guid>
            <pubDate>Sun, 05 Jul 2020 17:42:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python Utility ISort 5.0 Release]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23740400">thread link</a>) | @throwaway333444
<br/>
July 5, 2020 | https://timothycrosley.github.io/isort/docs/major_releases/introducing_isort_5/ | <a href="https://web.archive.org/web/*/https://timothycrosley.github.io/isort/docs/major_releases/introducing_isort_5/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        
      
      
      <main role="main">
        <div data-md-component="container">
          
            
              
            
            
              
            
          
          <div>
            <article>
              
                
                  <a href="https://github.com/timothycrosley/isort/edit/develop/docs/major_releases/introducing_isort_5.md" title="Edit this page"></a>
                
                
                
<p><a href="https://timothycrosley.github.io/isort/"><img alt="isort 5 - the best version of isort yet" src="https://raw.githubusercontent.com/timothycrosley/isort/develop/art/logo_5.png"></a></p>
<p>isort 5.0.0 is the first major release of isort in over five years and the first significant refactoring of isort since it was conceived more than ten years ago.
It's also the first version to require Python 3 (Python 3.6+ at that!) to run - though it can still be run on source files from any version of Python.
This does mean that there may be some pain with the upgrade process, but we believe the improvements will be well worth it.</p>
<p><a href="https://timothycrosley.github.io/isort/CHANGELOG/">Click here for an attempt at full changelog with a list of breaking changes.</a></p>
<p><a href="https://timothycrosley.github.io/isort/docs/upgrade_guides/5.0.0/">Using isort 4.x.x? Click here for the isort 5.0.0 upgrade guide.</a></p>
<p><a href="https://timothycrosley.github.io/isort/docs/quick_start/0.-try/">Try isort 5 right now from your browser!</a></p>
<p>So why the massive change?</p>

<div><pre><span></span><code><span>isort --profile black .</span>
<span>isort --profile django .</span>
<span>isort --profile pycharm .</span>
<span>isort --profile google .</span>
<span>isort --profile open_stack .</span>
<span>isort --profile plone .</span>
<span>isort --profile attrs .</span>
<span>isort --profile hug .</span>
</code></pre></div>


<p>isort is very configurable. That's great, but it can be overwhelming, both for users and for the isort project. isort now comes with profiles for the most common isort configurations,
so you likely will not need to configure anything at all. This also means that as a project, isort can run extensive tests against these specific profiles to ensure nothing breaks over time.</p>

<div><pre><span></span><code><span>import</span> <span>a</span>  <span># &lt;- These are sorted</span>
<span>import</span> <span>b</span>

<span>b</span><span>.</span><span>install</span><span>(</span><span>a</span><span>)</span>

<span>import</span> <span>os</span>  <span># &lt;- And these are sorted</span>
<span>import</span> <span>sys</span>


<span>def</span> <span>my_function</span><span>():</span>
    <span>import</span> <span>x</span>  <span># &lt;- Even these are sorted!</span>
    <span>import</span> <span>z</span>
</code></pre></div>


<p>isort 5 will find and sort contiguous section of imports no matter where they are.
It also allows you to place code in-between imports without any hacks required.</p>




<p>isort has been refactored to use a streaming architecture. This means it can sort files of <em>any</em> size (even larger than the Python interpreter supports!) without breaking a sweat.
It also means that even when sorting imports in smaller files, it is faster and more resource-efficient.</p>

<p>Sorting the same file with the same configuration should give you the same output no matter what computer or OS you are running. Extensive effort has been placed around refactoring
how modules are placed and how configuration files are loaded to ensure this is the case.</p>

<div><pre><span></span><code><span>cimport</span> <span>ctime</span>
<span>from</span> <span>cpython</span> <span>cimport</span> <span>PyLong_FromVoidPtr</span>
<span>from</span> <span>cpython</span> <span>cimport</span> <span>bool</span> <span>as</span> <span>py_bool</span>
<span>from</span> <span>cython.operator</span> <span>cimport</span> <span>dereference</span> <span>as</span> <span>deref</span>
<span>from</span> <span>cython.operator</span> <span>cimport</span> <span>preincrement</span> <span>as</span> <span>preinc</span>
<span>from</span> <span>libc.stdint</span> <span>cimport</span> <span>uint64_t</span><span>,</span> <span>uintptr_t</span>
<span>from</span> <span>libc.stdlib</span> <span>cimport</span> <span>atoi</span><span>,</span> <span>calloc</span><span>,</span> <span>free</span><span>,</span> <span>malloc</span>
<span>from</span> <span>libc.string</span> <span>cimport</span> <span>memcpy</span><span>,</span> <span>strlen</span>
<span>from</span> <span>libcpp</span> <span>cimport</span> <span>bool</span> <span>as</span> <span>cpp_bool</span>
<span>from</span> <span>libcpp.map</span> <span>cimport</span> <span>map</span> <span>as</span> <span>cpp_map</span>
<span>from</span> <span>libcpp.pair</span> <span>cimport</span> <span>pair</span> <span>as</span> <span>cpp_pair</span>
<span>from</span> <span>libcpp.string</span> <span>cimport</span> <span>string</span> <span>as</span> <span>cpp_string</span>
<span>from</span> <span>libcpp.vector</span> <span>cimport</span> <span>vector</span> <span>as</span> <span>cpp_vector</span>
<span>from</span> <span>multimap</span> <span>cimport</span> <span>multimap</span> <span>as</span> <span>cpp_multimap</span>
<span>from</span> <span>wstring</span> <span>cimport</span> <span>wstring</span> <span>as</span> <span>cpp_wstring</span>
</code></pre></div>


<p>isort 5 adds seamless support for Cython (<code>.pyx</code>) files.</p>

<div><pre><span></span><code><span>import</span> <span>e</span>
<span>import</span> <span>f</span>

<span># isort: off  &lt;- Turns isort parsing off</span>

<span>import</span> <span>b</span>
<span>import</span> <span>a</span>

<span># isort: on  &lt;- Turns isort parsing back on</span>

<span>import</span> <span>c</span>
<span>import</span> <span>d</span>
</code></pre></div>


<p>isort 5 adds support for <a href="https://timothycrosley.github.io/isort/docs/configuration/action_comments/">Action Comments</a> which provide a quick and convient way to control the flow of parsing within single source files.</p>

<div><pre><span></span><code><span>import</span> <span>isort</span>

<span>isort</span><span>.</span><span>code</span><span>(</span><span>"""</span>
<span>import b</span>
<span>import a</span>
<span>"""</span><span>)</span> <span>==</span> <span>"""</span>
<span>import a</span>
<span>import b</span>
<span>"""</span>
</code></pre></div>


<p>isort now exposes its programmatic API as a first-class citizen. This API makes it easy to extend or use isort in your own Python project. You can see the full documentation for this new API <a href="https://timothycrosley.github.io/isort/reference/isort/api/">here</a>.</p>

<p>A major focus for the release was to give isort a solid foundation for the next 5-10 years of the project's life.
isort has been refactored into functional components that are easily testable. The project now has 100% code coverage.
It utilizes tools like <a href="https://hypothesis.readthedocs.io/en/latest/">Hypothesis</a> to reduce the number of unexpected errors.
It went from fully dynamic to fully static typing using mypy. Finally, it utilizes the latest linters both on (like <a href="https://deepsource.io/gh/timothycrosley/isort/">DeepSource</a>) and offline (like <a href="https://flake8.pycqa.org/en/latest/">Flake8</a>) to help ensure a higher bar for all code contributions into the future.</p>

<p><a href="https://timothycrosley.github.io/isort/docs/quick_start/0.-try/">Try isort 5 right now from your browser!</a></p>
<p>OR</p>
<p>Install isort locally using <code>pip3 install isort</code>.</p>
<p><a href="https://timothycrosley.github.io/isort/docs/quick_start/1.-install/">Click here for full installation instructions.</a></p>
                
                  
                
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        

      
    </div></div>]]>
            </description>
            <link>https://timothycrosley.github.io/isort/docs/major_releases/introducing_isort_5/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740400</guid>
            <pubDate>Sun, 05 Jul 2020 17:42:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Ongoing Accomplishment of the Big Five]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23740367">thread link</a>) | @elsewhen
<br/>
July 5, 2020 | https://carcinisation.com/2020/07/04/the-ongoing-accomplishment-of-the-big-five/ | <a href="https://web.archive.org/web/*/https://carcinisation.com/2020/07/04/the-ongoing-accomplishment-of-the-big-five/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-732">
	<!-- .entry-header -->

	
	
	<div>
		
<p><em>by a literal banana</em></p>
<p>I have been trying to understand the “<a href="https://en.wikipedia.org/wiki/Lexical_hypothesis" target="_blank" rel="noopener">lexical hypothesis</a>” of personality, and its modern descendant, the <a href="https://en.wikipedia.org/wiki/Big_Five_personality_traits" target="_blank" rel="noopener">Five Factor Model of personality</a>, for <a href="https://carcinisation.com/2020/01/27/ignorance-a-skilled-practice/">several</a> <a href="https://carcinisation.com/2020/06/24/the-extended-sniff-test/">months</a>. In that time, I have said some provocative things about the Big Five, and even some unkind things that I admit were unbecoming to a banana. Here, I wish to situate the Five Factor Model in the context of its historical development and modern use, and to demonstrate to the reader the surprising accomplishment that it represents for the field of psychology.<span id="more-732"></span></p>
<p>In personality research, the “lexical hypothesis” refers to a hypothesis attributed to Francis Galton (1884). Galton supposed that each human language would reflect important realities of human character within that language and culture. In particular, he noted that the words used to evaluate character and personality are very numerous (he estimated over a thousand, using a thesaurus), and often overlap in meaning.</p>
<p>But Galton immediately left his thesaurus behind, readily admitting of the impossibility of <a href="https://carcinisation.com/2020/06/26/words-fail/">defining</a> any aspect of character. Rather, he turned to experimental means of testing the character in various ways, and insisted that <em>no particular map or model of personality is needed to start from</em>.</p>
<p>Nowhere in his essay does Galton propose surveys as a means for studying character. He would probably regard such methods as unscientific, as indicated in his final paragraph:</p>
<blockquote><p>[C]haracter ought to be measured by carefully recorded acts, representative of the usual conduct. An ordinary generalisation is nothing more than a muddle of vague memories of inexact observations. It is an easy vice to generalise. We want lists of facts, every one of which may be separately verified, valued and revalued, and the whole accurately summed. It is the statistics of each man’s conduct in small every-day affairs, that will probably be found to give the simplest and most precise measure of his character.</p></blockquote>
<p>The methods that Galton proposed are exclusively non-linguistic. For instance, he commented that observing children involved in play quickly gives one an idea of each child’s emotional expression. Galton’s proposed methods prefigure both hidden camera prank shows and Goffman’s “breaching experiments:”</p>
<blockquote><p>I will not attempt to describe particular games of children or of others, nor to suggest experiments, more or less comic, that might be secretly made to elicit the manifestations we seek, as many such will occur to ingenious persons. They exist in abundance, and I feel sure that if two or three experimenters were to act zealously and judiciously together as secret accomplices, they would soon collect abundant statistics of conduct. They would gradually simplify their test conditions and extend their scope, learning to probe character more quickly and from more of its sides.</p></blockquote>
<p>Other methods Galton expressed enthusiasm for include heart rate measurement (he wore a home-brew heart-rate-measuring apparatus while he delivered the lecture that makes up the text) and methods discoverable from personal context (giving an example from Benjamin Franklin, of a man with one attractive and one deformed leg, who kept track of which leg his interlocutors paid attention to, as a gauge of their optimism or pessimism). Galton would be surprised, I think, to find that the most promising and scientific theory of personality in the twenty-first century is premised entirely on survey responses as its “facts.”</p>
<p>Early in the study of personality, there was a major shift of meaning in the lexical hypothesis. At first, the thesaurus and the word list were its tools of study (e.g., Allport &amp; Odbert, 1936); the idea was to find common factors of meaning in the words themselves. Of course, there is no particularly scientific way to decide how much the word “annoying” is the same as “obnoxious,” or how much either is the same as “low-status.” The major shift was to begin to measure the correlations of an entirely different construct: the correlations of the words <em>when used to describe a particular person</em>. That is, rather than trying to measure the underlying meaning of words, researchers began to measure the degree to which different words were applied to the same person. “Sameness” and “correlation” were no longer distinguishable concepts for the methods.</p>
<p>Initially, lists of adjectives, and eventually, short survey questions, were administered to subjects, who described either a person they knew or themselves. When the responses were subjected to factor analysis—a mathematical analysis to reveal the structure of correlations between responses—a varying number of factors emerged, depending on the methods and the researchers and the questions and the subjects, and these factors were given varying names. Since the early 1990s, the Five Factor Model has been dominant, although the names of the factors vary somewhat even today. The acronym OCEAN is used for the traits: Openness to experience (sometimes called “intellect” or “imagination” or “open-mindedness”), Conscientiousness, Extraversion (sometimes called “surgency”), Agreeableness, and Neuroticism (sometimes called “negative emotionality” or “emotional stability” reversed).<span>&nbsp;</span></p>
<p>Today, the five traits are measured with various survey instruments, with five questions on the shortest version (one for each aspect) and sixty questions on a common long-form version (that used by Soto, 2019). Survey instruments are validated in a number of ways: how much their responses correlate between testings (test-retest reliability, with astrological sign as the gold standard), how much different raters agree using the criteria (inter-rater reliability), and a nebulous concept of construct validity, which sometimes includes scientific gestures designed to ensure that the instrument measures what it purports to measure. Many papers present elaborate numerical artifacts of validation, and I have found that some characterize the validity of their instruments as “good” without providing an indication of what would be “not good enough.” From a brief review of dozens of validated instruments in social psychology, it seems to me that it is relatively easy to “validate” meaningless instruments. As long as the mathematical bona fides are present, the construct need not be meaningful in other ways. (The reader who is rightly suspicious of my broad and unsourced claims may wish to search Google Scholar with variations of “scale,” “inventory,” and “survey instrument,” and examine the results critically. The naming of factors is often a particularly interesting step.)</p>
<p>The strong claim made by advocates of the Five Factor Model is that any set of questions describing a human being, administered to subjects and the responses subjected to factor analysis, will reveal the same five factors (paraphrasing Jordan Peterson in <a href="https://youtu.be/pCceO_D4AlY" target="_blank" rel="noopener">this video</a>, around 11:10-16:40). This strong claim, though dubious in a number of respects, is a major part of the basis for the scientific legitimacy of the Big Five. It is interesting to see which aspects of the strong claim are admitted to be false by advocates of the Big Five, and how much is excused on the grounds that <i>at least it’s something</i>. The Five Factor Model is not perfect, advocates grant, but it is better than nothing. It is not clear how they measure “better than nothing;” this is a potentially interesting hypothesis in need of precisification, perhaps.</p>
<p>The Big Five exist as a special, scientifically validated property of language and survey methods, and that is one basis for their legitimacy. The other basis for the legitimacy of the Five Factor Model is its <i>replicable correlation with consequential life outcomes</i>. We know that the Big Five are not merely phantoms that fall out of a certain analysis of a certain use of language in WEIRD college students, because these traits are reliably correlated with things we care about.<span>&nbsp;</span></p>
<p>One of the most interesting features of the Big Five is the nature of its scientific evidence. Observe what is held out as a “replication” of the theory, and you will discover the theory’s true nature. The most impressive aspect of the ongoing accomplishment of the Five Factor Model is the degree to which it <i>deflects curiosity </i>about its underlying meaning with <i>rituals of scientific validation</i>, regardless of the rituals’ appropriateness in context. Since “replication” is the scientific ritual most recently shown to detect poor science in psychology, being shown to reliably “replicate” is a huge boost to the credibility of a theory.<span>&nbsp;</span></p>
<p>The interesting thing about the Five Factor Model is what it gets away with, in terms of being considered a theory, even though it is not causal, and makes no predictions. What counts as a “replication” of the Five Factor Model, as in Soto (2019), is the following: a correlation is found between one or more factors of the Five Factor Model and some other construct, and that correlation is found again in another sample, regardless of the size of the correlation. In almost all cases, and in 100% of Soto (2019)’s measures, the construct compared to a Big Five factor is derived from an online survey instrument.</p>
<p>What counts as a “consequential life outcome” is also fascinating. In most cases, the life outcome constructs are vague abstractions measured with survey instruments, much like the Big Five themselves. For instance, the life outcome “Inspiration” is measured with the Inspiration Scale, which asks the subject in four ways how often and how deeply inspired they are. Amazingly, this scale correlates a little bit with Extraversion and with Open-mindedness. Do these personality traits “predict” the life outcome of inspiration? Is “Inspiration” as instrumentalized here meaningfully different from the Big Five constructs, such that this correlation is meaningful?<span>&nbsp;</span></p>
<p>Compare the items for the construct “Inspiration” with the items for Extraversion and Open-mindedness used in Soto (2019):</p>
<p><b>Inspiration Scale Items</b></p>
<ul>
<li>I experience inspiration.</li></ul></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://carcinisation.com/2020/07/04/the-ongoing-accomplishment-of-the-big-five/">https://carcinisation.com/2020/07/04/the-ongoing-accomplishment-of-the-big-five/</a></em></p>]]>
            </description>
            <link>https://carcinisation.com/2020/07/04/the-ongoing-accomplishment-of-the-big-five/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740367</guid>
            <pubDate>Sun, 05 Jul 2020 17:36:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RISC-V, China, Nightingales]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23740272">thread link</a>) | @ceohockey60
<br/>
July 5, 2020 | https://interconnected.blog/riscv-china-nightingales/ | <a href="https://web.archive.org/web/*/https://interconnected.blog/riscv-china-nightingales/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>【想看中文的<a href="https://interconnected.blog/riscv-china-nightingales/#chinese-version-below">读者请点击这里</a>或滚动到本页下方】</p><p>Last weekend, I read <a href="https://www.huxiu.com/article/360061.html">a long, epic piece of techlore</a> that chronicled the fierce and bitter rivalry between TSMC and Samsung in their fight to become the world’s number 1 chip foundry, which stretched back three decades and continues today.</p><p>Among the many dramatic details was the “Nightingale program” that TSMC started in the mid-2010s to jumpstart its R&amp;D, because it was falling behind Samsung and losing Apple’s A9 chip orders to the Korean conglomerate. TSMC conceived of a three-shift, 24-hour non-stop R&amp;D operation, taking a page out of their fellow Taiwanese manufacturing behemoth Foxconn’s assembly operation. The “Nightingales” were engineers and researchers, who were willing to work the “graveyard shift” for a 30% increase in base salary and 50% increase in dividend payout. Due to this program, <strong>the total working hours clocked in Taiwan in 2014 was 2135</strong>, apparently the most of any economy in the world that year.</p><p>TSMC, and arguably Taiwan’s entire economy, was confronting an existential struggle at that time. SMIC (the largest chip foundry in China), and arguably China’s technological and economic future, is confronting a similarly existential struggle on a larger scale.</p><p>There are many interconnected elements that, when put together, could determine how China will come out on the other end of this struggle -- <strong>RISC-V, foundry technology, the “New Infrastructure” stimulus program, open source, and a few key TSMC personnels</strong>, who are now at the helm of China’s semiconductor industry.</p><p>Let’s take a look at each of them, sequentially and interconnectedly.</p><h2 id="risc-v-strengths-and-weaknesses">RISC-V: Strengths and Weaknesses</h2><p>The conversation around China’s journey towards technological self-reliance often involves <strong>RISC-V</strong> -- an open standard Instruction Set Architecture (ISA) for hardware that’s under open source licenses, thus any one can run, change, copy, and distribute it, in accordance with<a href="https://www.gnu.org/philosophy/free-sw.en.html"> the four freedoms</a> of open source.</p><figure><img src="https://lh6.googleusercontent.com/sVMZ8L3CA61u_kc0hdRdB9AItYEuK65vUJ70os7CAaFpogycLyqhYL_BbwMndKktijiEAF8Bi9WLyKCmW5ztmGE3Zhw2dQrRP0VwWcxWIsUqTFVFfYXIS4K5wp_SDExCRiug0cE1" alt=""><figcaption>RISC-V Ecosystem, courtesy of SiFive.</figcaption></figure><p>However, RISC-V is still young. Its<a href="https://riscv.org/specifications/"> user-space ISA</a> and<a href="https://riscv.org/specifications/privileged-isa/"> privileged ISA</a> wasn’t frozen, and thus ready for large-scale software and hardware development, until June 2019. The technology and community ecosystem is maturing, and support from large Chinese organizations has a lot to do with it. Of <a href="https://riscv.org/members-at-a-glance/">the six Premier Members</a> of the official RISC-V foundation, RISC-V International, &nbsp;four are Chinese organizations -- Alibaba, Huawei, RIOS Lab, and the Institute of Computing Technology of the Chinese Academy of Sciences.</p><p>But in the near future (say the next five years), what can RISC-V, the technology, realistically enable China to accomplish?</p><p><strong>What is it good for?</strong> &nbsp;RISC-V is a very good foundation for rapidly prototyping and building <strong>special purpose</strong> chips. The development cycle and experience feels closer to software than hardware. This speed in development is partly because it’s open-sourced -- no hassle in getting a commercial license, as oppose to its proprietary counterparts like ARM -- and also partly because the ISA itself is simplified and “reduced” (i.e. the R in RISC), as opposed to CISC (the C means “complex”) which underpins more powerful, proprietary ISAs like Intel’s x86. This reduced architecture enables and optimizes simple computation instructions well, literally elementary school math: addition, subtraction, multiplication, division, etc. It’s less capable of supporting complex mathematical operations, like matrix multiplication and partial derivative (used widely in Deep Learning AI).</p><p>Thus, in reality, chips designed using RISC-V have been used most commonly in <strong>IoT and embedded systems</strong> scenarios. Because of its simplicity and malleability, RISC-V chips also <strong>tend to have low power consumption</strong>, which is a good attribute when battery life is an issue, e.g. wearable devices. This reduced simplicity also means that the compiler (the software layer that translates code, like C, into machine instructions for a chip to execute) does not need to be purposefully designed to optimize performance on RISC-V. Using some common compilers <a href="https://riscv.org/software-status/#c-compilers-and-libraries">like GCC, which RISC-V </a>supports, will do.</p><p><strong>What does it lack? </strong>As you might’ve guessed, RISC-V’s reduced simplicity is also the source of its limitations. While many people like to pit RISC-V against a general purpose ISAs, like Intel’s, <strong>they are more compliments than competitors. </strong>In fact, special purpose RISC-V chips that accelerate certain computations for AI workloads do run side-by-side along general purpose Intel chips in the cloud. It’ll be a long time (more than five years, in my opinion) before RISC-V can enable the design of a <strong>general purpose</strong> chip that powers our iPhones, laptops, or cloud computing servers in a data center, with enough developers incentivized to both extend the ISA and the compiler and other infrastructure software on top of it.</p><p><strong>Can RISC-V become general purpose some day?</strong> Of course. <strong>But that’s not an inevitability</strong>. It’s <strong>a strategic choice</strong> that the RISC-V community can make and work towards, with all the complexity in upstream coordination, developer community building, and open governance, not to mention the work of building the technology itself, that must be executed collectively. That possible future is perhaps the most interesting question when we think about China’s self-reliance, which I’ll discuss in more detail below <strong>in the context of fostering open source</strong>.</p><h2 id="-new-infrastructure-">“New Infrastructure”</h2><p>With the strengths and weaknesses of RISC-V in mind, let’s see where RISC-V chips could get deployed in China’s economy and infrastructure in the foreseeable future.</p><p>It’s no secret that central government industrial policy matters a lot in China, even though its market-driven economy is what materializes much of that vision. The most relevant piece of policy is <a href="http://www.china.org.cn/business/2020-04/22/content_75961988.htm">the “New Infrastructure” spending plan </a>that came out of the National Development and Reform Commission, as a response to the COVID-19 pandemic to boost the economy. This infrastructure stimulus plan sits in a larger context of two other long-term strategic plans: Made in China 2025 and China Standards 2035.</p><p>The details of this “New Infrastructure” plan have emerged in the last couple months, with major emphasis in IT and digital infrastructure, not just traditional infrastructure like highways and railroads. As it often happens in China, the signals sent from the top have already shifted private investment dollars. Nascent chip startups, all of a sudden, are <a href="https://uk.reuters.com/article/uk-china-semiconductors-analysis/sino-u-s-tech-race-turbo-charges-china-chip-investment-triggering-bubble-fear-idUKKBN23V3CO">enjoying investor attention and bubbly valuations</a>.</p><p>With that said, here are some of the “New Infrastructure” sectors that I think RISC-V could play an immediate role in, given its strengths:</p><ul><li>IoT</li><li>Smart transportation</li><li>New energy vehicle chargers</li><li>Limited AI (specific workloads that need customized acceleration)</li><li>Autonomous vehicles (limited to certain types of sensors and data collection)</li></ul><p>And as for sectors that I don’t see RISC-V making much of a dent, given its current limitations:</p><ul><li>Cloud computing</li><li>5G (both base station construction and consumer devices)</li><li>Blockchain</li><li>Data centers</li><li>Big data</li><li>Large-scale AI training and production deployment</li></ul><p>As you can see, RISC-V impact would be limited,<strong> but not insignificant</strong>. The logical next step would be for China to help evolve RISC-V <strong>into a more general purpose ISA</strong>, and reduce its reliance on proprietary solutions from ARM or Intel that could always be subjected to more sanctions.</p><p>The path to that end would have to be fostering open source <strong>and doing it the right way.</strong></p><h2 id="fostering-open-source-the-right-way">Fostering Open Source, the Right Way</h2><p>Open source has been popping up in <a href="https://mp.weixin.qq.com/s/Qcze4R-7zL2wjMh_DNVCIQ">a lot of discussions</a> in various Chinese technical and R&amp;D communities, triggered in particular by MATLAB being now off-limit to Chinese universities that are on the U.S. export control entity list. The discussion inevitably leads to open source: are there open source alternatives to MATLAB? What about CAD softwares, like EDA tools, which every chip foundry needs? Will there be an open source EDA option?</p><p>Implicit in these discussions is a predominant “takers” mentality towards open source. In China, open source solutions are mostly seen as “free stuff” that you can take and use, without any expectation or incentive to give back (or in open source parlance: “contribute upstream”).</p><p>It’s already happening in RISC-V. Alibaba <a href="https://www.techspot.com/news/81177-china-alibaba-making-16-core-25-ghz-risc.html">sports the fastest RISC-V based processor to date</a>, but there’s no intention to my knowledge for the design to also be open-sourced or at least publicly shared for the benefit of the ecosystem. Many small startups in China, now showered with new investments, are doing the same -- using RISC-V to make special purpose chips that are effectively proprietary.</p><p><em>(This is not to generalize that all Chinese organizations are bad open source players; some are contributing a lot and have open source in their DNA. I’ve profiled many of the big tech firms and some startups from the lens in Part II of my “</em><a href="https://interconnected.blog/open-source-in-china-the-game/"><em>Open Source in China</em></a><em>” series.)</em></p><p><strong>If</strong> China hopes to evolve RISC-V into a more powerful, general-purpose building block to achieve semiconductor self-reliance, Chinese organizations, both individually and collectively, would have to shift from a zero-sum “takers” mentality to a positive-sum “stakeholders” mentality. What that means in reality is absorbing and practicing the open source way of doing things -- not just contributing code upstream and being more willing to share, but also behaviors like transparent governance, open discussions with other stakeholders and developers, and clear due process for decision-making, big and small. <strong>These are both technical and human complexities.</strong></p><p>With an existential struggle at hand, there’s reason to believe that Chinese companies may behave differently for the sake of achieving a national imperative and be less concerned about the tit-for-tat, zero-sum nature of market competition, which is quite cutthroat in China. And<strong> if done right</strong>, RISC-V could unleash massive technological innovation broadly and help China deal with its existential struggle specifically.</p><h2 id="foundries-smic-hsmc">Foundries: SMIC, HSMC</h2><p>Let’…</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://interconnected.blog/riscv-china-nightingales/">https://interconnected.blog/riscv-china-nightingales/</a></em></p>]]>
            </description>
            <link>https://interconnected.blog/riscv-china-nightingales/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740272</guid>
            <pubDate>Sun, 05 Jul 2020 17:22:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Laptop Battery Insights]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23740187">thread link</a>) | @theocs
<br/>
July 5, 2020 | https://blog.cfelde.com/2020/07/laptop-battery-insights/ | <a href="https://web.archive.org/web/*/https://blog.cfelde.com/2020/07/laptop-battery-insights/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>

<p>Back in 2016 I mentioned that I started <a href="https://blog.cfelde.com/2016/01/tracking-my-laptop-battery/">tracking my laptop battery statistics</a> on my then new MBP. Well, now that laptop has reached EOL, with its batteries getting swollen and the fan often running a bit fast, probably due to all the dust inside it.</p>
<p>While I didn’t have any complaints about the overall performance of my trusty old laptop, after 5-6 years of everyday use, I felt it was time to upgrade. And it didn’t feel safe with the batteries swelling either! I might look into refurbishing it, if the cost of new batteries aren’t too ridiculous.</p>
<p>Anyway, as I mentioned in my previous battery blog post, I started logging battery statistics once every half hours, on a simple cron job, with a simple little script.</p>
<figure><img src="https://blog.cfelde.com/wp-content/uploads/2016/01/script-1024x361.png" alt="" srcset="https://blog.cfelde.com/wp-content/uploads/2016/01/script-1024x361.png 1024w, https://blog.cfelde.com/wp-content/uploads/2016/01/script-300x106.png 300w, https://blog.cfelde.com/wp-content/uploads/2016/01/script-768x270.png 768w, https://blog.cfelde.com/wp-content/uploads/2016/01/script-660x232.png 660w, https://blog.cfelde.com/wp-content/uploads/2016/01/script.png 1204w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
<p>So let’s take a look at 5-6 years of data, starting with battery capacity:</p>
<figure><img src="https://blog.cfelde.com/wp-content/uploads/2020/07/Battery-max-capacity-vs-Date.png" alt="" srcset="https://blog.cfelde.com/wp-content/uploads/2020/07/Battery-max-capacity-vs-Date.png 600w, https://blog.cfelde.com/wp-content/uploads/2020/07/Battery-max-capacity-vs-Date-300x186.png 300w" sizes="(max-width: 600px) 100vw, 600px"></figure>
<p>Got to say that I’m impressed with the overall trend here. I was expecting it to have a stronger downwards trend, considering age and usage, but also compared to the number of hours of use I got when running on batteries. I guess maybe I incorrectly remember how long I initially could run it on batteries when it was new.</p>
<p>What about cycle count then?</p>
<figure><img src="https://blog.cfelde.com/wp-content/uploads/2020/07/Usage-hours-acc-vs-Date.png" alt="" srcset="https://blog.cfelde.com/wp-content/uploads/2020/07/Usage-hours-acc-vs-Date.png 600w, https://blog.cfelde.com/wp-content/uploads/2020/07/Usage-hours-acc-vs-Date-300x186.png 300w" sizes="(max-width: 600px) 100vw, 600px"></figure>
<p>Here we see the battery cycle count in red, using the y-axis on the right, together with the accumulated hours of use. As expected these follow each other.</p>
<p>I’ve seen some state that Apple expects a battery to retain 80% of it’s capacity at 1000 cycles. I’m not close to 1000 cycles, but compared to the slow downwards trend on the capacity chart, that’s maybe not unreasonable. However, with the swelling going on, I wouldn’t be comfortable trying to get to 1000 cycles.</p>
<p>I’ve <a href="https://docs.google.com/spreadsheets/d/1HA-T8m78_6uhR_hYgmkW-WktgLQ1JX6ufjH3s_bri-Y/edit?usp=sharing">published all the charts and raw data on Google Sheets</a>, so feel free to look around. The only other chart I considered including was one showing average and median use by day. But, as it turns out, these were rather equal, with a little peak on Tuesdays. These aren’t maybe that insightful anyway, as I often just leave my laptop running.</p>
</div>
</div></div>]]>
            </description>
            <link>https://blog.cfelde.com/2020/07/laptop-battery-insights/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740187</guid>
            <pubDate>Sun, 05 Jul 2020 17:10:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Choosing a Rust web framework]]>
            </title>
            <description>
<![CDATA[
Score 89 | Comments 30 (<a href="https://news.ycombinator.com/item?id=23740028">thread link</a>) | @LukeMathWalker
<br/>
July 5, 2020 | https://www.lpalmieri.com/posts/2020-07-04-choosing-a-rust-web-framework-2020-edition/ | <a href="https://web.archive.org/web/*/https://www.lpalmieri.com/posts/2020-07-04-choosing-a-rust-web-framework-2020-edition/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

<blockquote>
<p><em>This post was originally meant as a section of <a href="https://www.lpalmieri.com/posts/2020-05-24-zero-to-production-0-foreword/"><strong>Zero To Production</strong></a> to explain the reasoning behind our technology choice. It eventually grew so large to be its own article!</em></p>

<p><em>You can discuss the article on <a href="https://news.ycombinator.com/item?id=23740028">HackerNews</a> or <a href="https://www.reddit.com/r/rust/comments/hlpsw5/choosing_a_rust_web_framework_2020_edition/">r/rust</a></em>.</p>
</blockquote>

<p>As of July 2020, the main web frameworks in the Rust ecosystem are:</p>

<ul>
<li><a href="https://actix.rs/"><code>actix-web</code></a>;<br></li>
<li><a href="https://rocket.rs/"><code>rocket</code></a>;<br></li>
<li><a href="https://github.com/http-rs/tide"><code>tide</code></a>;<br></li>
<li><a href="https://github.com/seanmonstar/warp"><code>warp</code></a>.</li>
</ul>

<p>Which one should you pick if you are about to start building a new <strong>production-ready</strong> API in Rust?</p>

<p>I will break down where each of those web frameworks stands when it comes to:</p>

<ul>
<li><a href="#1-comprehensiveness">Comprehensiveness</a>;<br></li>
<li><a href="#2-community-and-adoption">Community and adoption</a>;<br></li>
<li><a href="#3-sync-vs-async">Sync vs Async</a>, as well as their choice of <a href="#3-1-futures-runtime">futures runtime</a>;<br></li>
<li><a href="#4-documentation-tutorials-and-examples">Documentation, tutorials and examples</a>;<br></li>
<li><a href="#5-api-and-ergonomics">API and ergonomics</a>.</li>
</ul>

<p>I will in the end make <a href="#6-our-choice">my recommendation</a>.<br>
Worth remarking that there are no absolutes: different circumstances (and taste) might lead you to a different pick.</p>

<h2 id="1-comprehensiveness">1. Comprehensiveness</h2>

<p><code>actix-web</code>, <code>tide</code> and <code>warp</code> are <em>slim</em> web frameworks: they offer you an HTTP web server, routing logic, middleware infrastructure and basic building blocks and abstractions to parse, manipulate and respond to HTTP requests.</p>

<p><code>rocket</code> takes a different approach - it aims to be batteries-included: the most common needs should be covered by functionality provided out-of-the-box by <code>rocket</code> itself, with hooks for you to extend <code>rocket</code> if your usecase needs it.<br>
It should not come as a surprise then that <code>rocket</code> ships an easy-to-use <a href="https://rocket.rs/v0.4/guide/state/#databases">integration to manage connection pools</a> for several popular database (e.g. Postgres, Redis, Memcache, etc.) as well as its own <a href="https://rocket.rs/v0.4/guide/configuration/">configuration system</a> in <a href="https://api.rocket.rs/v0.4/rocket_contrib/"><code>rocket-contrib</code></a>, an ancillary crate hosted in <code>rocket</code>’s own repository.</p>

<p>We can compare them to frameworks available in other ecosystems:</p>

<ul>
<li><code>actix-web</code>, <code>tide</code> and <code>warp</code> are closer in spirit to <a href="https://palletsprojects.com/p/flask/"><code>Flask</code></a> from Python or <a href="https://expressjs.com/"><code>Express</code></a> from Javascript - they might be opinionated, but they do not ship a configuration management system or an ORM integration out of the box. You are in charge of structuring your API as you deem appropriate, bringing all the necessary crates and patterns into the picture;<br></li>
<li><code>rocket</code> is closer to <a href="https://www.djangoproject.com/"><code>Django</code></a> from Python or <a href="https://symfony.com/"><code>Symphony</code></a> from PHP: a stable and solid core with a set of high-quality in-tree components to fulfill your every day needs when building a solid web application. <code>rocket</code> has still a long way to go to match its peers in breadth and scope, but it is definitely off to a good start.</li>
</ul>

<p>Of course this is a snapshot of the landscape as of today, but the situation is continuously shifting according to the maintainers’ intentions - e.g. <code>actix-web</code> has slowly been accumulating more and more supporting functionality (from security to session management) in <a href="https://github.com/actix/actix-extras"><code>actix-extras</code></a>, under the umbrella of the <code>actix</code> GitHub organization.<br>
Furthermore, using a slim web framework does not force you to write everything from scratch as soon as the framework is falling short of your needs: you can leverage the ecosystem built by the community around it to avoid re-inventing the wheel on every single project.</p>

<h2 id="2-community-and-adoption">2. Community and adoption</h2>

<p>Numbers can be misleading, but they are a good conversation starting point. Looking at <a href="https://crates.io/">crates.io</a>, we have:</p>

<table>
<thead>
<tr>
<th>Framework</th>
<th>Total Downloads</th>
<th>Daily Downloads</th>
</tr>
</thead>

<tbody>
<tr>
<td><code>actix-web</code></td>
<td>~1250k</td>
<td>~3000</td>
</tr>

<tr>
<td><code>rocket</code></td>
<td>~525k</td>
<td>~1000</td>
</tr>

<tr>
<td><code>warp</code></td>
<td>~435k</td>
<td>~3000</td>
</tr>

<tr>
<td><code>tide</code></td>
<td>~47k</td>
<td>~300</td>
</tr>
</tbody>
</table>

<p>The number of total downloads is obviously influenced by how long a framework has been around (e.g. <code>actix-web:0.1.0</code> came out at the end of 2017!) while daily downloads are a good gauge for the current level of interest around it.</p>

<p>You should care about adoption and community size for a couple of reasons:</p>

<ul>
<li>consistent production usage over years makes it way less likely that you are going to be the first one to spot a major defect. Others cried so that you could smile (most of the time);<br></li>
<li>it correlates with the number of supporting crates for that framework;<br></li>
<li>it correlates with the amount of tutorials, articles and helping hands you are likely to find if you are struggling.</li>
</ul>

<p>The second point is particularly important for slim frameworks.<br>
You can get a feel of the impact of community size, once again, by looking at the number of results popping up on <a href="https://crates.io/">crates.io</a> when searching a framework name:</p>

<table>
<thead>
<tr>
<th>Framework</th>
<th># results</th>
</tr>
</thead>

<tbody>
<tr>
<td><code>rocket</code></td>
<td>178</td>
</tr>

<tr>
<td><code>actix-web</code></td>
<td>113</td>
</tr>

<tr>
<td><code>warp</code></td>
<td>57</td>
</tr>

<tr>
<td><code>tide</code></td>
<td>20</td>
</tr>
</tbody>
</table>

<p>Will all those crates be relevant? Unlikely.<br>
Will a fair share of them be outdated or unproven? Definitely.</p>

<p>Nonetheless it is a good idea, before starting a project, to have a quick look for functionality you know for a fact you will need. Let’s make a couple of quick examples with features we will be relying on in the email newsletter implementation we are building in <em>Zero To Production</em>:</p>

<ul>
<li>if you need to add Prometheus’ metrics to your API you can get off the ground in a couple of minutes with <a href="https://crates.io/crates/actix-web-prom"><code>actix-web-prom</code></a> or <a href="https://crates.io/crates/rocket_prometheus"><code>rocket-prometheus</code></a>, both with thousands of downloads. If you are using <code>warp</code> or <code>tide</code> you will have to write the integration from scratch;<br></li>
<li>if you want to add distributed tracing, <a href="https://crates.io/crates/actix-web-opentelemetry"><code>actix-web-opentelemetry</code></a> has your back. You will have to re-implement it if you choose any other framework.</li>
</ul>

<p>Most of these features are not too much work to implement, but the effort (especially maintenance) compounds over time. You need to choose your framework with your eyes wide open on the level of commitment it is going to require.</p>

<h2 id="3-sync-vs-async">3. Sync vs Async</h2>

<p>Rust landed its <code>async</code>/<code>await</code> syntax in version <code>1.39</code> - a game changer in terms of ergonomics for asynchronous programming.<br>
It took some time for the whole Rust ecosystem to catch up and adopt it, but it’s fair to say that crates dealing with IO-bound workloads are now generally expected to be async-first (e.g. <code>reqwest</code>).</p>

<p>What about web frameworks?<br>
<code>actix-web</code> adopted <code>async</code>/<code>await</code> with its <code>0.2.x</code> release, same as <code>warp</code>, while <code>tide</code> was using <code>async</code>/<code>await</code> before its stabilisation relying on the <code>nightly</code> Rust compiler.<br>
<code>rocket</code>, instead, still exposes a synchronous interface. <code>async</code>/<code>await</code> support is expected as part of its next <code>0.5</code> release, <a href="https://github.com/SergioBenitez/Rocket/issues/1065">in the making since last summer</a>.</p>

<p>Should you rule out <code>rocket</code> as a viable option because it does not yet support asynchronous programming?<br>
It depends.<br>
If you are implementing an application to handle high volumes of traffic with strict performance requirements it might be better to opt for an async web framework.<br>
If that is not the case, the lack of async support in <code>rocket</code> should not be one of your primary concerns.</p>

<h3 id="3-1-futures-runtime">3.1. Futures runtime</h3>

<p><code>async</code>/<code>await</code> is not all sunshine and roses.<br>
Asynchronous programming in Rust is built on top of the <code>Future</code> trait: a future exposes a <code>poll</code> method which has to be called to allow the future to make progress. You can think of Rust’s futures as <em>lazy</em>: unless polled, there is no guarantee that they will execute to completion.<br>
This is often been described as a <em>pull</em> model compared to the <em>push</em> model adopted by other languages<sup id="fnref:async-announcement"><a href="#fn:async-announcement">1</a></sup>, which has some interesting implications when it comes to performance and task cancellation.</p>

<p>Wait a moment though - if futures are lazy and Rust does not ship a runtime in its standard library, who is in charge to call the <code>poll</code> method?<br>
<strong>BYOR</strong> - <strong>B</strong>ring <strong>Y</strong>our <strong>O</strong>wn <strong>R</strong>untime!<br>
The async runtime is literally a dependency of your project, brought in as a crate.<br>
This provides you with a great deal of flexibility: you could indeed implement your own runtime optimised to cater for the specific requirements of your usecase (see <a href="http://smallcultfollowing.com/babysteps/blog/2019/12/09/async-interview-2-cramertj/#async-interview-2-cramertj">the Fuchsia project</a> or <a href="https://github.com/bastion-rs/bastion"><code>bastion</code></a>’s actor framework) or simply choose the most suitable on a case-by-case basis according to the needs of your application.<br>
That sounds amazing on paper, but reality is a bit less glamorous: interoperability between runtimes is quite poor at the moment; mixing runtimes can be painful, often causing issues that are not straight-forward either to triage, detect or solve.<br>
While most libraries should not depend on runtimes directly, relying instead on the interfaces exposed by the <a href="https://docs.rs/futures/0.3.5/futures/"><code>futures</code></a> crate, this is often not the case due to historical baggage (e.g. <code>tokio</code> was for a long time the only available runtime in the ecosystem), practical needs (e.g. a framework has to be able to spawn tasks) or lack of standardisation (e.g. the ongoing discussion on the <code>AsyncRead</code>/<code>AsyncWrite</code> traits - see <a href="http://smallcultfollowing.com/babysteps/blog/2020/01/20/async-interview-5-steven-fackler/">here</a> and <a href="http://smallcultfollowing.com/babysteps/blog/2020/03/10/async-interview-7-withoutboats/#async-interview-7-withoutboats">here</a>).<br>
Therefore picking an async web framework goes beyond the framework itself: you are choosing an ecosystem of crates, suddenly making it much more cumbersome to consume libraries relying on a different async runtime.</p>

<p>The current state of affairs is far from ideal, but if you are writing async Rust today I’d recommend you to make a <em>deliberate</em> choice when it comes to your async runtime.</p>

<p>The two main general-purpose async runtimes currently available in Rust are <a href="https://tokio.rs/"><code>tokio</code></a> and <a href="https://github.com/async-rs/async-std"><code>async-std</code></a>.<br>
<code>tokio</code> has been around for quite some time and it has seen extensive production usage. It is fairly tunable, although this results in a larger and more complex API surface.<br>
<code>async-std</code> was released almost a year ago, around the time of <code>async</code>/<code>await</code> stabilization. It provides great ergonomics, while leaving less room for configuration knobs.</p>

<p><a href="https://crates.io/">crates.io</a> can once again be used as a gauge for adoption and readiness:</p>

<table>
<thead>
<tr>
<th>Runtime</th>
<th>Total Downloads</th>
<th>Daily Downloads</th>
</tr>
</thead>

<tbody>
<tr>
<td><code>tokio</code></td>
<td>~9600k</td>
<td>~30k</td>
</tr>

<tr>
<td><code>async-std</code></td>
<td>~600k</td>
<td>~4k</td>
</tr>
</tbody>
</table>

<p>How do frameworks map to runtimes?</p>

<table>
<thead>
<tr>
<th>Framework</th>
<th>Runtime</th>
</tr>
</thead>

<tbody>
<tr>
<td><code>actix-web</code></td>
<td><code>tokio</code></td>
</tr>

<tr>
<td><code>rocket</code> (<code>0.5.x</code>)</td>
<td><code>tokio</code></td>
</tr>

<tr>
<td><code>tide</code></td>
<td><code>async-std</code></td>
</tr>

<tr>
<td><code>warp</code></td>
<td><code>tokio</code></td>
</tr>
</tbody>
</table>

<h2 id="4-documentation-tutorials-and-examples">4. Documentation, tutorials and examples</h2>

<p>Having to dive into the source code to understand how something works can be fun (and educational!), but it should be a choice, not a necessity.<br>
In most situations I’d rather rely on the framework being well-documented, including non-trivial examples of relevant usage patterns.<br>
Good documentation, tutorials and fully-featured examples are <strong>mission-critical</strong> if you are working as part of a team, especially if one or more teammates are not experienced Rust developers.</p>

<p>Rust’s tooling treats documentation as a first class concept (just run <code>cargo doc --open</code> to get auto-generated docs for your project!) and it grew to be part of the culture of the Rust community itself. Library authors generally take it seriously and web frameworks are no exception to the general tendency: what you can find on <a href="https://docs.rs/">docs.rs</a> is quite thorough, with contextual examples …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.lpalmieri.com/posts/2020-07-04-choosing-a-rust-web-framework-2020-edition/">https://www.lpalmieri.com/posts/2020-07-04-choosing-a-rust-web-framework-2020-edition/</a></em></p>]]>
            </description>
            <link>https://www.lpalmieri.com/posts/2020-07-04-choosing-a-rust-web-framework-2020-edition/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740028</guid>
            <pubDate>Sun, 05 Jul 2020 16:49:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scaling Pandas: Comparing Dask, Ray, Modin, Vaex, and Rapids]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 30 (<a href="https://news.ycombinator.com/item?id=23740012">thread link</a>) | @FHMS
<br/>
July 5, 2020 | https://datarevenue.com/en-blog/pandas-vs-dask-vs-vaex-vs-modin-vs-rapids-vs-ray | <a href="https://web.archive.org/web/*/https://datarevenue.com/en-blog/pandas-vs-dask-vs-vaex-vs-modin-vs-rapids-vs-ray">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>Python and its most popular data wrangling library, Pandas, are soaring in popularity. Compared to competitors like Java, Python and Pandas make data exploration and transformation <strong>simple</strong>.</p><p>But both Python and Pandas are known to have issues around <strong>scalability</strong> and <strong>efficiency</strong>.</p><p>Python loses some efficiency right off the bat because it’s an interpreted, dynamically typed language. But more importantly, Python has always focused on simplicity and readability over raw power. Similarly, Pandas focuses on offering a simple, high-level API, largely ignoring performance. In fact, the creator of Pandas wrote “<a href="https://wesmckinney.com/blog/apache-arrow-pandas-internals/">The 10 things I hate about pandas</a>,” which summarizes these issues:</p><figure id="w-node-412b9aecdea3-e2612716"><p><img src="https://global-uploads.webflow.com/5d3ec351b1eba4332d213004/5ef62e9007b2509635bd1ba2_image3.png" alt="Ten things Wes McKinney hates about Pandas."></p><figcaption>Performance issues and lack of flexibility are the main things Pandas’ own creator doesn’t like about the library. (<a href="https://wesmckinney.com/blog/apache-arrow-pandas-internals/">source</a>)</figcaption></figure><p>So it’s no surprise that many developers are trying to add more power to Python and Pandas in various ways. Some of the most notable projects are:</p><ul role="list"><li><a href="https://www.datarevenue.com/ml-tools/dask"><strong>Dask</strong></a><strong>:</strong> a low-level scheduler and a high-level partial Pandas replacement, geared toward running code on compute clusters.</li><li><strong>Ray:</strong> a low-level framework for parallelizing Python code across processors or clusters.</li><li><a href="https://www.datarevenue.com/ml-tools/modin"><strong>Modin</strong></a><strong>:</strong> a drop-in replacement for Pandas, powered by either <strong>Dask</strong> or <strong>Ray</strong>.</li><li><a href="https://www.datarevenue.com/ml-tools/vaex"><strong>Vaex</strong></a><strong>:</strong> a partial Pandas replacement that uses lazy evaluation and memory mapping to allow developers to work with large datasets on standard machines.</li><li><a href="https://www.datarevenue.com/ml-tools/rapids"><strong>RAPIDS</strong></a><strong>: </strong>a collection of data-science libraries that run on GPUs and include <a href="https://github.com/rapidsai/cudf">cuDF</a>, a partial replacement for Pandas.</li></ul><p>There are others, too. Below is an overview of the Python data wrangling landscape:</p><figure id="w-node-78c43e6cecae-e2612716"><p><img src="https://global-uploads.webflow.com/5d3ec351b1eba4332d213004/5ef62eb85c7038610cea20d0_image2.png" alt="A graph showing how often popular data wrangling libraries are compared in Google searches."></p><figcaption>Dask, Modin, Vaex, Ray, and CuDF are often considered potential alternatives to each other. Source: Created with <a href="https://anvaka.github.io/vs/?query=Dask">this tool</a></figcaption></figure><p>So if you’re working with a lot of data and need faster results, which should you use?</p><h2><strong>Just tell me which one to try</strong></h2><p>Before you can make a decision about which tool to use, it’s good to have some more context about each of their approaches. We’ll compare each of them closely, but you’ll probably want to try them out in the following order:</p><ul role="list"><li><strong>Modin</strong>, with <strong>Ray</strong> as a backend. By installing these, you might see significant benefit by changing just a single line (`import pandas as pd` to `import modin.pandas as pd`). Unlike the other tools, Modin aims to reach full compatibility with Pandas.</li><li><strong>Dask</strong>,<strong> </strong>a larger and hence more complicated project. But Dask also provides <a href="https://docs.dask.org/en/latest/dataframe.html">Dask.dataframe</a>, a higher-level, Pandas-like library that can help you deal with <a href="https://en.wikipedia.org/wiki/External_memory_algorithm">out-of-core</a> datasets.</li><li><strong>Vaex, </strong>which is designed to help you work with large data on a standard laptop. Its Pandas replacement covers some of the Pandas API, but it’s more focused on exploration and visualization.</li><li><strong>RAPIDS, </strong>if you have access to NVIDIA graphics cards<strong>.</strong></li></ul><h2><strong>Quick comparison</strong></h2><p>Each of the libraries we examine has different strengths, weaknesses, and scaling strategies. The following table gives a broad overview of these. Of course, as with many things, most of the scores below are heavily dependent on your exact situation.&nbsp;</p><figure id="w-node-3fc1cb6579be-e2612716"><p><img src="https://global-uploads.webflow.com/5d3ec351b1eba4332d213004/5ef62ef85090a97b0c469fa9_image5.png" alt="A table comparing the tools across maturity, popularity, ease of adoption, and other metrics."></p><figcaption>Dask and Ray are more mature, but Modin and Vaex are easier to get started with. Rapids is useful if you have access to GPUs.</figcaption></figure><p>These are subjective grades, and they may vary widely given your specific circumstances. When assigning these grades, we considered:</p><ul role="list"><li><strong>Maturity: </strong>The time since the first commit and the number of commits.</li><li><strong>Popularity: </strong>The number of GitHub stars.</li><li><strong>Ease of Adoption: </strong>The amount of knowledge expected from users, presumed hardware resources, and ease of installation.</li><li><strong>Scaling ability: </strong>The broad dataset size limits for each tool, depending on whether it relies mainly on RAM, hard drive space on a single machine, or can scale up to clusters of machines.&nbsp;</li><li><strong>Use case: </strong>Whether the libraries are designed to speed up Python software in general (“<strong>General</strong>”), are focused on data science and machine learning (“<strong>Data science</strong>”), or are limited to simply replacing Pandas’ ‘DataFrame’ functionality (“<strong>DataFrame</strong>”).</li></ul><h2><strong>CPUs, GPUs, Clusters, or Algorithms?</strong></h2><p>If your dataset is too large to work with efficiently on a single machine, your main options are to run your code across…</p><ul role="list"><li><strong>...multiple threads or processors:</strong> Modern CPUs have several independent cores, and each core can run many threads. Ensuring that your program uses all the potential processing power by parallelizing across cores is often the easiest place to start.</li><li><strong>...GPU cores: </strong>Graphics cards were originally designed to efficiently carry out basic operations on millions of pixels in parallel. However, developers soon saw other uses for this power, and “GP-GPU” (general processing on a graphics processing unit) is now a popular way to speed up code that relies heavily on matrix manipulations.</li><li><strong>...compute clusters: </strong>Once you hit the limits of a single machine, you need a networked cluster of machines, working cooperatively.</li></ul><p>Apart from adding more hardware resources, clever algorithms can also improve efficiency. Tools like Vaex rely heavily on <a href="https://en.wikipedia.org/wiki/Lazy_evaluation"><strong>lazy evaluation</strong></a><strong> </strong>(not doing any computation until it’s certain the results are needed) and <a href="https://en.wikipedia.org/wiki/Memory-mapped_file"><strong>memory mapping</strong></a><strong> </strong>(treating files on hard drives as if they were loaded into RAM).</p><p>None of these strategies is inherently better than the others, and you should choose the one that suits your specific problem.</p><p>Parallel programming (no matter whether you’re using threads, CPU cores, GPUs, or clusters) offers many benefits, but it’s also quite complex, and it makes tasks such as debugging far more difficult.</p><p>Modern libraries can hide some – but not all – of this added complexity. No matter which tools you use, you’ll run the risk of expecting everything to work out neatly (below left), but getting chaos instead (below right).</p><figure id="w-node-7b8872b99c95-e2612716"><p><img src="https://global-uploads.webflow.com/5d3ec351b1eba4332d213004/5efef852495a4ce0972910e9_image4_s.jpg" alt="Puppies in a row eating food from different bowls – and then chaos ensues."></p><figcaption>Parallel processing doesn’t always work out as neatly as you expect. (<a href="https://www.reddit.com/r/aww/comments/2oagj8/multithreaded_programming_theory_and_practice/">Source</a>)</figcaption></figure><h2><strong>Dask vs. Ray vs. Modin vs. Vaex vs. RAPIDS</strong></h2><p>While not all of these libraries are direct alternatives to each other, it’s useful to compare them each head-to-head when deciding which one(s) to use for a project.</p><p>Before getting into the details, note that:</p><ul role="list"><li>RAPIDS is a collection of libraries. For this comparison, we consider only the <strong>cuDF</strong> component, which is the RAPIDS equivalent of Pandas.</li><li>Dask is better thought of as two projects: a low-level Python scheduler (similar in some ways to Ray) and a higher-level Dataframe module (similar in many ways to Pandas).</li></ul><h3><strong>Dask vs. Ray</strong></h3><p>Dask (as a lower-level scheduler) and Ray overlap quite a bit in their goal of making it easier to execute Python code in parallel across clusters of machines. Dask focuses more on the data science world, providing higher-level APIs that in turn provide partial replacements for Pandas, NumPy, and scikit-learn, in addition to a low-level scheduling and cluster management framework.</p><p>The creators of Dask and Ray discuss how the libraries compare in <a href="https://github.com/ray-project/ray/issues/642">this GitHub thread</a>, and they conclude that the scheduling strategy is one of the key differentiators. Dask uses a centralized scheduler to share work across multiple cores, while Ray uses distributed bottom-up scheduling.</p><h3><strong>Dask vs. Modin</strong></h3><p>Dask (the higher-level Dataframe) acknowledges the limitations of the Pandas API, and while it partially emulates this for familiarity, it doesn’t aim for full Pandas compatibility. If you have complicated existing Pandas code, it’s unlikely that you can simply switch out Pandas for Dask.Dataframe and have everything work as expected. By contrast, this is exactly the goal Modin is working toward: 100% coverage of Pandas. Modin can run on top of Dask but was originally built to work with Ray, and that integration remains more mature.</p><h3><strong>Dask vs. Vaex</strong></h3><p>Dask (Dataframe) is not fully compatible with Pandas, but it’s pretty close. These close ties mean that Dask also carries some of the baggage inherent to Pandas. Vaex deviates more from Pandas (although for basic operations, like reading data and computing summary statistics, it’s very similar) and therefore is also less constrained by it.</p><p>Ultimately, Dask is more focused on letting you scale your code to compute clusters, while Vaex makes it easier to work with large datasets on a single machine. Vaex also provides features to help you easily visualize and plot large datasets, while Dask focuses more on data processing and wrangling.</p><h3><strong>Dask vs. RAPIDS (cuDF)</strong></h3><p>Dask and RAPIDS play nicely together via an integration <a href="https://rapids.ai/dask.html">provided by</a> RAPIDS. If you have a compute cluster, you should use Dask. If you have an NVIDIA graphics card, you should use RAPIDS. If you have a compute cluster of NVIDIA GPUs, you should use both.</p><h3><strong>Ray vs. Modin or Vaex or RAPIDS</strong></h3><p>It’s not that meaningful to compare Ray to Modin, Vaex, or RAPIDS. Unlike the other libraries, Ray doesn’t offer high-level APIs or a Pandas equivalent. Instead, Ray powers Modin and <a href="https://docs.ray.io/en/latest/tune.html">integrates with RAPIDS</a> in a similar way to Dask.</p><h3><strong>Modin vs. Vaex</strong></h3><p>As with the Dask and Vaex comparison, Modin’s goal is to provide a full Pandas replacement, while Vaex deviates more from Pandas. Modin should be your first port of call if you’re looking for a quick way to speed up existing Pandas code, while Vaex is more likely to be interesting for new projects or specific use cases (especially visualizing large datasets on a single machine).</p><h3><strong>Modin vs. RAPIDS (cuDF)</strong></h3><p>Modin scales Pandas code by using many CPU cores, via Ray or Dask. RAPIDS scales Pandas code by running it on GPUs. If you have GPUs available, give RAPIDS a try. But the easiest win is likely to come from Modin, and you should probably turn to RAPIDS only after you’ve tried Modin first.</p><h3><strong>Vaex vs. RAPIDS (cuDF)</strong></h3><p>Vaex and RAPIDS are similar in that they can both provide performance boosts on a single machine: Vaex by better utilizing your computer’s hard drive and processor cores, and RAPIDS by using your computer’s GPU (if it’s available and compatible). The RAPIDS project as a whole aims to be much broader than Vaex, letting you do machine learning end-to-end without the data leaving your GPU. Vaex is better for prototyping and data exploration, letting you explore large datasets on consumer-grade machines.</p><h2><strong>Final remarks: Premature optimization is the root of all evil</strong></h2><p>It’s fun to play with new, specialized tools. That said, many …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://datarevenue.com/en-blog/pandas-vs-dask-vs-vaex-vs-modin-vs-rapids-vs-ray">https://datarevenue.com/en-blog/pandas-vs-dask-vs-vaex-vs-modin-vs-rapids-vs-ray</a></em></p>]]>
            </description>
            <link>https://datarevenue.com/en-blog/pandas-vs-dask-vs-vaex-vs-modin-vs-rapids-vs-ray</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740012</guid>
            <pubDate>Sun, 05 Jul 2020 16:47:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[3DChan V2, a 3D Imageboard]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23739898">thread link</a>) | @alexkrunch
<br/>
July 5, 2020 | https://3dchan.net/v3/ | <a href="https://web.archive.org/web/*/https://3dchan.net/v3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://3dchan.net/v3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739898</guid>
            <pubDate>Sun, 05 Jul 2020 16:33:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Play Hex against our RL agent]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739873">thread link</a>) | @natufunu
<br/>
July 5, 2020 | https://cleeff.github.io/hex | <a href="https://web.archive.org/web/*/https://cleeff.github.io/hex">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://cleeff.github.io/hex</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739873</guid>
            <pubDate>Sun, 05 Jul 2020 16:30:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Installment Subscription]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739829">thread link</a>) | @mikeberv
<br/>
July 5, 2020 | https://www.billiondollarstartupideas.com/ideas/installment-subscription | <a href="https://web.archive.org/web/*/https://www.billiondollarstartupideas.com/ideas/installment-subscription">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" data-updated-on="1593965992303" id="item-5f01f8bcc7077935484de88c"><div><div><div data-block-type="2" id="block-68653710b4fd3b7e6d4e"><div><p><strong>Problem: </strong>When you subscribe to something, you don’t built any equity or ownership. As soon as you cancel your subscription, you lose access to whatever you used to have. This phenomenon also happens with rent.</p><p><strong>Solution: </strong>A platform that specializes in creating financial instruments focused on the intersection of monthly subscriptions &amp; marginal cost to own. For example, Disney recently released Hamilton on Disney+ (<a href="https://www.theverge.com/2020/5/12/21255693/hamilton-musical-disney-plus-early-release-date-streaming-broadway-miranda">over a year early, too</a>) and is requiring that people subscribe to Disney+ in order to access it. What if, in addition, Disney allowed people to download the video and own it at a marginal cost, like an additional $0.99 or $4.99? Since subscriptions are often in the back of consumers’ minds (they only pay once a year or once a month) it’s much easier to sell add-ons to consumers once they are already on a subscription service.</p><p>This business would take a model that is already proven in gaming (in-game purchases) to generate new revenue sources for subscription companies. This model is extremely successful in gaming (<a href="https://www.gamesindustry.biz/articles/2018-06-27-69-percent-of-fortnite-players-have-bought-in-game-purchases-average-spend-is-usd85">69% of Fortnite players have bought in-game purchases and the average spend is $85</a>, netting <a href="https://www.businessinsider.com/how-much-money-does-fortnite-make-2019-1#:~:text=More%20specifically%3A%20%22Fortnite%22%20made,revenue%20numbers%20for%20%22Fortnite.%22">over $2.5 billion annually</a>), but has not been applied in other contexts. In their article on how the “<a href="https://www.theinformation.com/articles/pandemic-forces-studios-to-think-outside-the-box-on-movie-releases?utm_campaign=article_email&amp;utm_content=article-4411&amp;utm_medium=email&amp;utm_source=sg">Pandemic Forces Studios to Think Outside the Box on Movie Releases</a>,” <a href="https://www.theinformation.com/reporters/jessica-toonkel">Jessica Toonkel</a> and <a href="https://www.theinformation.com/reporters/tom-dotan">Tom Dotan</a> describe the pros and cons of a similar rent-to-buy option:</p><blockquote><p><strong>Introduce a rent-to-buy option.</strong>&nbsp;Give consumers the option, once they have rented a movie, to pay a little extra to own the film.&nbsp;</p><p><strong>Pros:</strong>&nbsp;This could drive more purchases of movies, as people would only fork over the extra money once they know they’ll like it enough to watch it again.&nbsp;</p><p><strong>Cons</strong>: Such an approach would only work for certain kinds of films, particularly children’s movies that kids are likely to watch repeatedly.</p></blockquote><p>This would be an innovation on the subscription-as-a-service and general subscription-based business models that have been extremely popular given the democratization of the internet.</p><p><strong>Monetization: </strong>Selling installment subscriptions as a service, or building a platform that takes a percentage of revenues to create these unique installment subscriptions.</p><p><strong>Contributed by: </strong><a href="https://www.michaelbervell.com/">Michael Bervell</a> (Billion Dollar Startup Ideas)</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.billiondollarstartupideas.com/ideas/installment-subscription</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739829</guid>
            <pubDate>Sun, 05 Jul 2020 16:25:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Here Is What You Need To Know Before Learning Code. Bookmark This Guide]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23739809">thread link</a>) | @yassinerajallah
<br/>
July 5, 2020 | https://devhypercharged.com/here-is-what-you-need-to-know-before-learning-how-to-code-bookmark-this-guide/ | <a href="https://web.archive.org/web/*/https://devhypercharged.com/here-is-what-you-need-to-know-before-learning-how-to-code-bookmark-this-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
			
<p>Before starting out, I’d like to take a minute to thank you for reading &amp; sharing my last article<span>&nbsp;</span><em><a href="https://devhypercharged.com/the-7-traps-that-make-your-software-unusable/">“You Need To Know These 7 Traps That Make Your Software Useless”</a></em></p>
<p>Since we have numerous new members joining the club, feel free to send me your requests, topics, comments, advice, and I’ll make sure to reply to each one of your emails!</p>
<p>Without further ado, let’s dive in.</p>
<p>Learning how to code can be daunting, the progress is slow, the concepts are unique, and the positive feedback loop that will keep you motivated is hard to maintain. Countless are the articles that tell you should learn some framework X because it’s the future or master a language Y because it’s robust. Personally, I wouldn’t have learned multiple stacks (Deep learning, iOS dev, Android dev, Game dev, Cloud services) had I found the right source to guide me. And this is what I wished I had known:</p>
<p>Before choosing what programming language/framework to learn, let’s establish these first principles:</p>
<h3><strong>Programming is an investment&nbsp;</strong></h3>
<p>Learning programming and taking it to the next level are two different things, this is what you’ll be working with for years to come, the market is competitive but you definitely have a spot – if you work hard+smart enough. You don’t need to be a genius but willing to sit down and work. Had I told anyone I wanted to learn deep learning when I was still a freshman with 0 experience in coding, they’d have laughed their life off.</p>
<p>When you pick a programming language, you’ll start building “assets”. Think of assets as utilities that help you in video games. The harder the level, the more you need them to win fast. Typically, after 2 or 3 side projects, you’ll be having a folder full of code snippets that will save you hours! (I’m constantly taking code from projects I’ve finished 3 years ago)</p>
<p>No, you don’t need to stick with your programming language and you can always bounce off to something else. That might sound counter-intuitive, but at least before switching, you’ll have an important cognitive asset:</p>
<ul>
<li>The ability to make complex decisions fast.</li>
<li>Knowing how to learn the new programming language/framework faster &amp; more reliably</li>
<li>Apply the same general concepts onto the new PL</li>
</ul>
<p>However, I don’t recommend switching areas frequently unless you have a valid technical reason for doing so.</p>
<h3><strong>You can’t skip the basics</strong></h3>
<p>Not fun to hear, I’m fully aware. But learning the basics is your first step into programming. Here, you build your tools, learn facts, and polish your skills. Many people struggle with this phase, and when stuck, they think programming isn’t for them.</p>
<p>Think of this step as learning how to reason in sequence. The human brain is a supercomputer on steroids, 1 + 1 appears trivial since you are looking at an equation from a top view. However, the machine only gets to look at 1 operand at a time, so you have to declare your intentions first then tell it what to do with your intentions.</p>
<p>Finally, you elevate your reasoning by solving a real-world problem using an algorithm (a set of instructions).</p>
<p>Again, it doesn’t have to be daunting or scary, as I always say, take an hour or two a day and learn at your own pace. Don’t compare with others because chances are you’ll feel overtaken. And there is no room for intelligence or stupidity in learning code. Only actions and results.</p>
<p>To close off this first part, I invite you to experiment and try whatever works for you. This isn’t the absolute rule on how to learn how to code. If the analogies aren’t that practical for you then great! set your own. If my logic is flawed, then also great, rethink yours! It’s always great to experiment.</p>
<p>Now let’s get you started with choosing the right platform, here is what you should know:</p>
<h2><strong>Gaming<span>&nbsp;</span></strong></h2>
<ul>
<li>Unity is your friend. I still remember the day I decided to make games and become a game dev. The language is C# and unbelievably easy to learn.</li>
<li>Some people prefer using Xcode, but the software is platform restricted, and from my experience, I found it a thousand times easier to learn game dev on Unity than Xcode</li>
<li>The game engine (Unity) does the heavy lifting, you tell the objects to move by a given speed and whether they can collide or not, and there you go, the embedded physics kick in</li>
<li>You’ll have a huge boost by learning design using Blender (An open-source software for design and animation) or similar. Nevertheless, it’s not required, but there will be instances when you wish you’d known how to design</li>
<li>You can compile your game for whatever platform! (Desktop, consoles, web, mobile, etc..) Check out<span>&nbsp;</span><a href="https://unity.com/features/multiplatform">this link</a><span>&nbsp;</span>for more info</li>
<li>The industry is competitive and requires a lot of discipline since you’ll be working long hours. Some like it some don’t, it’s up to you to decide</li>
<li>You are restricted a bit in terms of employment. There are only as many game dev companies out there, and if you don’t like the domain anymore, you’ll need to learn another skill instead of reusing what you already know</li>
<li>Game physics are annoying sometimes, however, the more you learn, the easier it gets – Classic debugging scenario. Game dev is inherently time-consuming given the small details to address. Also, often you’ll get unwanted guests: Bugs. The combinations of physics are near unlimited, sometimes you’ll find yourself debugging for 5 hours a small bug that you simply can’t fix. In this scenario, you can get help from someone you know or revert back to online forums.</li>
<li>No, you won’t make “easy” money with game development. It will take a bit of time to learn how to make smooth, flawless mechanics. So if you are doing it for the money only, maybe you want to save yourself the frustration.</li>
<li>If you are doing it by passion, by no means try it out! you’ll have so much fun creating weird games. Let your imagination go wild, it only gets better from there!</li>
</ul>
<h2><strong>Competitive Programming</strong></h2>
<ul>
<li>Simply practice and resilience: Back in freshman year, I decided to dive into competitive programming. It sounded nerdy and cool. I finished the “cracking the coding interview” by Google. Which contains 150 programming interview questions. I noticed slight progress given the giant amount of work I had to endure for a full summer.</li>
<li>If you want to make money through this, you sure love making money the hard way, but it’s doable. Nevertheless, this is a great way to get into big techs if you rank top in programming contests.</li>
<li>You only remember as much as you practice. The hidden trump card about Competitive programming isn’t the difficulty of the problems but how prepared are you. You don’t have to remember how you solved a problem but where you missed. If you stop practicing, you’ll feel you lost that ‘cognitive prowess’ that helped you draw links between multiple parts of the question.</li>
<li>More often than not, the standard programming language is C++. Python is on the rise too.</li>
</ul>
<h2><strong>Mobile Development</strong></h2>
<ul>
<li>Android or iOS, it’s up to you to choose. I prefer coding for iOS (Swift) because it feels much cleaner. Back in Android (Java/Kotlin), I had to deal with preliminary problems like fixing “Gradle” after an update to just get the project going. Also, I felt that Android was a bit messy to code for in a native language. So I switched to iOS.</li>
<li>iOS is more restricted, you need to pay $100/year for the Apple Developer Program. Also, you need the membership if you want to include advanced features in your app such as Deep Links, notifications, background activity, etc…</li>
<li>Android on the other side, you pay $25 for a<span>&nbsp;</span><strong>lifetime.</strong><span>&nbsp;</span>You submit as many apps as you want, and no one is restricting you in any way. You have a wide audience of developers and potential users waiting for your app. But on the other side, you are competing with more people.</li>
<li>Why not both? Use a framework! I learned both Android &amp; iOS dev and now I’m switching completely to Flutter (more on this in the last paragraph). Using a framework helps with coding for multiple platforms using the same code base. You don’t want to do double the work, and maintaining just 1 app needs<span>&nbsp;</span><strong>many!<span>&nbsp;</span></strong>people. It’s not a matter of “competency” but resources. If I judge by my skills, I don’t need anyone technical on my team, but often than not, I need many people to help me out because there are many small details to take care of.</li>
<li>App developers have a favorable edge in the job market. Mobile users are on the rise. According to BankMyCell, 3.5B people are using their smartphone and it’s only been growing to date</li>
<li>Career-wise, you can work anywhere from the comfort of your home. Also, you ‘ll progress quite fast if you know what you’re doing. Salaries are on the rise too, and the benefits are staggering. Finally, you’re not limited to some predefined companies, you can work for startups, freelance, build your own project, and so on.</li>
<li>This area is getting more &amp; more competitive, and there is a slight switch that is happening, which is the move to software development kits (aka Flutter, React native, etc…). Instead of paying a full-stack mobile dev to write code for 1 platform only, you can have the same code base work for multiple platforms.</li>
</ul>
<h2><strong>Web Development</strong></h2>
<ul>
<li>Web dev is in some serious demand as well. Here you don’t have a predefined programming language because you can literally combine multiple ones, for example: Html + CSS + JS. I never wanted to learn web dev because of javascript. Spaghetti language (sorry!) Also the idea of learning multiple languages to do 1 thing never made sense to me. However, in your case, this isn’t a problem anymore. If you are passionate about creating websites or Web apps, you can go for frameworks such as React Js or Flutter (in Beta). And you’re sorted for life.</li>
<li>No, you don’t need to worry about the “no-code tools” and the “website builders”. These can only help as much. If you want to focus on the backend (servers, technical logic, business logic, etc…) you are in a much better position given that each use case is different. And for a no-code tool to handle that, it’s pretty unreasonable.</li>
<li>Web Development is a dimension in itself. I’m not a web developer and don’t want to snap off someone …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://devhypercharged.com/here-is-what-you-need-to-know-before-learning-how-to-code-bookmark-this-guide/">https://devhypercharged.com/here-is-what-you-need-to-know-before-learning-how-to-code-bookmark-this-guide/</a></em></p>]]>
            </description>
            <link>https://devhypercharged.com/here-is-what-you-need-to-know-before-learning-how-to-code-bookmark-this-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739809</guid>
            <pubDate>Sun, 05 Jul 2020 16:23:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bug in Wireshark can be exploited by hackers for Denial of Service(DoS) attack]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739708">thread link</a>) | @vvpvijay
<br/>
July 5, 2020 | https://androidrookies.com/bug-in-wireshark-can-be-exploited-by-hackers-for-denial-of-servicedos-attack/ | <a href="https://web.archive.org/web/*/https://androidrookies.com/bug-in-wireshark-can-be-exploited-by-hackers-for-denial-of-servicedos-attack/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-8459"><div><div><div><h2>A flaw in network pentesting tool Wireshark allows hackers to remotely launch Denial of Service (DoS) and make CPU consume more resources</h2><p>If you are a hacker or a security researcher, you have probably used Wireshark. Wireshark is the world’s most popular network protocol analyzer. The software is free and open-source. <a href="https://www.wireshark.org/security/wnpa-sec-2020-09.html">Security researchers</a> have found a new vulnerability in the popular network sniffing tool. This vulnerability has been given the unique identifier <strong><a href="https://nvd.nist.gov/vuln/detail/CVE-2020-15466">CVE-2020-15466</a> and has a severity score of 5.7/10. </strong>The vulnerability could be exploited remotely by potential hackers to make the victim’s PC and CPU consume more resources and launch a denial of service (DoS) attack.</p><p><a href="https://androidrookies.com/the-complete-wireshark-cheat-sheet-to-live-sniff-network-traffic/" target="_blank"><span>The complete Wireshark cheat sheet to live-sniff network traffic</span></a></p><p>The vulnerability in Wireshark versions 3.2.0, 3.2.1, 3.2.2, 3.2.3, 3.2.4 exists due to an infinite loop within the GVCP dissector, allowing remote threat actors to deploy DoS attacks. A malicious hacker can pass a specially designed package tracking file to the vulnerable application, which will consume all system resources, leading to the DoS condition.</p><p>The report says that thought this Wireshark vulnerability can be exploited remotely by hackers, they have not found any evidence of it being exploited in the wild. Security researchers have also not found any malware variants authored to take advantage of the GVCP dissector infinite loop in Wireshark.</p><p>The <a href="https://bugs.wireshark.org/bugzilla/show_bug.cgi?id=16029">Wireshark developers</a> have already fixed the issue and have requested all the Wireshark users to update to the patched Wireshark version 3.2.5 which is available below:</p><div id="dl_box"><div id="accordion_download"><p>Wireshark developers have noted that there is no workaround for this particular vulnerability and Wireshark users have to to download the Wireshark version 3.2.5 to mitigate the risk of exploitation.</p></div></div></div></div></div></article><div><h3>About Author</h3><section> <img alt="" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20100%20100'%3E%3C/svg%3E" data-src="https://secure.gravatar.com/avatar/076b4a64b03cee86288f1132004881ab?s=100&amp;d=mm&amp;r=g" data-srcset="https://secure.gravatar.com/avatar/076b4a64b03cee86288f1132004881ab?s=200&amp;d=mm&amp;r=g 2x" height="100" width="100" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><div> <p>Hacker, coder, Jouno by night
When a good man is hurt, all who would be called good must suffer with him</p></div></section></div></div>]]>
            </description>
            <link>https://androidrookies.com/bug-in-wireshark-can-be-exploited-by-hackers-for-denial-of-servicedos-attack/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739708</guid>
            <pubDate>Sun, 05 Jul 2020 16:11:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Oops, I Wrote a C++ Compiler/Interpreter]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739677">thread link</a>) | @pcr910303
<br/>
July 5, 2020 | https://praeclarum.org/2018/08/27/oops-i-wrote-a-c-compiler.html | <a href="https://web.archive.org/web/*/https://praeclarum.org/2018/08/27/oops-i-wrote-a-c-compiler.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><strong>TL;DR</strong> I wrote a .NET library that can compile C/C++ code into
a byte code that it can also interpret. It is used in my
app <a href="http://icircuitapp.com/">iCircuit</a> to simulate Arduinos.
You can use it yourself with the nuget package <a href="https://www.fuget.org/packages/CLanguage">CLanguage</a>.</p>

<p><img src="https://praeclarum.org/images/2018/cdemo.gif" alt="Arduino code being edited in iCircuit"></p>

<h2 id="arduino-support-for-icircuit">Arduino Support for iCircuit</h2>

<p>The most requested feature for iCircuit, for years, has
been to support Arduino components.
I agreed with all my users that it would be an amazing
feature, but it was also a pretty big request that I wasn’t
sure I could complete.</p>

<p>I could easily add a component that <em>looked</em> like an Arduino -
had all the right pins, maybe even blinked an LED. However,
what people really wanted was a <em>programmable</em> Arduino
integrated into the circuit simulator.</p>

<p>Arduinos are programmed in C++ with a small base library known
as “Wiring”. Therefore, in order to simulate an Arduino, I
needed a C/C++ compiler and I needed to re-implement Wiring. Oh, and that compiler needs to
run on iOS, integrate into my circuit simulation, handle
bad code such as infinite loops and bad pointers, 
work within the sandbox (which means interpretation instead
of real execution), and it has to run on 4 platforms (iOS, Mac, Android, Windows).</p>

<p>Like I said, it was a big request! As tough as all that sounds,
I still personally wanted the feature and decided to find a way
to make it happen. Way back in 2010, I started work.</p>

<p>I first looked around for small C++ compilers and
interpreters that I could
get to work on iOS, Android, and Windows (iCircuit runs everywhere).
Sadly, the research was grim as no compiler
met all my requirements. Some would be nice and small but
only emit X86 code meaning I would have to write an X86 simulator. Others were so big and had so many dependencies
that I just gave up trying to get it to compile for iOS.</p>

<p>Fortunately in 2010, I was full of hubris and I figured now was the time in my life to write a C++ compiler. Oh how foolish…</p>

<h2 id="the-halcyon-days-of-2010">The Halcyon Days of 2010</h2>

<p>Compilers and Interpreters are, in principle, very simple
programs. I’d written a bunch of interpreters at this point
in my career and even wrote a couple simple compilers for very
small languages. I knew that C++ was a complex language, at
least syntactically (with all its type declarations) but that
its semantics - its model of computation - was rather basic.
I considered myself a good C++ programmer and thought I knew
the language inside and out. How hard could it be?</p>

<p>Like I said, hubris.</p>

<p>And so I embarked on writing my C++ compiler in C#
(the language iCircuit is written in).
I started by writing a C compiler because C++ is a monster of a
language. Most Arduino programs only use C features (I thought),
so it seemed like a reasonable starting point.</p>

<h3 id="writing-the-parser">Writing the Parser</h3>

<p>C is nice because you can actually parse it using
a <em>grammar definition</em> - a file that states the syntax of
the language. Grammars are great because you can use a code
generator to automatically create a parser for your language from this 
definition. This means you can focus on the semantics of
the language and let the parser generator deal with the syntax.</p>

<p>Back in 1985 someone posted a <a href="https://www.lysator.liu.se/c/ANSI-C-grammar-y.html">YACC grammar definition for C</a>
which served as my starting point.
I then used the <a href="https://www.cs.rit.edu/~ats/projects/lp/doc/jay/package-summary.html">jay parser generator</a> (the same tools used to generate the mono C# parser)
as my parser generator. This tool takes the grammar definition
and spits out nasty C# code to parse files. The
code is nasty because it’s fast and eschews standard coding
conventions for performance. I love it.</p>

<p>The process of creating the parser went very smoothly thanks
to this. The real work involves creating C# syntax classes
that mirror the grammar. These classes form the Abstract
Syntax Tree (AST) of the compiler. You can see the results
of this work by <a href="https://github.com/praeclarum/CLanguage/blob/master/CLanguage/Parser/CParser.jay">looking at my modified grammar</a>.</p>

<p>I ended up writing a <a href="https://github.com/praeclarum/CLanguage/tree/master/CLanguage/Syntax">variety of syntax classes</a> such as:</p>

<ul>
  <li><code>ForStatement</code> that captures the syntax of <code>for</code> loops</li>
  <li><code>BinaryExpression</code> that handles most math operators such as <code>+</code> and <code>*</code></li>
  <li><code>Block</code> that captures a sequence of statements</li>
</ul>

<p>And this is the point where I realized C was a bit more complex than I liked to think. My syntax classes were filled with scary names like “abstract
specifiers”, “type specifier”, “type qualifier”, “multi declarations”, and so on. I knew C
declarations were nutty but, oh my, they’re a disaster.</p>

<p>I was scared, but combatted that fear by writing a bunch of unit tests.
I figured, yes this problem is hard, but it’s just big - there was an end in sight. Maximum effort would be needed and would, hopefully, be rewarded.</p>

<p>And so I pressed on. I just kept writing sample code after sample code until
I understood how my concept of the language related to this
grammar. After some time, I was able to wrestle all these “specifiers”
into more manageable objects.</p>

<h3 id="definitions-and-types">Definitions and Types</h3>

<p>The next step to writing a compiler is
discovering definitions in code. Variable definitions, function
definitions, type definitions, all that. C and C++ are a little
wild because you can declare things multiple times but you can
only define them once. While C++ is designed to be compiled using
only a single pass over the AST, I ended up writing a multi-pass
compiler with separate stages for declaration discovery, resolution,
and emission.</p>

<p>Once I found declarations and definitions, I needed to build
a type system. Thankfully, at first glance, C’s types are very
basic. You have the machine types (ints and floats), 
structures, and, uh oh, pointers. The compiler would have to munge
around all the code and assemble and unify all these types.
I spent days and days just getting the integers right.</p>

<p>For example, we all know what this means:</p>



<p>But what does</p>

<div><div><pre><code><span>int</span> <span>long</span> <span>long</span> <span>short</span> <span>long</span> <span>foo</span><span>;</span>
</code></pre></div></div>

<p>mean? Unfortunately, that is valid code according to the grammar
I’m using, but it’s obviously not valid C code. 
The compiler has to deal with this kind of craziness.
Not even the integers are simple in C…</p>

<h3 id="emitting-executable-code">Emitting Executable Code</h3>

<p>Now it’s time for the compiler to earn its keep and emit
executable code. Most C compilers would emit X86 or ARM assembly.
However, there was no point in doing that as I can’t natively
execute code on iOS.</p>

<p>I decided to instead devise my own
virtual machine and byte code that would be easy to interpret.
I figured that if I controlled the compiler and the byte code
then I could arrange things to make the interpreter simple
and yet still expressive.</p>

<p>This was a bit of a gamble as it increased the number of
decisions I had to make. However, most byte codes I looked into
were very complex and I knew (I thought) I could keep my code
small and simple.</p>

<p>I settled on a stack-based virtual machine that is very similar
to how the Common Language Runtime (CLR) works. Every function
had a stack and computations were performed by pushing and popping
numbers to and from that stack. This is different from most real
machines like X86 that are <em>register-based</em> not stack-based.
Register-based machines scared me a bit because they reminded
me of very hard to read chapters of very hard to read books.
I knew how to implement them, but I lacked experience with them
and went with the simpler design.</p>

<p>Now that I had a semi-specified byte code and virtual machine,
it was only a matter of translating my syntax tree into byte
code. If you ignore performance, this is a trivial step for the compiler.
You can see, for example, how <code>if</code> statements get compiled by looking at the
<code>DoEmit</code> method of <code>IfStatement</code>:</p>

<div><div><pre><code><span>protected</span> <span>override</span> <span>void</span> <span>DoEmit</span> <span>(</span><span>EmitContext</span> <span>ec</span><span>)</span>
<span>{</span>
    <span>var</span> <span>falseLabel</span> <span>=</span> <span>ec</span><span>.</span><span>DefineLabel</span> <span>();</span>
    <span>var</span> <span>endLabel</span> <span>=</span> <span>ec</span><span>.</span><span>DefineLabel</span> <span>();</span>

    <span>Condition</span><span>.</span><span>Emit</span> <span>(</span><span>ec</span><span>);</span>
    <span>ec</span><span>.</span><span>EmitCastToBoolean</span> <span>(</span><span>Condition</span><span>.</span><span>GetEvaluatedCType</span> <span>(</span><span>ec</span><span>));</span>
    <span>ec</span><span>.</span><span>Emit</span> <span>(</span><span>OpCode</span><span>.</span><span>BranchIfFalse</span><span>,</span> <span>falseLabel</span><span>);</span>

    <span>TrueValue</span><span>.</span><span>Emit</span> <span>(</span><span>ec</span><span>);</span>
    <span>ec</span><span>.</span><span>Emit</span> <span>(</span><span>OpCode</span><span>.</span><span>Jump</span><span>,</span> <span>endLabel</span><span>);</span>

    <span>ec</span><span>.</span><span>EmitLabel</span> <span>(</span><span>falseLabel</span><span>);</span>
    <span>FalseValue</span><span>.</span><span>Emit</span> <span>(</span><span>ec</span><span>);</span>

    <span>ec</span><span>.</span><span>EmitLabel</span> <span>(</span><span>endLabel</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>This code first emits the condition. It then emits a branch to one of two
blocks - either the main body (<code>TrueValue</code>) or the <code>else</code> body (<code>FalseValue</code>).</p>

<p>I stole this emit architecture from the mono compiler - always steal from the best.</p>

<p>Most of those early decisions paid off well and after a few weeks
of work I was able to compile and interpret the most basic of
Arduino programs.</p>

<p>It was the hardest I ever had to work to get a stupid LED to blink.</p>

<h3 id="enough">Enough</h3>

<p>But that victory was met by a cold realization
of just how much more work was left to be done.</p>

<p>My compiler was working but it could only do math with 32 bit integers. My clever interpreter was stack based - which,
turns out, is not at all compatible with C’s flat memory model.
I had no idea how I would make real pointers work. I still
didn’t have support for structs. And this was all just for the
C compiler - I still needed to add C++ features!</p>

<p>And so, sadly, I gave up. It’s never easy to admit, but sometimes
problems are just too big for you.</p>

<h2 id="2018">2018</h2>

<p>Eight years is a long time and it’s funny how memories distort. 
I was working on the feature set for iCircuit 2 and Arduino was the first item on that list.
I knew I had a compiler capable of making an LED blink, and my memory
told me the compiler was nearly done it just needed a <em>bit</em> more work.
This time I reopened the code reluctantly, without hubris, mostly
curious to see what I would find.</p>

<p>I was pleasantly surprised to see how much ground I had covered
so long ago. I also realized that my memory betrayed me - the compiler had some
serious defects (no support for strings as a prime example) and that it was
going to be a lot of work to finish it. I remembered why I stopped 8 years ago.</p>

<p>However, after some thought, I decided that it was still useful.
It allowed you to use
the majority of the features of the Arduino and provided all the basics
you needed to write fun programs. 
I decided to release that compiler in <strong>iCircuit 1.9</strong> to 
finally provide the most requested feature of the app.</p>

<p>I was nervous, but very pleased to see that the 
Arduino component quickly became one of the most-used components in the app
and users seemed to love it.</p>

<h3 id="back-to-work">Back …</h3></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://praeclarum.org/2018/08/27/oops-i-wrote-a-c-compiler.html">https://praeclarum.org/2018/08/27/oops-i-wrote-a-c-compiler.html</a></em></p>]]>
            </description>
            <link>https://praeclarum.org/2018/08/27/oops-i-wrote-a-c-compiler.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739677</guid>
            <pubDate>Sun, 05 Jul 2020 16:06:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Population Based Training]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739659">thread link</a>) | @keyboardman
<br/>
July 5, 2020 | https://leimao.github.io/blog/Population-Based-Training/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Population-Based-Training/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>Training a machine learning model often requires a lot of hyperparameters, such as learning rate and regularization strength. The initial values of the hyperparameters and optionally how the hyperparameters are dynamically tuned during training would have a huge impact on the performance of the optimized model.</p>



<p>Given the combination of hyperparameter schedules are usually infinite, it is often not possible to do exhaustive search to find the best hyperparameter schedule for optimization, even with a lot of computer resources. Instead, what people often do is do hyperparameter grid search to some extent and optionally further fine-tune hyperparameters based on experience with a little bit more trials. While such method works well in practice, it requires a lot of human intervention and possibly miss a better model. Therefore, finding good hyperparameters and hyperparameter tuning approaches during optimization become critical for modeling.</p>



<p>In this blog post, I would like to discuss the <a href="https://arxiv.org/abs/1711.09846">population based training</a>, with a genetic algorithm inspired hyperparameter tuning schedule, proposed by DeepMind.</p>

<h3 id="machine-learning-optimization-theories">Machine Learning Optimization Theories</h3>

<p>Mathematically, a model consists of model parameters $\theta$, and our goal is to maximize or minimize an evaluation objective $Q(\theta)$. Typically, this $Q(\theta)$ already contains the entire model, the validation data, and a performance metric. For example, the evaluation objective for machine translation could be applying the validation data to the model, getting the outputs from the model, and compute the BLEU score, the performance metric, using the model outputs and ground truth labels. The evaluation objective $Q(\theta)$ does not have to be differentiable with respect to the model parameters $\theta$, and sometimes it could even be a black-box!</p>



<p>To maximize or minimize an evaluation objective $Q(\theta)$, we would need to find the optimized model parameters $\theta$, using some optimization techniques. In practice, we don’t want to use the evaluation objective for optimization, or the evaluation objective $Q(\theta)$ could not be directly used for optimization. For instance, the evaluation objective uses validation data and if we use the evaluation objective for optimization, the generalization of the optimized model would be usually poor in practice. Another common obstacle is that some optimization techniques requires the evaluation objective $Q(\theta)$ to be differentiable with respect to the model parameters $\theta$, but sometimes it is not the case.</p>



<p>Since the evaluation objective $Q(\theta)$ could not often be directly used for optimization, and we would propose a <a href="https://www.mathworks.com/help/gads/what-is-surrogate-optimization.html">surrogate objective</a> $\hat{Q}(\theta)$, hoping that by optimizing $\hat{Q}(\theta)$ with respect to the model parameters $\theta$, we would also achieve a good evaluation objective $Q(\theta)$. In machine learning, this surrogate objective is sometimes called training objective, and it contains the training data and the performance metric does not have to be the same to the one used in the evaluation objective. For example, the performance metric we used in machine translation model training is the sum of cross entropies, rather than BLEU score.</p>



<p>With the surrogate objective $\hat{Q}(\theta)$, finding the optimal parameters $\theta^{\ast}$ that maximize or minimize $\hat{Q}(\theta)$ does not happen magically. We would often need to use some optimization techniques to find the optimal parameters $\theta^{\ast}_{\hat{Q}(\theta)}$. Those optimization techniques would often introduce auxillary parameters $h$, which are often called as hyperparameters, to assist the finding of $\theta^{\ast}$. Therefore, given certain optimization techniques, the surrogate objective becomes $\hat{Q}(\theta | h)$. The hyperparameters could be some of the famous ones, such as the learning rate for gradient descent, and the regularization strength to prevent overfitting. However, this introduces some problems. The optimal parameters $\theta^{\ast}_{\hat{Q}(\theta|h)}$ for $\hat{Q}(\theta | h)$ might not be the same to the optimal parameters $\theta^{\ast}_{Q(\theta)}$ for $Q(\theta)$ which we truly care. Different $h$ would lead to different $\theta^{\ast}_{\hat{Q}(\theta|h)}$ and thus different values of $Q(\theta^{\ast}_{\hat{Q}(\theta|h)})$ which might or might not be close to $Q(\theta^{\ast}_{Q(\theta)})$.</p>



<p>Assuming the optimization technique would gives us good $\theta$ for $\hat{Q}(\theta | h)$, sometimes it could even be he the optimal parameters $\theta^{\ast}_{\hat{Q}(\theta|h)}$, how do we tune hyperparameters $h$ such that $Q(\theta)$ is as close to $Q(\theta^{\ast}_{Q(\theta)})$ as possible? Population based training, using the evolution of hyperparameters, is trying to solve this problem.</p>

<h3 id="population-based-training">Population Based Training</h3>

<p>Before we discuss the population based training, we would like to briefly review how people typically do hyperparameter tuning.</p>

<div>
<figure>
    <img src="https://leimao.github.io/images/blog/2020-06-28-Population-Based-Training/hyperparameter-tuning-paradigm.png">
    <figcaption>Hyperparameter Tuning Approaches</figcaption>
</figure>
</div>

<p>The sequential hyperparameter tuning approach is the most tedious for human beings but uses the least computation resources. We use one set of hyperparameters to train and evaluate the model. Based on the evaluation, we tune the hyperparameter and start the next round of training. We only runs one training instance throughout the entire tuning process but it could take a long time to find a good model that we feel satisfied with.</p>



<p>The parallel hyperparameter tuning approach is computation resource constrained. We run many training instances for different hyperparameters asynchronously, and find the best hyperparameters that gives the best evaluations. This approach, in my opinion, could hardly be called as “tuning”, since there is actually no tuning at all. The number of training instances we could run and the number of hyperparameters we would explore are solely dependent on how much computation resources we have and how much computation resource one training instance takes.</p>



<p>The population based hyperparameter tuning approach is a combination of the sequential approach and the parallel approach, with the human intervention in the sequential approach replaced with an automation from genetic algorithm. We run many training instance asynchronously with different hyperparameters $h_0$, and each training instance is updating the model parameters $\theta$ iteratively. At some point during the training, we compare the performances of all the training instances, and find out the one with the best performance. The rest of the training instances would start to use the exact same model parameters $\theta$ and the hyperparameters $h$ that the best training instance uses, which is called “exploitation”. Then, the hyperparameters $h$ for all the training instance other than the best training instance would be subject to some mutations, which is called “exploration”. In particular, “exploitation” means using the best configurations that the best training instance uses for all the training instances, “exploration” means mutating the hyperparameters for all the training instances other than the best training instance. The idea of population based training is simple and should be extremely familiar to the people who have experiences working with genetic algorithms.</p>

<h3 id="population-based-training-example">Population Based Training Example</h3>

<p>The DeepMind authors prepared a simple example to illustrate how the population based hyperparameter tuning approach is different from the other hyperparameter tuning approaches, such as grid search, given the same amount of computation resources.</p>



<p>In this particular setting, the evaluation objective is to maximize</p>



<p>where $\theta_0$ and $\theta_1$ are model parameters. The evaluation objective is treated as a black-box which we throw in $\theta_0$ and $\theta_1$ and generates a score. The maximum evaluation score it could achieve is $1.2$ when $\theta_0 = 0$ and $\theta_0 = 1$.</p>



<p>The surrogate objective we proposed is to maximize</p>



<p>where $h_0$ and $h_1$ are hyperparameters. We would use gradient ascent iteratively, with a fixed learning rate $\eta$, to optimize this surrogate objective, given the hyperparameters $h_0$ and $h_1$ and initial parameters $\theta_0$ and $\theta_1$.</p>



<p>Lucky us, the surrogate objective is very close to the black-box evaluation objective. If somehow we could be more lucky and use hyperparameters $h_0=1$ and $h_1=1$, optimizing surrogate objective would be equivalent to optimizing the evaluation objective, and we would be the most likely to have the maximum evaluation score.</p>



<p>We were given computation resources that allows running two training instances simultaneously. This time, we are not extremely lucky again. We used $\{h_0=1, h_1=0\}$ and $\{h_0=0, h_1=1\}$ as the initial hyperparameters for the two training instances, respectively. We want to check which hyperparameter tuning approach results in the best evaluation score, given the same amount of computation resources.</p>



<p>To make it “fair”, the model should be initialized with parameters $\theta_0=0.9$ and $\theta_1=0.9$, and each training instance is only allowed to use gradient ascent to update the hyperparameter $40$ times. The author did not mention what learning rate $\eta$ to use, but is the same for all training instances in all hyperparameter tuning approaches.</p>

<div>
<figure>
    <img src="https://leimao.github.io/images/blog/2020-06-28-Population-Based-Training/pbt-example.png">
    <figcaption>Population Based Training Example</figcaption>
</figure>
</div>

<p>The DeepMind authors created contour plots to make it easy to understand. The lighter the region is in the plot, the higher the evaluation score is. One training instance is denoted using black nodes, where each node represents the model parameters for each update iteration. The other training instance is denoted using red nodes. There are $2 \times 40 = 80$ nodes in total in one contour plot.</p>



<p>For grid search, because there is no actual hyperparameter tuning during training, $h_0$ and $h_1$ remain the same for the two training instances and the evaluation score is much lower than the possible …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/blog/Population-Based-Training/">https://leimao.github.io/blog/Population-Based-Training/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/blog/Population-Based-Training/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739659</guid>
            <pubDate>Sun, 05 Jul 2020 16:04:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Keanu: Probabilistic programming with Bayesian network models]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739643">thread link</a>) | @memexy
<br/>
July 5, 2020 | https://improbable-research.github.io/keanu/docs/getting-started/ | <a href="https://web.archive.org/web/*/https://improbable-research.github.io/keanu/docs/getting-started/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<div>
							<h2 id="your-model-as-a-bayesian-network">Your model as a Bayesian Network</h2>

<p>You need to describe your model to Keanu as a Bayesian network. A network is built from vertices. 
Vertices represent variables, which may be random or deterministic, and edges represent dependencies between variables. 
Your model’s state (i.e. data) is housed in these vertices as the vertex’s <code>value</code>. 
The value of a vertex can depend on the value of a parent vertex and can be updated in one of
two ways.</p>

<p>Let’s look at an example of two vertices A and B that contain some numbers as their values. Numbers from A and B are 
added together, which yields C.</p>



<p>If the number in A changes then the number in C will change as well and likewise for changes from B.</p>

<p>You can describe this in Keanu as:</p>

<div><div><pre><code><span>DoubleVertex</span> <span>A</span> <span>=</span> <span>new</span> <span>GaussianVertex</span><span>(</span><span>0</span><span>,</span> <span>1</span><span>);</span>
<span>DoubleVertex</span> <span>B</span> <span>=</span> <span>new</span> <span>GaussianVertex</span><span>(</span><span>0</span><span>,</span> <span>1</span><span>);</span>
<span>DoubleVertex</span> <span>C</span> <span>=</span> <span>A</span><span>.</span><span>plus</span><span>(</span><span>B</span><span>);</span>
</code></pre></div></div>

<h3 id="propagating-changes-forward">Propagating changes forward</h3>

<p>If you change A, you can tell C to recalculate based off of A’s new value and B’s unchanged value. 
To do this:</p>



<h3 id="evaluating-upstream-changes">Evaluating upstream changes</h3>

<p>But if you want to change both A and B then you probably don’t want to have C update twice. In that
case you would prefer to calculate C after both and A and B have changed and therefore calculating 
C once. This can be done by:</p>

<div><div><pre><code><span>A</span><span>.</span><span>setValue</span><span>(</span><span>1.234</span><span>);</span>
<span>B</span><span>.</span><span>setValue</span><span>(</span><span>4.321</span><span>);</span>
<span>C</span><span>.</span><span>lazyEval</span><span>();</span>
</code></pre></div></div>

<p>or</p>

<div><div><pre><code><span>A</span><span>.</span><span>setValue</span><span>(</span><span>1.234</span><span>);</span>
<span>B</span><span>.</span><span>setValue</span><span>(</span><span>4.321</span><span>);</span>
<span>VertexValuePropagation</span><span>.</span><span>cascadeUpdate</span><span>(</span><span>A</span><span>,</span> <span>B</span><span>);</span>
</code></pre></div></div>

<h3 id="observing-a-value">Observing a value</h3>

<p>Another central concept to Bayesian networks is observations. The value of a vertex can be “observed”, which
effectively locks the value of the vertex. Observing a vertex raises a flag on the vertex that tells an
inference algorithm to treat the vertex in a special way.</p>

<p>Observing vertices that contain numbers is a special case and is described more in the docs on <a href="https://improbable-research.github.io/keanu/docs/vertex-summary">Double vertices</a>.
In the interest of keeping this simple, take for example the case where instead of multiplying A and B, we apply the logical AND operator to their values.</p>

<div><div><pre><code>(A) _
     \
     AND -&gt; (C)
(B) _/
</code></pre></div></div>

<p>In this example, A and B contain boolean values and C is true only if both A and B are true. To describe this network in Keanu:</p>

<div><div><pre><code><span>BooleanVertex</span> <span>A</span> <span>=</span> <span>new</span> <span>BernoulliVertex</span><span>(</span><span>0.5</span><span>);</span>
<span>BooleanVertex</span> <span>B</span> <span>=</span> <span>new</span> <span>BernoulliVertex</span><span>(</span><span>0.5</span><span>);</span>
<span>BooleanVertex</span> <span>C</span> <span>=</span> <span>A</span><span>.</span><span>and</span><span>(</span><span>B</span><span>);</span>
</code></pre></div></div>

<p>To observe that C is true:</p>



<p>Now you can infer that A and B are also both true by sampling from the posterior distribution. Note: we will be covering MCMC sampling in the <a href="https://improbable-research.github.io/keanu/docs/inference-posterior-sampling/">Posterior Sampling</a> section.</p>

<div><div><pre><code><span>A</span><span>.</span><span>observe</span><span>(</span><span>true</span><span>);</span>
<span>B</span><span>.</span><span>observe</span><span>(</span><span>true</span><span>);</span>

<span>KeanuProbabilisticModel</span> <span>model</span> <span>=</span> <span>new</span> <span>KeanuProbabilisticModel</span><span>(</span><span>C</span><span>.</span><span>getConnectedGraph</span><span>());</span>
<span>NetworkSamples</span> <span>posteriorSamples</span> <span>=</span> <span>Keanu</span><span>.</span><span>Sampling</span><span>.</span><span>MetropolisHastings</span><span>.</span><span>withDefaultConfig</span><span>().</span><span>getPosteriorSamples</span><span>(</span>
    <span>model</span><span>,</span>
    <span>Arrays</span><span>.</span><span>asList</span><span>(</span><span>A</span><span>,</span> <span>B</span><span>),</span>
    <span>100000</span>
<span>).</span><span>drop</span><span>(</span><span>10000</span><span>).</span><span>downSample</span><span>(</span><span>2</span><span>);</span>
<span>double</span> <span>probabilityOfA</span> <span>=</span> <span>posteriorSamples</span><span>.</span><span>get</span><span>(</span><span>A</span><span>).</span><span>probability</span><span>(</span><span>isTrue</span> <span>-&gt;</span> <span>isTrue</span><span>.</span><span>scalar</span><span>()</span> <span>==</span> <span>true</span><span>);</span>
<span>//probabilityOfA evaluates to 1.0</span>
</code></pre></div></div>
<p><strong>You may be wondering why we go to all the hassle of doing inference</strong> rather than just writing something like the following:</p>
<div><div><pre><code><span>//WRONG</span>
<span>A</span><span>.</span><span>lazyEval</span><span>();</span>
<span>B</span><span>.</span><span>lazyEval</span><span>();</span>
<span>System</span><span>.</span><span>out</span><span>.</span><span>println</span><span>(</span><span>A</span><span>.</span><span>getValue</span><span>().</span><span>scalar</span><span>());</span>
</code></pre></div></div>
<p>The issue here is that A and B are vertices in the computation graph that describes our prior and taking the value from A and B will just return a random value as if the BernoulliVertex was referenced in isolation. 
In this very contrived example it seems obvious to us how the value of C should propagate values to A and B but this is not always so straightforward.
In general, this process is known as <em>variable elimination</em> and it is not supported by Keanu. 
Therefore, in order to infer the values of A and B, you have to perform inference using a posterior sampling algorithm like <a href="https://improbable-research.github.io/keanu/docs/inference-posterior-sampling/">MCMC</a>.</p>

<p><strong>You may also be wondering why we also observe A and B to be true</strong> in the above code. 
This is so that when our sampling algorithm (MCMC) starts to sample from the posterior, it will start from a network with a probability that is non-zero.
If we do not include this, then our network will get a random starting value, e.g. A is false and B is true, and then will discover that it is actually not possible to be in this state and will throw an error.</p>

<p>In general, A and B are known as <em>latent variables</em> because we do not directly observe them. In more complex cases, we may not know what starting state (like A: true, B: true in this case) to use. 
There are a couple of techniques that solve this problem so that we can leverage Bayesian Inference.
Firstly, you might choose to use the <code>ParticleFilter</code> class in order to find the most probable state to start your algorithm from.
Alternatively, you can create a new Bayesian network and use this to probe some random configurations a certain number of times to see if it can find a possible one.</p>
<div><div><pre><code><span>BayesianNetwork</span> <span>bayesianNetwork</span> <span>=</span> <span>new</span> <span>BayesianNetwork</span><span>(</span><span>C</span><span>.</span><span>getConnectedGraph</span><span>());</span>
<span>bayesianNetwork</span><span>.</span><span>probeForNonZeroProbability</span><span>(</span><span>10</span><span>);</span>
</code></pre></div></div>
<p>Now you can run MCMC on the BayesNet as it will start off in the correct configuration.</p>

<p>Instead of running MCMC you could also run one of our <a href="https://improbable-research.github.io/keanu/docs/inference-map">inference algorithms</a>.</p>

						</div><!-- /.content -->
					</div></div>]]>
            </description>
            <link>https://improbable-research.github.io/keanu/docs/getting-started/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739643</guid>
            <pubDate>Sun, 05 Jul 2020 16:01:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Best Python Reference Ever]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739589">thread link</a>) | @pizzaburek
<br/>
July 5, 2020 | https://gto76.github.io/python-cheatsheet | <a href="https://web.archive.org/web/*/https://gto76.github.io/python-cheatsheet">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  <header>
    
    
  </header>

  <span><i></i></span>
   <div><br><div><h2 id="toc"><a href="#toc" name="toc">#</a>Contents</h2><pre><code><strong>ToC</strong> = {
    <strong><span><span>'1. Collections'</span></span></strong>: [<a href="#list">List</a>, <a href="#dictionary">Dictionary</a>, <a href="#set">Set</a>, <a href="#tuple">Tuple</a>, <a href="#range">Range</a>, <a href="#enumerate">Enumerate</a>, <a href="#iterator">Iterator</a>, <a href="#generator">Generator</a>],
    <strong><span><span>'2. Types'</span></span></strong>:       [<a href="#type">Type</a>, <a href="#string">String</a>, <a href="#regex">Regular_Exp</a>, <a href="#format">Format</a>, <a href="#numbers">Numbers</a>, <a href="#combinatorics">Combinatorics</a>, <a href="#datetime">Datetime</a>],
    <strong><span><span>'3. Syntax'</span></span></strong>:      [<a href="#arguments">Args</a>, <a href="#inline">Inline</a>, <a href="#closure">Closure</a>, <a href="#decorator">Decorator</a>, <a href="#class">Class</a>, <a href="#ducktypes">Duck_Type</a>, <a href="#enum">Enum</a>, <a href="#exceptions">Exception</a>],
    <strong><span><span>'4. System'</span></span></strong>:      [<a href="#exit">Exit</a>, <a href="#print">Print</a>, <a href="#input">Input</a>, <a href="#commandlinearguments">Command_Line_Arguments</a>, <a href="#open">Open</a>, <a href="#path">Path</a>, <a href="#oscommands">OS_Commands</a>],
    <strong><span><span>'5. Data'</span></span></strong>:        [<a href="#json">JSON</a>, <a href="#pickle">Pickle</a>, <a href="#csv">CSV</a>, <a href="#sqlite">SQLite</a>, <a href="#bytes">Bytes</a>, <a href="#struct">Struct</a>, <a href="#array">Array</a>, <a href="#memoryview">Memory_View</a>, <a href="#deque">Deque</a>],
    <strong><span><span>'6. Advanced'</span></span></strong>:    [<a href="#threading">Threading</a>, <a href="#operator">Operator</a>, <a href="#introspection">Introspection</a>, <a href="#metaprograming">Metaprograming</a>, <a href="#eval">Eval</a>, <a href="#coroutines">Coroutine</a>],
    <strong><span><span>'7. Libraries'</span></span></strong>:   [<a href="#progressbar">Progress_Bar</a>, <a href="#plot">Plot</a>, <a href="#table">Table</a>, <a href="#curses">Curses</a>, <a href="#logging">Logging</a>, <a href="#scraping">Scraping</a>, <a href="#web">Web</a>, <a href="#profiling">Profile</a>,
                       <a href="#numpy">NumPy</a>, <a href="#image">Image</a>, <a href="#audio">Audio</a>, <a href="#pygame">Games</a>, <a href="#pandas">Data</a>, <a href="#cython">Cython</a>]
}
</code></pre></div></div>






<div><h2 id="main"><a href="#main" name="main">#</a>Main</h2><pre><code><span>if</span> __name__ == <span>'__main__'</span>:     
    main()
</code></pre></div>

<div><h2 id="list"><a href="#list" name="list">#</a>List</h2><pre><code>&lt;list&gt; = &lt;list&gt;[from_inclusive : to_exclusive : ±step_size]
</code></pre></div>

<pre><code>&lt;list&gt;.append(&lt;el&gt;)            
&lt;list&gt;.extend(&lt;collection&gt;)    
</code></pre>
<pre><code>&lt;list&gt;.sort()
&lt;list&gt;.reverse()
&lt;list&gt; = sorted(&lt;collection&gt;)
&lt;iter&gt; = reversed(&lt;list&gt;)
</code></pre>
<pre><code>sum_of_elements  = sum(&lt;collection&gt;)
elementwise_sum  = [sum(pair) <span>for</span> pair <span>in</span> zip(list_a, list_b)]
sorted_by_second = sorted(&lt;collection&gt;, key=<span>lambda</span> el: el[<span>1</span>])
sorted_by_both   = sorted(&lt;collection&gt;, key=<span>lambda</span> el: (el[<span>1</span>], el[<span>0</span>]))
flatter_list     = list(itertools.chain.from_iterable(&lt;list&gt;))
product_of_elems = functools.reduce(<span>lambda</span> out, el: out * el, &lt;collection&gt;)
list_of_chars    = list(&lt;str&gt;)
</code></pre>
<ul>
<li><strong>Module <a href="#operator">operator</a> provides functions itemgetter() and mul() that offer the same functionality as <a href="#lambda">lambda</a> expressions above.</strong></li>
</ul>
<pre><code>&lt;int&gt; = &lt;list&gt;.count(&lt;el&gt;)     
index = &lt;list&gt;.index(&lt;el&gt;)     
&lt;list&gt;.insert(index, &lt;el&gt;)     
&lt;el&gt; = &lt;list&gt;.pop([index])     
&lt;list&gt;.remove(&lt;el&gt;)            
&lt;list&gt;.clear()                 
</code></pre>
<div><h2 id="dictionary"><a href="#dictionary" name="dictionary">#</a>Dictionary</h2><pre><code>&lt;view&gt; = &lt;dict&gt;.keys()                          
&lt;view&gt; = &lt;dict&gt;.values()                        
&lt;view&gt; = &lt;dict&gt;.items()                         
</code></pre></div>

<pre><code>value  = &lt;dict&gt;.get(key, default=<span>None</span>)          
value  = &lt;dict&gt;.setdefault(key, default=<span>None</span>)   
&lt;dict&gt; = collections.defaultdict(&lt;type&gt;)        
&lt;dict&gt; = collections.defaultdict(<span>lambda</span>: <span>1</span>)     
</code></pre>
<pre><code>&lt;dict&gt; = dict(&lt;collection&gt;)                     
&lt;dict&gt; = dict(zip(keys, values))                
&lt;dict&gt; = dict.fromkeys(keys [, value])          
</code></pre>
<pre><code>&lt;dict&gt;.update(&lt;dict&gt;)                           
value = &lt;dict&gt;.pop(key)                         
{k <span>for</span> k, v <span>in</span> &lt;dict&gt;.items() <span>if</span> v == value}    
{k: v <span>for</span> k, v <span>in</span> &lt;dict&gt;.items() <span>if</span> k <span>in</span> keys}  
</code></pre>
<div><h3 id="counter">Counter</h3><pre><code><span>&gt;&gt;&gt; </span><span>from</span> collections <span>import</span> Counter
<span>&gt;&gt;&gt; </span>colors = [<span>'blue'</span>, <span>'blue'</span>, <span>'blue'</span>, <span>'red'</span>, <span>'red'</span>]
<span>&gt;&gt;&gt; </span>counter = Counter(colors)
<span>&gt;&gt;&gt; </span>counter[<span>'yellow'</span>] += <span>1</span>
Counter({<span>'blue'</span>: <span>3</span>, <span>'red'</span>: <span>2</span>, <span>'yellow'</span>: <span>1</span>})
<span>&gt;&gt;&gt; </span>counter.most_common()[<span>0</span>]
(<span>'blue'</span>, <span>3</span>)
</code></pre></div>



<pre><code>&lt;set&gt;.add(&lt;el&gt;)                                 
&lt;set&gt;.update(&lt;collection&gt;)                      
</code></pre>
<pre><code>&lt;set&gt;  = &lt;set&gt;.union(&lt;coll.&gt;)                   
&lt;set&gt;  = &lt;set&gt;.intersection(&lt;coll.&gt;)            
&lt;set&gt;  = &lt;set&gt;.difference(&lt;coll.&gt;)              
&lt;set&gt;  = &lt;set&gt;.symmetric_difference(&lt;coll.&gt;)    
&lt;bool&gt; = &lt;set&gt;.issubset(&lt;coll.&gt;)                
&lt;bool&gt; = &lt;set&gt;.issuperset(&lt;coll.&gt;)              
</code></pre>
<pre><code>&lt;el&gt; = &lt;set&gt;.pop()                              
&lt;set&gt;.remove(&lt;el&gt;)                              
&lt;set&gt;.discard(&lt;el&gt;)                             
</code></pre>
<div><h3 id="frozenset">Frozen Set</h3><ul>
<li><strong>Is immutable and hashable.</strong></li>
<li><strong>That means it can be used as a key in a dictionary or as an element in a set.</strong></li>
</ul><pre><code>&lt;frozenset&gt; = frozenset(&lt;collection&gt;)
</code></pre></div>


<div><h2 id="tuple"><a href="#tuple" name="tuple">#</a>Tuple</h2><p><strong>Tuple is an immutable and hashable list.</strong></p><pre><code>&lt;tuple&gt; = ()
&lt;tuple&gt; = (&lt;el&gt;, )
&lt;tuple&gt; = (&lt;el_1&gt;, &lt;el_2&gt; [, ...])
</code></pre></div>


<div><h3 id="namedtuple">Named Tuple</h3><p><strong>Tuple's subclass with named elements.</strong></p><pre><code><span>&gt;&gt;&gt; </span><span>from</span> collections <span>import</span> namedtuple
<span>&gt;&gt;&gt; </span>Point = namedtuple(<span>'Point'</span>, <span>'x y'</span>)
<span>&gt;&gt;&gt; </span>p = Point(<span>1</span>, y=<span>2</span>)
Point(x=<span>1</span>, y=<span>2</span>)
<span>&gt;&gt;&gt; </span>p[<span>0</span>]
<span>1</span>
<span>&gt;&gt;&gt; </span>p.x
<span>1</span>
<span>&gt;&gt;&gt; </span>getattr(p, <span>'y'</span>)
<span>2</span>
<span>&gt;&gt;&gt; </span>p._fields  
(<span>'x'</span>, <span>'y'</span>)
</code></pre></div>


<div><h2 id="range"><a href="#range" name="range">#</a>Range</h2><pre><code>&lt;range&gt; = range(to_exclusive)
&lt;range&gt; = range(from_inclusive, to_exclusive)
&lt;range&gt; = range(from_inclusive, to_exclusive, ±step_size)
</code></pre></div>

<pre><code>from_inclusive = &lt;range&gt;.start
to_exclusive   = &lt;range&gt;.stop
</code></pre>
<div><h2 id="enumerate"><a href="#enumerate" name="enumerate">#</a>Enumerate</h2><pre><code><span>for</span> i, el <span>in</span> enumerate(&lt;collection&gt; [, i_start]):
    ...
</code></pre></div>

<div><h2 id="iterator"><a href="#iterator" name="iterator">#</a>Iterator</h2><pre><code>&lt;iter&gt; = iter(&lt;collection&gt;)                 
&lt;iter&gt; = iter(&lt;function&gt;, to_exclusive)     
&lt;el&gt;   = next(&lt;iter&gt; [, default])           
&lt;list&gt; = list(&lt;iter&gt;)                       
</code></pre></div>

<div><h3 id="itertools">Itertools</h3><pre><code><span>from</span> itertools <span>import</span> count, repeat, cycle, chain, islice
</code></pre></div>

<pre><code>&lt;iter&gt; = count(start=<span>0</span>, step=<span>1</span>)             
&lt;iter&gt; = repeat(&lt;el&gt; [, times])             
&lt;iter&gt; = cycle(&lt;collection&gt;)                
</code></pre>
<pre><code>&lt;iter&gt; = chain(&lt;coll_1&gt;, &lt;coll_2&gt; [, ...])  
&lt;iter&gt; = chain.from_iterable(&lt;collection&gt;)  
</code></pre>
<pre><code>&lt;iter&gt; = islice(&lt;collection&gt;, to_exclusive)
&lt;iter&gt; = islice(&lt;collection&gt;, from_inclusive, to_exclusive [, +step_size])
</code></pre>
<div><h2 id="generator"><a href="#generator" name="generator">#</a>Generator</h2><ul>
<li><strong>Any function that contains a yield statement returns a generator.</strong></li>
<li><strong>Generators and iterators are interchangeable.</strong></li>
</ul><pre><code><span><span>def</span> <span>count</span><span>(start, step)</span>:</span>
    <span>while</span> <span>True</span>:
        <span>yield</span> start
        start += step
</code></pre></div>


<pre><code><span>&gt;&gt;&gt; </span>counter = count(<span>10</span>, <span>2</span>)
<span>&gt;&gt;&gt; </span>next(counter), next(counter), next(counter)
(<span>10</span>, <span>12</span>, <span>14</span>)
</code></pre>
<div><h2 id="type"><a href="#type" name="type">#</a>Type</h2><ul>
<li><strong>Everything is an object.</strong></li>
<li><strong>Every object has a type.</strong></li>
<li><strong>Type and class are synonymous.</strong></li>
</ul><pre><code>&lt;type&gt; = type(&lt;el&gt;)                          
&lt;bool&gt; = isinstance(&lt;el&gt;, &lt;type&gt;)            
</code></pre></div>


<pre><code><span>&gt;&gt;&gt; </span>type(<span>'a'</span>), <span>'a'</span>.__class__, str
(&lt;<span><span>class</span> '<span>str</span>'&gt;, &lt;<span>class</span> '<span>str</span>'&gt;, &lt;<span>class</span> '<span>str</span>'&gt;)
</span></code></pre>
<div><h4 id="sometypesdonothavebuiltinnamessotheymustbeimported">Some types do not have built-in names, so they must be imported:</h4><pre><code><span>from</span> types <span>import</span> FunctionType, MethodType, LambdaType, GeneratorType
</code></pre></div>

<div><h3 id="abstractbaseclasses">Abstract Base Classes</h3><p><strong>Each abstract base class specifies a set of virtual subclasses. These classes are then recognized by isinstance() and issubclass() as subclasses of the ABC, although they are really not.</strong></p><pre><code><span>&gt;&gt;&gt; </span><span>from</span> collections.abc <span>import</span> Sequence, Collection, Iterable
<span>&gt;&gt;&gt; </span>isinstance([<span>1</span>, <span>2</span>, <span>3</span>], Iterable)
<span>True</span>
</code></pre></div>


<pre><code>┏━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━┯━━━━━━━━━━━━┯━━━━━━━━━━━━┓
┃                  │  Sequence  │ Collection │  Iterable  ┃
┠──────────────────┼────────────┼────────────┼────────────┨
┃ list, range, str │     ✓      │     ✓      │     ✓      ┃
┃ dict, set        │            │     ✓      │     ✓      ┃
┃ iter             │            │            │     ✓      ┃
┗━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━┷━━━━━━━━━━━━┷━━━━━━━━━━━━┛
</code></pre>
<pre><code><span>&gt;&gt;&gt; </span><span>from</span> numbers <span>import</span> Integral, Rational, Real, Complex, Number
<span>&gt;&gt;&gt; </span>isinstance(<span>123</span>, Number)
<span>True</span>
</code></pre>
<pre><code>┏━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┓
┃                    │ Integral │ Rational │   Real   │ Complex  │  Number  ┃
┠────────────────────┼──────────┼──────────┼──────────┼──────────┼──────────┨
┃ int                │    ✓     │    ✓     │    ✓     │    ✓     │    ✓     ┃
┃ fractions.Fraction │          │    ✓     │    ✓     │    ✓     │    ✓     ┃
┃ float              │          │          │    ✓     │    ✓     │    ✓     ┃
┃ complex            │          │          │          │    ✓     │    ✓     ┃
┃ decimal.Decimal    │          │          │          │          │    ✓     ┃
┗━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┛
</code></pre>
<div><h2 id="string"><a href="#string" name="string">#</a>String</h2><pre><code>&lt;str&gt;  = &lt;str&gt;.strip()                       
&lt;str&gt;  = &lt;str&gt;.strip(<span>'&lt;chars&gt;'</span>)              
</code></pre></div>

<pre><code>&lt;list&gt; = &lt;str&gt;.split()                       
&lt;list&gt; = &lt;str&gt;.split(sep=<span>None</span>, maxsplit=<span>-1</span>)  
&lt;list&gt; = &lt;str&gt;.splitlines(keepends=<span>False</span>)    
&lt;str&gt;  = &lt;str&gt;.join(&lt;coll_of_strings&gt;)       
</code></pre>
<pre><code>&lt;bool&gt; = &lt;sub_str&gt; <span>in</span> &lt;str&gt;                  
&lt;bool&gt; = &lt;str&gt;.startswith(&lt;sub_str&gt;)         
&lt;bool&gt; = &lt;str&gt;.endswith(&lt;sub_str&gt;)           
&lt;int&gt;  = &lt;str&gt;.find(&lt;sub_str&gt;)               
&lt;int&gt;  = &lt;str&gt;.index(&lt;sub_str&gt;)              
</code></pre>
<pre><code>&lt;str&gt;  = &lt;str&gt;.replace(old, new [, count])   
&lt;str&gt;  = &lt;str&gt;.translate(&lt;table&gt;)            
</code></pre>
<pre><code>&lt;str&gt;  = chr(&lt;int&gt;)                          
&lt;int&gt;  = ord(&lt;str&gt;)                          
</code></pre>
<ul>
<li><strong>Also: <code><span>'lstrip()'</span></code>, <code><span>'rstrip()'</span></code>.</strong></li>
<li><strong>Also: <code><span>'lower()'</span></code>, <code><span>'upper()'</span></code>, <code><span>'capitalize()'</span></code> and <code><span>'title()'</span></code>.</strong></li>
</ul>
<div><h3 id="propertymethods">Property Methods</h3><pre><code>┏━━━━━━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┓
┃               │ [ !#$%…] │ [a-zA-Z] │  [¼½¾]   │  [²³¹]   │  [0-9]   ┃
┠───────────────┼──────────┼──────────┼──────────┼──────────┼──────────┨
┃ isprintable() │    ✓     │    ✓     │    ✓     │    ✓     │    ✓     ┃
┃ isalnum()     │          │    ✓     │    ✓     │    ✓     │    ✓     ┃
┃ isnumeric()   │          │          │    ✓     │    ✓     │    ✓     ┃
┃ isdigit()     │          │          │          │    ✓     │    ✓     ┃
┃ isdecimal()   │          │          │          │          │    ✓     ┃
┗━━━━━━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┛
</code></pre></div>

<ul>
<li><strong>Also: <code><span>'isspace()'</span></code> checks for <code><span>'[ \t\n\r\f\v…]'</span></code>.</strong></li>
</ul>
<div><h2 id="regex"><a href="#regex" name="regex">#</a>Regex</h2><pre><code><span>import</span> re
&lt;str&gt;   = re.sub(&lt;regex&gt;, new, text, count=<span>0</span>)  
&lt;list&gt;  = re.findall(&lt;regex&gt;, text)            
&lt;list&gt;  = re.split(&lt;regex&gt;, text, maxsplit=<span>0</span>)  
&lt;Match&gt; = re.search(&lt;regex&gt;, text)             
&lt;Match&gt; = re.match(&lt;regex&gt;, text)              
&lt;iter&gt;  = re.finditer(&lt;regex&gt;, text)           
</code></pre></div>

<ul>
<li><strong>Search() and match() return None if they can't find a match.</strong></li>
<li><strong>Argument <code><span>'flags=re.IGNORECASE'</span></code> can be used with all functions.</strong></li>
<li><strong>Argument <code><span>'flags=re.MULTILINE'</span></code> makes <code><span>'^'</span></code> and <code><span>'$'</span></code> match the start/end of each line.</strong></li>
<li><strong>Argument <code><span>'flags=re.DOTALL'</span></code> makes dot also accept the <code><span>'\n'</span></code>.</strong></li>
<li><strong>Use <code><span>r'\1'</span></code> or <code><span>'\\1'</span></code> for backreference.</strong></li>
<li><strong>Add <code><span>'?'</span></code> after an operator to make it non-greedy.</strong></li>
</ul>
<div><h3 id="matchobject">Match Object</h3><pre><code>&lt;str&gt;   = &lt;Match&gt;.group()                      
&lt;str&gt;   = &lt;Match&gt;.group(<span>1</span>)                     
&lt;tuple&gt; = &lt;Match&gt;.groups()                     
&lt;int&gt;   = &lt;Match&gt;.start()                      
&lt;int&gt;   = &lt;Match&gt;.end()                        
</code></pre></div>

<div><h3 id="specialsequences">Special Sequences</h3><ul>
<li><strong>By default digits, alphanumerics and whitespaces from all alphabets are matched, unless <code><span>'flags=re.ASCII'</span></code> argument is used.</strong></li>
<li><strong>Use a capital letter for negation.</strong></li>
</ul><pre><code><span>'\d'</span> == <span>'[0-9]'</span>                                
<span>'\w'</span> == <span>'[a-zA-Z0-9_]'</span>                         
<span>'\s'</span> == <span>'[ \t\n\r\f\v]'</span>                        
</code></pre></div>


<div><h2 id="format"><a href="#format" name="format">#</a>Format</h2><pre><code>&lt;str&gt; = <span>f'<span>{&lt;el_1&gt;}</span>, <span>{&lt;el_2&gt;}</span>'</span>
&lt;str&gt; = <span>'{}, {}'</span>.format(&lt;el_1&gt;, &lt;el_2&gt;)
</code></pre></div>

<div><h3 id="attributes">Attributes</h3><pre><code><span>&gt;&gt;&gt; </span><span>from</span> collections <span>import</span> namedtuple
<span>&gt;&gt;&gt; </span>Person = namedtuple(<span>'Person'</span>, <span>'name height'</span>)
<span>&gt;&gt;&gt; </span>person = Person(<span>'Jean-Luc'</span>, <span>187</span>)
<span>&gt;&gt;&gt; </span><span>f'<span>{person.height}</span>'</span>
<span>'187'</span>
<span>&gt;&gt;&gt; </span><span>'{p.height}'</span>.format(p=person)
<span>'187'</span>
</code></pre></div>

<div><h3 id="generaloptions">General Options</h3><pre><code>{&lt;el&gt;:&lt;<span>10</span>}                                     
{&lt;el&gt;:^<span>10</span>}                                     
{&lt;el&gt;:&gt;<span>10</span>}  …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gto76.github.io/python-cheatsheet">https://gto76.github.io/python-cheatsheet</a></em></p>]]>
            </description>
            <link>https://gto76.github.io/python-cheatsheet</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739589</guid>
            <pubDate>Sun, 05 Jul 2020 15:53:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Interface of Kai Krause's Software]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739545">thread link</a>) | @bschne
<br/>
July 5, 2020 | https://www.mprove.de/script/99/kai/index.html | <a href="https://web.archive.org/web/*/https://www.mprove.de/script/99/kai/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
			<div>
				<div>
					<h2 skip="">Contents</h2>
					<ol>
						<li><a href="https://www.mprove.de/script/99/kai/index.html#history"><b>Meta-History</b></a></li>
						<li><a href="https://www.mprove.de/script/99/kai/index.html#software"><b>The Software</b></a>
							<ul>
								<li>Maximize the Interface</li>
								<li>Full Screen Mode</li>
								<li>Rooms</li>
								<li>Minimize the Interface</li>
								<li>The Desktop</li>
							</ul>
						</li>
						<li><a href="https://www.mprove.de/script/99/kai/index.html#interfacelanguage"><b>Kai’s Interface Language</b></a>
							<ul>
								<li>Unfolding functionality</li>
								<li>MouseOver</li>
								<li>MouseDragging instead of Value-Slider</li>
								<li>Memory Dots / Five Favorites</li>
								<li><nobr>Transparency &amp; Shadows (KPT Lens f/x, Poser</nobr><nobr>)</nobr></li>
								<li>Full Screen Mode, <a href="https://www.mprove.de/script/99/kai/index.html#rooms">Rooms Metaphor</a></li>
								<li>Workspace – Desktop</li>
								<li>MetaWindow</li>
							</ul>
						</li>
						<li><a href="https://www.mprove.de/script/99/kai/index.html#references"><b>References</b></a></li>
					</ol>
				</div>
			</div>
			<h2><a name="history" id="history"></a>Meta-History</h2>
			<h3>CV</h3>
			<p><a id="Truong97" name="Truong97"></a><strong><a href="https://en.wikipedia.org/wiki/Kai_Krause">Kai Krause</a></strong> [today: <a href="http://kai.sub.blue/">kai.sub.blue</a>]was born 1957 in Dortmund. He came to California in 1976 with two friends. He worked as a musician for <em>Disney Sound Effects</em>; <strike>the sound track for “Star Trek: The Movie” was created on his synthesizers</strike>*. <span>* In fact Kai won a Clio Award for his sound effects in a Star Wars radio spot.</span> <a href="https://en.wikipedia.org/wiki/Emerson,_Lake_&amp;_Powell">Emerson, Lake &amp; Powell</a> bought sound systems from him and he is still working with <a href="https://petergabriel.com/">Peter Gabriel</a> today in order to fulfill his vision of visualized music as 3D sculptures. [<a href="https://www.mprove.de/script/99/kai/index.html#refTruong97">Truong97</a>]</p>
			<p>He was running a forum for several years on AOL: <a href="https://www.mprove.de/script/90/KPT/index.html"><em>Kai’s Power Tips &amp; Tricks</em></a>. He gave people tips and little pieces of code on line, simply because they shared his passion for computer graphics. This became an extensive and valuable collection of practical information how to get special effects with <em>Adobe Photoshop</em>. It can still be downloaded from several web sites. [<a id="KaiTT" name="KaiTT" href="https://www.mprove.de/script/99/kai/index.html#refKaiTT">KaiTT</a>]</p>
			<h3>The Company</h3>
			<p><img src="https://www.mprove.de/script/99/kai/_media/high/history.jpg" height="441" width="803"></p>
			<p>Fig. 1 Timeline with companies and products</p>
			<p><em>Harward Systems Corporation</em> (HSC Software Corp.) [also <em>Happy Software Company</em>] was founded by John Wilczak. Ben Weiss and Kai joined him in 1991 at HSC and created the first version of <em>Kai’s Power Tools</em>. KPT is a set of plug-ins that use the Adobe Photoshop programing interface for 3rd party filters. Many ideas from <a href="https://www.mprove.de/script/90/KPT/index.html">Kai’s Power Tips &amp; Tricks</a> get implemented as simple and easy to use pieces of software. KPT evolved until version 3 in 1995. This release contains the <em>Texture Explorer</em>, the <em>Spheroid Designer</em> and <em>KPT Lens f/x</em> among others. <em>Convolver</em> came out as a separate product. HSC was renamed to <em>MetaTools, Inc.</em> the same year.</p>
			<p>Eric Wenger and Phil Clevenger came into the team to develop a landscape-simulating product called <em>Bryce</em> (named after the <a href="https://www.nps.gov/brca/index.htm">Bryce Canyon</a>). They started creating other kinds of software starting with <em>Kai’s Power GOO</em>, <em>Kai’s Photo Soap</em> and <em>Kai’s Power Show</em>. Before GOO, Kai was well known only by computer artists as a creator of creative tools. With GOO, Kai became noticed by a much broader audience. People played with GOO. The complex and difficult algorithms are well hidden by the interface. Even children can change images of their classmates or teachers to funny caricatures. Kai himself calls this sort of computer programs <em>funware</em>.</p>
			<p>In 1998 Phil Clevenger and Kai managed to transfer the main interface concepts from Bryce to <em>Poser3</em>. Poser was originally created by <em>Fractal Design</em>. The companies MetaTools and Fractal Design merged in 1997. The new company was named <a href="https://en.wikipedia.org/wiki/MetaCreations"><em>MetaCreations Corp</em>.</a> In 1998 it had about 300 employees. The main office is in Santa Barbara, CA, but several other facilities e.g. in San Francisco, are part of MetaCreations. <a id="MCRE" name="MCRE"></a>[<a href="https://www.mprove.de/script/99/kai/index.html#refMCRE">MCRE</a>]</p>
			<h4>Update π-day 2018</h4>
			<ul>
				<li><a href="https://www.scribd.com/document/373825984/MataTools-Flyer-1996">MetaTools Flyer 1996</a></li>
				<li><a href="http://vv.arts.ucla.edu/teaching/software/lifeintheuniverse/"><em>Life in the Universe (1997)</em></a> – <a href="http://victoriavesna.com/index.php?p=teaching&amp;item=2">course material by Victoria Vesna</a>, UCLA (Thanks to Christopher Cowan for sharing the link.)
					<ul>
						<li><a href="https://www.facebook.com/kaikemono/posts/10216470444058859" target="_blank"><strike>Some thoughts by the designer Kai Gradert</strike></a></li>
					</ul>
				</li>
			</ul>
			<h2><a name="software" id="software"></a>The Software</h2>
			<h3>Maximize the Interface</h3>
			<h4>Full Screen Mode</h4>
			<p><a id="Kai95-1" name="Kai95-1"></a>Kai describes how it came to the large dialogs in KPT3:</p>
			<blockquote>
				<p>»I would love to interact with the image in the way that Levels or Curves does, but the plug-in interface as of today simply will not allow it. What that leads to is simply that the plug-in gets a rectangle and is supposed to do something with the pixels in some other room and then give them back.« [<a href="https://www.mprove.de/script/99/kai/index.html#refKai95">Kai95</a>]</p>
			</blockquote>
			<p>Many of the filters in KPT3 like <em>KPT Texture Explorer</em>, <em>KPT Spheroid Designer</em> and <em>KPT Convolver</em> use a rectangular area that fits on a 14" monitor. All other elements get blacked out – no menu bar, no Photoshop image window and no desktop. The user experience is really like coming into a room with a special suited environment for one specific task.</p>
			<p><a name="Fig2 KPT Texture"></a><img src="https://www.mprove.de/script/99/kai/_media/high/KPT3TextureExplorer.jpg" height="460" width="640"></p>
			<p>Fig. 2 KPT Texture Explorer 3.0</p>
			<p>KPT Texture Explorer is a modal dialog, that is especially prepared to create textures and nothing else.</p>
			<p><img id="spheroiddesigner" src="https://www.mprove.de/script/99/kai/_media/high/KPT3SpheroidDesigner.jpg" name="spheroiddesigner"></p>
			<p>Fig. 3 KPT Spheroid Designer 3.0</p>
			<p>KPT Spheroid Designer is meant to create collections of special looking orbs. Different controls allow the definition of light or to select a special surface structure for the orbs. The KPT users manual notes that Spheroid Designer may seem to resemble glass balls dropped into mud, but actually it’s meant to be glass balls embedded in an “old stale brownie”. [<a href="https://www.mprove.de/script/99/kai/index.html#refLombreglia97">Lombreglia97</a>]<br>
					<a id="kansei" name="kansei"></a></p>
			<p><a name="Fig4 KPT Convolver"></a><img id="convolver" src="https://www.mprove.de/script/99/kai/_media/high/KPTConvolver.jpg" name="convolver"></p>
			<p>Fig. 4 KPT Convolver</p>
			<p><a id="Tog96" name="Tog96"></a><a href="http://asktog.com/">Bruce “Tog” Tognazzini</a> writes about <em>Kansei Engineering</em>:</p>
			<blockquote>
				<p>»Since the year A.D. 618 the Japanese have been creating beautiful Zen gardens, environments of harmony designed to instill in their users a sense of serenity and peace. […] Every rock and tree is thoughtfully placed in patterns that are at once random and yet teeming with order. Rocks are not just strewn about; they are carefully arranged in odd-numbered groupings and sunk into the ground to give the illusion of age and stability. Waterfalls are not simply lined with interesting rocks; they are tuned to create just the right burble and plop. […]<br>
					
					Kansei speakes to a totality of experience: colors, sounds, shapes, tactile sensations, and kinesthesia, as well as the personality and consistency of interactions.« [<a href="https://www.mprove.de/script/99/kai/index.html#refTog96">Tog96</a>, pp. 171]</p>
			</blockquote>
			<p>Then Tog comes to software design:</p>
			<blockquote>
				<p>»Where does kansei start? Not with the hardware. Not with the software either. Kansei starts with attitude, as does quality. The original <a href="https://www.mprove.de/visionreality/text/3.1.6_xeroxstar.html">Xerox Star</a> team had it. So did the <a href="https://www.mprove.de/visionreality/text/3.1.8_lisa.html">Lisa</a> team, and the <a href="https://www.mprove.de/visionreality/text/3.1.9_macintosh.html">Mac</a> team after. All were dedicated to building a single, tightly integrated environment – a totality of experience. […]<br>
					KPT Convolver […] is a marvelous example of kansei design. It replaces the extensive lineup of filters that graphic designers traditionally grapple with when using such tools as Photoshop with a simple, integrated, harmonious environment.<br>
					In the past, designers have followed a process of picturing their desired end result in their mind, then applying a series of filters sequentially, without benefit of undo beyond the last-applied filter. Convolver lets users play, trying any combination of filters at will, either on their own or with the computer’s aid and advice. […] Both time and space lie at the user’s complete control.« [<a href="https://www.mprove.de/script/99/kai/index.html#refTog96">Tog96</a>, pp. 174]</p>
			</blockquote>
			<p>Many of the interface ideas evolved from <em>KPT</em> into <em>Bryce</em>. It is a whole environment that covers the complete screen. It overcomes the limitation of a fixed 14" rectangle, because the interface scales itself to the according screen dimensions. The same holds for <em>Poser3</em> and <em>KPT5</em> as they were shipped late in 1998.</p>
			<p><img id="bryce" src="https://www.mprove.de/script/99/kai/_media/high/bryce_full.jpg" name="bryce"></p>
			<p>Fig. 5 Bryce 2</p>
			<h4><a id="rooms" name="rooms"></a><a name="Lombreglia97"></a>Rooms</h4>
			<blockquote>
				<p>»The writer <a href="https://en.wikipedia.org/wiki/John_Updike">John Updike</a> is said to have several different writing rooms in his home, each used for a different kind of work -- a fiction room, a poetry room, a room for writing essays and book reviews. All writers want a special room for working (with door, without telephone), but why would any writer -- even such a deservedly successful and prosperous one as John Updike -- need entirely different rooms for different kinds of writing?<br>
					Actually, I know exactly why. Mr. Updike’s arrangement sounded great to me the first time I heard about it. I’m sure working in those rooms is his way of staying inspired, fighting boredom and distraction, getting creative work done by being in a space that’s not only set aside for work but that also somehow provokes that work, probably in quite subtle ways.« [<a href="https://www.mprove.de/script/99/kai/index.html#refLombreglia97">Lombreglia97</a>]</p>
			</blockquote>
			<p><a name="Fig6 GOO"></a><img id="goo" src="https://www.mprove.de/script/99/kai/_media/high/GOO.jpg" name="goo"></p>
			<p>Fig. 6 Kai’s Power GOO</p>
			<p>The <em>GOO room</em> is a specialized environment for shifting pixels around. But because Kai’s Power GOO is one of the first stand-alone applications from MetaTools some operating systems tasks like opening and closing images need to be accessible within the application. In order not to clutter the room that is special suited to edit the image, other rooms become part of the application. <span><a href="http://www.macworld.com/article/3005783/software-graphics/an-ode-to-kais-power-goo.html"><span>cf. An ode to Kai’s Power Goo, Macworld 11/2015</span></a></span> E.g. <em>Kai’s Photo Soap</em> (Fig. 7) initially presents you with a series of seven “rooms” – In, Prep, Tone, Color, Detail, Finishing and Out – which one can enter to perform particular tasks.</p>
			<p><img id="soap-rooms" src="https://www.mprove.de/script/99/kai/_media/high/SoapRooms.jpg" name="soap-rooms"></p>
			<p>Fig. 7 Plan-Room in Kai’s Photo Soap</p>
			<h3><a id="Bier93" name="Bier93"></a>Minimize the Interface</h3>
			<p>The concept of Magic Lenses was introduced by [<a href="https://www.mprove.de/script/99/kai/index.html#refBier93">Bier et al. 93</a>]. Two years later Kai designed a tool for KPT3 that can be dragged on top of an image. A circled look-through area shows a preview of the selected filter attributes.</p>
			<p><img id="lens" src="https://www.mprove.de/script/99/kai/_media/high/KPTLens.jpg" name="lens"></p>
			<p>Fig. 8 KPT Lens f/x 3.0 on top of a Photoshop image window</p>
			<p><a name="Kai95-2"></a>Kai himself describes the design concept that lead to the lens tool in KPT3:</p>
			<blockquote>
				<p>»What is called the “lenses” was in alpha known as the Dragon, as in “drag-on-the-image” and its design concept was so simple: make a precision instrument, like a little Swiss Army knife or a watch or microscope (it was also known as the fx Scope…) which has just a few very tiny controls around a center window. In this window a number of effects could be shown exactly as they would appear, over the real image, and updated in realtime.<br>
					It’s a lovely idea to keep all kinds of options hidden inside little wheels and dials that pop out to set and hide themselves during use… I think we have barely begun to use all the possibilities of that. And the actual interaction with the screen image is still a little clunky, hampered by the very illegality of bypassing the plug-in interface altogether.« [<a href="https://www.mprove.de/script/99/kai/index.html#refKai95">Kai95</a>]</p>
			</blockquote>
			<p>Soap is the consequent next step into this direction. The tools no longer need to be modal like the KPT lens; they can be used in a very natural modeless manner. Pens, brushes and erasers are distributed all over the workspace. They are large, they cast <strike>real</strike> virtual shadows, and the tips of the tools get pressed down while they are in use.</p>
			<p><img id="soap" src="https://www.mprove.de/script/99/kai/_media/high/Soap.jpg" name="soap" height="500" width="776"></p>
			<p>Fig. 9 …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mprove.de/script/99/kai/index.html">https://www.mprove.de/script/99/kai/index.html</a></em></p>]]>
            </description>
            <link>https://www.mprove.de/script/99/kai/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739545</guid>
            <pubDate>Sun, 05 Jul 2020 15:47:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Understand Things]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739474">thread link</a>) | @nqureshi
<br/>
July 5, 2020 | https://nabeelqu.co/understanding | <a href="https://web.archive.org/web/*/https://nabeelqu.co/understanding">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://nabeelqu.co/understanding</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739474</guid>
            <pubDate>Sun, 05 Jul 2020 15:38:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JIT Compilers Are Implemented and Fast: Julia, PyPy, LuaJIT, Graal and More]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23739416">thread link</a>) | @kipply
<br/>
July 5, 2020 | https://carolchen.me/blog/jits-impls/ | <a href="https://web.archive.org/web/*/https://carolchen.me/blog/jits-impls/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  <header>
    
    
  </header>

  <main id="main">
    
<article>
  <header>
    
    
  </header>
  <section id="js-article">
    
<p>This post goes into details of 5+ JITs and various optimization strategies and discuss how they work with different JITs. Information in this blog post is more <em>depth-first</em>, thus there are many important concepts that may be skipped.</p>
<p>For background on JIT compilers see <a href="https://carolchen.me/blog/jits-intro">A Deep Introduction to JIT Compilers: JITs are not very Just-in-time</a>. If the title does not make sense to you then it may be worth a skim. </p>
<blockquote>
<p><em>Mild Disclaimers, can be skipped</em>.</p>
</blockquote>
<blockquote>
<p>I will often describe an optimization behaviour and claim that it probably exists in some other compiler. Though I don't always check if an optimization exists in another JIT (it's sometimes ambiguous), I'll always state explicitly if I know it’s there. 
I will also provide code examples to show where an optimization might occur, however the optimization may not necessarily occur for that code because another optimization will take precedence. There may also be some general oversimplifications, but not more than I think exists in most posts like these. </p>
</blockquote>
<h2 id="table-of-contents-highlights">Table of Contents / Highlights<a href="#table-of-contents-highlights" aria-label="Anchor link for: table-of-contents-highlights"> <i></i></a>
</h2>
<ul>
<li><a href="https://carolchen.me/blog/jits-impls/#wait-but-you-said-meta-tracing">Meta-tracing in Pypy works</a></li>
<li><a href="https://carolchen.me/blog/jits-impls/#interpreting-c">How GraalVM languages support C extensions</a></li>
<li><a href="https://carolchen.me/blog/jits-impls/#go-back-to-the-interpreted-code-it-ll-be-faster">Deoptimisation</a></li>
<li><a href="https://carolchen.me/blog/jits-impls/#wet-code-is-fast-code-inlining-and-osr">Inlining and OSR</a></li>
<li><a href="https://carolchen.me/blog/jits-impls/#what-if-instead-of-instruction-based-ir-like-everyone-else-we-had-a-big-graph-and-also-it-modifies-itself">Seas of Nodes</a></li>
<li><a href="https://carolchen.me/blog/jits-impls/#yay-jit-compiled-code-let-s-compile-it-again-and-again">Tiering JITs</a></li>
</ul>

<p>LuaJIT employs a method called tracing. Pypy does meta-tracing, which involves using a system to generate tracing interpreters and JITs. Pypy and LuaJIT are not the reference implementations of Python or Lua, but a projects on their own. I would describe LuaJIT as shockingly fast, and it describes itself as one of the fastest dynamic language implementations -- which I buy fully.</p>
<p>To determine when to start tracing, the interpreting loop will look for "hot" loops to trace (the concept of "hot" code is universal to JITS!). Then, the compiler will "trace" the loop, recording executed operations to compile well optimized machine code. In LuaJIT, the compilation is performed on the traces with an instruction-like IR that is unique to LuaJIT. </p>
<h3 id="how-pypy-implements-tracing"><strong>How Pypy Implements Tracing</strong><a href="#how-pypy-implements-tracing" aria-label="Anchor link for: how-pypy-implements-tracing"> <i></i></a>
</h3>
<p>Pypy will start tracing a function after 1619 executions, and will compile it after another 1039 executions, meaning a function has to execute around 3000 times for it to start gaining speed. These constants were carefully tuned by the Pypy team (lots of constants are tuned for compilers in general!).</p>
<p>Dynamic languages make it hard to optimize things away. The following code could be statically eliminated by a stricter language, as <code>False</code> will always be falsy. However, in Python 2, that could not have been guaranteed before runtime.</p>
<pre><code><span>if </span><span>False</span><span>:
  </span><span>print</span><span>(</span><span>"FALSE"</span><span>)
</span></code></pre>
<p>For any sane program, the conditional will always be false. Unfortunately, the value of <code>False</code> could be reassigned and thus if the statement were in a loop, it could be redefined somewhere else. For this case, Pypy would build a "guard". When a guard fails, the JIT will fall back to the interpreting loop. Pypy then uses another constant (200), called <em>trace eagerness</em> to decide whether to compile the rest of the new path till the end of the loop. That sub-path is called a <em>bridge</em>.</p>
<p>Pypy also exposes all those constants as arguments that can be tweaked at execution, along with configuration for unrolling (expanding loops) and inlining! It also exposes some hooks so we can see when things are compiled. </p>
<pre><code><span>def </span><span>print_compiler_info</span><span>(</span><span>i</span><span>):
  </span><span>print</span><span>(i</span><span>.</span><span>type)
pypyjit</span><span>.</span><span>set_compile_hook</span><span>(print_compiler_info)

</span><span>for </span><span>i </span><span>in </span><span>range</span><span>(</span><span>10000</span><span>):
  </span><span>if </span><span>False</span><span>:
    </span><span>pass

</span><span>print</span><span>(pypyjit</span><span>.</span><span>get_stats_snapshot</span><span>()</span><span>.</span><span>counters)
</span></code></pre>
<p>Above, I set up a plain python program with a compile hook to print the type of compilation made. It also prints some data at the end, where I can see the number of guards. For the above I get one compilation of a loop and 66 guards. When I replaced the if statement with just a pass under the for-loop, I was left with 59 guards.</p>
<pre><code><span>for </span><span>i </span><span>in </span><span>range</span><span>(</span><span>10000</span><span>):
  </span><span>pass </span><span># removing the `if False` saved 7 guards!
</span></code></pre>
<p>With these two lines added to the for loop, I will get two compilations, with the new one being of type 'bridge'!</p>
<pre><code><span>if </span><span>random</span><span>.</span><span>randint</span><span>(</span><span>1</span><span>, </span><span>100</span><span>) </span><span>&lt; </span><span>20</span><span>:
  </span><span>False </span><span>= </span><span>True
</span></code></pre><h3 id="wait-but-you-said-meta-tracing">Wait, but you said Meta-tracing!<a href="#wait-but-you-said-meta-tracing" aria-label="Anchor link for: wait-but-you-said-meta-tracing"> <i></i></a>
</h3>
<p>The concept behind meta-tracing is “write an interpreter, get a compiler for free!” or more magically, “turn your interpreter into a JIT-compiler!”. This is just obviously a great thing, since writing compilers is hard so if we can get a great compiler for free that’s just a good deal. Pypy "has" an interpreter and a compiler, but there’s no explicit implementation of a traditional compiler.</p>
<p>Pypy has a toolchain called RPython (which was built for Pypy). It is a framework program for implementing interpreters. It is a language in that it specifies a subset of the Python language, namely to force things like static typing. It is a language to write an interpreter in. It is not a language to code in typed-Python, since it doesn’t care or have things like standard libraries or packages. Any RPython program is a valid Python program. RPython programs are transpiled to C and then compiled. Thus, the RPython meta-compiler exists as a compiled C program.</p>
<p>The “meta” in meta-tracing comes from the fact that the trace is on the execution of the interpreter rather than the execution of the program. The interpreter more or less behaves as any interpreter, with the added capability of tracing its own operations, and being engineered to optimize those traces by updating the path of the interpreter (itself). With further tracing, the path that the interpreter takes becomes more optimized. With a very optimized interpreter taking a specific, optimized path, the compiled machine code being used in that path from the compiled RPython can be used as the compilation. </p>
<p>In short, the “compiler” in Pypy is compiling your interpreter, which is why Pypy is sometimes referred to as a meta-compiler. The compiler is less for the program you're trying to execute, but rather for compiling the trace of the optimizing interpreter!</p>
<p>Metatracing might be confusing, so I wrote a very bad metatracing program that can only understand <code>a = 0</code> and <code>a++</code>to illustrate.</p>
<pre><code><span># interpreter written with RPython
</span><span>for </span><span>line </span><span>in </span><span>code:
  </span><span>if </span><span>line </span><span>== </span><span>"a = 0"</span><span>:
    </span><span>alloc</span><span>(a, </span><span>0</span><span>)
  </span><span>elif </span><span>line </span><span>== </span><span>"a++"</span><span>:
    </span><span>guard</span><span>(a, </span><span>"is_int"</span><span>) </span><span># notice how in Python, the type is unknown, but after being interpreted by RPython, the type is known
    </span><span>guard</span><span>(a, </span><span>"&gt; 0"</span><span>)
    </span><span>int_add</span><span>(a, </span><span>1</span><span>)
</span></code></pre>
<p>If I ran the following in a hot loop;</p>
<pre><code><span>a </span><span>= </span><span>0
</span><span>a</span><span>++
</span><span>a</span><span>++
</span></code></pre>
<p>Then the traces may look something like:</p>
<pre><code><span># Trace from numerous logs of the hot loop
</span><span>a </span><span>= </span><span>alloc</span><span>(</span><span>0</span><span>) </span><span># guards can go away
</span><span>a </span><span>= </span><span>int_add</span><span>(a, </span><span>1</span><span>)
a </span><span>= </span><span>int_add</span><span>(a, </span><span>2</span><span>)

</span><span># optimize trace to be compiled
</span><span>a </span><span>= </span><span>alloc</span><span>(</span><span>2</span><span>) </span><span># the section of code that executes this trace _is_ the compiled code
</span></code></pre>
<p>But the compiler isn't some special standalone unit, it's built into the interpreter! So the interpreter loop would actually look something like this</p>
<pre><code><span>for </span><span>line </span><span>in </span><span>code:
  </span><span>if </span><span>traces</span><span>.</span><span>is_compiled</span><span>(line):
    </span><span>run_compiled</span><span>(traces</span><span>.</span><span>compiled</span><span>(line))
    </span><span>continue
  elif </span><span>traces</span><span>.</span><span>is_optimized</span><span>(line):
    </span><span>compile</span><span>(traces</span><span>.</span><span>optimized</span><span>(line))
      </span><span>continue
  elif </span><span>line </span><span>== </span><span>"a = 0"
  </span><span># ....
</span></code></pre><h2 id="an-introduction-to-jvms">An Introduction to JVMs<a href="#an-introduction-to-jvms" aria-label="Anchor link for: an-introduction-to-jvms"> <i></i></a>
</h2>
<p>Disclaimer: I worked on/with a Graal-based language, <a href="https://github.com/oracle/truffleruby">TruffleRuby</a> for four months and loved it.</p>
<p>Hotspot (named after looking for <em>hot</em> spots) is the VM that ships with standard installations of Java, and there are actually multiple compilers in it for a tiered strategy. Hotspot is open source, with 250,000 lines of code which contains the compilers, and three garbage collectors. It does an <em>awesome</em> job at being a good JIT, there are some benchmarks that have Hotspot on par with C++ impls (oh my gosh so many asterisks on this, you can Google to find all the debate). Though Hotspot is not a tracing JIT, it employs a similar approach of having an interpreter, profiling and then compiling. There is not a specific name for what Hotspot does, though the closest categorization would probably be a Tiering JIT. </p>
<p>Strategies used in Hotspot inspired many of the subsequent JITs, the structure of language VMs and especially the development of Javascript engines. It also created a wave of JVM languages such as Scala, Kotlin, JRuby or Jython. JRuby and Jython are fun implementations of Ruby and Python that compile the source code down to the JVM bytecode and then have Hotspot execute it. These projects have been relatively successful at speeding up languages like Python and Ruby (Ruby more so than Python) without having to implement an entire toolchain like Pypy did. Hotspot is also unique in that it's a JIT for a less dynamic language (though it's technically it's a JIT for JVM bytecode and not Java). </p>
<p><img src="https://carolchen.me/blog/img/jits/vms.png" alt=""></p>
<p>GraalVM is a JavaVM and then some, written in Java. It can run any JVM language (Java, Scala, Kotlin, etc). It also supports a Native Image, to allow AOT compiled code through something called Substrate VM. Twitter runs a significant portion of their Scala services with Graal, so it must be pretty good, and better than the JVM in some ways despite being written in Java. </p>
<p>But wait, there's more! GraalVM also provides Truffle, a framework for implementing languages through building Abstract Syntax Tree (AST) interpreters. With Truffle, there’s no explicit step where JVM bytecode is created as with a conventional JVM language, rather Truffle will just use the interpreter and communicate with Graal to create machine code directly with profiling and a technique called partial evaluation. Partial evaluation is out of scope for this blog post, tl;dr it follows metatracing’s “write an interpreter, get a compiler for free” philosophy but is approached differently.</p>
<blockquote>
<p>TruffleJS, the Truffle implementation of Javascript outperforms the JavaScript V8 engine on select benchmarks which is really impressive since V8 has had numerous more years of development, Google money+resources poured in and some crazy skilled people working on it. TruffleJS is still by no means “better” than V8 (or other JS engines) on most measures but it is a sign of promise for Graal. </p>
</blockquote>

<h3 id="interpreting-c">Interpreting C<a href="#interpreting-c" aria-label="Anchor link for: interpreting-c"> <i></i></a>
</h3>
<p>A common problem with JIT implementations is support for C Extensions. Standard interpreters such …</p></section></article></main></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://carolchen.me/blog/jits-impls/">https://carolchen.me/blog/jits-impls/</a></em></p>]]>
            </description>
            <link>https://carolchen.me/blog/jits-impls/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739416</guid>
            <pubDate>Sun, 05 Jul 2020 15:31:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Andrew Wilkinson and Tiny Capital]]>
            </title>
            <description>
<![CDATA[
Score 77 | Comments 16 (<a href="https://news.ycombinator.com/item?id=23739381">thread link</a>) | @colinkeeley
<br/>
July 5, 2020 | https://colinkeeley.com/blog/andrew-wilkinson-tiny-capital-operating-manual | <a href="https://web.archive.org/web/*/https://colinkeeley.com/blog/andrew-wilkinson-tiny-capital-operating-manual">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-db1d94e86a488296a48d"><div><blockquote><p><em>“Let someone else run the marathon and incentivize them.”&nbsp;</em></p><p><em>-Andrew Wilkinson</em></p></blockquote><p><strong>What is Tiny?</strong></p><p><a href="http://tinycapital.com/">Tiny</a>&nbsp;is a long term holding company for internet businesses started by&nbsp;<a href="https://twitter.com/awilkinson">Andrew Wilkinson</a>&nbsp;and&nbsp;<a href="https://twitter.com/_sparling_?lang=en">Chris Sparling</a>. They take majority, generally whole, stakes in "profitable, simple, and often boring” internet businesses.&nbsp;</p><p><strong>Why are holding companies and micro private equity interesting?&nbsp;</strong></p><p>I suspect this is the most dependable way to become very wealthy. It isn’t as glamorous or as quick (potentially) as founding or investing in the next multi-billion dollar startup. This is a longer-term grind it out approach.&nbsp;</p><p>Starting companies is fun, but anyone who has done it knows it is a lot of work. Buying established businesses with existing cash flow isn’t as sexy so I suspect it is wildly underrated as a way of building wealth.&nbsp;</p><p>The reality is that it is easier to buy and improve businesses than to start them. It is easier to go from 3 to 10 than from 0 to 1. Even for the folks that have done it before.&nbsp;</p><p>There isn’t much info on how holding companies or micro-PEs like Tiny actually operate. I’ve listened to every podcast Andrew has been on and compiled these notes from them.&nbsp;</p><p>Here is what they are doing behind the scenes.</p><p><strong>How Andrew got started? Where the capital comes from?</strong></p><p>In 2006, Andrew founded&nbsp;<a href="http://metalab.co/">MetaLab</a>, a Victoria, Canada-based design agency shortly after high school. After rapid growth, he used the profits to diversify into a variety of businesses, which today form Tiny, a holding company he owns fully with his business partner Chris Sparling.&nbsp;</p><p>Agencies traditionally aren’t very profitable, but MetaLab is able to charge San Francisco agency rates and only pay Victoria, Canada wages.&nbsp;</p><p>Tiny shifted its focus from starting businesses to buying them in 2013 when MetaLab and all their other businesses combined were doing $7M/year in profit. Tiny is fully self-funded today.</p><p><strong>What’s the scale of Tiny now?</strong></p><p>Comfortably not tiny. It sounds like somewhere around $80-95M revenue per year (double-digit millions is what Andrew says) with highly profitable businesses. They have around 350-400 employees across 20ish companies.&nbsp;</p><p><strong>What Tiny looks for in businesses to buy?</strong></p><p>From their site:</p><blockquote><p><em>3-5+ years of operating history</em></p><p><em>Profits. A minimum $500k/year in annual profit, as high as $15MM.</em></p><p><em>A high-quality team in place. This is negotiable if the business is simple to operate and the team wants to leave.</em></p><p><em>We are open to owners sticking around, leaving cold turkey, or transitioning out over time. We'll work with you to transition.</em></p><p><em>Simple internet businesses that have high margins, don't require tons of people or complex technology, and have a competitive advantage that protects them from competitors. For example: A dominant brand, a large and loyal community, a niche vertical, or something similar.</em></p></blockquote><p>Andrew describes these businesses as "New Zealand companies.”</p><p>What is a New Zealand company?</p><ul data-rte-list="default"><li><p>It is in the middle of nowhere, nobody is paying attention to it, but it is quietly growing. It is not at risk of nuclear war.&nbsp;</p></li><li><p>It is self-sufficient and thriving. It’s food &amp; energy independent. A "safe" business isn't beholden to benevolent gatekeepers like Google or Facebook to reach their customer.&nbsp;</p></li></ul><p>Andrew is always worried about staying power.&nbsp;</p><p>An example of one of his New Zealand business is Dribbble:</p><ul data-rte-list="default"><li><p>Top 1,000 site on the internet&nbsp;</p></li><li><p>A huge community of designers</p></li><li><p>Profitable</p></li><li><p>Few competitors. Big companies are not trying to kill it or compete.&nbsp;</p></li><li><p>Not dependent on Facebook or Google for traffic. People type Dribbble.com into the address bar to visit.&nbsp;</p></li></ul><p><strong>Types of businesses Tiny has bought/started?</strong></p><p>I don’t know if this is by design, but it seems like Andrew has progressed from services to tools/products to platforms/communities to digital marketplaces.&nbsp;</p><ul data-rte-list="default"><li><p>Agencies: MetaLab (design agency), Double Up (podcast growth agency), 8020 (no-code agency)</p></li><li><p>SaaS tools:&nbsp;<a href="https://www.getflow.com/">Flow</a>&nbsp;(product management), Castro (podcast player), Supercast (podcast subscriptions)</p></li><li><p>Products: Caramba</p></li><li><p>Communities: Dribbble&nbsp;</p></li><li><p>Media: Designer News, RideHome (podcast network)</p></li><li><p>Job Boards:&nbsp;<a href="https://weworkremotely.com/">We Work Remotely</a></p></li><li><p>Digital goods marketplaces: Creative Market, Pixel Union</p></li></ul><p><strong>How Tiny companies operate?</strong></p><p>Tiny companies have fewer information responsibilities than typical PE-owned companies. There are no formal board meetings for example.&nbsp;</p><p>Once a month companies send Tiny a finance-only update with the P&amp;L, balance sheet, and KPIs. No operational info is included.&nbsp;</p><p>Once a quarter companies send Tiny a SWOT (strengths, weaknesses, opportunities, and threats) analysis.&nbsp;</p><p>Companies contact Tiny ASAP for emergencies, major news, or decisions.&nbsp;</p><p>Some CEOs will go 6 months or more without speaking with Andrew.&nbsp;</p><p><strong>How Tiny launches new businesses?</strong></p><p>Tiny’s primary business is buying majority stakes in businesses, not starting them. For a while Andrew would start a new business in any niche he was interested in. He tries to avoid that now and thinks it’s a lot better to buy something that is already good.</p><p>When Andrew does start a new business now, he delegates almost all aspects of it. He recently said he only spent something like 4 hours on each of the new businesses he has launched.&nbsp;</p><p>Andrew will pay for all the work to be done and the investment will form his stake in the business. He will find a CEO to run the business and pay the new CEOs a month or two of salaries to get things going. Then he’ll help with intros, but otherwise, he’ll be hands-off. All in he said it takes $10-50k to get off the ground with a great operator.</p><p><strong>Why do Founders sell to Tiny?</strong></p><p>Tiny is positioned as the good guys of private equity. The Berkshire Hathway of internet businesses.</p><p>They have become known for doing simple acquisitions. Andrew didn’t like the traditional acquisition process: long due diligence, and renegotiation of terms. Warren Buffet does deals in seven days and those are larger, more complex businesses. Smaller deals should be even quicker.</p><p>A challenge with this model is that it is difficult to acquire tech companies at reasonable prices. Acquiring boring traditional businesses is easier because the valuations are so much lower than tech companies. To successfully use this approach you need discipline around what you’re willing to pay for a business and a reputation for being easy to work with. Andrew gets deals by being a nice guy and offering a good home for businesses to live on. Contrast this with the typical PE approach of dramatically cutting costs (ie firing everyone) and squeezing as much profit out as possible. Some founders are looking more for freedom and an easy process than maximizing their financial outcome. </p><p>These smaller PE opportunities are underserved relative to the typical VC businesses. The lifestyle businesses that VC shuns are Andrew’s ideal companies. He is fishing in a less crowded pond. </p><p>Andrew will occasionally pay 10x for an amazing business, but that is rare.&nbsp;</p><p><strong>What happens to businesses after the sale?&nbsp;</strong></p><p>For the employees, it is business as usual for the most part. The goal is for the employees to not even notice.&nbsp; </p><p>The biggest difference is that Tiny becomes the bank. Cash is kept in the company based on historical working capital needs and any extra goes to the head office for new acquisitions.&nbsp; </p><p>Often Tiny buys product or designer-led startups that have grown organically. They will put standard best-practice marketing and sales processes in place and sometimes raise prices. Each company has its own CEO with a few exceptions like all job boards (5+) are under one CEO.&nbsp; </p><p>Tiny has a preference for remote companies where they can hire more affordably. Andrew estimates the cost of running a business in Canada can be 60-65% the cost of in California. Struggling American companies with inflated cost structures can reduce costs by moving to Canada. Canadian arbitrage includes lower salaries, not needing to pay medical benefits, SRED, and cheaper currency.</p><p><strong>Who runs the business after a sale?&nbsp;</strong></p><p>Often Andrew is buying from bootstrapped founders that have been at it for 5-10 years and want to move on.</p><p>Finding great people to run these companies is one of the hardest aspects of this model.&nbsp;</p><p>Andrew deals with this by paying up and hiring CEOs that have managed similar businesses at larger scales already before instead of trying to find underpriced less-experienced talent.&nbsp;</p><p>Months before closing on a deal Andrew works to identify opportunities for the business and a new leader to come in.&nbsp;</p><p>He finds these new CEOs through his existing CEOs by asking “we’re about to buy a business who’s the smartest person you know in the space."</p><p><strong>What does the operating company and Andrew do day-to-day?</strong></p><blockquote><p><em>“Entrepreneurship is just delegation”&nbsp;</em></p><p><em>-Andrew Wilkinson</em></p></blockquote><p>Andrew spends time looking for new deals and looking at their existing portfolio and thinking "how they could get fucked”.&nbsp;</p><p>Andrew says his strengths are:</p><ul data-rte-list="default"><li><p>Laser focused on problems for a short period of time. Moves fast.&nbsp;</p></li><li><p>Very good at 0 to 1. Burns bright for 15 days.&nbsp;</p></li><li><p>Inch deep and a mile wide</p></li><li><p>Not good at execution or day to day details</p></li></ul><p>Being comfortable with delegation is key to this model. Andrew is the owner, not the CEO. The owner can’t constantly be delegating what can or can’t be done or the CEO grows resentful. Some comfort with decisions being made that you don’t agree with comes with the territory. Large decisions that require more capital than usual are a discussion.&nbsp;</p><p><strong>How connected are businesses in the holding company?</strong></p><p>Tiny companies are not at all connected. They each operate independently.&nbsp;</p><p>CEOs will take calls and give advice on best practices, but nothing beyond small favors. Real work gets paid for. Tiny pays all companies for the work they do for the holding company and all work between companies is paid at the full rate.&nbsp;</p><p>Synergies are appealing, but they generally just make the CEOs resentful so they are avoided entirely.&nbsp;</p><p><strong>How much debt do they use?</strong></p><p>Tiny uses little debt for acquisitions (less than Berkshire Hathaway) and they like to pay off debt within 6 months. Debt comes from&nbsp;<a href="https://en.wikipedia.org/wiki/Business_Development_Bank_of_Canada"><strong>BDB of Canada</strong></a>, or traditional banks.</p><p><em>If you know of anything I should add to this please reach …</em></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://colinkeeley.com/blog/andrew-wilkinson-tiny-capital-operating-manual">https://colinkeeley.com/blog/andrew-wilkinson-tiny-capital-operating-manual</a></em></p>]]>
            </description>
            <link>https://colinkeeley.com/blog/andrew-wilkinson-tiny-capital-operating-manual</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739381</guid>
            <pubDate>Sun, 05 Jul 2020 15:26:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deciphering Repeated-Key XOR Ciphertexts Using Hamming Distance]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739362">thread link</a>) | @arpitbbhayani
<br/>
July 5, 2020 | https://arpitbhayani.me/blogs/decipher-repeated-key-xor?ref=hn | <a href="https://web.archive.org/web/*/https://arpitbhayani.me/blogs/decipher-repeated-key-xor?ref=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Encryption is a process of encoding messages such that it can only be read and understood by the intended parties. The process of extracting the original message from an encrypted one is called Decryption. Encryption usually scrambles the original message using a key, called the encryption key, that the involved parties agree on.</p>
<p>In the previous essay, we went through the <a href="https://arpitbhayani.me/blogs/decipher-single-xor">Single-byte XOR cipher</a> and found a way to decipher it without having any knowledge of the encryption key. In this essay, we find how to break a <a href="https://en.wikipedia.org/wiki/XOR_cipher">Repeating-key XOR cipher</a> with variable key length. The problem statement, defined above, is based on <a href="https://cryptopals.com/sets/1/challenges/6">Cryptopals Set 1 Challenge 6</a>.</p>

<p>The Repeating-key XOR cipher algorithm works with an encryption key with no constraint on its length, which makes it much stronger than a Single-byte XOR Cipher, where the encryption key length was restricted to a single byte.</p>
<h2>Encryption</h2>
<p>A plain text is encrypted using an encryption key by performing a bitwise <a href="https://en.wikipedia.org/wiki/Exclusive_or">XOR</a> operation on every character. The encryption key is repeated until it XORs every single character of the plain text and the resultant stream of bytes is again translated back as characters and sent to the other party. These encrypted bytes need not be among the usual printable characters and should ideally be interpreted as a stream of bytes. Following is the python-based implementation of this encryption process.</p>
<pre><code><span><span>def</span> <span>repeating_key_xor</span><span>(text: bytes, key: bytes)</span> -&gt; bytes:</span>
    <span>"""Given a plain text `text` as bytes and an encryption key `key`
    as bytes, the function encrypts the text by performing
    XOR of all the bytes and the `key` (in repeated manner) and returns
    the resultant XORed byte stream.
    """</span>
    
    
    
    repetitions = <span>1</span> + (len(text) // len(key))
    key = key * repetitions
    key = key[:len(text)]

    
    <span>return</span> bytes([b ^ k <span>for</span> b, k <span>in</span> zip(text, key)])
</code></pre>
<p>As an example, we encrypt the plain text - <code>secretattack</code> - with encryption key <code>$^!</code> and as per the algorithm, we first repeat the encryption key until it matches the length of the plain text and then XOR it against the plain text. The illustration below shows the entire encryption process.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/85919742-d1520600-b88b-11ea-8d71-aa36c58dc48a.png" alt="https://user-images.githubusercontent.com/4745789/85919742-d1520600-b88b-11ea-8d71-aa36c58dc48a.png"></p>
<p>For the first character in plain text - <code>s</code> - the byte i.e. ASCII value is <code>115</code> which when XORed with <code>$</code> results in <code>87</code> whose character equivalent is <code>W</code>, similarly for the second character <code>e</code> the encrypted byte is <code>;</code>, for <code>c</code> it is <code>B</code>, for the fourth character <code>r</code>, since the key repeats, the XOR is taken with <code>$</code> to get <code>V</code> and the process continues. The resultant encrypted text using repeated-key XOR on the plain text <code>secretattack</code> with key <code>$^!</code> is <code>W;BV;UE*UE=J</code>.</p>
<h2>Decryption</h2>
<p>Decryption is a process of extracting the original message from the encrypted ciphertext given the encryption key. XOR has a <a href="https://brainly.in/question/3038497">property</a> - if <code>a = b ^ c</code> then <code>b = a ^ c</code>, hence the decryption process is exactly the same as the encryption i.e. we first repeat the encryption key till it matches the length and then perform bitwise XOR with the ciphertext - the resultant bytes stream will be the original message.</p>
<p>Since encryption and decryption both have an exact same implementation - we pass the ciphertext to the function <code>repeating_key_xor</code>, defined above, to get the original message back.</p>
<pre><code><span>&gt;&gt;&gt; </span>repeating_key_xor(<span>b'W;BV;UE*UE=J'</span>, <span>b'$^!'</span>)
<span>b'secretattack'</span>
</code></pre>

<p>Things become really interesting when, given the encryption algorithm, we have to recover the original message from the ciphertext with no knowledge of the encryption key. Just like solving any other problem, the crux of deciphering the message encrypted using repeated-key XOR cipher is to break it down into manageable sub-problems and tackle them independently. We break this deciphering problem into the following two sub-problems:</p>
<ul>
<li>Finding the length of the Encryption Key</li>
<li>Bruteforce with all possible keys and finding the "most English" plain text</li>
</ul>
<h2>Finding the length of the Encryption Key</h2>
<p>In order to recover the original text from the cipher, we first find the length of the encryption key used and then apply brute force with all possible keys of the estimated length and deduce the plain text. Finding the length of the Encryption key makes the deciphering process quicker as it eliminates a lot of false keys and thus reducing the overall effort required during the brute force. In order to find the length of the Encryption Key, we need to have a better understanding of a seemingly unrelated topic - Hamming Distance.</p>
<h3>Hamming Distance</h3>
<p>Hamming distance between two bytes is the number of positions at which the corresponding bits differ. For a stream of bytes, of equal lengths, it is the sum of Hamming Distances between the corresponding bytes. Finding differences between bits can be efficiently done using bitwise XOR operation as the operation yields <code>0</code> when both the bits are the same and <code>1</code> when they differ. So for computing Hamming Distance between two bytes we XOR the bytes and count the number of <code>1</code> in its binary representation.</p>
<pre><code><span><span>def</span> <span>hamming_distance_bytes</span><span>(text1: bytes, text2: bytes)</span> -&gt; int:</span>
    <span>"""Given two stream of bytes, the function returns the Hamming Distance
    between the two.
    Note: If the two texts have unequal lengths, the hamming distance is
    computed only till one of the text exhausts, other bytes are not iterated.
    """</span>
    dist = <span>0</span>
    <span>for</span> byte1, byte2 <span>in</span> zip(text1, text2):
        dist += bin(byte1 ^ byte2).count(<span>'1'</span>)
    <span>return</span> dist

<span>&gt;&gt;&gt; </span>hamming_distance_bytes(<span>b'ab'</span>, <span>b'zb'</span>)
<span>4</span>
</code></pre>
<p>In the example above, we find that the hamming distance between two bytestreams <code>ab</code> and <code>zb</code> is <code>4</code>, which implies that the byte streams <code>ab</code> and <code>zb</code> differ at <code>4</code> different bits in their binary representations.</p>
<h3>Hamming Score</h3>
<p>Hamming distance is an absolute measure, hence in order to compare hamming distance across byte streams of varying lengths, it has to be normalized with the number of pairs of bits compared. We name this measure - Hamming Score - which thus is defined as the Hamming Distance per unit bit-pair. In python, Hamming Score is implemented as:</p>
<pre><code><span><span>def</span> <span>hamming_score_bytes</span><span>(text1: bytes, text2: bytes)</span> -&gt; float:</span>
    <span>"""Given two streams of bytes, the function computes a normalized Hamming
    Score based on the Hamming distance.
    Normalization is done by dividing the Hamming Distance by the number of bits
    present in the shorter text.
    """</span>
    <span>return</span> hamming_distance_bytes(text1, text2) / (<span>8</span> * min(len(text1), len(text2)))

<span>&gt;&gt;&gt; </span>hamming_score_bytes(<span>b'ab'</span>, <span>b'zb'</span>)
<span>0.25</span>
</code></pre>
<h3>What can we infer through Hamming Distance?</h3>
<p>Hamming Distance is an interesting measure; it effectively tells us the minimum number of bit flips required to convert one bytestream into another. It also implies that (on average) if the numerical values of two bytestreams are closer then their Hamming Distance and Hamming Score will be lower i.e it would take fewer bit flips to convert one into another.</p>
<p>This is evident from the fact that the average Hamming distance between any two bytes <code>[0-256)</code> picked at random is <code>3.9999</code> while that of any two lowercased English characters <code>[97, 122]</code> is just <code>2.45</code>. Similar ratios are observed for Hamming Score where <code>0.4999</code> is of the former while <code>0.3072</code> is of the later.</p>
<p>This inference comes in handy when we want to find out the length of Encryption Key in Repeating-key XOR Cipher as illustrated in the section below.</p>
<h3>Formal definition of encryption and decryption processes</h3>
<p>Say if <code>p</code> denotes the plaintext, <code>k</code> denotes the encryption key which is repeated to match the length of the plain text, and <code>c</code> denotes the ciphertext, we could define encryption and decryption processes as</p>
<pre><code>encryption: c[i] = p[i] XOR k[i]   <span>for</span> i <span>in</span> [<span>0</span>, len(c))
decryption: p[i] = c[i] XOR k[i]   <span>for</span> i <span>in</span> [<span>0</span>, len(p))
</code></pre>
<p>The above definitions, along with the rules of XOR operations, implying that if we XOR two bytes of the ciphertext, encrypted (XORed) using the same byte of the encryption key, we are effectively XORing the corresponding bytes of the plain text. If <code>k'</code> is the byte of the encryption key <code>k</code> which was used to encrypt (XOR) the bytes <code>p[i]</code> and <code>p[j]</code> of the plain text to generate <code>c[i]</code> and <code>c[j]</code> of the ciphertext, we could derive the following relation</p>
<pre><code># k' <span>is</span> the common byte <span>of</span> the key i.e. k' = k = k

c XOR c = (p XOR k') XOR (p XOR k')
              = p XOR k' XOR k' XOR p
              = p XOR 0 XOR p
              = p XOR p
</code></pre>
<p>The above relation, <code>c[i] XOR c[j]</code> equal to <code>p[i] XOR p[j]</code>, holds true only because both the bytes were XORed with the same byte <code>k'</code> of the encryption key; which in fact helped reduce the expression. If the byte from the encryption key which was used to XOR the pain texts were different then the relation was irreducible and we could not have possibly setup this relation.</p>
<h3>Chunking of ciphertext</h3>
<p>Chunking is the process where the ciphertext is split into smaller chunks (segments) of almost equal lengths. For example, chunking the ciphertext <code>W;BV;UE*UE=J</code> for chunk length <code>4</code> would create <code>3</code> chunks <code>W;BV</code>, <code>;UE*</code> and <code>UE=J</code>. The illustration below shows the chunks that would be formed for <code>W;BV;UE*UE=J</code> with chunks lengths varying from 2 to 6.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/86434084-24a7d680-bd1a-11ea-8346-aad7b42bab1c.png" alt="https://user-images.githubusercontent.com/4745789/86434084-24a7d680-bd1a-11ea-8346-aad7b42bab1c.png"></p>
<h3>XOR of the chunks</h3>
<p>Something very interesting happens when we compute the Average Hamming Score for all possible chunk lengths. If we consider the ciphertext <code>b'W;BV;UE*UE=J</code> and we chunk it with lengths varying from 2 to 6, we get the following distribution for the Average Hamming Score for each of the chunk length.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/86473899-6149f100-bd5f-11ea-908a-d4adabff1cf0.png" alt="https://user-images.githubusercontent.com/4745789/86473899-6149f100-bd5f-11ea-908a-d4adabff1cf0.png"></p>
<p>From the distribution above it is evident that the score was minimum at chunk length equalling <code>3</code>, which actually was the length of the Encryption Key used on the plain text. Is this mere coincidence or are we onto something?</p>
<p>When chunk length is equal to the length of the encryption key, the XOR operation on any two chunks will reduce the expression to XOR of the corresponding plain texts (as seen above), because there will be a perfect alignment of bytes from ciphertext and bytes from the keys i.e every <code>i</code>th byte from both the chunks would have been XORed with <code>i</code>th byte from the encryption key.</p>
<p>We have established that for chunk length equal to the length of the encryption key <code>c[i] XOR c[j]</code> …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://arpitbhayani.me/blogs/decipher-repeated-key-xor?ref=hn">https://arpitbhayani.me/blogs/decipher-repeated-key-xor?ref=hn</a></em></p>]]>
            </description>
            <link>https://arpitbhayani.me/blogs/decipher-repeated-key-xor?ref=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739362</guid>
            <pubDate>Sun, 05 Jul 2020 15:24:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ideas to make daily stand-up meetings engaging in remote work]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739264">thread link</a>) | @notatechie
<br/>
July 5, 2020 | https://www.peoplebox.ai/blog/how-to-use-daily-standup-meetings-for-remote-employee-engagement/ | <a href="https://web.archive.org/web/*/https://www.peoplebox.ai/blog/how-to-use-daily-standup-meetings-for-remote-employee-engagement/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-content-container">

        	<div id="post-content">
			
            	   <p><img src="https://www.peoplebox.ai/wp-content/uploads/2020/06/MS-teams.jpg" alt="daily standup meetings for remote employee engagement" width="840" height="472" srcset="https://www.peoplebox.ai/wp-content/uploads/2020/06/MS-teams.jpg 840w, https://www.peoplebox.ai/wp-content/uploads/2020/06/MS-teams-300x169.jpg 300w, https://www.peoplebox.ai/wp-content/uploads/2020/06/MS-teams-768x432.jpg 768w" sizes="(max-width: 840px) 100vw, 840px" data-srcset="https://www.peoplebox.ai/wp-content/uploads/2020/06/MS-teams.jpg 840w, https://www.peoplebox.ai/wp-content/uploads/2020/06/MS-teams-300x169.jpg 300w, https://www.peoplebox.ai/wp-content/uploads/2020/06/MS-teams-768x432.jpg 768w" data-src="https://www.peoplebox.ai/wp-content/uploads/2020/06/MS-teams.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>
<p>Source – Microsoft teams</p>
<p><span><span>D</span>aily standup meetings are a routine part of a manager’s life.&nbsp;</span><span>They serve as an axis to keep the team well-connected and in touch with each other’s role in achieving the common goal.&nbsp;</span></p>
<p><span>In the wake of COVID-19 pandemic, the world continues to embrace remote work more and more.</span></p>
<p><span>Consequently, a manager has to reinvent her strategies with a </span><a href="https://www.peoplebox.ai/blog/remote-first-vs-remote-friendly-companies-whats-the-difference/"><span>remote-friendly approach</span></a><span> and find ways to maintain high </span><a href="https://www.peoplebox.ai/blog/how-important-is-remote-employee-engagement-to-team-productivity/"><span>remote employee engagement</span></a><span>.</span></p>

<div>
<p><strong>Some of the biggest problems a manager with remote employees face is eliminating the communication gap and daily standup meetings can be an effective way to deal with it.</strong></p>
</div>



<p><span>A standup meeting can also help a manager in improving remote employee engagement and increasing productivity besides removing barriers to communication.</span></p>
<p><span>All you need to do is follow certain tips to ensure that you derive maximum value from the time you spend in your daily standup meetings.</span></p>
<p><span>In this article, we set out to explore what exactly is a daily standup meeting, how it can make a difference to your remote team and what you can do to make it more effective and engaging.&nbsp;</span></p>
<p><span>So, let’s begin.</span></p>
<h2><b>What is a daily standup meeting?</b></h2>
<p><span>In an agile team, a daily standup meeting is where the team gets together every day for a specific time to discuss the daily progress and the plan to be followed.&nbsp;</span></p>
<p><span>As the name suggests, people often do not sit down in this meeting to avoid long discussion, stress on the urgency and keep the meeting straight-to-the-point and time-bound.</span></p>
<p><span>It is supposed to last for 15 minutes and addresses three main questions&nbsp;</span></p>
<ul>
<li><span>What has been achieved?</span></li>
<li><span>What remains to be done?</span></li>
<li><span>Are there any issues that are hampering the completion of a task?&nbsp;</span></li>
</ul>
<h2><b>Why are daily-standup meetings vital in remote work?</b></h2>
<p><span>The purpose of a daily standup meeting is to keep everyone on the same page which becomes even more important when you are managing a remote team.&nbsp;</span></p>
<p><span>In a regular office scenario, team members can walk up to each other to clear doubts and are&nbsp; aware of the real-time updates which cannot happen in a remote work setup.&nbsp;</span></p>
<p><span>Hence, a standup meeting serves as a tool to address issues collectively and improve transparency amongst team members.&nbsp;</span></p>
<p><span>A team with remote employees, however,&nbsp; may have members distributed over different geographical locations.&nbsp;</span></p>
<p><span>The absence of physical proximity makes communication and coordination more complex with remote employees.</span></p>
<p><span>Thus, the role of standup meetings expand and become more essential.</span></p>

<div>
<p><strong>In a remote work environment, standup meetings become a focal point of bringing the whole team together daily and discuss action items, strategies and blockers on a common platform for better synergy. </strong></p>
</div>

<p><span>Mostly, a standup meeting is the only time when the remote employees are present with other team members in the same capacity.</span></p>
<p><span>It keeps them in the loop and more connected.</span></p>
<h2><b>Difference between daily standup and status update meeting</b></h2>
<p><span>Their difference lies in the question they aim to answer.&nbsp;</span></p>
<p><span>In a status update meeting, the main concern is – “</span><b><i>How much work has been completed?”</i></b></p>
<p><span>But, in a daily standup meeting, the core theme is – “</span><b><i>What is your action plan for the day?”</i></b></p>

<div>
<p><strong>A status update meeting focuses on the progress of the deliverables whereas a daily standup meeting aims to improve planning and achieve maximum team collaboration. </strong></p>
</div>


<p><span>A status update meeting helps a manager in knowing what an individual employee has completed up to a point of time.&nbsp;</span></p>
<p><span>A daily standup meeting, on the other hand, concentrates upon how a team can achieve its goals together and the roadblocks the team is focusing on.&nbsp;</span></p>
<p><span>A status update meeting wants to know the results whereas a daily standup meeting aims to understand the future course of action.&nbsp;</span></p>
<h2><b>Benefits of daily standup meetings for remote employees</b></h2>
<p><span>Besides the advantages of flexibility and freedom, remote work also ushers in a set of unique challenges.</span></p>
<p><span>Lack of coordination and miscommunication happen to be some of the problems that remote employees face.</span></p>
<p><span>But, they’re only the tip of the iceberg.</span></p>
<p><span>There’re many intricate issues that a remote employee may face which are completely different from that of a regular office-going employee.</span></p>
<p><span>A daily standup meeting can help a manager streamline a lot of them. Here’s how –&nbsp;</span></p>
<h3><span><span>1 </span></span><b>Helps in building team rapport</b></h3>
<p><b><span>One of the major challenges of remote work is lack of human connection. </span></b></p>
<p><b><span>The lack of personal connection and acquaintance may cause major obstacles and hamper interpersonal coordination.</span></b></p>

<div>
<p><strong>A daily standup meeting allows the entire team to be present at the same time on the same platform even if it’s virtual. </strong></p>
</div>


<p><span>Your remote employees will get a chance to interact with other team members and learn more about them.</span></p>
<h3><span><span>2 </span></span><b>Removes roadblocks</b></h3>
<p><b><span>For a remote employee, their manager is their immediate and often the first&nbsp; point of contact for every issue they may be facing.</span></b></p>
<p>Some of the problems can easily be solved with the help of a fellow team member instead of reaching out to you directly.</p>
<p><span>However, remote employees are not acquainted enough with their teammates and are reluctant to contact them.</span></p>

<div>
<p><strong>A daily standup gives them a chance to get to know the entire team and helps them get familiar with other employees’ personalities and skills. </strong></p>
</div>


<p><span>It also eases their hesitation in approaching others and they may even solve many problems with their team member’s help rather than approaching you for every single issue.</span></p>
<h3><span><span>3 </span></span><b>Encourages knowledge transfer</b></h3>
<p><b><span>Your remote employees work independently and depend upon their knowledge, research and your guidance for learning and execution of their task.&nbsp;</span></b></p>
<p><span>In a shared workspace,&nbsp; team members tend to consult each other and rely on each other’s expertise to get things done.</span></p>
<p><span>There will always be an Alex who’s great at excel or a Tina who can make a presentation look better with a few tweaks.&nbsp;</span></p>
<p><span>A remote employee might not get the opportunity to know either Alex or Tina without a daily standup meeting.</span></p>

<div>
<p><strong>When every employee shares their issues on a common platform, they may be able to find help or suggestions from another team member. </strong></p>
</div>


<p><span>This exchange will encourage the transfer of valuable information and strengthen your team.&nbsp;</span></p>
<h3><span><span>4 </span></span><b>Improved coordination</b></h3>
<p><b><span>A daily standup meeting will ensure that all your direct reports are aware of the progress and the upcoming action plan.&nbsp;</span></b></p>
<p><span>This way everyone is aware of the responsibilities and there’s no scope of miscommunication or confusion.</span></p>
<p><span>Increased transparency and better communication lead to maximum coordination and saving of time.&nbsp;</span></p>
<h3><span><span>5 </span></span><b>Instill a recognition of shared goals</b></h3>
<p><b><span>Often, remote employees become isolated and estranged from the organizational goals.&nbsp;</span></b></p>
<p><span>They know that they’re expected to deliver 5 articles, or deploy the code, or provide 5 designs by the end of the period.&nbsp;</span></p>
<p><span>However, they don’t know how it contributes to the company and how it affects the overall process.</span></p>
<p><span>In a daily standup meeting, they get a complete view of the bigger picture and where they stand in it.&nbsp;</span></p>
<p><span>It instils a sense of belonging and helps them realize where they fit in the puzzle.</span></p>
<p><span>This knowledge of their work’s importance will </span><a href="https://www.peoplebox.ai/blog/how-to-boost-employee-morale-through-one-on-one-meetings/"><span>boost their morale</span></a><span> and will make them feel included.&nbsp;</span></p>
<h2><b>How can daily stand-up meetings help in remote employee engagement?</b></h2>
<p><span>Due to the precautions being taken up after the Coronavirus outbreak, the number of remote employees will rise inevitably.</span></p>
<p><span>A </span><a href="https://www.gartner.com/en/newsroom/press-releases/2020-04-03-gartner-cfo-surey-reveals-74-percent-of-organizations-to-shift-some-employees-to-remote-work-permanently2"><span>research by Gartner</span></a><span> reveals that 74% of CFOs are planning to shift a considerable number of their employees to remote work permanently.</span></p>

<p><img src="https://www.peoplebox.ai/wp-content/uploads/2020/06/Gartner-remote-work.png" alt="daily standup and status update meeting" width="744" height="311" srcset="https://www.peoplebox.ai/wp-content/uploads/2020/06/Gartner-remote-work.png 744w, https://www.peoplebox.ai/wp-content/uploads/2020/06/Gartner-remote-work-300x125.png 300w" sizes="(max-width: 744px) 100vw, 744px" data-srcset="https://www.peoplebox.ai/wp-content/uploads/2020/06/Gartner-remote-work.png 744w, https://www.peoplebox.ai/wp-content/uploads/2020/06/Gartner-remote-work-300x125.png 300w" data-src="https://www.peoplebox.ai/wp-content/uploads/2020/06/Gartner-remote-work.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>

<p><span>While this move opens up new avenues to retain and hire diverse talent, it also poses the challenge of re-imagining the strategies to keep remote employees engaged and well-coordinated.</span></p>
<p><span>In a traditional workplace, daily standup meetings have been playing the role of channelizing better management among the team.&nbsp;</span></p>
<p><span>As a manager, you already know the ropes of conducting these meetings in a way that they are productive, engaging and interesting.&nbsp;</span></p>
<p><span>With the shift in workplace dynamics, you will have to accommodate remote employees and ensure that they are well-represented in the meeting.&nbsp;</span></p>
<p><span>Here’re a few tips that can help you out.&nbsp;</span></p>
<h2><b>Tips for productive &amp; engaging daily standup meetings for remote teams</b></h2>
<h3><span><span>1 </span></span><b>Decide a fixed time</b></h3>
<p><b><span>The reason why we have a standup meeting is to inculcate a routine of accountability, discipline and concrete planning in our team.&nbsp;</span></b></p>
<p><span>And, this is why you must decide upon a fixed time to conduct it every day.</span></p>
<p><span>If you change the time often, it will lead to confusion, delay and late arrival or absence of many employees.&nbsp;</span></p>
<p><span>With fixed time, your entire team will become habitual and will embrace it in their daily routine.&nbsp;</span></p>
<p><span>Ideally, a daily standup meeting should happen either at the beginning or the end of the day.</span></p>

<div>
<p><strong>A standup meeting at the start of the workday helps in planning the day while the one at the end helps in preparing your employees for what to expect the next day. </strong></p>
</div>


<p><span>In case, your remote employees are working from another timezone, you will need to ensure that they’re comfortable with the time.&nbsp;</span></p>
<p><span>Remember, a daily standup meeting will garner positive results only if all your team members are present; including your remote employees.&nbsp;</span></p>
<p><b><img alt="" width="20" height="28" data-src="https://www.peoplebox.ai/wp-content/uploads/2019/12/Untitled.png" src="https://www.peoplebox.ai/wp-content/uploads/2019/12/Untitled.png"> Pro tip: </b><span>Send out a calendar invite which includes a link to the virtual meeting and use the same link daily. </span></p>
<p><span>This will help all your direct reports in finding the meeting link every day without having to contact you or someone else.</span></p>
<h3><span><span>2 </span></span><b>Decide upon tech tools</b></h3>
<p><b><span>Now that your team has remote employees, you are more likely to conduct the daily standup meeting virtually.&nbsp;</span></b></p>
<p><span>Thus, it becomes important to have the right </span><a href="https://www.peoplebox.ai/blog/tools-for-effective-remote-one-on-one-meetings/"><span>tech tool</span></a><span>s for your support.</span></p>
<p><span>For a daily standup meeting, you will require the following kind of tools –</span></p>
<ul>
<li><span>A video conferencing tool like Skype or Google meet</span></li>
<li><span>A task management tool to keep a note of all the action items</span></li>
<li><span>An easy-to-use screen sharing mechanism</span></li>
</ul>
<p>Make sure that everyone agrees on the tools decided upon and have no technical difficulties in accessing them.</p>
<p><span>It’s a good idea to have a trial …</span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.peoplebox.ai/blog/how-to-use-daily-standup-meetings-for-remote-employee-engagement/">https://www.peoplebox.ai/blog/how-to-use-daily-standup-meetings-for-remote-employee-engagement/</a></em></p>]]>
            </description>
            <link>https://www.peoplebox.ai/blog/how-to-use-daily-standup-meetings-for-remote-employee-engagement/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739264</guid>
            <pubDate>Sun, 05 Jul 2020 15:13:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Art of Learning for Software Developers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739249">thread link</a>) | @kiyanwang
<br/>
July 5, 2020 | https://thevaluable.dev/learning-developer-efficiently-effectively/ | <a href="https://web.archive.org/web/*/https://thevaluable.dev/learning-developer-efficiently-effectively/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>
        

        <section>
            
                <picture>
                    
                        <source srcset="https://thevaluable.dev/images/2020/learning_developer/no-mistake.webp" type="image/webp">
                    
                    <img src="https://thevaluable.dev/images/2020/learning_developer/no-mistake.jpg" alt="Learning ">
                </picture>
            

            <p>“I’m trying to go down a bottomless pit. I’ll never make it till the end.”</p>
<p>That’s what I thought when I tried to create my own video game. I was young, beautiful, and I was struggling to use <code>for</code> loops and <code>arrays</code> at the same time.
There was so much to learn!</p>
<p>Fortunately, I found the strength to continue. More and more, the concepts behind programming began to make sense. From there, learning wasn’t a chore anymore, but an intrepid journey. Going through a book about C and trying to create my own adventure on MS-DOS was a crazy Indiana Jone’s-like discovery I’ll never forget.</p>
<p>My first video game wasn’t great, but it was mine. It was <em>my</em> creation. Yet, what I remember today, with a tear in my left eye, is not the result, but the learning process itself. It was these “Aha!” moments which brought me the most joy!</p>
<p>I love learning. For a long, long time. That’s why I tried, through the years, to make my learning gradually more effective and efficient.</p>
<p>Learning is essential for developers. We need to learn about the new breakthroughs, discoveries, and changes in the industry.</p>
<p>We need to learn about our history, to know what’s really new, what’s not, and what to do with it, <em>in what context</em>.</p>
<p>We need to learn about the business domain of the company we’re working with.</p>
<p>We need to learn how to better communicates with our teammates.</p>
<p>We need to learn about what our customers really want.</p>
<p>The list goes on and on.</p>
<p>As you might have guessed, this article will brush over the wide subject of learning, as a developer. We’ll try to answer these questions together:</p>
<ul>
<li>What’s learning?</li>
<li>Why do we learn? Should learning serve a goal?</li>
<li>How to avoid ineffective learning methods, procrastination, and distractions?</li>
<li>Should we have a mentor or learn by ourselves?</li>
<li>Is practice only makes perfect?</li>
<li>How to test ourselves to avoid the illusion of competence?</li>
<li>Are feedback important? What kind of feedback can you get? What feedback should you be interested in?</li>
</ul>
<p>Ready to dive? Good. Take your machete and let’s go together through the Deep Jungle of Knowledge.</p>
<h2 id="whats-learning">What’s learning?</h2>
<p>Sometimes, we can be very surprised of the meaning of common words. Especially if we never question their definitions.</p>
<p>For example, I’m always surprised to hear people saying that learning is only a question of memory. It’s not wrong, but it’s incomplete.</p>
<p>According to the <a href="https://www.lexico.com/definition/learning" target="_blank" rel="noopener">oxford dictionary</a>, learning means:</p>
<blockquote>
<p>The acquisition of knowledge or skills through study, experience, or being taught.</p>
</blockquote>
<p>This gives us clues about how to learn (study, experience, or being taught), but not really about the meaning of “acquisition of knowledge”.</p>
<p>Let’s look at the definition of <a href="https://www.lexico.com/definition/knowledge" target="_blank" rel="noopener">knowledge</a>:</p>
<blockquote>
<p>Facts, information, and skills acquired through experience or education; the theoretical or practical understanding of a subject.</p>
</blockquote>
<p>We can already see, thanks to these definitions, two main foundations for learning:</p>
<ol>
<li>Understanding</li>
<li>Remembering (acquisition)</li>
</ol>
<p>I’ll add a third one:</p>
<ol start="3">
<li>Transfer</li>
</ol>
<p>Transfer is applying the knowledge from the learning context to another context. For example, it could be applying the programming knowledge your learned at school to the side project you always dreamt to build.</p>
<p>Transfer is not a necessity for learning. After all, you can understand and remember something without ever using what you learned.</p>
<p>However, most of the time, we learn in hope to apply the knowledge acquired. That’s why it’s still a major component of our learning experiences.</p>
<h2 id="why-learning">Why Learning?</h2>

<picture>
    <source srcset="https://thevaluable.dev/images/2020/learning_developer/learn-good.webp" type="image/webp">
    <img src="https://thevaluable.dev/images/2020/learning_developer/learn-good.jpg" alt="There is only good in learning">
</picture>



<h3 id="enriching-your-life">Enriching Your Life</h3>
<p>Learning will enrich your life in multiple ways:</p>
<ul>
<li>Your opinions will evolve.</li>
<li>Your vision on the world will change.</li>
<li>You’ll feel strong connections with people who share your interests, creating passionate and mind-binding conversations.</li>
</ul>
<p>Learning can open doors in your professional life:</p>
<ul>
<li>It can help you climbing the corporate ladder.</li>
<li>It can help you to negotiate a better salary. After all, we are <a href="https://en.wikipedia.org/wiki/Knowledge_worker" target="_blank" rel="noopener">knowledge workers</a>: our worth is <em>partly</em> our knowledge.</li>
<li>It will create opportunities for <a href="https://thevaluable.dev/guide-debate-software-developer-skill/">healthy debates with your fellow colleagues</a>.</li>
<li>Your CTO might call you <a href="https://thevaluable.dev/software-developer-titles-junior-senior/">“Rockstar” or “Ninja”</a> too, you lucky pit of knowledge!</li>
</ul>
<h3 id="learning-with-or-without-goals">Learning With or Without Goals?</h3>
<p>When you try to learn something, it’s useful to have concrete goals you want to achieve with the knowledge acquired. These goals could be a good occasion to <em>transfer</em> your knowledge.</p>
<p>For example, you want to learn programming because you always dreamt to create a revolutionary video game, where you can break bricks with a ball. Maybe you want to learn what’s the <a href="https://thevaluable.dev/dry-principle-cost-benefit-example/">DRY principle</a>, to finally refactor your favorite legacy application.</p>
<p>Without meaningful goals, it will be difficult to be motivated in the long run. Learning is not easy. Understanding can be a daunting task (depending of what you learn), remembering even more so, and transfer is maybe the worst of all.</p>
<p>It takes time, too. That’s why being able to reach concrete goals with your new skills and knowledge can be very satisfying. It will give you the needed motivation to continue on your learning path.</p>
<p>It’s even more true when you try to learn complex topics. Your motivation is something you should try to assess and even measure along the way, to see if you need to boost it by making (and finishing) something important to you.</p>
<p>It’s always possible to learn for the sake of learning. Heck, I do it quite a lot myself. Yet, you need to have a good confidence on your motivation, and you need to be aware of the benefits of the learning journey itself.</p>
<p>If you have difficulties to find concrete ideas and goals where you can transfer your new knowledge, I wrote a whole article about techniques <a href="https://thevaluable.dev/generate-programming-side-project-ideas/">to generate project ideas</a>.</p>
<h2 id="how-deep-do-you-want-to-go">How Deep Do You Want to Go?</h2>

<picture>
    <source srcset="https://thevaluable.dev/images/2020/learning_developer/experts.webp" type="image/webp">
    <img src="https://thevaluable.dev/images/2020/learning_developer/experts.jpg" alt="Being an expert is not necessarily your goal">
</picture>



<p>Now that you have your goals, you need to decide <em>how much</em> you want to learn.</p>
<p>After all, you don’t need to be an expert in everything.</p>
<p>Moreover, knowledge acquisition is not like buying a new table for your living room. You need some maintenance not to forget the knowledge and skills acquired.</p>
<p>It means that you need to constantly refresh your knowledge and skills, for everything you want to be an expert at. It takes time, energy, and require, again, a lot of motivation.</p>
<p>For example, let’s say that your life’s dream is to write a PHP script to rename automatically thousands of your holidays pictures. You don’t need to be a PHP evangelist to answer your needs. Trying to understand superficially how PHP works to accomplish what you want might be enough.</p>
<p>Superficial learning works well if you don’t have any goal, too. You can read about programming paradigms for example, by pure curiosity, to have a global overview of all of them. You can still dive deeper if you wish later.</p>
<p>Beyond the superficial, the <a href="https://en.wikipedia.org/wiki/Dreyfus_model_of_skill_acquisition" target="_blank" rel="noopener">Dreyfus model of competence</a> can help you deciding how competent you want to become:</p>
<ul>
<li><strong>Novice</strong> - Shallow understanding, or no understanding at all.</li>
<li><strong>Advanced Beginner</strong> - Can make things works, often rely on following a series of steps.</li>
<li><strong>Competent</strong> - Can spot the roots of problems (background understanding), know all the rules and can select a rule depending of the situation. Still make many mistakes.</li>
<li><strong>Proficient</strong> - Very conscious about performance, know perfectly what approaches to take in what situation.</li>
<li><strong>Expert</strong> - Intuition very well developed, apply his skills without thoughts, performances look magical.</li>
</ul>
<p><a href="https://www.youtube.com/watch?v=i1nzADdV6zk" target="_blank" rel="noopener">Choose your destiny</a>, depending on your needs!</p>
<h2 id="preparing-your-learning-sessions">Preparing Your Learning Sessions</h2>

<picture>
    <source srcset="https://thevaluable.dev/images/2020/learning_developer/learning-not-playing.webp" type="image/webp">
    <img src="https://thevaluable.dev/images/2020/learning_developer/learning-not-playing.jpg" alt="You need to prepare your environment to learn efficiently">
</picture>



<p>Let’s see now how you should prepare yourself before learning anything.</p>
<p>The following advice won’t change your life from one day to another. You need to work on it, actively seeking to apply these advice, day after day. The rewards are, however, huge. I promise.</p>
<h3 id="the-mistakes-to-avoid">The Mistakes to Avoid</h3>
<p>Let’s go back years in your past, when you were young, innocent, and not a caffeine junky yet.</p>
<p>You’re at school. The teacher is speaking about whatever subject he wants you to learn. His tone is monotonous, he doesn’t believe in what he’s saying, you think about what you’ll eat at lunch.</p>
<p>You’re bored.</p>
<p>The seconds feel like minutes. Minutes feel like hours. You can’t do anything, except waiting. Will it ever end? Will you feel joy again? Is it the end of time?</p>
<p>Finally, against all odds, the course end. The teacher ask you to learn a new chapter of your book. He will test you next time.</p>
<p>At home, you read again and again the learning material. You have difficulties to concentrate, but you’re a serious boy (or girl), so you push yourself through. After five reading, you judge yourself good enough to pass the next test.</p>
<p>You close your book, satisfied with yourself, and switch on the TV, because Youtube might not exist yet.</p>
<p>What I just described is the worst way to learn something. <em>Passively</em> listening to somebody, then <em>passively</em> going through some learning materials might teach you something, but very, very slowly. You don’t need to be in a class for that: just switch on Youtube and consume <em>passively</em> any video on programming.</p>
<p>When you close your book after your passive learning, you think you learned something. Yet, when you’ll pass your test, you’ll understand that you really didn’t.</p>
<p>This is called <strong>illusion of competence</strong>: we have often the <em>impression</em> we learned something, even if we didn’t.</p>
<p>You should spend most of your time <em>actively learning</em>. You need to be an actor in your own learning, not only consuming it like you would consume Netflix.</p>
<p>I would compare active learning as playing a video game. Yes, I was a video game junky.</p>
<p>When you play, you’re actively doing something. Consequently, I’m sure you can remember many more video games than what you read in your last books.</p>
<p>This is due to two things:</p>
<ol>
<li>Video games are fun. You can make your learning experience fun, too. More you’ll learn what you love, more you’ll like the process of learning.</li>
<li>Playing is an active endeavor, not a passive one.</li>
</ol>
<p>That being said, before actively learning, you need first …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thevaluable.dev/learning-developer-efficiently-effectively/">https://thevaluable.dev/learning-developer-efficiently-effectively/</a></em></p>]]>
            </description>
            <link>https://thevaluable.dev/learning-developer-efficiently-effectively/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739249</guid>
            <pubDate>Sun, 05 Jul 2020 15:11:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Must Know 7 Traps That Make Your Software Useless]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739023">thread link</a>) | @yassinerajallah
<br/>
July 5, 2020 | https://devhypercharged.com/the-7-traps-that-make-your-software-unusable/ | <a href="https://web.archive.org/web/*/https://devhypercharged.com/the-7-traps-that-make-your-software-unusable/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			
			
<p><span>One of the unspoken areas about software development is building usable software. Learning how to code, coding something, and having it used by thousands is no easy task. In this article, I’ll be discussing the most important pillars that you need to address before launching your product.&nbsp;</span></p>

<p><span>My first app ever made was a social media, if you exceed 100 comments/post the app becomes crazy slow, the database over fetches, authentication was broken, and the whole world was burning down. Not a great spot to be in, but this goes without saying that paying close attention to some little details will save you months of technical debt and headache.&nbsp;</span></p>

<p><span>Note: Each point can be open for debate, this is what will get you started, the more you learn, the more reliable your app becomes.</span></p>

<p><span>Think of this as a checklist for your next product:</span></p>

<h2><span><strong>1- Code Safety</strong></span></h2>

<p><span>While coding (or when finished) the app, you want to make sure that the environment is safe, no user data is leaking, and the app is reliable and ready to scale for any spikes of usage.&nbsp;</span></p>

<ul>
<li><span>Avoid unwrapping values the unsafe way (aka check if the value is nil) then execute your logic. Surprisingly, this isn’t talked about that much and as a fresh software developer, you never know what will crash your app. You should never be 100% sure that a value won’t be nil, weird stuff happens.&nbsp;</span></li>
<li><span>Avoid retain cycles: While these are caused unintentionally and not easy to detect, you will need to run a check for your app to detect if memory is retained for some unused objects. Each IDE has tools to help you check for retain cycles and you need to make use of them. Xcode for example has a tab where you can detect memory spikes, deallocations, and CPU usage. There are many ways to detect if something is wrong with your app, hardware-wise, make sure to search on the net depending on your platform.&nbsp;</span></li>
</ul>

<figure><span><a href="https://cdn.substack.com/image/fetch/c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6b161812-de63-476e-b3c7-011b91f60f1f_606x619.png" target="_blank" rel="noreferrer noopener"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6b161812-de63-476e-b3c7-011b91f60f1f_606x619.png" alt="" data-src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6b161812-de63-476e-b3c7-011b91f60f1f_606x619.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></a></span></figure>

<ul>
<li><span>Protect your secret keys! More often than not, you’ll find yourself using 3rd party services. These services provide a “secret key” and a “test key” to get access to their API. In production you use the “secret key” and it’s secret for a reason. If leaked, another person will use it and you’ll pay the bill 🙂 not so fun. Even worse, this might leak your users’ data or even shut down the servers. That’s why it’s important to make use of “environment variables”. As the name applies, these are variables that live in the local machine. Say when a script wants to have access to that secret key, it can get it from the local machine. This way, you aren’t hardcoding anything into the script and at the same time keeping your code clean and secure.</span></li>
<li><span>Passwords: Now this is an underrated problem that isn’t talked about and can bring down a whole corporation. In some cases, when you aren’t using reliable 3rd party services for authentication such as AWS &amp; Firebase, you need to be hashing the passwords yourself. Personally, I always keep the hashing function as part of the API in a separate file. I include a random environment variable that I can keep track of which dictates how the password will be generated for a specific user depending on the information provided. And we are set! I don’t need to know my users’ password, I trigger the “sign-in” by triggering the same hashing function using the environment variable I stored before and everything is secure.</span></li>
<li><span>Don’t keep “Logs” (similar to print) when building for production! This is a great way to shoot yourself in the leg, keeping logging functions extends to the build and if you are logging sensitive information you’ll get in trouble. Just stick with classic print() statements; these are safe for usage in production and aren’t logged (from an iOS point of view)</span></li>
</ul>

<h2><span><strong>2-</strong> <strong>Help your project help you</strong></span></h2>

<p><span>After building a couple of apps in different areas with moderate difficulty, you’ll wish you’ve done many things differently, note these down and use them in your next project! My projects went from utter spaghetti mess to a clean hierarchy.&nbsp;</span></p>

<ul>
<li><span>In my case, I found it hard to keep track of the placement of my files in Xcode, so for each screen, I had a folder. The folder contains front-end logic, backend-logic, and unique utilities. As for general utilities, I’d keep them in a global folder to refer to them from every other file.</span></li>
<li><span>Think of factorizing the most. When coding, you want to have a file work as a global factor for other scripts that use the same functionality.</span></li>
<li><span>At some point, you’ll realize you are dealing with many folders, and your project is huge, but this is a thousand times better than having everything crammed into one folder and you waste 30seconds to just find a file</span></li>
</ul>

<p><span>You don’t need to follow my pattern. Find yours and keep experimenting.&nbsp;</span></p>

<h2><span><strong>3-</strong> <strong>Your servers will make you pay for what you don’t know (Literally)&nbsp;</strong></span></h2>

<p><span>Sometimes it’s tempting to use 3rd party services since they can make life easier. I’m all down for using these services and in fact, I use them a lot. However, you need to know the inside outs of their billing policies and know what you are billed for.&nbsp;</span></p>

<p><span>Rule of thumb:&nbsp;</span></p>

<ul>
<li><span>Add a service&nbsp;<strong>only when&nbsp;</strong>it can save you costs and/or enhance your UX. Yes, I just said you need to add a service that will save you money. For example; AWS has a free-tier usage per service. So instead of putting the pressure on just 1 service, you can make use of multiple, you take the roundabout but you end up saving costs early on.&nbsp;</span></li>
<li><span>Algorithmically speaking, you can save Database costs on your client-side. The intuitive way is by making fewer calls, caching user information, and preloading data for future usage. This obviously adds more work client-side, but it’s getting easier to integrate offline capabilities than ever.&nbsp;&nbsp;</span></li>
</ul>

<blockquote>
<p><span>Note:&nbsp; by experience, I noticed the more you save money client-side, the better is your UX, and the higher the performance gets. I’m aware this is a bold point to make so I’ll leave diving into it for another episode.</span></p>
</blockquote>

<ul>
<li><span>Scalability wise, make sure to keep your code usable for huge traffic spikes, these are basic algorithm analysis techniques and they are often shorter to code. For example: Use built-in sort functions, don’t’ iterate every time on a list of 100 items and above, cache your results, make use of dynamic programming (in short the previous result helps with the next result; read more on this&nbsp;<a href="https://medium.com/free-code-camp/demystifying-dynamic-programming-3efafb8d4296">here</a>)&nbsp;</span></li>
</ul>

<h2><span><strong>4- Just when you think you’re done…. Layout Issues</strong></span></h2>

<p><span>By now, you might think you’re done, but there is a bit more to the story. You’re very close though cheer up!&nbsp;</span></p>

<p><span>Often when building your projects, checking tutorials, StackOverflow, etc… you find hardcoded pixel values, typically: (width: 100, height: 100) or similar. These hardcoded are made for simplicity’s sake. No, your app won’t scale because each device has different # of pixels, etc.. That’s why:</span></p>

<ul>
<li><span>When coding, avoid using hardcoded values and make use of a percentage. You can have 2 static variables in a separate class from which you get the height and width of the current screen. This way while coding my layout I have fast access and scalable way of presenting my layout.&nbsp;</span>
<ul>
<li><span>Typically, you ‘ll be calling the class as : SomeClass.screenWidth * 0.5, this means “make my button’s width half of the super view’s width”</span></li>
<li><span>Same applies for the height</span></li>
</ul>
</li>
<li><span>Test on different physical devices, simulators aren’t that bad but sometimes screw up layout-wise, they also have more performance since they run on your computer. Sometimes when a layout or animation looks smooth, you might want to test it on a&nbsp; physical device and double-check for yourself.</span></li>
</ul>

<p><span>Don’t stress over the layout too much, have a fair looking one, make use of 3rd party packages/plugins/libraries for animation, there are many free services that help make your app look neat for the least effort possible. Remember, we are all about 20% investment 80% return in this newsletter 🙂</span></p>

<h2><span><strong>5-</strong> <strong>Client Error Handling: You can get away with this, but don’t overlook it</strong></span></h2>

<p><span>Error handling is fun, right? Or you might think you don’t need it so you just use a standard popup to show any “Error, try again later” message. DON’T. Bad coding, bad bad bad. Every app will crash/fail at some point, you want to provide a targetted message to what happened. While you can’t know every reason for failure, you know the error code. To get my projects up and running, I embed the error code with a standard failure popup, this way, when a user reports the problem during beta/production, I check the logs for the code. Fast and easy debugging!</span></p>

<p><span>At a later stage, you want to remove the codes and move to “natural language explanation”. You’ll start working on this when the time comes for enhancing your UX further.</span></p>

<h2><span><strong>6-</strong> <strong>Cross Services Error Handling</strong></span></h2>

<p><span>Same as in the previous case, but one important matter to take into consideration, if you are dealing with a financial backend (aka Stripe, etc..) you want to have your webhooks (API that receives transaction calls from Stripe, Paypal, etc… and here you update your database) react the right way. Error handling here is critical because you don’t want to flag a user as non-paying because they had their payment attempt succeed but you failed to call the database and make the necessary updates.</span></p>

<h2><span><strong>7-</strong> <strong>Test Cases: You can get away with this too</strong></span></h2>

<p><span>Writing test cases is indispensable for reliable software, especially when scaling and adding more features as a team. You never know who coded what and how that reacted with a piece of code you’ve written. If you are a solo developer and about to ship a basic product, you might get away with skipping this step but you need to keep in mind you’ll have to write test cases to avoid basic bugs in the future.</span></p>

<p><span>Well, this was a lengthy one. I hope you found this article helpful; sorry I had to make it this long but the process had to be detailed and practical. Consider sharing with your friends and anyone who might find this article helpful; and if you aren’t subscribed, consider doing so!&nbsp;</span></p>

<p><span>Until the next time, take care, byeeeeeee 🙂</span></p>

			
			
</div></div>]]>
            </description>
            <link>https://devhypercharged.com/the-7-traps-that-make-your-software-unusable/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739023</guid>
            <pubDate>Sun, 05 Jul 2020 14:41:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Free Productivity Templates – by experienced project delivery manager]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738963">thread link</a>) | @sssmith12
<br/>
July 5, 2020 | https://slidegame.io/templates/productivity | <a href="https://web.archive.org/web/*/https://slidegame.io/templates/productivity">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-page-sections="5f0081cc65a3745ddd2e2989" id="sections">
  
    <section data-section-id="5f0081cc65a3745ddd2e298b" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
  &quot;imageOverlayOpacity&quot; : 0.15,
  &quot;video&quot; : {
    &quot;playbackSpeed&quot; : 0.5,
    &quot;filter&quot; : 1,
    &quot;filterStrength&quot; : 0,
    &quot;zoom&quot; : 0
  },
  &quot;backgroundWidth&quot; : &quot;background-width--full-bleed&quot;,
  &quot;sectionHeight&quot; : &quot;section-height--medium&quot;,
  &quot;horizontalAlignment&quot; : &quot;horizontal-alignment--center&quot;,
  &quot;verticalAlignment&quot; : &quot;vertical-alignment--middle&quot;,
  &quot;contentWidth&quot; : &quot;content-width--wide&quot;,
  &quot;sectionTheme&quot; : &quot;&quot;,
  &quot;sectionAnimation&quot; : &quot;none&quot;,
  &quot;backgroundMode&quot; : &quot;image&quot;
}" data-animation="none">
  
  <div>
    <div>
      
      
      <div data-content-field="main-content" data-item-id="">
  <article id="article-">
  
    <div>
      <div>
        
        <div>
          
            <div data-content-field="categories">
              <p><span><a href="https://slidegame.io/templates?category=Productivity">Productivity</a></span>
            </p></div>
          

          <div data-animation-role="date">
            <p><time datetime="Jul 4" pubdate="" data-content-field="published-on">
              <span>Jul 4</span>
            </time></p><div data-content-field="author"><p>Written By <a href="https://slidegame.io/templates?author=5ee5fe816458d8282c591aa9">Undercover Consultant</a></p></div>
          </div>
        </div>
      </div>

      <div>
        <div><div data-layout-label="Post Body" data-type="item" id="item-5f00cb5c894f6b087dccdc0d"><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1593954613854_4362"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ee5ffd0884b542830fe6f69/1593954668728-VCGSX8PK4KLKR54ARKMB/ke17ZwdGBToddI8pDm48kPTrHXgsMrSIMwe6YW3w1AZ7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0k5fwC0WRNFJBIXiBeNI5fKTrY37saURwPBw8fO2esROAxn-RKSrlQamlL27g22X2A/image-asset.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5ee5ffd0884b542830fe6f69/1593954668728-VCGSX8PK4KLKR54ARKMB/ke17ZwdGBToddI8pDm48kPTrHXgsMrSIMwe6YW3w1AZ7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0k5fwC0WRNFJBIXiBeNI5fKTrY37saURwPBw8fO2esROAxn-RKSrlQamlL27g22X2A/image-asset.jpeg" data-image-dimensions="2500x1406" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5f01d16b6e62565b9d37f148" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5ee5ffd0884b542830fe6f69/1593954668728-VCGSX8PK4KLKR54ARKMB/ke17ZwdGBToddI8pDm48kPTrHXgsMrSIMwe6YW3w1AZ7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0k5fwC0WRNFJBIXiBeNI5fKTrY37saURwPBw8fO2esROAxn-RKSrlQamlL27g22X2A/image-asset.jpeg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-json="{&quot;hSize&quot;:null,&quot;floatDir&quot;:null,&quot;collectionId&quot;:&quot;5ef789ceaa257013942e5695&quot;,&quot;design&quot;:&quot;list&quot;,&quot;headerText&quot;:&quot;Featured&quot;,&quot;textSize&quot;:&quot;large&quot;,&quot;pageSize&quot;:10,&quot;imageAspectRatio&quot;:&quot;Auto&quot;,&quot;columnWidth&quot;:304,&quot;gutter&quot;:66,&quot;listImageSize&quot;:49,&quot;listImageAlignment&quot;:&quot;left&quot;,&quot;slidesPerRow&quot;:3,&quot;textAlignment&quot;:&quot;left&quot;,&quot;showTitle&quot;:true,&quot;showThumbnail&quot;:true,&quot;showExcerpt&quot;:true,&quot;showReadMoreLink&quot;:false,&quot;showPrice&quot;:true,&quot;productQuickViewEnabled&quot;:false,&quot;showPastOrUpcomingEvents&quot;:&quot;upcoming&quot;,&quot;metadataPosition&quot;:&quot;below-content&quot;,&quot;primaryMetadata&quot;:&quot;cats&quot;,&quot;secondaryMetadata&quot;:&quot;date&quot;,&quot;filter&quot;:{&quot;categoryIds&quot;:null,&quot;category&quot;:&quot;Productivity&quot;},&quot;autoCrop&quot;:true,&quot;lightbox&quot;:false,&quot;mixedContent&quot;:true,&quot;blockId&quot;:&quot;d0a4e93a683c2a59e72f&quot;}" data-block-type="55" id="block-yui_3_17_2_1_1593887581579_3803"><div>



<div>

  <div>

    <header>

      <!-- Collection Title -->
      <p><span>Featured</span>
        
      </p>

      <!-- Carousel Nav -->
      

    </header>

    <div>

      

        <div>

          
            <!-- Thumbnail -->
            

  
  <div>
    <a href="https://docs.google.com/spreadsheets/d/1SI4MpmbPEfAHyu9rq6d4zkIKk4Rz3rGWwDJIqG3B84Y/edit?usp=sharing" data-title="Weekly Productivity Planner" data-description="">
      <p><img data-src="https://static1.squarespace.com/static/5ee5ffd0884b542830fe6f69/5ef789ceaa257013942e5695/5f007d88d100920c14698bec/1593956094870/Weekly+Planner.png" data-image="https://static1.squarespace.com/static/5ee5ffd0884b542830fe6f69/5ef789ceaa257013942e5695/5f007d88d100920c14698bec/1593956094870/Weekly+Planner.png" data-image-dimensions="2500x1438" data-image-focal-point="0.5,0.5" alt="Weekly Productivity Planner" data-load="false" src="https://static1.squarespace.com/static/5ee5ffd0884b542830fe6f69/5ef789ceaa257013942e5695/5f007d88d100920c14698bec/1593956094870/Weekly+Planner.png">

    

    

        

        

      </p>
    </a>

    <!-- Products: Quick View -->
    

  </div>
  



          

          <div data-animation-role="content">

            <!-- Metadata (Above Title) -->
            <div>
              
              <div>

	





	<!-- Categories -->
	<p><span><a href="https://slidegame.io/individual-templates?category=Productivity">Productivity</a></span>








</p></div>
              
              <p><time datetime="2020-07-04">Jul 4, 2020</time>
	











</p>
            </div>

            
              <!-- Title -->
              <div>
                <p><a href="https://docs.google.com/spreadsheets/d/1SI4MpmbPEfAHyu9rq6d4zkIKk4Rz3rGWwDJIqG3B84Y/edit?usp=sharing">Weekly Productivity Planner</a></p></div>
            

            <!-- Metadata (Below Title) -->
            <div>
            
              <div>

	





	<!-- Categories -->
	<p><span><a href="https://slidegame.io/individual-templates?category=Productivity">Productivity</a></span>








</p></div>
              
              <p><time datetime="2020-07-04">Jul 4, 2020</time>
	











</p>
            </div>

            
              
            

            
              
              <!-- Excerpt -->
                <p>Complete productivity planning system inspired by <a href="https://twitter.com/jackbutcher" target="">@JackButcher</a>’s Daily Manifest</p>
              

              

              
            

            <!-- Metadata (Below Content) -->
            <div>
              
              <div>

	





	<!-- Categories -->
	<p><span><a href="https://slidegame.io/individual-templates?category=Productivity">Productivity</a></span>








</p></div>
              
              <p><time datetime="2020-07-04">Jul 4, 2020</time>
	











</p>
            </div>

          </div> <!-- End .summary-content -->

        </div> <!-- End .summary-item -->

      

        <div>

          
            <!-- Thumbnail -->
            

  
  <div>
    <a href="https://docs.google.com/spreadsheets/d/1AvuJ3o45X4aNbGKx01t1vFYOU9qh6H3825P5G0vdPg8/edit?usp=sharing" data-title="To Do Dashboard" data-description="">
      <p><img data-src="https://static1.squarespace.com/static/5ee5ffd0884b542830fe6f69/5ef789ceaa257013942e5695/5f007ce9c56ace3ec38705a6/1593953987776/To+Do+Dashboard.png" data-image="https://static1.squarespace.com/static/5ee5ffd0884b542830fe6f69/5ef789ceaa257013942e5695/5f007ce9c56ace3ec38705a6/1593953987776/To+Do+Dashboard.png" data-image-dimensions="2500x1438" data-image-focal-point="0.5,0.5" alt="To Do Dashboard" data-load="false" src="https://static1.squarespace.com/static/5ee5ffd0884b542830fe6f69/5ef789ceaa257013942e5695/5f007ce9c56ace3ec38705a6/1593953987776/To+Do+Dashboard.png">

    

    

        

        

      </p>
    </a>

    <!-- Products: Quick View -->
    

  </div>
  



          

          <div data-animation-role="content">

            <!-- Metadata (Above Title) -->
            <div>
              
              <div>

	





	<!-- Categories -->
	<p><span><a href="https://slidegame.io/individual-templates?category=Productivity">Productivity</a></span>








</p></div>
              
              <p><time datetime="2020-07-04">Jul 4, 2020</time>
	











</p>
            </div>

            
              <!-- Title -->
              <div>
                <p><a href="https://docs.google.com/spreadsheets/d/1AvuJ3o45X4aNbGKx01t1vFYOU9qh6H3825P5G0vdPg8/edit?usp=sharing">To Do Dashboard</a></p></div>
            

            <!-- Metadata (Below Title) -->
            <div>
            
              <div>

	





	<!-- Categories -->
	<p><span><a href="https://slidegame.io/individual-templates?category=Productivity">Productivity</a></span>








</p></div>
              
              <p><time datetime="2020-07-04">Jul 4, 2020</time>
	











</p>
            </div>

            
              
            

            
              
              <!-- Excerpt -->
                <p>Prioritise your to-do list with this template based on Eisenhower’s Matrix</p>
              

              

              
            

            <!-- Metadata (Below Content) -->
            <div>
              
              <div>

	





	<!-- Categories -->
	<p><span><a href="https://slidegame.io/individual-templates?category=Productivity">Productivity</a></span>








</p></div>
              
              <p><time datetime="2020-07-04">Jul 4, 2020</time>
	











</p>
            </div>

          </div> <!-- End .summary-content -->

        </div> <!-- End .summary-item -->

      

        <div>

          
            <!-- Thumbnail -->
            

  
  <div>
    <a href="https://docs.google.com/spreadsheets/d/1mvsCTgGzEu5HSGQrXOh53zaYPFIa9u5bq07JOMb006M/edit?usp=sharing" data-title="To-Do Kanban" data-description="">
      <p><img data-src="https://static1.squarespace.com/static/5ee5ffd0884b542830fe6f69/5ef789ceaa257013942e5695/5f00747bc56ace3ec38665cc/1593954088045/To+Do+Kanban.png" data-image="https://static1.squarespace.com/static/5ee5ffd0884b542830fe6f69/5ef789ceaa257013942e5695/5f00747bc56ace3ec38665cc/1593954088045/To+Do+Kanban.png" data-image-dimensions="2500x1438" data-image-focal-point="0.5,0.5" alt="To-Do Kanban" data-load="false" src="https://static1.squarespace.com/static/5ee5ffd0884b542830fe6f69/5ef789ceaa257013942e5695/5f00747bc56ace3ec38665cc/1593954088045/To+Do+Kanban.png">

    

    

        

        

      </p>
    </a>

    <!-- Products: Quick View -->
    

  </div>
  



          

          <div data-animation-role="content">

            <!-- Metadata (Above Title) -->
            <div>
              
              <div>

	





	<!-- Categories -->
	<p><span><a href="https://slidegame.io/individual-templates?category=Productivity">Productivity</a></span>








</p></div>
              
              <p><time datetime="2020-07-04">Jul 4, 2020</time>
	











</p>
            </div>

            
              <!-- Title -->
              <div>
                <p><a href="https://docs.google.com/spreadsheets/d/1mvsCTgGzEu5HSGQrXOh53zaYPFIa9u5bq07JOMb006M/edit?usp=sharing">To-Do Kanban</a></p></div>
            

            <!-- Metadata (Below Title) -->
            <div>
            
              <div>

	





	<!-- Categories -->
	<p><span><a href="https://slidegame.io/individual-templates?category=Productivity">Productivity</a></span>








</p></div>
              
              <p><time datetime="2020-07-04">Jul 4, 2020</time>
	











</p>
            </div>

            
              
            

            
              
              <!-- Excerpt -->
                <p>Keep on top of your progress with this simple Kanban template</p>
              

              

              
            

            <!-- Metadata (Below Content) -->
            <div>
              
              <div>

	





	<!-- Categories -->
	<p><span><a href="https://slidegame.io/individual-templates?category=Productivity">Productivity</a></span>








</p></div>
              
              <p><time datetime="2020-07-04">Jul 4, 2020</time>
	











</p>
            </div>

          </div> <!-- End .summary-content -->

        </div> <!-- End .summary-item -->

      

    </div> <!-- End .summary-item-list -->

  </div> <!-- End .summary-item-list-container -->

</div>
</div></div><div data-block-type="51" id="block-yui_3_17_2_1_1593954713804_5334"><div>


<div>
  <form data-form-id="5f01d2a438f0572cba9a6a03" autocomplete="on" method="POST" onsubmit="return (function (form) {
    Y.use('squarespace-form-submit', 'node', function usingFormSubmit(Y) {
      (new Y.Squarespace.FormSubmit(form)).submit({
        formId: '5f01d2a438f0572cba9a6a03',
        collectionId: '5f0081cc65a3745ddd2e2980',
        objectName: 'item-5f00cb5c894f6b087dccdc0d'
      });
    });
    return false;
  })(this);">
    <header>
      <h2>Never miss a template:</h2>
      <p>New templates sent to your inbox every week</p>
    </header>
    <div>
      <div>
        
        
          
            <p><label for="email-yui_3_17_2_1_1593954713804_5339-field">Email Address</label>
              
            </p>
          
        
          
        
      </div>
      
      
        
        
      
    </div>
    <div><p><strong>Please note: </strong>By submitting you email address you hereby accept and consent to our <a href="https://slidegame.io/terms-of-use">Terms of Use Policy</a>, <a href="https://slidegame.io/privacy-policy">Privacy Policy</a> and <a href="https://slidegame.io/acceptable-use-policy">Acceptable Use Policy</a></p></div>
    <p>Thank you!</p>
    
  </form>
</div>
</div></div></div></div></div></div>

        

        
        
          <div data-content-field="author">
            <p><a href="https://slidegame.io/templates?author=5ee5fe816458d8282c591aa9">
  
    <span data-tweaks="tweak-show-blog-item-author-profile">
      <img data-controller="AuthorProfileImageLoader" data-src="https://static1.squarespace.com/static/images/5ee5fe8198b8c739edac6a9d" data-image="https://static1.squarespace.com/static/images/5ee5fe8198b8c739edac6a9d" data-load="false" alt="">
    </span>
  
  <span>Undercover Consultant</span>
</a>



          </p></div>
        
      </div>

      <section>
        <div>
          
        </div>
      </section>
    </div>
  
</article>

</div>
    </div>
  </div>
</section>

  
</article></div>]]>
            </description>
            <link>https://slidegame.io/templates/productivity</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738963</guid>
            <pubDate>Sun, 05 Jul 2020 14:34:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: “Watch” any subreddit. Fetches videos from any subreddit]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738962">thread link</a>) | @paashabhai
<br/>
July 5, 2020 | https://arbazsiddiqui.github.io/rSlashVideos/ | <a href="https://web.archive.org/web/*/https://arbazsiddiqui.github.io/rSlashVideos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://arbazsiddiqui.github.io/rSlashVideos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738962</guid>
            <pubDate>Sun, 05 Jul 2020 14:34:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Prepare Emacs to Code in Rust]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738932">thread link</a>) | @frag
<br/>
July 5, 2020 | https://codingossip.github.io/2020/prepare-emacs-to-code-in-rust/ | <a href="https://web.archive.org/web/*/https://codingossip.github.io/2020/prepare-emacs-to-code-in-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>  <article itemscope="" itemtype="http://schema.org/BlogPosting">  <div itemprop="articleBody"> <p>Configuring Emacs as an IDE is not really a piece of cake, especially when “good” is not enough. When it comes to programming in Rust I personally enjoy IDEs like Visual Studio Code (the debugging scripts are really powerful). However the versatility of Emacs is unbeatable, especially in those situations in which one doesn’t really want to use different applications and wants to build a camp in one of them and stay there forever :) Since I am one of those people, I put together a configuration that would definitely make my life easier when I code in Rust or simply edit some text.</p> <p>Feel free to copy and share the <code>init.el</code> below (this goes under <code>~/.emacs.d/</code>)</p> <div><div><pre><code>(require 'package)
(add-to-list 'package-archives
         '("melpa" . "http://melpa.org/packages/") t)

(package-initialize)

;; yup this is for a f'ing copy&amp;paste
(setq x-select-enable-clipboard t)

(when (not package-archive-contents)
    (package-refresh-contents))

(unless (package-installed-p 'use-package)
  (package-install 'use-package))

(require 'use-package)

;; Rust stuff
(require 'rust-mode)
(add-hook 'rust-mode-hook
          (lambda () (setq indent-tabs-mode nil)))
(setq rust-format-on-save t)
(define-key rust-mode-map (kbd "C-c C-c") 'rust-run)
(add-hook 'rust-mode-hook 'cargo-minor-mode)

(add-hook 'rust-mode-hook
          (lambda ()
            (local-set-key (kbd "C-c &lt;tab&gt;") #'rust-format-buffer)))

(require 'company)
(require 'racer)
(require 'rust-mode)
(require 'electric)
(require 'eldoc)
(require 'flycheck)
(require 'flycheck-rust)

(add-to-list 'auto-mode-alist '("\\.rs\\'" . rust-mode))
(add-hook 'rust-mode-hook  #'company-mode)
(add-hook 'rust-mode-hook  #'racer-mode)
(add-hook 'racer-mode-hook #'company-mode)
(add-hook 'racer-mode-hook #'eldoc-mode)
(add-hook 'flycheck-mode-hook #'flycheck-rust-setup)

(define-key rust-mode-map (kbd "TAB") #'company-indent-or-complete-common)
(setq company-tooltip-align-annotations t)

;;(add-hook 'rust-mode-hook
;;          '(lambda ()
;;             (setq racer-cmd (concat (getenv "HOME") "/.cargo/bin/racer"))
;;             (setq racer-rust-src-path (concat (getenv "HOME") "/.rust-dev/rust/src"))
;;             (local-set-key (kbd "TAB") #'company-indent-or-complete-common)
;;             (electric-pair-mode 1)))
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;



(setq use-package-always-ensure t)

(add-to-list 'load-path "~/.emacs.d/custom")

(require 'setup-general)

(if (version&lt; emacs-version "24.4")
    (require 'setup-ivy-counsel)
  (require 'setup-helm)
  (require 'setup-helm-gtags))
;; (require 'setup-ggtags)
(require 'setup-cedet)
(require 'setup-editing)

;; (require-package 'atom-one-dark-theme)
;; (require-package 'golden-ratio)
;; (require 'golden-ratio)


;; function-args
;; (require 'function-args)
;; (fa-config-default)
;; (define-key c-mode-map  [(tab)] 'company-complete)
;; (define-key c++-mode-map  [(tab)] 'company-complete)
(custom-set-variables
 ;; custom-set-variables was added by Custom.
 ;; If you edit it by hand, you could mess it up, so be careful.
 ;; Your init file should contain only one such instance.
 ;; If there is more than one, they won't work right.
 '(package-selected-packages
   (quote
    (vscode-icon dired-explorer dired-sidebar racer projectile-codesearch smex flycheck-rust cargo rust-mode zygospore helm-gtags helm yasnippet ws-butler volatile-highlights use-package undo-tree iedit dtrt-indent counsel-projectile company clean-aindent-mode anzu))))
(custom-set-faces
 ;; custom-set-faces was added by Custom.
 ;; If you edit it by hand, you could mess it up, so be careful.
 ;; Your init file should contain only one such instance.
 ;; If there is more than one, they won't work right.
 )


;; UI stuff
;; Set initial frame size and position
(defun my/set-initial-frame ()
  (let* ((base-factor 0.70)
         (a-width (* (display-pixel-width) base-factor))
         (a-height (* (display-pixel-height) base-factor))
         (a-left (truncate (/ (- (display-pixel-width) a-width) 2)))
         (a-top (truncate (/ (- (display-pixel-height) a-height) 2))))
    (set-frame-position (selected-frame) a-left a-top)
    (set-frame-size (selected-frame) (truncate a-width)  (truncate a-height) t)))
(setq frame-resize-pixelwise t)
(my/set-initial-frame)

;; (load-theme 'atom-one-dark t)
(blink-cursor-mode 0)
(setq-default cursor-type 'bar)
(set-cursor-color "#cccccc")
(setq ring-bell-function 'ignore)
(golden-ratio-mode 1)

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;; Editing stuff
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(require 'saveplace)
;; (require-package 'rainbow-mode)
(require 'flycheck)

;; Highlights matching parenthesis
(show-paren-mode 1)

;; Highlight current line
(global-hl-line-mode 1)

;; Interactive search key bindings. By default, C-s runs
;; isearch-forward, so this swaps the bindings.
(global-set-key (kbd "C-s") 'isearch-forward-regexp)
(global-set-key (kbd "C-r") 'isearch-backward-regexp)
(global-set-key (kbd "C-M-s") 'isearch-forward)
(global-set-key (kbd "C-M-r") 'isearch-backward)
(define-key global-map (kbd "RET") 'newline-and-indent)

(add-hook 'after-init-hook #'global-flycheck-mode)

;; When you visit a file, point goes to the last place where it
;; was when you previously visited the same file.
;; http://www.emacswiki.org/emacs/SavePlace

(setq-default save-place t)
;; keep track of saved places in ~/.emacs.d/places
(setq save-place-file (concat user-emacs-directory "places"))

;; Emacs can automatically create backup files. This tells Emacs to
;; put all backups in ~/.emacs.d/backups. More info:
;; http://www.gnu.org/software/emacs/manual/html_node/elisp/Backup-Files.html
(setq backup-directory-alist `(("." . ,(concat user-emacs-directory
                                               "backups"))))
(setq auto-save-default nil)

(defun toggle-comment-on-line ()
  "Comment or uncomment current line."
  (interactive)
  (comment-or-uncomment-region (line-beginning-position) (line-end-position)))
(global-set-key (kbd "C-;") 'toggle-comment-on-line)

;; (add-hook 'prog-mode-hook #'rainbow-delimiters-mode)


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;; Navigation
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(require 'ido)
(require 'recentf)
;; (require-package 'ido-ubiquitous)
;; (require-package 'smex)
;; (require-package 'projectile)

(setq recentf-save-file (concat user-emacs-directory ".recentf"))
(recentf-mode 1)
(setq recentf-max-menu-items 40)

;; (ido-mode t)
;; (setq ido-enable-flex-matching t)
;; (setq ido-use-filename-at-point nil)
;; (setq ido-auto-merge-work-directories-length -1)
;; (setq ido-use-virtual-buffers t)

;; (ido-ubiquitous-mode 1)

;; Shows a list of buffers
(global-set-key (kbd "C-x C-b") 'ibuffer)


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;; Sidebar stuff
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(use-package vscode-icon)

(use-package dired-sidebar
  :ensure t
  :demand t
  :custom
  (dired-sidebar-theme 'vscode)
  :commands (dired-sidebar-toggle-sidebar))

(add-to-list 'load-path "/home/frag/.emacs.d/dired-sidebar")
(require 'dired-sidebar)
(dired-sidebar-toggle-sidebar)

(setq dired-sidebar-subtree-line-prefix "__")
(setq dired-sidebar-theme 'vscode)
(setq dired-sidebar-use-term-integration t)
(setq dired-sidebar-use-custom-font t)
</code></pre></div></div> </div> </article>  </div></div>]]>
            </description>
            <link>https://codingossip.github.io/2020/prepare-emacs-to-code-in-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738932</guid>
            <pubDate>Sun, 05 Jul 2020 14:29:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DNS Resolution and Records for Developers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23738908">thread link</a>) | @paashabhai
<br/>
July 5, 2020 | https://www.arbazsiddiqui.me/dns-resolution-and-records-for-developers/ | <a href="https://web.archive.org/web/*/https://www.arbazsiddiqui.me/dns-resolution-and-records-for-developers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><h2 id="introduction"><a href="#introduction" aria-label="introduction permalink"></a>Introduction</h2>
<p>Domain Name System (DNS) is something which we all use everyday without knowing the internal workings of it. How does a url we enter in our browser gets redirected to a specific server? How is it so fast? If you have setup any website you might be familiar with adding A record and CNAMEs. But what are they? What <code>@</code> as a host means? When to use what? This article try to answer all these questions. We will cover what DNS is, how does it work, what are different DNS records and their use cases.</p>
<h2 id="what-is-a-domain-name"><a href="#what-is-a-domain-name" aria-label="what is a domain name permalink"></a>What is a Domain Name?</h2>
<p>Lets first understand what a domain name is before we can jump into DNS. A domain name is a unique text identifier for a website or server. The domain name for this website is <code>arbazsiddiqui.me</code>. A domain has following structure :</p>
<div data-language="text"><pre><code>&lt;subdomain&gt;.&lt;domain&gt;.&lt;TLD&gt;</code></pre></div>
<p>Lets understand this via an example of <code>blog.arbazsiddiqui.me</code>.</p>
<p><code>.me</code> is the <code>Top Level Domain (TLD)</code>. This is the root of the domain and encompasses all domains in it. <code>.com</code>, <code>.org</code>, <code>.io</code> are all example of TLDs. <code>arbazsiddiqui</code> is the <code>domain</code> and technically a <code>subdomain</code> of <code>.me</code>. <code>blog</code> is a subdomain of <code>arbazsiddiqui</code>. We can chain this as far as we want, only thing to understand here is that <code>TLD</code> is the root and all subsequent domains are <code>subdomains</code> of the previous one.</p>
<h2 id="what-is-dns"><a href="#what-is-dns" aria-label="what is dns permalink"></a>What is DNS?</h2>
<p>The Domain Name System (DNS) is the phonebook of the internet. DNS is the mechanism which is responsible for converting human friendly urls like <code>arbazsiddiqui.me</code> to machine understandable IP addresses (<code>104.198.14.52</code> in this case). Each device connected to the Internet has a unique IP address which other machines use to find the device. DNS eliminate the need for humans to memorize IP addresses. </p>
<h2 id="how-does-dns-work"><a href="#how-does-dns-work" aria-label="how does dns work permalink"></a>How does DNS work?</h2>
<p>The process of finding a host name's IP address is called DNS resolution or DNS lookup. A server queries a bunch of other servers if they have the IP address of requested domain name. The other server might not know the IP of the requested domain but will point it to another server which might know it. After following up this chain we will eventually end up with the IP address of our domain. </p>
<p>A DNS resolution will typically require 4 hops (in a non cached scenario). </p>
<ol>
<li><strong>DNS Resolver</strong> : The DNS resolver is the computer that responds to a request from a client and takes the time to track down the DNS record. It will query all other subsequent servers on your behalf and after finding the IP address will respond with it.</li>
<li><strong>Root nameserver</strong> : This is the first step towards finding the IP of requested domain. A root nameserver has the IP address of TLD nameservers. So if you are requesting <code>example.com</code>, root nameserver will point DNS resolver to the IP address of TLD nameserver for <code>.com</code> and DNS resolver can process from there.</li>
<li><strong>TLD nameserver</strong> : TLD nameservers contain the IP addresses of all the subdomains which are the part of their TLD. So in our case of <code>example.com</code>, the <code>.com</code> TLD (which was pointed to use by <code>root nameserver</code>) will point DNS resolver towards the <code>Authoritative nameserver</code> of <code>example.com</code>. </li>
<li><strong>Authoritative nameserver</strong> : An authoritative DNS server is a server that actually holds, and is responsible for, DNS resource records. This is the server at the bottom of the DNS lookup chain that will respond with the queried resource record, ultimately allowing the web browser making the request to reach the IP address needed to access a website or other web resources. In our case, it will respond back with IP address <code>104.198.14.52</code> to the DNS resolver which will respond the same back to client. This marks the complete chain of a DNS lookup.</li>
</ol>
<p><span>
      <a href="https://www.arbazsiddiqui.me/static/db3c8c0870e1e9acf669cafbadc8ce69/f84cf/DNS-Lookup.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="DNS Lookup" title="DNS Lookup" src="https://d33wubrfki0l68.cloudfront.net/1a64d403b736a3ca4484b7d01be2af97595c2cd4/6cb51/static/db3c8c0870e1e9acf669cafbadc8ce69/faddd/dns-lookup.jpg" srcset="https://d33wubrfki0l68.cloudfront.net/bfa0948e86d586451ef4ba90b9b704006e942c03/c7c72/static/db3c8c0870e1e9acf669cafbadc8ce69/6a7c0/dns-lookup.jpg 213w,
https://d33wubrfki0l68.cloudfront.net/30ce1c0983d3fb89cf61182b8504c2353b1fef28/67f56/static/db3c8c0870e1e9acf669cafbadc8ce69/b9721/dns-lookup.jpg 425w,
https://d33wubrfki0l68.cloudfront.net/1a64d403b736a3ca4484b7d01be2af97595c2cd4/6cb51/static/db3c8c0870e1e9acf669cafbadc8ce69/faddd/dns-lookup.jpg 850w,
https://d33wubrfki0l68.cloudfront.net/5164b9b355447618c8bdc9481c7e10868993357a/52178/static/db3c8c0870e1e9acf669cafbadc8ce69/f84cf/dns-lookup.jpg 880w" sizes="(max-width: 850px) 100vw, 850px" loading="lazy">
  </a>
    </span></p>
<p>To know the IP address of a domain name you can simple do : </p>
<div data-language="terminal"><pre><code>dig arbazsiddiqui.me +short

104.198.14.52</code></pre></div>
<p><code>104.198.14.52</code> is the IP address of server hosting <code>arbazsiddiqui.me</code>.</p>
<h2 id="dns-records"><a href="#dns-records" aria-label="dns records permalink"></a>DNS Records</h2>
<p>DNS records are instructions that live in authoritative nameservers and provide information about a domain including what IP address is associated with that domain and how to handle requests for that domain. You as website owner are responsible for telling the Authoritative nameserver (the last stop in DNS lookup) the address of the server your website is hosted on. DNS records allows you to do multiple things such as adding subdomains. A record typically consist of three things a <code>Type</code>, a <code>Host</code> and a <code>Value</code>. Lets look at record types one by one.</p>
<h3 id="a-records"><a href="#a-records" aria-label="a records permalink"></a>A records</h3>
<p>An A record maps a domain name to an IPv4 address. It’s what you use to point <code>arbazsiddiqui.me</code> to <code>104.198.14.52</code>.</p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Host</th>
<th>Value</th>
<th>TTL</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>@</td>
<td>104.198.14.52</td>
<td>14400</td>
</tr>
</tbody>
</table>
<p>The above record means that when someone types <code>arbazsiddiqui.me</code> in the browser, the request will be directed to server on IP <code>104.198.14.52</code>. The <code>@</code> here indicates that this is a record for the root domain, and the ‘14400’ value is the TTL (Time To Live), listed in seconds. This means that if an A record gets updated, it takes 240 minutes (14400 seconds) to take effect.</p>
<blockquote>
<p>Some registrars like goDaddy call Host as Name.</p>
</blockquote>
<p>The <code>AAAA</code> record does the same for IPv6</p>
<h3 id="cname"><a href="#cname" aria-label="cname permalink"></a>CNAME</h3>
<p>A CNAME record is used when a domain or subdomain is an alias of another domain. In other words when you want to add a subdomain like <code>www</code> or <code>blog</code> to
<code>arbazsiddiqui.me</code>. The CNAME record's value is <strong>always</strong> another domain and NOT the IP address. Hence if you want to add a subdomain <code>www</code> to <code>arbazsiddiqui.me</code>, it will look like this : </p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Host</th>
<th>Value</th>
<th>TTL</th>
</tr>
</thead>
<tbody>
<tr>
<td>CNAME</td>
<td>www</td>
<td>arbazsiddiqui.me</td>
<td>14400</td>
</tr>
</tbody>
</table>
<p>This record states that when <code>www.arbazsiddiqui.me</code> is typed in browser, trigger a lookup for <code>value</code> which in this case is <code>arbazsiddiqui.me</code>. This will eventually serve the A record for <code>arbazsiddiqui.me</code> from above section. So CNAMEs can point to other domains or subdomains but the chain will eventually end up to an A record which will be used to serve website.</p>
<p>CNAME can also be used to point to another app hosted somewhere like heroku or netlify.</p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Host</th>
<th>Value</th>
<th>TTL</th>
</tr>
</thead>
<tbody>
<tr>
<td>CNAME</td>
<td>www</td>
<td>trusting-jennings-f13c44.netlify.com</td>
<td>14400</td>
</tr>
</tbody>
</table>
<h3 id="txt"><a href="#txt" aria-label="txt permalink"></a>TXT</h3>
<p>The text record let’s a domain administrator enter text into the DNS record. It is most commonly used to determine the ownership of the domain. For example to claim a domain on google search console you will have to add a token as TXT record so that google knows that you are the legit owner of your domain. </p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Host</th>
<th>Value</th>
<th>TTL</th>
</tr>
</thead>
<tbody>
<tr>
<td>TXT</td>
<td>@</td>
<td>google-site-verification=xyz</td>
<td>14400</td>
</tr>
</tbody>
</table>
<h3 id="mx"><a href="#mx" aria-label="mx permalink"></a>MX</h3>
<p>The mail exchange record directs email to a mail server. The value of MX record should be a domain.</p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Host</th>
<th>Value</th>
<th>Priority</th>
<th>TTL</th>
</tr>
</thead>
<tbody>
<tr>
<td>MX</td>
<td>@</td>
<td>mailhost.example.com</td>
<td>3</td>
<td>14400</td>
</tr>
<tr>
<td>MX</td>
<td>@</td>
<td>mailhost2.example.com</td>
<td>4</td>
<td>14400</td>
</tr>
</tbody>
</table>
<p>The new field <code>priority</code> here indicates the the order in which the message will be tried. Here <code>mailhost.example.com</code> will be tried first as it has higher priority and if it fails it will try <code>mailhost2.example.com</code>.</p>
<h2 id="caching"><a href="#caching" aria-label="caching permalink"></a>Caching</h2>
<p>In <a href="#how-does-dns-work">DNS lookup</a> section we saw that a DNS resolution is a 4 hop process, but on a good internet connection things work in a seamless manner. DNS uses UDP protocol which is fast but still doing so many resolution so quickly wont be possible without introducing caching. DNS responses are cached at many different levels. In your browser, in your domestic router, and also in intermediary networking hardware.</p>
<p>And if there’s caching, there’s also a way to expire the cache, and that’s the TTL (time to live). Any DNS record will have an associated TTL value, and that’s how much time their value can be stored (cached) by any involved party. You can change this at any time from the DNS server.</p>
<h2 id="hosts-file"><a href="#hosts-file" aria-label="hosts file permalink"></a>Hosts File</h2>
<p>All OS provides us with a <code>hosts</code> file. We can keep a list of domains and their respective IP addresses here. If a domain is listed here, it will take precedence over the normal DNS lookup flow and the clients will directly try to connect with IP listed against an IP. A line from <code>hosts</code> file looks like this : </p>

<p>Adding the websites you visit the mosts and their respective IPs might seem a good idea and will definitely save you some time spent in resolution but its too much of a hassle to keep this updating if the IP changes or as you get addicted to more websites. For this use case we can use tools like <a href="http://www.thekelleys.org.uk/dnsmasq/doc.html" target="_blank" rel="noopener noreferrer">dnsmasq</a> which is light weight caching server.</p>
<p>However hosts file is great way to check your new server without changing anything publicly, just edit this file and manually set your domain to point to the IP address of your new server, and you’ll be able to test it for real with a browser.</p>
<p>Another great use case of hosts file is to block unwanted sites by adding their domain to loopback IP <code>127.0.0.1</code>. This can be done to block ads, malwares or cure reddit addiction. Just add following lines to your <code>/etc/hosts</code> file: </p>

<h2 id="conclusion"><a href="#conclusion" aria-label="conclusion permalink"></a>Conclusion</h2>
<p>Its easy to forget the internal workings of internet behind all the cat videos. DNS resolution is one such internal mechanism which makes up the internet and its good to know how it works under the hood. In this article we learned what DNS is and how does a url in browser gets converted to an IP address. We also looked at DNS records and their respective use cases.</p></div></article></div>]]>
            </description>
            <link>https://www.arbazsiddiqui.me/dns-resolution-and-records-for-developers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738908</guid>
            <pubDate>Sun, 05 Jul 2020 14:26:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Stress Response Cycle: The Surprising Science Behind Feeling Better]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738861">thread link</a>) | @coffeeandjunk
<br/>
July 5, 2020 | https://coffeeandjunk.com/stress-response-cycle/ | <a href="https://web.archive.org/web/*/https://coffeeandjunk.com/stress-response-cycle/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <!-- 
            <figure class="post-full-image">
                <img
                    srcset="/content/images/size/w300/2020/07/stress-response-cycle.jpg 300w,
                            /content/images/size/w600/2020/07/stress-response-cycle.jpg 600w,
                            /content/images/size/w1000/2020/07/stress-response-cycle.jpg 1000w,
                            /content/images/size/w2000/2020/07/stress-response-cycle.jpg 2000w"
                    sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px"
                    src="/content/images/size/w2000/2020/07/stress-response-cycle.jpg"
                    alt="The Stress Response Cycle: The Surprising Science Behind Feeling Better"
                />
            </figure>
             -->

            <section>
                <div>
                    <p>The internet is littered with infinite content on managing stress. Most of them don’t know what they are talking about. The basic premise is always to “learn to chill”. But if it were so simple, there wouldn’t have been so many motivational videos and blog posts in the first place.</p><p>Stress is a physiological phenomenon, and unless we understand the science behind it, we cannot possibly know how to manage it. In her phenomenal book, <a href="https://amzn.to/31Kh4S5"><em>Come As You Are</em></a>, sex educator Emily Nagoski talks about the physiology of stress, and gives us important pointers to deal with it.</p><p>Let’s start by separating <em>stressors</em> from <em>stress</em>. Your stressors are the things that activate the stress response. For example, exams, bills, family, office, fretting about your career, all of that.</p><p>Your stress is the system of changes activated in your brain and body in response to those stressors. We refer stress as the fight-or-flight response, but its full description is: fight, flight, or freeze response. Stress is an evolutionarily adaptive mechanism that allows you to respond to perceived threats, such as being chased by a lion.</p><p>These days we are not chased by lions, and yet our body’s response to threats such as an incompetent boss is largely the same as it would be to a lion. Our primitive brain doesn’t differentiate much.</p><p>When your brain perceives a threat, you experience a massive biochemical and physiological change. Your bloodstream is flooded by adrenaline and cortisol. Your heart rate, respiration rate and blood pressure increases. Your immune and digestive functioning gets suppressed. Your pupils are dilated thereby shifting you into a vigilant and battle-ready state. You body prepares itself for the action to come.</p><p>What the “action” will be depends on the nature of the perceived threat. If it’s a lion, your brain informs you it’s the kind of threat that you are most likely to survive by trying to escape—flight. If the lion doesn’t get hold of you, you reach your village safely, and rejoice in relief.</p><p>There are times when your brain decides that you can best survive a threat by conquering—fight. You jump on the thief who tries to run off with your wallet.</p><p>This is the stress response cycle. It starts with a stressor (when your brain screams, I’m at risk), action (fight or flight), and relief (I’m safe). These two responses—fight and flight—are both accelerator stress response—the “GO!”</p><p>But suppose a stressor is such that your brain determines that you can neither survive it by escaping nor by conquering. The lion has already grabbed you, you don’t have any weapons to attack, and it’s too late to run. Your body has undergone a series of changes to prepare itself to deal with the threat, but this time you get the brakes stress response—the freeze—the “STOP!” instead of the “GO!” Your body shuts down. You can’t move, or can move only sluggishly. You senses slow down and you become dizzy. You surrender!</p><p>Animals in the wild play possum as a last-ditch effort to convince a predator that they’re already dead. Surrender also facilitates a painless death. But if an animal survives such an intense threat to its life, it shakes before getting up. It trembles. Its paws vibrate. It heaves a great big sigh. And then it gets up, shakes itself off before trotting away.</p><p>What’s happening here is that freeze has interrupted the “GO!” stress response of fight or flight, leaving all that adrenaline to go stale inside the animal’s body. When the animal shakes and shudders and sighs, its body releases the brake, completes the process triggered by fight/flight, and purges the residue, thereby completing the cycle.</p><p>My girlfriend underwent surgery a couple of years back. After coming out of anaesthesia, she started screaming and yelling with any obvious cause. Emily Nagoski calls it “the Feels”. Anaesthesia is medically induced freeze. She wasn’t in any danger, but she had a lot of Feels that needed to work themselves out in order to complete the cycle. Only rarely in our everyday lives does unlocking from freeze take such a dramatic form, but even in its smaller scale, that’s how the stress response cycle works, beginning, middle, and end—all innately built into the nervous system. The cycle needs to complete in order to relieve stress.</p><p>It sounds very simple, and it is. But stress is more complex in us humans due to modernity and other cultural reasons. For starters, modern stressors are lower in intensity and longer in duration—<em>chronic stressors</em>, in contrast to <em>acute stressors</em> like being chased by a lion.</p><p>Acute stressors have a clear beginning, middle, and end. Completing the cycle—running, surviving, celebrating—is inherently built in. It’s not so with chronic stressors. If our stress is chronic and we don’t take deliberate steps to complete the cycle, all that activated stress just hangs out inside us, making us sick, tired, and unable to experience pleasure in anything.</p><p>On top of that, our emotion-dismissing culture is uncomfortable with the Feels. As a result, most people’s idea of stress management is some version of “just relax” as if stress can be turned off like a light switch.</p><p>But most importantly, our ultrasocial human brains are really good at self-inhibition, stopping the stress response mid-cycle because “now is not an appropriate time for the Feels”—especially if you are in a public pace. We use this self-inhibition in order to facilitate social cooperation. We don’t want to freak anybody out, do we?</p><p>But unfortunately, our culture has eliminated all appropriate times for Feels. We’ve locked ourselves, culturally, into our own fear, rage, and despair. Hence most people resort to doing things that distract them from stress, such as alcohol, endless partying, binging on fast-food and Netflix. They’re all intended to do one thing: manage the underlying feelings. But it can be done in a healthy way as well. We just have to build time, space, and strategies for discharging our stress response cycles. That is the only way to deal with stress.</p><p>Think about what your body recognises as the behaviours that save you from lions. When you’re being chased by a lion, what do you do? You run. So when you’re stressed out by your job, what do you do? You run…or walk, or get on a bicycle, or go out dancing.</p><p>Physical activity is the single most efficient strategy to complete the stress response cycle, and recalibrate your central nervous system into a calm state. When people say, “Exercise is good for stress,” that is for real.</p><p>Alan Turing famously ran miles everyday to relieve stress. When asked why he does that he said, “I have such a stressful job that the only way I can get it out of my mind is by running hard; it’s the only way I can get some release.”</p><p>In his phenomenal book <a href="https://amzn.to/38v0jf9"><em>Spark: The Revolutionary New Science of Exercise and the Brain </em></a>, the author John J. Ratey, who’s an MD, talks about how simple physical actives like running, jogging, skipping can help us become not only fitter, but also happier and sharper.</p><p>In communities like No Lights No Lycra (NLNL), strangers gather to dance in the dark together, all sober, to shake the blues away. They are present in over 75 locations around the world, including Mumbai.</p><p>If you really want to move your body, you don’t have to go very far. Your home can become your stage. I personally, love to dance. Not that I’m a good dancer, but I love this as an activity to release inhibitions, move moods, and work up a sweat.</p><p>Few other activities that help you “feel better” are: sleep, humour, affection, meditation, allowing yourself a good old cry, or a primal scream.</p><p><a href="https://amzn.to/31Lb2Rh">Sleep</a> is essentially trauma and stress therapy, and I cannot “stress” more upon the importance of 8 hrs of daily sleep, no matter what.</p><p>If you are naturally humorous, it helps. If you are comfortable enough to crack bad jokes just to keep yourself entertained, it helps as well. Since we’re spending so much of time together after the lockdown, my girlfriend and I do this all the time. We crack silly jokes that others would find weird, childish, and sometimes even stupid. But this helps us deal with the day-to-day tribulations related to work and household chores.</p><p>A warm affectionate hug from your partner, your friend, or your parents is a great stress reliever. An affectionate hug essentially says, “You’re okay. You got it. It’s gonna be fine.” Hug more. Hug often.</p><p>If you’ve ever locked yourself in your room and sobbed for ten minutes or got on the top of a building and shouted your lungs out, and then at the end heaved a great big sigh and felt tremendously relieved, you have essentially helped yourself complete the stress response cycle.</p><p>Art, used in the same way, can help. My girlfriend’s sister does paintings in gouache. It started out as a hobby, but eventually it became a way discharge stress through the creative process. Journaling helps in similar ways. When mental health professionals suggest journaling or other expressive hobbies, they don’t mean that the construction of sentences or the task of drawing is inherently therapeutic, rather they are encouraging you to complete the cycle by pursuing little creative endeavours.</p><figure><img src="https://coffeeandjunk.com/content/images/2020/07/image.png"><figcaption>One of my girlfriend's sister's work</figcaption></figure><p>Don’t forget to treat yourself with affection during stressful times. I’ve known people for whom a hot shower and the rituals of painting their nails or doing their hair or putting on makeup fully transition them from a stressed-out state of mind to a warm, social state of mind.</p><p>These rituals and behaviours are forms of self-kindness. Apes eat insects out of each other’s fur. Bath bombs and body glitters are the modern human equivalent.</p><p>My point is, everybody has something that works—and everyone’s strategy is different. Whatever strategy you use, take deliberate steps to complete the cycle. Allow yourself to coast to the end without hitting the brake. As Emily Nagoski says, emotions are like tunnels; you have to walk all the way through the …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://coffeeandjunk.com/stress-response-cycle/">https://coffeeandjunk.com/stress-response-cycle/</a></em></p>]]>
            </description>
            <link>https://coffeeandjunk.com/stress-response-cycle/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738861</guid>
            <pubDate>Sun, 05 Jul 2020 14:21:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A few thoughts on the Zephyr's ASDL]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738815">thread link</a>) | @isidentical
<br/>
July 5, 2020 | https://tree.science/transitional-asdl.html | <a href="https://web.archive.org/web/*/https://tree.science/transitional-asdl.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<!-- /.post-info -->      <p>The Zephyr Abstract Syntax Description Language or shortly Zephyr's ASDL is a 
well known; mature (released at 1997~), descriptive language for defining ASTs 
(nodes and leaves) and other tree-like data structures. When it got released (and
even after one or two decades) it was more than capable of being used in major compilers,
including CPython's bytecode compiler (from v2.5~). But after having quite a bit
of experience with it, I started to realize that it can be improved in a few ways.
The whole post will contain my own humble opinions. Please feel free share your
own ones with me through the contact information at the end of the post. I'm currently
working on a demo project to enpower all the ideas that are being mentioned below, and
it would be really nice to hear from you about these.</p>

<p>Every field declaration in ASDL consists from this form <code>[type][qualifier]? [name]</code>;
where <code>[type]</code> is either something defined in the current spec, or a built-in one 
(such as <code>identifier</code>). And the <code>[qualifier]</code> is a mutually exclusive and optional
qualifier for the given type. There are 2 kinds of qualifiers <code>[qualifier]={?, *}</code>.
A question mark (<code>?</code>) means it can be either empty or something that belongs to the
<code>[type]</code>. On the other side, a star (<code>*</code>) means it is a zero or more element sequence
of given <code>[type]</code>. In theory, these 2 qualifiers might seem enough, but giving a basic
example might prove the otherwise. Let's imagine a simple AST of a python function.</p>
<div><pre><span></span>function = Function(identifier name, expr? returns, stmt* body)
</pre></div>


<p>It has a name, an optional return annotation, and a list of statements as it's body.
Which looks very accurate, right?</p>
<div><pre><span></span><span>def</span> <span>foo</span><span>()</span> <span>-&gt;</span> <span>int</span><span>:</span>
    <span>pass</span>

<span>def</span> <span>bar</span><span>():</span>
    <span>pass</span>
    <span>pass</span>
</pre></div>


<p>If we try to address these functions in the AST which we created earlier, it will
look something like this;</p>
<div><pre><span></span><span>Function</span><span>(</span><span>"foo"</span><span>,</span> <span>Expr</span><span>(</span><span>int</span><span>),</span> <span>[</span><span>PassStmt</span><span>()])</span>
<span>Function</span><span>(</span><span>"bar"</span><span>,</span> <span>None</span><span>,</span> <span>[</span><span>PassStmt</span><span>(),</span> <span>PassStmt</span><span>()])</span>
</pre></div>


<p>And there is nothing that looks wrong with this form, as long as it is generated
by some kind of parser. But Python allows users to craft and compile arbitrary ASTs.
As you might know, the function bodies in Python have to at least 1 statement, but
the ASDL implies that it might have zero (since <code>*</code> means zero or more). There goes the
conflict, this AST, <code>Function("baz", None, [])</code> is valid according to the ASDL spec,
but it later on it might crash the interpreter or might not pass the validation at all.
For CPython, there is a custom AST validator, which comes with the burden of maintenance,
just for ensuring that user crafted AST's won't crash the compiler.</p>
<div><pre><span></span><span>&gt;&gt;&gt;</span> <span>import</span> <span>ast</span>
<span>&gt;&gt;&gt;</span> <span>foo_mod</span> <span>=</span> <span>ast</span><span>.</span><span>parse</span><span>(</span><span>"def foo(): pass"</span><span>)</span>
<span>&gt;&gt;&gt;</span> <span>foo_mod</span><span>.</span><span>body</span><span>[</span><span>0</span><span>]</span><span>.</span><span>body</span><span>.</span><span>clear</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>compile</span><span>(</span><span>foo_mod</span><span>,</span> <span>"&lt;test&gt;"</span><span>,</span> <span>"exec"</span><span>)</span>
<span>Traceback</span> <span>(</span><span>most</span> <span>recent</span> <span>call</span> <span>last</span><span>):</span>
  <span>File</span> <span>"&lt;stdin&gt;"</span><span>,</span> <span>line</span> <span>1</span><span>,</span> <span>in</span> <span>&lt;</span><span>module</span><span>&gt;</span>
<span>ValueError</span><span>:</span> <span>empty</span> <span>body</span> <span>on</span> <span>FunctionDef</span> <span>&lt;=</span> <span>custom</span> <span>error</span>
</pre></div>


<div><pre><span></span><span>static</span> <span>int</span>
<span>validate_nonempty_seq</span><span>(</span><span>asdl_seq</span> <span>*</span><span>seq</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>what</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>owner</span><span>)</span>
<span>{</span>
    <span>if</span> <span>(</span><span>asdl_seq_LEN</span><span>(</span><span>seq</span><span>))</span>
        <span>return</span> <span>1</span><span>;</span>
    <span>PyErr_Format</span><span>(</span><span>PyExc_ValueError</span><span>,</span> <span>"empty %s on %s"</span><span>,</span> <span>what</span><span>,</span> <span>owner</span><span>);</span>
    <span>return</span> <span>0</span><span>;</span>
<span>}</span>
<span>static</span> <span>int</span>
<span>validate_body</span><span>(</span><span>asdl_seq</span> <span>*</span><span>body</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>owner</span><span>)</span>
<span>{</span>
    <span>return</span> <span>validate_nonempty_seq</span><span>(</span><span>body</span><span>,</span> <span>"body"</span><span>,</span> <span>owner</span><span>);</span>
<span>}</span>
<span>...</span>
    <span>case</span> <span>FunctionDef_kind</span><span>:</span>
        <span>return</span> <span>validate_body</span><span>(</span><span>stmt</span><span>-&gt;</span><span>v</span><span>.</span><span>FunctionDef</span><span>.</span><span>body</span><span>,</span> <span>"FunctionDef"</span><span>)</span>
</pre></div>


<p>Also this is not the only case where the AST doesn't comply with ASDL. For an example,
the AST of an dictionary defined as <code>Dict(expr* keys, expr* values)</code>, which means that
it has two list of <em>expressions</em> that are named <code>keys</code> and <code>values</code>. That makes sense
since, AST of <code>{'a': 'b'}</code> is just <code>Dict([Constant('a')], [Constant('b')])</code>. But when it
comes to dict unpacking inside of another dictionary with double-star operator, the AST
looks like this;</p>
<div><pre><span></span>Input: {**a, b:c}
Output:
Dict(
    keys=[
        None,
        Name(id='b', ctx=Load()),
    ],
    values=[
        Name(id='a', ctx=Load()),
        Name(id='c', ctx=Load()),
    ],
)
</pre></div>


<p>Did you see that there is an outlier among the <code>keys</code>, the <code>None</code>. This is because that field
qualifiers are mutually exclusive, and you can't chain them. Things like this would make the
ASDL a context-dependent thing and in some cases, they might increase the maintenance burden
(such as external verifiers, which I'll also address in the next section). The solution would
be as simple as just extending the current qualifiers and make them chainable. There are 2 design
I have in my mind. The first one is introducing new qualifiers in the same form</p>
<div><pre><span></span>* =&gt; zero or more sequence
+ =&gt; one or more sequence
? =&gt; optional
[&lt;field type&gt;] =&gt; also optional but chainable

FunctionDef(identifier name, expr? returns, stmt+ body)
Dict([expr]* keys, expr* values)
</pre></div>


<p>the second one is kind-a different might be hard to process in big ASDL's but more explicit.</p>
<div><pre><span></span>ZeroOrMore[&lt;field type&gt;] =&gt; such as *
OneOrMore[&lt;field type&gt;] =&gt; such as +
Opt/Optional[&lt;field type&gt;] =&gt; such as * or [&lt;field type&gt;]

FunctionDef(identifier name, Opt[returns], OneOrMore[body])
Dict(ZeroOrMore[Opt[keys]], ZerOrMore[values])
</pre></div>



<p>Integrating some source code inside of grammars isn't a new idea, a recent example would be the
Python's new parser generator, and the <a href="https://github.com/python/cpython/blob/master/Grammar/python.gram">grammar</a>
it consumes. I believe that this can be integrated very quickly to the ASDL itself, with a new but not an unorthodox
syntax. The purpose of these actions is going to be both verification and transitions (not limited to that). 
It might open a way to language extensions.</p>
<p>Bringing such actions would require a metadata format to the ASDL modules, the best form I can think of is
something similar to python decorators that will annotate the ASDL modules (namespaces, which are not
part of the original <a href="https://everet.org/wp-content/uploads/2012/05/The-Zephyr-Abstract-Syntax-Description-Language.pdf">paper</a>).</p>
<div><pre><span></span>@&lt;key&gt; &lt;value&gt;
module &lt;name&gt; {}

@actions C
@version 3.8
module Example {}
</pre></div>


<p>The action syntax will depend on the action's purpose</p>
<div><pre><span></span>{verify, transition} $left::right [where $condition] {
    [ACTION]
}
</pre></div>


<h2>Verifier Actions</h2>
<p>As I mentioned earlier, languages that allow users to create external ASTs requires a custom
validation step. Type checking will help in most cases, but there will be still some esoteric
ones left. It might be a controversial thing since some people might not want to host their
source code inside of a text spec (I dont know, maybe for their linters / formatters, or other
purposes), but this will ensure that the validation process is public and the clients of this AST
will know what nodes will be validated and which kind of methods will be used for their validation.</p>
<div><pre><span></span>verify $nodes::$fields [where $condition] {
    [ACTION]
}

verify Dict::(keys, values) {
    return len(keys) == len(values)
}

verify ImportFrom::level {
    return level &gt;= 0
}

verify Try::(handlers, finalbody, orelse) where len(handlers) == 0 {
    if len(finalbody) == 0 and len(orelse) &gt; 0:
        return False
    ...
}
</pre></div>


<h2>Transitioning</h2>
<p>Here it comes the other big problem and a use case for actions, the AST changes. If you are writing some kind of tool that consumes the AST (e.g: linter), it is not uncommon for you to get broken
in every release. The reason for that is  AST is also an internal format and things might just change
for internal reasons and no one gives you a guarantee about it won't change again. So you have to test
your tool on every major release and ensure the breakages are gone by creating tons of workarounds.</p>
<p>This is the case for even the simplest change, like changing the name of a node. The solution would be
a simple layer of "compatibility". The way it should work is that, for old nodes, it is going to keep
the same structure as the old ASTs even though the name of the form of that node is changed. Achieving
such a thing would be available in 2 ways: keeping ASDL of every version (and it would be definitely a
mess), or only the generated code for that nodes as a part of that "compatibility" layer. I'd personally
go for the latter. Let's do an imaginary example of 3 different language versions;</p>
<div><pre><span></span>@version 3.6
module Example {
    number = NumOrFloat(object value)
           | Complex(object value)
}
</pre></div>


<div><pre><span></span>@version 3.7
module Example {
    number = Num(object value)
           | Float(object value)
           | Complex(object value)
</pre></div>


<div><pre><span></span>@version 3.8
module Example {
    number = Number(object value, str kind)
</pre></div>


<p>The <code>3.6</code> version has 2 nodes, <code>NumOrFloat</code> for numbers and floats and <code>Complex</code> for imaginary numbers.
The <code>3.7</code> form splits <code>NumOrFloat</code> into 2 different nodes, a <code>Num</code> node and a <code>Float</code> node. And finally,
the <code>3.8</code> version has only 1 constructor, it is the <code>Number</code>, with an additional <code>kind</code> field. In theory
that no matter which version you are, in the "compatibility" layer, you would only have the <code>NumOrFloat</code> and
the <code>Complex</code> nodes. For providing that we need some kind of action to do the transition. </p>
<div><pre><span></span>transition $source::$destination [where $condition] {
    [ACTION]
}

transition Number::(Num, Float, Complex) {
    switch (origin-&gt;kind) {
        case 'integer':
            return Num(origin-&gt;value);
        case 'float':
            return Float(origin-&gt;value);
        case 'complex':
            return Complex(origin-&gt;value);
    }
}
</pre></div>


<p>The example upper takes a <code>3.8</code> <code>Number</code> node and outputs a <code>3.7</code> node (<code>Num</code>, <code>Float</code>, or <code>Complex</code>). This is
also going to be the case for <code>3.7</code>, it will take a <code>3.7</code> AST and output a <code>3.6</code> version. So in the end, all ASTs
will be the same in the imaginary "compatibility" layer.</p>
<div><pre><span></span>@version 3.7
module Example {
    number = Num(object value)
           | Float(object value)
           | Complex(object value)

    transition Float::NumOrFloat {
        return NumOrFloat(origin-&gt;value);
    }
}
</pre></div>



<p>I guess this is all, thanks for reading this and if you have any extra thoughts about this, I really want to listen to
all of them. Please contact me through <code>isidentical [at] tree.science</code> or twitter/telegram/discord (<code>@isidentical</code>)</p>
    </div></div>]]>
            </description>
            <link>https://tree.science/transitional-asdl.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738815</guid>
            <pubDate>Sun, 05 Jul 2020 14:16:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Web Development on GNU/Linux]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738681">thread link</a>) | @zooboole
<br/>
July 5, 2020 | https://phpocean.com/tutorials/computer-skills/web-development-on-gnu-linux/69 | <a href="https://web.archive.org/web/*/https://phpocean.com/tutorials/computer-skills/web-development-on-gnu-linux/69">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p>
                  Our website is made possible by displaying online advertisements to our visitors.
                  Please consider supporting us by disabling your ad blocker.
                </p>
              
              



              

              <p>There is a general concept that the nearer your web development environment is to your live web hosting environment the less the unexpected snags you will have to fix. The current usage of the Unix and Linux operating system for web servers is estimated as of 2020 at 67%.</p>

<p>So there is a very good chance that your web application will end up on a Linux OS server; you can increase that figure if you take into account Cloud technology which is primarily Linux.</p>

<p>This article looks at some of the nuances of using Linux for web development. I am of course biased in that I am a long time user of GNU/Linux particularly Slackware; currently, I maintain <a href="https://slackbuilds.org/repository/14.2/academic/latex2html/?search=latex2html" target="_blank">Latex2html</a> for the Slackware repository and contribute to <a href="https://docs.slackware.com/howtos:misc:anatomy_of_a_slackbuild" target="_blank">the Docs</a>.</p>

<p>I did use to use Windows for web stuff and it wasn't too bad in the old days when Windows Desktop as default was less cluttered. However generally I ended having to pay for third-party software such as CuteFTP. One day I built a new Desktop PC with a brand new blank hard drive. A blank hard drive with no OS! So it was decision time to pay for a Windows Install Disk, then have to pay for Office Suite or see what Linux can do.</p>

<p>I installed Linux and never looked back. As for CuteFTP I soon discovered there was a large repository where I could obtain the software free of Adverts, free of shareware and free of malware.</p>

<p>I mean it's hard enough coding and getting code bugs without throwing in, is that problem may be due to dodgy software I just installed?</p>

<p>When last in Ghana general comments to me were "why should I bother with that complicated Linux, when I can have Windows for free".</p>

<p>I don't buy that argument; if it was as simple as that why is not everybody in Ghana going from A to B on horses instead of cars. I mean a horse pretty much can do everything a car can, go uphill get you from A to B and only needs a bag of oats and a rub down!</p>

<p>It probably about decision and motivation. Let me just say I'm not here to judge and my air of superiority in using Slackware was recently given a knock and made me think from communication from <strong>Richard Stallman</strong> only last week.</p>

<blockquote>
  <p>Running an unauthorized copy of Windows still gives Microsoft power
  over you. So I say: an unauthorized copy of Windows is a very bad
  thing -- almost as bad as an authorized copy ;-{.</p>
  
  <p>Slackware GNU/Linux has two flaws. It contains nonfree programs. <a href="https://gnu.org/distros" target="_blank">See</a>
  <br> The developers call it "<strong>Slackware Linux</strong>"
  which is unfair to the GNU Project. <a href="https://gnu.org/gnu/linux-and-gnu.html">See</a>
   and <a href="https://gnu.org/gnu/gnu-linux-faq.html" target="_blank">this</a>, plus <a href="https://gnu.org/gnu/the-gnu-project.html" target="_blank">the history</a>.</p>
  
  <p><br> —  Dr. Richard Stallman</p>
</blockquote>

<p>So GNU/Linux Slackware is free as in free beer but not in terms of free in access to all of its code.</p>

<p>If you have only ever used Windows there will be a learning curve but there are choices on how fast you learn Linux. Things would be better if in 3rd World Countries such as Ghana they were serious in embracing Linux users and putting Linux onto the school Curriculum.</p>

<p>Some say Linux is complicated but more me I find it a more minimal experience especially using XFCE Desktop. I recently looked at a friend's laptop that was 30 gig and had Windows 10 on it. The hard drive was full but Windows wanted to do it said 2.8gig of updates. To be honest, how you can find your way around the system with all that clutter on the Desktop is beyond me!</p>

<p>The way I think about Linux is to use a car metaphor. Your Diesel car uses diesel and your petrol car, petrol. Apart from that, a driver uses his steering wheel, breaks, etc without a second thought about the engineering concept of the 4 stroke engine.</p>

<p>It's a bit like that in Linux. Once installed and you log in; you have at your disposal Firefox web browser and to all intents and purposes wouldn't know if you were on Linux or Windows.</p>

<p>All the other stuff like LibreOffice is available from the menu; the layout of LibreOffice is user-intuitive and you can save files as "doc".</p>

<p>Basically, the least complicated way is to use Linux as a normal user. In this case "file permissions" are set so that you will not be challenged.</p>

<p>On my Slackware GNU/Linux I have:</p>

<pre><code>bash-5.0$ php -v


PHP 7.4.1 (cli) (built: Dec 19 2019 00:29:31) ( ZTS )

Copyright (c) The PHP Group

Zend Engine v3.4.0, Copyright (c) Zend Technologies

with Zend OPcache v7.4.1, Copyright (c), by Zend Technologies

bash-5.0$
</code></pre>

<p>So with PHP 7.4.1 that's quite adequate to work for say CodeIgniter 4 or Symfony.</p>

<p>Since around 5.5 PHP came with its dev server you can simply do PHP development on your Desktop.</p>

<p>If for instance I download and unzip the latest CodeIgniter, cd into it and run this command:</p>

<pre><code>bash-5.0$ php spark serve

CodeIgniter CLI Tool - Version 4.0.3 - Server-Time: 2020-07-03 06:08:42am

CodeIgniter development server started on `http://localhost:8080`
</code></pre>

<p>Press Control-C to stop.</p>

<pre><code>[Fri Jul 3 12:08:42 2020] PHP 7.4.1 Development Server (http://localhost:8080) started
</code></pre>

<p>I am up and running and can see the landing page at <code>http://localhost:8080</code></p>

<p><img src="https://phpocean.com/assets/images/forum-uploads/de56d459c998c14d57b76a3c4a12d5e0.png" alt="PHP Development server"></p>

<p>As I previously said its best to develop in as near to as your live environment will be so maybe apache might be more appropriate. Also, MySQL needs a database server so you can't use MySQL with the above method but what you can do is easily use sqlite3.</p>

<p>I have a few projects I'm working on and one risk leaving things on the Desktop is that they are easily likely to be wiped.</p>

<p>Developing PHP on Linux in the apache web server is not that complicated; I have it set up so that each project has its own directory located at var/www/htdocs</p>

<blockquote>
  <p>|- htdocs</p>
  
  <p>|-- CI</p>
  
  <p>|-- gbn</p>
  
  <p>|-- ginabrookes</p>
  
  <p>|-- ginbrookes</p>
  
  <p>|-- index.php</p>
  
  <p>|-- mysymfony</p>
</blockquote>

<p>I access via a web page and via a set up using <code>httpd-vhosts.conf</code> file.</p>

<p>Basically, I give each project a different Local host address so that I can directly access each project</p>

<p>such as :</p>

<pre><code>127.0.0.2

127.0.0.3
</code></pre>

<p>In <code>httpd-vhosts.conf</code> file, I could do:</p>

<pre><code>&lt;VirtualHost 127.0.0.7:80&gt;

ServerName ginabrookes.com

ServerAlias www.ginabrookes.com

DocumentRoot "/var/www/htdocs/ginabrookes/public"

&lt;Directory "/var/www/htdocs/ginabrookes/public&gt;

Order allow, deny

Allow from All

AllowOverride All

Require all granted

&lt;/Directory&gt;

&lt;/VirtualHost&gt;
</code></pre>

<p>Or by editing I can use a domain name in the web address bar by matching IP to a name.</p>

<h3>For loopbacking.</h3>

<pre><code>127.0.0.1 localhost

127.0.0.1 darkstar.citreon.org darkstar

127.0.0.2 CI.org

127.0.0.6 ginbrookes.com

127.0.0.7 ginabrookes.com
End of hosts.
</code></pre>

<p>There are some quirks to editing the development code since files within the system that are not in your usual userspace come under root or apache.</p>

<p>Maybe I can address that at another time.</p>

<p>When you first use Linux as a "normal" user; it's not so bad; everything
is there from the menu such as Firefox and generally everything works no problem. You can create documents, open them later, and edit - no problem. Everything is fine in your "normal user space".</p>

<p>Then one day like being in some old mansion you get inquisitive and start to look into other areas, but you find all the doors locked. You try to do something and get a "permission denied" you start feeling like your under "house arrest" and maybe a panic attack coming on.</p>

<p>Well, that's one way of looking at it. Basically, everything outside your normal userspace comes under <code>root</code> or other labels.</p>

<p>Apache webserver is located in the central system, not in your user
space; this is probably one of the main bugs bears Windows users will
have.</p>

<p>If you have a PHP framework inside at directory say called my "mydev",
located at <code>/var/www/htdocs/mydev</code> then you are going to get a shock 
when you open up say a PHP class and edit something- you can't do it
because you don't have permission to do so.</p>

<p>In a nutshell, Linux is a multi-user system; it's designed so that users
don't wander into unknown territory and mess up the whole system.</p>

<p>So if you have web dev in Apache web server and can't edit the code
then how do you get around it?</p>

<p>Well if you look in <code>/etc/httpd/httpd.conf</code> you will find what Apache
runs as in terms of who owns it and under whose permission it runs
under.</p>

<p>Generally, you should see :</p>

<pre><code>user: Apache
group: Apache
</code></pre>

<p>So maybe your know thinking "oh I see it's like one of those poncy
exclusive golf clubs" - I can't get in unless I'm a member!</p>

<p>Sort of.</p>

<p>So say your user name is "andrew" how does andrew get into the
exclusive "apache" club? well, you can run this command:</p>

<pre><code># usermod -a -G apache andrew
</code></pre>

<p>That code will keep all the existing groups andrew belongs to but also, add andrew to the "apache" group.</p>

<p>To make sure your "mydev" is set up
you can run:</p>

<pre><code>bash-5.0# chown apache:apache mydev -R
bash-5.0# chmod 775 mydev -R
</code></pre>

<p>What <code>chmod 775</code> means is that the owner can read, write and execute and the group can do the same - that means that since user Andrew belongs to the Apache group he can now edit code no problem.</p>

<p>The 5 at the end of 775 means everybody else but owner and group. They can read the code, run it but they can't change the code.</p>

<p>Linux permission is a subject in itself. Of course, all this seems
complicated but just like some club that does car mechanics
if you have some guiding hand at a Linux group, it will all be clear.</p>

<p>Apart from maybe seeming complex to start with, Linux has benefits and
features:</p>

<p>It's a very robust system that can cope with erratic "dumsor" in Ghana
generally, you don't have to worry about viruses. There is an Aladdin's cave of software you can add to your system free.</p>

<p>Unlike Windows where you have the choice of either cloned and
very likely insecure system or pay every two years for a new OS; you can
upgrade your Linux system.</p>

<p>Once you get into Linux, then open software is at your door.
Then a brave new world beckons of getting involved with others on coding projects.</p>

<p>Also with Linux, you can …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://phpocean.com/tutorials/computer-skills/web-development-on-gnu-linux/69">https://phpocean.com/tutorials/computer-skills/web-development-on-gnu-linux/69</a></em></p>]]>
            </description>
            <link>https://phpocean.com/tutorials/computer-skills/web-development-on-gnu-linux/69</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738681</guid>
            <pubDate>Sun, 05 Jul 2020 13:58:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lost in Transition: How I'm Fixing My To-Do List]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738567">thread link</a>) | @dickiebush
<br/>
July 5, 2020 | https://www.dickiebush.com/articles/lost-in-transition-todo-list | <a href="https://web.archive.org/web/*/https://www.dickiebush.com/articles/lost-in-transition-todo-list">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="44" id="block-cf6e5a3f19c5dee8c56a"><div><p>I love a crisp to-do list.</p>
<p>Cracking open my notebook, I'm greeted by the column of unchecked boxes set the night before. I’m motivated by the potential for a day well-spent.</p>
<p>"Today's the day I get it all done," I say.</p>
<p>The morning always starts well. Coffee in-hand, I dive head-first into the first task with excitement. Because it's at the top of the list, it always gets done.</p>
<p>It's after this first checkmark goes into my notebook that my day starts to wobble. The rest of the day whizzes by in a blur. As the day comes to a close, the list of unchecked boxes glares back at me.</p>
<p>I've been thinking more about why this happens. And what I've found is single tasks get are easy to do. It's the transition between tasks when things start to crumble.</p>
<p>If I was able to check a box and move onto the next one, I would get through my list every time.</p>
<p>But checking a box usually comes with a break. And that breaks leads me to Twitter. And Twitter can lead me anywhere. </p>
<p>Before I know it, I'm lost in transition.</p>

<p>I lose myself in transition for three reasons:</p>
<ol>
<li>The next to-do is vague</li>
<li>The next to-do uses a different kind of thinking</li>
<li>The list itself is too long</li>
</ol>
<p>When the next task is vague, it can be intimidating. So I've started being very specific with the exact action that gets the task started.</p>
<p>Instead of "☐ Write Blog Post" I scribble "☐ Open Notion and Brainstorm Three Sentence Ideas."</p>
<p>When the next task uses a different kind of thinking, there is a high start-up cost. Switching from programming to writing looks doable on paper, but never works out in practice.</p>
<p>So I've started grouping together tasks which require the same way of thinking. I then structure my day around these groups, slotting the tasks accordingly. I'm most creative and productive early in the morning, but more thoughtful and analytical in the afternoon. When I'm through my morning creative tasks, I'll take a long walk and get ready for the analytical part of my day.</p>
<p>Finally, when the list is too long, I sometimes give up entirely. There are few more ambitious people than my 9 PM self setting my intentions for the next day. So recently I've started splitting my list into two lists — a "have-to-do" and a "nice-to-do."</p>
<p>The "have-to-do" is always shorter than the "nice-to-do." As long I check off each of the "have-to-dos," I feel good at the end of the day. Anything from the "nice-to-do" is just bonus points.</p>
<p>The last thing I'm doing when my list is too long is to simply shorten it. I look the list up and down, find the two lowest leverage tasks, and cross them out. It always pains me to do this, but I know it's the right thing to do. </p>

<p>We all want to get more done. If you experience similar feelings about your to-do list, give these tactics a try. The subtle changes have made me more effective and leave me closing each day a bit more fulfilled.</p>
</div></div></div>]]>
            </description>
            <link>https://www.dickiebush.com/articles/lost-in-transition-todo-list</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738567</guid>
            <pubDate>Sun, 05 Jul 2020 13:41:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The most logical explanation is that it comes from a laboratory]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 18 (<a href="https://news.ycombinator.com/item?id=23738545">thread link</a>) | @markdog12
<br/>
July 5, 2020 | https://www.minervanett.no/corona/the-most-logical-explanation-is-that-it-comes-from-a-laboratory/361860 | <a href="https://web.archive.org/web/*/https://www.minervanett.no/corona/the-most-logical-explanation-is-that-it-comes-from-a-laboratory/361860">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

            <section>

                
                <div>

    

            <h2>NYHET</h2>



        

        

            <h3 itemprop="description">
            The well-known Norwegian virologist Birger Sørensen and his colleagues have examined the corona virus. They believe it has certain properties which would not evolve naturally. These conclusions are politically controversial, but in this interview he shares the findings behind the headlines.
            </h3>

    

</div>


                <div><p>“I understand that this is controversial, but the public has a legitimate need to know, and it is important that it is possible to freely discuss alternate hypotheses on how the virus originated” Birger Sørensen starts to explain when Minerva visits him in his office one morning in Oslo.</p><p>Despite the explosiveness of his statements and research, Sørensen remains calm and collected.</p><p>Sørensen has been a point of controversy ever since former MI6 director Richard Dearlove cited a yet to be published article by Sørensen and his colleagues in an interview with The Daily Telegraph. The article claims that the virus that causes Covid-19 most likely has not emerged naturally.</p><p>“It’s a shame that there has already been so much talk about this, because I have yet to publish the article where I put forward my analysis”, Sørensen says in the form of an exasperated sigh.</p><p>Together with his colleagues, Angus Dalgleish and Andres Susrud have authored an article that looks into the most plausible explanations regarding the origins of the novel coronavirus. The article builds upon an already published article in the Quarterly Review of Biophysics that describes newly discovered properties in the virus spike protein. The authors are still in dialogue with scientific journals regarding an upcoming publication of the article.</p><p>News outlets are thus confronted with a difficult question: Are the findings and arguments Sørensen and his colleagues put forward of a sufficiently high quality to be presented and discussed in the public sphere? Sørensen explains that they in their dialogue with scientific journals are encountering a certain reluctance to publishing the article – without, however, proper scientific objections. Minerva has read a draft of the article, and has after an overall assessment decided that the findings and arguments do deserve public debate, and that this discussion cannot depend entirely on the publication process of scientific journals.</p><p>In this interview with Minerva, Sørensen therefore puts forward his hypothesis on why it is highly unlikely that the coronavirus emerged naturally.</p><p>On May 18th, WHO decided to conduct an inquiry into the coronavirus epidemic in China. Sørensen believes that it is important that this inquiry looks into new and alternate explanations for how the virus originated, beyond the already well-known suggestion that the virus originated in the Wuhan Seafood Market.</p><p>“There are very few who still believe that the epidemic started there, so as of today we have no good answers on how the epidemic started. Then we must also dare to look at more controversial, alternative explanations for the origin,” Sørensen says.</p><p>Birger Sørensen and one of his co-authors, Angus Dalgleish, are already known as HIV researchers par excellence.</p><p>In 2008, Sørensen’s work came to international <a href="https://www.dagensperspektiv.no/2008/norsk-firma-med-hiv-gjennombrudd">attention</a> when he launched a new immunotherapy for HIV. <a href="https://www.nature.com/search?author=%22Angus%20G.+Dalgleish%22">Angus Dalgleish</a> is the professor at St. George’s Medical School in London who became world famous in 1984 after having <a href="https://www.nature.com/articles/312763a0">discovered</a> a novel receptor that the HIV virus uses to enter human cells.</p><p>The purpose of the work Sørensen and his colleagues have done on the novel coronavirus, has been to produce a vaccine. And they have taken their experience in trialling HIV vaccines with them to analyse the coronavirus more thoroughly, in order to make a vaccine that can protect against Covid-19 without major side effects.</p><h2>Exceptionally well adjusted</h2><p>“The difference between our approach and other vaccine manufacturers is that we have a chemistry background, and we analyse the virus in detail as if we were making a drug,” Sørensen starts to explain.</p><p>“Biology is also chemistry, so by considering the virus from a chemistry perspective, we carry out more detailed analysis, zooming in on certain components.”</p><p>Sørensen takes us through the basic elements of their approach:</p><p>“The first thing you need to establish is which parts of the virus are changing, and which parts are stable. If you want to make a vaccine that lasts, you must stimulate the immune system to react against those parts of the virus that are constant, otherwise the effect will disappear and, in the worst-case scenario, lead to increased illness.</p><p>“Once we know this, we can try to make a vaccine. Where we differ is that we are trying to make a vaccine that uses elements that have as little in common with the body’s natural components as possible, so that the immune system is taught to recognise exactly what the vaccine should protect against”, Sørensen elaborates.</p><p>Sørensen believes this is an important insight which will prevent the immune system from being falsely stimulated in a way that could lead the vaccine to create too many dangerous side effects in the vaccinated person.</p><p>“When we have not succeeded in creating an HIV vaccine, despite the enormous efforts put into that endeavour for the past 30 years, it is because we haven’t understood this,” Sørensen continues.</p><p>He believes that there has not been enough interaction between the part of the pharmaceutical industry that makes HIV medicines and the part that runs the vaccine research. As a consequence, the knowledge you need to make a successful vaccine against HIV in the big pharmaceutical companies has not been adequately exploited by the big, international HIV preventing vaccine studies that have been carried out.”</p><p>Asked about what significance his approached has had when he has analyzed the coronavirus, Sørensen explains:</p><p>“We have examined which components of the virus are especially well suited to attach themselves to cells in humans. And we have done this by comparing the properties of the virus with human genetics. What we found was that this virus was exceptionally well adjusted to infect humans.”</p><p>He pauses for a second.</p><p>“So well that it was suspicious,” he adds.</p><h2>Perfected to infect humans</h2><p>It is already known that the novel coronavirus, like the virus that caused the SARS epidemic in Southeast Asia in 2002-2003, could attach itself to the ACE-2 receptors in the lower respiratory tract.</p><p>“But what we have discovered is that there are properties in this new virus which enables it to use an additional receptor, and create a binding to human cells in the upper respiratory tract and the intestines which is strong enough to produce an infection,” Sørensen elaborates.</p><p>Sørensen says that it is the use of this additional receptor that most likely results in a different illness in Covid-19 patients than the one resulting from SARS.</p><p>“This is what enables the virus to transmit to a greater degree between humans, without the virus having attached itself to the ACE-2 receptors in the lower respiratory tract, where it causes deep pneumonia.</p><p>“That is also why so many of the Covid-19 patients have mild symptoms at the start of the illness, and are contagious before they develop severe symptoms,” he adds.</p><p>It might also explain why some people are ‘super spreaders’ without being ill themselves, Sørensen says.</p><p>In the already published article Sørensen and his colleagues Angus Dalgleish and Andres Susrud describe what they claim is curious about the spike protein of the coronavirus, which makes it especially well suited to infect humans. These findings are the foundation for the hypothesis Sørensen and his colleagues develop in the new article, where they claim that the virus is not natural in origin.</p><div id="factbox-361864">
    <div>
        
        <h2>FACT BOX – Spike Protein</h2>
        <p>A spike protein is a part of the virus attached to the surface of the virus. The spike protein is used by the virus when it enters cells, enabling it to stick in humans. The properties of the spike determines which receptors a virus can utilise and thus which cells the virus can enter to create illness.</p>
        
    </div>
    
</div><p>“There are several factors that point towards this,” says Sørensen. “Firstly, this part of the virus is very stable; it mutates very little. That points to this virus as a fully developed, almost perfected virus for infecting humans.</p><p>“Secondly, this indicates that the structure of the virus cannot have evolved naturally. When we compare the novel coronavirus with the one that caused SARS, we see that there are altogether six inserts in this virus that stand out compared to other known SARS viruses,” he goes on explaining.</p><p>Sørensen says that several of these changes in the virus are unique, and that they do not exist in other known SARS coronaviruses.</p><p>“Four of these six changes have the property that they are suited to infect humans. This kind of aggregation of a type of property can be done simply in a laboratory, and helps to substantiate such an origin,” Sørensen points out.</p><h2>An artificially created virus</h2><p>Asked about whether this implies that the virus is not natural, Sørensen goes on to explain the laboratory process that leads to the creation of new viruses.</p><p>“In a sense it is natural. But the natural processes have most likely been accelerated in a laboratory,” he explains. “It’s also possible for a virus to attain these properties in nature, but it’s not likely. If the mutations had happened in nature, we would have most likely seen that the virus had attracted other properties through mutations, not just properties that help the virus to attach itself to human cells.”</p><p>Sørensen vividly explains this argument:</p><p>“Imagine that you have cultivated a billion coronaviruses you have gathered from nature, then you take this mass of viruses and inject them into a human cell culture from for example the upper respiratory tract. As a result, a few of these viruses will change in order to better attach themselves to …</p></div></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.minervanett.no/corona/the-most-logical-explanation-is-that-it-comes-from-a-laboratory/361860">https://www.minervanett.no/corona/the-most-logical-explanation-is-that-it-comes-from-a-laboratory/361860</a></em></p>]]>
            </description>
            <link>https://www.minervanett.no/corona/the-most-logical-explanation-is-that-it-comes-from-a-laboratory/361860</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738545</guid>
            <pubDate>Sun, 05 Jul 2020 13:38:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New revamped version of the AnyMeal recipe management software]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 29 (<a href="https://news.ycombinator.com/item?id=23738543">thread link</a>) | @wedesoft
<br/>
July 5, 2020 | https://www.wedesoft.de/software/2020/06/30/anymeal/ | <a href="https://web.archive.org/web/*/https://www.wedesoft.de/software/2020/06/30/anymeal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.wedesoft.de/software/2020/06/30/anymeal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738543</guid>
            <pubDate>Sun, 05 Jul 2020 13:37:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tatsuo Horiuchi is painting pictures on PC with MS EXCEL]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23738479">thread link</a>) | @donbox
<br/>
July 5, 2020 | http://pasokonga.com/index.htm | <a href="https://web.archive.org/web/*/http://pasokonga.com/index.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>順次パソコン画をUPしていきますのでよろしくお願いいたします<br>
When you want to see lager picture , click the  paintings listed hereunder.<br>
<b><span color="#ff0000" size="2">The pictures shown on this site are "ExcellArt"by TatsuoHoriuchi,<br>
which were drawn and painted with Excel suported on PC originaly,</span><span color="#ff0000" size="3"><br>
</span><span color="#ff0000" size="2">and were re-formatted(rasterized) into JPG for the data-compression.</span></b><br>
And w<span size="4">hen you wont to contact T.Horiuchi, please click mailto; </span><i><b><span size="4" color="#ff0000"><a href="mailto:cbl97790@pop06.odn.ne.jp">pasokongaka</a></span></b></i><br>
</p><div>
  <div>
    <p><b><span lang="EN-US">If you want such small size copy  as size:A3(42cm</span>＊<span lang="EN-US">29.7cm),it is possible to print on A3size paper and to ship.<o:p></o:p></span></b></p>
    <p><b><span lang="EN-US">and the price of this is JP\6500, and the cost of air parcel will be JP\3500.<o:p></o:p></span></b><b><span lang="EN-US"><o:p>&nbsp;</o:p></span></b></p>
    <p><span lang="EN-US">we will send the invoice by e-mail through PayPal system according to
    your information which picture you want to buy.<o:p></o:p></span><span color="#000000" size="4"><b>

<br>
    </b></span></p></div>
</div></div>]]>
            </description>
            <link>http://pasokonga.com/index.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738479</guid>
            <pubDate>Sun, 05 Jul 2020 13:27:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Top 3 Reasons Why Your Side-Projects Fail (As A Programmer)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738458">thread link</a>) | @yassinerajallah
<br/>
July 5, 2020 | https://devhypercharged.com/the-top-3-reasons-why-your-side-projects-fail-as-a-programmer/ | <a href="https://web.archive.org/web/*/https://devhypercharged.com/the-top-3-reasons-why-your-side-projects-fail-as-a-programmer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
			
<p>The road to creating the first successful startup / side-project is spiky. The reasons for you to fail are endless and the reasons to win are complex. How can you get your next big thing? And what is stopping you from achieving it as a software developer?</p>
<p>As a senior undergrad and aspiring entrepreneur, I created over 7 projects over the past 3 years. All of them miserably failed and lessons were learned the hard way. You don’t have to go through the same experience to learn the same lessons, here is the final summary of my 3 years journey</p>
<h2><strong>1 – Build and launch</strong></h2>
<p>This might sound trivial, but you actually need to launch. No, you don’t need the best looking product out there to be able to compete, and yes you can find people interested in your product specifically. The internet is an endless source of attention, wherever you go, there is at least 1 person that wished for a solution to a problem you are solving. If the problem you are solving isn’t a priority for the end consumer, you will know. Your project can only grow as much as you believe it can. You are the ship captain and you are the god of that little project, make it or kill it.</p>
<p>In my countless attempts to build a unicorn (jargon for a startup valued at at least $1B) I often never understood why my project was going to work or fail so I quit. Fun fact, soon after, people made it with the same exact idea. I often acted out of ambition, and needless to say, resilience is what gets you to success. The more you endure, the closer you get to where you want.</p>
<p>Before even launching your solution to a problem, think of what approach you are adopting:</p>
<p><strong>Product focused approach:&nbsp;</strong>Your sole purpose is the product, you forget about the market because you are sure the product solves the problem for some people out there. So you strive to make the best UI/UX product out there. The initial time investment makes the approach high-risk high-reward. Personally, I’m not a big fan, if you don’t know someone who can build an optimized and off the charts UI/UX product design, maybe you want to let this one approach down. You’d be better off with having an MVP (minimal viable product) a product with core features only.</p>
<p><strong>Market focused approach:</strong>&nbsp;This approach is the low-risk high-reward investment. You iterate crazy fast over multiple ideas and see what sticks. You can literally skip building a product, set up a landing page, and start talking to people. This approach is not easy either because it will require building your communication skills and learning how to ask questions. I recommend reading ‘The Mom Test’ for this purpose.</p>
<p>This approach is more secure since there is no upfront investment, and if you are building something not wanted, you’ll know it. You will for sure. On the other side, you are building a product with the community, so even though you are working on the project solo or duo, in practice you aren’t, since you get help as much as you talk to users.</p>
<h2><strong>2 – Build but listen</strong></h2>
<p>If you are building a high-end or low-end product, you want to keep talking to people. Think of it this way: You are sailing a ship at 1 in the morning, darkness is your refuge, and there is a storm. Your only way out is to look at the stars. But there are no stars! In this context, your users are your stars, no matter how much you shy away you’ll end up hurting yourself. No matter how confident you are building the right thing, you are putting your confidence into a reality check.</p>
<p>Some developers aren’t comfortable talking to people while others can: Fun fact, you still need to do it. And it’s only a matter of time until you realize that your end users are people like you because you are solving the problem for yourself, to begin with.</p>
<p>Main take away: build a rocket ship or a cookie, you still need to talk to users. Crazy how many people don’t do it and end up wasting 5 – 7 months of development (yup that’s me)</p>
<h2><strong>3 – Manage but learn</strong></h2>
<p>One of your duties as a software developer is switching hats – You didn’t sign up for this did you- One time you’ll act as the technical guru of the project and another you’ll need to make business decisions. Your project is a bottle in a sea, who will even notice it? Forget money, for the time being, no ads, no paid marketing. First, you need to build your ‘business’ skills: promote your product, look at analytics, draw correlations between features and retention, bootstrapping, etc.. You don’t need me to mention all of the problems because they are countless, and this is what’s exciting! You’ll find yourself forgetting your code and reading a huge stack of articles on how to promote your product.</p>
<p>Playing the business person is overwhelming, that’s why it is advised to have a cofounder. Finding one isn’t easy but doable. Sharing the tasks never exempts you from learning the business side of things but at least will lift off some pressure.</p>
<p>As a business person, you don’t want to be stiff, stubborn, or sensitive! If your decision is bad and someone told you, then guess what: you found a valuable member for the project. Not anyone dares to criticize a friend’s product, and the faster you acknowledge your mistakes, the faster you learn, the higher you climb toward your long-waited goal. Obviously, I’m not implying that you should always say you are wrong even if you don’t believe so.</p>
<p>Finally, read! Okay this is probably the best piece of information there is on this article. As cheesy as it might sound, reaaaaaaad!!!! It opens doors you never knew existed. In fact, you can play a game – what I did and had instantaneous results – curate 5 to 6 high detail articles about 1 niche topic. Read all of them and highlight what you find important. Guess what, you are now in the top 1% of your competitors in that specific niche.</p>
<p>If you found this article helpful share it with 1 person that you believe will learn from it, keep the flow of positivity and information going. Thank you sooooo much for reading this. Until the next time, bye 🙂</p>

			
			
</div></div>]]>
            </description>
            <link>https://devhypercharged.com/the-top-3-reasons-why-your-side-projects-fail-as-a-programmer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738458</guid>
            <pubDate>Sun, 05 Jul 2020 13:22:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remap Enter to Control in GNU/Linux (2020 Edition)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738344">thread link</a>) | @todsacerdoti
<br/>
July 5, 2020 | http://emacsredux.com/blog/2020/07/05/remap-enter-to-control-in-gnu-linux-2020-edition/ | <a href="https://web.archive.org/web/*/http://emacsredux.com/blog/2020/07/05/remap-enter-to-control-in-gnu-linux-2020-edition/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><strong>Note:</strong> Check out my <a href="http://emacsredux.com/blog/2013/11/12/a-crazy-productivity-boost-remap-return-to-control/">original article from 2013</a> about the rationale behind this remapping.</p>

<p>Recently I’ve switched back from macOS to GNU/Linux, as my primary development
environment, and I found out that my <a href="http://emacsredux.com/blog/2016/01/30/remap-return-to-control-in-gnu-slash-linux/">old article</a> on remapping <code>Enter</code>
to <code>Control</code> was no longer the optimal way to achieve this (e.g. - <code>xcape</code>
operates at the X level, which means it doesn’t work with Wayland or without a
GUI). It took me a bit of digging, but eventually I found
<a href="https://gitlab.com/interception/linux/plugins/dual-function-keys">dual-function-keys</a>
(a plugin for the <a href="https://gitlab.com/interception/linux/tools">interception
framework</a>), which does exactly
what I needed and it does it splendidly.</p>

<p>Unfortunately, the tool is not packaged for most
GNU/Linux distros<sup id="fnref:1"><a href="#fn:1">1</a></sup>, but setting it up from source is not that complex. In this article
I’ll share instructions that are specific to Ubuntu, but they should be
easy to modify for other Linux distros.</p>

<p>Let’s kick it off by downloading and installing the <code>interception</code> framework and
<code>dual-function-keys</code>:</p>

<pre><code># install build deps
$ sudo apt install libudev-dev libyaml-cpp-dev libevdev-dev cmake
# create a folder where to clone the source code
$ mkdir src &amp;&amp; cd src
# clone the necessary code
$ git clone https://gitlab.com/interception/linux/tools
$ git clone https://gitlab.com/interception/linux/plugins/dual-function-keys
# build and install the interception framework
$ cd tools
$ mkdir build
$ cd build
$ cmake ..
$ make
$ sudo make install
$ cd ../..
# build the dual-function-keys plugin
$ cd dual-functions-keys
$ make &amp;&amp; sudo make install
</code></pre>

<p>That wasn’t so hard, right? Now we have to create a couple of configuration files and we’re ready for action. The first one is <code>.dual-function-keys.yaml</code> (normally placed in your home folder):</p>

<div><div><pre><code><span># /home/username/.dual-function-keys.yaml</span>
<span>TIMING</span><span>:</span>
  <span>TAP_MILLISEC</span><span>:</span> <span>200</span>
  <span>DOUBLE_TAP_MILLISEC</span><span>:</span> <span>150</span>

<span>MAPPINGS</span><span>:</span>
  <span>-</span> <span>KEY</span><span>:</span> <span>KEY_ENTER</span>
    <span>TAP</span><span>:</span> <span>KEY_ENTER</span>
    <span>HOLD</span><span>:</span> <span>KEY_RIGHTCTRL</span>
</code></pre></div></div>

<p>That’s the main config for <code>dual-function-keys</code>, where we’re specifying the duration of a tap and double tap and our remapping rules. In our case there’s a single rule - <code>Enter</code> acts as <code>Enter</code> on tap (when pressed briefly) and as (right) <code>Control</code> when held down longer.</p>

<p>Then we need to create <code>/etc/udevmon.yaml</code> (you’ll need <code>sudo</code> for this):</p>

<div><div><pre><code><span># /etc/udevmon.yaml</span>
<span>-</span> <span>JOB</span><span>:</span> <span>"</span><span>intercept</span><span> </span><span>-g</span><span> </span><span>$DEVNODE</span><span> </span><span>|</span><span> </span><span>dual-function-keys</span><span> </span><span>-c</span><span> </span><span>/home/bozhidar/.dual-function-keys.yaml</span><span> </span><span>|</span><span> </span><span>uinput</span><span> </span><span>-d</span><span> </span><span>$DEVNODE"</span>
  <span>DEVICE</span><span>:</span>
    <span>EVENTS</span><span>:</span>
      <span>EV_KEY</span><span>:</span> <span>[</span><span>KEY_ENTER</span><span>,</span> <span>KEY_RIGHTCTRL</span><span>]</span>
</code></pre></div></div>

<p><strong>Note:</strong> Update the path the <code>.dual-function-keys.yaml</code> accordingly.</p>

<p>Finally we need to create a <code>systemd</code> service definition file for <code>udevmon</code> and start the new service:</p>

<div><div><pre><code><span># /etc/systemd/system/udevmon.service</span>

<span>[</span><span>Unit</span><span>]</span>
<span>Description=udevmon</span>
<span>Wants=systemd-udev-settle.service</span>
<span>After=systemd-udev-settle.service</span>

<span>[</span><span>Service</span><span>]</span>
<span>ExecStart=/usr/bin/nice -n -20 /usr/local/bin/udevmon -c /etc/udevmon.yaml</span>

<span>[</span><span>Install</span><span>]</span>
<span>WantedBy=multi-user.target</span>
</code></pre></div></div>

<p>Now we simply have to enable the <code>udevmon</code> service our remapping will kick in:</p>

<pre><code>$ sudo systemctl enable --now udevmon
</code></pre>

<p>That’s all! Now you can start enjoying your beloved productivity boost!</p>

<p>You can achieve a lot more with <code>dual-function-keys</code>, so I’d advice you to explore the
tool further. Keep hacking!</p>

<h2 id="alternatives">Alternatives</h2>

<p>Another option I considered was <a href="https://github.com/mooz/xkeysnail">xkeysnail</a>, which
seemed a bit simpler to setup, as it’s written in Python, and even has an <a href="https://github.com/mooz/xkeysnail/blob/master/example/config.py">example config geared towards Emacs users</a>. You might want to check it out.</p>

<p>If someone’s using another approach to achieve the same result I’d love to hear about it!</p>



  </div>
  
  
</article>

      </div>
    </div></div>]]>
            </description>
            <link>http://emacsredux.com/blog/2020/07/05/remap-enter-to-control-in-gnu-linux-2020-edition/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738344</guid>
            <pubDate>Sun, 05 Jul 2020 12:58:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Roam Research for Daily Productivity]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738309">thread link</a>) | @austinrileygray
<br/>
July 5, 2020 | https://www.austinrileygray.com/blog/roam-research-for-daily-productivity | <a href="https://web.archive.org/web/*/https://www.austinrileygray.com/blog/roam-research-for-daily-productivity">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>The Daily Routine</h2><p>Since making the switch to Roam for my productivity tool, I’ve started to enjoy the ease and simplicity of using the tool. Once I allocated time to develop a system that works for me within the tool, it streamlined my morning routine even more so than my last system in Notion. The greatest difference between the two systems is that I no longer have to store my daily notes page in any sort of hierarchy. Roam automatically saves a track record of my Daily Notes to the database, and they’re always searchable by date. On top of that, it’s also great to create pages on the fly with the [[]] keyboard shortcut for brain dumping thoughts around different topics / people / projects / strategies that come up while working. These pages are automatically saved to the database and are always searchable by topic/keyword as well.&nbsp;</p><div><p>Here's a screenshot of how I've been starting my days using my new productivity system in Roam:&nbsp;</p></div><figure id="w-node-1f15fb71f55a-83977b8e"><p><img src="https://uploads-ssl.webflow.com/5e0949b376f1c6bbe8b688cf/5f01cba0c33c889141c3a884_1rg6YpfCcukznlGOo47tYT9kplx8MGgbfu_BsPwrUMPZi_LwR_Ry1BjMyFlnCpldvSn6Wg7ZdCchsuUNaIQ-SJNooEEJGmz2ucQIRs11Meek7Ku--W3F1crKMvswN4-NPb92-Hwr.png" alt=""></p></figure><p>As you can see, I've saved this “Daily Routine” template as a favorite in my sidebar so that I can easily access this routine each morning when I begin my workday. The first thing I do when getting to my desk is copy this structure into my "Daily Notes" page. If you're not familiar with Roam yet, the tool automatically creates a new page each day under "Daily Notes." I'll break down each section of my Daily Routine below.&nbsp;<br></p><h3>Ramp Up</h3><p>This section consists of some daily habits I like to complete each morning to get my mind right for the work day. I start with 10 mins of meditation, move into a super quick workout with some pushups and situps to spark some good endorphins, write out what I'm thankful for, and finish by defining the most important project that I need to focus on. This process takes roughly 15 mins from start to finish. Once I'm done, I move directly into my Productive Cycle.<br></p><h3>Productive Cycle</h3><div><p>I've been geeking out on Deep Work since finishing the book in Q1. Through months of testing and iterations, I’ve developed a system that allows me to move the needle on my projects in an undistracted setting. Within my "Productive Cycle," I aim for 3 separate "Power Hours." This allows focused space and time to move projects forward first thing in the morning. By doing this at the beginning of my workday, I can dedicate the remainder of the day to the "shallow work" such as answering emails, jumping on zoom calls, and customer support. When I'm ready to begin each Power Hour, I expand the bullet point within Roam and begin answering the questions I’ve pre-programmed in the template shown below:</p></div><figure id="w-node-a26275288014-83977b8e"><p><img src="https://uploads-ssl.webflow.com/5e0949b376f1c6bbe8b688cf/5f01cba0dc9b2d35c5563a4d_Xe5t7sLEYqrXeMbp1r5WRoEynfcdmg85zqSnhpdiOTVV5KtQMTLIFyjPEo0QCFW4sXtJqlTw7p4vyhj0SmoBtDJL52ogVt3IK8tss4e3yTTF5HdEDQjt8zq3JpAVvbjLeclT4vFN.png" alt=""></p></figure><h4>Power Hours</h4><p>By answering the questions that I've pre-programmed for each Power Hour, I'm able to get crystal clear on exactly what I'm working on for the next hour. I've done some research and have learned that the brain can optimally focus for a a maximum time blocks of 45-52 minutes before needing a break. Therefore, I aim for 45 minutes of focus on the defined activity. Setting an alarm for your finish time does something to the brain to cut out any distractions that would take away from completing the activity. Even though the timer aspect has a profound effect on staying focused, it’s inevitable that some activities naturally require a few minutes over the allocated time block to complete. By setting the timer for 45 minutes, I’ve allowed for 7 minutes of buffer should the activity require extra time. Ultimately, by defining a time period for my work, I’m naturally more inclined to stay focused on the activity at hand.<br></p><h4>Planning &amp; Reflecting</h4><p>The planning portion takes roughly 2-3 mins before starting the actual focused work, and the "Reflect" section takes another 2-3 mins on the back end. If my project goes over the 45 minutes and runs closer to 52 minutes, this puts me really close to the 60 minute mark for the total session length.&nbsp;<br></p><p>By reflecting at the end of each Power Hour before my break, I can quickly capture what I completed and/or what still needs to be done to complete the defined activity. If I completed the activity, I use this time to write down what activity I should work on during the next Power Hour.<br></p><h4>Breaks</h4><p>When I complete each Power Hour, I take a 10 minute break to refill my coffee/tea and water bottle, use the restroom, and take a quick walk outside to get some Vitamin D and quickly check my phone to make sure nothing urgent is being requested from me.&nbsp;<br></p><p>I’ve noticed that there are some mornings where I’m so in the zone that breaks seem like a nuisance. But, I’ve been working to stay diligent in giving my brain a quick rest in between Power Hours and it seems to be working so far. Not only do breaks physically give your brain a rest, they also create clear stopping and starting points for different activities. AND, on top of that, breaks are a good time to add in some more pushups and situps to keep the blood flow moving :)&nbsp;</p><h4>Schedule</h4><p>I've been starting my Productive Cycle by jumping into my first Power Hour at 7 am so I can be done no later than 11 am.&nbsp; I’m aiming for 3 Power Hour sessions per morning, so after I add in the 10 minute breaks, it puts me finishing somewhere around 10:30am. Inevitably, I often get pulled into a request that needs my attention during a break, so I’ve been allowing the 30 minute buffer zone between 10:30 and 11 to make up for any lost time.<br></p><p>If you're interested in joining me in these Productive Cycle sessions, I've opened up a virtual link for others to join me and some other Green Spaces members via zoom. Send me an email to <a href="mailto:austinrileygray@gmail.com">austinrileygray@gmail.com</a> and let me know that you're interested in joining the Productive Cycle and I'll send over a free link to join the next cycle via Zoom. I’ve noticed an even greater amount of accountability and focus when doing these cycles with other movtivated individuals.&nbsp;<br></p><h3>Journal</h3><p>This is where I brain dump during the day. If I have a thought, idea, or to-do, this is the section where I place them. Creating to-do's in Roam is easy... all I have to do is type "/ todo" and click enter and a to-do is automatically created. I follow each to-do with /"today" "/tomorrow" or "/date picker" depending on which day I plan to complete the activity. This is nice because the to-do will show up on whichever day I assign it to in the daily notes filter.&nbsp;<br></p><h3>Reflect</h3><p>This is arguably the most important section of my daily routine and often the most neglected. With that being stated, reflecting on the day helps tremendously with knowing what I should be working on for the next day. When I take the time to complete this section, I'm laser focused on what needs to be done the next morning when starting my workday.&nbsp;<br></p><p>When I don't reflect at the end of the day, I end up wasting precious productive morning time thinking about what I need to work on when I'm starting the next day.&nbsp;<br></p><p>Moral of the story is: <strong>MAKE TIME TO REFLECT.</strong> This is as much of a reminder to myself as anything. It literally takes 5 minutes or less and is arguably the most valuable 5 minutes of each day.&nbsp;<br></p><h2>Conclusion</h2><p>Since incorporating this system into my daily routine, I can say with confidence that I've been more productive with my projects than I've ever been in my whole life. Completing my Productive Cycle first thing in the morning allows me to get what I need to get done before I get pulled into the daily whirlwind. It's great because I can dedicate the rest of the day to shallow work and being reactive without feeling bad about it. And working deeply is FUN and ENJOYABLE. I’m able to get into a state of "flow" that is hard for me to find outside of snowboarding or mountain biking.&nbsp;<br></p></div></div>]]>
            </description>
            <link>https://www.austinrileygray.com/blog/roam-research-for-daily-productivity</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738309</guid>
            <pubDate>Sun, 05 Jul 2020 12:53:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Solve problems more effectively by adopting a strategic mindset]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738231">thread link</a>) | @ChrisHardman29
<br/>
July 5, 2020 | https://www.sivv.io/article/5f01979d48951651ff15cb0b/Solve-problems-more-effectively-by-adopting-a-strategic-mindset | <a href="https://web.archive.org/web/*/https://www.sivv.io/article/5f01979d48951651ff15cb0b/Solve-problems-more-effectively-by-adopting-a-strategic-mindset">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.sivv.io/article/5f01979d48951651ff15cb0b/Solve-problems-more-effectively-by-adopting-a-strategic-mindset</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738231</guid>
            <pubDate>Sun, 05 Jul 2020 12:38:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Terminal illness: useful tips for being productive in the terminal]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738202">thread link</a>) | @ingve
<br/>
July 5, 2020 | https://www.selbekk.io/blog/2020/07/useful-tips-for-being-productive-in-the-terminal/ | <a href="https://web.archive.org/web/*/https://www.selbekk.io/blog/2020/07/useful-tips-for-being-productive-in-the-terminal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Just a disclaimer - I'm no terminal professional. Yet, over the 7 last years, I've learned a few very nice-to-know techniques that you might not have heard of. There's no guarantee that you'll learn anything from this, but a pretty bit chunk of my readers might learn at least a thing or two.</p><blockquote>A little side note here - these commands are meant for OSX only. They might work on Linux or WLS, but I haven't tried them out.</blockquote><h2>Use the clipboard!</h2><p>Every once in a while, you have some data in the clipboard that you want to use somehow, or you want to copy the output of a command into the clipboard. Either way - it's very possible to do!</p><p>So there are two commands you need to know - <code>pbcopy</code> and <code>pbpaste</code>. You can use them together with the pipe operator <code>|</code> and the "to file" operator <code>&gt;</code> to do really cool stuff. Here's a few examples:</p><p>To paste whatever is in your clipboard into a new file - let's say ".env" - you can do this:</p><pre><code>$ pbpaste &gt; .env</code></pre><p>No more creating a new file, then opening it in vim or VSCode to paste and save - now you can just type a few characters and get the job done!</p><p>Similarly, if you want to copy a file to the clipboard, you use the pipe operator and <code>pbcopy</code>. This is how it looks:</p><pre><code>$ cat .env | pbcopy</code></pre><p><code>cat</code> echoes out the entire contents of a file (in this instance <code>.env</code>) and the pipe operator passes it as input to the <code>pbcopy</code> command. Voilá - now you can copy the content of entire files without opening them!</p><p>I use this all the time when I need to copy my ssh key and paste it into GitHub or BitBucket. </p><p>You don't have to limit yourself to files though - pbcopy is much more flexible than that. Whatever you pipe in can be placed on the clipboard - so if you want to copy the result of a program (let's say an encryption program or a password generator), you just pipe it on in.</p><h2>Doing more with <code>less</code></h2><p>I often use the tiny file reader program <code>less</code> to scan, search and read through files. It's really powerful if you know how to use it, but even if you're just using it for the first time, you can just use the arrow keys on your keyboard to scroll through files directly in the terminal.</p><p>Now, I use this mostly to read configuration files, and if I come across something I need to change, I've always had to close the file I was looking at, and open it in an editor like <code>vim</code>. </p><p>Luckily - you can just type <code>v</code>, and the default editor (typically <code>vim</code>) opens up, focused on the <em>same line you were at</em>. Once you close <code>vim</code> (provided you know how to close <code>vim</code>), you're placed back in the same spot as you were as well.</p><p>Also - you can go the start of the document with <code>g</code>, and to the end with <code>shift + g</code>. You can search for a phrase by tapping <code>/</code>, and typing out whatever you're looking for. Navigate through the occurrences by <code>n</code> (forward) and <code>N</code> (backwards). And there's a ton of other things you can do (which you can read about <a href="https://www.linode.com/docs/quick-answers/linux/how-to-use-less/">here</a>).</p><h2>Open files and folders with <code>open</code></h2><p>Often times, you stumble across a file you want want to open the file's default application. That might be a video, an audio clip or perhaps a CSV file. You could exit the flow you're in, of course, and use Finder to navigate to your file and double click it - but we can do better.</p><p>If you want to open any file, you can use the <code>open</code> command to get it done from the terminal:</p><pre><code>$ open videos/screen_recording.mp4
$ open package.json
$ open images/vacation.png</code></pre><p>I usually don't open a lot of files this way, but I do open folders! Just use <code>open</code> on any folder, and you'll get started right away!</p><pre><code>$ open ~/Documents
$ open . # opens the current folder</code></pre><h2>Some power characters!-</h2><p>There are two really nice characters to know when using the terminal, and those two are <code>-</code> and <code>!</code>. </p><p>The <code>-</code> character (dash, hyphen, whatever you call it) works well in two contexts. You can add it to the <code>cd</code> command to return to the previous directory you were in, and you can add it to <code>git checkout</code> to check out the previous branch you were on.</p><pre><code># Example of using cd -
~/Documents $ cd /usr/bin
/usr/bin $ cd -
~/Documents $

# Example of using git checkout -
(master) $ git checkout feature-branch
(feature-branch) $ git checkout -
(master) $</code></pre><p>The exclamation mark is also pretty neat - it lets you search the history of command you've done previously, or re-use the arguments to the last command you used.</p><pre><code>$ !cat
$ # shows you the last command you ran that started with cat

$ less a.txt b.txt
$ vim !* # opens a.txt and b.txt in vim

$ less a.txt b.txt
$ vim !$ # opens b.txt in vim</code></pre><p>It's a neat little trick that I know for some reason, but I never use. Perhaps you'll find some use for it though!</p><p>Much more usable, however is the double exclamation point! Especially in conjunction with the <code>sudo</code> command. If you've ever run a command and realized you had to run it as an administrator, you can simply do <code>sudo !!</code> and re-run it with sudo!</p><pre><code>$ chmod +x /usr/share/firmlinks
chmod: Unable to change file mode on /usr/share/firmlinks: Operation not permitted
$ sudo !!
$</code></pre><h3>Searching the command history</h3><p>Speaking of command history - you don't really need the ! command when you know about the Ctrl+R shortcut! Tap it once, and you'll be able to do an interactive autocomplete search of your entire command history!</p><h2>Oh my...</h2><p>Lastly, I want to talk about oh-my-zsh. Zsh (pronounced sea shell) is a popular alternative to the well known bash shell, and <code>oh-my-zsh</code> is a small framework that adds a ton of useful functionality, aliases and plugins to make your workflow as smooth as possible.</p><p>If you haven't installed it already, you can do so by visiting their <a href="https://ohmyz.sh/">home page</a>. Next, pop up <a href="https://github.com/ohmyzsh/ohmyzsh/wiki/Cheatsheet">this cheat sheet</a> and start learning. There's a ton of useful shortcuts for git (like <code>gst</code> for <code>git status</code> and <code>gc</code> for <code>git commit</code>), but also really nifty commands like <code>...</code> for navigating two directories up or <code>take deep/directory/tree</code> for creating a new directory and navigating into it.</p><p>In addition, there are tons of great themes and plugins available to make your terminal super powerful. I've had <code>oh-my-zsh</code> installed for years, and I just love it more for every passing day.</p><h2>Last words</h2><p>These are some of my favorite tips for being productive in the terminal. There are tons of stuff I've skipped - like how to grep or exit vim - but to be honest I don't use those a lot either. I hope you found at least one new technique to add to your roster - and that you promise to share your favorite commands with me on Twitter.</p></div></div></div>]]>
            </description>
            <link>https://www.selbekk.io/blog/2020/07/useful-tips-for-being-productive-in-the-terminal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738202</guid>
            <pubDate>Sun, 05 Jul 2020 12:30:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Financial Statements: A Beginner's Guide]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738148">thread link</a>) | @refrigerator
<br/>
July 5, 2020 | https://www.causal.app/blog/whats-a-financial-statement | <a href="https://web.archive.org/web/*/https://www.causal.app/blog/whats-a-financial-statement">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The finance world is quickly entering the mainstream —</p><p>Every month a notable company goes public. Every week a hot startup raises millions of dollars. And every day moms, pops, and teens check on their stocks. </p><p>Whether a company builds rocket engines or mobile apps, they tell their story using the same language —&nbsp;financial statements. Here's how they work.</p><p>Let's say you run a subscription t-shirt business.</p><p>It's going well — you have happy customers and healthy profit. You're thinking of buying your own factory to make more t-shirts, more quickly, and more cheaply.</p><p>There's just one problem — you can't afford a factory.</p><p>So, you ask the bank for a loan. Your company is profitable and the factory will pay for itself in 3 years, so you know you'll be able to pay it back. But while you know this, the bank doesn't — you'll need to convince them. The bank, however, doesn't know anything about the subscription clothing business.</p><p>To get on the same page, you need a shared language for talking about your business.</p><p><h4 id="heading-1">Double-entry Bookkeeping: The birth of accounting</h4></p><p>Double-entry bookkeeping was the first formalism in finance. The Middle East had it in the <a href="https://www.jstor.org/stable/40697986" target="_blank">first century AD</a>, Korea independently got it in the <a href="https://www.worldcat.org/issn/1598-2661" target="_blank">11th century</a>, and by the <a href="https://web.archive.org/web/20170627232023/http://130.74.92.202:82/record=b1000778" target="_blank">1500s</a>, it had been well-documented across Europe.</p><p>It's a simple concept designed to reduce errors when documenting transactions: every entry to an "account" requires an equal and opposite entry to another "account".</p><p>If you bought some cotton to turn into t-shirts, you might record the transaction like this:</p><p>‍</p><figure id="w-node-371c827e421c-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefde0379b53032713cde77_bookkeeping.png" alt=""></p></figure><p>‍</p><p>When you spend $100 on cotton, your "Cash" account gets debited (loses) $100, and your "Materials" account gets credited (gains) $100. The underlying principle is that <em>you can't create something out of nothing</em>.</p><p>This might seem contrived, but with more and more transactions, it can help you spot errors. Since every entry has an equal and opposite entry, the sum of all the debits should always equal the sum of all the credits. If not, you know you made a mistake, and you can look back through your transactions to find it.</p><p>A list of transactions is pretty interesting — it tells a very detailed story about what your company's been up to. Certainly enough to answer the bank's questions when you ask for loan.</p><p>But just as the bank doesn't have time to learn about subscription t-shirts businesses, they don't have time to go through thousands of transactions. To understand what's going on, they need a shorter summary.</p><p><h4 id="heading-2">Financial Statement #1: The Balance Sheet</h4></p><p>If you went through all your transactions and worked out the net value of each account, you'd be able to see things like</p><ul role="list"><li>How much cash you have in the bank</li><li>The total value of the cotton in your inventory</li><li>How much money you owe to your cotton suppliers</li></ul><p>This will give you a snapshot of the current state of your company, split up into "everything you own" (<strong>Assets</strong>) and "everything you owe" (<strong>Liabilities</strong>) — a <strong>Balance Sheet</strong>. These generally won't be equal — ideally your assets will be worth more than your liabilities.</p><p>The difference between the assets and the liabilities is what you, the owner of the company, can rightfully stake a claim to. Crudely, if you sold all your assets today and used that money to pay off all your debts, you'd be left with a pile of cash all to yourself.</p><p>This idea is usually expressed by the "accounting equation":</p><p><strong>Assets - Liabilities = Shareholders Equity</strong></p><p>This is where the "balance" comes in: both sides of the equation are equal. Note that this equation is actually a definition — it asserts that the value of the <strong>Shareholders Equity</strong> is the difference between <strong>Assets</strong> and <strong>Liabilities</strong>. This is the same equation that underpins double-entry bookkeeping.</p><p>Here's what your balance sheet might look like:</p><p>‍</p><figure id="w-node-89b5b437bd58-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefde1a11602b68a068a079_balance-sheet.png" alt=""></p></figure><p>‍</p><p>The bank will be interested in seeing this before giving you a loan. It's a quick 'n' dirty way for them to understand the big picture:</p><ul role="list"><li>The orders of magnitude involved — does this company operate in the thousands, millions, or billions?</li><li>An estimate for how much the company is "worth", based on the shareholders equity</li><li>An indication of company health — is the company drowning in debt?</li></ul><p>Financiers often calculate metrics based on the balance sheet, to further summarise the information and to compare numbers across companies.</p><p>The <strong>Debt/Equity Ratio</strong> is a big one, telling you how much a company relies on borrowing money. If it's too high then the company might be too dependent on loans, but if it's too low, this might indicate an inefficiency, since borrowing money to spend on growth can be quicker than earning it the hard way.</p><p>So — the balance sheet summarises a lot about your company, in a way that the bank can understand.</p><p>Unfortunately, it doesn't answer a crucial question — "Do you make money?"</p><p><h4 id="heading-3">Financial Statement #2: The Income Statement (P&amp;L)</h4></p><p>The balance sheet is a snapshot of a single point in time. To understand whether a company makes money, you need see how things change over a period of time (e.g. every month).</p><p>The first thing you need to know is how much money you receive — your <strong>Revenue</strong>. You don't keep all of it — there are costs and expenses along the way — so you need to subtract these. The final number you end up with is your <strong>Profit</strong> — the money you've made at the end of the day.</p><p>Here's how you might do the calculation:</p><p>‍</p><figure id="w-node-a4e76259fbb4-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefe0c6c8f0be2b6743533b_p%26l.png" alt=""></p></figure><p>‍</p><p>You start at Revenue (the top line), subtract your costs, and end up at Profit (the "bottom line" — get it?). This is a simple <strong>Profit &amp; Loss (P&amp;L)</strong>, or <strong>Income Statement</strong>. Most companies make one every month, to keep an eye on things. </p><p>‍</p><figure id="w-node-fec0fade16bf-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefe17879b5309ce33ce18b_35274025-14536291245349646_origin.png" alt=""></p></figure><p>‍</p><p>With a P&amp;L, you and the bank can understand what's going in and out of your business. If your P&amp;L consistently shows a profit, then the bank will be happy, and so will you.</p><p>In theory, this is very simple. But in practice, each P&amp;L item has hidden nuances to address.</p><p>Let's take just the top line — what does <strong>Revenue</strong> actually mean?</p><p><strong>What is revenue?</strong></p><p>When you started selling shirts, it was a simpler time — you bought them in bulk from China and sold them at the local market.</p><p>Revenue, too, was simple — it was the cold hard cash in your hand.</p><p>But things changed. You started taking bulk orders from shops, who pay you 1 month after you deliver the shirts. And when you went online, your customers started paying you for 12 month subscriptions, all in one go.</p><p>It turns out that if you keep thinking of revenue as "cash in your hand", then things get a little weird —</p><ul role="list"><li>When you get a bulk order, your expenses shoot up. But since you don't get paid until next month, your profit goes way down this month.</li><li>When someone buys a 12-month subscription, your revenue spikes up. But for the next 11 months you have to keep delivering on the order (non-zero cost) without further payments (zero revenue) — your bottom line takes a hit.</li></ul><p>Bulk orders and upfront payments are great for your business, but if revenue means "cash in hand", then your P&amp;L might tell the opposite story.</p><p>A better way to think about revenue is as "the value of products delivered or service provided".</p><p>In each month of a subscription, you do 1 month of work. So even with 12 months' payment upfront, you only recognise 1/12th of that payment as revenue each month. The remaining 11/12th becomes <strong>Deferred Revenue.</strong> This is actually a liability on your balance sheet — your customers have essentially given you a loan which you must pay back each month, in the form of t-shirts.</p><p>The same principle applies for bulk orders — you recognise the revenue when you deliver the product, <em>not</em> when you get paid.</p><p>This is called <strong>Accrual Accounting</strong>, and it more accurately answers the question "Do you make money?".</p><p>So — you've got a balance sheet, showing your current financial state, and you've got a P&amp;L, showing how things change over time. The bank, however, remains unsatisfied.</p><p>Sadly, consistent profits, measured with accrual accounting, can still leave you penniless on payday.</p><p><h4 id="heading-4">Financial Statement #3: The Cashflow Statement</h4></p><p>In 1863, the Dowlais Iron Company had a dilemma.</p><p>On paper, things were great — they'd recovered from a downturn and were posting healthy profits. To smelt more iron, they set out to buy a new blast furnace. But despite their promising P&amp;L, it turned out that they had no cash to buy it.</p><p>What gives?</p><p>Their problem was in spending cash too quickly — as soon as they got some, they'd use it on inventory (iron ore, etc). The profits were rolling in, but the cash wasn't sticking around.</p><p>The company needed a way to understand how cash was coming in and out — the cashflow. Their solution was the origin of the modern <strong>Cashflow Statement</strong>.</p><p>Like the P&amp;L, the cashflow statement shows how things change over each month, but crucially, it only focuses on cash — how much you started with, what you spent it on, where you got more of it, and how much you ended up with. In short, the cashflow statement explains the difference between one balance sheet and the next.</p><figure id="w-node-508193268673-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefe644e9cf27ec56e99c29_Untitled-3.png" alt=""></p></figure><p>The bank should now have enough information to decide whether to give you a loan:</p><ul role="list"><li>Balance Sheet — shows everything that you own, and everything that you owe</li><li>P&amp;L/Income Statement — shows how your business operates</li><li>Cashflow Statement — shows how you spend and earn cash</li></ul><p>These financial statements are a shared language, letting businesses communicate across industries and borders. They also "flatten" a business' evolving operations — new business models, delivery methods, and products — to give a coherent view of a company through time.</p><p>Investors use financials to judge performance, lenders use them to assess credit-worthiness, and governments use them to make sure that taxes are correctly paid.</p><p>But the whole system only works if every company follows the same rules when compiling their financials. These rules require years of study to fully understand (this is why accountants exist) and include:</p><ul role="list"><li>How to recognise revenue —&nbsp;accrual accounting</li><li>How to "amortise" costs — spreading upfront expenses over time</li><li>How to "capitalise"&nbsp;costs —&nbsp;turning big purchases into assets on the balance sheet</li></ul><p>Who made these rules?</p><p><h4 id="heading-5">Accounting Standards: Mind the GAAP</h4></p><p>The Industrial Revolution …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.causal.app/blog/whats-a-financial-statement">https://www.causal.app/blog/whats-a-financial-statement</a></em></p>]]>
            </description>
            <link>https://www.causal.app/blog/whats-a-financial-statement</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738148</guid>
            <pubDate>Sun, 05 Jul 2020 12:22:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Redis running inside Docker container on Nvidia Jetson Nano]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738070">thread link</a>) | @gkorland
<br/>
July 5, 2020 | https://collabnix.com/running-redis-inside-docker-container-on-jetson-nano/ | <a href="https://web.archive.org/web/*/https://collabnix.com/running-redis-inside-docker-container-on-jetson-nano/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure><img src="https://collabnix.com/wp-content/uploads/2020/01/image.png" alt="" srcset="https://collabnix.com/wp-content/uploads/2020/01/image.png 1004w, https://collabnix.com/wp-content/uploads/2020/01/image-600x330.png 600w, https://collabnix.com/wp-content/uploads/2020/01/image-300x165.png 300w, https://collabnix.com/wp-content/uploads/2020/01/image-768x422.png 768w, https://collabnix.com/wp-content/uploads/2020/01/image-210x115.png 210w" sizes="(max-width: 1004px) 100vw, 1004px"></figure>







<p>If you are looking out for a small, affordable, low-powered system which comes by default with the power of modern AI for your developers, then NVIDIA Jetson Nano is the answer. NVIDIA Jetson Nano is an embedded system-on-module (SoM) and developer kit from NVIDIA, including an integrated 128-core Maxwell GPU, quad-core ARM A57 64-bit CPU, 4GB LPDDR4 memory, along with support for MIPI CSI-2 and PCIe Gen2 high-speed I/O &amp; that too within $99 price tag. Amazing, isn’t it?</p>



<p>The NVIDIA® Jetson Nano™ Developer Kit is purely an AI computer. It is a small, powerful computer that lets you run multiple neural networks in parallel for applications like image classification, object detection, segmentation, and speech processing. All in an easy-to-use platform that runs in as little as 5 watts. It is perfect for makers, learners, and developers that brings the power of modern artificial intelligence to a low-power, easy-to-use platform. </p>



<h2>Why Redis on Jetson Nano?</h2>



<p> <br>The major problem with existing IoT devices like Raspberry Pi or Jetson Nano board is that they uses a removable microSD card as its boot device and storage. Hence, the problem of temporarily storing data.  Imagine data received by sensors or 4k video images received every seconds on these IoT devices to perform on-device computations.  For major of IoT projects, a message queuing system like MQTT is all that is needed to connect sensors, devices and graphic interfaces together. But if you have hard requirements for high throughput or you’re storing special data types like binary data or image files then you should start considering Redis. </p>



<p>Redis is an open source, in-memory Data Structure Store, used as a database, a caching layer or a message broker. Today Redis supports different kinds of abstract data structures, such as strings, lists, maps, sets, sorted sets, HyperLogLog, bitmaps, streams, and spatial indexes. </p>



<p>As per <a href="https://redis.io/topics/ARM">this</a> link, Redis is ideal for IoT and Embedded devices for several reasons:</p>



<ul><li>Redis has a very small memory footprint and CPU requirements. It can run in small devices like the Raspberry Pi Zero without impacting the overall performance, using a small amount of memory, while delivering good performance for many use cases.</li><li>The data structures of Redis are often a good way to model IoT/embedded use cases. For example in order to accumulate time series data, to receive or queue commands to execute or responses to send back to the remote servers and so forth.</li><li>Modeling data inside Redis can be very useful in order to make in-device decisions for appliances that must respond very quickly or when the remote servers are offline.</li><li>Redis can be used as an interprocess communication system between the processes running in the device.</li><li>The append only file storage of Redis is well suited for the SSD cards.</li><li>The Redis 5 stream data structure was specifically designed for time series applications and has a very low memory overhead.</li></ul>



<p>It is important to note that both Redis 4 and Redis 5 versions supports the ARM processor in general. I have been playing around running containerized applications on Jetson Nano and couldn’t wait to try out Redis on top of NVIDIA Jetson Nano. </p>



<h2>Preparing Jetson Nano</h2>



<ul><li><strong>Unboxing Jetson Nano Pack</strong></li></ul>



<figure><img src="https://collabnix.com/wp-content/uploads/2019/09/image-5-1024x397.png" alt="" srcset="https://collabnix.com/wp-content/uploads/2019/09/image-5-1024x397.png 1024w, https://collabnix.com/wp-content/uploads/2019/09/image-5-600x233.png 600w, https://collabnix.com/wp-content/uploads/2019/09/image-5-300x116.png 300w, https://collabnix.com/wp-content/uploads/2019/09/image-5-768x298.png 768w, https://collabnix.com/wp-content/uploads/2019/09/image-5-210x81.png 210w, https://collabnix.com/wp-content/uploads/2019/09/image-5.png 1339w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<ul><li><strong>Preparing your microSD card</strong></li></ul>



<p>To prepare your microSD card, you’ll need a computer with Internet connection and the ability to read and write SD cards, either via a built-in SD card slot or adapter.</p>



<ol><li>Download the&nbsp;<a href="https://developer.nvidia.com/jetson-nano-sd-card-image-r322">Jetson Nano Developer Kit SD Card Image</a>, and note where it was saved on the computer.</li><li>Write the image to your microSD card( atleast 16GB size) by following the instructions below according to the type of computer you are using: Windows, Mac, or Linux. If you are using Windows laptop, you can use SDFormatter software for formatting your microSD card and Win32DiskImager to flash Jetson Nano Image. In case you are using Mac, you will need <a href="https://www.balena.io/etcher">Etcher </a>software.</li></ol>



<figure><img src="https://collabnix.com/wp-content/uploads/2019/09/image-7.png" alt="" srcset="https://collabnix.com/wp-content/uploads/2019/09/image-7.png 509w, https://collabnix.com/wp-content/uploads/2019/09/image-7-300x187.png 300w, https://collabnix.com/wp-content/uploads/2019/09/image-7-210x131.png 210w" sizes="(max-width: 509px) 100vw, 509px"></figure>



<ol><li>To prepare your microSD card, you’ll need a computer with Internet connection and the ability to read and write SD cards, either via a built-in SD card slot or adapter</li></ol>



<figure><img src="https://collabnix.com/wp-content/uploads/2019/09/image-6.png" alt="" srcset="https://collabnix.com/wp-content/uploads/2019/09/image-6.png 655w, https://collabnix.com/wp-content/uploads/2019/09/image-6-600x295.png 600w, https://collabnix.com/wp-content/uploads/2019/09/image-6-300x147.png 300w, https://collabnix.com/wp-content/uploads/2019/09/image-6-210x103.png 210w" sizes="(max-width: 655px) 100vw, 655px"></figure>



<p>The Jetson Nano SD card image is of 12GB(uncompressed size).</p>



<p>Next, It’s time to remove this tiny SD card from SD card reader and plugin it to Jetson Board to let it boot.</p>



<h2>Jetson Nano comes with 18.09 by default</h2>



<p>Yes, you read it correct. Jetson Nano is shipped with Docker Engine 18.09 by default. Let us verify OS version running on Jetson Nano first.</p>



<h2>Verifying OS running on Jetson Nano</h2>



<pre><code>jetson@jetson-desktop:~$ sudo cat /etc/os-release
NAME="Ubuntu"
VERSION="18.04.2 LTS (Bionic Beaver)"
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME="Ubuntu 18.04.2 LTS"
VERSION_ID="18.04"
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
VERSION_CODENAME=bionic
UBUNTU_CODENAME=bionic
jetson@jetson-desktop:~$</code></pre>



<h2><a href="https://github.com/collabnix/dockerlabs/tree/master/beginners/install/jetson-nano#verifying-docker"></a>Verifying Docker</h2>



<pre><code>jetson@jetson-desktop:~$ sudo docker version
Client:
 Version:           18.09.2
 API version:       1.39
 Go version:        go1.10.4
 Git commit:        6247962
 Built:             Tue Feb 26 23:51:35 2019
 OS/Arch:           linux/arm64
 Experimental:      false

Server:
 Engine:
  Version:          18.09.2
  API version:      1.39 (minimum version 1.12)
  Go version:       go1.10.4
  Git commit:       6247962
  Built:            Wed Feb 13 00:24:14 2019
  OS/Arch:          linux/arm64
  Experimental:     false
jetson@jetson-desktop:~$
</code></pre>



<h2><a href="https://github.com/collabnix/dockerlabs/tree/master/beginners/install/jetson-nano#updating-jetson"></a>Updating OS Repository</h2>



<pre><code>sudo apt update
</code></pre>



<h2><a href="https://github.com/collabnix/dockerlabs/tree/master/beginners/install/jetson-nano#installing-docker-1903"></a>Installing Docker 19.03 Binaries</h2>



<p>You will need curl command to update Docker 18.09 to 19.03 flawlessly.</p>



<pre><code>sudo apt install curl
</code></pre>



<pre><code>curl -sSL https://get.docker.com/ | sh
</code></pre>



<pre><code>jetson@jetson-desktop:~$ sudo docker version
Client: Docker Engine - Community
 Version:           19.03.2
 API version:       1.40
 Go version:        go1.12.8
 Git commit:        6a30dfc
 Built:             Thu Aug 29 05:32:21 2019
 OS/Arch:           linux/arm64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.2
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.8
  Git commit:       6a30dfc
  Built:            Thu Aug 29 05:30:53 2019
  OS/Arch:          linux/arm64
  Experimental:     false
 containerd:
  Version:          1.2.6
  GitCommit:        894b81a4b802e4eb2a91d1ce216b8817763c29fb
 runc:
  Version:          1.0.0-rc8
  GitCommit:        425e105d5a03fabd737a126ad93d62a9eeede87f
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
jetson@jetson-desktop:~$
</code></pre>



<h2><a href="https://github.com/collabnix/dockerlabs/tree/master/beginners/install/jetson-nano#installing-docker-compose"></a>Installing Docker Compose</h2>



<pre><code>root@jetson-desktop:/home/jetson# /usr/bin/docker-compose version
docker-compose version 1.17.1, build unknown
docker-py version: 2.5.1
CPython version: 2.7.15+
OpenSSL version: OpenSSL 1.1.1  11 Sep 2018
root@jetson-desktop:/home/jetson#
</code></pre>







<h2>Run Redis Server inside Docker </h2>



<p>Jetson Nano is ARMv8 (64bit) and hence we need to verify if ARM64v8 Redis image is available or not.  </p>



<pre><code>jetson@master1:~$ docker run --name redis-server -d arm64v8/redis redis-server --appendonly yes
6b80312b1e05499d565c6962b03f852db7064d5be97acb11dae31791b55ef320
jetson@master1:~$ docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES
6b80312b1e05        arm64v8/redis       "docker-entrypoint.s…"   6 seconds ago       Up 3 seconds        6379/tcp            redis-server
jetson@master1:~$

</code></pre>



<h2>Verify if Redis Server is running or not</h2>



<pre><code>jetson@master1:~$ docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES
340437cc7c7c        arm64v8/redis       "docker-entrypoint.s…"   35 seconds ago      Up 32 seconds       6379/tcp            myredis
</code></pre>



<h2>Checking the Redis Logs</h2>



<pre><code>jetson@master1:~$ docker logs -f 4e194
1:C 23 Dec 2019 15:49:21.819 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo
1:C 23 Dec 2019 15:49:21.819 # Redis version=5.0.7, bits=64, commit=00000000, modified=0, pid=1, just started
1:C 23 Dec 2019 15:49:21.819 # Configuration loaded
1:M 23 Dec 2019 15:49:21.828 * Running mode=standalone, port=6379.
1:M 23 Dec 2019 15:49:21.828 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.
1:M 23 Dec 2019 15:49:21.828 # Server initialized
1:M 23 Dec 2019 15:49:21.828 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.
1:M 23 Dec 2019 15:49:21.829 * Ready to accept connections

</code></pre>



<h2><a href="https://github.com/collabnix/dockerlabs/tree/master/beginners/install/jetson-nano/running-redis-on-jetson-nano#run-the-redis-cli-in-the-container"></a>Running the Redis CLI </h2>



<pre><code>jetson@master1:~$ docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                        NAMES
4e1941c5be9b        arm64v8/redis       "docker-entrypoint.s…"   5 minutes ago       Up 4 minutes        192.168.1.7:6379-&gt;6379/tcp   redis-server
jetson@master1:~$ docker exec -it 4e1941 sh
# redis-cli
127.0.0.1:6379&gt;

</code></pre>



<h2>Redis PING-PONG Test</h2>



<pre><code># redis-cli
127.0.0.1:6379&gt; ping
PONG
127.0.0.1:6379&gt;
</code></pre>



<h2>Verifying Redis Command Line Interface</h2>



<p><code>T</code>The redis-cli is the Redis command line interface, a simple program that allows to send commands to Redis, and read the replies sent by the server, directly from the terminal. </p>



<pre><code># redis-cli
127.0.0.1:6379&gt; ping
PONG
127.0.0.1:6379&gt; set name collabnix
OK
127.0.0.1:6379&gt; get name
"collabnix"
</code></pre>



<h2>Testing Redis CLI Counter Test</h2>



<pre><code>127.0.0.1:6379&gt; incr counter
(integer) 1
127.0.0.1:6379&gt; incr counter
(integer) 2
127.0.0.1:6379&gt;
</code></pre>



<h2><a href="https://github.com/collabnix/dockerlabs/tree/master/beginners/install/jetson-nano/running-redis-on-jetson-nano#connect-from-another-linked-container"></a>Connecting from other Linked container</h2>



<pre><code>jetson@master1:~$ docker run -it --rm …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://collabnix.com/running-redis-inside-docker-container-on-jetson-nano/">https://collabnix.com/running-redis-inside-docker-container-on-jetson-nano/</a></em></p>]]>
            </description>
            <link>https://collabnix.com/running-redis-inside-docker-container-on-jetson-nano/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738070</guid>
            <pubDate>Sun, 05 Jul 2020 12:06:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Big Sur: First Impressions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738004">thread link</a>) | @mpweiher
<br/>
July 5, 2020 | https://www.mothsoftware.com/blog_page.php?permalink=big-sur-first-impressions | <a href="https://web.archive.org/web/*/https://www.mothsoftware.com/blog_page.php?permalink=big-sur-first-impressions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>  
<div>
<p>All major websites that cover macOS have had a look at the shiny new features. I'm going to look at the parts that I don't like.</p><h2 id="toc_1">Comparison to Catalina</h2><p>In former times testing a new macOS version was easy: load it up. Do a bug report or 2. Finished. Mojave with the privacy additions was unpleasant.</p><p>Catalina was rough in the first versions. Apple managed to screw up access to the temp folder in such a way that some apps were unusable. For some users the temp folder was okay and for others it wasn't. The less I say about the privacy idiocy the better.</p><p>So last year was bad. How about this year? Well, it's not better.</p><h2 id="toc_2">The sounds</h2><p>I remember seeing a video about music in Star Wars versus Marvel films. Star Wars music (of course, I mean the first trilogy) is memorable. It conveys emotion. In Marvel films music is just background noise.</p><p>In Big Sur sounds went from Star Wars to Marvel. The experience is jarring and wrong.</p><h2 id="toc_3">Stability</h2><p>Oh my. My test laptop is a MacBook Air. Not really fast but enough for reading, browsing, doing emails, making fractals and software testing. Therefore, it doesn't have that many applications. Here is what I got:</p><ul><li><p>Dropbox didn't even start. They got their act together and a new, working version is available by now.</p></li><li><p>I was looking for a Dropbox replacement. The installer from pCloud didn't finish.
The support only told me that they would support Big Sur when the version of macOS would become available. Thanks for nothing.</p></li><li><p>Luminar is crashing on start. I contacted support. At least they tried a bit. Here is their last statement: „I am afraid we cannot investigate the issue further since you are using a beta version of MacOS. We would recommend you to roll back to Catalina OS.“. That made me laugh.</p></li><li><p>Maps has crashed 2 times in the 15 minutes I used it.</p></li><li><p>Mail has crashed already. Nothing new there.</p></li><li><p>The Air restarted on its own. After trying to install pCloud the Air also had to be restarted.</p></li><li><p>The app I use for developing Mail Archiver doesn't make apps right now. They were using a private framework that has vanished. Oops.</p></li></ul><h2 id="toc_4">Opening files</h2><p>Double click on a file, the app that should open the file comes to front and the file content is shown.</p><p>Seems kinda simple. Unfortunately, coming to front doesn't happen for Preview.</p><p><img src="https://www.mothsoftware.com/cms-data/gallery/hipwig/1-opening-files.jpg" alt="Big Sur opening file in background"></p><p>Intensely annoying. I've also seen this when installing the new Dropbox version.<img src="https://www.mothsoftware.com/cms-data/gallery/hipwig/2-opening-files.jpg"></p><h2 id="toc_5">White space</h2><p>Finder got more white-space that wasn't needed. I'm on a small screen here. Now I can see less text in Finder.<img src="https://www.mothsoftware.com/cms-data/gallery/hipwig/3-whitespace.jpg"></p><p>This also affects the mailboxes in Mail and the menubar applets. Are we going to get touchscreens? Is everything going to be treated as iPhone? I don’t get it. Perhaps the change makes sense on a 10k screen. But not on my Air.</p><h2 id="toc_6">Contrast</h2><p>The newer the version of macOS the less contrast there is. I made some bug reports to Apple for text that I can only read by squinting. The bug reports were closed as „by design“.</p><p>Big Sur has less contrast between foreground and background than ever.</p><p>Toolbars aren't in fashion anyways anymore. So it doesn't matter that I can barely see the selected item.<img src="https://www.mothsoftware.com/cms-data/gallery/hipwig/4-preferences.jpg" alt="Toolbar selected item barely visible"></p><p>When you are lucky you can still see the selected folder in a sidebar. At little bit at least:</p><p><img src="https://www.mothsoftware.com/cms-data/gallery/hipwig/5-finder-sidebar.jpg" alt="Finder sidebar"></p><p>Don't use an app that has a black background. Because then you can't see the selected folder at all. I can do the same in Finder with a dark desktop picture.<img src="https://www.mothsoftware.com/cms-data/gallery/hipwig/6-translucency.jpg"></p><p>And don't try to remove the translucency if you use menubar applets. Because then you won't be able to use them. They now show up white in white.</p><h2 id="toc_7">Buttons</h2><p>Every item in a user interface has meaning. You see buttons that you can click. The elements have a visual hierarchy. A shadow shows you what is in front and what is not. In iOS the difference between clickable and non-clickable items has been eroded.</p><p>Now you have buttons in macOS that can't be recognised as button. Because it's chic to show interface items when you mouse over them.</p><p>The upper area of the screenshot shows the toolbar of a Finder window. If you mouse of the buttons the buttons show up.</p><p><img src="https://www.mothsoftware.com/cms-data/gallery/hipwig/8-mouse-over.jpg" alt="Finder buttons mouse over"></p><h2 id="toc_8">Messageboxes</h2><p>And now we come to the worst part. Any type of messagebox now looks like on the iPhone.<img src="https://www.mothsoftware.com/cms-data/gallery/hipwig/9-messagebox.jpg"></p><p>But don't add too much text or you will get this gem of a bug. The text is beneath the scrollbar and not next to it.<img src="https://www.mothsoftware.com/cms-data/gallery/hipwig/10-messagebox.jpg"></p><p>Why? This design doesn't make ANY sense at all on a large screen. Did anyone have a problem with the old messageboxes???</p><h2 id="toc_9">Misc</h2><ul><li>The key combinations for menus always show up disabled. Even when the menu item itself is enabled.</li><li>When I navigate in Finder in column view to a new folder then the first item in the view is not the first item in the list but the third.</li><li>When opening screenshots where a scrollbar should be shown there is no scrollbar.</li></ul><h2 id="toc_10">Beta software</h2><p>This is my first impression of Big Sur. As with all beta software bugs are to be expected. But with a large company there are many many eyeballs that work with a software before it is released. They thought at this stage the software was ready for prime time.</p><p>There are a couple of items where I see improvement:</p><ul><li>It’s finally possible to see indetermined progressbars again. How long did it take them? 3 major versions?</li><li>When doing a search in Mail and changing the mailbox the search term remains. I can’t count how often I entered text in a searchfield, selected a different mailbox and had to enter the text again.</li></ul><p>A couple of developer friends said that they prefer the new look. And indeed Big Sur does look fresh and nice. But user interface and user experience are more than a „fresh look“.</p></div>




 
     
  </div></div>]]>
            </description>
            <link>https://www.mothsoftware.com/blog_page.php?permalink=big-sur-first-impressions</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738004</guid>
            <pubDate>Sun, 05 Jul 2020 11:50:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Introduction to Conflict-Free Replicated Data Types]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23737639">thread link</a>) | @signa11
<br/>
July 5, 2020 | https://lars.hupel.info/topics/crdt/01-intro.html | <a href="https://web.archive.org/web/*/https://lars.hupel.info/topics/crdt/01-intro.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>This is a series about Conflict-Free Replicated Data Types, or CRDTs for short.
Their purpose is to allow seamless replication of data on different nodes in a distributed system.
Merging is by construction always possible, without any conflicts.
This series assumes no knowledge about CRDTs, but be prepared to learn a thing or two about algebras.
All code samples on this page are interactive and executed in your browser.
Understanding the code is necessary for understanding the concepts, so you should be familiar with JavaScript.
If you notice any bugs on this page, <a href="https://github.com/larsrh/website/issues">please let me know</a>!</p><article>
    <p>Dear reader!
If you’re reading this, that’s most likely because you’ve pointed your browser to my website and/or followed a link to this page.
Maybe you’re even reading this from a mobile device!<sup id="fnref:footnote-mobile" role="doc-noteref"><a href="#fn:footnote-mobile">1</a></sup>
Perfect conditions for motivating what all this is about.</p>

<h2 id="contents">Contents</h2>

<ol>
  <li>Preliminaries (this page)</li>
  <li><a href="https://lars.hupel.info/topics/crdt/02-contracts">Algebras &amp; contracts</a></li>
  <li><a href="https://lars.hupel.info/topics/crdt/03-lattices">Lattices</a></li>
  <li><a href="https://lars.hupel.info/topics/crdt/04-combinators">Combinators</a></li>
  <li><a href="https://lars.hupel.info/topics/crdt/05-tombstones">Tombstones</a>
    <ul>
      <li>Side note on <a href="https://lars.hupel.info/topics/crdt/05a-adt">Abstract Data Types</a></li>
    </ul>
  </li>
  <li><a href="https://lars.hupel.info/topics/crdt/06-time">Time</a></li>
  <li><a href="https://lars.hupel.info/topics/crdt/07-deletion">Registers and Deletion</a></li>
  <li>Outlook (to be written)</li>
</ol>

<h2 id="the-web-is-a-truly-distributed-application-platform">The web is a truly distributed application platform</h2>

<p><a href="https://lars.hupel.info/img/topics/crdt/world.jpg" data-toggle="lightbox" data-footer="A network of nodes">
  <img src="https://lars.hupel.info/img/topics/crdt/world.jpg" alt="A network of nodes" data-toggle="tooltip" data-placement="bottom" title="A network of nodes">
</a></p>

<p>That’s right.
When you’re building a web application, you absolutely, positively have to care about the distributed aspect of the web.
(Unless your application is stateless, like my website.)</p>

<p>What does this mean?
You may have a bunch of users.
These users may be manipulating their data from a variety of devices.
Some devices may have a slow Internet connection.
Devices may go offline at any point in time.</p>

<p>Sometimes, application developers punt on this issue:
the mobile app displays “You’re offline” and won’t let you see your data (best case), or silently discard information (worst case).</p>

<p>One particular piece in the puzzle of building distributed applications is to figure out the <em>storage</em>.
Ideally, this storage should be resilient towards users that may become unavailable, concurrent edits, and so on.</p>

<p>Enter <em>Conflict-free Replicated Data Types</em>.
A glorious example of Computer Science naming that actually Makes Sense™, they attempt to provide a flexible solution to the storage problem.
The fundamental idea is this:
You have data.
This data is stored on multiple <em>replicas</em>.
CRDTs describe how to coordinate these replicas to always arrive at a consistent state.</p>

<p>Note that there are two different categories of CRDTs: <em>state-based</em> and <em>op-based</em>.
Both serve the same purpose, but work in different ways and come with their own design trade-offs.
In this series, I’m mostly going to focus on state-based CRDTs.</p>

<h2 id="about-crdts">About CRDTs</h2>

<p><a href="https://lars.hupel.info/img/topics/crdt/cool.webp" data-toggle="lightbox" data-footer="Abed Nadir thinks CRDTs are cool">
  <img src="https://lars.hupel.info/img/topics/crdt/cool.webp" alt="Abed Nadir thinks CRDTs are cool" data-toggle="tooltip" data-placement="bottom" title="Abed Nadir thinks CRDTs are cool">
</a></p>

<p>That’s it!
You now understand the idea behind CRDTs.</p>

<p>Of course, that’s only half the story.
There are at least two sides to understanding CRDTs deeply.</p>

<ol>
  <li>Knowing all the varieties (counters, maps, sets, …) and how they can be embedded in application software.</li>
  <li>Diving into the mathematical background (lattices! partial orderings! wooooooo) powering their implementations.</li>
</ol>

<p>In this series, I want to focus on the second aspect and explain everything that’s needed in a bottom-up fashion using interactive notebooks, diagrams and code notation that’s familiar with a large amount of programmers: JavaScript.
I’ll be employing a few libraries for testing code and visualizing data, but otherwise, there are no further dependencies.
The research papers that describe them often assume a great deal of background knowledge in abstract algebra.
I’ll try to introduce just the necessary knowledge gently.</p>

<p>If however, you want to learn more about their use, this series is not for you.
But fear not: there are tons of resources to check out, e.g. <a href="https://crdt.tech/">crdt.tech</a>.
There’s no tracking on this page so I won’t even notice if you’re gone 🤷</p>

<p>Still here?
Cool. <em>Cool, cool, cool.</em></p>

<p>But before we can strap in and talk about CRDTs, we first need to get some paperwork out of the way.</p>

<h2 id="how-to-work-with-this-document">How to work with this document</h2>

<p>All code snippets here are live: this page functions similarly to Jupyter Notebook.
The main difference is that all code is executed in your browser; there’s no roundtrip to a backend service.
Snippets are evaluated when a page is loaded and can be re-evaluated by clicking the <em>Run</em> button.
Feel free to change any snippet to your liking, but note that subsequent snippets are not automatically re-run.
If you want to reset the session, e.g. because you deleted some code, just reload the page.
Your code is not saved between reloads!</p>

<h2 id="tests">Tests</h2>

<p>This page has a built-in test runner.
It takes named <em>properties</em> that should be checked.
The term <em>property</em> is overloaded in programming, so let me be clear: I’m not talking about properties in an object; instead I’m talking about functions that may take arguments and return a truth value.
In other words, a property is a predicate that should be evaluated on ideally all inputs to see if it always holds.</p>

<p>In the following example, we have two properties, one is valid, the other one isn’t.
They are defined using the <a href="https://github.com/dubzzz/fast-check/">fast-check</a> library, which is available under the <code>fc</code> object.</p>

<div><div><pre><code>checkAll({
  "succeed": fc.property(fc.string(), x =&gt; x == x),
  "fail": fc.property(fc.string(), x =&gt; x != x)
});
</code></pre></div></div>

<p>Under the hood, fast-check automatically generates 100 different inputs.
Granted, 100 different inputs is not exactly <em>all inputs</em>, but since there are infinitely many strings, we can’t exactly do that, can we?
fast-check will call the function (e.g. <code>x =&gt; x == x</code>) with the inputs as specified (<code>fc.string()</code> generates ASCII strings with only printable characters).
If the function ever returns <code>false</code> or throws an exception, the property is marked as failed.
Otherwise, it’s marked as successful.</p>

<p>Fortunately, we can also use <a href="https://www.chaijs.com/">Chai</a> assertions inside our properties to get rich error messages:</p>

<div><div><pre><code>checkAll({
  "succeed": fc.property(fc.string(), x =&gt; assert.equal(x, x)),
  "fail": fc.property(fc.string(), x =&gt; assert.notEqual(x, x))
});
</code></pre></div></div>

<p>The great thing about fast-check is that it will automatically show you the <em>smallest</em> (and hopefully simplest) input it could find where the property failed.
This is called the <em>counterexample</em>.
There could be many counterexamples, but here, we only show one.</p>

<div><div><pre><code>checkAll({
  "strlen": fc.property(fc.string(), x =&gt; assert.isAtMost(x.trim().length, 5))
});
</code></pre></div></div>

<p>You’ll see in the results a failure where the counterexample has length 6 and does not just consist of spaces.</p>

<p>Note that a property could be invalid and we’d still not notice it because fast-check didn’t generate that input for us.
That’s a risk we have to live with.</p>

<h2 id="playground">Playground</h2>

<p>Intrigued?
Why not play around with the test runner a little.
Of course, you could modify the code boxes above, but maybe you were afraid to.
So, I prepared a special playground just for you.
Go wild!</p>

<div><div><pre><code>checkAll({
  "be-creative": null
});
</code></pre></div></div>

<p>Feel free to consult the <a href="https://github.com/dubzzz/fast-check/blob/v1.24.1/documentation/1-Guides/Arbitraries.md">fast-check documentation</a> about which data generators there are.</p>

<h2 id="printing">Printing</h2>

<p>The runner can also print different kinds of outputs, e.g. arrays.
Note that only the last expression in a snippet is printed.</p>

<div><div><pre><code>1 + 1;

[
  "this",
  "is",
  "an",
  "array"
]
</code></pre></div></div>

<p>If you define variables without <code>var</code> (or <code>const</code> or <code>let</code>), they can be accessed in subsequent snippets.
I will use that throughout the series.</p>

<p>We can define different printing for a particular object using the <code>interactiveRender</code> symbol.
It can be declared as a method and will be invoked by the runner automatically:</p>

<div><div><pre><code>class Test {
  constructor(value) {
    this.value = value;
  }

  [interactiveRender]() {
    return `Hi ${this.value}!`;
  }
}

new Test("reader")
</code></pre></div></div>

<h2 id="onwards">Onwards</h2>

<p>You are now ready to proceed with the actual introduction.
<a href="https://lars.hupel.info/topics/crdt/02-contracts">Go here</a> to learn all about contracts.</p>

<h2 id="testimonials">Testimonials</h2>

<p>People on The Internet™ seem to enjoy these posts:</p>

<div><blockquote><p lang="en" dir="ltr">Great read. This is as entertaining as educational.</p>— Julius Adorf (@jeadorf) <a href="https://twitter.com/jeadorf/status/1276235893586702336?ref_src=twsrc%5Etfw">June 25, 2020</a></blockquote>

</div>
<div><blockquote><div lang="en" dir="ltr"><p>GREAT STUFF</p><p>I found this incredibly accessible, as I have at best a shallow grasp of this kind of mathematics.</p><p>I'd only learned about Lattice theory in the last couple of weeks (while searching for partial ordering), and found your article on lattices easy to follow.</p><p>1/(2 V 3)</p></div>— david Kaye (--The "K" stands for Quality) (@dfkaye) <a href="https://twitter.com/dfkaye/status/1279152170869207040?ref_src=twsrc%5Etfw">July 3, 2020</a></blockquote>

</div>

<h2 id="references">References</h2>

<ul>
  <li>Map by TheAndrasBarta on <a href="https://pixabay.com/photos/world-europe-map-connections-1264062/">Pixabay</a></li>
  <li>Abed Nadir on <a href="https://giphy.com/gifs/community-abed-cool-2HONNTJbRhzKE">Giphy</a></li>
</ul>




<hr>

Thanks to the people who've read drafts of this series and provided valuable feedback:
Andrea, Clement Delafargue, Heiko Seeberger, Hillel Wayne, Johannes Link, Matthew Weidner, Princess.

  </article></div>]]>
            </description>
            <link>https://lars.hupel.info/topics/crdt/01-intro.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23737639</guid>
            <pubDate>Sun, 05 Jul 2020 09:58:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Depression Is a Fickle Beast]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23737470">thread link</a>) | @chrschwz
<br/>
July 5, 2020 | https://blog.christianschwarz.com/depression-is-a-fickle-beast | <a href="https://web.archive.org/web/*/https://blog.christianschwarz.com/depression-is-a-fickle-beast">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://blog.christianschwarz.com/depression-is-a-fickle-beast</link>
            <guid isPermaLink="false">hacker-news-small-sites-23737470</guid>
            <pubDate>Sun, 05 Jul 2020 09:04:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust on the ESP32 (2019)]]>
            </title>
            <description>
<![CDATA[
Score 128 | Comments 42 (<a href="https://news.ycombinator.com/item?id=23737451">thread link</a>) | @lnyan
<br/>
July 5, 2020 | https://mabez.dev/blog/posts/esp32-rust/ | <a href="https://web.archive.org/web/*/https://mabez.dev/blog/posts/esp32-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	  <p>About six months ago, I made a <a href="https://www.reddit.com/r/rust/comments/ar2d3r/espressif_have_finally_released_an_llvm_fork_this/">post on reddit</a> highlighting the launch of Espressif's llvm xtensa fork, not too long after, I had a working <code>rustc</code> toolchain capable of generating xtensa assembly. At this point I had to put this project to the side to finish my final year of university. Funnily enough I didn't stray too far, my final year project used Rust to create a <a href="https://github.com/MWatch">'smartwatch'</a> (I may write about this in the future, if anyone is interested). </p>
<p>Since then I have seen a few posts utilising my fork to run Rust on the <a href="https://www.espressif.com/en/products/hardware/esp32/overview">ESP32</a> (<a href="https://dentrassi.de/2019/06/16/rust-on-the-esp-and-how-to-get-started/">see this great write up</a> by ctron, if you haven't already), most of which are building on top of <a href="https://github.com/espressif/esp-idf">esp-idf</a> which is written in C. In this post I'll be discussing the steps I took to generate valid binaries for the xtensa architecture with <code>rustc</code> and then write some <code>no_std</code> code to build a blinky program for the ESP32 only using Rust!</p>
<h2 id="hacking-the-compiler">Hacking the compiler</h2>
<p>In March of 2019, Espressif released their first run at an <a href="https://github.com/espressif/llvm-xtensa">llvm fork</a> to support the xtensa architecure. Shortly after I got to work bootstrapping Rust to use this newly created fork. Prior to this project, I'd had no experience with the compiler, fortunately I came across the <a href="https://github.com/rust-lang/rust/pull/52787">RISCV PR</a> which gave me a rough idea of what was required. After <em>many</em> build attempts I finally got it working; I was now able to generate xtensa assembly from Rust source code!</p>
<p>The next step was to assemble and link the generated assembly. The llvm fork in it's current state cannot perform object generation, so we must use an external assembler. Luckily Rust allows us to do so by specifying the <code>linker_flavor</code> as <code>gcc</code> and providing a path to the linker with the <code>linker</code> target option, in this case <code>xtensa-esp32-elf-gcc</code>. After that I created a few built-in targets (which you can see <a href="https://github.com/MabezDev/rust-xtensa/blob/ad570c5cb999f62a03156286fdb5d3d1bbd0fb8b/src/librustc_target/spec/xtensa_esp32_none_elf.rs">here</a>); <code>xtensa-esp32-none-elf</code> for the ESP32; <code>xtensa-esp8266-none-elf</code> for the ESP8266; finally the <code>xtensa-unknown-none-elf</code> target for a generic xtensa target.</p>
<h2 id="blinky-code">Blinky code</h2>
<p>Now lets try and get a ESP32 board to blink the onboard LED using just Rust. First off, we need our basic program structure. The <code>xtensa_lx6_rt</code> crate does most of the heavy lifting in this respect, we simply need to define an entry point and the panic handler. Some of this may look vaguely familiar if you have any experience with <code>cortex-m</code> development on Rust, I've tried to mirror the API as best as I can.</p>
<pre><span>#![</span><span>no_std</span><span>]
#![</span><span>no_main</span><span>]


</span><span>use</span><span> xtensa_lx6_rt as _;

</span><span>use </span><span>core::panic::PanicInfo;

</span><span>/// Entry point - called by xtensa_lx6_rt after initialisation
</span><span>#[</span><span>no_mangle</span><span>]
</span><span>fn </span><span>main</span><span>() -&gt; ! {
    </span><span>loop </span><span>{}
}

</span><span>/// Simple panic handler
</span><span>#[</span><span>panic_handler</span><span>]
</span><span>fn </span><span>panic</span><span>(</span><span>_info</span><span>: &amp;PanicInfo) -&gt; ! {
    </span><span>loop </span><span>{}
}
</span></pre>
<p>Now lets add some register definitions for the peripherals we want to use. For our blinky program, we will need to control the GPIO peripheral. In the ESP32 (and most modern processors) peripherals are mapped to memory adresses, commonly refered to as memory mapped peripherals. To control a peripheral we simply need to write values to the right addresses in memory, with respect to the reference manual supplied by the chip manufacturer.</p>
<pre><span>/// GPIO output enable reg
</span><span>const </span><span>GPIO_ENABLE_W1TS_REG</span><span>: </span><span>u32 </span><span>= </span><span>0x3FF44024</span><span>;

</span><span>/// GPIO output set register
</span><span>const </span><span>GPIO_OUT_W1TS_REG</span><span>: </span><span>u32 </span><span>= </span><span>0x3FF44008</span><span>;
</span><span>/// GPIO output clear register
</span><span>const </span><span>GPIO_OUT_W1TC_REG </span><span>: </span><span>u32 </span><span>= </span><span>0x3FF4400C</span><span>;

</span><span>/// The GPIO hooked up to the onboard LED
</span><span>const </span><span>BLINKY_GPIO</span><span>: </span><span>u32 </span><span>= </span><span>2</span><span>;

</span><span>/// GPIO function mode
</span><span>const </span><span>GPIO_FUNCX_OUT_BASE</span><span>: </span><span>u32 </span><span>= </span><span>0x3FF44530</span><span>;
</span><span>const </span><span>GPIO_FUNCX_OUT_SEL_CFG</span><span>: </span><span>u32 </span><span>= </span><span>GPIO_FUNCX_OUT_BASE </span><span>+ (</span><span>BLINKY_GPIO </span><span>* </span><span>4</span><span>);
</span></pre>
<p>Using these definitions it should be possible to change the gpio for your board<sup><a href="#gpio_pin">1</a></sup> by changing the <code>BLINKY_GPIO</code>; for my board (NODEMCU ESP-32S) it was GPIO2.</p>
<h3 id="initialisation">Initialisation</h3>
<p>Next lets setup the pin as a GPIO output. For the ESP32, this is a two step process<sup><a href="#gpio_pin">1</a></sup>. Firstly, its simply a case of setting a bit in the GPIO ouput enable register. Secondly the pin has to be configured in GPIO mode. There are not enough pins for all the possible peripherals in the chip, to combat this each pin can have multiple function modes. In the case of the ESP32, each pin has up to 256 different functions, although not all are mapped. To put the pin in GPIO mode, we need to put in mode 256 (0x100), we do this by writing to the function select register. After issuing those two register writes, we should be able to turn on the GPIO by setting the relevant bit inside the GPIO set register<sup><a href="#2">2</a></sup>.</p>
<pre><span>#[</span><span>no_mangle</span><span>]
</span><span>fn </span><span>main</span><span>() -&gt; ! {

    </span><span>// configure the pin as an output
    </span><span>unsafe </span><span>{
        core::ptr::write_volatile(</span><span>GPIO_ENABLE_W1TS_REG </span><span>as </span><span>*mut </span><span>_, </span><span>0x1 </span><span>&lt;&lt; </span><span>BLINKY_GPIO</span><span>);
        </span><span>// 0x100 makes this pin a simple gpio pin - see the technical reference for more info
        </span><span>core::ptr::write_volatile(</span><span>GPIO_FUNCX_OUT_SEL_CFG </span><span>as </span><span>*mut </span><span>_, </span><span>0x100</span><span>); 
    }
    </span><span>// turn on the LED
    </span><span>unsafe </span><span>{
        core::ptr::write_volatile(</span><span>GPIO_OUT_W1TS_REG </span><span>as </span><span>*mut </span><span>_, </span><span>0x1 </span><span>&lt;&lt; idx);           
    }
    </span><span>loop </span><span>{}
}
</span></pre><h3 id="delaying">Delaying</h3>
<p>For the next stage of our blinky program, we need a way to delay; a simple approach could use <code>for</code> loop like so.</p>
<pre><span>pub fn </span><span>delay</span><span>(</span><span>clocks</span><span>: </span><span>u32</span><span>) {
    </span><span>let</span><span> dummy_var: </span><span>u32 </span><span>= </span><span>0</span><span>;
    </span><span>for </span><span>_ in </span><span>0</span><span>..clocks {
        </span><span>unsafe </span><span>{ core::ptr::read_volatile(&amp;dummy_var) };
    }
}
</span></pre>
<p>We add the volatile read so that the compiler doesn't optimise our delay away. The problem with this approach is that depending of the optimisation level, the number of clock cycles each iteration of the loop changes. We need a cycle accurate way of delaying, fortunately the ESP32 has an internal clock counting register which can be accessed with the read special register <code>rsr</code> instruction. Now are delay function looks like this.</p>
<pre><span>/// cycle accurate delay using the cycle counter register
</span><span>pub fn </span><span>delay</span><span>(</span><span>clocks</span><span>: </span><span>u32</span><span>) {
    </span><span>// NOTE: does not account for rollover
    // ommitted: the asm to read the ccount
    </span><span>let</span><span> target = </span><span>get_ccount</span><span>() + clocks;
    </span><span>loop </span><span>{
        </span><span>if </span><span>get_ccount</span><span>() &gt; target {
            </span><span>break</span><span>;
        }
    }
}
</span></pre>
<p>Now we have cycle accurate counting we can delay for one second by waiting for the number of cycles the processor will do in one second. The default clock speed on most ESP boards is 40mhz, hence waiting for 40 million cycles equates to a one second delay.</p>
<p>Bringing the snippets together and cleaning up the code into functions, we now have <code>main</code> that looks like this.</p>
<pre><span>#[</span><span>no_mangle</span><span>]
</span><span>fn </span><span>main</span><span>() -&gt; ! {
    </span><span>// configure the pin as an output
    </span><span>configure_pin_as_output</span><span>(</span><span>BLINKY_GPIO</span><span>);

    </span><span>loop </span><span>{
        </span><span>set_led</span><span>(</span><span>BLINKY_GPIO</span><span>, </span><span>true</span><span>);
        </span><span>delay</span><span>(</span><span>CORE_HZ</span><span>);
        </span><span>set_led</span><span>(</span><span>BLINKY_GPIO</span><span>, </span><span>false</span><span>);
        </span><span>delay</span><span>(</span><span>CORE_HZ</span><span>);
    }
}
</span></pre>
<p>After flashing to the board, and firing up our JTAG debugger<sup><a href="#1">3</a></sup>, we are greeted with a blinking LED!</p>

<p>The full source can be found in the <a href="https://github.com/MabezDev/xtensa-rust-quickstart">the xtensa quickstart repo</a> if you wish to try it for yourself.</p>
<p>Now I know what most of you are thinking at this point, it's not very Rusty; it contains bundles of unsafe and there are no real abstractions here, and you are right; but it's something to get the ball rolling.</p>
<h2 id="limitations">Limitations</h2>
<p>There are a few small teething issues, but by far the biggest being issue is that the fork struggles with generating debug info; the external assembler does not support <a href="https://sourceware.org/binutils/docs-2.24/as/CFI-directives.html#CFI-directives">CFI directives</a> something that all llvm targets need to support. CFI directives can easily be removed with some preprocessing, but does of course add an extra step. After pushing past that issue, I was still getting relocation linker errors. I opened <a href="https://github.com/espressif/llvm-xtensa/issues/10">an issue</a> to document my findings in the hopes it can be sorted in the next iteration of the llvm fork.</p>
<h2 id="future-work">Future work</h2>
<p>Once the debuginfo issue is sorted, I hope to start developing an ecosystem of HAL's and drivers similar to the <a href="https://github.com/stm32-rs">stm32-rs</a> and <a href="https://github.com/nrf-rs">nrf-rs</a>; I've already started the <a href="https://github.com/esp-rs">esp-rs</a> organization which is where <code>xtensa-lx6-rt</code> currently resides. Espressif has started the upstream process, the first ten patches are now in review, there should be an update coming to their fork moving from the older llvm6 to llvm8 (and hopefully some other additions and fixes too!).</p>
<h2 id="links">Links</h2>
<ul>
<li><a href="https://github.com/MabezDev/xtensa-rust-quickstart">xtensa-quickstart</a> - A quickstart project for using Rust on xtensa</li>
<li><a href="https://github.com/MabezDev/rust-xtensa">rust-xtensa</a> - The xtensa fork of Rust</li>
<li><a href="https://github.com/MabezDev">github</a> - My github</li>
</ul>
<br>
<hr>
<br>




	</div></div>]]>
            </description>
            <link>https://mabez.dev/blog/posts/esp32-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23737451</guid>
            <pubDate>Sun, 05 Jul 2020 09:00:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comparing (R) dplyr vs. (Julia) DataFrames.jl]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23737449">thread link</a>) | @mindB
<br/>
July 5, 2020 | https://bkamins.github.io/julialang/2020/07/03/dplyr-vs-df.html | <a href="https://web.archive.org/web/*/https://bkamins.github.io/julialang/2020/07/03/dplyr-vs-df.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    

<p>This time the post is inspired by the proposal of <a href="https://github.com/Arkoniak">Andrey Oskin</a>
(thank you for submitting it, below I have adapted business problem description
and <code>dplyr</code> source codes that Andrey provided).</p>

<p>Andrey shared with me typical tasks that he is faced with when doing logs
analysis. To make things concrete, assume that you have a site and you collect
users’ clicks. In the output of this process you get a table with two fields:
time of click (<code>ts</code> column below, measured in seconds) and the user identifier
(<code>user_id</code> column below).</p>

<p>Given such data there are natural business questions, that we can ask, like:</p>

<ol>
  <li>How many sessions an average user has?</li>
  <li>How many users have exactly two sessions?</li>
  <li>Find top 10 users, ordered by the descending number of sessions?</li>
  <li>What is the average time between sessions start?</li>
</ol>

<p>Session in these questions is a more or less arbitrary thing, usually,
it has a meaning of sequence of events that come together as there is
a short time difference between consecutive events. In the examples we
assume that if a user has not clicked on our site for 900 seconds after the last
click the session is over.</p>

<p>What I do in this post is take a toy data set that has this structure and
<code>dplyr</code> codes that Andrey shared with me that answer the business questions
presented above and rewrite them to DataFrames.jl.</p>

<p>The objective of this post is to compare the syntaxes of <code>dplyr</code> and
DataFrames.jl. Therefore neither <code>dplyr</code> nor DataFrames.jl codes were tuned
to be optimal. Rather I have just taken what Andrey proposed in <code>dplyr</code> and
translated it to DataFrames.jl in a way that first came to my mind (but trying
to use piping). However, in the last part of the post I out of curiosity I
decided compare the performance of the codes.</p>

<p>All codes were  tested under R version 4.0.2 and dplyr 1.0.0.
For Julia I used version 1.5.0-rc1.0 and packages: DataFrames.jl 0.21.4,
Pipe.jl 1.3.0, and ShiftedArrays 1.0.0. If you do not have much experience
with setting-up Julia project environments, in <a href="https://bkamins.github.io/julialang/2020/06/28/automatic-project-environments.html">this post</a> I give
a simple recipe how you can do it easily while ensuring you use exactly the same
versions of the packages as I do.</p>



<p>In the first step we load the required packages, create a data frame that
will be used later and sort it by the <code>ts</code> column.</p>

<p>In all examples in this post I first present R code, and then Julia code.
The expected output is shown in a comment. After each step I briefly comment
on the Julia code.</p>

<p><em>dplyr</em></p>

<figure><pre><code data-lang="r"><span>library</span><span>(</span><span>dplyr</span><span>)</span><span>

</span><span>df</span><span> </span><span>&lt;-</span><span> </span><span>data.frame</span><span>(</span><span>ts</span><span> </span><span>=</span><span> </span><span>c</span><span>(</span><span>1</span><span>,</span><span>10</span><span>,</span><span>20</span><span>,</span><span>1000</span><span>,</span><span>1010</span><span>,</span><span>1200</span><span>,</span><span>2200</span><span>,</span><span>2220</span><span>,</span><span>30</span><span>,</span><span>500</span><span>,</span><span>1500</span><span>,</span><span>1600</span><span>),</span><span>
                 </span><span>user_id</span><span> </span><span>=</span><span> </span><span>c</span><span>(</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>2</span><span>,</span><span>2</span><span>,</span><span>2</span><span>,</span><span>2</span><span>))</span><span> </span><span>%&gt;%</span><span>
    </span><span>arrange</span><span>(</span><span>ts</span><span>)</span><span>
</span><span>df</span><span>
</span><span>#      ts user_id</span><span>
</span><span># 1     1       1</span><span>
</span><span># 2    10       1</span><span>
</span><span># 3    20       1</span><span>
</span><span># 4    30       2</span><span>
</span><span># 5   500       2</span><span>
</span><span># 6  1000       1</span><span>
</span><span># 7  1010       1</span><span>
</span><span># 8  1200       1</span><span>
</span><span># 9  1500       2</span><span>
</span><span># 10 1600       2</span><span>
</span><span># 11 2200       1</span><span>
</span><span># 12 2220       1</span></code></pre></figure>

<p><em>DataFrames.jl</em></p>

<figure><pre><code data-lang="julia"><span>using</span> <span>DataFrames</span>
<span>using</span> <span>Pipe</span>
<span>using</span> <span>ShiftedArrays</span>
<span>using</span> <span>Statistics</span>

<span>df</span> <span>=</span> <span>@pipe</span> <span>DataFrame!</span><span>(</span><span>ts</span> <span>=</span> <span>[</span><span>1</span><span>,</span><span>10</span><span>,</span><span>20</span><span>,</span><span>1000</span><span>,</span><span>1010</span><span>,</span><span>1200</span><span>,</span><span>2200</span><span>,</span><span>2220</span><span>,</span><span>30</span><span>,</span><span>500</span><span>,</span><span>1500</span><span>,</span><span>1600</span><span>],</span>
                      <span>user_id</span> <span>=</span> <span>[</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>2</span><span>,</span><span>2</span><span>,</span><span>2</span><span>,</span><span>2</span><span>])</span> <span>|&gt;</span>
    <span>sort</span><span>(</span><span>_</span><span>,</span> <span>:</span><span>ts</span><span>)</span>
<span># 12×2 DataFrame</span>
<span># │ Row │ ts    │ user_id │</span>
<span># │     │ Int64 │ Int64   │</span>
<span># ├─────┼───────┼─────────┤</span>
<span># │ 1   │ 1     │ 1       │</span>
<span># │ 2   │ 10    │ 1       │</span>
<span># │ 3   │ 20    │ 1       │</span>
<span># │ 4   │ 30    │ 2       │</span>
<span># │ 5   │ 500   │ 2       │</span>
<span># │ 6   │ 1000  │ 1       │</span>
<span># │ 7   │ 1010  │ 1       │</span>
<span># │ 8   │ 1200  │ 1       │</span>
<span># │ 9   │ 1500  │ 2       │</span>
<span># │ 10  │ 1600  │ 2       │</span>
<span># │ 11  │ 2200  │ 1       │</span>
<span># │ 12  │ 2220  │ 1       │</span></code></pre></figure>

<p>In this step I used two things that are worth learning:</p>

<ul>
  <li>A <code>@pipe</code> macro from the Pipes.jl package allows to pass result of the left
hand side of <code>|&gt;</code> to the right hand side in the position where <code>_</code> is placed.
In this case <code>_</code> is a first argument to <code>sort</code>.</li>
  <li>I used <code>DataFrame!</code> constructor; the <code>!</code> in this case means that columns
passed to a freshly constructed data frame <em>are not copied</em> (by default
<code>DataFrame</code> constructor copies passed columns for safety).</li>
</ul>



<p>So the first task is to identify sessions in our data. For each user
a <code>session_id</code> column gives a number of session for this user, starting from
zero. Remember, that we assume that a fresh session starts for some user, if
two consecutive events for this user are separated by at least 900 seconds.</p>

<p><em>dplyr</em></p>

<figure><pre><code data-lang="r"><span>session_df</span><span> </span><span>&lt;-</span><span> </span><span>df</span><span> </span><span>%&gt;%</span><span>
    </span><span>group_by</span><span>(</span><span>user_id</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>mutate</span><span>(</span><span>prev_ts</span><span> </span><span>=</span><span> </span><span>lag</span><span>(</span><span>ts</span><span>))</span><span> </span><span>%&gt;%</span><span>
    </span><span>mutate</span><span>(</span><span>diff_ts</span><span> </span><span>=</span><span> </span><span>ts</span><span> </span><span>-</span><span> </span><span>prev_ts</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>mutate</span><span>(</span><span>diff_ts</span><span> </span><span>=</span><span> </span><span>ifelse</span><span>(</span><span>is.na</span><span>(</span><span>diff_ts</span><span>),</span><span> </span><span>0</span><span>,</span><span> </span><span>diff_ts</span><span>))</span><span> </span><span>%&gt;%</span><span>
    </span><span>mutate</span><span>(</span><span>session_start</span><span> </span><span>=</span><span> </span><span>ifelse</span><span>(</span><span>diff_ts</span><span> </span><span>&gt;=</span><span> </span><span>900</span><span>,</span><span> </span><span>1</span><span>,</span><span> </span><span>0</span><span>))</span><span> </span><span>%&gt;%</span><span>
    </span><span>mutate</span><span>(</span><span>session_id</span><span> </span><span>=</span><span> </span><span>cumsum</span><span>(</span><span>session_start</span><span>))</span><span> </span><span>%&gt;%</span><span>
    </span><span>select</span><span>(</span><span>-</span><span>prev_ts</span><span>,</span><span> </span><span>-</span><span>diff_ts</span><span>,</span><span> </span><span>-</span><span>session_start</span><span>)</span><span>
</span><span>session_df</span><span>
</span><span># # A tibble: 12 x 3</span><span>
</span><span># # Groups:   user_id [2]</span><span>
</span><span>#       ts user_id session_id</span><span>
</span><span>#    &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;</span><span>
</span><span>#  1     1       1          0</span><span>
</span><span>#  2    10       1          0</span><span>
</span><span>#  3    20       1          0</span><span>
</span><span>#  4    30       2          0</span><span>
</span><span>#  5   500       2          0</span><span>
</span><span>#  6  1000       1          1</span><span>
</span><span>#  7  1010       1          1</span><span>
</span><span>#  8  1200       1          1</span><span>
</span><span>#  9  1500       2          1</span><span>
</span><span># 10  1600       2          1</span><span>
</span><span># 11  2200       1          2</span><span>
</span><span># 12  2220       1          2</span></code></pre></figure>

<p><em>DataFrames.jl</em></p>

<figure><pre><code data-lang="julia"><span>session_df</span> <span>=</span> <span>@pipe</span> <span>df</span> <span>|&gt;</span>
    <span>groupby</span><span>(</span><span>_</span><span>,</span> <span>:</span><span>user_id</span><span>)</span> <span>|&gt;</span>
    <span>combine</span><span>(</span><span>:</span><span>ts</span> <span>=&gt;</span> <span>ts</span> <span>-&gt;</span> <span>begin</span>
        <span>prev_ts</span> <span>=</span> <span>lag</span><span>(</span><span>ts</span><span>)</span>
        <span>diff_ts</span> <span>=</span> <span>ts</span> <span>.-</span> <span>prev_ts</span>
        <span>diff_ts</span> <span>=</span> <span>coalesce</span><span>.</span><span>(</span><span>diff_ts</span><span>,</span> <span>0</span><span>)</span>
        <span>session_start</span> <span>=</span> <span>diff_ts</span> <span>.&gt;</span> <span>900</span>
        <span>session_id</span> <span>=</span> <span>cumsum</span><span>(</span><span>session_start</span><span>)</span>
        <span>return</span> <span>(</span><span>ts</span><span>=</span><span>ts</span><span>,</span> <span>session_id</span><span>=</span><span>session_id</span><span>)</span>
    <span>end</span><span>,</span> <span>_</span><span>,</span> <span>ungroup</span><span>=</span><span>false</span><span>)</span>
<span># GroupedDataFrame with 2 groups based on key: user_id</span>
<span># First Group (8 rows): user_id = 1</span>
<span># │ Row │ user_id │ ts    │ session_id │</span>
<span># │     │ Int64   │ Int64 │ Int64      │</span>
<span># ├─────┼─────────┼───────┼────────────┤</span>
<span># │ 1   │ 1       │ 1     │ 0          │</span>
<span># │ 2   │ 1       │ 10    │ 0          │</span>
<span># │ 3   │ 1       │ 20    │ 0          │</span>
<span># │ 4   │ 1       │ 1000  │ 1          │</span>
<span># │ 5   │ 1       │ 1010  │ 1          │</span>
<span># │ 6   │ 1       │ 1200  │ 1          │</span>
<span># │ 7   │ 1       │ 2200  │ 2          │</span>
<span># │ 8   │ 1       │ 2220  │ 2          │</span>
<span># ⋮</span>
<span># Last Group (4 rows): user_id = 2</span>
<span># │ Row │ user_id │ ts    │ session_id │</span>
<span># │     │ Int64   │ Int64 │ Int64      │</span>
<span># ├─────┼─────────┼───────┼────────────┤</span>
<span># │ 1   │ 2       │ 30    │ 0          │</span>
<span># │ 2   │ 2       │ 500   │ 0          │</span>
<span># │ 3   │ 2       │ 1500  │ 1          │</span>
<span># │ 4   │ 2       │ 1600  │ 1          │</span></code></pre></figure>

<p>Now I could have rewritten the <code>dpyr</code> code to DataFrames.jl in many ways, but
a most natural thing to do it was for me to use the following syntax:</p>
<div><div><pre><code>combine(source_column =&gt; transformation_function, grouped_data_frame)
</code></pre></div></div>
<p>With this approach I can conveniently define an anonymous function
within a <code>begin</code>-<code>end</code> block and return a <code>(ts=ts, session_id=session_id)</code> value
that is a <code>NamedTuple</code> and will get expanded into two columns of a data frame.</p>

<p>I use <code>ungroup=false</code> syntax to keep the result a <code>GroupedDataFrame</code> to match
what we get in <code>dplyr</code>.</p>

<p>Also, in the code of the function I use the <code>lag</code> function from ShiftedArrays.jl.</p>

<p>Now we have all information to answer our business questions.</p>



<p><em>dplyr</em></p>

<figure><pre><code data-lang="r"><span>session_df</span><span> </span><span>%&gt;%</span><span>
    </span><span>summarize</span><span>(</span><span>session_num</span><span> </span><span>=</span><span> </span><span>max</span><span>(</span><span>session_id</span><span>)</span><span> </span><span>+</span><span> </span><span>1</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>ungroup</span><span>()</span><span> </span><span>%&gt;%</span><span>
    </span><span>summarize</span><span>(</span><span>avg_sessions_per_user</span><span> </span><span>=</span><span> </span><span>sum</span><span>(</span><span>session_num</span><span>)</span><span> </span><span>/</span><span> </span><span>nrow</span><span>(</span><span>.</span><span>))</span><span>
</span><span># # A tibble: 1 x 1</span><span>
</span><span>#   avg_sessions_per_user</span><span>
</span><span>#                   &lt;dbl&gt;</span><span>
</span><span># 1                   2.5</span></code></pre></figure>

<p><em>DataFrames.jl</em></p>

<figure><pre><code data-lang="julia"><span>@pipe</span> <span>session_df</span> <span>|&gt;</span>
    <span>combine</span><span>(</span><span>_</span><span>,</span> <span>:</span><span>session_id</span> <span>=&gt;</span> <span>(</span><span>x</span> <span>-&gt;</span> <span>maximum</span><span>(</span><span>x</span><span>)</span> <span>+</span> <span>1</span><span>)</span> <span>=&gt;</span> <span>:</span><span>session_num</span><span>)</span> <span>|&gt;</span>
    <span>combine</span><span>(</span><span>_</span><span>,</span> <span>:</span><span>session_num</span> <span>=&gt;</span> <span>mean</span> <span>=&gt;</span> <span>:</span><span>avg_sessions_per_user</span><span>)</span>
<span># 1×1 DataFrame</span>
<span># │ Row │ avg_sessions_per_user │</span>
<span># │     │ Float64               │</span>
<span># ├─────┼───────────────────────┤</span>
<span># │ 1   │ 2.5                   │</span></code></pre></figure>

<p>Observe, that in the DataFrames.jl code the first <code>combine</code> is applied
to <code>GroupedDataFrame</code> while the second <code>combine</code> is applied to a <code>DataFrame</code>.</p>



<p><em>dplyr</em></p>

<figure><pre><code data-lang="r"><span>session_df</span><span> </span><span>%&gt;%</span><span>
    </span><span>summarize</span><span>(</span><span>session_num</span><span> </span><span>=</span><span> </span><span>max</span><span>(</span><span>session_id</span><span>)</span><span> </span><span>+</span><span> </span><span>1</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>filter</span><span>(</span><span>session_num</span><span> </span><span>==</span><span> </span><span>2</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>summarize</span><span>(</span><span>number_of_two_session_users</span><span> </span><span>=</span><span> </span><span>nrow</span><span>(</span><span>.</span><span>))</span><span>
</span><span># # A tibble: 1 x 1</span><span>
</span><span>#   number_of_two_session_users</span><span>
                        </span><span>&lt;</span><span>int</span><span>&gt;</span><span>
</span><span>1</span><span>                           </span><span>1</span></code></pre></figure>

<p><em>DataFrames.jl</em></p>

<figure><pre><code data-lang="julia"><span>@pipe</span> <span>session_df</span> <span>|&gt;</span>
    <span>combine</span><span>(</span><span>_</span><span>,</span> <span>:</span><span>session_id</span> <span>=&gt;</span> <span>(</span><span>x</span> <span>-&gt;</span> <span>maximum</span><span>(</span><span>x</span><span>)</span> <span>+</span> <span>1</span><span>)</span> <span>=&gt;</span> <span>:</span><span>session_num</span><span>)</span> <span>|&gt;</span>
    <span>filter</span><span>(</span><span>:</span><span>session_num</span> <span>=&gt;</span> <span>==</span><span>(</span><span>2</span><span>),</span> <span>_</span><span>)</span> <span>|&gt;</span>
    <span>DataFrame</span><span>(</span><span>number_of_two_session_users</span> <span>=</span> <span>nrow</span><span>(</span><span>_</span><span>))</span>
<span># 1×1 DataFrame</span>
<span># │ Row │ number_of_two_session_users │</span>
<span># │     │ Int64                       │</span>
<span># ├─────┼─────────────────────────────┤</span>
<span># │ 1   │ 1                           │</span></code></pre></figure>

<p>In this code observe that <code>:session_num =&gt; ==(2)</code> syntax means that in the
<code>filter</code> function we pass each element of <code>:session_num</code> column to <code>==(2)</code>
function, which is a <a href="https://en.wikipedia.org/wiki/Currying">curried</a> version of a standard <code>x == 2</code> comparison.</p>



<p><em>dplyr</em></p>

<figure><pre><code data-lang="r"><span>session_df</span><span> </span><span>%&gt;%</span><span>
    </span><span>summarize</span><span>(</span><span>session_num</span><span> </span><span>=</span><span> </span><span>max</span><span>(</span><span>session_id</span><span>)</span><span> </span><span>+</span><span> </span><span>1</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>ungroup</span><span>()</span><span> </span><span>%&gt;%</span><span>
    </span><span>arrange</span><span>(</span><span>desc</span><span>(</span><span>session_num</span><span>))</span><span> </span><span>%&gt;%</span><span>
    </span><span>mutate</span><span>(</span><span>rn</span><span> </span><span>=</span><span> </span><span>row_number</span><span>())</span><span> </span><span>%&gt;%</span><span>
    </span><span>filter</span><span>(</span><span>rn</span><span> </span><span>&lt;=</span><span> </span><span>10</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>select</span><span>(</span><span>-</span><span>rn</span><span>)</span><span>
</span><span># # A tibble: 2 x 2</span><span>
</span><span>#   user_id session_num</span><span>
</span><span>#     &lt;dbl&gt;       &lt;dbl&gt;</span><span>
</span><span># 1       1           3</span><span>
</span><span># 2       2           2</span></code></pre></figure>

<p><em>DataFrames.jl</em></p>

<figure><pre><code data-lang="julia"><span>@pipe</span> <span>session_df</span> <span>|&gt;</span>
    <span>combine</span><span>(</span><span>_</span><span>,</span> <span>:</span><span>session_id</span> <span>=&gt;</span> <span>(</span><span>x</span> <span>-&gt;</span> <span>maximum</span><span>(</span><span>x</span><span>)</span> <span>+</span> <span>1</span><span>)</span> <span>=&gt;</span> <span>:</span><span>session_num</span><span>)</span> <span>|&gt;</span>
    <span>sort</span><span>(</span><span>_</span><span>,</span> <span>:</span><span>session_num</span><span>,</span> <span>rev</span><span>=</span><span>true</span><span>)</span> <span>|&gt;</span>
    <span>first</span><span>(</span><span>_</span><span>,</span> <span>10</span><span>)</span>
<span># 2×2 DataFrame</span>
<span># │ Row │ user_id │ session_num │</span>
<span># │     │ Int64   │ Int64       │</span>
<span># ├─────┼─────────┼─────────────┤</span>
<span># │ 1   │ 1       │ 3           │</span>
<span># │ 2   │ 2       │ 2           │</span></code></pre></figure>

<p>Here note that in the <code>:session_id =&gt; (x -&gt; maximum(x) + 1) =&gt; :session_num</code>
expression we have to wrap <code>x -&gt; maximum(x) + 1</code> in parentheses to get the
correct result (if you would omit it <code>=&gt; :session_num</code> would be treated as a
part of an anonymous function definition).</p>



<p><em>dplyr</em></p>

<figure><pre><code data-lang="r"><span>session_df</span><span> </span><span>%&gt;%</span><span>
    </span><span>arrange</span><span>(</span><span>ts</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>group_by</span><span>(</span><span>user_id</span><span>,</span><span> </span><span>session_id</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>mutate</span><span>(</span><span>rn</span><span> </span><span>=</span><span> </span><span>row_number</span><span>())</span><span> </span><span>%&gt;%</span><span>
    </span><span>filter</span><span>(</span><span>rn</span><span> </span><span>==</span><span> </span><span>1</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>group_by</span><span>(</span><span>user_id</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>mutate</span><span>(</span><span>prev_start</span><span> </span><span>=</span><span> </span><span>lag</span><span>(</span><span>ts</span><span>))</span><span> </span><span>%&gt;%</span><span>
    </span><span>filter</span><span>(</span><span>!</span><span>is.na</span><span>(</span><span>prev_start</span><span>))</span><span> </span><span>%&gt;%</span><span>
    </span><span>mutate</span><span>(</span><span>sess_diff</span><span> </span><span>=</span><span> </span><span>ts</span><span> </span><span>-</span><span> </span><span>prev_start</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>ungroup</span><span>()</span><span> </span><span>%&gt;%</span><span>
    </span><span>summarize</span><span>(</span><span>avg_session_starts</span><span> </span><span>=</span><span> </span><span>mean</span><span>(</span><span>sess_diff</span><span>))</span><span>
</span><span># # A tibble: 1 x 1</span><span>
</span><span>#   avg_session_starts</span><span>
</span><span>#                &lt;dbl&gt;</span><span>
</span><span># 1               1223</span></code></pre></figure>

<p><em>DataFrames.jl</em></p>

<figure><pre><code data-lang="julia"><span>@pi…</span></code></pre></figure></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bkamins.github.io/julialang/2020/07/03/dplyr-vs-df.html">https://bkamins.github.io/julialang/2020/07/03/dplyr-vs-df.html</a></em></p>]]>
            </description>
            <link>https://bkamins.github.io/julialang/2020/07/03/dplyr-vs-df.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23737449</guid>
            <pubDate>Sun, 05 Jul 2020 08:59:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Absolem Keyboard]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23737163">thread link</a>) | @signa11
<br/>
July 5, 2020 | https://zealot.hu/absolem/ | <a href="https://web.archive.org/web/*/https://zealot.hu/absolem/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <div>

<p><img src="https://zealot.hu/absolem/pics/splash.jpg" alt="Absolem Splash"></p>

<h2 id="tldr">tl;dr</h2>

<p>I’ve designed and built my own mechanical keyboard.
It’s fucking awesome!
I’m going to ramble about it now, <em>in detail</em>.
Read on if you’re interested, or jump to either the <a href="#assembly">in-progress</a> or the <a href="#the-finished-product">finished</a> pictures, or post a comment to <a href="https://www.reddit.com/r/MechanicalKeyboards/comments/d0wls7/ladies_and_gentleman_the_absolem/">the reddit thread</a>, or… you know… do whatever you fancy.
I’m not your mom. :)</p>

<h2 id="contents">Contents</h2>

<ul>
  <li><a href="#intro">Intro</a></li>
  <li><a href="#research">Research</a></li>
  <li><a href="#design">Design</a></li>
  <li><a href="#build">Build</a></li>
  <li><a href="#firmware">Firmware</a></li>
  <li><a href="#keymap">Keymap</a></li>
  <li><a href="#writeup">Writeup</a></li>
  <li><a href="#future-work">Future work</a></li>
  <li><a href="#club">“Club”</a></li>
</ul>

<h2 id="intro">Intro</h2>

<p>Until about one and a half years ago, I’d been happily typing on a <a href="https://www.cnet.com/products/genius-slimstar-i220-keyboard-series/">basic Genius keyboard</a> with a QWERTZ (Hungarian QWERTY) layout.
Ah… simpler times!</p>

<p><img alt="Ignorance is bliss" src="https://zealot.hu/absolem/pics/fun/ignorance_is_bliss.gif">
</p>

<p>I was hovering at about 50-60 wpm, which – while decidedly not blazing fast – didn’t bother me much.
I also didn’t really care that my typing “technique” involved around 4-6 fingers and a lot of looking at the keyboard.
What <em>did</em> bother me was nights when I couldn’t actually see the keys and it slowed me down quite a bit.</p>

<p>If you’re thinking that my solution was learning to touch type, you’re wrong! (for now…)
I, of course, decided that I needed a backlit keyboard.
Around this time I was vaguely aware of mechanical keyboards and the “supposed” superior typing experience they provide.
So to celebrate my dissertation defense, – and after a cursory glance at full size vs. TKL arguments – I treated myself to a <a href="https://www.coolermaster.com/catalog/peripheral/keyboards/masterkeys-pro-s-white/">MasterKeys Pro S</a>.
And that’s where the problems started…</p>

<p>To be fair, the Pro S is a fine keyboard.
But it’s not even the thing that convinced me about mechs.
By the time it arrived, the geekhack-deskthority-r/mk Bermuda triangle sucked me in, and I was already too deep.
Looking back now, I think the main cause was that I started looking at the topic as genuine “research”, and in my mildly fanatic<a href="#footnote-1"><sup>1</sup></a> worldview that could only end with another “dissertation”, which is what this post is, I guess.</p>

<p>So, strap in as I rant about the whole journey that led me here.
Also, fair warning that I’m writing this on the already finished Absolem, which is just a pleasure to type on, so I’m going to be verbose! :P</p>

<h2 id="research">Research</h2>

<p>Being a researcher by trade, I can very much appreciate the need for seeing what someone has already done in order to not reinvent the wheel.
Also, following the old saying “stealing from one source is plagiarism; stealing from many is research”, I have basically patched together the (imho) best parts of what the current state of the art has to offer.
It was an interesting observation to make that almost all the best<a href="#footnote-2"><sup>2</sup></a> ergo aspects came from different places, while their combination didn’t exist yet.
That’s probably what lead to me deciding to design my own; had I found a board that checks all the boxes, I’d have just ordered that.
(I’m also secretly happy that it didn’t turn out like that, because this way I got to make my own, and it was a good chance to grow… but psst, don’t tell that to anyone!)</p>

<p>So with that in mind, let me just quickly walk you through the steps that lead me to “keeb enlightenment”.
Disclaimer, though: I’m only going to mention most concepts briefly to keep the post’s length manageable, but it can hopefully serve as a good starting point to begin your own, deeper research if you want.</p>

<h3 id="general-stuff">General stuff</h3>

<p>Okay, basics first, if you’re interested in the topic, you should browse <a href="https://geekhack.org/">GeekHack</a>, <a href="https://deskthority.net/">Deskthority</a>, and (of course) <a href="https://www.reddit.com/r/MechanicalKeyboards/">r/mk</a>.
(As an example, <a href="https://geekhack.org/index.php?topic=95771.0">here</a> are my tentative first steps in a brave new world over on Geekhack).</p>

<p>These places are not only chock full of information, ideas, and inspiration; they also house a very helpful and supportive community.
This is also where I’d like to thank a few people for their general help in this project, namely:</p>

<ul>
  <li><a href="https://geekhack.org/index.php?action=profile;u=55020">algernon</a>, fellow Hungarian keeb expert, for all the early advice,</li>
  <li><a href="https://feierabendprojekte.wordpress.com/2018/03/21/building-a-keyboard-by-hand/">Azel4231</a>, for his help in switch layout related measurements (I’m the “redditor” from the addendum…),</li>
  <li>and, naturally, <a href="https://www.reddit.com/user/Dotdash32/">DotDash32</a>, for the metric shitton of discussion we’ve done in both posts and reddit messages that really helped me shape what I should aim for.</li>
</ul>

<h3 id="staggers">Staggers</h3>

<p>What became really clear early on is that row-staggers are evil.
The reason they exist is pure path dependence (we’ve always done it like this, let’s keep doing it like this), and they should be eradicated.
For me, this is an issue that’s been a non-issue for a long long time, but now (that I’m “enlightened”) it’s impossible to unsee…
I mean, I sympathize with all the muscle memory that will be lost in a transition (I’m in the middle of one right now, after all), but that can’t be a good enough reason not to switch!
I’m not really a comment-y kind of guy, but you can find even me sometimes in the <a href="https://www.reddit.com/r/MechanicalKeyboards/comments/c8njw4/ergonomic/esr6nab/?context=8&amp;depth=9">middle of an argument</a> under reddit posts that claim some connection to ergonomics, yet still retain the row-stagger.</p>

<p>I’m much more “lenient” towards ortho (a.k.a. grid, or matrix) layouts, but the clear winner of this aspect (for me) is column-staggered boards.
Let’s give future aliens a chance to figure out how we looked like!</p>

<p><img alt="Nerd joke" src="https://zealot.hu/absolem/pics/fun/nerd_joke.jpg" width="60%">
</p>

<p>What’s more, I’m very much in favour of an “aggressive” stagger.
Many boards started in the right direction, but few went far enough, so I’ve been planning to be a little heavier-handed in the stagger department from the start.</p>

<p>As an example, compare a <a href="http://www.vortexgear.tw/vortex2_2.asp?kind=47&amp;kind2=220&amp;kind3=&amp;kind4=997">“traditional” TKL (or 60%)</a> vs. a <a href="https://olkb.com/planck">Planck</a> vs. an <a href="https://atreus.technomancy.us/">Atreus</a>.</p>

<h3 id="the-number-of-keys">The number of keys</h3>

<p>Today’s full size (and beyond) keyboards come from the assumption that there should be the same number of keys as there are desired functionalities and we should make our hands conform to the resulting layout.
I, on the other hand, think that the inverse of this is true, namely that we should make the number of the keys match what’s comfortably reachable from the home position and make the desired functionalities conform to that.</p>

<p><img alt="XKCD keyboard" src="https://zealot.hu/absolem/pics/fun/xkcd_keyboard.png" width="60%">
</p>

<p>This leads to a) touch typing – or at least a strictly enforced finger-key relationship (which has many more benefits I’m not going to discuss here) and b) to the need to significantly decrease the number of keys.
On the other extreme of the spectrum is <a href="http://plover.stenoknight.com/">stenography</a>, but even if we remain firmly within the realm of letter-based typing, we can (and should) make do following the “at most 1 key distance from home” principle.
That leaves at most 6 × 3 keywells + 3 thumb keys per hand.
I’d argue that anything more than that is bad.
(Not only “unnecessary” or “wasteful”, mind you, but actually bad. As in, it could be better with less…)</p>

<p>The natural result of a small number of keys while still wanting a large number of functions is the use of layers.
And layers – especially if combined with custom programmability, more on that later – are the “bees knees”!
Nevertheless, I encounter many posts that criticize the overuse of layers, or posts that express confusion about how a 40% keyboard can still be practical.
I’d refer the former group to their shift keys and the notable lack of dedicated capital letters on their boards, while the latter group should take a look at their phone while writing a text and tell me again how a really small keyboard is unusable.</p>

<p>Anyways, I digress…
The point is that I came to the conclusion that there should be very few keys with heavy layering support.
As an example, consider traditional keyboards vs. a <a href="https://github.com/foostan/crkbd">corne</a>.</p>

<h3 id="the-pinky-column">The pinky column</h3>

<p>Like we saw above, the pinky often gets 2 columns (similarly to the index finger) even when conforming to the “1 distance from home” (1DFH) rule; and much more when not.
What I’ve found is that a) it’s unnecessary with a sufficiently clever keymap and a lo(oooo)t of practice, and b) it <em>should</em> be avoided to spare your weakest fingers however you can.
So I’ve adopted a further restriction over the 1DFH to limit myself to 5 × 3 keys per hand (plus the thumbs, of course).</p>

<p>Regarding the physical layout of the pinky keys, my experiments (and my eyes, when looking at my hand) showed that the pinky can use a little bit of separation from the others.
This <em>could</em> theoretically apply to the ring and middle fingers, too, but I didn’t feel the need in those cases.
However, it really shouldn’t apply for the index finger, which already has an extra column to take care of, like in the case of the <a href="https://github.com/omkbd/Sector">Sector</a>.</p>

<p>As an example of pinky overworking, consider any regular layout (or even the <a href="https://ergodox-ez.com/">Ergodox</a>) vs. the <a href="https://geekhack.org/index.php?topic=89951.0">Minidox</a> (of which my design is basically a slightly refined, glued together, and wireless-ized version).
As for an illustration of the pinky angle, take a look at the <a href="https://github.com/pseudoku/ErgoWarp">ErgoWarp</a>.</p>

<h3 id="the-thumb-region">The thumb region</h3>

<p>Generally, there are three approaches for the thumbs:</p>

<ol>
  <li>SPACEBAR!!! – one of the thumbs can keep hacking away on a button that takes up 6-7 spaces, while the other just exists. Very efficient… <code>&lt;/sarcasm&gt;</code> There are more sophisticated layouts, with split spacebars and the like, but from an ergonomic standpoint, these are all subpar compared to the next two.</li>
  <li>Clusters – consider the <a href="https://ergodox-ez.com/">Ergodox</a> again. While this way is definitely better than a single spacebar, in my opinion it overcompensates with the amount of work it tries to give to the thumbs. The side effect of this is that very few of those thumb keys are actually convenient (or usable, according to some). This leads us nicely to:</li>
  <li>Fans – consider the <a href="https://shop.keyboard.io/">KeyboardIO Model 01</a>. This approach appreciates that the thumb actually moves in an arc, and doesn’t try to add extra functionality either above or below it.</li>
</ol>

<p><img alt="Thumb fractal" src="https://zealot.hu/absolem/pics/fun/thumb_fractal.jpg" width="40%">
</p>

<p>This is probably the only “really” original part of the Absolem design, as all the other stuff I’ve mentioned so far could be seen <em>somewhere</em> before.
And, depending on how we interpret “original”, maybe not even this…
But: I actually placed the thumb keys on an arc, with a measured thumb radius.
Yes, I actually had to refresh my trigonometry for this!
And I, of course, followed the 1DFH principle, too, so there can only be 3 (unlike the KeyboardIO’s 4).</p>

<p>I’d also like to mention, as someone with quite wide (read: fat) thumbs, I’ve aimed to have 1.25u thumb keys from the start, at least for the home position.
The sides can more easily be 1u because they don’t have a neighbor on one side, so there’s less chance for misclicking (mispressing?).
But the thumb home position (which is flanked by other thumb keys on both …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://zealot.hu/absolem/">https://zealot.hu/absolem/</a></em></p>]]>
            </description>
            <link>https://zealot.hu/absolem/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23737163</guid>
            <pubDate>Sun, 05 Jul 2020 07:34:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I interviewed 200 CTOs from growing startups – here's what came up]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23737154">thread link</a>) | @ev0xmusic
<br/>
July 5, 2020 | https://www.qovery.com/blog/i-interviewed-200-ctos-from-growing-startups-heres-what-came-up | <a href="https://web.archive.org/web/*/https://www.qovery.com/blog/i-interviewed-200-ctos-from-growing-startups-heres-what-came-up">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Between late 2019 and early 2020, I interviewed more than 200 CTOs of growing US and EU startups on the topics of the Cloud and their working methodologies. I discovered that 86% of these SMB startups use the Cloud and that 48% started their business on <a href="https://www.heroku.com/">Heroku</a> and then migrated to a Cloud provider - especially <a href="https://aws.amazon.com/">AWS</a> (Amazon Web Services).</p><p>This article explains:&nbsp;</p><ul role="list"><li>Why 48% of CTOs moved from Heroku to AWS.&nbsp;</li><li>Why migrating to AWS is a "hell" (a word I've often heard in my interviews).</li><li>How to simplify AWS and meet the needs of growing startups.</li></ul><h2>From Heroku to AWS</h2><p>Early in the life of a startup, the CTO's objective is to design a product quickly and then validate that the product's value proposition is the right one with the defined target. Technical decisions are pragmatic, saving valuable time on product delivery. For application hosting, the majority choice of CTOs is Heroku - because it's easy to get started, with virtually zero upfront cost, a price that grows with usage and maximum time spent on the product rather than managing the complexity of a server and database infrastructure.</p><p>When the startup's market positioning is the right one, the product is successful. The questions of recruitment and team structuring naturally arise, and it is from this point on that the CTO realizes that:</p><ul role="list"><li><strong>Heroku is not for teamwork</strong>: a group of developers will have to share the same environments (staging, development) at the risk of getting stuck on modifications. Heroku very quickly shows its limitations in this mode of operation and prevents development teams from being productive and efficient.</li><li><strong>Heroku is not for enterprise applications</strong>: Heroku considers the deployment and management of applications as a single unit. However, today an application is often made up of several apps - a frontend, a backend, and a database. Heroku does not allow you to manage a set of applications as a single application. This leads to difficulties in complexity management. And therefore, loss of team productivity.</li><li><strong>Heroku is outrageously expensive</strong>: even though AWS is not known for being cheap, Heroku is up to 10x more expensive than AWS for the same use. The more you use it, the more your bills go up. Peace of mind at a price, but it's tough to scale with Heroku.</li></ul><p>These negative points lead 48% of CTOs to replace Heroku by AWS. But not everything is as green on the other side of the fence...</p><h2>AWS hell for CTOs</h2><p>Pre-sales engineers at AWS have a real strength to promote the many advantages of their Cloud solution. Arguments such as free services for up to 2 years and technical support by a dedicated account manager and a team of Cloud architects resonate exceptionally well. Their crews know the field correctly and know how to reassure. Their products are of outstanding quality, and reliability is well proven. However, most of the CTOs we interviewed have no experience of what it means to use a Cloud provider such as AWS. From a technical point of view, you have to start from scratch - everything has to be built from the ground. Meaning, configuring the network, configuring the services, creating a CI for integration, and a CD for deployment - in short, getting your hands in the engine. In our study, we found two types of CTOs, the one who loves to get their hands dirty in the infrastructure, and the one who doesn't want to. The latter is predominant, and even in the case of the first, he lacks time to do what is necessary. The CTO then often turns to someone from his team who will have the cumbersome task of " re-creating " how Heroku works but often learning on-the-job. Months can go by until the CTO decides to do so:&nbsp;</p><ul role="list"><li>Contracting an external DevOps company</li></ul><p>OR</p><ul role="list"><li>Internalize this skill by recruiting it</li></ul><p>From that moment on, I often heard, "<strong>Recruiting a DevOps is a real hell, I wouldn't wish it on anyone</strong>". Not surprisingly, this skill is scarce and expensive - ~$180k/year in San Francisco. Recruiting a DevOps can take up to 12 months, not counting the months of work needed to get a tenth of a Heroku functionality.<br></p><p>AWS is complex to use, as it has to meet the needs of all businesses around the world. However, it is possible to simplify AWS. Here are some areas for improvement...</p><h2>Simplify AWS and meet the needs of growing startups</h2><p>To meet the needs of growing startups, we should be able to combine Heroku's simplicity with the flexibility of AWS. But where to start? Here are my thoughts:</p><h3>A UX designed for developers</h3><p>Heroku gets it; the developer is now the king. He's the one who turns ideas into products. Developers should be able to use AWS without any effort. AWS must be fully integrated into their working environment (IDE) to request what they need transparently. "I need a PostgreSQL version 12 database, a 20GB disk, and to have my application available at https://foo.bar - and of course all this on my Cloud account".</p><h3>An opinionated approach</h3><p>Even if there is no consensus work methodology in the R&amp;D departments of startups, most of them try to copy their elders with a functioning (most often) in the form of a Squad. The idea would be to ensure that the product can fit team working. GitOps and environment isolation (production, staging, dev) methodologies by "git" branch are a perfect start. GitOps methodologies would allow developers to maximize their productivity and never slow down their colleagues on the deployment of new features.</p><h3>Extensible</h3><p>Heroku's move to AWS is not insignificant. A growing startup needs technical extensibility. Deploying applications automatically is good, but allowing you to change everything at any time is even better. This leaves room for future DevOps to join the growing startup.</p><h2>To go further</h2><p>These areas of improvement apply to AWS as well as to other cloud providers such as Google Cloud Platform and Azure. At Qovery, we have begun this work of simplifying the Cloud. Our mission is to make it accessible to any developer, enabling growing startups to become the unicorns of tomorrow.<br></p><p><a href="https://jobs.qovery.com/">We're recruiting!</a></p><p>‍</p><p><a href="https://www.linkedin.com/pulse/jai-interview%25C3%25A9-200-ctos-de-startups-en-croissance-voici-philog%25C3%25A8ne/?trackingId=9l7kV9csR4ySm1Br7IXPuQ%3D%3D">French translation</a></p></div></div>]]>
            </description>
            <link>https://www.qovery.com/blog/i-interviewed-200-ctos-from-growing-startups-heres-what-came-up</link>
            <guid isPermaLink="false">hacker-news-small-sites-23737154</guid>
            <pubDate>Sun, 05 Jul 2020 07:32:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Moon as a rocket platform]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23737036">thread link</a>) | @uncertainquark
<br/>
July 4, 2020 | https://jatan.space/the-moon-as-a-rocket-platform/ | <a href="https://web.archive.org/web/*/https://jatan.space/the-moon-as-a-rocket-platform/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
		
	<main id="content" role="main">

	<div>
		<div>
						<article id="post-3564">
				<div>
<p>When dabbling with the laws of motion in the 17th century, Isaac Newton first realized that it is indeed possible to send an object out of Earth, into space. As long as an object is shot away from Earth with a high enough velocity, it <em>will</em> reach space and start orbiting our planet.</p>



<p>With the launch of the Sputnik satellite in 1957 onboard a powerful rocket, the Soviet Union achieved exactly that. For the first time in four billion years of life on Earth, something was intentionally sent to space.</p>



<div><figure><img src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/sputnik.jpg?fit=1024%2C388&amp;ssl=1" alt="" srcset="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/sputnik.jpg?w=1513&amp;ssl=1 1513w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/sputnik.jpg?resize=1024%2C388&amp;ssl=1 1024w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/sputnik.jpg?resize=200%2C76&amp;ssl=1 200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/sputnik.jpg?resize=768%2C291&amp;ssl=1 768w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/sputnik.jpg?resize=1200%2C454&amp;ssl=1 1200w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption><strong>Left:</strong> Launch of Sputnik satellite on October 4, 1957 by the Soviet Union, kickstarting the Space Age. <strong>Right:</strong> An engineer besides the finished Sputnik satellite. Credits: USSR</figcaption></figure></div>



<p>Give a satellite another speed boost, by either launching it on a more powerful rocket or using small thrusters onboard, and it can escape from Earth’s gravitational hold completely. That’s how you can send <a href="https://jatan.space/why-explore-venus/">missions to Venus</a>, Mars, <a href="https://jatan.space/why-explore-saturn/">Saturn</a> and beyond. But one of these two things is not quite like the other.</p>



<p>Enter the <a href="https://en.wikipedia.org/wiki/Tsiolkovsky_rocket_equation">rocket equation</a>.</p>



<p>The rocket equation is what allows scientists and engineers to quantify and compare the energy required to reach various destinations in space. Its implications are far-reaching but not intuitive – so I shall attempt to explain them without use of any math.</p>



<h3><strong>Getting to space</strong></h3>



<p>The rocket equation tells us the amount of energy a rocket must expend to go from the Earth’s surface to an orbit 250 kilometers above, called low Earth orbit, is almost thrice as much as going to the Moon from that low Earth orbit! Likewise, getting to low Earth orbit costs more than twice the energy required to reach Mars from that same orbit.<sup>1</sup></p>



<p>Even if we include the energy expenditure not just to reach the Moon from low Earth orbit but to land on it, getting to Earth orbit itself turns out to be about 50% more expensive. In other words, attaining Earth orbit is the first and the most significant barrier to space exploration.</p>



<div><figure><img src="https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/delta-v-earth-moon-mars.jpg?fit=1024%2C576&amp;ssl=1" alt="" srcset="https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/delta-v-earth-moon-mars.jpg?w=1920&amp;ssl=1 1920w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/delta-v-earth-moon-mars.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/delta-v-earth-moon-mars.jpg?resize=200%2C113&amp;ssl=1 200w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/delta-v-earth-moon-mars.jpg?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/delta-v-earth-moon-mars.jpg?resize=1536%2C864&amp;ssl=1 1536w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/delta-v-earth-moon-mars.jpg?resize=1200%2C675&amp;ssl=1 1200w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption>Energy expenditure to travel from one place in space to another, calculated using the rocket equation. Credit: ULA</figcaption></figure></div>



<blockquote><p>The giant leap for humanity was not stepping on the Moon but getting to Earth orbit.</p></blockquote>



<p>The rocket equation doesn’t just dictate how much energy you must spend to reach various destinations in space but also if you can reach space at all!</p>



<h3><strong>Planetbound</strong></h3>



<p>The satellite is but a small fraction of the total mass of the rocket that lifts it and yet has an effect on the rocket itself. Therein lies the core problem of rocket science.</p>



<p>Increasing the satellite’s mass, to make it more useful perhaps, also means more rocket fuel is required to put the satellite in the desired orbit. But more fuel makes the system weigh more. This means some more fuel is required to launch the now-heavier system into space. As a thumb rule, fuel requirements increase <a href="https://commons.wikimedia.org/wiki/File:Tsiolkovsky_rocket_equation.svg">exponentially</a> with every step increase in mass added to the satellite.</p>



<p>This is how we end up with rockets being mostly fuel and then some metal. Even the mighty Saturn V that sent astronauts to the Moon was 85% fuel, 13% rocket – including the rocket body, its plumbing and parts, and the rest 2% being the Moonbound spacecraft with astronauts sitting inside!</p>



<div><figure><img src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/saturn-v-cutaway-illustration.jpg?fit=1024%2C856&amp;ssl=1" alt="" srcset="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/saturn-v-cutaway-illustration.jpg?w=2100&amp;ssl=1 2100w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/saturn-v-cutaway-illustration.jpg?resize=1024%2C856&amp;ssl=1 1024w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/saturn-v-cutaway-illustration.jpg?resize=200%2C167&amp;ssl=1 200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/saturn-v-cutaway-illustration.jpg?resize=768%2C642&amp;ssl=1 768w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/saturn-v-cutaway-illustration.jpg?resize=1536%2C1284&amp;ssl=1 1536w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/saturn-v-cutaway-illustration.jpg?resize=2048%2C1712&amp;ssl=1 2048w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/saturn-v-cutaway-illustration.jpg?resize=1200%2C1003&amp;ssl=1 1200w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption>A cutaway illustration of the Saturn V rocket showing the rocket structure and the Moonbound spacecraft on top, which together comprise just 15% of the system’s mass, the rest 85% being fuel. <a href="https://solarsystem.nasa.gov/news/337/what-was-the-saturn-v/">Credit: NASA</a></figcaption></figure></div>



<p>At this point, if we were to make Earth more massive, a rocket would have to expend an enormous amount of energy against a more gruesome gravity well. More fuel would be required to get to space and your rocket might be something akin to 9 times more fuel than metal. Increase Earth’s mass further and the fuel-to-mass ratio would start <em>skyrocketing</em> to a point where it’s simply not possible to engineer such a near-all-fuel rocket!</p>



<p>Crunching the numbers in this manner, it turns out that if the Earth was 50% more massive, you simply wouldn’t be able to get to space even with the most energetic fuel combination (liquid hydrogen and liquid oxygen) available in chemical rockets.</p>



<p>Such a massive rocky planet is not imaginary, several of its kind exist. Of the 4,000+ planets around other stars we’ve discovered to date in our galaxy, about a thousand are something scientists call ‘Super Earths’. These are planets which are up to 10 times more massive than Earth and up to twice as large. Beyond that limit, planets don’t remain rocky and start turning into Uranus/Neptune-like gas giants.</p>



<div><figure><img src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/super-earth-size-comparison.jpg?fit=1024%2C546&amp;ssl=1" alt="" srcset="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/super-earth-size-comparison.jpg?w=1499&amp;ssl=1 1499w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/super-earth-size-comparison.jpg?resize=1024%2C546&amp;ssl=1 1024w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/super-earth-size-comparison.jpg?resize=200%2C107&amp;ssl=1 200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/super-earth-size-comparison.jpg?resize=768%2C409&amp;ssl=1 768w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/super-earth-size-comparison.jpg?resize=1200%2C640&amp;ssl=1 1200w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption>Size comparison of a Super Earth (artist’s impression) to Earth and Neptune. Credit: <a href="https://en.wikipedia.org/wiki/File:Exoplanet_Comparison_CoRoT-7_b.png">Aldaron</a>, <a href="https://www.flickr.com/photos/groovychk/474966449">Ginny Keller</a></figcaption></figure></div>



<p>Many of these Super Earths lie in the respective habitable zones around their stars i.e. conditions there could support life as we know it. Given that we’ve only searched a small fraction of our galaxy for planets, it’s fair to say there could be millions of Super Earths, many of which could host life.</p>



<p>If intelligent life were to develop on these Super Earths, they’d have a hard time building rockets that get things off-planet. Since even the most energetic chemical rockets won’t get them to space, they’d be incentivized to build something with more thrust that can, like nuclear propulsion based rockets. These will likely be far more expensive than chemical rockets but sometimes nature doesn’t give you a choice.</p>



<figure><img src="https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/orion-nuclear-rocket-concept.jpg?fit=1024%2C819&amp;ssl=1" alt="" srcset="https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/orion-nuclear-rocket-concept.jpg?w=1680&amp;ssl=1 1680w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/orion-nuclear-rocket-concept.jpg?resize=1024%2C819&amp;ssl=1 1024w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/orion-nuclear-rocket-concept.jpg?resize=200%2C160&amp;ssl=1 200w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/orion-nuclear-rocket-concept.jpg?resize=768%2C614&amp;ssl=1 768w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/orion-nuclear-rocket-concept.jpg?resize=1536%2C1229&amp;ssl=1 1536w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/orion-nuclear-rocket-concept.jpg?resize=1200%2C960&amp;ssl=1 1200w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption>In the 1960’s, US government labs, under Project Orion, investigated a nuclear fission based propulsion system as a potential solution for interstellar travel. For life on ‘Super Earths’, nuclear propulsion based rockets might be the only way to get to space. <a href="https://commons.wikimedia.org/wiki/File:Pulsed_Fission_Propulsion_Concept.jpg">Credit: NASA</a></figcaption></figure>



<p>Just like the rocket equation makes it exponentially harder to get off a planet with added mass to the planet, it also makes it exponentially easier to get off objects with lesser gravity. Now if only we had an object less massive than Earth that is accessible and resourceful..</p>



<h3><strong>Ad Luna</strong></h3>



<p>In order for humanity to survive and thrive long term, it makes sense to have a permanent human settlement on Mars as the red planet offers us a relatively benign environment. That’d require sending hundreds to thousands of tons of material from Earth to the martian surface via dozens to hundreds of huge rocket launches. That’s pretty much exactly what <a href="https://www.spacex.com/vehicles/starship/">SpaceX’s Starship</a> hopes to do. That’s where our celestial neighbor, the Moon, comes in.</p>



<p>The Moon has a much weaker gravity than Earth, allowing rockets to take off with ease. This was most notable during the Apollo missions, when even a small spacecraft hosting two astronauts <a href="https://www.youtube.com/watch?v=9HQfauGJaTs">could make its way to lunar orbit</a>. Moreover, the Moon lies at the outer edge of Earth’s gravity well, meaning it’s easy to escape our planet’s pull completely if launched from the Moon. Almost five times easier in fact.</p>



<p>If we establish a vast, permanent settlement on the Moon first, we can eventually tap into its resources to launch rockets from the Moon itself. NASA and ISRO missions have <a href="https://jatan.space/how-nasa-and-chandrayaan-discovered-water-on-the-moon/">discovered plenty of water ice</a> on the Moon’s poles. It’s possible that future human habitats built from mining the metal-rich lunar soil tap into this water ice for consumption needs. This water can also be split into hydrogen and oxygen for use as rocket fuel. Rockets taking off from an industrially enabled Moonbase can ride the lunar interplanetary highway to reach Mars more efficiently than from Earth.</p>



<figure><img src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?fit=1024%2C628&amp;ssl=1" alt="" srcset="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?w=3840&amp;ssl=1 3840w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?resize=1024%2C628&amp;ssl=1 1024w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?resize=200%2C123&amp;ssl=1 200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?resize=768%2C471&amp;ssl=1 768w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?resize=1536%2C942&amp;ssl=1 1536w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?resize=2048%2C1256&amp;ssl=1 2048w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?resize=1200%2C736&amp;ssl=1 1200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?w=2400&amp;ssl=1 2400w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?w=3600&amp;ssl=1 3600w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption>A SpaceX Starship rocket taking off from a Moonbase. <a href="https://www.spacex.com/media/starship_users_guide_v1.pdf">Credit: SpaceX</a></figcaption></figure>



<p>Sure, it would be expensive to build a vast, industrial Moonbase but if the goal is to expand sustainably into the solar system, we’re playing the game on the scale of hundreds to thousands of years. In this large scheme of things, the Moon can be <em>the</em> rocket platform to test and build a sustainable Mars presence at a much smaller cost than one done from Earth.</p>



<p>The Moon’s accessibility, low gravity barrier and resource potential are the reason why its proponents vouch for a sustainable return to the Moon first rather than targeting Mars. As the saying within the lunar circles goes,</p>



<blockquote><p>You can’t be a martian without being a lunatic.</p></blockquote>



<p>Being a Moon-first guy myself, I even made a meme to that effect.</p>







<h3><strong>The belt and beyond</strong></h3>



<p>The Moon’s advantages may extend to making homes for ourselves in the outer solar system as well. The rocket equation tells us that even if objects in the outer reaches of the solar may be closer to Mars than the Moon, the red planet’s deeper gravity well means more energy is required to get out of it than to reach those destinations from there.</p>



<p>Getting to the asteroid belt from the Moon’s surface is at least 40% less energy demanding for a rocket than from Mars’ surface – even though Mars is about <em>75 million km</em> closer to the belt! This is the difference gravity makes, and which the rocket equation allows us to see. The Moon can accelerate expanding settlements to these resource-rich asteroids. Some of these objects, like Ceres and Vesta, can in turn play the same role as the Moon can for Mars and the asteroid belt, and expand human settlements to moons of Jupiter and Saturn, and beyond.</p>



<figure><img src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/wanderers-asteroid-excavation.jpg?fit=1024%2C576&amp;ssl=1" alt="" srcset="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/wanderers-asteroid-excavation.jpg?w=1920&amp;ssl=1 1920w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/wanderers-asteroid-excavation.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/wanderers-asteroid-excavation.jpg?resize=200%2C113&amp;ssl=1 200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/wanderers-asteroid-excavation.jpg?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/wanderers-asteroid-excavation.jpg?resize=1536%2C864&amp;ssl=1 1536w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/wanderers-asteroid-excavation.jpg?resize=1200%2C675&amp;ssl=1 1200w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption>This concept shows an asteroid hollowed out on the inside and inhabited. A fleet of spaceships are lined up and approaching a docking area seen as glowing lights. <a href="http://www.erikwernquist.com/wanderers/gallery_excavation.html">Credit: Erik Wernquist</a></figcaption></figure>



<p>This finally brings us to the single most important takeaway from the rocket equation. The ability to extract and harness raw materials from low-gravity, resourceful space objects would free us from the tyranny of dragging everything out of Earth’s gravitational pull.</p>



<p>We cannot hope to be traveling among the stars if we don’t even expand into the solar system in an Earth-independent way and avail for ourselves a much larger resource pool. In-space manufacturing and industrialization is not just a good-to-have but a fundamental requirement for <a href="https://www.youtube.com/watch?v=YH3c1QZzRK4&amp;feature=emb_title">expansion into the solar system</a>. Only then humanity will be in an adequate position to venture to the nearest star and hopefully do it <a href="https://jatan.space/timeline-for-life-until-the-end-of-the-universe/">before the Sun …</a></p></div></article></div></div></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jatan.space/the-moon-as-a-rocket-platform/">https://jatan.space/the-moon-as-a-rocket-platform/</a></em></p>]]>
            </description>
            <link>https://jatan.space/the-moon-as-a-rocket-platform/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23737036</guid>
            <pubDate>Sun, 05 Jul 2020 06:48:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[4200 SaaS Business Ideas]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23737029">thread link</a>) | @jensbackbom
<br/>
July 4, 2020 | http://www.jensbackbom.com/businessideas/ | <a href="https://web.archive.org/web/*/http://www.jensbackbom.com/businessideas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.jensbackbom.com/businessideas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23737029</guid>
            <pubDate>Sun, 05 Jul 2020 06:47:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How my article became one-hit-wonder on HackerNews]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23736913">thread link</a>) | @vicek22
<br/>
July 4, 2020 | https://blog.viktomas.com/posts/one-hit-wonder-on-hn/ | <a href="https://web.archive.org/web/*/https://blog.viktomas.com/posts/one-hit-wonder-on-hn/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<article>
			
			


			

			<p>Today I’m going to tell the story of fleeting success. You’ll learn how my article reached the hacker news front page. And how it stayed there for two whole days, changing my perception about what is achievable with my writing hobby.</p>

<p>I started this blog as a new year’s resolution for 2020. One article per week. I didn’t have gigantic aspirations. I wanted to learn how to express myself better because <a href="https://blog.viktomas.com/posts/remote/">remote work</a> is all about written communication. And I wanted to share thoughts about my interests.</p>
<p>First two months I didn’t publish the articles I wrote. I didn’t want to create yet another blog with only a handful posts in it. The writing had to become a habit first.</p>
<p>After I started publishing on this site, I didn’t share it with anybody until late April when I mentioned <a href="https://blog.viktomas.com/posts/plaintext-passwords/">an article</a> on <a href="https://news.ycombinator.com/item?id=22914281">hacker news</a> for the first time. Two people liked it, and about fifty read it according to my analytics.</p>
<p>On Sunday 3rd of May 2020 at 9 AM (CET) I mention my article <a href="https://blog.viktomas.com/posts/losing-google-account/">“What would you do if you lost your Google account?"</a> on <a href="https://news.ycombinator.com/item?id=23057365">hacker news</a>. I was expecting the same results: a couple dozen people read it, a few would like it. But with strike of luck, plenty of people liked the article and of it went to the front page.</p>
<p>By 10 AM, fifteen hundred people visited the site, four times the number of visits since I started the blog. In the following 24 hours, another ten thousand people viewed the blog, and by the time the article left the front page on Monday, <strong>sixteen thousand people</strong> have read it<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>. The real number is going to be over thirty thousand because <a href="https://blog.viktomas.com/posts/adblock-skews-analytics/">60% of hacker news readers don’t show in analytics thanks to AdBlock</a>.</p>
<p>I was ecstatic. The whole day I was walking with a wide grin on my face. I immediately googled the WikiHow article on <a href="https://www.wikihow.com/Handle-Fame">How To handle fame</a>. And I took plenty of screenshots because I thought that the article is bound to drop off from the front page after a few minutes and I wanted to have a memory.</p>
<p><img src="https://blog.viktomas.com/images/posts/one-hit-wonder-hn/medium.gif" alt=""></p>
<p>There was a trickle of people coming to see the article ever since. Now about fifty people view the article each week.</p>
<p>The time of my two-day fame has now passed, but I took away valuable lessons.</p>
<p>The first lesson is that I can produce something of value outside of my programming job. I knew I design and write high-quality code and systems and I get well paid for doing that. However, this experience showed me that I could create something else people enjoy.</p>
<p>The second lesson is the type of article people enjoy. The generic articles about <a href="https://blog.viktomas.com/posts/foss/">FOSS</a> and <a href="https://blog.viktomas.com/posts/meditation-introduction/">Meditation</a> are presumably not as interesting as the more down-to-earth articles that contain a few howtos that people can apply straight away. Since the “loosing your google account” article this story repeated itself once more with the <a href="https://blog.viktomas.com/posts/slip-box/">Zettlekasten article</a>. This strengthens my hypothesis that the article needs to provide useful, applicable tool/information to the readers, not just abstract food for thought.</p>
<p>I liked Robert Heaton’s <a href="https://robertheaton.com/2019/09/24/how-to-come-up-with-blog-post-ideas/">Made-Up-Award principle</a>: you should write your article to be the best in some narrow category. Exaggerated example: “best introduction to ruby programming for marketing experts focusing on food marketing”. Another important rule for me is that I have to wish I found that article a few days/weeks before because it would help me solve a problem.</p>
<p>This event gave me just enough extrinsic motivation to help me overcome the initial period when I was considering whether I want to spend eight hours each week writing an article that fifty people read. It helped me to commit to writing as the next of my many hobbies.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>The numbers are from Mixpanel analytics. I copied them from a conversation with my friend because the Mixpanel stats have been long lost thanks to me exceeding the monthly limit. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

		</article>
	</div></div>]]>
            </description>
            <link>https://blog.viktomas.com/posts/one-hit-wonder-on-hn/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23736913</guid>
            <pubDate>Sun, 05 Jul 2020 06:03:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Best of R. A. Lafferty (Book Review)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23736876">thread link</a>) | @walterbell
<br/>
July 4, 2020 | https://fantasy-hive.co.uk/2020/05/the-best-of/ | <a href="https://web.archive.org/web/*/https://fantasy-hive.co.uk/2020/05/the-best-of/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <!-- ARTICAL CONTENT -->
                                                                <blockquote><p>“’There is only one story in the world,’ he said, ‘and it pulls two ways. There is the reason part that says “Hell, it can’t be” and there is the wonder part that says “Hell, maybe it is.”’”</p>
<p>Cliffs That Laughed, 1969</p></blockquote>
<blockquote><p>“Every science is made up entirely of anomalies rearranged to fit.”</p>
<p>Continued on Next Rock, 1970</p></blockquote>
<p><img src="https://i0.wp.com/fantasy-hive.co.uk/wp-content/uploads/2020/05/61ru6fMIQtL.jpg?resize=195%2C300&amp;ssl=1" alt="" width="195" height="300" srcset="https://i0.wp.com/fantasy-hive.co.uk/wp-content/uploads/2020/05/61ru6fMIQtL.jpg?resize=195%2C300&amp;ssl=1 195w, https://i0.wp.com/fantasy-hive.co.uk/wp-content/uploads/2020/05/61ru6fMIQtL.jpg?resize=400%2C616&amp;ssl=1 400w, https://i0.wp.com/fantasy-hive.co.uk/wp-content/uploads/2020/05/61ru6fMIQtL.jpg?resize=389%2C600&amp;ssl=1 389w, https://i0.wp.com/fantasy-hive.co.uk/wp-content/uploads/2020/05/61ru6fMIQtL.jpg?w=649&amp;ssl=1 649w" sizes="(max-width: 195px) 100vw, 195px" data-recalc-dims="1">Raphael Aloysius Lafferty was an American writer from Tulsa, Oklahoma, who wrote over two hundred short stories and thirty-two novels from 1960 to 1984. It is his genre-defying and hugely inventive short stories he is most well-known for. <em>The Best of R. A. Lafferty </em>(2019), edited by Jonathan Strahan and issued as part of Gollancz’s SF Masterworks series, collects 22 of these stories. Each story contains an introduction written by an author influenced by Lafferty’s work, including Neil Gaiman, Samuel R. Delany, Connie Willis, Jeff VanderMeer and Michael Swanwick. The stellar list of contributors should give you an idea of how far Lafferty’s literary influence extends beyond his relative obscurity. What they don’t tell you is just how wonderfully bizarre and compelling Lafferty’s writing is. Lafferty is a lover of myths, legends, tall tales, jokes, and shaggy dog stories. Any given Lafferty story is likely to be a combination of all of these, at least as much as it is a work of science fiction or fantasy, if not more. But then again their innate humour doesn’t hide Lafferty’s knack for mind-bending ideas or powerful emotional impact. Basically, there is nothing quite like a Lafferty short story, and once you’ve developed the taste for them you are likely to want more. After years of his work being out of print and difficult to find, Gollancz’s <em>Best of</em> serves as a welcome introduction to Lafferty’s writing.</p>
<p>Lafferty stories are immediately identifiable by his unique voice. So much of what makes these stories wonderful is in how they are told. Lafferty’s default style is that of the tall tale or shaggy dog story, and his fascination and love of stories leads to him playing various games with narrative convention. Nested stories – or stories nested within stories nested within stories – are common, as are puns and wordplay, frequently across various languages. ‘The Primary Education of the Camiroi’ is written as a school curriculum for alien children. Stories are frequently set up around a silly punchline, and are peppered with witty one-liners. The stories brim over with a love of language and storytelling, and the sheer joy of how these can be played with and rearranged in surprising new forms. However just because jokes and humour are an essential part of Lafferty’s toolbox does not mean that the stories are flippant or slight. At heart, Lafferty is interested in perspective, and how who is telling the story alters the perspective, and the best of his stories allow us to look at the familiar world around us in a new and unsettling way.</p>
<p>Many of Lafferty’s stories manage to take utterly bizarre, gonzo speculative fiction ideas and run with them, part of the fun being to take a ridiculous idea at face value to really see what it means. ‘Slow Tuesday Night’ imagines a world in which humanity’s perception has been sped up, to the extent that entire cultural movements and business careers rise and fall multiple times over the course of a single night. The story is breathtakingly fun, but also has a serious point to make about dwindling attention spans and the speed of modern life, anxieties that users of the internet will easily recognize. ‘Selenium Ghosts of the Eighteen Seventies’ reimagines the early days of television, where the programmes are given increased emotional resonance and depth every time they are watched, playing with the idea of how we imprint our emotions on the mass media we consume. ‘Thus We Frustrate Charlemagne’ takes the science fiction staple of using time travel to meddle with the past and so alter the future and takes it in unexpected and hilarious directions. The story is built around the pun of cutting one’s own throat with Ockham’s razor, which it uses to explore ideas around determinism and free will. Lafferty takes us through unexpected turning points in history, and wryly questions science fiction’s love of magical solutions to technologically framed problems. As such it is a pretty good example of his wayward genius at its best.</p>
<p>Lafferty had a fascination with Native American traditions and culture, and was aware of how the land of his native Oklahoma was taken from them. Many of his most powerful and devastating stories engage directly with colonialism and dispossession of native peoples. In ‘Narrow Valley’, a member of the Pawnee tribe manages to avoid having his land taken by the US government by geographically folding a valley so that it only appears five feet wide. ‘Land of the Great Horses’ sees the land of the Roma, which has been physically taken off the planet by alien powers, returned to them, whilst Los Angeles is removed and its people left to wander the Earth. ‘Ride a Tin Can’ explores the colonialist attitude at the heart of anthropological studies, and shows us the heart-breaking consequences of a people being denied their status as human. Other stories such as ‘Thieving Bear Planet’ and ‘Nine-Hundred Grandmothers’ explore situations where contact with alien beings goes horribly wrong because of the baggage and preconceptions the humans bring with them. These stories demonstrate that Lafferty’s humour and playfulness does not obscure his awareness of the darker side of human nature, that his love of America is tempered by his understanding of the tragic legacy of colonialism.</p>
<p>Many of Lafferty’s stories deal with folded realities, the idea that just underneath the world we know is a world more vital and strange, a realm of myth and imagination that informs the waking world. This is evident in ‘Boomer Flats’, in which a group of scientists on the hunt for the Abominable Snowman unwittingly enter a mythic realm and become part of the legend themselves. ‘The World as Will and Wallpaper’ anticipates the New Weird by imagining a world-engulfing city not just inspired by William Morris’s political ideals but geographically recursive like his iconic wallpaper designs. ‘Days of Grass, Days of Straw’ is about the secret days that do not fall on the calendar, when life is more vivid and colourful and bloody. Although any character’s attempts at trying to navigate these overlapping worlds is unlikely to be successful. Ceran Swicegood’s quest for knowledge about the origins of the universe in ‘Nine-Hundred Grandmothers’ is a joke he can never share in, whilst the three disappearing soldiers in ‘Cliffs That Laughed’ escape the siren’s call only to be dragged back in again. Jim Boomer and Art Slick give up trying to figure out how the people from ‘In Our Block’ achieve their impossible tasks and go to the pub instead. Transcendence most definitely exists in Lafferty’s stories, but it does not come easily, nor does it necessarily provide the answer the characters would like to hear.</p>
<p><em>The Best of R. A. Lafferty</em> is a wonderful introduction to Lafferty’s singular writing, and an excellent addition to the SF Masterworks series. It celebrates the work of one of the genre’s true originals, and hopefully, the endorsement of so many other wonderful writers throughout will lead more readers to discover Lafferty’s work. My only issue with it is that I’m somewhat at a loss now that it’s over. Most of Lafferty’s work remains out of print and his short story collections can command excessive prices over the internet. I very much hope that any publishers reading this will bring more of his stories back into print as soon as possible, as I am now thoroughly addicted and need my Lafferty fix.</p>

<p id="jp-relatedposts">
	<h3><em>Related</em></h3>
</p>                                                            </div></div>]]>
            </description>
            <link>https://fantasy-hive.co.uk/2020/05/the-best-of/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23736876</guid>
            <pubDate>Sun, 05 Jul 2020 05:51:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deciphering Repeated-Key XOR Ciphertexts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23736681">thread link</a>) | @arpitbbhayani
<br/>
July 4, 2020 | https://arpitbhayani.me/blogs/decipher-repeated-key-xor | <a href="https://web.archive.org/web/*/https://arpitbhayani.me/blogs/decipher-repeated-key-xor">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Encryption is a process of encoding messages such that it can only be read and understood by the intended parties. The process of extracting the original message from an encrypted one is called Decryption. Encryption usually scrambles the original message using a key, called the encryption key, that the involved parties agree on.</p>
<p>In the previous essay, we went through the <a href="https://arpitbhayani.me/blogs/decipher-single-xor">Single-byte XOR cipher</a> and found a way to decipher it without having any knowledge of the encryption key. In this essay, we find how to break a <a href="https://en.wikipedia.org/wiki/XOR_cipher">Repeating-key XOR cipher</a> with variable key length. The problem statement, defined above, is based on <a href="https://cryptopals.com/sets/1/challenges/6">Cryptopals Set 1 Challenge 6</a>.</p>

<p>The Repeating-key XOR cipher algorithm works with an encryption key with no constraint on its length, which makes it much stronger than a Single-byte XOR Cipher, where the encryption key length was restricted to a single byte.</p>
<h2>Encryption</h2>
<p>A plain text is encrypted using an encryption key by performing a bitwise <a href="https://en.wikipedia.org/wiki/Exclusive_or">XOR</a> operation on every character. The encryption key is repeated until it XORs every single character of the plain text and the resultant stream of bytes is again translated back as characters and sent to the other party. These encrypted bytes need not be among the usual printable characters and should ideally be interpreted as a stream of bytes. Following is the python-based implementation of this encryption process.</p>
<pre><code><span><span>def</span> <span>repeating_key_xor</span><span>(text: bytes, key: bytes)</span> -&gt; bytes:</span>
    <span>"""Given a plain text `text` as bytes and an encryption key `key`
    as bytes, the function encrypts the text by performing
    XOR of all the bytes and the `key` (in repeated manner) and returns
    the resultant XORed byte stream.
    """</span>
    
    
    
    repetitions = <span>1</span> + (len(text) // len(key))
    key = key * repetitions
    key = key[:len(text)]

    
    <span>return</span> bytes([b ^ k <span>for</span> b, k <span>in</span> zip(text, key)])
</code></pre>
<p>As an example, we encrypt the plain text - <code>secretattack</code> - with encryption key <code>$^!</code> and as per the algorithm, we first repeat the encryption key until it matches the length of the plain text and then XOR it against the plain text. The illustration below shows the entire encryption process.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/85919742-d1520600-b88b-11ea-8d71-aa36c58dc48a.png" alt="https://user-images.githubusercontent.com/4745789/85919742-d1520600-b88b-11ea-8d71-aa36c58dc48a.png"></p>
<p>For the first character in plain text - <code>s</code> - the byte i.e. ASCII value is <code>115</code> which when XORed with <code>$</code> results in <code>87</code> whose character equivalent is <code>W</code>, similarly for the second character <code>e</code> the encrypted byte is <code>;</code>, for <code>c</code> it is <code>B</code>, for the fourth character <code>r</code>, since the key repeats, the XOR is taken with <code>$</code> to get <code>V</code> and the process continues. The resultant encrypted text using repeated-key XOR on the plain text <code>secretattack</code> with key <code>$^!</code> is <code>W;BV;UE*UE=J</code>.</p>
<h2>Decryption</h2>
<p>Decryption is a process of extracting the original message from the encrypted ciphertext given the encryption key. XOR has a <a href="https://brainly.in/question/3038497">property</a> - if <code>a = b ^ c</code> then <code>b = a ^ c</code>, hence the decryption process is exactly the same as the encryption i.e. we first repeat the encryption key till it matches the length and then perform bitwise XOR with the ciphertext - the resultant bytes stream will be the original message.</p>
<p>Since encryption and decryption both have an exact same implementation - we pass the ciphertext to the function <code>repeating_key_xor</code>, defined above, to get the original message back.</p>
<pre><code><span>&gt;&gt;&gt; </span>repeating_key_xor(<span>b'W;BV;UE*UE=J'</span>, <span>b'$^!'</span>)
<span>b'secretattack'</span>
</code></pre>

<p>Things become really interesting when, given the encryption algorithm, we have to recover the original message from the ciphertext with no knowledge of the encryption key. Just like solving any other problem, the crux of deciphering the message encrypted using repeated-key XOR cipher is to break it down into manageable sub-problems and tackle them independently. We break this deciphering problem into the following two sub-problems:</p>
<ul>
<li>Finding the length of the Encryption Key</li>
<li>Bruteforce with all possible keys and finding the "most English" plain text</li>
</ul>
<h2>Finding the length of the Encryption Key</h2>
<p>In order to recover the original text from the cipher, we first find the length of the encryption key used and then apply brute force with all possible keys of the estimated length and deduce the plain text. Finding the length of the Encryption key makes the deciphering process quicker as it eliminates a lot of false keys and thus reducing the overall effort required during the brute force. In order to find the length of the Encryption Key, we need to have a better understanding of a seemingly unrelated topic - Hamming Distance.</p>
<h3>Hamming Distance</h3>
<p>Hamming distance between two bytes is the number of positions at which the corresponding bits differ. For a stream of bytes, of equal lengths, it is the sum of Hamming Distances between the corresponding bytes. Finding differences between bits can be efficiently done using bitwise XOR operation as the operation yields <code>0</code> when both the bits are the same and <code>1</code> when they differ. So for computing Hamming Distance between two bytes we XOR the bytes and count the number of <code>1</code> in its binary representation.</p>
<pre><code><span><span>def</span> <span>hamming_distance_bytes</span><span>(text1: bytes, text2: bytes)</span> -&gt; int:</span>
    <span>"""Given two stream of bytes, the function returns the Hamming Distance
    between the two.
    Note: If the two texts have unequal lengths, the hamming distance is
    computed only till one of the text exhausts, other bytes are not iterated.
    """</span>
    dist = <span>0</span>
    <span>for</span> byte1, byte2 <span>in</span> zip(text1, text2):
        dist += bin(byte1 ^ byte2).count(<span>'1'</span>)
    <span>return</span> dist

<span>&gt;&gt;&gt; </span>hamming_distance_bytes(<span>b'ab'</span>, <span>b'zb'</span>)
<span>4</span>
</code></pre>
<p>In the example above, we find that the hamming distance between two bytestreams <code>ab</code> and <code>zb</code> is <code>4</code>, which implies that the byte streams <code>ab</code> and <code>zb</code> differ at <code>4</code> different bits in their binary representations.</p>
<h3>Hamming Score</h3>
<p>Hamming distance is an absolute measure, hence in order to compare hamming distance across byte streams of varying lengths, it has to be normalized with the number of pairs of bits compared. We name this measure - Hamming Score - which thus is defined as the Hamming Distance per unit bit-pair. In python, Hamming Score is implemented as:</p>
<pre><code><span><span>def</span> <span>hamming_score_bytes</span><span>(text1: bytes, text2: bytes)</span> -&gt; float:</span>
    <span>"""Given two streams of bytes, the function computes a normalized Hamming
    Score based on the Hamming distance.
    Normalization is done by dividing the Hamming Distance by the number of bits
    present in the shorter text.
    """</span>
    <span>return</span> hamming_distance_bytes(text1, text2) / (<span>8</span> * min(len(text1), len(text2)))

<span>&gt;&gt;&gt; </span>hamming_score_bytes(<span>b'ab'</span>, <span>b'zb'</span>)
<span>0.25</span>
</code></pre>
<h3>What can we infer through Hamming Distance?</h3>
<p>Hamming Distance is an interesting measure; it effectively tells us the minimum number of bit flips required to convert one bytestream into another. It also implies that (on average) if the numerical values of two bytestreams are closer then their Hamming Distance and Hamming Score will be lower i.e it would take fewer bit flips to convert one into another.</p>
<p>This is evident from the fact that the average Hamming distance between any two bytes <code>[0-256)</code> picked at random is <code>3.9999</code> while that of any two lowercased English characters <code>[97, 122]</code> is just <code>2.45</code>. Similar ratios are observed for Hamming Score where <code>0.4999</code> is of the former while <code>0.3072</code> is of the later.</p>
<p>This inference comes in handy when we want to find out the length of Encryption Key in Repeating-key XOR Cipher as illustrated in the section below.</p>
<h3>Formal definition of encryption and decryption processes</h3>
<p>Say if <code>p</code> denotes the plaintext, <code>k</code> denotes the encryption key which is repeated to match the length of the plain text, and <code>c</code> denotes the ciphertext, we could define encryption and decryption processes as</p>
<pre><code>encryption: c[i] = p[i] XOR k[i]   <span>for</span> i <span>in</span> [<span>0</span>, len(c))
decryption: p[i] = c[i] XOR k[i]   <span>for</span> i <span>in</span> [<span>0</span>, len(p))
</code></pre>
<p>The above definitions, along with the rules of XOR operations, implying that if we XOR two bytes of the ciphertext, encrypted (XORed) using the same byte of the encryption key, we are effectively XORing the corresponding bytes of the plain text. If <code>k'</code> is the byte of the encryption key <code>k</code> which was used to encrypt (XOR) the bytes <code>p[i]</code> and <code>p[j]</code> of the plain text to generate <code>c[i]</code> and <code>c[j]</code> of the ciphertext, we could derive the following relation</p>
<pre><code># k' <span>is</span> the common byte <span>of</span> the key i.e. k' = k = k

c XOR c = (p XOR k') XOR (p XOR k')
              = p XOR k' XOR k' XOR p
              = p XOR 0 XOR p
              = p XOR p
</code></pre>
<p>The above relation, <code>c[i] XOR c[j]</code> equal to <code>p[i] XOR p[j]</code>, holds true only because both the bytes were XORed with the same byte <code>k'</code> of the encryption key; which in fact helped reduce the expression. If the byte from the encryption key which was used to XOR the pain texts were different then the relation was irreducible and we could not have possibly setup this relation.</p>
<h3>Chunking of ciphertext</h3>
<p>Chunking is the process where the ciphertext is split into smaller chunks (segments) of almost equal lengths. For example, chunking the ciphertext <code>W;BV;UE*UE=J</code> for chunk length <code>4</code> would create <code>3</code> chunks <code>W;BV</code>, <code>;UE*</code> and <code>UE=J</code>. The illustration below shows the chunks that would be formed for <code>W;BV;UE*UE=J</code> with chunks lengths varying from 2 to 6.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/86434084-24a7d680-bd1a-11ea-8346-aad7b42bab1c.png" alt="https://user-images.githubusercontent.com/4745789/86434084-24a7d680-bd1a-11ea-8346-aad7b42bab1c.png"></p>
<h3>XOR of the chunks</h3>
<p>Something very interesting happens when we compute the Average Hamming Score for all possible chunk lengths. If we consider the ciphertext <code>b'W;BV;UE*UE=J</code> and we chunk it with lengths varying from 2 to 6, we get the following distribution for the Average Hamming Score for each of the chunk length.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/86473899-6149f100-bd5f-11ea-908a-d4adabff1cf0.png" alt="https://user-images.githubusercontent.com/4745789/86473899-6149f100-bd5f-11ea-908a-d4adabff1cf0.png"></p>
<p>From the distribution above it is evident that the score was minimum at chunk length equalling <code>3</code>, which actually was the length of the Encryption Key used on the plain text. Is this mere coincidence or are we onto something?</p>
<p>When chunk length is equal to the length of the encryption key, the XOR operation on any two chunks will reduce the expression to XOR of the corresponding plain texts (as seen above), because there will be a perfect alignment of bytes from ciphertext and bytes from the keys i.e every <code>i</code>th byte from both the chunks would have been XORed with <code>i</code>th byte from the encryption key.</p>
<p>We have established that for chunk length equal to the length of the encryption key <code>c[i] XOR c[j]</code> …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://arpitbhayani.me/blogs/decipher-repeated-key-xor">https://arpitbhayani.me/blogs/decipher-repeated-key-xor</a></em></p>]]>
            </description>
            <link>https://arpitbhayani.me/blogs/decipher-repeated-key-xor</link>
            <guid isPermaLink="false">hacker-news-small-sites-23736681</guid>
            <pubDate>Sun, 05 Jul 2020 04:55:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My post was #3 on Hacker News]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23736656">thread link</a>) | @root993
<br/>
July 4, 2020 | https://www.sankalpjonna.com/posts/my-post-was-3-on-hacker-news | <a href="https://web.archive.org/web/*/https://www.sankalpjonna.com/posts/my-post-was-3-on-hacker-news">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Last Sunday I published a piece of content for the very first time on hacker news and it ended up getting the #3 spot for a few hours and stayed on the front page for an <a href="https://news.ycombinator.com/front?day=2020-06-28" target="_blank">entire day.</a> The post was about <a href="https://www.sankalpjonna.com/posts/our-aws-bill-is-2-of-revenue-heres-how-we-did-it" target="_blank">how we managed to get our AWS bill to &lt; 2% of our revenue</a>.</p><figure id="w-node-70cd5a19b74c-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f015791310d7d85125fef6b_O4P4rEPlKnx7Ng3ZdLmcl81BEdrR4uXkGzmWUwvFM9Ibl9UOF87Zi-4gIjv0F0MdYcbPlL0q_q3RiCywpMppiPUTyLqgVMoR6idh7sVNCR5LiPyWnYgf02BdaG1GBh6C6aenbS3H.png" alt=""></p><figcaption>Hacker News front page</figcaption></figure><p>This was a super thrilling experience for me because I have been a reader of Hacker news for a while but never actually posted anything or even created an account. This is why I had to ask my co-founder <a href="https://twitter.com/hipreetam93" target="_blank">Preetam</a> to post on my behalf as I did not have enough Karma points to even make one post!</p><p>‍</p><p>So I decided to continue this feedback loop of <strong>writing -&gt; being recognized -&gt; writing some more as a result</strong> by talking about what went into writing this post and what were the consequences of being featured on Hacker news.&nbsp;</p><p>‍</p><div><p>There were 3 primary reasons for this post&nbsp;</p></div><ol role="list"><li>Taking the first step at making a series of posts explaining how we solved various problems while building our <a href="https://apps.shopify.com/whatsapp-chat-button" target="_blank">WhatsApp Shopify app</a>. Problems that other indie hackers can relate to and hopefully not reinvent the wheel while solving them. We were hesitant to do this at first because we were afraid of competitors reading these posts and copying our strategies, but we realised recently that what we stand to gain from making a place for ourselves in this community outweighs the risk of competitors giving us trouble.</li></ol><ol start="2" role="list"><li>We plan to build more of such products in the future and It became very clear to us that we have to build our own distribution channels to get users instead of relying on a 3rd party channel like the Shopify App Store which we currently rely on to get 100% of our users. This post was the first attempt to drive some traffic to my personal blog, traffic that we can hopefully use to get the initial customers for our next venture.</li></ol><ol start="3" role="list"><li>An attempt to heal my imposter syndrome which kept holding me back over the years and prevented me from voicing my thoughts in public due to the fear of getting criticised. When I read all the negative comments to my post I realised that negative comments do not necessarily come from a negative place and the people posting such comments are just trying to voice their thoughts based on the unique situations that they deal with on a day to day basis. This means that criticism is very essential for growth</li></ol><p>‍</p><p><strong>Power of Hacker news and Reddit</strong>‍</p><p>‍</p><p>I posted this piece on<a href="http://reddit.com/r/Entrepreneur/" target="_blank"> reddit.com/r/Entrepreneur/</a> and Hacker news and at the time of making the post it did not occur to me that I should track the users that are visiting my blog as a result of these posts even though that was one of the primary intentions behind the post.&nbsp;</p><p>‍</p><p>I finished writing and publishing the post and went offline for a few hours when my co-founder <a href="https://twitter.com/hipreetam93" target="_blank">Preetam</a> texts me saying my post is on the front-page and I should add Google Analytics to my blog ASAP if I have not done it already. I quickly do so and start seeing results immediately&nbsp;</p><figure id="w-node-0de8a57abe57-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f015791594ffa6c974ece60_UPCnJKN5cQEljrF22coESNJOE3d7jZwgWNP8xLEkih0T_y5oR0-zYbdVHPN-Lh7ieejS0qmnWW9y2MFDkuo_n71O_zbIs5vZIZ5xAg1IDNaWT0YHP7BPJtgzhIVfwSp3bcWWLjLV.png" alt=""></p><figcaption>Google analytics data</figcaption></figure><p>‍</p><p>As you can see I got ~14k visits on my blog the day I posted it and since I added GA a few hours late, I am assuming I got around 20k or more visits. This was mind blowing to me.&nbsp;</p><figure id="w-node-de58744503f8-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f0157926dc9fcea598afa19_eXlhXdTDtdZx3rEncGgJrkkYR2XtySsWwjIR8Hof3N5RTJ3Gzblq7VaMfy1kmCjZRclUl8er-rEhvWx81p7bV632AI_TzADpLSPv1eGFFPLBbSgWAAZHzW9_ALR0AOgxlsyai-qY.png" alt=""></p><figcaption>Google analytics data</figcaption></figure><p>Looking into the data further it is quite clear that most of the traffic came from Hacker news. The fact that I had access to this kind of traffic and all I had to do was write about something that I myself experienced has given me a new perspective that is backed by actual numbers and graphs. We have all heard people tell us that it is important to write, but this can clearly be backed with actual numbers.&nbsp;</p><p>A few more things happened as a result of this post. I gained some new twitter followers, had engaging conversations with some of them and somebody even suggested that I add an RSS feed to my site so that they can follow my blog easily.&nbsp;</p><figure id="w-node-7aef82240888-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f015792e08dc7f5ad78f64b_dzsKkucLoEIlELWuS-2wMH3FsDPvL0abSgho2aEkTvihuHdoD0d7GTGBPtBrn0cEOhOtqs_csRmKdv9VK0GSkacNfALtQr4ByN0nA5S930229eCXsYaZ12_n6ZSAcuGtiHzNkPUY.png" alt=""></p><figcaption>Good folks of twitter helping me out</figcaption></figure><p>For someone who started writing for the first time, seeing so much visible evidence of the benefits of writing has certainly done a lot to fuel my desire to write even more. I am yet to discover what this means in the long run when the post matures enough to start ranking on google search.</p><p><strong>Learnings from people who read the post</strong>‍</p><p>‍</p><p>Here is a TLDR for folks who have not read the post: Use Lightsail, Amazon's approximation of a dedicated server.</p><p>The post highlighted how we managed to save a lot on AWS bills in exchange for sacrificing a bit of resilience and some folks did not take kindly to this fact.</p><figure id="w-node-48d76d4377b1-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f015792e830705462abc486_Zrrh_CUjp34hKeGUfsUwkFrV0E-eYtWOr3JnnzrAX-cPIl9K3BtiXxWnH_-m96m42GPnuxNAyfN_ohXlJBW-1K6eWwqNRxWK6oZgzN18fIdE1ouGAb5iKfMrM3LNIK6JjBzu2UdM.png" alt=""></p><figcaption>Harsh comment from a redditor</figcaption></figure><p>When I set up my app on AWS, it did not occur to me that Redundancy was super important. This is because we had the ability to do point in time restores of the Database and launch a new instance in case a disaster ever stuck, but what I failed to consider was the fact that sometimes an entire region in AWS can go dark in which case we won’t have the ability to do a restoration from a backup if that backup is on a region that is down. This is something that I have duly noted and will take into account going forward.</p><p>The above comment though harsh was a useful learning for me which would probably help me in the future but there were also comments that were not going to help anybody at all and my learnings from those comments was to not let them affect you. Find the feedback that will be useful in the long run and ignore the rest. The rest is just noise.</p><p>There were also many positive comments from people who found the post helpful and someone even commented that they moved all their instances to Lightsail after reading my post. There were people who appreciated the fact that I put a disclaimer at the end of my post explicitly saying that this is not a holy grail solution that will work for everyone and it is just something that worked for us.&nbsp;</p><p>Overall the learnings were all net positive and I look forward to sharing more and learning even more from the comments of all my future posts.</p><p><strong>Closing note</strong>‍</p><p>‍</p><p>I would like to conclude by encouraging anyone wanting to share their experiences to write and not be afraid to post it in public because it is totally worth it. You get some validation and you also get criticized but you will certainly find out that even after getting criticized, you are still alive and life goes on.</p></div></div>]]>
            </description>
            <link>https://www.sankalpjonna.com/posts/my-post-was-3-on-hacker-news</link>
            <guid isPermaLink="false">hacker-news-small-sites-23736656</guid>
            <pubDate>Sun, 05 Jul 2020 04:46:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Digital India App Innovation Challenge]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23736349">thread link</a>) | @rainhacker
<br/>
July 4, 2020 | https://innovate.mygov.in/app-challenge/ | <a href="https://web.archive.org/web/*/https://innovate.mygov.in/app-challenge/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    <div>
      <div id="tab1">
        <h3>Background</h3>
		<p>MeitY in partnership with Atal Innovation Mission – Niti Aayog launches <strong>Digital India AatmaNirbhar Bharat Innovate Challenge</strong>  to identify the best Indian Apps that are already being used by citizens and have the potential to scale and become world class Apps in their respective categories. This Innovation Challenge with various cash awards and incentives of featuring Apps on Leader Boards seeks to create an ecosystem where Indian entrepreneurs and Startups are incentivised to ideate, incubate, build, nurture and sustain Tech solutions that can serve not only citizens within India but also the world. 
		</p>
		<p>The Mantra is to Make in India for India and the World.  </p>
		
       <p>The AatmaNirbhar Bharat App Innovation Challenge is being launched in the following 8 broad categories:</p>
        <ul>
        <li>Office Productivity &amp; Work from Home</li>
        <li>Social Networking</li>
        <li>E-Learning</li>
        <li>Entertainment</li>
        <li>Health &amp; Wellness</li>
        <li>Business including Agritech and Fintech</li>
        <li>News </li>
        <li>Games</li>

        </ul>
		<p>There may be several sub categories within each category.</p>
		
		<h3>Indicative List of Sub Categories and Problem Statements</h3>
        
        <ul>
          <li>A mobile application harnessing the most accurate facial and / or body mapping technology to allow for a true-to-life virtual try out of products like spectacles, clothes, etc.</li>
<li>Mobile application for real-time speech-to-speech translation and camera translation of multiple languages.</li>
<li>An automated web-based application that handles business-to-business lead generation and cold emailing and is completely manageable from a mobile device itself.</li>
<li>Application to use mobile devices as image scanners with features like on the fly image correction, image editing, text recognition, etc.</li>
<li>Application to provide cloud storage integration, cross-platform file transfer via FTP or LAN, and a root browser on mobile device </li>
<li>A robust indigenous anti-virus software for mobile devices.</li>
<li>Application to optimize mobile device's performance by cleaning junk/cache files, optimizing device memory and optimizing battery usage.</li>
<li>A mobile based live streaming platform for hosting webinars, lectures, etc.</li>
<li>A mobile based messaging and video calling application</li>
<li>A mobile based microblogging application</li>
<li>A mobile based news application that uses cutting-edge technology to recommend the most relevant and interesting news individually to each use.</li>
<li>A mobile application offering satellite imagery and street maps, as well as functions such as a route planner for traveling by foot, car, or with public transportation. </li>
<li>A mobile based online gaming platform which also functions as a social hub for gamers</li>
<li>A mobile based photo-editing application with all standard image editing features</li>

		</ul>
		
      </div>
      <div id="tab2">
		<h3>ELIGIBILITY CRITERIA</h3>
        <p>Only Indian entrepreneurs and start-ups will be eligible to submit their entries in various categories</p>
        
		
        <h3>INNOVATION CHALLENGE PROCESS</h3>
        
        <ul>
          <li>The Innovation Challenge will be available on <a href="https://innovate.mygov.in/" target="_blank">innovate.mygov.in</a></li>
		  <li>The last date of submission of entry is 18th July 2020</li>
		  <li>The applicant needs to apply only online to submit their proposals by registering and logging on MyGov portal: <a href="https://www.mygov.in/" target="_blank">www.mygov.in</a></li>
		  <li>Applicants are advised to provide self-contained proposals with essential supporting materials provided as uploads for an informed and fair evaluation/review.</li>
		  <li>No changes will be accepted once proposals are submitted.</li>
		  <li>Providing incorrect information will lead to outright rejection of proposals.</li>
		</ul>
		
		<h3>Evaluation parameters</h3>
			<ul>
				<li>Ease of use</li>
				<li>Robustness</li>
				<li>Security features</li>
				<li>Scalability </li>
			</ul>
		<p>There will be a two stage Selection Process:</p>
			<ul>
				<li>1st Stage - Screening of eligible entries</li>
				<li>2nd Stage - Evaluation by Jury, with actual Demo</li>
			</ul>
		
		<h3>SELECTION PROCESS</h3>
			<ul>
				<li>Jury with experts from Private Sector &amp; Academia to Evaluate</li>
				<li>Shortlisted Apps to be awarded &amp; put on Leader boards</li>
				<li>Government to adopt suitable Apps, guide them to maturity</li>
			</ul>
		
		
      </div>
		<div id="tab3">
			<h3>IMPORTANT DATES</h3>
			<div>
				<table>
				<tbody><tr><td>Launch of Innovation Challenge:</td><td> 4th July 2020, on <a href="https://innovate.mygov.in/" target="_blank">innovate.mygov.in</a></td></tr>
				<tr><td>Last date for Submission: </td><td>18th July 2020 at 5:30 P.M</td></tr>
				<tr><td>Screening of Entries Received </td><td>20th to 24th July 2020</td></tr>
				<tr><td>Evaluation by the Jury </td><td>27th July to 3rd August  2020</td></tr>
				<tr><td>Final Announcement </td><td>7th August, 2020</td></tr>
				</tbody></table>
			</div>
		</div>
		
		<div id="tab4">
     <h3>AWARDS </h3>
     <p>Following Awards will be given in each of the Eight Categories</p>
     <div>
     <table>
     <tbody><tr><td>First Prize</td><td>20 Lakhs</td></tr>
     <tr><td>Second Prize </td><td>15 Lakhs</td></tr>
     <tr><td>Third Prize </td><td>10 Lakhs</td></tr>
     
     </tbody></table>
     </div>
     <p>For the purposes of evaluation, Jury may create sub categories in each category and then Apps will be classified into respective subcategories, based on functionality and evaluated. In case Sub Categories are created, the Prize Money for each sub category within each category will be as below:</p>
     <div>
     <table>
     <tbody><tr><td>First Prize</td><td>5 Lakhs</td></tr>
     <tr><td>Second Prize </td><td>3 Lakhs</td></tr>
     <tr><td>Third Prize </td><td>2 Lakhs</td></tr>
     </tbody></table>
     </div>
	
   
   </div>
		
     
      <div id="tab5">
      <h3>TERMS AND CONDITIONS </h3>
      <ul>
        <li>The contest is open to Indian  Citizens only.&nbsp;</li>
        <li>The decision of the Ministry of  Electronics and IT (MeitY) will be final and binding with regard to selection  on all stages.&nbsp;</li>
        <li>By making a submission in the  contest, all participants warrant and represent that to the best of their  knowledge, their submission is original and does not violate or misappropriate  any third party trade secret, “know-how,” copyright, patent or other  intellectual property right. Participants also warrant and represent that there  are no obligations of any nature, legal or otherwise, which would prohibit,  restrict, or interfere with their participation in the Contest or submission of  their design report, and agree to obtain any necessary clearances,  authorizations and/or approvals prior to participation.</li>
        <li>The participants agree that&nbsp;  MeitY will share information submitted by the participants as to panel experts,  reviewers etc. (any information that you may not want to share publicly should  not be submitted).</li>
		
		<li>Government does not claim ownership over Intellectual Property Right (IPR) for the Innovation that is sent to us by submitting an application. The IPR shall remain with the applicant at all times.</li>
		<li>Government reserves the right to publish the grantees information with regard to Name of the App , Brief summary, Key Functionalities , Developer Contact , Team details.</li>
	    
        <li>By entering the Contest, each  participant agrees to release&nbsp; MeitY from and against any losses, damages,  rights, claims and actions of any kind arising from&nbsp;
        <ul>
          <li>an  exclusion or disqualification of such participant pursuant to these  rules;&nbsp;</li>
          <li>late  or unsuccessful efforts to notify winners of any prize;&nbsp;</li>
          <li>forfeiture  of a prize and the selection of an alternate winner;&nbsp;</li>
          <li>late,  lost, delayed, damaged, misdirected, incomplete, illegible or unintelligible  entries;</li>
          <li>telephone,  electronic, hardware or software program, network, Internet, or computer  malfunctions, failures or difficulties of any kind;</li>
          <li>failed,  incomplete, garbled or delayed computer transmissions;</li>
          <li>any  condition caused by events beyond MeitY’s control that may cause the Contest to  be disrupted or corrupted; and</li>
          <li>any  injuries, losses or damages of any kind relating to participation in this  Contest.</li>
        </ul>
        </li>
      </ul>
	  <li>Government reserves the right, at its sole discretion, to cancel, terminate, suspend this contest and modify the rules, prizes &amp; funding related to the contest without prior notice. In no event shall Government or any other organizers be liable for any claims, losses, expenses or damages, arising out of or in connection with the foregoing.</li>
	  
	  <h3>CORRESPONDENCE</h3>
        <ul>
          <li>Any correspondence with participant will be done through an email provided by the participant at time of filling the application form. Organizers are not liable in case of email delivery failures.</li>
          <li>For any queries, please send mail at: <a href="mailto:connect@mygov.nic.in">connect@mygov.nic.in</a></li>
        </ul>
     
		<h3>DISCLAIMER</h3>
			<p>MeitY reserves the right, at its sole discretion, to cancel, terminate, suspend this contest and modify the rules, prizes &amp; funding related to the contest without prior notice. In no event shall  MeitY/Digital India/MyGov/NIC or any other organizers be liable for any claims, losses, expenses or damages, arising out of or in connection with the foregoing.</p>
		</div>
   
    
      
      
      
       
    </div>
  </div>
</div></div>]]>
            </description>
            <link>https://innovate.mygov.in/app-challenge/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23736349</guid>
            <pubDate>Sun, 05 Jul 2020 03:15:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Beginner's Guide to Abstraction]]>
            </title>
            <description>
<![CDATA[
Score 237 | Comments 79 (<a href="https://news.ycombinator.com/item?id=23735991">thread link</a>) | @jesseduffield
<br/>
July 4, 2020 | https://jesseduffield.com/beginners-guide-to-abstraction/ | <a href="https://web.archive.org/web/*/https://jesseduffield.com/beginners-guide-to-abstraction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-75">
	<!-- .entry-header -->

	
	
	<div>
		<p>In <em>The Pragmatic Programmer</em>, Andrew Hunt and David Thomas introduced the DRY (Don't Repeat Yourself) principle. The rationale being that if you see the same code copy+pasted 10 times you should probably factor that code into its own method/class.</p>
<p>But then Sandi Metz came along and <a href="https://www.sandimetz.com/blog/2016/1/20/the-wrong-abstraction">said</a>:</p>
<blockquote>
<p>Duplication is far cheaper than the wrong abstraction.</p>
</blockquote>
<p>And so the eternal war began.</p>
<h3>What is abstraction?</h3>
<p>For the purposes of this post I'm referring to the kind of abstraction as described in the <a href="https://en.wikipedia.org/wiki/Abstraction_(computer_science)#Abstraction_in_object_oriented_programming">Abstraction Principle</a>, which Wikipedia describes like so:</p>
<blockquote>
<p>In software engineering and programming language theory, the abstraction principle (or the principle of abstraction) is a basic dictum that aims to reduce duplication of information in a program (usually with emphasis on code duplication) whenever practical by making use of abstractions provided by the programming language or software libraries</p>
</blockquote>
<p>This post has nothing to say about the conceptual kind of abstraction where from the concrete examples of 'Parrot' and 'Sparrow' you create an abstraction of 'Bird'. This post is about duplicated code, how to respond to it, and how to respond to other people's responses to it.</p>
<p>I define the verb 'abstraction' to be an <em>attempt</em> to reduce complexity by combining repeated commonality into some generalisation. And so, the noun 'abstraction' is the result of that attempt. If you're somebody who believes abstraction is by definition a <em>successful</em> attempt, feel free to substitute the term 'wrong abstraction' with 'failure to abstract' throughout this post.</p>
<p>The process of abstraction typically goes like this:<br>
1) you identify different chunks of code that you think are all essentially doing the same thing<br>
2) you create a method or a class with a narrow interface which can be substituted in for all the chunks of code you found<br>
3) you go and swap out the chunks of code with a call to your method/class</p>
<h3>Abstraction is always a gamble</h3>
<p>In the world of software engineering, when requirements are always changing, every abstraction is a gamble. When you make an abstraction over some concrete things, you're making a bet that the concrete things are more similar than they are different, and that their similarities are not mere coincidences: that there is a common purpose shared by the concrete things which would lead them to evolve in lockstep as requirements evolve. If you win the bet, your codebase will be easier to work in and adding new use cases via your abstraction will be trivially easy. If you lose, you'll see a flash of fear in your colleague's eyes whenever they're assigned a ticket to make yet another extension to the misfigured monster that the once-innocent abstraction has now become</p>
<p>But risk abounds everywhere, and leaving duplicated code unabstracted is its own gamble. You're betting that the chunks of code will evolve in separate directions as requirements change and that their current similarities are more coincidence than a reflection of their common purpose. Win the bet and your colleague gets to sleep soundly at night knowing they won't be facing the abstraction monster at work the next day. Lose, and code that should have evolved in lockstep is now implemented in completely different ways across different files, where a developer fixes a bug identified in one place, only for the same bug to be reported days later in a completely different file.</p>
<p>Your job is to get good at making the right bets.</p>
<h3>The right/wrong abstraction</h3>
<p>You'll know that you've made the <em>right</em> abstraction when a long time passes and you haven't needed to expand the interface (an example of expanding the interface is adding an optional flag argument). You'll also know you've made the right abstraction when another developer doesn't find it that much harder to understand how the code behaves for a given use case than if somebody had written the code to satisfy the use case without the abstraction.</p>
<p>You'll know you've made the <em>wrong</em> abstraction when after a while the interface has been expanded to support various optional flags, each for a different use case, and you need to be a genius to reason about what the code will actually do for a given use case. By the way, if you have a string arg that merely gets fed into a switch statement inside a method and for each new use case you come up with a new accepted value for it, you <em>are</em> expanding the implicit interface, even if that fact isn't captured in your type system.</p>
<p>There is plenty of daylight between the perfect abstraction and the completely wrong abstraction (perhaps the interface needs to be fundamentally changed but afterwards you're back to having a good abstraction), and so the point of this section isn't to prescribe how much you should be abstracting, but to encourage you to think about both perspectives and be able to make a case in a PR review for why you think an abstraction should/should-not exist.</p>
<h3>Do you over or under-abstract?</h3>
<p>Given it is impossible to make the right decision with regards to abstraction every time, you are probably either somebody who over-abstracts or somebody who under-abstracts.</p>
<p>If common feedback on your PR reviews is that you should DRY up your code, you could probably benefit from doing a scan for duplicated code before submitting a PR and considering whether it belongs in its own method/class.</p>
<p>If you commonly get feedback that your methods are hard to understand because they support too many disparate use cases at once, you are probaby over-abstracting and should consider whether you should increase your tolerance for duplication.</p>
<p>Note that it's not always as simple as under-abstracting vs over-abstracting. Sometimes abstraction is appropriate, but you might take the wrong approach. If an abstraction is deemed wrong by the team, that doesn't mean no abstraction is necessarily the best alternative.</p>
<h3>Under-abstraction examples</h3>
<p>The main sign that you could be under-abstracting is that you have a heap of code doing the exact same thing called in a heap of places with no obvious reason why anybody would want the code to diverge.</p>
<h4>Example: Hard-coded formulas</h4>
<h5>Bad:</h5>
<pre><code># sphere has radius of 11
sphere_volume = 4*Math::PI/3*11**3
puts "the volume of the sphere is #{sphere_volume} cm^3"
...

radius = calculate_radius
volume = 4*Math::PI/3*radius**3
sphere.volume = volume</code></pre>
<h5>Good:</h5>
<pre><code>def sphere_volume(radius)
  4*Math::PI/3*radius**3
end

# sphere has radius of 11
sphere_volume = sphere_volume(11)
puts "the volume of the sphere is #{sphere_volume} cm^3"
...

radius = calculate_radius
volume = sphere_volume(radius)
sphere.volume = volume</code></pre>
<p>Why is it a good idea to abstract the formula for a sphere's volume into its own method? Because if mathematicians ever found out they got the formula wrong, you would want to go through all the places in your code that you used the formula and update it to be correct. That is, we know ahead of time that we want the code to be in lockstep. This is as safe a gamble as you can get.</p>
<h3>Over-abstraction examples</h3>
<p>The main sign that you're over-abstracting is that your method accepts a bunch of optional args:</p>
<h4>Example: Bloated method</h4>
<h5>Bad:</h5>
<pre><code>def average(arr, type = Integer, ignore_nulls = false)
  if arr.any?(&amp;:nil?)
    if ignore_nulls
      arr = arr.compact
    else
      return nil
    end
  end

  if type == String
    arr = arr.map(&amp;:to_i)
  end

  arr.sum / arr.size
end

puts average([1,2,3])
=&gt; 2

puts average(['1','2','3'], String)
=&gt; 2

puts average(['1','2','3', nil], String, true)
=&gt; 2

puts average([1, 2, 3, nil], Integer, false)
=&gt; nil</code></pre>
<p>If you want to know how the <code>average</code> method behaves when you're dealing with an array of strings with no <code>nil</code> values, you have to read through the first if condition which has nothing to do with your use case before reaching the code that does. Likewise if you want to know how the <code>average</code> method behaves when the array contains either nils or integers, the second if condition is irrelevant, but you'll still need to read through that to understand how the whole thing works.</p>
<p>If each of the use cases came up dozens or hundreds of times, maybe then it would make sense to retain the abstraction, but when the number of optional arguments is roughly equal to the number of different use cases, chances are you've got the wrong abstraction.</p>
<h5>Good:</h5>
<pre><code>def average(arr)
  arr.sum / arr.size
end

puts average([1,2,3])
=&gt; 2

arr = ['1','2','3'].map(&amp;:to_i)
puts average(arr)
=&gt; 2

arr = ['1','2','3', nil].compact.map(&amp;:to_i)
puts average(arr)
=&gt; 2

arr = [1, 2, 3, nil]
if arr.any?(&amp;:nil?)
  puts nil
else
  puts average(arr)
end
=&gt; nil</code></pre>
<p>In this case we're not removing the abstraction altogether: we're just keeping the part that actually applies to all cases. Now understanding the logic of any one invocation of our <code>average</code> method is trivial.</p>
<p>We now have <code>.map(&amp;:to_i)</code> being duplicated whereas it only appeared once in the <code>Bad</code> alternative, but it's a small cost for a vast improvement.</p>
<p>Note that looking at the <code>Good</code> variant, it's clear that the behaviour is quite different from one use case to the next, but that is not at all clear in the <code>Bad</code> variant because the method calls all look so simple and it was anybody's guess how much code inside <code>average</code> applied to each use case.</p>
<p>This is why abstractions go bad over time: because as you expand the interface more and more, it becomes harder and harder to judge how appropriate the abstraction is to any given use case, and developers end up assuming that all that convoluted code is vaguely relevant to the majority of use cases when in fact it's not.</p>
<h4>Example: Awkward class</h4>
<h5>Bad:</h5>
<pre><code>class Shape
  def initialize(radius: nil, width: nil, type:)
    @radius = radius
    @width = width
    @type = type
  end

  def area
    case @type
    when :square
      @width ** 2
    when :circle
      (@radius ** 2) * Math::PI
    end
  end

  def perimeter
    case @type
    when :square
      @width * 4
    when :circle
      @radius * 2 * Math::PI
    end
  end

  def diameter
    case @type
    when :square
      nil
    when :circle
 …</code></pre></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jesseduffield.com/beginners-guide-to-abstraction/">https://jesseduffield.com/beginners-guide-to-abstraction/</a></em></p>]]>
            </description>
            <link>https://jesseduffield.com/beginners-guide-to-abstraction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23735991</guid>
            <pubDate>Sun, 05 Jul 2020 01:12:40 GMT</pubDate>
        </item>
    </channel>
</rss>
